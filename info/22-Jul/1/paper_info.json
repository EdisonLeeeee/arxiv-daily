[
  {
    "id": "arXiv:2206.14841",
    "title": "Causality for Inherently Explainable Transformers: CAT-XPLAIN",
    "abstract": "There have been several post-hoc explanation approaches developed to explain\npre-trained black-box neural networks. However, there is still a gap in\nresearch efforts toward designing neural networks that are inherently\nexplainable. In this paper, we utilize a recently proposed instance-wise\npost-hoc causal explanation method to make an existing transformer architecture\ninherently explainable. Once trained, our model provides an explanation in the\nform of top-$k$ regions in the input space of the given instance contributing\nto its decision. We evaluate our method on binary classification tasks using\nthree image datasets: MNIST, FMNIST, and CIFAR. Our results demonstrate that\ncompared to the causality-based post-hoc explainer model, our inherently\nexplainable model achieves better explainability results while eliminating the\nneed of training a separate explainer model. Our code is available at\nhttps://github.com/mvrl/CAT-XPLAIN.",
    "descriptor": "\nComments: Accepted for spotlight presentation at the Explainable Artificial Intelligence for Computer Vision Workshop at CVPR 2022\n",
    "authors": [
      "Subash Khanal",
      "Benjamin Brodie",
      "Xin Xing",
      "Ai-Ling Lin",
      "Nathan Jacobs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14841"
  },
  {
    "id": "arXiv:2206.14846",
    "title": "Provably Efficient Reinforcement Learning for Online Adaptive Influence  Maximization",
    "abstract": "Online influence maximization aims to maximize the influence spread of a\ncontent in a social network with unknown network model by selecting a few seed\nnodes. Recent studies followed a non-adaptive setting, where the seed nodes are\nselected before the start of the diffusion process and network parameters are\nupdated when the diffusion stops. We consider an adaptive version of\ncontent-dependent online influence maximization problem where the seed nodes\nare sequentially activated based on real-time feedback. In this paper, we\nformulate the problem as an infinite-horizon discounted MDP under a linear\ndiffusion process and present a model-based reinforcement learning solution.\nOur algorithm maintains a network model estimate and selects seed users\nadaptively, exploring the social network while improving the optimal policy\noptimistically. We establish $\\widetilde O(\\sqrt{T})$ regret bound for our\nalgorithm. Empirical evaluations on synthetic network demonstrate the\nefficiency of our algorithm.",
    "descriptor": "",
    "authors": [
      "Kaixuan Huang",
      "Yu Wu",
      "Xuezhou Zhang",
      "Shenyinying Tu",
      "Qingyun Wu",
      "Mengdi Wang",
      "Huazheng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14846"
  },
  {
    "id": "arXiv:2206.14853",
    "title": "Fairness via In-Processing in the Over-parameterized Regime: A  Cautionary Tale",
    "abstract": "The success of DNNs is driven by the counter-intuitive ability of\nover-parameterized networks to generalize, even when they perfectly fit the\ntraining data. In practice, test error often continues to decrease with\nincreasing over-parameterization, referred to as double descent. This allows\npractitioners to instantiate large models without having to worry about\nover-fitting. Despite its benefits, however, prior work has shown that\nover-parameterization can exacerbate bias against minority subgroups. Several\nfairness-constrained DNN training methods have been proposed to address this\nconcern. Here, we critically examine MinDiff, a fairness-constrained training\nprocedure implemented within TensorFlow's Responsible AI Toolkit, that aims to\nachieve Equality of Opportunity. We show that although MinDiff improves\nfairness for under-parameterized models, it is likely to be ineffective in the\nover-parameterized regime. This is because an overfit model with zero training\nloss is trivially group-wise fair on training data, creating an \"illusion of\nfairness,\" thus turning off the MinDiff optimization (this will apply to any\ndisparity-based measures which care about errors or accuracy. It won't apply to\ndemographic parity). Within specified fairness constraints, under-parameterized\nMinDiff models can even have lower error compared to their over-parameterized\ncounterparts (despite baseline over-parameterized models having lower error).\nWe further show that MinDiff optimization is very sensitive to choice of batch\nsize in the under-parameterized regime. Thus, fair model training using MinDiff\nrequires time-consuming hyper-parameter searches. Finally, we suggest using\npreviously proposed regularization techniques, viz. L2, early stopping and\nflooding in conjunction with MinDiff to train fair over-parameterized models.",
    "descriptor": "",
    "authors": [
      "Akshaj Kumar Veldanda",
      "Ivan Brugere",
      "Jiahao Chen",
      "Sanghamitra Dutta",
      "Alan Mishler",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.14853"
  },
  {
    "id": "arXiv:2206.14854",
    "title": "Neural Motion Fields: Encoding Grasp Trajectories as Implicit Value  Functions",
    "abstract": "The pipeline of current robotic pick-and-place methods typically consists of\nseveral stages: grasp pose detection, finding inverse kinematic solutions for\nthe detected poses, planning a collision-free trajectory, and then executing\nthe open-loop trajectory to the grasp pose with a low-level tracking\ncontroller. While these grasping methods have shown good performance on\ngrasping static objects on a table-top, the problem of grasping dynamic objects\nin constrained environments remains an open problem. We present Neural Motion\nFields, a novel object representation which encodes both object point clouds\nand the relative task trajectories as an implicit value function parameterized\nby a neural network. This object-centric representation models a continuous\ndistribution over the SE(3) space and allows us to perform grasping reactively\nby leveraging sampling-based MPC to optimize this value function.",
    "descriptor": "\nComments: RSS 2022 Workshop on Implicit Representations for Robotic Manipulation\n",
    "authors": [
      "Yun-Chun Chen",
      "Adithyavairavan Murali",
      "Balakumar Sundaralingam",
      "Wei Yang",
      "Animesh Garg",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14854"
  },
  {
    "id": "arXiv:2206.14855",
    "title": "SoK: Content Moderation in Social Media, from Guidelines to Enforcement,  and Research to Practice",
    "abstract": "To counter online abuse and misinformation, social media platforms have been\nestablishing content moderation guidelines and employing various moderation\npolicies. The goal of this paper is to study these community guidelines and\nmoderation practices, as well as the relevant research publications to identify\nthe research gaps, differences in moderation techniques, and challenges that\nshould be tackled by the social media platforms and the research community at\nlarge. In this regard, we study and analyze in the US jurisdiction the fourteen\nmost popular social media content moderation guidelines and practices, and\nconsolidate them. We then introduce three taxonomies drawn from this analysis\nas well as covering over one hundred interdisciplinary research papers about\nmoderation strategies. We identified the differences between the content\nmoderation employed in mainstream social media platforms compared to fringe\nplatforms. We also highlight the implications of Section 230, the need for\ntransparency and opacity in content moderation, why platforms should shift from\na one-size-fits-all model to a more inclusive model, and lastly, we highlight\nwhy there is a need for a collaborative human-AI system.",
    "descriptor": "",
    "authors": [
      "Mohit Singhal",
      "Chen Ling",
      "Nihal Kumarswamy",
      "Gianluca Stringhini",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.14855"
  },
  {
    "id": "arXiv:2206.14858",
    "title": "Solving Quantitative Reasoning Problems with Language Models",
    "abstract": "Language models have achieved remarkable performance on a wide range of tasks\nthat require natural language understanding. Nevertheless, state-of-the-art\nmodels have generally struggled with tasks that require quantitative reasoning,\nsuch as solving mathematics, science, and engineering problems at the college\nlevel. To help close this gap, we introduce Minerva, a large language model\npretrained on general natural language data and further trained on technical\ncontent. The model achieves state-of-the-art performance on technical\nbenchmarks without the use of external tools. We also evaluate our model on\nover two hundred undergraduate-level problems in physics, biology, chemistry,\neconomics, and other sciences that require quantitative reasoning, and find\nthat the model can correctly answer nearly a third of them.",
    "descriptor": "\nComments: 12 pages, 5 figures + references and appendices\n",
    "authors": [
      "Aitor Lewkowycz",
      "Anders Andreassen",
      "David Dohan",
      "Ethan Dyer",
      "Henryk Michalewski",
      "Vinay Ramasesh",
      "Ambrose Slone",
      "Cem Anil",
      "Imanol Schlag",
      "Theo Gutman-Solo",
      "Yuhuai Wu",
      "Behnam Neyshabur",
      "Guy Gur-Ari",
      "Vedant Misra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14858"
  },
  {
    "id": "arXiv:2206.14862",
    "title": "Momentum Diminishes the Effect of Spectral Bias in Physics-Informed  Neural Networks",
    "abstract": "Physics-informed neural network (PINN) algorithms have shown promising\nresults in solving a wide range of problems involving partial differential\nequations (PDEs). However, they often fail to converge to desirable solutions\nwhen the target function contains high-frequency features, due to a phenomenon\nknown as spectral bias. In the present work, we exploit neural tangent kernels\n(NTKs) to investigate the training dynamics of PINNs evolving under stochastic\ngradient descent with momentum (SGDM). This demonstrates SGDM significantly\nreduces the effect of spectral bias. We have also examined why training a model\nvia the Adam optimizer can accelerate the convergence while reducing the\nspectral bias. Moreover, our numerical experiments have confirmed that\nwide-enough networks using SGDM still converge to desirable solutions, even in\nthe presence of high-frequency features. In fact, we show that the width of a\nnetwork plays a critical role in convergence.",
    "descriptor": "",
    "authors": [
      "Ghazal Farhani",
      "Alexander Kazachek",
      "Boyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14862"
  },
  {
    "id": "arXiv:2206.14863",
    "title": "Mapping the Design Space of Human-AI Interaction in Text Summarization",
    "abstract": "Automatic text summarization systems commonly involve humans for preparing\ndata or evaluating model performance, yet, there lacks a systematic\nunderstanding of humans' roles, experience, and needs when interacting with or\nbeing assisted by AI. From a human-centered perspective, we map the design\nopportunities and considerations for human-AI interaction in text summarization\nand broader text generation tasks. We first conducted a systematic literature\nreview of 70 papers, developing a taxonomy of five interactions in AI-assisted\ntext generation and relevant design dimensions. We designed text summarization\nprototypes for each interaction. We then interviewed 16 users, aided by the\nprototypes, to understand their expectations, experience, and needs regarding\nefficiency, control, and trust with AI in text summarization and propose design\nconsiderations accordingly.",
    "descriptor": "",
    "authors": [
      "Ruijia Cheng",
      "Alison Smith-Renner",
      "Ke Zhang",
      "Joel R. Tetreault",
      "Alejandro Jaimes"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.14863"
  },
  {
    "id": "arXiv:2206.14867",
    "title": "In-plane prestressing: Inspiration from a hair clip",
    "abstract": "Structural instability is a hazard that leads to catastrophic failure and is\ngenerally avoided through special designs. A trend, however, has emerged over\nthe past decades pointing to the harnessing of mechanisms with instability.\nInspired by the snapping of a hair clip, we are finessing the unique\ncharacteristics of the lateral-torsional buckling of beams and the snap-through\nof pre-buckled dome-like thin-wall structures in a new field: the in-plane\nprestressed mechanism. Analyses reveal how the 2D-3D assembly of an in-plane\nprestressed actuator (IPA) is achieved and how the post-buckling energy\nlandscape is pictured. Combining them with soft robotics, we show that the\ninclusion of a bistable IPA can enormously enhance the performance of an\nunderwater fish robot as well as inspire a finger-like soft gripper.",
    "descriptor": "",
    "authors": [
      "Zechen Xiong",
      "Liqi Chen",
      "Wenxiong Hao",
      "Pengfei Yang",
      "Xi Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.14867"
  },
  {
    "id": "arXiv:2206.14868",
    "title": "Teach me how to Interpolate a Myriad of Embeddings",
    "abstract": "Mixup refers to interpolation-based data augmentation, originally motivated\nas a way to go beyond empirical risk minimization (ERM). Yet, its extensions\nfocus on the definition of interpolation and the space where it takes place,\nwhile the augmentation itself is less studied: For a mini-batch of size $m$,\nmost methods interpolate between $m$ pairs with a single scalar interpolation\nfactor $\\lambda$.\nIn this work, we make progress in this direction by introducing MultiMix,\nwhich interpolates an arbitrary number $n$ of tuples, each of length $m$, with\none vector $\\lambda$ per tuple. On sequence data, we further extend to dense\ninterpolation and loss computation over all spatial positions. Overall, we\nincrease the number of tuples per mini-batch by orders of magnitude at little\nadditional cost. This is possible by interpolating at the very last layer\nbefore the classifier. Finally, to address inconsistencies due to linear target\ninterpolation, we introduce a self-distillation approach to generate and\ninterpolate synthetic targets.\nWe empirically show that our contributions result in significant improvement\nover state-of-the-art mixup methods on four benchmarks. By analyzing the\nembedding space, we observe that the classes are more tightly clustered and\nuniformly spread over the embedding space, thereby explaining the improved\nbehavior.",
    "descriptor": "",
    "authors": [
      "Shashanka Venkataramanan",
      "Ewa Kijak",
      "Laurent Amsaleg",
      "Yannis Avrithis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14868"
  },
  {
    "id": "arXiv:2206.14879",
    "title": "Programming Languages and Law: A Research Agenda",
    "abstract": "If code is law, then the language of law is a programming language. Lawyers\nand legal scholars can learn about law by studying programming-language theory,\nand programming-language tools can be usefully applied to legal problems. This\narticle surveys the history of research on programming languages and law and\npresents ten promising avenues for future efforts. Its goals are to explain how\nthe combination of programming languages and law is distinctive within the\nbroader field of computer science and law, and to demonstrate with concrete\nexamples the remarkable power of programming-language concepts in this new\ndomain.",
    "descriptor": "",
    "authors": [
      "James Grimmelmann"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.14879"
  },
  {
    "id": "arXiv:2206.14885",
    "title": "Space-Efficient Representation of Entity-centric Query Language Models",
    "abstract": "Virtual assistants make use of automatic speech recognition (ASR) to help\nusers answer entity-centric queries. However, spoken entity recognition is a\ndifficult problem, due to the large number of frequently-changing named\nentities. In addition, resources available for recognition are constrained when\nASR is performed on-device.\nIn this work, we investigate the use of probabilistic grammars as language\nmodels within the finite-state transducer (FST) framework. We introduce a\ndeterministic approximation to probabilistic grammars that avoids the explicit\nexpansion of non-terminals at model creation time, integrates directly with the\nFST framework, and is complementary to n-gram models.\nWe obtain a 10% relative word error rate improvement on long tail entity\nqueries compared to when a similarly-sized n-gram model is used without our\nmethod.",
    "descriptor": "\nComments: Interspeech '22\n",
    "authors": [
      "Christophe Van Gysel",
      "Mirko Hannemann",
      "Ernest Pusateri",
      "Youssef Oualil",
      "Ilya Oparin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14885"
  },
  {
    "id": "arXiv:2206.14892",
    "title": "Semantic Unfolding of StyleGAN Latent Space",
    "abstract": "Generative adversarial networks (GANs) have proven to be surprisingly\nefficient for image editing by inverting and manipulating the latent code\ncorresponding to an input real image. This editing property emerges from the\ndisentangled nature of the latent space. In this paper, we identify that the\nfacial attribute disentanglement is not optimal, thus facial editing relying on\nlinear attribute separation is flawed. We thus propose to improve semantic\ndisentanglement with supervision. Our method consists in learning a proxy\nlatent representation using normalizing flows, and we show that this leads to a\nmore efficient space for face image editing.",
    "descriptor": "\nComments: Accepted at ICIP22\n",
    "authors": [
      "Mustafa Shukor",
      "Xu Yao",
      "Bharath Bushan Damodaran",
      "Pierre Hellier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14892"
  },
  {
    "id": "arXiv:2206.14897",
    "title": "Discrete Langevin Sampler via Wasserstein Gradient Flow",
    "abstract": "Recently, a family of locally balanced (LB) samplers has demonstrated\nexcellent performance at sampling and learning energy-based models (EBMs) in\ndiscrete spaces. However, the theoretical understanding of this success is\nlimited. In this work, we show how LB functions give rise to LB dynamics\ncorresponding to Wasserstein gradient flow in a discrete space. From first\nprinciples, previous LB samplers can then be seen as discretizations of the LB\ndynamics with respect to Hamming distance. Based on this observation, we\npropose a new algorithm, the Locally Balanced Jump (LBJ), by discretizing the\nLB dynamics with respect to simulation time. As a result, LBJ has a\nlocation-dependent \"velocity\" that allows it to make proposals with larger\ndistances. Additionally, LBJ decouples each dimension into independent\nsub-processes, enabling convenient parallel implementation. We demonstrate the\nadvantages of LBJ for sampling and learning in various binary and categorical\ndistributions.",
    "descriptor": "",
    "authors": [
      "Haoran Sun",
      "Hanjun Dai",
      "Bo Dai",
      "Haomin Zhou",
      "Dale Schuurmans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14897"
  },
  {
    "id": "arXiv:2206.14898",
    "title": "Recognizing Map Graphs of Bounded Treewidth",
    "abstract": "A map graph is a graph admitting a representation in which vertices are\nnations on a spherical map and edges are shared curve segments or points\nbetween nations. We present an explicit fixed-parameter tractable algorithm for\nrecognizing map graphs parameterized by treewidth. The algorithm has time\ncomplexity that is linear in the size of the graph and, if the input is a\nyes-instance, it reports a certificate in the form of a so-called witness.\nFurthermore, this result is developed within a more general algorithmic\nframework that allows to test, for any $k$, if the input graph admits a $k$-map\n(where at most $k$ nations meet at a common point) or a hole-free~$k$-map\n(where each point of the sphere is covered by at least one nation). We point\nout that, although bounding the treewidth of the input graph also bounds the\nsize of its largest clique, the latter alone does not seem to be a strong\nenough structural limitation to obtain an efficient time complexity. In fact,\nwhile the largest clique in a $k$-map graph is $\\lfloor 3k/2 \\rfloor$, the\nrecognition of $k$-map graphs is still open for any fixed $k \\ge 5$.",
    "descriptor": "",
    "authors": [
      "Patrizio Angelini",
      "Michael A. Bekos",
      "Giordano Da Lozzo",
      "Martin Gronemann",
      "Fabrizio Montecchiani",
      "Alessandra Tappini"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.14898"
  },
  {
    "id": "arXiv:2206.14905",
    "title": "Generalized Pseudoskeleton Decompositions",
    "abstract": "We characterize some variations of pseudoskeleton (also called CUR)\ndecompositions for matrices and tensors over arbitrary fields. These\ncharacterizations extend previous results to arbitrary fields and to\ndecompositions which use generalized inverses of the constituent matrices, in\ncontrast to Moore--Penrose pseudoinverses in prior works which are specific to\nreal or complex valued matrices, and are significantly more structured.",
    "descriptor": "",
    "authors": [
      "Keaton Hamm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14905"
  },
  {
    "id": "arXiv:2206.14906",
    "title": "A Best-of-Both-Worlds Algorithm for Bandits with Delayed Feedback",
    "abstract": "We present a modified tuning of the algorithm of Zimmert and Seldin [2020]\nfor adversarial multiarmed bandits with delayed feedback, which in addition to\nthe minimax optimal adversarial regret guarantee shown by Zimmert and Seldin\nsimultaneously achieves a near-optimal regret guarantee in the stochastic\nsetting with fixed delays. Specifically, the adversarial regret guarantee is\n$\\mathcal{O}(\\sqrt{TK} + \\sqrt{dT\\log K})$, where $T$ is the time horizon, $K$\nis the number of arms, and $d$ is the fixed delay, whereas the stochastic\nregret guarantee is $\\mathcal{O}\\left(\\sum_{i \\neq i^*}(\\frac{1}{\\Delta_i}\n\\log(T) + \\frac{d}{\\Delta_{i}\\log K}) + d K^{1/3}\\log K\\right)$, where\n$\\Delta_i$ are the suboptimality gaps. We also present an extension of the\nalgorithm to the case of arbitrary delays, which is based on an oracle\nknowledge of the maximal delay $d_{max}$ and achieves $\\mathcal{O}(\\sqrt{TK} +\n\\sqrt{D\\log K} + d_{max}K^{1/3} \\log K)$ regret in the adversarial regime,\nwhere $D$ is the total delay, and $\\mathcal{O}\\left(\\sum_{i \\neq\ni^*}(\\frac{1}{\\Delta_i} \\log(T) + \\frac{\\sigma_{max}}{\\Delta_{i}\\log K}) +\nd_{max}K^{1/3}\\log K\\right)$ regret in the stochastic regime, where\n$\\sigma_{max}$ is the maximal number of outstanding observations. Finally, we\npresent a lower bound that matches regret upper bound achieved by the skipping\ntechnique of Zimmert and Seldin [2020] in the adversarial setting.",
    "descriptor": "",
    "authors": [
      "Saeed Masoudian",
      "Julian Zimmert",
      "Yevgeny Seldin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14906"
  },
  {
    "id": "arXiv:2206.14909",
    "title": "RAC Drawings of Graphs with Low Degree",
    "abstract": "Motivated by cognitive experiments providing evidence that large\ncrossing-angles do not impair the readability of a graph drawing, RAC (Right\nAngle Crossing) drawings were introduced to address the problem of producing\nreadable representations of non-planar graphs by supporting the optimal case in\nwhich all crossings form 90{\\deg} angles. In this work, we make progress on the\nproblem of finding RAC drawings of graphs of low degree. In this context, a\nlong-standing open question asks whether all degree-3 graphs admit\nstraight-line RAC drawings. This question has been positively answered for the\nHamiltonian degree-3 graphs. We improve on this result by extending to the\nclass of 3-edge-colorable degree-3 graphs. When each edge is allowed to have\none bend, we prove that degree-4 graphs admit such RAC drawings, a result which\nwas previously known only for degree-3 graphs. Finally, we show that\n7-edge-colorable degree-7 graphs admit RAC drawings with two bends per edge.\nThis improves over the previous result on degree-6 graphs.",
    "descriptor": "\nComments: Extended version of a paper presented at MFCS 2022\n",
    "authors": [
      "Patrizio Angelini",
      "Michael A. Bekos",
      "Julia Katheder",
      "Michael Kaufmann",
      "Maximilian Pfister"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.14909"
  },
  {
    "id": "arXiv:2206.14911",
    "title": "Minimum Weight Euclidean $(1+\\varepsilon)$-Spanners",
    "abstract": "Given a set $S$ of $n$ points in the plane and a parameter $\\varepsilon>0$, a\nEuclidean $(1+\\varepsilon)$-spanner is a geometric graph $G=(S,E)$ that\ncontains a path of weight at most $(1+\\varepsilon)\\|pq\\|_2$ for all $p,q\\in S$.\nWe show that the minimum weight of a Euclidean $(1+\\varepsilon)$-spanner for\n$n$ points in the unit square $[0,1]^2$ is $O(\\varepsilon^{-3/2}\\,\\sqrt{n})$,\nand this bound is the best possible. The upper bound is based on a new spanner\nalgorithm that sparsifies Yao-graphs. It improves upon the baseline\n$O(\\varepsilon^{-2}\\sqrt{n})$, obtained by combining a tight bound for the\nweight of an MST and a tight bound for the lightness of Euclidean\n$(1+\\varepsilon)$-spanners, which is the ratio of the spanner weight to the\nweight of the MST. The result generalizes to $d$-space for all $d\\in\n\\mathbb{N}$: The minimum weight of a Euclidean $(1+\\varepsilon)$-spanner for\n$n$ points in the unit cube $[0,1]^d$ is\n$O_d(\\varepsilon^{(1-d^2)/d}n^{(d-1)/d})$, and this bound is the best possible.\nFor the $n\\times n$ section of the integer lattice, we show that the minimum\nweight of a Euclidean $(1+\\varepsilon)$-spanner is between\n$\\Omega(\\varepsilon^{-3/4}n^2)$ and $O(\\varepsilon^{-1}\\log(\\varepsilon^{-1})\\,\nn^2)$. These bounds become $\\Omega(\\varepsilon^{-3/4}\\sqrt{n})$ and\n$O(\\varepsilon^{-1}\\log (\\varepsilon^{-1})\\sqrt{n})$ when scaled to a grid of\n$n$ points in the unit square.",
    "descriptor": "\nComments: 25 pages, 9 figures. An extended abstract appears in the Proceedings of WG 2022\n",
    "authors": [
      "Csaba D. T\u00f3th"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.14911"
  },
  {
    "id": "arXiv:2206.14912",
    "title": "Best of Both Worlds Model Selection",
    "abstract": "We study the problem of model selection in bandit scenarios in the presence\nof nested policy classes, with the goal of obtaining simultaneous adversarial\nand stochastic (\"best of both worlds\") high-probability regret guarantees. Our\napproach requires that each base learner comes with a candidate regret bound\nthat may or may not hold, while our meta algorithm plays each base learner\naccording to a schedule that keeps the base learner's candidate regret bounds\nbalanced until they are detected to violate their guarantees. We develop\ncareful mis-specification tests specifically designed to blend the above model\nselection criterion with the ability to leverage the (potentially benign)\nnature of the environment. We recover the model selection guarantees of the\nCORRAL algorithm for adversarial environments, but with the additional benefit\nof achieving high probability regret bounds, specifically in the case of nested\nadversarial linear bandits. More importantly, our model selection results also\nhold simultaneously in stochastic environments under gap assumptions. These are\nthe first theoretical results that achieve best of both world (stochastic and\nadversarial) guarantees while performing model selection in (linear) bandit\nscenarios.",
    "descriptor": "\nComments: 10 pages in main, 43 pages appendix\n",
    "authors": [
      "Aldo Pacchiano",
      "Christoph Dann",
      "Claudio Gentile"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14912"
  },
  {
    "id": "arXiv:2206.14913",
    "title": "GPTs at Factify 2022: Prompt Aided Fact-Verification",
    "abstract": "One of the most pressing societal issues is the fight against false news. The\nfalse claims, as difficult as they are to expose, create a lot of damage. To\ntackle the problem, fact verification becomes crucial and thus has been a topic\nof interest among diverse research communities. Using only the textual form of\ndata we propose our solution to the problem and achieve competitive results\nwith other approaches. We present our solution based on two approaches - PLM\n(pre-trained language model) based method and Prompt based method. The\nPLM-based approach uses the traditional supervised learning, where the model is\ntrained to take 'x' as input and output prediction 'y' as P(y|x). Whereas,\nPrompt-based learning reflects the idea to design input to fit the model such\nthat the original objective may be re-framed as a problem of (masked) language\nmodeling. We may further stimulate the rich knowledge provided by PLMs to\nbetter serve downstream tasks by employing extra prompts to fine-tune PLMs. Our\nexperiments showed that the proposed method performs better than just\nfine-tuning PLMs. We achieved an F1 score of 0.6946 on the FACTIFY dataset and\na 7th position on the competition leader-board.",
    "descriptor": "\nComments: Accepted in AAAI'22: First Workshop on Multimodal Fact-Checking and Hate Speech Detection, Februrary 22 - March 1, 2022,Vancouver, BC, Canada\n",
    "authors": [
      "Pawan Kumar Sahu",
      "Saksham Aggarwal",
      "Taneesh Gupta",
      "Gyanendra Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.14913"
  },
  {
    "id": "arXiv:2206.14923",
    "title": "On Non-Random Missing Labels in Semi-Supervised Learning",
    "abstract": "Semi-Supervised Learning (SSL) is fundamentally a missing label problem, in\nwhich the label Missing Not At Random (MNAR) problem is more realistic and\nchallenging, compared to the widely-adopted yet naive Missing Completely At\nRandom assumption where both labeled and unlabeled data share the same class\ndistribution. Different from existing SSL solutions that overlook the role of\n\"class\" in causing the non-randomness, e.g., users are more likely to label\npopular classes, we explicitly incorporate \"class\" into SSL. Our method is\nthree-fold: 1) We propose Class-Aware Propensity (CAP) that exploits the\nunlabeled data to train an improved classifier using the biased labeled data.\n2) To encourage rare class training, whose model is low-recall but\nhigh-precision that discards too many pseudo-labeled data, we propose\nClass-Aware Imputation (CAI) that dynamically decreases (or increases) the\npseudo-label assignment threshold for rare (or frequent) classes. 3) Overall,\nwe integrate CAP and CAI into a Class-Aware Doubly Robust (CADR) estimator for\ntraining an unbiased SSL model. Under various MNAR settings and ablations, our\nmethod not only significantly outperforms existing baselines but also surpasses\nother label bias removal SSL methods. Please check our code at:\nhttps://github.com/JoyHuYY1412/CADR-FixMatch.",
    "descriptor": "",
    "authors": [
      "Xinting Hu",
      "Yulei Niu",
      "Chunyan Miao",
      "Xian-Sheng Hua",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14923"
  },
  {
    "id": "arXiv:2206.14925",
    "title": "ComDensE : Combined Dense Embedding of Relation-aware and Common  Features for Knowledge Graph Completion",
    "abstract": "Real-world knowledge graphs (KG) are mostly incomplete. The problem of\nrecovering missing relations, called KG completion, has recently become an\nactive research area. Knowledge graph (KG) embedding, a low-dimensional\nrepresentation of entities and relations, is the crucial technique for KG\ncompletion. Convolutional neural networks in models such as ConvE, SACN,\nInteractE, and RGCN achieve recent successes. This paper takes a different\narchitectural view and proposes ComDensE which combines relation-aware and\ncommon features using dense neural networks. In the relation-aware feature\nextraction, we attempt to create relational inductive bias by applying an\nencoding function specific to each relation. In the common feature extraction,\nwe apply the common encoding function to all input embeddings. These encoding\nfunctions are implemented using dense layers in ComDensE. ComDensE achieves the\nstate-of-the-art performance in the link prediction in terms of MRR, HIT@1 on\nFB15k-237 and HIT@1 on WN18RR compared to the previous baseline approaches. We\nconduct an extensive ablation study to examine the effects of the\nrelation-aware layer and the common layer of the ComDensE. Experimental results\nillustrate that the combined dense architecture as implemented in ComDensE\nachieves the best performance.",
    "descriptor": "\nComments: International Conference on Pattern Recognition 2022, Accepted\n",
    "authors": [
      "Minsang Kim",
      "Seungjun Baek"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14925"
  },
  {
    "id": "arXiv:2206.14927",
    "title": "AFAFed -- Protocol analysis",
    "abstract": "In this paper, we design, analyze the convergence properties and address the\nimplementation aspects of AFAFed. This is a novel Asynchronous Fair Adaptive\nFederated learning framework for stream-oriented IoT application environments,\nwhich are featured by time-varying operating conditions, heterogeneous\nresource-limited devices (i.e., coworkers), non-i.i.d. local training data and\nunreliable communication links. The key new of AFAFed is the synergic co-design\nof: (i) two sets of adaptively tuned tolerance thresholds and fairness\ncoefficients at the coworkers and central server, respectively; and, (ii) a\ndistributed adaptive mechanism, which allows each coworker to adaptively tune\nown communication rate. The convergence properties of AFAFed under (possibly)\nnon-convex loss functions is guaranteed by a set of new analytical bounds,\nwhich formally unveil the impact on the resulting AFAFed convergence rate of a\nnumber of Federated Learning (FL) parameters, like, first and second moments of\nthe per-coworker number of consecutive model updates, data skewness,\ncommunication packet-loss probability, and maximum/minimum values of the\n(adaptively tuned) mixing coefficient used for model aggregation.",
    "descriptor": "",
    "authors": [
      "Enzo Baccarelli",
      "Michele Scarpiniti",
      "Alireza Momenzadeh",
      "Sima Sarv Ahrabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.14927"
  },
  {
    "id": "arXiv:2206.14928",
    "title": "Manifold Interpolating Optimal-Transport Flows for Trajectory Inference",
    "abstract": "Here, we present a method called Manifold Interpolating Optimal-Transport\nFlow (MIOFlow) that learns stochastic, continuous population dynamics from\nstatic snapshot samples taken at sporadic timepoints. MIOFlow combines dynamic\nmodels, manifold learning, and optimal transport by training neural ordinary\ndifferential equations (Neural ODE) to interpolate between static population\nsnapshots as penalized by optimal transport with manifold ground distance.\nFurther, we ensure that the flow follows the geometry by operating in the\nlatent space of an autoencoder that we call a geodesic autoencoder (GAE). In\nGAE the latent space distance between points is regularized to match a novel\nmultiscale geodesic distance on the data manifold that we define. We show that\nthis method is superior to normalizing flows, Schr\\\"odinger bridges and other\ngenerative models that are designed to flow from noise to data in terms of\ninterpolating between populations. Theoretically, we link these trajectories\nwith dynamic optimal transport. We evaluate our method on simulated data with\nbifurcations and merges, as well as scRNA-seq data from embryoid body\ndifferentiation, and acute myeloid leukemia treatment.",
    "descriptor": "\nComments: 19 pages, 4 tables, 13 figures\n",
    "authors": [
      "Guillaume Huguet",
      "D.S. Magruder",
      "Oluwadamilola Fasina",
      "Alexander Tong",
      "Manik Kuchroo",
      "Guy Wolf",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14928"
  },
  {
    "id": "arXiv:2206.14932",
    "title": "A Data Science Pipeline for Algorithmic Trading: A Comparative Study of  Applications for Finance and Cryptoeconomics",
    "abstract": "Recent advances in Artificial Intelligence (AI) have made algorithmic trading\nplay a central role in finance. However, current research and applications are\ndisconnected information islands. We propose a generally applicable pipeline\nfor designing, programming, and evaluating the algorithmic trading of stock and\ncrypto assets. Moreover, we demonstrate how our data science pipeline works\nwith respect to four conventional algorithms: the moving average crossover,\nvolume-weighted average price, sentiment analysis, and statistical arbitrage\nalgorithms. Our study offers a systematic way to program, evaluate, and compare\ndifferent trading strategies. Furthermore, we implement our algorithms through\nobject-oriented programming in Python3, which serves as open-source software\nfor future academic research and applications.",
    "descriptor": "\nComments: Accepted at: The First International Symposium on Recent Advances of Blockchain Evolution: Architecture, Intelligence, Incentive, and Applications\n",
    "authors": [
      "Luyao Zhang",
      "Tianyu Wu",
      "Saad Lahrichi",
      "Carlos-Gustavo Salas-Flores",
      "Jiayi Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "General Economics (econ.GN)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2206.14932"
  },
  {
    "id": "arXiv:2206.14938",
    "title": "NeRF, meet differential geometry!",
    "abstract": "Neural radiance fields, or NeRF, represent a breakthrough in the field of\nnovel view synthesis and 3D modeling of complex scenes from multi-view image\ncollections. Numerous recent works have been focusing on making the models more\nrobust, by means of regularization, so as to be able to train with possibly\ninconsistent and/or very sparse data. In this work, we scratch the surface of\nhow differential geometry can provide regularization tools for robustly\ntraining NeRF-like models, which are modified so as to represent continuous and\ninfinitely differentiable functions. In particular, we show how these tools\nyield a direct mathematical formalism of previously proposed NeRF variants\naimed at improving the performance in challenging conditions (i.e. RegNeRF).\nBased on this, we show how the same formalism can be used to natively encourage\nthe regularity of surfaces (by means of Gaussian and Mean Curvatures) making it\npossible, for example, to learn surfaces from a very limited number of views.",
    "descriptor": "",
    "authors": [
      "Thibaud Ehret",
      "Roger Mar\u00ed",
      "Gabriele Facciolo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14938"
  },
  {
    "id": "arXiv:2206.14939",
    "title": "Towards Dual-band Reconfigurable Metamaterial Surfaces for Satellite  Networking",
    "abstract": "The first low earth orbit satellite networks for internet service have\nrecently been deployed and are growing in size, yet will face deployment\nchallenges in many practical circumstances of interest. This paper explores how\na dual-band, electronically tunable smart surface can enable dynamic beam\nalignment between the satellite and mobile users, make service possible in\nurban canyons, and improve service in rural areas. Our design is the first of\nits kind to target dual channels in the Ku radio frequency band with a novel\ndual Huygens resonator design that leverages radio reciprocity to allow our\nsurface to simultaneously steer and modulate energy in the satellite uplink and\ndownlink directions, and in both reflective and transmissive modes of\noperation. Our surface, Wall-E, is designed and evaluated in an electromagnetic\nsimulator and demonstrates 94% transmission efficiency and an 85% reflection\nefficiency, with at most 6 dB power loss at steering angles over a 150-degree\nfield of view for both transmission and reflection. With a 75 sq cm surface,\nour link budget calculations predict a 4 dB and 24 dB improvement in the SNR of\na link entering the window of a rural home in comparison to the free-space path\nand brick wall penetration, respectively.",
    "descriptor": "\nComments: 9 pages including references, 9 figures\n",
    "authors": [
      "Kun Woo Cho",
      "Yasaman Ghasempour",
      "Kyle Jamieson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.14939"
  },
  {
    "id": "arXiv:2206.14946",
    "title": "Paving the Way Towards Mobile IAB: Problems, Solutions and Challenges",
    "abstract": "Deploying access and backhaul as wireless links, a.k.a. integrated access and\nbackhaul (IAB), is envisioned as a viable approach to enable flexible and dense\nnetworks. Even further, mobile IAB (mIAB) is a candidate solution to enhance\nthe connectivity of user equipments (UEs) moving together. In this context,\ndifferent of other works from the literature, the present work overviews the\nbasis for the deployment of mIAB by presenting: 1) the current status of IAB\nstandardization in the fifth generation (5G) new radio (NR); 2) a new taxonomy\nfor state-of-the-art works regarding fixed IAB and mIAB; 3) an extensive\nperformance analysis of mIAB based on simulation results; and 4) open\nchallenges and potential future prospects of mIAB. Specifically, the proposed\ntaxonomy classifies IAB works according to different perspectives and\ncategorizes mIAB works according to the type of mobility. For each type of\nmobility, the main studied topics are presented. Regarding the performance\nevaluation, we consider an urban macro scenario where mIAB nodes are deployed\nin buses in order to improve the passengers connection. The results show that,\ncompared to other network architectures, the deployment of mIAB nodes\nremarkably improves the passengers throughput and latency in both downlink and\nuplink.",
    "descriptor": "\nComments: Submitted to \"IEEE Access\"\n",
    "authors": [
      "Victor F. Monteiro",
      "Fco. Rafael M. Lima",
      "Darlan C. Moreira",
      "Diego A. Sousa",
      "Tarcisio F. Maciel",
      "Behrooz Makki",
      "Hans Hannu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14946"
  },
  {
    "id": "arXiv:2206.14969",
    "title": "Masked Part-Of-Speech Model: Does Modeling Long Context Help  Unsupervised POS-tagging?",
    "abstract": "Previous Part-Of-Speech (POS) induction models usually assume certain\nindependence assumptions (e.g., Markov, unidirectional, local dependency) that\ndo not hold in real languages. For example, the subject-verb agreement can be\nboth long-term and bidirectional. To facilitate flexible dependency modeling,\nwe propose a Masked Part-of-Speech Model (MPoSM), inspired by the recent\nsuccess of Masked Language Models (MLM). MPoSM can model arbitrary tag\ndependency and perform POS induction through the objective of masked POS\nreconstruction. We achieve competitive results on both the English Penn WSJ\ndataset as well as the universal treebank containing 10 diverse languages.\nThough modeling the long-term dependency should ideally help this task, our\nablation study shows mixed trends in different languages. To better understand\nthis phenomenon, we design a novel synthetic experiment that can specifically\ndiagnose the model's ability to learn tag agreement. Surprisingly, we find that\neven strong baselines fail to solve this problem consistently in a very\nsimplified setting: the agreement between adjacent words. Nonetheless, MPoSM\nachieves overall better performance. Lastly, we conduct a detailed error\nanalysis to shed light on other remaining challenges. Our code is available at\nhttps://github.com/owenzx/MPoSM",
    "descriptor": "\nComments: NAACL 2022 (16 pages)\n",
    "authors": [
      "Xiang Zhou",
      "Shiyue Zhang",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14969"
  },
  {
    "id": "arXiv:2206.14970",
    "title": "Controlling Material Appearance by Examples",
    "abstract": "Despite the ubiquitousness of materials maps in modern rendering pipelines,\ntheir editing and control remains a challenge. In this paper, we present an\nexample-based material control method to augment input material maps based on\nuser-provided material photos. We train a tileable version of MaterialGAN and\nleverage its material prior to guide the appearance transfer, optimizing its\nlatent space using differentiable rendering. Our method transfers the micro and\nmeso-structure textures of user provided target(s) photographs, while\npreserving the structure of the input and quality of the input material. We\nshow our methods can control existing material maps, increasing realism or\ngenerating new, visually appealing materials.",
    "descriptor": "",
    "authors": [
      "Yiwei Hu",
      "Milo\u0161 Ha\u0161an",
      "Paul Guerrero",
      "Holly Rushmeier",
      "Valentin Deschaintre"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.14970"
  },
  {
    "id": "arXiv:2206.14971",
    "title": "Boosting 3D Object Detection by Simulating Multimodality on Point Clouds",
    "abstract": "This paper presents a new approach to boost a single-modality (LiDAR) 3D\nobject detector by teaching it to simulate features and responses that follow a\nmulti-modality (LiDAR-image) detector. The approach needs LiDAR-image data only\nwhen training the single-modality detector, and once well-trained, it only\nneeds LiDAR data at inference. We design a novel framework to realize the\napproach: response distillation to focus on the crucial response samples and\navoid the background samples; sparse-voxel distillation to learn voxel\nsemantics and relations from the estimated crucial voxels; a fine-grained\nvoxel-to-point distillation to better attend to features of small and distant\nobjects; and instance distillation to further enhance the deep-feature\nconsistency. Experimental results on the nuScenes dataset show that our\napproach outperforms all SOTA LiDAR-only 3D detectors and even surpasses the\nbaseline LiDAR-image detector on the key NDS metric, filling 72% mAP gap\nbetween the single- and multi-modality detectors.",
    "descriptor": "\nComments: Published in CVPR 2022 as Oral\n",
    "authors": [
      "Wu Zheng",
      "Mingxuan Hong",
      "Li Jiang",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14971"
  },
  {
    "id": "arXiv:2206.14972",
    "title": "Machine Learning Approaches to Predict Breast Cancer: Bangladesh  Perspective",
    "abstract": "Nowadays, Breast cancer has risen to become one of the most prominent causes\nof death in recent years. Among all malignancies, this is the most frequent and\nthe major cause of death for women globally. Manually diagnosing this disease\nrequires a good amount of time and expertise. Breast cancer detection is\ntime-consuming, and the spread of the disease can be reduced by developing\nmachine-based breast cancer predictions. In Machine learning, the system can\nlearn from prior instances and find hard-to-detect patterns from noisy or\ncomplicated data sets using various statistical, probabilistic, and\noptimization approaches. This work compares several machine learning\nalgorithm's classification accuracy, precision, sensitivity, and specificity on\na newly collected dataset. In this work Decision tree, Random Forest, Logistic\nRegression, Naive Bayes, and XGBoost, these five machine learning approaches\nhave been implemented to get the best performance on our dataset. This study\nfocuses on finding the best algorithm that can forecast breast cancer with\nmaximum accuracy in terms of its classes. This work evaluated the quality of\neach algorithm's data classification in terms of efficiency and effectiveness.\nAnd also compared with other published work on this domain. After implementing\nthe model, this study achieved the best model accuracy, 94% on Random Forest\nand XGBoost.",
    "descriptor": "\nComments: 15 pages, 9 figures, accepted for publication as a book chapter to 2nd International Conference on Ubiquitous Computing and Intelligent Information Systems\n",
    "authors": [
      "Taminul Islam",
      "Arindom Kundu",
      "Nazmul Islam Khan",
      "Choyon Chandra Bonik",
      "Flora Akter",
      "Md Jihadul Islam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14972"
  },
  {
    "id": "arXiv:2206.14973",
    "title": "Benchmarking the Robustness of Deep Neural Networks to Common  Corruptions in Digital Pathology",
    "abstract": "When designing a diagnostic model for a clinical application, it is crucial\nto guarantee the robustness of the model with respect to a wide range of image\ncorruptions. Herein, an easy-to-use benchmark is established to evaluate how\ndeep neural networks perform on corrupted pathology images. Specifically,\ncorrupted images are generated by injecting nine types of common corruptions\ninto validation images. Besides, two classification and one ranking metrics are\ndesigned to evaluate the prediction and confidence performance under\ncorruption. Evaluated on two resulting benchmark datasets, we find that (1) a\nvariety of deep neural network models suffer from a significant accuracy\ndecrease (double the error on clean images) and the unreliable confidence\nestimation on corrupted images; (2) A low correlation between the validation\nand test errors while replacing the validation set with our benchmark can\nincrease the correlation. Our codes are available on\nhttps://github.com/superjamessyx/robustness_benchmark.",
    "descriptor": "\nComments: MICAAI2022\n",
    "authors": [
      "Yunlong Zhang",
      "Yuxuan Sun",
      "Honglin Li",
      "Sunyi Zheng",
      "Chenglu Zhu",
      "Lin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14973"
  },
  {
    "id": "arXiv:2206.14976",
    "title": "Semi-Supervised Generative Adversarial Network for Stress Detection  Using Partially Labeled Physiological Data",
    "abstract": "Physiological measurements involves observing variables that attribute to the\nnormative functioning of human systems and subsystems directly or indirectly.\nThe measurements can be used to detect affective states of a person with aims\nsuch as improving human-computer interactions. There are several methods of\ncollecting physiological data, but wearable sensors are a common, non-invasive\ntool for accurate readings. However, valuable information is hard to extract\nfrom the raw physiological data, especially for affective state detection.\nMachine Learning techniques are used to detect the affective state of a person\nthrough labeled physiological data. A clear problem with using labeled data is\ncreating accurate labels. An expert is needed to analyze a form of recording of\nparticipants and mark sections with different states such as stress and calm.\nWhile expensive, this method delivers a complete dataset with labeled data that\ncan be used in any number of supervised algorithms. An interesting question\narises from the expensive labeling: how can we reduce the cost while\nmaintaining high accuracy? Semi-Supervised learning (SSL) is a potential\nsolution to this problem. These algorithms allow for machine learning models to\nbe trained with only a small subset of labeled data (unlike unsupervised which\nuse no labels). They provide a way of avoiding expensive labeling. This paper\ncompares a fully supervised algorithm to a SSL on the public WESAD (Wearable\nStress and Affect Detection) Dataset for stress detection. This paper shows\nthat Semi-Supervised algorithms are a viable method for inexpensive affective\nstate detection systems with accurate results.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Nibraas Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14976"
  },
  {
    "id": "arXiv:2206.14977",
    "title": "Multiple Targets Directed Greybox Fuzzing",
    "abstract": "Directed greybox fuzzing (DGF) can quickly discover or reproduce bugs in\nprograms by seeking to reach a program location or explore some locations in\norder. However, due to their static stage division and coarse-grained energy\nscheduling, prior DGF tools perform poorly when facing multiple target\nlocations (targets for short).\nIn this paper, we present multiple targets directed greybox fuzzing which\naims to reach multiple programs locations in a fuzzing campaign. Specifically,\nwe propose a novel strategy to adaptively coordinate exploration and\nexploitation stages, and a novel energy scheduling strategy by considering more\nrelations between seeds and target locations. We implement our approaches in a\ntool called LeoFuzz and evaluate it on crash reproduction, true positives\nverification, and vulnerability exposure in real-world programs. Experimental\nresults show that LeoFuzz outperforms six state-of-the-art fuzzers, i.e., QYSM,\nAFLGo, Lolly, Berry, Beacon and WindRanger in terms of effectiveness and\nefficiency. Moreover, LeoFuzz has detected 23 new vulnerabilities in real-world\nprograms, and 11 of them have been assigned CVE IDs.",
    "descriptor": "\nComments: 14 pages, 5 figures, 10 tables\n",
    "authors": [
      "Hongliang Liang",
      "Xianglin Cheng",
      "Jie Liu",
      "Jin Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.14977"
  },
  {
    "id": "arXiv:2206.14980",
    "title": "On the image of an affine subspace under the inverse function within a  finite field",
    "abstract": "We consider the function $x^{-1}$ that inverses a finite field element $x \\in\n\\mathbb{F}_{p^n}$ ($p$ is prime, $0^{-1} = 0$) and affine\n$\\mathbb{F}_{p}$-subspaces of $\\mathbb{F}_{p^n}$ such that their images are\naffine subspaces as well. It is proven that the image of an affine subspace\n$L$, $|L| > 2$, is an affine subspace if and only if $L = q \\mathbb{F}_{p^k}$,\nwhere $q \\in \\mathbb{F}_{p^n}^{*}$ and $k \\mid n$. In other words, it is either\na subfield of $\\mathbb{F}_{p^n}$ or a subspace consisting of all elements of a\nsubfield multiplied by $q$. This generalizes the results that were obtained for\nlinear invariant subspaces in 2006. As a consequence, we propose a sufficient\ncondition providing that a function $A(x^{-1}) + b$ has no invariant affine\nsubspaces $U$ of cardinality $2 < |U| < p^n$ for an invertible linear\ntransformation $A: \\mathbb{F}_{p^n} \\to \\mathbb{F}_{p^n}$ and $b \\in\n\\mathbb{F}_{p^n}^{*}$. As an example, it is shown that the condition works for\nS-box of AES. Also, we demonstrate that some functions of the form $\\alpha\nx^{-1} + b$ have no invariant affine subspaces except for $\\mathbb{F}_{p^n}$,\nwhere $\\alpha, b \\in \\mathbb{F}_{p^n}^{*}$ and $n$ is arbitrary.",
    "descriptor": "",
    "authors": [
      "Nikolay Kolomeec",
      "Denis Bykov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2206.14980"
  },
  {
    "id": "arXiv:2206.14982",
    "title": "Building Multilingual Machine Translation Systems That Serve Arbitrary  X-Y Translations",
    "abstract": "Multilingual Neural Machine Translation (MNMT) enables one system to\ntranslate sentences from multiple source languages to multiple target\nlanguages, greatly reducing deployment costs compared with conventional\nbilingual systems. The MNMT training benefit, however, is often limited to\nmany-to-one directions. The model suffers from poor performance in one-to-many\nand many-to-many with zero-shot setup. To address this issue, this paper\ndiscusses how to practically build MNMT systems that serve arbitrary X-Y\ntranslation directions while leveraging multilinguality with a two-stage\ntraining strategy of pretraining and finetuning. Experimenting with the WMT'21\nmultilingual translation task, we demonstrate that our systems outperform the\nconventional baselines of direct bilingual models and pivot translation models\nfor most directions, averagely giving +6.0 and +4.1 BLEU, without the need for\narchitecture change or extra data collection. Moreover, we also examine our\nproposed approach in an extremely large-scale data setting to accommodate\npractical deployment scenarios.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Akiko Eriguchi",
      "Shufang Xie",
      "Tao Qin",
      "Hany Hassan Awadalla"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14982"
  },
  {
    "id": "arXiv:2206.14983",
    "title": "A Validity Perspective on Evaluating the Justified Use of Data-driven  Decision-making Algorithms",
    "abstract": "This work seeks to center validity considerations in deliberations around\nwhether and how to build data-driven algorithms in high-stakes domains. Toward\nthis end, we translate key concepts from validity theory to predictive\nalgorithms. We describe common challenges in problem formulation and data\nissues that jeopardize the validity of predictive algorithms. We distill these\nissues into a series of high-level questions intended to promote and document\nreflections on the legitimacy of the predictive task and the suitability of the\ndata. This contribution lays the foundation for co-designing a validity\nprotocol, in collaboration with real-world stakeholders, including\ndecision-makers, modelers, and members of potentially impacted communities, to\ncritically evaluate the justifiability of specific designs and uses of\ndata-driven algorithmic systems.",
    "descriptor": "",
    "authors": [
      "Amanda Coston",
      "Anna Kawakami",
      "Haiyi Zhu",
      "Ken Holstein",
      "Hoda Heidari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.14983"
  },
  {
    "id": "arXiv:2206.14987",
    "title": "Lookback for Learning to Branch",
    "abstract": "The expressive and computationally inexpensive bipartite Graph Neural\nNetworks (GNN) have been shown to be an important component of deep learning\nbased Mixed-Integer Linear Program (MILP) solvers. Recent works have\ndemonstrated the effectiveness of such GNNs in replacing the branching\n(variable selection) heuristic in branch-and-bound (B&B) solvers. These GNNs\nare trained, offline and on a collection of MILPs, to imitate a very good but\ncomputationally expensive branching heuristic, strong branching. Given that B&B\nresults in a tree of sub-MILPs, we ask (a) whether there are strong\ndependencies exhibited by the target heuristic among the neighboring nodes of\nthe B&B tree, and (b) if so, whether we can incorporate them in our training\nprocedure. Specifically, we find that with the strong branching heuristic, a\nchild node's best choice was often the parent's second-best choice. We call\nthis the \"lookback\" phenomenon. Surprisingly, the typical branching GNN of\nGasse et al. (2019) often misses this simple \"answer\". To imitate the target\nbehavior more closely by incorporating the lookback phenomenon in GNNs, we\npropose two methods: (a) target smoothing for the standard cross-entropy loss\nfunction, and (b) adding a Parent-as-Target (PAT) Lookback regularizer term.\nFinally, we propose a model selection framework to incorporate\nharder-to-formulate objectives such as solving time in the final models.\nThrough extensive experimentation on standard benchmark instances, we show that\nour proposal results in up to 22% decrease in the size of the B&B tree and up\nto 15% improvement in the solving times.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Prateek Gupta",
      "Elias B. Khalil",
      "Didier Chet\u00e9lat",
      "Maxime Gasse",
      "Yoshua Bengio",
      "Andrea Lodi",
      "M. Pawan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14987"
  },
  {
    "id": "arXiv:2206.14988",
    "title": "Towards Federated Long-Tailed Learning",
    "abstract": "Data privacy and class imbalance are the norm rather than the exception in\nmany machine learning tasks. Recent attempts have been launched to, on one\nside, address the problem of learning from pervasive private data, and on the\nother side, learn from long-tailed data. However, both assumptions might hold\nin practical applications, while an effective method to simultaneously\nalleviate both issues is yet under development. In this paper, we focus on\nlearning with long-tailed (LT) data distributions under the context of the\npopular privacy-preserved federated learning (FL) framework. We characterize\nthree scenarios with different local or global long-tailed data distributions\nin the FL framework, and highlight the corresponding challenges. The\npreliminary results under different scenarios reveal that substantial future\nwork are of high necessity to better resolve the characterized federated\nlong-tailed learning tasks.",
    "descriptor": "\nComments: Accepted by International Workshop on Trustworthy Federated Learning in Conjunction with IJCAI 2022 (FL-IJCAI'22)\n",
    "authors": [
      "Zihan Chen",
      "Songshang Liu",
      "Hualiang Wang",
      "Howard H. Yang",
      "Tony Q.S. Quek",
      "Zuozhu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.14988"
  },
  {
    "id": "arXiv:2206.14989",
    "title": "A Unified End-to-End Retriever-Reader Framework for Knowledge-based VQA",
    "abstract": "Knowledge-based Visual Question Answering (VQA) expects models to rely on\nexternal knowledge for robust answer prediction. Though significant it is, this\npaper discovers several leading factors impeding the advancement of current\nstate-of-the-art methods. On the one hand, methods which exploit the explicit\nknowledge take the knowledge as a complement for the coarsely trained VQA\nmodel. Despite their effectiveness, these approaches often suffer from noise\nincorporation and error propagation. On the other hand, pertaining to the\nimplicit knowledge, the multi-modal implicit knowledge for knowledge-based VQA\nstill remains largely unexplored. This work presents a unified end-to-end\nretriever-reader framework towards knowledge-based VQA. In particular, we shed\nlight on the multi-modal implicit knowledge from vision-language pre-training\nmodels to mine its potential in knowledge reasoning. As for the noise problem\nencountered by the retrieval operation on explicit knowledge, we design a novel\nscheme to create pseudo labels for effective knowledge supervision. This scheme\nis able to not only provide guidance for knowledge retrieval, but also drop\nthese instances potentially error-prone towards question answering. To validate\nthe effectiveness of the proposed method, we conduct extensive experiments on\nthe benchmark dataset. The experimental results reveal that our method\noutperforms existing baselines by a noticeable margin. Beyond the reported\nnumbers, this paper further spawns several insights on knowledge utilization\nfor future research with some empirical findings.",
    "descriptor": "",
    "authors": [
      "Yangyang Guo",
      "Liqiang Nie",
      "Yongkang Wong",
      "Yibing Liu",
      "Zhiyong Cheng",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14989"
  },
  {
    "id": "arXiv:2206.14992",
    "title": "Maniposynth: Bimodal Tangible Functional Programming",
    "abstract": "Traditionally, writing code is a non-graphical, abstract, and linear process.\nNot everyone is comfortable with this way of thinking at all times. Can\nprogramming be transformed into a graphical, concrete, non-linear activity?\nWhile nodes-and-wires and blocks-based programming environments do leverage\ngraphical direct manipulation, users perform their manipulations on abstract\nsyntax tree elements, which are still abstract. Is it possible to be more\nconcrete - could users instead directly manipulate live program values to\ncreate their program?\nWe present a system, Maniposynth, that reimagines functional programming as a\nnon-linear workflow where program expressions are spread on a 2D canvas. The\nlive results of those expressions are continuously displayed and available for\ndirect manipulation. The non-linear canvas liberates users to work\nout-of-order, and the live values can be interacted with via drag-and-drop.\nIncomplete programs are gracefully handled via hole expressions, which allow\nManiposynth to offer program synthesis. Throughout the workflow, the program is\nvalid OCaml code which the user may inspect and edit in their preferred text\neditor at any time.\nWith Maniposynth's direct manipulation features, we created 38 programs drawn\nfrom a functional data structures course. We additionally hired two\nprofessional OCaml developers to implement a subset of these programs. We\nreport on these experiences and discuss to what degree Maniposynth meets its\ngoals of providing a non-linear, concrete, graphical programming workflow.",
    "descriptor": "\nComments: ECOOP 2022 Paper + Appendices. 34 pages, 15 figures. For video figure and artifact, see this https URL\n",
    "authors": [
      "Brian Hempel",
      "Ravi Chugh"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.14992"
  },
  {
    "id": "arXiv:2206.14996",
    "title": "Cross-domain Federated Object Detection",
    "abstract": "Detection models trained by one party (server) may face severe performance\ndegradation when distributed to other users (clients). For example, in\nautonomous driving scenarios, different driving environments may bring obvious\ndomain shifts, which lead to biases in model predictions. Federated learning\nthat has emerged in recent years can enable multi-party collaborative training\nwithout leaking client data. In this paper, we focus on a special cross-domain\nscenario where the server contains large-scale data and multiple clients only\ncontain a small amount of data; meanwhile, there exist differences in data\ndistributions among the clients. In this case, traditional federated learning\ntechniques cannot take into account the learning of both the global knowledge\nof all participants and the personalized knowledge of a specific client. To\nmake up for this limitation, we propose a cross-domain federated object\ndetection framework, named FedOD. In order to learn both the global knowledge\nand the personalized knowledge in different domains, the proposed framework\nfirst performs the federated training to obtain a public global aggregated\nmodel through multi-teacher distillation, and sends the aggregated model back\nto each client for finetuning its personalized local model. After very few\nrounds of communication, on each client we can perform weighted ensemble\ninference on the public global model and the personalized local model. With the\nensemble, the generalization performance of the client-side model can\noutperform a single model with the same parameter scale. We establish a\nfederated object detection dataset which has significant background differences\nand instance differences based on multiple public autonomous driving datasets,\nand then conduct extensive experiments on the dataset. The experimental results\nvalidate the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Shangchao Su",
      "Bin Li",
      "Chengzhi Zhang",
      "Mingzhao Yang",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14996"
  },
  {
    "id": "arXiv:2206.14997",
    "title": "Security and Privacy vulnerabilities of 5G/6G and WiFi 6: Survey and  Research Directions from a Coexistence Perspective",
    "abstract": "Spectrum scarcity has been a major concern for achieving the desired quality\nof experience (QoE) in next-generation (5G/6G and beyond) networks supporting a\nmassive volume of mobile and IoT devices with low-latency and seamless\nconnectivity. Hence, spectrum sharing systems have been considered as a major\nenabler for next-generation wireless networks in meeting QoE demands. While\nmost current coexistence solutions and standards focus on performance\nimprovement and QoE optimization, the emerging security challenges of such\nnetwork environments have been ignored in the literature. The security\nframework of standalone networks (either 5G or WiFi) assumes the ownership of\nentire network resources from spectrum to core functions. Hence, all accesses\nto the network shall be authenticated and authorized within the intra-network\nsecurity system and is deemed illegal otherwise. However, coexistence network\nenvironments can lead to unprecedented security vulnerabilities and breaches as\nthe standalone networks shall tolerate unknown and out-of-network accesses,\nspecifically in the medium access. In this paper, for the first time in\nliterature, we review some of the critical and emerging security\nvulnerabilities in the 5G/WiFi coexistence network environment which have not\nbeen observed previously in standalone networks. Specifically, independent\nmedium access control (MAC) protocols and the resulting hidden node issues can\nresult in exploitation such as service blocking, deployment of rogue\nbase-stations, and eavesdropping attacks. We study potential vulnerabilities in\nthe perspective of physical layer authentication, network access security, and\ncross-layer authentication mechanisms. This study opens a new direction of\nresearch in the analysis and design of a security framework that can address\nthe unique challenges of coexistence networks.",
    "descriptor": "\nComments: Submitted to Computer Networks (Elsevier)\n",
    "authors": [
      "Keyvan Ramezanpour",
      "Jithin Jagannath",
      "Anu Jagannath"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.14997"
  },
  {
    "id": "arXiv:2206.14998",
    "title": "Understanding Physical Effects for Effective Tool-use",
    "abstract": "We present a robot learning and planning framework that produces an effective\ntool-use strategy with the least joint efforts, capable of handling objects\ndifferent from training. Leveraging a Finite Element Method (FEM)-based\nsimulator that reproduces fine-grained, continuous visual and physical effects\ngiven observed tool-use events, the essential physical properties contributing\nto the effects are identified through the proposed Iterative Deepening Symbolic\nRegression (IDSR) algorithm. We further devise an optimal control-based motion\nplanning scheme to integrate robot- and tool-specific kinematics and dynamics\nto produce an effective trajectory that enacts the learned properties. In\nsimulation, we demonstrate that the proposed framework can produce more\neffective tool-use strategies, drastically different from the observed ones in\ntwo exemplar tasks.",
    "descriptor": "",
    "authors": [
      "Zeyu Zhang",
      "Ziyuan Jiao",
      "Weiqi Wang",
      "Yixin Zhu",
      "Song-Chun Zhu",
      "Hangxin Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14998"
  },
  {
    "id": "arXiv:2206.15000",
    "title": "Grounded Copilot: How Programmers Interact with Code-Generating Models",
    "abstract": "Powered by recent advances in code-generating models, AI assistants like\nGithub Copilot promise to change the face of programming forever. But what is\nthis new face of programming? We present the first grounded theory analysis of\nhow programmers interact with Copilot, based on observing 20 participants--with\na range of prior experience using the assistant--as they solve diverse\nprogramming tasks across four languages. Our main finding is that interactions\nwith programming assistants are bimodal: in acceleration mode, the programmer\nknows what to do next and uses Copilot to get there faster; in exploration\nmode, the programmer is unsure how to proceed and uses Copilot to explore their\noptions. Based on our theory, we provide recommendations for improving the\nusability of future AI programming assistants.",
    "descriptor": "",
    "authors": [
      "Shraddha Barke",
      "Michael B. James",
      "Nadia Polikarpova"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2206.15000"
  },
  {
    "id": "arXiv:2206.15002",
    "title": "Spatial Transformer Network with Transfer Learning for Small-scale  Fine-grained Skeleton-based Tai Chi Action Recognition",
    "abstract": "Human action recognition is a quite hugely investigated area where most\nremarkable action recognition networks usually use large-scale coarse-grained\naction datasets of daily human actions as inputs to state the superiority of\ntheir networks. We intend to recognize our small-scale fine-grained Tai Chi\naction dataset using neural networks and propose a transfer-learning method\nusing NTU RGB+D dataset to pre-train our network. More specifically, the\nproposed method first uses a large-scale NTU RGB+D dataset to pre-train the\nTransformer-based network for action recognition to extract common features\namong human motion. Then we freeze the network weights except for the fully\nconnected (FC) layer and take our Tai Chi actions as inputs only to train the\ninitialized FC weights. Experimental results show that our general model\npipeline can reach a high accuracy of small-scale fine-grained Tai Chi action\nrecognition with even few inputs and demonstrate that our method achieves the\nstate-of-the-art performance compared with previous Tai Chi action recognition\nmethods.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Lin Yuan",
      "Zhen He",
      "Qiang Wang",
      "Leiyang Xu",
      "Xiang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15002"
  },
  {
    "id": "arXiv:2206.15004",
    "title": "Pad\u00e9-parametric FEM approximation for fractional powers of elliptic  operators on manifolds",
    "abstract": "This paper focuses on numerical approximation for fractional powers of\nelliptic operators on $2$-d manifolds. Firstly, parametric finite element\nmethod is employed to discretize the original problem. We then approximate\nfractional powers of the discrete elliptic operator by the product of rational\nfunctions, each of which is a diagonal Pad\\'e approximant for corresponding\npower function. Rigorous error analysis is carried out and sharp error bounds\nare presented which show that the scheme is robust for $\\alpha\\rightarrow 0^+$\nand $\\alpha \\rightarrow 1^-$. The cost of the proposed algorithm is solving\nsome elliptic problems. Since the approach is exponentially convergent with\nrespect to the number of solves, it is very efficient. Some numerical tests are\ngiven to confirm our theoretical analysis and the robustness of the algorithm.",
    "descriptor": "",
    "authors": [
      "Beiping Duan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.15004"
  },
  {
    "id": "arXiv:2206.15005",
    "title": "Continuous-Time and Multi-Level Graph Representation Learning for  Origin-Destination Demand Prediction",
    "abstract": "Traffic demand forecasting by deep neural networks has attracted widespread\ninterest in both academia and industry society. Among them, the pairwise\nOrigin-Destination (OD) demand prediction is a valuable but challenging problem\ndue to several factors: (i) the large number of possible OD pairs, (ii)\nimplicitness of spatial dependence, and (iii) complexity of traffic states. To\naddress the above issues, this paper proposes a Continuous-time and Multi-level\ndynamic graph representation learning method for Origin-Destination demand\nprediction (CMOD). Firstly, a continuous-time dynamic graph representation\nlearning framework is constructed, which maintains a dynamic state vector for\neach traffic node (metro stations or taxi zones). The state vectors keep\nhistorical transaction information and are continuously updated according to\nthe most recently happened transactions. Secondly, a multi-level structure\nlearning module is proposed to model the spatial dependency of station-level\nnodes. It can not only exploit relations between nodes adaptively from data,\nbut also share messages and representations via cluster-level and area-level\nvirtual nodes. Lastly, a cross-level fusion module is designed to integrate\nmulti-level memories and generate comprehensive node representations for the\nfinal prediction. Extensive experiments are conducted on two real-world\ndatasets from Beijing Subway and New York Taxi, and the results demonstrate the\nsuperiority of our model against the state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Liangzhe Han",
      "Xiaojian Ma",
      "Leilei Sun",
      "Bowen Du",
      "Yanjie Fu",
      "Weifeng Lv",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15005"
  },
  {
    "id": "arXiv:2206.15007",
    "title": "GSCLIP : A Framework for Explaining Distribution Shifts in Natural  Language",
    "abstract": "Helping end users comprehend the abstract distribution shifts can greatly\nfacilitate AI deployment. Motivated by this, we propose a novel task, dataset\nexplanation. Given two image data sets, dataset explanation aims to\nautomatically point out their dataset-level distribution shifts with natural\nlanguage. Current techniques for monitoring distribution shifts provide\ninadequate information to understand datasets with the goal of improving data\nquality. Therefore, we introduce GSCLIP, a training-free framework to solve the\ndataset explanation task. In GSCLIP, we propose the selector as the first\nquantitative evaluation method to identify explanations that are proper to\nsummarize dataset shifts. Furthermore, we leverage this selector to demonstrate\nthe superiority of a generator based on language model generation. Systematic\nevaluation on natural data shift verifies that GSCLIP, a combined system of a\nhybrid generator group and an efficient selector is not only easy-to-use but\nalso powerful for dataset explanation at scale.",
    "descriptor": "\nComments: Accepted by ICML 2022 DataPerf\n",
    "authors": [
      "Zhiying Zhu",
      "Weixin Liang",
      "James Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15007"
  },
  {
    "id": "arXiv:2206.15010",
    "title": "\"Diversity and Uncertainty in Moderation\" are the Key to Data Selection  for Multilingual Few-shot Transfer",
    "abstract": "Few-shot transfer often shows substantial gain over zero-shot\ntransfer~\\cite{lauscher2020zero}, which is a practically useful trade-off\nbetween fully supervised and unsupervised learning approaches for multilingual\npretrained model-based systems. This paper explores various strategies for\nselecting data for annotation that can result in a better few-shot transfer.\nThe proposed approaches rely on multiple measures such as data entropy using\n$n$-gram language model, predictive entropy, and gradient embedding. We propose\na loss embedding method for sequence labeling tasks, which induces diversity\nand uncertainty sampling similar to gradient embedding. The proposed data\nselection strategies are evaluated and compared for POS tagging, NER, and NLI\ntasks for up to 20 languages. Our experiments show that the gradient and loss\nembedding-based strategies consistently outperform random data selection\nbaselines, with gains varying with the initial performance of the zero-shot\ntransfer. Furthermore, the proposed method shows similar trends in improvement\neven when the model is fine-tuned using a lower proportion of the original\ntask-specific labeled training data for zero-shot transfer.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Shanu Kumar",
      "Sandipan Dandapat",
      "Monojit Choudhury"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.15010"
  },
  {
    "id": "arXiv:2206.15012",
    "title": "The Edge of Disaster: A Battle Between Autonomous Racing and Safety",
    "abstract": "Where agents must act while on the limits of a vehicle's capability in order\nto set competitive lap times. This places the agent on a knife's edge, with a\nvery small margin between success and loss of control. Pushing towards this\nlimit leads to a practical tension: we want agents to explore the limitations\nof vehicle control to maximise speed, but inadvertently going past that limit\nand losing control can cause irreparable damage to the vehicle itself. We\nprovide a model predictive control (MPC) baseline that is able to, in a single\nlap, safely adapt to an unseen racetrack and achieve competitive lap times. Our\napproaches efficacy is demonstrated in simulation using the Learn To Race\nChallenge's environment and metrics.",
    "descriptor": "",
    "authors": [
      "Matthew Howe",
      "James Bockman",
      "Adrian Orenstein",
      "Stefan Podgorski",
      "Sam Bahrami",
      "Ian Reid"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.15012"
  },
  {
    "id": "arXiv:2206.15014",
    "title": "Compressing Pre-trained Transformers via Low-Bit NxM Sparsity for  Natural Language Understanding",
    "abstract": "In recent years, large pre-trained Transformer networks have demonstrated\ndramatic improvements in many natural language understanding tasks. However,\nthe huge size of these models brings significant challenges to their\nfine-tuning and online deployment due to latency and cost constraints. New\nhardware supporting both N:M semi-structured sparsity and low-precision integer\ncomputation is a promising solution to boost DNN model serving efficiency.\nHowever, there have been very few studies that systematically investigate to\nwhat extent pre-trained Transformer networks benefit from the combination of\nthese techniques, as well as how to best compress each component of the\nTransformer. We propose a flexible compression framework NxMiFormer that\nperforms simultaneous sparsification and quantization using ADMM and STE-based\nQAT. Furthermore, we present and inexpensive, heuristic-driven search algorithm\nthat identifies promising heterogeneous compression configurations that meet a\ncompression ratio constraint. When evaluated across the GLUE suite of NLU\nbenchmarks, our approach can achieve up to 93% compression of the encoders of a\nBERT model while retaining 98.2% of the original model accuracy and taking full\nadvantage of the hardware's capabilities. Heterogeneous configurations found\nthe by the search heuristic maintain 99.5% of the baseline accuracy while still\ncompressing the model by 87.5%.",
    "descriptor": "",
    "authors": [
      "Connor Holmes",
      "Minjia Zhang",
      "Yuxiong He",
      "Bo Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15014"
  },
  {
    "id": "arXiv:2206.15015",
    "title": "Exploring Temporally Dynamic Data Augmentation for Video Recognition",
    "abstract": "Data augmentation has recently emerged as an essential component of modern\ntraining recipes for visual recognition tasks. However, data augmentation for\nvideo recognition has been rarely explored despite its effectiveness. Few\nexisting augmentation recipes for video recognition naively extend the image\naugmentation methods by applying the same operations to the whole video frames.\nOur main idea is that the magnitude of augmentation operations for each frame\nneeds to be changed over time to capture the real-world video's temporal\nvariations. These variations should be generated as diverse as possible using\nfewer additional hyper-parameters during training. Through this motivation, we\npropose a simple yet effective video data augmentation framework, DynaAugment.\nThe magnitude of augmentation operations on each frame is changed by an\neffective mechanism, Fourier Sampling that parameterizes diverse, smooth, and\nrealistic temporal variations. DynaAugment also includes an extended search\nspace suitable for video for automatic data augmentation methods. DynaAugment\nexperimentally demonstrates that there are additional performance rooms to be\nimproved from static augmentations on diverse video models. Specifically, we\nshow the effectiveness of DynaAugment on various video datasets and tasks:\nlarge-scale video recognition (Kinetics-400 and Something-Something-v2),\nsmall-scale video recognition (UCF- 101 and HMDB-51), fine-grained video\nrecognition (Diving-48 and FineGym), video action segmentation on Breakfast,\nvideo action localization on THUMOS'14, and video object detection on MOT17Det.\nDynaAugment also enables video models to learn more generalized representation\nto improve the model robustness on the corrupted videos.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Taeoh Kim",
      "Jinhyung Kim",
      "Minho Shim",
      "Sangdoo Yun",
      "Myunggu Kang",
      "Dongyoon Wee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15015"
  },
  {
    "id": "arXiv:2206.15016",
    "title": "Near Optimal Algorithm for Fault Tolerant Distance Oracle and Single  Source Replacement Path problem",
    "abstract": "In a graph $G$ with a source $s$, we design a distance oracle that can answer\nthe following query: Query$(s,t,e)$ -- find the length of shortest path from a\nfixed source $s$ to any destination vertex $t$ while avoiding any edge $e$. We\ndesign a deterministic algorithm that builds such an oracle in\n$\\tilde{O}(m\\sqrt n)$ time. Our oracle uses $\\tilde{O}(n\\sqrt n)$ space and can\nanswer queries in $\\tilde{O}(1)$ time. Our oracle is an improvement of the work\nof Bil\\`{o} et al. (ESA 2021) in the preprocessing time, which constructs the\nfirst deterministic oracle for this problem in $\\tilde{O}(m\\sqrt n+n^2)$ time.\nUsing our distance oracle, we also solve the {\\em single source replacement\npath problem} (SSR problem). Chechik and Cohen (SODA 2019) designed a\nrandomized combinatorial algorithm to solve the SSR problem. The running time\nof their algorithm is $\\tilde{O}(m\\sqrt n + n^2)$. In this paper, we show that\nthe SSR problem can be solved in $\\tilde{O}(m\\sqrt n + |\\mathcal{R}|)$ time,\nwhere $\\mathcal{R}$ is the output set of the SSR problem in $G$. Our SSR\nalgorithm is optimal (upto polylogarithmic factor) as there is a conditional\nlower bound of $\\Omega(m\\sqrt n)$ for any combinatorial algorithm that solves\nthis problem.",
    "descriptor": "\nComments: Accepted in ESA 2022\n",
    "authors": [
      "Dipan Dey",
      "Manoj Gupta"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15016"
  },
  {
    "id": "arXiv:2206.15017",
    "title": "Consensus Function from an $L_p^q-$norm Regularization Term for its Use  as Adaptive Activation Functions in Neural Networks",
    "abstract": "The design of a neural network is usually carried out by defining the number\nof layers, the number of neurons per layer, their connections or synapses, and\nthe activation function that they will execute. The training process tries to\noptimize the weights assigned to those connections, together with the biases of\nthe neurons, to better fit the training data. However, the definition of the\nactivation functions is, in general, determined in the design process and not\nmodified during the training, meaning that their behavior is unrelated to the\ntraining data set. In this paper we propose the definition and utilization of\nan implicit, parametric, non-linear activation function that adapts its shape\nduring the training process. This fact increases the space of parameters to\noptimize within the network, but it allows a greater flexibility and\ngeneralizes the concept of neural networks. Furthermore, it simplifies the\narchitectural design since the same activation function definition can be\nemployed in each neuron, letting the training process to optimize their\nparameters and, thus, their behavior. Our proposed activation function comes\nfrom the definition of the consensus variable from the optimization of a linear\nunderdetermined problem with an $L_p^q$ regularization term, via the\nAlternating Direction Method of Multipliers (ADMM). We define the neural\nnetworks using this type of activation functions as $pq-$networks. Preliminary\nresults show that the use of these neural networks with this type of adaptive\nactivation functions reduces the error in regression and classification\nexamples, compared to equivalent regular feedforward neural networks with fixed\nactivation functions.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Juan Heredia-Juesas",
      "Jos\u00e9 \u00c1. Mart\u00ednez-Lorenzo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.15017"
  },
  {
    "id": "arXiv:2206.15021",
    "title": "A Novel Position-based VR Online Shopping Recommendation System based on  Optimized Collaborative Filtering Algorithm",
    "abstract": "This paper proposes a VR supermarket with an intelligent recommendation,\nwhich consists of three parts. The VR supermarket, the recommendation system,\nand the database. The VR supermarket provides a 360-degree virtual environment\nfor users to move and interact in the virtual environment through VR devices.\nThe recommendation system will make intelligent recommendations to the target\nusers based on the data in the database. The intelligent recommendation system\nis developed based on item similarity (ICF), which solves the cold start\nproblem of ICF. This allows VR supermarkets to present real-time\nrecommendations in any situation. It not only makes up for the lack of user\nperception of item attributes in traditional online shopping systems but also\nVR Supermarket improves the shopping efficiency of users through the\nintelligent recommendation system. The application can be extended to\nenterprise-level systems, which adds new possibilities for users to do VR\nshopping at home.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Jianze Huang",
      "HaoLan Zhang",
      "Huanda Lu",
      "Xin Yu",
      "Shaoyin Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.15021"
  },
  {
    "id": "arXiv:2206.15025",
    "title": "Stochastic Bilevel Distributed Optimization over a Network",
    "abstract": "Bilevel optimization has been applied to a wide variety of machine learning\nmodels. Numerous stochastic bilevel optimization algorithms have been developed\nin recent years. However, most of them restrict their focus on the\nsingle-machine setting so that they are incapable of handling the distributed\ndata. To address this issue, under the setting where all participants compose a\nnetwork and perform the peer-to-peer communication in this network, we\ndeveloped two novel distributed stochastic bilevel optimization algorithms\nbased on the gradient tracking communication mechanism and two different\ngradient estimators. Additionally, we show that they can achieve\n$O(\\frac{1}{\\epsilon^{2}(1-\\lambda)^2})$ and\n$O(\\frac{1}{\\epsilon^{3/2}(1-\\lambda)^2})$ convergence rate respectively to\nobtain the $\\epsilon$-accuracy solution, where $1-\\lambda$ denotes the spectral\ngap of the communication network. To our knowledge, this is the first work\nachieving these theoretical results. Finally, we applied our algorithms to\npractical machine learning models, and the experimental results confirmed the\nefficacy of our algorithms.",
    "descriptor": "",
    "authors": [
      "Hongchang Gao",
      "Bin Gu",
      "My T. Thai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15025"
  },
  {
    "id": "arXiv:2206.15027",
    "title": "Interpretable Melody Generation from Lyrics with Discrete-Valued  Adversarial Training",
    "abstract": "Generating melody from lyrics is an interesting yet challenging task in the\narea of artificial intelligence and music. However, the difficulty of keeping\nthe consistency between input lyrics and generated melody limits the generation\nquality of previous works. In our proposal, we demonstrate our proposed\ninterpretable lyrics-to-melody generation system which can interact with users\nto understand the generation process and recreate the desired songs. To improve\nthe reliability of melody generation that matches lyrics, mutual information is\nexploited to strengthen the consistency between lyrics and generated melodies.\nGumbel-Softmax is exploited to solve the non-differentiability problem of\ngenerating discrete music attributes by Generative Adversarial Networks (GANs).\nMoreover, the predicted probabilities output by the generator is utilized to\nrecommend music attributes. Interacting with our lyrics-to-melody generation\nsystem, users can listen to the generated AI song as well as recreate a new\nsong by selecting from recommended music attributes.",
    "descriptor": "\nComments: 3 pages, 3 figures\n",
    "authors": [
      "Wei Duan",
      "Zhe Zhang",
      "Yi Yu",
      "Keizo Oyama"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15027"
  },
  {
    "id": "arXiv:2206.15030",
    "title": "Modern Question Answering Datasets and Benchmarks: A Survey",
    "abstract": "Question Answering (QA) is one of the most important natural language\nprocessing (NLP) tasks. It aims using NLP technologies to generate a\ncorresponding answer to a given question based on the massive unstructured\ncorpus. With the development of deep learning, more and more challenging QA\ndatasets are being proposed, and lots of new methods for solving them are also\nemerging. In this paper, we investigate influential QA datasets that have been\nreleased in the era of deep learning. Specifically, we begin with introducing\ntwo of the most common QA tasks - textual question answer and visual question\nanswering - separately, covering the most representative datasets, and then\ngive some current challenges of QA research.",
    "descriptor": "",
    "authors": [
      "Zhen Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.15030"
  },
  {
    "id": "arXiv:2206.15031",
    "title": "Timestamp-Supervised Action Segmentation with Graph Convolutional  Networks",
    "abstract": "We introduce a novel approach for temporal activity segmentation with\ntimestamp supervision. Our main contribution is a graph convolutional network,\nwhich is learned in an end-to-end manner to exploit both frame features and\nconnections between neighboring frames to generate dense framewise labels from\nsparse timestamp labels. The generated dense framewise labels can then be used\nto train the segmentation model. In addition, we propose a framework for\nalternating learning of both the segmentation model and the graph convolutional\nmodel, which first initializes and then iteratively refines the learned models.\nDetailed experiments on four public datasets, including 50 Salads, GTEA,\nBreakfast, and Desktop Assembly, show that our method is superior to the\nmulti-layer perceptron baseline, while performing on par with or better than\nthe state of the art in temporal activity segmentation with timestamp\nsupervision.",
    "descriptor": "\nComments: Accepted to IROS 2022\n",
    "authors": [
      "Hamza Khan",
      "Sanjay Haresh",
      "Awais Ahmed",
      "Shakeeb Siddiqui",
      "Andrey Konin",
      "M. Zeeshan Zia",
      "Quoc-Huy Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15031"
  },
  {
    "id": "arXiv:2206.15033",
    "title": "Causality-Based Multivariate Time Series Anomaly Detection",
    "abstract": "Anomaly detection in multivariate time series plays an important role in\nmonitoring the behaviors of various real-world systems, e.g., IT system\noperations or manufacturing industry. Previous approaches model the joint\ndistribution without considering the underlying mechanism of multivariate time\nseries, making them complicated and computationally hungry. In this paper, we\nformulate the anomaly detection problem from a causal perspective and view\nanomalies as instances that do not follow the regular causal mechanism to\ngenerate the multivariate data. We then propose a causality-based anomaly\ndetection approach, which first learns the causal structure from data and then\ninfers whether an instance is an anomaly relative to the local causal mechanism\nto generate each variable from its direct causes, whose conditional\ndistribution can be directly estimated from data. In light of the modularity\nproperty of causal systems, the original problem is divided into a series of\nseparate low-dimensional anomaly detection problems so that where an anomaly\nhappens can be directly identified. We evaluate our approach with both\nsimulated and public datasets as well as a case study on real-world AIOps\napplications, showing its efficacy, robustness, and practical feasibility.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Wenzhuo Yang",
      "Kun Zhang",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15033"
  },
  {
    "id": "arXiv:2206.15036",
    "title": "Brain-like combination of feedforward and recurrent network components  achieves prototype extraction and robust pattern recognition",
    "abstract": "Associative memory has been a prominent candidate for the computation\nperformed by the massively recurrent neocortical networks. Attractor networks\nimplementing associative memory have offered mechanistic explanation for many\ncognitive phenomena. However, attractor memory models are typically trained\nusing orthogonal or random patterns to avoid interference between memories,\nwhich makes them unfeasible for naturally occurring complex correlated stimuli\nlike images. We approach this problem by combining a recurrent attractor\nnetwork with a feedforward network that learns distributed representations\nusing an unsupervised Hebbian-Bayesian learning rule. The resulting network\nmodel incorporates many known biological properties: unsupervised learning,\nHebbian plasticity, sparse distributed activations, sparse connectivity,\ncolumnar and laminar cortical architecture, etc. We evaluate the synergistic\neffects of the feedforward and recurrent network components in complex pattern\nrecognition tasks on the MNIST handwritten digits dataset. We demonstrate that\nthe recurrent attractor component implements associative memory when trained on\nthe feedforward-driven internal (hidden) representations. The associative\nmemory is also shown to perform prototype extraction from the training data and\nmake the representations robust to severely distorted input. We argue that\nseveral aspects of the proposed integration of feedforward and recurrent\ncomputations are particularly attractive from a machine learning perspective.",
    "descriptor": "",
    "authors": [
      "Naresh Balaji Ravichandran",
      "Anders Lansner",
      "Pawel Herman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.15036"
  },
  {
    "id": "arXiv:2206.15037",
    "title": "Privacy Research with Marginalized Groups: What We Know, What's Needed,  and What's Next",
    "abstract": "People who are marginalized experience disproportionate harms when their\nprivacy is violated. Meeting their needs is vital for developing equitable and\nprivacy-protective technologies. In response, research at the intersection of\nprivacy and marginalization has acquired newfound urgency in the HCI and social\ncomputing community. In this literature review, we set out to understand how\nresearchers have investigated this area of study. What topics have been\nexamined, and how? What are the key findings and recommendations? And,\ncrucially, where do we go from here? Based on a review of papers on privacy and\nmarginalization published between 2010-2020 across HCI, Communication, and\nPrivacy-focused venues, we make three main contributions: (1) we identify key\nthemes in existing work and introduce the Privacy Responses and Costs framework\nto describe the tensions around protecting privacy in marginalized contexts,\n(2) we identify understudied research topics (e.g., race) and other avenues for\nfuture work, and (3) we characterize trends in research practices, including\nthe under-reporting of important methodological choices, and provide\nsuggestions for establishing shared best practices for this growing research\narea.",
    "descriptor": "\nComments: This paper has been accepted for publication in the Proceedings of the ACM on Human-Computer Interaction and will be presented at CSCW 2022\n",
    "authors": [
      "Shruti Sannon",
      "Andrea Forte"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.15037"
  },
  {
    "id": "arXiv:2206.15042",
    "title": "Automated Wheat Disease Detection using a ROS-based Autonomous Guided  UAV",
    "abstract": "With the increase in world population, food resources have to be modified to\nbe more productive, resistive, and reliable. Wheat is one of the most important\nfood resources in the world, mainly because of the variety of wheat-based\nproducts. Wheat crops are threatened by three main types of diseases which\ncause large amounts of annual damage in crop yield. These diseases can be\neliminated by using pesticides at the right time. While the task of manually\nspraying pesticides is burdensome and expensive, agricultural robotics can aid\nfarmers by increasing the speed and decreasing the amount of chemicals. In this\nwork, a smart autonomous system has been implemented on an unmanned aerial\nvehicle to automate the task of monitoring wheat fields. First, an image-based\ndeep learning approach is used to detect and classify disease-infected wheat\nplants. To find the most optimal method, different approaches have been\nstudied. Because of the lack of a public wheat-disease dataset, a custom\ndataset has been created and labeled. Second, an efficient mapping and\nnavigation system is presented using a simulation in the robot operating system\nand Gazebo environments. A 2D simultaneous localization and mapping algorithm\nis used for mapping the workspace autonomously with the help of a\nfrontier-based exploration method.",
    "descriptor": "",
    "authors": [
      "Behzad Safarijalal",
      "Yousef Alborzi",
      "Esmaeil Najafi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15042"
  },
  {
    "id": "arXiv:2206.15047",
    "title": "Improving Ensemble Distillation With Weight Averaging and Diversifying  Perturbation",
    "abstract": "Ensembles of deep neural networks have demonstrated superior performance, but\ntheir heavy computational cost hinders applying them for resource-limited\nenvironments. It motivates distilling knowledge from the ensemble teacher into\na smaller student network, and there are two important design choices for this\nensemble distillation: 1) how to construct the student network, and 2) what\ndata should be shown during training. In this paper, we propose a weight\naveraging technique where a student with multiple subnetworks is trained to\nabsorb the functional diversity of ensemble teachers, but then those\nsubnetworks are properly averaged for inference, giving a single student\nnetwork with no additional inference cost. We also propose a perturbation\nstrategy that seeks inputs from which the diversities of teachers can be better\ntransferred to the student. Combining these two, our method significantly\nimproves upon previous methods on various image classification tasks.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Giung Nam",
      "Hyungi Lee",
      "Byeongho Heo",
      "Juho Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15047"
  },
  {
    "id": "arXiv:2206.15049",
    "title": "ZeroC: A Neuro-Symbolic Model for Zero-shot Concept Recognition and  Acquisition at Inference Time",
    "abstract": "Humans have the remarkable ability to recognize and acquire novel visual\nconcepts in a zero-shot manner. Given a high-level, symbolic description of a\nnovel concept in terms of previously learned visual concepts and their\nrelations, humans can recognize novel concepts without seeing any examples.\nMoreover, they can acquire new concepts by parsing and communicating symbolic\nstructures using learned visual concepts and relations. Endowing these\ncapabilities in machines is pivotal in improving their generalization\ncapability at inference time. In this work, we introduce Zero-shot Concept\nRecognition and Acquisition (ZeroC), a neuro-symbolic architecture that can\nrecognize and acquire novel concepts in a zero-shot way. ZeroC represents\nconcepts as graphs of constituent concept models (as nodes) and their relations\n(as edges). To allow inference time composition, we employ energy-based models\n(EBMs) to model concepts and relations. We design ZeroC architecture so that it\nallows a one-to-one mapping between a symbolic graph structure of a concept and\nits corresponding EBM, which for the first time, allows acquiring new concepts,\ncommunicating its graph structure, and applying it to classification and\ndetection tasks (even across domains) at inference time. We introduce\nalgorithms for learning and inference with ZeroC. We evaluate ZeroC on a\nchallenging grid-world dataset which is designed to probe zero-shot concept\nrecognition and acquisition, and demonstrate its capability.",
    "descriptor": "\nComments: 25 pages, 9 figures\n",
    "authors": [
      "Tailin Wu",
      "Megan Tjandrasuwita",
      "Zhengxuan Wu",
      "Xuelin Yang",
      "Kevin Liu",
      "Rok Sosi\u010d",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15049"
  },
  {
    "id": "arXiv:2206.15051",
    "title": "Group-invariant tensor train networks for supervised learning",
    "abstract": "Invariance has recently proven to be a powerful inductive bias in machine\nlearning models. One such class of predictive or generative models are tensor\nnetworks. We introduce a new numerical algorithm to construct a basis of\ntensors that are invariant under the action of normal matrix representations of\nan arbitrary discrete group. This method can be up to several orders of\nmagnitude faster than previous approaches. The group-invariant tensors are then\ncombined into a group-invariant tensor train network, which can be used as a\nsupervised machine learning model. We applied this model to a protein binding\nclassification problem, taking into account problem-specific invariances, and\nobtained prediction accuracy in line with state-of-the-art deep learning\napproaches.",
    "descriptor": "",
    "authors": [
      "Brent Sprangers",
      "Nick Vannieuwenhoven"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.15051"
  },
  {
    "id": "arXiv:2206.15055",
    "title": "Efficient Collective Action for Tackling Time-Critical Cybersecurity  Threats",
    "abstract": "The latency reduction between the discovery of vulnerabilities, the build-up\nand dissemination of cyber-attacks has put significant pressure on\ncybersecurity professionals. For that, security researchers have increasingly\nresorted to collective action in order to reduce the time needed to\ncharacterize and tame outstanding threats. Here, we investigate how joining and\ncontributions dynamics on MISP, an open source threat intelligence sharing\nplatform, influence the time needed to collectively complete threat\ndescriptions. We find that performance, defined as the capacity to characterize\nquickly a threat event, is influenced by (i) its own complexity (negatively),\nby (ii) collective action (positively), and by (iii) learning, information\nintegration and modularity (positively). Our results inform on how collective\naction can be organized at scale and in a modular way to overcome a large\nnumber of time-critical tasks, such as cybersecurity threats.",
    "descriptor": "\nComments: 23 pages, 3 figures. Presented at the 21st Workshop on the Economics of Information Security (WEIS), 2022, Tulsa, USA\n",
    "authors": [
      "S\u00e9bastien Gillard",
      "Dimitri Percia David",
      "Alain Mermoud",
      "Thomas Maillart"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.15055"
  },
  {
    "id": "arXiv:2206.15056",
    "title": "FeaRLESS: Feature Refinement Loss for Ensembling Self-Supervised  Learning Features in Robust End-to-end Speech Recognition",
    "abstract": "Self-supervised learning representations (SSLR) have resulted in robust\nfeatures for downstream tasks in many fields. Recently, several SSLRs have\nshown promising results on automatic speech recognition (ASR) benchmark\ncorpora. However, previous studies have only shown performance for solitary\nSSLRs as an input feature for ASR models. In this study, we propose to\ninvestigate the effectiveness of diverse SSLR combinations using various fusion\nmethods within end-to-end (E2E) ASR models. In addition, we will show there are\ncorrelations between these extracted SSLRs. As such, we further propose a\nfeature refinement loss for decorrelation to efficiently combine the set of\ninput features. For evaluation, we show that the proposed 'FeaRLESS learning\nfeatures' perform better than systems without the proposed feature refinement\nloss for both the WSJ and Fearless Steps Challenge (FSC) corpora.",
    "descriptor": "\nComments: Accepted for Interspeech 2022\n",
    "authors": [
      "Szu-Jui Chen",
      "Jiamin Xie",
      "John H.L. Hansen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.15056"
  },
  {
    "id": "arXiv:2206.15058",
    "title": "A note on Linear Bottleneck networks and their Transition to  Multilinearity",
    "abstract": "Randomly initialized wide neural networks transition to linear functions of\nweights as the width grows, in a ball of radius $O(1)$ around initialization. A\nnecessary condition for this result is that all layers of the network are wide\nenough, i.e., all widths tend to infinity. However, the transition to linearity\nbreaks down when this infinite width assumption is violated. In this work we\nshow that linear networks with a bottleneck layer learn bilinear functions of\nthe weights, in a ball of radius $O(1)$ around initialization. In general, for\n$B-1$ bottleneck layers, the network is a degree $B$ multilinear function of\nweights. Importantly, the degree only depends on the number of bottlenecks and\nnot the total depth of the network.",
    "descriptor": "",
    "authors": [
      "Libin Zhu",
      "Parthe Pandit",
      "Mikhail Belkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15058"
  },
  {
    "id": "arXiv:2206.15063",
    "title": "Imputation under Differential Privacy",
    "abstract": "The literature on differential privacy almost invariably assumes that the\ndata to be analyzed are fully observed. In most practical applications this is\nan unrealistic assumption. A popular strategy to address this problem is\nimputation, in which missing values are replaced by estimated values given the\nobserved data. In this paper we evaluate various approaches to answering\nqueries on an imputed dataset in a differentially private manner, as well as\ndiscuss trade-offs as to where along the pipeline privacy is considered. We\nshow that if imputation is done without consideration to privacy, the\nsensitivity of certain queries can increase linearly with the number of\nincomplete records. On the other hand, for a general class of imputation\nstrategies, these worst case scenarios can be greatly reduced by ensuring\nprivacy already during the imputation stage. We use a simulated dataset to\ndemonstrate these results across a number of imputation schemes (both private\nand non-private) and examine their impact on the utility of a private query on\nthe data.",
    "descriptor": "\nComments: Preliminary version, to be expanded. 4 pages, 1 figure\n",
    "authors": [
      "Soumojit Das",
      "Jorg Dreschler",
      "Keith Merrill",
      "Shawn Merrill"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.15063"
  },
  {
    "id": "arXiv:2206.15065",
    "title": "Learning-Based Near-Orthogonal Superposition Code for MIMO Short Message  Transmission",
    "abstract": "Massive machine type communication (mMTC) has attracted new coding schemes\noptimized for reliable short message transmission. In this paper, a novel deep\nlearning-based near-orthogonal superposition (NOS) coding scheme is proposed to\ntransmit short messages in multiple-input multiple-output (MIMO) channels for\nmMTC applications. In the proposed MIMO-NOS scheme, a neural network-based\nencoder is optimized via end-to-end learning with a corresponding neural\nnetwork-based detector/decoder in a superposition-based auto-encoder framework\nincluding a MIMO channel. The proposed MIMO-NOS encoder spreads the information\nbits to multiple near-orthogonal high dimensional vectors to be combined\n(superimposed) into a single vector and reshaped for the space-time\ntransmission. For the receiver, we propose a novel looped K-best tree-search\nalgorithm with cyclic redundancy check (CRC) assistance to enhance the error\ncorrecting ability in the block-fading MIMO channel. Simulation results show\nthe proposed MIMO-NOS scheme outperforms maximum likelihood (ML) MIMO detection\ncombined with a polar code with CRC-assisted list decoding by 1-2 dB in various\nMIMO systems for short (32-64 bit) message transmission.",
    "descriptor": "\nComments: submitted for possible journal publication\n",
    "authors": [
      "Chenghong Bian",
      "Chin-Wei Hsu",
      "Changwoo Lee",
      "Hun-Seok Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.15065"
  },
  {
    "id": "arXiv:2206.15066",
    "title": "Story-thinking, computational-thinking, programming and software  engineering",
    "abstract": "Working with stories and working with computations require very different\nmodes of thought. We call the first mode \"story-thinking\" and the second\n\"computational-thinking\". The aim of this curiosity-driven paper is to explore\nthe nature of these two modes of thinking, and to do so in relation to\nprogramming, including software engineering as programming-in-the-large. We\nsuggest that story-thinking and computational-thinking may be understood as two\nways of attending to the world, and that each both contributes and neglects the\nworld, though in different ways and for different ends. We formulate two\nfundamental problems, i.e., the problem of \"neglectful representations\" and the\nproblem of oppositional ways of thinking. We briefly suggest two ways in which\nthese problems might be tackled and identify candidate hypotheses about the\ncurrent state of the world, one assertion about a possible future state, and\nseveral research questions for future research.",
    "descriptor": "\nComments: 12 pages, 2 figures and 2 tables\n",
    "authors": [
      "Austen Rainer",
      "Catherine Menon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.15066"
  },
  {
    "id": "arXiv:2206.15067",
    "title": "Language Model-Based Emotion Prediction Methods for Emotional Speech  Synthesis Systems",
    "abstract": "This paper proposes an effective emotional text-to-speech (TTS) system with a\npre-trained language model (LM)-based emotion prediction method. Unlike\nconventional systems that require auxiliary inputs such as manually defined\nemotion classes, our system directly estimates emotion-related attributes from\nthe input text. Specifically, we utilize generative pre-trained transformer\n(GPT)-3 to jointly predict both an emotion class and its strength in\nrepresenting emotions coarse and fine properties, respectively. Then, these\nattributes are combined in the emotional embedding space and used as\nconditional features of the TTS model for generating output speech signals.\nConsequently, the proposed system can produce emotional speech only from text\nwithout any auxiliary inputs. Furthermore, because the GPT-3 enables to capture\nemotional context among the consecutive sentences, the proposed method can\neffectively handle the paragraph-level generation of emotional speech.",
    "descriptor": "\nComments: Accepted in INTERSPEECH2022\n",
    "authors": [
      "Hyun-Wook Yoon",
      "Ohsung Kwon",
      "Hoyeon Lee",
      "Ryuichi Yamamoto",
      "Eunwoo Song",
      "Jae-Min Kim",
      "Min-Jae Hwang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.15067"
  },
  {
    "id": "arXiv:2206.15068",
    "title": "Accountable Private Set Cardinality for Distributed Measurement",
    "abstract": "We introduce cryptographic protocols for securely and efficiently computing\nthe cardinality of set union and set intersection. Our private set-cardinality\nprotocols (PSC) are designed for the setting in which a large set of parties in\na distributed system makes observations, and a small set of parties with more\nresources and higher reliability aggregates the observations. PSC allows for\nsecure and useful statistics gathering in privacy-preserving distributed\nsystems. For example, it allows operators of anonymity networks such as Tor to\nsecurely answer the questions: \"How many unique users are using the network?\"\nand \"How many hidden services are being accessed?\".\nWe prove the correctness and security of PSC in the Universal Composability\nframework against an active adversary that compromises all but one of the\naggregating parties. Although successful output cannot be guaranteed in this\nsetting, PSC either succeeds or terminates with an abort, and we furthermore\nmake the adversary accountable for causing an abort by blaming at least one\nmalicious party. We also show that PSC prevents adaptive corruption of the data\nparties from revealing past observations, which prevents them from being\nvictims of targeted compromise, and we ensure safe measurements by making\noutputs differentially private.\nWe present a proof-of-concept implementation of PSC and use it to demonstrate\nthat PSC operates with low computational overhead and reasonable bandwidth. It\ncan count tens of thousands of unique observations from tens to hundreds of\ndata-collecting parties while completing within hours. PSC is thus suitable for\ndaily measurements in a distributed system.",
    "descriptor": "\nComments: Includes additional appendix over version published in ACM TOPS. 37 pages, 11 figures\n",
    "authors": [
      "Ellis Fenske",
      "Akshaya Mani",
      "Aaron Johnson",
      "Micah Sherr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.15068"
  },
  {
    "id": "arXiv:2206.15072",
    "title": "Learnable Model-Driven Performance Prediction and Optimization for  Imperfect MIMO System: Framework and Application",
    "abstract": "State-of-the-art schemes for performance analysis and optimization of\nmultiple-input multiple-output systems generally experience degradation or even\nbecome invalid in dynamic complex scenarios with unknown interference and\nchannel state information (CSI) uncertainty. To adapt to the challenging\nsettings and better accomplish these network auto-tuning tasks, we propose a\ngeneric learnable model-driven framework in this paper. To explain how the\nproposed framework works, we consider regularized zero-forcing precoding as a\nusage instance and design a light-weight neural network for refined prediction\nof sum rate and detection error based on coarse model-driven approximations.\nThen, we estimate the CSI uncertainty on the learned predictor in an iterative\nmanner and, on this basis, optimize the transmit regularization term and\nsubsequent receive power scaling factors. A deep unfolded projected gradient\ndescent based algorithm is proposed for power scaling, which achieves favorable\ntrade-off between convergence rate and robustness.",
    "descriptor": "\nComments: 30 pages, 9 figures, submitted to IEEE Transaction on Wireless Communications (major revision)\n",
    "authors": [
      "Fan Meng",
      "Shengheng Liu",
      "Yongming Huang",
      "Zhaohua Lu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.15072"
  },
  {
    "id": "arXiv:2206.15076",
    "title": "BigBIO: A Framework for Data-Centric Biomedical Natural Language  Processing",
    "abstract": "Training and evaluating language models increasingly requires the\nconstruction of meta-datasets --diverse collections of curated data with clear\nprovenance. Natural language prompting has recently lead to improved zero-shot\ngeneralization by transforming existing, supervised datasets into a diversity\nof novel pretraining tasks, highlighting the benefits of meta-dataset curation.\nWhile successful in general-domain text, translating these data-centric\napproaches to biomedical language modeling remains challenging, as labeled\nbiomedical datasets are significantly underrepresented in popular data hubs. To\naddress this challenge, we introduce BigBIO a community library of 126+\nbiomedical NLP datasets, currently covering 12 task categories and 10+\nlanguages. BigBIO facilitates reproducible meta-dataset curation via\nprogrammatic access to datasets and their metadata, and is compatible with\ncurrent platforms for prompt engineering and end-to-end few/zero shot language\nmodel evaluation. We discuss our process for task schema harmonization, data\nauditing, contribution guidelines, and outline two illustrative use cases:\nzero-shot evaluation of biomedical prompts and large-scale, multi-task\nlearning. BigBIO is an ongoing community effort and is available at\nhttps://github.com/bigscience-workshop/biomedical",
    "descriptor": "\nComments: Submitted to NeurIPS 2022 Datasets and Benchmarks Track\n",
    "authors": [
      "Jason Alan Fries",
      "Leon Weber",
      "Natasha Seelam",
      "Gabriel Altay",
      "Debajyoti Datta",
      "Samuele Garda",
      "Myungsun Kang",
      "Ruisi Su",
      "Wojciech Kusa",
      "Samuel Cahyawijaya",
      "Fabio Barth",
      "Simon Ott",
      "Matthias Samwald",
      "Stephen Bach",
      "Stella Biderman",
      "Mario S\u00e4nger",
      "Bo Wang",
      "Alison Callahan",
      "Daniel Le\u00f3n Peri\u00f1\u00e1n",
      "Th\u00e9o Gigant",
      "Patrick Haller",
      "Jenny Chim",
      "Jose David Posada",
      "John Michael Giorgi",
      "Karthik Rangasai Sivaraman",
      "Marc P\u00e0mies",
      "Marianna Nezhurina",
      "Robert Martin",
      "Michael Cullan",
      "Moritz Freidank",
      "Nathan Dahlberg",
      "Shubhanshu Mishra",
      "Shamik Bose",
      "Nicholas Michio Broad",
      "Yanis Labrak",
      "Shlok S Deshmukh",
      "Sid Kiblawi",
      "Ayush Singh",
      "Minh Chien Vu",
      "Trishala Neeraj",
      "Jonas Golde",
      "Albert Villanova del Moral",
      "Benjamin Beilharz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.15076"
  },
  {
    "id": "arXiv:2206.15077",
    "title": "A perspective on Attitude Control Issues and Techniques",
    "abstract": "This paper reviews the attitude control problems for rigid-body systems,\nstarting from the attitude representation for rigid body kinematics. Highly\nredundant rotation matrix defines the attitude orientation globally and\nuniquely by 9 parameters, which is the most fundamental one, without any\nsingularities; minimum 3-parameter Euler angles or (modified) Rodrigues\nparameters define the attitude orientation neither globally nor uniquely, but\nthe former exhibits kinematical singularity and Gimbal lock, while the latter\ntwo exhibit geometrical singularity; once-redundant axis-angle or unit\nquaternion globally define the attitude rotation but not uniquely using 4\nparameters, but the former is not appropriate to define very small or very\nlarge rotations, while the latter shows unwinding phenomenon despite of the\nreduced computation burden. In addition, we explore the relationships among\nthose attitude representations, including the connections among Gimbal lock,\nunwinding phenomenon and a nowhere dense set of zero Lebesgue measure. Based on\nattitude representations, we analyze different attitude control laws, almost\nglobal control and global attitude control, nominal and general robustness, as\nwell as the technique tools.",
    "descriptor": "\nComments: 13 pages, 6 figures, 2 tables\n",
    "authors": [
      "Dandan Zhang",
      "Xin Jin",
      "Hongye Su"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.15077"
  },
  {
    "id": "arXiv:2206.15078",
    "title": "Laplacian Autoencoders for Learning Stochastic Representations",
    "abstract": "Representation learning has become a practical family of methods for building\nrich parametric codifications of massive high-dimensional data while succeeding\nin the reconstruction side. When considering unsupervised tasks with test-train\ndistribution shifts, the probabilistic viewpoint helps for addressing\noverconfidence and poor calibration of predictions. However, the direct\nintroduction of Bayesian inference on top of neural networks weights is still\nan ardous problem for multiple reasons, i.e. the curse of dimensionality or\nintractability issues. The Laplace approximation (LA) offers a solution here,\nas one may build Gaussian approximations of the posterior density of weights\nvia second-order Taylor expansions in certain locations of the parameter space.\nIn this work, we present a Bayesian autoencoder for unsupervised representation\nlearning inspired in LA. Our method implements iterative Laplace updates to\nobtain a novel variational lower-bound of the autoencoder evidence. The vast\ncomputational burden of the second-order partial derivatives is skipped via\napproximations of the Hessian matrix. Empirically, we demonstrate the\nscalability and performance of the Laplacian autoencoder by providing\nwell-calibrated uncertainties for out-of-distribution detection, geodesics for\ndifferential geometry and missing data imputations.",
    "descriptor": "",
    "authors": [
      "Marco Miani",
      "Frederik Warburg",
      "Pablo Moreno-Mu\u00f1oz",
      "Nicke Skafte Detlefsen",
      "S\u00f8ren Hauberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15078"
  },
  {
    "id": "arXiv:2206.15083",
    "title": "Hierarchical Mask Calibration for Unified Domain Adaptive Panoptic  Segmentation",
    "abstract": "Domain adaptive panoptic segmentation aims to mitigate data annotation\nchallenge by leveraging off-the-shelf annotated data in one or multiple related\nsource domains. However, existing studies employ two networks for instance\nsegmentation and semantic segmentation separately which lead to a large amount\nof network parameters with complicated and computationally intensive training\nand inference processes. We design UniDAPS, a Unified Domain Adaptive Panoptic\nSegmentation network that is simple but capable of achieving domain adaptive\ninstance segmentation and semantic segmentation simultaneously within a single\nnetwork. UniDAPS introduces Hierarchical Mask Calibration (HMC) that rectifies\nthe predicted pseudo masks, pseudo superpixels and pseudo pixels and performs\nnetwork re-training via an online self-training process on the fly. It has\nthree unique features: 1) it enables unified domain adaptive panoptic\nadaptation; 2) it mitigates false predictions and improves domain adaptive\npanoptic segmentation effectively; 3) it is end-to-end trainable with much less\nparameters and simpler training and inference pipeline. Extensive experiments\nover multiple public benchmarks show that UniDAPS achieves superior domain\nadaptive panoptic segmentation as compared with the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Jingyi Zhang",
      "Jiaxing Huang",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15083"
  },
  {
    "id": "arXiv:2206.15085",
    "title": "Skeleton-based Action Recognition via Adaptive Cross-Form Learning",
    "abstract": "Skeleton-based action recognition aims to project skeleton sequences to\naction categories, where skeleton sequences are derived from multiple forms of\npre-detected points. Compared with earlier methods that focus on exploring\nsingle-form skeletons via Graph Convolutional Networks (GCNs), existing methods\ntend to improve GCNs by leveraging multi-form skeletons due to their\ncomplementary cues. However, these methods (either adapting structure of GCNs\nor model ensemble) require the co-existence of all forms of skeletons during\nboth training and inference stages, while a typical situation in real life is\nthe existence of only partial forms for inference. To tackle this issue, we\npresent Adaptive Cross-Form Learning (ACFL), which empowers well-designed GCNs\nto generate complementary representation from single-form skeletons without\nchanging model capacity. Specifically, each GCN model in ACFL not only learns\naction representation from the single-form skeletons, but also adaptively\nmimics useful representations derived from other forms of skeletons. In this\nway, each GCN can learn how to strengthen what has been learned, thus\nexploiting model potential and facilitating action recognition as well.\nExtensive experiments conducted on three challenging benchmarks, i.e.,\nNTU-RGB+D 120, NTU-RGB+D 60 and UAV-Human, demonstrate the effectiveness and\ngeneralizability of the proposed method. Specifically, the ACFL significantly\nimproves various GCN models (i.e., CTR-GCN, MS-G3D, and Shift-GCN), achieving a\nnew record for skeleton-based action recognition.",
    "descriptor": "",
    "authors": [
      "Xuanhan Wang",
      "Yan Dai",
      "Lianli Gao",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2206.15085"
  },
  {
    "id": "arXiv:2206.15086",
    "title": "Colonoscopy Navigation using End-to-End Deep Visuomotor Control: A User  Study",
    "abstract": "Flexible endoscopes for colonoscopy present several limitations due to their\ninherent complexity, resulting in patient discomfort and lack of intuitiveness\nfor clinicians. Robotic devices together with autonomous control represent a\nviable solution to reduce the workload of endoscopists and the training time\nwhile improving the overall procedure outcome. Prior works on autonomous\nendoscope control use heuristic policies that limit their generalisation to the\nunstructured and highly deformable colon environment and require frequent human\nintervention. This work proposes an image-based control of the endoscope using\nDeep Reinforcement Learning, called Deep Visuomotor Control (DVC), to exhibit\nadaptive behaviour in convoluted sections of the colon tract. DVC learns a\nmapping between the endoscopic images and the control signal of the endoscope.\nA first user study of 20 expert gastrointestinal endoscopists was carried out\nto compare their navigation performance with DVC policies using a realistic\nvirtual simulator. The results indicate that DVC shows equivalent performance\non several assessment parameters, being more safer. Moreover, a second user\nstudy with 20 novice participants was performed to demonstrate easier human\nsupervision compared to a state-of-the-art heuristic control policy. Seamless\nsupervision of colonoscopy procedures would enable interventionists to focus on\nthe medical decision rather than on the control problem of the endoscope.",
    "descriptor": "\nComments: Accepted in IROS2022\n",
    "authors": [
      "Ameya Pore",
      "Martina Finocchiaro",
      "Diego Dall'Alba",
      "Albert Hernansanz",
      "Gastone Ciuti",
      "Alberto Arezzo",
      "Arianna Menciassi",
      "Alicia Casals",
      "Paolo Fiorini"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15086"
  },
  {
    "id": "arXiv:2206.15088",
    "title": "On graphs coverable by k shortest paths",
    "abstract": "We show that if the edges or vertices of an undirected graph $G$ can be\ncovered by $k$ shortest paths, then the pathwidth of $G$ is upper-bounded by a\nfunction of $k$. As a corollary, we prove that the problem Isometric Path Cover\nwith Terminals (which, given a graph $G$ and a set of $k$ pairs of vertices\ncalled \\emph{terminals}, asks whether $G$ can be covered by $k$ shortest paths,\neach joining a pair of terminals) is FPT with respect to the number of\nterminals. The same holds for the similar problem Strong Geodetic Set with\nTerminals (which, given a graph $G$ and a set of $k$ terminals, asks whether\nthere exist $\\binom{k}{2}$ shortest paths, each joining a distinct pair of\nterminals such that these paths cover $G$). Moreover, this implies that the\nrelated problems Isometric Path Cover and Strong Geodetic Set (defined\nsimilarly but where the set of terminals is not part of the input) are in XP\nwith respect to parameter $k$.",
    "descriptor": "",
    "authors": [
      "Ma\u00ebl Dumas",
      "Florent Foucaud",
      "Anthony Perez",
      "Ioan Todinca"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.15088"
  },
  {
    "id": "arXiv:2206.15089",
    "title": "Fairness and Cost Constrained Privacy-Aware Record Linkage",
    "abstract": "Record linkage algorithms match and link records from different databases\nthat refer to the same real-world entity based on direct and/or\nquasi-identifiers, such as name, address, age, and gender, available in the\nrecords. Since these identifiers generally contain personal identifiable\ninformation (PII) about the entities, record linkage algorithms need to be\ndeveloped with privacy constraints. Known as privacy-preserving record linkage\n(PPRL), many research studies have been conducted to perform the linkage on\nencoded and/or encrypted identifiers. Differential privacy (DP) combined with\ncomputationally efficient encoding methods, e.g. Bloom filter encoding, has\nbeen used to develop PPRL with provable privacy guarantees. The standard DP\nnotion does not however address other constraints, among which the most\nimportant ones are fairness-bias and cost of linkage in terms of number of\nrecord pairs to be compared. In this work, we propose new notions of\nfairness-constrained DP and fairness and cost-constrained DP for PPRL and\ndevelop a framework for PPRL with these new notions of DP combined with Bloom\nfilter encoding. We provide theoretical proofs for the new DP notions for\nfairness and cost-constrained PPRL and experimentally evaluate them on two\ndatasets containing person-specific data. Our experimental results show that\nwith these new notions of DP, PPRL with better performance (compared to the\nstandard DP notion for PPRL) can be achieved with regard to privacy, cost and\nfairness constraints.",
    "descriptor": "",
    "authors": [
      "Nan Wu",
      "Dinusha Vatsalan",
      "Sunny Verma",
      "Mohamed Ali Kaafar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.15089"
  },
  {
    "id": "arXiv:2206.15091",
    "title": "Slim Tree-Cut Width",
    "abstract": "Tree-cut width is a parameter that has been introduced as an attempt to\nobtain an analogue of treewidth for edge cuts. Unfortunately, in spite of its\ndesirable structural properties, it turned out that tree-cut width falls short\nas an edge-cut based alternative to treewidth in algorithmic aspects. This has\nled to the very recent introduction of a simple edge-based parameter called\nedge-cut width [WG 2022], which has precisely the algorithmic applications one\nwould expect from an analogue of treewidth for edge cuts, but does not have the\ndesired structural properties. In this paper, we study a variant of tree-cut\nwidth obtained by changing the threshold for so-called thin nodes in tree-cut\ndecompositions from 2 to 1. We show that this \"slim tree-cut width\" satisfies\nall the requirements of an edge-cut based analogue of treewidth, both\nstructural and algorithmic, while being less restrictive than edge-cut width.\nOur results also include an alternative characterization of slim tree-cut width\nvia an easy-to-use spanning-tree decomposition akin to the one used for\nedge-cut width, a characterization of slim tree-cut width in terms of forbidden\nimmersions as well as approximation algorithm for computing the parameter.",
    "descriptor": "\nComments: 18 pages, 5 figures, 1 table\n",
    "authors": [
      "Robert Ganian",
      "Viktoriia Korchemna"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15091"
  },
  {
    "id": "arXiv:2206.15095",
    "title": "Learning-Aided Beam Prediction in mmWave MU-MIMO Systems for High-Speed  Railway",
    "abstract": "The problem of beam alignment and tracking in high mobility scenarios such as\nhigh-speed railway (HSR) becomes extremely challenging, since large overhead\ncost and significant time delay are introduced for fast time-varying channel\nestimation. To tackle this challenge, we propose a learning-aided beam\nprediction scheme for HSR networks, which predicts the beam directions and the\nchannel amplitudes within a period of future time with fine time granularity,\nusing a group of observations. Concretely, we transform the problem of\nhigh-dimensional beam prediction into a two-stage task, i.e., a low-dimensional\nparameter estimation and a cascaded hybrid beamforming operation. In the first\nstage, the location and speed of a certain terminal are estimated by maximum\nlikelihood criterion, and a data-driven data fusion module is designed to\nimprove the final estimation accuracy and robustness. Then, the probable future\nbeam directions and channel amplitudes are predicted, based on the HSR scenario\npriors including deterministic trajectory, motion model, and channel model.\nFurthermore, we incorporate a learnable non-linear mapping module into the\noverall beam prediction to allow non-linear tracks. Both of the proposed\nlearnable modules are model-based and have a good interpretability. Compared to\nthe existing beam management scheme, the proposed beam prediction has (near)\nzero overhead cost and time delay. Simulation results verify the effectiveness\nof the proposed scheme.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Fan Meng",
      "Shengheng Liu",
      "Yongming Huang",
      "Zhaohua Lu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.15095"
  },
  {
    "id": "arXiv:2206.15097",
    "title": "Prefix-free parsing for building large tunnelled Wheeler graphs",
    "abstract": "We propose a new technique for creating a space-efficient index for large\nrepetitive text collections, such as pangenomic databases containing sequences\nof many individuals from the same species. We combine two recent techniques\nfrom this area: Wheeler graphs (Gagie et al., 2017) and prefix-free parsing\n(PFP, Boucher et al., 2019). Wheeler graphs (WGs) are a general framework\nencompassing several indexes based on the Burrows-Wheeler transform (BWT), such\nas the FM-index. Wheeler graphs admit a succinct representation which can be\nfurther compacted by employing the idea of tunnelling, which exploits\nredundancies in the form of parallel, equally-labelled paths called blocks that\ncan be merged into a single path. The problem of finding the optimal set of\nblocks for tunnelling, i.e. the one that minimizes the size of the resulting\nWG, is known to be NP-complete and remains the most computationally challenging\npart of the tunnelling process.\nTo find an adequate set of blocks in less time, we propose a new method based\non the prefix-free parsing (PFP). The idea of PFP is to divide the input text\ninto phrases of roughly equal sizes that overlap by a fixed number of\ncharacters. The original text is represented by a sequence of phrase ranks (the\nparse) and a list of all used phrases (the dictionary). In repetitive texts,\nthe PFP of the text is generally much shorter than the original. To speed up\nthe block selection for tunnelling, we apply the PFP to obtain the parse and\nthe dictionary of the text, tunnel the WG of the parse using existing\nheuristics and subsequently use this tunnelled parse to construct a compact WG\nof the original text. Compared with constructing a WG from the original text\nwithout PFP, our method is much faster and uses less memory on collections of\npangenomic sequences. Therefore, our method enables the use of WGs as a\npangenomic reference for real-world datasets.",
    "descriptor": "\nComments: 12 pages, 3 figures, 2 tables, to be published in the WABI (Workshop on Algorithms in Bioinformatics) 2022 conference proceedings\n",
    "authors": [
      "Adri\u00e1n Goga",
      "Andrej Bal\u00e1\u017e"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15097"
  },
  {
    "id": "arXiv:2206.15099",
    "title": "Automatic generation of interpretable hyperelastic material models by  symbolic regression",
    "abstract": "In this paper, we present a new procedure to automatically generate\ninterpretable hyperelastic material models. This approach is based on symbolic\nregression which represents an evolutionary algorithm searching for a\nmathematical model in the form of an algebraic expression. This results in a\nrelatively simple model with good agreement to experimental data. By expressing\nthe strain energy function in terms of its invariants or other parameters, it\nis possible to interpret the resulting algebraic formulation in a physical\ncontext. In addition, a direct implementation of the obtained algebraic\nequation is possible. For the validation of the proposed approach, benchmark\ntests on the basis of the generalized Mooney-Rivlin model are presented. In all\nthese tests, the chosen ansatz can find the predefined models. Additionally,\nthis method is applied for the multi-axial loading data set of vulcanized\nrubber. Finally, a data set for a temperature-dependent thermoplastic polyester\nelastomer is evaluated. In latter cases, good agreement with the experimental\ndata is obtained.",
    "descriptor": "",
    "authors": [
      "Rasul Abdusalamov",
      "Markus Hillg\u00e4rtner",
      "Mikhail Itskov"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.15099"
  },
  {
    "id": "arXiv:2206.15100",
    "title": "Computing the Parameterized Burrows--Wheeler Transform Online",
    "abstract": "Parameterized strings are a generalization of strings in that their\ncharacters are drawn from two different alphabets, where one is considered to\nbe the alphabet of static characters and the other to be the alphabet of\nparameter characters. Two parameterized strings are a parameterized match if\nthere is a bijection over all characters such that the bijection transforms one\nstring to the other while keeping the static characters (i.e., it behaves as\nthe identity on the static alphabet). Ganguly et al.~[SODA'2017] proposed the\nparameterized Burrows--Wheeler transform (PBWT) as a variant of the\nBurrows--Wheeler transform for space-efficient parameterized pattern matching.\nIn this paper, we propose an algorithm for computing the PBWT online by reading\nthe characters of a given input string one-by-one from right to left. Our\nalgorithm works in $O(|\\Pi| \\log n / \\log \\log n)$ amortized time for each\ninput character, where $n$, $\\Sigma$, and $\\Pi$ denote the size of the input\nstring, and the alphabets of the static and parameter characters, respectively.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Daiki Hashimoto",
      "Diptarama Hendrian",
      "Dominik K\u00f6ppl",
      "Ryo Yoshinaka",
      "Ayumi Shinohara"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15100"
  },
  {
    "id": "arXiv:2206.15102",
    "title": "DynamicFilter: an Online Dynamic Objects Removal Framework for Highly  Dynamic Environments",
    "abstract": "Emergence of massive dynamic objects will diversify spatial structures when\nrobots navigate in urban environments. Therefore, the online removal of dynamic\nobjects is critical. In this paper, we introduce a novel online removal\nframework for highly dynamic urban environments. The framework consists of the\nscan-to-map front-end and the map-to-map back-end modules. Both the front- and\nback-ends deeply integrate the visibility-based approach and map-based\napproach. The experiments validate the framework in highly dynamic simulation\nscenarios and real-world datasets.",
    "descriptor": "\nComments: ICRA 2022\n",
    "authors": [
      "Tingxiang Fan",
      "Bowen Shen",
      "Hua Chen",
      "Wei Zhang",
      "Jia Pan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.15102"
  },
  {
    "id": "arXiv:2206.15105",
    "title": "Approximation Algorithms for Continuous Clustering and Facility Location  Problems",
    "abstract": "We consider the approximability of center-based clustering problems where the\npoints to be clustered lie in a metric space, and no candidate centers are\nspecified. We call such problems \"continuous\", to distinguish from \"discrete\"\nclustering where candidate centers are specified. For many objectives, one can\nreduce the continuous case to the discrete case, and use an\n$\\alpha$-approximation algorithm for the discrete case to get a\n$\\beta\\alpha$-approximation for the continuous case, where $\\beta$ depends on\nthe objective: e.g. for $k$-median, $\\beta = 2$, and for $k$-means, $\\beta =\n4$. Our motivating question is whether this gap of $\\beta$ is inherent, or are\nthere better algorithms for continuous clustering than simply reducing to the\ndiscrete case? In a recent SODA 2021 paper, Cohen-Addad, Karthik, and Lee prove\na factor-$2$ and a factor-$4$ hardness, respectively, for continuous $k$-median\nand $k$-means, even when the number of centers $k$ is a constant. The discrete\ncase for a constant $k$ is exactly solvable in polytime, so the $\\beta$ loss\nseems unavoidable in some regimes.\nIn this paper, we approach continuous clustering via the round-or-cut\nframework. For four continuous clustering problems, we outperform the reduction\nto the discrete case. Notably, for the problem $\\lambda$-UFL, where $\\beta = 2$\nand the discrete case has a hardness of $1.27$, we obtain an approximation\nratio of $2.32 < 2 \\times 1.27$ for the continuous case. Also, for continuous\n$k$-means, where the best known approximation ratio for the discrete case is\n$9$, we obtain an approximation ratio of $32 < 4 \\times 9$. The key challenge\nis that most algorithms for discrete clustering, including the state of the\nart, depend on linear programs that become infinite-sized in the continuous\ncase. To overcome this, we design new linear programs for the continuous case\nwhich are amenable to the round-or-cut framework.",
    "descriptor": "\nComments: 27 pages, 0 figures\n",
    "authors": [
      "Deeparnab Chakrabarty",
      "Maryam Negahbani",
      "Ankita Sarkar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15105"
  },
  {
    "id": "arXiv:2206.15109",
    "title": "MKIoU Loss: Towards Accurate Oriented Object Detection in Aerial Images",
    "abstract": "Oriented bounding box regression is crucial for oriented object detection.\nHowever, regression-based methods often suffer from boundary problems and the\ninconsistency between loss and evaluation metrics. In this paper, a modulated\nKalman IoU loss of approximate SkewIoU is proposed, named MKIoU. To avoid\nboundary problems, we convert the oriented bounding box to Gaussian\ndistribution, then use the Kalman filter to approximate the intersection area.\nHowever, there exists significant difference between the calculated and actual\nintersection areas. Thus, we propose a modulation factor to adjust the\nsensitivity of angle deviation and width-height offset to loss variation,\nmaking the loss more consistent with the evaluation metric. Furthermore, the\nGaussian modeling method avoids the boundary problem but causes the angle\nconfusion of square objects simultaneously. Thus, the Gaussian Angle Loss (GA\nLoss) is presented to solve this problem by adding a corrected loss for square\ntargets. The proposed GA Loss can be easily extended to other Gaussian-based\nmethods. Experiments on three publicly available aerial image datasets, DOTA,\nUCAS-AOD, and HRSC2016, show the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Xinyi Yu",
      "Jiangping Lu",
      "Xinyi Yu",
      "Mi Lin",
      "Linlin Ou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15109"
  },
  {
    "id": "arXiv:2206.15115",
    "title": "A Two-Stage Bayesian Optimisation for Automatic Tuning of an Unscented  Kalman Filter for Vehicle Sideslip Angle Estimation",
    "abstract": "This paper presents a novel methodology to auto-tune an Unscented Kalman\nFilter (UKF). It involves using a Two-Stage Bayesian Optimisation (TSBO), based\non a t-Student Process to optimise the process noise parameters of a UKF for\nvehicle sideslip angle estimation. Our method minimises performance metrics,\ngiven by the average sum of the states' and measurement' estimation error for\nvarious vehicle manoeuvres covering a wide range of vehicle behaviour. The\npredefined cost function is minimised through a TSBO which aims to find a\nlocation in the feasible region that maximises the probability of improving the\ncurrent best solution. Results on an experimental dataset show the capability\nto tune the UKF in 79.9% less time than using a genetic algorithm (GA) and the\noverall capacity to improve the estimation performance in an experimental test\ndataset of 9.9% to the current state-of-the-art GA.",
    "descriptor": "\nComments: to be published in IEEE Intelligent Vehicles Symposium, Aachen, Germany, 2022\n",
    "authors": [
      "A. Bertipaglia",
      "B. Shyrokau",
      "M. Alirezaei",
      "R. Happee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.15115"
  },
  {
    "id": "arXiv:2206.15116",
    "title": "A Constructive Heuristic Algorithm for 3D Bin Packing of Irregular  Shaped Items",
    "abstract": "The three-dimensional bin packing problem (3D-BPP) plays an important role in\ncity logistics and manufacturing environments, due to its direct relevance to\noperational cost. Most existing literature have investigated the conventional\n3D-BPP, in which the shape of items are typically considered as regular shapes,\ne.g., rectangular-shaped rigid boxes or cylindrical-shaped containers. However,\n3D-BPP for non-rectangular shaped items are quite common in varies delivery\nschemes, especially in fresh food delivery, and few published studies focusing\non these issues. In this paper, we address a novel 3D-BPP variant in which the\nshape changing factor of non-rectangular and deformable items is incorporated\nto further enhance the loading efficiency and reduce the operational cost of\nrelated companies. Motivated by the compression process of item-loading, we\npropose a constructive heuristic (i.e., an improved dynamic-volume-based\npacking algorithm) to solve the studied problem. Experimental results over a\nset of randomly generated instances reveal that considering shape changing\nfactor is indeed able to achieve higher space utilization than that of\nconventional schemes, thereby has potential to save packaging and delivering\ncost, as well as enhance operation efficiency.",
    "descriptor": "",
    "authors": [
      "Qiruyi Zuo",
      "Xinglu Liu",
      "Wai Kin Victor Chan"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.15116"
  },
  {
    "id": "arXiv:2206.15119",
    "title": "Model-based vs Data-driven Estimation of Vehicle Sideslip Angle and  Benefits of Tyre Force Measurements",
    "abstract": "This paper provides a comprehensive comparison of model-based and data-driven\napproaches and analyses the benefits of using measured tyre forces for vehicle\nsideslip angle estimation. The model-based approaches are based on an extended\nKalman filter and an unscented Kalman filter, in which the measured tyre forces\nare utilised in the observation model. An adaptive covariance matrix is\nintroduced to minimise the tyre model mismatch during evasive manoeuvres. For\ndata-driven approaches, feed forward and recurrent neural networks are\nevaluated. Both approaches use the standard inertial measurement unit and the\ntyre force measurements as inputs. Using the large-scale experimental dataset\nof 216 manoeuvres, we demonstrate a significant improvement in accuracy using\ndata-driven vs. model-based approaches. Tyre force measurements improve the\nperformance of both model-based and data-driven approaches, especially in the\nnon-linear regime of tyres.",
    "descriptor": "\nComments: to be published in 15th International Symposium on Advanced Vehicle Control, Kanagawa, Japan, 2022\n",
    "authors": [
      "A. Bertipaglia",
      "D. de Mol",
      "M. Alirezaei",
      "R. Happee",
      "B. Shyrokau"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.15119"
  },
  {
    "id": "arXiv:2206.15128",
    "title": "Detecting and Recovering Adversarial Examples from Extracting Non-robust  and Highly Predictive Adversarial Perturbations",
    "abstract": "Deep neural networks (DNNs) have been shown to be vulnerable against\nadversarial examples (AEs) which are maliciously designed to fool target\nmodels. The normal examples (NEs) added with imperceptible adversarial\nperturbation, can be a security threat to DNNs. Although the existing AEs\ndetection methods have achieved a high accuracy, they failed to exploit the\ninformation of the AEs detected. Thus, based on high-dimension perturbation\nextraction, we propose a model-free AEs detection method, the whole process of\nwhich is free from querying the victim model. Research shows that DNNs are\nsensitive to the high-dimension features. The adversarial perturbation hiding\nin the adversarial example belongs to the high-dimension feature which is\nhighly predictive and non-robust. DNNs learn more details from high-dimension\ndata than others. In our method, the perturbation extractor can extract the\nadversarial perturbation from AEs as high-dimension feature, then the trained\nAEs discriminator determines whether the input is an AE. Experimental results\nshow that the proposed method can not only detect the adversarial examples with\nhigh accuracy, but also detect the specific category of the AEs. Meanwhile, the\nextracted perturbation can be used to recover the AEs to NEs.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Mingyu Dong",
      "Jiahao Chen",
      "Diqun Yan",
      "Jingxing Gao",
      "Li Dong",
      "Rangding Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15128"
  },
  {
    "id": "arXiv:2206.15129",
    "title": "Personalized Detection of Cognitive Biases in Actions of Users from  Their Logs: Anchoring and Recency Biases",
    "abstract": "Cognitive biases are mental shortcuts humans use in dealing with information\nand the environment, and which result in biased actions and behaviors (or,\nactions), unbeknownst to themselves. Biases take many forms, with cognitive\nbiases occupying a central role that inflicts fairness, accountability,\ntransparency, ethics, law, medicine, and discrimination. Detection of biases is\nconsidered a necessary step toward their mitigation. Herein, we focus on two\ncognitive biases - anchoring and recency. The recognition of cognitive bias in\ncomputer science is largely in the domain of information retrieval, and bias is\nidentified at an aggregate level with the help of annotated data. Proposing a\ndifferent direction for bias detection, we offer a principled approach along\nwith Machine Learning to detect these two cognitive biases from Web logs of\nusers' actions. Our individual user level detection makes it truly\npersonalized, and does not rely on annotated data. Instead, we start with two\nbasic principles established in cognitive psychology, use modified training of\nan attention network, and interpret attention weights in a novel way according\nto those principles, to infer and distinguish between these two biases. The\npersonalized approach allows detection for specific users who are susceptible\nto these biases when performing their tasks, and can help build awareness among\nthem so as to undertake bias mitigation.",
    "descriptor": "",
    "authors": [
      "Atanu R Sinha",
      "Navita Goyal",
      "Sunny Dhamnani",
      "Tanay Asija",
      "Raja K Dubey",
      "M V Kaarthik Raja",
      "Georgios Theocharous"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15129"
  },
  {
    "id": "arXiv:2206.15132",
    "title": "AI for CSI Feedback Enhancement in 5G-Advanced and 6G",
    "abstract": "The 3rd Generation Partnership Project has started the study of Release 18 in\n2021. Artificial intelligence (AI)-native air interface is one of the key\nfeatures of Release 18, where AI for channel state information (CSI) feedback\nenhancement is selected as the representative use case. This article provides a\ncomprehensive overview of AI for CSI feedback enhancement in 5G-Advanced and\n6G. The scope of the AI for CSI feedback enhancement in 5G-Advanced, including\noverhead reduction, accuracy improvement, and channel prediction, is first\npresented and discussed. Then, three representative frameworks of AI-enabled\nCSI feedback, including one-sided implicit feedback, two-sided\nautoencoder-based implicit feedback, and two-sided explicit feedback, are\nintroduced and compared. Finally, the considerations in the standardization of\nAI for CSI feedback enhancement, especially focusing on evaluation, complexity,\ncollaboration, generalization, information sharing, joint design with channel\nprediction, and reciprocity, have been identified and discussed. This article\nprovides a guideline for the standardization study of the AI-based CSI feedback\nenhancement.",
    "descriptor": "\nComments: 7 pages, 3 figures, 1 table. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Jiajia Guo",
      "Chao-Kai Wen",
      "Shi Jin",
      "Xiao Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.15132"
  },
  {
    "id": "arXiv:2206.15133",
    "title": "Transmissive RIS for 6G Communications: Design, Prototyping, and  Experimental Demonstrations",
    "abstract": "Reconfigurable intelligent surface (RIS) has been widely considered as a key\ntechnique to improve spectral efficiency for 6G communications. Compared with\nmost existing research that only focuses on the reflective RIS, the design and\nprototyping of a novel transmissive RIS are presented in this paper, and its\nenhancement to the RIS-aided communication system is experimentally\ndemonstrated. The 2-bit transmissive RIS element utilizes the penetration\nstructure, which combines a 1-bit current reversible dipole and a 90{\\deg}\ndigital phase shifter based on a quadrature hybrid coupler. A transmissive RIS\nprototype with 16$\\times$16 elements is designed, fabricated, and measured to\nverify the proposed design. The measured phase shift and insertion loss of the\nRIS element validate the 2-bit phase modulation capability. Being illuminated\nby a horn feed, the prototype achieves a maximum broadside gain of 22.0 dBi at\n27 GHz, and the two-dimensional beamforming capability with scan angles up to\n$\\pm$60{\\deg} is validated. The experimental results of the RIS-aided\ncommunication system verify that by introducing the extra gain and beam\nsteering capability, the transmissive RIS is able to achieve a higher data\nrate, reduce the transmit power, improve the transmission capability through\nobstacles, and dynamically adapt to the signal propagation direction.",
    "descriptor": "\nComments: 20 pages, 8 figures. This paper fabricates a 16$\\times$16 transmissive RIS and develops a transmissive RIS-aided mmWave communication prototype to demonstrate its performance\n",
    "authors": [
      "Junwen Tang",
      "Mingyao Cui",
      "Shenheng Xu",
      "Linglong Dai",
      "Fan Yang",
      "Maokun Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.15133"
  },
  {
    "id": "arXiv:2206.15138",
    "title": "DFGC 2022: The Second DeepFake Game Competition",
    "abstract": "This paper presents the summary report on our DFGC 2022 competition. The\nDeepFake is rapidly evolving, and realistic face-swaps are becoming more\ndeceptive and difficult to detect. On the contrary, methods for detecting\nDeepFakes are also improving. There is a two-party game between DeepFake\ncreators and defenders. This competition provides a common platform for\nbenchmarking the game between the current state-of-the-arts in DeepFake\ncreation and detection methods. The main research question to be answered by\nthis competition is the current state of the two adversaries when competed with\neach other. This is the second edition after the last year's DFGC 2021, with a\nnew, more diverse video dataset, a more realistic game setting, and more\nreasonable evaluation metrics. With this competition, we aim to stimulate\nresearch ideas for building better defenses against the DeepFake threats. We\nalso release our DFGC 2022 dataset contributed by both our participants and\nourselves to enrich the DeepFake data resources for the research community\n(https://github.com/NiCE-X/DFGC-2022).",
    "descriptor": "",
    "authors": [
      "Bo Peng",
      "Wei Xiang",
      "Yue Jiang",
      "Wei Wang",
      "Jing Dong",
      "Zhenan Sun",
      "Zhen Lei",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15138"
  },
  {
    "id": "arXiv:2206.15139",
    "title": "Pump Up Password Security! Evaluating and Enhancing Risk-Based  Authentication on a Real-World Large-Scale Online Service",
    "abstract": "Risk-based authentication (RBA) aims to protect users against attacks\ninvolving stolen passwords. RBA monitors features during login, and requests\nre-authentication when feature values widely differ from previously observed\nones. It is recommended by various national security organizations, and users\nperceive it more usable and equally secure than equivalent two-factor\nauthentication. Despite that, RBA is still only used by very few online\nservices. Reasons for this include a lack of validated open resources on RBA\nproperties, implementation, and configuration. This effectively hinders the RBA\nresearch, development, and adoption progress.\nTo close this gap, we provide the first long-term RBA analysis on a\nreal-world large-scale online service. We collected feature data of 3.3 million\nusers and 31.3 million login attempts over more than one year. Based on the\ndata, we provide (i) studies on RBA's real-world characteristics, and its\nconfigurations and enhancements to balance usability, security, and privacy,\n(ii) a machine learning based RBA parameter optimization method to support\nadministrators finding an optimal configuration for their own use case\nscenario, (iii) an evaluation of the round-trip time feature's potential to\nreplace the IP address for enhanced user privacy, and (iv) a synthesized RBA\ndata set to reproduce this research and to foster future RBA research. Our\nresults provide insights on selecting an optimized RBA configuration so that\nusers profit from RBA after just a few logins. The open data set enables\nresearchers to study, test, and improve RBA for widespread deployment in the\nwild.",
    "descriptor": "\nComments: 35 pages, 18 figures, 7 tables\n",
    "authors": [
      "Stephan Wiefling",
      "Paul Ren\u00e9 J\u00f8rgensen",
      "Sigurd Thunem",
      "Luigi Lo Iacono"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.15139"
  },
  {
    "id": "arXiv:2206.15143",
    "title": "Scalable K-FAC Training for Deep Neural Networks with Distributed  Preconditioning",
    "abstract": "The second-order optimization methods, notably the D-KFAC (Distributed\nKronecker Factored Approximate Curvature) algorithms, have gained traction on\naccelerating deep neural network (DNN) training on GPU clusters. However,\nexisting D-KFAC algorithms require to compute and communicate a large volume of\nsecond-order information, i.e., Kronecker factors (KFs), before preconditioning\ngradients, resulting in large computation and communication overheads as well\nas a high memory footprint. In this paper, we propose DP-KFAC, a novel\ndistributed preconditioning scheme that distributes the KF constructing tasks\nat different DNN layers to different workers. DP-KFAC not only retains the\nconvergence property of the existing D-KFAC algorithms but also enables three\nbenefits: reduced computation overhead in constructing KFs, no communication of\nKFs, and low memory footprint. Extensive experiments on a 64-GPU cluster show\nthat DP-KFAC reduces the computation overhead by 1.55x-1.65x, the communication\ncost by 2.79x-3.15x, and the memory footprint by 1.14x-1.47x in each\nsecond-order update compared to the state-of-the-art D-KFAC methods.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Lin Zhang",
      "Shaohuai Shi",
      "Wei Wang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.15143"
  },
  {
    "id": "arXiv:2206.15144",
    "title": "Neural Networks can Learn Representations with Gradient Descent",
    "abstract": "Significant theoretical work has established that in specific regimes, neural\nnetworks trained by gradient descent behave like kernel methods. However, in\npractice, it is known that neural networks strongly outperform their associated\nkernels. In this work, we explain this gap by demonstrating that there is a\nlarge class of functions which cannot be efficiently learned by kernel methods\nbut can be easily learned with gradient descent on a two layer neural network\noutside the kernel regime by learning representations that are relevant to the\ntarget task. We also demonstrate that these representations allow for efficient\ntransfer learning, which is impossible in the kernel regime.\nSpecifically, we consider the problem of learning polynomials which depend on\nonly a few relevant directions, i.e. of the form $f^\\star(x) = g(Ux)$ where $U:\n\\R^d \\to \\R^r$ with $d \\gg r$. When the degree of $f^\\star$ is $p$, it is known\nthat $n \\asymp d^p$ samples are necessary to learn $f^\\star$ in the kernel\nregime. Our primary result is that gradient descent learns a representation of\nthe data which depends only on the directions relevant to $f^\\star$. This\nresults in an improved sample complexity of $n\\asymp d^2 r + dr^p$.\nFurthermore, in a transfer learning setup where the data distributions in the\nsource and target domain share the same representation $U$ but have different\npolynomial heads we show that a popular heuristic for transfer learning has a\ntarget sample complexity independent of $d$.",
    "descriptor": "\nComments: COLT 2022\n",
    "authors": [
      "Alex Damian",
      "Jason D. Lee",
      "Mahdi Soltanolkotabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15144"
  },
  {
    "id": "arXiv:2206.15147",
    "title": "esCorpius: A Massive Spanish Crawling Corpus",
    "abstract": "In the recent years, transformer-based models have lead to significant\nadvances in language modelling for natural language processing. However, they\nrequire a vast amount of data to be (pre-)trained and there is a lack of\ncorpora in languages other than English. Recently, several initiatives have\npresented multilingual datasets obtained from automatic web crawling. However,\nthe results in Spanish present important shortcomings, as they are either too\nsmall in comparison with other languages, or present a low quality derived from\nsub-optimal cleaning and deduplication. In this paper, we introduce\n\\textsc{esCorpius}, a Spanish crawling corpus obtained from near 1 Pb of Common\nCrawl data. It is the most extensive corpus in Spanish with this level of\nquality in the extraction, purification and deduplication of web textual\ncontent. Our data curation process involves a novel highly parallel cleaning\npipeline and encompasses a series of deduplication mechanisms that together\nensure the integrity of both document and paragraph boundaries. Additionally,\nwe maintain both the source web page URL and the WARC shard origin URL in order\nto complain with EU regulations. \\textsc{esCorpius} has been released under CC\nBY-NC-ND 4.0 license and is available on HuggingFace.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Asier Guti\u00e9rrez-Fandi\u00f1o",
      "David P\u00e9rez-Fern\u00e1ndez",
      "Jordi Armengol-Estap\u00e9",
      "David Griol",
      "Zoraida Callejas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15147"
  },
  {
    "id": "arXiv:2206.15148",
    "title": "Probabilistic Model Checking for Strategic Equilibria-based Decision  Making: Advances and Challenges",
    "abstract": "Game-theoretic concepts have been extensively studied in economics to provide\ninsight into competitive behaviour and strategic decision making. As computing\nsystems increasingly involve concurrently acting autonomous agents,\ngame-theoretic approaches are becoming widespread in computer science as a\nfaithful modelling abstraction. These techniques can be used to reason about\nthe competitive or collaborative behaviour of multiple rational agents with\ndistinct goals or objectives. This paper provides an overview of recent\nadvances in developing a modelling, verification and strategy synthesis\nframework for concurrent stochastic games implemented in the probabilistic\nmodel checker PRISM-games. This is based on a temporal logic that supports\nfinite- and infinite-horizon temporal properties in both a zero-sum and\nnonzero-sum setting, the latter using Nash and correlated equilibria with\nrespect to two optimality criteria, social welfare and social fairness. We\nsummarise the key concepts, logics and algorithms and the currently available\ntool support. Future challenges and recent progress in adapting the framework\nand algorithmic solutions to continuous environments and neural networks are\nalso outlined.",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Marta Kwiatkowska",
      "Gethin Norman",
      "David Parker",
      "Gabriel Santos",
      "Rui Yan"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.15148"
  },
  {
    "id": "arXiv:2206.15149",
    "title": "Optimizing Character Animations using Online Crowdsourcing",
    "abstract": "This paper presents a novel approach for exploring diverse and expressive\nmotions that are physically correct and interactive. The approach combining\nuser participation in with the animation development process using\ncrowdsourcing to remove the need for data-driven libraries while address\naesthetic limitations. A core challenge for character animation solutions that\ndo not use pre-recorded data is they are constrained to specific actions or\nappear unnatural and out of place (compared to real-life movements). Character\nmovements are very subjective to human perception (easily identify underlying\nunnatural or strange patterns with simple actions, such as walking or\nclimbing). We present an approach that leverage's crowdsourcing to reduce these\nuncanny artifacts within generated character animations. Crowdsourcing\nanimations is an uncommon practice due to the complexities of having multiple\npeople working in parallel on a single animation. A web-based solution for\nanalysis and animation is presented in this paper. It allows users to optimize\nand evaluate complicated character animation mechanism conveniently on-line.\nThe context of this paper introduces a simple animation system, which is\nintegrated into a web-based solution (JavaScript/HTML5). Since Web browser are\ncommonly available on computers, the presented application is easy to use on\nany platform from any location (easy to maintain and share). Our system\ncombines the expressive power of web pages for visualising content on-the-fly\nwith a fully fledged interactive (physics-based) animation solution that\nincludes a rich set of libraries.",
    "descriptor": "",
    "authors": [
      "Benjamin Kenwright"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.15149"
  },
  {
    "id": "arXiv:2206.15153",
    "title": "Some $3$-designs and shortened codes from binary cyclic codes with three  zeros",
    "abstract": "Linear codes and $t$-designs are interactive with each other. It is well\nknown that some $t$-designs have been constructed by using certain linear codes\nin recent years. However, only a small number of infinite families of the\nextended codes of linear codes holding an infinite family of $t$-designs with\n$t\\geq 3$ are reported in the literature. In this paper, we study the extended\ncodes of the augmented codes of a class of binary cyclic codes with three zeros\nand their dual codes, and show that those codes hold $3$-designs. Furthermore,\nwe obtain some shortened codes from the studied cyclic codes and explicitly\ndetermine their parameters. Some of those shortened codes are optimal or almost\noptimal.",
    "descriptor": "\nComments: 18 pages. arXiv admin note: text overlap with arXiv:2110.03881, arXiv:2007.05923\n",
    "authors": [
      "Can Xiang",
      "Chunming Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.15153"
  },
  {
    "id": "arXiv:2206.15154",
    "title": "BoxGraph: Semantic Place Recognition and Pose Estimation from 3D LiDAR",
    "abstract": "This paper is about extremely robust and lightweight localisation using LiDAR\npoint clouds based on instance segmentation and graph matching. We model 3D\npoint clouds as fully-connected graphs of semantically identified components\nwhere each vertex corresponds to an object instance and encodes its shape.\nOptimal vertex association across graphs allows for full 6-Degree-of-Freedom\n(DoF) pose estimation and place recognition by measuring similarity. This\nrepresentation is very concise, condensing the size of maps by a factor of 25\nagainst the state-of-the-art, requiring only 3kB to represent a 1.4MB laser\nscan. We verify the efficacy of our system on the SemanticKITTI dataset, where\nwe achieve a new state-of-the-art in place recognition, with an average of\n88.4% recall at 100% precision where the next closest competitor follows with\n64.9%. We also show accurate metric pose estimation performance - estimating\n6-DoF pose with median errors of 10 cm and 0.33 deg.",
    "descriptor": "\nComments: Accepted for publication at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022\n",
    "authors": [
      "Georgi Pramatarov",
      "Daniele De Martini",
      "Matthew Gadd",
      "Paul Newman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.15154"
  },
  {
    "id": "arXiv:2206.15155",
    "title": "An Evaluation of Three-Stage Voice Conversion Framework for Noisy and  Reverberant Conditions",
    "abstract": "This paper presents a new voice conversion (VC) framework capable of dealing\nwith both additive noise and reverberation, and its performance evaluation.\nThere have been studied some VC researches focusing on real-world circumstances\nwhere speech data are interfered with background noise and reverberation. To\ndeal with more practical conditions where no clean target dataset is available,\none possible approach is zero-shot VC, but its performance tends to degrade\ncompared with VC using sufficient amount of target speech data. To leverage\nlarge amount of noisy-reverberant target speech data, we propose a three-stage\nVC framework based on denoising process using a pretrained denoising model,\ndereverberation process using a dereverberation model, and VC process using a\nnonparallel VC model based on a variational autoencoder. The experimental\nresults show that 1) noise and reverberation additively cause significant VC\nperformance degradation, 2) the proposed method alleviates the adverse effects\ncaused by both noise and reverberation, and significantly outperforms the\nbaseline directly trained on the noisy-reverberant speech data, and 3) the\npotential degradation introduced by the denoising and dereverberation still\ncauses noticeable adverse effects on VC performance.",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Yeonjong Choi",
      "Chao Xie",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.15155"
  },
  {
    "id": "arXiv:2206.15157",
    "title": "HRFuser: A Multi-resolution Sensor Fusion Architecture for 2D Object  Detection",
    "abstract": "Besides standard cameras, autonomous vehicles typically include multiple\nadditional sensors, such as lidars and radars, which help acquire richer\ninformation for perceiving the content of the driving scene. While several\nrecent works focus on fusing certain pairs of sensors - such as camera and\nlidar or camera and radar - by using architectural components specific to the\nexamined setting, a generic and modular sensor fusion architecture is missing\nfrom the literature. In this work, we focus on 2D object detection, a\nfundamental high-level task which is defined on the 2D image domain, and\npropose HRFuser, a multi-resolution sensor fusion architecture that scales\nstraightforwardly to an arbitrary number of input modalities. The design of\nHRFuser is based on state-of-the-art high-resolution networks for image-only\ndense prediction and incorporates a novel multi-window cross-attention block as\nthe means to perform fusion of multiple modalities at multiple resolutions.\nEven though cameras alone provide very informative features for 2D detection,\nwe demonstrate via extensive experiments on the nuScenes and Seeing Through Fog\ndatasets that our model effectively leverages complementary features from\nadditional modalities, substantially improving upon camera-only performance and\nconsistently outperforming state-of-the-art fusion methods for 2D detection\nboth in normal and adverse conditions. The source code will be made publicly\navailable.",
    "descriptor": "\nComments: 9 pages, 5 figures, 5 tables, the source code is publicly available at this https URL\n",
    "authors": [
      "Tim Broedermann",
      "Christos Sakaridis",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15157"
  },
  {
    "id": "arXiv:2206.15159",
    "title": "EfficientGrasp: A Unified Data-Efficient Learning to Grasp Method for  Multi-fingered Robot Hands",
    "abstract": "Autonomous grasping of novel objects that are previously unseen to a robot is\nan ongoing challenge in robotic manipulation. In the last decades, many\napproaches have been presented to address this problem for specific robot\nhands. The UniGrasp framework, introduced recently, has the ability to\ngeneralize to different types of robotic grippers; however, this method does\nnot work on grippers with closed-loop constraints and is data-inefficient when\napplied to robot hands with multigrasp configurations. In this paper, we\npresent EfficientGrasp, a generalized grasp synthesis and gripper control\nmethod that is independent of gripper model specifications. EfficientGrasp\nutilizes a gripper workspace feature rather than UniGrasp's gripper attribute\ninputs. This reduces memory use by 81.7% during training and makes it possible\nto generalize to more types of grippers, such as grippers with closed-loop\nconstraints. The effectiveness of EfficientGrasp is evaluated by conducting\nobject grasping experiments both in simulation and real-world; results show\nthat the proposed method also outperforms UniGrasp when considering only\ngrippers without closed-loop constraints. In these cases, EfficientGrasp shows\n9.85% higher accuracy in generating contact points and 3.10% higher grasping\nsuccess rate in simulation. The real-world experiments are conducted with a\ngripper with closed-loop constraints, which UniGrasp fails to handle while\nEfficientGrasp achieves a success rate of 83.3%. The main causes of grasping\nfailures of the proposed method are analyzed, highlighting ways of enhancing\ngrasp performance.",
    "descriptor": "\nComments: This paper has been accepted for publication in IEEE Robotics and Automation Letters (RA-L), and for presentation at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Kelin Li",
      "Nicholas Baron",
      "Xian Zhang",
      "Nicolas Rojas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.15159"
  },
  {
    "id": "arXiv:2206.15162",
    "title": "Using Person Embedding to Enrich Features and Data Augmentation for  Classification",
    "abstract": "Today, machine learning is applied in almost any field. In machine learning,\nwhere there are numerous methods, classification is one of the most basic and\ncrucial ones. Various problems can be solved by classification. The feature\nselection for model setup is extremely important, and producing new features\nvia feature engineering also has a vital place in the success of the model. In\nour study, fraud detection classification models are built on a labeled and\nimbalanced dataset as a case-study. Although it is a natural language\nprocessing method, a customer space has been created with word embedding, which\nhas been used in different areas, especially for recommender systems. The\ncustomer vectors in the created space are fed to the classification model as a\nfeature. Moreover, to increase the number of positive labels, rows with similar\ncharacteristics are re-labeled as positive by using customer similarity\ndetermined by embedding. The model in which embedding methods are included in\nthe classification, which provides a better representation of customers, has\nbeen compared with other models. Considering the results, it is observed that\nthe customer embedding method had a positive effect on the success of the\nclassification models.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Ahmet Tu\u011frul Bayrak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.15162"
  },
  {
    "id": "arXiv:2206.15163",
    "title": "Efficient Entity Candidate Generation for Low-Resource Languages",
    "abstract": "Candidate generation is a crucial module in entity linking. It also plays a\nkey role in multiple NLP tasks that have been proven to beneficially leverage\nknowledge bases. Nevertheless, it has often been overlooked in the monolingual\nEnglish entity linking literature, as naive approaches obtain very good\nperformance. Unfortunately, the existing approaches for English cannot be\nsuccessfully transferred to poorly resourced languages. This paper constitutes\nan in-depth analysis of the candidate generation problem in the context of\ncross-lingual entity linking with a focus on low-resource languages. Among\nother contributions, we point out limitations in the evaluation conducted in\nprevious works. We introduce a characterization of queries into types based on\ntheir difficulty, which improves the interpretability of the performance of\ndifferent methods. We also propose a light-weight and simple solution based on\nthe construction of indexes whose design is motivated by more complex transfer\nlearning based neural approaches. A thorough empirical analysis on 9 real-world\ndatasets under 2 evaluation settings shows that our simple solution outperforms\nthe state-of-the-art approach in terms of both quality and efficiency for\nalmost all datasets and query types.",
    "descriptor": "\nComments: LREC 2022\n",
    "authors": [
      "Alberto Garc\u00eda-Dur\u00e1n",
      "Akhil Arora",
      "Robert West"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15163"
  },
  {
    "id": "arXiv:2206.15165",
    "title": "MatPIM: Accelerating Matrix Operations with Memristive Stateful Logic",
    "abstract": "The emerging memristive Memory Processing Unit (mMPU) overcomes the memory\nwall through memristive devices that unite storage and logic for real\nprocessing-in-memory (PIM) systems. At the core of the mMPU is stateful logic,\nwhich is accelerated with memristive partitions to enable logic with massive\ninherent parallelism within crossbar arrays. This paper vastly accelerates the\nfundamental operations of matrix-vector multiplication and convolution in the\nmMPU, with either full-precision or binary elements. These proposed algorithms\nestablish an efficient foundation for large-scale mMPU applications such as\nneural-networks, image processing, and numerical methods. We overcome the\ninherent asymmetry limitation in the previous in-memory full-precision\nmatrix-vector multiplication solutions by utilizing techniques from block\nmatrix multiplication and reduction. We present the first fast in-memory binary\nmatrix-vector multiplication algorithm by utilizing memristive partitions with\na tree-based popcount reduction (39x faster than previous work). For\nconvolution, we present a novel in-memory input-parallel concept which we\nutilize for a full-precision algorithm that overcomes the asymmetry limitation\nin convolution, while also improving latency (2x faster than previous work),\nand the first fast binary algorithm (12x faster than previous work).",
    "descriptor": "",
    "authors": [
      "Orian Leitersdorf",
      "Ronny Ronen",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.15165"
  },
  {
    "id": "arXiv:2206.15167",
    "title": "Convergence Analysis of Dirichlet Energy Minimization for Spherical  Conformal Parameterizations",
    "abstract": "In this paper, we first derive a theoretical basis for spherical conformal\nparameterizations between a simply connected closed surface $\\mathcal{S}$ and a\nunit sphere $\\mathbb{S}^2$ by minimizing the Dirichlet energy on\n$\\overline{\\mathbb{C}}$ by stereographic projection. The Dirichlet energy can\nbe rewritten as the sum of the energies associated with the southern and\nnorthern hemispheres and can be decreased under an equivalence relation by\nalternatingly solving the corresponding Laplacian equations. Based on this\ntheoretical foundation, we develop a modified Dirichlet energy minimization\nwith nonequivalence deflation for the computation of the spherical conformal\nparameterization between $\\mathcal{S}$ and $\\mathbb{S}^2$. In addition, under\nsome mild conditions, we verify the asymptotically R-linear convergence of the\nproposed algorithm. Numerical experiments on various benchmarks confirm that\nthe assumptions for convergence always hold and indicate the efficiency,\nreliability and robustness of the developed modified Dirichlet energy\nminimization.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Wei-Hung Liao",
      "Tsung-Ming Huang",
      "Wen-Wei Lin",
      "Mei-Heng Yueh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.15167"
  },
  {
    "id": "arXiv:2206.15169",
    "title": "Minimization of Dynamical Systems over Monoids",
    "abstract": "Quantitative notions of bisimulation are well-known tools for the\nminimization of dynamical models such as Markov chains and differential\nequations. In a forward-type bisimulation, each state in the quotient model\nrepresents an equivalence class and the dynamical evolution gives the overall\nsum of its members in the original model. Here we introduce generalized forward\nbisimulation (GFB) for dynamical systems over commutative monoids and develop a\npartition refinement algorithm to compute the largest one. When the monoid is\n(R, +), our framework recovers probabilistic bisimulation for Markov chains and\nmore recent forward bisimulations for systems of nonlinear ordinary\ndifferential equations. When the monoid is (R, product) we can obtain nonlinear\nmodel reductions for discrete-time dynamical systems and ordinary differential\nequations where each variable in the quotient model represents the product of\noriginal variables in the equivalence class. When the domain is a finite set\nsuch as the Booleans B, we can apply GFB to Boolean networks, a widely used\ndynamical model in computational biology. Using a prototype implementation of\nour minimization algorithm for GFB, we find several disjunction- and\nconjuction-preserving reductions on 60 Boolean networks from two well-known\nmodel repositories.",
    "descriptor": "",
    "authors": [
      "Georgios Argyris",
      "Alberto Lluch Lafuente",
      "Mirco Tribastone",
      "Max Tschaikowski",
      "Andrea Vandin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2206.15169"
  },
  {
    "id": "arXiv:2206.15170",
    "title": "LiDAR-as-Camera for End-to-End Driving",
    "abstract": "The core task of any autonomous driving system is to transform sensory inputs\ninto driving commands. In end-to-end driving, this is achieved via a neural\nnetwork, with one or multiple cameras as the most commonly used input and\nlow-level driving command, e.g. steering angle, as output. However,\ndepth-sensing has been shown in simulation to make the end-to-end driving task\neasier. On a real car, combining depth and visual information can be\nchallenging, due to the difficulty of obtaining good spatial and temporal\nalignment of the sensors. To alleviate alignment problems, Ouster LiDARs can\noutput surround-view LiDAR-images with depth, intensity, and ambient radiation\nchannels. These measurements originate from the same sensor, rendering them\nperfectly aligned in time and space. We demonstrate that such LiDAR-images are\nsufficient for the real-car road-following task and perform at least equally to\ncamera-based models in the tested conditions, with the difference increasing\nwhen needing to generalize to new weather conditions. In the second direction\nof study, we reveal that the temporal smoothness of off-policy prediction\nsequences correlates equally well with actual on-policy driving ability as the\ncommonly used mean absolute error.",
    "descriptor": "",
    "authors": [
      "Ardi Tampuu",
      "Romet Aidla",
      "Jan Are van Gent",
      "Tambet Matiisen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.15170"
  },
  {
    "id": "arXiv:2206.15174",
    "title": "Graph-Time Convolutional Neural Networks: Architecture and Theoretical  Analysis",
    "abstract": "Devising and analyzing learning models for spatiotemporal network data is of\nimportance for tasks including forecasting, anomaly detection, and multi-agent\ncoordination, among others. Graph Convolutional Neural Networks (GCNNs) are an\nestablished approach to learn from time-invariant network data. The graph\nconvolution operation offers a principled approach to aggregate multiresolution\ninformation. However, extending the convolution principled learning and\nrespective analysis to the spatiotemporal domain is challenging because\nspatiotemporal data have more intrinsic dependencies. Hence, a higher\nflexibility to capture jointly the spatial and the temporal dependencies is\nrequired to learn meaningful higher-order representations. Here, we leverage\nproduct graphs to represent the spatiotemporal dependencies in the data and\nintroduce Graph-Time Convolutional Neural Networks (GTCNNs) as a principled\narchitecture to aid learning. The proposed approach can work with any type of\nproduct graph and we also introduce a parametric product graph to learn also\nthe spatiotemporal coupling. The convolution principle further allows a similar\nmathematical tractability as for GCNNs. In particular, the stability result\nshows GTCNNs are stable to spatial perturbations but there is an implicit\ntrade-off between discriminability and robustness; i.e., the more complex the\nmodel, the less stable. Extensive numerical results on benchmark datasets\ncorroborate our findings and show the GTCNN compares favorably with\nstate-of-the-art solutions. We anticipate the GTCNN to be a starting point for\nmore sophisticated models that achieve good performance but are also\nfundamentally grounded.",
    "descriptor": "",
    "authors": [
      "Mohammad Sabbaqi",
      "Elvin Isufi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15174"
  },
  {
    "id": "arXiv:2206.15176",
    "title": "A Time Series Forecasting Approach to Minimize Cold Start Time in  Cloud-Serverless Platform",
    "abstract": "Serverless computing is a buzzword that is being used commonly in the world\nof technology and among developers and businesses. Using the\nFunction-as-a-Service (FaaS) model of serverless, one can easily deploy their\napplications to the cloud and go live in a matter of days, it facilitates the\ndevelopers to focus on their core business logic and the backend process such\nas managing the infrastructure, scaling of the application, updation of\nsoftware and other dependencies is handled by the Cloud Service Provider. One\nof the features of serverless computing is ability to scale the containers to\nzero, which results in a problem called cold start. The challenging part is to\nreduce the cold start latency without the consumption of extra resources. In\nthis paper, we use SARIMA (Seasonal Auto Regressive Integrated Moving Average),\none of the classical time series forecasting models to predict the time at\nwhich the incoming request comes, and accordingly increase or decrease the\namount of required containers to minimize the resource wastage, thus reducing\nthe function launching time. Finally, we implement PBA (Prediction Based\nAutoscaler) and compare it with the default HPA (Horizontal Pod Autoscaler),\nwhich comes inbuilt with kubernetes. The results showed that PBA performs\nfairly better than the default HPA, while reducing the wastage of resources.",
    "descriptor": "",
    "authors": [
      "Akash Puliyadi Jegannathan",
      "Rounak Saha",
      "Sourav Kanti Addya"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.15176"
  },
  {
    "id": "arXiv:2206.15183",
    "title": "Neural Network Assisted Depth Map Packing for Compression Using Standard  Hardware Video Codecs",
    "abstract": "Depth maps are needed by various graphics rendering and processing\noperations. Depth map streaming is often necessary when such operations are\nperformed in a distributed system and it requires in most cases fast performing\ncompression, which is why video codecs are often used. Hardware implementations\nof standard video codecs enable relatively high resolution and framerate\ncombinations, even on resource constrained devices, but unfortunately those\nimplementations do not currently support RGB+depth extensions. However, they\ncan be used for depth compression by first packing the depth maps into RGB or\nYUV frames. We investigate depth map compression using a combination of depth\nmap packing followed by encoding with a standard video codec. We show that the\nprecision at which depth maps are packed has a large and nontrivial impact on\nthe resulting error caused by the combination of the packing scheme and lossy\ncompression when bitrate is constrained. Consequently, we propose a variable\nprecision packing scheme assisted by a neural network model that predicts the\noptimal precision for each depth map given a bitrate constraint. We demonstrate\nthat the model yields near optimal predictions and that it can be integrated\ninto a game engine with very low overhead using modern hardware.",
    "descriptor": "\nComments: paper under submission\n",
    "authors": [
      "Matti Siekkinen",
      "Teemu K\u00e4m\u00e4r\u00e4inen"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15183"
  },
  {
    "id": "arXiv:2206.15186",
    "title": "Out-of-Distribution Detection for Long-tailed and Fine-grained Skin  Lesion Images",
    "abstract": "Recent years have witnessed a rapid development of automated methods for skin\nlesion diagnosis and classification. Due to an increasing deployment of such\nsystems in clinics, it has become important to develop a more robust system\ntowards various Out-of-Distribution(OOD) samples (unknown skin lesions and\nconditions). However, the current deep learning models trained for skin lesion\nclassification tend to classify these OOD samples incorrectly into one of their\nlearned skin lesion categories. To address this issue, we propose a simple yet\nstrategic approach that improves the OOD detection performance while\nmaintaining the multi-class classification accuracy for the known categories of\nskin lesion. To specify, this approach is built upon a realistic scenario of a\nlong-tailed and fine-grained OOD detection task for skin lesion images. Through\nthis approach, 1) First, we target the mixup amongst middle and tail classes to\naddress the long-tail problem. 2) Later, we combine the above mixup strategy\nwith prototype learning to address the fine-grained nature of the dataset. The\nunique contribution of this paper is two-fold, justified by extensive\nexperiments. First, we present a realistic problem setting of OOD task for skin\nlesion. Second, we propose an approach to target the long-tailed and\nfine-grained aspects of the problem setting simultaneously to increase the OOD\nperformance.",
    "descriptor": "\nComments: Accepted to MICCAI 2022 (top 13% paper; early accept)\n",
    "authors": [
      "Deval Mehta",
      "Yaniv Gal",
      "Adrian Bowling",
      "Paul Bonnington",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15186"
  },
  {
    "id": "arXiv:2206.15189",
    "title": "Multi-Granularity Regularized Re-Balancing for Class Incremental  Learning",
    "abstract": "Deep learning models suffer from catastrophic forgetting when learning new\ntasks incrementally. Incremental learning has been proposed to retain the\nknowledge of old classes while learning to identify new classes. A typical\napproach is to use a few exemplars to avoid forgetting old knowledge. In such a\nscenario, data imbalance between old and new classes is a key issue that leads\nto performance degradation of the model. Several strategies have been designed\nto rectify the bias towards the new classes due to data imbalance. However,\nthey heavily rely on the assumptions of the bias relation between old and new\nclasses. Therefore, they are not suitable for complex real-world applications.\nIn this study, we propose an assumption-agnostic method, Multi-Granularity\nRegularized re-Balancing (MGRB), to address this problem. Re-balancing methods\nare used to alleviate the influence of data imbalance; however, we empirically\ndiscover that they would under-fit new classes. To this end, we further design\na novel multi-granularity regularization term that enables the model to\nconsider the correlations of classes in addition to re-balancing the data. A\nclass hierarchy is first constructed by grouping the semantically or visually\nsimilar classes. The multi-granularity regularization then transforms the\none-hot label vector into a continuous label distribution, which reflects the\nrelations between the target class and other classes based on the constructed\nclass hierarchy. Thus, the model can learn the inter-class relational\ninformation, which helps enhance the learning of both old and new classes.\nExperimental results on both public datasets and a real-world fault diagnosis\ndataset verify the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Huitong Chen",
      "Yu Wang",
      "Qinghua Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15189"
  },
  {
    "id": "arXiv:2206.15190",
    "title": "Classification of network topology and dynamics via sequence  characterization",
    "abstract": "Sequences arise in many real-world scenarios; thus, identifying the\nmechanisms behind symbol generation is essential to understanding many complex\nsystems. This paper analyzes sequences generated by agents walking on a\nnetworked topology. Given that in many real scenarios, the underlying processes\ngenerating the sequence is hidden, we investigate whether the reconstruction of\nthe network via the co-occurrence method is useful to recover both the network\ntopology and agent dynamics generating sequences. We found that the\ncharacterization of reconstructed networks provides valuable information\nregarding the process and topology used to create the sequences. In a machine\nlearning approach considering 16 combinations of network topology and agent\ndynamics as classes, we obtained an accuracy of 87% with sequences generated\nwith less than 40% of nodes visited. Larger sequences turned out to generate\nimproved machine learning models. Our findings suggest that the proposed\nmethodology could be extended to classify sequences and understand the\nmechanisms behind sequence generation.",
    "descriptor": "",
    "authors": [
      "Lucas Guerreiro",
      "Filipi N. Silva",
      "Diego R. Amancio"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15190"
  },
  {
    "id": "arXiv:2206.15192",
    "title": "Privacy-preserving household load forecasting based on non-intrusive  load monitoring: A federated deep learning approach",
    "abstract": "Load forecasting is very essential in the analysis and grid planning of power\nsystems. For this reason, we first propose a household load forecasting method\nbased on federated deep learning and non-intrusive load monitoring (NILM). For\nall we know, this is the first research on federated learning (FL) in household\nload forecasting based on NILM. In this method, the integrated power is\ndecomposed into individual device power by non-intrusive load monitoring, and\nthe power of individual appliances is predicted separately using a federated\ndeep learning model. Finally, the predicted power values of individual\nappliances are aggregated to form the total power prediction. Specifically, by\nseparately predicting the electrical equipment to obtain the predicted power,\nit avoids the error caused by the strong time dependence in the power signal of\na single device. And in the federated deep learning prediction model, the\nhousehold owners with the power data share the parameters of the local model\ninstead of the local power data, guaranteeing the privacy of the household user\ndata. The case results demonstrate that the proposed approach provides a better\nprediction effect than the traditional methodology that directly predicts the\naggregated signal as a whole. In addition, experiments in various federated\nlearning environments are designed and implemented to validate the validity of\nthis methodology.",
    "descriptor": "\nComments: Accepted by PeerJ Computer Science\n",
    "authors": [
      "Xinxin Zhou",
      "Jingru Feng",
      "Jian Wang",
      "Jianhong Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.15192"
  },
  {
    "id": "arXiv:2206.15195",
    "title": "The Topological BERT: Transforming Attention into Topology for Natural  Language Processing",
    "abstract": "In recent years, the introduction of the Transformer models sparked a\nrevolution in natural language processing (NLP). BERT was one of the first text\nencoders using only the attention mechanism without any recurrent parts to\nachieve state-of-the-art results on many NLP tasks.\nThis paper introduces a text classifier using topological data analysis. We\nuse BERT's attention maps transformed into attention graphs as the only input\nto that classifier. The model can solve tasks such as distinguishing spam from\nham messages, recognizing whether a sentence is grammatically correct, or\nevaluating a movie review as negative or positive. It performs comparably to\nthe BERT baseline and outperforms it on some tasks.\nAdditionally, we propose a new method to reduce the number of BERT's\nattention heads considered by the topological classifier, which allows us to\nprune the number of heads from 144 down to as few as ten with no reduction in\nperformance. Our work also shows that the topological model displays higher\nrobustness against adversarial attacks than the original BERT model, which is\nmaintained during the pruning process. To the best of our knowledge, this work\nis the first to confront topological-based models with adversarial attacks in\nthe context of NLP.",
    "descriptor": "",
    "authors": [
      "Ilan Perez",
      "Raphael Reinauer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2206.15195"
  },
  {
    "id": "arXiv:2206.15198",
    "title": "ListBERT: Learning to Rank E-commerce products with Listwise BERT",
    "abstract": "Efficient search is a critical component for an e-commerce platform with an\ninnumerable number of products. Every day millions of users search for products\npertaining to their needs. Thus, showing the relevant products on the top will\nenhance the user experience. In this work, we propose a novel approach of\nfusing a transformer-based model with various listwise loss functions for\nranking e-commerce products, given a user query. We pre-train a RoBERTa model\nover a fashion e-commerce corpus and fine-tune it using different listwise loss\nfunctions. Our experiments indicate that the RoBERTa model fine-tuned with an\nNDCG based surrogate loss function(approxNDCG) achieves an NDCG improvement of\n13.9% compared to other popular listwise loss functions like ListNET and\nListMLE. The approxNDCG based RoBERTa model also achieves an NDCG improvement\nof 20.6% compared to the pairwise RankNet based RoBERTa model. We call our\nmethodology of directly optimizing the RoBERTa model in an end-to-end manner\nwith a listwise surrogate loss function as ListBERT. Since there is a low\nlatency requirement in a real-time search setting, we show how these models can\nbe easily adopted by using a knowledge distillation technique to learn a\nrepresentation-focused student model that can be easily deployed and leads to\n~10 times lower ranking latency.",
    "descriptor": "\nComments: 5 Pages, 1 Figure, accepted in SigirEcom'22, Madrid, Spain\n",
    "authors": [
      "Lakshya Kumar",
      "Sagnik Sarkar"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.15198"
  },
  {
    "id": "arXiv:2206.15201",
    "title": "Learning-Augmented Query Policies for Minimum Spanning Tree with  Uncertainty",
    "abstract": "We study how to utilize (possibly erroneous) predictions in a model for\ncomputing under uncertainty in which an algorithm can query unknown data. Our\naim is to minimize the number of queries needed to solve the minimum spanning\ntree problem, a fundamental combinatorial optimization problem that has been\ncentral also to the research area of explorable uncertainty. For all integral\n$\\gamma\\ge 2$, we present algorithms that are $\\gamma$-robust and\n$(1+\\frac{1}{\\gamma})$-consistent, meaning that they use at most $\\gamma OPT$\nqueries if the predictions are arbitrarily wrong and at most\n$(1+\\frac{1}{\\gamma})OPT$ queries if the predictions are correct, where $OPT$\nis the optimal number of queries for the given instance. Moreover, we show that\nthis trade-off is best possible. Furthermore, we argue that a suitably defined\nhop distance is a useful measure for the amount of prediction error and design\nalgorithms with performance guarantees that degrade smoothly with the hop\ndistance. We also show that the predictions are PAC-learnable in our model. Our\nresults demonstrate that untrusted predictions can circumvent the known lower\nbound of~$2$, without any degradation of the worst-case ratio. To obtain our\nresults, we provide new structural insights for the minimum spanning tree\nproblem that might be useful in the context of query-based algorithms\nregardless of predictions. In particular, we generalize the concept of witness\nsets -- the key to lower-bounding the optimum -- by proposing novel global\nwitness set structures and completely new ways of adaptively using those.",
    "descriptor": "\nComments: This is an extended version of an ESA 2022 paper. arXiv admin note: text overlap with arXiv:2011.07385\n",
    "authors": [
      "Thomas Erlebach",
      "Murilo Santos de Lima",
      "Nicole Megow",
      "Jens Schl\u00f6ter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15201"
  },
  {
    "id": "arXiv:2206.15202",
    "title": "Tuple Interpretations and Applications to Higher-Order Runtime  Complexity",
    "abstract": "Tuple interpretations are a class of algebraic interpretation that subsumes\nboth polynomial and matrix interpretations as it does not impose simple\ntermination and allows non-linear interpretations. It was developed in the\ncontext of higher-order rewriting to study derivational complexity of algebraic\nfunctional systems. In this short paper, we continue our journey to study the\ncomplexity of higher-order TRSs by tailoring tuple interpretations to deal with\ninnermost runtime complexity.",
    "descriptor": "",
    "authors": [
      "Cynthia Kop",
      "Deivid Vale"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2206.15202"
  },
  {
    "id": "arXiv:2206.15203",
    "title": "Goodput Maximization with Quantized Feedback in the Finite Blocklength  Regime for Quasi-Static Channels",
    "abstract": "In this paper, we study a quantized feedback scheme to maximize the goodput\nof a finite blocklength communication scenario over a quasi-static fading\nchannel. It is assumed that the receiver has perfect channel state information\n(CSI) and sends back the CSI to the transmitter over a resolution-limited\nerror-free feedback channel. With this partial CSI, the transmitter is supposed\nto select the optimum transmission rate, such that it maximizes the overall\ngoodput of the communication system. This problem has been studied for the\nasymptotic blocklength regime, however, no solution has so far been presented\nfor finite blocklength. Here, we study this problem in two cases: with and\nwithout constraint on reliability. We first formulate the optimization problems\nand analytically solve them. Iterative algorithms that successfully exploit the\nsystem parameters for both cases are presented. It is shown that although the\nachievable maximum goodput decreases with shorter blocklengths and higher\nreliability requirements, significant improvement can be achieved even with\ncoarsely quantized feedback schemes.",
    "descriptor": "",
    "authors": [
      "Hasan Basri Celebi",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.15203"
  },
  {
    "id": "arXiv:2206.15204",
    "title": "Data-Efficient Learning via Minimizing Hyperspherical Energy",
    "abstract": "Deep learning on large-scale data is dominant nowadays. The unprecedented\nscale of data has been arguably one of the most important driving forces for\nthe success of deep learning. However, there still exist scenarios where\ncollecting data or labels could be extremely expensive, e.g., medical imaging\nand robotics. To fill up this gap, this paper considers the problem of\ndata-efficient learning from scratch using a small amount of representative\ndata. First, we characterize this problem by active learning on homeomorphic\ntubes of spherical manifolds. This naturally generates feasible hypothesis\nclass. With homologous topological properties, we identify an important\nconnection -- finding tube manifolds is equivalent to minimizing hyperspherical\nenergy (MHE) in physical geometry. Inspired by this connection, we propose a\nMHE-based active learning (MHEAL) algorithm, and provide comprehensive\ntheoretical guarantees for MHEAL, covering convergence and generalization\nanalysis. Finally, we demonstrate the empirical performance of MHEAL in a wide\nrange of applications on data-efficient learning, including deep clustering,\ndistribution matching, version space sampling and deep active learning.",
    "descriptor": "",
    "authors": [
      "Xiaofeng Cao",
      "Weiyang Liu",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15204"
  },
  {
    "id": "arXiv:2206.15205",
    "title": "When an Active Learner Meets a Black-box Teacher",
    "abstract": "Active learning maximizes the hypothesis updates to find those desired\nunlabeled data. An inherent assumption is that this learning manner can derive\nthose updates into the optimal hypothesis. However, its convergence may not be\nguaranteed well if those incremental updates are negative and disordered. In\nthis paper, we introduce a machine teacher who provides a black-box teaching\nhypothesis for an active learner, where the teaching hypothesis is an effective\napproximation for the optimal hypothesis. Theoretically, we prove that, under\nthe guidance of this teaching hypothesis, the learner can converge into a\ntighter generalization error and label complexity bound than those non-educated\nlearners who do not receive any guidance from a teacher. We further consider\ntwo teaching scenarios: teaching a white-box and black-box learner, where\nself-improvement of teaching is firstly proposed to improve the teaching\nperformance. Experiments verify this idea and show better performance than the\nfundamental active learning strategies, such as IWAL, IWAL-D, etc.",
    "descriptor": "",
    "authors": [
      "Xiaofeng Cao",
      "Yaming Guo",
      "Tieru Wu",
      "Ivor W. Tsang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15205"
  },
  {
    "id": "arXiv:2206.15211",
    "title": "Depth-CUPRL: Depth-Imaged Contrastive Unsupervised Prioritized  Representations in Reinforcement Learning for Mapless Navigation of Unmanned  Aerial Vehicles",
    "abstract": "Reinforcement Learning (RL) has presented an impressive performance in video\ngames through raw pixel imaging and continuous control tasks. However, RL\nperforms poorly with high-dimensional observations such as raw pixel images. It\nis generally accepted that physical state-based RL policies such as laser\nsensor measurements give a more sample-efficient result than learning by\npixels. This work presents a new approach that extracts information from a\ndepth map estimation to teach an RL agent to perform the mapless navigation of\nUnmanned Aerial Vehicle (UAV). We propose the Depth-Imaged Contrastive\nUnsupervised Prioritized Representations in Reinforcement Learning(Depth-CUPRL)\nthat estimates the depth of images with a prioritized replay memory. We used a\ncombination of RL and Contrastive Learning to lead with the problem of RL based\non images. From the analysis of the results with Unmanned Aerial Vehicles\n(UAVs), it is possible to conclude that our Depth-CUPRL approach is effective\nfor the decision-making and outperforms state-of-the-art pixel-based approaches\nin the mapless navigation capability.",
    "descriptor": "\nComments: Accepted to the IEEE International Conference on Intelligent Robots and Systems (ICROS) 2022\n",
    "authors": [
      "Junior Costa de Jesus",
      "Victor Augusto Kich",
      "Alisson Henrique Kolling",
      "Ricardo Bedin Grando",
      "Rodrigo da Silva Guerra",
      "Paulo Lilles Jorge Drews Jr"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15211"
  },
  {
    "id": "arXiv:2206.15218",
    "title": "The Body Scaling Effect and Its Impact on Physics Plausibility",
    "abstract": "In this study we investigated the effect of body ownership illusion-based\nbody scaling on physics plausibility in Virtual Reality (VR). Our interest was\nin examining whether body ownership illusion-based body scaling could affect\nthe plausibility of rigid body dynamics similarly to altering VR users' scale\nby manipulating their virtual interpupillary distance and viewpoint height. The\nprocedure involved the conceptual replication of two previous studies. We\ninvestigated physics plausibility with 40 participants under two conditions. In\nour synchronous condition, we used visuo-tactile stimuli to elicit a body\nownership illusion of inhabiting an invisible doll-sized body on participants\nreclining on an exam table. Our asynchronous condition was otherwise similar,\nbut the visuo-tactile stimuli were provided asynchronously to prevent the onset\nof the body ownership illusion. We were interested in whether the correct\napproximation of physics (true physics) or physics that are incorrect and\nappearing as if the environment is five times larger instead (movie physics)\nappear more realistic to participants as a function of body scale. We found\nthat movie physics did appear more realistic to participants under the body\nownership illusion condition. However, our hypothesis that true physics would\nappear more realistic in the asynchronous condition was unsupported. Our\nexploratory analyses revealed that movie physics were perceived as plausible\nunder both conditions. Moreover, we were not able to replicate previous\nfindings from literature concerning object size estimations while inhabiting a\nsmall invisible body. However, we found a significant opposite effect regarding\nsize estimations; the object sizes were on average underestimated during the\nsynchronous visuo-tactile condition when compared to the asynchronous\ncondition.",
    "descriptor": "\nComments: Accepted version. Published version at this https URL\n",
    "authors": [
      "Matti Pouke",
      "Evan G. Center",
      "Alexis P. Chambers",
      "Sakaria Pouke",
      "Timo Ojala",
      "Steven M. LaValle"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.15218"
  },
  {
    "id": "arXiv:2206.15219",
    "title": "libACA, pyACA, and ACA-Code: Audio Content Analysis in 3 Languages",
    "abstract": "The three packages libACA, pyACA, and ACA-Code provide reference\nimplementations for basic approaches and algorithms for the analysis of musical\naudio signals in three different languages: C++, Python, and Matlab. All three\npackages cover the same algorithms, such as extraction of low level audio\nfeatures, fundamental frequency estimation, as well as simple approaches to\nchord recognition, musical key detection, and onset detection. In addition, it\nimplementations of more generic algorithms useful in audio content analysis\nsuch as dynamic time warping and the Viterbi algorithm are provided. The three\npackages thus provide a practical cross-language and cross-platform reference\nto students and engineers implementing audio analysis algorithms and enable\nimplementation-focused learning of algorithms for audio content analysis and\nmusic information retrieval.",
    "descriptor": "\nComments: Preprint submitted to \"Software Impacts\"\n",
    "authors": [
      "Alexander Lerch"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.15219"
  },
  {
    "id": "arXiv:2206.15221",
    "title": "Domain Adaptive Pretraining for Multilingual Acronym Extraction",
    "abstract": "This paper presents our findings from participating in the multilingual\nacronym extraction shared task SDU@AAAI-22. The task consists of acronym\nextraction from documents in 6 languages within scientific and legal domains.\nTo address multilingual acronym extraction we employed BiLSTM-CRF with\nmultilingual XLM-RoBERTa embeddings. We pretrained the XLM-RoBERTa model on the\nshared task corpus to further adapt XLM-RoBERTa embeddings to the shared task\ndomain(s). Our system (team: SMR-NLP) achieved competitive performance for\nacronym extraction across all the languages.",
    "descriptor": "\nComments: SDU@AAAI-22\n",
    "authors": [
      "Usama Yaseen",
      "Stefan Langer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.15221"
  },
  {
    "id": "arXiv:2206.15225",
    "title": "Are Hitting Formulas Hard for Resolution?",
    "abstract": "Hitting formulas, introduced by Iwama, are an unusual class of propositional\nCNF formulas. Not only is their satisfiability decidable in polynomial time,\nbut even their models can be counted in closed form. This stands in stark\ncontrast with other polynomial-time decidable classes, which usually have\nalgorithms based on backtracking and resolution and for which model counting\nremains hard, like 2-SAT and Horn-SAT. However, those resolution-based\nalgorithms usually easily imply an upper bound on resolution complexity, which\nis missing for hitting formulas. Are hitting formulas hard for resolution?\nIn this paper we take the first steps towards answering this question. We\nshow that the resolution complexity of hitting formulas is dominated by\nso-called irreducible hitting formulas, first studied by Kullmann and Zhao,\nthat cannot be composed of smaller hitting formulas. However, by definition,\nlarge irreducible unsatisfiable hitting formulas are difficult to construct; it\nis not even known whether infinitely many exist. Building upon our theoretical\nresults, we implement an efficient algorithm on top of the Nauty software\npackage to enumerate all irreducible unsatisfiable hitting formulas with up to\n14 clauses. We also determine the exact resolution complexity of the generated\nhitting formulas with up to 13 clauses by extending a known SAT encoding for\nour purposes. Our experimental results suggest that hitting formulas are indeed\nhard for resolution.",
    "descriptor": "",
    "authors": [
      "Tom\u00e1\u0161 Peitl",
      "Stefan Szeider"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.15225"
  },
  {
    "id": "arXiv:2206.15228",
    "title": "Signed ego network model and its application to Twitter",
    "abstract": "The Ego Network Model (ENM) describes how individuals organise their social\nrelations in concentric circles (typically five) of decreasing intimacy, and it\nhas been found almost ubiquitously in social networks, both offline and online.\nThe ENM gauges the tie strength between peers in terms of interaction\nfrequency, which is easy to measure and provides a good proxy for the time\nspent nurturing the relationship. However, advances in signed network analysis\nhave shown that positive and negative relations play very different roles in\nnetwork dynamics. For this reason, this work sets out to investigate the ENM\nwhen including signed relations. The main contributions of this paper are\ntwofold: firstly, a novel method of signing relationships between individuals\nusing sentiment analysis and, secondly, an investigation of the properties of\nSigned Ego Networks (Ego Networks with signed connections). Signed Ego Networks\nare then extracted for the users of eight different Twitter datasets composed\nof both specialised users (e.g. journalists) and generic users. We find that\nnegative links are over-represented in the active part of the Ego Networks of\nall types of users, suggesting that Twitter users tend to engage regularly with\nnegative connections. Further, we observe that negative relationships are\noverwhelmingly predominant in the Ego Network circles of specialised users,\nhinting at very polarised online interactions for this category of users. In\naddition, negative relationships are found disproportionately more at the more\nintimate levels of the ENM for journalists, while their percentages are stable\nacross the circles of the other Twitter users",
    "descriptor": "",
    "authors": [
      "Jack Tacchi",
      "Chiara Boldrini",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.15228"
  },
  {
    "id": "arXiv:2206.15236",
    "title": "Stochastic Poisson Surface Reconstruction",
    "abstract": "We introduce a statistical extension of the classic Poisson Surface\nReconstruction algorithm for recovering shapes from 3D point clouds. Instead of\noutputting an implicit function, we represent the reconstructed shape as a\nmodified Gaussian Process, which allows us to conduct statistical queries\n(e.g., the likelihood of a point in space being on the surface or inside a\nsolid). We show that this perspective: improves PSR's integration into the\nonline scanning process, broadens its application realm, and opens the door to\nother lines of research such as applying task-specific priors.",
    "descriptor": "",
    "authors": [
      "Silvia Sell\u00e1n",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.15236"
  },
  {
    "id": "arXiv:2206.15237",
    "title": "Adherence to Misinformation on Social Media Through Socio-Cognitive and  Group-Based Processes",
    "abstract": "Previous work suggests that people's preference for different kinds of\ninformation depends on more than just accuracy. This could happen because the\nmessages contained within different pieces of information may either be\nwell-liked or repulsive. Whereas factual information must often convey\nuncomfortable truths, misinformation can have little regard for veracity and\nleverage psychological processes which increase its attractiveness and\nproliferation on social media. In this review, we argue that when\nmisinformation proliferates, this happens because the social media environment\nenables adherence to misinformation by reducing, rather than increasing, the\npsychological cost of doing so. We cover how attention may often be shifted\naway from accuracy and towards other goals, how social and individual cognition\nis affected by misinformation and the cases under which debunking it is most\neffective, and how the formation of online groups affects information\nconsumption patterns, often leading to more polarization and radicalization.\nThroughout, we make the case that polarization and misinformation adherence are\nclosely tied. We identify ways in which the psychological cost of adhering to\nmisinformation can be increased when designing anti-misinformation\ninterventions or resilient affordances, and we outline open research questions\nthat the CSCW community can take up in further understanding this cost.",
    "descriptor": "",
    "authors": [
      "Alexandros Efstratiou",
      "Emiliano De Cristofaro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.15237"
  },
  {
    "id": "arXiv:2206.15238",
    "title": "Runtime Analysis of Competitive co-Evolutionary Algorithms for Maximin  Optimisation of a Bilinear Function",
    "abstract": "Co-evolutionary algorithms have a wide range of applications, such as in\nhardware design, evolution of strategies for board games, and patching software\nbugs. However, these algorithms are poorly understood and applications are\noften limited by pathological behaviour, such as loss of gradient, relative\nover-generalisation, and mediocre objective stasis. It is an open challenge to\ndevelop a theory that can predict when co-evolutionary algorithms find\nsolutions efficiently and reliable.\nThis paper provides a first step in developing runtime analysis for\npopulation-based competitive co-evolutionary algorithms. We provide a\nmathematical framework for describing and reasoning about the performance of\nco-evolutionary processes. An example application of the framework shows a\nscenario where a simple co-evolutionary algorithm obtains a solution in\npolynomial expected time. Finally, we describe settings where the\nco-evolutionary algorithm needs exponential time with overwhelmingly high\nprobability to obtain a solution.",
    "descriptor": "\nComments: To appear in Proceedings of the Genetic and Evolutionary Computation Conference (GECCO' 22)\n",
    "authors": [
      "Per Kristian Lehre"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2206.15238"
  },
  {
    "id": "arXiv:2206.15241",
    "title": "Benchmark Dataset for Precipitation Forecasting by Post-Processing the  Numerical Weather Prediction",
    "abstract": "Precipitation forecasting is an important scientific challenge that has\nwide-reaching impacts on society. Historically, this challenge has been tackled\nusing numerical weather prediction (NWP) models, grounded on physics-based\nsimulations. Recently, many works have proposed an alternative approach, using\nend-to-end deep learning (DL) models to replace physics-based NWP. While these\nDL methods show improved performance and computational efficiency, they exhibit\nlimitations in long-term forecasting and lack the explainability of NWP models.\nIn this work, we present a hybrid NWP-DL workflow to fill the gap between\nstandalone NWP and DL approaches. Under this workflow, the NWP output is fed\ninto a deep model, which post-processes the data to yield a refined\nprecipitation forecast. The deep model is trained with supervision, using\nAutomatic Weather Station (AWS) observations as ground-truth labels. This can\nachieve the best of both worlds, and can even benefit from future improvements\nin NWP technology. To facilitate study in this direction, we present a novel\ndataset focused on the Korean Peninsula, termed KoMet (Korea Meteorological\nDataset), comprised of NWP predictions and AWS observations. For NWP, we use\nthe Global Data Assimilation and Prediction Systems-Korea Integrated Model\n(GDAPS-KIM).",
    "descriptor": "\nComments: Under Review on NeurIPS 22 Benchmark Dataset Track\n",
    "authors": [
      "Taehyeon Kim",
      "Namgyu Ho",
      "Donggyu Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.15241"
  },
  {
    "id": "arXiv:2206.15242",
    "title": "Secure Heterogeneous Multi-Robot Collaboration and Docking with  Hyperledger Fabric Blockchain",
    "abstract": "In recent years, multi-robot systems have received increasing attention from\nboth industry and academia. Besides the need of accurate and robust estimation\nof relative localization, security and trust in the system are essential to\nenable wider adoption. In this paper, we propose a framework using Hyperledger\nFabric for multi-robot collaboration in industrial applications. We rely on\nblockchain identities for the interaction of ground and aerial robots, and use\nsmart contracts for collaborative decision making. The use of ultra-wideband\n(UWB) localization for both autonomous navigation and robot collaboration\nextends our previous work in Fabric-based fleet management. We focus on an\ninventory management application which uses a ground robot and an aerial robot\nto inspect a warehouse-like environment and store information about the found\nobjects in the blockchain. We measure the impact of adding the blockchain\nlayer, analyze the transaction commit latency and compare the resource\nutilization of blockchain-related processes to the already running data\nprocessing modules.",
    "descriptor": "",
    "authors": [
      "Salma Salimi",
      "Paola Torrico Mor\u00f3n",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.15242"
  },
  {
    "id": "arXiv:2206.15248",
    "title": "CTrGAN: Cycle Transformers GAN for Gait Transfer",
    "abstract": "We attempt for the first time to address the problem of gait transfer. In\ncontrast to motion transfer, the objective here is not to imitate the source's\nnormal motions, but rather to transform the source's motion into a typical gait\npattern for the target. Using gait recognition models, we demonstrate that\nexisting techniques yield a discrepancy that can be easily detected. We\nintroduce a novel model, Cycle Transformers GAN (CTrGAN), that can successfully\ngenerate the target's natural gait. CTrGAN's generators consist of a decoder\nand encoder, both Transformers, where the attention is on the temporal domain\nbetween complete images rather than the spatial domain between patches. While\nrecent Transformer studies in computer vision mainly focused on discriminative\ntasks, we introduce an architecture that can be applied to synthesis tasks.\nUsing a widely-used gait recognition dataset, we demonstrate that our approach\nis capable of producing over an order of magnitude more realistic personalized\ngaits than existing methods, even when used with sources that were not\navailable during training.",
    "descriptor": "",
    "authors": [
      "Shahar Mahpod",
      "Noam Gaash",
      "G. Ben-Artzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15248"
  },
  {
    "id": "arXiv:2206.15251",
    "title": "Menger's Theorem for Temporal Paths (Not Walks)",
    "abstract": "A temporal graph is a graph whose edges are available only at specific times.\nIn this scenario, the only valid walks are the ones traversing adjacent edges\nrespecting their availability, i.e. sequence of adjacent edges whose appearing\ntimes are non-decreasing. Temporal paths are temporal walks where each vertex\nis not traversed twice, i.e. time instants of each vertex, called temporal\nvertices, are visited consecutively. While on static graphs Menger's Theorem\nrelies on disjoint paths, in temporal graphs the literature has focused on\ndisjoint temporal walks. In this paper we focus on Menger's Theorem for\ntemporal paths that are disjoint in temporal vertices. Given two vertices $s$\nand $t$, let $k$ be equal to the maximum number of temporal vertex disjoint\n$s,t$-paths. We prove that $k$ is equal to the minimum number of temporal\nvertices to be removed to break all the $s,t$-paths, i.e. Menger's Theorem\nholds, if and only if $k=1$. The latter property also allows us to show that\nthe related max-paths problem in temporal graphs is polynomial when $k\\le 2$.\nThis is best possible as we prove that such problem is \\NP-hard when $k\\ge 3$\nfor the directed case. Finally, we also give hardness results and an XP\nalgorithm for the related min-cut problem.",
    "descriptor": "",
    "authors": [
      "Allen Ibiapina",
      "Raul Lopes",
      "Andrea Marino",
      "Ana Silva"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.15251"
  },
  {
    "id": "arXiv:2206.15253",
    "title": "Cohomology in Constraint Satisfaction and Structure Isomorphism",
    "abstract": "Constraint satisfaction (CSP) and structure isomorphism (SI) are among the\nmost well-studied computational problems in Computer Science. While neither\nproblem is thought to be in $\\texttt{PTIME},$ much work is done on\n$\\texttt{PTIME}$ approximations to both problems. Two such historically\nimportant approximations are the $k$-consistency algorithm for CSP and the\n$k$-Weisfeiler-Leman algorithm for SI, both of which are based on propagating\nlocal partial solutions. The limitations of these algorithms are well-known;\n$k$-consistency can solve precisely those CSPs of bounded width and\n$k$-Weisfeiler-Leman can only distinguish structures which differ on properties\ndefinable in $C^k$. In this paper, we introduce a novel sheaf-theoretic\napproach to CSP and SI and their approximations. We show that both problems can\nbe viewed as deciding the existence of global sections of presheaves,\n$\\mathcal{H}_k(A,B)$ and $\\mathcal{I}_k(A,B)$ and that the success of the\n$k$-consistency and $k$-Weisfeiler-Leman algorithms correspond to the existence\nof certain efficiently computable subpresheaves of these. Furthermore, building\non work of Abramsky and others in quantum foundations, we show how to use\n\\v{C}ech cohomology in $\\mathcal{H}_k(A,B)$ and $\\mathcal{I}_k(A,B)$ to detect\nobstructions to the existence of the desired global sections and derive new\nefficient cohomological algorithms extending $k$-consistency and\n$k$-Weisfeiler-Leman. We show that cohomological $k$-consistency can solve\nsystems of equations over all finite rings and that cohomological\nWeisfeiler-Leman can distinguish positive and negative instances of the\nCai-F\\\"urer-Immerman property over several important classes of structures.",
    "descriptor": "",
    "authors": [
      "Adam \u00d3 Conghaile"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15253"
  },
  {
    "id": "arXiv:2206.15255",
    "title": "Neural Rendering for Stereo 3D Reconstruction of Deformable Tissues in  Robotic Surgery",
    "abstract": "Reconstruction of the soft tissues in robotic surgery from endoscopic stereo\nvideos is important for many applications such as intra-operative navigation\nand image-guided robotic surgery automation. Previous works on this task mainly\nrely on SLAM-based approaches, which struggle to handle complex surgical\nscenes. Inspired by recent progress in neural rendering, we present a novel\nframework for deformable tissue reconstruction from binocular captures in\nrobotic surgery under the single-viewpoint setting. Our framework adopts\ndynamic neural radiance fields to represent deformable surgical scenes in MLPs\nand optimize shapes and deformations in a learning-based manner. In addition to\nnon-rigid deformations, tool occlusion and poor 3D clues from a single\nviewpoint are also particular challenges in soft tissue reconstruction. To\novercome these difficulties, we present a series of strategies of tool\nmask-guided ray casting, stereo depth-cueing ray marching and stereo\ndepth-supervised optimization. With experiments on DaVinci robotic surgery\nvideos, our method significantly outperforms the current state-of-the-art\nreconstruction method for handling various complex non-rigid deformations. To\nour best knowledge, this is the first work leveraging neural rendering for\nsurgical scene 3D reconstruction with remarkable potential demonstrated. Code\nis available at: https://github.com/med-air/EndoNeRF.",
    "descriptor": "\nComments: 11 pages, 4 figures, conference\n",
    "authors": [
      "Yuehao Wang",
      "Yonghao Long",
      "Siu Hin Fan",
      "Qi Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15255"
  },
  {
    "id": "arXiv:2206.15258",
    "title": "Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D  Camera",
    "abstract": "We propose Neural-DynamicReconstruction (NDR), a template-free method to\nrecover high-fidelity geometry and motions of a dynamic scene from a monocular\nRGB-D camera. In NDR, we adopt the neural implicit function for surface\nrepresentation and rendering such that the captured color and depth can be\nfully utilized to jointly optimize the surface and deformations. To represent\nand constrain the non-rigid deformations, we propose a novel neural invertible\ndeforming network such that the cycle consistency between arbitrary two frames\nis automatically satisfied. Considering that the surface topology of dynamic\nscene might change over time, we employ a topology-aware strategy to construct\nthe topology-variant correspondence for the fused frames. NDR also further\nrefines the camera poses in a global optimization manner. Experiments on public\ndatasets and our collected dataset demonstrate that NDR outperforms existing\nmonocular dynamic reconstruction methods.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Hongrui Cai",
      "Wanquan Feng",
      "Xuetao Feng",
      "Yan Wang",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.15258"
  },
  {
    "id": "arXiv:2206.15263",
    "title": "Proposal of deployment reconfiguration for environment adaptation",
    "abstract": "To use heterogeneous hardware, programmers needed sufficient technical skills\nsuch as OpenMP, CUDA, and OpenCL. Therefore, I have proposed\nenvironment-adaptive software that enables high-performance operation by\nautomatically converting and configuring the code once written, and have been\nworking on automatic conversion and proper placement. However, until now, where\nto initially place the converted application has been considered, but the\noverall optimal placement has not been considered in consideration of the\nplacement status of other users. In this paper, as a new element of\nenvironment-adaptive software, I study the relocation during operation, which\nimproves the overall user satisfaction by considering the placement of other\nusers, using a linear programming method. It was confirmed that it can be\nproperly rearranged through simulation experiments.",
    "descriptor": "\nComments: 6 pages, 5 figures, in Japanese, IEICE Technical Report, ICM2022-13, July 2022\n",
    "authors": [
      "Yoji Yamato"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.15263"
  },
  {
    "id": "arXiv:2206.15268",
    "title": "Submission to Generic Event Boundary Detection Challenge@CVPR 2022:  Local Context Modeling and Global Boundary Decoding Approach",
    "abstract": "Generic event boundary detection (GEBD) is an important yet challenging task\nin video understanding, which aims at detecting the moments where humans\nnaturally perceive event boundaries. In this paper, we present a local context\nmodeling and global boundary decoding approach for GEBD task. Local context\nmodeling sub-network is proposed to perceive diverse patterns of generic event\nboundaries, and it generates powerful video representations and reliable\nboundary confidence. Based on them, global boundary decoding sub-network is\nexploited to decode event boundaries from a global view. Our proposed method\nachieves 85.13% F1-score on Kinetics-GEBD testing set, which achieves a more\nthan 22% F1-score boost compared to the baseline method. The code is available\nat https://github.com/JackyTown/GEBD_Challenge_CVPR2022.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.04771\n",
    "authors": [
      "Jiaqi Tang",
      "Zhaoyang Liu",
      "Jing Tan",
      "Chen Qian",
      "Wayne Wu",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15268"
  },
  {
    "id": "arXiv:2206.15269",
    "title": "Deep Reinforcement Learning with Swin Transformer",
    "abstract": "Transformers are neural network models that utilize multiple layers of\nself-attention heads. Attention is implemented in transformers as the\ncontextual embeddings of the 'key' and 'query'. Transformers allow the\nre-combination of attention information from different layers and the\nprocessing of all inputs at once, which are more convenient than recurrent\nneural networks when dealt with a large number of data. Transformers have\nexhibited great performances on natural language processing tasks in recent\nyears. Meanwhile, there have been tremendous efforts to adapt transformers into\nother fields of machine learning, such as Swin Transformer and Decision\nTransformer. Swin Transformer is a promising neural network architecture that\nsplits image pixels into small patches and applies local self-attention\noperations inside the (shifted) windows of fixed sizes. Decision Transformer\nhas successfully applied transformers to off-line reinforcement learning and\nshowed that random-walk samples from Atari games are sufficient to let an agent\nlearn optimized behaviors. However, it is considerably more challenging to\ncombine online reinforcement learning with transformers. In this article, we\nfurther explore the possibility of not modifying the reinforcement learning\npolicy, but only replacing the convolutional neural network architecture with\nthe self-attention architecture from Swin Transformer. Namely, we target at\nchanging how an agent views the world, but not how an agent plans about the\nworld. We conduct our experiment on 49 games in Arcade Learning Environment.\nThe results show that using Swin Transformer in reinforcement learning achieves\nsignificantly higher evaluation scores across the majority of games in Arcade\nLearning Environment. Thus, we conclude that online reinforcement learning can\nbenefit from exploiting self-attentions with spatial token embeddings.",
    "descriptor": "",
    "authors": [
      "Li Meng",
      "Morten Goodwin",
      "Anis Yazidi",
      "Paal Engelstad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15269"
  },
  {
    "id": "arXiv:2206.15273",
    "title": "Invariance Properties of the Natural Gradient in Overparametrised  Systems",
    "abstract": "The natural gradient field is a vector field that lives on a model equipped\nwith a distinguished Riemannian metric, e.g. the Fisher-Rao metric, and\nrepresents the direction of steepest ascent of an objective function on the\nmodel with respect to this metric. In practice, one tries to obtain the\ncorresponding direction on the parameter space by multiplying the ordinary\ngradient by the inverse of the Gram matrix associated with the metric. We refer\nto this vector on the parameter space as the natural parameter gradient. In\nthis paper we study when the pushforward of the natural parameter gradient is\nequal to the natural gradient. Furthermore we investigate the invariance\nproperties of the natural parameter gradient. Both questions are addressed in\nan overparametrised setting.",
    "descriptor": "",
    "authors": [
      "Jesse van Oostrum",
      "Johannes M\u00fcller",
      "Nihat Ay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.15273"
  },
  {
    "id": "arXiv:2206.15275",
    "title": "Multiclass-SGCN: Sparse Graph-based Trajectory Prediction with Agent  Class Embedding",
    "abstract": "Trajectory prediction of road users in real-world scenarios is challenging\nbecause their movement patterns are stochastic and complex. Previous\npedestrian-oriented works have been successful in modelling the complex\ninteractions among pedestrians, but fail in predicting trajectories when other\ntypes of road users are involved (e.g., cars, cyclists, etc.), because they\nignore user types. Although a few recent works construct densely connected\ngraphs with user label information, they suffer from superfluous spatial\ninteractions and temporal dependencies. To address these issues, we propose\nMulticlass-SGCN, a sparse graph convolution network based approach for\nmulti-class trajectory prediction that takes into consideration velocity and\nagent label information and uses a novel interaction mask to adaptively decide\nthe spatial and temporal connections of agents based on their interaction\nscores. The proposed approach significantly outperformed state-of-the-art\napproaches on the Stanford Drone Dataset, providing more realistic and\nplausible trajectory predictions.",
    "descriptor": "",
    "authors": [
      "Ruochen Li",
      "Stamos Katsigiannis",
      "Hubert P. H. Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15275"
  },
  {
    "id": "arXiv:2206.15276",
    "title": "R-MelNet: Reduced Mel-Spectral Modeling for Neural TTS",
    "abstract": "This paper introduces R-MelNet, a two-part autoregressive architecture with a\nfrontend based on the first tier of MelNet and a backend WaveRNN-style audio\ndecoder for neural text-to-speech synthesis. Taking as input a mixed sequence\nof characters and phonemes, with an optional audio priming sequence, this model\nproduces low-resolution mel-spectral features which are interpolated and used\nby a WaveRNN decoder to produce an audio waveform. Coupled with half precision\ntraining, R-MelNet uses under 11 gigabytes of GPU memory on a single commodity\nGPU (NVIDIA 2080Ti). We detail a number of critical implementation details for\nstable half precision training, including an approximate, numerically stable\nmixture of logistics attention. Using a stochastic, multi-sample per step\ninference scheme, the resulting model generates highly varied audio, while\nenabling text and audio based controls to modify output waveforms. Qualitative\nand quantitative evaluations of an R-MelNet system trained on a single speaker\nTTS dataset demonstrate the effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Kyle Kastner",
      "Aaron Courville"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.15276"
  },
  {
    "id": "arXiv:2206.15282",
    "title": "TINC: Temporally Informed Non-Contrastive Learning for Disease  Progression Modeling in Retinal OCT Volumes",
    "abstract": "Recent contrastive learning methods achieved state-of-the-art in low label\nregimes. However, the training requires large batch sizes and heavy\naugmentations to create multiple views of an image. With non-contrastive\nmethods, the negatives are implicitly incorporated in the loss, allowing\ndifferent images and modalities as pairs. Although the meta-information (i.e.,\nage, sex) in medical imaging is abundant, the annotations are noisy and prone\nto class imbalance. In this work, we exploited already existing temporal\ninformation (different visits from a patient) in a longitudinal optical\ncoherence tomography (OCT) dataset using temporally informed non-contrastive\nloss (TINC) without increasing complexity and need for negative pairs.\nMoreover, our novel pair-forming scheme can avoid heavy augmentations and\nimplicitly incorporates the temporal information in the pairs. Finally, these\nrepresentations learned from the pretraining are more successful in predicting\ndisease progression where the temporal information is crucial for the\ndownstream task. More specifically, our model outperforms existing models in\npredicting the risk of conversion within a time frame from intermediate\nage-related macular degeneration (AMD) to the late wet-AMD stage.",
    "descriptor": "\nComments: Accepted at MICCAI 2022\n",
    "authors": [
      "Taha Emre",
      "Arunava Chakravarty",
      "Antoine Rivail",
      "Sophie Riedl",
      "Ursula Schmidt-Erfurth",
      "Hrvoje Bogunovi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15282"
  },
  {
    "id": "arXiv:2206.15285",
    "title": "Machine learning for automated quality control in injection moulding  manufacturing",
    "abstract": "Machine learning (ML) may improve and automate quality control (QC) in\ninjection moulding manufacturing. As the labelling of extensive, real-world\nprocess data is costly, however, the use of simulated process data may offer a\nfirst step towards a successful implementation. In this study, simulated data\nwas used to develop a predictive model for the product quality of an injection\nmoulded sorting container. The achieved accuracy, specificity and sensitivity\non the test set was $99.4\\%$, $99.7\\%$ and $94.7\\%$, respectively. This study\nthus shows the potential of ML towards automated QC in injection moulding and\nencourages the extension to ML models trained on real-world data.",
    "descriptor": "\nComments: Accepted for publishing in ESANN conference proceedings 2022\n",
    "authors": [
      "Steven Michiels",
      "C\u00e9dric De Schryver",
      "Lynn Houthuys",
      "Frederik Vogeler",
      "Frederik Desplentere"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15285"
  },
  {
    "id": "arXiv:2206.15291",
    "title": "Sonification as a Reliable Alternative to Conventional Visual Surgical  Navigation",
    "abstract": "Despite the undeniable advantages of image-guided surgical assistance systems\nin terms of accuracy, such systems have not yet fully met surgeons' needs or\nexpectations regarding usability, time efficiency, and their integration into\nthe surgical workflow. On the other hand, perceptual studies have shown that\npresenting independent but causally correlated information via multimodal\nfeedback involving different sensory modalities can improve task performance.\nThis article investigates an alternative method for computer-assisted surgical\nnavigation, introduces a novel sonification methodology for navigated pedicle\nscrew placement, and discusses advanced solutions based on multisensory\nfeedback. The proposed method comprises a novel sonification solution for\nalignment tasks in four degrees of freedom based on frequency modulation (FM)\nsynthesis. We compared the resulting accuracy and execution time of the\nproposed sonification method with visual navigation, which is currently\nconsidered the state of the art. We conducted a phantom study in which 17\nsurgeons executed the pedicle screw placement task in the lumbar spine, guided\nby either the proposed sonification-based or the traditional visual navigation\nmethod. The results demonstrated that the proposed method is as accurate as the\nstate of the art while decreasing the surgeon's need to focus on visual\nnavigation displays instead of the natural focus on surgical tools and targeted\nanatomy during task execution.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Sasan Matinfar",
      "Mehrdad Salehi",
      "Daniel Suter",
      "Matthias Seibold",
      "Navid Navab",
      "Shervin Dehghani",
      "Florian Wanivenhaus",
      "Philipp F\u00fcrnstahl",
      "Mazda Farshad",
      "Nassir Navab"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.15291"
  },
  {
    "id": "arXiv:2206.15296",
    "title": "Self-SuperFlow: Self-supervised Scene Flow Prediction in Stereo  Sequences",
    "abstract": "In recent years, deep neural networks showed their exceeding capabilities in\naddressing many computer vision tasks including scene flow prediction. However,\nmost of the advances are dependent on the availability of a vast amount of\ndense per pixel ground truth annotations, which are very difficult to obtain\nfor real life scenarios. Therefore, synthetic data is often relied upon for\nsupervision, resulting in a representation gap between the training and test\ndata. Even though a great quantity of unlabeled real world data is available,\nthere is a huge lack in self-supervised methods for scene flow prediction.\nHence, we explore the extension of a self-supervised loss based on the Census\ntransform and occlusion-aware bidirectional displacements for the problem of\nscene flow prediction. Regarding the KITTI scene flow benchmark, our method\noutperforms the corresponding supervised pre-training of the same network and\nshows improved generalization capabilities while achieving much faster\nconvergence.",
    "descriptor": "\nComments: Accepted at ICIP 2022\n",
    "authors": [
      "Katharina Bendig",
      "Ren\u00e9 Schuster",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15296"
  },
  {
    "id": "arXiv:2206.15298",
    "title": "Design and Motion Planning for a Reconfigurable Robotic Base",
    "abstract": "A robotic platform for mobile manipulation needs to satisfy two contradicting\nrequirements for many real-world applications: A compact base is required to\nnavigate through cluttered indoor environments, while the support needs to be\nlarge enough to prevent tumbling or tip over, especially during fast\nmanipulation operations with heavy payloads or forceful interaction with the\nenvironment. This paper proposes a novel robot design that fulfills both\nrequirements through a versatile footprint. It can reconfigure its footprint to\na narrow configuration when navigating through tight spaces and to a wide\nstance when manipulating heavy objects. Furthermore, its triangular\nconfiguration allows for high-precision tasks on uneven ground by preventing\nsupport switches. A model predictive control strategy is presented that unifies\nplanning and control for simultaneous navigation, reconfiguration, and\nmanipulation. It converts task-space goals into whole-body motion plans for the\nnew robot. The proposed design has been tested extensively with a hardware\nprototype. The footprint reconfiguration allows to almost completely remove\nmanipulation-induced vibrations. The control strategy proves effective in both\nlab experiment and during a real-world construction task.",
    "descriptor": "\nComments: 8 pages, accepted for RA-L and IROS 2022\n",
    "authors": [
      "Johannes Pankert",
      "Giorgio Valsecchi",
      "Davide Baret",
      "Jon Zehnder",
      "Lukasz L. Pietrasik",
      "Marko Bjelonic",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.15298"
  },
  {
    "id": "arXiv:2206.15302",
    "title": "A Distributed Massive MIMO Channel Sounder for \"Big CSI Data\"-driven  Machine Learning",
    "abstract": "A distributed massive MIMO channel sounder for acquiring large CSI datasets,\ndubbed DICHASUS, is presented. The measured data has potential applications in\nthe study of various machine learning algorithms for user localization, JCAS,\nchannel charting, enabling massive MIMO in FDD operation, and many others. The\nproposed channel sounder architecture is distinct from similar previous designs\nin that each individual single-antenna receiver is completely autonomous,\nenabling arbitrary, spatially distributed antenna deployments, and offering\nvirtually unlimited scalability in the number of antennas. Optionally,\nextracted channel coefficient vectors can be tagged with ground truth position\ndata, obtained either through a GNSS receiver (for outdoor operation) or\nthrough various indoor positioning techniques.",
    "descriptor": "",
    "authors": [
      "Florian Euchner",
      "Marc Gauger",
      "Sebastian D\u00f6rner",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.15302"
  },
  {
    "id": "arXiv:2206.15303",
    "title": "Physics-informed machine learning for Structural Health Monitoring",
    "abstract": "The use of machine learning in Structural Health Monitoring is becoming more\ncommon, as many of the inherent tasks (such as regression and classification)\nin developing condition-based assessment fall naturally into its remit. This\nchapter introduces the concept of physics-informed machine learning, where one\nadapts ML algorithms to account for the physical insight an engineer will often\nhave of the structure they are attempting to model or assess. The chapter will\ndemonstrate how grey-box models, that combine simple physics-based models with\ndata-driven ones, can improve predictive capability in an SHM setting. A\nparticular strength of the approach demonstrated here is the capacity of the\nmodels to generalise, with enhanced predictive capability in different regimes.\nThis is a key issue when life-time assessment is a requirement, or when\nmonitoring data do not span the operational conditions a structure will\nundergo.\nThe chapter will provide an overview of physics-informed ML, introducing a\nnumber of new approaches for grey-box modelling in a Bayesian setting. The main\nML tool discussed will be Gaussian process regression, we will demonstrate how\nphysical assumptions/models can be incorporated through constraints, through\nthe mean function and kernel design, and finally in a state-space setting. A\nrange of SHM applications will be demonstrated, from loads monitoring tasks for\noff-shore and aerospace structures, through to performance monitoring for\nlong-span bridges.",
    "descriptor": "",
    "authors": [
      "Elizabeth J Cross",
      "Samuel J Gibson",
      "Matthew R Jones",
      "Daniel J Pitchforth",
      "Sikai Zhang",
      "Timothy J Rogers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15303"
  },
  {
    "id": "arXiv:2206.15304",
    "title": "Designs, Motion Mechanism, Motion Coordination, and Communication of  Bionic Robot Fishes: A Survey",
    "abstract": "In the last few years, there have been many new developments and significant\naccomplishments in the research of bionic robot fishes. However, in terms of\nswimming performance, existing bionic robot fishes lag far behind fish,\nprompting researchers to constantly develop innovative designs of various\nbionic robot fishes. In this paper, the latest designs of robot fishes are\npresented in detail, distinguished by the propulsion mode. New robot fishes\nmainly include soft robot fishes and rigid-soft coupled robot fishes. The\nlatest progress in the study of the swimming mechanism is analyzed on the basis\nof summarizing the main swimming theories of fish. The current state-of-the-art\nresearch in the new field of motion coordination and communication of multiple\nrobot fishes is summarized. The general research trend in robot fishes is to\nutilize more efficient and robust methods to best mimic real fish while\nexhibiting superior swimming performance. The current challenges and potential\nfuture research directions are discussed. Various methods are needed to narrow\nthe gap in swimming performance between robot fishes and fish. This paper is a\nfirst step to bring together roboticists and marine biologists interested in\nlearning state-of-the-art research on bionic robot fishes.",
    "descriptor": "",
    "authors": [
      "Zhiwei Yu",
      "Kai Li",
      "Yu Ji",
      "Simon X. Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.15304"
  },
  {
    "id": "arXiv:2206.15306",
    "title": "Transfer Learning with Deep Tabular Models",
    "abstract": "Recent work on deep learning for tabular data demonstrates the strong\nperformance of deep tabular models, often bridging the gap between gradient\nboosted decision trees and neural networks. Accuracy aside, a major advantage\nof neural models is that they learn reusable features and are easily fine-tuned\nin new domains. This property is often exploited in computer vision and natural\nlanguage applications, where transfer learning is indispensable when\ntask-specific training data is scarce. In this work, we demonstrate that\nupstream data gives tabular neural networks a decisive advantage over widely\nused GBDT models. We propose a realistic medical diagnosis benchmark for\ntabular transfer learning, and we present a how-to guide for using upstream\ndata to boost performance with a variety of tabular neural network\narchitectures. Finally, we propose a pseudo-feature method for cases where the\nupstream and downstream feature sets differ, a tabular-specific problem\nwidespread in real-world applications. Our code is available at\nhttps://github.com/LevinRoman/tabular-transfer-learning .",
    "descriptor": "",
    "authors": [
      "Roman Levin",
      "Valeriia Cherepanova",
      "Avi Schwarzschild",
      "Arpit Bansal",
      "C. Bayan Bruss",
      "Tom Goldstein",
      "Andrew Gordon Wilson",
      "Micah Goldblum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15306"
  },
  {
    "id": "arXiv:2206.15308",
    "title": "Fast sampling of satisfying assignments from random $k$-SAT",
    "abstract": "We give the first nearly linear time algorithm to approximately sample\nsatisfying assignments in the random $k$-SAT model when the density of the\nformula scales exponentially with $k$. The best previously known sampling\nalgorithm for the random $k$-SAT model applies when the density $\\alpha=m/n$ of\nthe formula is less than $2^{k/300}$ and runs in time $n^{\\exp(\\Theta(k))}$\n(Galanis, Goldberg, Guo and Yang, SIAM J. Comput., 2021). Here $n$ is the\nnumber of variables and $m$ is the number of clauses. Our algorithm achieves a\nsignificantly faster running time of $n^{1 + o_k(1)}$ and samples satisfying\nassignments up to density $\\alpha\\leq 2^{rk}$ for $r = 0.1402$.\nThe main challenge in our setting is the presence of many variables with\nunbounded degree, which causes significant correlations within the formula and\nimpedes the application of relevant Markov chain methods from the\nbounded-degree setting (Feng, Guo, Yin and Zhang, J. ACM, 2021; Jain, Pham and\nVuong, 2021). Our main technical contribution is a novel approach to bound the\nsum of influences in the $k$-SAT model which turns out to be robust against the\npresence of high-degree variables. This allows us to apply the spectral\nindependence framework and obtain fast mixing results of a uniform-block\nGlauber dynamics on a carefully selected subset of the variables. The final key\ningredient in our method is to take advantage of the sparsity of\nlogarithmic-sized connected sets and the expansion properties of the random\nformula, and establish relevant properties of the set of satisfying assignments\nthat enable the fast simulation of this Glauber dynamics.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Andreas Galanis",
      "Leslie Ann Goldberg",
      "Heng Guo",
      "Andr\u00e9s Herrera-Poyatos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15308"
  },
  {
    "id": "arXiv:2206.15312",
    "title": "FL-Tuning: Layer Tuning for Feed-Forward Network in Transformer",
    "abstract": "Prompt tuning is an emerging way of adapting pre-trained language models to\ndownstream tasks. However, the existing studies are mainly to add prompts to\nthe input sequence. This way would not work as expected due to the intermediate\nmulti-head self-attention and feed-forward network computation, making model\noptimization not very smooth. Hence, we propose a novel tuning way called layer\ntuning, aiming to add learnable parameters in Transformer layers. Specifically,\nwe focus on layer tuning for feed-forward network in the Transformer, namely\nFL-tuning. It introduces additional units into the hidden layer of each\nfeed-forward network. We conduct extensive experiments on the public CLUE\nbenchmark. The results show that: 1) Our FL-tuning outperforms prompt tuning\nmethods under both full-data and few-shot settings in almost all cases. In\nparticular, it improves accuracy by 17.93% (full-data setting) on WSC 1.0 and\nF1 by 16.142% (few-shot setting) on CLUENER over P-tuning v2. 2) Our FL-tuning\nis more stable and converges about 1.17 times faster than P-tuning v2. 3) With\nonly about 3% of Transformer's parameters to be trained, FL-tuning is\ncomparable with fine-tuning on most datasets, and significantly outperforms\nfine-tuning (e.g., accuracy improved by 12.9% on WSC 1.1) on several datasets.\nThe source codes are available at https://github.com/genggui001/FL-Tuning.",
    "descriptor": "",
    "authors": [
      "Jingping Liu",
      "Yuqiu Song",
      "Kui Xue",
      "Hongli Sun",
      "Chao Wang",
      "Lihan Chen",
      "Haiyun Jiang",
      "Jiaqing Liang",
      "Tong Ruan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15312"
  },
  {
    "id": "arXiv:2206.15316",
    "title": "Interpretable Anomaly Detection in Echocardiograms with Dynamic  Variational Trajectory Models",
    "abstract": "We propose a novel anomaly detection method for echocardiogram videos. The\nintroduced method takes advantage of the periodic nature of the heart cycle to\nlearn different variants of a variational latent trajectory model (TVAE). The\nmodels are trained on the healthy samples of an in-house dataset of infant\nechocardiogram videos consisting of multiple chamber views to learn a normative\nprior of the healthy population. During inference, maximum a posteriori (MAP)\nbased anomaly detection is performed to detect out-of-distribution samples in\nour dataset. The proposed method reliably identifies severe congenital heart\ndefects, such as Ebstein's Anomaly or Shonecomplex. Moreover, it achieves\nsuperior performance over MAP-based anomaly detection with standard variational\nautoencoders on the task of detecting pulmonary hypertension and right\nventricular dilation. Finally, we demonstrate that the proposed method provides\ninterpretable explanations of its output through heatmaps which highlight the\nregions corresponding to anomalous heart structures.",
    "descriptor": "\nComments: accepted at IMLH workshop ICML 2022\n",
    "authors": [
      "Alain Ryser",
      "Laura Manduchi",
      "Fabian Laumer",
      "Holger Michel",
      "Sven Wellmann",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15316"
  },
  {
    "id": "arXiv:2206.15321",
    "title": "Exploiting Inherent Elasticity of Serverless in Irregular Algorithms",
    "abstract": "Serverless computing, in particular the Function-as-a-Service (FaaS)\nexecution model, has recently shown to be effective for running large-scale\ncomputations. However, little attention has been paid to highly-parallel\napplications with unbalanced and irregular workloads. Typically, these\nworkloads have been kept out of the cloud due to the impossibility of\nanticipating their computing resources ahead of time, frequently leading to\nsevere resource over- and underprovisioning situations. Our main insight in\nthis article is, however, that the elasticity and ease of management of\nserverless computing technology can be a key enabler for effectively running\nthese problematic workloads for the first time in the cloud. More concretely,\nwe demonstrate that with a simple serverless executor pool abstraction one can\nachieve a better cost-performance trade-off than a Spark cluster of static size\nbuilt upon large EC2 virtual machines. To support this conclusion, we evaluate\nthree irregular algorithms: Unbalanced Tree Search (UTS), Mandelbrot Set using\nthe Mariani-Silver algorithm and Betweenness Centrality (BC) on a random graph.\nFor instance, our serverless implementation of UTS is able to outperform Spark\nby up to 55% with the same cost. We also show that a serverless environment can\noutperform a large EC2 in the BC algorithm by a 10% using the same amount of\nvirtual CPUs. This provides the first concrete evidence that highly-parallel,\nirregular workloads can be efficiently executed using purely stateless\nfunctions with almost zero burden on users i.e., no need for users to\nunderstand non-obvious system-level parameters and optimizations. Furthermore,\nwe show that UTS can benefit from the FaaS pay-as-you-go billing model, which\nmakes it worth for the first time to enable certain application-level\noptimizations that can lead to significant improvements (e.g. of 41%) with\nnegligible increase in cost.",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Gerard Finol",
      "Gerard Par\u00eds",
      "Pedro Garc\u00eda-L\u00f3pez",
      "Marc S\u00e1nchez-Artigas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.15321"
  },
  {
    "id": "arXiv:2206.15323",
    "title": "Solar Power Smoothing in a Nanogrid Testbed",
    "abstract": "High penetration of solar power introduces new challenges in the operation of\ndistribution systems. Considering the highly volatile nature of solar power\noutput due to changes in cloud coverage, maintaining the power balance and\noperating within ramp rate limits can be an issue. Great benefits can be\nbrought to the grid by smoothing solar power output at individual sites\nequipped with flexible resources such as electrical vehicles and battery\nstorage systems. This paper proposes several approaches to a solar smoothing\napplication by utilizing battery storage and EV charging control in a\n\"Nanogrid\" testbed located at a utility in Florida. The control algorithms\nfocus on both real-time application and predictive control depending on\nforecasts. The solar smoothing models are then compared using real data from\nthe Nanogrid site to present the effectiveness of the proposed models and\ncompare their results. Furthermore, the control methods are applied to the\nOrlando Utilities Commission (OUC) Nanogrid to confirm the simulation results.",
    "descriptor": "",
    "authors": [
      "Hossein Panamtash",
      "Rubin York",
      "Paul Brooker",
      "Justin Kramer",
      "Qun Zhou Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.15323"
  },
  {
    "id": "arXiv:2206.15328",
    "title": "Neural Annotation Refinement: Development of a New 3D Dataset for  Adrenal Gland Analysis",
    "abstract": "The human annotations are imperfect, especially when produced by junior\npractitioners. Multi-expert consensus is usually regarded as golden standard,\nwhile this annotation protocol is too expensive to implement in many real-world\nprojects. In this study, we propose a method to refine human annotation, named\nNeural Annotation Refinement (NeAR). It is based on a learnable implicit\nfunction, which decodes a latent vector into represented shape. By integrating\nthe appearance as an input of implicit functions, the appearance-aware NeAR\nfixes the annotation artefacts. Our method is demonstrated on the application\nof adrenal gland analysis. We first show that the NeAR can repair distorted\ngolden standards on a public adrenal gland segmentation dataset. Besides, we\ndevelop a new Adrenal gLand ANalysis (ALAN) dataset with the proposed NeAR,\nwhere each case consists of a 3D shape of adrenal gland and its diagnosis label\n(normal vs. abnormal) assigned by experts. We show that models trained on the\nshapes repaired by the NeAR can diagnose adrenal glands better than the\noriginal ones. The ALAN dataset will be open-source, with 1,594 shapes for\nadrenal gland diagnosis, which serves as a new benchmark for medical shape\nanalysis. Code and dataset are available at https://github.com/M3DV/NeAR.",
    "descriptor": "\nComments: MICCAI 2022\n",
    "authors": [
      "Jiancheng Yang",
      "Rui Shi",
      "Udaranga Wickramasinghe",
      "Qikui Zhu",
      "Bingbing Ni",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.15328"
  },
  {
    "id": "arXiv:2206.15331",
    "title": "GitHub Copilot AI pair programmer: Asset or Liability?",
    "abstract": "Automatic program synthesis is a long-lasting dream in software engineering.\nRecently, a promising Deep Learning (DL) based solution, called Copilot, has\nbeen proposed by Open AI and Microsoft as an industrial product. Although some\nstudies evaluate the correctness of Copilot solutions and report its issues,\nmore empirical evaluations are necessary to understand how developers can\nbenefit from it effectively. In this paper, we study the capabilities of\nCopilot in two different programming tasks: (1) generating (and reproducing)\ncorrect and efficient solutions for fundamental algorithmic problems, and (2)\ncomparing Copilot's proposed solutions with those of human programmers on a set\nof programming tasks. For the former, we assess the performance and\nfunctionality of Copilot in solving selected fundamental problems in computer\nscience, like sorting and implementing basic data structures. In the latter, a\ndataset of programming problems with human-provided solutions is used. The\nresults show that Copilot is capable of providing solutions for almost all\nfundamental algorithmic problems, however, some solutions are buggy and\nnon-reproducible. Moreover, Copilot has some difficulties in combining multiple\nmethods to generate a solution. Comparing Copilot to humans, our results show\nthat the correct ratio of human solutions is greater than Copilot's correct\nratio, while the buggy solutions generated by Copilot require less effort to be\nrepaired. While Copilot shows limitations as an assistant for developers\nespecially in advanced programming tasks, as highlighted in this study and\nprevious ones, it can generate preliminary solutions for basic programming\ntasks.",
    "descriptor": "\nComments: 20 pages, 6 figures\n",
    "authors": [
      "Arghavan Moradi Dakhel",
      "Vahid Majdinasab",
      "Amin Nikanjam",
      "Foutse Khomh",
      "Michel C. Desmarais",
      "Zhen Ming",
      "Jiang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15331"
  },
  {
    "id": "arXiv:2206.15335",
    "title": "Byzantine Agreement with Optimal Resilience via Statistical Fraud  Detection",
    "abstract": "Since the mid-1980s it has been known that Byzantine Agreement can be solved\nwith probability 1 asynchronously, even against an omniscient, computationally\nunbounded adversary that can adaptively \\emph{corrupt} up to $f<n/3$ parties.\nMoreover, the problem is insoluble with $f\\geq n/3$ corruptions. However,\nBracha's 1984 protocol achieved $f<n/3$ resilience at the cost of exponential\nexpected latency $2^{\\Theta(n)}$, a bound that has never been improved in this\nmodel with $f=\\lfloor (n-1)/3 \\rfloor$ corruptions.\nIn this paper we prove that Byzantine Agreement in the asynchronous, full\ninformation model can be solved with probability 1 against an adaptive\nadversary that can corrupt $f<n/3$ parties, while incurring only polynomial\nlatency with high probability. Our protocol follows earlier polynomial latency\nprotocols of King and Saia and Huang, Pettie, and Zhu, which had suboptimal\nresilience, namely $f \\approx n/10^9$ and $f<n/4$, respectively.\nResilience $f=(n-1)/3$ is uniquely difficult as this is the point at which\nthe influence of the Byzantine and honest players are of roughly equal\nstrength. The core technical problem we solve is to design a collective\ncoin-flipping protocol that eventually lets us flip a coin with an unambiguous\noutcome. In the beginning the influence of the Byzantine players is too\npowerful to overcome and they can essentially fix the coin's behavior at will.\nWe guarantee that after just a polynomial number of executions of the\ncoin-flipping protocol, either (a) the Byzantine players fail to fix the\nbehavior of the coin (thereby ending the game) or (b) we can ``blacklist''\nplayers such that the blacklisting rate for Byzantine players is at least as\nlarge as the blacklisting rate for good players. The blacklisting criterion is\nbased on a simple statistical test of fraud detection.",
    "descriptor": "",
    "authors": [
      "Shang-En Huang",
      "Seth Pettie",
      "Leqi Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.15335"
  },
  {
    "id": "arXiv:2206.15336",
    "title": "Tight Bounds for Online Matching in Bounded-Degree Graphs with Vertex  Capacities",
    "abstract": "We study the $b$-matching problem in bipartite graphs $G=(S,R,E)$. Each\nvertex $s\\in S$ is a server with individual capacity $b_s$. The vertices $r\\in\nR$ are requests that arrive online and must be assigned instantly to an\neligible server. The goal is to maximize the size of the constructed matching.\nWe assume that $G$ is a $(k,d)$-graph~\\cite{NW}, where $k$ specifies a lower\nbound on the degree of each server and $d$ is an upper bound on the degree of\neach request. This setting models matching problems in timely applications.\nWe present tight upper and lower bounds on the performance of deterministic\nonline algorithms. In particular, we develop a new online algorithm via a\nprimal-dual analysis. The optimal competitive ratio tends to~1, for arbitrary\n$k\\geq d$, as the server capacities increase. Hence, nearly optimal solutions\ncan be computed online. Our results also hold for the vertex-weighted problem\nextension, and thus for AdWords and auction problems in which each bidder\nissues individual, equally valued bids.\nOur bounds improve the previous best competitive ratios. The asymptotic\ncompetitiveness of~1 is a significant improvement over the previous factor of\n$1-1/e^{k/d}$, for the interesting range where $k/d\\geq 1$ is small. Recall\nthat $1-1/e\\approx 0.63$. Matching problems that admit a competitive ratio\narbitrarily close to~1 are rare. Prior results rely on randomization or\nprobabilistic input models.",
    "descriptor": "\nComments: 21 pages, 1 figure, full version of a paper accepted ESA 2022\n",
    "authors": [
      "Susanne Albers",
      "Sebastian Schubert"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15336"
  },
  {
    "id": "arXiv:2206.15339",
    "title": "Abstract morphing using the Hausdorff distance and Voronoi diagrams",
    "abstract": "This paper introduces two new abstract morphs for two $2$-dimensional shapes.\nThe intermediate shapes gradually reduce the Hausdorff distance to the goal\nshape and increase the Hausdorff distance to the initial shape. The morphs are\nconceptually simple and apply to shapes with multiple components and/or holes.\nWe prove some basic properties relating to continuity, containment, and area.\nThen we give an experimental analysis that includes the two new morphs and a\nrecently introduced abstract morph that is also based on the Hausdorff distance\n(Van Kreveld et al. Between shapes, using the Hausdorff distance. Computational\nGeometry 100:101817, 2022). We show results on the area and perimeter\ndevelopment throughout the morph, and also the number of components and holes.\nA visual comparison shows that one of the new morphs appears most attractive.",
    "descriptor": "",
    "authors": [
      "Lex de Kogel",
      "Marc van Kreveld",
      "Jordi L. Vermeulen"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.15339"
  },
  {
    "id": "arXiv:2206.15349",
    "title": "Revisiting Competitive Coding Approach for Palmprint Recognition: A  Linear Discriminant Analysis Perspective",
    "abstract": "The competitive Coding approach (CompCode) is one of the most promising\nmethods for palmprint recognition. Due to its high performance and simple\nformulation, it has been continuously studied for many years. However, although\nnumerous variations of CompCode have been proposed, a detailed analysis of the\nmethod is still absent. In this paper, we provide a detailed analysis of\nCompCode from the perspective of linear discriminant analysis (LDA) for the\nfirst time. A non-trivial sufficient condition under which the CompCode is\noptimal in the sense of Fisher's criterion is presented. Based on our analysis,\nwe examined the statistics of palmprints and concluded that CompCode deviates\nfrom the optimal condition. To mitigate the deviation, we propose a new method\ncalled Class-Specific CompCode that improves CompCode by excluding\nnon-palm-line areas from matching. A nonlinear mapping of the competitive code\nis also applied in this method to further enhance accuracy. Experiments on two\npublic databases demonstrate the effectiveness of the proposed method.",
    "descriptor": "\nComments: 12 pages, 14 figures\n",
    "authors": [
      "Lingfei Song",
      "Hua Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15349"
  },
  {
    "id": "arXiv:2206.15351",
    "title": "Deep Learning to See: Towards New Foundations of Computer Vision",
    "abstract": "The remarkable progress in computer vision over the last few years is, by and\nlarge, attributed to deep learning, fueled by the availability of huge sets of\nlabeled data, and paired with the explosive growth of the GPU paradigm. While\nsubscribing to this view, this book criticizes the supposed scientific progress\nin the field and proposes the investigation of vision within the framework of\ninformation-based laws of nature. Specifically, the present work poses\nfundamental questions about vision that remain far from understood, leading the\nreader on a journey populated by novel challenges resonating with the\nfoundations of machine learning. The central thesis is that for a deeper\nunderstanding of visual computational processes, it is necessary to look beyond\nthe applications of general purpose machine learning algorithms and focus\ninstead on appropriate learning theories that take into account the\nspatiotemporal nature of the visual signal.",
    "descriptor": "",
    "authors": [
      "Alessandro Betti",
      "Marco Gori",
      "Stefano Melacci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15351"
  },
  {
    "id": "arXiv:2206.15352",
    "title": "Learning Citywide Patterns of Life from Trajectory Monitoring",
    "abstract": "The recent proliferation of real-world human mobility datasets has catalyzed\ngeospatial and transportation research in trajectory prediction, demand\nforecasting, travel time estimation, and anomaly detection. However, these\ndatasets also enable, more broadly, a descriptive analysis of intricate systems\nof human mobility. We formally define patterns of life analysis as a natural,\nexplainable extension of online unsupervised anomaly detection, where we not\nonly monitor a data stream for anomalies but also explicitly extract normal\npatterns over time. To learn patterns of life, we adapt Grow When Required\n(GWR) episodic memory from research in computational biology and neurorobotics\nto a new domain of geospatial analysis. This biologically-inspired neural\nnetwork, related to self-organizing maps (SOM), constructs a set of \"memories\"\nor prototype traffic patterns incrementally as it iterates over the GPS stream.\nIt then compares each new observation to its prior experiences, inducing an\nonline, unsupervised clustering and anomaly detection on the data. We mine\npatterns-of-interest from the Porto taxi dataset, including both major public\nholidays and newly-discovered transportation anomalies, such as festivals and\nconcerts which, to our knowledge, have not been previously acknowledged or\nreported in prior work. We anticipate that the capability to incrementally\nlearn normal and abnormal road transportation behavior will be useful in many\ndomains, including smart cities, autonomous vehicles, and urban planning and\nmanagement.",
    "descriptor": "\nComments: 12 pages, 9 figures (including 2 pages and 2 figures in Appendix). Submitted to SIGSPATIAL 2022\n",
    "authors": [
      "Mark Tenzer",
      "Zeeshan Rasheed",
      "Khurram Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.15352"
  },
  {
    "id": "arXiv:2206.15353",
    "title": "Learning Underrepresented Classes from Decentralized Partially Labeled  Medical Images",
    "abstract": "Using decentralized data for federated training is one promising emerging\nresearch direction for alleviating data scarcity in the medical domain.\nHowever, in contrast to large-scale fully labeled data commonly seen in general\nobject recognition tasks, the local medical datasets are more likely to only\nhave images annotated for a subset of classes of interest due to high\nannotation costs. In this paper, we consider a practical yet under-explored\nproblem, where underrepresented classes only have few labeled instances\navailable and only exist in a few clients of the federated system. We show that\nstandard federated learning approaches fail to learn robust multi-label\nclassifiers with extreme class imbalance and address it by proposing a novel\nfederated learning framework, FedFew. FedFew consists of three stages, where\nthe first stage leverages federated self-supervised learning to learn\nclass-agnostic representations. In the second stage, the decentralized\npartially labeled data are exploited to learn an energy-based multi-label\nclassifier for the common classes. Finally, the underrepresented classes are\ndetected based on the energy and a prototype-based nearest-neighbor model is\nproposed for few-shot matching. We evaluate FedFew on multi-label thoracic\ndisease classification tasks and demonstrate that it outperforms the federated\nbaselines by a large margin.",
    "descriptor": "\nComments: Accepted by MICCAI 2022\n",
    "authors": [
      "Nanqing Dong",
      "Michael Kampffmeyer",
      "Irina Voiculescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15353"
  },
  {
    "id": "arXiv:2206.15359",
    "title": "Two-Stage Classifier for COVID-19 Misinformation Detection Using BERT: a  Study on Indonesian Tweets",
    "abstract": "The COVID-19 pandemic has caused globally significant impacts since the\nbeginning of 2020. This brought a lot of confusion to society, especially due\nto the spread of misinformation through social media. Although there were\nalready several studies related to the detection of misinformation in social\nmedia data, most studies focused on the English dataset. Research on COVID-19\nmisinformation detection in Indonesia is still scarce. Therefore, through this\nresearch, we collect and annotate datasets for Indonesian and build prediction\nmodels for detecting COVID-19 misinformation by considering the tweet's\nrelevance. The dataset construction is carried out by a team of annotators who\nlabeled the relevance and misinformation of the tweet data. In this study, we\npropose the two-stage classifier model using IndoBERT pre-trained language\nmodel for the Tweet misinformation detection task. We also experiment with\nseveral other baseline models for text classification. The experimental results\nshow that the combination of the BERT sequence classifier for relevance\nprediction and Bi-LSTM for misinformation detection outperformed other machine\nlearning models with an accuracy of 87.02%. Overall, the BERT utilization\ncontributes to the higher performance of most prediction models. We release a\nhigh-quality COVID-19 misinformation Tweet corpus in the Indonesian language,\nindicated by the high inter-annotator agreement.",
    "descriptor": "\nComments: 29 pages, 5 figures, submitted to Elsevier Journal\n",
    "authors": [
      "Douglas Raevan Faisal",
      "Rahmad Mahendra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.15359"
  },
  {
    "id": "arXiv:2206.15362",
    "title": "Quantum gene regulatory networks",
    "abstract": "In this work, we present a quantum circuit model for inferring gene\nregulatory networks (GRNs). The model is based on the idea of using qubit-qubit\nentanglement to simulate interactions between genes. We provide preliminary\nresults that suggest our quantum GRN modeling method is competitive and\nwarrants further investigation. Specifically, we present the results derived\nfrom the single-cell transcriptomic data of human cell lines, focusing on genes\nin involving innate immunity regulation. We demonstrate that our quantum\ncircuit model can be used to predict the presence or absence of regulatory\ninteractions between genes and estimate the strength and direction of the\ninteractions, setting the stage for further investigations on how quantum\ncomputing finds applications in data-driven life sciences and, more\nimportantly, to invite exploration of quantum algorithm design that takes\nadvantage of the single-cell data. The application of quantum computing on\nsingle-cell transcriptomic data likewise contributes to a novel understanding\nof GRNs, given that the relationship between fully interconnected genes can be\napproached more effectively by quantum modeling than by statistical\ncorrelations.",
    "descriptor": "",
    "authors": [
      "Cristhian Roman-Vicharra",
      "James J. Cai"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2206.15362"
  },
  {
    "id": "arXiv:2206.15363",
    "title": "Why we do need Explainable AI for Healthcare",
    "abstract": "The recent spike in certified Artificial Intelligence (AI) tools for\nhealthcare has renewed the debate around adoption of this technology. One\nthread of such debate concerns Explainable AI and its promise to render AI\ndevices more transparent and trustworthy. A few voices active in the medical AI\nspace have expressed concerns on the reliability of Explainable AI techniques,\nquestioning their use and inclusion in guidelines and standards. Revisiting\nsuch criticisms, this article offers a balanced and comprehensive perspective\non the utility of Explainable AI, focusing on the specificity of clinical\napplications of AI and placing them in the context of healthcare interventions.\nAgainst its detractors and despite valid concerns, we argue that the\nExplainable AI research program is still central to human-machine interaction\nand ultimately our main tool against loss of control, a danger that cannot be\nprevented by rigorous clinical validation alone.",
    "descriptor": "",
    "authors": [
      "Giovanni Cin\u00e0",
      "Tabea R\u00f6ber",
      "Rob Goedhart",
      "Ilker Birbil"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15363"
  },
  {
    "id": "arXiv:2206.15364",
    "title": "Online TSP with Predictions",
    "abstract": "We initiate the study of online routing problems with predictions, inspired\nby recent exciting results in the area of learning-augmented algorithms. A\nlearning-augmented online algorithm which incorporates predictions in a\nblack-box manner to outperform existing algorithms if the predictions are\naccurate while otherwise maintaining theoretical guarantees even when the\npredictions are extremely erroneous is a popular framework for overcoming\npessimistic worst-case competitive analysis.\nIn this study, we particularly begin investigating the classical online\ntraveling salesman problem (OLTSP), where future requests are augmented with\npredictions. Unlike the prediction models in other previous studies, each\nactual request in the OLTSP, associated with its arrival time and position, may\nnot coincide with the predicted ones, which, as imagined, leads to a\ntroublesome situation. Our main result is to study different prediction models\nand design algorithms to improve the best-known results in the different\nsettings. Moreover, we generalize the proposed results to the online\ndial-a-ride problem.",
    "descriptor": "",
    "authors": [
      "Hsiao-Yu Hu",
      "Hao-Ting Wei",
      "Meng-Hsi Li",
      "Kai-Min Chung",
      "Chung-Shou Liao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15364"
  },
  {
    "id": "arXiv:2206.15369",
    "title": "Improving the Generalization of Supervised Models",
    "abstract": "We consider the problem of training a deep neural network on a given\nclassification task, e.g., ImageNet-1K (IN1K), so that it excels at that task\nas well as at other (future) transfer tasks. These two seemingly contradictory\nproperties impose a trade-off between improving the model's generalization\nwhile maintaining its performance on the original task. Models trained with\nself-supervised learning (SSL) tend to generalize better than their supervised\ncounterparts for transfer learning; yet, they still lag behind supervised\nmodels on IN1K. In this paper, we propose a supervised learning setup that\nleverages the best of both worlds. We enrich the common supervised training\nframework using two key components of recent SSL models: multi-scale crops for\ndata augmentation and the use of an expendable projector head. We replace the\nlast layer of class weights with class prototypes computed on the fly using a\nmemory bank. We show that these three improvements lead to a more favorable\ntrade-off between the IN1K training task and 13 transfer tasks. Over all the\nexplored configurations, we single out two models: t-ReX that achieves a new\nstate of the art for transfer learning and outperforms top methods such as DINO\nand PAWS on IN1K, and t-ReX* that matches the highly optimized RSB-A1 model on\nIN1K while performing better on transfer tasks. Project page and pretrained\nmodels: https://europe.naverlabs.com/t-rex",
    "descriptor": "\nComments: Project page and pretrained models: this https URL\n",
    "authors": [
      "Mert Bulent Sariyildiz",
      "Yannis Kalantidis",
      "Karteek Alahari",
      "Diane Larlus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15369"
  },
  {
    "id": "arXiv:2206.15374",
    "title": "Verification and search algorithms for causal DAGs",
    "abstract": "We study two problems related to recovering causal graphs from interventional\ndata: (i) $\\textit{verification}$, where the task is to check if a purported\ncausal graph is correct, and (ii) $\\textit{search}$, where the task is to\nrecover the correct causal graph. For both, we wish to minimize the number of\ninterventions performed. For the first problem, we give a characterization of a\nminimal sized set of atomic interventions that is necessary and sufficient to\ncheck the correctness of a claimed causal graph. Our characterization uses the\nnotion of $\\textit{covered edges}$, which enables us to obtain simple proofs\nand also easily reason about earlier results. We also generalize our results to\nthe settings of bounded size interventions and node-dependent interventional\ncosts. For all the above settings, we provide the first known provable\nalgorithms for efficiently computing (near)-optimal verifying sets on general\ngraphs. For the second problem, we give a simple adaptive algorithm based on\ngraph separators that produces an atomic intervention set which fully orients\nany essential graph while using $\\mathcal{O}(\\log n)$ times the optimal number\nof interventions needed to $\\textit{verify}$ (verifying size) the underlying\nDAG on $n$ vertices. This approximation is tight as $\\textit{any}$ search\nalgorithm on an essential line graph has worst case approximation ratio of\n$\\Omega(\\log n)$ with respect to the verifying size. With bounded size\ninterventions, each of size $\\leq k$, our algorithm gives an $\\mathcal{O}(\\log\nn \\cdot \\log \\log k)$ factor approximation. Our result is the first known\nalgorithm that gives a non-trivial approximation guarantee to the verifying\nsize on general unweighted graphs and with bounded size interventions.",
    "descriptor": "",
    "authors": [
      "Davin Choo",
      "Kirankumar Shiragur",
      "Arnab Bhattacharyya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15374"
  },
  {
    "id": "arXiv:2206.15378",
    "title": "Mastering the Game of Stratego with Model-Free Multiagent Reinforcement  Learning",
    "abstract": "We introduce DeepNash, an autonomous agent capable of learning to play the\nimperfect information game Stratego from scratch, up to a human expert level.\nStratego is one of the few iconic board games that Artificial Intelligence (AI)\nhas not yet mastered. This popular game has an enormous game tree on the order\nof $10^{535}$ nodes, i.e., $10^{175}$ times larger than that of Go. It has the\nadditional complexity of requiring decision-making under imperfect information,\nsimilar to Texas hold'em poker, which has a significantly smaller game tree (on\nthe order of $10^{164}$ nodes). Decisions in Stratego are made over a large\nnumber of discrete actions with no obvious link between action and outcome.\nEpisodes are long, with often hundreds of moves before a player wins, and\nsituations in Stratego can not easily be broken down into manageably-sized\nsub-problems as in poker. For these reasons, Stratego has been a grand\nchallenge for the field of AI for decades, and existing AI methods barely reach\nan amateur level of play. DeepNash uses a game-theoretic, model-free deep\nreinforcement learning method, without search, that learns to master Stratego\nvia self-play. The Regularised Nash Dynamics (R-NaD) algorithm, a key component\nof DeepNash, converges to an approximate Nash equilibrium, instead of 'cycling'\naround it, by directly modifying the underlying multi-agent learning dynamics.\nDeepNash beats existing state-of-the-art AI methods in Stratego and achieved a\nyearly (2022) and all-time top-3 rank on the Gravon games platform, competing\nwith human expert players.",
    "descriptor": "",
    "authors": [
      "Julien Perolat",
      "Bart de Vylder",
      "Daniel Hennes",
      "Eugene Tarassov",
      "Florian Strub",
      "Vincent de Boer",
      "Paul Muller",
      "Jerome T. Connor",
      "Neil Burch",
      "Thomas Anthony",
      "Stephen McAleer",
      "Romuald Elie",
      "Sarah H. Cen",
      "Zhe Wang",
      "Audrunas Gruslys",
      "Aleksandra Malysheva",
      "Mina Khan",
      "Sherjil Ozair",
      "Finbarr Timbers",
      "Toby Pohlen",
      "Tom Eccles",
      "Mark Rowland",
      "Marc Lanctot",
      "Jean-Baptiste Lespiau",
      "Bilal Piot",
      "Shayegan Omidshafiei",
      "Edward Lockhart",
      "Laurent Sifre",
      "Nathalie Beauguerlange",
      "Remi Munos",
      "David Silver",
      "Satinder Singh",
      "Demis Hassabis",
      "Karl Tuyls"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.15378"
  },
  {
    "id": "arXiv:2206.15380",
    "title": "Mixed Reality as Communication Medium for Human-Robot Collaboration",
    "abstract": "Humans engaged in collaborative activities are naturally able to convey their\nintentions to teammates through multi-modal communication, which is made up of\nexplicit and implicit cues. Similarly, a more natural form of human-robot\ncollaboration may be achieved by enabling robots to convey their intentions to\nhuman teammates via multiple communication channels. In this paper, we\npostulate that a better communication may take place should collaborative\nrobots be able to anticipate their movements to human teammates in an intuitive\nway. In order to support such a claim, we propose a robot system's architecture\nthrough which robots can communicate planned motions to human teammates\nleveraging a Mixed Reality interface powered by modern head-mounted displays.\nSpecifically, the robot's hologram, which is superimposed to the real robot in\nthe human teammate's point of view, shows the robot's future movements,\nallowing the human to understand them in advance, and possibly react to them in\nan appropriate way. We conduct a preliminary user study to evaluate the\neffectiveness of the proposed anticipatory visualization during a complex\ncollaborative task. The experimental results suggest that an improved and more\nnatural collaboration can be achieved by employing this anticipatory\ncommunication mode.",
    "descriptor": "",
    "authors": [
      "Simone Macci\u00f2",
      "Alessandro Carf\u00ec",
      "Fulvio Mastrogiovanni"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.15380"
  },
  {
    "id": "arXiv:2206.15381",
    "title": "Visual grounding of abstract and concrete words: A response to G\u00fcnther  et al. (2020)",
    "abstract": "Current computational models capturing words' meaning mostly rely on textual\ncorpora. While these approaches have been successful over the last decades,\ntheir lack of grounding in the real world is still an ongoing problem. In this\npaper, we focus on visual grounding of word embeddings and target two important\nquestions. First, how can language benefit from vision in the process of visual\ngrounding? And second, is there a link between visual grounding and abstract\nconcepts? We investigate these questions by proposing a simple yet effective\napproach where language benefits from vision specifically with respect to the\nmodeling of both concrete and abstract words. Our model aligns word embeddings\nwith their corresponding visual representation without deteriorating the\nknowledge captured by textual distributional information. We apply our model to\na behavioral experiment reported by G\\\"unther et al. (2020), which addresses\nthe plausibility of having visual mental representations for abstract words.\nOur evaluation results show that: (1) It is possible to predict human behaviour\nto a large degree using purely textual embeddings. (2) Our grounded embeddings\nmodel human behavior better compared to their textual counterparts. (3)\nAbstract concepts benefit from visual grounding implicitly through their\nconnections to concrete concepts, rather than from having corresponding visual\nrepresentations.",
    "descriptor": "\nComments: To be submitted to the Mental Lexicon Journal: this https URL\n",
    "authors": [
      "Hassan Shahmohammadi",
      "Maria Heitmeier",
      "Elnaz Shafaei-Bajestan",
      "Hendrik P. A. Lensch",
      "Harald Baayen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.15381"
  },
  {
    "id": "arXiv:2206.15387",
    "title": "Where to Begin? Exploring the Impact of Pre-Training and Initialization  in Federated Learning",
    "abstract": "An oft-cited challenge of federated learning is the presence of data\nheterogeneity -- the data at different clients may follow very different\ndistributions. Several federated optimization methods have been proposed to\naddress these challenges. In the literature, empirical evaluations usually\nstart federated training from a random initialization. However, in many\npractical applications of federated learning, the server has access to proxy\ndata for the training task which can be used to pre-train a model before\nstarting federated training. We empirically study the impact of starting from a\npre-trained model in federated learning using four common federated learning\nbenchmark datasets. Unsurprisingly, starting from a pre-trained model reduces\nthe training time required to reach a target error rate and enables training\nmore accurate models (by up to 40\\%) than is possible than when starting from a\nrandom initialization. Surprisingly, we also find that the effect of data\nheterogeneity is much less significant when starting federated training from a\npre-trained initialization. Rather, when starting from a pre-trained model,\nusing an adaptive optimizer at the server, such as \\textsc{FedAdam},\nconsistently leads to the best accuracy. We recommend that future work\nproposing and evaluating federated optimization methods consider the\nperformance when starting both random and pre-trained initializations. We also\nbelieve this study raises several questions for further work on understanding\nthe role of heterogeneity in federated optimization.",
    "descriptor": "\nComments: v1\n",
    "authors": [
      "John Nguyen",
      "Kshitiz Malik",
      "Maziar Sanjabi",
      "Michael Rabbat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15387"
  },
  {
    "id": "arXiv:2206.15395",
    "title": "Polynomial-Time Optimal Equilibria with a Mediator in Extensive-Form  Games",
    "abstract": "For common notions of correlated equilibrium in extensive-form games,\ncomputing an optimal (e.g., welfare-maximizing) equilibrium is NP-hard. Other\nequilibrium notions -- communication (Forges 1986) and certification (Forges &\nKoessler 2005) equilibria -- augment the game with a mediator that has the\npower to both send and receive messages to and from the players -- and, in\nparticular, to remember the messages. In this paper, we investigate both\nnotions in extensive-form games from a computational lens. We show that optimal\nequilibria in both notions can be computed in polynomial time, the latter under\na natural additional assumption known in the literature. Our proof works by\nconstructing a mediator-augmented game of polynomial size that explicitly\nrepresents the mediator's decisions and actions. Our framework allows us to\ndefine an entire family of equilibria by varying the mediator's information\npartition, the players' ability to lie, and the players' ability to deviate.\nFrom this perspective, we show that other notions of equilibrium, such as\nextensive-form correlated equilibrium, correspond to the mediator having\nimperfect recall. This shows that, at least among all these equilibrium\nnotions, the hardness of computation is driven by the mediator's imperfect\nrecall. As special cases of our general construction, we recover 1) the\npolynomial-time algorithm of Conitzer & Sandholm (2004) for automated mechanism\ndesign in Bayes-Nash equilibria and 2) the correlation DAG algorithm of Zhang\net al (2022) for optimal correlation. Our algorithm is especially scalable when\nthe equilibrium notion is what we define as the full-certification equilibrium,\nwhere players cannot lie about their information but they can be silent. We\nback up our theoretical claims with experiments on a suite of standard\nbenchmark games.",
    "descriptor": "",
    "authors": [
      "Brian Hu Zhang",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.15395"
  },
  {
    "id": "arXiv:2206.15397",
    "title": "Randomized K-FACs: Speeding up K-FAC with Randomized Numerical Linear  Algebra",
    "abstract": "K-FAC is a successful tractable implementation of Natural Gradient for Deep\nLearning, which nevertheless suffers from the requirement to compute the\ninverse of the Kronecker factors (through an eigen-decomposition). This can be\nvery time-consuming (or even prohibitive) when these factors are large. In this\npaper, we theoretically show that, owing to the exponential-average\nconstruction paradigm of the Kronecker factors that is typically used, their\neigen-spectrum must decay. We show numerically that in practice this decay is\nvery rapid, leading to the idea that we could save substantial computation by\nonly focusing on the first few eigen-modes when inverting the\nKronecker-factors. Randomized Numerical Linear Algebra provides us with the\nnecessary tools to do so. Numerical results show we obtain $\\approx2.5\\times$\nreduction in per-epoch time and $\\approx3.3\\times$ reduction in time to target\naccuracy. We compare our proposed K-FAC sped-up versions with a more\ncomputationally efficient NG implementation, SENG, and observe we perform on\npar with it.",
    "descriptor": "\nComments: First version: 12 pages, 2 figures, 1 table\n",
    "authors": [
      "Constantin Octavian Puiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15397"
  },
  {
    "id": "arXiv:2206.15398",
    "title": "PolarFormer: Multi-camera 3D Object Detection with Polar Transformer",
    "abstract": "3D object detection in autonomous driving aims to reason \"what\" and \"where\"\nthe objects of interest present in a 3D world. Following the conventional\nwisdom of previous 2D object detection, existing methods often adopt the\ncanonical Cartesian coordinate system with perpendicular axis. However, we\nconjugate that this does not fit the nature of the ego car's perspective, as\neach onboard camera perceives the world in shape of wedge intrinsic to the\nimaging geometry with radical (non-perpendicular) axis. Hence, in this paper we\nadvocate the exploitation of the Polar coordinate system and propose a new\nPolar Transformer (PolarFormer) for more accurate 3D object detection in the\nbird's-eye-view (BEV) taking as input only multi-camera 2D images.\nSpecifically, we design a cross attention based Polar detection head without\nrestriction to the shape of input structure to deal with irregular Polar grids.\nFor tackling the unconstrained object scale variations along Polar's distance\ndimension, we further introduce a multi-scalePolar representation learning\nstrategy. As a result, our model can make best use of the Polar representation\nrasterized via attending to the corresponding image observation in a\nsequence-to-sequence fashion subject to the geometric constraints. Thorough\nexperiments on the nuScenes dataset demonstrate that our PolarFormer\noutperforms significantly state-of-the-art 3D object detection alternatives, as\nwell as yielding competitive performance on BEV semantic segmentation task.",
    "descriptor": "",
    "authors": [
      "Yanqin Jiang",
      "Li Zhang",
      "Zhenwei Miao",
      "Xiatian Zhu",
      "Jin Gao",
      "Weiming Hu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15398"
  },
  {
    "id": "arXiv:2206.15407",
    "title": "Shifts 2.0: Extending The Dataset of Real Distributional Shifts",
    "abstract": "Distributional shift, or the mismatch between training and deployment data,\nis a significant obstacle to the usage of machine learning in high-stakes\nindustrial applications, such as autonomous driving and medicine. This creates\na need to be able to assess how robustly ML models generalize as well as the\nquality of their uncertainty estimates. Standard ML baseline datasets do not\nallow these properties to be assessed, as the training, validation and test\ndata are often identically distributed. Recently, a range of dedicated\nbenchmarks have appeared, featuring both distributionally matched and shifted\ndata. Among these benchmarks, the Shifts dataset stands out in terms of the\ndiversity of tasks as well as the data modalities it features. While most of\nthe benchmarks are heavily dominated by 2D image classification tasks, Shifts\ncontains tabular weather forecasting, machine translation, and vehicle motion\nprediction tasks. This enables the robustness properties of models to be\nassessed on a diverse set of industrial-scale tasks and either universal or\ndirectly applicable task-specific conclusions to be reached. In this paper, we\nextend the Shifts Dataset with two datasets sourced from industrial, high-risk\napplications of high societal importance. Specifically, we consider the tasks\nof segmentation of white matter Multiple Sclerosis lesions in 3D magnetic\nresonance brain images and the estimation of power consumption in marine cargo\nvessels. Both tasks feature ubiquitous distributional shifts and a strict\nsafety requirement due to the high cost of errors. These new datasets will\nallow researchers to further explore robust generalization and uncertainty\nestimation in new situations. In this work, we provide a description of the\ndataset and baseline results for both tasks.",
    "descriptor": "",
    "authors": [
      "Andrey Malinin",
      "Andreas Athanasopoulos",
      "Muhamed Barakovic",
      "Meritxell Bach Cuadra",
      "Mark J. F. Gales",
      "Cristina Granziera",
      "Mara Graziani",
      "Nikolay Kartashev",
      "Konstantinos Kyriakopoulos",
      "Po-Jui Lu",
      "Nataliia Molchanova",
      "Antonis Nikitakis",
      "Vatsal Raina",
      "Francesco La Rosa",
      "Eli Sivena",
      "Vasileios Tsarsitalidis",
      "Efi Tsompopoulou",
      "Elena Volf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15407"
  },
  {
    "id": "arXiv:2206.15409",
    "title": "Automatically Balancing Model Accuracy and Complexity using Solution and  Fitness Evolution (SAFE)",
    "abstract": "When seeking a predictive model in biomedical data, one often has more than a\nsingle objective in mind, e.g., attaining both high accuracy and low complexity\n(to promote interpretability). We investigate herein whether multiple\nobjectives can be dynamically tuned by our recently proposed coevolutionary\nalgorithm, SAFE (Solution And Fitness Evolution). We find that SAFE is able to\nautomatically tune accuracy and complexity with no performance loss, as\ncompared with a standard evolutionary algorithm, over complex simulated\ngenetics datasets produced by the GAMETES tool.",
    "descriptor": "",
    "authors": [
      "Moshe Sipper",
      "Jason H. Moore",
      "Ryan J. Urbanowicz"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.15409"
  },
  {
    "id": "arXiv:2206.15414",
    "title": "Bounding and computing obstacle numbers of graphs",
    "abstract": "An obstacle representation of a graph $G$ consists of a set of pairwise\ndisjoint simply-connected closed regions and a one-to-one mapping of the\nvertices of $G$ to points such that two vertices are adjacent in $G$ if and\nonly if the line segment connecting the two corresponding points does not\nintersect any obstacle. The obstacle number of a graph is the smallest number\nof obstacles in an obstacle representation of the graph in the plane such that\nall obstacles are simple polygons.\nIt is known that the obstacle number of each $n$-vertex graph is $O(n \\log\nn)$ [Balko, Cibulka, and Valtr, 2018] and that there are $n$-vertex graphs\nwhose obstacle number is $\\Omega(n/(\\log\\log n)^2)$ [Dujmovi\\'c and Morin,\n2015]. We improve this lower bound to $\\Omega(n/\\log\\log n)$ for simple\npolygons and to $\\Omega(n)$ for convex polygons.\nTo obtain these stronger bounds, we improve known estimates on the number of\n$n$-vertex graphs with bounded obstacle number, solving a conjecture by\nDujmovi\\'c and Morin. We also show that if the drawing of some $n$-vertex graph\nis given as part of the input, then for some drawings $\\Omega(n^2)$ obstacles\nare required to turn them into an obstacle representation of the graph. Our\nbounds are asymptotically tight in several instances.\nWe complement these combinatorial bounds by two complexity results. First, we\nshow that computing the obstacle number of a graph $G$ is fixed-parameter\ntractable in the vertex cover number of $G$. Second, we show that, given a\ngraph $G$ and a simple polygon $P$, it is NP-hard to decide whether $G$ admits\nan obstacle representation using $P$ as the only obstacle.",
    "descriptor": "",
    "authors": [
      "Martin Balko",
      "Steven Chaplick",
      "Robert Ganian",
      "Siddharth Gupta",
      "Michael Hoffmann",
      "Pavel Valtr",
      "Alexander Wolff"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.15414"
  },
  {
    "id": "arXiv:2206.15415",
    "title": "MEAD: A Multi-Armed Approach for Evaluation of Adversarial Examples  Detectors",
    "abstract": "Detection of adversarial examples has been a hot topic in the last years due\nto its importance for safely deploying machine learning algorithms in critical\napplications. However, the detection methods are generally validated by\nassuming a single implicitly known attack strategy, which does not necessarily\naccount for real-life threats. Indeed, this can lead to an overoptimistic\nassessment of the detectors' performance and may induce some bias in the\ncomparison between competing detection schemes. We propose a novel multi-armed\nframework, called MEAD, for evaluating detectors based on several attack\nstrategies to overcome this limitation. Among them, we make use of three new\nobjectives to generate attacks. The proposed performance metric is based on the\nworst-case scenario: detection is successful if and only if all different\nattacks are correctly recognized. Empirically, we show the effectiveness of our\napproach. Moreover, the poor performance obtained for state-of-the-art\ndetectors opens a new exciting line of research.",
    "descriptor": "\nComments: This paper has been accepted to appear in the Proceedings of the 2022 European Conference on Machine Learning and Data Mining (ECML-PKDD), 19th to the 23rd of September, Grenoble, France\n",
    "authors": [
      "Federica Granese",
      "Marine Picot",
      "Marco Romanelli",
      "Francisco Messina",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15415"
  },
  {
    "id": "arXiv:2206.15416",
    "title": "UMPIRE: A Universal Moderator for the Participation in IETF Remote  Events",
    "abstract": "UMPIRE provides seamless meeting interaction among remote and local\nparticipants. It uses the BFCP, an IETF standard for moderation.BFCP introduces\nautomated floor control functions to a centralized conferencing environment.\nThis article discusses the design and implementation of the UMPIRE system and\nhighlights the most notable solutions we devised to handle variegated\nrequirements and constraints. We also discuss the lessons learned while\nexperiencing in the first person how the application of research results that\nhave eventually led to new standards still must confront a number of minor yet\nconcrete issues that might completely undermine the overall process of wide\nadoption by the community.",
    "descriptor": "\nComments: 8 pages, six figures\n",
    "authors": [
      "Simon Pietro Romano"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.15416"
  },
  {
    "id": "arXiv:2206.15418",
    "title": "Distributed asynchronous convergence detection without detection  protocol",
    "abstract": "In this paper, we address the problem of detecting the moment when an ongoing\nasynchronous parallel iterative process can be terminated to provide a\nsufficiently precise solution to a fixed-point problem being solved.\nFormulating the detection problem as a global solution identification problem,\nwe analyze the snapshot-based approach, which is the only one that allows for\nexact global residual error computation. From a recently developed approximate\nsnapshot protocol providing a reliable global residual error, we experimentally\ninvestigate here, as well, the reliability of a global residual error computed\nwithout any prior particular detection mechanism. Results on a single-site\nsupercomputer successfully show that such high-performance computing platforms\npossibly provide computational environments stable enough to allow for simply\nresorting to non-blocking reduction operations for computing reliable global\nresidual errors, which provides noticeable time saving, at both implementation\nand execution levels.",
    "descriptor": "",
    "authors": [
      "Guillaume Gbikpi-Benissan",
      "Frederic Magoules"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.15418"
  },
  {
    "id": "arXiv:2206.15420",
    "title": "JACK2: a new high-level communication library for parallel iterative  methods",
    "abstract": "In this paper, we address the problem of designing a distributed application\nmeant to run both classical and asynchronous iterations. MPI libraries are very\npopular and widely used in the scientific community, however asynchronous\niterative methods raise non-negligible difficulties about the efficient\nmanagement of communication requests and buffers. Moreover, a convergence\ndetection issue is introduced, which requires the implementation of one of the\nvarious state-of-the-art termination methods, which are not necessarily highly\nreliable for most computational environments. We propose here an MPI-based\ncommunication library which handles all these issues in a non-intrusive manner,\nproviding a unique interface for implementing both classical and asynchronous\niterations. Few details are highlighted about our approach to achieve best\ncommunication rates and ensure accurate convergence detection. Experimental\nresults on two supercomputers confirmed the low overhead communication costs\nintroduced, and the effectiveness of our library.",
    "descriptor": "",
    "authors": [
      "Guillaume Gbikpi-Benissan",
      "Frederic Magoules"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.15420"
  },
  {
    "id": "arXiv:2206.15423",
    "title": "Implicit Neural Spatial Filtering for Multichannel Source Separation in  the Waveform Domain",
    "abstract": "We present a single-stage casual waveform-to-waveform multichannel model that\ncan separate moving sound sources based on their broad spatial locations in a\ndynamic acoustic scene. We divide the scene into two spatial regions\ncontaining, respectively, the target and the interfering sound sources. The\nmodel is trained end-to-end and performs spatial processing implicitly, without\nany components based on traditional processing or use of hand-crafted spatial\nfeatures. We evaluate the proposed model on a real-world dataset and show that\nthe model matches the performance of an oracle beamformer followed by a\nstate-of-the-art single-channel enhancement network.",
    "descriptor": "\nComments: Interspeech 2022\n",
    "authors": [
      "Dejan Markovic",
      "Alexandre Defossez",
      "Alexander Richard"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.15423"
  },
  {
    "id": "arXiv:2206.15424",
    "title": "Metric Dimension Parameterized by Feedback Vertex Set and Other  Structural Parameters",
    "abstract": "For a graph $G$, a subset $S \\subseteq V(G)$ is called a \\emph{resolving set}\nif for any two vertices $u,v \\in V(G)$, there exists a vertex $w \\in S$ such\nthat $d(w,u) \\neq d(w,v)$. The {\\sc Metric Dimension} problem takes as input a\ngraph $G$ and a positive integer $k$, and asks whether there exists a resolving\nset of size at most $k$. This problem was introduced in the 1970s and is known\nto be NP-hard~[GT~61 in Garey and Johnson's book]. In the realm of\nparameterized complexity, Hartung and Nichterlein~[CCC~2013] proved that the\nproblem is W[2]-hard when parameterized by the natural parameter $k$. They also\nobserved that it is FPT when parameterized by the vertex cover number and asked\nabout its complexity under \\emph{smaller} parameters, in particular the\nfeedback vertex set number. We answer this question by proving that {\\sc Metric\nDimension} is W[1]-hard when parameterized by the feedback vertex set number.\nThis also improves the result of Bonnet and Purohit~[IPEC 2019] which states\nthat the problem is W[1]-hard parameterized by the treewidth. Regarding the\nparameterization by the vertex cover number, we prove that {\\sc Metric\nDimension} does not admit a polynomial kernel under this parameterization\nunless $NP\\subseteq coNP/poly$. We observe that a similar result holds when the\nparameter is the distance to clique. On the positive side, we show that {\\sc\nMetric Dimension} is FPT when parameterized by either the distance to cluster\nor the distance to co-cluster, both of which are smaller parameters than the\nvertex cover number.",
    "descriptor": "",
    "authors": [
      "Esther Galby",
      "Liana Khazaliya",
      "Fionn Mc Inerney",
      "Roohani Sharma",
      "Prafullkumar Tale"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15424"
  },
  {
    "id": "arXiv:2206.15426",
    "title": "Volume-Independent Music Matching by Frequency Spectrum Comparison",
    "abstract": "Often, I hear a piece of music and wonder what the name of the piece is.\nIndeed, there are applications such as Shazam app that provides music matching.\nHowever, the limitations of those apps are that the same piece performed by the\nsame musician cannot be identified if it is not the same recording. Shazam\nidentifies the recording of it, not the music. This is because Shazam matches\nthe variation in volume, not the frequencies of the sound. This research\nattempts to match music the way humans understand it: by the frequency spectrum\nof music, not the volume variation. Essentially, the idea is to precompute the\nfrequency spectrums of all the music in the database, then take the unknown\npiece and try to match its frequency spectrum against every segment of every\nmusic in the database. I did it by matching the frequency spectrum of the\nunknown piece to our database by sliding the window by 0.1 seconds and\ncalculating the error by taking Absolute value, normalizing the audio,\nsubtracting the normalized arrays, and taking the sum of absolute differences.\nThe segment that shows the least error is considered the candidate for the\nmatch. The matching performance proved to be dependent on the complexity of the\nmusic. Matching simple music, such as single note pieces, was successful.\nHowever, more complex pieces, such as Chopins Ballade 4, were not successful,\nthat is, the algorithm could not produce low error values in any of the music\nin the database. I suspect that it has to do with having too many notes:\nmismatches in the higher harmonics added up to a significant amount of errors,\nwhich swamps the calculations.",
    "descriptor": "",
    "authors": [
      "Anthony Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.15426"
  },
  {
    "id": "arXiv:2206.15428",
    "title": "Test2Vec: An Execution Trace Embedding for Test Case Prioritization",
    "abstract": "Most automated software testing tasks can benefit from the abstract\nrepresentation of test cases. Traditionally, this is done by encoding test\ncases based on their code coverage. Specification-level criteria can replace\ncode coverage to better represent test cases' behavior, but they are often not\ncost-effective. In this paper, we hypothesize that execution traces of the test\ncases can be a good alternative to abstract their behavior for automated\ntesting tasks. We propose a novel embedding approach, Test2Vec, that maps test\nexecution traces to a latent space. We evaluate this representation in the test\ncase prioritization (TP) task. Our default TP method is based on the similarity\nof the embedded vectors to historical failing test vectors. We also study an\nalternative based on the diversity of test vectors. Finally, we propose a\nmethod to decide which TP to choose, for a given test suite. The experiment is\nbased on several real and seeded faults with over a million execution traces.\nResults show that our proposed TP improves best alternatives by 41.80% in terms\nof the median normalized rank of the first failing test case (FFR). It\noutperforms traditional code coverage-based approaches by 25.05% and 59.25% in\nterms of median APFD and median normalized FFR.",
    "descriptor": "",
    "authors": [
      "Emad Jabbar",
      "Soheila Zangeneh",
      "Hadi Hemmati",
      "Robert Feldt"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15428"
  },
  {
    "id": "arXiv:2206.15429",
    "title": "Interactive Physically-Based Simulation of Roadheader Robot",
    "abstract": "Roadheader is an engineering robot widely used in underground engineering and\nmining industry. Interactive dynamics simulation of roadheader is a fundamental\nproblem in unmanned excavation and virtual reality training. However, current\nresearch is only based on traditional animation techniques or commercial game\nengines. There are few studies that apply real-time physical simulation of\ncomputer graphics to the field of roadheader robot. This paper aims to present\nan interactive physically-based simulation system of roadheader robot. To this\nend, an improved multibody simulation method based on generalized coordinates\nis proposed. First, our simulation method describes robot dynamics based on\ngeneralized coordinates. Compared to state-of-the-art methods, our method is\nmore stable and accurate. Numerical simulation results showed that our method\nhas significantly less error than the game engine in the same number of\niterations. Second, we adopt the symplectic Euler integrator instead of the\nconventional fourth-order Runge-Kutta (RK4) method for dynamics iteration.\nCompared with other integrators, our method is more stable in energy drift\nduring long-term simulation. The test results showed that our system achieved\nreal-time interaction performance of 60 frames per second (fps). Furthermore,\nwe propose a model format for geometric and robotics modeling of roadheaders to\nimplement the system. Our interactive simulation system of roadheader meets the\nrequirements of interactivity, accuracy and stability.",
    "descriptor": "",
    "authors": [
      "Shengzhe Hou",
      "Xinming Lu",
      "Wenli Gao",
      "Shuai Jiang",
      "Xingli Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.15429"
  },
  {
    "id": "arXiv:2206.15430",
    "title": "Evaluation of Performance-Trust vs Moral-Trust Violation in 3D  Environment",
    "abstract": "Human-Robot Interaction, in which a robot with some level of autonomy\ninteracts with a human to achieve a specific goal has seen much recent\nprogress. With the introduction of autonomous robots and the possibility of\nwidespread use of those in near future, it is critical that humans understand\nthe robot's intention while interacting with them as this will foster the\ndevelopment of human-robot trust. The new conceptualization of trust which had\nbeen introduced by researchers in recent years considers trust in Human-Robot\nInteraction to be a multidimensional nature. Two main aspects which are\nattributed to trust are performance trust and moral trust. We aim to design an\nexperiment to investigate the consequences of performance-trust violation and\nmoral-trust violation in a search and rescue scenario. We want to see if two\nsimilar robot failures, one caused by a performance-trust violation and the\nother by a moral-trust violation have distinct effects on human trust. In\naddition to this, we plan to develop an interface that allows us to investigate\nwhether altering the interface's modality from grid-world scenario (2D\nenvironment) to realistic simulation (3D environment) affects human perception\nof the task and the effects of the robot's failure on human trust.",
    "descriptor": "",
    "authors": [
      "Maitry Ronakbhai Trivedi",
      "Zahra Rezaei Khavas",
      "Paul Robinette"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15430"
  },
  {
    "id": "arXiv:2206.15436",
    "title": "Category-Level 6D Object Pose Estimation in the Wild: A Semi-Supervised  Learning Approach and A New Dataset",
    "abstract": "6D object pose estimation is one of the fundamental problems in computer\nvision and robotics research. While a lot of recent efforts have been made on\ngeneralizing pose estimation to novel object instances within the same\ncategory, namely category-level 6D pose estimation, it is still restricted in\nconstrained environments given the limited number of annotated data. In this\npaper, we collect Wild6D, a new unlabeled RGBD object video dataset with\ndiverse instances and backgrounds. We utilize this data to generalize\ncategory-level 6D object pose estimation in the wild with semi-supervised\nlearning. We propose a new model, called Rendering for Pose estimation network\nRePoNet, that is jointly trained using the free ground-truths with the\nsynthetic data, and a silhouette matching objective function on the real-world\ndata. Without using any 3D annotations on real data, our method outperforms\nstate-of-the-art methods on the previous dataset and our Wild6D test set (with\nmanual annotations for evaluation) by a large margin. Project page with Wild6D\ndata: https://oasisyang.github.io/semi-pose .",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yang Fu",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.15436"
  },
  {
    "id": "arXiv:2206.15437",
    "title": "Understanding Instance-Level Impact of Fairness Constraints",
    "abstract": "A variety of fairness constraints have been proposed in the literature to\nmitigate group-level statistical bias. Their impacts have been largely\nevaluated for different groups of populations corresponding to a set of\nsensitive attributes, such as race or gender. Nonetheless, the community has\nnot observed sufficient explorations for how imposing fairness constraints fare\nat an instance level. Building on the concept of influence function, a measure\nthat characterizes the impact of a training example on the target model and its\npredictive performance, this work studies the influence of training examples\nwhen fairness constraints are imposed. We find out that under certain\nassumptions, the influence function with respect to fairness constraints can be\ndecomposed into a kernelized combination of training examples. One promising\napplication of the proposed fairness influence function is to identify\nsuspicious training examples that may cause model discrimination by ranking\ntheir influence scores. We demonstrate with extensive experiments that training\non a subset of weighty data examples leads to lower fairness violations with a\ntrade-off of accuracy.",
    "descriptor": "\nComments: 17 pages, 6 figures, ICML 2022\n",
    "authors": [
      "Jialu Wang",
      "Xin Eric Wang",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.15437"
  },
  {
    "id": "arXiv:2206.15444",
    "title": "Learning Functions on Multiple Sets using Multi-Set Transformers",
    "abstract": "We propose a general deep architecture for learning functions on multiple\npermutation-invariant sets. We also show how to generalize this architecture to\nsets of elements of any dimension by dimension equivariance. We demonstrate\nthat our architecture is a universal approximator of these functions, and show\nsuperior results to existing methods on a variety of tasks including counting\ntasks, alignment tasks, distinguishability tasks and statistical distance\nmeasurements. This last task is quite important in Machine Learning. Although\nour approach is quite general, we demonstrate that it can generate approximate\nestimates of KL divergence and mutual information that are more accurate than\nprevious techniques that are specifically designed to approximate those\nstatistical distances.",
    "descriptor": "",
    "authors": [
      "Kira Selby",
      "Ahmad Rashid",
      "Ivan Kobyzev",
      "Mehdi Rezagholizadeh",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15444"
  },
  {
    "id": "arXiv:2206.15448",
    "title": "Learning Iterative Reasoning through Energy Minimization",
    "abstract": "Deep learning has excelled on complex pattern recognition tasks such as image\nclassification and object recognition. However, it struggles with tasks\nrequiring nontrivial reasoning, such as algorithmic computation. Humans are\nable to solve such tasks through iterative reasoning -- spending more time\nthinking about harder tasks. Most existing neural networks, however, exhibit a\nfixed computational budget controlled by the neural network architecture,\npreventing additional computational processing on harder tasks. In this work,\nwe present a new framework for iterative reasoning with neural networks. We\ntrain a neural network to parameterize an energy landscape over all outputs,\nand implement each step of the iterative reasoning as an energy minimization\nstep to find a minimal energy solution. By formulating reasoning as an energy\nminimization problem, for harder problems that lead to more complex energy\nlandscapes, we may then adjust our underlying computational budget by running a\nmore complex optimization procedure. We empirically illustrate that our\niterative reasoning approach can solve more accurate and generalizable\nalgorithmic reasoning tasks in both graph and continuous domains. Finally, we\nillustrate that our approach can recursively solve algorithmic problems\nrequiring nested reasoning",
    "descriptor": "\nComments: ICML 2022. Website at this https URL\n",
    "authors": [
      "Yilun Du",
      "Shuang Li",
      "Joshua B. Tenenbaum",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15448"
  },
  {
    "id": "arXiv:2206.15455",
    "title": "Hate Speech Criteria: A Modular Approach to Task-Specific Hate Speech  Definitions",
    "abstract": "\\textbf{Offensive Content Warning}: This paper contains offensive language\nonly for providing examples that clarify this research and do not reflect the\nauthors' opinions. Please be aware that these examples are offensive and may\ncause you distress.\nThe subjectivity of recognizing \\textit{hate speech} makes it a complex task.\nThis is also reflected by different and incomplete definitions in NLP. We\npresent \\textit{hate speech} criteria, developed with perspectives from law and\nsocial science, with the aim of helping researchers create more precise\ndefinitions and annotation guidelines on five aspects: (1) target groups, (2)\ndominance, (3) perpetrator characteristics, (4) type of negative group\nreference, and the (5) type of potential consequences/effects. Definitions can\nbe structured so that they cover a more broad or more narrow phenomenon. As\nsuch, conscious choices can be made on specifying criteria or leaving them\nopen. We argue that the goal and exact task developers have in mind should\ndetermine how the scope of \\textit{hate speech} is defined. We provide an\noverview of the properties of English datasets from \\url{hatespeechdata.com}\nthat may help select the most suitable dataset for a specific scenario.",
    "descriptor": "\nComments: Accepted at WOAH 2022, co-located at NAACL 2022. Cite ACL version\n",
    "authors": [
      "Urja Khurana",
      "Ivar Vermeulen",
      "Eric Nalisnick",
      "Marloes van Noorloos",
      "Antske Fokkens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.15455"
  },
  {
    "id": "arXiv:2206.15462",
    "title": "Improving Visual Grounding by Encouraging Consistent Gradient-based  Explanations",
    "abstract": "We propose a margin-based loss for vision-language model pretraining that\nencourages gradient-based explanations that are consistent with region-level\nannotations. We refer to this objective as Attention Mask Consistency (AMC) and\ndemonstrate that it produces superior visual grounding performance compared to\nmodels that rely instead on region-level annotations for explicitly training an\nobject detector such as Faster R-CNN. AMC works by encouraging gradient-based\nexplanation masks that focus their attention scores mostly within annotated\nregions of interest for images that contain such annotations. Particularly, a\nmodel trained with AMC on top of standard vision-language modeling objectives\nobtains a state-of-the-art accuracy of 86.59% in the Flickr30k visual grounding\nbenchmark, an absolute improvement of 5.48% when compared to the best previous\nmodel. Our approach also performs exceedingly well on established benchmarks\nfor referring expression comprehension and offers the added benefit by design\nof gradient-based explanations that better align with human annotations.",
    "descriptor": "",
    "authors": [
      "Ziyan Yang",
      "Kushal Kafle",
      "Franck Dernoncourt",
      "Vicente Ord\u00f3\u00f1ez Rom\u00e1n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15462"
  },
  {
    "id": "arXiv:2206.15463",
    "title": "QUIDAM: A Framework for Quantization-Aware DNN Accelerator and Model  Co-Exploration",
    "abstract": "As the machine learning and systems communities strive to achieve higher\nenergy-efficiency through custom deep neural network (DNN) accelerators, varied\nprecision or quantization levels, and model compression techniques, there is a\nneed for design space exploration frameworks that incorporate\nquantization-aware processing elements into the accelerator design space while\nhaving accurate and fast power, performance, and area models. In this work, we\npresent QUIDAM, a highly parameterized quantization-aware DNN accelerator and\nmodel co-exploration framework. Our framework can facilitate future research on\ndesign space exploration of DNN accelerators for various design choices such as\nbit precision, processing element type, scratchpad sizes of processing\nelements, global buffer size, number of total processing elements, and DNN\nconfigurations. Our results show that different bit precisions and processing\nelement types lead to significant differences in terms of performance per area\nand energy. Specifically, our framework identifies a wide range of design\npoints where performance per area and energy varies more than 5x and 35x,\nrespectively. With the proposed framework, we show that lightweight processing\nelements achieve on par accuracy results and up to 5.7x more performance per\narea and energy improvement when compared to the best INT16 based\nimplementation. Finally, due to the efficiency of the pre-characterized power,\nperformance, and area models, QUIDAM can speed up the design exploration\nprocess by 3-4 orders of magnitude as it removes the need for expensive\nsynthesis and characterization of each design.",
    "descriptor": "\nComments: 25 pages, 12 figures. arXiv admin note: substantial text overlap with arXiv:2205.13045, arXiv:2205.08648\n",
    "authors": [
      "Ahmet Inci",
      "Siri Garudanagiri Virupaksha",
      "Aman Jain",
      "Ting-Wu Chin",
      "Venkata Vivek Thallam",
      "Ruizhou Ding",
      "Diana Marculescu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15463"
  },
  {
    "id": "arXiv:2206.15465",
    "title": "Interpretability, Then What? Editing Machine Learning Models to Reflect  Human Knowledge and Values",
    "abstract": "Machine learning (ML) interpretability techniques can reveal undesirable\npatterns in data that models exploit to make predictions--potentially causing\nharms once deployed. However, how to take action to address these patterns is\nnot always clear. In a collaboration between ML and human-computer interaction\nresearchers, physicians, and data scientists, we develop GAM Changer, the first\ninteractive system to help domain experts and data scientists easily and\nresponsibly edit Generalized Additive Models (GAMs) and fix problematic\npatterns. With novel interaction techniques, our tool puts interpretability\ninto action--empowering users to analyze, validate, and align model behaviors\nwith their knowledge and values. Physicians have started to use our tool to\ninvestigate and fix pneumonia and sepsis risk prediction models, and an\nevaluation with 7 data scientists working in diverse domains highlights that\nour tool is easy to use, meets their model editing needs, and fits into their\ncurrent workflows. Built with modern web technologies, our tool runs locally in\nusers' web browsers or computational notebooks, lowering the barrier to use.\nGAM Changer is available at the following public demo link:\nhttps://interpret.ml/gam-changer.",
    "descriptor": "\nComments: Accepted at KDD 2022. 11 pages, 19 figures. For a demo video, see this https URL For a live demo, visit this https URL\n",
    "authors": [
      "Zijie J. Wang",
      "Alex Kale",
      "Harsha Nori",
      "Peter Stella",
      "Mark E. Nunnally",
      "Duen Horng Chau",
      "Mihaela Vorvoreanu",
      "Jennifer Wortman Vaughan",
      "Rich Caruana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.15465"
  },
  {
    "id": "arXiv:2206.15469",
    "title": "Watch and Match: Supercharging Imitation with Regularized Optimal  Transport",
    "abstract": "Imitation learning holds tremendous promise in learning policies efficiently\nfor complex decision making problems. Current state-of-the-art algorithms often\nuse inverse reinforcement learning (IRL), where given a set of expert\ndemonstrations, an agent alternatively infers a reward function and the\nassociated optimal policy. However, such IRL approaches often require\nsubstantial online interactions for complex control problems. In this work, we\npresent Regularized Optimal Transport (ROT), a new imitation learning algorithm\nthat builds on recent advances in optimal transport based trajectory-matching.\nOur key technical insight is that adaptively combining trajectory-matching\nrewards with behavior cloning can significantly accelerate imitation even with\nonly a few demonstrations. Our experiments on 20 visual control tasks across\nthe DeepMind Control Suite, the OpenAI Robotics Suite, and the Meta-World\nBenchmark demonstrate an average of 7.8X faster imitation to reach 90% of\nexpert performance compared to prior state-of-the-art methods. On real-world\nrobotic manipulation, with just one demonstration and an hour of online\ntraining, ROT achieves an average success rate of 90.1% across 14 tasks.",
    "descriptor": "\nComments: Robot videos are best viewed on this https URL\n",
    "authors": [
      "Siddhant Haldar",
      "Vaibhav Mathur",
      "Denis Yarats",
      "Lerrel Pinto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15469"
  },
  {
    "id": "arXiv:2206.15470",
    "title": "Dressing Avatars: Deep Photorealistic Appearance for Physically  Simulated Clothing",
    "abstract": "Despite recent progress in developing animatable full-body avatars, realistic\nmodeling of clothing - one of the core aspects of human self-expression -\nremains an open challenge. State-of-the-art physical simulation methods can\ngenerate realistically behaving clothing geometry at interactive rate. Modeling\nphotorealistic appearance, however, usually requires physically-based rendering\nwhich is too expensive for interactive applications. On the other hand,\ndata-driven deep appearance models are capable of efficiently producing\nrealistic appearance, but struggle at synthesizing geometry of highly dynamic\nclothing and handling challenging body-clothing configurations. To this end, we\nintroduce pose-driven avatars with explicit modeling of clothing that exhibit\nboth realistic clothing dynamics and photorealistic appearance learned from\nreal-world data. The key idea is to introduce a neural clothing appearance\nmodel that operates on top of explicit geometry: at train time we use\nhigh-fidelity tracking, whereas at animation time we rely on physically\nsimulated geometry. Our key contribution is a physically-inspired appearance\nnetwork, capable of generating photorealistic appearance with view-dependent\nand dynamic shadowing effects even for unseen body-clothing configurations. We\nconduct a thorough evaluation of our model and demonstrate diverse animation\nresults on several subjects and different types of clothing. Unlike previous\nwork on photorealistic full-body avatars, our approach can produce much richer\ndynamics and more realistic deformations even for loose clothing. We also\ndemonstrate that our formulation naturally allows clothing to be used with\navatars of different people while staying fully animatable, thus enabling, for\nthe first time, photorealistic avatars with novel clothing.",
    "descriptor": "\nComments: The supplementary video can be found on this https URL\n",
    "authors": [
      "Donglai Xiang",
      "Timur Bagautdinov",
      "Tuur Stuyck",
      "Fabian Prada",
      "Javier Romero",
      "Weipeng Xu",
      "Shunsuke Saito",
      "Jingfan Guo",
      "Breannan Smith",
      "Takaaki Shiratori",
      "Yaser Sheikh",
      "Jessica Hodgins",
      "Chenglei Wu"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15470"
  },
  {
    "id": "arXiv:2206.15472",
    "title": "On-Device Training Under 256KB Memory",
    "abstract": "On-device training enables the model to adapt to new data collected from the\nsensors by fine-tuning a pre-trained model. However, the training memory\nconsumption is prohibitive for IoT devices that have tiny memory resources. We\npropose an algorithm-system co-design framework to make on-device training\npossible with only 256KB of memory. On-device training faces two unique\nchallenges: (1) the quantized graphs of neural networks are hard to optimize\ndue to mixed bit-precision and the lack of normalization; (2) the limited\nhardware resource (memory and computation) does not allow full backward\ncomputation. To cope with the optimization difficulty, we propose\nQuantization-Aware Scaling to calibrate the gradient scales and stabilize\nquantized training. To reduce the memory footprint, we propose Sparse Update to\nskip the gradient computation of less important layers and sub-tensors. The\nalgorithm innovation is implemented by a lightweight training system, Tiny\nTraining Engine, which prunes the backward computation graph to support sparse\nupdates and offloads the runtime auto-differentiation to compile time. Our\nframework is the first practical solution for on-device transfer learning of\nvisual recognition on tiny IoT devices (e.g., a microcontroller with only 256KB\nSRAM), using less than 1/100 of the memory of existing frameworks while\nmatching the accuracy of cloud training+edge deployment for the tinyML\napplication VWW. Our study enables IoT devices to not only perform inference\nbut also continuously adapt to new data for on-device lifelong learning.",
    "descriptor": "",
    "authors": [
      "Ji Lin",
      "Ligeng Zhu",
      "Wei-Ming Chen",
      "Wei-Chen Wang",
      "Chuang Gan",
      "Song Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15472"
  },
  {
    "id": "arXiv:2206.15474",
    "title": "Forecasting Future World Events with Neural Networks",
    "abstract": "Forecasting future world events is a challenging but valuable task. Forecasts\nof climate, geopolitical conflict, pandemics and economic indicators help shape\npolicy and decision making. In these domains, the judgment of expert humans\ncontributes to the best forecasts. Given advances in language modeling, can\nthese forecasts be automated? To this end, we introduce Autocast, a dataset\ncontaining thousands of forecasting questions and an accompanying news corpus.\nQuestions are taken from forecasting tournaments, ensuring high quality,\nreal-world importance, and diversity. The news corpus is organized by date,\nallowing us to precisely simulate the conditions under which humans made past\nforecasts (avoiding leakage from the future). Motivated by the difficulty of\nforecasting numbers across orders of magnitude (e.g. global cases of COVID-19\nin 2022), we also curate IntervalQA, a dataset of numerical questions and\nmetrics for calibration. We test language models on our forecasting task and\nfind that performance is far below a human expert baseline. However,\nperformance improves with increased model size and incorporation of relevant\ninformation from the news corpus. In sum, Autocast poses a novel challenge for\nlarge language models and improved performance could bring large practical\nbenefits.",
    "descriptor": "\nComments: Code and the Autocast dataset are available at this https URL\n",
    "authors": [
      "Andy Zou",
      "Tristan Xiao",
      "Ryan Jia",
      "Joe Kwon",
      "Mantas Mazeika",
      "Richard Li",
      "Dawn Song",
      "Jacob Steinhardt",
      "Owain Evans",
      "Dan Hendrycks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.15474"
  },
  {
    "id": "arXiv:2206.15475",
    "title": "Causal Machine Learning: A Survey and Open Problems",
    "abstract": "Causal Machine Learning (CausalML) is an umbrella term for machine learning\nmethods that formalize the data-generation process as a structural causal model\n(SCM). This allows one to reason about the effects of changes to this process\n(i.e., interventions) and what would have happened in hindsight (i.e.,\ncounterfactuals). We categorize work in \\causalml into five groups according to\nthe problems they tackle: (1) causal supervised learning, (2) causal generative\nmodeling, (3) causal explanations, (4) causal fairness, (5) causal\nreinforcement learning. For each category, we systematically compare its\nmethods and point out open problems. Further, we review modality-specific\napplications in computer vision, natural language processing, and graph\nrepresentation learning. Finally, we provide an overview of causal benchmarks\nand a critical discussion of the state of this nascent field, including\nrecommendations for future work.",
    "descriptor": "",
    "authors": [
      "Jean Kaddour",
      "Aengus Lynch",
      "Qi Liu",
      "Matt J. Kusner",
      "Ricardo Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.15475"
  },
  {
    "id": "arXiv:2206.15476",
    "title": "AnoShift: A Distribution Shift Benchmark for Unsupervised Anomaly  Detection",
    "abstract": "Analyzing the distribution shift of data is a growing research direction in\nnowadays Machine Learning, leading to emerging new benchmarks that focus on\nproviding a suitable scenario for studying the generalization properties of ML\nmodels. The existing benchmarks are focused on supervised learning, and to the\nbest of our knowledge, there is none for unsupervised learning. Therefore, we\nintroduce an unsupervised anomaly detection benchmark with data that shifts\nover time, built over Kyoto-2006+, a traffic dataset for network intrusion\ndetection. This kind of data meets the premise of shifting the input\ndistribution: it covers a large time span ($10$ years), with naturally\noccurring changes over time (\\eg users modifying their behavior patterns, and\nsoftware updates). We first highlight the non-stationary nature of the data,\nusing a basic per-feature analysis, t-SNE, and an Optimal Transport approach\nfor measuring the overall distribution distances between years. Next, we\npropose AnoShift, a protocol splitting the data in IID, NEAR, and FAR testing\nsplits. We validate the performance degradation over time with diverse models\n(MLM to classical Isolation Forest). Finally, we show that by acknowledging the\ndistribution shift problem and properly addressing it, the performance can be\nimproved compared to the classical IID training (by up to $3\\%$, on average).\nDataset and code are available at https://github.com/bit-ml/AnoShift/.",
    "descriptor": "",
    "authors": [
      "Marius Dr\u0103goi",
      "Elena Burceanu",
      "Emanuela Haller",
      "Andrei Manolache",
      "Florin Brad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15476"
  },
  {
    "id": "arXiv:2206.15477",
    "title": "Denoised MDPs: Learning World Models Better Than the World Itself",
    "abstract": "The ability to separate signal from noise, and reason with clean\nabstractions, is critical to intelligence. With this ability, humans can\nefficiently perform real world tasks without considering all possible nuisance\nfactors.How can artificial agents do the same? What kind of information can\nagents safely discard as noises?\nIn this work, we categorize information out in the wild into four types based\non controllability and relation with reward, and formulate useful information\nas that which is both controllable and reward-relevant. This framework\nclarifies the kinds information removed by various prior work on representation\nlearning in reinforcement learning (RL), and leads to our proposed approach of\nlearning a Denoised MDP that explicitly factors out certain noise distractors.\nExtensive experiments on variants of DeepMind Control Suite and RoboDesk\ndemonstrate superior performance of our denoised world model over using raw\nobservations alone, and over prior works, across policy optimization control\ntasks as well as the non-control task of joint position regression.",
    "descriptor": "\nComments: Project page: this https URL Code: this https URL\n",
    "authors": [
      "Tongzhou Wang",
      "Simon S. Du",
      "Antonio Torralba",
      "Phillip Isola",
      "Amy Zhang",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15477"
  },
  {
    "id": "arXiv:2206.15478",
    "title": "On the Learning and Learnablity of Quasimetrics",
    "abstract": "Our world is full of asymmetries. Gravity and wind can make reaching a place\neasier than coming back. Social artifacts such as genealogy charts and citation\ngraphs are inherently directed. In reinforcement learning and control, optimal\ngoal-reaching strategies are rarely reversible (symmetrical). Distance\nfunctions supported on these asymmetrical structures are called quasimetrics.\nDespite their common appearance, little research has been done on the learning\nof quasimetrics.\nOur theoretical analysis reveals that a common class of learning algorithms,\nincluding unconstrained multilayer perceptrons (MLPs), provably fails to learn\na quasimetric consistent with training data. In contrast, our proposed Poisson\nQuasimetric Embedding (PQE) is the first quasimetric learning formulation that\nboth is learnable with gradient-based optimization and enjoys strong\nperformance guarantees. Experiments on random graphs, social graphs, and\noffline Q-learning demonstrate its effectiveness over many common baselines.",
    "descriptor": "\nComments: Project page: this https URL Code: this https URL\n",
    "authors": [
      "Tongzhou Wang",
      "Phillip Isola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15478"
  },
  {
    "id": "arXiv:2206.14820",
    "title": "Strong Lensing Source Reconstruction Using Continuous Neural Fields",
    "abstract": "From the nature of dark matter to the rate of expansion of our Universe,\nobservations of distant galaxies distorted through strong gravitational lensing\nhave the potential to answer some of the major open questions in astrophysics.\nModeling galaxy-galaxy strong lensing observations presents a number of\nchallenges as the exact configuration of both the background source and\nforeground lens galaxy is unknown. A timely call, prompted by a number of\nupcoming surveys anticipating high-resolution lensing images, demands methods\nthat can efficiently model lenses at their full complexity. In this work, we\nintroduce a method that uses continuous neural fields to non-parametrically\nreconstruct the complex morphology of a source galaxy while simultaneously\ninferring a distribution over foreground lens galaxy configurations. We\ndemonstrate the efficacy of our method through experiments on simulated data\ntargeting high-resolution lensing images similar to those anticipated in\nnear-future astrophysical surveys.",
    "descriptor": "\nComments: 8+2 pages, 3+2 figures, accepted at the Machine Learning for Astrophysics Workshop at ICML 2022\n",
    "authors": [
      "Siddharth Mishra-Sharma",
      "Ge Yang"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14820"
  },
  {
    "id": "arXiv:2206.14847",
    "title": "Deep Reinforcement Learning for Small Bowel Path Tracking using  Different Types of Annotations",
    "abstract": "Small bowel path tracking is a challenging problem considering its many folds\nand contact along its course. For the same reason, it is very costly to achieve\nthe ground-truth (GT) path of the small bowel in 3D. In this work, we propose\nto train a deep reinforcement learning tracker using datasets with different\ntypes of annotations. Specifically, we utilize CT scans that have only GT small\nbowel segmentation as well as ones with the GT path. It is enabled by designing\na unique environment that is compatible for both, including a reward definable\neven without the GT path. The performed experiments proved the validity of the\nproposed method. The proposed method holds a high degree of usability in this\nproblem by being able to utilize the scans with weak annotations, and thus by\npossibly reducing the required annotation cost.",
    "descriptor": "\nComments: Accepted to MICCAI 2022\n",
    "authors": [
      "Seung Yeon Shin",
      "Ronald M. Summers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14847"
  },
  {
    "id": "arXiv:2206.14861",
    "title": "Two-Stage COVID19 Classification Using BERT Features",
    "abstract": "We propose an automatic COVID1-19 diagnosis framework from lung CT-scan slice\nimages using double BERT feature extraction. In the first BERT feature\nextraction, A 3D-CNN is first used to extract CNN internal feature maps.\nInstead of using the global average pooling, a late BERT temporal pooing is\nused to aggregate the temporal information in these feature maps, followed by a\nclassification layer. This 3D-CNN-BERT classification network is first trained\non sampled fixed number of slice images from every original CT scan volume. In\nthe second stage, the 3D-CNN-BERT embedding features are extracted on all slice\nimages of every CT scan volume, and these features are averaged into a fixed\nnumber of segments. Then another BERT network is used to aggregate these\nmultiple features into a single feature followed by another classification\nlayer. The classification results of both stages are combined to generate final\noutputs. On the validation dataset, we achieve macro F1 score of 0.9164.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.14403\n",
    "authors": [
      "Weijun Tan",
      "Qi Yao",
      "Jingfeng Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14861"
  },
  {
    "id": "arXiv:2206.14866",
    "title": "iEmoTTS: Toward Robust Cross-Speaker Emotion Transfer and Control for  Speech Synthesis based on Disentanglement between Prosody and Timbre",
    "abstract": "The capability of generating speech with specific type of emotion is desired\nfor many applications of human-computer interaction. Cross-speaker emotion\ntransfer is a common approach to generating emotional speech when speech with\nemotion labels from target speakers is not available for model training. This\npaper presents a novel cross-speaker emotion transfer system, named iEmoTTS.\nThe system is composed of an emotion encoder, a prosody predictor, and a timbre\nencoder. The emotion encoder extracts the identity of emotion type as well as\nthe respective emotion intensity from the mel-spectrogram of input speech. The\nemotion intensity is measured by the posterior probability that the input\nutterance carries that emotion. The prosody predictor is used to provide\nprosodic features for emotion transfer. The timber encoder provides\ntimbre-related information for the system. Unlike many other studies which\nfocus on disentangling speaker and style factors of speech, the iEmoTTS is\ndesigned to achieve cross-speaker emotion transfer via disentanglement between\nprosody and timbre. Prosody is considered as the main carrier of\nemotion-related speech characteristics and timbre accounts for the essential\ncharacteristics for speaker identification. Zero-shot emotion transfer, meaning\nthat speech of target speakers are not seen in model training, is also realized\nwith iEmoTTS. Extensive experiments of subjective evaluation have been carried\nout. The results demonstrate the effectiveness of iEmoTTS as compared with\nother recently proposed systems of cross-speaker emotion transfer. It is shown\nthat iEmoTTS can produce speech with designated emotion type and controllable\nemotion intensity. With appropriate information bottleneck capacity, iEmoTTS is\nable to effectively transfer emotion information to a new speaker. Audio\nsamples are publicly\navailable\\footnote{https://patrick-g-zhang.github.io/iemotts/}.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Audio, Speech, and Language Processing\n",
    "authors": [
      "Guangyan Zhang",
      "Ying Qin",
      "Wenjie Zhang",
      "Jialun Wu",
      "Mei Li",
      "Yutao Gai",
      "Feijun Jiang",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.14866"
  },
  {
    "id": "arXiv:2206.14882",
    "title": "LIDL: Local Intrinsic Dimension Estimation Using Approximate Likelihood",
    "abstract": "Most of the existing methods for estimating the local intrinsic dimension of\na data distribution do not scale well to high-dimensional data. Many of them\nrely on a non-parametric nearest neighbors approach which suffers from the\ncurse of dimensionality. We attempt to address that challenge by proposing a\nnovel approach to the problem: Local Intrinsic Dimension estimation using\napproximate Likelihood (LIDL). Our method relies on an arbitrary density\nestimation method as its subroutine and hence tries to sidestep the\ndimensionality challenge by making use of the recent progress in parametric\nneural methods for likelihood estimation. We carefully investigate the\nempirical properties of the proposed method, compare them with our theoretical\npredictions, and show that LIDL yields competitive results on the standard\nbenchmarks for this problem and that it scales to thousands of dimensions. What\nis more, we anticipate this approach to improve further with the continuing\nadvances in the density estimation literature.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Piotr Tempczyk",
      "Rafa\u0142 Michaluk",
      "\u0141ukasz Garncarek",
      "Przemys\u0142aw Spurek",
      "Jacek Tabor",
      "Adam Goli\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14882"
  },
  {
    "id": "arXiv:2206.14893",
    "title": "Breaking indecision in multi-agent, multi-option dynamics",
    "abstract": "How does a group of agents break indecision when deciding about options with\nqualities that are hard to distinguish? Biological and artificial multi-agent\nsystems, from honeybees and bird flocks to bacteria, robots, and humans, often\nneed to overcome indecision when choosing among options in situations in which\nthe performance or even the survival of the group are at stake. Breaking\nindecision is also important because in a fully indecisive state agents are not\nbiased toward any specific option and therefore the agent group is maximally\nsensitive and prone to adapt to inputs and changes in its environment. Here, we\ndevelop a mathematical theory to study how decisions arise from the breaking of\nindecision. Our approach is grounded in both equivariant and network\nbifurcation theory. We model decision from indecision as synchrony-breaking in\ninfluence networks in which each node is the value assigned by an agent to an\noption. First, we show that three universal decision behaviors, namely,\ndeadlock, consensus, and dissensus, are the generic outcomes of\nsynchrony-breaking bifurcations from a fully synchronous state of indecision in\ninfluence networks. Second, we show that all deadlock and consensus value\npatterns and some dissensus value patterns are predicted by the symmetry of the\ninfluence networks. Third, we show that there are also many `exotic' dissensus\nvalue patterns. These patterns are predicted by network architecture, but not\nby network symmetries, through a new synchrony-breaking branching lemma. This\nis the first example of exotic solutions in an application. Numerical\nsimulations of a novel influence network model illustrate our theoretical\nresults.",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Alessio Franci",
      "Martin Golubitsky",
      "Ian Stewart",
      "Anastasia Bizyaeva",
      "Naomi Ehrich Leonard"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.14893"
  },
  {
    "id": "arXiv:2206.14896",
    "title": "Threshold for Detecting High Dimensional Geometry in Anisotropic Random  Geometric Graphs",
    "abstract": "In the anisotropic random geometric graph model, vertices correspond to\npoints drawn from a high-dimensional Gaussian distribution and two vertices are\nconnected if their distance is smaller than a specified threshold. We study\nwhen it is possible to hypothesis test between such a graph and an\nErd\\H{o}s-R\\'enyi graph with the same edge probability. If $n$ is the number of\nvertices and $\\alpha$ is the vector of eigenvalues, Eldan and Mikulincer show\nthat detection is possible when $n^3 \\gg (\\|\\alpha\\|_2/\\|\\alpha\\|_3)^6$ and\nimpossible when $n^3 \\ll (\\|\\alpha\\|_2/\\|\\alpha\\|_4)^4$. We show detection is\nimpossible when $n^3 \\ll (\\|\\alpha\\|_2/\\|\\alpha\\|_3)^6$, closing this gap and\naffirmatively resolving the conjecture of Eldan and Mikulincer.",
    "descriptor": "\nComments: 11 pages, comments welcome\n",
    "authors": [
      "Matthew Brennan",
      "Guy Bresler",
      "Brice Huang"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.14896"
  },
  {
    "id": "arXiv:2206.14903",
    "title": "CIRDataset: A large-scale Dataset for Clinically-Interpretable lung  nodule Radiomics and malignancy prediction",
    "abstract": "Spiculations/lobulations, sharp/curved spikes on the surface of lung nodules,\nare good predictors of lung cancer malignancy and hence, are routinely assessed\nand reported by radiologists as part of the standardized Lung-RADS clinical\nscoring criteria. Given the 3D geometry of the nodule and 2D slice-by-slice\nassessment by radiologists, manual spiculation/lobulation annotation is a\ntedious task and thus no public datasets exist to date for probing the\nimportance of these clinically-reported features in the SOTA malignancy\nprediction algorithms. As part of this paper, we release a large-scale\nClinically-Interpretable Radiomics Dataset, CIRDataset, containing 956\nradiologist QA/QC'ed spiculation/lobulation annotations on segmented lung\nnodules from two public datasets, LIDC-IDRI (N=883) and LUNGx (N=73). We also\npresent an end-to-end deep learning model based on multi-class Voxel2Mesh\nextension to segment nodules (while preserving spikes), classify spikes\n(sharp/spiculation and curved/lobulation), and perform malignancy prediction.\nPrevious methods have performed malignancy prediction for LIDC and LUNGx\ndatasets but without robust attribution to any clinically reported/actionable\nfeatures (due to known hyperparameter sensitivity issues with general\nattribution schemes). With the release of this comprehensively-annotated\nCIRDataset and end-to-end deep learning baseline, we hope that malignancy\nprediction methods can validate their explanations, benchmark against our\nbaseline, and provide clinically-actionable insights. Dataset, code, pretrained\nmodels, and docker containers are available at\nhttps://github.com/nadeemlab/CIR.",
    "descriptor": "\nComments: MICCAI 2022\n",
    "authors": [
      "Wookjin Choi",
      "Navdeep Dahiya",
      "Saad Nadeem"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14903"
  },
  {
    "id": "arXiv:2206.14916",
    "title": "The Hiatus Between Organism and Machine Evolution: Contrasting Mixed  Microbial Communities with Robots",
    "abstract": "Mixed microbial communities, usually composed of various bacterial and fungal\nspecies, are fundamental in a plethora of environments, from soil to human gut\nand skin. Their evolution is a paradigmatic example of intertwined dynamics,\nwhere not just the relations among species plays a role, but also the\nopportunities -- and possible harms -- that each species presents to the\nothers. These opportunities are in fact \\textit{affordances}, which can be\nseized by heritable variation and selection. In this paper, starting from a\nsystemic viewpoint of mixed microbial communities, we focus on the pivotal role\nof affordances in evolution and we contrast it to the artificial evolution of\nprograms and robots. We maintain that the two realms are neatly separated, in\nthat natural evolution proceeds by extending the space of its possibilities in\na completely open way, while the latter is inherently limited by the\nalgorithmic framework it is defined. This discrepancy characterises also an\nenvisioned setting in which robots evolve in the physical world. We present\narguments supporting our claim and we propose an experimental setting for\nassessing our statements. Rather than just discussing the limitations of the\nartificial evolution of machines, the aim of this contribution is to emphasize\nthe tremendous potential of the evolution of the biosphere, beautifully\nrepresented by the evolution of communities of microbes.",
    "descriptor": "",
    "authors": [
      "Andrea Roli",
      "Stuart A. Kauffman"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.14916"
  },
  {
    "id": "arXiv:2206.14917",
    "title": "Towards out of distribution generalization for problems in mechanics",
    "abstract": "There has been a massive increase in research interest towards applying data\ndriven methods to problems in mechanics. While traditional machine learning\n(ML) methods have enabled many breakthroughs, they rely on the assumption that\nthe training (observed) data and testing (unseen) data are independent and\nidentically distributed (i.i.d). Thus, traditional ML approaches often break\ndown when applied to real world mechanics problems with unknown test\nenvironments and data distribution shifts. In contrast, out-of-distribution\n(OOD) generalization assumes that the test data may shift (i.e., violate the\ni.i.d. assumption). To date, multiple methods have been proposed to improve the\nOOD generalization of ML methods. However, because of the lack of benchmark\ndatasets for OOD regression problems, the efficiency of these OOD methods on\nregression problems, which dominate the mechanics field, remains unknown. To\naddress this, we investigate the performance of OOD generalization methods for\nregression problems in mechanics. Specifically, we identify three OOD problems:\ncovariate shift, mechanism shift, and sampling bias. For each problem, we\ncreate two benchmark examples that extend the Mechanical MNIST dataset\ncollection, and we investigate the performance of popular OOD generalization\nmethods on these mechanics-specific regression problems. Our numerical\nexperiments show that in most cases, while the OOD generalization algorithms\nperform better compared to traditional ML methods on these OOD problems, there\nis a compelling need to develop more robust OOD generalization methods that are\neffective across multiple OOD scenarios. Overall, we expect that this study, as\nwell as the associated open access benchmark datasets, will enable further\ndevelopment of OOD generalization methods for mechanics specific regression\nproblems.",
    "descriptor": "",
    "authors": [
      "Lingxiao Yuan",
      "Harold S. Park",
      "Emma Lejeune"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2206.14917"
  },
  {
    "id": "arXiv:2206.14919",
    "title": "Identifying and Combating Bias in Segmentation Networks by leveraging  multiple resolutions",
    "abstract": "Exploration of bias has significant impact on the transparency and\napplicability of deep learning pipelines in medical settings, yet is so far\nwoefully understudied. In this paper, we consider two separate groups for which\ntraining data is only available at differing image resolutions. For group H,\navailable images and labels are at the preferred high resolution while for\ngroup L only deprecated lower resolution data exist. We analyse how this\nresolution-bias in the data distribution propagates to systematically biased\npredictions for group L at higher resolutions. Our results demonstrate that\nsingle-resolution training settings result in significant loss of volumetric\ngroup differences that translate to erroneous segmentations as measured by DSC\nand subsequent classification failures on the low resolution group. We further\nexplore how training data across resolutions can be used to combat this\nsystematic bias. Specifically, we investigate the effect of image resampling,\nscale augmentation and resolution independence and demonstrate that biases can\neffectively be reduced with multi-resolution approaches.",
    "descriptor": "",
    "authors": [
      "Leonie Henschel",
      "David K\u00fcgler",
      "Derek S Andrews",
      "Christine W Nordahl",
      "Martin Reuter"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14919"
  },
  {
    "id": "arXiv:2206.14929",
    "title": "Succinct Classical Verification of Quantum Computation",
    "abstract": "We construct a classically verifiable succinct interactive argument for\nquantum computation (BQP) with communication complexity and verifier runtime\nthat are poly-logarithmic in the runtime of the BQP computation (and polynomial\nin the security parameter). Our protocol is secure assuming the post-quantum\nsecurity of indistinguishability obfuscation (iO) and Learning with Errors\n(LWE). This is the first succinct argument for quantum computation in the plain\nmodel; prior work (Chia-Chung-Yamakawa, TCC '20) requires both a long common\nreference string and non-black-box use of a hash function modeled as a random\noracle.\nAt a technical level, we revisit the framework for constructing classically\nverifiable quantum computation (Mahadev, FOCS '18). We give a self-contained,\nmodular proof of security for Mahadev's protocol, which we believe is of\nindependent interest. Our proof readily generalizes to a setting in which the\nverifier's first message (which consists of many public keys) is compressed.\nNext, we formalize this notion of compressed public keys; we view the object as\na generalization of constrained/programmable PRFs and instantiate it based on\nindistinguishability obfuscation.\nFinally, we compile the above protocol into a fully succinct argument using a\n(sufficiently composable) succinct argument of knowledge for NP. Using our\nframework, we achieve several additional results, including\n- Succinct arguments for QMA (given multiple copies of the witness),\n- Succinct non-interactive arguments for BQP (or QMA) in the quantum random\noracle model, and\n- Succinct batch arguments for BQP (or QMA) assuming post-quantum LWE\n(without iO).",
    "descriptor": "\nComments: CRYPTO 2022\n",
    "authors": [
      "James Bartusek",
      "Yael Tauman Kalai",
      "Alex Lombardi",
      "Fermi Ma",
      "Giulio Malavolta",
      "Vinod Vaikuntanathan",
      "Thomas Vidick",
      "Lisa Yang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.14929"
  },
  {
    "id": "arXiv:2206.14941",
    "title": "The Vera C. Rubin Observatory Data Butler and Pipeline Execution System",
    "abstract": "The Rubin Observatory's Data Butler is designed to allow data file location\nand file formats to be abstracted away from the people writing the science\npipeline algorithms. The Butler works in conjunction with the workflow graph\nbuilder to allow pipelines to be constructed from the algorithmic tasks. These\npipelines can be executed at scale using object stores and multi-node clusters,\nor on a laptop using a local file system. The Butler and pipeline system are\nnow in daily use during Rubin construction and early operations.",
    "descriptor": "\nComments: 14 pages, 3 figures, submitted to Proc SPIE 12189, \"Software and Cyberinfrastructure for Astronomy VII\", Montreal, CA, July 2022\n",
    "authors": [
      "Tim Jenness",
      "James F. Bosch",
      "Nate B. Lust",
      "Nathan M. Pease",
      "Michelle Gower",
      "Mikolaj Kowalik",
      "Gregory P. Dubois-Felsmann",
      "Fritz Mueller",
      "Pim Schellart"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.14941"
  },
  {
    "id": "arXiv:2206.14943",
    "title": "Weighted ensemble: Recent mathematical developments",
    "abstract": "The weighted ensemble (WE) method, an enhanced sampling approach based on\nperiodically replicating and pruning trajectories in a set of parallel\nsimulations, has grown increasingly popular for computational biochemistry\nproblems, due in part to improved hardware and the availability of modern\nsoftware. Algorithmic and analytical improvements have also played an important\nrole, and progress has accelerated in recent years. Here, we discuss and\nelaborate on the WE method from a mathematical perspective, highlighting recent\nresults which have begun to yield greater computational efficiency. Notable\namong these innovations are variance reduction approaches that optimize\ntrajectory management for systems of arbitrary dimensionality.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "D. Aristoff",
      "J. Copperman",
      "G. Simpson",
      "R.J. Webber",
      "D.M. Zuckerman"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.14943"
  },
  {
    "id": "arXiv:2206.14947",
    "title": "Decision Forest Based EMG Signal Classification with Low Volume Dataset  Augmented with Random Variance Gaussian Noise",
    "abstract": "Electromyography signals can be used as training data by machine learning\nmodels to classify various gestures. We seek to produce a model that can\nclassify six different hand gestures with a limited number of samples that\ngeneralizes well to a wider audience while comparing the effect of our feature\nextraction results on model accuracy to other more conventional methods such as\nthe use of AR parameters on a sliding window across the channels of a signal.\nWe appeal to a set of more elementary methods such as the use of random bounds\non a signal, but desire to show the power these methods can carry in an online\nsetting where EMG classification is being conducted, as opposed to more\ncomplicated methods such as the use of the Fourier Transform. To augment our\nlimited training data, we used a standard technique, known as jitter, where\nrandom noise is added to each observation in a channel wise manner. Once all\ndatasets were produced using the above methods, we performed a grid search with\nRandom Forest and XGBoost to ultimately create a high accuracy model. For human\ncomputer interface purposes, high accuracy classification of EMG signals is of\nparticular importance to their functioning and given the difficulty and cost of\namassing any sort of biomedical data in a high volume, it is valuable to have\ntechniques that can work with a low amount of high-quality samples with less\nexpensive feature extraction methods that can reliably be carried out in an\nonline application.",
    "descriptor": "",
    "authors": [
      "Tekin Gunasar",
      "Alexandra Rekesh",
      "Atul Nair",
      "Penelope King",
      "Anastasiya Markova",
      "Jiaqi Zhang",
      "Isabel Tate"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14947"
  },
  {
    "id": "arXiv:2206.14951",
    "title": "CLTS-GAN: Color-Lighting-Texture-Specular Reflection Augmentation for  Colonoscopy",
    "abstract": "Automated analysis of optical colonoscopy (OC) video frames (to assist\nendoscopists during OC) is challenging due to variations in color, lighting,\ntexture, and specular reflections. Previous methods either remove some of these\nvariations via preprocessing (making pipelines cumbersome) or add diverse\ntraining data with annotations (but expensive and time-consuming). We present\nCLTS-GAN, a new deep learning model that gives fine control over color,\nlighting, texture, and specular reflection synthesis for OC video frames. We\nshow that adding these colonoscopy-specific augmentations to the training data\ncan improve state-of-the-art polyp detection/segmentation methods as well as\ndrive next generation of OC simulators for training medical students. The code\nand pre-trained models for CLTS-GAN are available on Computational Endoscopy\nPlatform GitHub (https://github.com/nadeemlab/CEP).",
    "descriptor": "\nComments: MICCAI 2022. **First two authors contributed equally\n",
    "authors": [
      "Shawn Mathew",
      "Saad Nadeem",
      "Arie Kaufman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.14951"
  },
  {
    "id": "arXiv:2206.14962",
    "title": "GLD-Net: Improving Monaural Speech Enhancement by Learning Global and  Local Dependency Features with GLD Block",
    "abstract": "For monaural speech enhancement, contextual information is important for\naccurate speech estimation. However, commonly used convolution neural networks\n(CNNs) are weak in capturing temporal contexts since they only build blocks\nthat process one local neighborhood at a time. To address this problem, we\nlearn from human auditory perception to introduce a two-stage trainable\nreasoning mechanism, referred as global-local dependency (GLD) block. GLD\nblocks capture long-term dependency of time-frequency bins both in global level\nand local level from the noisy spectrogram to help detecting correlations among\nspeech part, noise part, and whole noisy input. What is more, we conduct a\nmonaural speech enhancement network called GLD-Net, which adopts\nencoder-decoder architecture and consists of speech object branch, interference\nbranch, and global noisy branch. The extracted speech feature at global-level\nand local-level are efficiently reasoned and aggregated in each of the\nbranches. We compare the proposed GLD-Net with existing state-of-art methods on\nWSJ0 and DEMAND dataset. The results show that GLD-Net outperforms the\nstate-of-the-art methods in terms of PESQ and STOI.",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Xinmeng Xu",
      "Yang Wang",
      "Jie Jia",
      "Binbin Chen",
      "Jianjun Hao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.14962"
  },
  {
    "id": "arXiv:2206.14964",
    "title": "Improving Visual Speech Enhancement Network by Learning Audio-visual  Affinity with Multi-head Attention",
    "abstract": "Audio-visual speech enhancement system is regarded as one of promising\nsolutions for isolating and enhancing speech of desired speaker. Typical\nmethods focus on predicting clean speech spectrum via a naive convolution\nneural network based encoder-decoder architecture, and these methods a) are not\nadequate to use data fully, b) are unable to effectively balance audio-visual\nfeatures. The proposed model alleviates these drawbacks by a) applying a model\nthat fuses audio and visual features layer by layer in encoding phase, and that\nfeeds fused audio-visual features to each corresponding decoder layer, and more\nimportantly, b) introducing a 2-stage multi-head cross attention (MHCA)\nmechanism to infer audio-visual speech enhancement for balancing the fused\naudio-visual features and eliminating irrelevant features. This paper proposes\nattentional audio-visual multi-layer feature fusion model, in which MHCA units\nare applied to feature mapping at every layer of decoder. The proposed model\ndemonstrates the superior performance of the network against the\nstate-of-the-art models.",
    "descriptor": "\nComments: Accepted by Interspeech 2022. arXiv admin note: substantial text overlap with arXiv:2101.06268\n",
    "authors": [
      "Xinmeng Xu",
      "Yang Wang",
      "Jie Jia",
      "Binbin Chen",
      "Dejun Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.14964"
  },
  {
    "id": "arXiv:2206.14981",
    "title": "Randomized Coordinate Subgradient Method for Nonsmooth Optimization",
    "abstract": "Nonsmooth optimization finds wide applications in many engineering fields. In\nthis work, we propose to utilize the {Randomized Coordinate Subgradient Method}\n(RCS) for solving both nonsmooth convex and nonsmooth nonconvex (nonsmooth\nweakly convex) optimization problems. At each iteration, RCS randomly selects\none block coordinate rather than all the coordinates to update. Motivated by\npractical applications, we consider the {linearly bounded subgradients\nassumption} for the objective function, which is much more general than the\nLipschitz continuity assumption. Under such a general assumption, we conduct\nthorough convergence analysis for RCS in both convex and nonconvex cases and\nestablish both expected convergence rate and almost sure asymptotic convergence\nresults. In order to derive these convergence results, we establish a\nconvergence lemma and the relationship between the global metric subregularity\nproperties of a weakly convex function and its Moreau envelope, which are\nfundamental and of independent interests. Finally, we conduct several\nexperiments to show the possible superiority of RCS over the subgradient\nmethod.",
    "descriptor": "",
    "authors": [
      "Lei Zhao",
      "Ding Chen",
      "Daoli Zhu",
      "Xiao Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14981"
  },
  {
    "id": "arXiv:2206.14984",
    "title": "TTS-by-TTS 2: Data-selective augmentation for neural speech synthesis  using ranking support vector machine with variational autoencoder",
    "abstract": "Recent advances in synthetic speech quality have enabled us to train\ntext-to-speech (TTS) systems by using synthetic corpora. However, merely\nincreasing the amount of synthetic data is not always advantageous for\nimproving training efficiency. Our aim in this study is to selectively choose\nsynthetic data that are beneficial to the training process. In the proposed\nmethod, we first adopt a variational autoencoder whose posterior distribution\nis utilized to extract latent features representing acoustic similarity between\nthe recorded and synthetic corpora. By using those learned features, we then\ntrain a ranking support vector machine (RankSVM) that is well known for\neffectively ranking relative attributes among binary classes. By setting the\nrecorded and synthetic ones as two opposite classes, RankSVM is used to\ndetermine how the synthesized speech is acoustically similar to the recorded\ndata. Then, synthetic TTS data, whose distribution is close to the recorded\ndata, are selected from large-scale synthetic corpora. By using these data for\nretraining the TTS model, the synthetic quality can be significantly improved.\nObjective and subjective evaluation results show the superiority of the\nproposed method over the conventional methods.",
    "descriptor": "\nComments: Accepted to the conference of INTERSPEECH 2022\n",
    "authors": [
      "Eunwoo Song",
      "Ryuichi Yamamoto",
      "Ohsung Kwon",
      "Chan-Ho Song",
      "Min-Jae Hwang",
      "Suhyeon Oh",
      "Hyun-Wook Yoon",
      "Jin-Seob Kim",
      "Jae-Min Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.14984"
  },
  {
    "id": "arXiv:2206.14986",
    "title": "A Hierarchical Robust Control Strategy for Decentralized Signal-Free  Intersection Management",
    "abstract": "The development of connected and automated vehicles (CAVs) is the key to\nimprove urban mobility safety and efficiency. This paper focuses on the\ncooperative vehicle management at a signal-free intersection with consideration\nof vehicle modeling uncertainties and sensor measurement disturbances. The\nproblem is approached by a hierarchical robust control strategy (HRCS) in a\ndecentralized traffic coordination framework where optimal control and\ntube-based robust model predictive control (RMPC) methods are designed to\nhierarchically solve the optimal crossing order and the velocity trajectories\nof a group of CAVs in terms of energy consumption and throughput. To capture\nthe energy consumption of each vehicle, their powertrain system is modeled in\nline with an electric drive system. With a suitable relaxation and spatial\nmodeling approach, the optimization problems in HRCS can be formulated as\nconvex second-order cone programs (SOCPs), which provide unique and\ncomputationally efficient solution. A rigorous proof of the equivalence between\nthe convexified and the original problems is also provided. Simulation results\nillustrate the effectiveness and robustness of HRCS and reveal the impact of\ntraffic density on the control solution. The study of the Pareto optimal\nsolutions for the energy-time objective shows that a minor reduction in journey\ntime can considerably reduce energy consumption, which emphasizes the necessity\nof optimizing their trade-off. Finally, the numerical comparisons carried out\nfor different prediction horizons and sampling intervals provide insight into\nthe control design.",
    "descriptor": "\nComments: 14 pages, 9 figures, 3 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: text overlap with arXiv:2203.16870\n",
    "authors": [
      "Xiao Pan",
      "Boli Chen",
      "Li Dai",
      "Stelios Timotheou",
      "Simos A. Evangelou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.14986"
  },
  {
    "id": "arXiv:2206.14990",
    "title": "Bridging Mean-Field Games and Normalizing Flows with Trajectory  Regularization",
    "abstract": "Mean-field games (MFGs) are a modeling framework for systems with a large\nnumber of interacting agents. They have applications in economics, finance, and\ngame theory. Normalizing flows (NFs) are a family of deep generative models\nthat compute data likelihoods by using an invertible mapping, which is\ntypically parameterized by using neural networks. They are useful for density\nmodeling and data generation. While active research has been conducted on both\nmodels, few noted the relationship between the two. In this work, we unravel\nthe connections between MFGs and NFs by contextualizing the training of an NF\nas solving the MFG. This is achieved by reformulating the MFG problem in terms\nof agent trajectories and parameterizing a discretization of the resulting MFG\nwith flow architectures. With this connection, we explore two research\ndirections. First, we employ expressive NF architectures to accurately solve\nhigh-dimensional MFGs, sidestepping the curse of dimensionality in traditional\nnumerical methods. Compared with other deep learning approaches, our\ntrajectory-based formulation encodes the continuity equation in the neural\nnetwork, resulting in a better approximation of the population dynamics.\nSecond, we regularize the training of NFs with transport costs and show the\neffectiveness on controlling the model's Lipschitz bound, resulting in better\ngeneralization performance. We demonstrate numerical results through\ncomprehensive experiments on a variety of synthetic and real-life datasets.",
    "descriptor": "\nComments: 36 pages, 22 figures, 9 tables\n",
    "authors": [
      "Han Huang",
      "Jiajia Yu",
      "Jie Chen",
      "Rongjie Lai"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.14990"
  },
  {
    "id": "arXiv:2206.15069",
    "title": "PVT-COV19D: Pyramid Vision Transformer for COVID-19 Diagnosis",
    "abstract": "With the outbreak of COVID-19, a large number of relevant studies have\nemerged in recent years. We propose an automatic COVID-19 diagnosis framework\nbased on lung CT scan images, the PVT-COV19D. In order to accommodate the\ndifferent dimensions of the image input, we first classified the images using\nTransformer models, then sampled the images in the dataset according to normal\ndistribution, and fed the sampling results into the modified PVTv2 model for\ntraining. A large number of experiments on the COV19-CT-DB dataset demonstrate\nthe effectiveness of the proposed method.",
    "descriptor": "\nComments: 8 pages,1 figure\n",
    "authors": [
      "Lilang Zheng",
      "Jiaxuan Fang",
      "Xiaorun Tang",
      "Hanzhang Li",
      "Jiaxin Fan",
      "Tianyi Wang",
      "Rui Zhou",
      "Zhaoyan Yan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15069"
  },
  {
    "id": "arXiv:2206.15073",
    "title": "Custom Pretrainings and Adapted 3D-ConvNeXt Architecture for COVID  Detection and Severity Prediction",
    "abstract": "Since COVID strongly affects the respiratory system, lung CT scans can be\nused for the analysis of a patients health. We introduce an neural network for\nthe prediction of the severity of lung damage and the detection of infection\nusing three-dimensional CT-scans. Therefore, we adapt the recent ConvNeXt model\nto process three-dimensional data. Furthermore, we introduce different\npretraining methods specifically adjusted to improve the models ability to\nhandle three-dimensional CT-data. In order to test the performance of our\nmodel, we participate in the 2nd COV19D Competition for severity prediction and\ninfection detection.",
    "descriptor": "\nComments: 6 pages, no figures, informations about challenge submission\n",
    "authors": [
      "Daniel Kienzle",
      "Julian Lorenz",
      "Robin Sch\u00f6n",
      "Katja Ludwig",
      "Rainer Lienhart"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15073"
  },
  {
    "id": "arXiv:2206.15079",
    "title": "Prediction of Dilatory Behavior in eLearning: A Comparison of Multiple  Machine Learning Models",
    "abstract": "Procrastination, the irrational delay of tasks, is a common occurrence in\nonline learning. Potential negative consequences include higher risk of\ndrop-outs, increased stress, and reduced mood. Due to the rise of learning\nmanagement systems and learning analytics, indicators of such behavior can be\ndetected, enabling predictions of future procrastination and other dilatory\nbehavior. However, research focusing on such predictions is scarce. Moreover,\nstudies involving different types of predictors and comparisons between the\npredictive performance of various methods are virtually non-existent. In this\nstudy, we aim to fill these research gaps by analyzing the performance of\nmultiple machine learning algorithms when predicting the delayed or timely\nsubmission of online assignments in a higher education setting with two\ncategories of predictors: subjective, questionnaire-based variables and\nobjective, log-data based indicators extracted from a learning management\nsystem. The results show that models with objective predictors consistently\noutperform models with subjective predictors, and a combination of both\nvariable types perform slightly better. For each of these three options, a\ndifferent approach prevailed (Gradient Boosting Machines for the subjective,\nBayesian multilevel models for the objective, and Random Forest for the\ncombined predictors). We conclude that careful attention should be paid to the\nselection of predictors and algorithms before implementing such models in\nlearning management systems.",
    "descriptor": "\nComments: 20 pages, 6 tables, 6 photos\n",
    "authors": [
      "Christof Imhof",
      "Ioan-Sorin Comsa",
      "Martin Hlosta",
      "Behnam Parsaeifard",
      "Ivan Moser",
      "Per Bergamin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15079"
  },
  {
    "id": "arXiv:2206.15092",
    "title": "Treewidth versus clique number. III. Tree-independence number of graphs  with a forbidden structure",
    "abstract": "We continue the study of $(\\mathrm{tw},\\omega)$-bounded graph classes, that\nis, hereditary graph classes in which the treewidth can only be large due to\nthe presence of a large clique, with the goal of understanding the extent to\nwhich this property has useful algorithmic implications for the Independent Set\nand related problems. In the previous paper of the series [Dallard,\nMilani\\v{c}, and \\v{S}torgel, Treewidth versus clique number. II.\nTree-independence number], we introduced the tree-independence number, a\nmin-max graph invariant related to tree decompositions. Bounded\ntree-independence number implies both $(\\mathrm{tw},\\omega)$-boundedness and\nthe existence of a polynomial-time algorithm for the Maximum Weight Independent\nSet problem, provided that the input graph is given together with a tree\ndecomposition with bounded independence number.\nIn this paper, we consider six graph containment relations and for each of\nthem characterize the graphs $H$ for which any graph excluding $H$ with respect\nto the relation admits a tree decomposition with bounded independence number.\nThe induced minor relation is of particular interest: we show that excluding\neither a $K_5$ minus an edge or the $4$-wheel implies the existence of a tree\ndecomposition in which every bag is a clique plus at most $3$ vertices, while\nexcluding a complete bipartite graph $K_{2,q}$ implies the existence of a tree\ndecomposition with independence number at most $2(q-1)$. Our constructive\nproofs are obtained using a variety of tools, including $\\ell$-refined tree\ndecompositions, SPQR trees, and potential maximal cliques. They imply\npolynomial-time algorithms for the Independent Set and related problems in an\ninfinite family of graph classes; in particular, the results apply to the class\nof $1$-perfectly orientable graphs, answering a question of Beisegel,\nChudnovsky, Gurvich, Milani\\v{c}, and Servatius from 2019.",
    "descriptor": "\nComments: 44 pages; abstract has been shortened due to arXiv requirements. A previous arXiv post (arXiv:2111.04543) has been reorganized into two parts; this is the second of the two parts\n",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Martin Milani\u010d",
      "Kenny \u0160torgel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15092"
  },
  {
    "id": "arXiv:2206.15101",
    "title": "The maximum capability of a topological feature in link prediction",
    "abstract": "Link prediction aims to predict links of a network that are not directly\nvisible, with profound applications in biological and social systems. Despite\nintensive utilization of the topological feature in this task, it is unclear to\nwhat extent a particular feature can be leveraged to infer missing links. Here,\nwe show that the maximum capability of a topological feature follows a simple\nmathematical expression, which is independent of how an index gauges the\nfeature. Hence, a family of indexes associated with one topological feature\nshares the same performance limit. A feature's capability is lifted in the\nsupervised prediction, which in general gives rise to better results compared\nwith unsupervised prediction. The universality of the pattern uncovered is\nempirically verified by 550 structurally diverse networks, which can be applied\nto feature selection and the analysis of network characteristics associated\nwith a topological feature in link prediction.",
    "descriptor": "\nComments: 64 pages\n",
    "authors": [
      "Ran Yijun",
      "Xu Xiao-Ke",
      "Jia Tao"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.15101"
  },
  {
    "id": "arXiv:2206.15122",
    "title": "Space-Bounded Unitary Quantum Computation with Postselection",
    "abstract": "Space-bounded computation has been a central topic in classical and quantum\ncomplexity theory. In the quantum case, every elementary gate must be unitary.\nThis restriction makes it unclear whether the power of space-bounded\ncomputation changes by allowing intermediate measurement. In the bounded error\ncase, Fefferman and Remscrim [STOC 2021, pp.1343--1356] and Girish, Raz and\nZhan~[ICALP 2021, pp.73:1--73:20] recently provided the break-through results\nthat the power does not change. This paper shows that a similar result holds\nfor space-bounded quantum computation with postselection. Namely, it is proved\npossible to eliminate intermediate postselections and measurements in the\nspace-bounded quantum computation in the bounded-error setting. Our result\nstrengthens the recent result by Le Gall, Nishimura and Yakaryilmaz~[TQC 2021,\npp.10:1--10:17] that logarithmic-space bounded-error quantum computation with\nintermediate postselections and measurements is equivalent in computational\npower to logarithmic-space unbounded-error probabilistic computation. As an\napplication, it is shown that bounded-error space-bounded one-clean qubit\ncomputation (DQC1) with postselection is equivalent in computational power to\nunbounded-error space-bounded probabilistic computation, and the computational\nsupremacy of the bounded-error space-bounded DQC1 is interpreted in\ncomplexity-theoretic terms.",
    "descriptor": "\nComments: To appear in the proceedings of MFCS 2022. 15 pages\n",
    "authors": [
      "Seiichiro Tani"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.15122"
  },
  {
    "id": "arXiv:2206.15134",
    "title": "InsMix: Towards Realistic Generative Data Augmentation for Nuclei  Instance Segmentation",
    "abstract": "Nuclei Segmentation from histology images is a fundamental task in digital\npathology analysis. However, deep-learning-based nuclei segmentation methods\noften suffer from limited annotations. This paper proposes a realistic data\naugmentation method for nuclei segmentation, named InsMix, that follows a\nCopy-Paste-Smooth principle and performs morphology-constrained generative\ninstance augmentation. Specifically, we propose morphology constraints that\nenable the augmented images to acquire luxuriant information about nuclei while\nmaintaining their morphology characteristics (e.g., geometry and location). To\nfully exploit the pixel redundancy of the background and improve the model's\nrobustness, we further propose a background perturbation method, which randomly\nshuffles the background patches without disordering the original nuclei\ndistribution. To achieve contextual consistency between original and template\ninstances, a smooth-GAN is designed with a foreground similarity encoder (FSE)\nand a triplet loss. We validated the proposed method on two datasets, i.e.,\nKumar and CPS datasets. Experimental results demonstrate the effectiveness of\neach component and the superior performance achieved by our method to the\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted by MICCAI 2022 (early accepted)\n",
    "authors": [
      "Yi Lin",
      "Zeyu Wang",
      "Kwang-Ting Cheng",
      "Hao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15134"
  },
  {
    "id": "arXiv:2206.15156",
    "title": "Pulse Shape Simulation and Discrimination using Machine-Learning  Techniques",
    "abstract": "An essential metric for the quality of a particle-identification experiment\nis its statistical power to discriminate between signal and background. Pulse\nshape discrimination (PSD) is a basic method for this purpose in many nuclear,\nhigh-energy, and rare-event search experiments where scintillator detectors are\nused. Conventional techniques exploit the difference between decay-times of the\npulse from signal and background events or pulse signals caused by different\ntypes of radiation quanta to achieve good discrimination. However, such\ntechniques are efficient only when the total light-emission is sufficient to\nget a proper pulse profile. This is only possible when there is significant\nrecoil energy due to the incident particle in the detector. But, rare-event\nsearch experiments like neutrino or dark-matter direct search experiments don't\nalways satisfy these conditions. Hence, it becomes imperative to have a method\nthat can deliver very efficient discrimination in these scenarios. Neural\nnetwork-based machine-learning algorithms have been used for classification\nproblems in many areas of physics, especially in high-energy experiments, and\nhave given better results compared to conventional techniques. We present the\nresults of our investigations of two network-based methods viz. Dense Neural\nNetwork and Recurrent Neural Network, for pulse shape discrimination and\ncompare the same with conventional methods.",
    "descriptor": "\nComments: 18 pages, 39 figures\n",
    "authors": [
      "Shubham Dutta",
      "Sayan Ghosh",
      "Satyaki Bhattacharya",
      "Satyajit Saha"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15156"
  },
  {
    "id": "arXiv:2206.15177",
    "title": "A note on large deviations for interacting particle dynamics for finding  mixed equilibria in zero-sum games",
    "abstract": "Finding equilibria points in continuous minimax games has become a key\nproblem within machine learning, in part due to its connection to the training\nof generative adversarial networks. Because of existence and robustness issues,\nrecent developments have shifted from pure equilibria to focusing on mixed\nequilibria points. In this note we consider a method proposed by Domingo-Enrich\net al. for finding mixed equilibria in two-layer zero-sum games. The method is\nbased on entropic regularisation and the two competing strategies are\nrepresented by two sets of interacting particles. We show that the sequence of\nempirical measures of the particle system satisfies a large deviation principle\nas the number of particles grows to infinity, and how this implies convergence\nof the empirical measure and the associated Nikaid\\^o-Isoda error,\ncomplementing existing law of large numbers results.",
    "descriptor": "",
    "authors": [
      "Viktor Nilsson",
      "Pierre Nyquist"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.15177"
  },
  {
    "id": "arXiv:2206.15179",
    "title": "A Medical Image Fusion Method based on MDLatLRRv2",
    "abstract": "Since MDLatLRR only considers detailed parts (salient features) of input\nimages extracted by latent low-rank representation (LatLRR), it doesn't use\nbase parts (principal features) extracted by LatLRR effectively. Therefore, we\nproposed an improved multi-level decomposition method called MDLatLRRv2 which\neffectively analyzes and utilizes all the image features obtained by LatLRR.\nThen we apply MDLatLRRv2 to medical image fusion. The base parts are fused by\naverage strategy and the detail parts are fused by nuclear-norm operation. The\ncomparison with the existing methods demonstrates that the proposed method can\nachieve state-of-the-art fusion performance in objective and subjective\nassessment.",
    "descriptor": "",
    "authors": [
      "Xu Song",
      "Xiao-Jun Wu",
      "Hui Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15179"
  },
  {
    "id": "arXiv:2206.15182",
    "title": "The (de)biasing effect of GAN-based augmentation methods on skin lesion  images",
    "abstract": "New medical datasets are now more open to the public, allowing for better and\nmore extensive research. Although prepared with the utmost care, new datasets\nmight still be a source of spurious correlations that affect the learning\nprocess. Moreover, data collections are usually not large enough and are often\nunbalanced. One approach to alleviate the data imbalance is using data\naugmentation with Generative Adversarial Networks (GANs) to extend the dataset\nwith high-quality images. GANs are usually trained on the same biased datasets\nas the target data, resulting in more biased instances. This work explored\nunconditional and conditional GANs to compare their bias inheritance and how\nthe synthetic data influenced the models. We provided extensive manual data\nannotation of possibly biasing artifacts on the well-known ISIC dataset with\nskin lesions. In addition, we examined classification models trained on both\nreal and synthetic data with counterfactual bias explanations. Our experiments\nshowed that GANs inherited biases and sometimes even amplified them, leading to\neven stronger spurious correlations. Manual data annotation and synthetic\nimages are publicly available for reproducible scientific research.",
    "descriptor": "\nComments: Accepted to MICCAI2022\n",
    "authors": [
      "Agnieszka Miko\u0142ajczyk",
      "Sylwia Majchrowska",
      "Sandra Carrasco Limeros"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15182"
  },
  {
    "id": "arXiv:2206.15215",
    "title": "Learning Nonparametric Ordinary differential Equations: Application to  Sparse and Noisy Data",
    "abstract": "Learning nonparametric systems of Ordinary Differential Equations (ODEs)\n$\\dot x = f(t,x)$ from noisy and sparse data is an emerging machine learning\ntopic. We use the well-developed theory of Reproducing Kernel Hilbert Spaces\n(RKHS) to define candidates for $f$ for which the solution of the ODE exists\nand is unique. Learning $f$ consists of solving a constrained optimization\nproblem in an RKHS. We propose a penalty method that iteratively uses the\nRepresenter theorem and Euler approximations to provide a numerical solution.\nWe prove a generalization bound for the $L^2$ distance between $x$ and its\nestimator. Experiments are provided for the FitzHugh Nagumo oscillator and for\nthe prediction of the Amyloid level in the cortex of aging subjects. In both\ncases, we show competitive results when compared with the state of the art.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Kamel Lahouel",
      "Michael Wells",
      "David Lovitz",
      "Victor Rielly",
      "Ethan Lew",
      "Bruno Jedynak"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15215"
  },
  {
    "id": "arXiv:2206.15217",
    "title": "Implicit U-Net for volumetric medical image segmentation",
    "abstract": "U-Net has been the go-to architecture for medical image segmentation tasks,\nhowever computational challenges arise when extending the U-Net architecture to\n3D images. We propose the Implicit U-Net architecture that adapts the efficient\nImplicit Representation paradigm to supervised image segmentation tasks. By\ncombining a convolutional feature extractor with an implicit localization\nnetwork, our implicit U-Net has 40% less parameters than the equivalent U-Net.\nMoreover, we propose training and inference procedures to capitalize sparse\npredictions. When comparing to an equivalent fully convolutional U-Net,\nImplicit U-Net reduces by approximately 30% inference and training time as well\nas training memory footprint while achieving comparable results in our\nexperiments with two different abdominal CT scan datasets.",
    "descriptor": "\nComments: 11 pages, 4 figures, Accepted MIUA 2022\n",
    "authors": [
      "Sergio Naval Marimont",
      "Giacomo Tarroni"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15217"
  },
  {
    "id": "arXiv:2206.15254",
    "title": "Localizing the Recurrent Laryngeal Nerve via Ultrasound with a Bayesian  Shape Framework",
    "abstract": "Tumor infiltration of the recurrent laryngeal nerve (RLN) is a\ncontraindication for robotic thyroidectomy and can be difficult to detect via\nstandard laryngoscopy. Ultrasound (US) is a viable alternative for RLN\ndetection due to its safety and ability to provide real-time feedback. However,\nthe tininess of the RLN, with a diameter typically less than 3mm, poses\nsignificant challenges to the accurate localization of the RLN. In this work,\nwe propose a knowledge-driven framework for RLN localization, mimicking the\nstandard approach surgeons take to identify the RLN according to its\nsurrounding organs. We construct a prior anatomical model based on the inherent\nrelative spatial relationships between organs. Through Bayesian shape alignment\n(BSA), we obtain the candidate coordinates of the center of a region of\ninterest (ROI) that encloses the RLN. The ROI allows a decreased field of view\nfor determining the refined centroid of the RLN using a dual-path\nidentification network, based on multi-scale semantic information. Experimental\nresults indicate that the proposed method achieves superior hit rates and\nsubstantially smaller distance errors compared with state-of-the-art methods.",
    "descriptor": "\nComments: Early Accepted by MICCAI 2022\n",
    "authors": [
      "Haoran Dou",
      "Luyi Han",
      "Yushuang He",
      "Jun Xu",
      "Nishant Ravikumar",
      "Ritse Mann",
      "Alejandro F. Frangi",
      "Pew-Thian Yap",
      "Yunzhi Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15254"
  },
  {
    "id": "arXiv:2206.15274",
    "title": "Exposing and addressing the fragility of neural networks in digital  pathology",
    "abstract": "Neural networks have achieved impressive results in many medical imaging\ntasks but often perform substantially worse on out-of-distribution datasets\noriginating from different medical centres or patient cohorts. Evaluating this\nlack of ability to generalise and address the underlying problem are the two\nmain challenges in developing neural networks intended for clinical practice.\nIn this study, we develop a new method for evaluating neural network models'\nability to generalise by generating a large number of distribution-shifted\ndatasets, which can be used to thoroughly investigate their robustness to\nvariability encountered in clinical practice. Compared to external validation,\n\\textit{shifted evaluation} can provide explanations for why neural networks\nfail on a given dataset, thus offering guidance on how to improve model\nrobustness. With shifted evaluation, we demonstrate that neural networks,\ntrained with state-of-the-art methods, are highly fragile to even small\ndistribution shifts from training data, and in some cases lose all\ndiscrimination ability.\nTo address this fragility, we develop an augmentation strategy, explicitly\ndesigned to increase neural networks' robustness to distribution shifts.\n\\texttt{StrongAugment} is evaluated with large-scale, heterogeneous\nhistopathology data including five training datasets from two tissue types, 274\ndistribution-shifted datasets and 20 external datasets from four countries.\nNeural networks trained with \\texttt{StrongAugment} retain similar performance\non all datasets, even with distribution shifts where networks trained with\ncurrent state-of-the-art methods lose all discrimination ability. We recommend\nusing strong augmentation and shifted evaluation to train and evaluate all\nneural networks intended for clinical practice.",
    "descriptor": "\nComments: Code for the paper is available from: \\url{this https URL}\n",
    "authors": [
      "Joona Pohjonen",
      "Carolin St\u00fcrenberg",
      "Atte F\u00f6hr",
      "Esa Pitk\u00e4nen",
      "Antti Rannikko",
      "Tuomas Mirtti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15274"
  },
  {
    "id": "arXiv:2206.15284",
    "title": "QuASK -- Quantum Advantage Seeker with Kernels",
    "abstract": "QuASK is a quantum machine learning software written in Python that supports\nresearchers in designing, experimenting, and assessing different quantum and\nclassical kernels performance. This software is package agnostic and can be\nintegrated with all major quantum software packages (e.g. IBM Qiskit, Xanadu's\nPennylane, Amazon Braket). QuASK guides the user through a simple preprocessing\nof input data, definition and calculation of quantum and classical kernels,\neither custom or pre-defined ones. From this evaluation the package provides an\nassessment about potential quantum advantage and prediction bounds on\ngeneralization error. Moreover, it allows for the generation of parametric\nquantum kernels that can be trained using gradient-descent-based optimization,\ngrid search, or genetic algorithms. Projected quantum kernels, an effective\nsolution to mitigate the curse of dimensionality induced by the exponential\nscaling dimension of large Hilbert spaces, are also calculated. QuASK can\nfurthermore generate the observable values of a quantum model and use them to\nstudy the prediction capabilities of the quantum and classical kernels.",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Francesco Di Marcantonio",
      "Massimiliano Incudini",
      "Davide Tezza",
      "Michele Grossi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15284"
  },
  {
    "id": "arXiv:2206.15319",
    "title": "On extended boundary sequences of morphic and Sturmian words",
    "abstract": "Generalizing the notion of the boundary sequence introduced by Chen and Wen,\nthe $n$th term of the $\\ell$-boundary sequence of an infinite word is the\nfinite set of pairs $(u,v)$ of prefixes and suffixes of length $\\ell$ appearing\nin factors $uyv$ of length $n+\\ell$ ($n\\ge \\ell\\ge 1$). Otherwise stated, for\nincreasing values of $n$, one looks for all pairs of factors of length $\\ell$\nseparated by $n-\\ell$ symbols.\nFor the large class of addable numeration systems $U$, we show that if an\ninfinite word is $U$-automatic, then the same holds for its $\\ell$-boundary\nsequence. In particular, they are both morphic (or generated by an HD0L\nsystem). We also provide examples of numeration systems and $U$-automatic words\nwith a boundary sequence that is not $U$-automatic. In the second part of the\npaper, we study the $\\ell$-boundary sequence of a Sturmian word. We show that\nit is obtained through a sliding block code from the characteristic Sturmian\nword of the same slope. We also show that it is the image under a morphism of\nsome other characteristic Sturmian word.",
    "descriptor": "\nComments: A short version to appear in the proceedings of MFCS 2022\n",
    "authors": [
      "Michel Rigo",
      "Manon Stipulanti",
      "Markus A. Whiteland"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2206.15319"
  },
  {
    "id": "arXiv:2206.15356",
    "title": "Acoustic Room Compensation Using Local PCA-based Room Average PSD  Estimation",
    "abstract": "Acoustic room compensation techniques, which allow a sound reproduction\nsystem to counteract undesired alteration to the sound scene due to excessive\nroom resonances, have been widely studied. Extensive efforts have been reported\nto enlarge the region over which room equalization is effective and to contrast\nvariations of room transfer functions in space. A speaker-tuning technology\n\"Trueplay\" allows users to compensate for undesired room effects over an\nextended listening area based on a spatially averaged power spectral density\n(PSD) of the room, which is conventionally measured using microphones on\nportable devices when users move around the room. In this work, we propose a\nnovel system that leverages the measurement of the speaker echo path\nself-response to predict the room average PSD using a local PCA based approach.\nExperimental results confirm the effectiveness of the proposed estimation\nmethod, which further leads to a room compensation filter design that achieves\na good sound similarity compared to the reference system with the ground-truth\nroom average PSD while outperforming other systems that do not leverage the\nproposed estimator.",
    "descriptor": "\nComments: 5 pages, 7 figures, accepted to IWAENC 2022\n",
    "authors": [
      "Wenyu Jin",
      "Patrick McPherson",
      "Chris Pike",
      "Adib Mehrabi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2206.15356"
  },
  {
    "id": "arXiv:2206.15384",
    "title": "A data-driven Reduced Order Method for parametric optimal blood flow  control: application to coronary bypass graft",
    "abstract": "We consider an optimal flow control problem in a patient-specific coronary\nartery bypass graft with the aim of matching the blood flow velocity with given\nmeasurements as the Reynolds number varies in a physiological range. Blood flow\nis modelled with the steady incompressible Navier-Stokes equations. The\ngeometry consists in a stenosed left anterior descending artery where a single\nbypass is performed with the right internal thoracic artery. The control\nvariable is the unknown value of the normal stress at the outlet boundary,\nwhich is need for a correct set-up of the outlet boundary condition. For the\nnumerical solution of the parametric optimal flow control problem, we develop a\ndata-driven reduced order method that combines proper orthogonal decomposition\n(POD) with neural networks. We present numerical results showing that our\ndata-driven approach leads to a substantial speed-up with respect to a more\nclassical POD-Galerkin strategy proposed in [59], while having comparable\naccuracy.",
    "descriptor": "",
    "authors": [
      "Caterina Balzotti",
      "Pierfrancesco Siena",
      "Michele Girfoglio",
      "Annalisa Quaini",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.15384"
  },
  {
    "id": "arXiv:2206.15400",
    "title": "Learning Audio-Text Agreement for Open-vocabulary Keyword Spotting",
    "abstract": "In this paper, we propose a novel end-to-end user-defined keyword spotting\nmethod that utilizes linguistically corresponding patterns between speech and\ntext sequences. Unlike previous approaches requiring speech keyword enrollment,\nour method compares input queries with an enrolled text keyword sequence. To\nplace the audio and text representations within a common latent space, we adopt\nan attention-based cross-modal matching approach that is trained in an\nend-to-end manner with monotonic matching loss and keyword classification loss.\nWe also utilize a de-noising loss for the acoustic embedding network to improve\nrobustness in noisy environments. Additionally, we introduce the LibriPhrase\ndataset, a new short-phrase dataset based on LibriSpeech for efficiently\ntraining keyword spotting models. Our proposed method achieves competitive\nresults on various evaluation sets compared to other single-modal and\ncross-modal baselines.",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Hyeon-Kyeong Shin",
      "Hyewon Han",
      "Doyeon Kim",
      "Soo-Whan Chung",
      "Hong-Goo Kang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15400"
  },
  {
    "id": "arXiv:2206.15405",
    "title": "Multivariate trace estimation in constant quantum depth",
    "abstract": "There is a folkloric belief that a depth-$\\Theta(m)$ quantum circuit is\nneeded to estimate the trace of the product of $m$ density matrices (i.e., a\nmultivariate trace). We prove that this belief is overly conservative by\nconstructing a constant quantum-depth circuit for the task, inspired by the\nmethod of Shor error correction. Furthermore, our circuit demands only local\ngates in a two dimensional circuit -- we show how to implement it in a highly\nparallelized way on an architecture similar to that of Google's Sycamore\nprocessor. With these features, our algorithm brings the task of multivariate\ntrace estimation, crucial to applications in condensed matter and estimating\nnonlinear functions of quantum states, closer to the capabilities of near-term\nquantum processors. We instantiate the latter application with a theorem on\nestimating nonlinear functions of quantum states with ``well-behaved\"\npolynomial approximations.",
    "descriptor": "\nComments: 13 pages (including one appendix); 15 figures; one GIF\n",
    "authors": [
      "Yihui Quek",
      "Mark M. Wilde",
      "Eneet Kaur"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2206.15405"
  },
  {
    "id": "arXiv:2206.15408",
    "title": "Sub-8-Bit Quantization Aware Training for 8-Bit Neural Network  Accelerator with On-Device Speech Recognition",
    "abstract": "We present a novel sub-8-bit quantization-aware training (S8BQAT) scheme for\n8-bit neural network accelerators. Our method is inspired from Lloyd-Max\ncompression theory with practical adaptations for a feasible computational\noverhead during training. With the quantization centroids derived from a 32-bit\nbaseline, we augment training loss with a Multi-Regional Absolute Cosine\n(MRACos) regularizer that aggregates weights towards their nearest centroid,\neffectively acting as a pseudo compressor. Additionally, a periodically invoked\nhard compressor is introduced to improve the convergence rate by emulating\nruntime model weight quantization. We apply S8BQAT on speech recognition tasks\nusing Recurrent Neural NetworkTransducer (RNN-T) architecture. With S8BQAT, we\nare able to increase the model parameter size to reduce the word error rate by\n4-16% relatively, while still improving latency by 5%.",
    "descriptor": "\nComments: Accepted for publication in INTERSPEECH 2022\n",
    "authors": [
      "Kai Zhen",
      "Hieu Duy Nguyen",
      "Raviteja Chinta",
      "Nathan Susanj",
      "Athanasios Mouchtaris",
      "Tariq Afzal",
      "Ariya Rastrow"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.15408"
  },
  {
    "id": "arXiv:2206.15425",
    "title": "Growth and irreducibility in path-incompressible trees",
    "abstract": "We study effective randomness-preserving transformations of\npath-incompressible trees. There exists a path-incompressible tree with\ninfinitely many paths, which does not compute any perfect pathwise-random tree.\nSparse perfect path-incompressible trees can be effectively densified, almost\nsurely. We characterize the density of branching that pathwise-random trees can\nhave.",
    "descriptor": "",
    "authors": [
      "George Barmpalias",
      "Wei Wang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.15425"
  },
  {
    "id": "arXiv:2206.15427",
    "title": "Few-Shot Cross-Lingual TTS Using Transferable Phoneme Embedding",
    "abstract": "This paper studies a transferable phoneme embedding framework that aims to\ndeal with the cross-lingual text-to-speech (TTS) problem under the few-shot\nsetting. Transfer learning is a common approach when it comes to few-shot\nlearning since training from scratch on few-shot training data is bound to\noverfit. Still, we find that the naive transfer learning approach fails to\nadapt to unseen languages under extremely few-shot settings, where less than 8\nminutes of data is provided. We deal with the problem by proposing a framework\nthat consists of a phoneme-based TTS model and a codebook module to project\nphonemes from different languages into a learned latent space. Furthermore, by\nutilizing phoneme-level averaged self-supervised learned features, we\neffectively improve the quality of synthesized speeches. Experiments show that\nusing 4 utterances, which is about 30 seconds of data, is enough to synthesize\nintelligible speech when adapting to an unseen language using our framework.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Wei-Ping Huang",
      "Po-Chun Chen",
      "Sung-Feng Huang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15427"
  },
  {
    "id": "arXiv:2206.15431",
    "title": "Ensemble CNN models for Covid-19 Recognition and Severity Perdition From  3D CT-scan",
    "abstract": "Since the appearance of Covid-19 in late 2019, Covid-19 has become an active\nresearch topic for the artificial intelligence (AI) community. One of the most\ninteresting AI topics is Covid-19 analysis of medical imaging. CT-scan imaging\nis the most informative tool about this disease. This work is part of the 2nd\nCOV19D competition, where two challenges are set: Covid-19 Detection and\nCovid-19 Severity Detection from the CT-scans. For Covid-19 detection from\nCT-scans, we proposed an ensemble of 2D Convolution blocks with Densenet-161\nmodels. Here, each 2D convolutional block with Densenet-161 architecture is\ntrained separately and in testing phase, the ensemble model is based on the\naverage of their probabilities. On the other hand, we proposed an ensemble of\nConvolutional Layers with Inception models for Covid-19 severity detection. In\naddition to the Convolutional Layers, three Inception variants were used,\nnamely Inception-v3, Inception-v4 and Inception-Resnet. Our proposed approaches\noutperformed the baseline approach in the validation data of the 2nd COV19D\ncompetition by 11% and 16% for Covid-19 detection and Covid-19 severity\ndetection, respectively.",
    "descriptor": "",
    "authors": [
      "Fares Bougourzi",
      "Cosimo Distante",
      "Fadi Dornaika",
      "Abdelmalik Taleb-Ahmed"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15431"
  },
  {
    "id": "arXiv:2206.15432",
    "title": "Challenges and Opportunities in Multi-device Speech Processing",
    "abstract": "We review current solutions and technical challenges for automatic speech\nrecognition, keyword spotting, device arbitration, speech enhancement, and\nsource localization in multidevice home environments to provide context for the\nINTERSPEECH 2022 special session, \"Challenges and opportunities for signal\nprocessing and machine learning for multiple smart devices\". We also identify\nthe datasets needed to support these research areas. Based on the review and\nour research experience in the multi-device domain, we conclude with an outlook\non the future evolution",
    "descriptor": "\nComments: Accepted for INTERSPEECH 2022\n",
    "authors": [
      "Gregory Ciccarelli",
      "Jarred Barber",
      "Arun Nair",
      "Israel Cohen",
      "Tao Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15432"
  },
  {
    "id": "arXiv:2206.15441",
    "title": "Classical and learned MR to pseudo-CT mappings for accurate transcranial  ultrasound simulation",
    "abstract": "Model-based treatment planning for transcranial ultrasound therapy typically\ninvolves mapping the acoustic properties of the skull from an x-ray computed\ntomography (CT) image of the head. Here, three methods for generating pseudo-CT\nimages from magnetic resonance (MR) images were compared as an alternative to\nCT. A convolutional neural network (U-Net) was trained on paired MR-CT images\nto generate pseudo-CT images from either T1-weighted or zero-echo time (ZTE) MR\nimages (denoted tCT and zCT, respectively). A direct mapping from ZTE to\npseudo-CT was also implemented (denoted cCT). When comparing the pseudo-CT and\nground truth CT images for the test set, the mean absolute error was 133, 83,\nand 145 Hounsfield units (HU) across the whole head, and 398, 222, and 336 HU\nwithin the skull for the tCT, zCT, and cCT images, respectively. Ultrasound\nsimulations were also performed using the generated pseudo-CT images and\ncompared to simulations based on CT. An annular array transducer was used\ntargeting the visual or motor cortex. The mean differences in the simulated\nfocal pressure, focal position, and focal volume were 9.9%, 1.5 mm, and 15.1%\nfor simulations based on the tCT images, 5.7%, 0.6 mm, and 5.7% for the zCT,\nand 6.7%, 0.9 mm, and 12.1% for the cCT. The improved results for images mapped\nfrom ZTE highlight the advantage of using imaging sequences which improve\ncontrast of the skull bone. Overall, these results demonstrate that acoustic\nsimulations based on MR images can give comparable accuracy to those based on\nCT.",
    "descriptor": "",
    "authors": [
      "Maria Miscouridou",
      "Jos\u00e9 A. Pineda-Pardo",
      "Charlotte J. Stagg",
      "Bradley E. Treeby",
      "Antonio Stanziola"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15441"
  },
  {
    "id": "arXiv:2206.15445",
    "title": "Asymmetry Disentanglement Network for Interpretable Acute Ischemic  Stroke Infarct Segmentation in Non-Contrast CT Scans",
    "abstract": "Accurate infarct segmentation in non-contrast CT (NCCT) images is a crucial\nstep toward computer-aided acute ischemic stroke (AIS) assessment. In clinical\npractice, bilateral symmetric comparison of brain hemispheres is usually used\nto locate pathological abnormalities. Recent research has explored asymmetries\nto assist with AIS segmentation. However, most previous symmetry-based work\nmixed different types of asymmetries when evaluating their contribution to AIS.\nIn this paper, we propose a novel Asymmetry Disentanglement Network (ADN) to\nautomatically separate pathological asymmetries and intrinsic anatomical\nasymmetries in NCCTs for more effective and interpretable AIS segmentation. ADN\nfirst performs asymmetry disentanglement based on input NCCTs, which produces\ndifferent types of 3D asymmetry maps. Then a synthetic,\nintrinsic-asymmetry-compensated and pathology-asymmetry-salient NCCT volume is\ngenerated and later used as input to a segmentation network. The training of\nADN incorporates domain knowledge and adopts a tissue-type aware regularization\nloss function to encourage clinically-meaningful pathological asymmetry\nextraction. Coupled with an unsupervised 3D transformation network, ADN\nachieves state-of-the-art AIS segmentation performance on a public NCCT\ndataset. In addition to the superior performance, we believe the learned\nclinically-interpretable asymmetry maps can also provide insights towards a\nbetter understanding of AIS assessment. Our code is available at\nhttps://github.com/nihaomiao/MICCAI22_ADN.",
    "descriptor": "\nComments: MICCAI 2022\n",
    "authors": [
      "Haomiao Ni",
      "Yuan Xue",
      "Kelvin Wong",
      "John Volpi",
      "Stephen T.C. Wong",
      "James Z. Wang",
      "Xiaolei Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15445"
  },
  {
    "id": "arXiv:2206.15457",
    "title": "PhySRNet: Physics informed super-resolution network for application in  computational solid mechanics",
    "abstract": "Traditional approaches based on finite element analyses have been\nsuccessfully used to predict the macro-scale behavior of heterogeneous\nmaterials (composites, multicomponent alloys, and polycrystals) widely used in\nindustrial applications. However, this necessitates the mesh size to be smaller\nthan the characteristic length scale of the microstructural heterogeneities in\nthe material leading to computationally expensive and time-consuming\ncalculations. The recent advances in deep learning based image super-resolution\n(SR) algorithms open up a promising avenue to tackle this computational\nchallenge by enabling researchers to enhance the spatio-temporal resolution of\ndata obtained from coarse mesh simulations. However, technical challenges still\nremain in developing a high-fidelity SR model for application to computational\nsolid mechanics, especially for materials undergoing large deformation. This\nwork aims at developing a physics-informed deep learning based super-resolution\nframework (PhySRNet) which enables reconstruction of high-resolution\ndeformation fields (displacement and stress) from their low-resolution\ncounterparts without requiring high-resolution labeled data. We design a\nsynthetic case study to illustrate the effectiveness of the proposed framework\nand demonstrate that the super-resolved fields match the accuracy of an\nadvanced numerical solver running at 400 times the coarse mesh resolution while\nsimultaneously satisfying the (highly nonlinear) governing laws. The approach\nopens the door to applying machine learning and traditional numerical\napproaches in tandem to reduce computational complexity accelerate scientific\ndiscovery and engineering design.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.08676\n",
    "authors": [
      "Rajat Arora"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15457"
  },
  {
    "id": "arXiv:2206.15464",
    "title": "Practical Black Box Hamiltonian Learning",
    "abstract": "We study the problem of learning the parameters for the Hamiltonian of a\nquantum many-body system, given limited access to the system. In this work, we\nbuild upon recent approaches to Hamiltonian learning via derivative estimation.\nWe propose a protocol that improves the scaling dependence of prior works,\nparticularly with respect to parameters relating to the structure of the\nHamiltonian (e.g., its locality $k$). Furthermore, by deriving exact bounds on\nthe performance of our protocol, we are able to provide a precise numerical\nprescription for theoretically optimal settings of hyperparameters in our\nlearning protocol, such as the maximum evolution time (when learning with\nunitary dynamics) or minimum temperature (when learning with Gibbs states).\nThanks to these improvements, our protocol is practical for large problems: we\ndemonstrate this with a numerical simulation of our protocol on an 80-qubit\nsystem.",
    "descriptor": "\nComments: 32 pages, 10 figures\n",
    "authors": [
      "Andi Gu",
      "Lukasz Cincio",
      "Patrick J. Coles"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15464"
  },
  {
    "id": "arXiv:1711.02513",
    "title": "CGAlgebra: a Mathematica package for conformal geometric algebra. v.2.0",
    "abstract": "Comments: Improved version, one figure",
    "descriptor": "\nComments: Improved version, one figure\n",
    "authors": [
      "E. Alejandra Ortiz-Duran",
      "Jose L. Aragon"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/1711.02513"
  },
  {
    "id": "arXiv:1901.01632",
    "title": "Exploiting Network Loss for Distributed Approximate Computing with  NetApprox",
    "abstract": "Exploiting Network Loss for Distributed Approximate Computing with  NetApprox",
    "descriptor": "",
    "authors": [
      "Ke Liu",
      "Jinmou Li",
      "Shin-Yeh Tsai",
      "Theophilus Benson",
      "Yiying Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/1901.01632"
  },
  {
    "id": "arXiv:2001.00708",
    "title": "On Symmetric Gauss-Seidel ADMM Algorithm for $\\mathcal{H}_\\infty$  Guaranteed Cost Control with Convex Parameterization",
    "abstract": "Comments: 12 pages, 7 figures",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Jun Ma",
      "Zilong Cheng",
      "Xiaoxue Zhang",
      "Masayoshi Tomizuka",
      "Tong Heng Lee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2001.00708"
  },
  {
    "id": "arXiv:2002.12873",
    "title": "Federated Over-Air Subspace Tracking from Incomplete and Corrupted Data",
    "abstract": "Comments: To appear in IEEE Transactions on Signal Processing. changes to writing; more general result provided from which previous result follows as special case",
    "descriptor": "\nComments: To appear in IEEE Transactions on Signal Processing. changes to writing; more general result provided from which previous result follows as special case\n",
    "authors": [
      "Praneeth Narayanamurthy",
      "Namrata Vaswani",
      "Aditya Ramamoorthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.12873"
  },
  {
    "id": "arXiv:2003.05691",
    "title": "The Newer College Dataset: Handheld LiDAR, Inertial and Vision with  Ground Truth",
    "abstract": "The Newer College Dataset: Handheld LiDAR, Inertial and Vision with  Ground Truth",
    "descriptor": "",
    "authors": [
      "Milad Ramezani",
      "Yiduo Wang",
      "Marco Camurri",
      "David Wisth",
      "Matias Mattamala",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2003.05691"
  },
  {
    "id": "arXiv:2006.15670",
    "title": "Simplest random walk for approximating Robin boundary value problems and  ergodic limits of reflected diffusions",
    "abstract": "Comments: The Annals of Applied Probability (to appear)",
    "descriptor": "\nComments: The Annals of Applied Probability (to appear)\n",
    "authors": [
      "B. Leimkuhler",
      "A. Sharma",
      "M.V. Tretyakov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2006.15670"
  },
  {
    "id": "arXiv:2008.08548",
    "title": "A Survey of Knowledge-based Sequential Decision Making under Uncertainty",
    "abstract": "Comments: AI Magazine, Volume 43, Issue 2, Pages 249-266, 2022",
    "descriptor": "\nComments: AI Magazine, Volume 43, Issue 2, Pages 249-266, 2022\n",
    "authors": [
      "Shiqi Zhang",
      "Mohan Sridharan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2008.08548"
  },
  {
    "id": "arXiv:2011.02408",
    "title": "Which Minimizer Does My Neural Network Converge To?",
    "abstract": "Which Minimizer Does My Neural Network Converge To?",
    "descriptor": "",
    "authors": [
      "Manuel Nonnenmacher",
      "David Reeb",
      "Ingo Steinwart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.02408"
  },
  {
    "id": "arXiv:2011.14599",
    "title": "On the Challenges of Detecting Side-Channel Attacks in SGX",
    "abstract": "On the Challenges of Detecting Side-Channel Attacks in SGX",
    "descriptor": "",
    "authors": [
      "Jianyu Jiang",
      "Claudio Soriente",
      "Ghassan Karame"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.14599"
  },
  {
    "id": "arXiv:2101.07383",
    "title": "A DCNN-based Arbitrarily-Oriented Object Detector for Quality Control  and Inspection Application",
    "abstract": "A DCNN-based Arbitrarily-Oriented Object Detector for Quality Control  and Inspection Application",
    "descriptor": "",
    "authors": [
      "Kai Yao",
      "Alberto Ortiz",
      "Francisco Bonnin-Pascual"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.07383"
  },
  {
    "id": "arXiv:2101.12602",
    "title": "On the differential privacy of dynamic location obfuscation with  personalized error bounds",
    "abstract": "Comments: 9 pages, 10 figures",
    "descriptor": "\nComments: 9 pages, 10 figures\n",
    "authors": [
      "Zhang Shun",
      "Duan Benfei",
      "Chen Zhili",
      "Zhong Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2101.12602"
  },
  {
    "id": "arXiv:2102.00168",
    "title": "Learning Skills to Navigate without a Master: A Sequential Multi-Policy  Reinforcement Learning Algorithm",
    "abstract": "Comments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS): 2022",
    "descriptor": "\nComments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS): 2022\n",
    "authors": [
      "Ambedkar Dukkipati",
      "Rajarshi Banerjee",
      "Ranga Shaarad Ayyagari",
      "Dhaval Parmar Udaybhai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.00168"
  },
  {
    "id": "arXiv:2102.11572",
    "title": "Event-Based Automatic Differentiation of OpenMP with OpDiLib",
    "abstract": "Comments: 31 pages, 13 figures, 3 tables, 13 listings; new layout, additional references, refocused Section 3 (former Section 4), extended performance tests, overall polishing and shortening",
    "descriptor": "\nComments: 31 pages, 13 figures, 3 tables, 13 listings; new layout, additional references, refocused Section 3 (former Section 4), extended performance tests, overall polishing and shortening\n",
    "authors": [
      "Johannes Bl\u00fchdorn",
      "Max Sagebaum",
      "Nicolas R. Gauger"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2102.11572"
  },
  {
    "id": "arXiv:2103.02554",
    "title": "Enabling Visual Action Planning for Object Manipulation through Latent  Space Roadmap",
    "abstract": "Enabling Visual Action Planning for Object Manipulation through Latent  Space Roadmap",
    "descriptor": "",
    "authors": [
      "Martina Lippi",
      "Petra Poklukar",
      "Michael C. Welle",
      "Anastasia Varava",
      "Hang Yin",
      "Alessandro Marino",
      "Danica Kragic"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.02554"
  },
  {
    "id": "arXiv:2103.03293",
    "title": "Accelerating Second-Order Differential Dynamic Programming for  Rigid-Body Systems",
    "abstract": "Accelerating Second-Order Differential Dynamic Programming for  Rigid-Body Systems",
    "descriptor": "",
    "authors": [
      "John N. Nganga",
      "Patrick M. Wensing"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.03293"
  },
  {
    "id": "arXiv:2103.04903",
    "title": "A novel relaxation scheme for the numerical approximation of  Schr\u00f6dinger-Poisson type systems",
    "abstract": "Comments: 17pages, 10 figures",
    "descriptor": "\nComments: 17pages, 10 figures\n",
    "authors": [
      "Agissilaos Athanassoulis",
      "Theodoros Katsaounis",
      "Irene Kyza",
      "Stephen Metcalfe"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.04903"
  },
  {
    "id": "arXiv:2103.06102",
    "title": "Effectively Counting s-t Simple Paths in Directed Graphs",
    "abstract": "Effectively Counting s-t Simple Paths in Directed Graphs",
    "descriptor": "",
    "authors": [
      "Mostafa Haghir Chehreghani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2103.06102"
  },
  {
    "id": "arXiv:2103.16725",
    "title": "SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised  Classification",
    "abstract": "Comments: Accepted to CVPR 2021. First two authors contributed equally",
    "descriptor": "\nComments: Accepted to CVPR 2021. First two authors contributed equally\n",
    "authors": [
      "Zijian Hu",
      "Zhengyu Yang",
      "Xuefeng Hu",
      "Ram Nevatia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.16725"
  },
  {
    "id": "arXiv:2104.04658",
    "title": "Efficient Path Planning in Narrow Passages for Robots with Ellipsoidal  Components",
    "abstract": "Comments: 17 pages, 14 figures",
    "descriptor": "\nComments: 17 pages, 14 figures\n",
    "authors": [
      "Sipu Ruan",
      "Karen L. Poblete",
      "Hongtao Wu",
      "Qianli Ma",
      "Gregory S. Chirikjian"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.04658"
  },
  {
    "id": "arXiv:2104.09647",
    "title": "NewsEdits: A Dataset of Revision Histories for News Articles (Technical  Report: Data Processing)",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Alexander Spangher",
      "Jonathan May"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2104.09647"
  },
  {
    "id": "arXiv:2104.10263",
    "title": "StateCensusLaws.org: A Web Application for Consuming and Annotating  Legal Discourse Learning",
    "abstract": "StateCensusLaws.org: A Web Application for Consuming and Annotating  Legal Discourse Learning",
    "descriptor": "",
    "authors": [
      "Alexander Spangher",
      "Jonathan May"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.10263"
  },
  {
    "id": "arXiv:2104.11449",
    "title": "Reflexive combinatory algebras",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Marlou M. Gijzen",
      "Hajime Ishihara",
      "Tatsuji Kawai"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.11449"
  },
  {
    "id": "arXiv:2104.12755",
    "title": "Auto Response Generation in Online Medical Chat Services",
    "abstract": "Comments: It is accepted to be published in Journal of Healthcare Informatics Research",
    "descriptor": "\nComments: It is accepted to be published in Journal of Healthcare Informatics Research\n",
    "authors": [
      "Hadi Jahanshahi",
      "Syed Kazmi",
      "Mucahit Cevik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.12755"
  },
  {
    "id": "arXiv:2105.01382",
    "title": "A Subatomic Proof System for Decision Trees",
    "abstract": "Comments: To appear on ACM Transactions on Computational Logic",
    "descriptor": "\nComments: To appear on ACM Transactions on Computational Logic\n",
    "authors": [
      "Chris Barrett",
      "Alessio Guglielmi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.01382"
  },
  {
    "id": "arXiv:2105.01988",
    "title": "Dynamic QoS-Aware Traffic Planning for Time-Triggered Flows in the  Real-time Data Plane",
    "abstract": "Dynamic QoS-Aware Traffic Planning for Time-Triggered Flows in the  Real-time Data Plane",
    "descriptor": "",
    "authors": [
      "Jonathan Falk",
      "Heiko Geppert",
      "Frank D\u00fcrr",
      "Sukanya Bhowmik",
      "Kurt Rothermel"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.01988"
  },
  {
    "id": "arXiv:2106.13876",
    "title": "Knowledge-Grounded Self-Rationalization via Extractive and Natural  Language Explanations",
    "abstract": "Comments: Accepted in ICML 2022 as a spotlight",
    "descriptor": "\nComments: Accepted in ICML 2022 as a spotlight\n",
    "authors": [
      "Bodhisattwa Prasad Majumder",
      "Oana-Maria Camburu",
      "Thomas Lukasiewicz",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13876"
  },
  {
    "id": "arXiv:2106.15314",
    "title": "The cityseer Python package for pedestrian-scale network-based urban  analysis",
    "abstract": "Comments: Revision incorporating additional figure",
    "descriptor": "\nComments: Revision incorporating additional figure\n",
    "authors": [
      "Gareth D. Simons"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.15314"
  },
  {
    "id": "arXiv:2107.04616",
    "title": "A deep convolutional neural network that is invariant to time rescaling",
    "abstract": "A deep convolutional neural network that is invariant to time rescaling",
    "descriptor": "",
    "authors": [
      "Brandon G. Jacques",
      "Zoran Tiganj",
      "Aakash Sarkar",
      "Marc W. Howard",
      "Per B. Sederberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04616"
  },
  {
    "id": "arXiv:2107.05369",
    "title": "How to Approximate Ontology-Mediated Queries",
    "abstract": "How to Approximate Ontology-Mediated Queries",
    "descriptor": "",
    "authors": [
      "Anneke Haga",
      "Carsten Lutz",
      "Leif Sabellek",
      "Frank Wolter"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.05369"
  },
  {
    "id": "arXiv:2107.05895",
    "title": "A Theory of Spherical Diagrams",
    "abstract": "Comments: 8 pages, 14 figures",
    "descriptor": "\nComments: 8 pages, 14 figures\n",
    "authors": [
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.05895"
  },
  {
    "id": "arXiv:2107.07999",
    "title": "From block-Toeplitz matrices to differential equations on graphs:  towards a general theory for scalable masked Transformers",
    "abstract": "Comments: 20 pages, 12 figures",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "Krzysztof Choromanski",
      "Han Lin",
      "Haoxian Chen",
      "Tianyi Zhang",
      "Arijit Sehanobish",
      "Valerii Likhosherstov",
      "Jack Parker-Holder",
      "Tamas Sarlos",
      "Adrian Weller",
      "Thomas Weingarten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07999"
  },
  {
    "id": "arXiv:2107.08094",
    "title": "LAORAM: A Look Ahead ORAM Architecture for Training Large Embedding  Tables",
    "abstract": "LAORAM: A Look Ahead ORAM Architecture for Training Large Embedding  Tables",
    "descriptor": "",
    "authors": [
      "Rachit Rajat",
      "Yongqin Wang",
      "Murali Annavaram"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.08094"
  },
  {
    "id": "arXiv:2108.09117",
    "title": "OpenStreetMap-based Autonomous Navigation With LiDAR Naive-Valley-Path  Obstacle Avoidance",
    "abstract": "Comments: This paper is in its second revision for publication at IEEE Transactions on Intelligent Transportation Systems (T-ITS)",
    "descriptor": "\nComments: This paper is in its second revision for publication at IEEE Transactions on Intelligent Transportation Systems (T-ITS)\n",
    "authors": [
      "Miguel Angel Munoz-Banon",
      "Edison Velasco-Sanchez",
      "Francisco A. Candelas",
      "Fernando Torres"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.09117"
  },
  {
    "id": "arXiv:2108.11801",
    "title": "Unsupervised domain adaptation for clinician pose estimation and  instance segmentation in the operating room",
    "abstract": "Comments: Accepted at Elsevier Journal of Medical Image Analysis. Code is available at this https URL Supplementary video is available at this https URL",
    "descriptor": "\nComments: Accepted at Elsevier Journal of Medical Image Analysis. Code is available at this https URL Supplementary video is available at this https URL\n",
    "authors": [
      "Vinkle Srivastav",
      "Afshin Gangi",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11801"
  },
  {
    "id": "arXiv:2109.00528",
    "title": "Wasserstein GANs with Gradient Penalty Compute Congested Transport",
    "abstract": "Comments: 27 pages. This version accepted for publication at the 35th Annual Conference on Learning Theory (COLT 2022), this https URL",
    "descriptor": "\nComments: 27 pages. This version accepted for publication at the 35th Annual Conference on Learning Theory (COLT 2022), this https URL\n",
    "authors": [
      "Tristan Milne",
      "Adrian Nachman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.00528"
  },
  {
    "id": "arXiv:2109.10681",
    "title": "A Latent Restoring Force Approach to Nonlinear System Identification",
    "abstract": "Comments: 18 pages, 11 figures, preprint submitted to Mechanical Systems and Signal Processing",
    "descriptor": "\nComments: 18 pages, 11 figures, preprint submitted to Mechanical Systems and Signal Processing\n",
    "authors": [
      "Timothy J. Rogers",
      "Tobias Friis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.10681"
  },
  {
    "id": "arXiv:2109.13156",
    "title": "DAReN: A Collaborative Approach Towards Reasoning And Disentangling",
    "abstract": "DAReN: A Collaborative Approach Towards Reasoning And Disentangling",
    "descriptor": "",
    "authors": [
      "Pritish Sahu",
      "Kalliopi Basioti",
      "Vladimir Pavlovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.13156"
  },
  {
    "id": "arXiv:2110.02457",
    "title": "GDA-AM: On the effectiveness of solving minimax optimization via  Anderson Acceleration",
    "abstract": "Comments: 31 Pages, ICLR, minimax, Anderson Acceleration",
    "descriptor": "\nComments: 31 Pages, ICLR, minimax, Anderson Acceleration\n",
    "authors": [
      "Huan He",
      "Shifan Zhao",
      "Yuanzhe Xi",
      "Joyce C Ho",
      "Yousef Saad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02457"
  },
  {
    "id": "arXiv:2110.02830",
    "title": "Parameterized and Approximation Algorithms for the Steiner Arborescence  Problem on a Hypercube",
    "abstract": "Parameterized and Approximation Algorithms for the Steiner Arborescence  Problem on a Hypercube",
    "descriptor": "",
    "authors": [
      "Sugyani Mahapatra",
      "Manikandan Narayanan",
      "N S Narayanaswamy",
      "Vijayaragunathan Ramamoorthi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02830"
  },
  {
    "id": "arXiv:2110.03655",
    "title": "Augmenting Reinforcement Learning with Behavior Primitives for Diverse  Manipulation Tasks",
    "abstract": "Comments: IEEE ICRA 2022; Outstanding Learning Paper Award",
    "descriptor": "\nComments: IEEE ICRA 2022; Outstanding Learning Paper Award\n",
    "authors": [
      "Soroush Nasiriany",
      "Huihan Liu",
      "Yuke Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.03655"
  },
  {
    "id": "arXiv:2110.05323",
    "title": "ProgFed: Effective, Communication, and Computation Efficient Federated  Learning by Progressive Training",
    "abstract": "Comments: To appear in ICML 2022",
    "descriptor": "\nComments: To appear in ICML 2022\n",
    "authors": [
      "Hui-Po Wang",
      "Sebastian U. Stich",
      "Yang He",
      "Mario Fritz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05323"
  },
  {
    "id": "arXiv:2110.05436",
    "title": "A new method to detect projective equivalences and symmetries of  rational $3D$ curves",
    "abstract": "A new method to detect projective equivalences and symmetries of  rational $3D$ curves",
    "descriptor": "",
    "authors": [
      "U\u011fur G\u00f6z\u00fctok",
      "H\u00fcsn\u00fc An\u0131l \u00c7oban",
      "Yasemin Sa\u011f\u0131ro\u011flu",
      "Juan Gerardo Alc\u00e1zar"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Computational Geometry (cs.CG)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2110.05436"
  },
  {
    "id": "arXiv:2110.05706",
    "title": "Deep Fusion Prior for Multi-Focus Image Super Resolution Fusion",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Yuanjie Gu",
      "Zhibo Xiao",
      "Hailun Wang",
      "Cheng Liu",
      "Shouyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.05706"
  },
  {
    "id": "arXiv:2110.05942",
    "title": "Resolution of the Linear-Bounded Automata Question",
    "abstract": "Comments: A response to Mr. Preu's commentary added. Accuracies improved. A typos in formulas in the proof of Theorem 5 corrected. Other typos will be corrected future",
    "descriptor": "\nComments: A response to Mr. Preu's commentary added. Accuracies improved. A typos in formulas in the proof of Theorem 5 corrected. Other typos will be corrected future\n",
    "authors": [
      "Tianrong Lin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2110.05942"
  },
  {
    "id": "arXiv:2110.11395",
    "title": "SOSP: Efficiently Capturing Global Correlations by Second-Order  Structured Pruning",
    "abstract": "SOSP: Efficiently Capturing Global Correlations by Second-Order  Structured Pruning",
    "descriptor": "",
    "authors": [
      "Manuel Nonnenmacher",
      "Thomas Pfeil",
      "Ingo Steinwart",
      "David Reeb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11395"
  },
  {
    "id": "arXiv:2110.13589",
    "title": "AQP: An Open Modular Python Platform for Objective Speech and Audio  Quality Metrics",
    "abstract": "Comments: 6 pages, 3 figures, accepted and presented at ACM MMSys22, June, 2022, Athlone, Ireland",
    "descriptor": "\nComments: 6 pages, 3 figures, accepted and presented at ACM MMSys22, June, 2022, Athlone, Ireland\n",
    "authors": [
      "Jack Geraghty",
      "Jiazheng Li",
      "Alessandro Ragano",
      "Andrew Hines"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13589"
  },
  {
    "id": "arXiv:2110.13604",
    "title": "Finite Element Approximation of Large-Scale Isometric Deformations of  Parametrized Surfaces",
    "abstract": "Finite Element Approximation of Large-Scale Isometric Deformations of  Parametrized Surfaces",
    "descriptor": "",
    "authors": [
      "Martin Rumpf",
      "Stefan Simon",
      "Christoph Smoch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13604"
  },
  {
    "id": "arXiv:2110.13802",
    "title": "Linear Approximate Pattern Matching Algorithm",
    "abstract": "Comments: 15 pages double spaced",
    "descriptor": "\nComments: 15 pages double spaced\n",
    "authors": [
      "Anas Al-okaily",
      "Abdelghani Tbakhi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2110.13802"
  },
  {
    "id": "arXiv:2110.14468",
    "title": "DESTA: A Framework for Safe Reinforcement Learning with Markov Games of  Intervention",
    "abstract": "DESTA: A Framework for Safe Reinforcement Learning with Markov Games of  Intervention",
    "descriptor": "",
    "authors": [
      "David Mguni",
      "Usman Islam",
      "Yaqi Sun",
      "Xiuling Zhang",
      "Joel Jennings",
      "Aivar Sootla",
      "Changmin Yu",
      "Ziyan Wang",
      "Jun Wang",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14468"
  },
  {
    "id": "arXiv:2111.04543",
    "title": "Treewidth versus clique number. II. Tree-independence number",
    "abstract": "Comments: 33 pages; abstract has been shortened due to arXiv requirements. A previous version of this arXiv post has been reorganized into two parts; this is the first of the two parts",
    "descriptor": "\nComments: 33 pages; abstract has been shortened due to arXiv requirements. A previous version of this arXiv post has been reorganized into two parts; this is the first of the two parts\n",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Martin Milani\u010d",
      "Kenny \u0160torgel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.04543"
  },
  {
    "id": "arXiv:2111.04688",
    "title": "Universal and data-adaptive algorithms for model selection in linear  contextual bandits",
    "abstract": "Comments: 30 pages, to appear in ICML 2022",
    "descriptor": "\nComments: 30 pages, to appear in ICML 2022\n",
    "authors": [
      "Vidya Muthukumar",
      "Akshay Krishnamurthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.04688"
  },
  {
    "id": "arXiv:2111.11707",
    "title": "Boosting Neural Machine Translation with Dependency-Scaled  Self-Attention Network",
    "abstract": "Boosting Neural Machine Translation with Dependency-Scaled  Self-Attention Network",
    "descriptor": "",
    "authors": [
      "Ru Peng",
      "Nankai Lin",
      "Yi Fang",
      "Shengyi Jiang",
      "Tianyong Hao",
      "Boyu Chen",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.11707"
  },
  {
    "id": "arXiv:2111.12423",
    "title": "xFuzz: Machine Learning Guided Cross-Contract Fuzzing",
    "abstract": "Comments: IEEE Transactions on Dependable and Secure Computing (2022)",
    "descriptor": "\nComments: IEEE Transactions on Dependable and Secure Computing (2022)\n",
    "authors": [
      "Yinxing Xue",
      "Jiaming Ye",
      "Wei Zhang",
      "Jun Sun",
      "Lei Ma",
      "Haijun Wang",
      "Jianjun Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.12423"
  },
  {
    "id": "arXiv:2112.04153",
    "title": "Model-Value Inconsistency as a Signal for Epistemic Uncertainty",
    "abstract": "Comments: The first three authors contributed equally. Accepted at ICML 2022",
    "descriptor": "\nComments: The first three authors contributed equally. Accepted at ICML 2022\n",
    "authors": [
      "Angelos Filos",
      "Eszter V\u00e9rtes",
      "Zita Marinho",
      "Gregory Farquhar",
      "Diana Borsa",
      "Abram Friesen",
      "Feryal Behbahani",
      "Tom Schaul",
      "Andr\u00e9 Barreto",
      "Simon Osindero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04153"
  },
  {
    "id": "arXiv:2112.05664",
    "title": "Leveraging Joint-Diagonalization in Transform-Learning NMF",
    "abstract": "Leveraging Joint-Diagonalization in Transform-Learning NMF",
    "descriptor": "",
    "authors": [
      "Sixin Zhang",
      "Emmanuel Soubies",
      "C\u00e9dric F\u00e9votte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.05664"
  },
  {
    "id": "arXiv:2112.11014",
    "title": "fMRI Neurofeedback Learning Patterns are Predictive of Personal and  Clinical Traits",
    "abstract": "fMRI Neurofeedback Learning Patterns are Predictive of Personal and  Clinical Traits",
    "descriptor": "",
    "authors": [
      "Rotem Leibovitz",
      "Jhonathan Osin",
      "Lior Wolf",
      "Guy Gurevitch",
      "Talma Hendler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11014"
  },
  {
    "id": "arXiv:2201.02593",
    "title": "Equalized Focal Loss for Dense Long-Tailed Object Detection",
    "abstract": "Comments: Accepted by the IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR) 2022",
    "descriptor": "\nComments: Accepted by the IEEE/CVF Computer Vision and Pattern Recognition Conference (CVPR) 2022\n",
    "authors": [
      "Bo Li",
      "Yongqiang Yao",
      "Jingru Tan",
      "Gang Zhang",
      "Fengwei Yu",
      "Jianwei Lu",
      "Ye Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.02593"
  },
  {
    "id": "arXiv:2201.05212",
    "title": "Probabilistic design of optimal sequential decision-making algorithms in  learning and control",
    "abstract": "Probabilistic design of optimal sequential decision-making algorithms in  learning and control",
    "descriptor": "",
    "authors": [
      "Emiland Garrabe",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.05212"
  },
  {
    "id": "arXiv:2201.07219",
    "title": "Contrastive Pretraining for Echocardiography Segmentation with Limited  Data",
    "abstract": "Contrastive Pretraining for Echocardiography Segmentation with Limited  Data",
    "descriptor": "",
    "authors": [
      "Mohamed Saeed",
      "Rand Muhtaseb",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07219"
  },
  {
    "id": "arXiv:2201.09324",
    "title": "Supervised Visual Attention for Simultaneous Multimodal Machine  Translation",
    "abstract": "Comments: Accepted to Journal of Artificial Intelligence Research (JAIR)",
    "descriptor": "\nComments: Accepted to Journal of Artificial Intelligence Research (JAIR)\n",
    "authors": [
      "Veneta Haralampieva",
      "Ozan Caglayan",
      "Lucia Specia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.09324"
  },
  {
    "id": "arXiv:2201.11726",
    "title": "Search Trajectories Networks of Multiobjective Evolutionary Algorithms",
    "abstract": "Search Trajectories Networks of Multiobjective Evolutionary Algorithms",
    "descriptor": "",
    "authors": [
      "Yuri Lavinas",
      "Claus Aranha",
      "Gabriela Ochoa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11726"
  },
  {
    "id": "arXiv:2202.00789",
    "title": "Team Belief DAG: A Concise Representation for Team-Correlated  Game-Theoretic Decision Making",
    "abstract": "Team Belief DAG: A Concise Representation for Team-Correlated  Game-Theoretic Decision Making",
    "descriptor": "",
    "authors": [
      "Brian Hu Zhang",
      "Gabriele Farina",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.00789"
  },
  {
    "id": "arXiv:2202.01741",
    "title": "How to Leverage Unlabeled Data in Offline Reinforcement Learning",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Tianhe Yu",
      "Aviral Kumar",
      "Yevgen Chebotar",
      "Karol Hausman",
      "Chelsea Finn",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01741"
  },
  {
    "id": "arXiv:2202.01855",
    "title": "Self-supervised Learning with Random-projection Quantizer for Speech  Recognition",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Chung-Cheng Chiu",
      "James Qin",
      "Yu Zhang",
      "Jiahui Yu",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.01855"
  },
  {
    "id": "arXiv:2202.02832",
    "title": "Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin  Lesion Classification",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Peter J. Bevan",
      "Amir Atapour-Abarghouei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02832"
  },
  {
    "id": "arXiv:2202.07737",
    "title": "Ab-initio Contrast Estimation and Denoising of Cryo-EM Images",
    "abstract": "Ab-initio Contrast Estimation and Denoising of Cryo-EM Images",
    "descriptor": "",
    "authors": [
      "Yunpeng Shi",
      "Amit Singer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07737"
  },
  {
    "id": "arXiv:2202.08070",
    "title": "On Measuring Excess Capacity in Neural Networks",
    "abstract": "On Measuring Excess Capacity in Neural Networks",
    "descriptor": "",
    "authors": [
      "Florian Graf",
      "Sebastian Zeng",
      "Bastian Rieck",
      "Marc Niethammer",
      "Roland Kwitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08070"
  },
  {
    "id": "arXiv:2202.09128",
    "title": "Energy Efficient Dual-Functional Radar-Communication: Rate-Splitting  Multiple Access, Low-Resolution DACs, and RF Chain Selection",
    "abstract": "Energy Efficient Dual-Functional Radar-Communication: Rate-Splitting  Multiple Access, Low-Resolution DACs, and RF Chain Selection",
    "descriptor": "",
    "authors": [
      "Onur Dizdar",
      "Aryan Kaushik",
      "Bruno Clerckx",
      "Christos Masouros"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09128"
  },
  {
    "id": "arXiv:2202.10962",
    "title": "Adaptive Cut Selection in Mixed-Integer Linear Programming",
    "abstract": "Comments: Updated SCIP / Gurobi versions. Added constraint type features and new computational experiments",
    "descriptor": "\nComments: Updated SCIP / Gurobi versions. Added constraint type features and new computational experiments\n",
    "authors": [
      "Mark Turner",
      "Thorsten Koch",
      "Felipe Serrano",
      "Michael Winkler"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10962"
  },
  {
    "id": "arXiv:2202.11703",
    "title": "U-Attention to Textures: Hierarchical Hourglass Vision Transformer for  Universal Texture Synthesis",
    "abstract": "U-Attention to Textures: Hierarchical Hourglass Vision Transformer for  Universal Texture Synthesis",
    "descriptor": "",
    "authors": [
      "Shouchang Guo",
      "Valentin Deschaintre",
      "Douglas Noll",
      "Arthur Roullier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.11703"
  },
  {
    "id": "arXiv:2202.11912",
    "title": "A Rigorous Study of Integrated Gradients Method and Extensions to  Internal Neuron Attributions",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1703.01365 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1703.01365 by other authors\n",
    "authors": [
      "Daniel Lundstrom",
      "Tianjian Huang",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11912"
  },
  {
    "id": "arXiv:2202.11948",
    "title": "Domain Disentangled Generative Adversarial Network for Zero-Shot  Sketch-Based 3D Shape Retrieval",
    "abstract": "Comments: Accepted by AAAI 2022",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Rui Xu",
      "Zongyan Han",
      "Le Hui",
      "Jianjun Qian",
      "Jin Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11948"
  },
  {
    "id": "arXiv:2202.12205",
    "title": "Is Neuro-Symbolic AI Meeting its Promise in Natural Language Processing?  A Structured Review",
    "abstract": "Comments: Survey",
    "descriptor": "\nComments: Survey\n",
    "authors": [
      "Kyle Hamilton",
      "Aparna Nayak",
      "Bojan Bo\u017ei\u0107",
      "Luca Longo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12205"
  },
  {
    "id": "arXiv:2203.00977",
    "title": "Chained Generalisation Bounds",
    "abstract": "Chained Generalisation Bounds",
    "descriptor": "",
    "authors": [
      "Eugenio Clerico",
      "Amitis Shidani",
      "George Deligiannidis",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.00977"
  },
  {
    "id": "arXiv:2203.01703",
    "title": "Capturing Shape Information with Multi-Scale Topological Loss Terms for  3D Reconstruction",
    "abstract": "Capturing Shape Information with Multi-Scale Topological Loss Terms for  3D Reconstruction",
    "descriptor": "",
    "authors": [
      "Dominik J. E. Waibel",
      "Scott Atwell",
      "Matthias Meier",
      "Carsten Marr",
      "Bastian Rieck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.01703"
  },
  {
    "id": "arXiv:2203.02474",
    "title": "Rate-Distortion Theoretic Generalization Bounds for Stochastic Learning  Algorithms",
    "abstract": "Comments: Accepted for presentation at the Conference on Learning Theory (COLT) 2022",
    "descriptor": "\nComments: Accepted for presentation at the Conference on Learning Theory (COLT) 2022\n",
    "authors": [
      "Milad Sefidgaran",
      "Amin Gohari",
      "Ga\u00ebl Richard",
      "Umut \u015eim\u015fekli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.02474"
  },
  {
    "id": "arXiv:2203.04406",
    "title": "Routing with Privacy for Drone Package Delivery Systems",
    "abstract": "Routing with Privacy for Drone Package Delivery Systems",
    "descriptor": "",
    "authors": [
      "Geoffrey Ding",
      "Alex Berke",
      "Karthik Gopalakrishnan",
      "Kwassi H. Degue",
      "Hamsa Balakrishnan",
      "Max Z. Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04406"
  },
  {
    "id": "arXiv:2203.04592",
    "title": "Mapping global dynamics of benchmark creation and saturation in  artificial intelligence",
    "abstract": "Mapping global dynamics of benchmark creation and saturation in  artificial intelligence",
    "descriptor": "",
    "authors": [
      "Adriano Barbosa-Silva",
      "Simon Ott",
      "Kathrin Blagec",
      "Jan Brauner",
      "Matthias Samwald"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04592"
  },
  {
    "id": "arXiv:2203.07060",
    "title": "MotionSC: Data Set and Network for Real-Time Semantic Mapping in Dynamic  Environments",
    "abstract": "MotionSC: Data Set and Network for Real-Time Semantic Mapping in Dynamic  Environments",
    "descriptor": "",
    "authors": [
      "Joey Wilson",
      "Jingyu Song",
      "Yuewei Fu",
      "Arthur Zhang",
      "Andrew Capodieci",
      "Paramsothy Jayakumar",
      "Kira Barton",
      "Maani Ghaffari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07060"
  },
  {
    "id": "arXiv:2203.08439",
    "title": "Instance-level loss based multiple-instance learning framework for  acoustic scene classification",
    "abstract": "Instance-level loss based multiple-instance learning framework for  acoustic scene classification",
    "descriptor": "",
    "authors": [
      "Won-Gook Choi",
      "Joon-Hyuk Chang",
      "Jae-Mo Yang",
      "Han-Gil Moon"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.08439"
  },
  {
    "id": "arXiv:2203.08653",
    "title": "Counterfactual Inference of Second Opinions",
    "abstract": "Counterfactual Inference of Second Opinions",
    "descriptor": "",
    "authors": [
      "Nina L. Corvelo Benz",
      "Manuel Gomez Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08653"
  },
  {
    "id": "arXiv:2203.09180",
    "title": "A Novel End-To-End Network for Reconstruction of Non-Regularly Sampled  Image Data Using Locally Fully Connected Layers",
    "abstract": "Comments: 6 pages, 5 figures, 2 tables, IEEE 23rd International Workshop on Multimedia Signal Processing (MMSP). arXiv admin note: text overlap with arXiv:2203.00336",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables, IEEE 23rd International Workshop on Multimedia Signal Processing (MMSP). arXiv admin note: text overlap with arXiv:2203.00336\n",
    "authors": [
      "Simon Grosche",
      "Fabian Brand",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09180"
  },
  {
    "id": "arXiv:2203.10723",
    "title": "An Intermediate-level Attack Framework on The Basis of Linear Regression",
    "abstract": "Comments: Accepted by TPAMI; Code is available at this https URL",
    "descriptor": "\nComments: Accepted by TPAMI; Code is available at this https URL\n",
    "authors": [
      "Yiwen Guo",
      "Qizhang Li",
      "Wangmeng Zuo",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.10723"
  },
  {
    "id": "arXiv:2203.11891",
    "title": "Evolution Autoencodes Life's Interactions as Species that are Decoded  into Ecosystems",
    "abstract": "Evolution Autoencodes Life's Interactions as Species that are Decoded  into Ecosystems",
    "descriptor": "",
    "authors": [
      "Irun R. Cohen",
      "Assaf Marron"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.11891"
  },
  {
    "id": "arXiv:2203.12139",
    "title": "Approximate Inference for Stochastic Planning in Factored Spaces",
    "abstract": "Approximate Inference for Stochastic Planning in Factored Spaces",
    "descriptor": "",
    "authors": [
      "Zhennan Wu",
      "Roni Khardon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.12139"
  },
  {
    "id": "arXiv:2203.12886",
    "title": "Automatic Speech recognition for Speech Assessment of Persian Preschool  Children",
    "abstract": "Comments: 8 pages, 5 figures, 4 tables, 1 algorithm",
    "descriptor": "\nComments: 8 pages, 5 figures, 4 tables, 1 algorithm\n",
    "authors": [
      "Amirhossein Abaskohi",
      "Fatemeh Mortazavi",
      "Hadi Moradi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.12886"
  },
  {
    "id": "arXiv:2203.12905",
    "title": "Privileged Attribution Constrained Deep Networks for Facial Expression  Recognition",
    "abstract": "Privileged Attribution Constrained Deep Networks for Facial Expression  Recognition",
    "descriptor": "",
    "authors": [
      "Jules Bonnard",
      "Arnaud Dapogny",
      "Ferdinand Dhombres",
      "K\u00e9vin Bailly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12905"
  },
  {
    "id": "arXiv:2203.13447",
    "title": "Component-wise Analysis of Automatically Designed Multiobjective  Algorithms on Constrained Problems",
    "abstract": "Component-wise Analysis of Automatically Designed Multiobjective  Algorithms on Constrained Problems",
    "descriptor": "",
    "authors": [
      "Yuri Lavinas",
      "Gabriela Ochoa",
      "Claus Aranha"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13447"
  },
  {
    "id": "arXiv:2203.13968",
    "title": "Tuning Particle Accelerators with Safety Constraints using Bayesian  Optimization",
    "abstract": "Tuning Particle Accelerators with Safety Constraints using Bayesian  Optimization",
    "descriptor": "",
    "authors": [
      "Johannes Kirschner",
      "Mojmir Mutn\u00fd",
      "Andreas Krause",
      "Jaime Coello de Portugal",
      "Nicole Hiller",
      "Jochem Snuverink"
    ],
    "subjectives": [
      "Accelerator Physics (physics.acc-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13968"
  },
  {
    "id": "arXiv:2203.14416",
    "title": "Bunched LPCNet2: Efficient Neural Vocoders Covering Devices from Cloud  to Edge",
    "abstract": "Comments: Interspeech 2022",
    "descriptor": "\nComments: Interspeech 2022\n",
    "authors": [
      "Sangjun Park",
      "Kihyun Choo",
      "Joohyung Lee",
      "Anton V. Porov",
      "Konstantin Osipov",
      "June Sig Sung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.14416"
  },
  {
    "id": "arXiv:2203.14939",
    "title": "Pupil-aware Holography",
    "abstract": "Pupil-aware Holography",
    "descriptor": "",
    "authors": [
      "Praneeth Chakravarthula",
      "Seung-Hwan Baek",
      "Florian Schiffers",
      "Ethan Tseng",
      "Grace Kuo",
      "Andrew Maimone",
      "Nathan Matsuda",
      "Oliver Cossairt",
      "Douglas Lanman",
      "Felix Heide"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.14939"
  },
  {
    "id": "arXiv:2203.15537",
    "title": "On Metric Learning for Audio-Text Cross-Modal Retrieval",
    "abstract": "Comments: 5 pages, accepted to InterSpeech2022",
    "descriptor": "\nComments: 5 pages, accepted to InterSpeech2022\n",
    "authors": [
      "Xinhao Mei",
      "Xubo Liu",
      "Jianyuan Sun",
      "Mark D. Plumbley",
      "Wenwu Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.15537"
  },
  {
    "id": "arXiv:2203.16318",
    "title": "Near-Field Communications for 6G: Fundamentals, Challenges, Potentials,  and Future Directions",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Mingyao Cui",
      "Zidong Wu",
      "Yu Lu",
      "Xiuhong Wei",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16318"
  },
  {
    "id": "arXiv:2203.16361",
    "title": "Rainbow Keywords: Efficient Incremental Learning for Online Spoken  Keyword Spotting",
    "abstract": "Comments: Accepted to Interspeech 2022",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Yang Xiao",
      "Nana Hou",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16361"
  },
  {
    "id": "arXiv:2203.16637",
    "title": "Hybrid Handcrafted and Learnable Audio Representation for Analysis of  Speech Under Cognitive and Physical Load",
    "abstract": "Comments: Submitted to InterSpeech 2022",
    "descriptor": "\nComments: Submitted to InterSpeech 2022\n",
    "authors": [
      "Gasser Elbanna",
      "Alice Biryukov",
      "Neil Scheidwasser-Clow",
      "Lara Orlandic",
      "Pablo Mainar",
      "Mikolaj Kegler",
      "Pierre Beckmann",
      "Milos Cernak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16637"
  },
  {
    "id": "arXiv:2203.17190",
    "title": "Mixed-Phoneme BERT: Improving BERT with Mixed Phoneme and Sup-Phoneme  Representations for Text to Speech",
    "abstract": "Comments: Accepted by interspeech 2022",
    "descriptor": "\nComments: Accepted by interspeech 2022\n",
    "authors": [
      "Guangyan Zhang",
      "Kaitao Song",
      "Xu Tan",
      "Daxin Tan",
      "Yuzi Yan",
      "Yanqing Liu",
      "Gang Wang",
      "Wei Zhou",
      "Tao Qin",
      "Tan Lee",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17190"
  },
  {
    "id": "arXiv:2204.00768",
    "title": "VQTTS: High-Fidelity Text-to-Speech Synthesis with Self-Supervised VQ  Acoustic Feature",
    "abstract": "Comments: Accepted to Interspeech 2022",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Chenpeng Du",
      "Yiwei Guo",
      "Xie Chen",
      "Kai Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.00768"
  },
  {
    "id": "arXiv:2204.00791",
    "title": "CL-XABSA: Contrastive Learning for Cross-lingual Aspect-based Sentiment  Analysis",
    "abstract": "CL-XABSA: Contrastive Learning for Cross-lingual Aspect-based Sentiment  Analysis",
    "descriptor": "",
    "authors": [
      "Nankai Lin",
      "Yingwen Fu",
      "Xiaotian Lin",
      "Aimin Yang",
      "Shengyi Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.00791"
  },
  {
    "id": "arXiv:2204.00984",
    "title": "Stability of the Minimum Energy Path",
    "abstract": "Stability of the Minimum Energy Path",
    "descriptor": "",
    "authors": [
      "Xuanyu Liu",
      "Huajie Chen",
      "Christoph Ortner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.00984"
  },
  {
    "id": "arXiv:2204.02090",
    "title": "VocaLiST: An Audio-Visual Synchronisation Model for Lips and Voices",
    "abstract": "Comments: Paper accepted to Interspeech 2022; Project Page: this https URL",
    "descriptor": "\nComments: Paper accepted to Interspeech 2022; Project Page: this https URL\n",
    "authors": [
      "Venkatesh S. Kadandale",
      "Juan F. Montesinos",
      "Gloria Haro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02090"
  },
  {
    "id": "arXiv:2204.02390",
    "title": "Learning Pneumatic Non-Prehensile Manipulation with a Mobile Blower",
    "abstract": "Comments: Accepted to IEEE Robotics and Automation Letters (RA-L), 2022 and IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted to IEEE Robotics and Automation Letters (RA-L), 2022 and IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2022. Project page: this https URL\n",
    "authors": [
      "Jimmy Wu",
      "Xingyuan Sun",
      "Andy Zeng",
      "Shuran Song",
      "Szymon Rusinkiewicz",
      "Thomas Funkhouser"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02390"
  },
  {
    "id": "arXiv:2204.02967",
    "title": "Enhanced Direct Speech-to-Speech Translation Using Self-supervised  Pre-training and Data Augmentation",
    "abstract": "Comments: Accepted to be published in the Proceedings of Interspeech 2022",
    "descriptor": "\nComments: Accepted to be published in the Proceedings of Interspeech 2022\n",
    "authors": [
      "Sravya Popuri",
      "Peng-Jen Chen",
      "Changhan Wang",
      "Juan Pino",
      "Yossi Adi",
      "Jiatao Gu",
      "Wei-Ning Hsu",
      "Ann Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02967"
  },
  {
    "id": "arXiv:2204.03379",
    "title": "Correcting Mispronunciations in Speech using Spectrogram Inpainting",
    "abstract": "Comments: Accepted for publication at Interspeech 2022",
    "descriptor": "\nComments: Accepted for publication at Interspeech 2022\n",
    "authors": [
      "Talia Ben-Simon",
      "Felix Kreuk",
      "Faten Awwad",
      "Jacob T. Cohen",
      "Joseph Keshet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03379"
  },
  {
    "id": "arXiv:2204.04718",
    "title": "Rethinking Exponential Averaging of the Fisher",
    "abstract": "Comments: - fixed small bug in QE-KLD-WRM and thus improved results slightly - Corrected the acknowledgement section - removed redundat paragraph in S2.4 - introduced a small section with connection to second order methods (S4.5) - some minor rephrasing - added a new short discussion: S4 of Suppl. mat",
    "descriptor": "\nComments: - fixed small bug in QE-KLD-WRM and thus improved results slightly - Corrected the acknowledgement section - removed redundat paragraph in S2.4 - introduced a small section with connection to second order methods (S4.5) - some minor rephrasing - added a new short discussion: S4 of Suppl. mat\n",
    "authors": [
      "Constantin Octavian Puiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.04718"
  },
  {
    "id": "arXiv:2204.05649",
    "title": "ADFF: Attention Based Deep Feature Fusion Approach for Music Emotion  Recognition",
    "abstract": "Comments: It has been received by Interspeech2022",
    "descriptor": "\nComments: It has been received by Interspeech2022\n",
    "authors": [
      "Zi Huang",
      "Shulei Ji",
      "Zhilan Hu",
      "Chuangjian Cai",
      "Jing Luo",
      "Xinyu Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.05649"
  },
  {
    "id": "arXiv:2204.05737",
    "title": "LifeLonger: A Benchmark for Continual Disease Classification",
    "abstract": "LifeLonger: A Benchmark for Continual Disease Classification",
    "descriptor": "",
    "authors": [
      "Mohammad Mahdi Derakhshani",
      "Ivona Najdenkoska",
      "Tom van Sonsbeek",
      "Xiantong Zhen",
      "Dwarikanath Mahapatra",
      "Marcel Worring",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05737"
  },
  {
    "id": "arXiv:2204.06322",
    "title": "Production federated keyword spotting via distillation, filtering, and  joint federated-centralized training",
    "abstract": "Comments: Accepted to Interspeech 2022",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Andrew Hard",
      "Kurt Partridge",
      "Neng Chen",
      "Sean Augenstein",
      "Aishanee Shah",
      "Hyun Jin Park",
      "Alex Park",
      "Sara Ng",
      "Jessica Nguyen",
      "Ignacio Lopez Moreno",
      "Rajiv Mathews",
      "Fran\u00e7oise Beaufays"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.06322"
  },
  {
    "id": "arXiv:2204.06535",
    "title": "Multilingual Event Linking to Wikidata",
    "abstract": "Comments: Camera-ready for Multilingual Information Access workshop at NAACL 2022",
    "descriptor": "\nComments: Camera-ready for Multilingual Information Access workshop at NAACL 2022\n",
    "authors": [
      "Adithya Pratapa",
      "Rishubh Gupta",
      "Teruko Mitamura"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.06535"
  },
  {
    "id": "arXiv:2204.07230",
    "title": "Learning two-phase microstructure evolution using neural operators and  autoencoder architectures",
    "abstract": "Learning two-phase microstructure evolution using neural operators and  autoencoder architectures",
    "descriptor": "",
    "authors": [
      "Vivek Oommen",
      "Khemraj Shukla",
      "Somdatta Goswami",
      "Remi Dingreville",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.07230"
  },
  {
    "id": "arXiv:2204.07763",
    "title": "UFRC: A Unified Framework for Reliable COVID-19 Detection on  Crowdsourced Cough Audio",
    "abstract": "UFRC: A Unified Framework for Reliable COVID-19 Detection on  Crowdsourced Cough Audio",
    "descriptor": "",
    "authors": [
      "Jiangeng Chang",
      "Yucheng Ruan",
      "Cui Shaoze",
      "John Soong Tshon Yit",
      "Mengling Feng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07763"
  },
  {
    "id": "arXiv:2204.09381",
    "title": "Exploration strategies for articulatory synthesis of complex syllable  onsets",
    "abstract": "Comments: Accepted at Interspeech 2022",
    "descriptor": "\nComments: Accepted at Interspeech 2022\n",
    "authors": [
      "Daniel R. van Niekerk",
      "Anqi Xu",
      "Branislav Gerazov",
      "Paul K. Krug",
      "Peter Birkholz",
      "Yi Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.09381"
  },
  {
    "id": "arXiv:2204.11582",
    "title": "Graph-DETR3D: Rethinking Overlapping Regions for Multi-View 3D Object  Detection",
    "abstract": "Comments: Accepted to ACM MM 2022",
    "descriptor": "\nComments: Accepted to ACM MM 2022\n",
    "authors": [
      "Zehui Chen",
      "Zhenyu Li",
      "Shiquan Zhang",
      "Liangji Fang",
      "Qinhong Jiang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.11582"
  },
  {
    "id": "arXiv:2204.13663",
    "title": "ADVISER: AI-Driven Vaccination Intervention Optimiser for Increasing  Vaccine Uptake in Nigeria",
    "abstract": "Comments: Accepted for publication at International Joint Conference on Artificial Intelligence 2022, AI for Good Track (IJCAI-22)",
    "descriptor": "\nComments: Accepted for publication at International Joint Conference on Artificial Intelligence 2022, AI for Good Track (IJCAI-22)\n",
    "authors": [
      "Vineet Nair",
      "Kritika Prakash",
      "Michael Wilbur",
      "Aparna Taneja",
      "Corrine Namblard",
      "Oyindamola Adeyemo",
      "Abhishek Dubey",
      "Abiodun Adereni",
      "Milind Tambe",
      "Ayan Mukhopadhyay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.13663"
  },
  {
    "id": "arXiv:2205.01897",
    "title": "Virtual Analog Modeling of Distortion Circuits Using Neural Ordinary  Differential Equations",
    "abstract": "Comments: 8 pages, 10 figures, accepted for DAFx 2022 conference, for associated audio examples, see this https URL",
    "descriptor": "\nComments: 8 pages, 10 figures, accepted for DAFx 2022 conference, for associated audio examples, see this https URL\n",
    "authors": [
      "Jan Wilczek",
      "Alec Wright",
      "Vesa V\u00e4lim\u00e4ki",
      "Emanu\u00ebl Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01897"
  },
  {
    "id": "arXiv:2205.04108",
    "title": "On the Storage Overhead of Proof-of-Work Blockchains",
    "abstract": "On the Storage Overhead of Proof-of-Work Blockchains",
    "descriptor": "",
    "authors": [
      "Alessandro Sforzin",
      "Matteo Maso",
      "Claudio Soriente",
      "Ghassan Karame"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.04108"
  },
  {
    "id": "arXiv:2205.04956",
    "title": "Parallel Batch-Dynamic Minimum Spanning Forest and the Efficiency of  Dynamic Agglomerative Graph Clustering",
    "abstract": "Comments: SPAA 2022",
    "descriptor": "\nComments: SPAA 2022\n",
    "authors": [
      "Tom Tseng",
      "Laxman Dhulipala",
      "Julian Shun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.04956"
  },
  {
    "id": "arXiv:2205.05770",
    "title": "De-biasing \"bias\" measurement",
    "abstract": "De-biasing \"bias\" measurement",
    "descriptor": "",
    "authors": [
      "Kristian Lum",
      "Yunfeng Zhang",
      "Amanda Bower"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.05770"
  },
  {
    "id": "arXiv:2205.06060",
    "title": "$H^1$-stability of an L2-type method on general nonuniform meshes for  subdiffusion equation",
    "abstract": "$H^1$-stability of an L2-type method on general nonuniform meshes for  subdiffusion equation",
    "descriptor": "",
    "authors": [
      "Chaoyu Quan",
      "Xu Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.06060"
  },
  {
    "id": "arXiv:2205.07444",
    "title": "A Deep Reinforcement Learning Blind AI in DareFightingICE",
    "abstract": "Comments: 2022 IEEE Conference on Games (CoG 2022)",
    "descriptor": "\nComments: 2022 IEEE Conference on Games (CoG 2022)\n",
    "authors": [
      "Thai Van Nguyen",
      "Xincheng Dai",
      "Ibrahim Khan",
      "Ruck Thawonmas",
      "Hai V. Pham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.07444"
  },
  {
    "id": "arXiv:2205.08487",
    "title": "Systematic Mapping Protocol: Variability Management in Dynamic Software  Product Lines for Self-Adaptive Systems",
    "abstract": "Comments: Systematic mapping protocol. Keywords: Self-adaptive systems, reconfiguration, Dynamic software product lines, systematic mapping. 9 pages, 2 figures, 6 tables",
    "descriptor": "\nComments: Systematic mapping protocol. Keywords: Self-adaptive systems, reconfiguration, Dynamic software product lines, systematic mapping. 9 pages, 2 figures, 6 tables\n",
    "authors": [
      "Oscar Aguayo",
      "Samuel Sep\u00falveda"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.08487"
  },
  {
    "id": "arXiv:2205.09626",
    "title": "BARS: Towards Open Benchmarking for Recommender Systems",
    "abstract": "Comments: Accepted by SIGIR 2022. Revised camera-ready version",
    "descriptor": "\nComments: Accepted by SIGIR 2022. Revised camera-ready version\n",
    "authors": [
      "Jieming Zhu",
      "Quanyu Dai",
      "Liangcai Su",
      "Rong Ma",
      "Jinyang Liu",
      "Guohao Cai",
      "Xi Xiao",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.09626"
  },
  {
    "id": "arXiv:2205.10218",
    "title": "Learning Task-relevant Representations for Generalization via  Characteristic Functions of Reward Sequence Distributions",
    "abstract": "Comments: Accepted to KDD 2022",
    "descriptor": "\nComments: Accepted to KDD 2022\n",
    "authors": [
      "Rui Yang",
      "Jie Wang",
      "Zijie Geng",
      "Mingxuan Ye",
      "Shuiwang Ji",
      "Bin Li",
      "Feng Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10218"
  },
  {
    "id": "arXiv:2205.10955",
    "title": "Investigating classification learning curves for automatically generated  and labelled plant images",
    "abstract": "Investigating classification learning curves for automatically generated  and labelled plant images",
    "descriptor": "",
    "authors": [
      "Michael A. Beck",
      "Christopher P. Bidinosti",
      "Christopher J. Henry",
      "Manisha Ajmani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10955"
  },
  {
    "id": "arXiv:2205.13202",
    "title": "More Recent Advances in (Hyper)Graph Partitioning",
    "abstract": "More Recent Advances in (Hyper)Graph Partitioning",
    "descriptor": "",
    "authors": [
      "\u00dcmit V. \u00c7ataly\u00fcrek",
      "Karen D. Devine",
      "Marcelo Fonseca Faraj",
      "Lars Gottesb\u00fcren",
      "Tobias Heuer",
      "Henning Meyerhenke",
      "Peter Sanders",
      "Sebastian Schlag",
      "Christian Schulz",
      "Daniel Seemaier",
      "Dorothea Wagner"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13202"
  },
  {
    "id": "arXiv:2205.14506",
    "title": "Introducing Non-Linearity into Quantum Generative Models",
    "abstract": "Introducing Non-Linearity into Quantum Generative Models",
    "descriptor": "",
    "authors": [
      "Kaitlin Gili",
      "Mykolas Sveistrys",
      "Chris Ballance"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14506"
  },
  {
    "id": "arXiv:2205.15195",
    "title": "Personalized Acoustic Echo Cancellation for Full-duplex Communications",
    "abstract": "Comments: submitted to INTERSPEECH 22",
    "descriptor": "\nComments: submitted to INTERSPEECH 22\n",
    "authors": [
      "Shimin Zhang",
      "Ziteng Wang",
      "Yukai Ju",
      "Yihui Fu",
      "Yueyue Na",
      "Qiang Fu",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.15195"
  },
  {
    "id": "arXiv:2205.15254",
    "title": "Pooling Revisited: Your Receptive Field is Suboptimal",
    "abstract": "Comments: CVPR 2022; reference updated for section 2",
    "descriptor": "\nComments: CVPR 2022; reference updated for section 2\n",
    "authors": [
      "Dong-Hwan Jang",
      "Sanghyeok Chu",
      "Joonhyuk Kim",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15254"
  },
  {
    "id": "arXiv:2206.01651",
    "title": "D'ARTAGNAN: Counterfactual Video Generation",
    "abstract": "Comments: Accepted for MICCAI 2022",
    "descriptor": "\nComments: Accepted for MICCAI 2022\n",
    "authors": [
      "Hadrien Reynaud",
      "Athanasios Vlontzos",
      "Mischa Dombrowski",
      "Ciar\u00e1n Lee",
      "Arian Beqiri",
      "Paul Leeson",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01651"
  },
  {
    "id": "arXiv:2206.01727",
    "title": "New Progress in Classic Area: Polynomial Root-squaring and Root-finding",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Victor Y. Pan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.01727"
  },
  {
    "id": "arXiv:2206.01863",
    "title": "Recursive Deformable Image Registration Network with Mutual Attention",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2203.04290",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.04290\n",
    "authors": [
      "Jian-Qing Zheng",
      "Ziyang Wang",
      "Baoru Huang",
      "Ngee Han Lim",
      "Tonia Vincent",
      "Bartlomiej W. Papiez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01863"
  },
  {
    "id": "arXiv:2206.01939",
    "title": "Learning Generative Factors of Neuroimaging Data with Variational  auto-encoders",
    "abstract": "Learning Generative Factors of Neuroimaging Data with Variational  auto-encoders",
    "descriptor": "",
    "authors": [
      "Maksim Zhdanov",
      "Saskia Steinmann",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2206.01939"
  },
  {
    "id": "arXiv:2206.02983",
    "title": "Review on Multiple Plagiarism: A Performance Comparison Study",
    "abstract": "Comments: 6 pages, 1 figures",
    "descriptor": "\nComments: 6 pages, 1 figures\n",
    "authors": [
      "Jabir Al Nahian",
      "Abu Kaisar Mohammad Masum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.02983"
  },
  {
    "id": "arXiv:2206.03149",
    "title": "Self-Training of Handwritten Word Recognition for Synthetic-to-Real  Adaptation",
    "abstract": "Comments: Accepted for publication in International Conference on Pattern Recognition (ICPR) 2022",
    "descriptor": "\nComments: Accepted for publication in International Conference on Pattern Recognition (ICPR) 2022\n",
    "authors": [
      "Fabian Wolf",
      "Gernot A. Fink"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03149"
  },
  {
    "id": "arXiv:2206.03820",
    "title": "SUPER-IVIM-DC: Intra-voxel incoherent motion based Fetal lung maturity  assessment from limited DWI data using supervised learning coupled with  data-consistency",
    "abstract": "Comments: Accepted to the International Conference on Medical Image Computing and Computer Assisted Intervention - MICCAI 2022, to be held during Sept 18-22 in Singapore",
    "descriptor": "\nComments: Accepted to the International Conference on Medical Image Computing and Computer Assisted Intervention - MICCAI 2022, to be held during Sept 18-22 in Singapore\n",
    "authors": [
      "Noam Korngut",
      "Elad Rotman",
      "Onur Afacan",
      "Sila Kurugol",
      "Yael Zaffrani-Reznikov",
      "Shira Nemirovsky-Rotman",
      "Simon Warfield",
      "Moti Freiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.03820"
  },
  {
    "id": "arXiv:2206.05862",
    "title": "X-Risk Analysis for AI Research",
    "abstract": "X-Risk Analysis for AI Research",
    "descriptor": "",
    "authors": [
      "Dan Hendrycks",
      "Mantas Mazeika"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05862"
  },
  {
    "id": "arXiv:2206.06174",
    "title": "Predicting Corporate Risk by Jointly Modeling Company Networks and  Dialogues in Earnings Conference Calls",
    "abstract": "Predicting Corporate Risk by Jointly Modeling Company Networks and  Dialogues in Earnings Conference Calls",
    "descriptor": "",
    "authors": [
      "Yunxin Sang",
      "Yang Bao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06174"
  },
  {
    "id": "arXiv:2206.06855",
    "title": "A new convergence proof for approximations of the Stefan problem",
    "abstract": "A new convergence proof for approximations of the Stefan problem",
    "descriptor": "",
    "authors": [
      "Robert Eymard",
      "Thierry Gallou\u00ebt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.06855"
  },
  {
    "id": "arXiv:2206.06986",
    "title": "Exploring Representation of Horn Clauses using GNNs (Extended Technique  Report)",
    "abstract": "Exploring Representation of Horn Clauses using GNNs (Extended Technique  Report)",
    "descriptor": "",
    "authors": [
      "Chencheng Liang",
      "Philipp R\u00fcmmer",
      "Marc Brockschmidt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06986"
  },
  {
    "id": "arXiv:2206.07915",
    "title": "Barrier Certified Safety Learning Control: When Sum-of-Square  Programming Meets Reinforcement Learning",
    "abstract": "Comments: 6 pages, 6 figures, CCTA2022 conference",
    "descriptor": "\nComments: 6 pages, 6 figures, CCTA2022 conference\n",
    "authors": [
      "Hejun Huang",
      "Zhenglong Li",
      "Dongkun Han"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07915"
  },
  {
    "id": "arXiv:2206.08493",
    "title": "Nonconforming finite elements for the Brinkman and $-\\text{curl}\u0394  \\text{curl}$ problems on cubical meshes",
    "abstract": "Nonconforming finite elements for the Brinkman and $-\\text{curl}\u0394  \\text{curl}$ problems on cubical meshes",
    "descriptor": "",
    "authors": [
      "Qian Zhang",
      "Min Zhang",
      "Zhimin Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.08493"
  },
  {
    "id": "arXiv:2206.09309",
    "title": "TBraTS: Trusted Brain Tumor Segmentation",
    "abstract": "Comments: 11 pages, 4 figures, Accepted by MICCAI 2022",
    "descriptor": "\nComments: 11 pages, 4 figures, Accepted by MICCAI 2022\n",
    "authors": [
      "Ke Zou",
      "Xuedong Yuan",
      "Xiaojing Shen",
      "Meng Wang",
      "Huazhu Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09309"
  },
  {
    "id": "arXiv:2206.09411",
    "title": "A Stirling-type formula for the distribution of the length of longest  increasing subsequences, applied to finite size corrections to the random  matrix limit",
    "abstract": "Comments: 25 pages, 6 figures, 3 tables; variance discussed in new {\\S}4.4; simplifications in {\\S}3.2: derived kernels have finite rank; improved numerical stabilization in {\\S}3.3; associated table of exact values has been extended for up to $n=1000$",
    "descriptor": "\nComments: 25 pages, 6 figures, 3 tables; variance discussed in new {\\S}4.4; simplifications in {\\S}3.2: derived kernels have finite rank; improved numerical stabilization in {\\S}3.3; associated table of exact values has been extended for up to $n=1000$\n",
    "authors": [
      "Folkmar Bornemann"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.09411"
  },
  {
    "id": "arXiv:2206.09425",
    "title": "Semi-implicit high resolution numerical scheme for conservation laws",
    "abstract": "Comments: Slightly revised version that is submitted to AMC journal",
    "descriptor": "\nComments: Slightly revised version that is submitted to AMC journal\n",
    "authors": [
      "Peter Frolkovi\u010d",
      "Michal \u017derav\u00fd"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09425"
  },
  {
    "id": "arXiv:2206.09677",
    "title": "GraphFramEx: Towards Systematic Evaluation of Explainability Methods for  Graph Neural Networks",
    "abstract": "Comments: Submitted to Neurips 2022 Conference",
    "descriptor": "\nComments: Submitted to Neurips 2022 Conference\n",
    "authors": [
      "Kenza Amara",
      "Rex Ying",
      "Zitao Zhang",
      "Zhihao Han",
      "Yinan Shan",
      "Ulrik Brandes",
      "Sebastian Schemm",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.09677"
  },
  {
    "id": "arXiv:2206.09769",
    "title": "Test-time image-to-image translation ensembling improves  out-of-distribution generalization in histopathology",
    "abstract": "Comments: Accepted at MICCAI2022 Conference",
    "descriptor": "\nComments: Accepted at MICCAI2022 Conference\n",
    "authors": [
      "Marin Scalbert",
      "Maria Vakalopoulou",
      "Florent Couzini\u00e9-Devy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09769"
  },
  {
    "id": "arXiv:2206.10430",
    "title": "Automatic Pull Request Title Generation",
    "abstract": "Comments: Accepted by the ICSME'22 research track",
    "descriptor": "\nComments: Accepted by the ICSME'22 research track\n",
    "authors": [
      "Ting Zhang",
      "Ivana Clairine Irsan",
      "Ferdian Thung",
      "DongGyun Han",
      "David Lo",
      "Lingxiao Jiang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.10430"
  },
  {
    "id": "arXiv:2206.11804",
    "title": "Rethinking Surgical Instrument Segmentation: A Background Image Can Be  All You Need",
    "abstract": "Comments: 10 pages, MICCAI2022",
    "descriptor": "\nComments: 10 pages, MICCAI2022\n",
    "authors": [
      "An Wang",
      "Mobarakol Islam",
      "Mengya Xu",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11804"
  },
  {
    "id": "arXiv:2206.11844",
    "title": "Quant-BnB: A Scalable Branch-and-Bound Method for Optimal Decision Trees  with Continuous Features",
    "abstract": "Quant-BnB: A Scalable Branch-and-Bound Method for Optimal Decision Trees  with Continuous Features",
    "descriptor": "",
    "authors": [
      "Rahul Mazumder",
      "Xiang Meng",
      "Haoyue Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11844"
  },
  {
    "id": "arXiv:2206.12038",
    "title": "BYOL-S: Learning Self-supervised Speech Representations by Bootstrapping",
    "abstract": "Comments: Submitted to HEAR-PMLR 2021",
    "descriptor": "\nComments: Submitted to HEAR-PMLR 2021\n",
    "authors": [
      "Gasser Elbanna",
      "Neil Scheidwasser-Clow",
      "Mikolaj Kegler",
      "Pierre Beckmann",
      "Karl El Hajal",
      "Milos Cernak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.12038"
  },
  {
    "id": "arXiv:2206.12275",
    "title": "A Literature Review on Serverless Computing",
    "abstract": "A Literature Review on Serverless Computing",
    "descriptor": "",
    "authors": [
      "Jinfeng Wen",
      "Zhenpeng Chen",
      "Xuanzhe Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.12275"
  },
  {
    "id": "arXiv:2206.12512",
    "title": "FetReg2021: A Challenge on Placental Vessel Segmentation and  Registration in Fetoscopy",
    "abstract": "Comments: Submitted to MedIA (Medical Image Analysis)",
    "descriptor": "\nComments: Submitted to MedIA (Medical Image Analysis)\n",
    "authors": [
      "Sophia Bano",
      "Alessandro Casella",
      "Francisco Vasconcelos",
      "Abdul Qayyum",
      "Abdesslam Benzinou",
      "Moona Mazher",
      "Fabrice Meriaudeau",
      "Chiara Lena",
      "Ilaria Anita Cintorrino",
      "Gaia Romana De Paolis",
      "Jessica Biagioli",
      "Daria Grechishnikova",
      "Jing Jiao",
      "Bizhe Bai",
      "Yanyan Qiao",
      "Binod Bhattarai",
      "Rebati Raman Gaire",
      "Ronast Subedi",
      "Eduard Vazquez",
      "Szymon P\u0142otka",
      "Aneta Lisowska",
      "Arkadiusz Sitek",
      "George Attilakos",
      "Ruwan Wimalasundera",
      "Anna L David",
      "Dario Paladini",
      "Jan Deprest",
      "Elena De Momi",
      "Leonardo S Mattos",
      "Sara Moccia",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12512"
  },
  {
    "id": "arXiv:2206.12531",
    "title": "Maximum independent set (stable set) problem: A mathematical programming  model with valid inequalities and computational testing",
    "abstract": "Comments: Corrected a few typos in the previous version.. Added more information about computational testing",
    "descriptor": "\nComments: Corrected a few typos in the previous version.. Added more information about computational testing\n",
    "authors": [
      "Prabhu Manyem"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.12531"
  },
  {
    "id": "arXiv:2206.12797",
    "title": "Impact of Channel Memory on the Data Freshness",
    "abstract": "Impact of Channel Memory on the Data Freshness",
    "descriptor": "",
    "authors": [
      "Qixing Guan",
      "Xiaoli Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12797"
  },
  {
    "id": "arXiv:2206.12901",
    "title": "Noise-aware Physics-informed Machine Learning for Robust PDE Discovery",
    "abstract": "Comments: 13 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice",
    "descriptor": "\nComments: 13 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice\n",
    "authors": [
      "Pongpisit Thanasutives",
      "Takeshi Morita",
      "Masayuki Numao",
      "Ken-ichi Fukui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.12901"
  },
  {
    "id": "arXiv:2206.13187",
    "title": "Implementing a Chatbot Solution for Learning Management System",
    "abstract": "Comments: Keywords: education, eLearning, chatbot, machine learning, artificial intelligence",
    "descriptor": "\nComments: Keywords: education, eLearning, chatbot, machine learning, artificial intelligence\n",
    "authors": [
      "Dimitrios Chaskopoulos",
      "Jonas Eilertsen H\u00e6gdahl",
      "Petter Sagvold",
      "Claire Trinquet",
      "Maryam Edalati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13187"
  },
  {
    "id": "arXiv:2206.13238",
    "title": "SR-DEM: an efficient discrete element method framework for particles  with surface of revolution",
    "abstract": "Comments: Manuscript for submission to Elsevier Journal - Powder Technology",
    "descriptor": "\nComments: Manuscript for submission to Elsevier Journal - Powder Technology\n",
    "authors": [
      "Fei-Liang Yuan",
      "Martin Sommerfeld",
      "Berend van Wachem"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2206.13238"
  },
  {
    "id": "arXiv:2206.13318",
    "title": "Key-frame Guided Network for Thyroid Nodule Recognition using Ultrasound  Videos",
    "abstract": "Key-frame Guided Network for Thyroid Nodule Recognition using Ultrasound  Videos",
    "descriptor": "",
    "authors": [
      "Yuchen Wang",
      "Zhongyu Li",
      "Xiangxiang Cui",
      "Liangliang Zhang",
      "Xiang Luo",
      "Meng Yang",
      "Shi Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13318"
  },
  {
    "id": "arXiv:2206.13348",
    "title": "A Novel Unified Self-alignment Method of SINS Based on FGO",
    "abstract": "Comments: 9 pages, Journal Papers",
    "descriptor": "\nComments: 9 pages, Journal Papers\n",
    "authors": [
      "Hanwen Zhou",
      "Xiufen Ye"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.13348"
  },
  {
    "id": "arXiv:2206.13358",
    "title": "FIDO2 With Two Displays$\\unicode{x2013}$Or How to Protect  Security-Critical Web Transactions Against Malware Attacks",
    "abstract": "FIDO2 With Two Displays$\\unicode{x2013}$Or How to Protect  Security-Critical Web Transactions Against Malware Attacks",
    "descriptor": "",
    "authors": [
      "Timon Hackenjos",
      "Benedikt Wagner",
      "Julian Herr",
      "Jochen Rill",
      "Marek Wehmer",
      "Niklas Goerke",
      "Ingmar Baumgart"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.13358"
  },
  {
    "id": "arXiv:2206.13398",
    "title": "An Efficient Industrial Federated Learning Framework for AIoT: A Face  Recognition Application",
    "abstract": "Comments: FL-IJCAL'22 Accepted Paper",
    "descriptor": "\nComments: FL-IJCAL'22 Accepted Paper\n",
    "authors": [
      "Youlong Ding",
      "Xueyang Wu",
      "Zhitao Li",
      "Zeheng Wu",
      "Shengqi Tan",
      "Qian Xu",
      "Weike Pan",
      "Qiang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13398"
  },
  {
    "id": "arXiv:2206.13644",
    "title": "Feature Refinement to Improve High Resolution Image Inpainting",
    "abstract": "Comments: 5 pages, 5 figures, Published in CVPR Workshop on Computer Vision for Augmented and Virtual Reality, New Orleans, LA, 2022",
    "descriptor": "\nComments: 5 pages, 5 figures, Published in CVPR Workshop on Computer Vision for Augmented and Virtual Reality, New Orleans, LA, 2022\n",
    "authors": [
      "Prakhar Kulshreshtha",
      "Brian Pugh",
      "Salma Jiddi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.13644"
  },
  {
    "id": "arXiv:2206.13689",
    "title": "Tiny-Sepformer: A Tiny Time-Domain Transformer Network for Speech  Separation",
    "abstract": "Comments: Accepted by Interspeech 2022",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Jian Luo",
      "Jianzong Wang",
      "Ning Cheng",
      "Edward Xiao",
      "Xulong Zhang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.13689"
  },
  {
    "id": "arXiv:2206.13737",
    "title": "Adversarial Consistency for Single Domain Generalization in Medical  Image Segmentation",
    "abstract": "Comments: MICCAI2022 accpted",
    "descriptor": "\nComments: MICCAI2022 accpted\n",
    "authors": [
      "Yanwu Xu",
      "Shaoan Xie",
      "Maxwell Reynolds",
      "Matthew Ragoza",
      "Mingming Gong",
      "Kayhan Batmanghelich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13737"
  },
  {
    "id": "arXiv:2206.13873",
    "title": "High-order Lohner-type algorithm for rigorous computation of Poincar\u00e9  maps in systems of Delay Differential Equations with several delays",
    "abstract": "High-order Lohner-type algorithm for rigorous computation of Poincar\u00e9  maps in systems of Delay Differential Equations with several delays",
    "descriptor": "",
    "authors": [
      "Robert Szczelina",
      "Piotr Zgliczy\u0144ski"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.13873"
  },
  {
    "id": "arXiv:2206.13879",
    "title": "Optimal analysis of finite element methods for the stochastic Stokes  equations",
    "abstract": "Optimal analysis of finite element methods for the stochastic Stokes  equations",
    "descriptor": "",
    "authors": [
      "Buyang Li",
      "Shu Ma",
      "Weiwei Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.13879"
  },
  {
    "id": "arXiv:2206.13947",
    "title": "Long Range Language Modeling via Gated State Spaces",
    "abstract": "Long Range Language Modeling via Gated State Spaces",
    "descriptor": "",
    "authors": [
      "Harsh Mehta",
      "Ankit Gupta",
      "Ashok Cutkosky",
      "Behnam Neyshabur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.13947"
  },
  {
    "id": "arXiv:2206.14142",
    "title": "Let the paintings play",
    "abstract": "Let the paintings play",
    "descriptor": "",
    "authors": [
      "Paola Gervasio",
      "Alfio Quarteroni",
      "Daniele Cassani"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.14142"
  },
  {
    "id": "arXiv:2206.14286",
    "title": "TPU-KNN: K Nearest Neighbor Search at Peak FLOP/s",
    "abstract": "TPU-KNN: K Nearest Neighbor Search at Peak FLOP/s",
    "descriptor": "",
    "authors": [
      "Felix Chern",
      "Blake Hechtman",
      "Andy Davis",
      "Ruiqi Guo",
      "David Majnemer",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14286"
  },
  {
    "id": "arXiv:2206.14323",
    "title": "A wideband generalization of the near-field region for extremely large  phased-arrays",
    "abstract": "A wideband generalization of the near-field region for extremely large  phased-arrays",
    "descriptor": "",
    "authors": [
      "Nitish Deshpande",
      "Miguel R. Castellanos",
      "Saeed R. Khosravirad",
      "Jinfeng Du",
      "Harish Viswanathan",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14323"
  },
  {
    "id": "arXiv:2206.14329",
    "title": "On the R\u00e9nyi Cross-Entropy",
    "abstract": "Comments: To appear in the Proceedings of CWIT'22",
    "descriptor": "\nComments: To appear in the Proceedings of CWIT'22\n",
    "authors": [
      "Ferenc Cole Thierrin",
      "Fady Alajaji",
      "Tam\u00e1s Linder"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14329"
  },
  {
    "id": "arXiv:2206.14359",
    "title": "TE2Rules: Extracting Rule Lists from Tree Ensembles",
    "abstract": "TE2Rules: Extracting Rule Lists from Tree Ensembles",
    "descriptor": "",
    "authors": [
      "G Roshan Lal",
      "Xiaotong Chen",
      "Varun Mithal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14359"
  },
  {
    "id": "arXiv:2206.14362",
    "title": "Lower Bounds on the Error Probability for Invariant Causal Prediction",
    "abstract": "Comments: Accepted to the 2022 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)",
    "descriptor": "\nComments: Accepted to the 2022 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)\n",
    "authors": [
      "Austin Goddard",
      "Yu Xiang",
      "Ilya Soloveychik"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.14362"
  },
  {
    "id": "arXiv:2206.14366",
    "title": "Knowledge Distillation of Transformer-based Language Models Revisited",
    "abstract": "Knowledge Distillation of Transformer-based Language Models Revisited",
    "descriptor": "",
    "authors": [
      "Chengqiang Lu",
      "Jianwei Zhang",
      "Yunfei Chu",
      "Zhengyu Chen",
      "Jingren Zhou",
      "Fei Wu",
      "Haiqing Chen",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14366"
  },
  {
    "id": "arXiv:2206.14421",
    "title": "Cyclical Kernel Adaptive Metropolis",
    "abstract": "Cyclical Kernel Adaptive Metropolis",
    "descriptor": "",
    "authors": [
      "Jianan Canal Li",
      "Yimeng Zeng",
      "Wentao Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14421"
  },
  {
    "id": "arXiv:2206.14429",
    "title": "Equilibria and Convergence in Fire Sale Games",
    "abstract": "Equilibria and Convergence in Fire Sale Games",
    "descriptor": "",
    "authors": [
      "Nils Bertschinger",
      "Martin Hoefer",
      "Simon Krogmann",
      "Pascal Lenzner",
      "Steffen Schuldenzucker",
      "Lisa Wilhelmi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.14429"
  },
  {
    "id": "arXiv:2206.14516",
    "title": "On Hull-Variation Problem of Equivalent Linear Codes",
    "abstract": "Comments: 32 pages. maximal hull dimension introduced",
    "descriptor": "\nComments: 32 pages. maximal hull dimension introduced\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14516"
  }
]
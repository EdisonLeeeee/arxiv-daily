[
  {
    "id": "arXiv:2207.10078",
    "title": "The sparse representation related with fractional heat equations",
    "abstract": "This study introduces pre-orthogonal adaptive Fourier decomposition (POAFD)\nto obtain approximations and numerical solutions to the fractional Laplacian\ninitial value problem and the extension problem of Caffarelli and Silvestre\n(generalized Poisson equation). The method, as the first step, expands the\ninitial data function into a sparse series of the fundamental solutions with\nfast convergence, and, as the second step, makes use the semigroup or the\nreproducing kernel property of each of the expanding entries. Experiments show\neffectiveness and efficiency of the proposed series solutions.",
    "descriptor": "",
    "authors": [
      "Pengtao Li",
      "Tao Qian",
      "Ieng Tak Leong",
      "Wei Qu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10078"
  },
  {
    "id": "arXiv:2207.10079",
    "title": "On continuum modeling of cell aggregation phenomena",
    "abstract": "Cellular aggregates play a significant role in the evolution of biological\nsystems such as tumor growth, tissue spreading, wound healing, and biofilm\nformation. Analysis of such biological systems, in principle, includes\nexamining the interplay of cell-cell interactions together with the cell-matrix\ninteraction. These two interaction types mainly drive the dynamics of cellular\naggregates which is intrinsically out of equilibrium. Here we propose a\nnon-linear continuum mechanics formulation and the corresponding finite element\nsimulation framework to model the physics of cellular aggregate formation. As\nan example, we focus in particular on the process of bacterial colony formation\nas recently studied by Kuan et al. Thereby we describe the aggregation process\nas an active phase separation phenomenon. We develop a Lagrangian continuum\ndescription of the problem which yields a substantial simplification to the\nformulations of the governing equations. Due to the presence of spatial Hessian\nand Laplacian operators, a gradient-enhanced approach is required to\nincorporate C1 continuity. In addition, a robust and efficient finite element\nformulation of the problem is provided. Taylor-Hood finite elements are\nutilized for the implementation to avoid instabilities related to the LBB\ncondition. Finally, through a set of numerical examples, the influence of\nvarious parameters on the dynamics of the cellular aggregate formation is\ninvestigated. Our proposed methodology furnishes a general framework for the\ninvestigation of the rheology and non-equilibrium dynamics of cellular\naggregates.",
    "descriptor": "",
    "authors": [
      "Soheil Firooz",
      "Stefan Kaessmair",
      "Vasily Zaburdaev",
      "Ali Javili",
      "Paul Steinmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10079"
  },
  {
    "id": "arXiv:2207.10081",
    "title": "What Do We Maximize in Self-Supervised Learning?",
    "abstract": "In this paper, we examine self-supervised learning methods, particularly\nVICReg, to provide an information-theoretical understanding of their\nconstruction. As a first step, we demonstrate how information-theoretic\nquantities can be obtained for a deterministic network, offering a possible\nalternative to prior work that relies on stochastic models. This enables us to\ndemonstrate how VICReg can be (re)discovered from first principles and its\nassumptions about data distribution. Furthermore, we empirically demonstrate\nthe validity of our assumptions, confirming our novel understanding of VICReg.\nFinally, we believe that the derivation and insights we obtain can be\ngeneralized to many other SSL methods, opening new avenues for theoretical and\npractical understanding of SSL and transfer learning.",
    "descriptor": "",
    "authors": [
      "Ravid Shwartz-Ziv",
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10081"
  },
  {
    "id": "arXiv:2207.10082",
    "title": "Model Compression for Resource-Constrained Mobile Robots",
    "abstract": "The number of mobile robots with constrained computing resources that need to\nexecute complex machine learning models has been increasing during the past\ndecade. Commonly, these robots rely on edge infrastructure accessible over\nwireless communication to execute heavy computational complex tasks. However,\nthe edge might become unavailable and, consequently, oblige the execution of\nthe tasks on the robot. This work focuses on making it possible to execute the\ntasks on the robots by reducing the complexity and the total number of\nparameters of pre-trained computer vision models. This is achieved by using\nmodel compression techniques such as Pruning and Knowledge Distillation. These\ncompression techniques have strong theoretical and practical foundations, but\ntheir combined usage has not been widely explored in the literature. Therefore,\nthis work especially focuses on investigating the effects of combining these\ntwo compression techniques. The results of this work reveal that up to 90% of\nthe total number of parameters of a computer vision model can be removed\nwithout any considerable reduction in the model's accuracy.",
    "descriptor": "\nComments: In Proceedings AREA 2022, arXiv:2207.09058\n",
    "authors": [
      "Timotheos Souroulla",
      "Alberto Hata",
      "Ahmad Terra",
      "\u00d6zer \u00d6zkahraman",
      "Rafia Inam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10082"
  },
  {
    "id": "arXiv:2207.10083",
    "title": "Mixed-Precision Inference Quantization: Radically Towards Faster  inference speed, Lower Storage requirement, and Lower Loss",
    "abstract": "Based on the model's resilience to computational noise, model quantization is\nimportant for compressing models and improving computing speed. Existing\nquantization techniques rely heavily on experience and \"fine-tuning\" skills. In\nthe majority of instances, the quantization model has a larger loss than a full\nprecision model. This study provides a methodology for acquiring a\nmixed-precise quantization model with a lower loss than the full precision\nmodel. In addition, the analysis demonstrates that, throughout the inference\nprocess, the loss function is mostly affected by the noise of the layer inputs.\nIn particular, we will demonstrate that neural networks with massive identity\nmappings are resistant to the quantization method. It is also difficult to\nimprove the performance of these networks using quantization.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.05137\n",
    "authors": [
      "Daning Cheng",
      "Wenguang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10083"
  },
  {
    "id": "arXiv:2207.10106",
    "title": "World Robot Challenge 2020 -- Partner Robot: A Data-Driven Approach for  Room Tidying with Mobile Manipulator",
    "abstract": "Tidying up a household environment using a mobile manipulator poses various\nchallenges in robotics, such as adaptation to large real-world environmental\nvariations, and safe and robust deployment in the presence of humans.The\nPartner Robot Challenge in World Robot Challenge (WRC) 2020, a global\ncompetition held in September 2021, benchmarked tidying tasks in the real home\nenvironments, and importantly, tested for full system performances.For this\nchallenge, we developed an entire household service robot system, which\nleverages a data-driven approach to adapt to numerous edge cases that occur\nduring the execution, instead of classical manual pre-programmed solutions.In\nthis paper, we describe the core ingredients of the proposed robot system,\nincluding visual recognition, object manipulation, and motion planning. Our\nrobot system won the second prize, verifying the effectiveness and potential of\ndata-driven robot systems for mobile manipulation in home environments.",
    "descriptor": "",
    "authors": [
      "Tatsuya Matsushima",
      "Yuki Noguchi",
      "Jumpei Arima",
      "Toshiki Aoki",
      "Yuki Okita",
      "Yuya Ikeda",
      "Koki Ishimoto",
      "Shohei Taniguchi",
      "Yuki Yamashita",
      "Shoichi Seto",
      "Shixiang Shane Gu",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10106"
  },
  {
    "id": "arXiv:2207.10120",
    "title": "BRACE: The Breakdancing Competition Dataset for Dance Motion Synthesis",
    "abstract": "Generative models for audio-conditioned dance motion synthesis map music\nfeatures to dance movements. Models are trained to associate motion patterns to\naudio patterns, usually without an explicit knowledge of the human body. This\napproach relies on a few assumptions: strong music-dance correlation,\ncontrolled motion data and relatively simple poses and movements. These\ncharacteristics are found in all existing datasets for dance motion synthesis,\nand indeed recent methods can achieve good results.We introduce a new dataset\naiming to challenge these common assumptions, compiling a set of dynamic dance\nsequences displaying complex human poses. We focus on breakdancing which\nfeatures acrobatic moves and tangled postures. We source our data from the Red\nBull BC One competition videos. Estimating human keypoints from these videos is\ndifficult due to the complexity of the dance, as well as the multiple moving\ncameras recording setup. We adopt a hybrid labelling pipeline leveraging deep\nestimation models as well as manual annotations to obtain good quality keypoint\nsequences at a reduced cost. Our efforts produced the BRACE dataset, which\ncontains over 3 hours and 30 minutes of densely annotated poses. We test\nstate-of-the-art methods on BRACE, showing their limitations when evaluated on\ncomplex sequences. Our dataset can readily foster advance in dance motion\nsynthesis. With intricate poses and swift movements, models are forced to go\nbeyond learning a mapping between modalities and reason more effectively about\nbody structure and movements.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Davide Moltisanti",
      "Jinyi Wu",
      "Bo Dai",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10120"
  },
  {
    "id": "arXiv:2207.10123",
    "title": "Animation from Blur: Multi-modal Blur Decomposition with Motion Guidance",
    "abstract": "We study the challenging problem of recovering detailed motion from a single\nmotion-blurred image. Existing solutions to this problem estimate a single\nimage sequence without considering the motion ambiguity for each region.\nTherefore, the results tend to converge to the mean of the multi-modal\npossibilities. In this paper, we explicitly account for such motion ambiguity,\nallowing us to generate multiple plausible solutions all in sharp detail. The\nkey idea is to introduce a motion guidance representation, which is a compact\nquantization of 2D optical flow with only four discrete motion directions.\nConditioned on the motion guidance, the blur decomposition is led to a\nspecific, unambiguous solution by using a novel two-stage decomposition\nnetwork. We propose a unified framework for blur decomposition, which supports\nvarious interfaces for generating our motion guidance, including human input,\nmotion information from adjacent video frames, and learning from a video\ndataset. Extensive experiments on synthesized datasets and real-world data show\nthat the proposed framework is qualitatively and quantitatively superior to\nprevious methods, and also offers the merit of producing physically plausible\nand diverse solutions. Code is available at\nhttps://github.com/zzh-tech/Animation-from-Blur.",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Zhihang Zhong",
      "Xiao Sun",
      "Zhirong Wu",
      "Yinqiang Zheng",
      "Stephen Lin",
      "Imari Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10123"
  },
  {
    "id": "arXiv:2207.10128",
    "title": "Towards Better Evaluation for Dynamic Link Prediction",
    "abstract": "There has been recent success in learning from static graphs, but despite\ntheir prevalence, learning from time-evolving graphs remains challenging. We\ndesign new, more stringent evaluation procedures for link prediction specific\nto dynamic graphs, which reflect real-world considerations and can better\ncompare different methods' strengths and weaknesses. In particular, we create\ntwo visualization techniques to understand the recurring patterns of edges over\ntime. They show that many edges reoccur at later time steps. Therefore, we\npropose a pure memorization baseline called EdgeBank. It achieves surprisingly\nstrong performance across multiple settings, partly due to the easy negative\nedges used in the current evaluation setting. Hence, we introduce two more\nchallenging negative sampling strategies that improve robustness and can better\nmatch real-world applications. Lastly, we introduce five new dynamic graph\ndatasets from a diverse set of domains missing from current benchmarks,\nproviding new challenges and opportunities for future research.",
    "descriptor": "",
    "authors": [
      "Farimah Poursafaei",
      "Shenyang Huang",
      "Kellin Pelrine",
      "Reihaneh Rabbany"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10128"
  },
  {
    "id": "arXiv:2207.10129",
    "title": "Dynamic Load Altering EV Attacks Against Power Grid Frequency Control",
    "abstract": "Driven by the necessity to combat climate change, Electric Vehicles (EV) are\nbeing deployed to take advantage of their ability in reducing emissions\ngenerated by the transportation sector. This deployment has left the power grid\nvulnerable to attacks through the EV infrastructure. This paper is written from\nan attacker\\'s perspective and proposes a dynamic load altering strategy\nthrough manipulating EV charging to destabilize the grid. The attack is\nformulated based on feedback control theory, i.e., designing an attack based on\nLinear Matrix Inequalities (LMIs). After the stability metric and controller\ndesign have been established, we demonstrate our attack method against the\nKundur 2 area grid. The attack scenario includes a cap of 200 MW EV load\ncontrolled by the attacker. However, the results show that even with this\nlimitation, the attacker would be successful in pushing the grid toward\ninstability and blackout.",
    "descriptor": "\nComments: \"\\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.\"\n",
    "authors": [
      "Mohammad Ali Sayed",
      "Mohsen Ghafouri",
      "Mourad Debbabi",
      "Chadi Assi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10129"
  },
  {
    "id": "arXiv:2207.10130",
    "title": "Latent Discriminant deterministic Uncertainty",
    "abstract": "Predictive uncertainty estimation is essential for deploying Deep Neural\nNetworks in real-world autonomous systems. However, most successful approaches\nare computationally intensive. In this work, we attempt to address these\nchallenges in the context of autonomous driving perception tasks. Recently\nproposed Deterministic Uncertainty Methods (DUM) can only partially meet such\nrequirements as their scalability to complex computer vision tasks is not\nobvious. In this work we advance a scalable and effective DUM for\nhigh-resolution semantic segmentation, that relaxes the Lipschitz constraint\ntypically hindering practicality of such architectures. We learn a discriminant\nlatent space by leveraging a distinction maximization layer over an\narbitrarily-sized set of trainable prototypes. Our approach achieves\ncompetitive results over Deep Ensembles, the state-of-the-art for uncertainty\nprediction, on image classification, segmentation and monocular depth\nestimation tasks. Our code is available at https://github.com/ENSTA-U2IS/LDU",
    "descriptor": "\nComments: 24 pages. Accepted at ECCV 2022\n",
    "authors": [
      "Gianni Franchi",
      "Xuanlong Yu",
      "Andrei Bursuc",
      "Emanuel Aldea",
      "Severine Dubuisson",
      "David Filliat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10130"
  },
  {
    "id": "arXiv:2207.10131",
    "title": "Continual Variational Autoencoder Learning via Online Cooperative  Memorization",
    "abstract": "Due to their inference, data representation and reconstruction properties,\nVariational Autoencoders (VAE) have been successfully used in continual\nlearning classification tasks. However, their ability to generate images with\nspecifications corresponding to the classes and databases learned during\nContinual Learning (CL) is not well understood and catastrophic forgetting\nremains a significant challenge. In this paper, we firstly analyze the\nforgetting behaviour of VAEs by developing a new theoretical framework that\nformulates CL as a dynamic optimal transport problem. This framework proves\napproximate bounds to the data likelihood without requiring the task\ninformation and explains how the prior knowledge is lost during the training\nprocess. We then propose a novel memory buffering approach, namely the Online\nCooperative Memorization (OCM) framework, which consists of a Short-Term Memory\n(STM) that continually stores recent samples to provide future information for\nthe model, and a Long-Term Memory (LTM) aiming to preserve a wide diversity of\nsamples. The proposed OCM transfers certain samples from STM to LTM according\nto the information diversity selection criterion without requiring any\nsupervised signals. The OCM framework is then combined with a dynamic VAE\nexpansion mixture network for further enhancing its performance.",
    "descriptor": "\nComments: Accepted by European Conference on Computer Vision 2022 (ECCV 2022)\n",
    "authors": [
      "Fei Ye",
      "Adrian G. Bors"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10131"
  },
  {
    "id": "arXiv:2207.10137",
    "title": "A Generalized & Robust Framework For Timestamp Supervision in Temporal  Action Segmentation",
    "abstract": "In temporal action segmentation, Timestamp supervision requires only a\nhandful of labelled frames per video sequence. For unlabelled frames, previous\nworks rely on assigning hard labels, and performance rapidly collapses under\nsubtle violations of the annotation assumptions. We propose a novel\nExpectation-Maximization (EM) based approach that leverages the label\nuncertainty of unlabelled frames and is robust enough to accommodate possible\nannotation errors. With accurate timestamp annotations, our proposed method\nproduces SOTA results and even exceeds the fully-supervised setup in several\nmetrics and datasets. When applied to timestamp annotations with missing action\nsegments, our method presents stable performance. To further test our\nformulation's robustness, we introduce the new challenging annotation setup of\nSkip-tag supervision. This setup relaxes constraints and requires annotations\nof any fixed number of random frames in a video, making it more flexible than\nTimestamp supervision while remaining competitive.",
    "descriptor": "",
    "authors": [
      "Rahul Rahaman",
      "Dipika Singhania",
      "Alexandre Thiery",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10137"
  },
  {
    "id": "arXiv:2207.10139",
    "title": "Mixed finite element method for a second order Dirichlet boundary  control problem",
    "abstract": "The main aim of this article is to analyze mixed finite element method for\nthe second order Dirichlet boundary control problem. Therein, we develop both a\npriori and a posteriori error analysis using the energy space based approach.\nWe obtain optimal order a priori error estimates in the energy norm and\n$L^2$-norm with the help of auxiliary problems. The reliability and the\nefficiency of proposed a posteriori error estimator is discussed using the\nHelmholtz decomposition. Numerical experiments are presented to confirm the\ntheoretical findings.",
    "descriptor": "",
    "authors": [
      "Divay Garg",
      "Kamana Porwal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10139"
  },
  {
    "id": "arXiv:2207.10141",
    "title": "AudioScopeV2: Audio-Visual Attention Architectures for Calibrated  Open-Domain On-Screen Sound Separation",
    "abstract": "We introduce AudioScopeV2, a state-of-the-art universal audio-visual\non-screen sound separation system which is capable of learning to separate\nsounds and associate them with on-screen objects by looking at in-the-wild\nvideos. We identify several limitations of previous work on audio-visual\non-screen sound separation, including the coarse resolution of spatio-temporal\nattention, poor convergence of the audio separation model, limited variety in\ntraining and evaluation data, and failure to account for the trade off between\npreservation of on-screen sounds and suppression of off-screen sounds. We\nprovide solutions to all of these issues. Our proposed cross-modal and\nself-attention network architectures capture audio-visual dependencies at a\nfiner resolution over time, and we also propose efficient separable variants\nthat are capable of scaling to longer videos without sacrificing much\nperformance. We also find that pre-training the separation model only on audio\ngreatly improves results. For training and evaluation, we collected new human\nannotations of onscreen sounds from a large database of in-the-wild videos\n(YFCC100M). This new dataset is more diverse and challenging. Finally, we\npropose a calibration procedure that allows exact tuning of on-screen\nreconstruction versus off-screen suppression, which greatly simplifies\ncomparing performance between models with different operating points. Overall,\nour experimental results show marked improvements in on-screen separation\nperformance under much more general conditions than previous methods with\nminimal additional computational complexity.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Efthymios Tzinis",
      "Scott Wisdom",
      "Tal Remez",
      "John R. Hershey"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10141"
  },
  {
    "id": "arXiv:2207.10143",
    "title": "What Made This Test Flake? Pinpointing Classes Responsible for Test  Flakiness",
    "abstract": "Flaky tests are defined as tests that manifest non-deterministic behaviour by\npassing and failing intermittently for the same version of the code. These\ntests cripple continuous integration with false alerts that waste developers'\ntime and break their trust in regression testing. To mitigate the effects of\nflakiness, both researchers and industrial experts proposed strategies and\ntools to detect and isolate flaky tests. However, flaky tests are rarely fixed\nas developers struggle to localise and understand their causes. Additionally,\ndevelopers working with large codebases often need to know the sources of\nnon-determinism to preserve code quality, i.e., avoid introducing technical\ndebt linked with non-deterministic behaviour, and to avoid introducing new\nflaky tests. To aid with these tasks, we propose re-targeting Fault\nLocalisation techniques to the flaky component localisation problem, i.e.,\npinpointing program classes that cause the non-deterministic behaviour of flaky\ntests. In particular, we employ Spectrum-Based Fault Localisation (SBFL), a\ncoverage-based fault localisation technique commonly adopted for its simplicity\nand effectiveness. We also utilise other data sources, such as change history\nand static code metrics, to further improve the localisation. Our results show\nthat augmenting SBFL with change and code metrics ranks flaky classes in the\ntop-1 and top-5 suggestions, in 26% and 47% of the cases. Overall, we\nsuccessfully reduced the average number of classes inspected to locate the\nfirst flaky class to 19% of the total number of classes covered by flaky tests.\nOur results also show that localisation methods are effective in major\nflakiness categories, such as concurrency and asynchronous waits, indicating\ntheir general ability to identify flaky components.",
    "descriptor": "\nComments: Accepted at the 38th IEEE International Conference on Software Maintenance and Evolution (ICSME)\n",
    "authors": [
      "Sarra Habchi",
      "Guillaume Haben",
      "Jeongju Sohn",
      "Adriano Franci",
      "Mike Papadakis",
      "Maxime Cordy",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.10143"
  },
  {
    "id": "arXiv:2207.10148",
    "title": "Learning Deformable Object Manipulation from Expert Demonstrations",
    "abstract": "We present a novel Learning from Demonstration (LfD) method, Deformable\nManipulation from Demonstrations (DMfD), to solve deformable manipulation tasks\nusing states or images as inputs, given expert demonstrations. Our method uses\ndemonstrations in three different ways, and balances the trade-off between\nexploring the environment online and using guidance from experts to explore\nhigh dimensional spaces effectively. We test DMfD on a set of representative\nmanipulation tasks for a 1-dimensional rope and a 2-dimensional cloth from the\nSoftGym suite of tasks, each with state and image observations. Our method\nexceeds baseline performance by up to 12.9% for state-based tasks and up to\n33.44% on image-based tasks, with comparable or better robustness to\nrandomness. Additionally, we create two challenging environments for folding a\n2D cloth using image-based observations, and set a performance benchmark for\nthem. We deploy DMfD on a real robot with a minimal loss in normalized\nperformance during real-world execution compared to simulation (~6%). Source\ncode is on github.com/uscresl/dmfd",
    "descriptor": "\nComments: Accepted to IEEE Robotics & Automation Letters (RA-L) and IEEE IROS 2022. Project website: this https URL\n",
    "authors": [
      "Gautam Salhotra",
      "I-Chun Arthur Liu",
      "Marcus Dominguez-Kuhne",
      "Gaurav S. Sukhatme"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10148"
  },
  {
    "id": "arXiv:2207.10149",
    "title": "Digraphwave: Scalable Extraction of Structural Node Embeddings via  Diffusion on Directed Graphs",
    "abstract": "Structural node embeddings, vectors capturing local connectivity information\nfor each node in a graph, have many applications in data mining and machine\nlearning, e.g., network alignment and node classification, clustering and\nanomaly detection. For the analysis of directed graphs, e.g., transactions\ngraphs, communication networks and social networks, the capability to capture\ndirectional information in the structural node embeddings is highly desirable,\nas is scalability of the embedding extraction method. Most existing methods are\nnevertheless only designed for undirected graph. Therefore, we present\nDigraphwave -- a scalable algorithm for extracting structural node embeddings\non directed graphs. The Digraphwave embeddings consist of compressed diffusion\npattern signatures, which are twice enhanced to increase their discriminate\ncapacity. By proving a lower bound on the heat contained in the local vicinity\nof a diffusion initialization node, theoretically justified diffusion timescale\nvalues are established, and Digraphwave is left with only two easy-to-interpret\nhyperparameters: the embedding dimension and a neighbourhood resolution\nspecifier. In our experiments, the two embedding enhancements, named\ntransposition and aggregation, are shown to lead to a significant increase in\nmacro F1 score for classifying automorphic identities, with Digraphwave\noutperforming all other structural embedding baselines. Moreover, Digraphwave\neither outperforms or matches the performance of all baselines on real graph\ndatasets, displaying a particularly large performance gain in a network\nalignment task, while also being scalable to graphs with millions of nodes and\nedges, running up to 30x faster than a previous diffusion pattern based method\nand with a fraction of the memory consumption.",
    "descriptor": "",
    "authors": [
      "Ciwan Ceylan",
      "Kambiz Ghoorchian",
      "Danica Kragic"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10149"
  },
  {
    "id": "arXiv:2207.10150",
    "title": "Tackling Long-Tailed Category Distribution Under Domain Shifts",
    "abstract": "Machine learning models fail to perform well on real-world applications when\n1) the category distribution P(Y) of the training dataset suffers from\nlong-tailed distribution and 2) the test data is drawn from different\nconditional distributions P(X|Y). Existing approaches cannot handle the\nscenario where both issues exist, which however is common for real-world\napplications. In this study, we took a step forward and looked into the problem\nof long-tailed classification under domain shifts. We designed three novel core\nfunctional blocks including Distribution Calibrated Classification Loss,\nVisual-Semantic Mapping and Semantic-Similarity Guided Augmentation.\nFurthermore, we adopted a meta-learning framework which integrates these three\nblocks to improve domain generalization on unseen target domains. Two new\ndatasets were proposed for this problem, named AWA2-LTS and ImageNet-LTS. We\nevaluated our method on the two datasets and extensive experimental results\ndemonstrate that our proposed method can achieve superior performance over\nstate-of-the-art long-tailed/domain generalization approaches and the\ncombinations. Source codes and datasets can be found at our project page\nhttps://xiaogu.site/LTDS.",
    "descriptor": "\nComments: accepted to ECCV 2022\n",
    "authors": [
      "Xiao Gu",
      "Yao Guo",
      "Zeju Li",
      "Jianing Qiu",
      "Qi Dou",
      "Yuxuan Liu",
      "Benny Lo",
      "Guang-Zhong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10150"
  },
  {
    "id": "arXiv:2207.10152",
    "title": "Automated Kantian Ethics: A Faithful Implementation",
    "abstract": "As we grant artificial intelligence increasing power and independence in\ncontexts like healthcare, policing, and driving, AI faces moral dilemmas but\nlacks the tools to solve them. Warnings from regulators, philosophers, and\ncomputer scientists about the dangers of unethical artificial intelligence have\nspurred interest in automated ethics-i.e., the development of machines that can\nperform ethical reasoning. However, prior work in automated ethics rarely\nengages with philosophical literature. Philosophers have spent centuries\ndebating moral dilemmas so automated ethics will be most nuanced, consistent,\nand reliable when it draws on philosophical literature. In this paper, I\npresent an implementation of automated Kantian ethics that is faithful to the\nKantian philosophical tradition. I formalize Kant's categorical imperative in\nDyadic Deontic Logic, implement this formalization in the Isabelle theorem\nprover, and develop a testing framework to evaluate how well my implementation\ncoheres with expected properties of Kantian ethic. My system is an early step\ntowards philosophically mature ethical AI agents and it can make nuanced\njudgements in complex ethical dilemmas because it is grounded in philosophical\nliterature. Because I use an interactive theorem prover, my system's judgements\nare explainable.",
    "descriptor": "\nComments: 20 pages, 8 figures, to appear in KI: 45th German Conference on Artificial Intelligence\n",
    "authors": [
      "Lavanya Singh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.10152"
  },
  {
    "id": "arXiv:2207.10155",
    "title": "Analysis of the Effect of Low-Overhead Lossy Image Compression on the  Performance of Visual Crowd Counting for Smart City Applications",
    "abstract": "Images and video frames captured by cameras placed throughout smart cities\nare often transmitted over the network to a server to be processed by deep\nneural networks for various tasks. Transmission of raw images, i.e., without\nany form of compression, requires high bandwidth and can lead to congestion\nissues and delays in transmission. The use of lossy image compression\ntechniques can reduce the quality of the images, leading to accuracy\ndegradation. In this paper, we analyze the effect of applying low-overhead\nlossy image compression methods on the accuracy of visual crowd counting, and\nmeasure the trade-off between bandwidth reduction and the obtained accuracy.",
    "descriptor": "",
    "authors": [
      "Arian Bakhtiarnia",
      "B\u0142a\u017cej Leporowski",
      "Lukas Esterle",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10155"
  },
  {
    "id": "arXiv:2207.10156",
    "title": "Structural Causal 3D Reconstruction",
    "abstract": "This paper considers the problem of unsupervised 3D object reconstruction\nfrom in-the-wild single-view images. Due to ambiguity and intrinsic\nill-posedness, this problem is inherently difficult to solve and therefore\nrequires strong regularization to achieve disentanglement of different latent\nfactors. Unlike existing works that introduce explicit regularizations into\nobjective functions, we look into a different space for implicit regularization\n-- the structure of latent space. Specifically, we restrict the structure of\nlatent space to capture a topological causal ordering of latent factors (i.e.,\nrepresenting causal dependency as a directed acyclic graph). We first show that\ndifferent causal orderings matter for 3D reconstruction, and then explore\nseveral approaches to find a task-dependent causal factor ordering. Our\nexperiments demonstrate that the latent space structure indeed serves as an\nimplicit regularization and introduces an inductive bias beneficial for\nreconstruction.",
    "descriptor": "\nComments: ECCV 2022 (32 pages, 22 figures)\n",
    "authors": [
      "Weiyang Liu",
      "Zhen Liu",
      "Liam Paull",
      "Adrian Weller",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10156"
  },
  {
    "id": "arXiv:2207.10157",
    "title": "Visual Knowledge Tracing",
    "abstract": "Each year, thousands of people learn new visual categorization tasks --\nradiologists learn to recognize tumors, birdwatchers learn to distinguish\nsimilar species, and crowd workers learn how to annotate valuable data for\napplications like autonomous driving. As humans learn, their brain updates the\nvisual features it extracts and attend to, which ultimately informs their final\nclassification decisions. In this work, we propose a novel task of tracing the\nevolving classification behavior of human learners as they engage in\nchallenging visual classification tasks. We propose models that jointly extract\nthe visual features used by learners as well as predicting the classification\nfunctions they utilize. We collect three challenging new datasets from real\nhuman learners in order to evaluate the performance of different visual\nknowledge tracing methods. Our results show that our recurrent models are able\nto predict the classification behavior of human learners on three challenging\nmedical image and species identification tasks.",
    "descriptor": "\nComments: 14 pages, 4 figures, 14 supplemental pages, 11 supplemental figures, accepted to European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Neehar Kondapaneni",
      "Pietro Perona",
      "Oisin Mac Aodha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.10157"
  },
  {
    "id": "arXiv:2207.10158",
    "title": "GOCA: Guided Online Cluster Assignment for Self-Supervised Video  Representation Learning",
    "abstract": "Clustering is a ubiquitous tool in unsupervised learning. Most of the\nexisting self-supervised representation learning methods typically cluster\nsamples based on visually dominant features. While this works well for\nimage-based self-supervision, it often fails for videos, which require\nunderstanding motion rather than focusing on background. Using optical flow as\ncomplementary information to RGB can alleviate this problem. However, we\nobserve that a naive combination of the two views does not provide meaningful\ngains. In this paper, we propose a principled way to combine two views.\nSpecifically, we propose a novel clustering strategy where we use the initial\ncluster assignment of each view as prior to guide the final cluster assignment\nof the other view. This idea will enforce similar cluster structures for both\nviews, and the formed clusters will be semantically abstract and robust to\nnoisy inputs coming from each individual view. Additionally, we propose a novel\nregularization strategy to address the feature collapse problem, which is\ncommon in cluster-based self-supervised learning methods. Our extensive\nevaluation shows the effectiveness of our learned representations on downstream\ntasks, e.g., video retrieval and action recognition. Specifically, we\noutperform the state of the art by 7% on UCF and 4% on HMDB for video\nretrieval, and 5% on UCF and 6% on HMDB for video classification",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Huseyin Coskun",
      "Alireza Zareian",
      "Joshua L. Moore",
      "Federico Tombari",
      "Chen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10158"
  },
  {
    "id": "arXiv:2207.10169",
    "title": "Pediatric Bone Age Assessment using Deep Learning Models",
    "abstract": "Bone age assessment (BAA) is a standard method for determining the age\ndifference between skeletal and chronological age. Manual processes are\ncomplicated and necessitate the expertise of experts. This is where deep\nlearning comes into play. In this study, pre-trained models like VGG-16,\nInceptionV3, XceptionNet, and MobileNet are used to assess the bone age of the\ninput data, and their mean average errors are compared and evaluated to see\nwhich model predicts the best.",
    "descriptor": "\nComments: 18 pages, 28 figures, 1 table\n",
    "authors": [
      "Aravinda Raman",
      "Sameena Pathan",
      "Tanweer Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10169"
  },
  {
    "id": "arXiv:2207.10170",
    "title": "Illusionary Attacks on Sequential Decision Makers and Countermeasures",
    "abstract": "Autonomous intelligent agents deployed to the real-world need to be robust\nagainst adversarial attacks on sensory inputs. Existing work in reinforcement\nlearning focuses on minimum-norm perturbation attacks, which were originally\nintroduced to mimic a notion of perceptual invariance in computer vision. In\nthis paper, we note that such minimum-norm perturbation attacks can be\ntrivially detected by victim agents, as these result in observation sequences\nthat are not consistent with the victim agent's actions. Furthermore, many\nreal-world agents, such as physical robots, commonly operate under human\nsupervisors, which are not susceptible to such perturbation attacks. As a\nresult, we propose to instead focus on illusionary attacks, a novel form of\nattack that is consistent with the world model of the victim agent. We provide\na formal definition of this novel attack framework, explore its characteristics\nunder a variety of conditions, and conclude that agents must seek realism\nfeedback to be robust to illusionary attacks.",
    "descriptor": "",
    "authors": [
      "Tim Franzmeyer",
      "Jo\u00e3o F. Henriques",
      "Jakob N. Foerster",
      "Philip H.S. Torr",
      "Adel Bibi",
      "Christian Schroeder de Witt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10170"
  },
  {
    "id": "arXiv:2207.10172",
    "title": "Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw  Puzzles",
    "abstract": "Video Anomaly Detection (VAD) is an important topic in computer vision.\nMotivated by the recent advances in self-supervised learning, this paper\naddresses VAD by solving an intuitive yet challenging pretext task, i.e.,\nspatio-temporal jigsaw puzzles, which is cast as a multi-label fine-grained\nclassification problem. Our method exhibits several advantages over existing\nworks: 1) the spatio-temporal jigsaw puzzles are decoupled in terms of spatial\nand temporal dimensions, responsible for capturing highly discriminative\nappearance and motion features, respectively; 2) full permutations are used to\nprovide abundant jigsaw puzzles covering various difficulty levels, allowing\nthe network to distinguish subtle spatio-temporal differences between normal\nand abnormal events; and 3) the pretext task is tackled in an end-to-end manner\nwithout relying on any pre-trained models. Our method outperforms\nstate-of-the-art counterparts on three public benchmarks. Especially on\nShanghaiTech Campus, the result is superior to reconstruction and\nprediction-based methods by a large margin.",
    "descriptor": "\nComments: Accepted by ECCV'2022\n",
    "authors": [
      "Guodong Wang",
      "Yunhong Wang",
      "Jie Qin",
      "Dongming Zhang",
      "Xiuguo Bao",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10172"
  },
  {
    "id": "arXiv:2207.10174",
    "title": "Scene Recognition with Objectness, Attribute and Category Learning",
    "abstract": "Scene classification has established itself as a challenging research\nproblem. Compared to images of individual objects, scene images could be much\nmore semantically complex and abstract. Their difference mainly lies in the\nlevel of granularity of recognition. Yet, image recognition serves as a key\npillar for the good performance of scene recognition as the knowledge attained\nfrom object images can be used for accurate recognition of scenes. The existing\nscene recognition methods only take the category label of the scene into\nconsideration. However, we find that the contextual information that contains\ndetailed local descriptions are also beneficial in allowing the scene\nrecognition model to be more discriminative. In this paper, we aim to improve\nscene recognition using attribute and category label information encoded in\nobjects. Based on the complementarity of attribute and category labels, we\npropose a Multi-task Attribute-Scene Recognition (MASR) network which learns a\ncategory embedding and at the same time predicts scene attributes. Attribute\nacquisition and object annotation are tedious and time consuming tasks. We\ntackle the problem by proposing a partially supervised annotation strategy in\nwhich human intervention is significantly reduced. The strategy provides a much\nmore cost-effective solution to real world scenarios, and requires considerably\nless annotation efforts. Moreover, we re-weight the attribute predictions\nconsidering the level of importance indicated by the object detected scores.\nUsing the proposed method, we efficiently annotate attribute labels for four\nlarge-scale datasets, and systematically investigate how scene and attribute\nrecognition benefit from each other. The experimental results demonstrate that\nMASR learns a more discriminative representation and achieves competitive\nrecognition performance compared to the state-of-the-art methods",
    "descriptor": "",
    "authors": [
      "Ji Zhang",
      "Jean-Paul Ainam",
      "Li-hui Zhao",
      "Wenai Song",
      "Xin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10174"
  },
  {
    "id": "arXiv:2207.10175",
    "title": "Governor: a Reference Generator for Nonlinear Model Predictive Control  in Legged Robots",
    "abstract": "Model Predictive Control (MPC) approaches are widely used in robotics, since\nthey allow to compute updated trajectories while the robot is moving. They\ngenerally require heuristic references for the tracking terms and proper tuning\nof parameters of the cost function in order to obtain good performance. When\nfor example, a legged robot has to react to disturbances from the environment\n(e.g., recover after a push) or track a certain goal with statically unstable\ngaits, the effectiveness of the algorithm can degrade. In this work we propose\na novel optimization-based Reference Generator, named Governor, which exploits\na Linear Inverted Pendulum model to compute reference trajectories for the\nCenter of Mass, while taking into account the possible under-actuation of a\ngait (e.g. in a trot). The obtained trajectories are used as references for the\ncost function of the Nonlinear MPC presented in our previous work [1]. We also\npresent a formulation that can guarantee a certain response time to reach a\ngoal, without the need to tune the weights of the cost terms. In addition,\nfoothold locations are corrected to drive the robot towards the goal. We\ndemonstrate the effectiveness of our approach both in simulations and\nexperiments in different scenarios with the Aliengo robot.",
    "descriptor": "",
    "authors": [
      "Angelo Bratta",
      "Michele Focchi",
      "Niraj Rathod",
      "Mario Zanon",
      "Alberto Bemporad",
      "Claudio Semini"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10175"
  },
  {
    "id": "arXiv:2207.10180",
    "title": "Controllable and Guided Face Synthesis for Unconstrained Face  Recognition",
    "abstract": "Although significant advances have been made in face recognition (FR), FR in\nunconstrained environments remains challenging due to the domain gap between\nthe semi-constrained training datasets and unconstrained testing scenarios. To\naddress this problem, we propose a controllable face synthesis model (CFSM)\nthat can mimic the distribution of target datasets in a style latent space.\nCFSM learns a linear subspace with orthogonal bases in the style latent space\nwith precise control over the diversity and degree of synthesis. Furthermore,\nthe pre-trained synthesis model can be guided by the FR model, making the\nresulting images more beneficial for FR model training. Besides, target dataset\ndistributions are characterized by the learned orthogonal bases, which can be\nutilized to measure the distributional similarity among face datasets. Our\napproach yields significant performance gains on unconstrained benchmarks, such\nas IJB-B, IJB-C, TinyFace and IJB-S (+5.76% Rank1).",
    "descriptor": "\nComments: to be published in ECCV 2022\n",
    "authors": [
      "Feng Liu",
      "Minchul Kim",
      "Anil Jain",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10180"
  },
  {
    "id": "arXiv:2207.10183",
    "title": "2D GANs Meet Unsupervised Single-view 3D Reconstruction",
    "abstract": "Recent research has shown that controllable image generation based on\npre-trained GANs can benefit a wide range of computer vision tasks. However,\nless attention has been devoted to 3D vision tasks. In light of this, we\npropose a novel image-conditioned neural implicit field, which can leverage 2D\nsupervisions from GAN-generated multi-view images and perform the single-view\nreconstruction of generic objects. Firstly, a novel offline StyleGAN-based\ngenerator is presented to generate plausible pseudo images with full control\nover the viewpoint. Then, we propose to utilize a neural implicit function,\nalong with a differentiable renderer to learn 3D geometry from pseudo images\nwith object masks and rough pose initializations. To further detect the\nunreliable supervisions, we introduce a novel uncertainty module to predict\nuncertainty maps, which remedy the negative effect of uncertain regions in\npseudo images, leading to a better reconstruction performance. The\neffectiveness of our approach is demonstrated through superior single-view 3D\nreconstruction results of generic objects.",
    "descriptor": "\nComments: to be published in ECCV 2022\n",
    "authors": [
      "Feng Liu",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10183"
  },
  {
    "id": "arXiv:2207.10185",
    "title": "An Introduction to Modern Statistical Learning",
    "abstract": "This work in progress aims to provide a unified introduction to statistical\nlearning, building up slowly from classical models like the GMM and HMM to\nmodern neural networks like the VAE and diffusion models. There are today many\ninternet resources that explain this or that new machine-learning algorithm in\nisolation, but they do not (and cannot, in so brief a space) connect these\nalgorithms with each other or with the classical literature on statistical\nmodels, out of which the modern algorithms emerged. Also conspicuously lacking\nis a single notational system which, although unfazing to those already\nfamiliar with the material (like the authors of these posts), raises a\nsignificant barrier to the novice's entry. Likewise, I have aimed to assimilate\nthe various models, wherever possible, to a single framework for inference and\nlearning, showing how (and why) to change one model into another with minimal\nalteration (some of them novel, others from the literature).\nSome background is of course necessary. I have assumed the reader is familiar\nwith basic multivariable calculus, probability and statistics, and linear\nalgebra. The goal of this book is certainly not completeness, but rather to\ndraw a more or less straight-line path from the basics to the extremely\npowerful new models of the last decade. The goal then is to complement, not\nreplace, such comprehensive texts as Bishop's \\emph{Pattern Recognition and\nMachine Learning}, which is now 15 years old.",
    "descriptor": "\nComments: Manuscript draft; 123 pages, 9 figures\n",
    "authors": [
      "Joseph G. Makin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10185"
  },
  {
    "id": "arXiv:2207.10188",
    "title": "Bitwidth-Adaptive Quantization-Aware Neural Network Training: A  Meta-Learning Approach",
    "abstract": "Deep neural network quantization with adaptive bitwidths has gained\nincreasing attention due to the ease of model deployment on various platforms\nwith different resource budgets. In this paper, we propose a meta-learning\napproach to achieve this goal. Specifically, we propose MEBQAT, a simple yet\neffective way of bitwidth-adaptive quantization aware training (QAT) where\nmeta-learning is effectively combined with QAT by redefining meta-learning\ntasks to incorporate bitwidths. After being deployed on a platform, MEBQAT\nallows the (meta-)trained model to be quantized to any candidate bitwidth then\nhelps to conduct inference without much accuracy drop from quantization.\nMoreover, with a few-shot learning scenario, MEBQAT can also adapt a model to\nany bitwidth as well as any unseen target classes by adding conventional\noptimization or metric-based meta-learning. We design variants of MEBQAT to\nsupport both (1) a bitwidth-adaptive quantization scenario and (2) a new\nfew-shot learning scenario where both quantization bitwidths and target classes\nare jointly adapted. We experimentally demonstrate their validity in multiple\nQAT schemes. By comparing their performance to (bitwidth-dedicated) QAT,\nexisting bitwidth adaptive QAT and vanilla meta-learning, we find that merging\nbitwidths into meta-learning tasks achieves a higher level of robustness.",
    "descriptor": "\nComments: 14 pages (except references), 2 figures, to appear in ECCV 2022\n",
    "authors": [
      "Jiseok Youn",
      "Jaehun Song",
      "Hyung-Sin Kim",
      "Saewoong Bahk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10188"
  },
  {
    "id": "arXiv:2207.10192",
    "title": "Building Human Values into Recommender Systems: An Interdisciplinary  Synthesis",
    "abstract": "Recommender systems are the algorithms which select, filter, and personalize\ncontent across many of the worlds largest platforms and apps. As such, their\npositive and negative effects on individuals and on societies have been\nextensively theorized and studied. Our overarching question is how to ensure\nthat recommender systems enact the values of the individuals and societies that\nthey serve. Addressing this question in a principled fashion requires technical\nknowledge of recommender design and operation, and also critically depends on\ninsights from diverse fields including social science, ethics, economics,\npsychology, policy and law. This paper is a multidisciplinary effort to\nsynthesize theory and practice from different perspectives, with the goal of\nproviding a shared language, articulating current design approaches, and\nidentifying open problems. It is not a comprehensive survey of this large\nspace, but a set of highlights identified by our diverse author cohort. We\ncollect a set of values that seem most relevant to recommender systems\noperating across different domains, then examine them from the perspectives of\ncurrent industry practice, measurement, product design, and policy approaches.\nImportant open problems include multi-stakeholder processes for defining values\nand resolving trade-offs, better values-driven measurements, recommender\ncontrols that people use, non-behavioral algorithmic feedback, optimization for\nlong-term outcomes, causal inference of recommender effects, academic-industry\nresearch collaborations, and interdisciplinary policy-making.",
    "descriptor": "",
    "authors": [
      "Jonathan Stray",
      "Alon Halevy",
      "Parisa Assar",
      "Dylan Hadfield-Menell",
      "Craig Boutilier",
      "Amar Ashar",
      "Lex Beattie",
      "Michael Ekstrand",
      "Claire Leibowicz",
      "Connie Moon Sehat",
      "Sara Johansen",
      "Lianne Kerlin",
      "David Vickrey",
      "Spandana Singh",
      "Sanne Vrijenhoek",
      "Amy Zhang",
      "McKane Andrus",
      "Natali Helberger",
      "Polina Proutskova",
      "Tanushree Mitra",
      "Nina Vasan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10192"
  },
  {
    "id": "arXiv:2207.10199",
    "title": "Provably tuning the ElasticNet across instances",
    "abstract": "An important unresolved challenge in the theory of regularization is to set\nthe regularization coefficients of popular techniques like the ElasticNet with\ngeneral provable guarantees. We consider the problem of tuning the\nregularization parameters of Ridge regression, LASSO, and the ElasticNet across\nmultiple problem instances, a setting that encompasses both cross-validation\nand multi-task hyperparameter optimization. We obtain a novel structural result\nfor the ElasticNet which characterizes the loss as a function of the tuning\nparameters as a piecewise-rational function with algebraic boundaries. We use\nthis to bound the structural complexity of the regularized loss functions and\nshow generalization guarantees for tuning the ElasticNet regression\ncoefficients in the statistical setting. We also consider the more challenging\nonline learning setting, where we show vanishing average expected regret\nrelative to the optimal parameter pair. We further extend our results to tuning\nclassification algorithms obtained by thresholding regression fits regularized\nby Ridge, LASSO, or ElasticNet. Our results are the first general\nlearning-theoretic guarantees for this important class of problems that avoid\nstrong assumptions on the data distribution. Furthermore, our guarantees hold\nfor both validation and popular information criterion objectives.",
    "descriptor": "",
    "authors": [
      "Maria-Florina Balcan",
      "Mikhail Khodak",
      "Dravyansh Sharma",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.10199"
  },
  {
    "id": "arXiv:2207.10200",
    "title": "Revisiting Hotels-50K and Hotel-ID",
    "abstract": "In this paper, we propose revisited versions for two recent hotel recognition\ndatasets: Hotels50K and Hotel-ID. The revisited versions provide evaluation\nsetups with different levels of difficulty to better align with the intended\nreal-world application, i.e. countering human trafficking. Real-world scenarios\ninvolve hotels and locations that are not captured in the current data sets,\ntherefore it is important to consider evaluation settings where classes are\ntruly unseen. We test this setup using multiple state-of-the-art image\nretrieval models and show that as expected, the models' performances decrease\nas the evaluation gets closer to the real-world unseen settings. The rankings\nof the best performing models also change across the different evaluation\nsettings, which further motivates using the proposed revisited datasets.",
    "descriptor": "\nComments: ICML 2022 DataPerf Workshop\n",
    "authors": [
      "Aarash Feizi",
      "Arantxa Casanova",
      "Adriana Romero-Soriano",
      "Reihaneh Rabbany"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.10200"
  },
  {
    "id": "arXiv:2207.10201",
    "title": "Hybrid CNN-Transformer Model For Facial Affect Recognition In the ABAW4  Challenge",
    "abstract": "This paper describes our submission to the fourth Affective Behavior Analysis\n(ABAW) competition. We proposed a hybrid CNN-Transformer model for the\nMulti-Task-Learning (MTL) and Learning from Synthetic Data (LSD) task.\nExperimental results on validation dataset shows that our method achieves\nbetter performance than baseline model, which verifies that the effectiveness\nof proposed network.",
    "descriptor": "",
    "authors": [
      "Lingfeng Wang",
      "Haocheng Li",
      "Chunyin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10201"
  },
  {
    "id": "arXiv:2207.10204",
    "title": "Watermark-Based Code Construction for Finite-State Markov Channel with  Synchronisation Errors",
    "abstract": "With advancements in telecommunications, data transmission over increasingly\nharsher channels that produce synchronisation errors is inevitable. Coding\nschemes for such channels are available through techniques such as the\nDavey-MacKay watermark coding; however, this is limited to memoryless channel\nestimates. Memory must be accounted for to ensure a realistic channel\napproximation - similar to a Finite State Markov Chain or Fritchman Model. A\nnovel code construction and decoder are developed to correct synchronisation\nerrors while considering the channel's correlated memory effects by\nincorporating ideas from the watermark scheme and memory modelling. Simulation\nresults show that the proposed code construction and decoder rival the first\nand second-order Davey-MacKay type watermark decoder and even perform slightly\nbetter when the inner-channel capacity is higher than 0.9. The proposed system\nand decoder may prove helpful in fields such as free-space optics and possibly\nmolecular communication, where harsh channels are used for communication.",
    "descriptor": "\nComments: Submitted to Elsevier Digital Signal Processing\n",
    "authors": [
      "Shamin Achari",
      "Ling Cheng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10204"
  },
  {
    "id": "arXiv:2207.10205",
    "title": "On the Robustness of 3D Object Detectors",
    "abstract": "In recent years, significant progress has been achieved for 3D object\ndetection on point clouds thanks to the advances in 3D data collection and deep\nlearning techniques. Nevertheless, 3D scenes exhibit a lot of variations and\nare prone to sensor inaccuracies as well as information loss during\npre-processing. Thus, it is crucial to design techniques that are robust\nagainst these variations. This requires a detailed analysis and understanding\nof the effect of such variations. This work aims to analyze and benchmark\npopular point-based 3D object detectors against several data corruptions. To\nthe best of our knowledge, we are the first to investigate the robustness of\npoint-based 3D object detectors. To this end, we design and evaluate\ncorruptions that involve data addition, reduction, and alteration. We further\nstudy the robustness of different modules against local and global variations.\nOur experimental results reveal several intriguing findings. For instance, we\nshow that methods that integrate Transformers at a patch or object level lead\nto increased robustness, compared to using Transformers at the point level.",
    "descriptor": "",
    "authors": [
      "Fatima Albreiki",
      "Sultan Abughazal",
      "Jean Lahoud",
      "Rao Anwer",
      "Hisham Cholakkal",
      "Fahad Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10205"
  },
  {
    "id": "arXiv:2207.10212",
    "title": "Scalability Analysis of a Global Blockchain For Immunization Records",
    "abstract": "While vaccinations continue to be rolled out to curb the ongoing COVID-19\npandemic, their verification is becoming a requirement for the re-incorporation\nof individuals into many social activities or travel. Blockchain technology has\nbeen widely proposed to manage vaccination records and their verification in\nmany politically-bound regions. However, the high contagiousness of COVID-19\ncalls for a global vaccination campaign. Therefore, a blockchain for\nvaccination management must scale up to support such a campaign and be\nadaptable to the requirements of different countries. While there have been\nmany proposals of blockchain frameworks that balance the access and\nimmutability of vaccination records, their scalability, a critical feature, has\nnot yet been addressed.\nIn this paper, we propose a scalable and cooperative Global Immunization\nInformation Blockchain-based System (GEOS) that leverages the global\ninteroperability of immunization information systems. We model GEOS and\ndescribe its requirements, features, and operation. We analyze the\ncommunications and the delays incurred by the national and international\nconsensus processes and blockchain interoperability in GEOS. Such\ncommunications are pivotal in enabling global-scale interoperability and access\nto electronic vaccination records for verification. We show that GEOS ably\nkeeps up with the global vaccination rates of COVID-19 as an example of its\nscalability.",
    "descriptor": "",
    "authors": [
      "Jorge Medina",
      "Roberto Rojas-Cessa",
      "Ziqian Dong",
      "Vatcharapan Umpaichitra"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.10212"
  },
  {
    "id": "arXiv:2207.10213",
    "title": "Spotting Temporally Precise, Fine-Grained Events in Video",
    "abstract": "We introduce the task of spotting temporally precise, fine-grained events in\nvideo (detecting the precise moment in time events occur). Precise spotting\nrequires models to reason globally about the full-time scale of actions and\nlocally to identify subtle frame-to-frame appearance and motion differences\nthat identify events during these actions. Surprisingly, we find that top\nperforming solutions to prior video understanding tasks such as action\ndetection and segmentation do not simultaneously meet both requirements. In\nresponse, we propose E2E-Spot, a compact, end-to-end model that performs well\non the precise spotting task and can be trained quickly on a single GPU. We\ndemonstrate that E2E-Spot significantly outperforms recent baselines adapted\nfrom the video action detection, segmentation, and spotting literature to the\nprecise spotting task. Finally, we contribute new annotations and splits to\nseveral fine-grained sports action datasets to make these datasets suitable for\nfuture work on precise spotting.",
    "descriptor": "\nComments: ECCV 2022; Website URL: this https URL\n",
    "authors": [
      "James Hong",
      "Haotian Zhang",
      "Micha\u00ebl Gharbi",
      "Matthew Fisher",
      "Kayvon Fatahalian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10213"
  },
  {
    "id": "arXiv:2207.10217",
    "title": "Hydra: Hybrid Server Power Model",
    "abstract": "With the growing complexity of big data workloads that require abundant data\nand computation, data centers consume a tremendous amount of power daily. In an\neffort to minimize data center power consumption, several studies developed\npower models that can be used for job scheduling either reducing the number of\nactive servers or balancing workloads across servers at their peak energy\nefficiency points. Due to increasing software and hardware heterogeneity, we\nobserved that there is no single power model that works the best for all server\nconditions. Some complicated machine learning models themselves incur\nperformance and power overheads and hence it is not desirable to use them\nfrequently. There are no power models that consider containerized workload\nexecution. In this paper, we propose a hybrid server power model, Hydra, that\nconsiders both prediction accuracy and performance overhead. Hydra dynamically\nchooses the best power model for the given server conditions. Compared with\nstate-of-the-art solutions, Hydra outperforms across all compute-intensity\nlevels on heterogeneous servers.",
    "descriptor": "",
    "authors": [
      "Nigel Bernard",
      "Hoa Nguyen",
      "Aman Chandan",
      "Savyasachi Jagdeeshan",
      "Namdev Prabhugaonkar",
      "Rutuja Shah",
      "Hyeran Jeon"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10217"
  },
  {
    "id": "arXiv:2207.10218",
    "title": "The Game of Hidden Rules: A New Kind of Benchmark Challenge for Machine  Learning",
    "abstract": "As machine learning (ML) is more tightly woven into society, it is imperative\nthat we better characterize ML's strengths and limitations if we are to employ\nit responsibly. Existing benchmark environments for ML, such as board and video\ngames, offer well-defined benchmarks for progress, but constituent tasks are\noften complex, and it is frequently unclear how task characteristics contribute\nto overall difficulty for the machine learner. Likewise, without a systematic\nassessment of how task characteristics influence difficulty, it is challenging\nto draw meaningful connections between performance in different benchmark\nenvironments. We introduce a novel benchmark environment that offers an\nenormous range of ML challenges and enables precise examination of how task\nelements influence practical difficulty. The tool frames learning tasks as a\n\"board-clearing game,\" which we call the Game of Hidden Rules (GOHR). The\nenvironment comprises an expressive rule language and a captive server\nenvironment that can be installed locally. We propose a set of benchmark\nrule-learning tasks and plan to support a performance leader-board for\nresearchers interested in attempting to learn our rules. GOHR complements\nexisting environments by allowing fine, controlled modifications to tasks,\nenabling experimenters to better understand how each facet of a given learning\ntask contributes to its practical difficulty for an arbitrary ML algorithm.",
    "descriptor": "\nComments: 9 pages, 5 figures. Additional documentation information available at this http URL\n",
    "authors": [
      "Eric Pulick",
      "Shubham Bharti",
      "Yiding Chen",
      "Vladimir Menkov",
      "Yonatan Mintz",
      "Paul Kantor",
      "Vicki M. Bier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10218"
  },
  {
    "id": "arXiv:2207.10221",
    "title": "Slimmable Quantum Federated Learning",
    "abstract": "Quantum federated learning (QFL) has recently received increasing attention,\nwhere quantum neural networks (QNNs) are integrated into federated learning\n(FL). In contrast to the existing static QFL methods, we propose slimmable QFL\n(SlimQFL) in this article, which is a dynamic QFL framework that can cope with\ntime-varying communication channels and computing energy limitations. This is\nmade viable by leveraging the unique nature of a QNN where its angle parameters\nand pole parameters can be separately trained and dynamically exploited.\nSimulation results corroborate that SlimQFL achieves higher classification\naccuracy than Vanilla QFL, particularly under poor channel conditions on\naverage.",
    "descriptor": "\nComments: ICML 2022 Workshop on Dynamic Neural Networks (Spotlight Paper)\n",
    "authors": [
      "Won Joon Yun",
      "Jae Pyoung Kim",
      "Soyi Jung",
      "Jihong Park",
      "Mehdi Bennis",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.10221"
  },
  {
    "id": "arXiv:2207.10222",
    "title": "Direct Localization in Underwater Acoustics via Convolutional Neural  Networks: A Data-Driven Approach",
    "abstract": "Direct localization (DLOC) methods, which use the observed data to localize a\nsource at an unknown position in a one-step procedure, generally outperform\ntheir indirect two-step counterparts (e.g., using time-difference of arrivals).\nHowever, underwater acoustic DLOC methods require prior knowledge of the\nenvironment, and are computationally costly, hence slow. We propose, what is to\nthe best of our knowledge, the first data-driven DLOC method. Inspired by\nclassical and contemporary optimal model-based DLOC solutions, and leveraging\nthe capabilities of convolutional neural networks (CNNs), we devise a holistic\nCNN-based solution. Our method includes a specifically-tailored input\nstructure, architecture, loss function, and a progressive training procedure,\nwhich are of independent interest in the broader context of machine learning.\nWe demonstrate that our method outperforms attractive alternatives, and\nasymptotically matches the performance of an oracle optimal model-based\nsolution.",
    "descriptor": "",
    "authors": [
      "Amir Weiss",
      "Toros Arikan",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10222"
  },
  {
    "id": "arXiv:2207.10223",
    "title": "Fairness Testing: A Comprehensive Survey and Analysis of Trends",
    "abstract": "Software systems are vulnerable to fairness bugs and frequently exhibit\nunfair behaviors, making software fairness an increasingly important concern\nfor software engineers. Research has focused on helping software engineers to\ndetect fairness bugs automatically. This paper provides a comprehensive survey\nof existing research on fairness testing. We collect 113 papers and organise\nthem based on the testing workflow (i.e., the testing activities) and the\ntesting components (i.e., where to find fairness bugs) for conducting fairness\ntesting. We also analyze the research focus, trends, promising directions, as\nwell as widely-adopted datasets and open source tools for fairness testing.",
    "descriptor": "",
    "authors": [
      "Zhenpeng Chen",
      "Jie M. Zhang",
      "Max Hort",
      "Federica Sarro",
      "Mark Harman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.10223"
  },
  {
    "id": "arXiv:2207.10225",
    "title": "On Label Granularity and Object Localization",
    "abstract": "Weakly supervised object localization (WSOL) aims to learn representations\nthat encode object location using only image-level category labels. However,\nmany objects can be labeled at different levels of granularity. Is it an\nanimal, a bird, or a great horned owl? Which image-level labels should we use?\nIn this paper we study the role of label granularity in WSOL. To facilitate\nthis investigation we introduce iNatLoc500, a new large-scale fine-grained\nbenchmark dataset for WSOL. Surprisingly, we find that choosing the right\ntraining label granularity provides a much larger performance boost than\nchoosing the best WSOL algorithm. We also show that changing the label\ngranularity can significantly improve data efficiency.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Elijah Cole",
      "Kimberly Wilber",
      "Grant Van Horn",
      "Xuan Yang",
      "Marco Fornoni",
      "Pietro Perona",
      "Serge Belongie",
      "Andrew Howard",
      "Oisin Mac Aodha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10225"
  },
  {
    "id": "arXiv:2207.10226",
    "title": "Improving Privacy-Preserving Vertical Federated Learning by Efficient  Communication with ADMM",
    "abstract": "Federated learning (FL) enables distributed devices to jointly train a shared\nmodel while keeping the training data local. Different from the horizontal FL\n(HFL) setting where each client has partial data samples, vertical FL (VFL),\nwhich allows each client to collect partial features, has attracted intensive\nresearch efforts recently. In this paper, we identified two challenges that\nstate-of-the-art VFL frameworks are facing: (1) some works directly average the\nlearned feature embeddings and therefore might lose the unique properties of\neach local feature set; (2) server needs to communicate gradients with the\nclients for each training step, incurring high communication cost that leads to\nrapid consumption of privacy budgets. In this paper, we aim to address the\nabove challenges and propose an efficient VFL with multiple linear heads (VIM)\nframework, where each head corresponds to local clients by taking the separate\ncontribution of each client into account. In addition, we propose an\nAlternating Direction Method of Multipliers (ADMM)-based method to solve our\noptimization problem, which reduces the communication cost by allowing multiple\nlocal updates in each step, and thus leads to better performance under\ndifferential privacy. We consider various settings including VFL with model\nsplitting and without model splitting. For both settings, we carefully analyze\nthe differential privacy mechanism for our framework. Moreover, we show that a\nbyproduct of our framework is that the weights of learned linear heads reflect\nthe importance of local clients. We conduct extensive evaluations and show that\non four real-world datasets, VIM achieves significantly higher performance and\nfaster convergence compared with state-of-the-arts. We also explicitly evaluate\nthe importance of local clients and show that VIM enables functionalities such\nas client-level explanation and client denoising.",
    "descriptor": "",
    "authors": [
      "Chulin Xie",
      "Pin-Yu Chen",
      "Ce Zhang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10226"
  },
  {
    "id": "arXiv:2207.10228",
    "title": "MeshMAE: Masked Autoencoders for 3D Mesh Data Analysis",
    "abstract": "Recently, self-supervised pre-training has advanced Vision Transformers on\nvarious tasks w.r.t. different data modalities, e.g., image and 3D point cloud\ndata. In this paper, we explore this learning paradigm for 3D mesh data\nanalysis based on Transformers. Since applying Transformer architectures to new\nmodalities is usually non-trivial, we first adapt Vision Transformer to 3D mesh\ndata processing, i.e., Mesh Transformer. In specific, we divide a mesh into\nseveral non-overlapping local patches with each containing the same number of\nfaces and use the 3D position of each patch's center point to form positional\nembeddings. Inspired by MAE, we explore how pre-training on 3D mesh data with\nthe Transformer-based structure benefits downstream 3D mesh analysis tasks. We\nfirst randomly mask some patches of the mesh and feed the corrupted mesh into\nMesh Transformers. Then, through reconstructing the information of masked\npatches, the network is capable of learning discriminative representations for\nmesh data. Therefore, we name our method MeshMAE, which can yield\nstate-of-the-art or comparable performance on mesh analysis tasks, i.e.,\nclassification and segmentation. In addition, we also conduct comprehensive\nablation studies to show the effectiveness of key designs in our method.",
    "descriptor": "\nComments: accepted by ECCV\n",
    "authors": [
      "Yaqian Liang",
      "Shanshan Zhao",
      "Baosheng Yu",
      "Jing Zhang",
      "Fazhi He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10228"
  },
  {
    "id": "arXiv:2207.10229",
    "title": "Spatial Aware Multi-Task Learning Based Speech Separation",
    "abstract": "During the Covid, online meetings have become an indispensable part of our\nlives. This trend is likely to continue due to their convenience and broad\nreach. However, background noise from other family members, roommates,\noffice-mates not only degrades the voice quality but also raises serious\nprivacy issues. In this paper, we develop a novel system, called Spatial Aware\nMulti-task learning-based Separation (SAMS), to extract audio signals from the\ntarget user during teleconferencing. Our solution consists of three novel\ncomponents: (i) generating fine-grained location embeddings from the user's\nvoice and inaudible tracking sound, which contains the user's position and rich\nmultipath information, (ii) developing a source separation neural network using\nmulti-task learning to jointly optimize source separation and location, and\n(iii) significantly speeding up inference to provide a real-time guarantee. Our\ntestbed experiments demonstrate the effectiveness of our approach",
    "descriptor": "",
    "authors": [
      "Wei Sun",
      "Mei Wang",
      "Lili Qiu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10229"
  },
  {
    "id": "arXiv:2207.10230",
    "title": "On Linear Power Control Policies for Energy Harvesting Communications",
    "abstract": "A comprehensive analysis of linear power control polices, which include the\nwell-known greedy policy and fixed fraction policy as special cases, is\nprovided. The notions of maximin optimal linear policy for given battery\ncapacity $c$ and mean-to-capacity ratio $p$ as well as its $c$-universal\nversions are introduced. It is shown, among others, that the fixed fraction\npolicy is $c$-universal additive-gap optimal but not $c$-universal\nmultiplicative-factor optimal. Tight semi-universal bounds on the\nbattery-capacity-threshold for the optimality of the greedy policy are\nestablished for certain families of energy arrival distributions.",
    "descriptor": "\nComments: 30 pages, 4 figures\n",
    "authors": [
      "Hafez M. Garmaroudi",
      "Zikai Dou",
      "Shengtian Yang",
      "Jun Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.10230"
  },
  {
    "id": "arXiv:2207.10234",
    "title": "Chance constrained day-ahead robust flexibility needs assessment for low  voltage distribution network",
    "abstract": "For market-based procurement of low voltage (LV) flexibility, DSOs identify\nthe amount of flexibility needed for resolving probable distribution network\n(DN) voltage and thermal congestion. A framework is required to avoid over or\nunder procurement of flexibility in the presence of uncertainty. To this end,\nwe propose a scenario-based robust chance-constrained (CC) day-ahead\nflexibility needs assessment (FNA) framework. The CC level is analogous to the\nrisk DSO is willing to take in flexibility planning. Multi-period optimal power\nflow is performed to calculate the amount of flexibility needed to avoid\nnetwork issues. Flexibility is defined in terms of nodal power ramp-up and\nramp-down and cumulative energy needs over a full day for each node. Future\nuncertainties are considered as multiple scenarios generated using multivariate\nGaussian distribution and Cholesky decomposition. These scenarios are utilized\nto solve the flexibility needs assessment optimal power flow (FNA-OPF) problem.\nZonal clustering of an LV feeder is performed using electrical distance as a\nmeasure and spatial partitioning. The FNA tool calculates ramp-up and ramp-down\nflexibility's power and energy requirements. Energy and power needs are often\nvalued differently in many energy markets. We identify the marginal value of\nflexibility associated with energy and power needs separately. From numerical\nresults for an LV feeder, it is observed that zonal flexibility needs\nassessment is more immune to uncertainty than nodal flexibility needs, making\nit more useful for DSOs to evaluate day-ahead flexibility procurement. We also\npropose a Pareto optimal mechanism for selecting CC level to reduce flexibility\nneeds while reducing DN congestion.",
    "descriptor": "",
    "authors": [
      "Md Umar Hashmi",
      "Arpan Koirala",
      "Hakan Ergun",
      "Dirk Van Hertem"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10234"
  },
  {
    "id": "arXiv:2207.10237",
    "title": "SPIN: An Empirical Evaluation on Sharing Parameters of Isotropic  Networks",
    "abstract": "Recent isotropic networks, such as ConvMixer and vision transformers, have\nfound significant success across visual recognition tasks, matching or\noutperforming non-isotropic convolutional neural networks (CNNs). Isotropic\narchitectures are particularly well-suited to cross-layer weight sharing, an\neffective neural network compression technique. In this paper, we perform an\nempirical evaluation on methods for sharing parameters in isotropic networks\n(SPIN). We present a framework to formalize major weight sharing design\ndecisions and perform a comprehensive empirical evaluation of this design\nspace. Guided by our experimental results, we propose a weight sharing strategy\nto generate a family of models with better overall efficiency, in terms of\nFLOPs and parameters versus accuracy, compared to traditional scaling methods\nalone, for example compressing ConvMixer by 1.9x while improving accuracy on\nImageNet. Finally, we perform a qualitative study to further understand the\nbehavior of weight sharing in isotropic architectures. The code is available at\nhttps://github.com/apple/ml-spin.",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Chien-Yu Lin",
      "Anish Prabhu",
      "Thomas Merth",
      "Sachin Mehta",
      "Anurag Ranjan",
      "Maxwell Horton",
      "Mohammad Rastegari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10237"
  },
  {
    "id": "arXiv:2207.10240",
    "title": "Differentially Private Partial Set Cover with Applications to Facility  Location",
    "abstract": "It was observed in \\citet{gupta2009differentially} that the Set Cover problem\nhas strong impossibility results under differential privacy. In our work, we\nobserve that these hardness results dissolve when we turn to the Partial Set\nCover problem, where we only need to cover a $\\rho$-fraction of the elements in\nthe universe, for some $\\rho\\in(0,1)$. We show that this relaxation enables us\nto avoid the impossibility results: under loose conditions on the input set\nsystem, we give differentially private algorithms which output an explicit set\ncover with non-trivial approximation guarantees. In particular, this is the\nfirst differentially private algorithm which outputs an explicit set cover.\nUsing our algorithm for Partial Set Cover as a subroutine, we give a\ndifferentially private (bicriteria) approximation algorithm for a facility\nlocation problem which generalizes $k$-center/$k$-supplier with outliers. Like\nwith the Set Cover problem, no algorithm has been able to give non-trivial\nguarantees for $k$-center/$k$-supplier-type facility location problems due to\nthe high sensitivity and impossibility results. Our algorithm shows that\nrelaxing the covering requirement to serving only a $\\rho$-fraction of the\npopulation, for $\\rho\\in(0,1)$, enables us to circumvent the inherent hardness.\nOverall, our work is an important step in tackling and understanding\nimpossibility results in private combinatorial optimization.",
    "descriptor": "\nComments: 12 pages. Poster at TPDP 2022\n",
    "authors": [
      "George Z. Li",
      "Dung Nguyen",
      "Anil Vullikanti"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10240"
  },
  {
    "id": "arXiv:2207.10241",
    "title": "Unsupervised Legendre-Galerkin Neural Network for Stiff Partial  Differential Equations",
    "abstract": "Machine learning methods have been lately used to solve differential\nequations and dynamical systems. These approaches have been developed into a\nnovel research field known as scientific machine learning in which techniques\nsuch as deep neural networks and statistical learning are applied to classical\nproblems of applied mathematics. Because neural networks provide an\napproximation capability, computational parameterization through machine\nlearning and optimization methods achieve noticeable performance when solving\nvarious partial differential equations (PDEs). In this paper, we develop a\nnovel numerical algorithm that incorporates machine learning and artificial\nintelligence to solve PDEs. In particular, we propose an unsupervised machine\nlearning algorithm based on the Legendre-Galerkin neural network to find an\naccurate approximation to the solution of different types of PDEs. The proposed\nneural network is applied to the general 1D and 2D PDEs as well as singularly\nperturbed PDEs that possess boundary layer behavior.",
    "descriptor": "\nComments: 29 pages, 8 figures\n",
    "authors": [
      "Junho Choi",
      "Namjung Kim",
      "Youngjoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10241"
  },
  {
    "id": "arXiv:2207.10242",
    "title": "A Ransomware Triage Approach using a Task Memory based on Meta-Transfer  Learning Framework",
    "abstract": "Solutions for rapid prioritization of different ransomware have been raised\nto formulate fast response plans to minimize socioeconomic damage from the\nmassive growth of ransomware attacks in recent years. To address this concern,\nwe propose a ransomware triage approach that can rapidly classify and\nprioritize different ransomware classes. Our Siamese Neural Network (SNN) based\napproach utilizes a pre-trained ResNet18 network in a meta-learning fashion to\nreduce the biases in weight and parameter calculations typically associated\nwith a machine learning model trained with a limited number of training\nsamples. Instead of image features typically used as inputs to many existing\nmachine learning-based triage applications, our approach uses the entropy\nfeatures directly obtained from the ransomware binary files to improve feature\nrepresentation, resilient to obfuscation noise, and computationally less\nexpensive. Our triage approach can classify ransomware samples into the correct\nclasses if the ransomware features significantly match known ransomware\nprofiles. Our evaluation shows that this classification part of our proposed\napproach achieves the accuracy exceeding 88% and outperforms other similar\nclassification only machine learning-based approaches. In addition, we offer a\nnew triage strategy based on the normalized and regularized weight ratios that\nevaluate the level of similarity matching across ransomware classes to identify\nany risky and unknown ransomware (e.g., zero-day attacks) so that a rapid\nfurther analysis can be conducted",
    "descriptor": "",
    "authors": [
      "Jinting Zhu",
      "Julian Jang-Jaccard",
      "Ian Welch",
      "Harith Al-Sahaf",
      "Seyit Camtepe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10242"
  },
  {
    "id": "arXiv:2207.10245",
    "title": "The Birth of Bias: A case study on the evolution of gender bias in an  English language model",
    "abstract": "Detecting and mitigating harmful biases in modern language models are widely\nrecognized as crucial, open problems. In this paper, we take a step back and\ninvestigate how language models come to be biased in the first place. We use a\nrelatively small language model, using the LSTM architecture trained on an\nEnglish Wikipedia corpus. With full access to the data and to the model\nparameters as they change during every step while training, we can map in\ndetail how the representation of gender develops, what patterns in the dataset\ndrive this, and how the model's internal state relates to the bias in a\ndownstream task (semantic textual similarity). We find that the representation\nof gender is dynamic and identify different phases during training.\nFurthermore, we show that gender information is represented increasingly\nlocally in the input embeddings of the model and that, as a consequence,\ndebiasing these can be effective in reducing the downstream bias. Monitoring\nthe training dynamics, allows us to detect an asymmetry in how the female and\nmale gender are represented in the input embeddings. This is important, as it\nmay cause naive mitigation strategies to introduce new undesirable biases. We\ndiscuss the relevance of the findings for mitigation strategies more generally\nand the prospects of generalizing our methods to larger language models, the\nTransformer architecture, other languages and other undesirable biases.",
    "descriptor": "\nComments: Accepted at the 4th Workshop on Gender Bias in Natural Language Processing (NAACL, 2022)\n",
    "authors": [
      "Oskar van der Wal",
      "Jaap Jumelet",
      "Katrin Schulz",
      "Willem Zuidema"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10245"
  },
  {
    "id": "arXiv:2207.10246",
    "title": "GBDF: Gender Balanced DeepFake Dataset Towards Fair DeepFake Detection",
    "abstract": "Facial forgery by deepfakes has raised severe societal concerns. Several\nsolutions have been proposed by the vision community to effectively combat the\nmisinformation on the internet via automated deepfake detection systems. Recent\nstudies have demonstrated that facial analysis-based deep learning models can\ndiscriminate based on protected attributes. For the commercial adoption and\nmassive roll-out of the deepfake detection technology, it is vital to evaluate\nand understand the fairness (the absence of any prejudice or favoritism) of\ndeepfake detectors across demographic variations such as gender and race. As\nthe performance differential of deepfake detectors between demographic\nsubgroups would impact millions of people of the deprived sub-group. This paper\naims to evaluate the fairness of the deepfake detectors across males and\nfemales. However, existing deepfake datasets are not annotated with demographic\nlabels to facilitate fairness analysis. To this aim, we manually annotated\nexisting popular deepfake datasets with gender labels and evaluated the\nperformance differential of current deepfake detectors across gender. Our\nanalysis on the gender-labeled version of the datasets suggests (a) current\ndeepfake datasets have skewed distribution across gender, and (b) commonly\nadopted deepfake detectors obtain unequal performance across gender with mostly\nmales outperforming females. Finally, we contributed a gender-balanced and\nannotated deepfake dataset, GBDF, to mitigate the performance differential and\nto promote research and development towards fairness-aware deep fake detectors.\nThe GBDF dataset is publicly available at: https://github.com/aakash4305/GBDF",
    "descriptor": "\nComments: 26th International Conference on Pattern Recognition (ICPR) 2022| Montreal, Canada\n",
    "authors": [
      "Aakash Varma Nadimpalli",
      "Ajita Rattani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10246"
  },
  {
    "id": "arXiv:2207.10248",
    "title": "Can locational disparity of prosumer energy optimization due to inverter  rules be limited?",
    "abstract": "To mitigate issues related to growth of variable smart loads and distributed\ngeneration, distribution system operators (DSO) now make it binding for\nprosumers with inverters to operate under pre-set rules. In particular, the\nmaximum active and reactive power set points for prosumers are based on local\nvoltage measurements to ensure that inverter output does not cause voltage\nviolations. However, such actions may restrict the range available for local\nenergy management, thus reducing the profit which prosumer would otherwise have\nmade. This work analyses the loss of arbitrage opportunity and ability to\nperform voltage regulation for active prosumers due to inverter operational\nrules and location along a radial distribution network (DN). We model the\narbitrage opportunity as a linear programming based local control for load and\nenergy storage output based on electricity price variations, while ensuring\nthat active and reactive injection limits are respected at finer time scales.\nWe observe that relative feeder location determines the effect of inverter\nrules on arbitrage profits, with more adverse losses for prosumers located\nfarther away from the substation. Subsequently, we propose a hybrid control\npolicy that helps minimize this locational discrepancy while regulating the\nnodal voltage. Case studies are presented using three identical prosumers\nlocated at different parts of a test network. We observe that the proposed\nhybrid policy reduces the locational disparity to less than 1.4\\% between\nprosumers connected at the head and end of the feeder.",
    "descriptor": "",
    "authors": [
      "Md Umar Hashmi",
      "Deepjoyti Deka",
      "Ana Bu\u0161i\u0107",
      "Dirk Van Hertem"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10248"
  },
  {
    "id": "arXiv:2207.10254",
    "title": "The Two-Stripe Symmetric Circulant TSP is in P",
    "abstract": "The symmetric circulant TSP is a special case of the traveling salesman\nproblem in which edge costs are symmetric and obey circulant symmetry. Despite\nthe substantial symmetry of the input, remarkably little is known about the\nsymmetric circulant TSP, and the complexity of the problem has been an\noften-cited open question. Considerable effort has been made to understand the\ncase in which only edges of two lengths are allowed to have finite cost: the\ntwo-stripe symmetric circulant TSP. In this paper, we resolve the complexity of\nthe two-stripe symmetric circulant TSP. To do so, we reduce two-stripe\nsymmetric circulant TSP to the problem of finding certain minimum-cost\nHamiltonian paths on cylindrical graphs. We then solve this Hamiltonian path\nproblem. Our results show that the two-stripe symmetric circulant TSP is in P.\nNote that a two-stripe symmetric circulant TSP instance consists of a constant\nnumber of inputs (including $n$, the number of cities), so that a\npolynomial-time algorithm for the decision problem must run in time\npolylogarithmic in $n$, and a polynomial-time algorithm for the optimization\nproblem cannot output the tour. We address this latter difficulty by showing\nthat the optimal tour must fall into one of two parameterized classes of tours,\nand that we can output the class and the parameters in polynomial time. Thus we\nmake a substantial contribution to the set of polynomial-time solvable special\ncases of the TSP, and take an important step towards resolving the complexity\nof the general symmetric circulant TSP.",
    "descriptor": "\nComments: 72 pages, 26 figures. A preliminary version appeared in IPCO 2022\n",
    "authors": [
      "Samuel C. Gutekunst",
      "Billy Jin",
      "David P. Williamson"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.10254"
  },
  {
    "id": "arXiv:2207.10255",
    "title": "SplitMixer: Fat Trimmed From MLP-like Models",
    "abstract": "We present SplitMixer, a simple and lightweight isotropic MLP-like\narchitecture, for visual recognition. It contains two types of interleaving\nconvolutional operations to mix information across spatial locations (spatial\nmixing) and channels (channel mixing). The first one includes sequentially\napplying two depthwise 1D kernels, instead of a 2D kernel, to mix spatial\ninformation. The second one is splitting the channels into overlapping or\nnon-overlapping segments, with or without shared parameters, and applying our\nproposed channel mixing approaches or 3D convolution to mix channel\ninformation. Depending on design choices, a number of SplitMixer variants can\nbe constructed to balance accuracy, the number of parameters, and speed. We\nshow, both theoretically and experimentally, that SplitMixer performs on par\nwith the state-of-the-art MLP-like models while having a significantly lower\nnumber of parameters and FLOPS. For example, without strong data augmentation\nand optimization, SplitMixer achieves around 94% accuracy on CIFAR-10 with only\n0.28M parameters, while ConvMixer achieves the same accuracy with about 0.6M\nparameters. The well-known MLP-Mixer achieves 85.45% with 17.1M parameters. On\nCIFAR-100 dataset, SplitMixer achieves around 73% accuracy, on par with\nConvMixer, but with about 52% fewer parameters and FLOPS. We hope that our\nresults spark further research towards finding more efficient vision\narchitectures and facilitate the development of MLP-like models. Code is\navailable at https://github.com/aliborji/splitmixer.",
    "descriptor": "",
    "authors": [
      "Ali Borji",
      "Sikun Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10255"
  },
  {
    "id": "arXiv:2207.10256",
    "title": "SGBANet: Semantic GAN and Balanced Attention Network for Arbitrarily  Oriented Scene Text Recognition",
    "abstract": "Scene text recognition is a challenging task due to the complex backgrounds\nand diverse variations of text instances. In this paper, we propose a novel\nSemantic GAN and Balanced Attention Network (SGBANet) to recognize the texts in\nscene images. The proposed method first generates the simple semantic feature\nusing Semantic GAN and then recognizes the scene text with the Balanced\nAttention Module. The Semantic GAN aims to align the semantic feature\ndistribution between the support domain and target domain. Different from the\nconventional image-to-image translation methods that perform at the image\nlevel, the Semantic GAN performs the generation and discrimination on the\nsemantic level with the Semantic Generator Module (SGM) and Semantic\nDiscriminator Module (SDM). For target images (scene text images), the Semantic\nGenerator Module generates simple semantic features that share the same feature\ndistribution with support images (clear text images). The Semantic\nDiscriminator Module is used to distinguish the semantic features between the\nsupport domain and target domain. In addition, a Balanced Attention Module is\ndesigned to alleviate the problem of attention drift. The Balanced Attention\nModule first learns a balancing parameter based on the visual glimpse vector\nand semantic glimpse vector, and then performs the balancing operation for\nobtaining a balanced glimpse vector. Experiments on six benchmarks, including\nregular datasets, i.e., IIIT5K, SVT, ICDAR2013, and irregular datasets, i.e.,\nICDAR2015, SVTP, CUTE80, validate the effectiveness of our proposed method.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Dajian Zhong",
      "Shujing Lyu",
      "Palaiahnakote Shivakumara",
      "Bing Yin",
      "Jiajia Wu",
      "Umapada Pal",
      "Yue Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10256"
  },
  {
    "id": "arXiv:2207.10257",
    "title": "Injecting 3D Perception of Controllable NeRF-GAN into StyleGAN for  Editable Portrait Image Synthesis",
    "abstract": "Over the years, 2D GANs have achieved great successes in photorealistic\nportrait generation. However, they lack 3D understanding in the generation\nprocess, thus they suffer from multi-view inconsistency problem. To alleviate\nthe issue, many 3D-aware GANs have been proposed and shown notable results, but\n3D GANs struggle with editing semantic attributes. The controllability and\ninterpretability of 3D GANs have not been much explored. In this work, we\npropose two solutions to overcome these weaknesses of 2D GANs and 3D-aware\nGANs. We first introduce a novel 3D-aware GAN, SURF-GAN, which is capable of\ndiscovering semantic attributes during training and controlling them in an\nunsupervised manner. After that, we inject the prior of SURF-GAN into StyleGAN\nto obtain a high-fidelity 3D-controllable generator. Unlike existing\nlatent-based methods allowing implicit pose control, the proposed\n3D-controllable StyleGAN enables explicit pose control over portrait\ngeneration. This distillation allows direct compatibility between 3D control\nand many StyleGAN-based techniques (e.g., inversion and stylization), and also\nbrings an advantage in terms of computational resources. Our codes are\navailable at https://github.com/jgkwak95/SURF-GAN.",
    "descriptor": "\nComments: ECCV 2022, project page: this https URL\n",
    "authors": [
      "Jeong-gi Kwak",
      "Yuanming Li",
      "Dongsik Yoon",
      "Donghyeon Kim",
      "David Han",
      "Hanseok Ko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.10257"
  },
  {
    "id": "arXiv:2207.10258",
    "title": "Region Aware Video Object Segmentation with Deep Motion Modeling",
    "abstract": "Current semi-supervised video object segmentation (VOS) methods usually\nleverage the entire features of one frame to predict object masks and update\nmemory. This introduces significant redundant computations. To reduce\nredundancy, we present a Region Aware Video Object Segmentation (RAVOS)\napproach that predicts regions of interest (ROIs) for efficient object\nsegmentation and memory storage. RAVOS includes a fast object motion tracker to\npredict their ROIs in the next frame. For efficient segmentation, object\nfeatures are extracted according to the ROIs, and an object decoder is designed\nfor object-level segmentation. For efficient memory storage, we propose motion\npath memory to filter out redundant context by memorizing the features within\nthe motion path of objects between two frames. Besides RAVOS, we also propose a\nlarge-scale dataset, dubbed OVOS, to benchmark the performance of VOS models\nunder occlusions. Evaluation on DAVIS and YouTube-VOS benchmarks and our new\nOVOS dataset show that our method achieves state-of-the-art performance with\nsignificantly faster inference time, e.g., 86.1 J&F at 42 FPS on DAVIS and 84.4\nJ&F at 23 FPS on YouTube-VOS.",
    "descriptor": "",
    "authors": [
      "Bo Miao",
      "Mohammed Bennamoun",
      "Yongsheng Gao",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10258"
  },
  {
    "id": "arXiv:2207.10262",
    "title": "A Labelled Sequent Calculus for Public Announcement Logic",
    "abstract": "Public announcement logic(PAL) is an extension of epistemic logic (EL) with\nsome reduction axioms. In this paper, we propose a cut-free labelled sequent\ncalculus for PAL, which is an extension of that for EL with sequent rules\nadapted from the reduction axioms. This calculus admits cut and allows\nterminating proof search.",
    "descriptor": "",
    "authors": [
      "Hao Wu",
      "Hans van Ditmarsch",
      "Jinsheng Chen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.10262"
  },
  {
    "id": "arXiv:2207.10265",
    "title": "FOCUS: Fairness via Agent-Awareness for Federated Learning on  Heterogeneous Data",
    "abstract": "Federated learning (FL) provides an effective paradigm to train machine\nlearning models over distributed data with privacy protection. However, recent\nstudies show that FL is subject to various security, privacy, and fairness\nthreats due to the potentially malicious and heterogeneous local agents. For\ninstance, it is vulnerable to local adversarial agents who only contribute\nlow-quality data, with the goal of harming the performance of those with\nhigh-quality data. This kind of attack hence breaks existing definitions of\nfairness in FL that mainly focus on a certain notion of performance parity. In\nthis work, we aim to address this limitation and propose a formal definition of\nfairness via agent-awareness for FL (FAA), which takes the heterogeneous data\ncontributions of local agents into account. In addition, we propose a fair FL\ntraining algorithm based on agent clustering (FOCUS) to achieve FAA.\nTheoretically, we prove the convergence and optimality of FOCUS under mild\nconditions for linear models and general convex loss functions with bounded\nsmoothness. We also prove that FOCUS always achieves higher fairness measured\nby FAA compared with standard FedAvg protocol under both linear models and\ngeneral convex loss functions. Empirically, we evaluate FOCUS on four datasets,\nincluding synthetic data, images, and texts under different settings, and we\nshow that FOCUS achieves significantly higher fairness based on FAA while\nmaintaining similar or even higher prediction accuracy compared with FedAvg.",
    "descriptor": "",
    "authors": [
      "Wenda Chu",
      "Chulin Xie",
      "Boxin Wang",
      "Linyi Li",
      "Lang Yin",
      "Han Zhao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.10265"
  },
  {
    "id": "arXiv:2207.10269",
    "title": "Human-centric Image Cropping with Partition-aware and Content-preserving  Features",
    "abstract": "Image cropping aims to find visually appealing crops in an image, which is an\nimportant yet challenging task. In this paper, we consider a specific and\npractical application: human-centric image cropping, which focuses on the\ndepiction of a person. To this end, we propose a human-centric image cropping\nmethod with two novel feature designs for the candidate crop: partition-aware\nfeature and content-preserving feature. For partition-aware feature, we divide\nthe whole image into nine partitions based on the human bounding box and treat\ndifferent partitions in a candidate crop differently conditioned on the human\ninformation. For content-preserving feature, we predict a heatmap indicating\nthe important content to be included in a good crop, and extract the geometric\nrelation between the heatmap and a candidate crop. Extensive experiments\ndemonstrate that our method can perform favorably against state-of-the-art\nimage cropping methods on human-centric image cropping task. Code is available\nat https://github.com/bcmi/Human-Centric-Image-Cropping.",
    "descriptor": "",
    "authors": [
      "Bo Zhang",
      "Li Niu",
      "Xing Zhao",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10269"
  },
  {
    "id": "arXiv:2207.10271",
    "title": "DeltaGAN: Towards Diverse Few-shot Image Generation with Sample-Specific  Delta",
    "abstract": "Learning to generate new images for a novel category based on only a few\nimages, named as few-shot image generation, has attracted increasing research\ninterest. Several state-of-the-art works have yielded impressive results, but\nthe diversity is still limited. In this work, we propose a novel Delta\nGenerative Adversarial Network (DeltaGAN), which consists of a reconstruction\nsubnetwork and a generation subnetwork. The reconstruction subnetwork captures\nintra-category transformation, i.e., delta, between same-category pairs. The\ngeneration subnetwork generates sample-specific delta for an input image, which\nis combined with this input image to generate a new image within the same\ncategory. Besides, an adversarial delta matching loss is designed to link the\nabove two subnetworks together. Extensive experiments on six benchmark datasets\ndemonstrate the effectiveness of our proposed method. Our code is available at\nhttps://github.com/bcmi/DeltaGAN-Few-Shot-Image-Generation.",
    "descriptor": "\nComments: This paper is accepted by ECCV 2022. arXiv admin note: substantial text overlap with arXiv:2009.08753\n",
    "authors": [
      "Yan Hong",
      "Li Niu",
      "Jianfu Zhang",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10271"
  },
  {
    "id": "arXiv:2207.10273",
    "title": "Don't Forget Me: Accurate Background Recovery for Text Removal via  Modeling Local-Global Context",
    "abstract": "Text removal has attracted increasingly attention due to its various\napplications on privacy protection, document restoration, and text editing. It\nhas shown significant progress with deep neural network. However, most of the\nexisting methods often generate inconsistent results for complex background. To\naddress this issue, we propose a Contextual-guided Text Removal Network, termed\nas CTRNet. CTRNet explores both low-level structure and high-level\ndiscriminative context feature as prior knowledge to guide the process of\nbackground restoration. We further propose a Local-global Content Modeling\n(LGCM) block with CNNs and Transformer-Encoder to capture local features and\nestablish the long-term relationship among pixels globally. Finally, we\nincorporate LGCM with context guidance for feature modeling and decoding.\nExperiments on benchmark datasets, SCUT-EnsText and SCUT-Syn show that CTRNet\nsignificantly outperforms the existing state-of-the-art methods. Furthermore, a\nqualitative experiment on examination papers also demonstrates the\ngeneralization ability of our method. The codes and supplement materials are\navailable at https://github.com/lcy0604/CTRNet.",
    "descriptor": "",
    "authors": [
      "Chongyu Liu",
      "Lianwen Jin",
      "Yuliang Liu",
      "Canjie Luo",
      "Bangdong Chen",
      "Fengjun Guo",
      "Kai Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10273"
  },
  {
    "id": "arXiv:2207.10275",
    "title": "Adversary Detection and Resilient Control for Multi-Agent Systems",
    "abstract": "This paper presents an adversary detection mechanism and a resilient control\nframework for multi-agent systems under spatiotemporal constraints. Safety in\nmulti-agent systems is typically addressed under the assumption that all agents\ncollaborate to ensure the forward invariance of a desired safe set. This work\nanalyzes agent behaviors based on certain behavior metrics, and designs a\nproactive adversary detection mechanism based on the notion of the critical\nregion for the system operation. In particular, the presented detection\nmechanism not only identifies adversarial agents, but also ensures all-time\nsafety for intact agents. Then, based on the analysis and detection results, a\nresilient QP-based controller is presented to ensure safety and liveness\nconstraints for intact agents. Simulation results validate the efficacy of the\npresented theoretical contributions.",
    "descriptor": "",
    "authors": [
      "Aquib Mustafa",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10275"
  },
  {
    "id": "arXiv:2207.10276",
    "title": "ProMix: Combating Label Noise via Maximizing Clean Sample Utility",
    "abstract": "The ability to train deep neural networks under label noise is appealing, as\nimperfectly annotated data are relatively cheaper to obtain. State-of-the-art\napproaches are based on semi-supervised learning(SSL), which selects small loss\nexamples as clean and then applies SSL techniques for boosted performance.\nHowever, the selection step mostly provides a medium-sized and decent-enough\nclean subset, which overlooks a rich set of clean samples. In this work, we\npropose a novel noisy label learning framework ProMix that attempts to maximize\nthe utility of clean samples for boosted performance. Key to our method, we\npropose a matched high-confidence selection technique that selects those\nexamples having high confidence and matched prediction with its given labels.\nCombining with the small-loss selection, our method is able to achieve a\nprecision of 99.27 and a recall of 98.22 in detecting clean samples on the\nCIFAR-10N dataset. Based on such a large set of clean data, ProMix improves the\nbest baseline method by +2.67% on CIFAR-10N and +1.61% on CIFAR-100N datasets.\nThe code and data are available at https://github.com/Justherozen/ProMix",
    "descriptor": "\nComments: Winner of the 1st Learning and Mining with Noisy Labels Challenge in IJCAI-ECAI 2022 (an informal technical report)\n",
    "authors": [
      "Haobo Wang",
      "Ruixuan Xiao",
      "Yiwen Dong",
      "Lei Feng",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10276"
  },
  {
    "id": "arXiv:2207.10278",
    "title": "Beyond single receptive field: A receptive field  fusion-and-stratification network for airborne laser scanning point cloud  classification",
    "abstract": "The classification of airborne laser scanning (ALS) point clouds is a\ncritical task of remote sensing and photogrammetry fields. Although recent deep\nlearning-based methods have achieved satisfactory performance, they have\nignored the unicity of the receptive field, which makes the ALS point cloud\nclassification remain challenging for the distinguishment of the areas with\ncomplex structures and extreme scale variations. In this article, for the\nobjective of configuring multi-receptive field features, we propose a novel\nreceptive field fusion-and-stratification network (RFFS-Net). With a novel\ndilated graph convolution (DGConv) and its extension annular dilated\nconvolution (ADConv) as basic building blocks, the receptive field fusion\nprocess is implemented with the dilated and annular graph fusion (DAGFusion)\nmodule, which obtains multi-receptive field feature representation through\ncapturing dilated and annular graphs with various receptive regions. The\nstratification of the receptive fields with point sets of different resolutions\nas the calculation bases is performed with Multi-level Decoders nested in\nRFFS-Net and driven by the multi-level receptive field aggregation loss\n(MRFALoss) to drive the network to learn in the direction of the supervision\nlabels with different resolutions. With receptive field\nfusion-and-stratification, RFFS-Net is more adaptable to the classification of\nregions with complex structures and extreme scale variations in large-scale ALS\npoint clouds. Evaluated on the ISPRS Vaihingen 3D dataset, our RFFS-Net\nsignificantly outperforms the baseline approach by 5.3% on mF1 and 5.4% on\nmIoU, accomplishing an overall accuracy of 82.1%, an mF1 of 71.6%, and an mIoU\nof 58.2%. Furthermore, experiments on the LASDU dataset and the 2019 IEEE-GRSS\nData Fusion Contest dataset show that RFFS-Net achieves a new state-of-the-art\nclassification performance.",
    "descriptor": "\nComments: accepted to ISPRS Journal\n",
    "authors": [
      "Yongqiang Mao",
      "Kaiqiang Chen",
      "Wenhui Diao",
      "Xian Sun",
      "Xiaonan Lu",
      "Kun Fu",
      "Martin Weinmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10278"
  },
  {
    "id": "arXiv:2207.10279",
    "title": "Gradient-based Point Cloud Denoising with Uniformity",
    "abstract": "Point clouds captured by depth sensors are often contaminated by noises,\nobstructing further analysis and applications. In this paper, we emphasize the\nimportance of point distribution uniformity to downstream tasks. We demonstrate\nthat point clouds produced by existing gradient-based denoisers lack uniformity\ndespite having achieved promising quantitative results. To this end, we propose\nGPCD++, a gradient-based denoiser with an ultra-lightweight network named\nUniNet to address uniformity. Compared with previous state-of-the-art methods,\nour approach not only generates competitive or even better denoising results,\nbut also significantly improves uniformity which largely benefits applications\nsuch as surface reconstruction.",
    "descriptor": "",
    "authors": [
      "Tian-Xing Xu",
      "Yuan-Chen Guo",
      "Yong-Liang Yang",
      "Song-Hai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.10279"
  },
  {
    "id": "arXiv:2207.10281",
    "title": "Multi-element flow-driven spectral chaos (ME-FSC) method for uncertainty  quantification of dynamical systems",
    "abstract": "The flow-driven spectral chaos (FSC) is a recently developed method for\ntracking and quantifying uncertainties in the long-time response of stochastic\ndynamical systems using the spectral approach. The method uses a novel concept\ncalled 'enriched stochastic flow maps' as a means to construct an evolving\nfinite-dimensional random function space that is both accurate and\ncomputationally efficient in time. In this paper, we present a multi-element\nversion of the FSC method (the ME-FSC method for short) to tackle (mainly)\nthose dynamical systems that are inherently discontinuous over the probability\nspace. In ME-FSC, the random domain is partitioned into several elements, and\nthen the problem is solved separately on each random element using the FSC\nmethod. Subsequently, results are aggregated to compute the probability moments\nof interest using the law of total probability. To demonstrate the\neffectiveness of the ME-FSC method in dealing with discontinuities and\nlong-time integration of stochastic dynamical systems, four representative\nnumerical examples are presented in this paper, including the Van-der-Pol\noscillator problem and the Kraichnan-Orszag three-mode problem. Results show\nthat the ME-FSC method is capable of solving problems that have strong\nnonlinear dependencies over the probability space, both reliably and at low\ncomputational cost.",
    "descriptor": "\nComments: Preprint submitted to Journal of Computational Physics (Elsevier)\n",
    "authors": [
      "Hugo Esquivel",
      "Arun Prakash",
      "Guang Lin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10281"
  },
  {
    "id": "arXiv:2207.10282",
    "title": "An Evolutionary Game based Secure Clustering Protocol with Fuzzy Trust  Evaluation and Outlier Detection for Wireless Sensor Networks",
    "abstract": "Trustworthy and reliable data delivery is a challenging task in Wireless\nSensor Networks (WSNs) due to unique characteristics and constraints. To\nacquire secured data delivery and address the conflict between security and\nenergy, in this paper we present an evolutionary game based secure clustering\nprotocol with fuzzy trust evaluation and outlier detection for WSNs. Firstly, a\nfuzzy trust evaluation method is presented to transform the transmission\nevidences into trust values while effectively alleviating the trust\nuncertainty. And then, a K-Means based outlier detection scheme is proposed to\nfurther analyze plenty of trust values obtained via fuzzy trust evaluation or\ntrust recommendation. It can discover the commonalities and differences among\nsensor nodes while improving the accuracy of outlier detection. Finally, we\npresent an evolutionary game based secure clustering protocol to achieve a\ntrade-off between security assurance and energy saving for sensor nodes when\nelecting for the cluster heads. A sensor node which failed to be the cluster\nhead can securely choose its own head by isolating the suspicious nodes.\nSimulation results verify that our secure clustering protocol can effectively\ndefend the network against the attacks from internal selfish or compromised\nnodes. Correspondingly, the timely data transfer rate can be improved\nsignificantly.",
    "descriptor": "",
    "authors": [
      "Liu Yang",
      "Yinzhi Lu",
      "Simon X. Yang",
      "Yuanchang Zhong",
      "Tan Guo",
      "Zhifang Liang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10282"
  },
  {
    "id": "arXiv:2207.10283",
    "title": "Switching One-Versus-the-Rest Loss to Increase the Margin of Logits for  Adversarial Robustness",
    "abstract": "Defending deep neural networks against adversarial examples is a key\nchallenge for AI safety. To improve the robustness effectively, recent methods\nfocus on important data points near the decision boundary in adversarial\ntraining. However, these methods are vulnerable to Auto-Attack, which is an\nensemble of parameter-free attacks for reliable evaluation. In this paper, we\nexperimentally investigate the causes of their vulnerability and find that\nexisting methods reduce margins between logits for the true label and the other\nlabels while keeping their gradient norms non-small values. Reduced margins and\nnon-small gradient norms cause their vulnerability since the largest logit can\nbe easily flipped by the perturbation. Our experiments also show that the\nhistogram of the logit margins has two peaks, i.e., small and large logit\nmargins. From the observations, we propose switching one-versus-the-rest loss\n(SOVR), which uses one-versus-the-rest loss when data have small logit margins\nso that it increases the margins. We find that SOVR increases logit margins\nmore than existing methods while keeping gradient norms small and outperforms\nthem in terms of the robustness against Auto-Attack.",
    "descriptor": "\nComments: 20 pages, 16 figures\n",
    "authors": [
      "Sekitoshi Kanai",
      "Shin'ya Yamaguchi",
      "Masanori Yamada",
      "Hiroshi Takahashi",
      "Yasutoshi Ida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.10283"
  },
  {
    "id": "arXiv:2207.10284",
    "title": "Multi Resolution Analysis (MRA) for Approximate Self-Attention",
    "abstract": "Transformers have emerged as a preferred model for many tasks in natural\nlangugage processing and vision. Recent efforts on training and deploying\nTransformers more efficiently have identified many strategies to approximate\nthe self-attention matrix, a key module in a Transformer architecture.\nEffective ideas include various prespecified sparsity patterns, low-rank basis\nexpansions and combinations thereof. In this paper, we revisit classical\nMultiresolution Analysis (MRA) concepts such as Wavelets, whose potential value\nin this setting remains underexplored thus far. We show that simple\napproximations based on empirical feedback and design choices informed by\nmodern hardware and implementation challenges, eventually yield a MRA-based\napproach for self-attention with an excellent performance profile across most\ncriteria of interest. We undertake an extensive set of experiments and\ndemonstrate that this multi-resolution scheme outperforms most efficient\nself-attention proposals and is favorable for both short and long sequences.\nCode is available at \\url{https://github.com/mlpen/mra-attention}.",
    "descriptor": "\nComments: ICML2022\n",
    "authors": [
      "Zhanpeng Zeng",
      "Sourav Pal",
      "Jeffery Kline",
      "Glenn M Fung",
      "Vikas Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10284"
  },
  {
    "id": "arXiv:2207.10285",
    "title": "Grounding Visual Representations with Texts for Domain Generalization",
    "abstract": "Reducing the representational discrepancy between source and target domains\nis a key component to maximize the model generalization. In this work, we\nadvocate for leveraging natural language supervision for the domain\ngeneralization task. We introduce two modules to ground visual representations\nwith texts containing typical reasoning of humans: (1) Visual and Textual Joint\nEmbedder and (2) Textual Explanation Generator. The former learns the\nimage-text joint embedding space where we can ground high-level\nclass-discriminative information into the model. The latter leverages an\nexplainable model and generates explanations justifying the rationale behind\nits decision. To the best of our knowledge, this is the first work to leverage\nthe vision-and-language cross-modality approach for the domain generalization\ntask. Our experiments with a newly created CUB-DG benchmark dataset demonstrate\nthat cross-modality supervision can be successfully used to ground\ndomain-invariant visual representations and improve the model generalization.\nFurthermore, in the large-scale DomainBed benchmark, our proposed method\nachieves state-of-the-art results and ranks 1st in average performance for five\nmulti-domain datasets. The dataset and codes are available at\nhttps://github.com/mswzeus/GVRT.",
    "descriptor": "\nComments: 25 pages (including Supplementary Materials), ECCV 2022 camera ready version\n",
    "authors": [
      "Seonwoo Min",
      "Nokyung Park",
      "Siwon Kim",
      "Seunghyun Park",
      "Jinkyu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10285"
  },
  {
    "id": "arXiv:2207.10286",
    "title": "Comparative Study on Supervised versus Semi-supervised Machine Learning  for Anomaly Detection of In-vehicle CAN Network",
    "abstract": "As the central nerve of the intelligent vehicle control system, the\nin-vehicle network bus is crucial to the security of vehicle driving. One of\nthe best standards for the in-vehicle network is the Controller Area Network\n(CAN bus) protocol. However, the CAN bus is designed to be vulnerable to\nvarious attacks due to its lack of security mechanisms. To enhance the security\nof in-vehicle networks and promote the research in this area, based upon a\nlarge scale of CAN network traffic data with the extracted valuable features,\nthis study comprehensively compared fully-supervised machine learning with\nsemi-supervised machine learning methods for CAN message anomaly detection.\nBoth traditional machine learning models (including single classifier and\nensemble models) and neural network based deep learning models are evaluated.\nFurthermore, this study proposed a deep autoencoder based semi-supervised\nlearning method applied for CAN message anomaly detection and verified its\nsuperiority over other semi-supervised methods. Extensive experiments show that\nthe fully-supervised methods generally outperform semi-supervised ones as they\nare using more information as inputs. Typically the developed XGBoost based\nmodel obtained state-of-the-art performance with the best accuracy (98.65%),\nprecision (0.9853), and ROC AUC (0.9585) beating other methods reported in the\nliterature.",
    "descriptor": "\nComments: 6 pages, 5 figures, accepted by the 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022)\n",
    "authors": [
      "Yongqi Dong",
      "Kejia Chen",
      "Yinxuan Peng",
      "Zhiyuan Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10286"
  },
  {
    "id": "arXiv:2207.10287",
    "title": "Towards Accurate Open-Set Recognition via Background-Class  Regularization",
    "abstract": "In open-set recognition (OSR), classifiers should be able to reject\nunknown-class samples while maintaining high closed-set classification\naccuracy. To effectively solve the OSR problem, previous studies attempted to\nlimit latent feature space and reject data located outside the limited space\nvia offline analyses, e.g., distance-based feature analyses, or complicated\nnetwork architectures. To conduct OSR via a simple inference process (without\noffline analyses) in standard classifier architectures, we use distance-based\nclassifiers instead of conventional Softmax classifiers. Afterwards, we design\na background-class regularization strategy, which uses background-class data as\nsurrogates of unknown-class ones during training phase. Specifically, we\nformulate a novel regularization loss suitable for distance-based classifiers,\nwhich reserves sufficiently large class-wise latent feature spaces for known\nclasses and forces background-class samples to be located far away from the\nlimited spaces. Through our extensive experiments, we show that the proposed\nmethod provides robust OSR results, while maintaining high closed-set\nclassification accuracy.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Wonwoo Cho",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10287"
  },
  {
    "id": "arXiv:2207.10290",
    "title": "AugRmixAT: A Data Processing and Training Method for Improving Multiple  Robustness and Generalization Performance",
    "abstract": "Deep neural networks are powerful, but they also have shortcomings such as\ntheir sensitivity to adversarial examples, noise, blur, occlusion, etc.\nMoreover, ensuring the reliability and robustness of deep neural network models\nis crucial for their application in safety-critical areas. Much previous work\nhas been proposed to improve specific robustness. However, we find that the\nspecific robustness is often improved at the sacrifice of the additional\nrobustness or generalization ability of the neural network model. In\nparticular, adversarial training methods significantly hurt the generalization\nperformance on unperturbed data when improving adversarial robustness. In this\npaper, we propose a new data processing and training method, called AugRmixAT,\nwhich can simultaneously improve the generalization ability and multiple\nrobustness of neural network models. Finally, we validate the effectiveness of\nAugRmixAT on the CIFAR-10/100 and Tiny-ImageNet datasets. The experiments\ndemonstrate that AugRmixAT can improve the model's generalization performance\nwhile enhancing the white-box robustness, black-box robustness, common\ncorruption robustness, and partial occlusion robustness.",
    "descriptor": "\nComments: Accepted by ICME2022\n",
    "authors": [
      "Xiaoliang Liu",
      "Furao Shen",
      "Jian Zhao",
      "Changhai Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10290"
  },
  {
    "id": "arXiv:2207.10292",
    "title": "Image Generation Network for Covert Transmission in Online Social  Network",
    "abstract": "Online social networks have stimulated communications over the Internet more\nthan ever, making it possible for secret message transmission over such noisy\nchannels. In this paper, we propose a Coverless Image Steganography Network,\ncalled CIS-Net, that synthesizes a high-quality image directly conditioned on\nthe secret message to transfer. CIS-Net is composed of four modules, namely,\nthe Generation, Adversarial, Extraction, and Noise Module. The receiver can\nextract the hidden message without any loss even the images have been distorted\nby JPEG compression attacks. To disguise the behaviour of steganography, we\ncollected images in the context of profile photos and stickers and train our\nnetwork accordingly. As such, the generated images are more inclined to escape\nfrom malicious detection and attack. The distinctions from previous image\nsteganography methods are majorly the robustness and losslessness against\ndiverse attacks. Experiments over diverse public datasets have manifested the\nsuperior ability of anti-steganalysis.",
    "descriptor": "\nComments: ACMMM2022 Poster\n",
    "authors": [
      "Zhengxin You",
      "Qichao Ying",
      "Sheng Li",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10292"
  },
  {
    "id": "arXiv:2207.10293",
    "title": "Multi-task Cross Attention Network in Facial Behavior Analysis",
    "abstract": "Facial behavior analysis is a broad topic with various categories such as\nfacial emotion recognition, age and gender recognition, ... Many studies focus\non individual tasks while the multi-task learning approach is still open and\nrequires more research. In this paper, we present our solution and experiment\nresult for the Multi-Task Learning challenge of the Affective Behavior Analysis\nin-the-wild competition. The challenge is a combination of three tasks: action\nunit detection, facial expression recognition and valance-arousal estimation.\nTo address this challenge, we introduce a cross-attentive module to improve\nmulti-task learning performance. Additionally, a facial graph is applied to\ncapture the association among action units. As a result, we achieve the\nevaluation measure of 1.24 on the validation data provided by the organizers,\nwhich is better than the baseline result of 0.30.",
    "descriptor": "",
    "authors": [
      "Dang-Khanh Nguyen",
      "Sudarshan Pant",
      "Ngoc-Huynh Ho",
      "Guee-Sang Lee",
      "Soo-Huyng Kim",
      "Hyung-Jeong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10293"
  },
  {
    "id": "arXiv:2207.10295",
    "title": "Addressing Optimism Bias in Sequence Modeling for Reinforcement Learning",
    "abstract": "Impressive results in natural language processing (NLP) based on the\nTransformer neural network architecture have inspired researchers to explore\nviewing offline reinforcement learning (RL) as a generic sequence modeling\nproblem. Recent works based on this paradigm have achieved state-of-the-art\nresults in several of the mostly deterministic offline Atari and D4RL\nbenchmarks. However, because these methods jointly model the states and actions\nas a single sequencing problem, they struggle to disentangle the effects of the\npolicy and world dynamics on the return. Thus, in adversarial or stochastic\nenvironments, these methods lead to overly optimistic behavior that can be\ndangerous in safety-critical systems like autonomous driving. In this work, we\npropose a method that addresses this optimism bias by explicitly disentangling\nthe policy and world models, which allows us at test time to search for\npolicies that are robust to multiple possible futures in the environment. We\ndemonstrate our method's superior performance on a variety of autonomous\ndriving tasks in simulation.",
    "descriptor": "",
    "authors": [
      "Adam Villaflor",
      "Zhe Huang",
      "Swapnil Pande",
      "John Dolan",
      "Jeff Schneider"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10295"
  },
  {
    "id": "arXiv:2207.10296",
    "title": "Perspectives on distribution network flexible and curtailable resource  activation and needs assessment",
    "abstract": "A curtailable and flexible resource activation framework is proposed for\nsolving distribution network (DN) voltage and thermal congestions. This\nframework utilizes network state in absence of such flexible or curtailable\nresources as an input for calculating flexibility activation signal (FAS). FAS\ndesign is motivated by volt-Var and volt-watt inverter control. The FAS has\nsome similarities with optimal power flow duals, also referred to as locational\nmarginal prices. These dual variables are active in case of network violations.\nFAS due to drooping design, corrects prior to any network limit violations. The\nnonlinear resource dispatch optimal power flow (RDOPF) is convexified using\nsecond-order cone (SOC) relaxations. Three case studies are performed, which\nare compared using performance indices proposed in this work. The first case\nstudy highlights the multi-objective nature of SOC relaxed RDOPF and provides a\nPareto front tuning mechanism for reducing DN losses while also reducing the\noptimality gap of the SOC relaxed problem with respect to RDOPF. The second\ncase study presents a methodology for evaluating temporal and locational\nflexibility needs assessment of a DN, which DSO's can utilize for flexibility\nplanning. The last case study quantifies the impact of reactive power\nflexibility for a DN with varying load power factor. We observe that active\npower flexibility needs can be reduced by up to 50\\% for DN with power factor\nof 0.8.",
    "descriptor": "",
    "authors": [
      "Md Umar Hashmi",
      "Arpan Koirala",
      "Hakan Ergun",
      "Dirk Van Hertem"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10296"
  },
  {
    "id": "arXiv:2207.10297",
    "title": "Action2Score: An Embedding Approach To Score Player Action",
    "abstract": "Multiplayer Online Battle Arena (MOBA) is one of the most successful game\ngenres. MOBA games such as League of Legends have competitive environments\nwhere players race for their rank. In most MOBA games, a player's rank is\ndetermined by the match result (win or lose). It seems natural because of the\nnature of team play, but in some sense, it is unfair because the players who\nput a lot of effort lose their rank just in case of loss and some players even\nget free-ride on teammates' efforts in case of a win. To reduce the\nside-effects of the team-based ranking system and evaluate a player's\nperformance impartially, we propose a novel embedding model that converts a\nplayer's actions into quantitative scores based on the actions' respective\ncontribution to the team's victory. Our model is built using a sequence-based\ndeep learning model with a novel loss function working on the team match. The\nsequence-based deep learning model process the action sequence from the game\nstart to the end of a player in a team play using a GRU unit that takes a\nhidden state from the previous step and the current input selectively. The loss\nfunction is designed to help the action score to reflect the final score and\nthe success of the team. We showed that our model can evaluate a player's\nindividual performance fairly and analyze the contributions of the player's\nrespective actions.",
    "descriptor": "\nComments: 20 pages, 8 figures, 4 tables; accepted to ACM CHIPLAY 2022, and PACM on Human-Computer Interaction\n",
    "authors": [
      "Junho Jang",
      "Ji Young Woo",
      "Huy Kang Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10297"
  },
  {
    "id": "arXiv:2207.10298",
    "title": "Deep Learning for Unsupervised Anomaly Localization in Industrial  Images: A Survey",
    "abstract": "Currently, deep learning-based visual inspection has been highly successful\nwith the help of supervised learning methods. However, in real industrial\nscenarios, the scarcity of defect samples, the cost of annotation, and the lack\nof a priori knowledge of defects may render supervised-based methods\nineffective. In recent years, unsupervised anomaly localization algorithms have\nbecome more widely used in industrial inspection tasks. This paper aims to help\nresearchers in this field by comprehensively surveying recent achievements in\nunsupervised anomaly localization in industrial images using deep learning. The\nsurvey reviews more than 120 significant publications covering different\naspects of anomaly localization, mainly covering various concepts, challenges,\ntaxonomies, benchmark datasets, and quantitative performance comparisons of the\nmethods reviewed. In reviewing the achievements to date, this paper provides\ndetailed predictions and analysis of several future research directions. This\nreview provides detailed technical information for researchers interested in\nindustrial anomaly localization and who wish to apply it to the localization of\nanomalies in other fields.",
    "descriptor": "\nComments: submit to IEEE TIM\n",
    "authors": [
      "Xian Tao",
      "Xinyi Gong",
      "Xin Zhang",
      "Shaohua Yan",
      "Chandranath Adak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10298"
  },
  {
    "id": "arXiv:2207.10299",
    "title": "Learn From All: Erasing Attention Consistency for Noisy Label Facial  Expression Recognition",
    "abstract": "Noisy label Facial Expression Recognition (FER) is more challenging than\ntraditional noisy label classification tasks due to the inter-class similarity\nand the annotation ambiguity. Recent works mainly tackle this problem by\nfiltering out large-loss samples. In this paper, we explore dealing with noisy\nlabels from a new feature-learning perspective. We find that FER models\nremember noisy samples by focusing on a part of the features that can be\nconsidered related to the noisy labels instead of learning from the whole\nfeatures that lead to the latent truth. Inspired by that, we propose a novel\nErasing Attention Consistency (EAC) method to suppress the noisy samples during\nthe training process automatically. Specifically, we first utilize the flip\nsemantic consistency of facial images to design an imbalanced framework. We\nthen randomly erase input images and use flip attention consistency to prevent\nthe model from focusing on a part of the features. EAC significantly\noutperforms state-of-the-art noisy label FER methods and generalizes well to\nother tasks with a large number of classes like CIFAR100 and Tiny-ImageNet. The\ncode is available at\nhttps://github.com/zyh-uaiaaaa/Erasing-Attention-Consistency.",
    "descriptor": "",
    "authors": [
      "Yuhang Zhang",
      "Chengrui Wang",
      "Xu Ling",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10299"
  },
  {
    "id": "arXiv:2207.10302",
    "title": "On an Edge-Preserving Variational Model for Optical Flow Estimation",
    "abstract": "It is well known that classical formulations resembling the Horn and Schunck\nmodel are still largely competitive due to the modern implementation practices.\nIn most cases, these models outperform many modern flow estimation methods. In\nview of this, we propose an effective implementation design for an\nedge-preserving $L^1$ regularization approach to optical flow. The mathematical\nwell-posedness of our proposed model is studied in the space of functions of\nbounded variations $BV(\\Omega,\\mathbb{R}^2)$. The implementation scheme is\ndesigned in multiple steps. The flow field is computed using the robust\nChambolle-Pock primal-dual algorithm. Motivated by the recent studies of Castro\nand Donoho we extend the heuristic of iterated median filtering to our flow\nestimation. Further, to refine the flow edges we use the weighted median filter\nestablished by Li and Osher as a post-processing step. Our experiments on the\nMiddlebury dataset show that the proposed method achieves the best average\nangular and end-point errors compared to some of the state-of-the-art Horn and\nSchunck based variational methods.",
    "descriptor": "",
    "authors": [
      "Hirak Doshi",
      "N. Uday Kiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10302"
  },
  {
    "id": "arXiv:2207.10303",
    "title": "Frequency Permutation Subsets for Joint Radar and Communication",
    "abstract": "This paper focuses on waveform design for joint radar and communication\nsystems and presents a new subset selection process to improve the\ncommunication error rate performance and global accuracy of radar sensing of\nthe random stepped frequency permutation waveform. An optimal communication\nreceiver based on integer programming is proposed to handle any subset of\npermutations followed by a more efficient sub-optimal receiver based on the\nHungarian algorithm. Considering optimum maximum likelihood detection, the\nblock error rate is analyzed under both additive white Gaussian noise and\ncorrelated Rician fading. We propose two methods to select a permutation subset\nwith an improved block error rate and an efficient encoding scheme to map the\ninformation symbols to selected permutations under these subsets. From the\nradar perspective, the ambiguity function is analyzed with regards to the local\nand the global accuracy of target detection. Furthermore, a subset selection\nmethod to reduce the maximum sidelobe height is proposed by extending the\nproperties of Costas arrays. Finally, the process of remapping the frequency\ntones to the symbol set used to generate permutations is introduced as a method\nto improve both the communication and radar performances of the selected\npermutation subset.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Shalanika Dayarathna",
      "Rajitha Senanayake",
      "Peter Smith",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10303"
  },
  {
    "id": "arXiv:2207.10305",
    "title": "Subgraph Matching via Query-Conditioned Subgraph Matching Neural  Networks and Bi-Level Tree Search",
    "abstract": "Recent advances have shown the success of using reinforcement learning and\nsearch to solve NP-hard graph-related tasks, such as Traveling Salesman\nOptimization, Graph Edit Distance computation, etc. However, it remains unclear\nhow one can efficiently and accurately detect the occurrences of a small query\ngraph in a large target graph, which is a core operation in graph database\nsearch, biomedical analysis, social group finding, etc. This task is called\nSubgraph Matching which essentially performs subgraph isomorphism check between\na query graph and a large target graph. One promising approach to this\nclassical problem is the \"learning-to-search\" paradigm, where a reinforcement\nlearning (RL) agent is designed with a learned policy to guide a search\nalgorithm to quickly find the solution without any solved instances for\nsupervision. However, for the specific task of Subgraph Matching, though the\nquery graph is usually small given by the user as input, the target graph is\noften orders-of-magnitude larger. It poses challenges to the neural network\ndesign and can lead to solution and reward sparsity. In this paper, we propose\nN-BLS with two innovations to tackle the challenges: (1) A novel\nencoder-decoder neural network architecture to dynamically compute the matching\ninformation between the query and the target graphs at each search state; (2) A\nMonte Carlo Tree Search enhanced bi-level search framework for training the\npolicy and value networks. Experiments on five large real-world target graphs\nshow that N-BLS can significantly improve the subgraph matching performance.",
    "descriptor": "",
    "authors": [
      "Yunsheng Bai",
      "Derek Xu",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10305"
  },
  {
    "id": "arXiv:2207.10307",
    "title": "Knowledge-enhanced Black-box Attacks for Recommendations",
    "abstract": "Recent studies have shown that deep neural networks-based recommender systems\nare vulnerable to adversarial attacks, where attackers can inject carefully\ncrafted fake user profiles (i.e., a set of items that fake users have\ninteracted with) into a target recommender system to achieve malicious\npurposes, such as promote or demote a set of target items. Due to the security\nand privacy concerns, it is more practical to perform adversarial attacks under\nthe black-box setting, where the architecture/parameters and training data of\ntarget systems cannot be easily accessed by attackers. However, generating\nhigh-quality fake user profiles under black-box setting is rather challenging\nwith limited resources to target systems. To address this challenge, in this\nwork, we introduce a novel strategy by leveraging items' attribute information\n(i.e., items' knowledge graph), which can be publicly accessible and provide\nrich auxiliary knowledge to enhance the generation of fake user profiles. More\nspecifically, we propose a knowledge graph-enhanced black-box attacking\nframework (KGAttack) to effectively learn attacking policies through deep\nreinforcement learning techniques, in which knowledge graph is seamlessly\nintegrated into hierarchical policy networks to generate fake user profiles for\nperforming adversarial black-box attacks. Comprehensive experiments on various\nreal-world datasets demonstrate the effectiveness of the proposed attacking\nframework under the black-box setting.",
    "descriptor": "\nComments: Accepted in the KDD'22\n",
    "authors": [
      "Jingfan Chen",
      "Wenqi Fan",
      "Guanghui Zhu",
      "Xiangyu Zhao",
      "Chunfeng Yuan",
      "Qing Li",
      "Yihua Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.10307"
  },
  {
    "id": "arXiv:2207.10308",
    "title": "UniFed: A Benchmark for Federated Learning Frameworks",
    "abstract": "Federated Learning (FL) has become a practical and popular paradigm in\nmachine learning. However, currently, there is no systematic solution that\ncovers diverse use cases. Practitioners often face the challenge of how to\nselect a matching FL framework for their use case. In this work, we present\nUniFed, the first unified benchmark for standardized evaluation of the existing\nopen-source FL frameworks. With 15 evaluation scenarios, we present both\nqualitative and quantitative evaluation results of nine existing popular\nopen-sourced FL frameworks, from the perspectives of functionality, usability,\nand system performance. We also provide suggestions on framework selection\nbased on the benchmark conclusions and point out future improvement directions.",
    "descriptor": "\nComments: Code: this https URL Website: this https URL\n",
    "authors": [
      "Xiaoyuan Liu",
      "Tianneng Shi",
      "Chulin Xie",
      "Qinbin Li",
      "Kangping Hu",
      "Haoyu Kim",
      "Xiaojun Xu",
      "Bo Li",
      "Dawn Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10308"
  },
  {
    "id": "arXiv:2207.10309",
    "title": "A Survey on Leveraging Pre-trained Generative Adversarial Networks for  Image Editing and Restoration",
    "abstract": "Generative adversarial networks (GANs) have drawn enormous attention due to\nthe simple yet effective training mechanism and superior image generation\nquality. With the ability to generate photo-realistic high-resolution (e.g.,\n$1024\\times1024$) images, recent GAN models have greatly narrowed the gaps\nbetween the generated images and the real ones. Therefore, many recent works\nshow emerging interest to take advantage of pre-trained GAN models by\nexploiting the well-disentangled latent space and the learned GAN priors. In\nthis paper, we briefly review recent progress on leveraging pre-trained\nlarge-scale GAN models from three aspects, i.e., 1) the training of large-scale\ngenerative adversarial networks, 2) exploring and understanding the pre-trained\nGAN models, and 3) leveraging these models for subsequent tasks like image\nrestoration and editing. More information about relevant methods and\nrepositories can be found at https://github.com/csmliu/pretrained-GANs.",
    "descriptor": "\nComments: 25 pages, 11 figures\n",
    "authors": [
      "Ming Liu",
      "Yuxiang Wei",
      "Xiaohe Wu",
      "Wangmeng Zuo",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.10309"
  },
  {
    "id": "arXiv:2207.10312",
    "title": "AdaNeRF: Adaptive Sampling for Real-time Rendering of Neural Radiance  Fields",
    "abstract": "Novel view synthesis has recently been revolutionized by learning neural\nradiance fields directly from sparse observations. However, rendering images\nwith this new paradigm is slow due to the fact that an accurate quadrature of\nthe volume rendering equation requires a large number of samples for each ray.\nPrevious work has mainly focused on speeding up the network evaluations that\nare associated with each sample point, e.g., via caching of radiance values\ninto explicit spatial data structures, but this comes at the expense of model\ncompactness. In this paper, we propose a novel dual-network architecture that\ntakes an orthogonal direction by learning how to best reduce the number of\nrequired sample points. To this end, we split our network into a sampling and\nshading network that are jointly trained. Our training scheme employs fixed\nsample positions along each ray, and incrementally introduces sparsity\nthroughout training to achieve high quality even at low sample counts. After\nfine-tuning with the target number of samples, the resulting compact neural\nrepresentation can be rendered in real-time. Our experiments demonstrate that\nour approach outperforms concurrent compact neural representations in terms of\nquality and frame rate and performs on par with highly efficient hybrid\nrepresentations. Code and supplementary material is available at\nhttps://thomasneff.github.io/adanerf.",
    "descriptor": "\nComments: ECCV 2022. Project page: this https URL\n",
    "authors": [
      "Andreas Kurz",
      "Thomas Neff",
      "Zhaoyang Lv",
      "Michael Zollh\u00f6fer",
      "Markus Steinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.10312"
  },
  {
    "id": "arXiv:2207.10314",
    "title": "Semi-Supervised Learning of Optical Flow by Flow Supervisor",
    "abstract": "A training pipeline for optical flow CNNs consists of a pretraining stage on\na synthetic dataset followed by a fine tuning stage on a target dataset.\nHowever, obtaining ground truth flows from a target video requires a tremendous\neffort. This paper proposes a practical fine tuning method to adapt a\npretrained model to a target dataset without ground truth flows, which has not\nbeen explored extensively. Specifically, we propose a flow supervisor for\nself-supervision, which consists of parameter separation and a student output\nconnection. This design is aimed at stable convergence and better accuracy over\nconventional self-supervision methods which are unstable on the fine tuning\ntask. Experimental results show the effectiveness of our method compared to\ndifferent self-supervision methods for semi-supervised learning. In addition,\nwe achieve meaningful improvements over state-of-the-art optical flow models on\nSintel and KITTI benchmarks by exploiting additional unlabeled datasets. Code\nis available at https://github.com/iwbn/flow-supervisor.",
    "descriptor": "",
    "authors": [
      "Woobin Im",
      "Sebin Lee",
      "Sung-Eui Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10314"
  },
  {
    "id": "arXiv:2207.10315",
    "title": "SeedFormer: Patch Seeds based Point Cloud Completion with Upsample  Transformer",
    "abstract": "Point cloud completion has become increasingly popular among generation tasks\nof 3D point clouds, as it is a challenging yet indispensable problem to recover\nthe complete shape of a 3D object from its partial observation. In this paper,\nwe propose a novel SeedFormer to improve the ability of detail preservation and\nrecovery in point cloud completion. Unlike previous methods based on a global\nfeature vector, we introduce a new shape representation, namely Patch Seeds,\nwhich not only captures general structures from partial inputs but also\npreserves regional information of local patterns. Then, by integrating seed\nfeatures into the generation process, we can recover faithful details for\ncomplete point clouds in a coarse-to-fine manner. Moreover, we devise an\nUpsample Transformer by extending the transformer structure into basic\noperations of point generators, which effectively incorporates spatial and\nsemantic relationships between neighboring points. Qualitative and quantitative\nevaluations demonstrate that our method outperforms state-of-the-art completion\nnetworks on several benchmark datasets. Our code is available at\nhttps://github.com/hrzhou2/seedformer.",
    "descriptor": "\nComments: Camera-ready, to be published in ECCV 2022, with supplementary material\n",
    "authors": [
      "Haoran Zhou",
      "Yun Cao",
      "Wenqing Chu",
      "Junwei Zhu",
      "Tong Lu",
      "Ying Tai",
      "Chengjie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10315"
  },
  {
    "id": "arXiv:2207.10316",
    "title": "AutoAlignV2: Deformable Feature Aggregation for Dynamic Multi-Modal 3D  Object Detection",
    "abstract": "Point clouds and RGB images are two general perceptional sources in\nautonomous driving. The former can provide accurate localization of objects,\nand the latter is denser and richer in semantic information. Recently,\nAutoAlign presents a learnable paradigm in combining these two modalities for\n3D object detection. However, it suffers from high computational cost\nintroduced by the global-wise attention. To solve the problem, we propose\nCross-Domain DeformCAFA module in this work. It attends to sparse learnable\nsampling points for cross-modal relational modeling, which enhances the\ntolerance to calibration error and greatly speeds up the feature aggregation\nacross different modalities. To overcome the complex GT-AUG under multi-modal\nsettings, we design a simple yet effective cross-modal augmentation strategy on\nconvex combination of image patches given their depth information. Moreover, by\ncarrying out a novel image-level dropout training scheme, our model is able to\ninfer in a dynamic manner. To this end, we propose AutoAlignV2, a faster and\nstronger multi-modal 3D detection framework, built on top of AutoAlign.\nExtensive experiments on nuScenes benchmark demonstrate the effectiveness and\nefficiency of AutoAlignV2. Notably, our best model reaches 72.4 NDS on nuScenes\ntest leaderboard, achieving new state-of-the-art results among all published\nmulti-modal 3D object detectors. Code will be available at\nhttps://github.com/zehuichen123/AutoAlignV2.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Zehui Chen",
      "Zhenyu Li",
      "Shiquan Zhang",
      "Liangji Fang",
      "Qinhong Jiang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10316"
  },
  {
    "id": "arXiv:2207.10318",
    "title": "Efficient CNN Architecture Design Guided by Visualization",
    "abstract": "Modern efficient Convolutional Neural Networks(CNNs) always use Depthwise\nSeparable Convolutions(DSCs) and Neural Architecture Search(NAS) to reduce the\nnumber of parameters and the computational complexity. But some inherent\ncharacteristics of networks are overlooked. Inspired by visualizing feature\nmaps and N$\\times$N(N$>$1) convolution kernels, several guidelines are\nintroduced in this paper to further improve parameter efficiency and inference\nspeed. Based on these guidelines, our parameter-efficient CNN architecture,\ncalled \\textit{VGNetG}, achieves better accuracy and lower latency than\nprevious networks with about 30%$\\thicksim$50% parameters reduction. Our\nVGNetG-1.0MP achieves 67.7% top-1 accuracy with 0.99M parameters and 69.2%\ntop-1 accuracy with 1.14M parameters on ImageNet classification dataset.\nFurthermore, we demonstrate that edge detectors can replace learnable\ndepthwise convolution layers to mix features by replacing the N$\\times$N\nkernels with fixed edge detection kernels. And our VGNetF-1.5MP archives\n64.4%(-3.2%) top-1 accuracy and 66.2%(-1.4%) top-1 accuracy with additional\nGaussian kernels.",
    "descriptor": "\nComments: ICME 2022\n",
    "authors": [
      "Liangqi Zhang",
      "Haibo Shen",
      "Yihao Luo",
      "Xiang Cao",
      "Leixilan Pan",
      "Tianjiang Wang",
      "Qi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10318"
  },
  {
    "id": "arXiv:2207.10320",
    "title": "OIMNet++: Prototypical Normalization and Localization-aware Learning for  Person Search",
    "abstract": "We address the task of person search, that is, localizing and re-identifying\nquery persons from a set of raw scene images. Recent approaches are typically\nbuilt upon OIMNet, a pioneer work on person search, that learns joint person\nrepresentations for performing both detection and person re-identification\n(reID) tasks. To obtain the representations, they extract features from\npedestrian proposals, and then project them on a unit hypersphere with L2\nnormalization. These methods also incorporate all positive proposals, that\nsufficiently overlap with the ground truth, equally to learn person\nrepresentations for reID. We have found that 1) the L2 normalization without\nconsidering feature distributions degenerates the discriminative power of\nperson representations, and 2) positive proposals often also depict background\nclutter and person overlaps, which could encode noisy features to person\nrepresentations. In this paper, we introduce OIMNet++ that addresses the\naforementioned limitations. To this end, we introduce a novel normalization\nlayer, dubbed ProtoNorm, that calibrates features from pedestrian proposals,\nwhile considering a long-tail distribution of person IDs, enabling L2\nnormalized person representations to be discriminative. We also propose a\nlocalization-aware feature learning scheme that encourages better-aligned\nproposals to contribute more in learning discriminative representations.\nExperimental results and analysis on standard person search benchmarks\ndemonstrate the effectiveness of OIMNet++.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Sanghoon Lee",
      "Youngmin Oh",
      "Donghyeon Baek",
      "Junghyup Lee",
      "Bumsub Ham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10320"
  },
  {
    "id": "arXiv:2207.10321",
    "title": "Stochastic rounding variance and probabilistic bounds: A new approach *",
    "abstract": "Stochastic rounding (SR) offers an alternative to the deterministic IEEE-754\nfloating-point rounding modes. In some applications such as PDEs, ODEs and\nneural networks, SR empirically improves the numerical behavior and convergence\nto accurate solutions while no sound theoretical background has been provided.\nRecent works by Ipsen, Zhou, Higham, and Mary have computed SR probabilistic\nerror bounds for basic linear algebra kernels. For example, the inner product\nSR probabilistic bound of the forward error is proportional to $\\sqrt$ nu\ninstead of nu for the default rounding mode. To compute the bounds, these works\nshow that the errors accumulated in computation form a martingale. This paper\nproposes an alternative framework to characterize SR errors based on the\ncomputation of the variance. We pinpoint common error patterns in numerical\nalgorithms and propose a lemma that bounds their variance. For each probability\nand through Bienaym{\\'e}-Chebyshev inequality, this bound leads to better\nprobabilistic error bound in several situations. Our method has the advantage\nof providing a tight probabilistic bound for all algorithms fitting our model.\nWe show how the method can be applied to give SR error bounds for the inner\nproduct and Horner polynomial evaluation.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2207.03837\n",
    "authors": [
      "El-Mehdi El Arar",
      "Devan Sohier",
      "Pablo de Oliveira Castro",
      "Eric Petit"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10321"
  },
  {
    "id": "arXiv:2207.10330",
    "title": "Reinforcement learning for Energies of the future and carbon neutrality:  a Challenge Design",
    "abstract": "Current rapid changes in climate increase the urgency to change energy\nproduction and consumption management, to reduce carbon and other green-house\ngas production. In this context, the French electricity network management\ncompany RTE (R{\\'e}seau de Transport d'{\\'E}lectricit{\\'e}) has recently\npublished the results of an extensive study outlining various scenarios for\ntomorrow's French power management. We propose a challenge that will test the\nviability of such a scenario. The goal is to control electricity transportation\nin power networks, while pursuing multiple objectives: balancing production and\nconsumption, minimizing energetic losses, and keeping people and equipment safe\nand particularly avoiding catastrophic failures. While the importance of the\napplication provides a goal in itself, this challenge also aims to push the\nstate-of-the-art in a branch of Artificial Intelligence (AI) called\nReinforcement Learning (RL), which offers new possibilities to tackle control\nproblems. In particular, various aspects of the combination of Deep Learning\nand RL called Deep Reinforcement Learning remain to be harnessed in this\napplication domain. This challenge belongs to a series started in 2019 under\nthe name \"Learning to run a power network\" (L2RPN). In this new edition, we\nintroduce new more realistic scenarios proposed by RTE to reach carbon\nneutrality by 2050, retiring fossil fuel electricity production, increasing\nproportions of renewable and nuclear energy and introducing batteries.\nFurthermore, we provide a baseline using state-of-the-art reinforcement\nlearning algorithm to stimulate the future participants.",
    "descriptor": "",
    "authors": [
      "Ga\u00ebtan Serr\u00e9",
      "Eva Boguslawski",
      "Benjamin Donnot",
      "Adrien Pav\u00e3o",
      "Isabelle Guyon",
      "Antoine Marot"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10330"
  },
  {
    "id": "arXiv:2207.10334",
    "title": "Efficient Search of Multiple Neural Architectures with Different  Complexities via Importance Sampling",
    "abstract": "Neural architecture search (NAS) aims to automate architecture design\nprocesses and improve the performance of deep neural networks. Platform-aware\nNAS methods consider both performance and complexity and can find\nwell-performing architectures with low computational resources. Although\nordinary NAS methods result in tremendous computational costs owing to the\nrepetition of model training, one-shot NAS, which trains the weights of a\nsupernetwork containing all candidate architectures only once during the search\nprocess, has been reported to result in a lower search cost. This study focuses\non the architecture complexity-aware one-shot NAS that optimizes the objective\nfunction composed of the weighted sum of two metrics, such as the predictive\nperformance and number of parameters. In existing methods, the architecture\nsearch process must be run multiple times with different coefficients of the\nweighted sum to obtain multiple architectures with different complexities. This\nstudy aims at reducing the search cost associated with finding multiple\narchitectures. The proposed method uses multiple distributions to generate\narchitectures with different complexities and updates each distribution using\nthe samples obtained from multiple distributions based on importance sampling.\nThe proposed method allows us to obtain multiple architectures with different\ncomplexities in a single architecture search, resulting in reducing the search\ncost. The proposed method is applied to the architecture search of\nconvolutional neural networks on the CIAFR-10 and ImageNet datasets.\nConsequently, compared with baseline methods, the proposed method finds\nmultiple architectures with varying complexities while requiring less\ncomputational effort.",
    "descriptor": "\nComments: Accepted as a conference paper at the 31st International Conference on Artificial Neural Networks (ICANN 2022). The final authenticated publication will be available in the Springer Lecture Notes in Computer Science (LNCS)\n",
    "authors": [
      "Yuhei Noda",
      "Shota Saito",
      "Shinichi Shirakawa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.10334"
  },
  {
    "id": "arXiv:2207.10341",
    "title": "UFO: Unified Feature Optimization",
    "abstract": "This paper proposes a novel Unified Feature Optimization (UFO) paradigm for\ntraining and deploying deep models under real-world and large-scale scenarios,\nwhich requires a collection of multiple AI functions. UFO aims to benefit each\nsingle task with a large-scale pretraining on all tasks. Compared with the well\nknown foundation model, UFO has two different points of emphasis, i.e.,\nrelatively smaller model size and NO adaptation cost: 1) UFO squeezes a wide\nrange of tasks into a moderate-sized unified model in a multi-task learning\nmanner and further trims the model size when transferred to down-stream tasks.\n2) UFO does not emphasize transfer to novel tasks. Instead, it aims to make the\ntrimmed model dedicated for one or more already-seen task. With these two\ncharacteristics, UFO provides great convenience for flexible deployment, while\nmaintaining the benefits of large-scale pretraining. A key merit of UFO is that\nthe trimming process not only reduces the model size and inference consumption,\nbut also even improves the accuracy on certain tasks. Specifically, UFO\nconsiders the multi-task training and brings two-fold impact on the unified\nmodel: some closely related tasks have mutual benefits, while some tasks have\nconflicts against each other. UFO manages to reduce the conflicts and to\npreserve the mutual benefits through a novel Network Architecture Search (NAS)\nmethod. Experiments on a wide range of deep representation learning tasks\n(i.e., face recognition, person re-identification, vehicle re-identification\nand product retrieval) show that the model trimmed from UFO achieves higher\naccuracy than its single-task-trained counterpart and yet has smaller model\nsize, validating the concept of UFO. Besides, UFO also supported the release of\n17 billion parameters computer vision (CV) foundation model which is the\nlargest CV model in the industry.",
    "descriptor": "\nComments: Accepted in ECCV 2022\n",
    "authors": [
      "Teng Xi",
      "Yifan Sun",
      "Deli Yu",
      "Bi Li",
      "Nan Peng",
      "Gang Zhang",
      "Xinyu Zhang",
      "Zhigang Wang",
      "Jinwen Chen",
      "Jian Wang",
      "Lufei Liu",
      "Haocheng Feng",
      "Junyu Han",
      "Jingtuo Liu",
      "Errui Ding",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10341"
  },
  {
    "id": "arXiv:2207.10342",
    "title": "Language Model Cascades",
    "abstract": "Prompted models have demonstrated impressive few-shot learning abilities.\nRepeated interactions at test-time with a single model, or the composition of\nmultiple models together, further expands capabilities. These compositions are\nprobabilistic models, and may be expressed in the language of graphical models\nwith random variables whose values are complex data types such as strings.\nCases with control flow and dynamic structure require techniques from\nprobabilistic programming, which allow implementing disparate model structures\nand inference strategies in a unified language. We formalize several existing\ntechniques from this perspective, including scratchpads / chain of thought,\nverifiers, STaR, selection-inference, and tool use. We refer to the resulting\nprograms as language model cascades.",
    "descriptor": "\nComments: Presented as spotlight at the Beyond Bases workshop at ICML 2022 (this https URL)\n",
    "authors": [
      "David Dohan",
      "Winnie Xu",
      "Aitor Lewkowycz",
      "Jacob Austin",
      "David Bieber",
      "Raphael Gontijo Lopes",
      "Yuhuai Wu",
      "Henryk Michalewski",
      "Rif A. Saurous",
      "Jascha Sohl-dickstein",
      "Kevin Murphy",
      "Charles Sutton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10342"
  },
  {
    "id": "arXiv:2207.10345",
    "title": "CADyQ: Content-Aware Dynamic Quantization for Image Super-Resolution",
    "abstract": "Despite breakthrough advances in image super-resolution (SR) with\nconvolutional neural networks (CNNs), SR has yet to enjoy ubiquitous\napplications due to the high computational complexity of SR networks.\nQuantization is one of the promising approaches to solve this problem. However,\nexisting methods fail to quantize SR models with a bit-width lower than 8 bits,\nsuffering from severe accuracy loss due to fixed bit-width quantization applied\neverywhere. In this work, to achieve high average bit-reduction with less\naccuracy loss, we propose a novel Content-Aware Dynamic Quantization (CADyQ)\nmethod for SR networks that allocates optimal bits to local regions and layers\nadaptively based on the local contents of an input image. To this end, a\ntrainable bit selector module is introduced to determine the proper bit-width\nand quantization level for each layer and a given local image patch. This\nmodule is governed by the quantization sensitivity that is estimated by using\nboth the average magnitude of image gradient of the patch and the standard\ndeviation of the input feature of the layer. The proposed quantization pipeline\nhas been tested on various SR networks and evaluated on several standard\nbenchmarks extensively. Significant reduction in computational complexity and\nthe elevated restoration accuracy clearly demonstrate the effectiveness of the\nproposed CADyQ framework for SR. Codes are available at\nhttps://github.com/Cheeun/CADyQ.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Cheeun Hong",
      "Sungyong Baik",
      "Heewon Kim",
      "Seungjun Nah",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.10345"
  },
  {
    "id": "arXiv:2207.10347",
    "title": "Demystifying Dependency Bugs in Deep Learning Stack",
    "abstract": "Recent breakthroughs in deep learning (DL) techniques have stimulated\nsignificant growth in developing DL-enabled applications. These DL\napplications, built upon a heterogeneous and complex DL stack (e.g., Nvidia\nGPU, Linux, CUDA driver, Python runtime, and TensorFlow), are subject to\nsoftware and hardware dependencies across the DL stack. A persistent challenge\nin dependency management across the entire engineering lifecycle is posed by\nthe asynchronous and radical evolution as well as the complex version\nconstraints among dependencies. Developers might introduce dependency bugs\n(DBs) in selecting, using and maintaining dependencies. However, the\ncharacteristics of DBs in DL stack is still under-investigated, hindering\npractical solutions to dependency management in DL stack. To fill this gap,\nthis paper presents the first comprehensive study to characterize symptoms,\nroot causes and fix patterns of DBs across the whole DL stack with 326 DBs\ncollected from StackOverflow posts. For each DB, we first investigate the\nsymptom as well as the lifecyle stage and dependency where the symptom is\nexposed. Then, we analyze the root cause as well as the lifecycle stage and\ndependency where the root cause is introduced. Finally, we explore the fix\npattern as well as the knowledge sources that are used to fix it. Our findings\nfrom this study shed light on the implications on dependency management, e.g.,\nconstructing dependency knowledge graph for the entire DL stack, recommending\ndependencies, detecting, localizing and fixing dependency bugs, and upgrading\nand migrating dependencies.",
    "descriptor": "",
    "authors": [
      "Kaifeng Huang",
      "Bihuan Chen",
      "Susheng Wu",
      "Junmin Cao",
      "Lei Ma",
      "Xin Peng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.10347"
  },
  {
    "id": "arXiv:2207.10351",
    "title": "Auto Machine Learning for Medical Image Analysis by Unifying the Search  on Data Augmentation and Neural Architecture",
    "abstract": "Automated data augmentation, which aims at engineering augmentation policy\nautomatically, recently draw a growing research interest. Many previous\nauto-augmentation methods utilized a Density Matching strategy by evaluating\npolicies in terms of the test-time augmentation performance. In this paper, we\ntheoretically and empirically demonstrated the inconsistency between the train\nand validation set of small-scale medical image datasets, referred to as\nin-domain sampling bias. Next, we demonstrated that the in-domain sampling bias\nmight cause the inefficiency of Density Matching. To address the problem, an\nimproved augmentation search strategy, named Augmented Density Matching, was\nproposed by randomly sampling policies from a prior distribution for training.\nMoreover, an efficient automatical machine learning(AutoML) algorithm was\nproposed by unifying the search on data augmentation and neural architecture.\nExperimental results indicated that the proposed methods outperformed\nstate-of-the-art approaches on MedMNIST, a pioneering benchmark designed for\nAutoML in medical image analysis.",
    "descriptor": "",
    "authors": [
      "Jianwei Zhang",
      "Dong Li",
      "Lituan Wang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10351"
  },
  {
    "id": "arXiv:2207.10353",
    "title": "Secure Lightweight Authentication for Multi User IoT Environment",
    "abstract": "The Internet of Things (IoT) is giving a boost to a plethora of new\nopportunities for the robust and sustainable deployment of cyber physical\nsystems. The cornerstone of any IoT system is the sensing devices. These\nsensing devices have considerable resource constraints, including insufficient\nbattery capacity, CPU capability, and physical security. Because of such\nresource constraints, designing lightweight cryptographic protocols is an\nopportunity. Remote User Authentication ensures that two parties establish a\nsecure and durable session key. This study presents a lightweight and safe\nauthentication strategy for the user-gateway (U GW) IoT network model. The\nproposed system is designed leveraging Elliptic Curve Cryptography (ECC). We\nundertake a formal security analysis with both the Automated Validation of\nInternet Security Protocols (AVISPA) and Burrows Abadi Needham (BAN) logic\ntools and an information security assessment with the Delev Yao channel. We use\npublish subscribe based Message Queuing Telemetry Transport (MQTT) protocol for\ncommunication. Additionally, the performance analysis and comparison of\nsecurity features show that the proposed scheme is resilient to well known\ncryptographic threats.",
    "descriptor": "",
    "authors": [
      "Chintan Patel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10353"
  },
  {
    "id": "arXiv:2207.10354",
    "title": "Learning from Data with Noisy Labels Using Temporal Self-Ensemble",
    "abstract": "There are inevitably many mislabeled data in real-world datasets. Because\ndeep neural networks (DNNs) have an enormous capacity to memorize noisy labels,\na robust training scheme is required to prevent labeling errors from degrading\nthe generalization performance of DNNs. Current state-of-the-art methods\npresent a co-training scheme that trains dual networks using samples associated\nwith small losses. In practice, however, training two networks simultaneously\ncan burden computing resources. In this study, we propose a simple yet\neffective robust training scheme that operates by training only a single\nnetwork. During training, the proposed method generates temporal self-ensemble\nby sampling intermediate network parameters from the weight trajectory formed\nby stochastic gradient descent optimization. The loss sum evaluated with these\nself-ensembles is used to identify incorrectly labeled samples. In parallel,\nour method generates multi-view predictions by transforming an input data into\nvarious forms and considers their agreement to identify incorrectly labeled\nsamples. By combining the aforementioned metrics, we present the proposed {\\it\nself-ensemble-based robust training} (SRT) method, which can filter the samples\nwith noisy labels to reduce their influence on training. Experiments on\nwidely-used public datasets demonstrate that the proposed method achieves a\nstate-of-the-art performance in some categories without training the dual\nnetworks.",
    "descriptor": "",
    "authors": [
      "Jun Ho Lee",
      "Jae Soon Baik",
      "Tae Hwan Hwang",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10354"
  },
  {
    "id": "arXiv:2207.10355",
    "title": "Unimodal vs. Multimodal Siamese Networks for Outfit Completion",
    "abstract": "The popularity of online fashion shopping continues to grow. The ability to\noffer an effective recommendation to customers is becoming increasingly\nimportant. In this work, we focus on Fashion Outfits Challenge, part of SIGIR\n2022 Workshop on eCommerce. The challenge is centered around Fill in the Blank\n(FITB) task that implies predicting the missing outfit, given an incomplete\noutfit and a list of candidates. In this paper, we focus on applying siamese\nnetworks on the task. More specifically, we explore how combining information\nfrom multiple modalities (textual and visual modality) impacts the performance\nof the model on the task. We evaluate our model on the test split provided by\nthe challenge organizers and the test split with gold assignments that we\ncreated during the development phase. We discover that using both visual, and\nvisual and textual data demonstrates promising results on the task. We conclude\nby suggesting directions for further improvement of our method.",
    "descriptor": "\nComments: 3 pages, 2 figures\n",
    "authors": [
      "Mariya Hendriksen",
      "Viggo Overes"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.10355"
  },
  {
    "id": "arXiv:2207.10358",
    "title": "Domain Decomposition Learning Methods for Solving Elliptic Problems",
    "abstract": "With the aid of hardware and software developments, there has been a surge of\ninterests in solving partial differential equations by deep learning\ntechniques, and the integration with domain decomposition strategies has\nrecently attracted considerable attention due to its enhanced representation\nand parallelization capacity of the network solution. While there are already\nseveral works that substitute the numerical solver of overlapping Schwarz\nmethods with the deep learning approach, the non-overlapping counterpart has\nnot been thoroughly studied yet because of the inevitable interface overfitting\nproblem that would propagate the errors to neighbouring subdomains and\neventually hamper the convergence of outer iteration. In this work, a novel\nlearning approach, i.e., the compensated deep Ritz method, is proposed to\nenable the flux transmission across subregion interfaces with guaranteed\naccuracy, thereby allowing us to construct effective learning algorithms for\nrealizing the more general non-overlapping domain decomposition methods in the\npresence of overfitted interface conditions. Numerical experiments on a series\nof elliptic boundary value problems including the regular and irregular\ninterfaces, low and high dimensions, smooth and high-contrast coefficients on\nmultidomains are carried out to validate the effectiveness of our proposed\ndomain decomposition learning algorithms.",
    "descriptor": "",
    "authors": [
      "Qi Sun",
      "Xuejun Xu",
      "Haotian Yi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10358"
  },
  {
    "id": "arXiv:2207.10362",
    "title": "LocVTP: Video-Text Pre-training for Temporal Localization",
    "abstract": "Video-Text Pre-training (VTP) aims to learn transferable representations for\nvarious downstream tasks from large-scale web videos. To date, almost all\nexisting VTP methods are limited to retrieval-based downstream tasks, e.g.,\nvideo retrieval, whereas their transfer potentials on localization-based tasks,\ne.g., temporal grounding, are under-explored. In this paper, we experimentally\nanalyze and demonstrate the incompatibility of current VTP methods with\nlocalization tasks, and propose a novel Localization-oriented Video-Text\nPre-training framework, dubbed as LocVTP. Specifically, we perform the\nfine-grained contrastive alignment as a complement to the coarse-grained one by\na clip-word correspondence discovery scheme. To further enhance the temporal\nreasoning ability of the learned feature, we propose a context projection head\nand a temporal aware contrastive loss to perceive the contextual relationships.\nExtensive experiments on four downstream tasks across six datasets demonstrate\nthat our LocVTP achieves state-of-the-art performance on both retrieval-based\nand localization-based tasks. Furthermore, we conduct comprehensive ablation\nstudies and thorough analyses to explore the optimum model designs and training\nstrategies.",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Meng Cao",
      "Tianyu Yang",
      "Junwu Weng",
      "Can Zhang",
      "Jue Wang",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10362"
  },
  {
    "id": "arXiv:2207.10367",
    "title": "EC-KitY: Evolutionary Computation Tool Kit in Python with Seamless  Machine Learning Integration",
    "abstract": "EC-KitY is a comprehensive Python library for doing evolutionary computation\n(EC), licensed under GNU General Public License v3.0, and compatible with\nscikit-learn. Designed with modern software engineering and machine learning\nintegration in mind, EC-KitY can support all popular EC paradigms, including\ngenetic algorithms, genetic programming, coevolution, evolutionary\nmulti-objective optimization, and more. This paper provides an overview of the\npackage, including the ease of setting up an EC experiment, the architecture,\nthe main features, and a comparison with other libraries.",
    "descriptor": "\nComments: 6 pages, 1 figure, 1 table. Submitted to Elsevier SoftwareX\n",
    "authors": [
      "Moshe Sipper",
      "Tomer Halperin",
      "Itai Tzruia",
      "Achiya Elyasaf"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10367"
  },
  {
    "id": "arXiv:2207.10368",
    "title": "Land Classification in Satellite Images by Injecting Traditional  Features to CNN Models",
    "abstract": "Deep learning methods have been successfully applied to remote sensing\nproblems for several years. Among these methods, CNN based models have high\naccuracy in solving the land classification problem using satellite or aerial\nimages. Although these models have high accuracy, this generally comes with\nlarge memory size requirements. On the other hand, it is desirable to have\nsmall-sized models for applications, such as the ones implemented on unmanned\naerial vehicles, with low memory space. Unfortunately, small-sized CNN models\ndo not provide high accuracy as with their large-sized versions. In this study,\nwe propose a novel method to improve the accuracy of CNN models, especially the\nones with small size, by injecting traditional features to them. To test the\neffectiveness of the proposed method, we applied it to the CNN models\nSqueezeNet, MobileNetV2, ShuffleNetV2, VGG16, and ResNet50V2 having size 0.5 MB\nto 528 MB. We used the sample mean, gray level co-occurrence matrix features,\nHu moments, local binary patterns, histogram of oriented gradients, and color\ninvariants as traditional features for injection. We tested the proposed method\non the EuroSAT dataset to perform land classification. Our experimental results\nshow that the proposed method significantly improves the land classification\naccuracy especially when applied to small-sized CNN models.",
    "descriptor": "",
    "authors": [
      "Mehmet Cagri Aksoy",
      "Beril Sirmacek",
      "Cem Unsalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10368"
  },
  {
    "id": "arXiv:2207.10371",
    "title": "UAV Trajectory, User Association and Power Control for Multi-UAV Enabled  Energy Harvesting Communications: Offline Design and Online Reinforcement  Learning",
    "abstract": "In this paper, we consider multiple solar-powered wireless nodes which\nutilize the harvested solar energy to transmit collected data to multiple\nunmanned aerial vehicles (UAVs) in the uplink. In this context, we jointly\ndesign UAV flight trajectories, UAV-node communication associations, and uplink\npower control to effectively utilize the harvested energy and manage co-channel\ninterference within a finite time horizon. To ensure the fairness of wireless\nnodes, the design goal is to maximize the worst user rate. The joint design\nproblem is highly non-convex and requires causal (future) knowledge of the\ninstantaneous energy state information (ESI) and channel state information\n(CSI), which are difficult to predict in reality. To overcome these challenges,\nwe propose an offline method based on convex optimization that only utilizes\nthe average ESI and CSI. The problem is solved by three convex subproblems with\nsuccessive convex approximation (SCA) and alternative optimization. We further\ndesign an online convex-assisted reinforcement learning (CARL) method to\nimprove the system performance based on real-time environmental information. An\nidea of multi-UAV regulated flight corridors, based on the optimal offline UAV\ntrajectories, is proposed to avoid unnecessary flight exploration by UAVs and\nenables us to improve the learning efficiency and system performance, as\ncompared with the conventional reinforcement learning (RL) method. Computer\nsimulations are used to verify the effectiveness of the proposed methods. The\nproposed CARL method provides 25% and 12% improvement on the worst user rate\nover the offline and conventional RL methods.",
    "descriptor": "",
    "authors": [
      "Chien-Wei Fu",
      "Meng-Lin Ku",
      "Yu-Jia Chen",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.10371"
  },
  {
    "id": "arXiv:2207.10372",
    "title": "Convergence analysis of multi-step one-shot methods for linear inverse  problems",
    "abstract": "In this work we are interested in general linear inverse problems where the\ncorresponding forward problem is solved iteratively using fixed point methods.\nThen one-shot methods, which iterate at the same time on the forward problem\nsolution and on the inverse problem unknown, can be applied. We analyze two\nvariants of the so-called multi-step one-shot methods and establish sufficient\nconditions on the descent step for their convergence, by studying the\neigenvalues of the block matrix of the coupled iterations. Several numerical\nexperiments are provided to illustrate the convergence of these methods in\ncomparison with the classical usual and shifted gradient descent. In\nparticular, we observe that very few inner iterations on the forward problem\nare enough to guarantee good convergence of the inversion algorithm.",
    "descriptor": "",
    "authors": [
      "Marcella Bonazzoli",
      "Houssem Haddar",
      "Tuan Anh Vu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.10372"
  },
  {
    "id": "arXiv:2207.10376",
    "title": "Multi-Asset Closed-Loop Reservoir Management Using Deep Reinforcement  Learning",
    "abstract": "Closed-loop reservoir management (CLRM), in which history matching and\nproduction optimization are performed multiple times over the life of an asset,\ncan provide significant improvement in the specified objective. These\nprocedures are computationally expensive due to the large number of flow\nsimulations required for data assimilation and optimization. Existing CLRM\nprocedures are applied asset by asset, without utilizing information that could\nbe useful over a range assets. Here, we develop a CLRM framework for multiple\nassets with varying numbers of wells. We use deep reinforcement learning to\ntrain a single global control policy that is applicable for all assets\nconsidered. The new framework is an extension of a recently introduced control\npolicy methodology for individual assets. Embedding layers are incorporated\ninto the representation to handle the different numbers of decision variables\nthat arise for the different assets. Because the global control policy learns a\nunified representation of useful features from multiple assets, it is less\nexpensive to construct than asset-by-asset training (we observe about 3x\nspeedup in our examples). The production optimization problem includes a\nrelative-change constraint on the well settings, which renders the results\nsuitable for practical use. We apply the multi-asset CLRM framework to 2D and\n3D water-flooding examples. In both cases, four assets with different well\ncounts, well configurations, and geostatistical descriptions are considered.\nNumerical experiments demonstrate that the global control policy provides\nobjective function values, for both the 2D and 3D cases, that are nearly\nidentical to those from control policies trained individually for each asset.\nThis promising finding suggests that multi-asset CLRM may indeed represent a\nviable practical strategy.",
    "descriptor": "",
    "authors": [
      "Yusuf Nasir",
      "Louis J. Durlofsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Computational Physics (physics.comp-ph)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.10376"
  },
  {
    "id": "arXiv:2207.10379",
    "title": "Temporal Saliency Query Network for Efficient Video Recognition",
    "abstract": "Efficient video recognition is a hot-spot research topic with the explosive\ngrowth of multimedia data on the Internet and mobile devices. Most existing\nmethods select the salient frames without awareness of the class-specific\nsaliency scores, which neglect the implicit association between the saliency of\nframes and its belonging category. To alleviate this issue, we devise a novel\nTemporal Saliency Query (TSQ) mechanism, which introduces class-specific\ninformation to provide fine-grained cues for saliency measurement.\nSpecifically, we model the class-specific saliency measuring process as a\nquery-response task. For each category, the common pattern of it is employed as\na query and the most salient frames are responded to it. Then, the calculated\nsimilarities are adopted as the frame saliency scores. To achieve it, we\npropose a Temporal Saliency Query Network (TSQNet) that includes two\ninstantiations of the TSQ mechanism based on visual appearance similarities and\ntextual event-object relations. Afterward, cross-modality interactions are\nimposed to promote the information exchange between them. Finally, we use the\nclass-specific saliencies of the most confident categories generated by two\nmodalities to perform the selection of salient frames. Extensive experiments\ndemonstrate the effectiveness of our method by achieving state-of-the-art\nresults on ActivityNet, FCVID and Mini-Kinetics datasets. Our project page is\nat https://lawrencexia2008.github.io/projects/tsqnet .",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Boyang Xia",
      "Zhihao Wang",
      "Wenhao Wu",
      "Haoran Wang",
      "Jungong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10379"
  },
  {
    "id": "arXiv:2207.10383",
    "title": "Optimal locally recoverable codes with hierarchy from nested $F$-adic  expansions",
    "abstract": "In this paper we construct new optimal hierarchical locally recoverable\ncodes. Our construction is based on a combination of the ideas of\n\\cite{ballentine2019codes,sasidharan2015codes} with an algebraic number\ntheoretical approach that allows to give a finer tuning of the minimum distance\nof the intermediate code (allowing larger dimension of the final code), and to\nremove restrictions on the arithmetic properties of $q$ compared with the size\nof the locality sets in the hierarchy. In turn, we manage to obtain codes with\na wide set of parameters both for the size $q$ of the base field, and for the\nhierarchy size, while keeping the optimality of the codes we construct.",
    "descriptor": "\nComments: Comments are welcome!\n",
    "authors": [
      "Austin Dukes",
      "Giacomo Micheli",
      "Vincenzo Pallozzi Lavorante"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2207.10383"
  },
  {
    "id": "arXiv:2207.10384",
    "title": "Detecting and Preventing Shortcut Learning for Fair Medical AI using  Shortcut Testing (ShorT)",
    "abstract": "Machine learning (ML) holds great promise for improving healthcare, but it is\ncritical to ensure that its use will not propagate or amplify health\ndisparities. An important step is to characterize the (un)fairness of ML models\n- their tendency to perform differently across subgroups of the population -\nand to understand its underlying mechanisms. One potential driver of\nalgorithmic unfairness, shortcut learning, arises when ML models base\npredictions on improper correlations in the training data. However, diagnosing\nthis phenomenon is difficult, especially when sensitive attributes are causally\nlinked with disease. Using multi-task learning, we propose the first method to\nassess and mitigate shortcut learning as a part of the fairness assessment of\nclinical ML systems, and demonstrate its application to clinical tasks in\nradiology and dermatology. Finally, our approach reveals instances when\nshortcutting is not responsible for unfairness, highlighting the need for a\nholistic approach to fairness mitigation in medical AI.",
    "descriptor": "",
    "authors": [
      "Alexander Brown",
      "Nenad Tomasev",
      "Jan Freyberg",
      "Yuan Liu",
      "Alan Karthikesalingam",
      "Jessica Schrouff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10384"
  },
  {
    "id": "arXiv:2207.10385",
    "title": "Integrating Terrestrial and Non-terrestrial Networks: 3D Opportunities  and Challenges",
    "abstract": "Integrating terrestrial and non-terrestrial networks has the potential of\nconnecting the unconnected and enhancing the user experience for the\nalready-connected, with technological and societal implications of the greatest\nlong-term significance. A convergence of ground, air, and space wireless\ncommunications also represents a formidable endeavor for the mobile and\nsatellite communications industries alike, as it entails defining and\nintelligently orchestrating a new 3D wireless network architecture. In this\narticle, we present the key opportunities and challenges arising from this\n(r)evolution by presenting some of its disruptive use-cases and key building\nblocks, reviewing the relevant standardization activities, and pointing to open\nresearch problems. By considering two multi-operator paradigms, we also\nshowcase how terrestrial networks could be efficiently re-engineered to cater\nfor aerial services, or opportunistically complemented by non-terrestrial\ninfrastructure to augment their current capabilities.",
    "descriptor": "",
    "authors": [
      "Giovanni Geraci",
      "David Lopez-Perez",
      "Mohamed Benzaghta",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10385"
  },
  {
    "id": "arXiv:2207.10386",
    "title": "Temporal Verification with Answer-Effect Modification",
    "abstract": "Type-and-effect systems are a widely-used approach to program verification,\nverifying the result of a computation using types, and the behavior using\neffects. This paper extends an effect system for verifying temporal,\nvalue-dependent properties on event sequences yielded by programs to the\ndelimited control operators shift0/reset0. While these delimited control\noperators enable useful and powerful programming techniques, they hinder\nreasoning about the behavior of programs because of their ability to suspend,\nresume, discard, and duplicate delimited continuations. This problem is more\nserious in effect systems for temporal properties because these systems must be\ncapable of identifying what event sequences are yielded by captured\ncontinuations. Our key observation for achieving effective reasoning in the\npresence of the delimited control operators is that their use modifies answer\neffects, which are temporal effects of the continuations. Based on this\nobservation, we extend an effect system for temporal verification to\naccommodate answer-effect modification. Allowing answer-effect modification\nenables easily reasoning about traces that captured continuations yield.\nAnother novel feature of our effect system is the support for dependently-typed\ncontinuations, which allows us to reason about programs more precisely. We\nprove soundness of the effect system for finite event sequences via type safety\nand that for infinite event sequences using a logical relation.",
    "descriptor": "",
    "authors": [
      "Taro Sekiyama",
      "Hiroshi Unno"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.10386"
  },
  {
    "id": "arXiv:2207.10387",
    "title": "Pose for Everything: Towards Category-Agnostic Pose Estimation",
    "abstract": "Existing works on 2D pose estimation mainly focus on a certain category, e.g.\nhuman, animal, and vehicle. However, there are lots of application scenarios\nthat require detecting the poses/keypoints of the unseen class of objects. In\nthis paper, we introduce the task of Category-Agnostic Pose Estimation (CAPE),\nwhich aims to create a pose estimation model capable of detecting the pose of\nany class of object given only a few samples with keypoint definition. To\nachieve this goal, we formulate the pose estimation problem as a keypoint\nmatching problem and design a novel CAPE framework, termed POse Matching\nNetwork (POMNet). A transformer-based Keypoint Interaction Module (KIM) is\nproposed to capture both the interactions among different keypoints and the\nrelationship between the support and query images. We also introduce\nMulti-category Pose (MP-100) dataset, which is a 2D pose dataset of 100 object\ncategories containing over 20K instances and is well-designed for developing\nCAPE algorithms. Experiments show that our method outperforms other baseline\napproaches by a large margin. Codes and data are available at\nhttps://github.com/luminxu/Pose-for-Everything.",
    "descriptor": "\nComments: ECCV 2022 Oral\n",
    "authors": [
      "Lumin Xu",
      "Sheng Jin",
      "Wang Zeng",
      "Wentao Liu",
      "Chen Qian",
      "Wanli Ouyang",
      "Ping Luo",
      "Xiaogang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10387"
  },
  {
    "id": "arXiv:2207.10388",
    "title": "NSNet: Non-saliency Suppression Sampler for Efficient Video Recognition",
    "abstract": "It is challenging for artificial intelligence systems to achieve accurate\nvideo recognition under the scenario of low computation costs. Adaptive\ninference based efficient video recognition methods typically preview videos\nand focus on salient parts to reduce computation costs. Most existing works\nfocus on complex networks learning with video classification based objectives.\nTaking all frames as positive samples, few of them pay attention to the\ndiscrimination between positive samples (salient frames) and negative samples\n(non-salient frames) in supervisions. To fill this gap, in this paper, we\npropose a novel Non-saliency Suppression Network (NSNet), which effectively\nsuppresses the responses of non-salient frames. Specifically, on the frame\nlevel, effective pseudo labels that can distinguish between salient and\nnon-salient frames are generated to guide the frame saliency learning. On the\nvideo level, a temporal attention module is learned under dual video-level\nsupervisions on both the salient and the non-salient representations. Saliency\nmeasurements from both two levels are combined for exploitation of\nmulti-granularity complementary information. Extensive experiments conducted on\nfour well-known benchmarks verify our NSNet not only achieves the\nstate-of-the-art accuracy-efficiency trade-off but also present a significantly\nfaster (2.4~4.3x) practical inference speed than state-of-the-art methods. Our\nproject page is at https://lawrencexia2008.github.io/projects/nsnet .",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Boyang Xia",
      "Wenhao Wu",
      "Haoran Wang",
      "Rui Su",
      "Dongliang He",
      "Haosen Yang",
      "Xiaoran Fan",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10388"
  },
  {
    "id": "arXiv:2207.10390",
    "title": "On the Implementation of a Reinforcement Learning-based Capacity Sharing  Algorithm in O-RAN",
    "abstract": "The capacity sharing problem in Radio Access Network (RAN) slicing deals with\nthe distribution of the capacity available in each RAN node among various RAN\nslices to satisfy their traffic demands and efficiently use the radio\nresources. While several capacity sharing algorithmic solutions have been\nproposed in the literature, their practical implementation still remains as a\ngap. In this paper, the implementation of a Reinforcement Learning-based\ncapacity sharing algorithm over the O-RAN architecture is discussed, providing\ninsights into the operation of the involved interfaces and the containerization\nof the solution. Moreover, the description of the testbed implemented to\nvalidate the solution is included and some performance and validation results\nare presented.",
    "descriptor": "\nComments: Submitted to IEEE GLOBECOM 2022 workshop on NextGenRAN\n",
    "authors": [
      "Irene Vil\u00e0",
      "Oriol Sallent",
      "Jordi P\u00e9rez-Romero"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10390"
  },
  {
    "id": "arXiv:2207.10391",
    "title": "Error Compensation Framework for Flow-Guided Video Inpainting",
    "abstract": "The key to video inpainting is to use correlation information from as many\nreference frames as possible. Existing flow-based propagation methods split the\nvideo synthesis process into multiple steps: flow completion -> pixel\npropagation -> synthesis. However, there is a significant drawback that the\nerrors in each step continue to accumulate and amplify in the next step. To\nthis end, we propose an Error Compensation Framework for Flow-guided Video\nInpainting (ECFVI), which takes advantage of the flow-based method and offsets\nits weaknesses. We address the weakness with the newly designed flow completion\nmodule and the error compensation network that exploits the error guidance map.\nOur approach greatly improves the temporal consistency and the visual quality\nof the completed videos. Experimental results show the superior performance of\nour proposed method with the speed up of x6, compared to the state-of-the-art\nmethods. In addition, we present a new benchmark dataset for evaluation by\nsupplementing the weaknesses of existing test datasets.",
    "descriptor": "\nComments: ECCV2022 accepted\n",
    "authors": [
      "Jaeyeon Kang",
      "Seoung Wug Oh",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10391"
  },
  {
    "id": "arXiv:2207.10392",
    "title": "FADE: Fusing the Assets of Decoder and Encoder for Task-Agnostic  Upsampling",
    "abstract": "We consider the problem of task-agnostic feature upsampling in dense\nprediction where an upsampling operator is required to facilitate both\nregion-sensitive tasks like semantic segmentation and detail-sensitive tasks\nsuch as image matting. Existing upsampling operators often can work well in\neither type of the tasks, but not both. In this work, we present FADE, a novel,\nplug-and-play, and task-agnostic upsampling operator. FADE benefits from three\ndesign choices: i) considering encoder and decoder features jointly in\nupsampling kernel generation; ii) an efficient semi-shift convolutional\noperator that enables granular control over how each feature point contributes\nto upsampling kernels; iii) a decoder-dependent gating mechanism for enhanced\ndetail delineation. We first study the upsampling properties of FADE on toy\ndata and then evaluate it on large-scale semantic segmentation and image\nmatting. In particular, FADE reveals its effectiveness and task-agnostic\ncharacteristic by consistently outperforming recent dynamic upsampling\noperators in different tasks. It also generalizes well across convolutional and\ntransformer architectures with little computational overhead. Our work\nadditionally provides thoughtful insights on what makes for task-agnostic\nupsampling. Code is available at: this http URL",
    "descriptor": "\nComments: Accepted to ECCV 2022. Code is available at this http URL\n",
    "authors": [
      "Hao Lu",
      "Wenze Liu",
      "Hongtao Fu",
      "Zhiguo Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10392"
  },
  {
    "id": "arXiv:2207.10395",
    "title": "Sobolev Training for Implicit Neural Representations with Approximated  Image Derivatives",
    "abstract": "Recently, Implicit Neural Representations (INRs) parameterized by neural\nnetworks have emerged as a powerful and promising tool to represent different\nkinds of signals due to its continuous, differentiable properties, showing\nsuperiorities to classical discretized representations. However, the training\nof neural networks for INRs only utilizes input-output pairs, and the\nderivatives of the target output with respect to the input, which can be\naccessed in some cases, are usually ignored. In this paper, we propose a\ntraining paradigm for INRs whose target output is image pixels, to encode image\nderivatives in addition to image values in the neural network. Specifically, we\nuse finite differences to approximate image derivatives. We show how the\ntraining paradigm can be leveraged to solve typical INRs problems, i.e., image\nregression and inverse rendering, and demonstrate this training paradigm can\nimprove the data-efficiency and generalization capabilities of INRs. The code\nof our method is available at\n\\url{https://github.com/megvii-research/Sobolev_INRs}.",
    "descriptor": "",
    "authors": [
      "Wentao Yuan",
      "Qingtian Zhu",
      "Xiangyue Liu",
      "Yikang Ding",
      "Haotian Zhang",
      "Chi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10395"
  },
  {
    "id": "arXiv:2207.10397",
    "title": "CodeT: Code Generation with Generated Tests",
    "abstract": "Given a programming problem, pre-trained language models such as Codex have\ndemonstrated the ability to generate multiple different code solutions via\nsampling. However, selecting a correct or best solution from those samples\nstill remains a challenge. While an easy way to verify the correctness of a\ncode solution is through executing test cases, producing high-quality test\ncases is prohibitively expensive. In this paper, we explore the use of\npre-trained language models to automatically generate test cases, calling our\nmethod CodeT: Code generation with generated Tests. CodeT executes the code\nsolutions using the generated test cases, and then chooses the best solution\nbased on a dual execution agreement with both the generated test cases and\nother generated solutions. We evaluate CodeT on five different pre-trained\nmodels with both HumanEval and MBPP benchmarks. Extensive experimental results\ndemonstrate CodeT can achieve significant, consistent, and surprising\nimprovements over previous methods. For example, CodeT improves the pass@1 on\nHumanEval to 65.8%, an increase of absolute 18.8% on the code-davinci-002\nmodel, and an absolute 20+% improvement over previous state-of-the-art results.",
    "descriptor": "",
    "authors": [
      "Bei Chen",
      "Fengji Zhang",
      "Anh Nguyen",
      "Daoguang Zan",
      "Zeqi Lin",
      "Jian-Guang Lou",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.10397"
  },
  {
    "id": "arXiv:2207.10398",
    "title": "D2-TPred: Discontinuous Dependency for Trajectory Prediction under  Traffic Lights",
    "abstract": "A profound understanding of inter-agent relationships and motion behaviors is\nimportant to achieve high-quality planning when navigating in complex\nscenarios, especially at urban traffic intersections. We present a trajectory\nprediction approach with respect to traffic lights, D2-TPred, which uses a\nspatial dynamic interaction graph (SDG) and a behavior dependency graph (BDG)\nto handle the problem of discontinuous dependency in the spatial-temporal\nspace. Specifically, the SDG is used to capture spatial interactions by\nreconstructing sub-graphs for different agents with dynamic and changeable\ncharacteristics during each frame. The BDG is used to infer motion tendency by\nmodeling the implicit dependency of the current state on priors behaviors,\nespecially the discontinuous motions corresponding to acceleration,\ndeceleration, or turning direction. Moreover, we present a new dataset for\nvehicle trajectory prediction under traffic lights called VTP-TL. Our\nexperimental results show that our model achieves more than {20.45% and 20.78%\n}improvement in terms of ADE and FDE, respectively, on VTP-TL as compared to\nother trajectory prediction algorithms. The dataset and code are available at:\nhttps://github.com/VTP-TL/D2-TPred.",
    "descriptor": "\nComments: Accepted to ECCV2022, 17 pages, 6 figures. Project page: this https URL\n",
    "authors": [
      "Yuzhen Zhang",
      "Wentong Wang",
      "Weizhi Guo",
      "Pei Lv",
      "Mingliang Xu",
      "Wei Chen",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10398"
  },
  {
    "id": "arXiv:2207.10400",
    "title": "Correspondence Matters for Video Referring Expression Comprehension",
    "abstract": "We investigate the problem of video Referring Expression Comprehension (REC),\nwhich aims to localize the referent objects described in the sentence to visual\nregions in the video frames. Despite the recent progress, existing methods\nsuffer from two problems: 1) inconsistent localization results across video\nframes; 2) confusion between the referent and contextual objects. To this end,\nwe propose a novel Dual Correspondence Network (dubbed as DCNet) which\nexplicitly enhances the dense associations in both the inter-frame and\ncross-modal manners. Firstly, we aim to build the inter-frame correlations for\nall existing instances within the frames. Specifically, we compute the\ninter-frame patch-wise cosine similarity to estimate the dense alignment and\nthen perform the inter-frame contrastive learning to map them close in feature\nspace. Secondly, we propose to build the fine-grained patch-word alignment to\nassociate each patch with certain words. Due to the lack of this kind of\ndetailed annotations, we also predict the patch-word correspondence through the\ncosine similarity. Extensive experiments demonstrate that our DCNet achieves\nstate-of-the-art performance on both video and image REC benchmarks.\nFurthermore, we conduct comprehensive ablation studies and thorough analyses to\nexplore the optimal model designs. Notably, our inter-frame and cross-modal\ncontrastive losses are plug-and-play functions and are applicable to any video\nREC architectures. For example, by building on top of Co-grounding, we boost\nthe performance by 1.48% absolute improvement on Accu.@0.5 for VID-Sentence\ndataset.",
    "descriptor": "\nComments: Accepted by ACM MM\n",
    "authors": [
      "Meng Cao",
      "Ji Jiang",
      "Long Chen",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10400"
  },
  {
    "id": "arXiv:2207.10401",
    "title": "Detection and Mitigation of Corrupted Information in Distributed Model  Predictive Control Based on Resource Allocation",
    "abstract": "In distributed predictive control structures, communication among agents is\nrequired to achieve a consensus and approach an optimal global behavior. Such\nnegotiation mechanisms are sensitive to attacks on these exchanges. This paper\nproposes a monitoring scheme that detects and mitigates these attacks' effects\nin a resource allocation framework. The performance of the proposed method is\nillustrated through simulations of the temperature control of multiple rooms\nunder power scarcity.",
    "descriptor": "",
    "authors": [
      "Rafael Acc\u00e1cio Nogueira",
      "Romain Bourdais",
      "Herv\u00e9 Gu\u00e9guen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.10401"
  },
  {
    "id": "arXiv:2207.10402",
    "title": "Detecting Deepfake by Creating Spatio-Temporal Regularity Disruption",
    "abstract": "Despite encouraging progress in deepfake detection, generalization to unseen\nforgery types remains a significant challenge due to the limited forgery clues\nexplored during training. In contrast, we notice a common phenomenon in\ndeepfake: fake video creation inevitably disrupts the statistical regularity in\noriginal videos. Inspired by this observation, we propose to boost the\ngeneralization of deepfake detection by distinguishing the \"regularity\ndisruption\" that does not appear in real videos. Specifically, by carefully\nexamining the spatial and temporal properties, we propose to disrupt a real\nvideo through a Pseudo-fake Generator and create a wide range of pseudo-fake\nvideos for training. Such practice allows us to achieve deepfake detection\nwithout using fake videos and improves the generalization ability in a simple\nand efficient manner. To jointly capture the spatial and temporal disruptions,\nwe propose a Spatio-Temporal Enhancement block to learn the regularity\ndisruption across space and time on our self-created videos. Through\ncomprehensive experiments, our method exhibits excellent performance on several\ndatasets.",
    "descriptor": "",
    "authors": [
      "Jiazhi Guan",
      "Hang Zhou",
      "Mingming Gong",
      "Youjian Zhao",
      "Errui Ding",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10402"
  },
  {
    "id": "arXiv:2207.10404",
    "title": "Semantic-aware Modular Capsule Routing for Visual Question Answering",
    "abstract": "Visual Question Answering (VQA) is fundamentally compositional in nature, and\nmany questions are simply answered by decomposing them into modular\nsub-problems. The recent proposed Neural Module Network (NMN) employ this\nstrategy to question answering, whereas heavily rest with off-the-shelf layout\nparser or additional expert policy regarding the network architecture design\ninstead of learning from the data. These strategies result in the\nunsatisfactory adaptability to the semantically-complicated variance of the\ninputs, thereby hindering the representational capacity and generalizability of\nthe model. To tackle this problem, we propose a Semantic-aware modUlar caPsulE\nRouting framework, termed as SUPER, to better capture the instance-specific\nvision-semantic characteristics and refine the discriminative representations\nfor prediction. Particularly, five powerful specialized modules as well as\ndynamic routers are tailored in each layer of the SUPER network, and the\ncompact routing spaces are constructed such that a variety of customizable\nroutes can be sufficiently exploited and the vision-semantic representations\ncan be explicitly calibrated. We comparatively justify the effectiveness and\ngeneralization ability of our proposed SUPER scheme over five benchmark\ndatasets, as well as the parametric-efficient advantage. It is worth\nemphasizing that this work is not to pursue the state-of-the-art results in\nVQA. Instead, we expect that our model is responsible to provide a novel\nperspective towards architecture learning and representation calibration for\nVQA.",
    "descriptor": "\nComments: 12 pages, 4 figures, submitted to IEEE Transactions on Image Processing\n",
    "authors": [
      "Yudong Han",
      "Jianhua Yin",
      "Jianlong Wu",
      "Yinwei Wei",
      "Liqiang Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10404"
  },
  {
    "id": "arXiv:2207.10409",
    "title": "Sequence Models for Drone vs Bird Classification",
    "abstract": "Drone detection has become an essential task in object detection as drone\ncosts have decreased and drone technology has improved. It is, however,\ndifficult to detect distant drones when there is weak contrast, long range, and\nlow visibility. In this work, we propose several sequence classification\narchitectures to reduce the detected false-positive ratio of drone tracks.\nMoreover, we propose a new drone vs. bird sequence classification dataset to\ntrain and evaluate the proposed architectures. 3D CNN, LSTM, and Transformer\nbased sequence classification architectures have been trained on the proposed\ndataset to show the effectiveness of the proposed idea. As experiments show,\nusing sequence information, bird classification and overall F1 scores can be\nincreased by up to 73% and 35%, respectively. Among all sequence classification\nmodels, R(2+1)D-based fully convolutional model yields the best transfer\nlearning and fine-tuning results.",
    "descriptor": "\nComments: Submitted to AVSS 2022\n",
    "authors": [
      "Fatih Cagatay Akyon",
      "Erdem Akagunduz",
      "Sinan Onur Altinuc",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10409"
  },
  {
    "id": "arXiv:2207.10422",
    "title": "Differentiable Integrated Motion Prediction and Planning with Learnable  Cost Function for Autonomous Driving",
    "abstract": "Predicting the future states of surrounding traffic participants and planning\na safe, smooth, and socially compliant trajectory accordingly is crucial for\nautonomous vehicles. There are two major issues with the current autonomous\ndriving system: the prediction module is often decoupled from the planning\nmodule and the cost function for planning is hard to specify and tune. To\ntackle these issues, we propose an end-to-end differentiable framework that\nintegrates prediction and planning modules and is able to learn the cost\nfunction from data. Specifically, we employ a differentiable nonlinear\noptimizer as the motion planner, which takes the predicted trajectories of\nsurrounding agents given by the neural network as input and optimizes the\ntrajectory for the autonomous vehicle, thus enabling all operations in the\nframework to be differentiable including the cost function weights. The\nproposed framework is trained on a large-scale real-world driving dataset to\nimitate human driving trajectories in the entire driving scene and validated in\nboth open-loop and closed-loop manners. The open-loop testing results reveal\nthat the proposed method outperforms the baseline methods across a variety of\nmetrics and delivers planning-centric prediction results, allowing the planning\nmodule to output close-to-human trajectories. In closed-loop testing, the\nproposed method shows the ability to handle complex urban driving scenarios and\nrobustness against the distributional shift that imitation learning methods\nsuffer from. Importantly, we find that joint training of planning and\nprediction modules achieves better performance than planning with a separate\ntrained prediction module in both open-loop and closed-loop tests. Moreover,\nthe ablation study indicates that the learnable components in the framework are\nessential to ensure planning stability and performance.",
    "descriptor": "",
    "authors": [
      "Zhiyu Huang",
      "Haochen Liu",
      "Jingda Wu",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10422"
  },
  {
    "id": "arXiv:2207.10424",
    "title": "A Linter for Isabelle: Implementation and Evaluation",
    "abstract": "In interactive theorem proving, formalization quality is a key factor for\nmaintainability and re-usability of developments and can also impact\nproof-checking performance. Commonly, anti-patterns that cause quality issues\nare known to experienced users. However, in many theorem prover systems, there\nare no automatic tools to check for their presence and make less experienced\nusers aware of them. We attempt to fill this gap in the Isabelle environment by\ndeveloping a linter as a publicly available add-on component. The linter offers\nbasic configurability, extensibility, Isabelle/jEdit integration, and a\nstandalone command-line tool. We uncovered 480 potential problems in\nIsabelle/HOL, 14016 in other formalizations of the Isabelle distribution, and\nan astonishing 59573 in the AFP. With a specific lint bundle for AFP\nsubmissions, we found that submission guidelines were violated in 1595 cases.\nWe set out to alleviate problems in Isabelle/HOL and solved 168 of them so far;\nwe found that high-severity lints corresponded to actual problems most of the\ntime, individual users often made the same mistakes in many places, and that\nsolving those problems retrospectively amounts to a substantial amount of work.\nIn contrast, solving these problems interactively for new developments usually\nincurs only little overhead, as we found in a quantitative user survey with 22\nparticipants (less than a minute for more than 60% of participants). We also\nfound that a good explanation of problems is key to the users' ease of solving\nthese problems (correlation coefficient 0.48), and their satisfaction with the\nend result (correlation coefficient 0.62).",
    "descriptor": "\nComments: Isabelle Workshop 2022\n",
    "authors": [
      "Yecine Megdiche",
      "Fabian Huch",
      "Lukas Stevens"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.10424"
  },
  {
    "id": "arXiv:2207.10425",
    "title": "KD-MVS: Knowledge Distillation Based Self-supervised Learning for MVS",
    "abstract": "Supervised multi-view stereo (MVS) methods have achieved remarkable progress\nin terms of reconstruction quality, but suffer from the challenge of collecting\nlarge-scale ground-truth depth. In this paper, we propose a novel\nself-supervised training pipeline for MVS based on knowledge distillation,\ntermed \\textit{KD-MVS}, which mainly consists of self-supervised teacher\ntraining and distillation-based student training. Specifically, the teacher\nmodel is trained in a self-supervised fashion using both photometric and\nfeaturemetric consistency. Then we distill the knowledge of the teacher model\nto the student model through probabilistic knowledge transferring. With the\nsupervision of validated knowledge, the student model is able to outperform its\nteacher by a large margin. Extensive experiments performed on multiple datasets\nshow our method can even outperform supervised methods.",
    "descriptor": "",
    "authors": [
      "Yikang Ding",
      "Qingtian Zhu",
      "Xiangyue Liu",
      "Wentao Yuan",
      "Haotian Zhang",
      "CHi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10425"
  },
  {
    "id": "arXiv:2207.10430",
    "title": "The Neural Race Reduction: Dynamics of Abstraction in Gated Networks",
    "abstract": "Our theoretical understanding of deep learning has not kept pace with its\nempirical success. While network architecture is known to be critical, we do\nnot yet understand its effect on learned representations and network behavior,\nor how this architecture should reflect task structure.In this work, we begin\nto address this gap by introducing the Gated Deep Linear Network framework that\nschematizes how pathways of information flow impact learning dynamics within an\narchitecture. Crucially, because of the gating, these networks can compute\nnonlinear functions of their input. We derive an exact reduction and, for\ncertain cases, exact solutions to the dynamics of learning. Our analysis\ndemonstrates that the learning dynamics in structured networks can be\nconceptualized as a neural race with an implicit bias towards shared\nrepresentations, which then govern the model's ability to systematically\ngeneralize, multi-task, and transfer. We validate our key insights on\nnaturalistic datasets and with relaxed assumptions. Taken together, our work\ngives rise to general hypotheses relating neural architecture to learning and\nprovides a mathematical approach towards understanding the design of more\ncomplex architectures and the role of modularity and compositionality in\nsolving real-world problems. The code and results are available at\nhttps://www.saxelab.org/gated-dln .",
    "descriptor": "\nComments: ICML 2022; 23 pages; 10 figures\n",
    "authors": [
      "Andrew M. Saxe",
      "Shagun Sodhani",
      "Sam Lewallen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10430"
  },
  {
    "id": "arXiv:2207.10432",
    "title": "A Wavelet Transform and self-supervised learning-based framework for  bearing fault diagnosis with limited labeled data",
    "abstract": "Traditional supervised bearing fault diagnosis methods rely on massive\nlabelled data, yet annotations may be very time-consuming or infeasible. The\nfault diagnosis approach that utilizes limited labelled data is becoming\nincreasingly popular. In this paper, a Wavelet Transform (WT) and\nself-supervised learning-based bearing fault diagnosis framework is proposed to\naddress the lack of supervised samples issue. Adopting the WT and cubic spline\ninterpolation technique, original measured vibration signals are converted to\nthe time-frequency maps (TFMs) with a fixed scale as inputs. The Vision\nTransformer (ViT) is employed as the encoder for feature extraction, and the\nself-distillation with no labels (DINO) algorithm is introduced in the proposed\nframework for self-supervised learning with limited labelled data and\nsufficient unlabeled data. Two rolling bearing fault datasets are used for\nvalidations. In the case of both datasets only containing 1% labelled samples,\nutilizing the feature vectors extracted by the trained encoder without\nfine-tuning, over 90\\% average diagnosis accuracy can be obtained based on the\nsimple K-Nearest Neighbor (KNN) classifier. Furthermore, the superiority of the\nproposed method is demonstrated in comparison with other self-supervised fault\ndiagnosis methods.",
    "descriptor": "\nComments: 20 pages, 9 figures, 6 tables\n",
    "authors": [
      "Yuhong Jin",
      "Lei Hou",
      "Ming Du",
      "Yushu Chen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2207.10432"
  },
  {
    "id": "arXiv:2207.10433",
    "title": "StreamYOLO: Real-time Object Detection for Streaming Perception",
    "abstract": "The perceptive models of autonomous driving require fast inference within a\nlow latency for safety. While existing works ignore the inevitable\nenvironmental changes after processing, streaming perception jointly evaluates\nthe latency and accuracy into a single metric for video online perception,\nguiding the previous works to search trade-offs between accuracy and speed. In\nthis paper, we explore the performance of real time models on this metric and\nendow the models with the capacity of predicting the future, significantly\nimproving the results for streaming perception. Specifically, we build a simple\nframework with two effective modules. One is a Dual Flow Perception module\n(DFP). It consists of dynamic flow and static flow in parallel to capture\nmoving tendency and basic detection feature, respectively. Trend Aware Loss\n(TAL) is the other module which adaptively generates loss weight for each\nobject with its moving speed. Realistically, we consider multiple velocities\ndriving scene and further propose Velocity-awared streaming AP (VsAP) to\njointly evaluate the accuracy. In this realistic setting, we design a efficient\nmix-velocity training strategy to guide detector perceive any velocities. Our\nsimple method achieves the state-of-the-art performance on Argoverse-HD dataset\nand improves the sAP and VsAP by 4.7% and 8.2% respectively compared to the\nstrong baseline, validating its effectiveness.",
    "descriptor": "\nComments: Extended version of arXiv:2203.12338\n",
    "authors": [
      "Jinrong Yang",
      "Songtao Liu",
      "Zeming Li",
      "Xiaoping Li",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10433"
  },
  {
    "id": "arXiv:2207.10434",
    "title": "DC-ShadowNet: Single-Image Hard and Soft Shadow Removal Using  Unsupervised Domain-Classifier Guided Network",
    "abstract": "Shadow removal from a single image is generally still an open problem. Most\nexisting learning-based methods use supervised learning and require a large\nnumber of paired images (shadow and corresponding non-shadow images) for\ntraining. A recent unsupervised method, Mask-ShadowGAN, addresses this\nlimitation. However, it requires a binary mask to represent shadow regions,\nmaking it inapplicable to soft shadows. To address the problem, in this paper,\nwe propose an unsupervised domain-classifier guided shadow removal network,\nDC-ShadowNet. Specifically, we propose to integrate a shadow/shadow-free domain\nclassifier into a generator and its discriminator, enabling them to focus on\nshadow regions. To train our network, we introduce novel losses based on\nphysics-based shadow-free chromaticity, shadow-robust perceptual features, and\nboundary smoothness. Moreover, we show that our unsupervised network can be\nused for test-time training that further improves the results. Our experiments\nshow that all these novel components allow our method to handle soft shadows,\nand also to perform better on hard shadows both quantitatively and\nqualitatively than the existing state-of-the-art shadow removal methods.",
    "descriptor": "\nComments: Accepted to ICCV2021, this https URL\n",
    "authors": [
      "Yeying Jin",
      "Aashish Sharma",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10434"
  },
  {
    "id": "arXiv:2207.10435",
    "title": "Human Trajectory Prediction via Neural Social Physics",
    "abstract": "Trajectory prediction has been widely pursued in many fields, and many\nmodel-based and model-free methods have been explored. The former include\nrule-based, geometric or optimization-based models, and the latter are mainly\ncomprised of deep learning approaches. In this paper, we propose a new method\ncombining both methodologies based on a new Neural Differential Equation model.\nOur new model (Neural Social Physics or NSP) is a deep neural network within\nwhich we use an explicit physics model with learnable parameters. The explicit\nphysics model serves as a strong inductive bias in modeling pedestrian\nbehaviors, while the rest of the network provides a strong data-fitting\ncapability in terms of system parameter estimation and dynamics stochasticity\nmodeling. We compare NSP with 15 recent deep learning methods on 6 datasets and\nimprove the state-of-the-art performance by 5.56%-70%. Besides, we show that\nNSP has better generalizability in predicting plausible trajectories in\ndrastically different scenarios where the density is 2-5 times as high as the\ntesting data. Finally, we show that the physics model in NSP can provide\nplausible explanations for pedestrian behaviors, as opposed to black-box deep\nlearning. Code is available:\nhttps://github.com/realcrane/Human-Trajectory-Prediction-via-Neural-Social-Physics.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Jiangbei Yue",
      "Dinesh Manocha",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10435"
  },
  {
    "id": "arXiv:2207.10436",
    "title": "Mining Relations among Cross-Frame Affinities for Video Semantic  Segmentation",
    "abstract": "The essence of video semantic segmentation (VSS) is how to leverage temporal\ninformation for prediction. Previous efforts are mainly devoted to developing\nnew techniques to calculate the cross-frame affinities such as optical flow and\nattention. Instead, this paper contributes from a different angle by mining\nrelations among cross-frame affinities, upon which better temporal information\naggregation could be achieved. We explore relations among affinities in two\naspects: single-scale intrinsic correlations and multi-scale relations.\nInspired by traditional feature processing, we propose Single-scale Affinity\nRefinement (SAR) and Multi-scale Affinity Aggregation (MAA). To make it\nfeasible to execute MAA, we propose a Selective Token Masking (STM) strategy to\nselect a subset of consistent reference tokens for different scales when\ncalculating affinities, which also improves the efficiency of our method. At\nlast, the cross-frame affinities strengthened by SAR and MAA are adopted for\nadaptively aggregating temporal information. Our experiments demonstrate that\nthe proposed method performs favorably against state-of-the-art VSS methods.\nThe code is publicly available at https://github.com/GuoleiSun/VSS-MRCFA",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Guolei Sun",
      "Yun Liu",
      "Hao Tang",
      "Ajad Chhatkuli",
      "Le Zhang",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10436"
  },
  {
    "id": "arXiv:2207.10437",
    "title": "Communication Lower Bounds and Optimal Algorithms for Multiple  Tensor-Times-Matrix Computation",
    "abstract": "Multiple Tensor-Times-Matrix (Multi-TTM) is a key computation in algorithms\nfor computing and operating with the Tucker tensor decomposition, which is\nfrequently used in multidimensional data analysis. We establish communication\nlower bounds that determine how much data movement is required to perform the\nMulti-TTM computation in parallel. The crux of the proof relies on analytically\nsolving a constrained, nonlinear optimization problem. We also present a\nparallel algorithm to perform this computation that organizes the processors\ninto a logical grid with twice as many modes as the input tensor. We show that\nwith correct choices of grid dimensions, the communication cost of the\nalgorithm attains the lower bounds and is therefore communication optimal.\nFinally, we show that our algorithm can significantly reduce communication\ncompared to the straightforward approach of expressing the computation as a\nsequence of tensor-times-matrix operations.",
    "descriptor": "",
    "authors": [
      "Hussam Al Daas",
      "Grey Ballard",
      "Laura Grigori",
      "Suraj Kumar",
      "Kathryn Rouse"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.10437"
  },
  {
    "id": "arXiv:2207.10438",
    "title": "Incorporating Prior Knowledge into Reinforcement Learning for Soft  Tissue Manipulation with Autonomous Grasping Point Selection",
    "abstract": "Previous soft tissue manipulation studies assumed that the grasping point was\nknown and the target deformation can be achieved. During the operation, the\nconstraints are supposed to be constant, and there is no obstacles around the\nsoft tissue. To go beyond these assumptions, a deep reinforcement learning\nframework with prior knowledge is proposed for soft tissue manipulation under\nunknown constraints, such as the force applied by fascia. The prior knowledge\nis represented through an intuitive manipulation strategy. As an action of the\nagent, a regulator factor is used to coordinate the intuitive approach and the\ndeliberate network. A reward function is designed to balance the exploration\nand exploitation for large deformation. Successful simulation results verify\nthat the proposed framework can manipulate the soft tissue while avoiding\nobstacles and adding new position constraints. Compared with the soft\nactor-critic (SAC) algorithm, the proposed framework can accelerate the\ntraining procedure and improve the generalization.",
    "descriptor": "",
    "authors": [
      "Xian He",
      "Shuai Zhang",
      "Shanlin Yang",
      "Bo Ouyang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10438"
  },
  {
    "id": "arXiv:2207.10441",
    "title": "Deep Audio Waveform Prior",
    "abstract": "Convolutional neural networks contain strong priors for generating natural\nlooking images [1]. These priors enable image denoising, super resolution, and\ninpainting in an unsupervised manner. Previous attempts to demonstrate similar\nideas in audio, namely deep audio priors, (i) use hand picked architectures\nsuch as harmonic convolutions, (ii) only work with spectrogram input, and (iii)\nhave been used mostly for eliminating Gaussian noise [2]. In this work we show\nthat existing SOTA architectures for audio source separation contain deep\npriors even when working with the raw waveform. Deep priors can be discovered\nby training a neural network to generate a single corrupted signal when given\nwhite noise as input. A network with relevant deep priors is likely to generate\na cleaner version of the signal before converging on the corrupted signal. We\ndemonstrate this restoration effect with several corruptions: background noise,\nreverberations, and a gap in the signal (audio inpainting).",
    "descriptor": "\nComments: Interspeech 2022\n",
    "authors": [
      "Arnon Turetzky",
      "Tzvi Michelson",
      "Yossi Adi",
      "Shmuel Peleg"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10441"
  },
  {
    "id": "arXiv:2207.10447",
    "title": "Weakly Supervised Object Localization via Transformer with Implicit  Spatial Calibration",
    "abstract": "Weakly Supervised Object Localization (WSOL), which aims to localize objects\nby only using image-level labels, has attracted much attention because of its\nlow annotation cost in real applications. Recent studies leverage the advantage\nof self-attention in visual Transformer for long-range dependency to re-active\nsemantic regions, aiming to avoid partial activation in traditional class\nactivation mapping (CAM). However, the long-range modeling in Transformer\nneglects the inherent spatial coherence of the object, and it usually diffuses\nthe semantic-aware regions far from the object boundary, making localization\nresults significantly larger or far smaller. To address such an issue, we\nintroduce a simple yet effective Spatial Calibration Module (SCM) for accurate\nWSOL, incorporating semantic similarities of patch tokens and their spatial\nrelationships into a unified diffusion model. Specifically, we introduce a\nlearnable parameter to dynamically adjust the semantic correlations and spatial\ncontext intensities for effective information propagation. In practice, SCM is\ndesigned as an external module of Transformer, and can be removed during\ninference to reduce the computation cost. The object-sensitive localization\nability is implicitly embedded into the Transformer encoder through\noptimization in the training phase. It enables the generated attention maps to\ncapture the sharper object boundaries and filter the object-irrelevant\nbackground area. Extensive experimental results demonstrate the effectiveness\nof the proposed method, which significantly outperforms its counterpart TS-CAM\non both CUB-200 and ImageNet-1K benchmarks. The code is available at\nhttps://github.com/164140757/SCM.",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Haotian Bai",
      "Ruimao Zhang",
      "Jiong Wang",
      "Xiang Wan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10447"
  },
  {
    "id": "arXiv:2207.10448",
    "title": "An Efficient Spatio-Temporal Pyramid Transformer for Action Detection",
    "abstract": "The task of action detection aims at deducing both the action category and\nlocalization of the start and end moment for each action instance in a long,\nuntrimmed video. While vision Transformers have driven the recent advances in\nvideo understanding, it is non-trivial to design an efficient architecture for\naction detection due to the prohibitively expensive self-attentions over a long\nsequence of video clips. To this end, we present an efficient hierarchical\nSpatio-Temporal Pyramid Transformer (STPT) for action detection, building upon\nthe fact that the early self-attention layers in Transformers still focus on\nlocal patterns. Specifically, we propose to use local window attention to\nencode rich local spatio-temporal representations in the early stages while\napplying global attention modules to capture long-term space-time dependencies\nin the later stages. In this way, our STPT can encode both locality and\ndependency with largely reduced redundancy, delivering a promising trade-off\nbetween accuracy and efficiency. For example, with only RGB input, the proposed\nSTPT achieves 53.6% mAP on THUMOS14, surpassing I3D+AFSD RGB model by over 10%\nand performing favorably against state-of-the-art AFSD that uses additional\nflow features with 31% fewer GFLOPs, which serves as an effective and efficient\nend-to-end Transformer-based framework for action detection.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Yuetian Weng",
      "Zizheng Pan",
      "Mingfei Han",
      "Xiaojun Chang",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10448"
  },
  {
    "id": "arXiv:2207.10449",
    "title": "Spectral Variational Multi-Scale method for parabolic problems.  Application to 1D transient advection-diffusion equations",
    "abstract": "In this work, we introduce a Variational Multi-Scale (VMS) method for the\nnumerical approximation of parabolic problems, where sub-grid scales are\napproximated from the eigenpairs of associated elliptic operator. The abstract\nmethod is particularized to the one-dimensional advection-diffusion equations,\nfor which the sub-grid components are exactly calculated in terms of a spectral\nexpansion when the advection velocity is approximated by piecewise constant\nvelocities on the grid elements.\nWe prove error estimates that in particular imply that when Lagrange finite\nelement discretisations in space are used, the spectral VMS method coincides\nwith the exact solution of the implicit Euler semi-discretisation of the\nadvection-diffusion problem at the Lagrange interpolation nodes. We also build\na feasible method to solve the evolutive advection-diffusion problems by means\nof an offline/online strategy with reduced computational complexity.\nWe perform some numerical tests in good agreement with the theoretical\nexpectations, that show an improved accuracy with respect to several stabilised\nmethods.",
    "descriptor": "",
    "authors": [
      "Chac\u00f3n Rebollo",
      "Tom\u00e1s",
      "Fern\u00e1ndez-Garc\u00eda",
      "Soledad",
      "Moreno-Lopez",
      "David",
      "S\u00e1nchez Mu\u00f1oz",
      "Isabel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10449"
  },
  {
    "id": "arXiv:2207.10454",
    "title": "Temporal and Spatial Online Integrated Calibration for Camera and LiDAR",
    "abstract": "While camera and LiDAR are widely used in most of the assisted and autonomous\ndriving systems, only a few works have been proposed to associate the temporal\nsynchronization and extrinsic calibration for camera and LiDAR which are\ndedicated to online sensors data fusion. The temporal and spatial calibration\ntechnologies are facing the challenges of lack of relevance and real-time. In\nthis paper, we introduce the pose estimation model and environmental robust\nline features extraction to improve the relevance of data fusion and instant\nonline ability of correction. Dynamic targets eliminating aims to seek optimal\npolicy considering the correspondence of point cloud matching between adjacent\nmoments. The searching optimization process aims to provide accurate parameters\nwith both computation accuracy and efficiency. To demonstrate the benefits of\nthis method, we evaluate it on the KITTI benchmark with ground truth value. In\nonline experiments, our approach improves the accuracy by 38.5\\% than the soft\nsynchronization method in temporal calibration. While in spatial calibration,\nour approach automatically corrects disturbance errors within 0.4 second and\nachieves an accuracy of 0.3-degree. This work can promote the research and\napplication of sensor fusion.",
    "descriptor": "",
    "authors": [
      "Shouan Wang",
      "Xinyu Zhang",
      "GuiPeng Zhang",
      "Yijin Xiong",
      "Ganglin Tian",
      "Shichun Guo",
      "Jun Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10454"
  },
  {
    "id": "arXiv:2207.10455",
    "title": "Magic ELF: Image Deraining Meets Association Learning and Transformer",
    "abstract": "Convolutional neural network (CNN) and Transformer have achieved great\nsuccess in multimedia applications. However, little effort has been made to\neffectively and efficiently harmonize these two architectures to satisfy image\nderaining. This paper aims to unify these two architectures to take advantage\nof their learning merits for image deraining. In particular, the local\nconnectivity and translation equivariance of CNN and the global aggregation\nability of self-attention (SA) in Transformer are fully exploited for specific\nlocal context and global structure representations. Based on the observation\nthat rain distribution reveals the degradation location and degree, we\nintroduce degradation prior to help background recovery and accordingly present\nthe association refinement deraining scheme. A novel multi-input attention\nmodule (MAM) is proposed to associate rain perturbation removal and background\nrecovery. Moreover, we equip our model with effective depth-wise separable\nconvolutions to learn the specific feature representations and trade off\ncomputational complexity. Extensive experiments show that our proposed method\n(dubbed as ELF) outperforms the state-of-the-art approach (MPRNet) by 0.25 dB\non average, but only accounts for 11.7\\% and 42.1\\% of its computational cost\nand parameters. The source code is available at\nhttps://github.com/kuijiang94/Magic-ELF.",
    "descriptor": "",
    "authors": [
      "Kui Jiang",
      "Zhongyuan Wang",
      "Chen Chen",
      "Zheng Wang",
      "Laizhong Cui",
      "Chia-Wen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10455"
  },
  {
    "id": "arXiv:2207.10456",
    "title": "Semantic-Aware Fine-Grained Correspondence",
    "abstract": "Establishing visual correspondence across images is a challenging and\nessential task. Recently, an influx of self-supervised methods have been\nproposed to better learn representations for visual correspondence. However, we\nfind that these methods often fail to leverage semantic information and\nover-rely on the matching of low-level features. In contrast, human vision is\ncapable of distinguishing between distinct objects as a pretext to tracking.\nInspired by this paradigm, we propose to learn semantic-aware fine-grained\ncorrespondence. Firstly, we demonstrate that semantic correspondence is\nimplicitly available through a rich set of image-level self-supervised methods.\nWe further design a pixel-level self-supervised learning objective which\nspecifically targets fine-grained correspondence. For downstream tasks, we fuse\nthese two kinds of complementary correspondence representations together,\ndemonstrating that they boost performance synergistically. Our method surpasses\nprevious state-of-the-art self-supervised methods using convolutional networks\non a variety of visual correspondence tasks, including video object\nsegmentation, human pose tracking, and human part tracking.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Yingdong Hu",
      "Renhao Wang",
      "Kaifeng Zhang",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10456"
  },
  {
    "id": "arXiv:2207.10457",
    "title": "A Survey of Robotic Harvesting Systems and Enabling Technologies",
    "abstract": "This paper presents a comprehensive review of ground agricultural robotic\nsystems and applications with special focus on harvesting that span research\nand commercial products and results, as well as their enabling technologies.\nThe majority of literature concerns the development of crop detection, field\nnavigation via vision and their related challenges. Health monitoring, yield\nestimation, water status inspection, seed planting and weed removal are\nfrequently encountered tasks. Regarding robotic harvesting, apples,\nstrawberries, tomatoes and sweet peppers are mainly the crops considered in\npublications, research projects and commercial products. The reported\nharvesting agricultural robotic solutions, typically consist of a mobile\nplatform, a single robotic arm/manipulator and various navigation/vision\nsystems. This paper reviews reported development of specific functionalities\nand hardware, typically required by an operating agricultural robot harvester;\nthey include (a) vision systems, (b) motion planning/navigation methodologies\n(for the robotic platform and/or arm), (c) Human-Robot-Interaction (HRI)\nstrategies with 3D visualization, (d) system operation planning & grasping\nstrategies and (e) robotic end-effector/gripper design. Clearly, automated\nagriculture and specifically autonomous harvesting via robotic systems is a\nresearch area that remains wide open, offering several challenges where new\ncontributions can be made.",
    "descriptor": "\nComments: This paper is a pre-print version under review\n",
    "authors": [
      "Leonidas Droukas",
      "Zoe Doulgeri",
      "Nikolaos L. Tsakiridis",
      "Dimitra Triantafyllou",
      "Ioannis Kleitsiotis",
      "Ioannis Mariolis",
      "Dimitrios Giakoumis",
      "Dimitrios Tzovaras",
      "Dimitrios Kateris",
      "Dionysis Bochtis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10457"
  },
  {
    "id": "arXiv:2207.10465",
    "title": "Nonlinear Model Predictive Control for Quadrupedal Locomotion Using  Second-Order Sensitivity Analysis",
    "abstract": "We present a versatile nonlinear model predictive control (NMPC) formulation\nfor quadrupedal locomotion. Our formulation jointly optimizes a base trajectory\nand a set of footholds over a finite time horizon based on simplified dynamics\nmodels. We leverage second-order sensitivity analysis and a sparse Gauss-Newton\n(SGN) method to solve the resulting optimal control problems. We further\ndescribe our ongoing effort to verify our approach through simulation and\nhardware experiments. Finally, we extend our locomotion framework to deal with\nchallenging tasks that comprise gap crossing, movement on stepping stones, and\nmulti-robot control.",
    "descriptor": "\nComments: 5 pages. 5 figures. Presented in ICRA 2022: 6th Full-Day Workshop on Legged Robots. The first two authors contributed equally to this work. The supplementary video is available in this https URL\n",
    "authors": [
      "Dongho Kang",
      "Flavio De Vincenti",
      "Stelian Coros"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10465"
  },
  {
    "id": "arXiv:2207.10466",
    "title": "High-Level Approaches to Hardware Security: A Tutorial",
    "abstract": "Designers use third-party intellectual property (IP) cores and outsource\nvarious steps in the integrated circuit (IC) design and manufacturing flow. As\na result, security vulnerabilities have been rising. This is forcing IC\ndesigners and end users to re-evaluate their trust in ICs. If attackers get\nhold of an unprotected IC, they can reverse engineer the IC and pirate the IP.\nSimilarly, if attackers get hold of a design, they can insert malicious\ncircuits or take advantage of \"backdoors\" in a design. Unintended design bugs\ncan also result in security weaknesses. This tutorial paper provides an\nintroduction to the domain of hardware security through two pedagogical\nexamples of hardware security problems. The first is a walk-through of the scan\nchain-based side channel attack. The second is a walk-through of logic locking\nof digital designs. The tutorial material is accompanied by open access digital\nresources that are linked in this article.",
    "descriptor": "\nComments: 36 pages, 13 figures\n",
    "authors": [
      "Hammond Pearce",
      "Ramesh Karri",
      "Benjamin Tan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10466"
  },
  {
    "id": "arXiv:2207.10469",
    "title": "Fast Data Driven Estimation of Cluster Number in Multiplex Images using  Embedded Density Outliers",
    "abstract": "The usage of chemical imaging technologies is becoming a routine\naccompaniment to traditional methods in pathology. Significant technological\nadvances have developed these next generation techniques to provide rich,\nspatially resolved, multidimensional chemical images. The rise of digital\npathology has significantly enhanced the synergy of these imaging modalities\nwith optical microscopy and immunohistochemistry, enhancing our understanding\nof the biological mechanisms and progression of diseases. Techniques such as\nimaging mass cytometry provide labelled multidimensional (multiplex) images of\nspecific components used in conjunction with digital pathology techniques.\nThese powerful techniques generate a wealth of high dimensional data that\ncreate significant challenges in data analysis. Unsupervised methods such as\nclustering are an attractive way to analyse these data, however, they require\nthe selection of parameters such as the number of clusters. Here we propose a\nmethodology to estimate the number of clusters in an automatic data-driven\nmanner using a deep sparse autoencoder to embed the data into a lower\ndimensional space. We compute the density of regions in the embedded space, the\nmajority of which are empty, enabling the high density regions to be detected\nas outliers and provide an estimate for the number of clusters. This framework\nprovides a fully unsupervised and data-driven method to analyse\nmultidimensional data. In this work we demonstrate our method using 45\nmultiplex imaging mass cytometry datasets. Moreover, our model is trained using\nonly one of the datasets and the learned embedding is applied to the remaining\n44 images providing an efficient process for data analysis. Finally, we\ndemonstrate the high computational efficiency of our method which is two orders\nof magnitude faster than estimating via computing the sum squared distances as\na function of cluster number.",
    "descriptor": "\nComments: 8 pages, 6 figures, conference paper\n",
    "authors": [
      "Spencer A. Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.10469"
  },
  {
    "id": "arXiv:2207.10478",
    "title": "Room geometry blind inference based on the localization of real sound  source and first order reflections",
    "abstract": "The conventional room geometry blind inference techniques with acoustic\nsignals are conducted based on the prior knowledge of the environment, such as\nthe room impulse response (RIR) or the sound source position, which will limit\nits application under known scenarios. To solve this problem, we have proposed\na room geometry reconstruction method in this paper by using the geometric\nrelation between the direct signal and first-order reflections. In addition to\nthe information of the compact microphone array itself, this method does not\nneed any precognition of the environmental parameters. Besides, the\nlearning-based DNN models are designed and used to improve the accuracy and\nintegrity of the localization results of the direct source and first-order\nreflections. The direction of arrival (DOA) and time difference of arrival\n(TDOA) information of the direct and reflected signals are firstly estimated\nusing the proposed DCNN and TD-CNN models, which have higher sensitivity and\naccuracy than the conventional methods. Then the position of the sound source\nis inferred by integrating the DOA, TDOA and array height using the proposed\nDNN model. After that, the positions of image sources and corresponding\nboundaries are derived based on the geometric relation. Experimental results of\nboth simulations and real measurements verify the effectiveness and accuracy of\nthe proposed techniques compared with the conventional methods under different\nreverberant environments.",
    "descriptor": "",
    "authors": [
      "Shan Gao",
      "Xihong Wu",
      "Tianshu Qu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10478"
  },
  {
    "id": "arXiv:2207.10479",
    "title": "Wer ist schuld, wenn Algorithmen irren? Entscheidungsautomatisierung,  Organisationen und Verantwortung",
    "abstract": "Algorithmic decision support (ADS) is increasingly used in a whole array of\ndifferent contexts and structures in various areas of society, influencing many\npeople's lives. Its use raises questions, among others, about accountability,\ntransparency and responsibility. Our article aims to give a brief overview of\nthe central issues connected to ADS, responsibility and decision-making in\norganisational contexts and identify open questions and research gaps.\nFurthermore, we describe a set of guidelines and a complementary digital tool\nto assist practitioners in mapping responsibility when introducing ADS within\ntheir organisational context.\n--\nAlgorithmenunterst\\\"utzte Entscheidungsfindung (algorithmic decision support,\nADS) kommt in verschiedenen Kontexten und Strukturen vermehrt zum Einsatz und\nbeeinflusst in diversen gesellschaftlichen Bereichen das Leben vieler Menschen.\nIhr Einsatz wirft einige Fragen auf, unter anderem zu den Themen Rechenschaft,\nTransparenz und Verantwortung. Im Folgenden m\\\"ochten wir einen \\\"Uberblick\n\\\"uber die wichtigsten Fragestellungen rund um ADS, Verantwortung und\nEntscheidungsfindung in organisationalen Kontexten geben und einige offene\nFragen und Forschungsl\\\"ucken aufzeigen. Weiters beschreiben wir als konkrete\nHilfestellung f\\\"ur die Praxis einen von uns entwickelten Leitfaden samt\nerg\\\"anzendem digitalem Tool, welches Anwender:innen insbesondere bei der\nVerortung und Zuordnung von Verantwortung bei der Nutzung von ADS in\norganisationalen Kontexten helfen soll.",
    "descriptor": "\nComments: 18 pages, 2 figures, in German\n",
    "authors": [
      "Angelika Adensamer",
      "Rita Gsenger",
      "Lukas Daniel Klausner"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10479"
  },
  {
    "id": "arXiv:2207.10480",
    "title": "A micropolar shell formulation for hard-magnetic soft materials",
    "abstract": "Hard-magnetic soft materials (HMSMs) are particulate composites that consist\nof a soft matrix embedded with particles of high remnant magnetic induction.\nSince the application of an external magnetic flux induces a body couple in\nHMSMs, the Cauchy stress tensor in these materials is asymmetric, in general.\nTherefore, the micropolar continuum theory can be employed to capture the\ndeformation of these materials. On the other hand, the geometries and\nstructures made of HMSMs often possess small thickness compared to the overall\ndimensions of the body. Accordingly, in the present contribution, a\n10-parameter micropolar shell formulation to model the finite elastic\ndeformation of thin structures made of HMSMs and subject to magnetic stimuli is\ndeveloped. The present shell formulation allows for using three-dimensional\nconstitutive laws without any need for modification to apply the plane stress\nassumption in thin structures. Due to the highly nonlinear nature of the\ngoverning equations, a nonlinear finite element formulation for numerical\nsimulations is also developed. To circumvent locking at large distortions, an\nenhanced assumed strain formulation is adopted. The performance of the\ndeveloped formulation is examined in several numerical examples. It is shown\nthat the proposed formulation is an effective tool for simulating the\ndeformation of thin bodies made of HMSMs.",
    "descriptor": "",
    "authors": [
      "Farzam Dadgar-Rad",
      "Mokarram Hossain"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10480"
  },
  {
    "id": "arXiv:2207.10481",
    "title": "Whiteness-based parameter selection for Poisson data in variational  image processing",
    "abstract": "We propose a novel automatic parameter selection strategy for variational\nimaging problems under Poisson noise corruption. The selection of a suitable\nregularization parameter, whose value is crucial in order to achieve high\nquality reconstructions, is known to be a particularly hard task in low\nphoton-count regimes. In this work, we extend the so-called residual whiteness\nprinciple originally designed for additive white noise to Poisson data. The\nproposed strategy relies on the study of the whiteness property of a\nstandardized Poisson noise process. After deriving the theoretical properties\nthat motivate our proposal, we solve the target minimization problem with a\nlinearized version of the alternating direction method of multipliers, which is\nparticularly suitable in presence of a general linear forward operator. Our\nstrategy is extensively tested on image restoration and computed tomography\nreconstruction problems, and compared to the well-known discrepancy principle\nfor Poisson noise proposed by Zanella at al. and with a nearly exact version of\nit previously proposed by the authors.",
    "descriptor": "",
    "authors": [
      "Francesca Bevilacqua",
      "Alessandro Lanza",
      "Monica Pragliola",
      "Fiorella Sgallari"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10481"
  },
  {
    "id": "arXiv:2207.10482",
    "title": "LPYOLO: Low Precision YOLO for Face Detection on FPGA",
    "abstract": "In recent years, number of edge computing devices and artificial intelligence\napplications on them have advanced excessively. In edge computing, decision\nmaking processes and computations are moved from servers to edge devices.\nHence, cheap and low power devices are required. FPGAs are very low power,\ninclined to do parallel operations and deeply suitable devices for running\nConvolutional Neural Networks (CNN) which are the fundamental unit of an\nartificial intelligence application. Face detection on surveillance systems is\nthe most expected application on the security market. In this work, TinyYolov3\narchitecture is redesigned and deployed for face detection. It is a CNN based\nobject detection method and developed for embedded systems. PYNQ-Z2 is selected\nas a target board which has low-end Xilinx Zynq 7020 System-on-Chip (SoC) on\nit. Redesigned TinyYolov3 model is defined in numerous bit width precisions\nwith Brevitas library which brings fundamental CNN layers and activations in\ninteger quantized form. Then, the model is trained in a quantized structure\nwith WiderFace dataset. In order to decrease latency and power consumption,\nonchip memory of the FPGA is configured as a storage of whole network\nparameters and the last activation function is modified as rescaled HardTanh\ninstead of Sigmoid. Also, high degree of parallelism is applied to logical\nresources of the FPGA. The model is converted to an HLS based application with\nusing FINN framework and FINN-HLS library which includes the layer definitions\nin C++. Later, the model is synthesized and deployed. CPU of the SoC is\nemployed with multithreading mechanism and responsible for preprocessing,\npostprocessing and TCP/IP streaming operations. Consequently, 2.4 Watt total\nboard power consumption, 18 Frames-Per-Second (FPS) throughput and 0.757 mAP\naccuracy rate on Easy category of the WiderFace are achieved with 4 bits\nprecision model.",
    "descriptor": "\nComments: Accepted to MVML2022\n",
    "authors": [
      "Bestami G\u00fcnay",
      "Sefa Burak Okcu",
      "Hasan \u015eakir Bilge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10482"
  },
  {
    "id": "arXiv:2207.10483",
    "title": "Noncommutative extensions of parameters in the asymptotic spectrum of  graphs",
    "abstract": "The zero-error capacity of a classical channel is a parameter of its\nconfusability graph, and is equal to the minimum of the values of graph\nparameters that are additive under the disjoint union, multiplicative under the\nstrong product, monotone under homomorphisms between the complements, and\nnormalized. We show that any such function either has uncountably many\nextensions to noncommutative graphs with similar properties, or no such\nextensions at all. More precisely, we find that every extension has an exponent\nthat characterizes its values on the confusability graphs of identity quantum\nchannels, and the set of admissible exponents is either an unbounded\nsubinterval of $[1,\\infty)$ or empty. In particular, the set of admissible\nexponents for the Lov\\'asz number, the projective rank, and the fractional\nHaemers bound over the complex numbers are maximal, while the fractional clique\ncover number does not have any extensions.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "P\u00e9ter Vrana"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.10483"
  },
  {
    "id": "arXiv:2207.10484",
    "title": "Splitting schemes for FitzHugh--Nagumo stochastic partial differential  equations",
    "abstract": "We design and study splitting integrators for the temporal discretization of\nthe stochastic FitzHugh--Nagumo system. This system is a model for signal\npropagation in nerve cells where the voltage variable is solution of a\none-dimensional parabolic PDE with a cubic nonlinearity driven by additive\nspace-time white noise. We first show that the numerical solutions have finite\nmoments. We then prove that the splitting schemes have, at least, the strong\nrate of convergence $1/4$. Finally, numerical experiments illustrating the\nperformance of the splitting schemes are provided.",
    "descriptor": "",
    "authors": [
      "Charles-Edouard Br\u00e9hier",
      "David Cohen",
      "Giuseppe Giordano"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2207.10484"
  },
  {
    "id": "arXiv:2207.10489",
    "title": "Online Localisation and Colored Mesh Reconstruction Architecture for 3D  Visual Feedback in Robotic Exploration Missions",
    "abstract": "This paper introduces an Online Localisation and Colored Mesh Reconstruction\n(OLCMR) ROS perception architecture for ground exploration robots aiming to\nperform robust Simultaneous Localisation And Mapping (SLAM) in challenging\nunknown environments and provide an associated colored 3D mesh representation\nin real time. It is intended to be used by a remote human operator to easily\nvisualise the mapped environment during or after the mission or as a\ndevelopment base for further researches in the field of exploration robotics.\nThe architecture is mainly composed of carefully-selected open-source ROS\nimplementations of a LiDAR-based SLAM algorithm alongside a colored surface\nreconstruction procedure using a point cloud and RGB camera images projected\ninto the 3D space. The overall performances are evaluated on the Newer College\nhandheld LiDAR-Vision reference dataset and on two experimental trajectories\ngathered on board of representative wheeled robots in respectively urban and\ncountryside outdoor environments. Index Terms: Field Robots, Mapping, SLAM,\nColored Surface Reconstruction",
    "descriptor": "",
    "authors": [
      "Quentin Serdel",
      "Christophe Grand",
      "Julien Marzat",
      "Julien Moras"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10489"
  },
  {
    "id": "arXiv:2207.10491",
    "title": "More constructions of $n$-cycle permutations",
    "abstract": "$n$-cycle permutations with small $n$ have the advantage that their\ncompositional inverses are efficient in terms of implementation. They can be\nalso used in constructing Bent functions and designing codes. Since the AGW\nCriterion was proposed, the permuting property of several forms of polynomials\nhas been studied. In this paper, characterizations of several types of\n$n$-cycle permutations are investigated. Three criteria for $ n $-cycle\npermutations of the form $xh(\\lambda(x))$, $ h(\\psi(x)) \\varphi(x)+g(\\psi(x)) $\nand $g\\left( x^{q^i} -x +\\delta \\right) +bx $ with general $n$ are provided. We\ndemonstrate these criteria by providing explicit constructions. For the form of\n$x^rh(x^s)$, several new explicit triple-cycle permutations are also provided.\nFinally, we also consider triple-cycle permutations of the form $x^t + c\\rm\nTr_{q^m/q}(x^s)$ and provide one explicit construction. Many of our\nconstructions are both new in the $n$-cycle property and the permutation\nproperty.",
    "descriptor": "\nComments: 20 pages. arXiv admin note: text overlap with arXiv:2007.14865 by other authors\n",
    "authors": [
      "Tailin Niu",
      "Kangquan Li",
      "Longjiang Qu",
      "Bing Sun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.10491"
  },
  {
    "id": "arXiv:2207.10494",
    "title": "Multi-Event-Camera Depth Estimation and Outlier Rejection by Refocused  Events Fusion",
    "abstract": "Event cameras are bio-inspired sensors that offer advantages over traditional\ncameras. They work asynchronously, sampling the scene with microsecond\nresolution and producing a stream of brightness changes. This unconventional\noutput has sparked novel computer vision methods to unlock the camera's\npotential. We tackle the problem of event-based stereo 3D reconstruction for\nSLAM. Most event-based stereo methods try to exploit the camera's high temporal\nresolution and event simultaneity across cameras to establish matches and\nestimate depth. By contrast, we investigate how to estimate depth without\nexplicit data association by fusing Disparity Space Images (DSIs) originated in\nefficient monocular methods. We develop fusion theory and apply it to design\nmulti-camera 3D reconstruction algorithms that produce state-of-the-art\nresults, as we confirm by comparing against four baseline methods and testing\non a variety of available datasets.",
    "descriptor": "\nComments: 19 pages, 18 figures, 9 tables\n",
    "authors": [
      "Suman Ghosh",
      "Guillermo Gallego"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10494"
  },
  {
    "id": "arXiv:2207.10495",
    "title": "A Forgotten Danger in DNN Supervision Testing: Generating and Detecting  True Ambiguity",
    "abstract": "Deep Neural Networks (DNNs) are becoming a crucial component of modern\nsoftware systems, but they are prone to fail under conditions that are\ndifferent from the ones observed during training (out-of-distribution inputs)\nor on inputs that are truly ambiguous, i.e., inputs that admit multiple classes\nwith nonzero probability in their ground truth labels. Recent work proposed DNN\nsupervisors to detect high-uncertainty inputs before their possible\nmisclassification leads to any harm. To test and compare the capabilities of\nDNN supervisors, researchers proposed test generation techniques, to focus the\ntesting effort on high-uncertainty inputs that should be recognized as\nanomalous by supervisors. However, existing test generators can only produce\nout-of-distribution inputs. No existing model- and supervisor-independent\ntechnique supports the generation of truly ambiguous test inputs.\nIn this paper, we propose a novel way to generate ambiguous inputs to test\nDNN supervisors and used it to empirically compare several existing supervisor\ntechniques. In particular, we propose AmbiGuess to generate ambiguous samples\nfor image classification problems. AmbiGuess is based on gradient-guided\nsampling in the latent space of a regularized adversarial autoencoder.\nMoreover, we conducted what is - to the best of our knowledge - the most\nextensive comparative study of DNN supervisors, considering their capabilities\nto detect 4 distinct types of high-uncertainty inputs, including truly\nambiguous ones.",
    "descriptor": "",
    "authors": [
      "Michael Weiss",
      "Andr\u00e9 Garc\u00eda G\u00f3mez",
      "Paolo Tonella"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10495"
  },
  {
    "id": "arXiv:2207.10496",
    "title": "The Unscented Transform Controller: a new model predictive control law  for highly nonlinear systems",
    "abstract": "The Unscented Transform which is the basis of the Unscented Kalman Filter,\nUKF, is used here to develop a novel predictive controller for non-linear\nplants, called the Unscented Transform Controller, UTC. The UTC can be seen as\nthe dual of the UKF, the same way as the LQG regulator and the Kalman Filter\nare related. The UTC is demonstrated on the control of complex maneuvers in\nfree fall of a virtual skydiver the model of which was verified in wind tunnel\nand free fall experiments.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Anna Clarke",
      "Per Olof Gutman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10496"
  },
  {
    "id": "arXiv:2207.10498",
    "title": "Towards Efficient Adversarial Training on Vision Transformers",
    "abstract": "Vision Transformer (ViT), as a powerful alternative to Convolutional Neural\nNetwork (CNN), has received much attention. Recent work showed that ViTs are\nalso vulnerable to adversarial examples like CNNs. To build robust ViTs, an\nintuitive way is to apply adversarial training since it has been shown as one\nof the most effective ways to accomplish robust CNNs. However, one major\nlimitation of adversarial training is its heavy computational cost. The\nself-attention mechanism adopted by ViTs is a computationally intense operation\nwhose expense increases quadratically with the number of input patches, making\nadversarial training on ViTs even more time-consuming. In this work, we first\ncomprehensively study fast adversarial training on a variety of vision\ntransformers and illustrate the relationship between the efficiency and\nrobustness. Then, to expediate adversarial training on ViTs, we propose an\nefficient Attention Guided Adversarial Training mechanism. Specifically,\nrelying on the specialty of self-attention, we actively remove certain patch\nembeddings of each layer with an attention-guided dropping strategy during\nadversarial training. The slimmed self-attention modules accelerate the\nadversarial training on ViTs significantly. With only 65\\% of the fast\nadversarial training time, we match the state-of-the-art results on the\nchallenging ImageNet benchmark.",
    "descriptor": "",
    "authors": [
      "Boxi Wu",
      "Jindong Gu",
      "Zhifeng Li",
      "Deng Cai",
      "Xiaofei He",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10498"
  },
  {
    "id": "arXiv:2207.10506",
    "title": "Multi-modal Retinal Image Registration Using a Keypoint-Based Vessel  Structure Aligning Network",
    "abstract": "In ophthalmological imaging, multiple imaging systems, such as color fundus,\ninfrared, fluorescein angiography, optical coherence tomography (OCT) or OCT\nangiography, are often involved to make a diagnosis of retinal disease.\nMulti-modal retinal registration techniques can assist ophthalmologists by\nproviding a pixel-based comparison of aligned vessel structures in images from\ndifferent modalities or acquisition times. To this end, we propose an\nend-to-end trainable deep learning method for multi-modal retinal image\nregistration. Our method extracts convolutional features from the vessel\nstructure for keypoint detection and description and uses a graph neural\nnetwork for feature matching. The keypoint detection and description network\nand graph neural network are jointly trained in a self-supervised manner using\nsynthetic multi-modal image pairs and are guided by synthetically sampled\nground truth homographies. Our method demonstrates higher registration accuracy\nas competing methods for our synthetic retinal dataset and generalizes well for\nour real macula dataset and a public fundus dataset.",
    "descriptor": "\nComments: 11 pages, 3 figures, 3 tables, accepted to MICCAI 2022\n",
    "authors": [
      "Aline Sindel",
      "Bettina Hohberger",
      "Andreas Maier",
      "Vincent Christlein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10506"
  },
  {
    "id": "arXiv:2207.10510",
    "title": "Autonomous Vehicles in 5G and Beyond: A Survey",
    "abstract": "Fifth Generation (5G) technology is an emerging and fast adopting technology\nwhich is being utilized in most of the novel applications that require highly\nreliable low-latency communications. It has the capability to provide greater\ncoverage, better access, and best suited for high density networks. Having all\nthese benefits, it clearly implies that 5G could be used to satisfy the\nrequirements of Autonomous vehicles. Automated driving Vehicles and systems are\ndeveloped with a promise to provide comfort, safe and efficient drive reducing\nthe risk of life. But, recently there are fatalities due to these autonomous\nvehicles and systems. This is due to the lack of robust state-of-art which has\nto be improved further. With the advent of 5G technology and rise of autonomous\nvehicles (AVs), road safety is going to get more secure with less human errors.\nHowever, integration of 5G and AV is still at its infant stage with several\nresearch challenges that needs to be addressed. This survey first starts with a\ndiscussion on the current advancements in AVs, automation levels, enabling\ntechnologies and 5G requirements. Then, we focus on the emerging techniques\nrequired for integrating 5G technology with AVs, impact of 5G and B5G\ntechnologies on AVs along with security concerns in AVs. The paper also\nprovides a comprehensive survey of recent developments in terms of\nstandardisation activities on 5G autonomous vehicle technology and current\nprojects. The article is finally concluded with lessons learnt, future research\ndirections and challenges.",
    "descriptor": "\nComments: Submitted for peer review\n",
    "authors": [
      "Saqib Hakak",
      "Thippa Reddy Gadekallu",
      "Swarna Priya Ramu",
      "Parimala M",
      "Praveen Kumar Reddy Maddikunta",
      "Chamitha de Alwis",
      "Madhusanka Liyanage"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.10510"
  },
  {
    "id": "arXiv:2207.10511",
    "title": "A cost effective eye movement tracker based wheel chair control  algorithm for people with paraplegia",
    "abstract": "Spinal cord injuries can often lead to quadriplegia in patients limiting\ntheir mobility. Wheelchairs could be a good proposition for patients, but most\nof them operate either manually or with the help of electric motors operated\nwith a joystick. This, however, requires the use of hands, making it unsuitable\nfor quadriplegic patients. Controlling eye movement, on the other hand, is\nretained even by people who undergo brain injury. Monitoring the movements in\nthe eye can be a helpful tool in generating control signals for the wheelchair.\nThis paper is an approach to converting obtained signals from the eye into\nmeaningful signals by trying to control a bot that imitates a wheelchair. The\noverall system is cost-effective and uses simple image processing and pattern\nrecognition to control the bot. An android application is developed, which\ncould be used by the patients' aid for more refined control of the wheelchair\nin the actual scenario.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Skanda Upadhyaya",
      "Shravan Bhat",
      "Siddhanth P. Rao",
      "V Ashwin",
      "Krishnan Chemmangat"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10511"
  },
  {
    "id": "arXiv:2207.10517",
    "title": "MQRetNN: Multi-Horizon Time Series Forecasting with Retrieval  Augmentation",
    "abstract": "Multi-horizon probabilistic time series forecasting has wide applicability to\nreal-world tasks such as demand forecasting. Recent work in neural time-series\nforecasting mainly focus on the use of Seq2Seq architectures. For example,\nMQTransformer - an improvement of MQCNN - has shown the state-of-the-art\nperformance in probabilistic demand forecasting. In this paper, we consider\nincorporating cross-entity information to enhance model performance by adding a\ncross-entity attention mechanism along with a retrieval mechanism to select\nwhich entities to attend over. We demonstrate how our new neural architecture,\nMQRetNN, leverages the encoded contexts from a pretrained baseline model on the\nentire population to improve forecasting accuracy. Using MQCNN as the baseline\nmodel (due to computational constraints, we do not use MQTransformer), we first\nshow on a small demand forecasting dataset that it is possible to achieve ~3%\nimprovement in test loss by adding a cross-entity attention mechanism where\neach entity attends to all others in the population. We then evaluate the model\nwith our proposed retrieval methods - as a means of approximating an attention\nover a large population - on a large-scale demand forecasting application with\nover 2 million products and observe ~1% performance gain over the MQCNN\nbaseline.",
    "descriptor": "\nComments: Accepted at 8th SIGKDD International Workshop on Mining and Learning from Time Series\n",
    "authors": [
      "Sitan Yang",
      "Carson Eisenach",
      "Dhruv Madeka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10517"
  },
  {
    "id": "arXiv:2207.10519",
    "title": "Real-Time Elderly Monitoring for Senior Safety by Lightweight Human  Action Recognition",
    "abstract": "With an increasing number of elders living alone, care-giving from a distance\nbecomes a compelling need, particularly for safety. Real-time monitoring and\naction recognition are essential to raise an alert timely when abnormal\nbehaviors or unusual activities occur. While wearable sensors are widely\nrecognized as a promising solution, highly depending on user's ability and\nwillingness makes them inefficient. In contrast, video streams collected\nthrough non-contact optical cameras provide richer information and release the\nburden on elders. In this paper, leveraging the Independently-Recurrent neural\nNetwork (IndRNN) we propose a novel Real-time Elderly Monitoring for senior\nSafety (REMS) based on lightweight human action recognition (HAR) technology.\nUsing captured skeleton images, the REMS scheme is able to recognize abnormal\nbehaviors or actions and preserve the user's privacy. To achieve high accuracy,\nthe HAR module is trained and fine-tuned using multiple databases. An extensive\nexperimental study verified that REMS system performs action recognition\naccurately and timely. REMS meets the design goals as a privacy-preserving\nelderly safety monitoring system and possesses the potential to be adopted in\nvarious smart monitoring systems.",
    "descriptor": "",
    "authors": [
      "Han Sun",
      "Yu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10519"
  },
  {
    "id": "arXiv:2207.10524",
    "title": "NusaCrowd: A Call for Open and Reproducible NLP Research in Indonesian  Languages",
    "abstract": "At the center of the underlying issues that halt Indonesian natural language\nprocessing (NLP) research advancement, we find data scarcity. Resources in\nIndonesian languages, especially the local ones, are extremely scarce and\nunderrepresented. Many Indonesian researchers do not publish their dataset.\nFurthermore, the few public datasets that we have are scattered across\ndifferent platforms, thus makes performing reproducible and data-centric\nresearch in Indonesian NLP even more arduous. Rising to this challenge, we\ninitiate the first Indonesian NLP crowdsourcing effort, NusaCrowd. NusaCrowd\nstrives to provide the largest datasheets aggregation with standardized data\nloading for NLP tasks in all Indonesian languages. By enabling open and\ncentralized access to Indonesian NLP resources, we hope NusaCrowd can tackle\nthe data scarcity problem hindering NLP progress in Indonesia and bring NLP\npractitioners to move towards collaboration.",
    "descriptor": "",
    "authors": [
      "Samuel Cahyawijaya",
      "Alham Fikri Aji",
      "Holy Lovenia",
      "Genta Indra Winata",
      "Bryan Wilie",
      "Rahmad Mahendra",
      "Fajri Koto",
      "David Moeljadi",
      "Karissa Vincentio",
      "Ade Romadhony",
      "Ayu Purwarianti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10524"
  },
  {
    "id": "arXiv:2207.10526",
    "title": "PA-PUF: A Novel Priority Arbiter PUF",
    "abstract": "This paper proposes a 3-input arbiter-based novel physically unclonable\nfunction (PUF) design. Firstly, a 3-input priority arbiter is designed using a\nsimple arbiter, two multiplexers (2:1), and an XOR logic gate. The priority\narbiter has an equal probability of 0's and 1's at the output, which results in\nexcellent uniformity (49.45%) while retrieving the PUF response. Secondly, a\nnew PUF design based on priority arbiter PUF (PA-PUF) is presented. The PA-PUF\ndesign is evaluated for uniqueness, non-linearity, and uniformity against the\nstandard tests. The proposed PA-PUF design is configurable in\nchallenge-response pairs through an arbitrary number of feed-forward priority\narbiters introduced to the design. We demonstrate, through extensive\nexperiments, reliability of 100% after performing the error correction\ntechniques and uniqueness of 49.63%. Finally, the design is compared with the\nliterature to evaluate its implementation efficiency, where it is clearly found\nto be superior compared to the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Simranjeet Singh",
      "Srinivasu Bodapati",
      "Sachin Patkar",
      "Rainer Leupers",
      "Anupam Chattopadhyay",
      "Farhad Merchant"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10526"
  },
  {
    "id": "arXiv:2207.10530",
    "title": "Neural Network Learning of Chemical Bond Representations in Spectral  Indices and Features",
    "abstract": "In this paper we investigate neural networks for classification in\nhyperspectral imaging with a focus on connecting the architecture of the\nnetwork with the physics of the sensing and materials present. Spectroscopy is\nthe process of measuring light reflected or emitted by a material as a function\nwavelength. Molecular bonds present in the material have vibrational\nfrequencies which affect the amount of light measured at each wavelength. Thus\nthe measured spectrum contains information about the particular chemical\nconstituents and types of bonds. For example, chlorophyll reflects more light\nin the near-IR rage (800-900nm) than in the red (625-675nm) range, and this\ndifference can be measured using a normalized vegetation difference index\n(NDVI), which is commonly used to detect vegetation presence, health, and type\nin imagery collected at these wavelengths. In this paper we show that the\nweights in a Neural Network trained on different vegetation classes learn to\nmeasure this difference in reflectance. We then show that a Neural Network\ntrained on a more complex set of ten different polymer materials will learn\nspectral 'features' evident in the weights for the network, and these features\ncan be used to reliably distinguish between the different types of polymers.\nExamination of the weights provides a human-interpretable understanding of the\nnetwork.",
    "descriptor": "",
    "authors": [
      "Bill Basener"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2207.10530"
  },
  {
    "id": "arXiv:2207.10531",
    "title": "Hybrid Data-Driven Closure Strategies for Reduced Order Modeling",
    "abstract": "In this paper, we propose hybrid data-driven ROM closures for fluid flows.\nThese new ROM closures combine two fundamentally different strategies: (i)\npurely data-driven ROM closures, both for the velocity and the pressure; and\n(ii) physically based, eddy viscosity data-driven closures, which model the\nenergy transfer in the system. The first strategy consists in the addition of\nclosure/correction terms to the governing equations, which are built from the\navailable data. The second strategy includes turbulence modeling by adding eddy\nviscosity terms, which are determined by using machine learning techniques. The\ntwo strategies are combined for the first time in this paper to investigate a\ntwo-dimensional flow past a circular cylinder at Re=50000. Our numerical\nresults show that the hybrid data-driven ROM is more accurate than both the\npurely data-driven ROM and the eddy viscosity ROM.",
    "descriptor": "",
    "authors": [
      "Anna Ivagnes",
      "Giovanni Stabile",
      "Andrea Mola",
      "Traian Iliescu",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10531"
  },
  {
    "id": "arXiv:2207.10534",
    "title": "Assume, Guarantee or Repair -- A Regular Framework for Non Regular  Properties (full version)",
    "abstract": "We present Assume-Guarantee-Repair (AGR) - a novel framework which verifies\nthat a program satisfies a set of properties and also repairs the program in\ncase the verification fails. We consider communicating programs - these are\nsimple C-like programs, extended with synchronous actions over communication\nchannels. Our method, which consists of a learning-based approach to\nassume-guarantee reasoning, performs verification and repair simultaneously: in\nevery iteration, AGR either makes another step towards proving that the\n(current) system satisfies the required properties, or alters the system in a\nway that brings it closer to satisfying the properties. To handle\ninfinite-state systems we build finite abstractions, for which we check the\nsatisfaction of complex properties that contain first-order constraints, using\nboth syntactic and semantic-aware methods. We implemented AGR and evaluated it\non various communication protocols. Our experiments present compact proofs of\ncorrectness and quick repairs.",
    "descriptor": "",
    "authors": [
      "Hadar Frenkel",
      "Orna Grumberg",
      "Corina S. Pasareanu",
      "Sarai Sheinvald"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2207.10534"
  },
  {
    "id": "arXiv:2207.10541",
    "title": "Optimal precision for GANs",
    "abstract": "When learning disconnected distributions, Generative adversarial networks\n(GANs) are known to face model misspecification. Indeed, a continuous mapping\nfrom a unimodal latent distribution to a disconnected one is impossible, so\nGANs necessarily generate samples outside of the support of the target\ndistribution. This raises a fundamental question: what is the latent space\npartition that minimizes the measure of these areas? Building on a recent\nresult of geometric measure theory, we prove that an optimal GANs must\nstructure its latent space as a 'simplicial cluster' - a Voronoi partition\nwhere cells are convex cones - when the dimension of the latent space is larger\nthan the number of modes. In this configuration, each Voronoi cell maps to a\ndistinct mode of the data. We derive both an upper and a lower bound on the\noptimal precision of GANs learning disconnected manifolds. Interestingly, these\ntwo bounds have the same order of decrease: $\\sqrt{\\log m}$, $m$ being the\nnumber of modes. Finally, we perform several experiments to exhibit the\ngeometry of the latent space and experimentally show that GANs have a geometry\nwith similar properties to the theoretical one.",
    "descriptor": "",
    "authors": [
      "Thibaut Issenhuth",
      "Ugo Tanielian",
      "J\u00e9r\u00e9mie Mary",
      "David Picard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.10541"
  },
  {
    "id": "arXiv:2207.10543",
    "title": "Closed-Loop Next-Best-View Planning for Target-Driven Grasping",
    "abstract": "Picking a specific object from clutter is an essential component of many\nmanipulation tasks. Partial observations often require the robot to collect\nadditional views of the scene before attempting a grasp. This paper proposes a\nclosed-loop next-best-view planner that drives exploration based on occluded\nobject parts. By continuously predicting grasps from an up-to-date scene\nreconstruction, our policy can decide online to finalize a grasp execution or\nto adapt the robot's trajectory for further exploration. We show that our\nreactive approach decreases execution times without loss of grasp success rates\ncompared to common camera placements and handles situations where the fixed\nbaselines fail. Video and code are available at\nhttps://github.com/ethz-asl/active_grasp.",
    "descriptor": "\nComments: Submitted to IROS 2022\n",
    "authors": [
      "Michel Breyer",
      "Lionel Ott",
      "Roland Siegwart",
      "Jen Jen Chung"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10543"
  },
  {
    "id": "arXiv:2207.10547",
    "title": "Surrey System for DCASE 2022 Task 5: Few-shot Bioacoustic Event  Detection with Segment-level Metric Learning",
    "abstract": "Few-shot audio event detection is a task that detects the occurrence time of\na novel sound class given a few examples. In this work, we propose a system\nbased on segment-level metric learning for the DCASE 2022 challenge of few-shot\nbioacoustic event detection (task 5). We make better utilization of the\nnegative data within each sound class to build the loss function, and use\ntransductive inference to gain better adaptation on the evaluation set. For the\ninput feature, we find the per-channel energy normalization concatenated with\ndelta mel-frequency cepstral coefficients to be the most effective combination.\nWe also introduce new data augmentation and post-processing procedures for this\ntask. Our final system achieves an f-measure of 68.74 on the DCASE task 5\nvalidation set, outperforming the baseline performance of 29.5 by a large\nmargin. Our system is fully open-sourced at\nhttps://github.com/haoheliu/DCASE_2022_Task_5.",
    "descriptor": "\nComments: Technical Report of the system that ranks 2nd in the DCASE Challenge Task 5. arXiv admin note: text overlap with arXiv:2207.07773\n",
    "authors": [
      "Haohe Liu",
      "Xubo Liu",
      "Xinhao Mei",
      "Qiuqiang Kong",
      "Wenwu Wang",
      "Mark D. Plumbley"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10547"
  },
  {
    "id": "arXiv:2207.10551",
    "title": "Scaling Laws vs Model Architectures: How does Inductive Bias Influence  Scaling?",
    "abstract": "There have been a lot of interest in the scaling properties of Transformer\nmodels. However, not much has been done on the front of investigating the\neffect of scaling properties of different inductive biases and model\narchitectures. Do model architectures scale differently? If so, how does\ninductive bias affect scaling behaviour? How does this influence upstream\n(pretraining) and downstream (transfer)? This paper conducts a systematic study\nof scaling behaviour of ten diverse model architectures such as Transformers,\nSwitch Transformers, Universal Transformers, Dynamic convolutions, Performers,\nand recently proposed MLP-Mixers. Via extensive experiments, we show that (1)\narchitecture is an indeed an important consideration when performing scaling\nand (2) the best performing model can fluctuate at different scales. We believe\nthat the findings outlined in this work has significant implications to how\nmodel architectures are currently evaluated in the community.",
    "descriptor": "",
    "authors": [
      "Yi Tay",
      "Mostafa Dehghani",
      "Samira Abnar",
      "Hyung Won Chung",
      "William Fedus",
      "Jinfeng Rao",
      "Sharan Narang",
      "Vinh Q. Tran",
      "Dani Yogatama",
      "Donald Metzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10551"
  },
  {
    "id": "arXiv:2207.10552",
    "title": "A Primer on Topological Data Analysis to Support Image Analysis Tasks in  Environmental Science",
    "abstract": "Topological data analysis (TDA) is a tool from data science and mathematics\nthat is beginning to make waves in environmental science. In this work, we seek\nto provide an intuitive and understandable introduction to a tool from TDA that\nis particularly useful for the analysis of imagery, namely persistent homology.\nWe briefly discuss the theoretical background but focus primarily on\nunderstanding the output of this tool and discussing what information it can\nglean. To this end, we frame our discussion around a guiding example of\nclassifying satellite images from the Sugar, Fish, Flower, and Gravel Dataset\nproduced for the study of mesocale organization of clouds by Rasp et. al. in\n2020 (arXiv:1906:01906). We demonstrate how persistent homology and its\nvectorization, persistence landscapes, can be used in a workflow with a simple\nmachine learning algorithm to obtain good results, and explore in detail how we\ncan explain this behavior in terms of image-level features. One of the core\nstrengths of persistent homology is how interpretable it can be, so throughout\nthis paper we discuss not just the patterns we find, but why those results are\nto be expected given what we know about the theory of persistent homology. Our\ngoal is that a reader of this paper will leave with a better understanding of\nTDA and persistent homology, be able to identify problems and datasets of their\nown for which persistent homology could be helpful, and gain an understanding\nof results they obtain from applying the included GitHub example code.",
    "descriptor": "\nComments: This work has been submitted to Artificial Intelligence for the Earth Systems (AIES). Copyright in this work may be transferred without further notice\n",
    "authors": [
      "Lander Ver Hoef",
      "Henry Adams",
      "Emily J. King",
      "Imme Ebert-Uphoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "General Topology (math.GN)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.10552"
  },
  {
    "id": "arXiv:2207.10553",
    "title": "The MABe22 Benchmarks for Representation Learning of Multi-Agent  Behavior",
    "abstract": "Real-world behavior is often shaped by complex interactions between multiple\nagents. To scalably study multi-agent behavior, advances in unsupervised and\nself-supervised learning have enabled a variety of different behavioral\nrepresentations to be learned from trajectory data. To date, there does not\nexist a unified set of benchmarks that can enable comparing methods\nquantitatively and systematically across a broad set of behavior analysis\nsettings. We aim to address this by introducing a large-scale, multi-agent\ntrajectory dataset from real-world behavioral neuroscience experiments that\ncovers a range of behavior analysis tasks. Our dataset consists of trajectory\ndata from common model organisms, with 9.6 million frames of mouse data and 4.4\nmillion frames of fly data, in a variety of experimental settings, such as\ndifferent strains, lengths of interaction, and optogenetic stimulation. A\nsubset of the frames also consist of expert-annotated behavior labels.\nImprovements on our dataset corresponds to behavioral representations that work\nacross multiple organisms and is able to capture differences for common\nbehavior analysis tasks.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Jennifer J. Sun",
      "Andrew Ulmer",
      "Dipam Chakraborty",
      "Brian Geuther",
      "Edward Hayes",
      "Heng Jia",
      "Vivek Kumar",
      "Zachary Partridge",
      "Alice Robie",
      "Catherine E. Schretter",
      "Chao Sun",
      "Keith Sheppard",
      "Param Uttarwar",
      "Pietro Perona",
      "Yisong Yue",
      "Kristin Branson",
      "Ann Kennedy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2207.10553"
  },
  {
    "id": "arXiv:2207.10556",
    "title": "Tight Bounds for Monotone Minimal Perfect Hashing",
    "abstract": "The monotone minimal perfect hash function (MMPHF) problem is the following\nindexing problem. Given a set $S= \\{s_1,\\ldots,s_n\\}$ of $n$ distinct keys from\na universe $U$ of size $u$, create a data structure $DS$ that answers the\nfollowing query:\n\\[ RankOp(q) = \\text{rank of } q \\text{ in } S \\text{ for all } q\\in S\n~\\text{ and arbitrary answer otherwise.}\n\\]\nSolutions to the MMPHF problem are in widespread use in both theory and\npractice.\nThe best upper bound known for the problem encodes $DS$ in $O(n\\log\\log\\log\nu)$ bits and performs queries in $O(\\log u)$ time. It has been an open problem\nto either improve the space upper bound or to show that this somewhat odd\nlooking bound is tight.\nIn this paper, we show the latter: specifically that any data structure\n(deterministic or randomized) for monotone minimal perfect hashing of any\ncollection of $n$ elements from a universe of size $u$ requires $\\Omega(n \\cdot\n\\log\\log\\log{u})$ expected bits to answer every query correctly.\nWe achieve our lower bound by defining a graph $\\mathbf{G}$ where the nodes\nare the possible ${u \\choose n}$ inputs and where two nodes are adjacent if\nthey cannot share the same $DS$. The size of $DS$ is then lower bounded by the\nlog of the chromatic number of $\\mathbf{G}$. Finally, we show that the\nfractional chromatic number (and hence the chromatic number) of $\\mathbf{G}$ is\nlower bounded by $2^{\\Omega(n \\log\\log\\log u)}$.",
    "descriptor": "",
    "authors": [
      "Sepehr Assadi",
      "Martin Farach-Colton",
      "William Kuszmaul"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.10556"
  },
  {
    "id": "arXiv:2207.10561",
    "title": "Careful What You Wish For: on the Extraction of Adversarially Trained  Models",
    "abstract": "Recent attacks on Machine Learning (ML) models such as evasion attacks with\nadversarial examples and models stealing through extraction attacks pose\nseveral security and privacy threats. Prior work proposes to use adversarial\ntraining to secure models from adversarial examples that can evade the\nclassification of a model and deteriorate its performance. However, this\nprotection technique affects the model's decision boundary and its prediction\nprobabilities, hence it might raise model privacy risks. In fact, a malicious\nuser using only a query access to the prediction output of a model can extract\nit and obtain a high-accuracy and high-fidelity surrogate model. To have a\ngreater extraction, these attacks leverage the prediction probabilities of the\nvictim model. Indeed, all previous work on extraction attacks do not take into\nconsideration the changes in the training process for security purposes. In\nthis paper, we propose a framework to assess extraction attacks on\nadversarially trained models with vision datasets. To the best of our\nknowledge, our work is the first to perform such evaluation. Through an\nextensive empirical study, we demonstrate that adversarially trained models are\nmore vulnerable to extraction attacks than models obtained under natural\ntraining circumstances. They can achieve up to $\\times1.2$ higher accuracy and\nagreement with a fraction lower than $\\times0.75$ of the queries. We\nadditionally find that the adversarial robustness capability is transferable\nthrough extraction attacks, i.e., extracted Deep Neural Networks (DNNs) from\nrobust models show an enhanced accuracy to adversarial examples compared to\nextracted DNNs from naturally trained (i.e. standard) models.",
    "descriptor": "\nComments: To be published in the proceedings of the 19th Annual International Conference on Privacy, Security & Trust (PST 2022). The conference proceedings will be included in IEEE Xplore as in previous editions of the conference\n",
    "authors": [
      "Kacem Khaled",
      "Gabriela Nicolescu",
      "Felipe Gohring de Magalh\u00e3es"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10561"
  },
  {
    "id": "arXiv:2207.10562",
    "title": "CheckINN: Wide Range Neural Network Verification in Imandra",
    "abstract": "Neural networks are increasingly relied upon as components of complex\nsafety-critical systems such as autonomous vehicles. There is high demand for\ntools and methods that embed neural network verification in a larger\nverification cycle. However, neural network verification is difficult due to a\nwide range of verification properties of interest, each typically only amenable\nto verification in specialised solvers. In this paper, we show how Imandra, a\nfunctional programming language and a theorem prover originally designed for\nverification, validation and simulation of financial infrastructure can offer a\nholistic infrastructure for neural network verification. We develop a novel\nlibrary CheckINN that formalises neural networks in Imandra, and covers\ndifferent important facets of neural network verification.",
    "descriptor": "\nComments: PPDP 2022, 24th International Symposium on Principles and Practice of Declarative Programming\n",
    "authors": [
      "Remi Desmartin",
      "Grant Passmore",
      "Ekaterina Komendantskaya",
      "Matthew Daggitt"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.10562"
  },
  {
    "id": "arXiv:2207.10563",
    "title": "Let's Talk About Socio-Technical Angst: Tracing the History and  Evolution of Dark Patterns on Twitter from 2010-2021",
    "abstract": "Designers' use of deceptive and manipulative design practices have become\nincreasingly ubiquitous, impacting users' ability to make choices that respect\ntheir agency and autonomy. These practices have been popularly defined through\nthe term \"dark patterns\" which has gained attention from designers, privacy\nscholars, and more recently, even legal scholars and regulators. The increased\ninterest in the term and underpinnings of dark patterns across a range of\nsociotechnical practitioners intrigued us to study the evolution of the\nconcept, to potentially speculate the future trajectory of conversations around\ndark patterns. In this paper, we examine the history and evolution of the\nTwitter discourse through #darkpatterns from its inception in June 2010 until\nApril 2021, using a combination of quantitative and qualitative methods to\ndescribe how this discourse has changed over time. We frame the evolution of\nthis discourse as an emergent transdisciplinary conversation that connects\nmultiple disciplinary perspectives through the shared concept of dark patterns,\nwhereby these participants engage in a conversation marked by socio-technical\nangst in order to identify and fight back against deceptive design practices.\nWe discuss the potential future trajectories of this discourse and\nopportunities for further scholarship at the intersection of design, policy,\nand activism.",
    "descriptor": "",
    "authors": [
      "Ikechukwu Obi",
      "Colin M. Gray",
      "Shruthi Sai Chivukula",
      "Ja-Nae Duane",
      "Janna Johns",
      "Matthew Will",
      "Ziqing Li",
      "Thomas Carlock"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.10563"
  },
  {
    "id": "arXiv:2207.10564",
    "title": "Unsupervised Night Image Enhancement: When Layer Decomposition Meets  Light-Effects Suppression",
    "abstract": "Night images suffer not only from low light, but also from uneven\ndistributions of light. Most existing night visibility enhancement methods\nfocus mainly on enhancing low-light regions. This inevitably leads to over\nenhancement and saturation in bright regions, such as those regions affected by\nlight effects (glare, floodlight, etc). To address this problem, we need to\nsuppress the light effects in bright regions while, at the same time, boosting\nthe intensity of dark regions. With this idea in mind, we introduce an\nunsupervised method that integrates a layer decomposition network and a\nlight-effects suppression network. Given a single night image as input, our\ndecomposition network learns to decompose shading, reflectance and\nlight-effects layers, guided by unsupervised layer-specific prior losses. Our\nlight-effects suppression network further suppresses the light effects and, at\nthe same time, enhances the illumination in dark regions. This light-effects\nsuppression network exploits the estimated light-effects layer as the guidance\nto focus on the light-effects regions. To recover the background details and\nreduce hallucination/artefacts, we propose structure and high-frequency\nconsistency losses. Our quantitative and qualitative evaluations on real images\nshow that our method outperforms state-of-the-art methods in suppressing night\nlight effects and boosting the intensity of dark regions.",
    "descriptor": "\nComments: Accepted to ECCV2022\n",
    "authors": [
      "Yeying Jin",
      "Wenhan Yang",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10564"
  },
  {
    "id": "arXiv:2207.10569",
    "title": "A Reinforcement Learning-based Offensive semantics Censorship System for  Chatbots",
    "abstract": "The rapid development of artificial intelligence (AI) technology has enabled\nlarge-scale AI applications to land in the market and practice. However, while\nAI technology has brought many conveniences to people in the productization\nprocess, it has also exposed many security issues. Especially, attacks against\nonline learning vulnerabilities of chatbots occur frequently. Therefore, this\npaper proposes a semantics censorship chatbot system based on reinforcement\nlearning, which is mainly composed of two parts: the Offensive semantics\ncensorship model and the semantics purification model. Offensive semantics\nreview can combine the context of user input sentences to detect the rapid\nevolution of Offensive semantics and respond to Offensive semantics responses.\nThe semantics purification model For the case of chatting robot models, it has\nbeen contaminated by large numbers of offensive semantics, by strengthening the\noffensive reply learned by the learning algorithm, rather than rolling back to\nthe early versions. In addition, by integrating a once-through learning\napproach, the speed of semantics purification is accelerated while reducing the\nimpact on the quality of replies. The experimental results show that our\nproposed approach reduces the probability of the chat model generating\noffensive replies and that the integration of the few-shot learning algorithm\nimproves the training speed rapidly while effectively slowing down the decline\nin BLEU values.",
    "descriptor": "",
    "authors": [
      "Shaokang Cai",
      "Dezhi Han",
      "Zibin Zheng",
      "Dun Li",
      "NoelCrespi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10569"
  },
  {
    "id": "arXiv:2207.10572",
    "title": "Big Data and Education: using big data analytics in language learning",
    "abstract": "Working with big data using data mining tools is rapidly becoming a trend in\neducation industry. The combination of the current capacity to collect, store,\nmanage and process data in a timely manner, and data from online educational\nplatforms represents an unprecedented opportunity for educational institutes,\nlearners, educators, and researchers. In this position paper, we consider some\nbasic concepts as well as most popular tools, methods and techniques regarding\nEducational Data Mining and Learning Analytics, and discuss big data\napplications in language learning, in particular.",
    "descriptor": "",
    "authors": [
      "Vahid Ashrafimoghari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10572"
  },
  {
    "id": "arXiv:2207.10573",
    "title": "AI Based Chatbot: An Approach of Utilizing On Customer Service  Assistance",
    "abstract": "Providing the best customer experience is one of the primary concerns for the\nfirms that are based online. The advancement of machine learning is\nrevolutionising the company's attitude towards the client through improving the\nservice quality by implementing chatbot solutions, which gives the user instant\nand satisfactory answers to their enquiries. The acceptance of this technology\nis increasing with the new improvements and efficiency of the chatbot system.\nThis thesis paper will cover the concept of chatbot system for the company, as\na use case we took AK traders Ltd. It involves the research work on various\nchatbot technologies available and based on research, use them to develop a\nchatbot system for the company. This system will work based on the text as a\nconversational agent that can interact with humans by natural language. The\nmain objective project is to develop the chatbot solution that could comply\nwith complex questions and logical output answers in a well-defined approach.\nThe ultimate goal is to give high-quality results (answers) based on user input\n(question). For the successful implementation of this project, we have\nundertaken an in-depth analysis of the various machine learning techniques\navailable and followed well-structured implementation to figure out the best\nsolution for the company. The primary concern of this project includes natural\nlanguage processing (NLP), machine learning and the vector space model (VSM).\nThe outcome of the project shows the problem-solving technique for the\nimplementation of the chatbot system for the company at a reasonable quality\nlevel",
    "descriptor": "",
    "authors": [
      "Rejwan Bin Sulaiman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10573"
  },
  {
    "id": "arXiv:2207.10574",
    "title": "Face-to-Face Co-Located Human-Human Social Interaction Analysis using  Nonverbal Cues: A Survey",
    "abstract": "This work presents a systematic review of recent efforts (since 2010) aimed\nat automatic analysis of nonverbal cues displayed in face-to-face co-located\nhuman-human social interactions. The main reason for focusing on nonverbal cues\nis that these are the physical, machine detectable traces of social and\npsychological phenomena. Therefore, detecting and understanding nonverbal cues\nmeans, at least to a certain extent, to detect and understand social and\npsychological phenomena. The covered topics are categorized into three as: a)\nmodeling social traits, such as leadership, dominance, personality traits, b)\nsocial role recognition and social relations detection and c) interaction\ndynamics analysis in terms of group cohesion, empathy, rapport and so forth. We\ntarget the co-located interactions, in which the interactants are always\nhumans. The survey covers a wide spectrum of settings and scenarios, including\nfree-standing interactions, meetings, indoor and outdoor social exchanges,\ndyadic conversations, and crowd dynamics. For each of them, the survey\nconsiders the three main elements of nonverbal cues analysis, namely data,\nsensing approaches and computational methodologies. The goal is to highlight\nthe main advances of the last decade, to point out existing limitations, and to\noutline future directions.",
    "descriptor": "\nComments: Submitted to ACM Computing and Surveys\n",
    "authors": [
      "Cigdem Beyan",
      "Alessandro Vinciarelli",
      "Alessio Del Bue"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.10574"
  },
  {
    "id": "arXiv:2207.10576",
    "title": "Democratizing Ethical Assessment of Natural Language Generation Models",
    "abstract": "Natural language generation models are computer systems that generate\ncoherent language when prompted with a sequence of words as context. Despite\ntheir ubiquity and many beneficial applications, language generation models\nalso have the potential to inflict social harms by generating discriminatory\nlanguage, hateful speech, profane content, and other harmful material. Ethical\nassessment of these models is therefore critical. But it is also a challenging\ntask, requiring an expertise in several specialized domains, such as\ncomputational linguistics and social justice. While significant strides have\nbeen made by the research community in this domain, accessibility of such\nethical assessments to the wider population is limited due to the high entry\nbarriers. This article introduces a new tool to democratize and standardize\nethical assessment of natural language generation models: Tool for Ethical\nAssessment of Language generation models (TEAL), a component of Credo AI Lens,\nan open-source assessment framework.",
    "descriptor": "\nComments: 28th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2022), August 14-18, 2022, Washington, DC\n",
    "authors": [
      "Amin Rasekh",
      "Ian Eisenberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10576"
  },
  {
    "id": "arXiv:2207.10580",
    "title": "Feedback capacity of Gaussian channels with memory",
    "abstract": "We consider the feedback capacity of a MIMO channel whose channel output is\ngiven by a linear state-space model driven by the channel inputs and a Gaussian\nprocess. The generality of our state-space model subsumes all previous studied\nmodels such as additive channels with colored Gaussian noise, and channels with\nan arbitrary dependence on previous channel inputs or outputs. The main result\nis a computable feedback capacity expression that is given as a convex\noptimization problem subject to a detectability condition. We demonstrate the\ncapacity result on the auto-regressive Gaussian noise channel, where we show\nthat even a single time-instance delay in the feedback reduces the feedback\ncapacity significantly in the stationary regime. On the other hand, for large\nregression parameters (in the non-stationary regime), the feedback capacity can\nbe approached with delayed feedback. Finally, we show that the detectability\ncondition is satisfied for scalar models and conjecture that it is true for\nMIMO models.",
    "descriptor": "\nComments: This paper was presented at the ISIT 2022\n",
    "authors": [
      "Oron Sabag",
      "Victoria Kostina",
      "Babak Hassibi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.10580"
  },
  {
    "id": "arXiv:2207.10582",
    "title": "Designing An Illumination-Aware Network for Deep Image Relighting",
    "abstract": "Lighting is a determining factor in photography that affects the style,\nexpression of emotion, and even quality of images. Creating or finding\nsatisfying lighting conditions, in reality, is laborious and time-consuming, so\nit is of great value to develop a technology to manipulate illumination in an\nimage as post-processing. Although previous works have explored techniques\nbased on the physical viewpoint for relighting images, extensive supervisions\nand prior knowledge are necessary to generate reasonable images, restricting\nthe generalization ability of these works. In contrast, we take the viewpoint\nof image-to-image translation and implicitly merge ideas of the conventional\nphysical viewpoint. In this paper, we present an Illumination-Aware Network\n(IAN) which follows the guidance from hierarchical sampling to progressively\nrelight a scene from a single image with high efficiency. In addition, an\nIllumination-Aware Residual Block (IARB) is designed to approximate the\nphysical rendering process and to extract precise descriptors of light sources\nfor further manipulations. We also introduce a depth-guided geometry encoder\nfor acquiring valuable geometry- and structure-related representations once the\ndepth information is available. Experimental results show that our proposed\nmethod produces better quantitative and qualitative relighting results than\nprevious state-of-the-art methods. The code and models are publicly available\non https://github.com/NK-CS-ZZL/IAN.",
    "descriptor": "\nComments: Accepted for publication as a Regular paper in the IEEE Transactions on Image Processing (T-IP)\n",
    "authors": [
      "Zuo-Liang Zhu",
      "Zhen Li",
      "Rui-Xun Zhang",
      "Chun-Le Guo",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10582"
  },
  {
    "id": "arXiv:2207.10588",
    "title": "On Hardness of Testing Equivalence to Sparse Polynomials Under Shifts",
    "abstract": "We say that two given polynomials $f, g \\in R[X]$, over a ring $R$, are\nequivalent under shifts if there exists a vector $a \\in R^n$ such that $f(X+a)\n= g(X)$. Grigoriev and Karpinski (FOCS 1990), Lakshman and Saunders (SICOMP,\n1995), and Grigoriev and Lakshman (ISSAC 1995) studied the problem of testing\npolynomial equivalence of a given polynomial to any $t$-sparse polynomial, over\nthe rational numbers, and gave exponential time algorithms. In this paper, we\nprovide hardness results for this problem. Formally, for a ring $R$, let\n$\\mathrm{SparseShift}_R$ be the following decision problem. Given a polynomial\n$P(X)$, is there a vector $a$ such that $P(X+a)$ contains fewer monomials than\n$P(X)$. We show that $\\mathrm{SparseShift}_R$ is at least as hard as checking\nif a given system of polynomial equations over $R[x_1,\\ldots, x_n]$ has a\nsolution (Hilbert's Nullstellensatz).\nAs a consequence of this reduction, we get the following results.\n1. $\\mathrm{SparseShift}_\\mathbb{Z}$ is undecidable.\n2. For any ring $R$ (which is not a field) such that $\\mathrm{HN}_R$ is\n$\\mathrm{NP}_R$-complete over the Blum-Shub-Smale model of computation,\n$\\mathrm{SparseShift}_{R}$ is also $\\mathrm{NP}_{R}$-complete. In particular,\n$\\mathrm{SparseShift}_{\\mathbb{Z}}$ is also\n$\\mathrm{NP}_{\\mathbb{Z}}$-complete.\nWe also study the gap version of the $\\mathrm{SparseShift}_R$ and show the\nfollowing.\n1. For every function $\\beta: \\mathbb{N}\\to\\mathbb{R}_+$ such that $\\beta\\in\no(1)$, $N^\\beta$-gap-$\\mathrm{SparseShift}_\\mathbb{Z}$ is also undecidable\n(where $N$ is the input length).\n2. For $R=\\mathbb{F}_p, \\mathbb{Q}, \\mathbb{R}$ or $\\mathbb{Z}_q$ and for\nevery $\\beta>1$ the $\\beta$-gap-$\\mathrm{SparseShift}_R$ problem is\n$\\mathrm{NP}$-hard.",
    "descriptor": "",
    "authors": [
      "Suryajith Chillara",
      "Coral Grichener",
      "Amir Shpilka"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2207.10588"
  },
  {
    "id": "arXiv:2207.10589",
    "title": "Boosting 3D Object Detection via Object-Focused Image Fusion",
    "abstract": "3D object detection has achieved remarkable progress by taking point clouds\nas the only input. However, point clouds often suffer from incomplete geometric\nstructures and the lack of semantic information, which makes detectors hard to\naccurately classify detected objects. In this work, we focus on how to\neffectively utilize object-level information from images to boost the\nperformance of point-based 3D detector. We present DeMF, a simple yet effective\nmethod to fuse image information into point features. Given a set of point\nfeatures and image feature maps, DeMF adaptively aggregates image features by\ntaking the projected 2D location of the 3D point as reference. We evaluate our\nmethod on the challenging SUN RGB-D dataset, improving state-of-the-art results\nby a large margin (+2.1 mAP@0.25 and +2.3mAP@0.5). Code is available at\nhttps://github.com/haoy945/DeMF.",
    "descriptor": "",
    "authors": [
      "Hao Yang",
      "Chen Shi",
      "Yihong Chen",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10589"
  },
  {
    "id": "arXiv:2207.10590",
    "title": "On Feller Continuity and Full Abstraction (Long Version)",
    "abstract": "We study the nature of applicative bisimilarity in $\\lambda$-calculi endowed\nwith operators for sampling from continuous distributions. On the one hand, we\nshow that bisimilarity, logical equivalence, and testing equivalence all\ncoincide with contextual equivalence when real numbers can be manipulated only\nthrough continuous functions. The key ingredient towards this result is a novel\nnotion of Feller-continuity for labelled Markov processes, which we believe of\nindependent interest, being a broad class of LMPs for which coinductive and\nlogically inspired equivalences coincide. On the other hand, we show that if no\nconstraint is put on the way real numbers are manipulated, characterizing\ncontextual equivalence turns out to be hard, and most of the aforementioned\nnotions of equivalence are even unsound.",
    "descriptor": "",
    "authors": [
      "Gilles Barthe",
      "Rapha\u00eblle Crubill\u00e9",
      "Ugo Dal Lago",
      "Francesco Gavazzo"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.10590"
  },
  {
    "id": "arXiv:2207.10591",
    "title": "FDD Massive MIMO Channel Training Optimal Rate Distortion Bounds and the  Efficiency of one-shot Schemes",
    "abstract": "We study the problem of providing channel state information (CSI) at the\ntransmitter in multi-user massive MIMO systems operating in frequency division\nduplexing (FDD). The wideband MIMO channel is a vector-valued random process\ncorrelated in time, space (antennas), and frequency (subcarriers). The base\nstation (BS) broadcasts periodically beta_tr pilot symbols from its M antenna\nports to K single-antenna users (UEs). Correspondingly, the K UEs send feedback\nmessages about their channel state using beta_fb symbols in the uplink (UL).\nUsing results from remote rate-distortion theory, we show that, as snr reaches\ninfty, the optimal feedback strategy achieves a channel state estimation mean\nsquared error (MSE) that behaves as Theta(1) if beta_tr < r and as\nTheta(snr^(-alpha)) when beta_tr >=r, where alpha = min(beta_fb/r, 1), where r\nis the rank of the channel covariance matrix. The MSE-optimal rate-distortion\nstrategy implies encoding of long sequences of channel states, which would\nyield completely stale CSI and therefore poor multiuser precoding performance.\nHence, we consider three practical one-shot CSI strategies with minimum\none-slot delay and analyze their large-SNR channel estimation MSE behavior.\nThese are: (1) digital feedback via entropy-coded scalar quantization (ECSQ),\n(2) analog feedback (AF), and (3) local channel estimation at the UEs and\ndigital feedback. These schemes have different requirements in terms of\nknowledge of the channel statistics at the UE and at the BS. In particular, the\nlatter strategy requires no statistical knowledge and is closely inspired by a\nCSI feedback scheme currently proposed in 3GPP standardization.",
    "descriptor": "",
    "authors": [
      "Mahdi Barzegar Khalilsarai",
      "Yi Song",
      "Tianyu Yang",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.10591"
  },
  {
    "id": "arXiv:2207.10600",
    "title": "Knowledge Transfer and Distillation from Autoregressive to  Non-Autoregressive Speech Recognition",
    "abstract": "Modern non-autoregressive~(NAR) speech recognition systems aim to accelerate\nthe inference speed; however, they suffer from performance degradation compared\nwith autoregressive~(AR) models as well as the huge model size issue. We\npropose a novel knowledge transfer and distillation architecture that leverages\nknowledge from AR models to improve the NAR performance while reducing the\nmodel's size. Frame- and sequence-level objectives are well-designed for\ntransfer learning. To further boost the performance of NAR, a beam search\nmethod on Mask-CTC is developed to enlarge the search space during the\ninference stage. Experiments show that the proposed NAR beam search relatively\nreduces CER by over 5% on AISHELL-1 benchmark with a tolerable\nreal-time-factor~(RTF) increment. By knowledge transfer, the NAR student who\nhas the same size as the AR teacher obtains relative CER reductions of 8/16% on\nAISHELL-1 dev/test sets, and over 25% relative WER reductions on LibriSpeech\ntest-clean/other sets. Moreover, the ~9x smaller NAR models achieve ~25%\nrelative CER/WER reductions on both AISHELL-1 and LibriSpeech benchmarks with\nthe proposed knowledge transfer and distillation.",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Xun Gong",
      "Zhikai Zhou",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10600"
  },
  {
    "id": "arXiv:2207.10603",
    "title": "Unsupervised pre-training of graph transformers on patient population  graphs",
    "abstract": "Pre-training has shown success in different areas of machine learning, such\nas Computer Vision, Natural Language Processing (NLP), and medical imaging.\nHowever, it has not been fully explored for clinical data analysis. An immense\namount of clinical records are recorded, but still, data and labels can be\nscarce for data collected in small hospitals or dealing with rare diseases. In\nsuch scenarios, pre-training on a larger set of unlabelled clinical data could\nimprove performance. In this paper, we propose novel unsupervised pre-training\ntechniques designed for heterogeneous, multi-modal clinical data for patient\noutcome prediction inspired by masked language modeling (MLM), by leveraging\ngraph deep learning over population graphs. To this end, we further propose a\ngraph-transformer-based network, designed to handle heterogeneous clinical\ndata. By combining masking-based pre-training with a transformer-based network,\nwe translate the success of masking-based pre-training in other domains to\nheterogeneous clinical data. We show the benefit of our pre-training method in\na self-supervised and a transfer learning setting, utilizing three medical\ndatasets TADPOLE, MIMIC-III, and a Sepsis Prediction Dataset. We find that our\nproposed pre-training methods help in modeling the data at a patient and\npopulation level and improve performance in different fine-tuning tasks on all\ndatasets.",
    "descriptor": "\nComments: 20 pages, 3 figures, 20 tables\n",
    "authors": [
      "Chantal Pellegrini",
      "Nassir Navab",
      "Anees Kazi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10603"
  },
  {
    "id": "arXiv:2207.10606",
    "title": "Approximate Differentiable Rendering with Algebraic Surfaces",
    "abstract": "Differentiable renderers provide a direct mathematical link between an\nobject's 3D representation and images of that object. In this work, we develop\nan approximate differentiable renderer for a compact, interpretable\nrepresentation, which we call Fuzzy Metaballs. Our approximate renderer focuses\non rendering shapes via depth maps and silhouettes. It sacrifices fidelity for\nutility, producing fast runtimes and high-quality gradient information that can\nbe used to solve vision tasks. Compared to mesh-based differentiable renderers,\nour method has forward passes that are 5x faster and backwards passes that are\n30x faster. The depth maps and silhouette images generated by our method are\nsmooth and defined everywhere. In our evaluation of differentiable renderers\nfor pose estimation, we show that our method is the only one comparable to\nclassic techniques. In shape from silhouette, our method performs well using\nonly gradient descent and a per-pixel loss, without any surrogate losses or\nregularization. These reconstructions work well even on natural video sequences\nwith segmentation artifacts. Project page:\nhttps://leonidk.github.io/fuzzy-metaballs",
    "descriptor": "\nComments: Accepted to the European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Leonid Keselman",
      "Martial Hebert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.10606"
  },
  {
    "id": "arXiv:2207.10607",
    "title": "Deep Statistic Shape Model for Myocardium Segmentation",
    "abstract": "Accurate segmentation and motion estimation of myocardium have always been\nimportant in clinic field, which essentially contribute to the downstream\ndiagnosis. However, existing methods cannot always guarantee the shape\nintegrity for myocardium segmentation. In addition, motion estimation requires\npoint correspondence on the myocardium region across different frames. In this\npaper, we propose a novel end-to-end deep statistic shape model to focus on\nmyocardium segmentation with both shape integrity and boundary correspondence\npreserving. Specifically, myocardium shapes are represented by a fixed number\nof points, whose variations are extracted by Principal Component Analysis\n(PCA). Deep neural network is used to predict the transformation parameters\n(both affine and deformation), which are then used to warp the mean point cloud\nto the image domain. Furthermore, a differentiable rendering layer is\nintroduced to incorporate mask supervision into the framework to learn more\naccurate point clouds. In this way, the proposed method is able to consistently\nproduce anatomically reasonable segmentation mask without post processing.\nAdditionally, the predicted point cloud guarantees boundary correspondence for\nsequential images, which contributes to the downstream tasks, such as the\nmotion estimation of myocardium. We conduct several experiments to demonstrate\nthe effectiveness of the proposed method on several benchmark datasets.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Xiaoling Hu",
      "Xiao Chen",
      "Yikang Liu",
      "Eric Z. Chen",
      "Terrence Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10607"
  },
  {
    "id": "arXiv:2207.10611",
    "title": "Incentive Designs for Stackelberg Games with a Large Number of Followers  and their Mean-Field Limits",
    "abstract": "We study incentive designs for a class of stochastic Stackelberg games with\none leader and a large number of (finite as well as infinite population of)\nfollowers. We investigate whether the leader can craft a strategy under a\ndynamic information structure that induces a desired behavior among the\nfollowers. For the finite population setting, under sufficient conditions, we\nshow that there exist symmetric incentive strategies for the leader that attain\napproximately optimal performance from the leader's viewpoint and lead to an\napproximate symmetric (pure) Nash best response among the followers. Driving\nthe follower population to infinity, we arrive at the interesting result that\nin this infinite-population regime the leader cannot design a smooth\n\"finite-energy\" incentive strategy, namely, a mean-field limit for such games\nis not well-defined. As a way around this, we introduce a class of stochastic\nStackelberg games with a leader, a major follower, and a finite or infinite\npopulation of minor followers, where the leader provides an incentive only for\nthe major follower, who in turn influences the rest of the followers through\nher strategy. For this class of problems, we are able to establish the\nexistence of an incentive strategy with finitely many minor followers. We also\nshow that if the leader's strategy with finitely many minor followers converges\nas their population size grows, then the limit defines an incentive strategy\nfor the corresponding mean-field Stackelberg game. Examples of quadratic\nGaussian games are provided to illustrate both positive and negative results.\nIn addition, as a byproduct of our analysis, we establish existence of a\nrandomized incentive strategy for the class mean-field Stackelberg games, which\nin turn provides an approximation for an incentive strategy of the\ncorresponding finite population Stackelberg game.",
    "descriptor": "\nComments: 1 figure\n",
    "authors": [
      "Sina Sanjari",
      "Subhonmesh Bose",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.10611"
  },
  {
    "id": "arXiv:2207.10614",
    "title": "A Dense Material Segmentation Dataset for Indoor and Outdoor Scene  Parsing",
    "abstract": "A key algorithm for understanding the world is material segmentation, which\nassigns a label (metal, glass, etc.) to each pixel. We find that a model\ntrained on existing data underperforms in some settings and propose to address\nthis with a large-scale dataset of 3.2 million dense segments on 44,560 indoor\nand outdoor images, which is 23x more segments than existing data. Our data\ncovers a more diverse set of scenes, objects, viewpoints and materials, and\ncontains a more fair distribution of skin types. We show that a model trained\non our data outperforms a state-of-the-art model across datasets and\nviewpoints. We propose a large-scale scene parsing benchmark and baseline of\n0.729 per-pixel accuracy, 0.585 mean class accuracy and 0.420 mean IoU across\n46 materials.",
    "descriptor": "",
    "authors": [
      "Paul Upchurch",
      "Ransen Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10614"
  },
  {
    "id": "arXiv:2207.10615",
    "title": "The Gift That Keeps on Giving: Generosity is Contagious in Multiplayer  Online Games",
    "abstract": "Understanding social interactions and generous behaviors have long been of\nconsiderable interest in the social science community. While the contagion of\ngenerosity is documented in the real world, less is known about such phenomenon\nin virtual worlds and whether it has an actionable impact on user behavior and\nretention. In this work, we analyze social dynamics in the virtual world of the\npopular massively multiplayer online role-playing game (MMORPG) Sky: Children\nof Light. We develop a framework to reveal the patterns of generosity in such\nsocial environments and provide empirical evidence of social contagion and\ncontagious generosity. Players become more engaged in the game after playing\nwith others and especially with friends. We also find that players who\nexperience generosity first-hand or even observe other players conduct generous\nacts become more generous themselves in the future. Additionally, we show that\nboth receiving and observing generosity lead to higher future engagement in the\ngame. Since Sky resembles the real world from a social play aspect, the\nimplications of our findings also go beyond this virtual world.",
    "descriptor": "\nComments: 22 pages, 6 figures, 6 tables. To appear in the Proceedings of the ACM on Human-Computer Interaction (PACM HCI), CSCW 2022\n",
    "authors": [
      "Alexander J. Bisberg",
      "Julie Jiang",
      "Yilei Zeng",
      "Emily Chen",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10615"
  },
  {
    "id": "arXiv:2207.10617",
    "title": "Leveraging Natural Supervision for Language Representation Learning and  Generation",
    "abstract": "Recent breakthroughs in Natural Language Processing (NLP) have been driven by\nlanguage models trained on a massive amount of plain text. While powerful,\nderiving supervision from textual resources is still an open question. For\nexample, language model pretraining often neglects the rich, freely-available\nstructures in textual data. In this thesis, we describe three lines of work\nthat seek to improve the training and evaluation of neural models using\nnaturally-occurring supervision.\nWe first investigate self-supervised training losses to help enhance the\nperformance of pretrained language models for various NLP tasks. Specifically,\nwe alter the sentence prediction loss to make it better suited to other\npretraining losses and more challenging to solve. We design an intermediate\nfinetuning step that uses self-supervised training to promote models' ability\nin cross-task generalization.\nThen we describe methods to leverage the structures in Wikipedia and\nparaphrases. In particular, we propose training losses to exploit hyperlinks,\narticle structures, and article category graphs for entity-, discourse-,\nentailment-related knowledge. We propose a framework that uses paraphrase pairs\nto disentangle semantics and syntax in sentence representations. We extend the\nframework for a novel generation task that controls the syntax of output text\nwith a sentential exemplar.\nLastly, we discuss our work on tailoring textual resources for establishing\nchallenging evaluation tasks. We introduce three datasets by defining novel\ntasks using various fan-contributed websites, including a long-form\ndata-to-text generation dataset, a screenplay summarization dataset, and a\nlong-form story generation dataset. These datasets have unique characteristics\noffering challenges to future work in their respective task settings.",
    "descriptor": "\nComments: PhD Thesis\n",
    "authors": [
      "Mingda Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10617"
  },
  {
    "id": "arXiv:2207.10623",
    "title": "MetaComp: Learning to Adapt for Online Depth Completion",
    "abstract": "Relying on deep supervised or self-supervised learning, previous methods for\ndepth completion from paired single image and sparse depth data have achieved\nimpressive performance in recent years. However, facing a new environment where\nthe test data occurs online and differs from the training data in the RGB image\ncontent and depth sparsity, the trained model might suffer severe performance\ndrop. To encourage the trained model to work well in such conditions, we expect\nit to be capable of adapting to the new environment continuously and\neffectively. To achieve this, we propose MetaComp. It utilizes the\nmeta-learning technique to simulate adaptation policies during the training\nphase, and then adapts the model to new environments in a self-supervised\nmanner in testing. Considering that the input is multi-modal data, it would be\nchallenging to adapt a model to variations in two modalities simultaneously,\ndue to significant differences in structure and form of the two modal data.\nTherefore, we further propose to disentangle the adaptation procedure in the\nbasic meta-learning training into two steps, the first one focusing on the\ndepth sparsity while the second attending to the image content. During testing,\nwe take the same strategy to adapt the model online to new multi-modal data.\nExperimental results and comprehensive ablations show that our MetaComp is\ncapable of adapting to the depth completion in a new environment effectively\nand robust to changes in different modalities.",
    "descriptor": "",
    "authors": [
      "Yang Chen",
      "Shanshan Zhao",
      "Wei Ji",
      "Mingming Gong",
      "Liping Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10623"
  },
  {
    "id": "arXiv:2207.10625",
    "title": "A Dynamical Systems Algorithm for Clustering in Hyperspectral Imagery",
    "abstract": "In this paper we present a new dynamical systems algorithm for clustering in\nhyperspectral images. The main idea of the algorithm is that data points are\n\\`pushed\\' in the direction of increasing density and groups of pixels that end\nup in the same dense regions belong to the same class. This is essentially a\nnumerical solution of the differential equation defined by the gradient of the\ndensity of data points on the data manifold. The number of classes is automated\nand the resulting clustering can be extremely accurate. In addition to\nproviding a accurate clustering, this algorithm presents a new tool for\nunderstanding hyperspectral data in high dimensions. We evaluate the algorithm\non the Urban (Available at www.tec.ary.mil/Hypercube/) scene comparing\nperformance against the k-means algorithm using pre-identified classes of\nmaterials as ground truth.",
    "descriptor": "",
    "authors": [
      "William F. Basener",
      "Alexey Castrodad",
      "David Messinger",
      "Jennifer Mahle",
      "Paul Prue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2207.10625"
  },
  {
    "id": "arXiv:2207.10629",
    "title": "A Solution to Adaptive Mobile Manipulator Throwing",
    "abstract": "Mobile manipulator throwing is a promising method to increase the flexibility\nand efficiency of dynamic manipulation in factories. Its major challenge is to\nefficiently plan a feasible throw under a wide set of task specifications. We\nanalyze the throwing problem and show that it can be reduced to a simpler\nplanar problem, hence reducing greatly the computational costs. Using data\nanalysis and machine learning, we build a model of the object's inverted flying\ndynamics and the robot's kinematic feasibility, which enables throwing motion\ngeneration in 1 ms given target position query. Due to the computational\nefficiency of our method, we show that, the system is adaptive when disturbed\nduring task execution, via replanning on the fly to find out an alternative\nthrow, instead of sticking to the original plan. Code is available at:\nhttps://github.com/liuyangdh/mobile-throwing",
    "descriptor": "\nComments: Accepted at IROS 2022\n",
    "authors": [
      "Yang Liu",
      "Aradhana Nayak",
      "Aude Billard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10629"
  },
  {
    "id": "arXiv:2207.10635",
    "title": "Widespread Underestimation of Sensitivity in Differentially Private  Libraries and How to Fix It",
    "abstract": "We identify a new class of vulnerabilities in implementations of differential\nprivacy. Specifically, they arise when computing basic statistics such as sums,\nthanks to discrepancies between the implemented arithmetic using finite data\ntypes (namely, ints or floats) and idealized arithmetic over the reals or\nintegers. These discrepancies cause the sensitivity of the implemented\nstatistics (i.e., how much one individual's data can affect the result) to be\nmuch higher than the sensitivity we expect. Consequently, essentially all\ndifferential privacy libraries fail to introduce enough noise to hide\nindividual-level information as required by differential privacy, and we show\nthat this may be exploited in realistic attacks on differentially private query\nsystems. In addition to presenting these vulnerabilities, we also provide a\nnumber of solutions, which modify or constrain the way in which the sum is\nimplemented in order to recover the idealized or near-idealized bounds on\nsensitivity.",
    "descriptor": "\nComments: Presented at TPDP 2022\n",
    "authors": [
      "S\u00edlvia Casacuberta",
      "Michael Shoemate",
      "Salil Vadhan",
      "Connor Wagaman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10635"
  },
  {
    "id": "arXiv:2207.10639",
    "title": "Session-based Cyberbullying Detection in Social Media: A Survey",
    "abstract": "Cyberbullying is a pervasive problem in online social media, where a bully\nabuses a victim through a social media session. By investigating cyberbullying\nperpetrated through social media sessions, recent research has looked into\nmining patterns and features for modeling and understanding the two defining\ncharacteristics of cyberbullying: repetitive behavior and power imbalance. In\nthis survey paper, we define the Session-based Cyberbullying Detection\nframework that encapsulates the different steps and challenges of the problem.\nBased on this framework, we provide a comprehensive overview of session-based\ncyberbullying detection in social media, delving into existing efforts from a\ndata and methodological perspective. Our review leads us to propose\nevidence-based criteria for a set of best practices to create session-based\ncyberbullying datasets. In addition, we perform benchmark experiments comparing\nthe performance of state-of-the-art session-based cyberbullying detection\nmodels as well as large pre-trained language models across two different\ndatasets. Through our review, we also put forth a set of open challenges as\nfuture research directions.",
    "descriptor": "",
    "authors": [
      "Peiling Yi",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10639"
  },
  {
    "id": "arXiv:2207.10641",
    "title": "Deep Learning Reveals Patterns of Diverse and Changing Sentiments  Towards COVID-19 Vaccines Based on 11 Million Tweets",
    "abstract": "Over 12 billion doses of COVID-19 vaccines have been administered at the time\nof writing. However, public perceptions of vaccines have been complex. We\nanalyzed COVID-19 vaccine-related tweets to understand the evolving perceptions\nof COVID-19 vaccines. We finetuned a deep learning classifier using a\nstate-of-the-art model, XLNet, to detect each tweet's sentiment automatically.\nWe employed validated methods to extract the users' race or ethnicity, gender,\nage, and geographical locations from user profiles. Incorporating multiple data\nsources, we assessed the sentiment patterns among subpopulations and juxtaposed\nthem against vaccine uptake data to unravel their interactive patterns.\n11,211,672 COVID-19 vaccine-related tweets corresponding to 2,203,681 users\nover two years were analyzed. The finetuned model for sentiment classification\nyielded an accuracy of 0.92 on testing set. Users from various demographic\ngroups demonstrated distinct patterns in sentiments towards COVID-19 vaccines.\nUser sentiments became more positive over time, upon which we observed\nsubsequent upswing in the population-level vaccine uptake. Surrounding dates\nwhere positive sentiments crest, we detected encouraging news or events\nregarding vaccine development and distribution. Positive sentiments in\npregnancy-related tweets demonstrated a delayed pattern compared with trends in\ngeneral population, with postponed vaccine uptake trends. Distinctive patterns\nacross subpopulations suggest the need of tailored strategies. Global news and\nevents profoundly involved in shaping users' thoughts on social media.\nPopulations with additional concerns, such as pregnancy, demonstrated more\nsubstantial hesitancy since lack of timely recommendations. Feature analysis\nrevealed hesitancies of various subpopulations stemmed from clinical trial\nlogics, risks and complications, and urgency of scientific evidence.",
    "descriptor": "",
    "authors": [
      "Hanyin Wang",
      "Meghan R. Hutch",
      "Yikuan Li",
      "Adrienne S. Kline",
      "Sebastian Otero",
      "Leena B. Mithal",
      "Emily S. Miller",
      "Andrew Naidech",
      "Yuan Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10641"
  },
  {
    "id": "arXiv:2207.10642",
    "title": "Generative Multiplane Images: Making a 2D GAN 3D-Aware",
    "abstract": "What is really needed to make an existing 2D GAN 3D-aware? To answer this\nquestion, we modify a classical GAN, i.e., StyleGANv2, as little as possible.\nWe find that only two modifications are absolutely necessary: 1) a multiplane\nimage style generator branch which produces a set of alpha maps conditioned on\ntheir depth; 2) a pose-conditioned discriminator. We refer to the generated\noutput as a 'generative multiplane image' (GMPI) and emphasize that its\nrenderings are not only high-quality but also guaranteed to be view-consistent,\nwhich makes GMPIs different from many prior works. Importantly, the number of\nalpha maps can be dynamically adjusted and can differ between training and\ninference, alleviating memory concerns and enabling fast training of GMPIs in\nless than half a day at a resolution of $1024^2$. Our findings are consistent\nacross three challenging and common high-resolution datasets, including FFHQ,\nAFHQv2, and MetFaces.",
    "descriptor": "\nComments: ECCV2022; Project Page: this https URL\n",
    "authors": [
      "Xiaoming Zhao",
      "Fangchang Ma",
      "David G\u00fcera",
      "Zhile Ren",
      "Alexander G. Schwing",
      "Alex Colburn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10642"
  },
  {
    "id": "arXiv:2207.10643",
    "title": "STOP: A dataset for Spoken Task Oriented Semantic Parsing",
    "abstract": "End-to-end spoken language understanding (SLU) predicts intent directly from\naudio using a single model. It promises to improve the performance of assistant\nsystems by leveraging acoustic information lost in the intermediate textual\nrepresentation and preventing cascading errors from Automatic Speech\nRecognition (ASR). Further, having one unified model has efficiency advantages\nwhen deploying assistant systems on-device. However, the limited number of\npublic audio datasets with semantic parse labels hinders the research progress\nin this area. In this paper, we release the Spoken Task-Oriented semantic\nParsing (STOP) dataset, the largest and most complex SLU dataset to be publicly\navailable. Additionally, we define low-resource splits to establish a benchmark\nfor improving SLU when limited labeled data is available. Furthermore, in\naddition to the human-recorded audio, we are releasing a TTS-generated version\nto benchmark the performance for low-resource domain adaptation of end-to-end\nSLU systems. Initial experimentation show end-to-end SLU models performing\nslightly worse than their cascaded counterparts, which we hope encourages\nfuture work in this direction.",
    "descriptor": "",
    "authors": [
      "Paden Tomasello",
      "Po-Chun Hsu",
      "Akshat Shrivastava",
      "Daniel Lazar",
      "Duc Le",
      "Adithya Sagar",
      "Ali Elkahky",
      "Jade Copet",
      "Wei-Ning Hsu",
      "Yossef Mordechay",
      "Robin Algayres",
      "Tu Ahn Nguyen",
      "Emmanuel Dupoux",
      "Luke Zettlemoyer",
      "Abdelrahman Mohamed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10643"
  },
  {
    "id": "arXiv:2207.10644",
    "title": "CTL-MTNet: A Novel CapsNet and Transfer Learning-Based Mixed Task Net  for the Single-Corpus and Cross-Corpus Speech Emotion Recognition",
    "abstract": "Speech Emotion Recognition (SER) has become a growing focus of research in\nhuman-computer interaction. An essential challenge in SER is to extract common\nattributes from different speakers or languages, especially when a specific\nsource corpus has to be trained to recognize the unknown data coming from\nanother speech corpus. To address this challenge, a Capsule Network (CapsNet)\nand Transfer Learning based Mixed Task Net (CTLMTNet) are proposed to deal with\nboth the singlecorpus and cross-corpus SER tasks simultaneously in this paper.\nFor the single-corpus task, the combination of Convolution-Pooling and\nAttention CapsNet module CPAC) is designed by embedding the self-attention\nmechanism to the CapsNet, guiding the module to focus on the important features\nthat can be fed into different capsules. The extracted high-level features by\nCPAC provide sufficient discriminative ability. Furthermore, to handle the\ncross-corpus task, CTL-MTNet employs a Corpus Adaptation Adversarial Module\n(CAAM) by combining CPAC with Margin Disparity Discrepancy (MDD), which can\nlearn the domain-invariant emotion representations through extracting the\nstrong emotion commonness. Experiments including ablation studies and\nvisualizations on both singleand cross-corpus tasks using four well-known SER\ndatasets in different languages are conducted for performance evaluation and\ncomparison. The results indicate that in both tasks the CTL-MTNet showed better\nperformance in all cases compared to a number of state-of-the-art methods. The\nsource code and the supplementary materials are available at:\nhttps://github.com/MLDMXM2017/CTLMTNet",
    "descriptor": "\nComments: this paper has been accepted by IJCAI 2022. Please cite it by: Xin-Cheng Wen#, JiaXin Ye#, Yan Luo, Yong Xu, Xuan-Ze WANG, Chang-Li Wu, Kun-Hong Liu*, CTL-MTNet: A Novel CapsNet and Transfer Learning-Based Mixed Task Net for the Single-Corpus and Cross-Corpus Speech Emotion Recognition, IJCAI 2022\n",
    "authors": [
      "Xin-Cheng Wen",
      "Jia-Xin Ye",
      "Yan Luo",
      "Yong Xu",
      "Xuan-Ze Wang",
      "Chang-Li Wu",
      "Kun-Hong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10644"
  },
  {
    "id": "arXiv:2207.10645",
    "title": "Wide & Deep Learning for Judging Student Performance in Online  One-on-one Math Classes",
    "abstract": "In this paper, we investigate the opportunities of automating the judgment\nprocess in online one-on-one math classes. We build a Wide & Deep framework to\nlearn fine-grained predictive representations from a limited amount of noisy\nclassroom conversation data that perform better student judgments. We conducted\nexperiments on the task of predicting students' levels of mastery of example\nquestions and the results demonstrate the superiority and availability of our\nmodel in terms of various evaluation metrics.",
    "descriptor": "\nComments: Accepted at AIED'22: The 23rd International Conference on Artificial Intelligence in Education, 2022\n",
    "authors": [
      "Jiahao Chen",
      "Zitao Liu",
      "Weiqi Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10645"
  },
  {
    "id": "arXiv:2207.10646",
    "title": "MARS : a Method for the Adaptive Removal of Stiffness in PDEs",
    "abstract": "The E(xplicit)I(implicit)N(null) method was developed recently to remove\nnumerical instability from PDEs, adding and subtracting an operator\n$\\mathcal{D}$ of arbitrary structure, treating the operator implicitly in one\ncase, and explicitly in the other. Here we extend this idea by devising an\nadaptive procedure to find an optimal approximation for $\\mathcal{D}$. We\npropose a measure of the numerical error which detects numerical instabilities\nacross all wavelengths, and adjust each Fourier component of $\\mathcal{D}$ to\nthe smallest value such that numerical instability is suppressed. We show that\nfor a number of nonlinear and non-local PDEs, in one and two dimensions, the\nspectrum of $\\mathcal{D}$ adapts automatically and dynamically to the\ntheoretical result for marginal stability. Our method thus has the same\nstability properties as a fully implicit method, while only requiring the\ncomputational cost comparable to an explicit solver. The adaptive implicit part\nis diagonal in Fourier space, and thus leads to minimal overhead compared to\nthe explicit method.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Laurent Duchemin",
      "Jens Eggers"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.10646"
  },
  {
    "id": "arXiv:2207.10648",
    "title": "A No-Code Low-Code Paradigm for Authoring Business Automations Using  Natural Language",
    "abstract": "Most business process automation is still developed using traditional\nautomation technologies such as workflow engines. These systems provide domain\nspecific languages that require both business knowledge and programming skills\nto effectively use. As such, business users often lack adequate programming\nskills to fully leverage these code oriented environments. We propose a\nparadigm for the construction of business automations using natural language.\nThe approach applies a large language model to translate business rules and\nautomations described in natural language, into a domain specific language\ninterpretable by a business rule engine. We compare the performance of various\nlanguage model configurations, across various target domains, and explore the\nuse of constrained decoding to ensure syntactically correct generation of\noutput.",
    "descriptor": "",
    "authors": [
      "Michael Desmond",
      "Evelyn Duesterwald",
      "Vatche Isahagian",
      "Vinod Muthusamy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10648"
  },
  {
    "id": "arXiv:2207.10649",
    "title": "Multilingual Disinformation Detection for Digital Advertising",
    "abstract": "In today's world, the presence of online disinformation and propaganda is\nmore widespread than ever. Independent publishers are funded mostly via digital\nadvertising, which is unfortunately also the case for those publishing\ndisinformation content. The question of how to remove such publishers from\nadvertising inventory has long been ignored, despite the negative impact on the\nopen internet. In this work, we make the first step towards quickly detecting\nand red-flagging websites that potentially manipulate the public with\ndisinformation. We build a machine learning model based on multilingual text\nembeddings that first determines whether the page mentions a topic of interest,\nthen estimates the likelihood of the content being malicious, creating a\nshortlist of publishers that will be reviewed by human experts. Our system\nempowers internal teams to proactively, rather than defensively, blacklist\nunsafe content, thus protecting the reputation of the advertisement provider.",
    "descriptor": "\nComments: Disinformation Countermeasures and Machine Learning Workshop at ICML 2022\n",
    "authors": [
      "Zofia Trstanova",
      "Nadir El Manouzi",
      "Maryline Chen",
      "Andre L. V. da Cunha",
      "Sergei Ivanov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10649"
  },
  {
    "id": "arXiv:2207.10651",
    "title": "Sensitivity-enhanced generalized polynomial chaos for efficient  uncertainty quantification",
    "abstract": "We present an enriched formulation of the Least Squares (LSQ) regression\nmethod for Uncertainty Quantification (UQ) using generalised polynomial chaos\n(gPC). More specifically, we enrich the linear system with additional equations\nfor the gradient (or sensitivity) of the Quantity of Interest with respect to\nthe stochastic variables. This sensitivity is computed very efficiently for all\nvariables by solving an adjoint system of equations at each sampling point of\nthe stochastic space. The associated computational cost is similar to one\nsolution of the direct problem. For the selection of the sampling points, we\napply a greedy algorithm which is based on the pivoted QR decomposition of the\nmeasurement matrix. We call the new approach sensitivity-enhanced generalised\npolynomial chaos, or se-gPC. We apply the method to several test cases to test\naccuracy and convergence with increasing chaos order, including an aerodynamic\ncase with $40$ stochastic parameters. The method is found to produce accurate\nestimations of the statistical moments using the minimum number of sampling\npoints. The computational cost scales as $\\sim m^{p-1}$, instead of $\\sim m^p$\nof the standard LSQ formulation, where $m$ is the number of stochastic\nvariables and $p$ the chaos order. The solution of the adjoint system of\nequations is implemented in many computational mechanics packages, thus the\ninfrastructure exists for the application of the method to a wide variety of\nengineering problems.",
    "descriptor": "",
    "authors": [
      "Kyriakos D. Kantarakias",
      "George Papadakis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Analysis of PDEs (math.AP)",
      "Spectral Theory (math.SP)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.10651"
  },
  {
    "id": "arXiv:2207.10652",
    "title": "O-Dang! The Ontology of Dangerous Speech Messages",
    "abstract": "Inside the NLP community there is a considerable amount of language resources\ncreated, annotated and released every day with the aim of studying specific\nlinguistic phenomena. Despite a variety of attempts in order to organize such\nresources has been carried on, a lack of systematic methods and of possible\ninteroperability between resources are still present. Furthermore, when storing\nlinguistic information, still nowadays, the most common practice is the concept\nof \"gold standard\", which is in contrast with recent trends in NLP that aim at\nstressing the importance of different subjectivities and points of view when\ntraining machine learning and deep learning methods. In this paper we present\nO-Dang!: The Ontology of Dangerous Speech Messages, a systematic and\ninteroperable Knowledge Graph (KG) for the collection of linguistic annotated\ndata. O-Dang! is designed to gather and organize Italian datasets into a\nstructured KG, according to the principles shared within the Linguistic Linked\nOpen Data community. The ontology has also been designed to account for a\nperspectivist approach, since it provides a model for encoding both gold\nstandard and single-annotator labels in the KG. The paper is structured as\nfollows. In Section 1 the motivations of our work are outlined. Section 2\ndescribes the O-Dang! Ontology, that provides a common semantic model for the\nintegration of datasets in the KG. The Ontology Population stage with\ninformation about corpora, users, and annotations is presented in Section 3.\nFinally, in Section 4 an analysis of offensiveness across corpora is provided\nas a first case study for the resource.",
    "descriptor": "",
    "authors": [
      "Marco A. Stranisci",
      "Simona Frenda",
      "Mirko Lai",
      "Oscar Araque",
      "Alessandra T. Cignarella",
      "Valerio Basile",
      "Viviana Patti",
      "Cristina Bosco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10652"
  },
  {
    "id": "arXiv:2207.10653",
    "title": "RepFair-GAN: Mitigating Representation Bias in GANs Using Gradient  Clipping",
    "abstract": "Fairness has become an essential problem in many domains of Machine Learning\n(ML), such as classification, natural language processing, and Generative\nAdversarial Networks (GANs). In this research effort, we study the unfairness\nof GANs. We formally define a new fairness notion for generative models in\nterms of the distribution of generated samples sharing the same protected\nattributes (gender, race, etc.). The defined fairness notion (representational\nfairness) requires the distribution of the sensitive attributes at the test\ntime to be uniform, and, in particular for GAN model, we show that this\nfairness notion is violated even when the dataset contains equally represented\ngroups, i.e., the generator favors generating one group of samples over the\nothers at the test time. In this work, we shed light on the source of this\nrepresentation bias in GANs along with a straightforward method to overcome\nthis problem. We first show on two widely used datasets (MNIST, SVHN) that when\nthe norm of the gradient of one group is more important than the other during\nthe discriminator's training, the generator favours sampling data from one\ngroup more than the other at test time. We then show that controlling the\ngroups' gradient norm by performing group-wise gradient norm clipping in the\ndiscriminator during the training leads to a more fair data generation in terms\nof representational fairness compared to existing models while preserving the\nquality of generated samples.",
    "descriptor": "",
    "authors": [
      "Patrik Joslin Kenfack",
      "Kamil Sabbagh",
      "Ad\u00edn Ram\u00edrez Rivera",
      "Adil Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10653"
  },
  {
    "id": "arXiv:2207.10654",
    "title": "Emotion detection of social data: APIs comparative study",
    "abstract": "The development of emotion detection technology has emerged as a highly\nvaluable possibility in the corporate sector due to the nearly limitless uses\nof this new discipline, particularly with the unceasing propagation of social\ndata. In recent years, the electronic marketplace has witnessed the\nestablishment of a large number of start-up businesses with an almost sole\nfocus on building new commercial and open-source tools and APIs for emotion\ndetection and recognition. Yet, these tools and APIs must be continuously\nreviewed and evaluated, and their performances should be reported and\ndiscussed. There is a lack of research to empirically compare current emotion\ndetection technologies in terms of the results obtained from each model using\nthe same textual dataset. Also, there is a lack of comparative studies that\napply benchmark comparison to social data. This study compares eight\ntechnologies; IBM Watson NLU, ParallelDots, Symanto-Ekman, Crystalfeel, Text to\nEmotion, Senpy, Textprobe, and NLP Cloud. The comparison was undertaken using\ntwo different datasets. The emotions from the chosen datasets were then derived\nusing the incorporated APIs. The performance of these APIs was assessed using\nthe aggregated scores that they delivered as well as the theoretically proven\nevaluation metrics such as the micro-average of accuracy, classification error,\nprecision, recall, and f1-score. Lastly, the assessment of these APIs\nincorporating the evaluation measures is reported and discussed.",
    "descriptor": "",
    "authors": [
      "Bilal Abu-Salih",
      "Mohammad Alhabashneh",
      "Dengya Zhu",
      "Albara Awajan",
      "Yazan Alshamaileh",
      "Bashar Al-Shboul",
      "Mohammad Alshraideh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10654"
  },
  {
    "id": "arXiv:2207.10656",
    "title": "Adaptive sparse interpolation for accelerating nonlinear stochastic  reduced-order modeling with time-dependent bases",
    "abstract": "Stochastic reduced-order modeling based on time-dependent bases (TDBs) has\nproven successful for extracting and exploiting low-dimensional manifold from\nstochastic partial differential equations (SPDEs). The nominal computational\ncost of solving a rank-$r$ reduced-order model (ROM) based on time-dependent\nbasis, a.k.a. TDB-ROM, is roughly equal to that of solving the full-order model\nfor $r$ random samples. As of now, this nominal performance can only be\nachieved for linear or quadratic SPDEs -- at the expense of a highly intrusive\nprocess. On the other hand, for problems with non-polynomial nonlinearity, the\ncomputational cost of solving the TDB evolution equations is the same as\nsolving the full-order model. In this work, we present an adaptive sparse\ninterpolation algorithm that enables stochastic TDB-ROMs to achieve nominal\ncomputational cost for generic nonlinear SPDEs. Our algorithm constructs a\nlow-rank approximation for the right hand side of the SPDE using the discrete\nempirical interpolation method (DEIM). The presented algorithm does not require\nany offline computation and as a result the low-rank approximation can adapt to\nany transient changes of the dynamics on the fly. We also propose a\nrank-adaptive strategy to control the error of the sparse interpolation. Our\nalgorithm achieves computational speedup by adaptive sampling of the state and\nrandom spaces. We illustrate the efficiency of our approach for two test cases:\n(1) one-dimensional stochastic Burgers' equation, and (2) two-dimensional\ncompressible Navier-Stokes equations subject to one-hundred-dimensional random\nperturbations. In all cases, the presented algorithm results in orders of\nmagnitude reduction in the computational cost.",
    "descriptor": "\nComments: 30 pages, 14 figures\n",
    "authors": [
      "Mohammad Hossein Naderi",
      "Hessam Babaee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2207.10656"
  },
  {
    "id": "arXiv:2207.10657",
    "title": "Non-convex, ringing-free, FFT-accelerated solver using an incremental  approximate energy functional",
    "abstract": "Fourier-accelerated micromechanical homogenization has been developed and\napplied to a variety of problems, despite being prone to ringing artifacts. In\naddition, the majority of Fourier-accelerated solvers applied to\nFFT-accelerated schemes only apply to convex problems. We here introduce a that\nallows to employ modern efficient and non-convex iterative solvers, such as\ntrust-region solvers or LBFGS in a FFT-accelerated scheme. These solvers need\nthe explicit energy functional of the system in their standard form. We develop\na modified trust region solver, capable of handling non-convex micromechanical\nhomogenization problems such as continuum damage employing the approximate\nincremental energy functional. We use the developed solver as the solver of a\nringing-free FFT-accelerated solution scheme, namely the projection based\nscheme with finite element discretization.",
    "descriptor": "\nComments: 34 pages, 9 Figures\n",
    "authors": [
      "Ali Falsafi",
      "Richard J. Leute",
      "Martin Ladeck\u00fd",
      "Till Junge"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.10657"
  },
  {
    "id": "arXiv:2207.10659",
    "title": "Novel Class Discovery without Forgetting",
    "abstract": "Humans possess an innate ability to identify and differentiate instances that\nthey are not familiar with, by leveraging and adapting the knowledge that they\nhave acquired so far. Importantly, they achieve this without deteriorating the\nperformance on their earlier learning. Inspired by this, we identify and\nformulate a new, pragmatic problem setting of NCDwF: Novel Class Discovery\nwithout Forgetting, which tasks a machine learning model to incrementally\ndiscover novel categories of instances from unlabeled data, while maintaining\nits performance on the previously seen categories. We propose 1) a method to\ngenerate pseudo-latent representations which act as a proxy for (no longer\navailable) labeled data, thereby alleviating forgetting, 2) a\nmutual-information based regularizer which enhances unsupervised discovery of\nnovel classes, and 3) a simple Known Class Identifier which aids generalized\ninference when the testing data contains instances form both seen and unseen\ncategories. We introduce experimental protocols based on CIFAR-10, CIFAR-100\nand ImageNet-1000 to measure the trade-off between knowledge retention and\nnovel class discovery. Our extensive evaluations reveal that existing models\ncatastrophically forget previously seen categories while identifying novel\ncategories, while our method is able to effectively balance between the\ncompeting objectives. We hope our work will attract further research into this\nnewly identified pragmatic problem setting.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "K J Joseph",
      "Sujoy Paul",
      "Gaurav Aggarwal",
      "Soma Biswas",
      "Piyush Rai",
      "Kai Han",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10659"
  },
  {
    "id": "arXiv:2207.10660",
    "title": "Omni3D: A Large Benchmark and Model for 3D Object Detection in the Wild",
    "abstract": "Recognizing scenes and objects in 3D from a single image is a longstanding\ngoal of computer vision with applications in robotics and AR/VR. For 2D\nrecognition, large datasets and scalable solutions have led to unprecedented\nadvances. In 3D, existing benchmarks are small in size and approaches\nspecialize in few object categories and specific domains, e.g. urban driving\nscenes. Motivated by the success of 2D recognition, we revisit the task of 3D\nobject detection by introducing a large benchmark, called Omni3D. Omni3D\nre-purposes and combines existing datasets resulting in 234k images annotated\nwith more than 3 million instances and 97 categories.3D detection at such scale\nis challenging due to variations in camera intrinsics and the rich diversity of\nscene and object types. We propose a model, called Cube R-CNN, designed to\ngeneralize across camera and scene types with a unified approach. We show that\nCube R-CNN outperforms prior works on the larger Omni3D and existing\nbenchmarks. Finally, we prove that Omni3D is a powerful dataset for 3D object\nrecognition, show that it improves single-dataset performance and can\naccelerate learning on new smaller datasets via pre-training.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Garrick Brazil",
      "Julian Straub",
      "Nikhila Ravi",
      "Justin Johnson",
      "Georgia Gkioxari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10660"
  },
  {
    "id": "arXiv:2207.10661",
    "title": "In Defense of Online Models for Video Instance Segmentation",
    "abstract": "In recent years, video instance segmentation (VIS) has been largely advanced\nby offline models, while online models gradually attracted less attention\npossibly due to their inferior performance. However, online methods have their\ninherent advantage in handling long video sequences and ongoing videos while\noffline models fail due to the limit of computational resources. Therefore, it\nwould be highly desirable if online models can achieve comparable or even\nbetter performance than offline models. By dissecting current online models and\noffline models, we demonstrate that the main cause of the performance gap is\nthe error-prone association between frames caused by the similar appearance\namong different instances in the feature space. Observing this, we propose an\nonline framework based on contrastive learning that is able to learn more\ndiscriminative instance embeddings for association and fully exploit history\ninformation for stability. Despite its simplicity, our method outperforms all\nonline and offline methods on three benchmarks. Specifically, we achieve 49.5\nAP on YouTube-VIS 2019, a significant improvement of 13.2 AP and 2.1 AP over\nthe prior online and offline art, respectively. Moreover, we achieve 30.2 AP on\nOVIS, a more challenging dataset with significant crowding and occlusions,\nsurpassing the prior art by 14.8 AP. The proposed method won first place in the\nvideo instance segmentation track of the 4th Large-scale Video Object\nSegmentation Challenge (CVPR2022). We hope the simplicity and effectiveness of\nour method, as well as our insight into current methods, could shed light on\nthe exploration of VIS models.",
    "descriptor": "\nComments: ECCV 2022, Oral\n",
    "authors": [
      "Junfeng Wu",
      "Qihao Liu",
      "Yi Jiang",
      "Song Bai",
      "Alan Yuille",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10661"
  },
  {
    "id": "arXiv:2207.10662",
    "title": "Generalizable Patch-Based Neural Rendering",
    "abstract": "Neural rendering has received tremendous attention since the advent of Neural\nRadiance Fields (NeRF), and has pushed the state-of-the-art on novel-view\nsynthesis considerably. The recent focus has been on models that overfit to a\nsingle scene, and the few attempts to learn models that can synthesize novel\nviews of unseen scenes mostly consist of combining deep convolutional features\nwith a NeRF-like model. We propose a different paradigm, where no deep features\nand no NeRF-like volume rendering are needed. Our method is capable of\npredicting the color of a target ray in a novel scene directly, just from a\ncollection of patches sampled from the scene. We first leverage epipolar\ngeometry to extract patches along the epipolar lines of each reference view.\nEach patch is linearly projected into a 1D feature vector and a sequence of\ntransformers process the collection. For positional encoding, we parameterize\nrays as in a light field representation, with the crucial difference that the\ncoordinates are canonicalized with respect to the target ray, which makes our\nmethod independent of the reference frame and improves generalization. We show\nthat our approach outperforms the state-of-the-art on novel view synthesis of\nunseen scenes even when being trained with considerably less data than prior\nwork.",
    "descriptor": "\nComments: Project Page with code and results at this https URL\n",
    "authors": [
      "Mohammed Suhail",
      "Carlos Esteves",
      "Leonid Sigal",
      "Ameesh Makadia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10662"
  },
  {
    "id": "arXiv:2207.10663",
    "title": "Neural Pixel Composition: 3D-4D View Synthesis from Multi-Views",
    "abstract": "We present Neural Pixel Composition (NPC), a novel approach for continuous\n3D-4D view synthesis given only a discrete set of multi-view observations as\ninput. Existing state-of-the-art approaches require dense multi-view\nsupervision and an extensive computational budget. The proposed formulation\nreliably operates on sparse and wide-baseline multi-view imagery and can be\ntrained efficiently within a few seconds to 10 minutes for hi-res (12MP)\ncontent, i.e., 200-400X faster convergence than existing methods. Crucial to\nour approach are two core novelties: 1) a representation of a pixel that\ncontains color and depth information accumulated from multi-views for a\nparticular location and time along a line of sight, and 2) a multi-layer\nperceptron (MLP) that enables the composition of this rich information provided\nfor a pixel location to obtain the final color output. We experiment with a\nlarge variety of multi-view sequences, compare to existing approaches, and\nachieve better results in diverse and challenging settings. Finally, our\napproach enables dense 3D reconstruction from sparse multi-views, where COLMAP,\na state-of-the-art 3D reconstruction approach, struggles.",
    "descriptor": "\nComments: A technical report on 3D-4D view synthesis (40 pages, 22 figures and 18 tables). High-resolution version of paper: this http URL Project page (containing video results): this http URL\n",
    "authors": [
      "Aayush Bansal",
      "Michael Zollhoefer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.10663"
  },
  {
    "id": "arXiv:2207.10664",
    "title": "Exploring Fine-Grained Audiovisual Categorization with the SSW60 Dataset",
    "abstract": "We present a new benchmark dataset, Sapsucker Woods 60 (SSW60), for advancing\nresearch on audiovisual fine-grained categorization. While our community has\nmade great strides in fine-grained visual categorization on images, the\ncounterparts in audio and video fine-grained categorization are relatively\nunexplored. To encourage advancements in this space, we have carefully\nconstructed the SSW60 dataset to enable researchers to experiment with\nclassifying the same set of categories in three different modalities: images,\naudio, and video. The dataset covers 60 species of birds and is comprised of\nimages from existing datasets, and brand new, expert-curated audio and video\ndatasets. We thoroughly benchmark audiovisual classification performance and\nmodality fusion experiments through the use of state-of-the-art transformer\nmethods. Our findings show that performance of audiovisual fusion methods is\nbetter than using exclusively image or audio based methods for the task of\nvideo classification. We also present interesting modality transfer\nexperiments, enabled by the unique construction of SSW60 to encompass three\ndifferent modalities. We hope the SSW60 dataset and accompanying baselines spur\nresearch in this fascinating area.",
    "descriptor": "\nComments: ECCV 2022 Camera Ready\n",
    "authors": [
      "Grant Van Horn",
      "Rui Qian",
      "Kimberly Wilber",
      "Hartwig Adam",
      "Oisin Mac Aodha",
      "Serge Belongie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10664"
  },
  {
    "id": "arXiv:2207.10665",
    "title": "One-dimensional Tensor Network Recovery",
    "abstract": "We study the recovery of the underlying graphs or permutations for tensors in\ntensor ring or tensor train format. Our proposed algorithms compare the\nmatricization ranks after down-sampling, whose complexity is $O(d\\log d)$ for\n$d$-th order tensors. We prove that our algorithms can almost surely recover\nthe correct graph or permutation when tensor entries can be observed without\nnoise. We further establish the robustness of our algorithms against\nobservational noise. The theoretical results are validated by numerical\nexperiments.",
    "descriptor": "",
    "authors": [
      "Ziang Chen",
      "Jianfeng Lu",
      "Anru R. Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.10665"
  },
  {
    "id": "arXiv:2207.10666",
    "title": "TinyViT: Fast Pretraining Distillation for Small Vision Transformers",
    "abstract": "Vision transformer (ViT) recently has drawn great attention in computer\nvision due to its remarkable model capability. However, most prevailing ViT\nmodels suffer from huge number of parameters, restricting their applicability\non devices with limited resources. To alleviate this issue, we propose TinyViT,\na new family of tiny and efficient small vision transformers pretrained on\nlarge-scale datasets with our proposed fast distillation framework. The central\nidea is to transfer knowledge from large pretrained models to small ones, while\nenabling small models to get the dividends of massive pretraining data. More\nspecifically, we apply distillation during pretraining for knowledge transfer.\nThe logits of large teacher models are sparsified and stored in disk in advance\nto save the memory cost and computation overheads. The tiny student\ntransformers are automatically scaled down from a large pretrained model with\ncomputation and parameter constraints. Comprehensive experiments demonstrate\nthe efficacy of TinyViT. It achieves a top-1 accuracy of 84.8% on ImageNet-1k\nwith only 21M parameters, being comparable to Swin-B pretrained on ImageNet-21k\nwhile using 4.2 times fewer parameters. Moreover, increasing image resolutions,\nTinyViT can reach 86.5% accuracy, being slightly better than Swin-L while using\nonly 11% parameters. Last but not the least, we demonstrate a good transfer\nability of TinyViT on various downstream tasks. Code and models are available\nat https://github.com/microsoft/Cream/tree/main/TinyViT.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Kan Wu",
      "Jinnian Zhang",
      "Houwen Peng",
      "Mengchen Liu",
      "Bin Xiao",
      "Jianlong Fu",
      "Lu Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10666"
  },
  {
    "id": "arXiv:2207.10667",
    "title": "Online Domain Adaptation for Semantic Segmentation in Ever-Changing  Conditions",
    "abstract": "Unsupervised Domain Adaptation (UDA) aims at reducing the domain gap between\ntraining and testing data and is, in most cases, carried out in offline manner.\nHowever, domain changes may occur continuously and unpredictably during\ndeployment (e.g. sudden weather changes). In such conditions, deep neural\nnetworks witness dramatic drops in accuracy and offline adaptation may not be\nenough to contrast it. In this paper, we tackle Online Domain Adaptation (OnDA)\nfor semantic segmentation. We design a pipeline that is robust to continuous\ndomain shifts, either gradual or sudden, and we evaluate it in the case of\nrainy and foggy scenarios. Our experiments show that our framework can\neffectively adapt to new domains during deployment, while not being affected by\ncatastrophic forgetting of the previous domains.",
    "descriptor": "\nComments: ECCV 2022. Project page: this https URL\n",
    "authors": [
      "Theodoros Panagiotakopoulos",
      "Pier Luigi Dovesi",
      "Linus H\u00e4renstam-Nielsen",
      "Matteo Poggi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10667"
  },
  {
    "id": "arXiv:2008.12627",
    "title": "Deep Reinforcement Learning for Field Development Optimization",
    "abstract": "The field development optimization (FDO) problem represents a challenging\nmixed-integer nonlinear programming (MINLP) problem in which we seek to obtain\nthe number of wells, their type, location, and drilling sequence that maximizes\nan economic metric. Evolutionary optimization algorithms have been effectively\napplied to solve the FDO problem, however, these methods provide only a\ndeterministic (single) solution which are generally not robust towards small\nchanges in the problem setup. In this work, the goal is to apply convolutional\nneural network-based (CNN) deep reinforcement learning (DRL) algorithms to the\nfield development optimization problem in order to obtain a policy that maps\nfrom different states or representation of the underlying geological model to\noptimal decisions. The proximal policy optimization (PPO) algorithm is\nconsidered with two CNN architectures of varying number of layers and\ncomposition. Both networks obtained policies that provide satisfactory results\nwhen compared to a hybrid particle swarm optimization - mesh adaptive direct\nsearch (PSO-MADS) algorithm that has been shown to be effective at solving the\nFDO problem.",
    "descriptor": "",
    "authors": [
      "Yusuf Nasir"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2008.12627"
  },
  {
    "id": "arXiv:2203.13375",
    "title": "Deep reinforcement learning for optimal well control in subsurface  systems with uncertain geology",
    "abstract": "A general control policy framework based on deep reinforcement learning (DRL)\nis introduced for closed-loop decision making in subsurface flow settings.\nTraditional closed-loop modeling workflows in this context involve the repeated\napplication of data assimilation/history matching and robust optimization\nsteps. Data assimilation can be particularly challenging in cases where both\nthe geological style (scenario) and individual model realizations are\nuncertain. The closed-loop reservoir management (CLRM) problem is formulated\nhere as a partially observable Markov decision process, with the associated\noptimization problem solved using a proximal policy optimization algorithm.\nThis provides a control policy that instantaneously maps flow data observed at\nwells (as are available in practice) to optimal well pressure settings. The\npolicy is represented by a temporal convolution and gated transformer blocks.\nTraining is performed in a preprocessing step with an ensemble of prior\ngeological models, which can be drawn from multiple geological scenarios.\nExample cases involving the production of oil via water injection, with both 2D\nand 3D geological models, are presented. The DRL-based methodology is shown to\nresult in an NPV increase of 15% (for the 2D cases) and 33% (3D cases) relative\nto robust optimization over prior models, and to an average improvement of 4%\nin NPV relative to traditional CLRM. The solutions from the control policy are\nfound to be comparable to those from deterministic optimization, in which the\ngeological model is assumed to be known, even when multiple geological\nscenarios are considered. The control policy approach results in a 76% decrease\nin computational cost relative to traditional CLRM with the algorithms and\nparameter settings considered in this work.",
    "descriptor": "",
    "authors": [
      "Yusuf Nasir",
      "Louis J. Durlofsky"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.13375"
  },
  {
    "id": "arXiv:2207.10097",
    "title": "Complexity of the Guided Local Hamiltonian Problem: Improved Parameters  and Extension to Excited States",
    "abstract": "Recently it was shown that the so-called guided local Hamiltonian problem --\nestimating the smallest eigenvalue of a $k$-local Hamiltonian when provided\nwith a description of a quantum state ('guiding state') that is guaranteed to\nhave substantial overlap with the true groundstate -- is BQP-complete for $k\n\\geq 6$ when the required precision is inverse polynomial in the system size\n$n$, and remains hard even when the overlap of the guiding state with the\ngroundstate is close to a constant $\\left(\\frac12 -\n\\Omega\\left(\\frac{1}{\\mathop{poly}(n)}\\right)\\right)$. We improve upon this\nresult in three ways: by showing that it remains BQP-complete when i) the\nHamiltonian is 2-local, ii) the overlap between the guiding state and target\neigenstate is as large as $1 - \\Omega\\left(\\frac{1}{\\mathop{poly}(n)}\\right)$,\nand iii) when one is interested in estimating energies of excited states,\nrather than just the groundstate. Interestingly, iii) is only made possible by\nfirst showing that ii) holds.",
    "descriptor": "\nComments: 21 pages, 3 figures\n",
    "authors": [
      "Chris Cade",
      "Marten Folkertsma",
      "Jordi Weggemans"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2207.10097"
  },
  {
    "id": "arXiv:2207.10140",
    "title": "Learning Underspecified Models",
    "abstract": "This paper examines whether one can learn to play an optimal action while\nonly knowing part of true specification of the environment. We choose the\noptimal pricing problem as our laboratory, where the monopolist is endowed with\nan underspecified model of the market demand, but can observe market outcomes.\nIn contrast to conventional learning models where the model specification is\ncomplete and exogenously fixed, the monopolist has to learn the specification\nand the parameters of the demand curve from the data. We formulate the learning\ndynamics as an algorithm that forecast the optimal price based on the data,\nfollowing the machine learning literature (Shalev-Shwartz and Ben-David\n(2014)). Inspired by PAC learnability, we develop a new notion of learnability\nby requiring that the algorithm must produce an accurate forecast with a\nreasonable amount of data uniformly over the class of models consistent with\nthe part of the true specification. In addition, we assume that the monopolist\nhas a lexicographic preference over the payoff and the complexity cost of the\nalgorithm, seeking an algorithm with a minimum number of parameters subject to\nPAC-guaranteeing the optimal solution (Rubinstein (1986)). We show that for the\nset of demand curves with strictly decreasing uniformly Lipschitz continuous\nmarginal revenue curve, the optimal algorithm recursively estimates the slope\nand the intercept of the linear demand curve, even if the actual demand curve\nis not linear. The monopolist chooses a misspecified model to save\ncomputational cost, while learning the true optimal decision uniformly over the\nset of underspecified demand curves.",
    "descriptor": "",
    "authors": [
      "In-Koo Cho",
      "Jonathan Libgober"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10140"
  },
  {
    "id": "arXiv:2207.10163",
    "title": "Constrained Prescriptive Trees via Column Generation",
    "abstract": "With the abundance of available data, many enterprises seek to implement\ndata-driven prescriptive analytics to help them make informed decisions. These\nprescriptive policies need to satisfy operational constraints, and proactively\neliminate rule conflicts, both of which are ubiquitous in practice. It is also\ndesirable for them to be simple and interpretable, so they can be easily\nverified and implemented. Existing approaches from the literature center around\nconstructing variants of prescriptive decision trees to generate interpretable\npolicies. However, none of the existing methods are able to handle constraints.\nIn this paper, we propose a scalable method that solves the constrained\nprescriptive policy generation problem. We introduce a novel path-based\nmixed-integer program (MIP) formulation which identifies a (near) optimal\npolicy efficiently via column generation. The policy generated can be\nrepresented as a multiway-split tree which is more interpretable and\ninformative than a binary-split tree due to its shorter rules. We demonstrate\nthe efficacy of our method with extensive experiments on both synthetic and\nreal datasets.",
    "descriptor": "",
    "authors": [
      "Shivaram Subramanian",
      "Wei Sun",
      "Youssef Drissi",
      "Markus Ettl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10163"
  },
  {
    "id": "arXiv:2207.10167",
    "title": "Liver Segmentation using Turbolift Learning for CT and Cone-beam C-arm  Perfusion Imaging",
    "abstract": "Model-based reconstruction employing the time separation technique (TST) was\nfound to improve dynamic perfusion imaging of the liver using C-arm cone-beam\ncomputed tomography (CBCT). To apply TST using prior knowledge extracted from\nCT perfusion data, the liver should be accurately segmented from the CT scans.\nReconstructions of primary and model-based CBCT data need to be segmented for\nproper visualisation and interpretation of perfusion maps. This research\nproposes Turbolift learning, which trains a modified version of the multi-scale\nAttention UNet on different liver segmentation tasks serially, following the\norder of the trainings CT, CBCT, CBCT TST - making the previous trainings act\nas pre-training stages for the subsequent ones - addressing the problem of\nlimited number of datasets for training. For the final task of liver\nsegmentation from CBCT TST, the proposed method achieved an overall Dice scores\nof 0.874$\\pm$0.031 and 0.905$\\pm$0.007 in 6-fold and 4-fold cross-validation\nexperiments, respectively - securing statistically significant improvements\nover the model, which was trained only for that task. Experiments revealed that\nTurbolift not only improves the overall performance of the model but also makes\nit robust against artefacts originating from the embolisation materials and\ntruncation artefacts. Additionally, in-depth analyses confirmed the order of\nthe segmentation tasks. This paper shows the potential of segmenting the liver\nfrom CT, CBCT, and CBCT TST, learning from the available limited training data,\nwhich can possibly be used in the future for the visualisation and evaluation\nof the perfusion maps for the treatment evaluation of liver diseases.",
    "descriptor": "",
    "authors": [
      "Hana Haselji\u0107",
      "Soumick Chatterjee",
      "Robert Frysch",
      "Vojt\u011bch Kulvait",
      "Vladimir Semshchikov",
      "Bennet Hensen",
      "Frank Wacker",
      "Inga Br\u00fcsch",
      "Thomas Werncke",
      "Oliver Speck",
      "Andreas N\u00fcrnberger",
      "Georg Rose"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.10167"
  },
  {
    "id": "arXiv:2207.10171",
    "title": "Pseudoperiodic Words and a Question of Shevelev",
    "abstract": "We generalize the familiar notion of periodicity in sequences to a new kind\nof pseudoperiodicity, and we prove some basic results about it. We revisit the\nresults of a 2012 paper of Shevelev and reprove his results in a simpler and\nmore unified manner, and provide a complete answer to one of his previously\nunresolved questions. We consider finding words with specific pseudoperiods and\nhaving the smallest possible critical exponent. Finally, we consider the\nproblem of determining whether a finite word is pseudoperiodic of a given size,\nand show that it is NP-complete.",
    "descriptor": "",
    "authors": [
      "Joseph Meleshko",
      "Pascal Ochem",
      "Jeffrey Shallit",
      "Sonja Linghui Shan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2207.10171"
  },
  {
    "id": "arXiv:2207.10181",
    "title": "Flow-based Visual Quality Enhancer for Super-resolution Magnetic  Resonance Spectroscopic Imaging",
    "abstract": "Magnetic Resonance Spectroscopic Imaging (MRSI) is an essential tool for\nquantifying metabolites in the body, but the low spatial resolution limits its\nclinical applications. Deep learning-based super-resolution methods provided\npromising results for improving the spatial resolution of MRSI, but the\nsuper-resolved images are often blurry compared to the experimentally-acquired\nhigh-resolution images. Attempts have been made with the generative adversarial\nnetworks to improve the image visual quality. In this work, we consider another\ntype of generative model, the flow-based model, of which the training is more\nstable and interpretable compared to the adversarial networks. Specifically, we\npropose a flow-based enhancer network to improve the visual quality of\nsuper-resolution MRSI. Different from previous flow-based models, our enhancer\nnetwork incorporates anatomical information from additional image modalities\n(MRI) and uses a learnable base distribution. In addition, we impose a guide\nloss and a data-consistency loss to encourage the network to generate images\nwith high visual quality while maintaining high fidelity. Experiments on a\n1H-MRSI dataset acquired from 25 high-grade glioma patients indicate that our\nenhancer network outperforms the adversarial networks and the baseline\nflow-based methods. Our method also allows visual quality adjustment and\nuncertainty estimation.",
    "descriptor": "\nComments: Accepted by DGM4MICCAI 2022\n",
    "authors": [
      "Siyuan Dong",
      "Gilbert Hangel",
      "Eric Z. Chen",
      "Shanhui Sun",
      "Wolfgang Bogner",
      "Georg Widhalm",
      "Chenyu You",
      "John A. Onofrey",
      "Robin de Graaf",
      "James S. Duncan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10181"
  },
  {
    "id": "arXiv:2207.10216",
    "title": "Globally stable and locally optimal model predictive control using a  softened initial state constraint -- extended version",
    "abstract": "To address feasibility issues in model predictive control (MPC), most\nimplementations relax hard state constraints using additional slack variables\nwith a suitable penalty. We propose an alternative strategy for open-loop\nasymptotically/Lyapunov stable nonlinear systems by relaxing the initial state\nconstraint with a suitable penalty. The proposed MPC framework is globally\nfeasible, ensures (semi-)global asymptotic stability, and (approximately)\nrecovers the closed-loop properties of the nominal MPC on the feasible set. The\nproposed framework can be naturally combined with a robust formulation to\nensure robustness subject to bounded disturbances while retaining\ninput-ot-state stability in case of arbitrarily large disturbances. We also\nshow how the overall design can be simplified in case the nonlinear system is\nexponentially stable. In the special case of linear systems, the proposed MPC\nformulation reduces to a quadratic program and the offline design and online\ncomputational complexity is only marginally increased compared to anominal\ndesign. Benefits compared to classical soft contrained MPC formulations are\ndemonstrated with numerical examples.",
    "descriptor": "",
    "authors": [
      "Johannes K\u00f6hler",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10216"
  },
  {
    "id": "arXiv:2207.10250",
    "title": "Improved Hardness Results for the Guided Local Hamiltonian Problem",
    "abstract": "Estimating the ground state energy of a local Hamiltonian is a central\nproblem in quantum chemistry. In order to further investigate its complexity\nand the potential of quantum algorithms for quantum chemistry, Gharibian and Le\nGall (STOC 2022) recently introduced the guided local Hamiltonian problem\n(GLH), which is a variant of the local Hamiltonian problem where an\napproximation of a ground state is given as an additional input. Gharibian and\nLe Gall showed quantum advantage (more precisely, BQP-completeness) for GLH\nwith $6$-local Hamiltonians when the guiding vector has overlap\n(inverse-polynomially) close to 1/2 with a ground state. In this paper, we\noptimally improve both the locality and the overlap parameters: we show that\nthis quantum advantage (BQP-completeness) persists even with 2-local\nHamiltonians, and even when the guiding vector has overlap\n(inverse-polynomially) close to 1 with a ground state. Moreover, we show that\nthe quantum advantage also holds for 2-local physically motivated Hamiltonians\non a 2D square lattice. This makes a further step towards establishing\npractical quantum advantage in quantum chemistry.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Sevag Gharibian",
      "Ryu Hayakawa",
      "Fran\u00e7ois Le Gall",
      "Tomoyuki Morimae"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2207.10250"
  },
  {
    "id": "arXiv:2207.10289",
    "title": "A comprehensive study of non-adaptive and residual-based adaptive  sampling for physics-informed neural networks",
    "abstract": "Physics-informed neural networks (PINNs) have shown to be an effective tool\nfor solving forward and inverse problems of partial differential equations\n(PDEs). PINNs embed the PDEs into the loss of the neural network, and this PDE\nloss is evaluated at a set of scattered residual points. The distribution of\nthese points are highly important to the performance of PINNs. However, in the\nexisting studies on PINNs, only a few simple residual point sampling methods\nhave mainly been used. Here, we present a comprehensive study of two categories\nof sampling: non-adaptive uniform sampling and adaptive nonuniform sampling. We\nconsider six uniform sampling, including (1) equispaced uniform grid, (2)\nuniformly random sampling, (3) Latin hypercube sampling, (4) Halton sequence,\n(5) Hammersley sequence, and (6) Sobol sequence. We also consider a resampling\nstrategy for uniform sampling. To improve the sampling efficiency and the\naccuracy of PINNs, we propose two new residual-based adaptive sampling methods:\nresidual-based adaptive distribution (RAD) and residual-based adaptive\nrefinement with distribution (RAR-D), which dynamically improve the\ndistribution of residual points based on the PDE residuals during training.\nHence, we have considered a total of 10 different sampling methods, including\nsix non-adaptive uniform sampling, uniform sampling with resampling, two\nproposed adaptive sampling, and an existing adaptive sampling. We extensively\ntested the performance of these sampling methods for four forward problems and\ntwo inverse problems in many setups. Our numerical results presented in this\nstudy are summarized from more than 6000 simulations of PINNs. We show that the\nproposed adaptive sampling methods of RAD and RAR-D significantly improve the\naccuracy of PINNs with fewer residual points. The results obtained in this\nstudy can also be used as a practical guideline in choosing sampling methods.",
    "descriptor": "",
    "authors": [
      "Chenxi Wu",
      "Min Zhu",
      "Qinyang Tan",
      "Yadhu Kartha",
      "Lu Lu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10289"
  },
  {
    "id": "arXiv:2207.10294",
    "title": "Optimal Control of Multi-Agent Systems with Processing Delays",
    "abstract": "In this article, we consider a cooperative control problem involving\ndynamically decoupled linear plants. The (output-feedback) controllers for each\nplant communicate with each other according to a fixed and known network\ntopology, and each transmission incurs a fixed continuous-time processing\ndelay. We provide an explicit closed-form expression for the optimal\ndecentralized controller and its associated cost under these communication\nconstraints and standard linear quadratic Gaussian (LQG) assumptions for the\nplants and cost function. We find the exact solution without discretizing or\notherwise approximating the delays. We also present an implementation of each\nsub-controller that is efficiently computable, and is composed of standard\nfinite-dimensional linear time-invariant (LTI) and finite impulse response\n(FIR) components, and has an intuitive observer-regulator architecture\nreminiscent of the classical separation principle.",
    "descriptor": "",
    "authors": [
      "Mruganka Kashyap",
      "Laurent Lessard"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10294"
  },
  {
    "id": "arXiv:2207.10324",
    "title": "Improved Generative Model for Weakly Supervised Chest Anomaly  Localization via Pseudo-paired Registration with Bilaterally Symmetrical Data  Augmentation",
    "abstract": "Image translation based on a generative adversarial network (GAN-IT) is a\npromising method for precise localization of abnormal regions in chest X-ray\nimages (AL-CXR). However, heterogeneous unpaired datasets undermine existing\nmethods to extract key features and distinguish normal from abnormal cases,\nresulting in inaccurate and unstable AL-CXR. To address this problem, we\npropose an improved two-stage GAN-IT involving registration and data\naugmentation. For the first stage, we introduce an invertible\ndeep-learning-based registration technique that virtually and reasonably\nconverts unpaired data into paired data for learning registration maps. This\nnovel approach achieves high registration performance. For the second stage, we\napply data augmentation to diversify anomaly locations by swapping the left and\nright lung regions on the uniform registered frames, further improving the\nperformance by alleviating imbalance in data distribution showing left and\nright lung lesions. Our method is intended for application to existing GAN-IT\nmodels, allowing existing architecture to benefit from key features for\ntranslation. By showing that the AL-CXR performance is uniformly improved when\napplying the proposed method, we believe that GAN-IT for AL-CXR can be deployed\nin clinical environments, even if learning data are scarce.",
    "descriptor": "\nComments: Kyung-Su Kim and Seong Je Oh have contributed equally to this work as the co-first author. Kyung-Su Kim (kskim.doc@gmail.com) and Myung Jin Chung (mj1.chung@samsung.com) have contributed equally to this work as the co-corresponding author\n",
    "authors": [
      "Kyung-Su Kim",
      "Seong Je Oh",
      "Tae Uk Kim",
      "Myung Jin Chung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10324"
  },
  {
    "id": "arXiv:2207.10415",
    "title": "Log Barriers for Safe Black-box Optimization with Application to Safe  Reinforcement Learning",
    "abstract": "Optimizing noisy functions online, when evaluating the objective requires\nexperiments on a deployed system, is a crucial task arising in manufacturing,\nrobotics and many others. Often, constraints on safe inputs are unknown ahead\nof time, and we only obtain noisy information, indicating how close we are to\nviolating the constraints. Yet, safety must be guaranteed at all times, not\nonly for the final output of the algorithm.\nWe introduce a general approach for seeking a stationary point in high\ndimensional non-linear stochastic optimization problems in which maintaining\nsafety during learning is crucial. Our approach called LB-SGD is based on\napplying stochastic gradient descent (SGD) with a carefully chosen adaptive\nstep size to a logarithmic barrier approximation of the original problem. We\nprovide a complete convergence analysis of non-convex, convex, and\nstrongly-convex smooth constrained problems, with first-order and zeroth-order\nfeedback. Our approach yields efficient updates and scales better with\ndimensionality compared to existing approaches.\nWe empirically compare the sample complexity and the computational cost of\nour method with existing safe learning approaches. Beyond synthetic benchmarks,\nwe demonstrate the effectiveness of our approach on minimizing constraint\nviolation in policy search tasks in safe reinforcement learning (RL).",
    "descriptor": "\nComments: 34 pages, 8 pages of appendix\n",
    "authors": [
      "Ilnura Usmanova",
      "Yarden As",
      "Maryam Kamgarpour",
      "Andreas Krause"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10415"
  },
  {
    "id": "arXiv:2207.10442",
    "title": "Estimation of Non-Crossing Quantile Regression Process with Deep ReQU  Neural Networks",
    "abstract": "We propose a penalized nonparametric approach to estimating the quantile\nregression process (QRP) in a nonseparable model using rectifier quadratic unit\n(ReQU) activated deep neural networks and introduce a novel penalty function to\nenforce non-crossing of quantile regression curves. We establish the\nnon-asymptotic excess risk bounds for the estimated QRP and derive the mean\nintegrated squared error for the estimated QRP under mild smoothness and\nregularity conditions. To establish these non-asymptotic risk and estimation\nerror bounds, we also develop a new error bound for approximating $C^s$ smooth\nfunctions with $s >0$ and their derivatives using ReQU activated neural\nnetworks. This is a new approximation result for ReQU networks and is of\nindependent interest and may be useful in other problems. Our numerical\nexperiments demonstrate that the proposed method is competitive with or\noutperforms two existing methods, including methods using reproducing kernels\nand random forests, for nonparametric quantile regression.",
    "descriptor": "\nComments: 44 pages, 10 figures, 6 tables\n",
    "authors": [
      "Guohao Shen",
      "Yuling Jiao",
      "Yuanyuan Lin",
      "Joel L. Horowitz",
      "Jian Huang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10442"
  },
  {
    "id": "arXiv:2207.10446",
    "title": "COBRA: Cpu-Only aBdominal oRgan segmentAtion",
    "abstract": "Abdominal organ segmentation is a difficult and time-consuming task. To\nreduce the burden on clinical experts, fully-automated methods are highly\ndesirable. Current approaches are dominated by Convolutional Neural Networks\n(CNNs) however the computational requirements and the need for large data sets\nlimit their application in practice. By implementing a small and efficient\ncustom 3D CNN, compiling the trained model and optimizing the computational\ngraph: our approach produces high accuracy segmentations (Dice Similarity\nCoefficient (%): Liver: 97.3$\\pm$1.3, Kidneys: 94.8$\\pm$3.6, Spleen:\n96.4$\\pm$3.0, Pancreas: 80.9$\\pm$10.1) at a rate of 1.6 seconds per image.\nCrucially, we are able to perform segmentation inference solely on CPU (no GPU\nrequired), thereby facilitating easy and widespread deployment of the model\nwithout specialist hardware.",
    "descriptor": "\nComments: MCR-RRR submission for the Fast and Low GPU memory Abdominal oRgan sEgmentation Challenge (FLARE) at MICCAI 2021\n",
    "authors": [
      "Edward G. A. Henderson",
      "D\u00f3nal M. McSweeney",
      "Andrew F. Green"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10446"
  },
  {
    "id": "arXiv:2207.10485",
    "title": "Towards Confident Detection of Prostate Cancer using High Resolution  Micro-ultrasound",
    "abstract": "MOTIVATION: Detection of prostate cancer during transrectal ultrasound-guided\nbiopsy is challenging. The highly heterogeneous appearance of cancer, presence\nof ultrasound artefacts, and noise all contribute to these difficulties. Recent\nadvancements in high-frequency ultrasound imaging - micro-ultrasound - have\ndrastically increased the capability of tissue imaging at high resolution. Our\naim is to investigate the development of a robust deep learning model\nspecifically for micro-ultrasound-guided prostate cancer biopsy. For the model\nto be clinically adopted, a key challenge is to design a solution that can\nconfidently identify the cancer, while learning from coarse histopathology\nmeasurements of biopsy samples that introduce weak labels. METHODS: We use a\ndataset of micro-ultrasound images acquired from 194 patients, who underwent\nprostate biopsy. We train a deep model using a co-teaching paradigm to handle\nnoise in labels, together with an evidential deep learning method for\nuncertainty estimation. We evaluate the performance of our model using the\nclinically relevant metric of accuracy vs. confidence. RESULTS: Our model\nachieves a well-calibrated estimation of predictive uncertainty with area under\nthe curve of 88$\\%$. The use of co-teaching and evidential deep learning in\ncombination yields significantly better uncertainty estimation than either\nalone. We also provide a detailed comparison against state-of-the-art in\nuncertainty estimation.",
    "descriptor": "",
    "authors": [
      "Mahdi Gilany",
      "Paul Wilson",
      "Amoon Jamzad",
      "Fahimeh Fooladgar",
      "Minh Nguyen Nhat To",
      "Brian Wodlinger",
      "Purang Abolmaesumi",
      "Parvin Mousavi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10485"
  },
  {
    "id": "arXiv:2207.10486",
    "title": "Bayesian Recurrent Units and the Forward-Backward Algorithm",
    "abstract": "Using Bayes's theorem, we derive a unit-wise recurrence as well as a backward\nrecursion similar to the forward-backward algorithm. The resulting Bayesian\nrecurrent units can be integrated as recurrent neural networks within deep\nlearning frameworks, while retaining a probabilistic interpretation from the\ndirect correspondence with hidden Markov models. Whilst the contribution is\nmainly theoretical, experiments on speech recognition indicate that adding the\nderived units at the end of state-of-the-art recurrent architectures can\nimprove the performance at a very low cost in terms of trainable parameters.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Alexandre Bittar",
      "Philip N. Garner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10486"
  },
  {
    "id": "arXiv:2207.10488",
    "title": "Metropolis Monte Carlo sampling: convergence, localization transition  and optimality",
    "abstract": "Among random sampling methods, Markov Chain Monte Carlo algorithms are\nforemost. Using a combination of analytical and numerical approaches, we study\ntheir convergence properties towards the steady state, within a random walk\nMetropolis scheme. We show that the deviations from the target steady-state\ndistribution feature a localization transition as a function of the\ncharacteristic length of the attempted jumps defining the random walk. This\ntransition changes drastically the error which is introduced by incomplete\nconvergence, and discriminates two regimes where the relaxation mechanism is\nlimited respectively by diffusion and by rejection.",
    "descriptor": "",
    "authors": [
      "Alexei D. Chepelianskii",
      "Satya N. Majumdar",
      "Hendrik Schawe",
      "Emmanuel Trizac"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.10488"
  },
  {
    "id": "arXiv:2207.10650",
    "title": "Deep Learning of Radiative Atmospheric Transfer with an Autoencoder",
    "abstract": "As electro-optical energy from the sun propagates through the atmosphere it\nis affected by radiative transfer effects including absorption, emission, and\nscattering. Modeling these affects is essential for scientific remote sensing\nmeasurements of the earth and atmosphere. For example, hyperspectral imagery is\na form of digital imagery collected with many, often hundreds, of wavelengths\nof light in pixel. The amount of light measured at the sensor is the result of\nemitted sunlight, atmospheric radiative transfer, and the reflectance off the\nmaterials on the ground, all of which vary per wavelength resulting from\nmultiple physical phenomena. Therefore measurements of the ground spectra or\natmospheric constituents requires separating these different contributions per\nwavelength. In this paper, we create an autoencoder similar to denoising\nautoencoders treating the atmospheric affects as 'noise' and ground reflectance\nas truth per spectrum. We generate hundreds of thousands of training samples by\ntaking random samples of spectra from laboratory measurements and adding\natmospheric affects using physics-based modelling via MODTRAN\n(this http URL) by varying atmospheric inputs. This\nprocess ideally could create an autoencoder that would separate atmospheric\neffects and ground reflectance in hyperspectral imagery, a process called\natmospheric compensation which is difficult and time-consuming requiring a\ncombination of heuristic approximations, estimates of physical quantities, and\nphysical modelling. While the accuracy of our method is not as good as other\nmethods in the field, this an important first step in applying the growing\nfield of deep learning of physical principles to atmospheric compensation in\nhyperspectral imagery and remote sensing.",
    "descriptor": "",
    "authors": [
      "Abigail Basener",
      "Bill Basener"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Pattern Formation and Solitons (nlin.PS)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.10650"
  },
  {
    "id": "arXiv:1602.08927",
    "title": "High-Dimensional $L_2$Boosting: Rate of Convergence",
    "abstract": "Comments: 19 pages, 4 tables; AMS 2000 subject classifications: Primary 62J05, 62J07, 41A25; secondary 49M15, 68Q32",
    "descriptor": "\nComments: 19 pages, 4 tables; AMS 2000 subject classifications: Primary 62J05, 62J07, 41A25; secondary 49M15, 68Q32\n",
    "authors": [
      "Ye Luo",
      "Martin Spindler",
      "Jannis K\u00fcck"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/1602.08927"
  },
  {
    "id": "arXiv:1806.00582",
    "title": "Federated Learning with Non-IID Data",
    "abstract": "Federated Learning with Non-IID Data",
    "descriptor": "",
    "authors": [
      "Yue Zhao",
      "Meng Li",
      "Liangzhen Lai",
      "Naveen Suda",
      "Damon Civin",
      "Vikas Chandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1806.00582"
  },
  {
    "id": "arXiv:1808.02686",
    "title": "An Improved Bound for Weak Epsilon-Nets in the Plane",
    "abstract": "Comments: A preliminary version to appear in the proceedings of FOCS 2018. Full version to appear in Journal of ACM",
    "descriptor": "\nComments: A preliminary version to appear in the proceedings of FOCS 2018. Full version to appear in Journal of ACM\n",
    "authors": [
      "Natan Rubin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1808.02686"
  },
  {
    "id": "arXiv:1907.03532",
    "title": "Classification of Macromolecule Type Based on Sequences of Amino Acids  Using Deep Learning",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Sarwar Khan",
      "Faisal Ghaffar",
      "Imad ali",
      "qazi mazhar"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1907.03532"
  },
  {
    "id": "arXiv:1909.04881",
    "title": "Algebraic Property Graphs",
    "abstract": "Algebraic Property Graphs",
    "descriptor": "",
    "authors": [
      "Joshua Shinavier",
      "Ryan Wisnesky",
      "Joshua G. Meyers"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/1909.04881"
  },
  {
    "id": "arXiv:1910.03384",
    "title": "Experimental Validation of Feedback Optimization in Power Distribution  Grids",
    "abstract": "Experimental Validation of Feedback Optimization in Power Distribution  Grids",
    "descriptor": "",
    "authors": [
      "Lukas Ortmann",
      "Adrian Hauswirth",
      "Ivo Caduff",
      "Florian D\u00f6rfler",
      "Saverio Bolognani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1910.03384"
  },
  {
    "id": "arXiv:1911.10686",
    "title": "Zero-Shot Imitating Collaborative Manipulation Plans from YouTube  Cooking Videos",
    "abstract": "Comments: 8 pages, 9 figures",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Hejia Zhang",
      "Jie Zhong",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1911.10686"
  },
  {
    "id": "arXiv:1911.12426",
    "title": "Conditional Hierarchical Bayesian Tucker Decomposition for Genetic Data  Analysis",
    "abstract": "Comments: 35 pages, 8 figures, 5 tables",
    "descriptor": "\nComments: 35 pages, 8 figures, 5 tables\n",
    "authors": [
      "Adam Sandler",
      "Diego Klabjan",
      "Yuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.12426"
  },
  {
    "id": "arXiv:2002.03938",
    "title": "Distribution Approximation and Statistical Estimation Guarantees of  Generative Adversarial Networks",
    "abstract": "Comments: Version two extends to low-dimensional linear and mixture distributions",
    "descriptor": "\nComments: Version two extends to low-dimensional linear and mixture distributions\n",
    "authors": [
      "Minshuo Chen",
      "Wenjing Liao",
      "Hongyuan Zha",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.03938"
  },
  {
    "id": "arXiv:2007.08600",
    "title": "Denial-of-Service Vulnerability of Hash-based Transaction Sharding:  Attack and Countermeasure",
    "abstract": "Comments: To be published in IEEE Transactions on Computers",
    "descriptor": "\nComments: To be published in IEEE Transactions on Computers\n",
    "authors": [
      "Truc Nguyen",
      "My T. Thai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2007.08600"
  },
  {
    "id": "arXiv:2007.09075",
    "title": "Efficient Linear and Affine Codes for Correcting Insertions/Deletions",
    "abstract": "Efficient Linear and Affine Codes for Correcting Insertions/Deletions",
    "descriptor": "",
    "authors": [
      "Kuan Cheng",
      "Venkatesan Guruswami",
      "Bernhard Haeupler",
      "Xin Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2007.09075"
  },
  {
    "id": "arXiv:2007.15820",
    "title": "Photorealism in Driving Simulations: Blending Generative Adversarial  Image Synthesis with Rendering",
    "abstract": "Comments: 10 pages, 5 figures, IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: 10 pages, 5 figures, IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Ekim Yurtsever",
      "Dongfang Yang",
      "Ibrahim Mert Koc",
      "Keith A. Redmill"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2007.15820"
  },
  {
    "id": "arXiv:2009.02540",
    "title": "A Survey of Deep Learning Architectures for Intelligent Reflecting  Surfaces",
    "abstract": "Comments: 7 pages and 5 figures. This work has been submitted to the IEEE for publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 7 pages and 5 figures. This work has been submitted to the IEEE for publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ahmet M. Elbir",
      "Kumar Vijay Mishra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.02540"
  },
  {
    "id": "arXiv:2010.00974",
    "title": "Computation of invariant sets via immersion for discrete-time nonlinear  systems",
    "abstract": "Comments: Computational details of Example 2 are added. This paper is provisionally accepted in Automatica",
    "descriptor": "\nComments: Computational details of Example 2 are added. This paper is provisionally accepted in Automatica\n",
    "authors": [
      "Zheming Wang",
      "Rapha\u00ebl M. Jungers",
      "Chong-Jin Ong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.00974"
  },
  {
    "id": "arXiv:2010.10504",
    "title": "Pushing the Limits of Semi-Supervised Learning for Automatic Speech  Recognition",
    "abstract": "Comments: 11 pages, 3 figures, 5 tables. Accepted to NeurIPS SAS 2020 Workshop; v2: minor errors corrected",
    "descriptor": "\nComments: 11 pages, 3 figures, 5 tables. Accepted to NeurIPS SAS 2020 Workshop; v2: minor errors corrected\n",
    "authors": [
      "Yu Zhang",
      "James Qin",
      "Daniel S. Park",
      "Wei Han",
      "Chung-Cheng Chiu",
      "Ruoming Pang",
      "Quoc V. Le",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2010.10504"
  },
  {
    "id": "arXiv:2011.08894",
    "title": "Contrastive Registration for Unsupervised Medical Image Segmentation",
    "abstract": "Comments: 12 pages, 8 figures, 4 tables",
    "descriptor": "\nComments: 12 pages, 8 figures, 4 tables\n",
    "authors": [
      "Lihao Liu",
      "Angelica I Aviles-Rivero",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.08894"
  },
  {
    "id": "arXiv:2012.01496",
    "title": "Flow-driven spectral chaos (FSC) method for simulating long-time  dynamics of arbitrary-order non-linear stochastic dynamical systems",
    "abstract": "Comments: Preprint submitted to Journal of Computational Physics (Elsevier). This is an updated version of the journal article (for more information, see the Errata sheet included at the end of the document)",
    "descriptor": "\nComments: Preprint submitted to Journal of Computational Physics (Elsevier). This is an updated version of the journal article (for more information, see the Errata sheet included at the end of the document)\n",
    "authors": [
      "Hugo Esquivel",
      "Arun Prakash",
      "Guang Lin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.01496"
  },
  {
    "id": "arXiv:2101.05940",
    "title": "Implicit Surface Reconstruction with a Curl-free Radial Basis Function  Partition of Unity Method",
    "abstract": "Implicit Surface Reconstruction with a Curl-free Radial Basis Function  Partition of Unity Method",
    "descriptor": "",
    "authors": [
      "Kathryn P. Drake",
      "Edward J. Fuselier",
      "Grady B. Wright"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.05940"
  },
  {
    "id": "arXiv:2101.08238",
    "title": "AXM-Net: Implicit Cross-Modal Feature Alignment for Person  Re-identification",
    "abstract": "Comments: AAAI-2022 (Oral Paper)",
    "descriptor": "\nComments: AAAI-2022 (Oral Paper)\n",
    "authors": [
      "Ammarah Farooq",
      "Muhammad Awais",
      "Josef Kittler",
      "Syed Safwan Khalid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.08238"
  },
  {
    "id": "arXiv:2101.09818",
    "title": "Encrypted Internet traffic classification using a supervised Spiking  Neural Network",
    "abstract": "Comments: 22 pages, 8 figures. Neurocomputing (2022)",
    "descriptor": "\nComments: 22 pages, 8 figures. Neurocomputing (2022)\n",
    "authors": [
      "Ali Rasteh",
      "Florian Delpech",
      "Carlos Aguilar-Melchor",
      "Romain Zimmer",
      "Saeed Bagheri Shouraki",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.09818"
  },
  {
    "id": "arXiv:2102.07454",
    "title": "Tight Revenue Gaps among Multi-Unit Mechanisms",
    "abstract": "Tight Revenue Gaps among Multi-Unit Mechanisms",
    "descriptor": "",
    "authors": [
      "Yaonan Jin",
      "Shunhua Jiang",
      "Pinyan Lu",
      "Hengjie Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2102.07454"
  },
  {
    "id": "arXiv:2102.09237",
    "title": "Strongly Connected Topology Model and Confirmation-based Propagation  Method for Cross-chain Interaction",
    "abstract": "Strongly Connected Topology Model and Confirmation-based Propagation  Method for Cross-chain Interaction",
    "descriptor": "",
    "authors": [
      "Hong Su"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.09237"
  },
  {
    "id": "arXiv:2103.01955",
    "title": "The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games",
    "abstract": "The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games",
    "descriptor": "",
    "authors": [
      "Chao Yu",
      "Akash Velu",
      "Eugene Vinitsky",
      "Yu Wang",
      "Alexandre Bayen",
      "Yi Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2103.01955"
  },
  {
    "id": "arXiv:2104.10412",
    "title": "Comprehensive Multi-Modal Interactions for Referring Image Segmentation",
    "abstract": "Comments: Findings of ACL 2022",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Kanishk Jain",
      "Vineet Gandhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10412"
  },
  {
    "id": "arXiv:2104.12081",
    "title": "How Well Does Self-Supervised Pre-Training Perform with Streaming Data?",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Dapeng Hu",
      "Shipeng Yan",
      "Qizhengqiu Lu",
      "Lanqing Hong",
      "Hailin Hu",
      "Yifan Zhang",
      "Zhenguo Li",
      "Xinchao Wang",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.12081"
  },
  {
    "id": "arXiv:2105.04733",
    "title": "Fast and Simple One-Way High-Dimensional Quantum Key Distribution",
    "abstract": "Fast and Simple One-Way High-Dimensional Quantum Key Distribution",
    "descriptor": "",
    "authors": [
      "Kfir Sulimany",
      "Rom Dudkiewicz",
      "Simcha Korenblit",
      "Hagai S. Eisenberg",
      "Yaron Bromberg",
      "Michael Ben-Or"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2105.04733"
  },
  {
    "id": "arXiv:2105.08237",
    "title": "Towards Unsupervised Sketch-based Image Retrieval",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Conghui Hu",
      "Yongxin Yang",
      "Yunpeng Li",
      "Timothy M. Hospedales",
      "Yi-Zhe Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.08237"
  },
  {
    "id": "arXiv:2105.09401",
    "title": "Contrastive Learning with Complex Heterogeneity",
    "abstract": "Comments: Accepted by KDD22",
    "descriptor": "\nComments: Accepted by KDD22\n",
    "authors": [
      "Lecheng Zheng",
      "Jinjun Xiong",
      "Yada Zhu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.09401"
  },
  {
    "id": "arXiv:2105.10544",
    "title": "Flow-driven spectral chaos (FSC) method for long-time integration of  second-order stochastic dynamical systems",
    "abstract": "Comments: Preprint submitted to Journal of Computational and Applied Mathematics (Elsevier). arXiv admin note: text overlap with arXiv:2012.01496",
    "descriptor": "\nComments: Preprint submitted to Journal of Computational and Applied Mathematics (Elsevier). arXiv admin note: text overlap with arXiv:2012.01496\n",
    "authors": [
      "Hugo Esquivel",
      "Arun Prakash",
      "Guang Lin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.10544"
  },
  {
    "id": "arXiv:2105.12019",
    "title": "On learning parametric distributions from quantized samples",
    "abstract": "Comments: Short version accepted for publication at the IEEE Information Theory Symposium (ISIT) 2021; this version contains the detailed proofs with some minor corrections",
    "descriptor": "\nComments: Short version accepted for publication at the IEEE Information Theory Symposium (ISIT) 2021; this version contains the detailed proofs with some minor corrections\n",
    "authors": [
      "Septimia Sarbu",
      "Abdellatif Zaidi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.12019"
  },
  {
    "id": "arXiv:2105.14230",
    "title": "Transforming the Latent Space of StyleGAN for Real Face Editing",
    "abstract": "Comments: 28 pages, 15 figures",
    "descriptor": "\nComments: 28 pages, 15 figures\n",
    "authors": [
      "Heyi Li",
      "Jinlong Liu",
      "Xinyu Zhang",
      "Yunzhi Bai",
      "Huayan Wang",
      "Klaus Mueller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14230"
  },
  {
    "id": "arXiv:2107.02572",
    "title": "Unsupervised Knowledge-Transfer for Learned Image Reconstruction",
    "abstract": "Unsupervised Knowledge-Transfer for Learned Image Reconstruction",
    "descriptor": "",
    "authors": [
      "Riccardo Barbano",
      "Zeljko Kereta",
      "Andreas Hauptmann",
      "Simon R. Arridge",
      "Bangti Jin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02572"
  },
  {
    "id": "arXiv:2107.11020",
    "title": "Emotion analysis and detection during COVID-19",
    "abstract": "Comments: LREC 2022",
    "descriptor": "\nComments: LREC 2022\n",
    "authors": [
      "Tiberiu Sosea",
      "Chau Pham",
      "Alexander Tekle",
      "Cornelia Caragea",
      "Junyi Jessy Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.11020"
  },
  {
    "id": "arXiv:2107.12549",
    "title": "DISP6D: Disentangled Implicit Shape and Pose Learning for Scalable 6D  Pose Estimation",
    "abstract": "Comments: Accepted by European Conference on Computer Vision, 2022; Project page: this https URL",
    "descriptor": "\nComments: Accepted by European Conference on Computer Vision, 2022; Project page: this https URL\n",
    "authors": [
      "Yilin Wen",
      "Xiangyu Li",
      "Hao Pan",
      "Lei Yang",
      "Zheng Wang",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.12549"
  },
  {
    "id": "arXiv:2108.01199",
    "title": "Neural Image Representations for Multi-Image Fusion and Layer Separation",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Seonghyeon Nam",
      "Marcus A. Brubaker",
      "Michael S. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01199"
  },
  {
    "id": "arXiv:2108.05479",
    "title": "Automatic Gaze Analysis: A Survey of Deep Learning based Approaches",
    "abstract": "Automatic Gaze Analysis: A Survey of Deep Learning based Approaches",
    "descriptor": "",
    "authors": [
      "Shreya Ghosh",
      "Abhinav Dhall",
      "Munawar Hayat",
      "Jarrod Knibbe",
      "Qiang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.05479"
  },
  {
    "id": "arXiv:2108.13650",
    "title": "Heterogeneous Graph Neural Network with Multi-view Representation  Learning",
    "abstract": "Comments: Submitted to TKDE",
    "descriptor": "\nComments: Submitted to TKDE\n",
    "authors": [
      "Zezhi Shao",
      "Yongjun Xu",
      "Wei Wei",
      "Fei Wang",
      "Zhao Zhang",
      "Feida Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13650"
  },
  {
    "id": "arXiv:2109.02606",
    "title": "Gaussian Process Uniform Error Bounds with Unknown Hyperparameters for  Safety-Critical Applications",
    "abstract": "Gaussian Process Uniform Error Bounds with Unknown Hyperparameters for  Safety-Critical Applications",
    "descriptor": "",
    "authors": [
      "Alexandre Capone",
      "Armin Lederer",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.02606"
  },
  {
    "id": "arXiv:2109.03159",
    "title": "Analysis of Regularized Learning for Generalized Data in Banach Spaces",
    "abstract": "Comments: 36 pages, 1 figure",
    "descriptor": "\nComments: 36 pages, 1 figure\n",
    "authors": [
      "Qi Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.03159"
  },
  {
    "id": "arXiv:2109.06126",
    "title": "Neural Network Guided Evolutionary Fuzzing for Finding Traffic  Violations of Autonomous Vehicles",
    "abstract": "Neural Network Guided Evolutionary Fuzzing for Finding Traffic  Violations of Autonomous Vehicles",
    "descriptor": "",
    "authors": [
      "Ziyuan Zhong",
      "Gail Kaiser",
      "Baishakhi Ray"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06126"
  },
  {
    "id": "arXiv:2109.06662",
    "title": "Identifying partial mouse brain microscopy images from Allen reference  atlas using a contrastively learned semantic space",
    "abstract": "Comments: Published in the Proceedings of International Workshop on Biomedical Image Registration (WBIR-2022). Source code available at this https URL 12 pages, 6 figures",
    "descriptor": "\nComments: Published in the Proceedings of International Workshop on Biomedical Image Registration (WBIR-2022). Source code available at this https URL 12 pages, 6 figures\n",
    "authors": [
      "Justinas Antanavicius",
      "Roberto Leiras",
      "Raghavendra Selvan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06662"
  },
  {
    "id": "arXiv:2109.07775",
    "title": "Fast-Replanning Motion Control for Non-Holonomic Vehicles with Aborting  A*",
    "abstract": "Comments: Accepted to IROS 22",
    "descriptor": "\nComments: Accepted to IROS 22\n",
    "authors": [
      "Marcell Missura",
      "Arindam Roychoudhury",
      "Maren Bennewitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07775"
  },
  {
    "id": "arXiv:2109.11936",
    "title": "Towards Autonomous Visual Navigation in Arable Fields",
    "abstract": "Towards Autonomous Visual Navigation in Arable Fields",
    "descriptor": "",
    "authors": [
      "Alireza Ahmadi",
      "Michael Halstead",
      "Chris McCool"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.11936"
  },
  {
    "id": "arXiv:2110.00058",
    "title": "Rectangular Spiral Galaxies are Still Hard",
    "abstract": "Comments: 24 pages, 24 figures. Thorough revision including new Section 2 proof which handles the promise problem",
    "descriptor": "\nComments: 24 pages, 24 figures. Thorough revision including new Section 2 proof which handles the promise problem\n",
    "authors": [
      "Erik D. Demaine",
      "Maarten L\u00f6ffler",
      "Christiane Schmidt"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2110.00058"
  },
  {
    "id": "arXiv:2110.03040",
    "title": "Approximate Quantiles for Stochastic Optimal Control of LTI Systems with  Arbitrary Disturbances",
    "abstract": "Comments: Accepted to American Control Conference (ACC) 2022. Final submission",
    "descriptor": "\nComments: Accepted to American Control Conference (ACC) 2022. Final submission\n",
    "authors": [
      "Shawn Priore",
      "Christopher Petersen",
      "Meeko Oishi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.03040"
  },
  {
    "id": "arXiv:2110.06342",
    "title": "Decentralized Connectivity Maintenance for Multi-robot Systems Under  Motion and Sensing Uncertainties",
    "abstract": "Comments: Accepted in NAVIGATION: Journal of The Institute of Navigation",
    "descriptor": "\nComments: Accepted in NAVIGATION: Journal of The Institute of Navigation\n",
    "authors": [
      "Akshay Shetty",
      "Timmy Hussain",
      "Grace Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.06342"
  },
  {
    "id": "arXiv:2110.08323",
    "title": "On Learning the Transformer Kernel",
    "abstract": "Comments: Accepted to TMLR",
    "descriptor": "\nComments: Accepted to TMLR\n",
    "authors": [
      "Sankalan Pal Chowdhury",
      "Adamos Solomou",
      "Avinava Dubey",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08323"
  },
  {
    "id": "arXiv:2110.08708",
    "title": "Robust Pedestrian Attribute Recognition Using Group Sparsity for  Occlusion Videos",
    "abstract": "Comments: 9 pages, 4 figures",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Geonu Lee",
      "Kimin Yun",
      "Jungchan Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08708"
  },
  {
    "id": "arXiv:2110.10199",
    "title": "Theoretical Advances in Current Estimation and Navigation from a  Glider-Based Acoustic Doppler Current Profiler (ADCP)",
    "abstract": "Comments: Submitted to Journal of Atmospheric and Oceanic Technology. 15 pages main text. 10 pages figures, tables, bibliography, appendices",
    "descriptor": "\nComments: Submitted to Journal of Atmospheric and Oceanic Technology. 15 pages main text. 10 pages figures, tables, bibliography, appendices\n",
    "authors": [
      "Jacob Stevens-Haas",
      "Sarah E. Webster",
      "Aleksandr Aravkin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.10199"
  },
  {
    "id": "arXiv:2110.10326",
    "title": "Disentanglement of Emotional Style and Speaker Identity for Expressive  Voice Conversion",
    "abstract": "Comments: Accepted by Interspeech 2022",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Zongyang Du",
      "Berrak Sisman",
      "Kun Zhou",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.10326"
  },
  {
    "id": "arXiv:2110.12379",
    "title": "Variational quantum algorithm for Gaussian discrete solitons and their  boson sampling",
    "abstract": "Comments: Minor changes. 21 figures and 20 pages",
    "descriptor": "\nComments: Minor changes. 21 figures and 20 pages\n",
    "authors": [
      "Claudio Conti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.12379"
  },
  {
    "id": "arXiv:2110.14284",
    "title": "APPTeK: Agent-Based Predicate Prediction in Temporal Knowledge Graphs",
    "abstract": "APPTeK: Agent-Based Predicate Prediction in Temporal Knowledge Graphs",
    "descriptor": "",
    "authors": [
      "Christian M.M. Frey",
      "Yunpu Ma",
      "Matthias Schubert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14284"
  },
  {
    "id": "arXiv:2110.14755",
    "title": "Algorithmic encoding of protected characteristics in image-based models  for disease detection",
    "abstract": "Comments: Code available on this https URL",
    "descriptor": "\nComments: Code available on this https URL\n",
    "authors": [
      "Ben Glocker",
      "Charles Jones",
      "Melanie Bernhardt",
      "Stefan Winzeck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14755"
  },
  {
    "id": "arXiv:2111.03463",
    "title": "RADAMS: Resilient and Adaptive Alert and Attention Management Strategy  against Informational Denial-of-Service (IDoS) Attacks",
    "abstract": "RADAMS: Resilient and Adaptive Alert and Attention Management Strategy  against Informational Denial-of-Service (IDoS) Attacks",
    "descriptor": "",
    "authors": [
      "Linan Huang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.03463"
  },
  {
    "id": "arXiv:2111.05610",
    "title": "CLIP2TV: Align, Match and Distill for Video-Text Retrieval",
    "abstract": "CLIP2TV: Align, Match and Distill for Video-Text Retrieval",
    "descriptor": "",
    "authors": [
      "Zijian Gao",
      "Jingyu Liu",
      "Weiqi Sun",
      "Sheng Chen",
      "Dedan Chang",
      "Lili Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.05610"
  },
  {
    "id": "arXiv:2111.07640",
    "title": "AnimeCeleb: Large-Scale Animation CelebHeads Dataset for Head  Reenactment",
    "abstract": "Comments: 40 pages; Accepted to ECCV 2022; code and dataset URL added",
    "descriptor": "\nComments: 40 pages; Accepted to ECCV 2022; code and dataset URL added\n",
    "authors": [
      "Kangyeol Kim",
      "Sunghyun Park",
      "Jaeseong Lee",
      "Sunghyo Chung",
      "Junsoo Lee",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.07640"
  },
  {
    "id": "arXiv:2111.12747",
    "title": "Layered Controllable Video Generation",
    "abstract": "Comments: This paper has been accepted to ECCV 2022 as an Oral paper",
    "descriptor": "\nComments: This paper has been accepted to ECCV 2022 as an Oral paper\n",
    "authors": [
      "Jiahui Huang",
      "Yuhe Jin",
      "Kwang Moo Yi",
      "Leonid Sigal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12747"
  },
  {
    "id": "arXiv:2111.13362",
    "title": "Data Invariants to Understand Unsupervised Out-of-Distribution Detection",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Lars Doorenbos",
      "Raphael Sznitman",
      "Pablo M\u00e1rquez-Neila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13362"
  },
  {
    "id": "arXiv:2111.14824",
    "title": "Learning to Fit Morphable Models",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Vasileios Choutas",
      "Federica Bogo",
      "Jingjing Shen",
      "Julien Valentin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14824"
  },
  {
    "id": "arXiv:2111.15264",
    "title": "EdiBERT, a generative model for image editing",
    "abstract": "EdiBERT, a generative model for image editing",
    "descriptor": "",
    "authors": [
      "Thibaut Issenhuth",
      "Ugo Tanielian",
      "J\u00e9r\u00e9mie Mary",
      "David Picard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15264"
  },
  {
    "id": "arXiv:2111.15664",
    "title": "OCR-free Document Understanding Transformer",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Geewook Kim",
      "Teakgyu Hong",
      "Moonbin Yim",
      "Jeongyeon Nam",
      "Jinyoung Park",
      "Jinyeong Yim",
      "Wonseok Hwang",
      "Sangdoo Yun",
      "Dongyoon Han",
      "Seunghyun Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15664"
  },
  {
    "id": "arXiv:2112.00649",
    "title": "Digital Twinning Remote Laboratories for Online Practical Learning",
    "abstract": "Comments: 56 pages, 14 figures. arXiv admin note: text overlap with arXiv:2106.09344. Added version accepted for publication",
    "descriptor": "\nComments: 56 pages, 14 figures. arXiv admin note: text overlap with arXiv:2106.09344. Added version accepted for publication\n",
    "authors": [
      "Claire Palmer",
      "Ben Roullier",
      "Muhammad Aamir",
      "Frank McQuade",
      "Leonardo Stella",
      "Ashiq Anjum"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00649"
  },
  {
    "id": "arXiv:2112.00826",
    "title": "Inducing Causal Structure for Interpretable Neural Networks",
    "abstract": "Inducing Causal Structure for Interpretable Neural Networks",
    "descriptor": "",
    "authors": [
      "Atticus Geiger",
      "Zhengxuan Wu",
      "Hanson Lu",
      "Josh Rozner",
      "Elisa Kreiss",
      "Thomas Icard",
      "Noah D. Goodman",
      "Christopher Potts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00826"
  },
  {
    "id": "arXiv:2112.01759",
    "title": "NeRF-SR: High-Quality Neural Radiance Fields using Supersampling",
    "abstract": "Comments: Accepted to MM 2022. Project Page: this https URL",
    "descriptor": "\nComments: Accepted to MM 2022. Project Page: this https URL\n",
    "authors": [
      "Chen Wang",
      "Xian Wu",
      "Yuan-Chen Guo",
      "Song-Hai Zhang",
      "Yu-Wing Tai",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.01759"
  },
  {
    "id": "arXiv:2112.02274",
    "title": "Self-supervised Graph Learning for Occasional Group Recommendation",
    "abstract": "Comments: This paper uses self-supervised learning technique to enhance the embeddings of users/groups/items, the idea is novel in group recommendation scenario. However, some presentations need to be revised, so as to let the readers understand",
    "descriptor": "\nComments: This paper uses self-supervised learning technique to enhance the embeddings of users/groups/items, the idea is novel in group recommendation scenario. However, some presentations need to be revised, so as to let the readers understand\n",
    "authors": [
      "Bowen Hao",
      "Hongzhi Yin",
      "Cuiping Li",
      "Hong Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.02274"
  },
  {
    "id": "arXiv:2112.03184",
    "title": "HIVE: Evaluating the Human Interpretability of Visual Explanations",
    "abstract": "Comments: ECCV 2022. Code and supplementary material are at this https URL",
    "descriptor": "\nComments: ECCV 2022. Code and supplementary material are at this https URL\n",
    "authors": [
      "Sunnie S. Y. Kim",
      "Nicole Meister",
      "Vikram V. Ramaswamy",
      "Ruth Fong",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03184"
  },
  {
    "id": "arXiv:2112.03478",
    "title": "Generative Adversarial Networks for Labeled Acceleration Data  Augmentation for Structural Damage Detection",
    "abstract": "Generative Adversarial Networks for Labeled Acceleration Data  Augmentation for Structural Damage Detection",
    "descriptor": "",
    "authors": [
      "Furkan Luleci",
      "F. Necati Catbas",
      "Onur Avci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03478"
  },
  {
    "id": "arXiv:2112.04487",
    "title": "Joint Global and Local Hierarchical Priors for Learned Image Compression",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jun-Hyuk Kim",
      "Byeongho Heo",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04487"
  },
  {
    "id": "arXiv:2112.05082",
    "title": "Fast Electromagnetic Validations of Large-Scale Digital Coding  Metasurfaces Accelerated by Recurrence Rebuild and Retrieval Method",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Yu Zhao",
      "Shang Xiang",
      "Long Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2112.05082"
  },
  {
    "id": "arXiv:2112.05140",
    "title": "NeRF for Outdoor Scene Relighting",
    "abstract": "Comments: 22 pages, 10 figures, 2 tables; ECCV 2022; project web page: this https URL",
    "descriptor": "\nComments: 22 pages, 10 figures, 2 tables; ECCV 2022; project web page: this https URL\n",
    "authors": [
      "Viktor Rudnev",
      "Mohamed Elgharib",
      "William Smith",
      "Lingjie Liu",
      "Vladislav Golyanik",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.05140"
  },
  {
    "id": "arXiv:2112.06569",
    "title": "Triangle Attack: A Query-efficient Decision-based Adversarial Attack",
    "abstract": "Comments: Accepted by ECCV 2022, code is available at this https URL",
    "descriptor": "\nComments: Accepted by ECCV 2022, code is available at this https URL\n",
    "authors": [
      "Xiaosen Wang",
      "Zeliang Zhang",
      "Kangheng Tong",
      "Dihong Gong",
      "Kun He",
      "Zhifeng Li",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06569"
  },
  {
    "id": "arXiv:2112.08275",
    "title": "SeqFormer: Sequential Transformer for Video Instance Segmentation",
    "abstract": "Comments: ECCV 2022, Oral",
    "descriptor": "\nComments: ECCV 2022, Oral\n",
    "authors": [
      "Junfeng Wu",
      "Yi Jiang",
      "Song Bai",
      "Wenqing Zhang",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08275"
  },
  {
    "id": "arXiv:2112.08684",
    "title": "Mimic Embedding via Adaptive Aggregation: Learning Generalizable Person  Re-identification",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Boqiang Xu",
      "Jian Liang",
      "Lingxiao He",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08684"
  },
  {
    "id": "arXiv:2112.08775",
    "title": "DProST: Dynamic Projective Spatial Transformer Network for 6D Pose  Estimation",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Jaewoo Park",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08775"
  },
  {
    "id": "arXiv:2112.08879",
    "title": "Bottom Up Top Down Detection Transformers for Language Grounding in  Images and Point Clouds",
    "abstract": "Comments: First two authors contributed equally | ECCV 2022 Camera Ready",
    "descriptor": "\nComments: First two authors contributed equally | ECCV 2022 Camera Ready\n",
    "authors": [
      "Ayush Jain",
      "Nikolaos Gkanatsios",
      "Ishita Mediratta",
      "Katerina Fragkiadaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08879"
  },
  {
    "id": "arXiv:2112.09217",
    "title": "High-Dimensional Inference in Bayesian Networks",
    "abstract": "High-Dimensional Inference in Bayesian Networks",
    "descriptor": "",
    "authors": [
      "Fritz M. Bayer",
      "Giusi Moffa",
      "Niko Beerenwinkel",
      "Jack Kuipers"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09217"
  },
  {
    "id": "arXiv:2112.10762",
    "title": "StyleSwin: Transformer-based GAN for High-resolution Image Generation",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Bowen Zhang",
      "Shuyang Gu",
      "Bo Zhang",
      "Jianmin Bao",
      "Dong Chen",
      "Fang Wen",
      "Yong Wang",
      "Baining Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.10762"
  },
  {
    "id": "arXiv:2112.12143",
    "title": "Scaling Open-Vocabulary Image Segmentation with Image-Level Labels",
    "abstract": "Comments: Accepted at ECCV 2022",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Golnaz Ghiasi",
      "Xiuye Gu",
      "Yin Cui",
      "Tsung-Yi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12143"
  },
  {
    "id": "arXiv:2112.13715",
    "title": "SmoothNet: A Plug-and-Play Network for Refining Human Poses in Videos",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Ailing Zeng",
      "Lei Yang",
      "Xuan Ju",
      "Jiefeng Li",
      "Jianyi Wang",
      "Qiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.13715"
  },
  {
    "id": "arXiv:2112.14303",
    "title": "A proof system for graph (non)-isomorphism verification",
    "abstract": "Comments: 36 pages, 11 figures, 3 tables",
    "descriptor": "\nComments: 36 pages, 11 figures, 3 tables\n",
    "authors": [
      "Milan Bankovi\u0107",
      "Ivan Drecun",
      "Filip Mari\u0107"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.14303"
  },
  {
    "id": "arXiv:2201.00689",
    "title": "CausalMTA: Eliminating the User Confounding Bias for Causal Multi-touch  Attribution",
    "abstract": "Comments: 11 pages, 5 figures This paper has been accepted in KDD 2022",
    "descriptor": "\nComments: 11 pages, 5 figures This paper has been accepted in KDD 2022\n",
    "authors": [
      "Di Yao",
      "Chang Gong",
      "Lei Zhang",
      "Sheng Chen",
      "Jingping Bi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.00689"
  },
  {
    "id": "arXiv:2201.02006",
    "title": "A comparison of different methods of identifying publications related to  the United Nations Sustainable Development Goals: Case Study of SDG 13:  Climate Action",
    "abstract": "A comparison of different methods of identifying publications related to  the United Nations Sustainable Development Goals: Case Study of SDG 13:  Climate Action",
    "descriptor": "",
    "authors": [
      "Philip James Purnell"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2201.02006"
  },
  {
    "id": "arXiv:2201.03639",
    "title": "Multi-Query Video Retrieval",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Zeyu Wang",
      "Yu Wu",
      "Karthik Narasimhan",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.03639"
  },
  {
    "id": "arXiv:2201.04343",
    "title": "An Efficient and Adaptive Granular-ball Generation Method in  Classification Problem",
    "abstract": "An Efficient and Adaptive Granular-ball Generation Method in  Classification Problem",
    "descriptor": "",
    "authors": [
      "Shuyin Xia",
      "Xiaochuan Dai",
      "Guoyin Wang",
      "Xinbo Gao",
      "Elisabeth Giem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04343"
  },
  {
    "id": "arXiv:2201.10355",
    "title": "Neural Architecture Search for Spiking Neural Networks",
    "abstract": "Comments: Accepted to European Conference on Computer Vision (ECCV) 2022",
    "descriptor": "\nComments: Accepted to European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Youngeun Kim",
      "Yuhang Li",
      "Hyoungseob Park",
      "Yeshwanth Venkatesha",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.10355"
  },
  {
    "id": "arXiv:2201.10392",
    "title": "Human-Robot Collaborative Carrying of Objects with Unknown Deformation  Characteristics",
    "abstract": "Comments: 7 pages, 7 figures, accepted at IEEE International Conference on Intelligent Robots and Systems (IROS 2022), for associated video, see this https URL",
    "descriptor": "\nComments: 7 pages, 7 figures, accepted at IEEE International Conference on Intelligent Robots and Systems (IROS 2022), for associated video, see this https URL\n",
    "authors": [
      "Doganay Sirintuna",
      "Alberto Giammarino",
      "Arash Ajoudani"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.10392"
  },
  {
    "id": "arXiv:2201.12765",
    "title": "Improving Robustness by Enhancing Weak Subnets",
    "abstract": "Comments: To appear in ECCV 2022",
    "descriptor": "\nComments: To appear in ECCV 2022\n",
    "authors": [
      "Yong Guo",
      "David Stutz",
      "Bernt Schiele"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12765"
  },
  {
    "id": "arXiv:2202.00553",
    "title": "Neural Tangent Kernel Beyond the Infinite-Width Limit: Effects of Depth  and Initialization",
    "abstract": "Neural Tangent Kernel Beyond the Infinite-Width Limit: Effects of Depth  and Initialization",
    "descriptor": "",
    "authors": [
      "Mariia Seleznova",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00553"
  },
  {
    "id": "arXiv:2202.02317",
    "title": "Webly Supervised Concept Expansion for General Purpose Vision Models",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Amita Kamath",
      "Christopher Clark",
      "Tanmay Gupta",
      "Eric Kolve",
      "Derek Hoiem",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02317"
  },
  {
    "id": "arXiv:2202.03390",
    "title": "Geometric Multimodal Contrastive Representation Learning",
    "abstract": "Comments: ICML 2022 Camera ready version",
    "descriptor": "\nComments: ICML 2022 Camera ready version\n",
    "authors": [
      "Petra Poklukar",
      "Miguel Vasco",
      "Hang Yin",
      "Francisco S. Melo",
      "Ana Paiva",
      "Danica Kragic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03390"
  },
  {
    "id": "arXiv:2202.03469",
    "title": "Locally Random P-adic Alloy Codes with Channel Coding Theorems for  Distributed Coded Tensors",
    "abstract": "Comments: 9 pages, preprint",
    "descriptor": "\nComments: 9 pages, preprint\n",
    "authors": [
      "Pedro Soto",
      "Haibin Guan",
      "Jun Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03469"
  },
  {
    "id": "arXiv:2202.03874",
    "title": "Combining Intra-Risk and Contagion Risk for Enterprise Bankruptcy  Prediction Using Graph Neural Networks",
    "abstract": "Comments: 12 pages, 8 figures",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Yu Zhao",
      "Shaopeng Wei",
      "Yu Guo",
      "Qing Yang",
      "Xingyan Chen",
      "Qing Li",
      "Fuzhen Zhuang",
      "Ji Liu",
      "Gang Kou"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03874"
  },
  {
    "id": "arXiv:2202.06255",
    "title": "Strategy Synthesis for Zero-sum Neuro-symbolic Concurrent Stochastic  Games (Extended Version)",
    "abstract": "Comments: 31 pages, 4 figures",
    "descriptor": "\nComments: 31 pages, 4 figures\n",
    "authors": [
      "Rui Yan",
      "Gabriel Santos",
      "Gethin Norman",
      "David Parker",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.06255"
  },
  {
    "id": "arXiv:2202.08578",
    "title": "An Equivalence Between Data Poisoning and Byzantine Gradient Attacks",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2106.02398",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.02398\n",
    "authors": [
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "L\u00ea-Nguy\u00ean Hoang",
      "Oscar Villemaud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08578"
  },
  {
    "id": "arXiv:2202.08771",
    "title": "Realistic Blur Synthesis for Learning Image Deblurring",
    "abstract": "Comments: ECCV 2022,Project page: this http URL",
    "descriptor": "\nComments: ECCV 2022,Project page: this http URL\n",
    "authors": [
      "Jaesung Rim",
      "Geonung Kim",
      "Jungeon Kim",
      "Junyong Lee",
      "Seungyong Lee",
      "Sunghyun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08771"
  },
  {
    "id": "arXiv:2202.12316",
    "title": "AutoIP: A United Framework to Integrate Physics into Gaussian Processes",
    "abstract": "AutoIP: A United Framework to Integrate Physics into Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Da Long",
      "Zheng Wang",
      "Aditi Krishnapriyan",
      "Robert Kirby",
      "Shandian Zhe",
      "Michael Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12316"
  },
  {
    "id": "arXiv:2203.00798",
    "title": "TANDEM: Learning Joint Exploration and Decision Making with Tactile  Sensors",
    "abstract": "Comments: Accepted to Robotics and Automation Letters (RA-L) and International Conference on Intelligent Robots and Systems (IROS) 2022",
    "descriptor": "\nComments: Accepted to Robotics and Automation Letters (RA-L) and International Conference on Intelligent Robots and Systems (IROS) 2022\n",
    "authors": [
      "Jingxi Xu",
      "Shuran Song",
      "Matei Ciocarlie"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.00798"
  },
  {
    "id": "arXiv:2203.01171",
    "title": "Imitation of Manipulation Skills Using Multiple Geometries",
    "abstract": "Imitation of Manipulation Skills Using Multiple Geometries",
    "descriptor": "",
    "authors": [
      "Boyang Ti",
      "Yongsheng Gao",
      "Jie Zhao",
      "Sylvain Calinon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.01171"
  },
  {
    "id": "arXiv:2203.02113",
    "title": "FS-COCO: Towards Understanding of Freehand Sketches of Common Objects in  Context",
    "abstract": "Comments: Accepted in ECCV 2022. Project Page: this https URL",
    "descriptor": "\nComments: Accepted in ECCV 2022. Project Page: this https URL\n",
    "authors": [
      "Pinaki Nath Chowdhury",
      "Aneeshan Sain",
      "Ayan Kumar Bhunia",
      "Tao Xiang",
      "Yulia Gryaditskaya",
      "Yi-Zhe Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02113"
  },
  {
    "id": "arXiv:2203.03871",
    "title": "Discriminability-Transferability Trade-Off: An Information-Theoretic  Perspective",
    "abstract": "Comments: Accepted by ECCV 2022, Quan Cui and Bingchen Zhao contributed equally to this work",
    "descriptor": "\nComments: Accepted by ECCV 2022, Quan Cui and Bingchen Zhao contributed equally to this work\n",
    "authors": [
      "Quan Cui",
      "Bingchen Zhao",
      "Zhao-Min Chen",
      "Borui Zhao",
      "Renjie Song",
      "Jiajun Liang",
      "Boyan Zhou",
      "Osamu Yoshie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03871"
  },
  {
    "id": "arXiv:2203.03890",
    "title": "ClearPose: Large-scale Transparent Object Dataset and Benchmark",
    "abstract": "Comments: ECCV 2022 accepted paper",
    "descriptor": "\nComments: ECCV 2022 accepted paper\n",
    "authors": [
      "Xiaotong Chen",
      "Huijie Zhang",
      "Zeren Yu",
      "Anthony Opipari",
      "Odest Chadwicke Jenkins"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.03890"
  },
  {
    "id": "arXiv:2203.05683",
    "title": "Deep Multimodal Guidance for Medical Image Classification",
    "abstract": "Deep Multimodal Guidance for Medical Image Classification",
    "descriptor": "",
    "authors": [
      "Mayur Mallya",
      "Ghassan Hamarneh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05683"
  },
  {
    "id": "arXiv:2203.05684",
    "title": "PC-SwinMorph: Patch Representation for Unsupervised Medical Image  Registration and Segmentation",
    "abstract": "Comments: 10 pages, 7 figures, 2 tables",
    "descriptor": "\nComments: 10 pages, 7 figures, 2 tables\n",
    "authors": [
      "Lihao Liu",
      "Zhening Huang",
      "Pietro Li\u00f2",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Angelica I. Aviles-Rivero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05684"
  },
  {
    "id": "arXiv:2203.07694",
    "title": "Implicit field supervision for robust non-rigid shape matching",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Ramana Sundararaman",
      "Gautam Pai",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07694"
  },
  {
    "id": "arXiv:2203.08614",
    "title": "A Model of Job Parallelism for Latency Reduction in Large-Scale Systems",
    "abstract": "A Model of Job Parallelism for Latency Reduction in Large-Scale Systems",
    "descriptor": "",
    "authors": [
      "Ayalvadi Ganesh",
      "Arpan Mukhopadhyay"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.08614"
  },
  {
    "id": "arXiv:2203.08713",
    "title": "DeciWatch: A Simple Baseline for 10x Efficient 2D and 3D Pose Estimation",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Ailing Zeng",
      "Xuan Ju",
      "Lei Yang",
      "Ruiyuan Gao",
      "Xizhou Zhu",
      "Bo Dai",
      "Qiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08713"
  },
  {
    "id": "arXiv:2203.08914",
    "title": "Knee arthritis severity measurement using deep learning: a publicly  available algorithm with a multi-institutional validation showing  radiologist-level performance",
    "abstract": "Knee arthritis severity measurement using deep learning: a publicly  available algorithm with a multi-institutional validation showing  radiologist-level performance",
    "descriptor": "",
    "authors": [
      "Hanxue Gu",
      "Keyu Li",
      "Roy J. Colglazier",
      "Jichen Yang",
      "Michael Lebhar",
      "Jonathan O'Donnell",
      "William A. Jiranek",
      "Richard C. Mather",
      "Rob J. French",
      "Nicholas Said",
      "Jikai Zhang",
      "Christine Park",
      "Maciej A. Mazurowski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08914"
  },
  {
    "id": "arXiv:2203.09839",
    "title": "Time-Optimal Online Replanning for Agile Quadrotor Flight",
    "abstract": "Comments: 8 pages, 10 figures",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Angel Romero",
      "Robert Penicka",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09839"
  },
  {
    "id": "arXiv:2203.10157",
    "title": "ViewFormer: NeRF-free Neural Rendering from Few Images Using  Transformers",
    "abstract": "Comments: ECCV 2022 poster",
    "descriptor": "\nComments: ECCV 2022 poster\n",
    "authors": [
      "Jon\u00e1\u0161 Kulh\u00e1nek",
      "Erik Derner",
      "Torsten Sattler",
      "Robert Babu\u0161ka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10157"
  },
  {
    "id": "arXiv:2203.10821",
    "title": "Sem2NeRF: Converting Single-View Semantic Masks to Neural Radiance  Fields",
    "abstract": "Comments: ECCV2022, Code: this https URL Project Page: this https URL",
    "descriptor": "\nComments: ECCV2022, Code: this https URL Project Page: this https URL\n",
    "authors": [
      "Yuedong Chen",
      "Qianyi Wu",
      "Chuanxia Zheng",
      "Tat-Jen Cham",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.10821"
  },
  {
    "id": "arXiv:2203.11305",
    "title": "Generative Adversarial Network for Future Hand Segmentation from  Egocentric Video",
    "abstract": "Generative Adversarial Network for Future Hand Segmentation from  Egocentric Video",
    "descriptor": "",
    "authors": [
      "Wenqi Jia",
      "Miao Liu",
      "James M. Rehg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11305"
  },
  {
    "id": "arXiv:2203.11589",
    "title": "Adaptive Patch Exiting for Scalable Single Image Super-Resolution",
    "abstract": "Comments: ECCV 2022 Oral",
    "descriptor": "\nComments: ECCV 2022 Oral\n",
    "authors": [
      "Shizun Wang",
      "Jiaming Liu",
      "Kaixin Chen",
      "Xiaoqi Li",
      "Ming Lu",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11589"
  },
  {
    "id": "arXiv:2203.11726",
    "title": "AI-enabled Assessment of Cardiac Systolic and Diastolic Function from  Echocardiography",
    "abstract": "AI-enabled Assessment of Cardiac Systolic and Diastolic Function from  Echocardiography",
    "descriptor": "",
    "authors": [
      "Esther Puyol-Ant\u00f3n",
      "Bram Ruijsink",
      "Baldeep S. Sidhu",
      "Justin Gould",
      "Bradley Porter",
      "Mark K. Elliott",
      "Vishal Mehta",
      "Haotian Gu",
      "Miguel Xochicale",
      "Alberto Gomez",
      "Christopher A. Rinaldi",
      "Martin Cowie",
      "Phil Chowienczyk",
      "Reza Razavi",
      "Andrew P. King"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.11726"
  },
  {
    "id": "arXiv:2203.11819",
    "title": "A Broad Study of Pre-training for Domain Generalization and Adaptation",
    "abstract": "A Broad Study of Pre-training for Domain Generalization and Adaptation",
    "descriptor": "",
    "authors": [
      "Donghyun Kim",
      "Kaihong Wang",
      "Stan Sclaroff",
      "Kate Saenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11819"
  },
  {
    "id": "arXiv:2203.11834",
    "title": "Improving Generalization in Federated Learning by Seeking Flat Minima",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Debora Caldarola",
      "Barbara Caputo",
      "Marco Ciccone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11834"
  },
  {
    "id": "arXiv:2203.11947",
    "title": "CM-GAN: Image Inpainting with Cascaded Modulation GAN and Object-Aware  Training",
    "abstract": "Comments: 32 pages, 19 figures",
    "descriptor": "\nComments: 32 pages, 19 figures\n",
    "authors": [
      "Haitian Zheng",
      "Zhe Lin",
      "Jingwan Lu",
      "Scott Cohen",
      "Eli Shechtman",
      "Connelly Barnes",
      "Jianming Zhang",
      "Ning Xu",
      "Sohrab Amirghodsi",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11947"
  },
  {
    "id": "arXiv:2203.13104",
    "title": "R-DFCIL: Relation-Guided Representation Learning for Data-Free Class  Incremental Learning",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Qiankun Gao",
      "Chen Zhao",
      "Bernard Ghanem",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13104"
  },
  {
    "id": "arXiv:2203.13571",
    "title": "Adaptive Neural Network-based OFDM Receivers",
    "abstract": "Comments: Submitted to SPAWC 2022",
    "descriptor": "\nComments: Submitted to SPAWC 2022\n",
    "authors": [
      "Moritz Benedikt Fischer",
      "Sebastian D\u00f6rner",
      "Sebastian Cammerer",
      "Takayuki Shimizu",
      "Hongsheng Lu",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.13571"
  },
  {
    "id": "arXiv:2203.16194",
    "title": "FlowFormer: A Transformer Architecture for Optical Flow",
    "abstract": "Comments: Project Page: this https URL",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Zhaoyang Huang",
      "Xiaoyu Shi",
      "Chao Zhang",
      "Qiang Wang",
      "Ka Chun Cheung",
      "Hongwei Qin",
      "Jifeng Dai",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16194"
  },
  {
    "id": "arXiv:2204.00492",
    "title": "Provable concept learning for interpretable predictions using  variational autoencoders",
    "abstract": "Provable concept learning for interpretable predictions using  variational autoencoders",
    "descriptor": "",
    "authors": [
      "Armeen Taeb",
      "Nicolo Ruggeri",
      "Carina Schnuck",
      "Fanny Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.00492"
  },
  {
    "id": "arXiv:2204.01599",
    "title": "DODA: Data-oriented Sim-to-Real Domain Adaptation for 3D Semantic  Segmentation",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Runyu Ding",
      "Jihan Yang",
      "Li Jiang",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01599"
  },
  {
    "id": "arXiv:2204.01692",
    "title": "Long Movie Clip Classification with State-Space Video Models",
    "abstract": "Long Movie Clip Classification with State-Space Video Models",
    "descriptor": "",
    "authors": [
      "Md Mohaiminul Islam",
      "Gedas Bertasius"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.01692"
  },
  {
    "id": "arXiv:2204.01702",
    "title": "Personalized Prediction of Future Lesion Activity and Treatment Effect  in Multiple Sclerosis from Baseline MRI",
    "abstract": "Comments: Accepted to MIDL 2022",
    "descriptor": "\nComments: Accepted to MIDL 2022\n",
    "authors": [
      "Joshua Durso-Finley",
      "Jean-Pierre R. Falet",
      "Brennan Nichyporuk",
      "Douglas L. Arnold",
      "Tal Arbel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01702"
  },
  {
    "id": "arXiv:2204.02776",
    "title": "3D face reconstruction with dense landmarks",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Erroll Wood",
      "Tadas Baltrusaitis",
      "Charlie Hewitt",
      "Matthew Johnson",
      "Jingjing Shen",
      "Nikola Milosavljevic",
      "Daniel Wilde",
      "Stephan Garbin",
      "Chirag Raman",
      "Jamie Shotton",
      "Toby Sharp",
      "Ivan Stojiljkovic",
      "Tom Cashman",
      "Julien Valentin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02776"
  },
  {
    "id": "arXiv:2204.02874",
    "title": "ECLIPSE: Efficient Long-range Video Retrieval using Sight and Sound",
    "abstract": "Comments: ECCV 2022 Oral project page: this https URL",
    "descriptor": "\nComments: ECCV 2022 Oral project page: this https URL\n",
    "authors": [
      "Yan-Bo Lin",
      "Jie Lei",
      "Mohit Bansal",
      "Gedas Bertasius"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02874"
  },
  {
    "id": "arXiv:2204.03039",
    "title": "DSGN++: Exploiting Visual-Spatial Relation for Stereo-based 3D Detectors",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Yilun Chen",
      "Shijia Huang",
      "Shu Liu",
      "Bei Yu",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03039"
  },
  {
    "id": "arXiv:2204.03383",
    "title": "Overlay journals: a study of the current landscape",
    "abstract": "Overlay journals: a study of the current landscape",
    "descriptor": "",
    "authors": [
      "Antti Mikael Rousi",
      "Mikael Laakso"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2204.03383"
  },
  {
    "id": "arXiv:2204.04162",
    "title": "Stable Matching: Choosing Which Proposals to Make",
    "abstract": "Comments: 52 pages",
    "descriptor": "\nComments: 52 pages\n",
    "authors": [
      "Ishan Agarwal",
      "Richard Cole"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.04162"
  },
  {
    "id": "arXiv:2204.07049",
    "title": "Sim-to-Real 6D Object Pose Estimation via Iterative Self-training for  Robotic Bin Picking",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Kai Chen",
      "Rui Cao",
      "Stephen James",
      "Yichuan Li",
      "Yun-Hui Liu",
      "Pieter Abbeel",
      "Qi Dou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07049"
  },
  {
    "id": "arXiv:2204.07159",
    "title": "A Level Set Theory for Neural Implicit Evolution under Explicit Flows",
    "abstract": "Comments: ECCV 2022 (Oral); Project Page at this https URL",
    "descriptor": "\nComments: ECCV 2022 (Oral); Project Page at this https URL\n",
    "authors": [
      "Ishit Mehta",
      "Manmohan Chandraker",
      "Ravi Ramamoorthi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07159"
  },
  {
    "id": "arXiv:2204.07733",
    "title": "GitNet: Geometric Prior-based Transformation for Birds-Eye-View  Segmentation",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Shi Gong",
      "Xiaoqing Ye",
      "Xiao Tan",
      "Jingdong Wang",
      "Errui Ding",
      "Yu Zhou",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07733"
  },
  {
    "id": "arXiv:2204.09817",
    "title": "Making the Most of Text Semantics to Improve Biomedical Vision--Language  Processing",
    "abstract": "Comments: To appear in ECCV 2022. Code: this https URL Dataset: this https URL Demo Notebook: this https URL",
    "descriptor": "\nComments: To appear in ECCV 2022. Code: this https URL Dataset: this https URL Demo Notebook: this https URL\n",
    "authors": [
      "Benedikt Boecking",
      "Naoto Usuyama",
      "Shruthi Bannur",
      "Daniel C. Castro",
      "Anton Schwaighofer",
      "Stephanie Hyland",
      "Maria Wetscherek",
      "Tristan Naumann",
      "Aditya Nori",
      "Javier Alvarez-Valle",
      "Hoifung Poon",
      "Ozan Oktay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.09817"
  },
  {
    "id": "arXiv:2204.10740",
    "title": "Embracing AWKWARD! Real-time Adjustment of Reactive Plans Using Social  Norms",
    "abstract": "Comments: 18 pages, 2 figures, 3 Tables, 4 Formalisms, Accepted at COINE 2022 Workshop",
    "descriptor": "\nComments: 18 pages, 2 figures, 3 Tables, 4 Formalisms, Accepted at COINE 2022 Workshop\n",
    "authors": [
      "Leila Methnani",
      "Andreas Antoniades",
      "Andreas Theodorou"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.10740"
  },
  {
    "id": "arXiv:2204.11008",
    "title": "Long-term Spatio-temporal Forecasting via Dynamic Multiple-Graph  Attention",
    "abstract": "Comments: Accepted by the 31st International Joint Conference on Artificial Intelligence and the 25th European Conference on Artificial Intelligence (IJCAI-ECAI 2022)",
    "descriptor": "\nComments: Accepted by the 31st International Joint Conference on Artificial Intelligence and the 25th European Conference on Artificial Intelligence (IJCAI-ECAI 2022)\n",
    "authors": [
      "Wei Shao",
      "Zhiling Jin",
      "Shuo Wang",
      "Yufan Kang",
      "Xiao Xiao",
      "Hamid Menouar",
      "Zhaofeng Zhang",
      "Junshan Zhang",
      "Flora Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.11008"
  },
  {
    "id": "arXiv:2204.13749",
    "title": "Learning to Split for Automatic Bias Detection",
    "abstract": "Learning to Split for Automatic Bias Detection",
    "descriptor": "",
    "authors": [
      "Yujia Bao",
      "Regina Barzilay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.13749"
  },
  {
    "id": "arXiv:2204.13750",
    "title": "A First Runtime Analysis of the NSGA-II on a Multimodal Problem",
    "abstract": "A First Runtime Analysis of the NSGA-II on a Multimodal Problem",
    "descriptor": "",
    "authors": [
      "Zhongdi Qu",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.13750"
  },
  {
    "id": "arXiv:2204.14154",
    "title": "Outage Performance of Uplink Rate Splitting Multiple Access with  Randomly Deployed Users",
    "abstract": "Comments: 38 pages,9 figures",
    "descriptor": "\nComments: 38 pages,9 figures\n",
    "authors": [
      "Huabing Lu",
      "Xianzhong Xie",
      "Zhaoyuan Shi",
      "Hongjian Lei",
      "Nan Zhao",
      "Jun Cai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.14154"
  },
  {
    "id": "arXiv:2205.02301",
    "title": "BodySLAM: Joint Camera Localisation, Mapping, and Human Motion Tracking",
    "abstract": "Comments: ECCV 2022. Video: this https URL",
    "descriptor": "\nComments: ECCV 2022. Video: this https URL\n",
    "authors": [
      "Dorian F. Henning",
      "Tristan Laidlow",
      "Stefan Leutenegger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02301"
  },
  {
    "id": "arXiv:2205.03268",
    "title": "Robustness of Neural Architectures for Audio Event Detection",
    "abstract": "Robustness of Neural Architectures for Audio Event Detection",
    "descriptor": "",
    "authors": [
      "Juncheng B Li",
      "Zheng Wang",
      "Shuhui Qu",
      "Florian Metze"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.03268"
  },
  {
    "id": "arXiv:2205.03447",
    "title": "Machine Learning-Friendly Biomedical Datasets for Equivalence and  Subsumption Ontology Matching",
    "abstract": "Comments: Accepted paper in the 21st International Semantic Web Conference (ISWC-2022)",
    "descriptor": "\nComments: Accepted paper in the 21st International Semantic Web Conference (ISWC-2022)\n",
    "authors": [
      "Yuan He",
      "Jiaoyan Chen",
      "Hang Dong",
      "Ernesto Jim\u00e9nez-Ruiz",
      "Ali Hadian",
      "Ian Horrocks"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2205.03447"
  },
  {
    "id": "arXiv:2205.04992",
    "title": "KeypointNeRF: Generalizing Image-based Volumetric Avatars using Relative  Spatial Encoding of Keypoints",
    "abstract": "Comments: To appear at ECCV 2022. The project page is available at this https URL",
    "descriptor": "\nComments: To appear at ECCV 2022. The project page is available at this https URL\n",
    "authors": [
      "Marko Mihajlovic",
      "Aayush Bansal",
      "Michael Zollhoefer",
      "Siyu Tang",
      "Shunsuke Saito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.04992"
  },
  {
    "id": "arXiv:2205.07267",
    "title": "The Cavendish Computors: The women working in scientific computing for  Radio Astronomy",
    "abstract": "Comments: First presented at the Joint BSHM CSHPM/SCHPM Conference People, Places, Practices at St Andrews, July 2021",
    "descriptor": "\nComments: First presented at the Joint BSHM CSHPM/SCHPM Conference People, Places, Practices at St Andrews, July 2021\n",
    "authors": [
      "Verity Allan"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computers and Society (cs.CY)",
      "History and Philosophy of Physics (physics.hist-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.07267"
  },
  {
    "id": "arXiv:2205.07982",
    "title": "TOCH: Spatio-Temporal Object-to-Hand Correspondence for Motion  Refinement",
    "abstract": "TOCH: Spatio-Temporal Object-to-Hand Correspondence for Motion  Refinement",
    "descriptor": "",
    "authors": [
      "Keyang Zhou",
      "Bharat Lal Bhatnagar",
      "Jan Eric Lenssen",
      "Gerard Pons-Moll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.07982"
  },
  {
    "id": "arXiv:2205.13419",
    "title": "The way we cite: common metadata used across disciplines for defining  bibliographic references",
    "abstract": "The way we cite: common metadata used across disciplines for defining  bibliographic references",
    "descriptor": "",
    "authors": [
      "Erika Alves dos Santos",
      "Silvio Peroni",
      "Marcos Luiz Mucheroni"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2205.13419"
  },
  {
    "id": "arXiv:2205.15814",
    "title": "Contrasting quadratic assignments for set-based representation learning",
    "abstract": "Contrasting quadratic assignments for set-based representation learning",
    "descriptor": "",
    "authors": [
      "Artem Moskalev",
      "Ivan Sosnovik",
      "Volker Fischer",
      "Arnold Smeulders"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15814"
  },
  {
    "id": "arXiv:2206.00065",
    "title": "FELARE: Fair Scheduling of Machine Learning Tasks on Heterogeneous Edge  Systems",
    "abstract": "FELARE: Fair Scheduling of Machine Learning Tasks on Heterogeneous Edge  Systems",
    "descriptor": "",
    "authors": [
      "Ali Mokhtari",
      "Md Abir Hossen",
      "Pooyan Jamshidi",
      "Mohsen Amini Salehi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.00065"
  },
  {
    "id": "arXiv:2206.04382",
    "title": "CLIP-Actor: Text-Driven Recommendation and Stylization for Animating  Human Meshes",
    "abstract": "Comments: Accepted at ECCV 2022. [Project page] this https URL [Code] this https URL",
    "descriptor": "\nComments: Accepted at ECCV 2022. [Project page] this https URL [Code] this https URL\n",
    "authors": [
      "Kim Youwang",
      "Kim Ji-Yeon",
      "Tae-Hyun Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.04382"
  },
  {
    "id": "arXiv:2206.04583",
    "title": "Clustering with Queries under Semi-Random Noise",
    "abstract": "Comments: Accepted for presentation at the Conference on Learning Theory (COLT) 2022",
    "descriptor": "\nComments: Accepted for presentation at the Conference on Learning Theory (COLT) 2022\n",
    "authors": [
      "Alberto Del Pia",
      "Mingchen Ma",
      "Christos Tzamos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.04583"
  },
  {
    "id": "arXiv:2206.05195",
    "title": "Nominal Metaphor Generation with Multitask Learning",
    "abstract": "Comments: INLG 2022",
    "descriptor": "\nComments: INLG 2022\n",
    "authors": [
      "Yucheng Li",
      "Chenghua Lin",
      "Frank Geurin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.05195"
  },
  {
    "id": "arXiv:2206.06422",
    "title": "Symbolic Regression in Materials Science: Discovering Interatomic  Potentials from Data",
    "abstract": "Comments: Submitted to the GPTP XIX Workshop, June 2-4 2022, University of Michigan, Ann Arbor, Michigan",
    "descriptor": "\nComments: Submitted to the GPTP XIX Workshop, June 2-4 2022, University of Michigan, Ann Arbor, Michigan\n",
    "authors": [
      "Bogdan Burlacu",
      "Michael Kommenda",
      "Gabriel Kronberger",
      "Stephan Winkler",
      "Michael Affenzeller"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06422"
  },
  {
    "id": "arXiv:2206.06957",
    "title": "Continual-Learning-as-a-Service (CLaaS): On-Demand Efficient Adaptation  of Predictive Models",
    "abstract": "Continual-Learning-as-a-Service (CLaaS): On-Demand Efficient Adaptation  of Predictive Models",
    "descriptor": "",
    "authors": [
      "Rudy Semola",
      "Vincenzo Lomonaco",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.06957"
  },
  {
    "id": "arXiv:2206.07434",
    "title": "Self-Supervised Implicit Attention: Guided Attention by The Model Itself",
    "abstract": "Self-Supervised Implicit Attention: Guided Attention by The Model Itself",
    "descriptor": "",
    "authors": [
      "Jinyi Wu",
      "Xun Gong",
      "Zhemin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07434"
  },
  {
    "id": "arXiv:2206.07765",
    "title": "US News and Social Media Framing around Vaping",
    "abstract": "US News and Social Media Framing around Vaping",
    "descriptor": "",
    "authors": [
      "Keyu Chen",
      "Marzieh Babaeianjelodar",
      "Yiwen Shi",
      "Rohan Aanegola",
      "Lam Yin Cheung",
      "Preslav Ivanov Nakov",
      "Shweta Yadav",
      "Angus Bancroft",
      "Ashiqur R. KhudaBukhsh",
      "Munmun De Choudhury",
      "Frederick L. Altice",
      "Navin Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.07765"
  },
  {
    "id": "arXiv:2206.08194",
    "title": "Online Segmentation of LiDAR Sequences: Dataset and Algorithm",
    "abstract": "Comments: Code and data are available at: this https URL",
    "descriptor": "\nComments: Code and data are available at: this https URL\n",
    "authors": [
      "Romain Loiseau",
      "Mathieu Aubry",
      "Lo\u00efc Landrieu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08194"
  },
  {
    "id": "arXiv:2206.08920",
    "title": "VectorMapNet: End-to-end Vectorized HD Map Learning",
    "abstract": "VectorMapNet: End-to-end Vectorized HD Map Learning",
    "descriptor": "",
    "authors": [
      "Yicheng Liu",
      "Yue Wang",
      "Yilun Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.08920"
  },
  {
    "id": "arXiv:2206.10255",
    "title": "GNN-PMB: A Simple but Effective Online 3D Multi-Object Tracker without  Bells and Whistles",
    "abstract": "GNN-PMB: A Simple but Effective Online 3D Multi-Object Tracker without  Bells and Whistles",
    "descriptor": "",
    "authors": [
      "Jianan Liu",
      "Liping Bai",
      "Yuxuan Xia",
      "Tao Huang",
      "Bing Zhu",
      "Qing-Long Han"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10255"
  },
  {
    "id": "arXiv:2206.10594",
    "title": "How is Vaping Framed on Online Knowledge Dissemination Platforms?",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2206.07765, arXiv:2206.09024",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.07765, arXiv:2206.09024\n",
    "authors": [
      "Keyu Chen",
      "Yiwen Shi",
      "jun luo",
      "joyce jiang",
      "Shweta Yadav",
      "Munmun De Choudhury",
      "Ashiqur R. KhudaBukhsh",
      "Marzieh Babaeianjelodar",
      "Frederick Altice",
      "Navin Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.10594"
  },
  {
    "id": "arXiv:2206.10746",
    "title": "A Practical Methodology for ML-Based EM Side Channel Disassemblers",
    "abstract": "Comments: Accepted to the poster section of the 7th IEEE European Symposium on Security and Privacy 2022",
    "descriptor": "\nComments: Accepted to the poster section of the 7th IEEE European Symposium on Security and Privacy 2022\n",
    "authors": [
      "Cesar N. Arguello",
      "Hunter Searle",
      "Sara Rampazzi",
      "Kevin R. B. Butler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10746"
  },
  {
    "id": "arXiv:2206.11048",
    "title": "Automated GI tract segmentation using deep learning",
    "abstract": "Comments: 8 pages, 9 figures",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Manhar Sharma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11048"
  },
  {
    "id": "arXiv:2206.12531",
    "title": "Maximum independent set (stable set) problem: A mathematical programming  model with valid inequalities and computational testing",
    "abstract": "Comments: Revised the algorithm.. Added more information about computational testing",
    "descriptor": "\nComments: Revised the algorithm.. Added more information about computational testing\n",
    "authors": [
      "Prabhu Manyem"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.12531"
  },
  {
    "id": "arXiv:2206.12923",
    "title": "Video Activity Localisation with Uncertainties in Temporal Boundary",
    "abstract": "Video Activity Localisation with Uncertainties in Temporal Boundary",
    "descriptor": "",
    "authors": [
      "Jiabo Huang",
      "Hailin Jin",
      "Shaogang Gong",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12923"
  },
  {
    "id": "arXiv:2206.13179",
    "title": "AixBench: A Code Generation Benchmark Dataset",
    "abstract": "AixBench: A Code Generation Benchmark Dataset",
    "descriptor": "",
    "authors": [
      "Yiyang Hao",
      "Ge Li",
      "Yongqiang Liu",
      "Xiaowei Miao",
      "He Zong",
      "Siyuan Jiang",
      "Yang Liu",
      "He Wei"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.13179"
  },
  {
    "id": "arXiv:2206.13350",
    "title": "Intractable Group-theoretic Problems Around Zero-knowledge Proofs",
    "abstract": "Intractable Group-theoretic Problems Around Zero-knowledge Proofs",
    "descriptor": "",
    "authors": [
      "Cansu Betin Onur"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.13350"
  },
  {
    "id": "arXiv:2206.13979",
    "title": "Attack Agnostic Dataset: Towards Generalization and Stabilization of  Audio DeepFake Detection",
    "abstract": "Comments: Proceedings of INTERSPEECH 2022 (Updated version: corrected ASVspoof dataset description)",
    "descriptor": "\nComments: Proceedings of INTERSPEECH 2022 (Updated version: corrected ASVspoof dataset description)\n",
    "authors": [
      "Piotr Kawa",
      "Marcin Plata",
      "Piotr Syga"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.13979"
  },
  {
    "id": "arXiv:2206.15475",
    "title": "Causal Machine Learning: A Survey and Open Problems",
    "abstract": "Comments: 191 pages. v02. Work in progress. Feedback and comments are highly appreciated!",
    "descriptor": "\nComments: 191 pages. v02. Work in progress. Feedback and comments are highly appreciated!\n",
    "authors": [
      "Jean Kaddour",
      "Aengus Lynch",
      "Qi Liu",
      "Matt J. Kusner",
      "Ricardo Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.15475"
  },
  {
    "id": "arXiv:2206.15477",
    "title": "Denoised MDPs: Learning World Models Better Than the World Itself",
    "abstract": "Comments: Project page: this https URL Code: this https URL",
    "descriptor": "\nComments: Project page: this https URL Code: this https URL\n",
    "authors": [
      "Tongzhou Wang",
      "Simon S. Du",
      "Antonio Torralba",
      "Phillip Isola",
      "Amy Zhang",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15477"
  },
  {
    "id": "arXiv:2207.01260",
    "title": "CPrune: Compiler-Informed Model Pruning for Efficient Target-Aware DNN  Execution",
    "abstract": "Comments: 18 pages, 9 figures, accepted to ECCV 2022",
    "descriptor": "\nComments: 18 pages, 9 figures, accepted to ECCV 2022\n",
    "authors": [
      "Taeho Kim",
      "Yongin Kwon",
      "Jemin Lee",
      "Taeho Kim",
      "Sangtae Ha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.01260"
  },
  {
    "id": "arXiv:2207.01382",
    "title": "Exploring Lottery Ticket Hypothesis in Spiking Neural Networks",
    "abstract": "Comments: Accepted to European Conference on Computer Vision (ECCV) 2022",
    "descriptor": "\nComments: Accepted to European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Youngeun Kim",
      "Yuhang Li",
      "Hyoungseob Park",
      "Yeshwanth Venkatesha",
      "Ruokai Yin",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.01382"
  },
  {
    "id": "arXiv:2207.01700",
    "title": "Emergency Management and Recovery of Luna Classic",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Edward Kim",
      "Tobias Andersen",
      "Marventus",
      "A.E.",
      "Pedro Borges",
      "David Schmidt",
      "Matthew Western"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.01700"
  },
  {
    "id": "arXiv:2207.03074",
    "title": "Visual-Assisted Sound Source Depth Estimation in the Wild",
    "abstract": "Comments: 13 pages;in submission",
    "descriptor": "\nComments: 13 pages;in submission\n",
    "authors": [
      "Wei Sun",
      "Lili Qiu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.03074"
  },
  {
    "id": "arXiv:2207.03745",
    "title": "Revisiting Chernoff Information with Likelihood Ratio Exponential  Families",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Frank Nielsen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.03745"
  },
  {
    "id": "arXiv:2207.03851",
    "title": "Storehouse: a Reinforcement Learning Environment for Optimizing  Warehouse Management",
    "abstract": "Comments: 9 pages, 6 figures, accepted in WCCI 2022",
    "descriptor": "\nComments: 9 pages, 6 figures, accepted in WCCI 2022\n",
    "authors": [
      "Julen Cestero",
      "Marco Quartulli",
      "Alberto Maria Metelli",
      "Marcello Restelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.03851"
  },
  {
    "id": "arXiv:2207.03955",
    "title": "Outliers, Dynamics, and the Independence Postulate",
    "abstract": "Outliers, Dynamics, and the Independence Postulate",
    "descriptor": "",
    "authors": [
      "Samuel Epstein"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2207.03955"
  },
  {
    "id": "arXiv:2207.04574",
    "title": "Brain-Aware Replacements for Supervised Contrastive Learning in  Detection of Alzheimer's Disease",
    "abstract": "Brain-Aware Replacements for Supervised Contrastive Learning in  Detection of Alzheimer's Disease",
    "descriptor": "",
    "authors": [
      "Mehmet Sayg\u0131n Seyfio\u011flu",
      "Zixuan Liu",
      "Pranav Kamath",
      "Sadjyot Gangolli",
      "Sheng Wang",
      "Thomas Grabowski",
      "Linda Shapiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04574"
  },
  {
    "id": "arXiv:2207.04680",
    "title": "Towards Scale-Aware, Robust, and Generalizable Unsupervised Monocular  Depth Estimation by Integrating IMU Motion Dynamics",
    "abstract": "Comments: Accepted to ECCV 2022. Code is released at this https URL",
    "descriptor": "\nComments: Accepted to ECCV 2022. Code is released at this https URL\n",
    "authors": [
      "Sen Zhang",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04680"
  },
  {
    "id": "arXiv:2207.05223",
    "title": "Bootstrapping a User-Centered Task-Oriented Dialogue System",
    "abstract": "Comments: Published in 1st Proceedings of Alexa Prize TaskBot (Alexa Prize 2021). TacoBot won 3rd place in the challenge. See project website this https URL for details",
    "descriptor": "\nComments: Published in 1st Proceedings of Alexa Prize TaskBot (Alexa Prize 2021). TacoBot won 3rd place in the challenge. See project website this https URL for details\n",
    "authors": [
      "Shijie Chen",
      "Ziru Chen",
      "Xiang Deng",
      "Ashley Lewis",
      "Lingbo Mo",
      "Samuel Stevens",
      "Zhen Wang",
      "Xiang Yue",
      "Tianshu Zhang",
      "Yu Su",
      "Huan Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05223"
  },
  {
    "id": "arXiv:2207.05342",
    "title": "Video Graph Transformer for Video Question Answering",
    "abstract": "Comments: ECCV'22",
    "descriptor": "\nComments: ECCV'22\n",
    "authors": [
      "Junbin Xiao",
      "Pan Zhou",
      "Tat-Seng Chua",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.05342"
  },
  {
    "id": "arXiv:2207.05366",
    "title": "Image and Model Transformation with Secret Key for Vision Transformer",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Hitoshi Kiya",
      "Ryota Iijima",
      "MaungMaung Aprilpyone",
      "Yuma Kinoshita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.05366"
  },
  {
    "id": "arXiv:2207.06652",
    "title": "Every Preference Changes Differently: Neural Multi-Interest Preference  Model with Temporal Dynamics for Recommendation",
    "abstract": "Every Preference Changes Differently: Neural Multi-Interest Preference  Model with Temporal Dynamics for Recommendation",
    "descriptor": "",
    "authors": [
      "Hui Shi",
      "Yupeng Gu",
      "Yitong Zhou",
      "Bo Zhao",
      "Sicun Gao",
      "Jishen Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.06652"
  },
  {
    "id": "arXiv:2207.06819",
    "title": "Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks",
    "abstract": "Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Evan Caville",
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.06819"
  },
  {
    "id": "arXiv:2207.06902",
    "title": "Parallel Flowshop in YewPar",
    "abstract": "Comments: 13 pages, 2 figures",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Ignas Knizikevi\u010dius",
      "Phil Trinder",
      "Blair Archibald",
      "Jinghua Yan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2207.06902"
  },
  {
    "id": "arXiv:2207.07353",
    "title": "A category-theoretic proof of the ergodic decomposition theorem",
    "abstract": "Comments: 29 pages",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Sean Moss",
      "Paolo Perrone"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2207.07353"
  },
  {
    "id": "arXiv:2207.07394",
    "title": "FRAS: Federated Reinforcement Learning empowered Adaptive Point Cloud  Video Streaming",
    "abstract": "FRAS: Federated Reinforcement Learning empowered Adaptive Point Cloud  Video Streaming",
    "descriptor": "",
    "authors": [
      "Yu Gao",
      "Zhi Liu",
      "Bo Han",
      "Pan Hui",
      "Pengyuan Zhou"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.07394"
  },
  {
    "id": "arXiv:2207.07656",
    "title": "FLOWGEN: Fast and slow graph generation",
    "abstract": "Comments: This version to be presented at Dynn workshop @ ICML 2022",
    "descriptor": "\nComments: This version to be presented at Dynn workshop @ ICML 2022\n",
    "authors": [
      "Aman Madaan",
      "Yiming Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.07656"
  },
  {
    "id": "arXiv:2207.07698",
    "title": "Quasi-Monte Carlo and discontinuous Galerkin",
    "abstract": "Quasi-Monte Carlo and discontinuous Galerkin",
    "descriptor": "",
    "authors": [
      "Vesa Kaarnioja",
      "Andreas Rupp"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.07698"
  },
  {
    "id": "arXiv:2207.07929",
    "title": "Towards Lightweight Super-Resolution with Dual Regression Learning",
    "abstract": "Comments: Journal extension of DRN. arXiv admin note: text overlap with arXiv:2003.07018",
    "descriptor": "\nComments: Journal extension of DRN. arXiv admin note: text overlap with arXiv:2003.07018\n",
    "authors": [
      "Yong Guo",
      "Jingdong Wang",
      "Qi Chen",
      "Jiezhang Cao",
      "Zeshuai Deng",
      "Yanwu Xu",
      "Jian Chen",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.07929"
  },
  {
    "id": "arXiv:2207.08225",
    "title": "Teaching Qubits to Sing: Mission Impossible?",
    "abstract": "Comments: Preprint of paper to appear in International Journal of Unconventional Computing. Audio recordings of the musical examples and programming code are available: this https URL",
    "descriptor": "\nComments: Preprint of paper to appear in International Journal of Unconventional Computing. Audio recordings of the musical examples and programming code are available: this https URL\n",
    "authors": [
      "Eduardo Reck Miranda",
      "Brian N. Siegelwax"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.08225"
  },
  {
    "id": "arXiv:2207.08350",
    "title": "Towards Understanding The Semidefinite Relaxations of Truncated  Least-Squares in Robust Rotation Search",
    "abstract": "Comments: presented in part in ECCV 2022",
    "descriptor": "\nComments: presented in part in ECCV 2022\n",
    "authors": [
      "Liangzu Peng",
      "Mahyar Fazlyab",
      "Ren\u00e9 Vidal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08350"
  },
  {
    "id": "arXiv:2207.08560",
    "title": "Latency-Aware Collaborative Perception",
    "abstract": "Comments: 14 pages, 11 figures, Accepted by European conference on computer vision, 2022",
    "descriptor": "\nComments: 14 pages, 11 figures, Accepted by European conference on computer vision, 2022\n",
    "authors": [
      "Zixing Lei",
      "Shunli Ren",
      "Yue Hu",
      "Wenjun Zhang",
      "Siheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.08560"
  },
  {
    "id": "arXiv:2207.08601",
    "title": "Geometry-Aware Reference Synthesis for Multi-View Image Super-Resolution",
    "abstract": "Comments: 16 pages, 10 figures, ACM MULTIMEDIA 2022",
    "descriptor": "\nComments: 16 pages, 10 figures, ACM MULTIMEDIA 2022\n",
    "authors": [
      "Ri Cheng",
      "Yuqi Sun",
      "Bo Yan",
      "Weimin Tan",
      "Chenxi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08601"
  },
  {
    "id": "arXiv:2207.08631",
    "title": "Latent Partition Implicit with Surface Codes for 3D Representation",
    "abstract": "Comments: 20pages,14figures",
    "descriptor": "\nComments: 20pages,14figures\n",
    "authors": [
      "Chao Chen",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08631"
  },
  {
    "id": "arXiv:2207.08653",
    "title": "Leveraging Action Affinity and Continuity for Semi-supervised Temporal  Action Segmentation",
    "abstract": "Comments: 16 pages, 5 figures",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Guodong Ding",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.08653"
  },
  {
    "id": "arXiv:2207.08920",
    "title": "Recognizing Hand Use and Hand Role at Home After Stroke from Egocentric  Video",
    "abstract": "Comments: Appendix is included",
    "descriptor": "\nComments: Appendix is included\n",
    "authors": [
      "Meng-Fen Tsai",
      "Rosalie H. Wang",
      "Jo\u015be Zariffa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08920"
  },
  {
    "id": "arXiv:2207.09033",
    "title": "Using the Newton-Raphson Method with Automatic Differentiation to  Numerically Solve Implied Volatility of Stock Option through Binomial Model",
    "abstract": "Using the Newton-Raphson Method with Automatic Differentiation to  Numerically Solve Implied Volatility of Stock Option through Binomial Model",
    "descriptor": "",
    "authors": [
      "Wanchaloem Wunkaew",
      "Yuqing Liu",
      "Kirill V. Golubnichiy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.09033"
  },
  {
    "id": "arXiv:2207.09314",
    "title": "Self-Supervised Interactive Object Segmentation Through a  Singulation-and-Grasping Approach",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Houjian Yu",
      "Changhyun Choi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09314"
  },
  {
    "id": "arXiv:2207.09445",
    "title": "PoserNet: Refining Relative Camera Poses Exploiting Object Detections",
    "abstract": "Comments: Accepted at ECCV 2022",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Matteo Taiana",
      "Matteo Toso",
      "Stuart James",
      "Alessio Del Bue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09445"
  },
  {
    "id": "arXiv:2207.09508",
    "title": "HSE-NN Team at the 4th ABAW Competition: Multi-task Emotion Recognition  and Learning from Synthetic Images",
    "abstract": "Comments: 13 pages, 3 figures, 8 tables",
    "descriptor": "\nComments: 13 pages, 3 figures, 8 tables\n",
    "authors": [
      "Andrey V. Savchenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09508"
  },
  {
    "id": "arXiv:2207.09582",
    "title": "Segmentation of 3D Dental Images Using Deep Learning",
    "abstract": "Segmentation of 3D Dental Images Using Deep Learning",
    "descriptor": "",
    "authors": [
      "Omar Boudraa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09582"
  },
  {
    "id": "arXiv:2207.09629",
    "title": "Perspective Phase Angle Model for Polarimetric 3D Reconstruction",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Guangcheng Chen",
      "Li He",
      "Yisheng Guan",
      "Hong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09629"
  },
  {
    "id": "arXiv:2207.09655",
    "title": "How can I improve my scientific impact? The most influential factors in  predicting the h-index",
    "abstract": "Comments: 14 pages, 1 figure",
    "descriptor": "\nComments: 14 pages, 1 figure\n",
    "authors": [
      "Fakhri Momeni",
      "Philipp Mayr",
      "Stefan Dietze"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2207.09655"
  },
  {
    "id": "arXiv:2207.09657",
    "title": "Multigraph Topology Design for Cross-Silo Federated Learning",
    "abstract": "Multigraph Topology Design for Cross-Silo Federated Learning",
    "descriptor": "",
    "authors": [
      "Binh X. Nguyen",
      "Tuong Do",
      "Hien Nguyen",
      "Vuong Pham",
      "Toan Tran",
      "Erman Tjiputra",
      "Quang Tran",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.09657"
  },
  {
    "id": "arXiv:2207.09662",
    "title": "HTNet: Anchor-free Temporal Action Localization with Hierarchical  Transformers",
    "abstract": "Comments: 6 pages",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Tae-Kyung Kang",
      "Gun-Hee Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09662"
  },
  {
    "id": "arXiv:2207.09675",
    "title": "ERA: Expert Retrieval and Assembly for Early Action Prediction",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Lin Geng Foo",
      "Tianjiao Li",
      "Hossein Rahmani",
      "Qiuhong Ke",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09675"
  },
  {
    "id": "arXiv:2207.09812",
    "title": "The Anatomy of Video Editing: A Dataset and Benchmark Suite for  AI-Assisted Video Editing",
    "abstract": "Comments: Code is available at: this https URL",
    "descriptor": "\nComments: Code is available at: this https URL\n",
    "authors": [
      "Dawit Mureja Argaw",
      "Fabian Caba Heilbron",
      "Joon-Young Lee",
      "Markus Woodson",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09812"
  },
  {
    "id": "arXiv:2207.09860",
    "title": "Learning to Solve Soft-Constrained Vehicle Routing Problems with  Lagrangian Relaxation",
    "abstract": "Learning to Solve Soft-Constrained Vehicle Routing Problems with  Lagrangian Relaxation",
    "descriptor": "",
    "authors": [
      "Qiaoyue Tang",
      "Yangzhe Kong",
      "Lemeng Pan",
      "Choonmeng Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09860"
  },
  {
    "id": "arXiv:2207.09933",
    "title": "Robust Landmark-based Stent Tracking in X-ray Fluoroscopy",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Luojie Huang",
      "Yikang Liu",
      "Li Chen",
      "Eric Z. Chen",
      "Xiao Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09933"
  },
  {
    "id": "arXiv:2207.09971",
    "title": "NeuralNEB -- Neural Networks can find Reaction Paths Fast",
    "abstract": "NeuralNEB -- Neural Networks can find Reaction Paths Fast",
    "descriptor": "",
    "authors": [
      "Mathias Schreiner",
      "Arghya Bhowmik",
      "Tejs Vegge",
      "Ole Winther"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.09971"
  },
  {
    "id": "arXiv:2207.09980",
    "title": "ReFactorGNNs: Revisiting Factorisation-based Models from a  Message-Passing Perspective",
    "abstract": "ReFactorGNNs: Revisiting Factorisation-based Models from a  Message-Passing Perspective",
    "descriptor": "",
    "authors": [
      "Yihong Chen",
      "Pushkar Mishra",
      "Luca Franceschi",
      "Pasquale Minervini",
      "Pontus Stenetorp",
      "Sebastian Riedel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.09980"
  },
  {
    "id": "arXiv:2207.10022",
    "title": "Secrets of Event-Based Optical Flow",
    "abstract": "Comments: 23 pages, 11 figures, 7 tables, this https URL",
    "descriptor": "\nComments: 23 pages, 11 figures, 7 tables, this https URL\n",
    "authors": [
      "Shintaro Shiba",
      "Yoshimitsu Aoki",
      "Guillermo Gallego"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10022"
  },
  {
    "id": "arXiv:2207.10025",
    "title": "Learning from Synthetic Data: Facial Expression Classification based on  Ensemble of Multi-task Networks",
    "abstract": "Comments: Page 3, Added reference [2], [33]",
    "descriptor": "\nComments: Page 3, Added reference [2], [33]\n",
    "authors": [
      "Jae-Yeop Jeong",
      "Yeong-Gi Hong",
      "JiYeon Oh",
      "Sumin Hong",
      "Jin-Woo Jeong",
      "Yuchul Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10025"
  },
  {
    "id": "arXiv:2207.10047",
    "title": "Densely Constrained Depth Estimator for Monocular 3D Object Detection",
    "abstract": "Comments: Accepted by ECCV2022",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Yingyan Li",
      "Yuntao Chen",
      "Jiawei He",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10047"
  }
]
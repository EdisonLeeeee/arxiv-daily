[
  {
    "id": "arXiv:2207.04045",
    "title": "Runtime Analysis for Permutation-based Evolutionary Algorithms",
    "abstract": "While the theoretical analysis of evolutionary algorithms (EAs) has made\nsignificant progress for pseudo-Boolean optimization problems in the last 25\nyears, only sporadic theoretical results exist on how EAs solve\npermutation-based problems.\nTo overcome the lack of permutation-based benchmark problems, we propose a\ngeneral way to transfer the classic pseudo-Boolean benchmarks into benchmarks\ndefined on sets of permutations. We then conduct a rigorous runtime analysis of\nthe permutation-based $(1+1)$ EA proposed by Scharnow, Tinnefeld, and Wegener\n(2004) on the analogues of the \\textsc{LeadingOnes} and \\textsc{Jump}\nbenchmarks. The latter shows that, different from bit-strings, it is not only\nthe Hamming distance that determines how difficult it is to mutate a\npermutation $\\sigma$ into another one $\\tau$, but also the precise cycle\nstructure of $\\sigma \\tau^{-1}$. For this reason, we also regard the more\nsymmetric scramble mutation operator. We observe that it not only leads to\nsimpler proofs, but also reduces the runtime on jump functions with odd jump\nsize by a factor of $\\Theta(n)$. Finally, we show that a heavy-tailed version\nof the scramble operator, as in the bit-string case, leads to a speed-up of\norder $m^{\\Theta(m)}$ on jump functions with jump size~$m$.%",
    "descriptor": "\nComments: Journal version of our paper at GECCO 2022. arXiv admin note: substantial text overlap with arXiv:2204.07637\n",
    "authors": [
      "Benjamin Doerr",
      "Yassine Ghannane",
      "Marouane Ibn Brahim"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04045"
  },
  {
    "id": "arXiv:2207.04046",
    "title": "Optimal Pattern synthesis of linear antenna array using Ant Hill  Colonization Optimization algorithm(AHCOA)",
    "abstract": "The aim of this paper is to introduce AHCOA to the electromagnetic and\nantenna community. AHCOA is a new nature inspired meta heuristic algorithm\ninspired by how there is a hierarchy and departments in the ant hill\ncolonization. It has high probabilistic potential in solving not only\nunconstrained but also constrained optimization problems. In this paper the\nAHCOA is applied to linear antenna array for better pattern synthesis in the\nfollowing ways : By uniform excitation considering equal spacing of the antenna\nelements with respect to the uniform array. AHCOA is used in obtaining an array\npattern to achieve minimum side lobe levels. The results are compared to other\nstate of the art nature based algorithms such as ant lion optimizer, which show\na considerable improvement in AHCOA.",
    "descriptor": "",
    "authors": [
      "Sunit Shantanu Digamber Fulari",
      "Harbinder Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.04046"
  },
  {
    "id": "arXiv:2207.04047",
    "title": "A Framework Based on Generational and Environmental Response Strategies  for Dynamic Multi-objective Optimization",
    "abstract": "Due to the dynamics and uncertainty of the dynamic multi-objective\noptimization problems (DMOPs), it is difficult for algorithms to find a\nsatisfactory solution set before the next environmental change, especially for\nsome complex environments. One reason may be that the information in the\nenvironmental static stage can not be used well in the traditional framework.\nIn this paper, a novel framework based on generational and environmental\nresponse strategies (FGERS) is proposed, in which response strategies are run\nboth in the environmental change stage and the environmental static stage to\nobtain population evolution information of those both stages. Unlike in the\ntraditional framework, response strategies are only run in the environmental\nchange stage. For simplicity, the feed-forward center point strategy was chosen\nto be the response strategy in the novel dynamic framework (FGERS-CPS).\nFGERS-CPS is not only to predict change trend of the optimum solution set in\nthe environmental change stage, but to predict the evolution trend of the\npopulation after several generations in the environmental static stage.\nTogether with the feed-forward center point strategy, a simple memory strategy\nand adaptive diversity maintenance strategy were used to form the complete\nFGERS-CPS. On 13 DMOPs with various characteristics, FGERS-CPS was compared\nwith four classical response strategies in the traditional framework.\nExperimental results show that FGERS-CPS is effective for DMOPs.",
    "descriptor": "",
    "authors": [
      "Qingya Li",
      "Xiangzhi Liu",
      "Fuqiang Wang",
      "Shuai Wang",
      "Peng Zhang",
      "Xiaoming Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04047"
  },
  {
    "id": "arXiv:2207.04049",
    "title": "Learning Causal Effects on Hypergraphs",
    "abstract": "Hypergraphs provide an effective abstraction for modeling multi-way group\ninteractions among nodes, where each hyperedge can connect any number of nodes.\nDifferent from most existing studies which leverage statistical dependencies,\nwe study hypergraphs from the perspective of causality. Specifically, in this\npaper, we focus on the problem of individual treatment effect (ITE) estimation\non hypergraphs, aiming to estimate how much an intervention (e.g., wearing face\ncovering) would causally affect an outcome (e.g., COVID-19 infection) of each\nindividual node. Existing works on ITE estimation either assume that the\noutcome on one individual should not be influenced by the treatment assignments\non other individuals (i.e., no interference), or assume the interference only\nexists between pairs of connected individuals in an ordinary graph. We argue\nthat these assumptions can be unrealistic on real-world hypergraphs, where\nhigher-order interference can affect the ultimate ITE estimations due to the\npresence of group interactions. In this work, we investigate high-order\ninterference modeling, and propose a new causality learning framework powered\nby hypergraph neural networks. Extensive experiments on real-world hypergraphs\nverify the superiority of our framework over existing baselines.",
    "descriptor": "",
    "authors": [
      "Jing Ma",
      "Mengting Wan",
      "Longqi Yang",
      "Jundong Li",
      "Brent Hecht",
      "Jaime Teevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04049"
  },
  {
    "id": "arXiv:2207.04050",
    "title": "Few-Example Clustering via Contrastive Learning",
    "abstract": "We propose Few-Example Clustering (FEC), a novel algorithm that performs\ncontrastive learning to cluster few examples. Our method is composed of the\nfollowing three steps: (1) generation of candidate cluster assignments, (2)\ncontrastive learning for each cluster assignment, and (3) selection of the best\ncandidate. Based on the hypothesis that the contrastive learner with the\nground-truth cluster assignment is trained faster than the others, we choose\nthe candidate with the smallest training loss in the early stage of learning in\nstep (3). Extensive experiments on the \\textit{mini}-ImageNet and CUB-200-2011\ndatasets show that FEC outperforms other baselines by about 3.2% on average\nunder various scenarios. FEC also exhibits an interesting learning curve where\nclustering performance gradually increases and then sharply drops.",
    "descriptor": "",
    "authors": [
      "Minguk Jang",
      "Sae-Young Chung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04050"
  },
  {
    "id": "arXiv:2207.04052",
    "title": "Robust optimal investment and risk control for an insurer with general  insider information",
    "abstract": "In this paper, we study the robust optimal investment and risk control\nproblem for an insurer who owns the insider information about the financial\nmarket and the insurance market under model uncertainty. Both financial risky\nasset process and insurance risk process are assumed to be very general jump\ndiffusion processes. The insider information is of the most general form rather\nthan the initial enlargement type. We use the theory of forward integrals to\ngive the first half characterization of the robust optimal strategy and\ntransform the anticipating stochastic differential game problem into the\nnonanticipative stochastic differential game problem. Then we adopt the\nstochastic maximum principle to obtain the total characterization of the robust\nstrategy. We discuss the two typical situations when the insurer is `small' and\n`large' by Malliavin calculus. For the `small' insurer, we obtain the\nclosed-form solution in the continuous case and the half closed-form solution\nin the case with jumps. For the `large' insurer, we reduce the problem to the\nquadratic backward stochastic differential equation (BSDE) and obtain the\nclosed-form solution in the continuous case without model uncertainty. We\ndiscuss some impacts of the model uncertainty, insider information and the\n`large' insurer on the optimal strategy.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2207.03738\n",
    "authors": [
      "Chao Yu",
      "Yuhan Cheng",
      "Yilun Song"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04052"
  },
  {
    "id": "arXiv:2207.04053",
    "title": "On the Need and Applicability of Causality for Fair Machine Learning",
    "abstract": "Causal reasoning has an indispensable role in how humans make sense of the\nworld and come to decisions in everyday life. While $20th$ century science was\nreserved from making causal claims as too strong and not achievable, the $21st$\ncentury is marked by the return of causality encouraged by the mathematization\nof causal notions and the introduction of the non-deterministic concept of\ncause~\\cite{illari2011look}. Besides its common use cases in epidemiology,\npolitical, and social sciences, causality turns out to be crucial in evaluating\nthe fairness of automated decisions, both in a legal and everyday sense. We\nprovide arguments and examples of why causality is particularly important for\nfairness evaluation. In particular, we point out the social impact of\nnon-causal predictions and the legal anti-discrimination process that relies on\ncausal claims. We conclude with a discussion about the challenges and\nlimitations of applying causality in practical scenarios as well as possible\nsolutions.",
    "descriptor": "",
    "authors": [
      "R\u016bta Binkyt\u0117",
      "Sami Zhioua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.04053"
  },
  {
    "id": "arXiv:2207.04054",
    "title": "Online Learning in Supply-Chain Games",
    "abstract": "We study a repeated game between a supplier and a retailer who want to\nmaximize their respective profits without full knowledge of the problem\nparameters. After characterizing the uniqueness of the Stackelberg equilibrium\nof the stage game with complete information, we show that even with partial\nknowledge of the joint distribution of demand and production costs, natural\nlearning dynamics guarantee convergence of the joint strategy profile of\nsupplier and retailer to the Stackelberg equilibrium of the stage game. We also\nprove finite-time bounds on the supplier's regret and asymptotic bounds on the\nretailer's regret, where the specific rates depend on the type of knowledge\npreliminarily available to the players. In the special case when the supplier\nis not strategic (vertical integration), we prove optimal finite-time regret\nbounds on the retailer's regret (or, equivalently, the social welfare) when\ncosts and demand are adversarially generated and the demand is censored.",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Cesa-Bianchi",
      "Tommaso Cesari",
      "Takayuki Osogami",
      "Marco Scarsini",
      "Segev Wasserkrug"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04054"
  },
  {
    "id": "arXiv:2207.04055",
    "title": "Causal Discovery using Model Invariance through Knockoff Interventions",
    "abstract": "Cause-effect analysis is crucial to understand the underlying mechanism of a\nsystem. We propose to exploit model invariance through interventions on the\npredictors to infer causality in nonlinear multivariate systems of time series.\nWe model nonlinear interactions in time series using DeepAR and then expose the\nmodel to different environments using Knockoffs-based interventions to test\nmodel invariance. Knockoff samples are pairwise exchangeable, in-distribution\nand statistically null variables generated without knowing the response. We\ntest model invariance where we show that the distribution of the response\nresidual does not change significantly upon interventions on non-causal\npredictors. We evaluate our method on real and synthetically generated time\nseries. Overall our method outperforms other widely used causality methods,\ni.e, VAR Granger causality, VARLiNGAM and PCMCI+.",
    "descriptor": "",
    "authors": [
      "Wasim Ahmad",
      "Maha Shadaydeh",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04055"
  },
  {
    "id": "arXiv:2207.04056",
    "title": "Large Scale Mask Optimization Via Convolutional Fourier Neural Operator  and Litho-Guided Self Training",
    "abstract": "Machine learning techniques have been extensively studied for mask\noptimization problems, aiming at better mask printability, shorter turnaround\ntime, better mask manufacturability, and so on. However, most of these\nresearches are focusing on the initial solution generation of small design\nregions. To further realize the potential of machine learning techniques on\nmask optimization tasks, we present a Convolutional Fourier Neural Operator\n(CFNO) that can efficiently learn layout tile dependencies and hence promise\nstitch-less large-scale mask optimization with the limited intervention of\nlegacy tools. We discover the possibility of litho-guided self-training (LGST)\nthrough a trained machine learning model when solving non-convex optimization\nproblems, which allows iterative model and dataset update and brings\nsignificant model performance improvement. Experimental results show that, for\nthe first time, our machine learning-based framework outperforms\nstate-of-the-art academic numerical mask optimizers with an order of magnitude\nspeedup.",
    "descriptor": "\nComments: 9 pages, 10 figures, in preparation for journal submission\n",
    "authors": [
      "Haoyu Yang",
      "Zongyi Li",
      "Kumara Sastry",
      "Saumyadip Mukhopadhyay",
      "Anima Anandkumar",
      "Brucek Khailany",
      "Vivek Singh",
      "Haoxing Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04056"
  },
  {
    "id": "arXiv:2207.04075",
    "title": "Models Out of Line: A Fourier Lens on Distribution Shift Robustness",
    "abstract": "Improving the accuracy of deep neural networks (DNNs) on out-of-distribution\n(OOD) data is critical to an acceptance of deep learning (DL) in real world\napplications. It has been observed that accuracies on in-distribution (ID)\nversus OOD data follow a linear trend and models that outperform this baseline\nare exceptionally rare (and referred to as \"effectively robust\"). Recently,\nsome promising approaches have been developed to improve OOD robustness: model\npruning, data augmentation, and ensembling or zero-shot evaluating large\npretrained models. However, there still is no clear understanding of the\nconditions on OOD data and model properties that are required to observe\neffective robustness. We approach this issue by conducting a comprehensive\nempirical study of diverse approaches that are known to impact OOD robustness\non a broad range of natural and synthetic distribution shifts of CIFAR-10 and\nImageNet. In particular, we view the \"effective robustness puzzle\" through a\nFourier lens and ask how spectral properties of both models and OOD data\ninfluence the corresponding effective robustness. We find this Fourier lens\noffers some insight into why certain robust models, particularly those from the\nCLIP family, achieve OOD robustness. However, our analysis also makes clear\nthat no known metric is consistently the best explanation (or even a strong\nexplanation) of OOD robustness. Thus, to aid future research into the OOD\npuzzle, we address the gap in publicly-available models with effective\nrobustness by introducing a set of pretrained models--RobustNets--with varying\nlevels of OOD robustness.",
    "descriptor": "",
    "authors": [
      "Sara Fridovich-Keil",
      "Brian R. Bartoldson",
      "James Diffenderfer",
      "Bhavya Kailkhura",
      "Peer-Timo Bremer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04075"
  },
  {
    "id": "arXiv:2207.04084",
    "title": "Adaptive Self-supervision Algorithms for Physics-informed Neural  Networks",
    "abstract": "Physics-informed neural networks (PINNs) incorporate physical knowledge from\nthe problem domain as a soft constraint on the loss function, but recent work\nhas shown that this can lead to optimization difficulties. Here, we study the\nimpact of the location of the collocation points on the trainability of these\nmodels. We find that the vanilla PINN performance can be significantly boosted\nby adapting the location of the collocation points as training proceeds.\nSpecifically, we propose a novel adaptive collocation scheme which\nprogressively allocates more collocation points (without increasing their\nnumber) to areas where the model is making higher errors (based on the gradient\nof the loss function in the domain). This, coupled with a judicious restarting\nof the training during any optimization stalls (by simply resampling the\ncollocation points in order to adjust the loss landscape) leads to better\nestimates for the prediction error. We present results for several problems,\nincluding a 2D Poisson and diffusion-advection system with different forcing\nfunctions. We find that training vanilla PINNs for these problems can result in\nup to 70% prediction error in the solution, especially in the regime of low\ncollocation points. In contrast, our adaptive schemes can achieve up to an\norder of magnitude smaller error, with similar computational complexity as the\nbaseline. Furthermore, we find that the adaptive methods consistently perform\non-par or slightly better than vanilla PINN method, even for large collocation\npoint regimes. The code for all the experiments has been open sourced.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Shashank Subramanian",
      "Robert M. Kirby",
      "Michael W. Mahoney",
      "Amir Gholami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.04084"
  },
  {
    "id": "arXiv:2207.04089",
    "title": "SInGE: Sparsity via Integrated Gradients Estimation of Neuron Relevance",
    "abstract": "The leap in performance in state-of-the-art computer vision methods is\nattributed to the development of deep neural networks. However it often comes\nat a computational price which may hinder their deployment. To alleviate this\nlimitation, structured pruning is a well known technique which consists in\nremoving channels, neurons or filters, and is commonly applied in order to\nproduce more compact models. In most cases, the computations to remove are\nselected based on a relative importance criterion. At the same time, the need\nfor explainable predictive models has risen tremendously and motivated the\ndevelopment of robust attribution methods that highlight the relative\nimportance of pixels of an input image or feature map. In this work, we discuss\nthe limitations of existing pruning heuristics, among which magnitude and\ngradient-based methods. We draw inspiration from attribution methods to design\na novel integrated gradient pruning criterion, in which the relevance of each\nneuron is defined as the integral of the gradient variation on a path towards\nthis neuron removal. Furthermore, we propose an entwined DNN pruning and\nfine-tuning flowchart to better preserve DNN accuracy while removing\nparameters. We show through extensive validation on several datasets,\narchitectures as well as pruning scenarios that the proposed method, dubbed\nSInGE, significantly outperforms existing state-of-the-art DNN pruning methods.",
    "descriptor": "",
    "authors": [
      "Edouard Yvinec",
      "Arnaud Dapogny",
      "Matthieu Cord",
      "Kevin Bailly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04089"
  },
  {
    "id": "arXiv:2207.04093",
    "title": "An Integrated Framework for DevSecOps Adoption",
    "abstract": "Introduction of DevOps into the software development life cycle represents a\ncultural shift in the IT culture, amalgamating development and operations to\nimprove delivery speed in a rapid and maintainable manner. At the same time,\nsecurity threats and breaches are expected to grow as more enterprises move to\nnew agile frameworks for rapid product delivery. Meanwhile, DevSecOps is a\nmindset change that revolutionizes software development by embedding security\nat each step of the software cycle, leading to resilient software. This paper\ndiscusses a framework organization can use to embed DevSecOps swiftly and\nefficiently into the general IT culture.",
    "descriptor": "",
    "authors": [
      "Akanksha Gupta"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.04093"
  },
  {
    "id": "arXiv:2207.04095",
    "title": "A Study on the Effectiveness of Using Telepresence and Multiple Cameras  in Remote Physical Therapy",
    "abstract": "The present research investigates the effectiveness of using a telepresence\nsystem compared to a video conferencing system and the effectiveness of using\ntwo cameras compared to one camera for remote physical therapy. The\ntelepresence system that was used is Telegie, which allows users to see a place\nin 3D through a VR headset. Using two cameras with a video conferencing system\nallows users to see a place from multiple angles and provides additional\nspatial information. These two approaches of providing users additional spatial\ninformation were examined and compared in the context of remote physical\ntherapy through a user study with 11 physical therapists who had subject matter\nexpertise and 76 participants who acted as physical therapy patients. We\nconducted detailed interviews of therapists at the end of their participation.\nResults showed that none of the main effects of using telepresence and using\ntwo cameras were supported via t-tests. However, additional analyses using\nlinear mixed models with individual differences of participants controlled\nrevealed a marginally significant positive effect of using two cameras on\nassessment scores from the therapists.\nThe findings of this paper indicate that video fidelity of remote\ncommunication systems matters and therefore suggest telepresence systems should\nprovide sufficient video clarity. Spatial ability of patients was found as a\nstrong predictor of therapist assessments.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Hanseul Jun",
      "Husam Shaik",
      "Michael Lewek",
      "Henry Fuchs",
      "Jeremy Bailenson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.04095"
  },
  {
    "id": "arXiv:2207.04096",
    "title": "On Optimum Enumerative Sphere Shaping Blocklength at Different Symbol  Rates for the Nonlinear Fiber Channel",
    "abstract": "We show that a 0.9 dB SNR improvement can be obtained via short-blocklength\nenumerative sphere shaping for single-span transmission at 56 GBd. This gain\nvanishes for higher symbol rates and a larger number of spans.",
    "descriptor": "\nComments: 3 pages, 3 figures, presented at the OECC/PSC 2022\n",
    "authors": [
      "Yunus Can G\u00fcltekin",
      "Olga Vassilieva",
      "Inwoong Kim",
      "Paparao Palacharla",
      "Chigo Okonkwo",
      "Alex Alvarado"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.04096"
  },
  {
    "id": "arXiv:2207.04098",
    "title": "Guarding a Translating Line with an Attached Defender",
    "abstract": "In this paper we consider a Target-guarding differential game where the\nDefender must protect a linearly moving line segment by intercepting the\nAttacker who tries to reach it. In contrast to common Target-guarding problems,\nwe assume that the Defender is attached to the Target and moves along with it.\nThis assumption affects the Defender's maximum speed depending on its heading\ndirection. A zero-sum differential game of degree for the Attacker-winning\nscenario is studied, where the payoff is defined to be the distance between the\ntwo agents at the time of reaching the Target. We derive the equilibrium\nstrategies and the Value function by leveraging the solution for the\ninfinite-length Target scenario. The zero-level set of this Value function\nprovides the barrier surface that divides the state space into Defender-winning\nand Attacker-winning regions. We present simulation results at the end to\ndemonstrate the theoretical results.",
    "descriptor": "",
    "authors": [
      "Goutam Das",
      "Daigo Shishika"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04098"
  },
  {
    "id": "arXiv:2207.04103",
    "title": "StatMix: Data augmentation method that relies on image statistics in  federated learning",
    "abstract": "Availability of large amount of annotated data is one of the pillars of deep\nlearning success. Although numerous big datasets have been made available for\nresearch, this is often not the case in real life applications (e.g. companies\nare not able to share data due to GDPR or concerns related to intellectual\nproperty rights protection). Federated learning (FL) is a potential solution to\nthis problem, as it enables training a global model on data scattered across\nmultiple nodes, without sharing local data itself. However, even FL methods\npose a threat to data privacy, if not handled properly. Therefore, we propose\nStatMix, an augmentation approach that uses image statistics, to improve\nresults of FL scenario(s). StatMix is empirically tested on CIFAR-10 and\nCIFAR-100, using two neural network architectures. In all FL experiments,\napplication of StatMix improves the average accuracy, compared to the baseline\ntraining (with no use of StatMix). Some improvement can also be observed in\nnon-FL setups.",
    "descriptor": "",
    "authors": [
      "Dominik Lewy",
      "Jacek Ma\u0144dziuk",
      "Maria Ganzha",
      "Marcin Paprzycki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04103"
  },
  {
    "id": "arXiv:2207.04104",
    "title": "Evaluating Systemic Error Detection Methods using Synthetic Images",
    "abstract": "We introduce SpotCheck, a framework for generating synthetic datasets to use\nfor evaluating methods for discovering blindspots (i.e., systemic errors) in\nimage classifiers. We use SpotCheck to run controlled studies of how various\nfactors influence the performance of blindspot discovery methods. Our\nexperiments reveal several shortcomings of existing methods, such as relatively\npoor performance in settings with multiple blindspots and sensitivity to\nhyperparameters. Further, we find that a method based on dimensionality\nreduction, PlaneSpot, is competitive with existing methods, which has promising\nimplications for the development of interactive tools.",
    "descriptor": "",
    "authors": [
      "Gregory Plumb",
      "Nari Johnson",
      "\u00c1ngel Alexander Cabrera",
      "Marco Tulio Ribeiro",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04104"
  },
  {
    "id": "arXiv:2207.04106",
    "title": "Improving Entity Disambiguation by Reasoning over a Knowledge Base",
    "abstract": "Recent work in entity disambiguation (ED) has typically neglected structured\nknowledge base (KB) facts, and instead relied on a limited subset of KB\ninformation, such as entity descriptions or types. This limits the range of\ncontexts in which entities can be disambiguated. To allow the use of all KB\nfacts, as well as descriptions and types, we introduce an ED model which links\nentities by reasoning over a symbolic knowledge base in a fully differentiable\nfashion. Our model surpasses state-of-the-art baselines on six well-established\nED datasets by 1.3 F1 on average. By allowing access to all KB information, our\nmodel is less reliant on popularity-based entity priors, and improves\nperformance on the challenging ShadowLink dataset (which emphasises infrequent\nand ambiguous entities) by 12.7 F1.",
    "descriptor": "\nComments: Accepted at NAACL 2022\n",
    "authors": [
      "Tom Ayoola",
      "Joseph Fisher",
      "Andrea Pierleoni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04106"
  },
  {
    "id": "arXiv:2207.04108",
    "title": "ReFinED: An Efficient Zero-shot-capable Approach to End-to-End Entity  Linking",
    "abstract": "We introduce ReFinED, an efficient end-to-end entity linking model which uses\nfine-grained entity types and entity descriptions to perform linking. The model\nperforms mention detection, fine-grained entity typing, and entity\ndisambiguation for all mentions within a document in a single forward pass,\nmaking it more than 60 times faster than competitive existing approaches.\nReFinED also surpasses state-of-the-art performance on standard entity linking\ndatasets by an average of 3.7 F1. The model is capable of generalising to\nlarge-scale knowledge bases such as Wikidata (which has 15 times more entities\nthan Wikipedia) and of zero-shot entity linking. The combination of speed,\naccuracy and scale makes ReFinED an effective and cost-efficient system for\nextracting entities from web-scale datasets, for which the model has been\nsuccessfully deployed. Our code and pre-trained models are available at\nhttps://github.com/alexa/ReFinED",
    "descriptor": "\nComments: Accepted at NAACL Industry Track 2022\n",
    "authors": [
      "Tom Ayoola",
      "Shubhi Tyagi",
      "Joseph Fisher",
      "Christos Christodoulopoulos",
      "Andrea Pierleoni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04108"
  },
  {
    "id": "arXiv:2207.04113",
    "title": "Seasonal Encoder-Decoder Architecture for Forecasting",
    "abstract": "Deep learning (DL) in general and Recurrent neural networks (RNNs) in\nparticular have seen high success levels in sequence based applications. This\npaper pertains to RNNs for time series modelling and forecasting. We propose a\nnovel RNN architecture capturing (stochastic) seasonal correlations\nintelligently while capable of accurate multi-step forecasting. It is motivated\nfrom the well-known encoder-decoder (ED) architecture and multiplicative\nseasonal auto-regressive model. It incorporates multi-step (multi-target)\nlearning even in the presence (or absence) of exogenous inputs. It can be\nemployed on single or multiple sequence data. For the multiple sequence case,\nwe also propose a novel greedy recursive procedure to build (one or more)\npredictive models across sequences when per-sequence data is less. We\ndemonstrate via extensive experiments the utility of our proposed architecture\nboth in single sequence and multiple sequence scenarios.",
    "descriptor": "",
    "authors": [
      "Avinash Achar",
      "Soumen Pachal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04113"
  },
  {
    "id": "arXiv:2207.04115",
    "title": "Vertex Sparsifiers for Hyperedge Connectivity",
    "abstract": "Recently, Chalermsook et al. [SODA'21(arXiv:2007.07862)] introduces a notion\nof vertex sparsifiers for $c$-edge connectivity, which has found applications\nin parameterized algorithms for network design and also led to exciting dynamic\nalgorithms for $c$-edge st-connectivity [Jin and Sun\nFOCS'22(arXiv:2004.07650)]. We study a natural extension called vertex\nsparsifiers for $c$-hyperedge connectivity and construct a sparsifier whose\nsize matches the state-of-the-art for normal graphs. More specifically, we show\nthat, given a hypergraph $G=(V,E)$ with $n$ vertices and $m$ hyperedges with\n$k$ terminal vertices and a parameter $c$, there exists a hypergraph $H$\ncontaining only $O(kc^{3})$ hyperedges that preserves all minimum cuts (up to\nvalue $c$) between all subset of terminals. This matches the best bound of\n$O(kc^{3})$ edges for normal graphs by [Liu'20(arXiv:2011.15101)]. Moreover,\n$H$ can be constructed in almost-linear $O(p^{1+o(1)} + n(rc\\log n)^{O(rc)}\\log\nm)$ time where $r=\\max_{e\\in E}|e|$ is the rank of $G$ and $p=\\sum_{e\\in E}|e|$\nis the total size of $G$, or in $\\text{poly}(m, n)$ time if we slightly relax\nthe size to $O(kc^{3}\\log^{1.5}(kc))$ hyperedges.",
    "descriptor": "\nComments: submitted to ESA 2022\n",
    "authors": [
      "Han Jiang",
      "Shang-En Huang",
      "Thatchaphol Saranurak",
      "Tian Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.04115"
  },
  {
    "id": "arXiv:2207.04117",
    "title": "Ablation Study of How Run Time Assurance Impacts the Training and  Performance of Reinforcement Learning Agents",
    "abstract": "Reinforcement Learning (RL) has become an increasingly important research\narea as the success of machine learning algorithms and methods grows. To combat\nthe safety concerns surrounding the freedom given to RL agents while training,\nthere has been an increase in work concerning Safe Reinforcement Learning\n(SRL). However, these new and safe methods have been held to less scrutiny than\ntheir unsafe counterparts. For instance, comparisons among safe methods often\nlack fair evaluation across similar initial condition bounds and hyperparameter\nsettings, use poor evaluation metrics, and cherry-pick the best training runs\nrather than averaging over multiple random seeds. In this work, we conduct an\nablation study using evaluation best practices to investigate the impact of run\ntime assurance (RTA), which monitors the system state and intervenes to assure\nsafety, on effective learning. By studying multiple RTA approaches in both\non-policy and off-policy RL algorithms, we seek to understand which RTA methods\nare most effective, whether the agents become dependent on the RTA, and the\nimportance of reward shaping versus safe exploration in RL agent training. Our\nconclusions shed light on the most promising directions of SRL, and our\nevaluation methodology lays the groundwork for creating better comparisons in\nfuture SRL work.",
    "descriptor": "",
    "authors": [
      "Nathaniel Hamilton",
      "Kyle Dunlap",
      "Taylor T Johnson",
      "Kerianne L Hobbs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04117"
  },
  {
    "id": "arXiv:2207.04118",
    "title": "Automatic Exploration of Textual Environments with Language-Conditioned  Autotelic Agents",
    "abstract": "In this extended abstract we discuss the opportunities and challenges of\nstudying intrinsically-motivated agents for exploration in textual\nenvironments. We argue that there is important synergy between text\nenvironments and autonomous agents. We identify key properties of text worlds\nthat make them suitable for exploration by autonmous agents, namely, depth,\nbreadth, progress niches and the ease of use of language goals; we identify\ndrivers of exploration for such agents that are implementable in text worlds.\nWe discuss the opportunities of using autonomous agents to make progress on\ntext environment benchmarks. Finally we list some specific challenges that need\nto be overcome in this area.",
    "descriptor": "",
    "authors": [
      "Laetitia Teodorescu",
      "Eric Yuan",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04118"
  },
  {
    "id": "arXiv:2207.04121",
    "title": "Braid-based architecture search",
    "abstract": "In this article, we propose the approach to structural optimization of neural\nnetworks, based on the braid theory. The paper describes the basics of braid\ntheory as applied to the description of graph structures of neural networks. It\nis shown how networks of various topologies can be built using braid structures\nbetween layers of neural networks. The operation of a neural network based on\nthe braid theory is compared with a homogeneous deep neural network and a\nnetwork with random intersections between layers that do not correspond to the\nordering of the braids. Results are obtained showing the advantage of\nbraid-based networks over comparable architectures in classification problems.",
    "descriptor": "\nComments: 10 pages, 8 figures, PRICAI-2022 conference. arXiv admin note: substantial text overlap with arXiv:2104.10010\n",
    "authors": [
      "Olga Lukyanova",
      "Oleg Nikitin",
      "Alex Kunin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.04121"
  },
  {
    "id": "arXiv:2207.04122",
    "title": "Sudowoodo: Contrastive Self-supervised Learning for Multi-purpose Data  Integration and Preparation",
    "abstract": "Machine learning (ML) is playing an increasingly important role in data\nmanagement tasks, particularly in Data Integration and Preparation (DI&P). The\nsuccess of ML-based approaches, however, heavily relies on the availability of\nlarge-scale, high-quality labeled datasets for different tasks. Moreover, the\nwide variety of DI&P tasks and pipelines oftentimes requires customizing ML\nsolutions which can incur a significant cost for model engineering and\nexperimentation. These factors inevitably hold back the adoption of ML-based\napproaches to new domains and tasks.\nIn this paper, we propose Sudowoodo, a multi-purpose DI&P framework based on\ncontrastive representation learning. Sudowoodo features a unified,\nmatching-based problem definition capturing a wide range of DI&P tasks\nincluding Entity Matching (EM) in data integration, error correction in data\ncleaning, semantic type detection in data discovery, and more. Contrastive\nlearning enables Sudowoodo to learn similarity-aware data representations from\na large corpus of data items (e.g., entity entries, table columns) without\nusing any labels. The learned representations can later be either directly used\nor facilitate fine-tuning with only a few labels to support different DI&P\ntasks. Our experiment results show that Sudowoodo achieves multiple\nstate-of-the-art results on different levels of supervision and outperforms\nprevious best specialized blocking or matching solutions for EM. Sudowoodo also\nachieves promising results in data cleaning and semantic type detection tasks\nshowing its versatility in DI&P applications.",
    "descriptor": "",
    "authors": [
      "Runhui Wang",
      "Yuliang Li",
      "Jin Wang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.04122"
  },
  {
    "id": "arXiv:2207.04125",
    "title": "Out of Distribution Detection via Neural Network Anchoring",
    "abstract": "Our goal in this paper is to exploit heteroscedastic temperature scaling as a\ncalibration strategy for out of distribution (OOD) detection.\nHeteroscedasticity here refers to the fact that the optimal temperature\nparameter for each sample can be different, as opposed to conventional\napproaches that use the same value for the entire distribution. To enable this,\nwe propose a new training strategy called anchoring that can estimate\nappropriate temperature values for each sample, leading to state-of-the-art OOD\ndetection performance across several benchmarks. Using NTK theory, we show that\nthis temperature function estimate is closely linked to the epistemic\nuncertainty of the classifier, which explains its behavior. In contrast to some\nof the best-performing OOD detection approaches, our method does not require\nexposure to additional outlier datasets, custom calibration objectives, or\nmodel ensembling. Through empirical studies with different OOD detection\nsettings -- far OOD, near OOD, and semantically coherent OOD - we establish a\nhighly effective OOD detection approach. Code and models can be accessed here\n-- https://github.com/rushilanirudh/AMP",
    "descriptor": "",
    "authors": [
      "Rushil Anirudh",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04125"
  },
  {
    "id": "arXiv:2207.04129",
    "title": "Not all broken defenses are equal: The dead angles of adversarial  accuracy",
    "abstract": "Robustness to adversarial attack is typically evaluated with adversarial\naccuracy. This metric is however too coarse to properly capture all robustness\nproperties of machine learning models. Many defenses, when evaluated against a\nstrong attack, do not provide accuracy improvements while still contributing\npartially to adversarial robustness. Popular certification methods suffer from\nthe same issue, as they provide a lower bound to accuracy. To capture finer\nrobustness properties we propose a new metric for L2 robustness, adversarial\nangular sparsity, which partially answers the question \"how many adversarial\nexamples are there around an input\". We demonstrate its usefulness by\nevaluating both \"strong\" and \"weak\" defenses. We show that some\nstate-of-the-art defenses, delivering very similar accuracy, can have very\ndifferent sparsity on the inputs that they are not robust on. We also show that\nsome weak defenses actually decrease robustness, while others strengthen it in\na measure that accuracy cannot capture. These differences are predictive of how\nuseful such defenses can become when combined with adversarial training.",
    "descriptor": "",
    "authors": [
      "Raphael Olivier",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.04129"
  },
  {
    "id": "arXiv:2207.04132",
    "title": "Cross-Attention Transformer for Video Interpolation",
    "abstract": "We propose TAIN (Transformers and Attention for video INterpolation), a\nresidual neural network for video interpolation, which aims to interpolate an\nintermediate frame given two consecutive image frames around it. We first\npresent a novel visual transformer module, named Cross-Similarity (CS), to\nglobally aggregate input image features with similar appearance as those of the\npredicted interpolated frame. These CS features are then used to refine the\ninterpolated prediction. To account for occlusions in the CS features, we\npropose an Image Attention (IA) module to allow the network to focus on CS\nfeatures from one frame over those of the other. Additionally, we augment our\ntraining dataset with an occluder patch that moves across frames to improve the\nnetwork's robustness to occlusions and large motion. Because existing methods\nyield smooth predictions especially near MBs, we use an additional training\nloss based on image gradient to yield sharper predictions. TAIN outperforms\nexisting methods that do not require flow estimation and performs comparably to\nflow-based methods while being computationally efficient in terms of inference\ntime on Vimeo90k, UCF101, and SNU-FILM benchmarks.",
    "descriptor": "",
    "authors": [
      "Hannah Halin Kim",
      "Shuzhi Yu",
      "Shuai Yuan",
      "Carlo Tomasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04132"
  },
  {
    "id": "arXiv:2207.04134",
    "title": "Modeling and Predicting Transistor Aging under Workload Dependency using  Machine Learning",
    "abstract": "The pivotal issue of reliability is one of colossal concern for circuit\ndesigners. The driving force is transistor aging, dependent on operating\nvoltage and workload. At the design time, it is difficult to estimate\nclose-to-the-edge guardbands that keep aging effects during the lifetime at\nbay. This is because the foundry does not share its calibrated physics-based\nmodels, comprised of highly confidential technology and material parameters.\nHowever, the unmonitored yet necessary overestimation of degradation amounts to\na performance decline, which could be preventable. Furthermore, these\nphysics-based models are exceptionally computationally complex. The costs of\nmodeling millions of individual transistors at design time can be evidently\nexorbitant. We propose the revolutionizing prospect of a machine learning model\ntrained to replicate the physics-based model, such that no confidential\nparameters are disclosed. This effectual workaround is fully accessible to\ncircuit designers for the purposes of design optimization. We demonstrate the\nmodels' ability to generalize by training on data from one circuit and applying\nit successfully to a benchmark circuit. The mean relative error is as low as\n1.7%, with a speedup of up to 20X. Circuit designers, for the first time ever,\nwill have ease of access to a high-precision aging model, which is paramount\nfor efficient designs. This work is a promising step in the direction of\nbridging the wide gulf between the foundry and circuit designers.",
    "descriptor": "",
    "authors": [
      "Paul R. Genssler",
      "Hamza E. Barkam",
      "Karthik Pandaram",
      "Mohsen Imani",
      "Hussam Amrouch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04134"
  },
  {
    "id": "arXiv:2207.04136",
    "title": "CompoSuite: A Compositional Reinforcement Learning Benchmark",
    "abstract": "We present CompoSuite, an open-source simulated robotic manipulation\nbenchmark for compositional multi-task reinforcement learning (RL). Each\nCompoSuite task requires a particular robot arm to manipulate one individual\nobject to achieve a task objective while avoiding an obstacle. This\ncompositional definition of the tasks endows CompoSuite with two remarkable\nproperties. First, varying the robot/object/objective/obstacle elements leads\nto hundreds of RL tasks, each of which requires a meaningfully different\nbehavior. Second, RL approaches can be evaluated specifically for their ability\nto learn the compositional structure of the tasks. This latter capability to\nfunctionally decompose problems would enable intelligent agents to identify and\nexploit commonalities between learning tasks to handle large varieties of\nhighly diverse problems. We benchmark existing single-task, multi-task, and\ncompositional learning algorithms on various training settings, and assess\ntheir capability to compositionally generalize to unseen tasks. Our evaluation\nexposes the shortcomings of existing RL approaches with respect to\ncompositionality and opens new avenues for investigation.",
    "descriptor": "\nComments: Published at 1st Conference on Lifelong Learning Agents, 2022; code: this https URL\n",
    "authors": [
      "Jorge A. Mendez",
      "Marcel Hussing",
      "Meghna Gummadi",
      "Eric Eaton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04136"
  },
  {
    "id": "arXiv:2207.04140",
    "title": "An Outlook on the Future Marine Traffic Management System for Autonomous  Ships",
    "abstract": "In the shipping digitalisation process, the peak will be reached with the\nadvent of a wholly autonomous and at the same time safe and reliable ship. Full\nautonomy could be obtained by two linked Artificial-Intelligence systems\nrepresenting the ship navigator and the ship engineer that possess sensing and\nanalysis skills, situational awareness, planning, and control capabilities.\nMany efforts have been made in developing onboard systems; however, the shore\nfacilities are not ready yet to deal with these new technologies. The paper\naims to present the innovative technologies and methodologies needed to develop\na futuristic Vessel Traffic System. The proposed systems will aim at faultless\ndata acquisition and processing, provide input to decision-making systems, and\nsuggest evasive manoeuvre; to deal with hazards and systems failure without\nhuman intervention onboard. The system is composed of three different and\ninteracting layers. The first is an artificially intelligent tool to detect and\ncontrol autonomous ships, thanks to situation recognition and obstacle\navoidance strategies. The second is an orchestration and management platform\ndesigned to coordinate the sensing-actuation infrastructure and the AI\nalgorithms results made available by multiple ships, mustering edge, and\ndistributed computing techniques to fulfil the specific harsh requirements of\nthe sea environment. The final part is a holistic guidance-navigation-control\nframework to manage autonomous ships navigation in a crowded area. Eventually,\na cyber-physical scenario, using both a ship digital-twin and a real\nmodel-scale ship, is suggested to test and validate the innovative system\nwithout the availability of a full-scale scenario.",
    "descriptor": "",
    "authors": [
      "Michele Martelli",
      "Antonio Virdis",
      "Alberto Gotta",
      "Pietro Cassar\u00c0",
      "Maria Di Summa"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.04140"
  },
  {
    "id": "arXiv:2207.04143",
    "title": "Interactive Recommendations for Optimal Allocations in Markets with  Constraints",
    "abstract": "Recommendation systems when employed in markets play a dual role: they assist\nusers in selecting their most desired items from a large pool and they help in\nallocating a limited number of items to the users who desire them the most.\nDespite the prevalence of capacity constraints on allocations in many\nreal-world recommendation settings, a principled way of incorporating them in\nthe design of these systems has been lacking. Motivated by this, we propose an\ninteractive framework where the system provider can enhance the quality of\nrecommendations to the users by opportunistically exploring allocations that\nmaximize user rewards and respect the capacity constraints using appropriate\npricing mechanisms. We model the problem as an instance of a low-rank\ncombinatorial multi-armed bandit problem with selection constraints on the\narms. We employ an integrated approach using techniques from collaborative\nfiltering, combinatorial bandits, and optimal resource allocation to provide an\nalgorithm that provably achieves sub-linear regret, namely $\\tilde{\\mathcal{O}}\n( \\sqrt{N M (N+M) RT} )$ in $T$ rounds for a problem with $N$ users, $M$ items\nand rank $R$ mean reward matrix. Empirical studies on synthetic and real-world\ndata also demonstrate the effectiveness and performance of our approach.",
    "descriptor": "",
    "authors": [
      "Yigit Efe Erginbas",
      "Soham Phade",
      "Kannan Ramchandran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.04143"
  },
  {
    "id": "arXiv:2207.04144",
    "title": "L$_0$onie: Compressing COINs with L$_0$-constraints",
    "abstract": "Advances in Implicit Neural Representations (INR) have motivated research on\ndomain-agnostic compression techniques. These methods train a neural network to\napproximate an object, and then store the weights of the trained model. For\nexample, given an image, a network is trained to learn the mapping from pixel\nlocations to RGB values. In this paper, we propose L$_0$onie, a\nsparsity-constrained extension of the COIN compression method. Sparsity allows\nto leverage the faster learning of overparameterized networks, while retaining\nthe desirable compression rate of smaller models. Moreover, our constrained\nformulation ensures that the final model respects a pre-determined compression\nrate, dispensing of the need for expensive architecture search.",
    "descriptor": "\nComments: Presented at the Sparsity in Neural Networks (SNN) Workshop 2022. Code available at this https URL\n",
    "authors": [
      "Juan Ramirez",
      "Jose Gallego-Posada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04144"
  },
  {
    "id": "arXiv:2207.04145",
    "title": "Strong Anonymity for Mesh Messaging",
    "abstract": "Messaging systems built on mesh networks consisting of smartphones\ncommunicating over Bluetooth have been used by protesters around the world\nafter governments have disrupted Internet connectivity. Unfortunately, existing\nsystems have been shown to be insecure; most concerningly by not adequately\nhiding metadata. This is further complicated by the fact that wireless\ncommunication such as Bluetooth is inherently a broadcasting medium. In this\npaper, we present a new threat model that captures the security requirements of\nprotesters in this setting. We then provide a solution that satisfies the\nrequired security properties, hides all relevant metadata, scales to moderately\nsized protests, and supports group messaging. This is achieved by broadcasting\nall messages in a way that limits the overhead of duplicate messages, ensuring\nthat ciphertexts do not leak metadata, and limiting what can be learned by\nobserving user behavior. We also build a model of our system and numerically\nevaluate it to support our claims and analyze how many users it supports.\nFinally, we discuss further extensions that remove potential bottlenecks in\nscaling and support substantially more users.",
    "descriptor": "\nComments: 21 pages, 11 figures\n",
    "authors": [
      "Neil Perry",
      "Bruce Spang",
      "Saba Eskandarian",
      "Dan Boneh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04145"
  },
  {
    "id": "arXiv:2207.04146",
    "title": "Information Rates with Non Ideal Photon Detectors in Time-Entanglement  Based QKD",
    "abstract": "We develop new methods of quantifying the impact of photon detector\nimperfections on achievable secret key rates in Time-Entanglement based Quantum\nKey Distribution (QKD). We address photon detection timing jitter, detector\ndowntime, and photon dark counts and show how each may decrease the maximum\nachievable secret key rate in different ways. We begin with a standard Discrete\nMemoryless Channel (DMC) model to get a good bound on the mutual information\nlost due to the timing jitter, then introduce a novel Markov Chain (MC) based\nmodel to characterize the effect of detector downtime and show how it\nintroduces memory to the key generation process. Finally, we propose a new\nmethod of including dark counts in the analysis that shows how dark counts can\nbe especially detrimental when using the common Pulse Position Modulation (PPM)\nfor key generation. Our results show that these three imperfections can\nsignificantly reduce the achievable secret key rate when using PPM for QKD.\nAdditionally, one of our main results is providing tooling for experimentalists\nto predict their systems' achievable secret key rate given the detector\nspecifications.",
    "descriptor": "",
    "authors": [
      "Dunbar Birnie IV",
      "Christopher Cheng",
      "Emina Soljanin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.04146"
  },
  {
    "id": "arXiv:2207.04148",
    "title": "Exploring Machine Learning for Classification of QUIC Flows over  Satellite",
    "abstract": "Automatic traffic classification is increasingly important in networking due\nto the current trend of encrypting transport information (e.g., behind HTTP\nencrypted tunnels) which prevents intermediate nodes to access end-to-end\ntransport headers. This paper proposes an architecture for supporting Quality\nof Service (QoS) in hybrid terrestrial and SATCOM networks based on automated\ntraffic classification. Traffic profiles are constructed by machine-learning\n(ML) algorithms using the series of packet sizes and arrival times of QUIC\nconnections. Thus, the proposed QoS method does not require an explicit setup\nof a path (i.e. it provides soft QoS), but employs agents within the network to\nverify that flows conform to a given traffic profile. Results over a range of\nML models encourage integrating ML technology in SATCOM equipment. The\navailability of higher computation power at a low cost creates fertile ground\nfor the implementation of these techniques.",
    "descriptor": "",
    "authors": [
      "Raffaello Secchi",
      "Pietro Cassar\u00e0",
      "Alberto Gotta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.04148"
  },
  {
    "id": "arXiv:2207.04149",
    "title": "Cyber-Physical Attack Leveraging Subsynchronous Resonance",
    "abstract": "This paper discusses how a cyber attack could take advantage of torsional\nresonances in the shaft of turbo-generators to inflict severe physical damage\nto a power system. If attackers were able to take over the control of a battery\nenergy storage device, they could modulate the injection of this device at a\nfrequency that matches one of the sub-synchronous resonance frequencies of a\ngenerator. Small changes in injection might be sufficient to excite one of\nthese mechanical resonances, resulting in metal fatigue and ultimately a\ncatastrophic failure in the shaft of the generator. Using a state-space model\nof the electromechanical system, the paper develops transfer functions linking\nthe magnitude of the malicious injections to the magnitude of oscillations in\nthe speed and angle of the various masses connected to the shaft. Numerical\nresults from a two-area power system demonstrate the existence of vulnerable\nfrequencies and show that damaging mechanical oscillations can be triggered\nwithout causing easily detectable signals at the generator terminals.",
    "descriptor": "\nComments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Bosong Li",
      "Baosen Zhang",
      "Daniel S. Kirschen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04149"
  },
  {
    "id": "arXiv:2207.04153",
    "title": "Probing Classifiers are Unreliable for Concept Removal and Detection",
    "abstract": "Neural network models trained on text data have been found to encode\nundesired linguistic or sensitive attributes in their representation. Removing\nsuch attributes is non-trivial because of a complex relationship between the\nattribute, text input, and the learnt representation. Recent work has proposed\npost-hoc and adversarial methods to remove such unwanted attributes from a\nmodel's representation. Through an extensive theoretical and empirical\nanalysis, we show that these methods can be counter-productive: they are unable\nto remove the attributes entirely, and in the worst case may end up destroying\nall task-relevant features. The reason is the methods' reliance on a probing\nclassifier as a proxy for the attribute. Even under the most favorable\nconditions when an attribute's features in representation space can alone\nprovide 100% accuracy for learning the probing classifier, we prove that\npost-hoc or adversarial methods will fail to remove the attribute correctly.\nThese theoretical implications are confirmed by empirical experiments on models\ntrained on synthetic, Multi-NLI, and Twitter datasets. For sensitive\napplications of attribute removal such as fairness, we recommend caution\nagainst using these methods and propose a spuriousness metric to gauge the\nquality of the final classifier.",
    "descriptor": "",
    "authors": [
      "Abhinav Kumar",
      "Chenhao Tan",
      "Amit Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04153"
  },
  {
    "id": "arXiv:2207.04154",
    "title": "TalkToModel: Understanding Machine Learning Models With Open Ended  Dialogues",
    "abstract": "Machine Learning (ML) models are increasingly used to make critical decisions\nin real-world applications, yet they have also become more complex, making them\nharder to understand. To this end, several techniques to explain model\npredictions have been proposed. However, practitioners struggle to leverage\nexplanations because they often do not know which to use, how to interpret the\nresults, and may have insufficient data science experience to obtain\nexplanations. In addition, most current works focus on generating one-shot\nexplanations and do not allow users to follow up and ask fine-grained questions\nabout the explanations, which can be frustrating. In this work, we address\nthese challenges by introducing TalkToModel: an open-ended dialogue system for\nunderstanding machine learning models. Specifically, TalkToModel comprises\nthree key components: 1) a natural language interface for engaging in\ndialogues, making understanding ML models highly accessible, 2) a dialogue\nengine that adapts to any tabular model and dataset, interprets natural\nlanguage, maps it to appropriate operations (e.g., feature importance\nexplanations, counterfactual explanations, showing model errors), and generates\ntext responses, and 3) an execution component that run the operations and\nensures explanations are accurate. We carried out quantitative and human\nsubject evaluations of TalkToModel. We found the system understands user\nquestions on novel datasets and models with high accuracy, demonstrating the\nsystem's capacity to generalize to new situations. In human evaluations, 73% of\nhealthcare workers (e.g., doctors and nurses) agreed they would use TalkToModel\nover baseline point-and-click systems, and 84.6% of ML graduate students agreed\nTalkToModel was easier to use.",
    "descriptor": "\nComments: Pre-print; comments welcome! Reach out to dslack@uci.edu\n",
    "authors": [
      "Dylan Slack",
      "Satyapriya Krishna",
      "Himabindu Lakkaraju",
      "Sameer Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04154"
  },
  {
    "id": "arXiv:2207.04156",
    "title": "Automated Audio Captioning and Language-Based Audio Retrieval",
    "abstract": "This project involved participation in the DCASE 2022 Competition (Task 6)\nwhich had two subtasks: (1) Automated Audio Captioning and (2) Language-Based\nAudio Retrieval. The first subtask involved the generation of a textual\ndescription for audio samples, while the goal of the second was to find audio\nsamples within a fixed dataset that match a given description. For both\nsubtasks, the Clotho dataset was used. The models were evaluated on BLEU1,\nBLEU2, BLEU3, ROUGEL, METEOR, CIDEr, SPICE, and SPIDEr scores for audio\ncaptioning and R1, R5, R10 and mARP10 scores for audio retrieval. We have\nconducted a handful of experiments that modify the baseline models for these\ntasks. Our final architecture for Automated Audio Captioning is close to the\nbaseline performance, while our model for Language-Based Audio Retrieval has\nsurpassed its counterpart.",
    "descriptor": "\nComments: DCASE 2022 Competition (Task 6)\n",
    "authors": [
      "Clive Gomes",
      "Hyejin Park",
      "Patrick Kollman",
      "Yi Song"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04156"
  },
  {
    "id": "arXiv:2207.04158",
    "title": "A Survey of Task-Based Machine Learning Content Extraction Services for  VIDINT",
    "abstract": "This paper provides a comparison of current video content extraction tools\nwith a focus on comparing commercial task-based machine learning services.\nVideo intelligence (VIDINT) data has become a critical intelligence source in\nthe past decade. The need for AI-based analytics and automation tools to\nextract and structure content from video has quickly become a priority for\norganizations needing to search, analyze and exploit video at scale. With rapid\ngrowth in machine learning technology, the maturity of machine transcription,\nmachine translation, topic tagging, and object recognition tasks are improving\nat an exponential rate, breaking performance records in speed and accuracy as\nnew applications evolve. Each section of this paper reviews and compares\nproducts, software resources and video analytics capabilities based on tasks\nrelevant to extracting information from video with machine learning techniques.",
    "descriptor": "",
    "authors": [
      "Joshua Brunk",
      "Nathan Jermann",
      "Ryan Sharp",
      "Carl D. Hoover"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.04158"
  },
  {
    "id": "arXiv:2207.04159",
    "title": "The SPEC-RG Reference Architecture for the Edge Continuum",
    "abstract": "Edge computing promises lower processing latencies and better privacy control\nthan cloud computing for task offloading as edge devices are positioned closer\nto users. Realizing this promise depends on building strong theoretical and\nengineering foundations of computing based on an edge continuum connecting edge\nto other resources. In the SPEC-RG Cloud Group, we conducted a systematic study\nof computing models for task offloading and found that these models have many\nshared characteristics. Despite these commonalities, no systematic model or\narchitecture for task offloading currently exists. In this paper, we address\nthis need by proposing a reference architecture for task offloading in the edge\ncontinuum and synthesize its components using well-understood abstractions,\nservices, and resources from cloud computing. We provide domain-specific\narchitectures for deep learning and industrial IoT and show how this unified\ncomputing model opens up application development as developers are no longer\nlimited to the single set of constraints posed by current isolated computing\nmodels. Additionally, we demonstrate the utility of the architecture by\ndesigning a deployment and benchmarking framework for edge continuum\napplications and investigate the performance of various edge continuum\ndeployments. The framework allows for fine-grained discovery of the edge\ncontinuum deployment space, including the emulation of complex networks, all\nwith minimal user input required. To enhance the performance analysis\ncapabilities of the benchmark, we introduce an analytical first-order\nperformance model that can be used to explore multiple application deployment\nscenarios such as local processing on endpoints or offloading between cloud or\nedge. The deployment and benchmarking framework is open-sourced and available\nat https://github.com/atlarge-research/continuum.",
    "descriptor": "\nComments: 14 pages, SPEC-RG technical report\n",
    "authors": [
      "Matthijs Jansen",
      "Auday Al-Dulaimy",
      "Alessandro V. Papadopoulos",
      "Animesh Trivedi",
      "Alexandru Iosup"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.04159"
  },
  {
    "id": "arXiv:2207.04161",
    "title": "Few 'Zero Level Set'-Shot Learning of Shape Signed Distance Functions in  Feature Space",
    "abstract": "We explore a new idea for learning based shape reconstruction from a point\ncloud, based on the recently popularized implicit neural shape representations.\nWe cast the problem as a few-shot learning of implicit neural signed distance\nfunctions in feature space, that we approach using gradient based\nmeta-learning. We use a convolutional encoder to build a feature space given\nthe input point cloud. An implicit decoder learns to predict signed distance\nvalues given points represented in this feature space. Setting the input point\ncloud, i.e. samples from the target shape function's zero level set, as the\nsupport (i.e. context) in few-shot learning terms, we train the decoder such\nthat it can adapt its weights to the underlying shape of this context with a\nfew (5) tuning steps. We thus combine two types of implicit neural network\nconditioning mechanisms simultaneously for the first time, namely feature\nencoding and meta-learning. Our numerical and qualitative evaluation shows that\nin the context of implicit reconstruction from a sparse point cloud, our\nproposed strategy, i.e. meta-learning in feature space, outperforms existing\nalternatives, namely standard supervised learning in feature space, and\nmeta-learning in euclidean space, while still providing fast inference.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Amine Ouasfi",
      "Adnane Boukhayma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04161"
  },
  {
    "id": "arXiv:2207.04163",
    "title": "Optimizing Bipedal Maneuvers of Single Rigid-Body Models for  Reinforcement Learning",
    "abstract": "In this work, we propose a method to generate reduced-order model reference\ntrajectories for general classes of highly dynamic maneuvers for bipedal robots\nfor use in sim-to-real reinforcement learning. Our approach is to utilize a\nsingle rigid-body model (SRBM) to optimize libraries of trajectories offline to\nbe used as expert references in the reward function of a learned policy. This\nmethod translates the model's dynamically rich rotational and translational\nbehaviour to a full-order robot model and successfully transfers to real\nhardware. The SRBM's simplicity allows for fast iteration and refinement of\nbehaviors, while the robustness of learning-based controllers allows for highly\ndynamic motions to be transferred to hardware. % Within this work we introduce\na set of transferability constraints that amend the SRBM dynamics to actual\nbipedal robot hardware, our framework for creating optimal trajectories for\ndynamic stepping, turning maneuvers and jumps as well as our approach to\nintegrating reference trajectories to a reinforcement learning policy. Within\nthis work we introduce a set of transferability constraints that amend the SRBM\ndynamics to actual bipedal robot hardware, our framework for creating optimal\ntrajectories for a variety of highly dynamic maneuvers as well as our approach\nto integrating reference trajectories for a high-speed running reinforcement\nlearning policy. We validate our methods on the bipedal robot Cassie on which\nwe were successfully able to demonstrate highly dynamic grounded running gaits\nup to 3.0 m/s.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Ryan Batke",
      "Fangzhou Yu",
      "Jeremy Dao",
      "Jonathan Hurst",
      "Ross L. Hatton",
      "Alan Fern",
      "Kevin Green"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04163"
  },
  {
    "id": "arXiv:2207.04165",
    "title": "Extracting Replayable Interactions from Videos of Mobile App Usage",
    "abstract": "Screen recordings of mobile apps are a popular and readily available way for\nusers to share how they interact with apps, such as in online tutorial videos,\nuser reviews, or as attachments in bug reports. Unfortunately, both people and\nsystems can find it difficult to reproduce touch-driven interactions from video\npixel data alone. In this paper, we introduce an approach to extract and replay\nuser interactions in videos of mobile apps, using only pixel information in\nvideo frames. To identify interactions, we apply heuristic-based image\nprocessing and convolutional deep learning to segment screen recordings,\nclassify the interaction in each segment, and locate the interaction point. To\nreplay interactions on another device, we match elements on app screens using\nUI element detection. We evaluate the feasibility of our pixel-based approach\nusing two datasets: the Rico mobile app dataset and a new dataset of 64 apps\nwith both iOS and Android versions. We find that our end-to-end approach can\nsuccessfully replay a majority of interactions (iOS--84.1%, Android--78.4%) on\ndifferent devices, which is a step towards supporting a variety of scenarios,\nincluding automatically annotating interactions in existing videos, automated\nUI testing, and creating interactive app tutorials.",
    "descriptor": "",
    "authors": [
      "Jieshan Chen",
      "Amanda Swearngin",
      "Jason Wu",
      "Titus Barik",
      "Jeffrey Nichols",
      "Xiaoyi Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.04165"
  },
  {
    "id": "arXiv:2207.04166",
    "title": "Variational Mixtures of ODEs for Inferring Cellular Gene Expression  Dynamics",
    "abstract": "A key problem in computational biology is discovering the gene expression\nchanges that regulate cell fate transitions, in which one cell type turns into\nanother. However, each individual cell cannot be tracked longitudinally, and\ncells at the same point in real time may be at different stages of the\ntransition process. This can be viewed as a problem of learning the behavior of\na dynamical system from observations whose times are unknown. Additionally, a\nsingle progenitor cell type often bifurcates into multiple child cell types,\nfurther complicating the problem of modeling the dynamics. To address this\nproblem, we developed an approach called variational mixtures of ordinary\ndifferential equations. By using a simple family of ODEs informed by the\nbiochemistry of gene expression to constrain the likelihood of a deep\ngenerative model, we can simultaneously infer the latent time and latent state\nof each cell and predict its future gene expression state. The model can be\ninterpreted as a mixture of ODEs whose parameters vary continuously across a\nlatent space of cell states. Our approach dramatically improves data fit,\nlatent time inference, and future cell state estimation of single-cell gene\nexpression data compared to previous approaches.",
    "descriptor": "",
    "authors": [
      "Yichen Gu",
      "David Blaauw",
      "Joshua Welch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2207.04166"
  },
  {
    "id": "arXiv:2207.04171",
    "title": "A Systematic Review and Thematic Analysis of Community-Collaborative  Approaches to Computing Research",
    "abstract": "HCI researchers have been gradually shifting attention from individual users\nto communities when engaging in research, design, and system development.\nHowever, our field has yet to establish a cohesive, systematic understanding of\nthe challenges, benefits, and commitments of community-collaborative approaches\nto research. We conducted a systematic review and thematic analysis of 47\ncomputing research papers discussing participatory research with communities\nfor the development of technological artifacts and systems, published over the\nlast two decades. From this review, we identified seven themes associated with\nthe evolution of a project: from establishing community partnerships to\nsustaining results. Our findings suggest that several tensions characterize\nthese projects, many of which relate to the power and position of researchers,\nand the computing research environment, relative to community partners. We\ndiscuss the implications of our findings and offer methodological proposals to\nguide HCI, and computing research more broadly, towards practices that center\ncommunities.",
    "descriptor": "",
    "authors": [
      "Ned Cooper",
      "Tiffanie Horne",
      "Gillian Hayes",
      "Courtney Heldreth",
      "Michal Lahav",
      "Jess Scon Holbrook",
      "Lauren Wilcox"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.04171"
  },
  {
    "id": "arXiv:2207.04172",
    "title": "Auction for Double-Wide Ads",
    "abstract": "We propose an auction for online advertising where each ad occupies either\none square or two horizontally-adjacent squares of a grid of squares. Our\nprimary application are ads for products shown on retail websites such as\nInstacart or Amazon where the products are naturally organized into a grid. We\npropose efficient algorithms for computing the optimal layout of the ads and\npricing of the ads. The auction is a generalization of the generalized\nsecond-price (GSP) auction used by internet search engines (e.g. Google,\nMicrosoft Bing, Yahoo!).",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Jonathan Gu",
      "David Pal",
      "Kevin Ryan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.04172"
  },
  {
    "id": "arXiv:2207.04174",
    "title": "Towards Multimodal Vision-Language Models Generating Non-Generic Text",
    "abstract": "Vision-language models can assess visual context in an image and generate\ndescriptive text. While the generated text may be accurate and syntactically\ncorrect, it is often overly general. To address this, recent work has used\noptical character recognition to supplement visual information with text\nextracted from an image. In this work, we contend that vision-language models\ncan benefit from additional information that can be extracted from an image,\nbut are not used by current models. We modify previous multimodal frameworks to\naccept relevant information from any number of auxiliary classifiers. In\nparticular, we focus on person names as an additional set of tokens and create\na novel image-caption dataset to facilitate captioning with person names. The\ndataset, Politicians and Athletes in Captions (PAC), consists of captioned\nimages of well-known people in context. By fine-tuning pretrained models with\nthis dataset, we demonstrate a model that can naturally integrate facial\nrecognition tokens into generated text by training on limited data. For the PAC\ndataset, we provide a discussion on collection and baseline benchmark scores.",
    "descriptor": "",
    "authors": [
      "Wes Robbins",
      "Zanyar Zohourianshahzadi",
      "Jugal Kalita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04174"
  },
  {
    "id": "arXiv:2207.04175",
    "title": "Direct Handheld Burst Imaging to Simulated Defocus",
    "abstract": "A shallow depth-of-field image keeps the subject in focus, and the foreground\nand background contexts blurred. This effect requires much larger lens\napertures than those of smartphone cameras. Conventional methods acquire RGB-D\nimages and blur image regions based on their depth. However, this approach is\nnot suitable for reflective or transparent surfaces, or finely detailed object\nsilhouettes, where the depth value is inaccurate or ambiguous.\nWe present a learning-based method to synthesize the defocus blur in shallow\ndepth-of-field images from handheld bursts acquired with a single small\naperture lens. Our deep learning model directly produces the shallow\ndepth-of-field image, avoiding explicit depth-based blurring. The simulated\naperture diameter equals the camera translation during burst acquisition. Our\nmethod does not suffer from artifacts due to inaccurate or ambiguous depth\nestimation, and it is well-suited to portrait photography.",
    "descriptor": "\nComments: ICIP 2022\n",
    "authors": [
      "Meng-Lin Wu",
      "Venkata Ravi Kiran Dayana",
      "Hau Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04175"
  },
  {
    "id": "arXiv:2207.04179",
    "title": "Transformer Neural Processes: Uncertainty-Aware Meta Learning Via  Sequence Modeling",
    "abstract": "Neural Processes (NPs) are a popular class of approaches for meta-learning.\nSimilar to Gaussian Processes (GPs), NPs define distributions over functions\nand can estimate uncertainty in their predictions. However, unlike GPs, NPs and\ntheir variants suffer from underfitting and often have intractable likelihoods,\nwhich limit their applications in sequential decision making. We propose\nTransformer Neural Processes (TNPs), a new member of the NP family that casts\nuncertainty-aware meta learning as a sequence modeling problem. We learn TNPs\nvia an autoregressive likelihood-based objective and instantiate it with a\nnovel transformer-based architecture. The model architecture respects the\ninductive biases inherent to the problem structure, such as invariance to the\nobserved data points and equivariance to the unobserved points. We further\ninvestigate knobs within the TNP framework that tradeoff expressivity of the\ndecoding distribution with extra computation. Empirically, we show that TNPs\nachieve state-of-the-art performance on various benchmark problems,\noutperforming all previous NP variants on meta regression, image completion,\ncontextual multi-armed bandits, and Bayesian optimization.",
    "descriptor": "\nComments: International Conference on Machine Learning 2022\n",
    "authors": [
      "Tung Nguyen",
      "Aditya Grover"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04179"
  },
  {
    "id": "arXiv:2207.04182",
    "title": "Explainable Legal Case Matching via Inverse Optimal Transport-based  Rationale Extraction",
    "abstract": "As an essential operation of legal retrieval, legal case matching plays a\ncentral role in intelligent legal systems. This task has a high demand on the\nexplainability of matching results because of its critical impacts on\ndownstream applications -- the matched legal cases may provide supportive\nevidence for the judgments of target cases and thus influence the fairness and\njustice of legal decisions. Focusing on this challenging task, we propose a\nnovel and explainable method, namely \\textit{IOT-Match}, with the help of\ncomputational optimal transport, which formulates the legal case matching\nproblem as an inverse optimal transport (IOT) problem. Different from most\nexisting methods, which merely focus on the sentence-level semantic similarity\nbetween legal cases, our IOT-Match learns to extract rationales from paired\nlegal cases based on both semantics and legal characteristics of their\nsentences. The extracted rationales are further applied to generate faithful\nexplanations and conduct matching. Moreover, the proposed IOT-Match is robust\nto the alignment label insufficiency issue commonly in practical legal case\nmatching tasks, which is suitable for both supervised and semi-supervised\nlearning paradigms. To demonstrate the superiority of our IOT-Match method and\nconstruct a benchmark of explainable legal case matching task, we not only\nextend the well-known Challenge of AI in Law (CAIL) dataset but also build a\nnew Explainable Legal cAse Matching (ELAM) dataset, which contains lots of\nlegal cases with detailed and explainable annotations. Experiments on these two\ndatasets show that our IOT-Match outperforms state-of-the-art methods\nconsistently on matching prediction, rationale extraction, and explanation\ngeneration.",
    "descriptor": "\nComments: to be published in SIGIR 2022\n",
    "authors": [
      "Weijie Yu",
      "Zhongxiang Sun",
      "Jun Xu",
      "Zhenhua Dong",
      "Xu Chen",
      "Hongteng Xu",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.04182"
  },
  {
    "id": "arXiv:2207.04183",
    "title": "Learning Robust Representation for Joint Grading of Ophthalmic Diseases  via Adaptive Curriculum and Feature Disentanglement",
    "abstract": "Diabetic retinopathy (DR) and diabetic macular edema (DME) are leading causes\nof permanent blindness worldwide. Designing an automatic grading system with\ngood generalization ability for DR and DME is vital in clinical practice.\nHowever, prior works either grade DR or DME independently, without considering\ninternal correlations between them, or grade them jointly by shared feature\nrepresentation, yet ignoring potential generalization issues caused by\ndifficult samples and data bias. Aiming to address these problems, we propose a\nframework for joint grading with the dynamic difficulty-aware weighted loss\n(DAW) and the dual-stream disentangled learning architecture (DETACH). Inspired\nby curriculum learning, DAW learns from simple samples to difficult samples\ndynamically via measuring difficulty adaptively. DETACH separates features of\ngrading tasks to avoid potential emphasis on the bias. With the addition of DAW\nand DETACH, the model learns robust disentangled feature representations to\nexplore internal correlations between DR and DME and achieve better grading\nperformance. Experiments on three benchmarks show the effectiveness and\nrobustness of our framework under both the intra-dataset and cross-dataset\ntests.",
    "descriptor": "\nComments: Accepted by MICCAI22\n",
    "authors": [
      "Haoxuan Che",
      "Haibo Jin",
      "Hao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04183"
  },
  {
    "id": "arXiv:2207.04184",
    "title": "Koopman-Model Predictive Control with Signal Temporal Logic  Specifications for Temperature Regulation of a Warm-Water Supply System",
    "abstract": "Control of warm-water supply for dialysis treatment in a hospital environment\nis typical of safety-critical control problems. In order to guarantee the\ncontinuity of warm-water supply satisfying physical specifications for a wide\nrange of operating conditions, it is inevitable to consider the nonlinearity\ninvolved in a dynamic model of a warm-water supply system for the control\ndesign. In this paper, we propose to incorporate control specifications\ndescribed by signal temporal logic, which is a temporal logic with semantics\nover finite-time signals in formal methods, into the so-called Koopman-Model\nPredictive Control (MPC) as a novel technique of nonlinear MPC based on the\nKoopman operator framework for nonlinear systems. This enables us to generate a\nsequence of optimal inputs such that the controlled state of a nonlinear system\ncan satisfy the specifications. The proposal is applied to the temperature\nregulation of warm-water supply, and its effectiveness is established\nnumerically.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Ryo Miyashita",
      "Yoshihiko Susuki",
      "Atsushi Ishigame"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04184"
  },
  {
    "id": "arXiv:2207.04185",
    "title": "Domain Alignment Meets Fully Test-Time Adaptation",
    "abstract": "A foundational requirement of a deployed ML model is to generalize to data\ndrawn from a testing distribution that is different from training. A popular\nsolution to this problem is to adapt a pre-trained model to novel domains using\nonly unlabeled data. In this paper, we focus on a challenging variant of this\nproblem, where access to the original source data is restricted. While fully\ntest-time adaptation (FTTA) and unsupervised domain adaptation (UDA) are\nclosely related, the advances in UDA are not readily applicable to TTA, since\nmost UDA methods require access to the source data. Hence, we propose a new\napproach, CATTAn, that bridges UDA and FTTA, by relaxing the need to access\nentire source data, through a novel deep subspace alignment strategy. With a\nminimal overhead of storing the subspace basis set for the source data, CATTAn\nenables unsupervised alignment between source and target data during\nadaptation. Through extensive experimental evaluation on multiple 2D and 3D\nvision benchmarks (ImageNet-C, Office-31, OfficeHome, DomainNet, PointDA-10)\nand model architectures, we demonstrate significant gains in FTTA performance.\nFurthermore, we make a number of crucial findings on the utility of the\nalignment objective even with inherently robust models, pre-trained ViT\nrepresentations and under low sample availability in the target domain.",
    "descriptor": "\nComments: 16 Pages including references, 5 figures\n",
    "authors": [
      "Kowshik Thopalli",
      "Pavan Turaga",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04185"
  },
  {
    "id": "arXiv:2207.04186",
    "title": "A Study on Self-Supervised Object Detection Pretraining",
    "abstract": "In this work, we study different approaches to self-supervised pretraining of\nobject detection models. We first design a general framework to learn a\nspatially consistent dense representation from an image, by randomly sampling\nand projecting boxes to each augmented view and maximizing the similarity\nbetween corresponding box features. We study existing design choices in the\nliterature, such as box generation, feature extraction strategies, and using\nmultiple views inspired by its success on instance-level image representation\nlearning techniques. Our results suggest that the method is robust to different\nchoices of hyperparameters, and using multiple views is not as effective as\nshown for instance-level image representation learning. We also design two\nauxiliary tasks to predict boxes in one view from their features in the other\nview, by (1) predicting boxes from the sampled set by using a contrastive loss,\nand (2) predicting box coordinates using a transformer, which potentially\nbenefits downstream object detection tasks. We found that these tasks do not\nlead to better object detection performance when finetuning the pretrained\nmodel on labeled data.",
    "descriptor": "",
    "authors": [
      "Trung Dang",
      "Simon Kornblith",
      "Huy Thong Nguyen",
      "Peter Chin",
      "Maryam Khademi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04186"
  },
  {
    "id": "arXiv:2207.04188",
    "title": "Supervised Machine Learning for Effective Missile Launch Based on Beyond  Visual Range Air Combat Simulations",
    "abstract": "This work compares supervised machine learning methods using reliable data\nfrom constructive simulations to estimate the most effective moment for\nlaunching missiles during air combat. We employed resampling techniques to\nimprove the predictive model, analyzing accuracy, precision, recall, and\nf1-score. Indeed, we could identify the remarkable performance of the models\nbased on decision trees and the significant sensitivity of other algorithms to\nresampling techniques. The models with the best f1-score brought values of\n0.379 and 0.465 without and with the resampling technique, respectively, which\nis an increase of 22.69%. Thus, if desirable, resampling techniques can improve\nthe model's recall and f1-score with a slight decline in accuracy and\nprecision. Therefore, through data obtained through constructive simulations,\nit is possible to develop decision support tools based on machine learning\nmodels, which may improve the flight quality in BVR air combat, increasing the\neffectiveness of offensive missions to hit a particular target.",
    "descriptor": "",
    "authors": [
      "Joao P. A. Dantas",
      "Andre N. Costa",
      "Felipe L. L. Medeiros",
      "Diego Geraldo",
      "Marcos R. O. A. Maximo",
      "Takashi Yoneyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04188"
  },
  {
    "id": "arXiv:2207.04192",
    "title": "Efficient Stackelberg Strategies for Finitely Repeated Games",
    "abstract": "We study the problem of efficiently computing optimal strategies in\nasymmetric leader-follower games repeated a finite number of times, which\npresents a different set of technical challenges than the infinite-horizon\nsetting. More precisely, we give efficient algorithms for finding approximate\nStackelberg equilibria in finite-horizon repeated two-player games, along with\nrates of convergence depending on the horizon $T$. We give two algorithms, one\ncomputing strategies with an optimal $\\frac{1}{T}$ rate at the expense of an\nexponential dependence on the number of actions, and another (randomized)\napproach computing strategies with no dependence on the number of actions but a\nworse dependence on $T$ of $\\frac{1}{T^{0.25}}$. Both algorithms build upon a\nlinear program to produce simple automata leader strategies and induce\ncorresponding automata best-responses for the follower. We complement these\nresults by showing that approximating the Stackelberg value in three-player\nfinite-horizon repeated games is a computationally hard problem via a reduction\nfrom the balanced vertex cover problem.",
    "descriptor": "",
    "authors": [
      "Eshwar Ram Arunachaleswaran",
      "Natalie Collina",
      "Micheal Kearns"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.04192"
  },
  {
    "id": "arXiv:2207.04194",
    "title": "Online algorithms for finding distinct substrings with length and  multiple prefix and suffix conditions",
    "abstract": "Let two static sequences of strings $P$ and $S$, representing prefix and\nsuffix conditions respectively, be given as input for preprocessing. For the\nquery, let two positive integers $k_1$ and $k_2$ be given, as well as a string\n$T$ given in an online manner, such that $T_i$ represents the length-$i$ prefix\nof $T$ for $1 \\leq i \\leq |T|$. In this paper we are interested in computing\nthe set $\\mathit{ans_i}$ of distinct substrings $w$ of $T_i$ such that $k_1\n\\leq |w| \\leq k_2$, and $w$ contains some $p \\in P$ as a prefix and some $s \\in\nS$ as a suffix. Let $\\sigma$ denote the alphabet size. Then, we show that after\n$O((\\Vert P\\Vert +\\Vert S\\Vert)\\log\\sigma)$-time preprocessing, the counting\nproblem of outputting $|\\mathit{ans_i}|$ on each iteration $i$ can be solved in\n$O(|T_i| \\log\\sigma)$ cumulative time, while the reporting problem can be\nsolved in $O(|T_i| \\log\\sigma + |\\mathit{ans_i}|)$ cumulative time, with both\nproblems requiring only $O(|T_i|+\\Vert P\\Vert + \\Vert S\\Vert)$ working space.\nThe preprocessing time can be reduced to $O(\\Vert P\\Vert +\\Vert S\\Vert)$ for\ninteger alphabets of size polynomial with regard to $\\Vert P\\Vert +\\Vert\nS\\Vert$. Here, for a sequence of strings $A$, $\\Vert A\\Vert=\\sum_{u\\in A}|u|$.\nOur algorithms have possible applications to network traffic classification.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Laurentius Leonard",
      "Shunsuke Inenaga",
      "Hideo Bannai",
      "Takuya Mieno"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.04194"
  },
  {
    "id": "arXiv:2207.04196",
    "title": "Robotic Depowdering for Additive Manufacturing via Pose Tracking",
    "abstract": "With the rapid development of powder-based additive manufacturing,\ndepowdering, a process of removing unfused powder that covers 3D-printed parts,\nhas become a major bottleneck to further improve its productiveness.\nTraditional manual depowdering is extremely time-consuming and costly, and some\nprior automated systems either require pre-depowdering or lack adaptability to\ndifferent 3D-printed parts. To solve these problems, we introduce a robotic\nsystem that automatically removes unfused powder from the surface of 3D-printed\nparts. The key component is a visual perception system, which consists of a\npose-tracking module that tracks the 6D pose of powder-occluded parts in\nreal-time, and a progress estimation module that estimates the depowdering\ncompletion percentage. The tracking module can be run efficiently on a laptop\nCPU at up to 60 FPS. Experiments show that our depowdering system can remove\nunfused powder from the surface of various 3D-printed parts without causing any\ndamage. To the best of our knowledge, this is one of the first vision-based\nrobotic depowdering systems that adapt to parts with various shapes without the\nneed for pre-depowdering.",
    "descriptor": "\nComments: The 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems. Video link: this https URL\n",
    "authors": [
      "Zhenwei Liu",
      "Junyi Geng",
      "Xikai Dai",
      "Tomasz Swierzewski",
      "Kenji Shimada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04196"
  },
  {
    "id": "arXiv:2207.04197",
    "title": "Multi-label Classification with High-rank and High-order Label  Correlations",
    "abstract": "Exploiting label correlations is important to multi-label classification.\nPrevious methods capture the high-order label correlations mainly by\ntransforming the label matrix to a latent label space with low-rank matrix\nfactorization. However, the label matrix is generally a full-rank or\napproximate full-rank matrix, making the low-rank factorization inappropriate.\nBesides, in the latent space, the label correlations will become implicit. To\nthis end, we propose a simple yet effective method to depict the high-order\nlabel correlations explicitly, and at the same time maintain the high-rank of\nthe label matrix. Moreover, we estimate the label correlations and infer model\nparameters simultaneously via the local geometric structure of the input to\nachieve mutual enhancement. Comparative studies over ten benchmark data sets\nvalidate the effectiveness of the proposed algorithm in multi-label\nclassification. The exploited high-order label correlations are consistent with\ncommon sense empirically. Our code is publicly available at\nhttps://github.com/601175936/HOMI.",
    "descriptor": "",
    "authors": [
      "Chongjie Si",
      "Yuheng Jia",
      "Ran Wang",
      "Min-Ling Zhang",
      "Yanghe Feng",
      "Qu Chongxiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04197"
  },
  {
    "id": "arXiv:2207.04198",
    "title": "Improved Binary Forward Exploration: Learning Rate Scheduling Method for  Stochastic Optimization",
    "abstract": "A new gradient-based optimization approach by automatically scheduling the\nlearning rate has been proposed recently, which is called Binary Forward\nExploration (BFE). The Adaptive version of BFE has also been discussed\nthereafter. In this paper, the improved algorithms based on them will be\ninvestigated, in order to optimize the efficiency and robustness of the new\nmethodology. This improved approach provides a new perspective to scheduling\nthe update of learning rate and will be compared with the stochastic gradient\ndescent (SGD) algorithm with momentum or Nesterov momentum and the most\nsuccessful adaptive learning rate algorithm e.g. Adam. The goal of this method\ndoes not aim to beat others but provide a different viewpoint to optimize the\ngradient descent process. This approach combines the advantages of the\nfirst-order and second-order optimizations in the aspects of speed and\nefficiency.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2207.02763\n",
    "authors": [
      "Xin Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04198"
  },
  {
    "id": "arXiv:2207.04199",
    "title": "Serving Hybrid-Cloud SQL Interactive Queries at Twitter",
    "abstract": "The demand for data analytics has been consistently increasing in the past\nyears at Twitter. In order to fulfill the requirements and provide a highly\nscalable and available query experience, a large-scale in-house SQL system is\nheavily relied on. Recently, we evolved the SQL system into a hybrid-cloud SQL\nfederation system, compliant with Twitter's Partly Cloudy strategy. The\nhybrid-cloud SQL federation system is capable of processing queries across\nTwitter's data centers and the public cloud, interacting with around 10PB of\ndata per day.\nIn this paper, the design of the hybrid-cloud SQL federation system is\npresented, which consists of query, cluster, and storage federations. We\nidentify challenges in a modern SQL system and demonstrate how our system\naddresses them with some important design decisions. We also conduct\nqualitative examinations and summarize instructive lessons learned from the\ndevelopment and operation of such a SQL system.",
    "descriptor": "\nComments: Submitted to ECSA 2021 post-proceedings\n",
    "authors": [
      "Chunxu Tang",
      "Beinan Wang",
      "Huijun Wu",
      "Zhenzhao Wang",
      "Yao Li",
      "Vrushali Channapattan",
      "Zhenxiao Luo",
      "Ruchin Kabra",
      "Mainak Ghosh",
      "Nikhil Kantibhai Navadiya",
      "Prachi Mishra",
      "Prateek Mukhedkar",
      "Anneliese Lu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.04199"
  },
  {
    "id": "arXiv:2207.04200",
    "title": "Learning Structured Representations of Visual Scenes",
    "abstract": "As the intermediate-level representations bridging the two levels, structured\nrepresentations of visual scenes, such as visual relationships between pairwise\nobjects, have been shown to not only benefit compositional models in learning\nto reason along with the structures but provide higher interpretability for\nmodel decisions. Nevertheless, these representations receive much less\nattention than traditional recognition tasks, leaving numerous open challenges\nunsolved. In the thesis, we study how machines can describe the content of the\nindividual image or video with visual relationships as the structured\nrepresentations. Specifically, we explore how structured representations of\nvisual scenes can be effectively constructed and learned in both the\nstatic-image and video settings, with improvements resulting from external\nknowledge incorporation, bias-reducing mechanism, and enhanced representation\nmodels. At the end of this thesis, we also discuss some open challenges and\nlimitations to shed light on future directions of structured representation\nlearning for visual scenes.",
    "descriptor": "\nComments: Ph.D. thesis at the National University of Singapore\n",
    "authors": [
      "Meng-Jiun Chiou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.04200"
  },
  {
    "id": "arXiv:2207.04201",
    "title": "Human-centric Spatio-Temporal Video Grounding via the Combination of  Mutual Matching Network and TubeDETR",
    "abstract": "In this technical report, we represent our solution for the Human-centric\nSpatio-Temporal Video Grounding (HC-STVG) track of the 4th Person in Context\n(PIC) workshop and challenge. Our solution is built on the basis of TubeDETR\nand Mutual Matching Network (MMN). Specifically, TubeDETR exploits a video-text\nencoder and a space-time decoder to predict the starting time, the ending time\nand the tube of the target person. MMN detects persons in images, links them as\ntubes, extracts features of person tubes and the text description, and predicts\nthe similarities between them to choose the most likely person tube as the\ngrounding result. Our solution finally finetunes the results by combining the\nspatio localization of MMN and with temporal localization of TubeDETR. In the\nHC-STVG track of the 4th PIC challenge, our solution achieves the third place.",
    "descriptor": "",
    "authors": [
      "Fan Yu",
      "Zhixiang Zhao",
      "Yuchen Wang",
      "Yi Xu",
      "Tongwei Ren",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.04201"
  },
  {
    "id": "arXiv:2207.04202",
    "title": "Smart Multi-tenant Federated Learning",
    "abstract": "Federated learning (FL) is an emerging distributed machine learning method\nthat empowers in-situ model training on decentralized edge devices. However,\nmultiple simultaneous training activities could overload resource-constrained\ndevices. In this work, we propose a smart multi-tenant FL system, MuFL, to\neffectively coordinate and execute simultaneous training activities. We first\nformalize the problem of multi-tenant FL, define multi-tenant FL scenarios, and\nintroduce a vanilla multi-tenant FL system that trains activities sequentially\nto form baselines. Then, we propose two approaches to optimize multi-tenant FL:\n1) activity consolidation merges training activities into one activity with a\nmulti-task architecture; 2) after training it for rounds, activity splitting\ndivides it into groups by employing affinities among activities such that\nactivities within a group have better synergy. Extensive experiments\ndemonstrate that MuFL outperforms other methods while consuming 40% less\nenergy. We hope this work will inspire the community to further study and\noptimize multi-tenant FL.",
    "descriptor": "",
    "authors": [
      "Weiming Zhuang",
      "Yonggang Wen",
      "Shuai Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.04202"
  },
  {
    "id": "arXiv:2207.04203",
    "title": "Learning to Separate Voices by Spatial Regions",
    "abstract": "We consider the problem of audio voice separation for binaural applications,\nsuch as earphones and hearing aids. While today's neural networks perform\nremarkably well (separating $4+$ sources with 2 microphones) they assume a\nknown or fixed maximum number of sources, K. Moreover, today's models are\ntrained in a supervised manner, using training data synthesized from generic\nsources, environments, and human head shapes.\nThis paper intends to relax both these constraints at the expense of a slight\nalteration in the problem definition. We observe that, when a received mixture\ncontains too many sources, it is still helpful to separate them by region,\ni.e., isolating signal mixtures from each conical sector around the user's\nhead. This requires learning the fine-grained spatial properties of each\nregion, including the signal distortions imposed by a person's head. We propose\na two-stage self-supervised framework in which overheard voices from earphones\nare pre-processed to extract relatively clean personalized signals, which are\nthen used to train a region-wise separation model. Results show promising\nperformance, underscoring the importance of personalization over a generic\nsupervised approach. (audio samples available at our project website:\nhttps://uiuc-earable-computing.github.io/binaural/. We believe this result\ncould help real-world applications in selective hearing, noise cancellation,\nand audio augmented reality.",
    "descriptor": "\nComments: Accepted to ICML 2020. For associated audio samples, see this https URL\n",
    "authors": [
      "Zhongweiyang Xu",
      "Romit Roy Choudhury"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04203"
  },
  {
    "id": "arXiv:2207.04204",
    "title": "Variational Approach for Intensity Domain Multi-exposure Image Fusion",
    "abstract": "Recent innovations shows that blending of details captured by single Low\nDynamic Range (LDR) sensor overcomes the limitations of standard digital\ncameras to capture details from high dynamic range scene. We present a method\nto produce well-exposed fused image that can be displayed directly on\nconventional display devices. The ambition is to preserve details in poorly\nilluminated and brightly illuminated regions. Proposed approach does not\nrequire true radiance reconstruction and tone manipulation steps. The aforesaid\nobjective is achieved by taking into account local information measure that\nselect well-exposed regions across input exposures. In addition, Contrast\nLimited Adaptive Histogram equalization (CLAHE) is introduced to improve\nuniformity of input multi-exposure image prior to fusion.",
    "descriptor": "\nComments: 18 pages, 6 figures, Book Chapter\n",
    "authors": [
      "Harbinder Singh",
      "Dinesh Arora",
      "Vinay Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04204"
  },
  {
    "id": "arXiv:2207.04206",
    "title": "A Study of Syntactic Multi-Modality in Non-Autoregressive Machine  Translation",
    "abstract": "It is difficult for non-autoregressive translation (NAT) models to capture\nthe multi-modal distribution of target translations due to their conditional\nindependence assumption, which is known as the \"multi-modality problem\",\nincluding the lexical multi-modality and the syntactic multi-modality. While\nthe first one has been well studied, the syntactic multi-modality brings severe\nchallenge to the standard cross entropy (XE) loss in NAT and is under studied.\nIn this paper, we conduct a systematic study on the syntactic multi-modality\nproblem. Specifically, we decompose it into short- and long-range syntactic\nmulti-modalities and evaluate several recent NAT algorithms with advanced loss\nfunctions on both carefully designed synthesized datasets and real datasets. We\nfind that the Connectionist Temporal Classification (CTC) loss and the\nOrder-Agnostic Cross Entropy (OAXE) loss can better handle short- and\nlong-range syntactic multi-modalities respectively. Furthermore, we take the\nbest of both and design a new loss function to better handle the complicated\nsyntactic multi-modality in real-world datasets. To facilitate practical usage,\nwe provide a guide to use different loss functions for different kinds of\nsyntactic multi-modality.",
    "descriptor": "",
    "authors": [
      "Kexun Zhang",
      "Rui Wang",
      "Xu Tan",
      "Junliang Guo",
      "Yi Ren",
      "Tao Qin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04206"
  },
  {
    "id": "arXiv:2207.04208",
    "title": "SCouT: Synthetic Counterfactuals via Spatiotemporal Transformers for  Actionable Healthcare",
    "abstract": "The Synthetic Control method has pioneered a class of powerful data-driven\ntechniques to estimate the counterfactual reality of a unit from donor units.\nAt its core, the technique involves a linear model fitted on the\npre-intervention period that combines donor outcomes to yield the\ncounterfactual. However, linearly combining spatial information at each time\ninstance using time-agnostic weights fails to capture important inter-unit and\nintra-unit temporal contexts and complex nonlinear dynamics of real data. We\ninstead propose an approach to use local spatiotemporal information before the\nonset of the intervention as a promising way to estimate the counterfactual\nsequence. To this end, we suggest a Transformer model that leverages particular\npositional embeddings, a modified decoder attention mask, and a novel\npre-training task to perform spatiotemporal sequence-to-sequence modeling. Our\nexperiments on synthetic data demonstrate the efficacy of our method in the\ntypical small donor pool setting and its robustness against noise. We also\ngenerate actionable healthcare insights at the population and patient levels by\nsimulating a state-wide public health policy to evaluate its effectiveness, an\nin silico trial for asthma medications to support randomized controlled trials,\nand a medical intervention for patients with Friedreich's ataxia to improve\nclinical decision-making and promote personalized therapy.",
    "descriptor": "",
    "authors": [
      "Bhishma Dedhia",
      "Roshini Balasubramanian",
      "Niraj K. Jha"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04208"
  },
  {
    "id": "arXiv:2207.04209",
    "title": "Invisible Backdoor Attacks Using Data Poisoning in the Frequency Domain",
    "abstract": "With the broad application of deep neural networks (DNNs), backdoor attacks\nhave gradually attracted attention. Backdoor attacks are insidious, and\npoisoned models perform well on benign samples and are only triggered when\ngiven specific inputs, which cause the neural network to produce incorrect\noutputs. The state-of-the-art backdoor attack work is implemented by data\npoisoning, i.e., the attacker injects poisoned samples into the dataset, and\nthe models trained with that dataset are infected with the backdoor. However,\nmost of the triggers used in the current study are fixed patterns patched on a\nsmall fraction of an image and are often clearly mislabeled, which is easily\ndetected by humans or defense methods such as Neural Cleanse and SentiNet.\nAlso, it's difficult to be learned by DNNs without mislabeling, as they may\nignore small patterns. In this paper, we propose a generalized backdoor attack\nmethod based on the frequency domain, which can implement backdoor implantation\nwithout mislabeling and accessing the training process. It is invisible to\nhuman beings and able to evade the commonly used defense methods. We evaluate\nour approach in the no-label and clean-label cases on three datasets (CIFAR-10,\nSTL-10, and GTSRB) with two popular scenarios (self-supervised learning and\nsupervised learning). The results show our approach can achieve a high attack\nsuccess rate (above 90%) on all the tasks without significant performance\ndegradation on main tasks. Also, we evaluate the bypass performance of our\napproach for different kinds of defenses, including the detection of training\ndata (i.e., Activation Clustering), the preprocessing of inputs (i.e.,\nFiltering), the detection of inputs (i.e., SentiNet), and the detection of\nmodels (i.e., Neural Cleanse). The experimental results demonstrate that our\napproach shows excellent robustness to such defenses.",
    "descriptor": "",
    "authors": [
      "Chang Yue",
      "Peizhuo Lv",
      "Ruigang Liang",
      "Kai Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04209"
  },
  {
    "id": "arXiv:2207.04211",
    "title": "BOSS: Bottom-up Cross-modal Semantic Composition with Hybrid  Counterfactual Training for Robust Content-based Image Retrieval",
    "abstract": "Content-Based Image Retrieval (CIR) aims to search for a target image by\nconcurrently comprehending the composition of an example image and a\ncomplementary text, which potentially impacts a wide variety of real-world\napplications, such as internet search and fashion retrieval. In this scenario,\nthe input image serves as an intuitive context and background for the search,\nwhile the corresponding language expressly requests new traits on how specific\ncharacteristics of the query image should be modified in order to get the\nintended target image. This task is challenging since it necessitates learning\nand understanding the composite image-text representation by incorporating\ncross-granular semantic updates. In this paper, we tackle this task by a novel\n\\underline{\\textbf{B}}ottom-up cr\\underline{\\textbf{O}}ss-modal\n\\underline{\\textbf{S}}emantic compo\\underline{\\textbf{S}}ition (\\textbf{BOSS})\nwith Hybrid Counterfactual Training framework, which sheds new light on the CIR\ntask by studying it from two previously overlooked perspectives:\n\\emph{implicitly bottom-up composition of visiolinguistic representation} and\n\\emph{explicitly fine-grained correspondence of query-target construction}. On\nthe one hand, we leverage the implicit interaction and composition of\ncross-modal embeddings from the bottom local characteristics to the top global\nsemantics, preserving and transforming the visual representation conditioned on\nlanguage semantics in several continuous steps for effective target image\nsearch. On the other hand, we devise a hybrid counterfactual training strategy\nthat can reduce the model's ambiguity for similar queries.",
    "descriptor": "",
    "authors": [
      "Wenqiao Zhang",
      "Jiannan Guo",
      "Mengze Li",
      "Haochen Shi",
      "Shengyu Zhang",
      "Juncheng Li",
      "Siliang Tang",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.04211"
  },
  {
    "id": "arXiv:2207.04213",
    "title": "Dual-path Attention is All You Need for Audio-Visual Speech Extraction",
    "abstract": "Audio-visual target speech extraction, which aims to extract a certain\nspeaker's speech from the noisy mixture by looking at lip movements, has made\nsignificant progress combining time-domain speech separation models and visual\nfeature extractors (CNN). One problem of fusing audio and video information is\nthat they have different time resolutions. Most current research upsamples the\nvisual features along the time dimension so that audio and video features are\nable to align in time. However, we believe that lip movement should mostly\ncontain long-term, or phone-level information. Based on this assumption, we\npropose a new way to fuse audio-visual features. We observe that for DPRNN\n\\cite{dprnn}, the interchunk dimension's time resolution could be very close to\nthe time resolution of video frames. Like \\cite{sepformer}, the LSTM in DPRNN\nis replaced by intra-chunk and inter-chunk self-attention, but in the proposed\nalgorithm, inter-chunk attention incorporates the visual features as an\nadditional feature stream. This prevents the upsampling of visual cues,\nresulting in more efficient audio-visual fusion. The result shows we achieve\nsuperior results compared with other time-domain based audio-visual fusion\nmodels.",
    "descriptor": "",
    "authors": [
      "Zhongweiyang Xu",
      "Xulin Fan",
      "Mark Hasegawa-Johnson"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04213"
  },
  {
    "id": "arXiv:2207.04214",
    "title": "Adaptive Structural Similarity Preserving for Unsupervised Cross Modal  Hashing",
    "abstract": "Cross-modal hashing is an important approach for multimodal data management\nand application. Existing unsupervised cross-modal hashing algorithms mainly\nrely on data features in pre-trained models to mine their similarity\nrelationships. However, their optimization objectives are based on the static\nmetric between the original uni-modal features, without further exploring data\ncorrelations during the training. In addition, most of them mainly focus on\nassociation mining and alignment among pairwise instances in continuous space\nbut ignore the latent structural correlations contained in the semantic hashing\nspace. In this paper, we propose an unsupervised hash learning framework,\nnamely Adaptive Structural Similarity Preservation Hashing (ASSPH), to solve\nthe above problems. Firstly, we propose an adaptive learning scheme, with\nlimited data and training batches, to enrich semantic correlations of unlabeled\ninstances during the training process and meanwhile to ensure a smooth\nconvergence of the training process. Secondly, we present an asymmetric\nstructural semantic representation learning scheme. We introduce structural\nsemantic metrics based on graph adjacency relations during the semantic\nreconstruction and correlation mining stage and meanwhile align the structure\nsemantics in the hash space with an asymmetric binary optimization process.\nFinally, we conduct extensive experiments to validate the enhancements of our\nwork in comparison with existing works.",
    "descriptor": "\nComments: Accepted to ACM Multimedia 2022 as Poster\n",
    "authors": [
      "Liang Li",
      "Baihua Zheng",
      "Weiwei Sun"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.04214"
  },
  {
    "id": "arXiv:2207.04216",
    "title": "Wasserstein Graph Distance based on $L_1$-Approximated Tree Edit  Distance between Weisfeiler-Lehman Subtrees",
    "abstract": "The Weisfeiler-Lehman (WL) test has been widely applied to graph kernels,\nmetrics, and neural networks. However, it considers only the graph consistency,\nresulting in the weak descriptive power of structural information. Thus, it\nlimits the performance improvement of applied methods. In addition, the\nsimilarity and distance between graphs defined by the WL test are in coarse\nmeasurements. To the best of our knowledge, this paper clarifies these facts\nfor the first time and defines a metric we call the Wasserstein WL subtree\n(WWLS) distance. We introduce the WL subtree as the structural information in\nthe neighborhood of nodes and assign it to each node. Then we define a new\ngraph embedding space based on $L_1$-approximated tree edit distance\n($L_1$-TED): the $L_1$ norm of the difference between node feature vectors on\nthe space is the $L_1$-TED between these nodes. We further propose a fast\nalgorithm for graph embedding. Finally, we use the Wasserstein distance to\nreflect the $L_1$-TED to the graph level. The WWLS can capture small changes in\nstructure that are difficult with traditional metrics. We demonstrate its\nperformance in several graph classification and metric validation experiments.",
    "descriptor": "",
    "authors": [
      "Zhongxi Fang",
      "Jianming Huang",
      "Xun Su",
      "Hiroyuki Kasai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04216"
  },
  {
    "id": "arXiv:2207.04217",
    "title": "Generating Pseudo-labels Adaptively for Few-shot Model-Agnostic  Meta-Learning",
    "abstract": "Model-Agnostic Meta-Learning (MAML) is a famous few-shot learning method that\nhas inspired many follow-up efforts, such as ANIL and BOIL. However, as an\ninductive method, MAML is unable to fully utilize the information of query set,\nlimiting its potential of gaining higher generality. To address this issue, we\npropose a simple yet effective method that generates psuedo-labels adaptively\nand could boost the performance of the MAML family. The proposed methods,\ndubbed Generative Pseudo-label based MAML (GP-MAML), GP-ANIL and GP-BOIL,\nleverage statistics of the query set to improve the performance on new tasks.\nSpecifically, we adaptively add pseudo labels and pick samples from the query\nset, then re-train the model using the picked query samples together with the\nsupport set. The GP series can also use information from the pseudo query set\nto re-train the network during the meta-testing. While some transductive\nmethods, such as Transductive Propagation Network (TPN), struggle to achieve\nthis goal.",
    "descriptor": "\nComments: 13 pages, 2 Figures\n",
    "authors": [
      "Guodong Liu",
      "Tongling Wang",
      "Shuoxi Zhang",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04217"
  },
  {
    "id": "arXiv:2207.04218",
    "title": "Subclasses of Class Function used to Implement Transformations of  Statistical Models",
    "abstract": "A library of software for inductive inference guided by the Minimum Message\nLength (MML) principle was created previously. It contains various\n(object-oriented-) classes and subclasses of statistical Model and can be used\nto infer Models from given data sets in machine learning problems. Here\ntransformations of statistical Models are considered and implemented within the\nlibrary so as to have desirable properties from the object-oriented programming\nand mathematical points of view. The subclasses of class Function needed to do\nsuch transformations are defined.",
    "descriptor": "",
    "authors": [
      "Lloyd Allison"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04218"
  },
  {
    "id": "arXiv:2207.04220",
    "title": "Rethinking Persistent Homology for Visual Recognition",
    "abstract": "Persistent topological properties of an image serve as an additional\ndescriptor providing an insight that might not be discovered by traditional\nneural networks. The existing research in this area focuses primarily on\nefficiently integrating topological properties of the data in the learning\nprocess in order to enhance the performance. However, there is no existing\nstudy to demonstrate all possible scenarios where introducing topological\nproperties can boost or harm the performance. This paper performs a detailed\nanalysis of the effectiveness of topological properties for image\nclassification in various training scenarios, defined by: the number of\ntraining samples, the complexity of the training data and the complexity of the\nbackbone network. We identify the scenarios that benefit the most from\ntopological features, e.g., training simple networks on small datasets.\nAdditionally, we discuss the problem of topological consistency of the datasets\nwhich is one of the major bottlenecks for using topological features for\nclassification. We further demonstrate how the topological inconsistency can\nharm the performance for certain scenarios.",
    "descriptor": "\nComments: To appear in ICML 2022 Workshop on Topology, Algebra, and Geometry in Machine Learning\n",
    "authors": [
      "Ekaterina Khramtsova",
      "Guido Zuccon",
      "Xi Wang",
      "Mahsa Baktashmotlagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04220"
  },
  {
    "id": "arXiv:2207.04221",
    "title": "Learning to Register Unbalanced Point Pairs",
    "abstract": "Recent 3D registration methods can effectively handle large-scale or\npartially overlapping point pairs. However, despite its practicality, matching\nthe unbalanced pairs in terms of spatial scale and density has been overlooked.\nWe present a novel 3D registration method, called UPPNet, for the unbalanced\npoint pairs. We propose a hierarchical framework to find inlier correspondences\neffectively by gradually reducing search space. Our method predicts the\nsubregions of the target points likely to be overlapped with the query points.\nThe following super-point matching module and fine-grained refinement module\nestimate accurate inlier correspondences between two point clouds. Furthermore,\nwe apply geometric constraints to refine the correspondences that satisfy\nspatial compatibility. Correspondence prediction is trained end-to-end, and our\napproach can predict the proper rigid transformation with a single forward pass\ngiven unbalanced point cloud pairs. To validate the efficacy of the proposed\nmethod, we create a KITTI-UPP dataset by augmenting the KITTI LiDAR dataset.\nExperiments on this dataset reveal that the proposed approach significantly\noutperforms state-of-the-art pairwise point cloud registration methods by a\nlarge margin, resulting in 78% improvement in Registration Recall when the\ntarget point cloud is about 10$\\times$ spatially larger and about 10$\\times$\ntimes denser than the query point cloud.",
    "descriptor": "",
    "authors": [
      "Kanghee Lee",
      "Junha Lee",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04221"
  },
  {
    "id": "arXiv:2207.04224",
    "title": "SiaTrans: Siamese Transformer Network for RGB-D Salient Object Detection  with Depth Image Classification",
    "abstract": "RGB-D SOD uses depth information to handle challenging scenes and obtain\nhigh-quality saliency maps. Existing state-of-the-art RGB-D saliency detection\nmethods overwhelmingly rely on the strategy of directly fusing depth\ninformation. Although these methods improve the accuracy of saliency prediction\nthrough various cross-modality fusion strategies, misinformation provided by\nsome poor-quality depth images can affect the saliency prediction result. To\naddress this issue, a novel RGB-D salient object detection model (SiaTrans) is\nproposed in this paper, which allows training on depth image quality\nclassification at the same time as training on SOD. In light of the common\ninformation between RGB and depth images on salient objects, SiaTrans uses a\nSiamese transformer network with shared weight parameters as the encoder and\nextracts RGB and depth features concatenated on the batch dimension, saving\nspace resources without compromising performance. SiaTrans uses the Class token\nin the backbone network (T2T-ViT) to classify the quality of depth images\nwithout preventing the token sequence from going on with the saliency detection\ntask. Transformer-based cross-modality fusion module (CMF) can effectively fuse\nRGB and depth information. And in the testing process, CMF can choose to fuse\ncross-modality information or enhance RGB information according to the quality\nclassification signal of the depth image. The greatest benefit of our designed\nCMF and decoder is that they maintain the consistency of RGB and RGB-D\ninformation decoding: SiaTrans decodes RGB-D or RGB information under the same\nmodel parameters according to the classification signal during testing.\nComprehensive experiments on nine RGB-D SOD benchmark datasets show that\nSiaTrans has the best overall performance and the least computation compared\nwith recent state-of-the-art methods.",
    "descriptor": "\nComments: 21 pages, 7 figures\n",
    "authors": [
      "Xingzhao Jia",
      "Dongye Changlei",
      "Yanjun Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04224"
  },
  {
    "id": "arXiv:2207.04227",
    "title": "On the Robustness and Anomaly Detection of Sparse Neural Networks",
    "abstract": "The robustness and anomaly detection capability of neural networks are\ncrucial topics for their safe adoption in the real-world. Moreover, the\nover-parameterization of recent networks comes with high computational costs\nand raises questions about its influence on robustness and anomaly detection.\nIn this work, we show that sparsity can make networks more robust and better\nanomaly detectors. To motivate this even further, we show that a pre-trained\nneural network contains, within its parameter space, sparse subnetworks that\nare better at these tasks without any further training. We also show that\nstructured sparsity greatly helps in reducing the complexity of expensive\nrobustness and detection methods, while maintaining or even improving their\nresults on these tasks. Finally, we introduce a new method, SensNorm, which\nuses the sensitivity of weights derived from an appropriate pruning method to\ndetect anomalous samples in the input.",
    "descriptor": "",
    "authors": [
      "Morgane Ayle",
      "Bertrand Charpentier",
      "John Rachwan",
      "Daniel Z\u00fcgner",
      "Simon Geisler",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04227"
  },
  {
    "id": "arXiv:2207.04228",
    "title": "Batch-efficient EigenDecomposition for Small and Medium Matrices",
    "abstract": "EigenDecomposition (ED) is at the heart of many computer vision algorithms\nand applications. One crucial bottleneck limiting its usage is the expensive\ncomputation cost, particularly for a mini-batch of matrices in the deep neural\nnetworks. In this paper, we propose a QR-based ED method dedicated to the\napplication scenarios of computer vision. Our proposed method performs the ED\nentirely by batched matrix/vector multiplication, which processes all the\nmatrices simultaneously and thus fully utilizes the power of GPUs. Our\ntechnique is based on the explicit QR iterations by Givens rotation with double\nWilkinson shifts. With several acceleration techniques, the time complexity of\nQR iterations is reduced from $O{(}n^5{)}$ to $O{(}n^3{)}$. The numerical test\nshows that for small and medium batched matrices (\\emph{e.g.,} $dim{<}32$) our\nmethod can be much faster than the Pytorch SVD function. Experimental results\non visual recognition and image generation demonstrate that our methods also\nachieve competitive performances.",
    "descriptor": "\nComments: Accepted by ECCV22\n",
    "authors": [
      "Yue Song",
      "Nicu Sebe",
      "Wei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04228"
  },
  {
    "id": "arXiv:2207.04231",
    "title": "CEG4N: Counter-Example Guided Neural Network Quantization Refinement",
    "abstract": "Neural networks are essential components of learning-based software systems.\nHowever, their high compute, memory, and power requirements make using them in\nlow resources domains challenging. For this reason, neural networks are often\nquantized before deployment. Existing quantization techniques tend to degrade\nthe network accuracy. We propose Counter-Example Guided Neural Network\nQuantization Refinement (CEG4N). This technique combines search-based\nquantization and equivalence verification: the former minimizes the\ncomputational requirements, while the latter guarantees that the network's\noutput does not change after quantization. We evaluate CEG4N~on a diverse set\nof benchmarks, including large and small networks. Our technique successfully\nquantizes the networks in our evaluation while producing models with up to 72%\nbetter accuracy than state-of-the-art techniques.",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o Batista P. Matos Jr.",
      "Iury Bessa",
      "Edoardo Manino",
      "Xidan Song",
      "Lucas C. Cordeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.04231"
  },
  {
    "id": "arXiv:2207.04232",
    "title": "Research on the construction of self-dual MDS codes based on GRS codes",
    "abstract": "In this paper, we construct some new classes of maximum distance separable\n(MDS) self-dual codes over $F_q$ by using (extended) generalized Reed-Solomon\ncodes. In this paper, for finite field with odd characteristic, we construct\nsome new classes of MDS self-dual codes than previous works.",
    "descriptor": "\nComments: 26 pages,1 table\n",
    "authors": [
      "Ruhao Wan",
      "Shixin Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04232"
  },
  {
    "id": "arXiv:2207.04236",
    "title": "Sparse Ellipsometry: Portable Acquisition of Polarimetric SVBRDF and  Shape with Unstructured Flash Photography",
    "abstract": "Ellipsometry techniques allow to measure polarization information of\nmaterials, requiring precise rotations of optical components with different\nconfigurations of lights and sensors. This results in cumbersome capture\ndevices, carefully calibrated in lab conditions, and in very long acquisition\ntimes, usually in the order of a few days per object. Recent techniques allow\nto capture polarimetric spatially-varying reflectance information, but limited\nto a single view, or to cover all view directions, but limited to spherical\nobjects made of a single homogeneous material. We present sparse ellipsometry,\na portable polarimetric acquisition method that captures both polarimetric\nSVBRDF and 3D shape simultaneously. Our handheld device consists of\noff-the-shelf, fixed optical components. Instead of days, the total acquisition\ntime varies between twenty and thirty minutes per object. We develop a complete\npolarimetric SVBRDF model that includes diffuse and specular components, as\nwell as single scattering, and devise a novel polarimetric inverse rendering\nalgorithm with data augmentation of specular reflection samples via generative\nmodeling. Our results show a strong agreement with a recent ground-truth\ndataset of captured polarimetric BRDFs of real-world objects.",
    "descriptor": "",
    "authors": [
      "Inseung Hwang",
      "Daniel S. Jeon",
      "Adolfo Mu\u00f1oz",
      "Diego Gutierrez",
      "Xin Tong",
      "Min H. Kim"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04236"
  },
  {
    "id": "arXiv:2207.04237",
    "title": "Few-shot training LLMs for project-specific code-summarization",
    "abstract": "Very large language models (LLMs), such as GPT-3 and Codex have achieved\nstate-of-the-art performance on several natural-language tasks, and show great\npromise also for code. A particularly exciting aspect of LLMs is their knack\nfor few-shot and zero-shot learning: they can learn to perform a task with very\nfew examples. Few-shotting has particular synergies in software engineering,\nwhere there are a lot of phenomena (identifier names, APIs, terminology, coding\npatterns) that are known to be highly project-specific. However,\nproject-specific data can be quite limited, especially early in the history of\na project; thus the few-shot learning capacity of LLMs might be very relevant.\nIn this paper, we investigate the use few-shot training with the very large GPT\n(Generative Pre-trained Transformer) Codex model, and find evidence suggesting\nthat one can significantly surpass state-of-the-art models for\ncode-summarization, leveraging project-specific training.",
    "descriptor": "\nComments: Accepted at ASE-NIER (2022) track\n",
    "authors": [
      "Toufique Ahmed",
      "Premkumar Devanbu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04237"
  },
  {
    "id": "arXiv:2207.04238",
    "title": "Complexity of Public Goods Games on Graphs",
    "abstract": "We study the computational complexity of \"public goods games on networks\". In\nthis model, each vertex in a graph is an agent that needs to take a binary\ndecision of whether to \"produce a good\" or not. Each agent's utility depends on\nthe number of its neighbors in the graph that produce the good, as well as on\nits own action. This dependence can be captured by a \"pattern\" $T:{\\rm\nI\\!N}\\rightarrow\\{0,1\\}$ that describes an agent's best response to every\npossible number of neighbors that produce the good. Answering a question of\n[Papadimitriou and Peng, 2021], we prove that for some simple pattern $T$ the\nproblem of determining whether a non-trivial pure Nash equilibrium exists is\nNP-complete. We extend our result to a wide class of such $T$, but also find a\nnew polynomial time algorithm for some specific simple pattern $T$. We leave\nopen the goal of characterizing the complexity for all patterns.",
    "descriptor": "\nComments: To be published in 15th Symposium on Algorithmic Game Theory (SAGT 2022)\n",
    "authors": [
      "Matan Gilboa",
      "Noam Nisan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.04238"
  },
  {
    "id": "arXiv:2207.04240",
    "title": "Deep Reinforcement Learning for Long-Term Voltage Stability Control",
    "abstract": "Deep reinforcement learning (DRL) is a machine learning-based method suited\nfor complex and high-dimensional control problems. In this study, a real-time\ncontrol system based on DRL is developed for long-term voltage stability\nevents. The possibility of using system services from demand response (DR) and\nenergy storage systems (ESS) as control measures to stabilize the system is\ninvestigated. The performance of the DRL control is evaluated on a modified\nNordic32 test system. The results show that the DRL control quickly learns an\neffective control policy that can handle the uncertainty involved when using DR\nand ESS. The DRL control is compared to a rule-based load shedding scheme and\nthe DRL control is shown to stabilize the system both significantly faster and\nwith lesser load curtailment. Finally, when testing and evaluating the\nperformance on load and disturbance scenarios that were not included in the\ntraining data, the robustness and generalization capability of the control were\nshown to be effective.",
    "descriptor": "\nComments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Hannes Hagmar",
      "Le Anh Tuan",
      "Robert Eriksson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04240"
  },
  {
    "id": "arXiv:2207.04242",
    "title": "PI-Trans: Parallel-ConvMLP and Implicit-Transformation Based GAN for  Cross-View Image Translation",
    "abstract": "For semantic-guided cross-view image translation, it is crucial to learn\nwhere to sample pixels from the source view image and where to reallocate them\nguided by the target view semantic map, especially when there is little overlap\nor drastic view difference between the source and target images. Hence, one not\nonly needs to encode the long-range dependencies among pixels in both the\nsource view image and target view the semantic map but also needs to translate\nthese learned dependencies. To this end, we propose a novel generative\nadversarial network, PI-Trans, which mainly consists of a novel\nParallel-ConvMLP module and an Implicit Transformation module at multiple\nsemantic levels. Extensive experimental results show that the proposed PI-Trans\nachieves the best qualitative and quantitative performance by a large margin\ncompared to the state-of-the-art methods on two challenging datasets. The code\nwill be made available at https://github.com/Amazingren/PI-Trans.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Bin Ren",
      "Hao Tang",
      "Yiming Wang",
      "Xia Li",
      "Wei Wang",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04242"
  },
  {
    "id": "arXiv:2207.04244",
    "title": "Delayed Impact of Interdisciplinary Research",
    "abstract": "Interdisciplinary research increasingly fuels innovation, and is considered\nto be a key to tomorrow breakthrough. Yet little is known about whether\ninterdisciplinary research manifests delayed impact. Here, we use the time to\nreach the citation peak to quantify the highest impact time and citation\ndynamics, and examine its relationship with interdisciplinarity. Using large\nscale publication datasets, our results suggest that interdisciplinary papers\nshow significant delayed impact both microscopically per paper and\nmacroscopically collectively, as it takes longer time for interdisciplinary\npapers to reach their citation peak. Furthermore, we study the underlying\nforces of such delayed impact, finding that the effect goes beyond the Matthew\neffect (i.e., the rich-get-richer effect). Finally, we find that team size and\ncontent conventionality only partly account for this effect. Overall, our\nresults suggest that governments, research administrators, funding agencies\nshould be aware of this general feature of interdisciplinary science, which may\nhave broad policy implications.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Yang Zhang",
      "Yang Wang",
      "Haifeng Du",
      "Shlomo Havlin"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.04244"
  },
  {
    "id": "arXiv:2207.04250",
    "title": "Improving saliency models' predictions of the next fixation with humans'  intrinsic cost of gaze shifts",
    "abstract": "The human prioritization of image regions can be modeled in a time invariant\nfashion with saliency maps or sequentially with scanpath models. However, while\nboth types of models have steadily improved on several benchmarks and datasets,\nthere is still a considerable gap in predicting human gaze. Here, we leverage\ntwo recent developments to reduce this gap: theoretical analyses establishing a\nprincipled framework for predicting the next gaze target and the empirical\nmeasurement of the human cost for gaze switches independently of image content.\nWe introduce an algorithm in the framework of sequential decision making, which\nconverts any static saliency map into a sequence of dynamic history-dependent\nvalue maps, which are recomputed after each gaze shift. These maps are based on\n1) a saliency map provided by an arbitrary saliency model, 2) the recently\nmeasured human cost function quantifying preferences in magnitude and direction\nof eye movements, and 3) a sequential exploration bonus, which changes with\neach subsequent gaze shift. The parameters of the spatial extent and temporal\ndecay of this exploration bonus are estimated from human gaze data. The\nrelative contributions of these three components were optimized on the MIT1003\ndataset for the NSS score and are sufficient to significantly outperform\npredictions of the next gaze target on NSS and AUC scores for five state of the\nart saliency models on three image data sets. Thus, we provide an\nimplementation of human gaze preferences, which can be used to improve\narbitrary saliency models' predictions of humans' next gaze targets.",
    "descriptor": "",
    "authors": [
      "Florian Kadner",
      "Tobias Thomas",
      "David Hoppe",
      "Constantin A. Rothkopf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04250"
  },
  {
    "id": "arXiv:2207.04258",
    "title": "A novel evaluation methodology for supervised Feature Ranking algorithms",
    "abstract": "Both in the domains of Feature Selection and Interpretable AI, there exists a\ndesire to `rank' features based on their importance. Such feature importance\nrankings can then be used to either: (1) reduce the dataset size or (2)\ninterpret the Machine Learning model. In the literature, however, such Feature\nRankers are not evaluated in a systematic, consistent way. Many papers have a\ndifferent way of arguing which feature importance ranker works best. This paper\nfills this gap, by proposing a new evaluation methodology. By making use of\nsynthetic datasets, feature importance scores can be known beforehand, allowing\nmore systematic evaluation. To facilitate large-scale experimentation using the\nnew methodology, a benchmarking framework was built in Python, called fseval.\nThe framework allows running experiments in parallel and distributed over\nmachines on HPC systems. By integrating with an online platform called Weights\nand Biases, charts can be interactively explored on a live dashboard. The\nsoftware was released as open-source software, and is published as a package on\nthe PyPi platform. The research concludes by exploring one such large-scale\nexperiment, to find the strengths and weaknesses of the participating\nalgorithms, on many fronts.",
    "descriptor": "\nComments: 56 pages, 29 figures\n",
    "authors": [
      "Jeroen G. S. Overschie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.04258"
  },
  {
    "id": "arXiv:2207.04268",
    "title": "Cell-average based neural network method for high dimensional parabolic  differential equations",
    "abstract": "In this paper, we introduce cell-average based neural network (CANN) method\nto solve high-dimensional parabolic partial differential equations. The method\nis based on the integral or weak formulation of partial differential equations.\nA feedforward network is considered to train the solution average of cells in\nneighboring time. Initial values and approximate solution at $t=\\Delta t$\nobtained by high order numerical method are taken as the inputs and outputs of\nnetwork, respectively. We use supervised training combined with a simple\nbackpropagation algorithm to train the network parameters. We find that the\nneural network has been trained to optimality for high-dimensional problems,\nthe CFL condition is not strictly limited for CANN method and the trained\nnetwork is used to solve the same problem with different initial values. For\nthe high-dimensional parabolic equations, the convergence is observed and the\nerrors are shown related to spatial mesh size but independent of time step\nsize.",
    "descriptor": "\nComments: 21 pages, 8 figures and 17 tables\n",
    "authors": [
      "Hong Zhang",
      "Hongying Huang",
      "Jue Yan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04268"
  },
  {
    "id": "arXiv:2207.04272",
    "title": "Efficient Backward Reachability using the Minkowski Difference of  Constrained Zonotopes",
    "abstract": "Backward reachability analysis is essential to synthesizing controllers that\nensure the correctness of closed-loop systems. This paper is concerned with\ndeveloping scalable algorithms that under-approximate the backward reachable\nsets, for discrete-time uncertain linear and nonlinear systems. Our algorithm\nsequentially linearizes the dynamics, and uses constrained zonotopes for set\nrepresentation and computation. The main technical ingredient of our algorithm\nis an efficient way to under-approximate the Minkowski difference between a\nconstrained zonotopic minuend and a zonotopic subtrahend, which consists of all\npossible values of the uncertainties and the linearization error. This\nMinkowski difference needs to be represented as a constrained zonotope to\nenable subsequent computation, but, as we show, it is impossible to find a\npolynomial-sized representation for it in polynomial time. Our algorithm finds\na polynomial-sized under-approximation in polynomial time. We further analyze\nthe conservatism of this under-approximation technique, and show that it is\nexact under some conditions. Based on the developed Minkowski difference\ntechnique, we detail two backward reachable set computation algorithms to\ncontrol the linearization error and incorporate nonconvex state constraints.\nSeveral examples illustrate the effectiveness of our algorithms.",
    "descriptor": "\nComments: This article will be presented at the International Conference on Embedded Software (EMSOFT) 2022 and will appear as part of the ESWEEK-TCAD special issue\n",
    "authors": [
      "Liren Yang",
      "Hang Zhang",
      "Jean-Baptiste Jeannin",
      "Necmiye Ozay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2207.04272"
  },
  {
    "id": "arXiv:2207.04273",
    "title": "Scheduling Versus Contention for Massive Random Access in Massive MIMO  Systems",
    "abstract": "Massive machine-type communications protocols have typically been designed\nunder the assumption that coordination between users requires significant\ncommunication overhead and is thus impractical. Recent progress in efficient\nactivity detection and collision-free scheduling, however, indicates that the\ncost of coordination can be much less than the naive scheme for scheduling.\nThis work considers a scenario in which a massive number of devices with\nsporadic traffic seek to access a massive multiple-input multiple-output (MIMO)\nbase-station (BS) and explores an approach in which device activity detection\nis followed by a single common feedback broadcast message, which is used both\nto schedule the active users to different transmission slots and to assign\northogonal pilots to the users for channel estimation. The proposed coordinated\ncommunication scheme is compared to two prevalent contention-based schemes:\ncoded pilot access, which is based on the principle of coded slotted ALOHA, and\nan approximate message passing scheme for joint user activity detection and\nchannel estimation. Numerical results indicate that scheduled massive access\nprovides significant gains in the number of successful transmissions per slot\nand in sum rate, due to the reduced interference, at only a small cost of\nfeedback.",
    "descriptor": "\nComments: 14 pages, 10 figures. Accepted in IEEE Transactions on Communications\n",
    "authors": [
      "Justin Kang",
      "Wei Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.04273"
  },
  {
    "id": "arXiv:2207.04284",
    "title": "How Do Drivers Self-Regulate their Secondary Task Engagements? The  Effect of Driving Automation on Touchscreen Interactions and Glance Behavior",
    "abstract": "With ever-improving driver assistance systems and large touchscreens becoming\nthe main in-vehicle interface, drivers are more tempted than ever to engage in\ndistracting non-driving-related tasks. However, little research exists on how\ndriving automation affects drivers' self-regulation when interacting with\ncenter stack touchscreens. To investigate this, we employ multilevel models on\na real-world driving dataset consisting of 10,139 sequences. Our results show\nsignificant differences in drivers' interaction and glance behavior in response\nto varying levels of driving automation, vehicle speed, and road curvature.\nDuring partially automated driving, drivers are not only more likely to engage\nin secondary touchscreen tasks, but their mean glance duration toward the\ntouchscreen also increases by 12% (Level 1) and 20% (Level 2) compared to\nmanual driving. We further show that the effect of driving automation on\ndrivers' self-regulation is larger than that of vehicle speed and road\ncurvature. The derived knowledge can facilitate the safety evaluation of\ninfotainment systems and the development of context-aware driver monitoring\nsystems.",
    "descriptor": "",
    "authors": [
      "Patrick Ebel",
      "Moritz Berger",
      "Christoph Lingenfelder",
      "Andreas Vogelsang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.04284"
  },
  {
    "id": "arXiv:2207.04285",
    "title": "A Closer Look into Transformer-Based Code Intelligence Through Code  Transformation: Challenges and Opportunities",
    "abstract": "Transformer-based models have demonstrated state-of-the-art performance in\nmany intelligent coding tasks such as code comment generation and code\ncompletion. Previous studies show that deep learning models are sensitive to\nthe input variations, but few studies have systematically studied the\nrobustness of Transformer under perturbed input code. In this work, we\nempirically study the effect of semantic-preserving code transformation on the\nperformance of Transformer. Specifically, 24 and 27 code transformation\nstrategies are implemented for two popular programming languages, Java and\nPython, respectively. For facilitating analysis, the strategies are grouped\ninto five categories: block transformation, insertion/deletion transformation,\ngrammatical statement transformation, grammatical token transformation, and\nidentifier transformation. Experiments on three popular code intelligence\ntasks, including code completion, code summarization and code search,\ndemonstrate insertion/deletion transformation and identifier transformation\nshow the greatest impact on the performance of Transformer. Our results also\nsuggest that Transformer based on abstract syntax trees (ASTs) shows more\nrobust performance than the model based on only code sequence under most code\ntransformations. Besides, the design of positional encoding can impact the\nrobustness of Transformer under code transformation. Based on our findings, we\ndistill some insights about the challenges and opportunities for\nTransformer-based code intelligence.",
    "descriptor": "",
    "authors": [
      "Yaoxian Li",
      "Shiyi Qi",
      "Cuiyun Gao",
      "Yun Peng",
      "David Lo",
      "Zenglin Xu",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.04285"
  },
  {
    "id": "arXiv:2207.04293",
    "title": "Attention and Self-Attention in Random Forests",
    "abstract": "New models of random forests jointly using the attention and self-attention\nmechanisms are proposed for solving the regression problem. The models can be\nregarded as extensions of the attention-based random forest whose idea stems\nfrom applying a combination of the Nadaraya-Watson kernel regression and the\nHuber's contamination model to random forests. The self-attention aims to\ncapture dependencies of the tree predictions and to remove noise or anomalous\npredictions in the random forest. The self-attention module is trained jointly\nwith the attention module for computing weights. It is shown that the training\nprocess of attention weights is reduced to solving a single quadratic or linear\noptimization problem. Three modifications of the general approach are proposed\nand compared. A specific multi-head self-attention for the random forest is\nalso considered. Heads of the self-attention are obtained by changing its\ntuning parameters including the kernel parameters and the contamination\nparameter of models. Numerical experiments with various datasets illustrate the\nproposed models and show that the supplement of the self-attention improves the\nmodel performance for many datasets.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2201.02880\n",
    "authors": [
      "Lev V. Utkin",
      "Andrei V. Konstantinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.04293"
  },
  {
    "id": "arXiv:2207.04295",
    "title": "Explainable AI (XAI) in Biomedical Signal and Image Processing: Promises  and Challenges",
    "abstract": "Artificial intelligence has become pervasive across disciplines and fields,\nand biomedical image and signal processing is no exception. The growing and\nwidespread interest on the topic has triggered a vast research activity that is\nreflected in an exponential research effort. Through study of massive and\ndiverse biomedical data, machine and deep learning models have revolutionized\nvarious tasks such as modeling, segmentation, registration, classification and\nsynthesis, outperforming traditional techniques. However, the difficulty in\ntranslating the results into biologically/clinically interpretable information\nis preventing their full exploitation in the field. Explainable AI (XAI)\nattempts to fill this translational gap by providing means to make the models\ninterpretable and providing explanations. Different solutions have been\nproposed so far and are gaining increasing interest from the community. This\npaper aims at providing an overview on XAI in biomedical data processing and\npoints to an upcoming Special Issue on Deep Learning in Biomedical Image and\nSignal Processing of the IEEE Signal Processing Magazine that is going to\nappear in March 2022.",
    "descriptor": "\nComments: IEEE ICIP 2022\n",
    "authors": [
      "Guang Yang",
      "Arvind Rao",
      "Christine Fernandez-Maloigne",
      "Vince Calhoun",
      "Gloria Menegaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04295"
  },
  {
    "id": "arXiv:2207.04296",
    "title": "TensorIR: An Abstraction for Automatic Tensorized Program Optimization",
    "abstract": "Deploying deep learning models on various devices has become an important\ntopic. The wave of hardware specialization brings a diverse set of acceleration\nprimitives for multi-dimensional tensor computations. These new acceleration\nprimitives, along with the emerging machine learning models, bring tremendous\nengineering challenges. In this paper, we present TensorIR, a compiler\nabstraction for optimizing programs with these tensor computation primitives.\nTensorIR generalizes the loop nest representation used in existing machine\nlearning compilers to bring tensor computation as the first-class citizen.\nFinally, we build an end-to-end framework on top of our abstraction to\nautomatically optimize deep learning models for given tensor computation\nprimitives. Experimental results show that TensorIR compilation automatically\nuses the tensor computation primitives for given hardware backends and delivers\nperformance that is competitive to state-of-art hand-optimized systems across\nplatforms.",
    "descriptor": "",
    "authors": [
      "Siyuan Feng",
      "Bohan Hou",
      "Hongyi Jin",
      "Wuwei Lin",
      "Junru Shao",
      "Ruihang Lai",
      "Zihao Ye",
      "Lianmin Zheng",
      "Cody Hao Yu",
      "Yong Yu",
      "Tianqi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.04296"
  },
  {
    "id": "arXiv:2207.04297",
    "title": "SHDM-NET: Heat Map Detail Guidance with Image Matting for Industrial  Weld Semantic Segmentation Network",
    "abstract": "In actual industrial production, the assessment of the steel plate welding\neffect is an important task, and the segmentation of the weld section is the\nbasis of the assessment. This paper proposes an industrial weld segmentation\nnetwork based on a deep learning semantic segmentation algorithm fused with\nheatmap detail guidance and Image Matting to solve the automatic segmentation\nproblem of weld regions. In the existing semantic segmentation networks, the\nboundary information can be preserved by fusing the features of both high-level\nand low-level layers. However, this method can lead to insufficient expression\nof the spatial information in the low-level layer, resulting in inaccurate\nsegmentation boundary positioning. We propose a detailed guidance module based\non heatmaps to fully express the segmented region boundary information in the\nlow-level network to address this problem. Specifically, the expression of\nboundary information can be enhanced by adding a detailed branch to predict\nsegmented boundary and then matching it with the boundary heat map generated by\nmask labels to calculate the mean square error loss. In addition, although deep\nlearning has achieved great success in the field of semantic segmentation, the\nprecision of the segmentation boundary region is not high due to the loss of\ndetailed information caused by the classical segmentation network in the\nprocess of encoding and decoding process. This paper introduces a matting\nalgorithm to calibrate the boundary of the segmentation region of the semantic\nsegmentation network to solve this problem. Through many experiments on\nindustrial weld data sets, the effectiveness of our method is demonstrated, and\nthe MIOU reaches 97.93%. It is worth noting that this performance is comparable\nto human manual segmentation ( MIOU 97.96%).",
    "descriptor": "",
    "authors": [
      "Qi Wang",
      "Jingwu Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04297"
  },
  {
    "id": "arXiv:2207.04303",
    "title": "Towards Achieving Thermal Comfort through Physiologically Cloud based  controlled HVAC System",
    "abstract": "Thermal comfort in shared spaces is essential to occupants well-being and\nnecessary in the management of energy consumption. Existing thermal control\nsystems for indoor shared spaces adjust temperature set points mechanically,\nmaking it difficult to intelligently achieve thermal comfort for all. Recent\nstudies have shown that thermal comfort in a shared space is difficult to\nachieve due to individual preferences and the inability of occupants to reach a\nthermal compromise on temperature set points. This paper proposes a thermal\ncomfort system to automatically adjust the temperature set-points in a shared\nspace whilst recognising individual preferences. The control strategy of the\nproposed system is based on an algorithm to adjust the temperature set point of\nthe shared space using the individual thermal preferences and predicted thermal\ncomfort value of the occupants. The thermal preferences of the occupants are\ndetermined first and used as part of the occupants profile, which is mapped to\nthermal comfort values predicted from the occupants measured physiological data\nand environmental data. A consensus is reached by the algorithm to find the\noptimal temperature set-point, which takes into account individual thermal\npreferences and their physiological responses.",
    "descriptor": "",
    "authors": [
      "Isibor Kennedy Ihianle",
      "Pedro Machado",
      "Kayode Owa",
      "David Ada Adama"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04303"
  },
  {
    "id": "arXiv:2207.04305",
    "title": "Training Robust Deep Models for Time-Series Domain: Novel Algorithms and  Theoretical Analysis",
    "abstract": "Despite the success of deep neural networks (DNNs) for real-world\napplications over time-series data such as mobile health, little is known about\nhow to train robust DNNs for time-series domain due to its unique\ncharacteristics compared to images and text data. In this paper, we propose a\nnovel algorithmic framework referred as RObust Training for Time-Series (RO-TS)\nto create robust DNNs for time-series classification tasks. Specifically, we\nformulate a min-max optimization problem over the model parameters by\nexplicitly reasoning about the robustness criteria in terms of additive\nperturbations to time-series inputs measured by the global alignment kernel\n(GAK) based distance. We also show the generality and advantages of our\nformulation using the summation structure over time-series alignments by\nrelating both GAK and dynamic time warping (DTW). This problem is an instance\nof a family of compositional min-max optimization problems, which are\nchallenging and open with unclear theoretical guarantee. We propose a\nprincipled stochastic compositional alternating gradient descent ascent\n(SCAGDA) algorithm for this family of optimization problems. Unlike traditional\nmethods for time-series that require approximate computation of distance\nmeasures, SCAGDA approximates the GAK based distance on-the-fly using a moving\naverage approach. We theoretically analyze the convergence rate of SCAGDA and\nprovide strong theoretical support for the estimation of GAK based distance.\nOur experiments on real-world benchmarks demonstrate that RO-TS creates more\nrobust DNNs when compared to adversarial training using prior methods that rely\non data augmentation or new definitions of loss functions. We also demonstrate\nthe importance of GAK for time-series data over the Euclidean distance. The\nsource code of RO-TS algorithms is available at\nhttps://github.com/tahabelkhouja/Robust-Training-for-Time-Series",
    "descriptor": "\nComments: Published AAAI 2022\n",
    "authors": [
      "Taha Belkhouja",
      "Yan Yan",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04305"
  },
  {
    "id": "arXiv:2207.04306",
    "title": "Out-of-Distribution Detection in Time-Series Domain: A Novel Seasonal  Ratio Scoring Approach",
    "abstract": "Safe deployment of time-series classifiers for real-world applications relies\non the ability to detect the data which is not generated from the same\ndistribution as training data. This task is referred to as out-of-distribution\n(OOD) detection. We consider the novel problem of OOD detection for the\ntime-series domain. We discuss the unique challenges posed by time-series data\nand explain why prior methods from the image domain will perform poorly.\nMotivated by these challenges, this paper proposes a novel {\\em Seasonal Ratio\nScoring (SRS)} approach. SRS consists of three key algorithmic steps. First,\neach input is decomposed into class-wise semantic component and remainder.\nSecond, this decomposition is employed to estimate the class-wise conditional\nlikelihoods of the input and remainder using deep generative models. The\nseasonal ratio score is computed from these estimates. Third, a threshold\ninterval is identified from the in-distribution data to detect OOD examples.\nExperiments on diverse real-world benchmarks demonstrate that the SRS method is\nwell-suited for time-series OOD detection when compared to baseline methods.\nOpen-source code for SRS method is provided at\nhttps://github.com/tahabelkhouja/SRS",
    "descriptor": "",
    "authors": [
      "Taha Belkhouja",
      "Yan Yan",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04306"
  },
  {
    "id": "arXiv:2207.04307",
    "title": "Adversarial Framework with Certified Robustness for Time-Series Domain  via Statistical Features",
    "abstract": "Time-series data arises in many real-world applications (e.g., mobile health)\nand deep neural networks (DNNs) have shown great success in solving them.\nDespite their success, little is known about their robustness to adversarial\nattacks. In this paper, we propose a novel adversarial framework referred to as\nTime-Series Attacks via STATistical Features (TSA-STAT)}. To address the unique\nchallenges of time-series domain, TSA-STAT employs constraints on statistical\nfeatures of the time-series data to construct adversarial examples. Optimized\npolynomial transformations are used to create attacks that are more effective\n(in terms of successfully fooling DNNs) than those based on additive\nperturbations. We also provide certified bounds on the norm of the statistical\nfeatures for constructing adversarial examples. Our experiments on diverse\nreal-world benchmark datasets show the effectiveness of TSA-STAT in fooling\nDNNs for time-series domain and in improving their robustness. The source code\nof TSA-STAT algorithms is available at\nhttps://github.com/tahabelkhouja/Time-Series-Attacks-via-STATistical-Features",
    "descriptor": "\nComments: Published at Journal of Artificial Intelligence Research\n",
    "authors": [
      "Taha Belkhouja",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04307"
  },
  {
    "id": "arXiv:2207.04308",
    "title": "Dynamic Time Warping based Adversarial Framework for Time-Series Domain",
    "abstract": "Despite the rapid progress on research in adversarial robustness of deep\nneural networks (DNNs), there is little principled work for the time-series\ndomain. Since time-series data arises in diverse applications including mobile\nhealth, finance, and smart grid, it is important to verify and improve the\nrobustness of DNNs for the time-series domain. In this paper, we propose a\nnovel framework for the time-series domain referred as {\\em Dynamic Time\nWarping for Adversarial Robustness (DTW-AR)} using the dynamic time warping\nmeasure. Theoretical and empirical evidence is provided to demonstrate the\neffectiveness of DTW over the standard Euclidean distance metric employed in\nprior methods for the image domain. We develop a principled algorithm justified\nby theoretical analysis to efficiently create diverse adversarial examples\nusing random alignment paths. Experiments on diverse real-world benchmarks show\nthe effectiveness of DTW-AR to fool DNNs for time-series data and to improve\ntheir robustness using adversarial training. The source code of DTW-AR\nalgorithms is available at https://github.com/tahabelkhouja/DTW-AR",
    "descriptor": "",
    "authors": [
      "Taha Belkhouja",
      "Yan Yan",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04308"
  },
  {
    "id": "arXiv:2207.04312",
    "title": "At the Intersection of Deep Learning and Conceptual Art: The End of  Signature",
    "abstract": "MIT wanted to commission a large scale artwork that would serve to\n'illuminate a new campus gateway, inaugurate a space of exchange between MIT\nand Cambridge, and inspire our students, faculty, visitors, and the surrounding\ncommunity to engage with art in new ways and to have art be part of their daily\nlives.' Among other things, the art was to reflect the fact that scientific\ndiscovery is often the result of many individual contributions, both\nacknowledged and unacknowledged. In this work, a group of computer scientists\ncollaborated with a conceptual artist to produce a collective signature, or a\nsignature learned from contributions of an entire community. After collecting\nsignatures from two communities -- the university, and the surrounding city --\nthe computer scientists developed generative models and a human-in-the-loop\nfeedback process to work with the artist create an original signature-like\nstructure representative of each community. These signatures are now\nlarge-scale steel, LED and neon light sculptures that appear to sign two new\nbuildings in Cambridge, MA.",
    "descriptor": "",
    "authors": [
      "Divya Shanmugam",
      "Katie Lewis",
      "Jose Javier Gonzalez-Ortiz",
      "Agnieszka Kurant",
      "John Guttag"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.04312"
  },
  {
    "id": "arXiv:2207.04313",
    "title": "QKVA grid: Attention in Image Perspective and Stacked DETR",
    "abstract": "We present a new model named Stacked-DETR(SDETR), which inherits the main\nideas in canonical DETR. We improve DETR in two directions: simplifying the\ncost of training and introducing the stacked architecture to enhance the\nperformance. To the former, we focus on the inside of the Attention block and\npropose the QKVA grid, a new perspective to describe the process of attention.\nBy this, we can step further on how Attention works for image problems and the\neffect of multi-head. These two ideas contribute the design of single-head\nencoder-layer. To the latter, SDETR reaches great improvement(+1.1AP, +3.4APs)\nto DETR. Especially to the performance on small objects, SDETR achieves better\nresults to the optimized Faster R-CNN baseline, which was a shortcoming in\nDETR. Our changes are based on the code of DETR. Training code and pretrained\nmodels are available at https://github.com/shengwenyuan/sdetr.",
    "descriptor": "",
    "authors": [
      "Wenyuan Sheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04313"
  },
  {
    "id": "arXiv:2207.04316",
    "title": "Improving Diffusion Model Efficiency Through Patching",
    "abstract": "Diffusion models are a powerful class of generative models that iteratively\ndenoise samples to produce data. While many works have focused on the number of\niterations in this sampling procedure, few have focused on the cost of each\niteration. We find that adding a simple ViT-style patching transformation can\nconsiderably reduce a diffusion model's sampling time and memory usage. We\njustify our approach both through an analysis of the diffusion model objective,\nand through empirical experiments on LSUN Church, ImageNet 256, and FFHQ 1024.\nWe provide implementations in Tensorflow and Pytorch.",
    "descriptor": "",
    "authors": [
      "Troy Luhman",
      "Eric Luhman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04316"
  },
  {
    "id": "arXiv:2207.04317",
    "title": "On the Relationship between Counterfactual Explainer and Recommender: A  Framework and Preliminary Observations",
    "abstract": "Recommender systems employ machine learning models to learn from historical\ndata to predict the preferences of users. Deep neural network (DNN) models such\nas neural collaborative filtering (NCF) are increasingly popular. However, the\ntangibility and trustworthiness of the recommendations are questionable due to\nthe complexity and lack of explainability of the models. To enable\nexplainability, recent techniques such as ACCENT and FIA are looking for\ncounterfactual explanations that are specific historical actions of a user, the\nremoval of which leads to a change to the recommendation result. In this work,\nwe present a general framework for both DNN and non-DNN models so that the\ncounterfactual explainers all belong to it with specific choices of components.\nThis framework first estimates the influence of a certain historical action\nafter its removal and then uses search algorithms to find the minimal set of\nsuch actions for the counterfactual explanation. With this framework, we are\nable to investigate the relationship between the explainers and recommenders.\nWe empirically study two recommender models (NCF and Factorization Machine) and\ntwo datasets (MovieLens and Yelp). We analyze the relationship between the\nperformance of the recommender and the quality of the explainer. We observe\nthat with standard evaluation metrics, the explainers deliver worse performance\nwhen the recommendations are more accurate. This indicates that having good\nexplanations to correct predictions is harder than having them to wrong\npredictions. The community needs more fine-grained evaluation metrics to\nmeasure the quality of counterfactual explanations to recommender systems.",
    "descriptor": "\nComments: Accepted by KDD 2022 Workshop on Data Science and Artificial Intelligence for Responsible Recommendations (DS4RRS)\n",
    "authors": [
      "Gang Liu",
      "Zhihan Zhang",
      "Zheng Ning",
      "Meng Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.04317"
  },
  {
    "id": "arXiv:2207.04318",
    "title": "Determinant Maximization via Matroid Intersection Algorithms",
    "abstract": "Determinant maximization problem gives a general framework that models\nproblems arising in as diverse fields as statistics\n\\cite{pukelsheim2006optimal}, convex geometry \\cite{Khachiyan1996}, fair\nallocations\\linebreak \\cite{anari2016nash}, combinatorics \\cite{AnariGV18},\nspectral graph theory \\cite{nikolov2019proportional}, network design, and\nrandom processes \\cite{kulesza2012determinantal}. In an instance of a\ndeterminant maximization problem, we are given a collection of vectors\n$U=\\{v_1,\\ldots, v_n\\} \\subset \\RR^d$, and a goal is to pick a subset\n$S\\subseteq U$ of given vectors to maximize the determinant of the matrix\n$\\sum_{i\\in S} v_i v_i^\\top $. Often, the set $S$ of picked vectors must\nsatisfy additional combinatorial constraints such as cardinality constraint\n$\\left(|S|\\leq k\\right)$ or matroid constraint ($S$ is a basis of a matroid\ndefined on the vectors).\nIn this paper, we give a polynomial-time deterministic algorithm that returns\na $r^{O(r)}$-approximation for any matroid of rank $r\\leq d$. This improves\nprevious results that give $e^{O(r^2)}$-approximation algorithms relying on\n$e^{O(r)}$-approximate \\emph{estimation} algorithms\n\\cite{NikolovS16,anari2017generalization,AnariGV18,madan2020maximizing} for any\n$r\\leq d$. All previous results use convex relaxations and their relationship\nto stable polynomials and strongly log-concave polynomials. In contrast, our\nalgorithm builds on combinatorial algorithms for matroid intersection, which\niteratively improve any solution by finding an \\emph{alternating negative\ncycle} in the \\emph{exchange graph} defined by the matroids. While the\n$\\det(.)$ function is not linear, we show that taking appropriate linear\napproximations at each iteration suffice to give the improved approximation\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Adam Brown",
      "Aditi Laddha",
      "Madhusudhan Pittu",
      "Mohit Singh",
      "Prasad Tetali"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.04318"
  },
  {
    "id": "arXiv:2207.04320",
    "title": "Snipper: A Spatiotemporal Transformer for Simultaneous Multi-Person 3D  Pose Estimation Tracking and Forecasting on a Video Snippet",
    "abstract": "Multi-person pose understanding from RGB videos includes three complex tasks:\npose estimation, tracking and motion forecasting. Among these three tasks, pose\nestimation and tracking are correlated, and tracking is crucial to motion\nforecasting. Most existing works either focus on a single task or employ\ncascaded methods to solve each individual task separately. In this paper, we\npropose Snipper, a framework to perform multi-person 3D pose estimation,\ntracking and motion forecasting simultaneously in a single inference.\nSpecifically, we first propose a deformable attention mechanism to aggregate\nspatiotemporal information from video snippets. Building upon this deformable\nattention, a visual transformer is learned to encode the spatiotemporal\nfeatures from multi-frame images and to decode informative pose features to\nupdate multi-person pose queries. Last, these queries are regressed to predict\nmulti-person pose trajectories and future motions in one forward pass. In the\nexperiments, we show the effectiveness of Snipper on three challenging public\ndatasets where a generic model rivals specialized state-of-art baselines for\npose estimation, tracking, and forecasting. Code is available at\n\\href{https://github.com/JimmyZou/Snipper}{https://github.com/JimmyZou/Snipper}.",
    "descriptor": "",
    "authors": [
      "Shihao Zou",
      "Yuanlu Xu",
      "Chao Li",
      "Lingni Ma",
      "Li Cheng",
      "Minh Vo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04320"
  },
  {
    "id": "arXiv:2207.04321",
    "title": "Minimum strongly biconnected spanning directed subgraph problem",
    "abstract": "Let $G=(V,E)$ be a strongly biconnected directed graph. In this paper we\nconsider the problem of computing an edge subset $H \\subseteq E$ of minimum\nsize such that the directed subgraph $(V,H)$ is strongly biconnected.",
    "descriptor": "",
    "authors": [
      "Raed Jaberi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.04321"
  },
  {
    "id": "arXiv:2207.04325",
    "title": "Unsupervised Joint Image Transfer and Uncertainty Quantification using  Patch Invariant Networks",
    "abstract": "Unsupervised image transfer enables intra- and inter-modality transfer for\nmedical applications where a large amount of paired training data is not\nabundant. To ensure a structure-preserving mapping from the input to the target\ndomain, existing methods for unpaired medical image transfer are commonly based\non cycle-consistency, causing additional computation resources and instability\ndue to the learning of an inverse mapping. This paper presents a novel method\nfor uni-directional domain mapping where no paired data is needed throughout\nthe entire training process. A reasonable transfer is ensured by employing the\nGAN architecture and a novel generator loss based on patch invariance. To be\nmore precise, generator outputs are evaluated and compared on different scales,\nwhich brings increased attention to high-frequency details as well as implicit\ndata augmentation. This novel term also gives the opportunity to predict\naleatoric uncertainty by modeling an input-dependent scale map for the patch\nresiduals. The proposed method is comprehensively evaluated on three renowned\nmedical databases. Superior accuracy on these datasets compared to four\ndifferent state-of-the-art methods for unpaired image transfer suggests the\ngreat potential of this approach for uncertainty-aware medical image\ntranslation. Implementation of the proposed framework is released here:\nhttps://github.com/anger-man/unsupervised-image-transfer-and-uq.",
    "descriptor": "",
    "authors": [
      "Christoph Angermann",
      "Markus Haltmeier",
      "Ahsan Raza Siyal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.04325"
  },
  {
    "id": "arXiv:2207.04327",
    "title": "Error Analysis of Tensor-Train Cross Approximation",
    "abstract": "Tensor train decomposition is widely used in machine learning and quantum\nphysics due to its concise representation of high-dimensional tensors,\novercoming the curse of dimensionality. Cross approximation-originally\ndeveloped for representing a matrix from a set of selected rows and columns-is\nan efficient method for constructing a tensor train decomposition of a tensor\nfrom few of its entries. While tensor train cross approximation has achieved\nremarkable performance in practical applications, its theoretical analysis, in\nparticular regarding the error of the approximation, is so far lacking. To our\nknowledge, existing results only provide element-wise approximation accuracy\nguarantees, which lead to a very loose bound when extended to the entire\ntensor. In this paper, we bridge this gap by providing accuracy guarantees in\nterms of the entire tensor for both exact and noisy measurements. Our results\nillustrate how the choice of selected subtensors affects the quality of the\ncross approximation and that the approximation error caused by model error\nand/or measurement error may not grow exponentially with the order of the\ntensor. These results are verified by numerical experiments, and may have\nimportant implications for the usefulness of cross approximations for\nhigh-order tensors, such as those encountered in the description of quantum\nmany-body states.",
    "descriptor": "",
    "authors": [
      "Zhen Qin",
      "Alexander Lidiak",
      "Zhexuan Gong",
      "Gongguo Tang",
      "Michael B. Wakin",
      "Zhihui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04327"
  },
  {
    "id": "arXiv:2207.04330",
    "title": "Multi-Model Federated Learning with Provable Guarantees",
    "abstract": "Federated Learning (FL) is a variant of distributed learning where edge\ndevices collaborate to learn a model without sharing their data with the\ncentral server or each other. We refer to the process of training multiple\nindependent models simultaneously in a federated setting using a common pool of\nclients as multi-model FL. In this work, we propose two variants of the popular\nFedAvg algorithm for multi-model FL, with provable convergence guarantees. We\nfurther show that for the same amount of computation, multi-model FL can have\nbetter performance than training each model separately. We supplement our\ntheoretical results with experiments in strongly convex, convex, and non-convex\nsettings.",
    "descriptor": "",
    "authors": [
      "Neelkamal Bhuyan",
      "Sharayu Moharir",
      "Gauri Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.04330"
  },
  {
    "id": "arXiv:2207.04335",
    "title": "Development and Testing of a Smart Bin toward Automated Rearing of Black  Soldier Fly Larvae",
    "abstract": "The Black Soldier Fly (BSF), can be an effective alternative to traditional\ndisposal of food and agricultural waste (biowaste) such as landfills because\nits larvae are able to quickly transform biowaste into ready-to-use biomass.\nHowever, several challenges remain to ensure that BSF farming is economically\nviable at different scales and can be widely implemented. Manual labor is\nrequired to ensure optimal conditions to rear the larvae, from aerating the\nfeeding substrate to monitoring abiotic conditions during the growth cycle.\nThis paper introduces a proof-of-concept automated method of rearing BSF larvae\nto ensure optimal growing conditions while at the same time reducing manual\nlabor. We retrofit existing BSF rearing bins with a \"smart lid,\" named as such\ndue to the hot-swappable nature of the lid with multiple bins. The system\nautomatically aerates the larvae-diet substrate and provides bio-information of\nthe larvae to users in real time. The proposed solution uses a custom aeration\nmethod and an array of sensors to create a soft real time system. Growth of\nlarvae is monitored using thermal imaging and classical computer vision\ntechniques. Experimental testing reveals that our automated approach produces\nBSF larvae on par with manual techniques.",
    "descriptor": "",
    "authors": [
      "Kevin Urrutia Avila",
      "Merrick Campbell",
      "Kerry Mauck",
      "Marco Gebiola",
      "Konstantinos Karydis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04335"
  },
  {
    "id": "arXiv:2207.04338",
    "title": "Variance Reduced ProxSkip: Algorithm, Theory and Application to  Federated Learning",
    "abstract": "We study distributed optimization methods based on the {\\em local training\n(LT)} paradigm: achieving communication efficiency by performing richer local\ngradient-based training on the clients before parameter averaging. Looking back\nat the progress of the field, we {\\em identify 5 generations of LT methods}: 1)\nheuristic, 2) homogeneous, 3) sublinear, 4) linear, and 5) accelerated. The\n5${}^{\\rm th}$ generation, initiated by the ProxSkip method of Mishchenko,\nMalinovsky, Stich and Richt\\'{a}rik (2022) and its analysis, is characterized\nby the first theoretical confirmation that LT is a communication acceleration\nmechanism. Inspired by this recent progress, we contribute to the 5${}^{\\rm\nth}$ generation of LT methods by showing that it is possible to enhance them\nfurther using {\\em variance reduction}. While all previous theoretical results\nfor LT methods ignore the cost of local work altogether, and are framed purely\nin terms of the number of communication rounds, we show that our methods can be\nsubstantially faster in terms of the {\\em total training cost} than the\nstate-of-the-art method ProxSkip in theory and practice in the regime when\nlocal computation is sufficiently expensive. We characterize this threshold\ntheoretically, and confirm our theoretical predictions with empirical results.",
    "descriptor": "\nComments: 38 pages, 2 algorithms, 4 theorems, 11 figures\n",
    "authors": [
      "Grigory Malinovsky",
      "Kai Yi",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04338"
  },
  {
    "id": "arXiv:2207.04342",
    "title": "Improved Lower Bounds for Submodular Function Minimization",
    "abstract": "We provide a generic technique for constructing families of submodular\nfunctions to obtain lower bounds for submodular function minimization (SFM).\nApplying this technique, we prove that any deterministic SFM algorithm on a\nground set of $n$ elements requires at least $\\Omega(n \\log n)$ queries to an\nevaluation oracle. This is the first super-linear query complexity lower bound\nfor SFM and improves upon the previous best lower bound of $2n$ given by [Graur\net al., ITCS 2020]. Using our construction, we also prove that any (possibly\nrandomized) parallel SFM algorithm, which can make up to $\\mathsf{poly}(n)$\nqueries per round, requires at least $\\Omega(n / \\log n)$ rounds to minimize a\nsubmodular function. This improves upon the previous best lower bound of\n$\\tilde{\\Omega}(n^{1/3})$ rounds due to [Chakrabarty et al., FOCS 2021], and\nsettles the parallel complexity of query-efficient SFM up to logarithmic\nfactors due to a recent advance in [Jiang, SODA 2021].",
    "descriptor": "\nComments: To appear in FOCS 2022\n",
    "authors": [
      "Deeparnab Chakrabarty",
      "Andrei Graur",
      "Haotian Jiang",
      "Aaron Sidford"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04342"
  },
  {
    "id": "arXiv:2207.04343",
    "title": "Explaining Chest X-ray Pathologies in Natural Language",
    "abstract": "Most deep learning algorithms lack explanations for their predictions, which\nlimits their deployment in clinical practice. Approaches to improve\nexplainability, especially in medical imaging, have often been shown to convey\nlimited information, be overly reassuring, or lack robustness. In this work, we\nintroduce the task of generating natural language explanations (NLEs) to\njustify predictions made on medical images. NLEs are human-friendly and\ncomprehensive, and enable the training of intrinsically explainable models. To\nthis goal, we introduce MIMIC-NLE, the first, large-scale, medical imaging\ndataset with NLEs. It contains over 38,000 NLEs, which explain the presence of\nvarious thoracic pathologies and chest X-ray findings. We propose a general\napproach to solve the task and evaluate several architectures on this dataset,\nincluding via clinician assessment.",
    "descriptor": "",
    "authors": [
      "Maxime Kayser",
      "Cornelius Emde",
      "Oana-Maria Camburu",
      "Guy Parsons",
      "Bartlomiej Papiez",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04343"
  },
  {
    "id": "arXiv:2207.04344",
    "title": "Freedom to Choose: Understanding Input Modality Preferences of People  with Upper-body Motor Impairments for Activities of Daily Living",
    "abstract": "Many people with upper-body motor impairments encounter challenges while\nperforming Activities of Daily Living (ADLs) and Instrumental Activities of\nDaily Living (IADLs), such as toileting, grooming, and managing finances, which\nhave impacts on their Quality of Life (QOL). Although existing assistive\ntechnologies enable people with upper-body motor impairments to use different\ninput modalities to interact with computing devices independently (e.g., using\nvoice to interact with a computer), many people still require Personal Care\nAssistants (PCAs) to perform ADLs. Multimodal input has the potential to enable\nusers to perform ADLs without human assistance. We conducted 12 semi-structured\ninterviews with people who have upper-body motor impairments to capture their\nexisting practices and challenges of performing ADLs, identify opportunities to\nexpand the input possibilities for assistive devices, and understand user\npreferences for multimodal interaction during everyday tasks. Finally, we\ndiscuss implications for the design and use of multimodal input solutions to\nsupport user independence and collaborative experiences when performing daily\nliving tasks.",
    "descriptor": "\nComments: ASSETS 2022\n",
    "authors": [
      "Franklin Mingzhe Li",
      "Michael Xieyang Liu",
      "Yang Zhang",
      "Patrick Carrington"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.04344"
  },
  {
    "id": "arXiv:2207.04350",
    "title": "Distributed-Memory Parallel Contig Generation for De Novo Long-Read  Genome Assembly",
    "abstract": "De novo genome assembly, i.e., rebuilding the sequence of an unknown genome\nfrom redundant and erroneous short sequences, is a key but computationally\nintensive step in many genomics pipelines. The exponential growth of genomic\ndata is increasing the computational demand and requires scalable,\nhigh-performance approaches. In this work, we present a novel\ndistributed-memory algorithm that, from a string graph representation of the\ngenome and using sparse matrices, generates the contig set, i.e., overlapping\nsequences that form a map representing a region of a chromosome. Using matrix\nabstraction, we mask branches in the string graph and compute the connected\ncomponent to group genomic sequences that belong to the same linear chain\n(i.e., contig). Then, we perform multiway number partitioning to minimize the\nload imbalance in local assembly, i.e., concatenation of sequences from a given\ncontig. Based on the assignment obtained by partitioning, we compute the induce\nsubgraph function to redistribute sequences between processes, resulting in a\nset of local sparse matrices. Finally, we traverse each matrix using\ndepth-first search to concatenate sequences. Our algorithm shows good scaling\nwith parallel efficiency up to 80% on 128 nodes, resulting in uniform genome\ncoverage and showing promising results in terms of assembly quality. Our contig\ngeneration algorithm localizes the assembly process to significantly reduce the\namount of computation spent on this step. Our work is a step forward for\nefficient de novo long read assembly of large genomes in a distributed memory.",
    "descriptor": "\nComments: ICPP22, August 29-September 1, 2022, Bordeaux, France\n",
    "authors": [
      "Giulia Guidi",
      "Gabriel Raulet",
      "Daniel Rokhsar",
      "Leonid Oliker",
      "Katherine Yelick",
      "Aydin Buluc"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2207.04350"
  },
  {
    "id": "arXiv:2207.04354",
    "title": "An Introduction to Lifelong Supervised Learning",
    "abstract": "This primer is an attempt to provide a detailed summary of the different\nfacets of lifelong learning. We start with Chapter 2 which provides a\nhigh-level overview of lifelong learning systems. In this chapter, we discuss\nprominent scenarios in lifelong learning (Section 2.4), provide 8 Introduction\na high-level organization of different lifelong learning approaches (Section\n2.5), enumerate the desiderata for an ideal lifelong learning system (Section\n2.6), discuss how lifelong learning is related to other learning paradigms\n(Section 2.7), describe common metrics used to evaluate lifelong learning\nsystems (Section 2.8). This chapter is more useful for readers who are new to\nlifelong learning and want to get introduced to the field without focusing on\nspecific approaches or benchmarks.",
    "descriptor": "\nComments: Lifelong Learning Primer\n",
    "authors": [
      "Shagun Sodhani",
      "Mojtaba Farmazi",
      "Sanket Vaibhav Mehta",
      "Pranshu Malviya",
      "Mohamed Abdelsalam",
      "Janarthanan Janarthanan",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04354"
  },
  {
    "id": "arXiv:2207.04356",
    "title": "A Comparative Study of Self-supervised Speech Representation Based Voice  Conversion",
    "abstract": "We present a large-scale comparative study of self-supervised speech\nrepresentation (S3R)-based voice conversion (VC). In the context of\nrecognition-synthesis VC, S3Rs are attractive owing to their potential to\nreplace expensive supervised representations such as phonetic posteriorgrams\n(PPGs), which are commonly adopted by state-of-the-art VC systems. Using\nS3PRL-VC, an open-source VC software we previously developed, we provide a\nseries of in-depth objective and subjective analyses under three VC settings:\nintra-/cross-lingual any-to-one (A2O) and any-to-any (A2A) VC, using the voice\nconversion challenge 2020 (VCC2020) dataset. We investigated S3R-based VC in\nvarious aspects, including model type, multilinguality, and supervision. We\nalso studied the effect of a post-discretization process with k-means\nclustering and showed how it improves in the A2A setting. Finally, the\ncomparison with state-of-the-art VC systems demonstrates the competitiveness of\nS3R-based VC and also sheds light on the possible improving directions.",
    "descriptor": "\nComments: Accepted to IEEE Journal of Selected Topics in Signal Processing. arXiv admin note: substantial text overlap with arXiv:2110.06280\n",
    "authors": [
      "Wen-Chin Huang",
      "Shu-Wen Yang",
      "Tomoki Hayashi",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04356"
  },
  {
    "id": "arXiv:2207.04357",
    "title": "Joint Analysis of Acoustic Scenes and Sound Events with Weakly labeled  Data",
    "abstract": "Considering that acoustic scenes and sound events are closely related to each\nother, in some previous papers, a joint analysis of acoustic scenes and sound\nevents utilizing multitask learning (MTL)-based neural networks was proposed.\nIn conventional methods, a strongly supervised scheme is applied to sound event\ndetection in MTL models, which requires strong labels of sound events in model\ntraining; however, annotating strong event labels is quite time-consuming. In\nthis paper, we thus propose a method for the joint analysis of acoustic scenes\nand sound events based on the MTL framework with weak labels of sound events.\nIn particular, in the proposed method, we introduce the multiple-instance\nlearning scheme for weakly supervised training of sound event detection and\nevaluate four pooling functions, namely, max pooling, average pooling,\nexponential softmax pooling, and attention pooling. Experimental results\nobtained using parts of the TUT Acoustic Scenes 2016/2017 and TUT Sound Events\n2016/2017 datasets show that the proposed MTL-based method with weak labels\noutperforms the conventional single-task-based scene classification and event\ndetection models with weak labels in terms of both the scene classification and\nevent detection performances.",
    "descriptor": "\nComments: Accepted to IWAENC2022\n",
    "authors": [
      "Shunsuke Tsubaki",
      "Keisuke Imoto",
      "Nobutaka Ono"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04357"
  },
  {
    "id": "arXiv:2207.04359",
    "title": "A Privacy-Preserving Energy Management System for Cooperative  Multi-Microgrid Networks",
    "abstract": "This paper presents an Energy Management System (EMS) that considers power\nexchanges between a set of interconnected microgrids (MGs) and the main grid,\nin the context of Multi-MG (MMG) systems. The model is first formulated as a\ncentralized optimization problem, which is then decomposed into subproblems\ncorresponding to each MG, using Lagrangian relaxation, and solved through a\ndistributed approach using a subgradient method. The proposed model determines\nthe power exchanges minimizing the operation cost of each MG, considering grid\nconstraints and preserving the privacy of each MG by not revealing their\ngeneration cost and demand information. The distributed approach is validated\nwith respect to the centralized problem, and various case studies are presented\nto demonstrate the performance of the proposed approach, comparing the costs of\nthe MGs operating individually and cooperatively. The results show that all MGs\nin the MMG system improve their cost as consequence of the power exchanges,\nthus demonstrating the advantages of interconnecting MGs.",
    "descriptor": "\nComments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Carlos Ceja-Espinosa",
      "Mehrdad Pirnia",
      "Claudio A. Ca\u00f1izares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04359"
  },
  {
    "id": "arXiv:2207.04360",
    "title": "Motion Planning and Tracking Control of Unmanned Underwater Vehicles:  Technologies, Challenges and Prospects",
    "abstract": "The motion planning and tracking control techniques of unmanned underwater\nvehicles (UUV) are fundamentally significant for efficient and robust UUV\nnavigation, which is crucial for underwater rescue, facility maintenance,\nmarine resource exploration, aquatic recreation, etc. Studies on UUV motion\nplanning and tracking control have been growing rapidly worldwide, which are\nusually sorted into the following topics: task assignment of the multi-UUV\nsystem, UUV path planning and UUV trajectory tracking. This paper provides a\ncomprehensive review of conventional and intelligent technologies for motion\nplanning and tracking control of UUVs. Analysis of the benefits and drawbacks\nof these various methodologies in literature is presented. In addition, the\nchallenges and prospects of UUV motion planning and tracking control are\nprovided as possible developments for future research.",
    "descriptor": "",
    "authors": [
      "Danjie Zhu",
      "Tao Yan",
      "Simon X. Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04360"
  },
  {
    "id": "arXiv:2207.04361",
    "title": "State Dropout-Based Curriculum Reinforcement Learning for Self-Driving  at Unsignalized Intersections",
    "abstract": "Traversing intersections is a challenging problem for autonomous vehicles,\nespecially when the intersections do not have traffic control. Recently deep\nreinforcement learning has received massive attention due to its success in\ndealing with autonomous driving tasks. In this work, we address the problem of\ntraversing unsignalized intersections using a novel curriculum for deep\nreinforcement learning. The proposed curriculum leads to: 1) A faster training\nprocess for the reinforcement learning agent, and 2) Better performance\ncompared to an agent trained without curriculum. Our main contribution is\ntwo-fold: 1) Presenting a unique curriculum for training deep reinforcement\nlearning agents, and 2) showing the application of the proposed curriculum for\nthe unsignalized intersection traversal task. The framework expects processed\nobservations of the surroundings from the perception system of the autonomous\nvehicle. We test our method in the CommonRoad motion planning simulator on\nT-intersections and four-way intersections.",
    "descriptor": "\nComments: 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 6 pages, 6 figures\n",
    "authors": [
      "Shivesh Khaitan",
      "John M. Dolan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04361"
  },
  {
    "id": "arXiv:2207.04362",
    "title": "Abstract Processes in the Absence of Conflicts in General  Place/Transition Systems",
    "abstract": "Goltz and Reisig generalised Petri's concept of processes of one-safe Petri\nnets to general nets where places carry multiple tokens. BD-processes are\nequivalence classes of Goltz-Reisig processes connected through the swapping\ntransformation of Best and Devillers; they can be considered as an alternative\nrepresentation of runs of nets. Here we present an order respecting bijection\nbetween the BD-processes and the FS-processes of a countable net, the latter\nbeing defined -- in an analogous way -- as equivalence classes of firing\nsequences. Using this, we show that a countable net without binary conflicts\nhas a (unique) largest BD-process.",
    "descriptor": "\nComments: The above result appeared already in our technical report arXiv:2103.00729, although formulated and proven differently, since there we didn't have the preorder $\\sqsubseteq_1^\\infty$, introduced in arXiv:2103.01490. Our revised proofs are conceptually simpler, as they avoid the auxiliary concepts of BD-runs and FS-runs\n",
    "authors": [
      "Rob van Glabbeek",
      "Ursula Goltz",
      "Jens-Wolfhard Schicke-Uffmann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.04362"
  },
  {
    "id": "arXiv:2207.04363",
    "title": "Secure UAV-to-Ground MIMO Communications: Joint Transceiver and Location  Optimization",
    "abstract": "Unmanned aerial vehicles (UAVs) are foreseen to constitute promising airborne\ncommunication devices as a benefit of their superior channel quality. But\nUAV-to-ground (U2G) communications are vulnerable to eavesdropping. Hence, we\nconceive a sophisticated physical layer security solution for improving the\nsecrecy rate of multi-antenna aided U2G systems. Explicitly, the secrecy rate\nof the U2G MIMO wiretap channels is derived by using random matrix theory. The\nresultant explicit expression is then applied in the joint optimization of the\nMIMO transceiver and the UAV location relying on an alternating optimization\ntechnique. Our numerical results show that the joint transceiver and location\noptimization conceived facilitates secure communications even in the\nchallenging scenario, where the legitimate channel of confidential information\nis inferior to the eavesdropping channel.",
    "descriptor": "\nComments: 15 pages, 11 figures. To appear in IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Zhong Zheng",
      "Xinyao Wang",
      "Zesong Fei",
      "Qingqing Wu",
      "Bin Li",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.04363"
  },
  {
    "id": "arXiv:2207.04364",
    "title": "Planning Sequential Tasks on Contact Graph",
    "abstract": "We devise a 3D scene graph representation, contact graph+ (cg+), for\nefficient sequential task planning. Augmented with predicate-like attributes,\nthis contact graph-based representation abstracts scene layouts with succinct\ngeometric information and valid robot-scene interactions. Goal configurations,\nnaturally specified on contact graphs, can be produced by a genetic algorithm\nwith a stochastic optimization method. A task plan is then initialized by\ncomputing the Graph Editing Distance (GED) between the initial contact graphs\nand the goal configurations, which generates graph edit operations\ncorresponding to possible robot actions. We finalize the task plan by imposing\nconstraints to regulate the temporal feasibility of graph edit operations,\nensuring valid task and motion correspondences. In a series of simulations and\nexperiments, robots successfully complete complex sequential object\nrearrangement tasks that are difficult to specify using conventional planning\nlanguage like Planning Domain Definition Language (PDDL), demonstrating the\nhigh feasibility and potential of robot sequential task planning on contact\ngraph.",
    "descriptor": "\nComments: 8 pages, 6 figures. Accepted by IROS 2022\n",
    "authors": [
      "Ziyuan Jiao",
      "Yida Niu",
      "Zeyu Zhang",
      "Song-Chun Zhu",
      "Yixin Zhu",
      "Hangxin Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04364"
  },
  {
    "id": "arXiv:2207.04367",
    "title": "Domain Adaptation Under Behavioral and Temporal Shifts for Natural Time  Series Mobile Activity Recognition",
    "abstract": "Increasingly, human behavior is captured on mobile devices, leading to an\nincreased interest in automated human activity recognition. However, existing\ndatasets typically consist of scripted movements. Our long-term goal is to\nperform mobile activity recognition in natural settings. We collect a dataset\nto support this goal with activity categories that are relevant for downstream\ntasks such as health monitoring and intervention. Because of the large\nvariations present in human behavior, we collect data from many participants\nacross two different age groups. Because human behavior can change over time,\nwe also collect data from participants over a month's time to capture the\ntemporal drift. We hypothesize that mobile activity recognition can benefit\nfrom unsupervised domain adaptation algorithms. To address this need and test\nthis hypothesis, we analyze the performance of domain adaptation across people\nand across time. We then enhance unsupervised domain adaptation with\ncontrastive learning and with weak supervision when label proportions are\navailable. The dataset is available at\nhttps://github.com/WSU-CASAS/smartwatch-data",
    "descriptor": "\nComments: 8th SIGKDD International Workshop on Mining and Learning from Time Series, 2022\n",
    "authors": [
      "Garrett Wilson",
      "Janardhan Rao Doppa",
      "Diane J. Cook"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04367"
  },
  {
    "id": "arXiv:2207.04374",
    "title": "The $q$-ary Golay complementary arrays of size $\\mathbf{2}^{(m)}$ are  standard",
    "abstract": "To find the non-standard binary Golay complementary sequences (GCSs) of\nlength $2^{m}$ or theoretically prove the nonexistence of them are still open.\nSince it has been shown that all the standard $q$-ary (where $q$ is even) GCSs\nof length $2^m$ can be obtained by standard $q$-ary Golay complementary array\npair (GAP) of dimension $m$ and size $2\\times 2 \\times \\cdots \\times 2$\n(abbreviated to size $\\mathbf{2}^{(m)}$), it's natural to ask whether all the\n$q$-ary GAP of size $\\mathbf{2}^{(m)}$ are standard. We give a positive answer\nto this question.",
    "descriptor": "",
    "authors": [
      "Erzhong Xue",
      "Zilong Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04374"
  },
  {
    "id": "arXiv:2207.04375",
    "title": "An Input-Output Feedback Linearization based Exponentially Stable  Controller for Multi-UAV Payload Transport",
    "abstract": "In this paper, an exponentially stable trajectory tracking controller is\nproposed for multi-UAV payload transport. The multi-UAV payload system has a\n2-DOF magnetic spherical joint between the UAVs and the vertical rigid links of\nthe payload frame, so the UAVs can roll or pitch freely. These vertical links\nare rigidly attached to the payload and cannot move. An input-output feedback\nlinearized model is derived for the complete payload-UAV system along with\nthrust vectoring control for trajectory tracking of the payload. The\ntheoretical analysis on tracking control laws shows that control law is\nexponentially stable, thus guaranteeing safe transportation along the desired\ntrajectory. To validate the performance of the proposed control law, the\nresults for a numerical simulation as well as a high-fidelity Gazebo real-time\nsimulation are presented. Next, the robustness of the proposed controller is\nanalyzed against two practical situations: External disturbance on the payload\nand payload mass uncertainty. The results clearly indicate that the proposed\ncontroller is robust and computationally efficient while achieving\nexponentially stable trajectory tracking.",
    "descriptor": "\nComments: Submitted to IEEE - Transactions on Robotics (IEEE - TRO)\n",
    "authors": [
      "Nishanth Rao",
      "Suresh Sundaram"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04375"
  },
  {
    "id": "arXiv:2207.04376",
    "title": "On Graph Neural Network Fairness in the Presence of Heterophilous  Neighborhoods",
    "abstract": "We study the task of node classification for graph neural networks (GNNs) and\nestablish a connection between group fairness, as measured by statistical\nparity and equal opportunity, and local assortativity, i.e., the tendency of\nlinked nodes to have similar attributes. Such assortativity is often induced by\nhomophily, the tendency for nodes of similar properties to connect. Homophily\ncan be common in social networks where systemic factors have forced individuals\ninto communities which share a sensitive attribute. Through synthetic graphs,\nwe study the interplay between locally occurring homophily and fair\npredictions, finding that not all node neighborhoods are equal in this respect\n-- neighborhoods dominated by one category of a sensitive attribute often\nstruggle to obtain fair treatment, especially in the case of diverging local\nclass and sensitive attribute homophily. After determining that a relationship\nbetween local homophily and fairness exists, we investigate if the issue of\nunfairness can be associated to the design of the applied GNN model. We show\nthat by adopting heterophilous GNN designs capable of handling disassortative\ngroup labels, group fairness in locally heterophilous neighborhoods can be\nimproved by up to 25% over homophilous designs in real and synthetic datasets.",
    "descriptor": "\nComments: 6 pages, KDD 2022 DLG Workshop\n",
    "authors": [
      "Donald Loveland",
      "Jiong Zhu",
      "Mark Heimann",
      "Ben Fish",
      "Michael T. Schaub",
      "Danai Koutra"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04376"
  },
  {
    "id": "arXiv:2207.04380",
    "title": "Connect the Dots: Tighter Discrete Approximations of Privacy Loss  Distributions",
    "abstract": "The privacy loss distribution (PLD) provides a tight characterization of the\nprivacy loss of a mechanism in the context of differential privacy (DP). Recent\nwork has shown that PLD-based accounting allows for tighter $(\\varepsilon,\n\\delta)$-DP guarantees for many popular mechanisms compared to other known\nmethods. A key question in PLD-based accounting is how to approximate any\n(potentially continuous) PLD with a PLD over any specified discrete support.\nWe present a novel approach to this problem. Our approach supports both\npessimistic estimation, which overestimates the hockey-stick divergence (i.e.,\n$\\delta$) for any value of $\\varepsilon$, and optimistic estimation, which\nunderestimates the hockey-stick divergence. Moreover, we show that our\npessimistic estimate is the best possible among all pessimistic estimates.\nExperimental evaluation shows that our approach can work with much larger\ndiscretization intervals while keeping a similar error bound compared to\nprevious approaches and yet give a better approximation than existing methods.",
    "descriptor": "\nComments: Appeared in Privacy Enhancing Technologies Symposium (PETS) 2022\n",
    "authors": [
      "Vadym Doroshenko",
      "Badih Ghazi",
      "Pritish Kamath",
      "Ravi Kumar",
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04380"
  },
  {
    "id": "arXiv:2207.04381",
    "title": "Faster Privacy Accounting via Evolving Discretization",
    "abstract": "We introduce a new algorithm for numerical composition of privacy random\nvariables, useful for computing the accurate differential privacy parameters\nfor composition of mechanisms. Our algorithm achieves a running time and memory\nusage of $\\mathrm{polylog}(k)$ for the task of self-composing a mechanism, from\na broad class of mechanisms, $k$ times; this class, e.g., includes the\nsub-sampled Gaussian mechanism, that appears in the analysis of differentially\nprivate stochastic gradient descent. By comparison, recent work by Gopi et al.\n(NeurIPS 2021) has obtained a running time of $\\widetilde{O}(\\sqrt{k})$ for the\nsame task. Our approach extends to the case of composing $k$ different\nmechanisms in the same class, improving upon their running time and memory\nusage from $\\widetilde{O}(k^{1.5})$ to $\\widetilde{O}(k)$.",
    "descriptor": "\nComments: Appeared in International Conference on Machine Learning (ICML) 2022\n",
    "authors": [
      "Badih Ghazi",
      "Pritish Kamath",
      "Ravi Kumar",
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04381"
  },
  {
    "id": "arXiv:2207.04384",
    "title": "Sparse and Safe Frequency Regulation for Inverter Intensive Microgrids",
    "abstract": "This paper developed a novel control approach for the sparse and safe\nfrequency regulation for inverter intensive microgrids (MGs). In the scenario,\nthe inverters and external grids are expected to reach a synchronized desired\nfrequency under regulations. To this end, the active power set-point acting as\na control from a high-level controller is designed while considering two\nimportant performance metrics \"sparsity\" and \"safety\", which are to reduce the\ninformation exchange between controllers and ensure that the frequency keeps in\nsafety regions during the whole operation process. Our proposed control design\nframework allows the sparse linear feedback controller (SLFC) to be unified\nwith a family of conditions for safe control using control barrier functions. A\nquadratic programming (QP) problem is then constructed, and the real-time\ncontrol policy is obtained by solving the QP problem. Importantly, we also\nfound that the real-time control for each inverter depends on the cross-layer\ncommunication network topology which is the union of the one between\ncontrollers from SLFC and the one determined by the power flow network.\nFurthermore, our approach has been validated through extensive numerical\nsimulations.",
    "descriptor": "",
    "authors": [
      "Junhui Zhang",
      "Lizhi Ding",
      "Xiaonan Lu",
      "Wenyuan Tang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04384"
  },
  {
    "id": "arXiv:2207.04391",
    "title": "Proceedings The 7th International Workshop on Symbolic-Numeric Methods  for Reasoning about CPS and IoT",
    "abstract": "The proceedings of the 7th International Workshop on Symbolic-Numeric Methods\nfor Reasoning about CPS and IoT (SNR 2021) feature five peer-reviewed\ncontributions and three invited talks.\nSNR focuses on the combination of symbolic and numeric methods for reasoning\nabout Cyber-Physical Systems and the Internet of Things to facilitate model\nidentification, specification, verification, and control synthesis for these\nsystems. The synergy between symbolic and numerical approaches is fruitful\nthanks to their complementarity.",
    "descriptor": "",
    "authors": [
      "Anne Remke",
      "Dung Hoang Tran"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2207.04391"
  },
  {
    "id": "arXiv:2207.04394",
    "title": "Radiomics-Guided Global-Local Transformer for Weakly Supervised  Pathology Localization in Chest X-Rays",
    "abstract": "Before the recent success of deep learning methods for automated medical\nimage analysis, practitioners used handcrafted radiomic features to\nquantitatively describe local patches of medical images. However, extracting\ndiscriminative radiomic features relies on accurate pathology localization,\nwhich is difficult to acquire in real-world settings. Despite advances in\ndisease classification and localization from chest X-rays, many approaches fail\nto incorporate clinically-informed domain knowledge. For these reasons, we\npropose a Radiomics-Guided Transformer (RGT) that fuses \\textit{global} image\ninformation with \\textit{local} knowledge-guided radiomics information to\nprovide accurate cardiopulmonary pathology localization and classification\n\\textit{without any bounding box annotations}. RGT consists of an image\nTransformer branch, a radiomics Transformer branch, and fusion layers that\naggregate image and radiomic information. Using the learned self-attention of\nits image branch, RGT extracts a bounding box for which to compute radiomic\nfeatures, which are further processed by the radiomics branch; learned image\nand radiomic features are then fused and mutually interact via cross-attention\nlayers. Thus, RGT utilizes a novel end-to-end feedback loop that can bootstrap\naccurate pathology localization only using image-level disease labels.\nExperiments on the NIH ChestXRay dataset demonstrate that RGT outperforms prior\nworks in weakly supervised disease localization (by an average margin of 3.6\\%\nover various intersection-over-union thresholds) and classification (by 1.1\\%\nin average area under the receiver operating characteristic curve). Code and\ntrained models will be released upon acceptance.",
    "descriptor": "",
    "authors": [
      "Yan Han",
      "Gregory Holste",
      "Ying Ding",
      "Ahmed Tewfik",
      "Yifan Peng",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04394"
  },
  {
    "id": "arXiv:2207.04396",
    "title": "Scalable Privacy-enhanced Benchmark Graph Generative Model for Graph  Convolutional Networks",
    "abstract": "A surge of interest in Graph Convolutional Networks (GCN) has produced\nthousands of GCN variants, with hundreds introduced every year. In contrast,\nmany GCN models re-use only a handful of benchmark datasets as many graphs of\ninterest, such as social or commercial networks, are proprietary. We propose a\nnew graph generation problem to enable generating a diverse set of benchmark\ngraphs for GCNs following the distribution of a source graph -- possibly\nproprietary -- with three requirements: 1) benchmark effectiveness as a\nsubstitute for the source graph for GCN research, 2) scalability to process\nlarge-scale real-world graphs, and 3) a privacy guarantee for end-users. With a\nnovel graph encoding scheme, we reframe large-scale graph generation problem\ninto medium-length sequence generation problem and apply the strong generation\npower of the Transformer architecture to the graph domain. Extensive\nexperiments across a vast body of graph generative models show that our model\ncan successfully generate benchmark graphs with the realistic graph structure,\nnode attributes, and node labels required to benchmark GCNs on node\nclassification tasks.",
    "descriptor": "",
    "authors": [
      "Minji Yoon",
      "Yue Wu",
      "John Palowitch",
      "Bryan Perozzi",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04396"
  },
  {
    "id": "arXiv:2207.04397",
    "title": "2DPASS: 2D Priors Assisted Semantic Segmentation on LiDAR Point Clouds",
    "abstract": "As camera and LiDAR sensors capture complementary information used in\nautonomous driving, great efforts have been made to develop semantic\nsegmentation algorithms through multi-modality data fusion. However,\nfusion-based approaches require paired data, i.e., LiDAR point clouds and\ncamera images with strict point-to-pixel mappings, as the inputs in both\ntraining and inference, which seriously hinders their application in practical\nscenarios. Thus, in this work, we propose the 2D Priors Assisted Semantic\nSegmentation (2DPASS), a general training scheme, to boost the representation\nlearning on point clouds, by fully taking advantage of 2D images with rich\nappearance. In practice, by leveraging an auxiliary modal fusion and\nmulti-scale fusion-to-single knowledge distillation (MSFSKD), 2DPASS acquires\nricher semantic and structural information from the multi-modal data, which are\nthen online distilled to the pure 3D network. As a result, equipped with\n2DPASS, our baseline shows significant improvement with only point cloud\ninputs. Specifically, it achieves the state-of-the-arts on two large-scale\nbenchmarks (i.e. SemanticKITTI and NuScenes), including top-1 results in both\nsingle and multiple scan(s) competitions of SemanticKITTI.",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Xu Yan",
      "Jiantao Gao",
      "Chaoda Zheng",
      "Chao Zheng",
      "Ruimao Zhang",
      "Shenghui Cui",
      "Zhen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04397"
  },
  {
    "id": "arXiv:2207.04398",
    "title": "Self-supervised Learning with Local Contrastive Loss for Detection and  Semantic Segmentation",
    "abstract": "We present a self-supervised learning (SSL) method suitable for semi-global\ntasks such as object detection and semantic segmentation. We enforce local\nconsistency between self-learned features, representing corresponding image\nlocations of transformed versions of the same image, by minimizing a\npixel-level local contrastive (LC) loss during training. LC-loss can be added\nto existing self-supervised learning methods with minimal overhead. We evaluate\nour SSL approach on two downstream tasks -- object detection and semantic\nsegmentation, using COCO, PASCAL VOC, and CityScapes datasets. Our method\noutperforms the existing state-of-the-art SSL approaches by 1.9% on COCO object\ndetection, 1.4% on PASCAL VOC detection, and 0.6% on CityScapes segmentation.",
    "descriptor": "",
    "authors": [
      "Ashraful Islam",
      "Ben Lundell",
      "Harpreet Sawhney",
      "Sudipta Sinha",
      "Peter Morales",
      "Richard J. Radke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04398"
  },
  {
    "id": "arXiv:2207.04399",
    "title": "Horizontal and Vertical Attention in Transformers",
    "abstract": "Transformers are built upon multi-head scaled dot-product attention and\npositional encoding, which aim to learn the feature representations and token\ndependencies. In this work, we focus on enhancing the distinctive\nrepresentation by learning to augment the feature maps with the self-attention\nmechanism in Transformers. Specifically, we propose the horizontal attention to\nre-weight the multi-head output of the scaled dot-product attention before\ndimensionality reduction, and propose the vertical attention to adaptively\nre-calibrate channel-wise feature responses by explicitly modelling\ninter-dependencies among different channels. We demonstrate the Transformer\nmodels equipped with the two attentions have a high generalization capability\nacross different supervised learning tasks, with a very minor additional\ncomputational cost overhead. The proposed horizontal and vertical attentions\nare highly modular, which can be inserted into various Transformer models to\nfurther improve the performance. Our code is available in the supplementary\nmaterial.",
    "descriptor": "",
    "authors": [
      "Litao Yu",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04399"
  },
  {
    "id": "arXiv:2207.04403",
    "title": "Self-attention on Multi-Shifted Windows for Scene Segmentation",
    "abstract": "Scene segmentation in images is a fundamental yet challenging problem in\nvisual content understanding, which is to learn a model to assign every image\npixel to a categorical label. One of the challenges for this learning task is\nto consider the spatial and semantic relationships to obtain descriptive\nfeature representations, so learning the feature maps from multiple scales is a\ncommon practice in scene segmentation. In this paper, we explore the effective\nuse of self-attention within multi-scale image windows to learn descriptive\nvisual features, then propose three different strategies to aggregate these\nfeature maps to decode the feature representation for dense prediction. Our\ndesign is based on the recently proposed Swin Transformer models, which totally\ndiscards convolution operations. With the simple yet effective multi-scale\nfeature learning and aggregation, our models achieve very promising performance\non four public scene segmentation datasets, PASCAL VOC2012, COCO-Stuff 10K,\nADE20K and Cityscapes.",
    "descriptor": "",
    "authors": [
      "Litao Yu",
      "Zhibin Li",
      "Jian Zhang",
      "Qiang Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04403"
  },
  {
    "id": "arXiv:2207.04410",
    "title": "CoMER: Modeling Coverage for Transformer-based Handwritten Mathematical  Expression Recognition",
    "abstract": "The Transformer-based encoder-decoder architecture has recently made\nsignificant advances in recognizing handwritten mathematical expressions.\nHowever, the transformer model still suffers from the lack of coverage problem,\nmaking its expression recognition rate (ExpRate) inferior to its RNN\ncounterpart. Coverage information, which records the alignment information of\nthe past steps, has proven effective in the RNN models. In this paper, we\npropose CoMER, a model that adopts the coverage information in the transformer\ndecoder. Specifically, we propose a novel Attention Refinement Module (ARM) to\nrefine the attention weights with past alignment information without hurting\nits parallelism. Furthermore, we take coverage information to the extreme by\nproposing self-coverage and cross-coverage, which utilize the past alignment\ninformation from the current and previous layers. Experiments show that CoMER\nimproves the ExpRate by 0.61%/2.09%/1.59% compared to the current\nstate-of-the-art model, and reaches 59.33%/59.81%/62.97% on the CROHME\n2014/2016/2019 test sets.",
    "descriptor": "\nComments: Accept by ECCV 2022\n",
    "authors": [
      "Wenqi Zhao",
      "Liangcai Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04410"
  },
  {
    "id": "arXiv:2207.04415",
    "title": "SFNet: Faster, Accurate, and Domain Agnostic Semantic Segmentation via  Semantic Flow",
    "abstract": "In this paper, we focus on exploring effective methods for faster, accurate,\nand domain agnostic semantic segmentation. Inspired by the Optical Flow for\nmotion alignment between adjacent video frames, we propose a Flow Alignment\nModule (FAM) to learn \\textit{Semantic Flow} between feature maps of adjacent\nlevels, and broadcast high-level features to high resolution features\neffectively and efficiently. Furthermore, integrating our FAM to a common\nfeature pyramid structure exhibits superior performance over other real-time\nmethods even on light-weight backbone networks, such as ResNet-18 and DFNet.\nThen to further speed up the inference procedure, we also present a novel Gated\nDual Flow Alignment Module to directly align high resolution feature maps and\nlow resolution feature maps where we term improved version network as\nSFNet-Lite. Extensive experiments are conducted on several challenging\ndatasets, where results show the effectiveness of both SFNet and SFNet-Lite. In\nparticular, the proposed SFNet-Lite series achieve 80.1 mIoU while running at\n60 FPS using ResNet-18 backbone and 78.8 mIoU while running at 120 FPS using\nSTDC backbone on RTX-3090. Moreover, we unify four challenging driving datasets\n(i.e., Cityscapes, Mapillary, IDD and BDD) into one large dataset, which we\nnamed Unified Driving Segmentation (UDS) dataset. It contains diverse domain\nand style information. We benchmark several representative works on UDS. Both\nSFNet and SFNet-Lite still achieve the best speed and accuracy trade-off on UDS\nwhich serves as a strong baseline in such a new challenging setting. All the\ncode and models are publicly available at https://github.com/lxtGH/SFSegNets.",
    "descriptor": "\nComments: Extension of Previous work arXiv:2002.10120\n",
    "authors": [
      "Xiangtai Li",
      "Jiangning Zhang",
      "Yibo Yang",
      "Guangliang Cheng",
      "Kuiyuan Yang",
      "Yunhai Tong",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04415"
  },
  {
    "id": "arXiv:2207.04418",
    "title": "Spatiotemporal motion planning with combinatorial reasoning for  autonomous driving",
    "abstract": "Motion planning for urban environments with numerous moving agents can be\nviewed as a combinatorial problem. With passing an obstacle before, after,\nright or left, there are multiple options an autonomous vehicle could choose to\nexecute. These combinatorial aspects need to be taken into account in the\nplanning framework. We address this problem by proposing a novel planning\napproach that combines trajectory planning and maneuver reasoning. We define a\nclassification for dynamic obstacles along a reference curve that allows us to\nextract tactical decision sequences. We separate longitudinal and lateral\nmovement to speed up the optimization-based trajectory planning. To map the set\nof obtained trajectories to maneuver variants, we define a semantic language to\ndescribe them. This allows us to choose an optimal trajectory while also\nensuring maneuver consistency over time. We demonstrate the capabilities of our\napproach for a scenario that is still widely considered to be challenging.",
    "descriptor": "\nComments: published at IEEE IV 2018\n",
    "authors": [
      "Klemens Esterle",
      "Patrick Hart",
      "Julian Bernhard",
      "Alois Knoll"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04418"
  },
  {
    "id": "arXiv:2207.04423",
    "title": "Dual-Correction Adaptation Network for Noisy Knowledge Transfer",
    "abstract": "Previous unsupervised domain adaptation (UDA) methods aim to promote target\nlearning via a single-directional knowledge transfer from label-rich source\ndomain to unlabeled target domain, while its reverse adaption from target to\nsource has not jointly been considered yet so far. In fact, in some real\nteaching practice, a teacher helps students learn while also gets promotion\nfrom students to some extent, which inspires us to explore a dual-directional\nknowledge transfer between domains, and thus propose a Dual-Correction\nAdaptation Network (DualCAN) in this paper. However, due to the asymmetrical\nlabel knowledge across domains, transfer from unlabeled target to labeled\nsource poses a more difficult challenge than the common source-to-target\ncounterpart. First, the target pseudo-labels predicted by source commonly\ninvolve noises due to model bias, hence in the reverse adaptation, they may\nhurt the source performance and bring a negative target-to-source transfer.\nSecondly, source domain usually contains innate noises, which will inevitably\naggravate the target noises, leading to noise amplification across domains. To\nthis end, we further introduce a Noise Identification and Correction (NIC)\nmodule to correct and recycle noises in both domains. To our best knowledge,\nthis is the first naive attempt of dual-directional adaptation for noisy UDA,\nand naturally applicable to noise-free UDA. A theory justification is given to\nstate the rationality of our intuition. Empirical results confirm the\neffectiveness of DualCAN with remarkable performance gains over\nstate-of-the-arts, particularly for extreme noisy tasks (e.g., ~+ 15% on Pw->Pr\nand Pr->Rw of Office-Home).",
    "descriptor": "",
    "authors": [
      "Yunyun Wang",
      "Weiwen Zheng",
      "Songcan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04423"
  },
  {
    "id": "arXiv:2207.04424",
    "title": "An Overview of Cyber Threats, Attacks, and Countermeasures on the  Primary Domains of Smart Cities",
    "abstract": "A smart city is a place where existing facilities and services are enhanced\nby digital technology to benefit people and companies. The most critical\ninfrastructures in this city are interconnected. Increased data exchange across\nmunicipal domains aims to manage the essential assets, leading to more\nautomation in city governance and optimization of the dynamic offered services.\nHowever, no clear guideline or standard exists for modeling these data flows.\nAs a result, operators, municipalities, policymakers, manufac-turers, solution\nproviders, and vendors are forced to accept systems with limited scalability\nand varying needs. Nonetheless, it is critical to raise awareness about smart\ncity cybersecurity and implement suitable measures to safeguard citizens'\nprivacy and security because the cyber threats seem to be well-organized,\ndiverse, and sophisticated. This study aims to present an overview of cyber\nthreats, attacks, and countermeasures on the primary domains of smart cities\n(smart government, smart mobility, smart environment, smart living, smart\nhealthcare, smart economy, and smart people) to present information extracted\nfrom state-of-the-art to policymakers to perceive the critical situation and,\nat the same time, to be a valuable resource for the scientific community.",
    "descriptor": "",
    "authors": [
      "Vasiliki Demertzi",
      "Stavros Demertzis",
      "Konstantinos Demertzis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04424"
  },
  {
    "id": "arXiv:2207.04429",
    "title": "LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language,  Vision, and Action",
    "abstract": "Goal-conditioned policies for robotic navigation can be trained on large,\nunannotated datasets, providing for good generalization to real-world settings.\nHowever, particularly in vision-based settings where specifying goals requires\nan image, this makes for an unnatural interface. Language provides a more\nconvenient modality for communication with robots, but contemporary methods\ntypically require expensive supervision, in the form of trajectories annotated\nwith language descriptions. We present a system, LM-Nav, for robotic navigation\nthat enjoys the benefits of training on unannotated large datasets of\ntrajectories, while still providing a high-level interface to the user. Instead\nof utilizing a labeled instruction following dataset, we show that such a\nsystem can be constructed entirely out of pre-trained models for navigation\n(ViNG), image-language association (CLIP), and language modeling (GPT-3),\nwithout requiring any fine-tuning or language-annotated robot data. We\ninstantiate LM-Nav on a real-world mobile robot and demonstrate long-horizon\nnavigation through complex, outdoor environments from natural language\ninstructions. For videos of our experiments, code release, and an interactive\nColab notebook that runs in your browser, please check out our project page\nhttps://sites.google.com/view/lmnav",
    "descriptor": "\nComments: Project page this https URL\n",
    "authors": [
      "Dhruv Shah",
      "Blazej Osinski",
      "Brian Ichter",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04429"
  },
  {
    "id": "arXiv:2207.04434",
    "title": "Hiding Your Signals: A Security Analysis of PPG-based Biometric  Authentication",
    "abstract": "Recently, physiological signal-based biometric systems have received wide\nattention. Unlike traditional biometric features, physiological signals can not\nbe easily compromised (usually unobservable to human eyes).\nPhotoplethysmography (PPG) signal is easy to measure, making it more attractive\nthan many other physiological signals for biometric authentication. However,\nwith the advent of remote PPG (rPPG), unobservability has been challenged when\nthe attacker can remotely steal the rPPG signals by monitoring the victim's\nface, subsequently posing a threat to PPG-based biometrics. In PPG-based\nbiometric authentication, current attack approaches mandate the victim's PPG\nsignal, making rPPG-based attacks neglected. In this paper, we firstly analyze\nthe security of PPG-based biometrics, including user authentication and\ncommunication protocols. We evaluate the signal waveforms, heart rate and\ninter-pulse-interval information extracted by five rPPG methods, including four\ntraditional optical computing methods (CHROM, POS, LGI, PCA) and one deep\nlearning method (CL_rPPG). We conducted experiments on five datasets (PURE,\nUBFC_rPPG, UBFC_Phys, LGI_PPGI, and COHFACE) to collect a comprehensive set of\nresults. Our empirical studies show that rPPG poses a serious threat to the\nauthentication system. The success rate of the rPPG signal spoofing attack in\nthe user authentication system reached 0.35. The bit hit rate is 0.6 in\ninter-pulse-interval-based security protocols. Further, we propose an active\ndefence strategy to hide the physiological signals of the face to resist the\nattack. It reduces the success rate of rPPG spoofing attacks in user\nauthentication to 0.05. The bit hit rate was reduced to 0.5, which is at the\nlevel of a random guess. Our strategy effectively prevents the exposure of PPG\nsignals to protect users' sensitive physiological data.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Lin Li",
      "Chao Chen",
      "Lei Pan",
      "Yonghang Tai",
      "Jun Zhang",
      "Yang Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04434"
  },
  {
    "id": "arXiv:2207.04438",
    "title": "SRRT: Search Region Regulation Tracking",
    "abstract": "Dominant trackers generate a fixed-size rectangular region based on the\nprevious prediction or initial bounding box as the model input, i.e., search\nregion. While this manner leads to improved tracking efficiency, a fixed-size\nsearch region lacks flexibility and is likely to fail in cases, e.g., fast\nmotion and distractor interference. Trackers tend to lose the target object due\nto the limited search region or be interfered by distractors due to excessive\nsearch region. In this work, we propose a novel tracking paradigm, called\nSearch Region Regulation Tracking (SRRT), which applies a proposed search\nregion regulator to estimate an optimal search region dynamically for every\nframe. To adapt the object's appearance variation during tracking, we further\npropose a locking-state determined updating strategy for reference frame\nupdating. Our SRRT framework is very concise without fancy design, yet achieves\nevident improvements on the baselines and competitive results with other\nstate-of-the-art trackers on seven challenging benchmarks. On the large-scale\nLaSOT benchmark, our SRRT improves SiamRPN++ and TransT with the absolute gains\nof 4.6% and 3.1% in terms of AUC.",
    "descriptor": "",
    "authors": [
      "Jiawen Zhu",
      "Xin Chen",
      "Dong Wang",
      "Wenda Zhao",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04438"
  },
  {
    "id": "arXiv:2207.04439",
    "title": "Efficient RDF Streaming for the Edge-Cloud Continuum",
    "abstract": "With the ongoing, gradual shift of large-scale distributed systems towards\nthe edge-cloud continuum, the need arises for software solutions that are\nuniversal, scalable, practical, and grounded in well-established technologies.\nSimultaneously, semantic technologies, especially in the streaming context, are\nbecoming increasingly important for enabling interoperability in edge-cloud\nsystems. However, in recent years, the field of semantic data streaming has\nbeen stagnant, and there are no available solutions that would fit those\nrequirements. To fill this gap, in this contribution, a novel end-to-end RDF\nstreaming approach is proposed (named Jelly). The method is simple to\nimplement, yet very elastic, and designed to fit a wide variety of use cases.\nIts practical performance is evaluated in a series of experiments, including\nend-to-end throughput and latency measurements. It is shown that Jelly achieves\nvastly superior performance to the currently available approaches. The\npresented method makes significant progress towards enabling high-performance\nsemantic data processing in a wide variety of applications, including future\nedge-cloud systems. Moreover, this study opens up the possibility of applying\nand evaluating the method in real-life scenarios, which will be the focus of\nfurther research.",
    "descriptor": "\nComments: In review -- submitted to the IEEE 8th World Forum on Internet of Things\n",
    "authors": [
      "Piotr Sowinski",
      "Katarzyna Wasielewska-Michniewska",
      "Maria Ganzha",
      "Wieslaw Pawlowski",
      "Pawel Szmeja",
      "Marcin Paprzycki"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2207.04439"
  },
  {
    "id": "arXiv:2207.04442",
    "title": "Encrypted extremum seeking for privacy-preserving PID tuning  as-a-Service",
    "abstract": "Wireless communication offers many benefits for control such as substantially\nreduced deployment costs, higher flexibility, as well as easier data access. It\nis thus not surprising that smart and wireless sensors and actuators are\nincreasingly used in industry. With these enhanced possibilities, exciting new\ntechnologies such as Control-as-a-Service arise, where (for example) controller\ndesign or tuning based on input-output-data can be outsourced to a cloud or\nmobile device. This implies, however, that sensitive plant information may\nbecome available to service providers or, possibly, attackers.\nAgainst this background, we focus on privacy-preserving optimal PID tuning\nas-a-Service here. In particular, we combine homomorphic encryption with\nextremum seeking in order to provide a purely data-driven and confidential\ntuning algorithm. The encrypted realization requires several adaptions of\nestablished extremum seekers. These encompass relative parameter updates,\nstochastic gradient approximations, and a normalized objective function. As a\nresult, and as illustrated by various numerical examples, the proposed\nencrypted extremum seeker is able to tune PID controllers for a wide variety of\nplants without being too conservative.",
    "descriptor": "",
    "authors": [
      "Nils Schl\u00fcter",
      "Matthias Neuhaus",
      "Moritz Schulze Darup"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04442"
  },
  {
    "id": "arXiv:2207.04443",
    "title": "openCFS: Open Source Finite Element Software for Coupled Field  Simulation -- Part Acoustics",
    "abstract": "Although many numerical simulation tools have been developed and are on the\nmarket, there is still a strong need for appropriate tools capable to simulate\nmulti-field problems. Therefore, openCFS provides an open-source framework for\nimplementing partial differential equations using the finite element method.\nSince 2000, the software has been developed continuously. The result of is\nopenCFS (before 2020 known as CFS++ Coupled Field Simulations written in C++).\nIn this paper, we present for the first time the open-source software with a\nfocus on the acoustic module.",
    "descriptor": "\nComments: 8 pages, 4 figures, software description, working paper\n",
    "authors": [
      "Stefan Schoder",
      "Klaus Roppert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.04443"
  },
  {
    "id": "arXiv:2207.04445",
    "title": "Not Just Skipping. Understanding the Effect of Sponsored Content on  Users' Decision-Making in Online Health Search",
    "abstract": "Advertisements (ads) are an innate part of search engine business models.\nAdvertisers are willing to pay search engines to promote their content to a\nprominent position in the search result page (SERP). This raises concerns about\nthe search engine manipulation effect (SEME): the opinions of users can be\ninfluenced by the way search results are presented. In this work, we\ninvestigate the connection between SEME and sponsored content in the health\ndomain. We conduct a series of user studies in which participants need to\nevaluate the effectiveness of different non-prescription natural remedies for\nvarious medical conditions. We present participants SERPs with different\nintentionally created biases towards certain viewpoints, with or without\nsponsored content, and ask them to evaluate the effectiveness of the treatment\nonly based on the information presented to them. We investigate two types of\nsponsored content: 1. Direct marketing ads that directly market the product\nwithout expressing an opinion about its effectiveness, and 2. Indirect\nmarketing ads that explicitly advocate the product's effectiveness on the\ncondition in the query. Our results reveal a significant difference between the\ninfluence on users from these two ad types. Though direct marketing ads are\nmostly skipped by users, they can tilt users decision making towards more\npositive viewpoints. Indirect marketing ads affect both the users' examination\nbehaviour and their perception of the treatment's effectiveness. We further\ndiscover that the contrast between the indirect marketing ads and the viewpoint\npresented in the organic search results plays an important role in users'\ndecision-making. When the contrast is high, users exhibit a strong preference\ntowards a negative viewpoint, and when the contrast is low or none, users\nexhibit preference towards a more positive viewpoint.",
    "descriptor": "\nComments: 10 pages, double column\n",
    "authors": [
      "Anat Hashavit",
      "Hongning Wang",
      "Tamar Stern",
      "Sarit Kraus"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.04445"
  },
  {
    "id": "arXiv:2207.04447",
    "title": "Human-Centric Research for NLP: Towards a Definition and Guiding  Questions",
    "abstract": "With Human-Centric Research (HCR) we can steer research activities so that\nthe research outcome is beneficial for human stakeholders, such as end users.\nBut what exactly makes research human-centric? We address this question by\nproviding a working definition and define how a research pipeline can be split\ninto different stages in which human-centric components can be added.\nAdditionally, we discuss existing NLP with HCR components and define a series\nof guiding questions, which can serve as starting points for researchers\ninterested in exploring human-centric research approaches. We hope that this\nwork would inspire researchers to refine the proposed definition and to pose\nother questions that might be meaningful for achieving HCR.",
    "descriptor": "",
    "authors": [
      "Bhushan Kotnis",
      "Kiril Gashteovski",
      "Julia Gastinger",
      "Giuseppe Serra",
      "Francesco Alesiani",
      "Timo Sztyler",
      "Ammar Shaker",
      "Na Gong",
      "Carolin Lawrence",
      "Zhao Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04447"
  },
  {
    "id": "arXiv:2207.04448",
    "title": "Mix-Teaching: A Simple, Unified and Effective Semi-Supervised Learning  Framework for Monocular 3D Object Detection",
    "abstract": "Monocular 3D object detection is an essential perception task for autonomous\ndriving. However, the high reliance on large-scale labeled data make it costly\nand time-consuming during model optimization. To reduce such over-reliance on\nhuman annotations, we propose Mix-Teaching, an effective semi-supervised\nlearning framework applicable to employ both labeled and unlabeled images in\ntraining stage. Mix-Teaching first generates pseudo-labels for unlabeled images\nby self-training. The student model is then trained on the mixed images\npossessing much more intensive and precise labeling by merging instance-level\nimage patches into empty backgrounds or labeled images. This is the first to\nbreak the image-level limitation and put high-quality pseudo labels from multi\nframes into one image for semi-supervised training. Besides, as a result of the\nmisalignment between confidence score and localization quality, it's hard to\ndiscriminate high-quality pseudo-labels from noisy predictions using only\nconfidence-based criterion. To that end, we further introduce an\nuncertainty-based filter to help select reliable pseudo boxes for the above\nmixing operation. To the best of our knowledge, this is the first unified SSL\nframework for monocular 3D object detection. Mix-Teaching consistently improves\nMonoFlex and GUPNet by significant margins under various labeling ratios on\nKITTI dataset. For example, our method achieves around +6.34% AP@0.7\nimprovement against the GUPNet baseline on validation set when using only 10%\nlabeled data. Besides, by leveraging full training set and the additional 48K\nraw images of KITTI, it can further improve the MonoFlex by +4.65% improvement\non AP@0.7 for car detection, reaching 18.54% AP@0.7, which ranks the 1st place\namong all monocular based methods on KITTI test leaderboard. The code and\npretrained models will be released at\nhttps://github.com/yanglei18/Mix-Teaching.",
    "descriptor": "\nComments: 11 pages, 5 figures, 7 tables\n",
    "authors": [
      "Lei Yang",
      "Xinyu Zhang",
      "Li Wang",
      "Minghan Zhu",
      "Chuang Zhang",
      "Jun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04448"
  },
  {
    "id": "arXiv:2207.04452",
    "title": "NGAME: Negative Mining-aware Mini-batching for Extreme Classification",
    "abstract": "Extreme Classification (XC) seeks to tag data points with the most relevant\nsubset of labels from an extremely large label set. Performing deep XC with\ndense, learnt representations for data points and labels has attracted much\nattention due to its superiority over earlier XC methods that used sparse,\nhand-crafted features. Negative mining techniques have emerged as a critical\ncomponent of all deep XC methods that allow them to scale to millions of\nlabels. However, despite recent advances, training deep XC models with large\nencoder architectures such as transformers remains challenging. This paper\nidentifies that memory overheads of popular negative mining techniques often\nforce mini-batch sizes to remain small and slow training down. In response,\nthis paper introduces NGAME, a light-weight mini-batch creation technique that\noffers provably accurate in-batch negative samples. This allows training with\nlarger mini-batches offering significantly faster convergence and higher\naccuracies than existing negative sampling techniques. NGAME was found to be up\nto 16% more accurate than state-of-the-art methods on a wide array of benchmark\ndatasets for extreme classification, as well as 3% more accurate at retrieving\nsearch engine queries in response to a user webpage visit to show personalized\nads. In live A/B tests on a popular search engine, NGAME yielded up to 23%\ngains in click-through-rates.",
    "descriptor": "",
    "authors": [
      "Kunal Dahiya",
      "Nilesh Gupta",
      "Deepak Saini",
      "Akshay Soni",
      "Yajun Wang",
      "Kushal Dave",
      "Jian Jiao",
      "Gururaj K",
      "Prasenjit Dey",
      "Amit Singh",
      "Deepesh Hada",
      "Vidit Jain",
      "Bhawna Paliwal",
      "Anshul Mittal",
      "Sonu Mehta",
      "Ramachandran Ramjee",
      "Sumeet Agarwal",
      "Purushottam Kar",
      "Manik Varma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.04452"
  },
  {
    "id": "arXiv:2207.04453",
    "title": "Multilingual Persuasion Detection: Video Games as an Invaluable Data  Source for NLP",
    "abstract": "Role-playing games (RPGs) have a considerable amount of text in video game\ndialogues. Quite often this text is semi-annotated by the game developers. In\nthis paper, we extract a multilingual dataset of persuasive dialogue from\nseveral RPGs. We show the viability of this data in building a persuasion\ndetection system using a natural language processing (NLP) model called BERT.\nWe believe that video games have a lot of unused potential as a datasource for\na variety of NLP tasks. The code and data described in this paper are available\non Zenodo.",
    "descriptor": "\nComments: DiGRA 2022\n",
    "authors": [
      "Teemu P\u00f6yh\u00f6nen",
      "Mika H\u00e4m\u00e4l\u00e4inen",
      "Khalid Alnajjar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04453"
  },
  {
    "id": "arXiv:2207.04454",
    "title": "Dynamic Traffic Assignment for Electric Vehicles",
    "abstract": "We initiate the study of dynamic traffic assignment for electrical vehicles\naddressing the specific challenges such as range limitations and the\npossibility of battery recharge at predefined charging locations. We pose the\ndynamic equilibrium problem within the deterministic queueing model of Vickrey\nand as our main result, we establish the existence of an energy-feasible\ndynamic equilibrium. There are three key modeling-ingredients for obtaining\nthis existence result:\n* We introduce a walk-based definition of dynamic traffic flows which allows\nfor cyclic routing behavior as a result of recharging events en route.\n* We use abstract convex feasibility sets in an appropriate function space to\nmodel the energy-feasibility of used walks.\n* We introduce the concept of capacitated dynamic equilibrium walk-flows\nwhich generalize the former unrestricted dynamic equilibrium path-flows.\nViewed in this framework, we show the existence of an energy-feasible dynamic\nequilibrium by applying an infinite dimensional variational inequality, which\nin turn requires a careful analysis of continuity properties of the network\nloading as a result of injecting flow into walks. We complement our theoretical\nresults by a computational study in which we design a fixed-point algorithm\ncomputing energy-feasible dynamic equilibria. We apply the algorithm to\nstandard real-world instances from the traffic assignment community\nillustrating the complex interplay of resulting travel times, energy\nconsumption and prices paid at equilibrium.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Lukas Graf",
      "Tobias Harks",
      "Prashant Palkar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04454"
  },
  {
    "id": "arXiv:2207.04455",
    "title": "The Price of Stability for First Price Auction",
    "abstract": "This paper establishes the Price of Stability (PoS) for First Price Auctions,\nfor all equilibrium concepts that have been studied in the literature: Bayes\nNash Equilibrium $\\subsetneq$ Bayes Correlated Equilibrium $\\subsetneq$ Bayes\nCoarse Correlated Equilibrium}\n$\\bullet$ Bayes Nash Equilibrium: For independent valuations, the tight PoS\nis $1 - 1/ e^{2} \\approx 0.8647$, matching the counterpart Price of Anarchy\n(PoA) bound \\cite{JL22}. For correlated valuations, the tight $\\PoS$ is $1 - 1\n/ e \\approx 0.6321$, matching the counterpart PoA bound \\cite{ST13,S14}. This\nresult indicates that, in the worst cases, efficiency degradation depends not\non different selections among Bayes Nash Equilibria.\n$\\bullet$ Bayesian Coarse Correlated Equilibrium: For independent or\ncorrelated valuations, the tight PoS is always $1 = 100\\%$, i.e., no efficiency\ndegradation, different from the counterpart PoA bound $1 - 1 / e \\approx\n0.6321$ \\cite{ST13,S14}. This result indicates that First Price Auctions can be\nfully efficient when we allow the more general equilibrium concepts.",
    "descriptor": "\nComments: Complement results from the earlier work \"First Price Auction is 1-1/e^2 Efficient\" (arXiv:2207.01761)\n",
    "authors": [
      "Yaonan Jin",
      "Pinyan Lu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.04455"
  },
  {
    "id": "arXiv:2207.04457",
    "title": "TCR: A Transformer Based Deep Network for Predicting Cancer Drugs  Response",
    "abstract": "Predicting clinical outcomes to anti-cancer drugs on a personalized basis is\nchallenging in cancer treatment due to the heterogeneity of tumors. Traditional\ncomputational efforts have been made to model the effect of drug response on\nindividual samples depicted by their molecular profile, yet overfitting occurs\nbecause of the high dimension for omics data, hindering models from clinical\napplication. Recent research shows that deep learning is a promising approach\nto build drug response models by learning alignment patterns between drugs and\nsamples. However, existing studies employed the simple feature fusion strategy\nand only considered the drug features as a whole representation while ignoring\nthe substructure information that may play a vital role when aligning drugs and\ngenes. Hereby in this paper, we propose TCR (Transformer based network for\nCancer drug Response) to predict anti-cancer drug response. By utilizing an\nattention mechanism, TCR is able to learn the interactions between drug\natom/sub-structure and molecular signatures efficiently in our study.\nFurthermore, a dual loss function and cross sampling strategy were designed to\nimprove the prediction power of TCR. We show that TCR outperformed all other\nmethods under various data splitting strategies on all evaluation matrices\n(some with significant improvement). Extensive experiments demonstrate that TCR\nshows significantly improved generalization ability on independent in-vitro\nexperiments and in-vivo real patient data. Our study highlights the prediction\npower of TCR and its potential value for cancer drug repurpose and precision\noncology treatment.",
    "descriptor": "\nComments: 11 pages,7 figures\n",
    "authors": [
      "Jie Gao",
      "Jing Hu",
      "Wanqing Sun",
      "Yili Shen",
      "Xiaonan Zhang",
      "Xiaomin Fang",
      "Fan Wang",
      "Guodong Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2207.04457"
  },
  {
    "id": "arXiv:2207.04459",
    "title": "A Decentralised Real Estate Transfer Verification Based on  Self-Sovereign Identity and Smart Contracts",
    "abstract": "Since its first introduction in late 90s, the use of marketplaces has\ncontinued to grow, today virtually everything from physical assets to services\ncan be purchased on digital marketplaces, real estate is not an exception. Some\nmarketplaces allow acclaimed asset owners to advertise their products, to which\nthe services gets commission/percentage from proceeds of sale/lease. Despite\nthe success recorded in the use of the marketplaces, they are not without\nlimitations which include identity and property fraud, impersonation and the\nuse of centralised technology with trusted parties that are prone to single\npoint of failures (SPOF). Being one of the most valuable assets, real estate\nhas been a target for marketplace fraud as impersonators take pictures of\nproperties they do not own, upload them on marketplace with promising prices\nthat lures innocent or naive buyers. This paper addresses these issues by\nproposing a self sovereign identity (SSI) and smart contract based framework\nfor identity verification and verified transaction management on secure digital\nmarketplaces. First, the use of SSI technology enable methods for acquiring\nverified credential (VC) that are verifiable on a decentralised blockchain\nregistry to identify both real estate owner(s) and real estate property.\nSecond, the smart contracts are used to negotiate the secure transfer of real\nestate property deeds on the marketplace. To assess the viability of our\nproposal we define an application scenario and compare our work with other\napproaches",
    "descriptor": "\nComments: Shehu, A-S.; Pinto, A. and Correia, M. (2022). A Decentralised Real Estate Transfer Verification based on Self-Sovereign Identity and Smart Contracts. This article has been accepted for publication In Proceedings of the 19th International Conference on Security and Cryptography\n",
    "authors": [
      "Abubakar-Sadiq Shehu",
      "Antonio Pinto",
      "Manuel E. Correia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04459"
  },
  {
    "id": "arXiv:2207.04465",
    "title": "Progressively-connected Light Field Network for Efficient View Synthesis",
    "abstract": "This paper presents a Progressively-connected Light Field network (ProLiF),\nfor the novel view synthesis of complex forward-facing scenes. ProLiF encodes a\n4D light field, which allows rendering a large batch of rays in one training\nstep for image- or patch-level losses. Directly learning a neural light field\nfrom images has difficulty in rendering multi-view consistent images due to its\nunawareness of the underlying 3D geometry. To address this problem, we propose\na progressive training scheme and regularization losses to infer the underlying\ngeometry during training, both of which enforce the multi-view consistency and\nthus greatly improves the rendering quality. Experiments demonstrate that our\nmethod is able to achieve significantly better rendering quality than the\nvanilla neural light fields and comparable results to NeRF-like rendering\nmethods on the challenging LLFF dataset and Shiny Object dataset. Moreover, we\ndemonstrate better compatibility with LPIPS loss to achieve robustness to\nvarying light conditions and CLIP loss to control the rendering style of the\nscene. Project page: https://totoro97.github.io/projects/prolif.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Peng Wang",
      "Yuan Liu",
      "Guying Lin",
      "Jiatao Gu",
      "Lingjie Liu",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.04465"
  },
  {
    "id": "arXiv:2207.04467",
    "title": "Noisy Heuristics NAS: A Network Morphism based Neural Architecture  Search using Heuristics",
    "abstract": "Network Morphism based Neural Architecture Search (NAS) is one of the most\nefficient methods, however, knowing where and when to add new neurons or remove\ndis-functional ones is generally left to black-box Reinforcement Learning\nmodels. In this paper, we present a new Network Morphism based NAS called Noisy\nHeuristics NAS which uses heuristics learned from manually developing neural\nnetwork models and inspired by biological neuronal dynamics. Firstly, we add\nnew neurons randomly and prune away some to select only the best fitting\nneurons. Secondly, we control the number of layers in the network using the\nrelationship of hidden units to the number of input-output connections. Our\nmethod can increase or decrease the capacity or non-linearity of models online\nwhich is specified with a few meta-parameters by the user. Our method\ngeneralizes both on toy datasets and on real-world data sets such as MNIST,\nCIFAR-10, and CIFAR-100. The performance is comparable to the hand-engineered\narchitecture ResNet-18 with the similar parameters.",
    "descriptor": "\nComments: 11 pages, 10 figures, DyNN workshop at the 39 th International Conference on Machine Learning, 2022\n",
    "authors": [
      "Suman Sapkota",
      "Binod Bhattarai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.04467"
  },
  {
    "id": "arXiv:2207.04470",
    "title": "Sparse Pairwise Re-ranking with Pre-trained Transformers",
    "abstract": "Pairwise re-ranking models predict which of two documents is more relevant to\na query and then aggregate a final ranking from such preferences. This is often\nmore effective than pointwise re-ranking models that directly predict a\nrelevance value for each document. However, the high inference overhead of\npairwise models limits their practical application: usually, for a set of $k$\ndocuments to be re-ranked, preferences for all $k^2-k$ comparison pairs\nexcluding self-comparisons are aggregated. We investigate whether the\nefficiency of pairwise re-ranking can be improved by sampling from all pairs.\nIn an exploratory study, we evaluate three sampling methods and five preference\naggregation methods. The best combination allows for an order of magnitude\nfewer comparisons at an acceptable loss of retrieval effectiveness, while\ncompetitive effectiveness is already achieved with about one third of the\ncomparisons.",
    "descriptor": "\nComments: Accepted at ICTIR 2022\n",
    "authors": [
      "Lukas Gienapp",
      "Maik Fr\u00f6be",
      "Matthias Hagen",
      "Martin Potthast"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.04470"
  },
  {
    "id": "arXiv:2207.04471",
    "title": "Towards Proper Contrastive Self-supervised Learning Strategies For Music  Audio Representation",
    "abstract": "The common research goal of self-supervised learning is to extract a general\nrepresentation which an arbitrary downstream task would benefit from. In this\nwork, we investigate music audio representation learned from different\ncontrastive self-supervised learning schemes and empirically evaluate the\nembedded vectors on various music information retrieval (MIR) tasks where\ndifferent levels of the music perception are concerned. We analyze the results\nto discuss the proper direction of contrastive learning strategies for\ndifferent MIR tasks. We show that these representations convey a comprehensive\ninformation about the auditory characteristics of music in general, although\neach of the self-supervision strategies has its own effectiveness in certain\naspect of information.",
    "descriptor": "\nComments: 2022 IEEE International Conference on Multimedia and Expo (ICME)\n",
    "authors": [
      "Jeong Choi",
      "Seongwon Jang",
      "Hyunsouk Cho",
      "Sehee Chung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04471"
  },
  {
    "id": "arXiv:2207.04474",
    "title": "Opposing Half Guards",
    "abstract": "We study the art gallery problem for opposing half guards: guards that can\neither see to their left or to their right only. We present art gallery\ntheorems, show that the location of half guards in 2-guardable polygons is not\nrestricted to extensions, show that the problem is NP-hard in monotone\npolygons, and present approximation algorithms for spiral and staircase\npolygons.",
    "descriptor": "\nComments: 17 pages, 12 figures. A preliminary version was published in the 34th Canadian Conference on Computational Geometry (CCCG 2022)\n",
    "authors": [
      "Erik Krohn",
      "Bengt J. Nilsson",
      "Christiane Schmidt"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2207.04474"
  },
  {
    "id": "arXiv:2207.04476",
    "title": "Myers-Briggs personality classification from social media text using  pre-trained language models",
    "abstract": "In Natural Language Processing, the use of pre-trained language models has\nbeen shown to obtain state-of-the-art results in many downstream tasks such as\nsentiment analysis, author identification and others. In this work, we address\nthe use of these methods for personality classification from text. Focusing on\nthe Myers-Briggs (MBTI) personality model, we describe a series of experiments\nin which the well-known Bidirectional Encoder Representations from Transformers\n(BERT) model is fine-tuned to perform MBTI classification. Our main findings\nsuggest that the current approach significantly outperforms well-known text\nclassification models based on bag-of-words and static word embeddings alike\nacross multiple evaluation scenarios, and generally outperforms previous work\nin the field.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Vitor Garcia dos Santos",
      "Ivandr\u00e9 Paraboni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04476"
  },
  {
    "id": "arXiv:2207.04479",
    "title": "Scaling up ML-based Black-box Planning with Partial STRIPS Models",
    "abstract": "A popular approach for sequential decision-making is to perform\nsimulator-based search guided with Machine Learning (ML) methods like policy\nlearning. On the other hand, model-relaxation heuristics can guide the search\neffectively if a full declarative model is available. In this work, we consider\nhow a practitioner can improve ML-based black-box planning on settings where a\ncomplete symbolic model is not available. We show that specifying an incomplete\nSTRIPS model that describes only part of the problem enables the use of\nrelaxation heuristics. Our findings on several planning domains suggest that\nthis is an effective way to improve ML-based black-box planning beyond\ncollecting more data or tuning ML architectures.",
    "descriptor": "\nComments: 10 pages. Presented in workshops: RDDPS @ ICAPS 2022 and PRL @ IJCAI 2022\n",
    "authors": [
      "Matias Greco",
      "\u00c1lvaro Torralba",
      "Jorge A. Baier",
      "Hector Palacios"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04479"
  },
  {
    "id": "arXiv:2207.04488",
    "title": "APX-Hardness of the Minimum Vision Points Problem",
    "abstract": "Placing a minimum number of guards on a given watchman route in a polygonal\ndomain is called the {\\em minimum vision points problem}. We prove that finding\nthe minimum number of vision points on a shortest watchman route in a simple\npolygon is APX-Hard. We then extend the proof to the class of rectilinear\npolygons having at most three dent orientations.",
    "descriptor": "\nComments: 9 pages, 5 figures. A preliminary version was presented at the 38th European Workshop on Computational Geometry EuroCG 2022\n",
    "authors": [
      "Mayank Chaturvedi",
      "Bengt J. Nilsson"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2207.04488"
  },
  {
    "id": "arXiv:2207.04491",
    "title": "DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in  Transformer",
    "abstract": "Recently, Transformer-based methods, which predict polygon points or Bezier\ncurve control points to localize texts, are quite popular in scene text\ndetection. However, the used point label form implies the reading order of\nhumans, which affects the robustness of Transformer model. As for the model\narchitecture, the formulation of queries used in decoder has not been fully\nexplored by previous methods. In this paper, we propose a concise dynamic point\nscene text detection Transformer network termed DPText-DETR, which directly\nuses point coordinates as queries and dynamically updates them between decoder\nlayers. We point out a simple yet effective positional point label form to\ntackle the side effect of the original one. Moreover, an Enhanced Factorized\nSelf-Attention module is designed to explicitly model the circular shape of\npolygon point sequences beyond non-local attention. Extensive experiments prove\nthe training efficiency, robustness, and state-of-the-art performance on\nvarious arbitrary shape scene text benchmarks. Beyond detector, we observe that\nexisting end-to-end spotters struggle to recognize inverse-like texts. To\nevaluate their performance objectively and facilitate future research, we\npropose an Inverse-Text test set containing 500 manually labeled images. The\ncode and Inverse-Text test set will be available at\nhttps://github.com/ymy-k/DPText-DETR.",
    "descriptor": "",
    "authors": [
      "Maoyuan Ye",
      "Jing Zhang",
      "Shanshan Zhao",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04491"
  },
  {
    "id": "arXiv:2207.04494",
    "title": "Towards Adaptive Unknown Authentication for Universal Domain Adaptation  by Classifier Paradox",
    "abstract": "Universal domain adaptation (UniDA) is a general unsupervised domain\nadaptation setting, which addresses both domain and label shifts in adaptation.\nIts main challenge lies in how to identify target samples in unshared or\nunknown classes. Previous methods commonly strive to depict sample \"confidence\"\nalong with a threshold for rejecting unknowns, and align feature distributions\nof shared classes across domains. However, it is still hard to pre-specify a\n\"confidence\" criterion and threshold which are adaptive to various real tasks,\nand a mis-prediction of unknowns further incurs misalignment of features in\nshared classes. In this paper, we propose a new UniDA method with adaptive\nUnknown Authentication by Classifier Paradox (UACP), considering that samples\nwith paradoxical predictions are probably unknowns belonging to none of the\nsource classes. In UACP, a composite classifier is jointly designed with two\ntypes of predictors. That is, a multi-class (MC) predictor classifies samples\nto one of the multiple source classes, while a binary one-vs-all (OVA)\npredictor further verifies the prediction by MC predictor. Samples with\nverification failure or paradox are identified as unknowns. Further, instead of\nfeature alignment for shared classes, implicit domain alignment is conducted in\noutput space such that samples across domains share the same decision boundary,\nthough with feature discrepancy. Empirical results validate UACP under both\nopen-set and universal UDA settings.",
    "descriptor": "",
    "authors": [
      "Yunyun Wang",
      "Yao Liu",
      "Songcan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04494"
  },
  {
    "id": "arXiv:2207.04497",
    "title": "One-shot Neural Backdoor Erasing via Adversarial Weight Masking",
    "abstract": "Recent studies show that despite achieving high accuracy on a number of\nreal-world applications, deep neural networks (DNNs) can be backdoored: by\ninjecting triggered data samples into the training dataset, the adversary can\nmislead the trained model into classifying any test data to the target class as\nlong as the trigger pattern is presented. To nullify such backdoor threats,\nvarious methods have been proposed. Particularly, a line of research aims to\npurify the potentially compromised model. However, one major limitation of this\nline of work is the requirement to access sufficient original training data:\nthe purifying performance is a lot worse when the available training data is\nlimited. In this work, we propose Adversarial Weight Masking (AWM), a novel\nmethod capable of erasing the neural backdoors even in the one-shot setting.\nThe key idea behind our method is to formulate this into a min-max optimization\nproblem: first, adversarially recover the trigger patterns and then (soft) mask\nthe network weights that are sensitive to the recovered patterns. Comprehensive\nevaluations of several benchmark datasets suggest that AWM can largely improve\nthe purifying effects over other state-of-the-art methods on various available\ntraining dataset sizes.",
    "descriptor": "\nComments: 17 pages, 5 figures, 8 tables\n",
    "authors": [
      "Shuwen Chai",
      "Jinghui Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04497"
  },
  {
    "id": "arXiv:2207.04498",
    "title": "Multi-UAV Collaborative Sensing and Communication: Joint Task Allocation  and Power Optimization",
    "abstract": "Compared to a single UAV with limited sensing coverage and communication\ncapability, multi-UAV cooperation is able to provide more effective sensing and\ntransmission (S&T) services. Nevertheless, most existing works on multi-UAV\nsensing mainly focus on mutually exclusive task allocation and independent data\ntransmission, which did not fully exploit the benefit of multi-UAV sensing and\ncommunication. Motivated by this, we propose a novel multi-UAV cooperative S&T\nscheme with replicated sensing task allocation. Although replicated task\nallocation may sound counter-intuitive, it can actually foster cooperative\ntransmission among multiple UAVs and thus reduce the overall sensing mission\ncompletion time. To obtain the optimal task allocation and transmit power of\nthe proposed scheme, a mission completion time minimization problem is\nformulated. To solve this problem, a necessary condition for replicated sensing\ntask allocation is derived. For the cases of replicated sensing, the considered\nproblem is transformed into a monotonic optimization and is solved by the\ngeneric Polyblock algorithm. To efficiently evaluate the mission completion\ntime in each iteration of the Polyblock algorithm, new auxiliary variables are\nintroduced to decouple the otherwise sophisticated joint optimization of\ntransmission time and power. While for the degenerated case of non-replicated\nsensing, the closed-form expression of the optimal transmission time is derived",
    "descriptor": "\nComments: 30 pages, submitted to IEEE for possible publication\n",
    "authors": [
      "Kaitao Meng",
      "Xiaofan He",
      "Qingqing Wu",
      "Deshi Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04498"
  },
  {
    "id": "arXiv:2207.04500",
    "title": "FIB: A Method for Evaluation of Feature Impact Balance in  Multi-Dimensional Data",
    "abstract": "Errors might not have the same consequences depending on the task at hand.\nNevertheless, there is limited research investigating the impact of imbalance\nin the contribution of different features in an error vector. Therefore, we\npropose the Feature Impact Balance (FIB) score. It measures whether there is a\nbalanced impact of features in the discrepancies between two vectors. We\ndesigned the FIB score to lie in [0, 1]. Scores close to 0 indicate that a\nsmall number of features contribute to most of the error, and scores close to 1\nindicate that most features contribute to the error equally. We experimentally\nstudy the FIB on different datasets, using AutoEncoders and Variational\nAutoEncoders. We show how the feature impact balance varies during training and\nshowcase its usability to support model selection for single output and\nmulti-output tasks.",
    "descriptor": "",
    "authors": [
      "Xavier F. Cadet",
      "Sara Ahmadi-Abhari",
      "Hamed Haddadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04500"
  },
  {
    "id": "arXiv:2207.04502",
    "title": "Building Open Knowledge Graph for Metal-Organic Frameworks (MOF-KG):  Challenges and Case Studies",
    "abstract": "Metal-Organic Frameworks (MOFs) are a class of modular, porous crystalline\nmaterials that have great potential to revolutionize applications such as gas\nstorage, molecular separations, chemical sensing, catalysis, and drug delivery.\nThe Cambridge Structural Database (CSD) reports 10,636 synthesized MOF crystals\nwhich in addition contains ca. 114,373 MOF-like structures. The sheer number of\nsynthesized (plus potentially synthesizable) MOF structures requires\nresearchers pursue computational techniques to screen and isolate MOF\ncandidates. In this demo paper, we describe our effort on leveraging knowledge\ngraph methods to facilitate MOF prediction, discovery, and synthesis. We\npresent challenges and case studies about (1) construction of a MOF knowledge\ngraph (MOF-KG) from structured and unstructured sources and (2) leveraging the\nMOF-KG for discovery of new or missing knowledge.",
    "descriptor": "\nComments: Accepted by the International Workshop on Knowledge Graphs and Open Knowledge Network (OKN'22) Co-located with the 28th ACM SIGKDD Conference\n",
    "authors": [
      "Yuan An",
      "Jane Greenberg",
      "Xintong Zhao",
      "Xiaohua Hu",
      "Scott McCLellan",
      "Alex Kalinowski",
      "Fernando J. Uribe-Romo",
      "Kyle Langlois",
      "Jacob Furst",
      "Diego A. G\u00f3mez-Gualdr\u00f3n",
      "Fernando Fajardo-Rojas",
      "Katherine Ardila"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04502"
  },
  {
    "id": "arXiv:2207.04503",
    "title": "BotNet Intrusion Detection System in Internet of Things with Developed  Deep Learning",
    "abstract": "The rapid growth of technology has led to the creation of computing networks.\nThe applications of the Internet of Things are becoming more and more visible\nwith the expansion and development of sensors and the use of a series of\nequipment to connect to the Internet. Of course, the growth of any network will\nalso provide some challenges. The main challenge of IoT like any other network\nis its security. In the field of security, there are issues such as attack\ndetection, authentication, encryption and the so on. One of the most important\nattack is cyber-attacks that disrupt the network usage. One of the most\nimportant attacks on the IoT is BotNet attack. The most important challenges of\nthis topic include very high computational complexity, lack of comparison with\nprevious methods, lack of scalability, high execution time, lack of review of\nthe proposed approach in terms of accuracy to detect and classify attacks and\nintrusions. Using intrusion detection systems for the IoT is an important step\nin identifying and detecting various attacks. Therefore, an algorithm that can\nsolve these challenges has provided a near-optimal method. Using training-based\nmodels and algorithms such as Deep Dearning-Reinforcement Learning and XGBoost\nlearning in combination (DRL-XGBoost) models can be an interesting approach to\novercoming previous weaknesses. The data of this research is Bot-IoT-2018.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Amirabas Kabiri Zamani",
      "Amirahmad Chapnevis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04503"
  },
  {
    "id": "arXiv:2207.04505",
    "title": "On the properties of path additions for traffic routing",
    "abstract": "In this paper we investigate the impact of path additions to transport\nnetworks with optimised traffic routing. In particular, we study the behaviour\nof total travel time, and consider both self-interested routing paradigms, such\nas User Equilibrium (UE) routing, as well as cooperative paradigms, such as\nclassic Multi-Commodity (MC) network flow and System Optimal (SO) routing. We\nprovide a formal framework for designing transport networks through iterative\npath additions, introducing the concepts of trip spanning tree and trip path\ngraph. Using this formalisation, we prove multiple properties of the objective\nfunction for transport network design. Since the underlying routing problem is\nNP-Hard, we investigate properties that provide guarantees in approximate\nalgorithm design. Firstly, while Braess' paradox has shown that total travel\ntime is not monotonic non-increasing with respect to path additions under\nself-interested routing (UE), we prove that, instead, monotonicity holds for\ncooperative routing (MC and SO). This result has the important implication that\ncooperative agents make the best use of redundant infrastructure. Secondly, we\nprove via a counterexample that the intuitive statement `adding a path to a\ntransport network always grants greater or equal benefit to users than adding\nit to a superset of that network' is false. In other words we prove that, for\nall the routing formulations studied, total travel time is not supermodular\nwith respect to path additions. While this counter-intuitive result yields a\nhardness property for algorithm design, we provide particular instances where,\ninstead, the property of supermodularity holds. Our study on monotonicity and\nsupermodularity of total travel time with respect to path additions provides\nformal proofs and scenarios that constitute important insights for transport\nnetwork designers.",
    "descriptor": "",
    "authors": [
      "Matteo Bettini",
      "Amanda Prorok"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04505"
  },
  {
    "id": "arXiv:2207.04507",
    "title": "Closing the Gap Between Directed Hopsets and Shortcut Sets",
    "abstract": "For an n-vertex directed graph $G = (V,E)$, a $\\beta$-\\emph{shortcut set} $H$\nis a set of additional edges $H \\subseteq V \\times V$ such that $G \\cup H$ has\nthe same transitive closure as $G$, and for every pair $u,v \\in V$, there is a\n$uv$-path in $G \\cup H$ with at most $\\beta$ edges. A natural generalization of\nshortcut sets to distances is a $(\\beta,\\epsilon)$-\\emph{hopset} $H \\subseteq V\n\\times V$, where the requirement is that $H$ and $G \\cup H$ have the same\nshortest-path distances, and for every $u,v \\in V$, there is a\n$(1+\\epsilon)$-approximate shortest path in $G \\cup H$ with at most $\\beta$\nedges.\nThere is a large literature on the tradeoff between the size of a shortcut\nset / hopset and the value of $\\beta$. We highlight the most natural point on\nthis tradeoff: what is the minimum value of $\\beta$, such that for any graph\n$G$, there exists a $\\beta$-shortcut set (or a $(\\beta,\\epsilon)$-hopset) with\n$O(n)$ edges? Not only is this a natural structural question in its own right,\nbut shortcuts sets / hopsets form the core of many distributed, parallel, and\ndynamic algorithms for reachability / shortest paths. Until very recently the\nbest known upper bound was a folklore construction showing $\\beta =\nO(n^{1/2})$, but in a breakthrough result Kogan and Parter [SODA 2022] improve\nthis to $\\beta = \\tilde{O}(n^{1/3})$ for shortcut sets and $\\tilde{O}(n^{2/5})$\nfor hopsets.\nOur result is to close the gap between shortcut sets and hopsets. That is, we\nshow that for any graph $G$ and any fixed $\\epsilon$ there is a\n$(\\tilde{O}(n^{1/3}),\\epsilon)$ hopset with $O(n)$ edges. More generally, we\nachieve a smooth tradeoff between hopset size and $\\beta$ which exactly matches\nthe tradeoff of Kogan and Parter for shortcut sets (up to polylog factors).\nUsing a very recent black-box reduction of Kogan and Parter, our new hopset\nimplies improved bounds for approximate distance preservers.",
    "descriptor": "\nComments: Abstract shortened to meet arXiv requirements\n",
    "authors": [
      "Aaron Bernstein",
      "Nicole Wein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.04507"
  },
  {
    "id": "arXiv:2207.04508",
    "title": "Adaptive Virtual Neuroarchitecture",
    "abstract": "Our surrounding environment impacts our cognitive-emotional processes on a\ndaily basis and shapes our physical, psychological and social wellbeing.\nAlthough the effects of the built environment on our psycho-physiological\nprocesses are well studied, virtual environment design with a potentially\nsimilar impact on the user, has received limited attention. Based on the\ninfluence of space design on a user and combining that with the dynamic\naffordances of virtual spaces, we present the idea of adaptive virtual\nneuroarchitecture (AVN), where virtual environments respond to the user and the\nuser's real world context while simultaneously influencing them both in\nrealtime. To show how AVN has been explored in current research, we present a\nsampling of recent work that demonstrates reciprocal relationships using\nphysical affordances (space, objects), the user's state (physiological,\ncognitive, emotional), and the virtual world used in the design of novel\nvirtual reality experiences. We believe AVN has the potential to help us learn\nhow to design spaces and environments that can enhance the wellbeing of their\ninhabitants.",
    "descriptor": "",
    "authors": [
      "Abhinandan Jain",
      "Pattie Maes",
      "Misha Sra"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.04508"
  },
  {
    "id": "arXiv:2207.04512",
    "title": "Learning-based Monocular 3D Reconstruction of Birds: A Contemporary  Survey",
    "abstract": "In nature, the collective behavior of animals, such as flying birds is\ndominated by the interactions between individuals of the same species. However,\nthe study of such behavior among the bird species is a complex process that\nhumans cannot perform using conventional visual observational techniques such\nas focal sampling in nature. For social animals such as birds, the mechanism of\ngroup formation can help ecologists understand the relationship between social\ncues and their visual characteristics over time (e.g., pose and shape). But,\nrecovering the varying pose and shapes of flying birds is a highly challenging\nproblem. A widely-adopted solution to tackle this bottleneck is to extract the\npose and shape information from 2D image to 3D correspondence. Recent advances\nin 3D vision have led to a number of impressive works on the 3D shape and pose\nestimation, each with different pros and cons. To the best of our knowledge,\nthis work is the first attempt to provide an overview of recent advances in 3D\nbird reconstruction based on monocular vision, give both computer vision and\nbiology researchers an overview of existing approaches, and compare their\ncharacteristics.",
    "descriptor": "\nComments: To be presented at the Workshop (VAIB 2022) of the International Conference on Patten Recognition\n",
    "authors": [
      "Seyed Mojtaba Marvasti-Zadeh",
      "Mohammad N.S. Jahromi",
      "Javad Khaghanix",
      "Devin Goodsman",
      "Nilanjan Ray",
      "Nadir Erbilgin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04512"
  },
  {
    "id": "arXiv:2207.04513",
    "title": "A stochastic Galerkin method with adaptive time-stepping for the  Navier-Stokes equations",
    "abstract": "We study the time-dependent Navier-Stokes equations in the context of\nstochastic finite element discretizations. Specifically, we assume that the\nviscosity is a random field given in the form of a generalized polynomial chaos\nexpansion, and we use the stochastic Galerkin method to extend the methodology\nfrom [D. A. Kay et al., \\textit{SIAM J. Sci. Comput.} 32(1), pp. 111--128,\n2010] into this framework. For the resulting stochastic problem, we explore the\nproperties of the resulting stochastic solutions, and we also compare the\nresults with that of Monte Carlo and stochastic collocation. Since the\ntime-stepping scheme is fully implicit, we also propose strategies for\nefficient solution of the stochastic Galerkin linear systems using a\npreconditioned Krylov subspace method. The effectiveness of the stochastic\nGalerkin method is illustrated by numerical experiments.",
    "descriptor": "\nComments: 20 pages, 16 figures\n",
    "authors": [
      "Bed\u0159ich Soused\u00edk",
      "Randy Price"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2207.04513"
  },
  {
    "id": "arXiv:2207.04515",
    "title": "Developing an AI-enabled IIoT platform -- Lessons learned from early use  case validation",
    "abstract": "For a broader adoption of AI in industrial production, adequate\ninfrastructure capabilities are crucial. This includes easing the integration\nof AI with industrial devices, support for distributed deployment, monitoring,\nand consistent system configuration. Existing IIoT platforms still lack\nrequired capabilities to flexibly integrate reusable AI services and relevant\nstandards such as Asset Administration Shells or OPC UA in an open,\necosystem-based manner. This is exactly what our next level Intelligent\nIndustrial Production Ecosphere (IIP-Ecosphere) platform addresses, employing a\nhighly configurable low-code based approach. In this paper, we introduce the\ndesign of this platform and discuss an early evaluation in terms of a\ndemonstrator for AI-enabled visual quality inspection. This is complemented by\ninsights and lessons learned during this early evaluation activity.",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Holger Eichelberger",
      "Gregory Palmer",
      "Svenja Reimer",
      "Tat Trong Vu",
      "Hieu Do",
      "Sofiane Laridi",
      "Alexander Weber",
      "Claudia Nieder\u00e9e",
      "Thomas Hildebrandt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.04515"
  },
  {
    "id": "arXiv:2207.04521",
    "title": "Information-Theoretic Bounds for Steganography in Multimedia",
    "abstract": "Steganography in multimedia aims to embed secret data into an innocent\nlooking multimedia cover object. This embedding introduces some distortion to\nthe cover object and produces a corresponding stego object. The embedding\ndistortion is measured by a cost function that determines the detection\nprobability of the existence of the embedded secret data. A cost function\nrelated to the maximum embedding rate is typically employed to evaluate a\nsteganographic system. In addition, the distribution of multimedia sources\nfollows the Gibbs distribution which is a complex statistical model that\nrestricts analysis. Thus, previous multimedia steganographic approaches either\nassume a relaxed distribution or presume a proposition on the maximum embedding\nrate and then try to prove it is correct. Conversely, this paper introduces an\nanalytic approach to determining the maximum embedding rate in multimedia cover\nobjects through a constrained optimization problem concerning the relationship\nbetween the maximum embedding rate and the probability of detection by any\nsteganographic detector. The KL-divergence between the distributions for the\ncover and stego objects is used as the cost function as it upper bounds the\nperformance of the optimal steganographic detector. An equivalence between the\nGibbs and correlated-multivariate-quantized-Gaussian distributions is\nestablished to solve this optimization problem. The solution provides an\nanalytic form for the maximum embedding rate in terms of the WrightOmega\nfunction. Moreover, it is proven that the maximum embedding rate is in\nagreement with the commonly used Square Root Law (SRL) for steganography, but\nthe solution presented here is more accurate. Finally, the theoretical results\nobtained are verified experimentally.",
    "descriptor": "",
    "authors": [
      "Hassan Y. El Arsh",
      "Amr Abdelaziz",
      "Ahmed Elliethy",
      "Hussein A. Aly",
      "T. Aaron Gulliver"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04521"
  },
  {
    "id": "arXiv:2207.04522",
    "title": "Accelerating Polarization via Alphabet Extension",
    "abstract": "Polarization is an unprecedented coding technique in that it not only\nachieves channel capacity, but also does so at a faster speed of convergence\nthan any other technique. This speed is measured by the \"scaling exponent\" and\nits importance is three-fold. Firstly, estimating the scaling exponent is\nchallenging and demands a deeper understanding of the dynamics of communication\nchannels. Secondly, scaling exponents serve as a benchmark for different\nvariants of polar codes that helps us select the proper variant for real-life\napplications. Thirdly, the need to optimize for the scaling exponent sheds\nlight on how to reinforce the design of polar code.\nIn this paper, we generalize the binary erasure channel (BEC), the simplest\ncommunication channel and the protagonist of many polar code studies, to the\n\"tetrahedral erasure channel\" (TEC). We then invoke Mori--Tanaka's $2 \\times 2$\nmatrix over GF$(4)$ to construct polar codes over TEC. Our main contribution is\nshowing that the dynamic of TECs converges to an almost--one-parameter family\nof channels, which then leads to an upper bound of $3.328$ on the scaling\nexponent. This is the first non-binary matrix whose scaling exponent is\nupper-bounded. It also polarizes BEC faster than all known binary matrices up\nto $23 \\times 23$ in size. Our result indicates that expanding the alphabet is\na more effective and practical alternative to enlarging the matrix in order to\nachieve faster polarization.",
    "descriptor": "\nComments: 22 pages, 4 figures. Accepted to RANDOM 2022\n",
    "authors": [
      "Iwan Duursma",
      "Ryan Gabrys",
      "Venkatesan Guruswami",
      "Ting-Chun Lin",
      "Hsin-Po Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04522"
  },
  {
    "id": "arXiv:2207.04523",
    "title": "Facilitated machine learning for image-based fruit quality assessment in  developing countries",
    "abstract": "Automated image classification is a common task for supervised machine\nlearning in food science. An example is the image-based classification of the\nfruit's external quality or ripeness. For this purpose, deep convolutional\nneural networks (CNNs) are typically used. These models usually require a large\nnumber of labeled training samples and enhanced computational resources. While\ncommercial fruit sorting lines readily meet these requirements, the use of\nmachine learning approaches can be hindered by these prerequisites, especially\nfor smallholder farmers in the developing world. We propose an alternative\nmethod based on pre-trained vision transformers (ViTs) that is particularly\nsuitable for domains with low availability of data and limited computational\nresources. It can be easily implemented with limited resources on a standard\ndevice, which can democratize the use of these models for smartphone-based\nimage classification in developing countries. We demonstrate the\ncompetitiveness of our method by benchmarking two different classification\ntasks on domain data sets of banana and apple fruits with well-established CNN\napproaches. Our method achieves a classification accuracy of less than one\npercent below the best-performing CNN (0.950 vs. 0.958) on a training data set\nof 3745 images. At the same time, our method is superior when only a small\nnumber of labeled training samples is available. It requires three times less\ndata to achieve a 0.90 accuracy compared to CNNs. In addition, visualizations\nof low-dimensional feature embeddings show that the model used in our study\nextracts excellent features from unseen data without allocating labels.",
    "descriptor": "",
    "authors": [
      "Manuel Knott",
      "Fernando Perez-Cruz",
      "Thijs Defraeye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04523"
  },
  {
    "id": "arXiv:2207.04526",
    "title": "Efficient Multi-Task RGB-D Scene Analysis for Indoor Environments",
    "abstract": "Semantic scene understanding is essential for mobile agents acting in various\nenvironments. Although semantic segmentation already provides a lot of\ninformation, details about individual objects as well as the general scene are\nmissing but required for many real-world applications. However, solving\nmultiple tasks separately is expensive and cannot be accomplished in real time\ngiven limited computing and battery capabilities on a mobile platform. In this\npaper, we propose an efficient multi-task approach for RGB-D scene\nanalysis~(EMSANet) that simultaneously performs semantic and instance\nsegmentation~(panoptic segmentation), instance orientation estimation, and\nscene classification. We show that all tasks can be accomplished using a single\nneural network in real time on a mobile platform without diminishing\nperformance - by contrast, the individual tasks are able to benefit from each\nother. In order to evaluate our multi-task approach, we extend the annotations\nof the common RGB-D indoor datasets NYUv2 and SUNRGB-D for instance\nsegmentation and orientation estimation. To the best of our knowledge, we are\nthe first to provide results in such a comprehensive multi-task setting for\nindoor scene analysis on NYUv2 and SUNRGB-D.",
    "descriptor": "\nComments: To be published in IEEE International Joint Conference on Neural Networks (IJCNN) 2022\n",
    "authors": [
      "Daniel Seichter",
      "S\u00f6hnke Benedikt Fischedick",
      "Mona K\u00f6hler",
      "Horst-Michael Gro\u00df"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04526"
  },
  {
    "id": "arXiv:2207.04534",
    "title": "An Open-Source Tool for Longitudinal Whole-Brain and White Matter Lesion  Segmentation",
    "abstract": "In this paper we describe and validate a longitudinal method for whole-brain\nsegmentation of longitudinal MRI scans. It builds upon an existing whole-brain\nsegmentation method that can handle multi-contrast data and robustly analyze\nimages with white matter lesions. This method is here extended with\nsubject-specific latent variables that encourage temporal consistency between\nits segmentation results, enabling it to better track subtle morphological\nchanges in dozens of neuroanatomical structures and white matter lesions. We\nvalidate the proposed method on multiple datasets of control subjects and\npatients suffering from Alzheimer's disease and multiple sclerosis, and compare\nits results against those obtained with its original cross-sectional\nformulation and two benchmark longitudinal methods. The results indicate that\nthe method attains a higher test-retest reliability, while being more sensitive\nto longitudinal disease effect differences between patient groups. An\nimplementation is publicly available as part of the open-source neuroimaging\npackage FreeSurfer.",
    "descriptor": "",
    "authors": [
      "Stefano Cerri",
      "Douglas N. Greve",
      "Andrew Hoopes",
      "Henrik Lundell",
      "Hartwig R. Siebner",
      "Mark M\u00fchlau",
      "Koen Van Leemput"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04534"
  },
  {
    "id": "arXiv:2207.04535",
    "title": "Depthformer : Multiscale Vision Transformer For Monocular Depth  Estimation With Local Global Information Fusion",
    "abstract": "Attention-based models such as transformers have shown outstanding\nperformance on dense prediction tasks, such as semantic segmentation, owing to\ntheir capability of capturing long-range dependency in an image. However, the\nbenefit of transformers for monocular depth prediction has seldom been explored\nso far. This paper benchmarks various transformer-based models for the depth\nestimation task on an indoor NYUV2 dataset and an outdoor KITTI dataset. We\npropose a novel attention-based architecture, Depthformer for monocular depth\nestimation that uses multi-head self-attention to produce the multiscale\nfeature maps, which are effectively combined by our proposed decoder network.\nWe also propose a Transbins module that divides the depth range into bins whose\ncenter value is estimated adaptively per image. The final depth estimated is a\nlinear combination of bin centers for each pixel. Transbins module takes\nadvantage of the global receptive field using the transformer module in the\nencoding stage. Experimental results on NYUV2 and KITTI depth estimation\nbenchmark demonstrate that our proposed method improves the state-of-the-art by\n3.3%, and 3.3% respectively in terms of Root Mean Squared Error (RMSE).",
    "descriptor": "",
    "authors": [
      "Ashutosh Agarwal",
      "Chetan Arora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04535"
  },
  {
    "id": "arXiv:2207.04539",
    "title": "Multi-task Envisioning Transformer-based Autoencoder for Corporate  Credit Rating Migration Early Prediction",
    "abstract": "Corporate credit ratings issued by third-party rating agencies are quantified\nassessments of a company's creditworthiness. Credit Ratings highly correlate to\nthe likelihood of a company defaulting on its debt obligations. These ratings\nplay critical roles in investment decision-making as one of the key risk\nfactors. They are also central to the regulatory framework such as BASEL II in\ncalculating necessary capital for financial institutions. Being able to predict\nrating changes will greatly benefit both investors and regulators alike. In\nthis paper, we consider the corporate credit rating migration early prediction\nproblem, which predicts the credit rating of an issuer will be upgraded,\nunchanged, or downgraded after 12 months based on its latest financial\nreporting information at the time. We investigate the effectiveness of\ndifferent standard machine learning algorithms and conclude these models\ndeliver inferior performance. As part of our contribution, we propose a new\nMulti-task Envisioning Transformer-based Autoencoder (META) model to tackle\nthis challenging problem. META consists of Positional Encoding,\nTransformer-based Autoencoder, and Multi-task Prediction to learn effective\nrepresentations for both migration prediction and rating prediction. This\nenables META to better explore the historical data in the training stage for\none-year later prediction. Experimental results show that META outperforms all\nbaseline models.",
    "descriptor": "\nComments: SIGKDD Conference on Knowledge Discovery and Data Mining, 2022\n",
    "authors": [
      "Han Yue",
      "Steve Xia",
      "Hongfu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04539"
  },
  {
    "id": "arXiv:2207.04543",
    "title": "Scaling the Number of Tasks in Continual Learning",
    "abstract": "Standard gradient descent algorithms applied to sequences of tasks are known\nto produce catastrophic forgetting in deep neural networks. When trained on a\nnew task in a sequence, the model updates its parameters on the current task,\nforgetting past knowledge.\nThis article explores scenarios where we scale the number of tasks in a\nfinite environment. Those scenarios are composed of a long sequence of tasks\nwith reoccurring data.\nWe show that in such setting, stochastic gradient descent can learn,\nprogress, and converge to a solution that according to existing literature\nneeds a continual learning algorithm. In other words, we show that the model\nperforms knowledge retention and accumulation without specific memorization\nmechanisms.\nWe propose a new experimentation framework, SCoLe (Scaling Continual\nLearning), to study the knowledge retention and accumulation of algorithms in\npotentially infinite sequences of tasks. To explore this setting, we performed\na large number of experiments on sequences of 1,000 tasks to better understand\nthis new family of settings.\nWe also propose a slight modifications to the vanilla stochastic gradient\ndescent to facilitate continual learning in this setting.\nThe SCoLe framework represents a good simulation of practical training\nenvironments with reoccurring situations and allows the study of convergence\nbehavior in long sequences. Our experiments show that previous results on short\nscenarios cannot always be extrapolated to longer scenarios.",
    "descriptor": "",
    "authors": [
      "Timoth\u00e9e Lesort",
      "Oleksiy Ostapenko",
      "Diganta Misra",
      "Md Rifat Arefin",
      "Pau Rodr\u00edguez",
      "Laurent Charlin",
      "Irina Rish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04543"
  },
  {
    "id": "arXiv:2207.04546",
    "title": "FairDistillation: Mitigating Stereotyping in Language Models",
    "abstract": "Large pre-trained language models are successfully being used in a variety of\ntasks, across many languages. With this ever-increasing usage, the risk of\nharmful side effects also rises, for example by reproducing and reinforcing\nstereotypes. However, detecting and mitigating these harms is difficult to do\nin general and becomes computationally expensive when tackling multiple\nlanguages or when considering different biases. To address this, we present\nFairDistillation: a cross-lingual method based on knowledge distillation to\nconstruct smaller language models while controlling for specific biases. We\nfound that our distillation method does not negatively affect the downstream\nperformance on most tasks and successfully mitigates stereotyping and\nrepresentational harms. We demonstrate that FairDistillation can create fairer\nlanguage models at a considerably lower cost than alternative approaches.",
    "descriptor": "\nComments: Accepted at ECML-PKDD 2022\n",
    "authors": [
      "Pieter Delobelle",
      "Bettina Berendt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04546"
  },
  {
    "id": "arXiv:2207.04547",
    "title": "Wi-Fi Assist: Enhancing Vehicular Wi-Fi Connectivity with an  Infrastructure-driven Approach",
    "abstract": "Vehicles access the Internet via cellular networks, instead of Wi-Fi\nnetworks. This choice has been mostly justified by the ubiquitous coverage of\ncellular networks: Wi-Fi coverage has been shown to be inadequate in the past,\neven in urban areas.\nWe argue that providing Internet connectivity to vehicles via Wi-Fi is worth\na revisit. Motivated by improvements in Wi-Fi network coverage in recent years,\nwe propose Wi-Fi Assist, an add-on to current Wi-Fi infrastructures which\ndiffers from existing solutions in two key ways: (1) it is heavily\ninfrastructure-driven; and (2) defines an interface for low-latency cooperation\nbetween different WLAN service sets, managed by different service providers.",
    "descriptor": "\nComments: 3 pages, 2 figures, 2 tables, accompanying paper for poster presented at CoNext 2017's Student Workshop\n",
    "authors": [
      "Antonio Rodrigues",
      "Peter Steenkiste",
      "Ana Aguiar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.04547"
  },
  {
    "id": "arXiv:2207.04548",
    "title": "Differential Imaging Forensics: A Feasibility Study",
    "abstract": "We motivate and develop a new line of digital forensics. In the meanwhile, we\npropose a novel approach to photographer identification, a rarely explored\nauthorship attribution problem. We report a proof-of-concept study, which shows\nthe feasibility of our method. Our contributions include a new forensic method\nfor photographer de-anonymization and revealing a novel privacy threat which\nhad been ignored before. The success of our creation builds on top of a new\noptical side-channel which we have discovered, as well as on how to exploit it\neffectively. We also make the first attempt to bridge side channels and inverse\nproblems, two fields that appear to be completely isolated from each other but\nhave deep connections.",
    "descriptor": "",
    "authors": [
      "Aur\u00e9lien Bourquard",
      "Jeff Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04548"
  },
  {
    "id": "arXiv:2207.04551",
    "title": "Depth Perspective-aware Multiple Object Tracking",
    "abstract": "This paper aims to tackle Multiple Object Tracking (MOT), an important\nproblem in computer vision but remains challenging due to many practical\nissues, especially occlusions. Indeed, we propose a new real-time Depth\nPerspective-aware Multiple Object Tracking (DP-MOT) approach to tackle the\nocclusion problem in MOT. A simple yet efficient Subject-Ordered Depth\nEstimation (SODE) is first proposed to automatically order the depth positions\nof detected subjects in a 2D scene in an unsupervised manner. Using the output\nfrom SODE, a new Active pseudo-3D Kalman filter, a simple but effective\nextension of Kalman filter with dynamic control variables, is then proposed to\ndynamically update the movement of objects. In addition, a new high-order\nassociation approach is presented in the data association step to incorporate\nfirst-order and second-order relationships between the detected objects. The\nproposed approach consistently achieves state-of-the-art performance compared\nto recent MOT methods on standard MOT benchmarks.",
    "descriptor": "\nComments: In review PR journal\n",
    "authors": [
      "Kha Gia Quach",
      "Huu Le",
      "Pha Nguyen",
      "Chi Nhan Duong",
      "Tien Dai Bui",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04551"
  },
  {
    "id": "arXiv:2207.04557",
    "title": "Mechanisms that Incentivize Data Sharing in Federated Learning",
    "abstract": "Federated learning is typically considered a beneficial technology which\nallows multiple agents to collaborate with each other, improve the accuracy of\ntheir models, and solve problems which are otherwise too data-intensive /\nexpensive to be solved individually. However, under the expectation that other\nagents will share their data, rational agents may be tempted to engage in\ndetrimental behavior such as free-riding where they contribute no data but\nstill enjoy an improved model. In this work, we propose a framework to analyze\nthe behavior of such rational data generators. We first show how a naive scheme\nleads to catastrophic levels of free-riding where the benefits of data sharing\nare completely eroded. Then, using ideas from contract theory, we introduce\naccuracy shaping based mechanisms to maximize the amount of data generated by\neach agent. These provably prevent free-riding without needing any payment\nmechanism.",
    "descriptor": "",
    "authors": [
      "Sai Praneeth Karimireddy",
      "Wenshuo Guo",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2207.04557"
  },
  {
    "id": "arXiv:2207.04560",
    "title": "A polynomial-time approximation to a minimum dominating set in a graph",
    "abstract": "A {\\em dominating set} of a graph $G=(V,E)$ is a subset of vertices\n$S\\subseteq V$ such that every vertex $v\\in V\\setminus S$ has at least one\nneighbor in $S$. Finding a dominating set with the minimum cardinality in a\nconnected graph $G=(V,E)$ is known to be NP-hard. A polynomial-time\napproximation algorithm for this problem, described here, works in two stages.\nAt the first stage a dominant set is generated by a greedy algorithm, and at\nthe second stage this dominating set is purified (reduced). The reduction is\nachieved by the analysis of the flowchart of the algorithm of the first stage\nand a special kind of clustering of the dominating set generated at the first\nstage. The clustering of the dominating set naturally leads to a special kind\nof a spanning forest of graph $G$, which serves as a basis for the second\npurification stage. We expose some types of graphs for which the algorithm of\nthe first stage already delivers an optimal solution and derive sufficient\nconditions when the overall algorithm constructs an optimal solution. We give\nthree alternative approximation ratios for the algorithm of the first stage,\ntwo of which are expressed in terms of solely invariant problem instance\nparameters, and we also give one additional approximation ratio for the overall\ntwo-stage algorithm. The greedy algorithm of the first stage turned out to be\nessentially the same as the earlier known state-of-the-art algorithms for the\nset cover and dominating set problem Chv\\'atal \\cite{chvatal} and Parekh\n\\cite{parekh}. The second purification stage results in a significant reduction\nof the dominant set created at the first stage, in practice. The practical\nbehavior of both stages was verified for randomly generated problem instances.\nThe computational experiments emphasize the gap between a solution of Stage 1\nand a solution of Stage 2.",
    "descriptor": "",
    "authors": [
      "Frank Hernandez",
      "Ernesto Parra",
      "Jose Maria Sigarreta",
      "Nodari Vakhania"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2207.04560"
  },
  {
    "id": "arXiv:2207.04561",
    "title": "New Optimal Periodic Control Policy for the Optimal Periodic Performance  of a Chemostat Using a Fourier-Gegenbauer-Based Predictor-Corrector Method",
    "abstract": "In its simplest form, the chemostat consists of microorganisms or cells which\ngrow continually in a specific phase of growth while competing for a single\nlimiting nutrient. Under certain conditions on the cells' growth rate,\nsubstrate concentration, and dilution rate, the theory predicts and numerical\nexperiments confirm that a periodically operated chemostat exhibits an\n\"over-yielding\" state in which the performance becomes higher than that at the\nsteady-state operation. In this paper we show that an optimal control policy\nfor maximizing the chemostat performance can be accurately and efficiently\nderived numerically using a novel class of integral-pseudospectral methods and\nadaptive h-integral-pseudospectral methods composed through a\npredictor-corrector algorithm. Some new formulas for the construction of\nFourier pseudospectral integration matrices and barycentric shifted Gegenbauer\nquadratures are derived. A rigorous study of the errors and convergence rates\nof shifted Gegenbauer quadratures as well as the truncated Fourier series,\ninterpolation operators, and integration operators for nonsmooth and generally\nT-periodic functions is presented. We introduce also a novel adaptive scheme\nfor detecting jump discontinuities and reconstructing a discontinuous function\nfrom the pseudospectral data. An extensive set of numerical simulations is\npresented to support the derived theoretical foundations.",
    "descriptor": "\nComments: 37 pages, 20 figures\n",
    "authors": [
      "Kareem T. Elgindy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04561"
  },
  {
    "id": "arXiv:2207.04564",
    "title": "Domain Confused Contrastive Learning for Unsupervised Domain Adaptation",
    "abstract": "In this work, we study Unsupervised Domain Adaptation (UDA) in a challenging\nself-supervised approach. One of the difficulties is how to learn task\ndiscrimination in the absence of target labels. Unlike previous literature\nwhich directly aligns cross-domain distributions or leverages reverse gradient,\nwe propose Domain Confused Contrastive Learning (DCCL) to bridge the source and\nthe target domains via domain puzzles, and retain discriminative\nrepresentations after adaptation. Technically, DCCL searches for a most\ndomain-challenging direction and exquisitely crafts domain confused\naugmentations as positive pairs, then it contrastively encourages the model to\npull representations towards the other domain, thus learning more stable and\neffective domain invariances. We also investigate whether contrastive learning\nnecessarily helps with UDA when performing other data augmentations. Extensive\nexperiments demonstrate that DCCL significantly outperforms baselines.",
    "descriptor": "\nComments: 14 pages, 7 figures, NAACL 2022\n",
    "authors": [
      "Quanyu Long",
      "Tianze Luo",
      "Wenya Wang",
      "Sinno Jialin Pan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04564"
  },
  {
    "id": "arXiv:2207.04566",
    "title": "A Probabilistic Model Of Interaction Dynamics for Dyadic Face-to-Face  Settings",
    "abstract": "Natural conversations between humans often involve a large number of\nnon-verbal nuanced expressions, displayed at key times throughout the\nconversation. Understanding and being able to model these complex interactions\nis essential for creating realistic human-agent communication, whether in the\nvirtual or physical world. As social robots and intelligent avatars emerge in\npopularity and utility, being able to realistically model and generate these\ndynamic expressions throughout conversations is critical. We develop a\nprobabilistic model to capture the interaction dynamics between pairs of\nparticipants in a face-to-face setting, allowing for the encoding of\nsynchronous expressions between the interlocutors. This interaction encoding is\nthen used to influence the generation when predicting one agent's future\ndynamics, conditioned on the other's current dynamics. FLAME features are\nextracted from videos containing natural conversations between subjects to\ntrain our interaction model. We successfully assess the efficacy of our\nproposed model via quantitative metrics and qualitative metrics, and show that\nit successfully captures the dynamics of a pair of interacting dyads. We also\ntest the model with a never-before-seen parent-infant dataset comprising of two\ndifferent modes of communication between the dyads, and show that our model\nsuccessfully delineates between the modes, based on their interacting dynamics.",
    "descriptor": "",
    "authors": [
      "Renke Wang",
      "Ifeoma Nwogu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04566"
  },
  {
    "id": "arXiv:2207.04567",
    "title": "A discontinuous Galerkin based multiscale method for heterogeneous  elastic wave equations",
    "abstract": "In this paper, we develop a local multiscale model reduction strategy for the\nelastic wave equation in strongly heterogeneous media, which is achieved by\nsolving the problem in a coarse mesh with multiscale basis functions. We use\nthe interior penalty discontinuous Galerkin (IPDG) to couple the multiscale\nbasis functions that contain important heterogeneous media information. The\nconstruction of efficient multiscale basis functions starts with extracting\ndominant modes of carefully defined spectral problems to represent important\nmedia feature, which is followed by solving a constraint energy minimization\nproblems. Then a Petrov-Galerkin projection and systematization onto the coarse\ngrid is applied. As a result, an explicit and energy conserving scheme is\nobtained for fast online simulation. The method exhibits both coarse-mesh and\nspectral convergence as long as one appropriately chose the oversampling size.\nWe rigorously analyze the stability and convergence of the proposed method.\nNumerical results are provided to show the performance of the multiscale method\nand confirm the theoretical results.",
    "descriptor": "",
    "authors": [
      "Zhongqian Wang",
      "Shubin Fu",
      "Zishang Li",
      "Eric Chung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2207.04567"
  },
  {
    "id": "arXiv:2207.04569",
    "title": "FedSS: Federated Learning with Smart Selection of clients",
    "abstract": "Federated learning provides the ability to learn over heterogeneous user data\nin a distributed manner, while preserving user privacy. However, its current\nclients selection technique is a source of bias as it discriminates against\nslow clients. For starters, it selects clients that satisfy certain network and\nsystem specific criteria, thus not selecting slow clients. Even when such\nclients are included in the training process, they either straggle the training\nor are altogether dropped from the round for being too slow. Our proposed idea\nlooks to find a sweet spot between fast convergence and heterogeneity by\nlooking at smart clients selection and scheduling techniques.",
    "descriptor": "",
    "authors": [
      "Ammar Tahir",
      "Yongzhou Chen",
      "Prashanti Nilayam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.04569"
  },
  {
    "id": "arXiv:2207.04574",
    "title": "Brain-Aware Replacements for Supervised Contrastive Learning",
    "abstract": "We propose a novel framework for Alzheimer's disease (AD) detection using\nbrain MRIs. The framework starts with a data augmentation method called\nBrain-Aware Replacements (BAR), which leverages a standard brain parcellation\nto replace medically-relevant 3D brain regions in an anchor MRI from a randomly\npicked MRI to create synthetic samples. Ground truth \"hard\" labels are also\nlinearly mixed depending on the replacement ratio in order to create \"soft\"\nlabels. BAR produces a great variety of realistic-looking synthetic MRIs with\nhigher local variability compared to other mix-based methods, such as CutMix.\nOn top of BAR, we propose using a soft-label-capable supervised contrastive\nloss, aiming to learn the relative similarity of representations that reflect\nhow mixed are the synthetic MRIs using our soft labels. This way, we do not\nfully exhaust the entropic capacity of our hard labels, since we only use them\nto create soft labels and synthetic MRIs through BAR. We show that a model\npre-trained using our framework can be further fine-tuned with a cross-entropy\nloss using the hard labels that were used to create the synthetic samples. We\nvalidated the performance of our framework in a binary AD detection task\nagainst both from-scratch supervised training and state-of-the-art\nself-supervised training plus fine-tuning approaches. Then we evaluated BAR's\nindividual performance compared to another mix-based method CutMix by\nintegrating it within our framework. We show that our framework yields superior\nresults in both precision and recall for the AD detection task.",
    "descriptor": "",
    "authors": [
      "Mehmet Sayg\u0131n Seyfio\u011flu",
      "Zixuan Liu",
      "Pranav Kamath",
      "Sadjyot Gangolli",
      "Sheng Wang",
      "Thomas Grabowski",
      "Linda Shapiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04574"
  },
  {
    "id": "arXiv:2207.04575",
    "title": "A Waste Copper Granules Rating System Based on Machine Vision",
    "abstract": "In the field of waste copper granules recycling, engineers should be able to\nidentify all different sorts of impurities in waste copper granules and\nestimate their mass proportion relying on experience before rating. This manual\nrating method is costly, lacking in objectivity and comprehensiveness. To\ntackle this problem, we propose a waste copper granules rating system based on\nmachine vision and deep learning. We firstly formulate the rating task into a\n2D image recognition and purity regression task. Then we design a two-stage\nconvolutional rating network to compute the mass purity and rating level of\nwaste copper granules. Our rating network includes a segmentation network and a\npurity regression network, which respectively calculate the semantic\nsegmentation heatmaps and purity results of the waste copper granules. After\ntraining the rating network on the augmented datasets, experiments on real\nwaste copper granules demonstrate the effectiveness and superiority of the\nproposed network. Specifically, our system is superior to the manual method in\nterms of accuracy, effectiveness, robustness, and objectivity.",
    "descriptor": "",
    "authors": [
      "Kaikai Zhao",
      "Yajie Cui",
      "Zhaoxiang Liu",
      "Shiguo Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04575"
  },
  {
    "id": "arXiv:2207.04580",
    "title": "Computational coupled large-deformation periporomechanics for dynamic  failure and fracturing in variably saturated porous media",
    "abstract": "The large-deformation mechanics and multiphysics of continuous or fracturing\npartially saturated porous media under static and dynamic loads are significant\nin engineering and science. This article is devoted to a computational coupled\nlarge-deformation periporomechanics paradigm assuming passive air pressure for\nmodeling dynamic failure and fracturing in variably saturated porous media. The\ncoupled governing equations for bulk and fracture material points are\nformulated in the current/deformed configuration through the updated\nLagrangian-Eulerian framework. It is hypothesized that the horizon of a mixed\nmaterial point remains spherical, and its neighbor points are determined in the\ncurrent configuration. As a significant contribution, the mixed\ninterface/phreatic material points near the phreatic line are explicitly\nconsidered for modeling the transition from partial to full saturation (vice\nversa) through the mixed peridynamic state concept. We have formulated the\ncoupled constitutive correspondence principle and stabilization scheme in the\nupdated Lagrangian-Eulerian framework for bulk and interface points. We\nnumerically implement the coupled large deformation periporomechanics through a\nfully implicit fractional-step algorithm in time and a hybrid updated\nLagrangian-Eulerian meshfree method in space. Numerical examples are presented\nto validate the implemented stabilized computational coupled large deformation\nperiporomechanics and demonstrate its efficacy and robustness in modeling\ndynamic failure and fracturing in variably saturated porous media.",
    "descriptor": "",
    "authors": [
      "Shashank Menon",
      "Xiaoyu Song"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04580"
  },
  {
    "id": "arXiv:2207.04581",
    "title": "How Robust is your Fair Model? Exploring the Robustness of Diverse  Fairness Strategies",
    "abstract": "With the introduction of machine learning in high-stakes decision making,\nensuring algorithmic fairness has become an increasingly important problem to\nsolve. In response to this, many mathematical definitions of fairness have been\nproposed, and a variety of optimisation techniques have been developed, all\ndesigned to maximise a defined notion of fairness. However, fair solutions are\nreliant on the quality of the training data, and can be highly sensitive to\nnoise. Recent studies have shown that robustness (the ability for a model to\nperform well on unseen data) plays a significant role in the type of strategy\nthat should be used when approaching a new problem and, hence, measuring the\nrobustness of these strategies has become a fundamental problem. In this work,\nwe therefore propose a new criterion to measure the robustness of various\nfairness optimisation strategies - the \\textit{robustness ratio}. We conduct\nmultiple extensive experiments on five bench mark fairness data sets using\nthree of the most popular fairness strategies with respect to four of the most\npopular definitions of fairness. Our experiments empirically show that fairness\nmethods that rely on threshold optimisation are very sensitive to noise in all\nthe evaluated data sets, despite mostly outperforming other methods. This is in\ncontrast to the other two methods, which are less fair for low noise scenarios\nbut fairer for high noise ones. To the best of our knowledge, we are the first\nto quantitatively evaluate the robustness of fairness optimisation strategies.\nThis can potentially can serve as a guideline in choosing the most suitable\nfairness strategy for various data sets.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Edward Small",
      "Wei Shao",
      "Zeliang Zhang",
      "Peihan Liu",
      "Jeffrey Chan",
      "Kacper Sokol",
      "Flora Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.04581"
  },
  {
    "id": "arXiv:2207.04582",
    "title": "Numerical Approximations of the Allen-Cahn-Ohta-Kawasaki (ACOK) Equation  with Modified Physics Informed Neural Networks (PINNs)",
    "abstract": "The physics informed neural networks (PINNs) has been widely utilized to\nnumerically approximate PDE problems. While PINNs has achieved good results in\nproducing solutions for many partial differential equations, studies have shown\nthat it does not perform well on phase field models. In this paper, we\npartially address this issue by introducing a modified physics informed neural\nnetworks. In particular, they are used to numerically approximate\nAllen-Cahn-Ohta-Kawasaki (ACOK) equation with a volume constraint.",
    "descriptor": "",
    "authors": [
      "Jingjing Xu",
      "Jia Zhao",
      "Yanxiang Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04582"
  },
  {
    "id": "arXiv:2207.04584",
    "title": "HEGrid: A High Efficient Multi-Channel Radio Astronomical Data Gridding  Framework in Heterogeneous Computing Environments",
    "abstract": "The challenge to fully exploit the potential of existing and upcoming\nscientific instruments like large single-dish radio telescopes is to process\nthe collected massive data effectively and efficiently. As a \"quasi 2D stencil\ncomputation\" with the \"Moore neighborhood pattern,\" gridding is the most\ncomputationally intensive step in data reduction pipeline for radio astronomy\nstudies, enabling astronomers to create correct sky images for further\nanalysis. However, the existing gridding frameworks can either only run on\nmulti-core CPU architecture or do not support high-concurrency, multi-channel\ndata gridding. Their performance is then limited, and there are emerging needs\nfor innovative gridding frameworks to process data from large single-dish radio\ntelescopes like the Five-hundred-meter Aperture Spherical Telescope (FAST). To\naddress those challenges, we developed a High Efficient Gridding framework,\nHEGrid, by overcoming the above limitations. Specifically, we propose and\nconstruct the gridding pipeline in heterogeneous computing environments and\nachieve multi-pipeline concurrency for high performance multi-channel\nprocessing. Furthermore, we propose pipeline-based co-optimization to alleviate\nthe potential negative performance impact of possible intra- and inter-pipeline\nlow computation and I/O utilization, including component share-based redundancy\nelimination, thread-level data reuse and overlapping I/O and computation. Our\nexperiments are based on both simulated datasets and actual FAST observational\ndatasets. The results show that HEGrid outperforms other state-of-the-art\ngridding frameworks by up to 5.5x and has robust hardware portability,\nincluding AMD Radeon Instinct GPU and NVIDIA GPU.",
    "descriptor": "\nComments: 12 pages, 17 figures\n",
    "authors": [
      "Hao Wang",
      "Ce Yu",
      "Jian Xiao",
      "Shanjiang Tang",
      "Min Long",
      "Ming Zhu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.04584"
  },
  {
    "id": "arXiv:2207.04585",
    "title": "A multi-level interpretable sleep stage scoring system by infusing  experts' knowledge into a deep network architecture",
    "abstract": "In recent years, deep learning has shown potential and efficiency in a wide\narea including computer vision, image and signal processing. Yet, translational\nchallenges remain for user applications due to a lack of interpretability of\nalgorithmic decisions and results. This black box problem is particularly\nproblematic for high-risk applications such as medical-related decision-making.\nThe current study goal was to design an interpretable deep learning system for\ntime series classification of electroencephalogram (EEG) for sleep stage\nscoring as a step toward designing a transparent system. We have developed an\ninterpretable deep neural network that includes a kernel-based layer based on a\nset of principles used for sleep scoring by human experts in the visual\nanalysis of polysomnographic records. A kernel-based convolutional layer was\ndefined and used as the first layer of the system and made available for user\ninterpretation. The trained system and its results were interpreted in four\nlevels from the microstructure of EEG signals, such as trained kernels and the\neffect of each kernel on the detected stages, to macrostructures, such as the\ntransition between stages. The proposed system demonstrated greater performance\nthan prior studies and the results of interpretation showed that the system\nlearned information which was consistent with expert knowledge.",
    "descriptor": "",
    "authors": [
      "Hamid Niknazar",
      "Sara C. Mednick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04585"
  },
  {
    "id": "arXiv:2207.04586",
    "title": "PF4Microservices: A decomposion scheme for microservices based on  Problem Frames",
    "abstract": "In recent years, microservice architecture has become a popular architectural\nstyle in software engineering, with its natural support for DevOps and\ncontinuous delivery, as well as its scalability and extensibility, which drive\nindustry practitioners to migrate to microservice architecture. However, there\nare many challenges in adopting a microservice architecture, the most important\nof which is how to properly decomposition a monolithic system into\nmicroservices. Currently, microservice decomposition decisions for monolithic\nsystems rely on subjective human experience, which is a costly, time-consuming\nprocess with high uncertainty of results. To address this problem, this paper\nproposes a method for microservice decomposition using Jackson Problem Frames.\nIn this method, requirements of the system are analysed, descriptions of the\ninteractions between the proposed software and its environment is obtained,\nmultiple problem diagrams are constructed, and then the problem diagrams are\nmerged by analyzing the correlation and similarity between them, resulting in a\nmicroservice decomposition scheme. A case study is also conducted based on a\nsmart parking system. The results of the study show that the method can perform\nmicroservice decomposition based on requirements and the software environment,\nresulting in reducing the decisionmaking burden of developers, with reasonable\ndecomposition results.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Zhi Li",
      "Yitao Bo",
      "Hongbin Xiao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.04586"
  },
  {
    "id": "arXiv:2207.04587",
    "title": "Gradual Domain Adaptation without Indexed Intermediate Domains",
    "abstract": "The effectiveness of unsupervised domain adaptation degrades when there is a\nlarge discrepancy between the source and target domains. Gradual domain\nadaptation (GDA) is one promising way to mitigate such an issue, by leveraging\nadditional unlabeled data that gradually shift from the source to the target.\nThrough sequentially adapting the model along the \"indexed\" intermediate\ndomains, GDA substantially improves the overall adaptation performance. In\npractice, however, the extra unlabeled data may not be separated into\nintermediate domains and indexed properly, limiting the applicability of GDA.\nIn this paper, we investigate how to discover the sequence of intermediate\ndomains when it is not already available. Concretely, we propose a\ncoarse-to-fine framework, which starts with a coarse domain discovery step via\nprogressive domain discriminator training. This coarse domain sequence then\nundergoes a fine indexing step via a novel cycle-consistency loss, which\nencourages the next intermediate domain to preserve sufficient discriminative\nknowledge of the current intermediate domain. The resulting domain sequence can\nthen be used by a GDA algorithm. On benchmark data sets of GDA, we show that\nour approach, which we name Intermediate DOmain Labeler (IDOL), can lead to\ncomparable or even better adaptation performance compared to the pre-defined\ndomain sequence, making GDA more applicable and robust to the quality of domain\nsequences. Codes are available at https://github.com/hongyouc/IDOL.",
    "descriptor": "\nComments: Accepted to NeurIPS 2021\n",
    "authors": [
      "Hong-You Chen",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04587"
  },
  {
    "id": "arXiv:2207.04591",
    "title": "Hybrid iLQR Model Predictive Control for Contact Implicit Stabilization  on Legged Robots",
    "abstract": "Model Predictive Control (MPC) is a popular strategy for controlling robots\nbut is difficult for systems with contact due to the complex nature of hybrid\ndynamics. To implement MPC for systems with contact, dynamic models are often\nsimplified or contact sequences fixed in time in order to plan trajectories\nefficiently. In this work, we extend Hybrid iterative Linear Quadratic\nRegulator to work in a MPC fashion (HiLQR MPC) by 1) modifying how the cost\nfunction is computed when contact modes do not align, 2) utilizing\nparallelizations when simulating rigid body dynamics, and 3) using efficient\nanalytical derivative computations of the rigid body dynamics. The result is a\nsystem that can modify the contact sequence of the reference behavior and plan\nwhole body motions cohesively -- which is crucial when dealing with large\nperturbations. HiLQR MPC is tested on two systems: first, the hybrid cost\nmodification is validated on a simple actuated bouncing ball hybrid system.\nThen HiLQR MPC is compared against methods that utilize centroidal dynamic\nassumptions on a quadruped robot (Unitree A1). HiLQR MPC outperforms the\ncentroidal methods in both simulation and hardware tests.",
    "descriptor": "\nComments: Submitted to Transactions on Robotics\n",
    "authors": [
      "Nathan J. Kong",
      "Chuanzheng Li",
      "Aaron M. Johnson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04591"
  },
  {
    "id": "arXiv:2207.04594",
    "title": "IaaS Procurement by Simulated Annealing",
    "abstract": "Considering the problem of resource allocation for potentially complex and\ndiverse streaming (e.g., query processing) or long-running iterative (e.g.,\ndeep learning) workloads in the public cloud, we argue that a framework based\non simulated annealing is suitable for navigating performance/cost trade-offs\nwhen selecting from among heterogeneous service offerings. Annealing is\nparticularly useful when the complex workload and heterogeneous service\nofferings may vary over time. Based on a macroscopic objective that combines\nboth performance and cost terms, annealing facilitates light-weight and\ncoherent policies of exploration and exploitation when considering the service\nsuite offered by a cloud provider. In this paper, we first give some background\non simulated annealing and then demonstrate through experiments the usefulness\nof a particular resource management framework based on it: selecting the types\nand numbers of virtual machines for a particular job stream.",
    "descriptor": "",
    "authors": [
      "Nader Alfares",
      "Ata Fatahi Baarzi",
      "George Kesidis",
      "Aman Jain"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2207.04594"
  },
  {
    "id": "arXiv:2207.04601",
    "title": "Some Discussions on PHY Security in DF Relay",
    "abstract": "Physical layer (PHY) security in decode-and-forward (DF) relay systems is\ndiscussed. Based on the types of wiretap links, the secrecy performance of\nthree typical secure DF relay models is analyzed. Different from conventional\nworks in this field, rigorous derivations of the secrecy channel capacity are\nprovided from an information-theoretic perspective. Meanwhile, closed-form\nexpressions are derived to characterize the secrecy outage probability (SOP).\nFor the sake of unveiling more system insights, asymptotic analyses are\nperformed on the SOP for a sufficiently large signal-to-noise ratio (SNR). The\nanalytical results are validated by computer simulations and are in excellent\nagreement.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Chongjun Ouyang",
      "Hao Xu",
      "Xujie Zang",
      "Hongwen Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.04601"
  },
  {
    "id": "arXiv:2207.04602",
    "title": "Adaptive Fine-Grained Predicates Learning for Scene Graph Generation",
    "abstract": "The performance of current Scene Graph Generation (SGG) models is severely\nhampered by hard-to-distinguish predicates, e.g., woman-on/standing on/walking\non-beach. As general SGG models tend to predict head predicates and\nre-balancing strategies prefer tail categories, none of them can appropriately\nhandle hard-to-distinguish predicates. To tackle this issue, inspired by\nfine-grained image classification, which focuses on differentiating\nhard-to-distinguish objects, we propose an Adaptive Fine-Grained Predicates\nLearning (FGPL-A) which aims at differentiating hard-to-distinguish predicates\nfor SGG. First, we introduce an Adaptive Predicate Lattice (PL-A) to figure out\nhard-to-distinguish predicates, which adaptively explores predicate\ncorrelations in keeping with model's dynamic learning pace. Practically, PL-A\nis initialized from SGG dataset, and gets refined by exploring model's\npredictions of current mini-batch. Utilizing PL-A, we propose an Adaptive\nCategory Discriminating Loss (CDL-A) and an Adaptive Entity Discriminating Loss\n(EDL-A), which progressively regularize model's discriminating process with\nfine-grained supervision concerning model's dynamic learning status, ensuring\nbalanced and efficient learning process. Extensive experimental results show\nthat our proposed model-agnostic strategy significantly boosts performance of\nbenchmark models on VG-SGG and GQA-SGG datasets by up to 175% and 76% on Mean\nRecall@100, achieving new state-of-the-art performance. Moreover, experiments\non Sentence-to-Graph Retrieval and Image Captioning tasks further demonstrate\npracticability of our method.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2204.02597\n",
    "authors": [
      "Xinyu Lyu",
      "Lianli Gao",
      "Pengpeng Zeng",
      "Heng Tao Shen",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04602"
  },
  {
    "id": "arXiv:2207.04604",
    "title": "Privacy-preserving Decentralized Deep Learning with Multiparty  Homomorphic Encryption",
    "abstract": "Decentralized deep learning plays a key role in collaborative model training\ndue to its attractive properties, including tolerating high network latency and\nless prone to single-point failures. Unfortunately, such a training mode is\nmore vulnerable to data privacy leaks compared to other distributed training\nframeworks. Existing efforts exclusively use differential privacy as the\ncornerstone to alleviate the data privacy threat. However, it is still not\nclear whether differential privacy can provide a satisfactory utility-privacy\ntrade-off for model training, due to its inherent contradictions. To address\nthis problem, we propose D-MHE, the first secure and efficient decentralized\ntraining framework with lossless precision. Inspired by the latest developments\nin the homomorphic encryption technology, we design a multiparty version of\nBrakerski-Fan-Vercauteren (BFV), one of the most advanced cryptosystems, and\nuse it to implement private gradient updates of users'local models. D-MHE can\nreduce the communication complexity of general Secure Multiparty Computation\n(MPC) tasks from quadratic to linear in the number of users, making it very\nsuitable and scalable for large-scale decentralized learning systems. Moreover,\nD-MHE provides strict semantic security protection even if the majority of\nusers are dishonest with collusion. We conduct extensive experiments on MNIST\nand CIFAR-10 datasets to demonstrate the superiority of D-MHE in terms of model\naccuracy, computation and communication cost compared with existing schemes.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Guowen Xu",
      "Guanlin Li",
      "Shangwei Guo",
      "Tianwei Zhang",
      "Hongwei Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04604"
  },
  {
    "id": "arXiv:2207.04606",
    "title": "SparseTIR: Composable Abstractions for Sparse Compilation in Deep  Learning",
    "abstract": "Sparse tensors are rapidly becoming critical components of modern deep\nlearning workloads. However, developing high-performance sparse operators can\nbe difficult and tedious, and existing vendor libraries cannot satisfy the\nescalating demands from new operators. Sparse tensor compilers simplify the\ndevelopment of operators, but efficient sparse compilation for deep learning\nremains challenging because a single sparse format cannot maximize hardware\nefficiency, and single-shot compilers cannot keep up with latest hardware and\nsystem advances. We show that the key to addressing both challenges is two\nforms of composability. In this paper, we propose SparseTIR, a sparse tensor\ncompilation abstraction that offers composable formats and composable\ntransformations for deep learning workloads. SparseTIR constructs a search\nspace over these composable components for performance tuning. With these\nimprovements, SparseTIR obtains consistent performance speedups vs vendor\nlibraries on GPUs for single operators: 1.1-3.3x for GNN operators and 1.1-4.4x\nfor sparse transformer operators. SparseTIR also accelerates end-to-end GNNs by\n1.1-2.2x for GraphSAGE training and 0.9-26x for RGCN inference.",
    "descriptor": "",
    "authors": [
      "Zihao Ye",
      "Ruihang Lai",
      "Junru Shao",
      "Tianqi Chen",
      "Luis Ceze"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.04606"
  },
  {
    "id": "arXiv:2207.04607",
    "title": "A Penalty Approach for Normalizing Feature Distributions to Build  Confounder-Free Models",
    "abstract": "Translating machine learning algorithms into clinical applications requires\naddressing challenges related to interpretability, such as accounting for the\neffect of confounding variables (or metadata). Confounding variables affect the\nrelationship between input training data and target outputs. When we train a\nmodel on such data, confounding variables will bias the distribution of the\nlearned features. A recent promising solution, MetaData Normalization (MDN),\nestimates the linear relationship between the metadata and each feature based\non a non-trainable closed-form solution. However, this estimation is confined\nby the sample size of a mini-batch and thereby may cause the approach to be\nunstable during training. In this paper, we extend the MDN method by applying a\nPenalty approach (referred to as PDMN). We cast the problem into a bi-level\nnested optimization problem. We then approximate this optimization problem\nusing a penalty method so that the linear parameters within the MDN layer are\ntrainable and learned on all samples. This enables PMDN to be plugged into any\narchitectures, even those unfit to run batch-level operations, such as\ntransformers and recurrent models. We show improvement in model accuracy and\ngreater independence from confounders using PMDN over MDN in a synthetic\nexperiment and a multi-label, multi-site dataset of magnetic resonance images\n(MRIs).",
    "descriptor": "",
    "authors": [
      "Anthony Vento",
      "Qingyu Zhao",
      "Robert Paul",
      "Kilian M. Pohl",
      "Ehsan Adeli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04607"
  },
  {
    "id": "arXiv:2207.04612",
    "title": "Synergy and Symmetry in Deep Learning: Interactions between the Data,  Model, and Inference Algorithm",
    "abstract": "Although learning in high dimensions is commonly believed to suffer from the\ncurse of dimensionality, modern machine learning methods often exhibit an\nastonishing power to tackle a wide range of challenging real-world learning\nproblems without using abundant amounts of data. How exactly these methods\nbreak this curse remains a fundamental open question in the theory of deep\nlearning. While previous efforts have investigated this question by studying\nthe data (D), model (M), and inference algorithm (I) as independent modules, in\nthis paper, we analyze the triplet (D, M, I) as an integrated system and\nidentify important synergies that help mitigate the curse of dimensionality. We\nfirst study the basic symmetries associated with various learning algorithms\n(M, I), focusing on four prototypical architectures in deep learning:\nfully-connected networks (FCN), locally-connected networks (LCN), and\nconvolutional networks with and without pooling (GAP/VEC). We find that\nlearning is most efficient when these symmetries are compatible with those of\nthe data distribution and that performance significantly deteriorates when any\nmember of the (D, M, I) triplet is inconsistent or suboptimal.",
    "descriptor": "\nComments: Accepted by ICML 2022; 23 pages\n",
    "authors": [
      "Lechao Xiao",
      "Jeffrey Pennington"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04612"
  },
  {
    "id": "arXiv:2207.04614",
    "title": "Instance Shadow Detection with A Single-Stage Detector",
    "abstract": "This paper formulates a new problem, instance shadow detection, which aims to\ndetect shadow instance and the associated object instance that cast each shadow\nin the input image. To approach this task, we first compile a new dataset with\nthe masks for shadow instances, object instances, and shadow-object\nassociations. We then design an evaluation metric for quantitative evaluation\nof the performance of instance shadow detection. Further, we design a\nsingle-stage detector to perform instance shadow detection in an end-to-end\nmanner, where the bidirectional relation learning module and the deformable\nmaskIoU head are proposed in the detector to directly learn the relation\nbetween shadow instances and object instances and to improve the accuracy of\nthe predicted masks. Finally, we quantitatively and qualitatively evaluate our\nmethod on the benchmark dataset of instance shadow detection and show the\napplicability of our method on light direction estimation and photo editing.",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI). This is the journal version of arXiv:1911.07034 and this https URL\n",
    "authors": [
      "Tianyu Wang",
      "Xiaowei Hu",
      "Pheng-Ann Heng",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.04614"
  },
  {
    "id": "arXiv:2207.04620",
    "title": "Hercules: Boosting the Performance of Privacy-preserving Federated  Learning",
    "abstract": "In this paper, we address the problem of privacy-preserving federated neural\nnetwork training with $N$ users. We present Hercules, an efficient and\nhigh-precision training framework that can tolerate collusion of up to $N-1$\nusers. Hercules follows the POSEIDON framework proposed by Sav et al.\n(NDSS'21), but makes a qualitative leap in performance with the following\ncontributions: (i) we design a novel parallel homomorphic computation method\nfor matrix operations, which enables fast Single Instruction and Multiple Data\n(SIMD) operations over ciphertexts. For the multiplication of two $h\\times h$\ndimensional matrices, our method reduces the computation complexity from\n$O(h^3)$ to $O(h)$. This greatly improves the training efficiency of the neural\nnetwork since the ciphertext computation is dominated by the convolution\noperations; (ii) we present an efficient approximation on the sign function\nbased on the composite polynomial approximation. It is used to approximate\nnon-polynomial functions (i.e., ReLU and max), with the optimal asymptotic\ncomplexity. Extensive experiments on various benchmark datasets (BCW, ESR,\nCREDIT, MNIST, SVHN, CIFAR-10 and CIFAR-100) show that compared with POSEIDON,\nHercules obtains up to 4% increase in model accuracy, and up to 60$\\times$\nreduction in the computation and communication cost.",
    "descriptor": "",
    "authors": [
      "Guowen Xu",
      "Xingshuo Han",
      "Shengmin Xu",
      "Tianwei Zhang",
      "Hongwei Li",
      "Xinyi Huang",
      "Robert H. Deng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04620"
  },
  {
    "id": "arXiv:2207.04622",
    "title": "Edge-preserving Near-light Photometric Stereo with Neural Surfaces",
    "abstract": "This paper presents a near-light photometric stereo method that faithfully\npreserves sharp depth edges in the 3D reconstruction. Unlike previous methods\nthat rely on finite differentiation for approximating depth partial derivatives\nand surface normals, we introduce an analytically differentiable neural surface\nin near-light photometric stereo for avoiding differentiation errors at sharp\ndepth edges, where the depth is represented as a neural function of the image\ncoordinates. By further formulating the Lambertian albedo as a dependent\nvariable resulting from the surface normal and depth, our method is\ninsusceptible to inaccurate depth initialization. Experiments on both synthetic\nand real-world scenes demonstrate the effectiveness of our method for detailed\nshape recovery with edge preservation.",
    "descriptor": "",
    "authors": [
      "Heng Guo",
      "Hiroaki Santo",
      "Boxin Shi",
      "Yasuyuki Matsushita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04622"
  },
  {
    "id": "arXiv:2207.04623",
    "title": "Deep neural network based adaptive learning for switched systems",
    "abstract": "In this paper, we present a deep neural network based adaptive learning\n(DNN-AL) approach for switched systems. Currently, deep neural network based\nmethods are actively developed for learning governing equations in unknown\ndynamic systems, but their efficiency can degenerate for switching systems,\nwhere structural changes exist at discrete time instants. In this new DNN-AL\nstrategy, observed datasets are adaptively decomposed into subsets, such that\nno structural changes within each subset. During the adaptive procedures, DNNs\nare hierarchically constructed, and unknown switching time instants are\ngradually identified. Especially, network parameters at previous iteration\nsteps are reused to initialize networks for the later iteration steps, which\ngives efficient training procedures for the DNNs. For the DNNs obtained through\nour DNN-AL, bounds of the prediction error are established. Numerical studies\nare conducted to demonstrate the efficiency of DNN-AL.",
    "descriptor": "",
    "authors": [
      "Junjie He",
      "Zhihang Xu",
      "Qifeng Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04623"
  },
  {
    "id": "arXiv:2207.04624",
    "title": "Hierarchical Latent Structure for Multi-Modal Vehicle Trajectory  Forecasting",
    "abstract": "Variational autoencoder (VAE) has widely been utilized for modeling data\ndistributions because it is theoretically elegant, easy to train, and has nice\nmanifold representations. However, when applied to image reconstruction and\nsynthesis tasks, VAE shows the limitation that the generated sample tends to be\nblurry. We observe that a similar problem, in which the generated trajectory is\nlocated between adjacent lanes, often arises in VAE-based trajectory\nforecasting models. To mitigate this problem, we introduce a hierarchical\nlatent structure into the VAE-based forecasting model. Based on the assumption\nthat the trajectory distribution can be approximated as a mixture of simple\ndistributions (or modes), the low-level latent variable is employed to model\neach mode of the mixture and the high-level latent variable is employed to\nrepresent the weights for the modes. To model each mode accurately, we\ncondition the low-level latent variable using two lane-level context vectors\ncomputed in novel ways, one corresponds to vehicle-lane interaction and the\nother to vehicle-vehicle interaction. The context vectors are also used to\nmodel the weights via the proposed mode selection network. To evaluate our\nforecasting model, we use two large-scale real-world datasets. Experimental\nresults show that our model is not only capable of generating clear multi-modal\ntrajectory distributions but also outperforms the state-of-the-art (SOTA)\nmodels in terms of prediction accuracy. Our code is available at\nhttps://github.com/d1024choi/HLSTrajForecast.",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Dooseop Choi",
      "KyoungWook Min"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04624"
  },
  {
    "id": "arXiv:2207.04625",
    "title": "FSHMEM: Supporting Partitioned Global Address Space on FPGAs for  Large-Scale Hardware Acceleration Infrastructure",
    "abstract": "By providing highly efficient one-sided communication with globally shared\nmemory space, Partitioned Global Address Space (PGAS) has become one of the\nmost promising parallel computing models in high-performance computing (HPC).\nMeanwhile, FPGA is getting attention as an alternative compute platform for HPC\nsystems with the benefit of custom computing and design flexibility. However,\nthe exploration of PGAS has not been conducted on FPGAs, unlike the traditional\nmessage passing interface. This paper proposes FSHMEM, a software/hardware\nframework that enables the PGAS programming model on FPGAs. We implement the\ncore functions of GASNet specification on FPGA for native PGAS integration in\nhardware, while its programming interface is designed to be highly compatible\nwith legacy software. Our experiments show that FSHMEM achieves the peak\nbandwidth of 3813 MB/s, which is more than 95% of the theoretical maximum,\noutperforming the prior works by 9.5$\\times$. It records 0.35$us$ and 0.59$us$\nlatency for remote write and read operations, respectively. Finally, we conduct\na case study on the two Intel D5005 FPGA nodes integrating Intel's deep\nlearning accelerator. The two-node system programmed by FSHMEM achieves\n1.94$\\times$ and 1.98$\\times$ speedup for matrix multiplication and convolution\noperation, respectively, showing its scalability potential for HPC\ninfrastructure.",
    "descriptor": "\nComments: This paper will be published in the 2022 32nd International Conference on Field Programmable Logic and Applications (FPL)\n",
    "authors": [
      "Yashael Faith Arthanto",
      "David Ojika",
      "Joo-Young Kim"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2207.04625"
  },
  {
    "id": "arXiv:2207.04630",
    "title": "On the Principles of Parsimony and Self-Consistency for the Emergence of  Intelligence",
    "abstract": "Ten years into the revival of deep networks and artificial intelligence, we\npropose a theoretical framework that sheds light on understanding deep networks\nwithin a bigger picture of Intelligence in general. We introduce two\nfundamental principles, Parsimony and Self-consistency, that we believe to be\ncornerstones for the emergence of Intelligence, artificial or natural. While\nthese two principles have rich classical roots, we argue that they can be\nstated anew in entirely measurable and computable ways. More specifically, the\ntwo principles lead to an effective and efficient computational framework,\ncompressive closed-loop transcription, that unifies and explains the evolution\nof modern deep networks and many artificial intelligence practices. While we\nmainly use modeling of visual data as an example, we believe the two principles\nwill unify understanding of broad families of autonomous intelligent systems\nand provide a framework for understanding the brain.",
    "descriptor": "\nComments: 23 pages, 11 figures\n",
    "authors": [
      "Yi Ma",
      "Doris Tsao",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04630"
  },
  {
    "id": "arXiv:2207.04631",
    "title": "Partial Resampling of Imbalanced Data",
    "abstract": "Imbalanced data is a frequently encountered problem in machine learning.\nDespite a vast amount of literature on sampling techniques for imbalanced data,\nthere is a limited number of studies that address the issue of the optimal\nsampling ratio. In this paper, we attempt to fill the gap in the literature by\nconducting a large scale study of the effects of sampling ratio on\nclassification accuracy. We consider 10 popular sampling methods and evaluate\ntheir performance over a range of ratios based on 20 datasets. The results of\nthe numerical experiments suggest that the optimal sampling ratio is between\n0.7 and 0.8 albeit the exact ratio varies depending on the dataset.\nFurthermore, we find that while factors such the original imbalance ratio or\nthe number of features do not play a discernible role in determining the\noptimal ratio, the number of samples in the dataset may have a tangible effect.",
    "descriptor": "",
    "authors": [
      "Firuz Kamalov",
      "Amir F. Atiya",
      "Dina Elreedy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04631"
  },
  {
    "id": "arXiv:2207.04632",
    "title": "SkexGen: Autoregressive Generation of CAD Construction Sequences with  Disentangled Codebooks",
    "abstract": "We present SkexGen, a novel autoregressive generative model for\ncomputer-aided design (CAD) construction sequences containing\nsketch-and-extrude modeling operations. Our model utilizes distinct Transformer\narchitectures to encode topological, geometric, and extrusion variations of\nconstruction sequences into disentangled codebooks. Autoregressive Transformer\ndecoders generate CAD construction sequences sharing certain properties\nspecified by the codebook vectors. Extensive experiments demonstrate that our\ndisentangled codebook representation generates diverse and high-quality CAD\nmodels, enhances user control, and enables efficient exploration of the design\nspace. The code is available at https://samxuxiang.github.io/skexgen.",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Xiang Xu",
      "Karl D.D. Willis",
      "Joseph G. Lambourne",
      "Chin-Yi Cheng",
      "Pradeep Kumar Jayaraman",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04632"
  },
  {
    "id": "arXiv:2207.04635",
    "title": "Optimal Storage and Solar Capacity of a Residential Household under Net  Metering and Time-of-Use Pricing Mechanisms",
    "abstract": "Incentive programs and ongoing reduction in costs are driving joint\ninstallation of solar PV panels and storage systems in residential households.\nThere is a need for optimal investment decisions to reduce the electricity\nconsumption costs of the households further. In this paper, we first develop\nanalytical expression of storage investment decision and then of solar\ninvestment decision for a household which is under net metering billing\nmechanism with time of use pricing condition. Using real data of a residential\nhousehold in Austin, TX, USA, we study how the investment decisions would\nprovide benefit for a period of one year. Results show significant profit when\nusing storage devices and solar panels optimally for the system.",
    "descriptor": "",
    "authors": [
      "K. Victor Sam Moses Babu",
      "Pratyush Chakraborty",
      "Enrique Baeyens",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04635"
  },
  {
    "id": "arXiv:2207.04637",
    "title": "SIMC 2.0: Improved Secure ML Inference Against Malicious Clients",
    "abstract": "In this paper, we study the problem of secure ML inference against a\nmalicious client and a semi-trusted server such that the client only learns the\ninference output while the server learns nothing. This problem is first\nformulated by Lehmkuhl \\textit{et al.} with a solution (MUSE, Usenix\nSecurity'21), whose performance is then substantially improved by Chandran et\nal.'s work (SIMC, USENIX Security'22). However, there still exists a nontrivial\ngap in these efforts towards practicality, giving the challenges of overhead\nreduction and secure inference acceleration in an all-round way.\nWe propose SIMC 2.0, which complies with the underlying structure of SIMC,\nbut significantly optimizes both the linear and non-linear layers of the model.\nSpecifically, (1) we design a new coding method for homomorphic parallel\ncomputation between matrices and vectors. It is custom-built through the\ninsight into the complementarity between cryptographic primitives in SIMC. As a\nresult, it can minimize the number of rotation operations incurred in the\ncalculation process, which is very computationally expensive compared to other\nhomomorphic operations e.g., addition, multiplication). (2) We reduce the size\nof the garbled circuit (GC) (used to calculate nonlinear activation functions,\ne.g., ReLU) in SIMC by about two thirds. Then, we design an alternative\nlightweight protocol to perform tasks that are originally allocated to the\nexpensive GCs. Compared with SIMC, our experiments show that SIMC 2.0 achieves\na significant speedup by up to $17.4\\times $ for linear layer computation, and\nat least $1.3\\times$ reduction of both the computation and communication\noverheads in the implementation of non-linear layers under different data\ndimensions. Meanwhile, SIMC 2.0 demonstrates an encouraging runtime boost by\n$2.3\\sim 4.3\\times$ over SIMC on different state-of-the-art ML models.",
    "descriptor": "",
    "authors": [
      "Guowen Xu",
      "Xingshuo Han",
      "Tianwei Zhang",
      "Hongwei Li",
      "Robert H.Deng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04637"
  },
  {
    "id": "arXiv:2207.04638",
    "title": "Learning Closed-loop Dough Manipulation Using a Differentiable Reset  Module",
    "abstract": "Deformable object manipulation has many applications such as cooking and\nlaundry folding in our daily lives. Manipulating elastoplastic objects such as\ndough is particularly challenging because dough lacks a compact state\nrepresentation and requires contact-rich interactions. We consider the task of\nflattening a piece of dough into a specific shape from RGB-D images. While the\ntask is seemingly intuitive for humans, there exist local optima for common\napproaches such as naive trajectory optimization. We propose a novel trajectory\noptimizer that optimizes through a differentiable \"reset\" module, transforming\na single-stage, fixed-initialization trajectory into a multistage,\nmulti-initialization trajectory where all stages are optimized jointly. We then\ntrain a closed-loop policy on the demonstrations generated by our trajectory\noptimizer. Our policy receives partial point clouds as input, allowing ease of\ntransfer from simulation to the real world. We show that our policy can perform\nreal-world dough manipulation, flattening a ball of dough into a target shape.",
    "descriptor": "",
    "authors": [
      "Carl Qi",
      "Xingyu Lin",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04638"
  },
  {
    "id": "arXiv:2207.04639",
    "title": "A Dual-Polarization Information Guided Network for SAR Ship  Classification",
    "abstract": "How to fully utilize polarization to enhance synthetic aperture radar (SAR)\nship classification remains an unresolved issue. Thus, we propose a\ndual-polarization information guided network (DPIG-Net) to solve it.",
    "descriptor": "",
    "authors": [
      "Tianwen Zhang",
      "Xiaoling Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04639"
  },
  {
    "id": "arXiv:2207.04645",
    "title": "Single Mode Multi-frequency Factorization Method for the Inverse Source  Problem in Acoustic Waveguides",
    "abstract": "This paper investigates the inverse source problem with a single propagating\nmode at multiple frequencies in an acoustic waveguide. The goal is to provide\nboth theoretical justifications and efficient algorithms for imaging extended\nsources using the sampling methods. In contrast to the existing far/near field\noperator based on the integral over the space variable in the sampling methods,\na multi-frequency far-field operator is introduced based on the integral over\nthe frequency variable. This far-field operator is defined in a way to\nincorporate the possibly non-linear dispersion relation, a unique feature in\nwaveguides. The factorization method is deployed to establish a rigorous\ncharacterization of the range support which is the support of source in the\ndirection of wave propagation. A related factorization-based sampling method is\nalso discussed. These sampling methods are shown to be capable of imaging the\nrange support of the source. Numerical examples are provided to illustrate the\nperformance of the sampling methods, including an example to image a complete\nsound-soft block.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Shixu Meng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2207.04645"
  },
  {
    "id": "arXiv:2207.04646",
    "title": "DelightfulTTS 2: End-to-End Speech Synthesis with Adversarial  Vector-Quantized Auto-Encoders",
    "abstract": "Current text to speech (TTS) systems usually leverage a cascaded acoustic\nmodel and vocoder pipeline with mel-spectrograms as the intermediate\nrepresentations, which suffer from two limitations: 1) the acoustic model and\nvocoder are separately trained instead of jointly optimized, which incurs\ncascaded errors; 2) the intermediate speech representations (e.g.,\nmel-spectrogram) are pre-designed and lose phase information, which are\nsub-optimal. To solve these problems, in this paper, we develop DelightfulTTS\n2, a new end-to-end speech synthesis system with automatically learned speech\nrepresentations and jointly optimized acoustic model and vocoder. Specifically,\n1) we propose a new codec network based on vector-quantized auto-encoders with\nadversarial training (VQ-GAN) to extract intermediate frame-level speech\nrepresentations (instead of traditional representations like mel-spectrograms)\nand reconstruct speech waveform; 2) we jointly optimize the acoustic model\n(based on DelightfulTTS) and the vocoder (the decoder of VQ-GAN), with an\nauxiliary loss on the acoustic model to predict intermediate speech\nrepresentations. Experiments show that DelightfulTTS 2 achieves a CMOS gain\n+0.14 over DelightfulTTS, and more method analyses further verify the\neffectiveness of the developed system.",
    "descriptor": "\nComments: To appear in Interspeech 2022\n",
    "authors": [
      "Yanqing Liu",
      "Ruiqing Xue",
      "Lei He",
      "Xu Tan",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.04646"
  },
  {
    "id": "arXiv:2207.04647",
    "title": "Epi-constructivism: Decidable sets of computable numbers as foundational  objects for mathematics",
    "abstract": "It is well known that the R, the set of real numbers, is an abstract set,\nwhere almost all its elements cannot be described in any finite language.\nWe investigate possible approaches to what might be called an\nepi-constructionist approach to mathematics. While most constructive\nmathematics is concerned with constructive proofs, the agenda here is that the\nobjects that we study, specifically the class of numbers that we study, should\nbe an enumerable set of finite symbol strings. These might also be called\ndecidable constructive real numbers, that is our class of numbers should be a\ncomputable sets of explicitly represented computable numbers.\nThere have been various investigations of the computable numbers going back\nto Turing. Most are however not expressed constructively, rather computable is\na property assigned to some of the abstract real numbers. Other definitions\ndefine constructive real numbers without reference to the abstract R, but the\nconstruction is undecidable, i.e., we cannot determine if a given construction\nrepresents a computable real number or not. For example, we may define a real\nas a computable convergent sequence of rationals, but cannot in general decide\nif a given computable sequence is convergent.\nThis paper explores several specific classes of decidable constructive real\nnumbers that could form foundational objects for what we might call an\nepi-constructionist mathematics.",
    "descriptor": "",
    "authors": [
      "Zvi Schreiber"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.04647"
  },
  {
    "id": "arXiv:2207.04648",
    "title": "Learning Large-scale Universal User Representation with Sparse Mixture  of Experts",
    "abstract": "Learning user sequence behaviour embedding is very sophisticated and\nchallenging due to the complicated feature interactions over time and high\ndimensions of user features. Recent emerging foundation models, e.g., BERT and\nits variants, encourage a large body of researchers to investigate in this\nfield. However, unlike natural language processing (NLP) tasks, the parameters\nof user behaviour model come mostly from user embedding layer, which makes most\nexisting works fail in training a universal user embedding of large scale.\nFurthermore, user representations are learned from multiple downstream tasks,\nand the past research work do not address the seesaw phenomenon. In this paper,\nwe propose SUPERMOE, a generic framework to obtain high quality user\nrepresentation from multiple tasks. Specifically, the user behaviour sequences\nare encoded by MoE transformer, and we can thus increase the model capacity to\nbillions of parameters, or even to trillions of parameters. In order to deal\nwith seesaw phenomenon when learning across multiple tasks, we design a new\nloss function with task indicators. We perform extensive offline experiments on\npublic datasets and online experiments on private real-world business\nscenarios. Our approach achieves the best performance over state-of-the-art\nmodels, and the results demonstrate the effectiveness of our framework.",
    "descriptor": "\nComments: Accepted by ICML 2022 Pre-training Workshop\n",
    "authors": [
      "Caigao Jiang",
      "Siqiao Xue",
      "James Zhang",
      "Lingyue Liu",
      "Zhibo Zhu",
      "Hongyan Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04648"
  },
  {
    "id": "arXiv:2207.04649",
    "title": "Fast Density-Peaks Clustering: Multicore-based Parallelization Approach",
    "abstract": "Clustering multi-dimensional points is a fundamental task in many fields, and\ndensity-based clustering supports many applications as it can discover clusters\nof arbitrary shapes. This paper addresses the problem of Density-Peaks\nClustering (DPC), a recently proposed density-based clustering framework.\nAlthough DPC already has many applications, its straightforward implementation\nincurs a quadratic time computation to the number of points in a given dataset,\nthereby does not scale to large datasets. To enable DPC on large datasets, we\npropose efficient algorithms for DPC. Specifically, we propose an exact\nalgorithm, Ex-DPC, and two approximation algorithms, Approx-DPC and\nS-Approx-DPC. Under a reasonable assumption about a DPC parameter, our\nalgorithms are sub-quadratic, i.e., break the quadratic barrier. Besides,\nApprox-DPC does not require any additional parameters and can return the same\ncluster centers as those of Ex-DPC, rendering an accurate clustering result.\nS-Approx-DPC requires an approximation parameter but can speed up its\ncomputational efficiency. We further present that their efficiencies can be\naccelerated by leveraging multicore processing. We conduct extensive\nexperiments using synthetic and real datasets, and our experimental results\ndemonstrate that our algorithms are efficient, scalable, and accurate.",
    "descriptor": "",
    "authors": [
      "Daichi Amagata",
      "Takahiro Hara"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.04649"
  },
  {
    "id": "arXiv:2207.04651",
    "title": "A Lexicon and Depth-wise Separable Convolution Based Handwritten Text  Recognition System",
    "abstract": "Cursive handwritten text recognition is a challenging research problem in the\ndomain of pattern recognition. The current state-of-the-art approaches include\nmodels based on convolutional recurrent neural networks and multi-dimensional\nlong short-term memory recurrent neural networks techniques. These methods are\nhighly computationally extensive as well model is complex at design level. In\nrecent studies, combination of convolutional neural network and gated\nconvolutional neural networks based models demonstrated less number of\nparameters in comparison to convolutional recurrent neural networks based\nmodels. In the direction to reduced the total number of parameters to be\ntrained, in this work, we have used depthwise convolution in place of standard\nconvolutions with a combination of gated-convolutional neural network and\nbidirectional gated recurrent unit to reduce the total number of parameters to\nbe trained. Additionally, we have also included a lexicon based word beam\nsearch decoder at testing step. It also helps in improving the the overall\naccuracy of the model. We have obtained 3.84% character error rate and 9.40%\nword error rate on IAM dataset; 4.88% character error rate and 14.56% word\nerror rate in George Washington dataset, respectively.",
    "descriptor": "",
    "authors": [
      "Lalita Kumari",
      "Sukhdeep Singh",
      "VVS Rathore",
      "Anuj Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04651"
  },
  {
    "id": "arXiv:2207.04655",
    "title": "Personalizing Federated Medical Image Segmentation via Local Calibration",
    "abstract": "Medical image segmentation under federated learning (FL) is a promising\ndirection by allowing multiple clinical sites to collaboratively learn a global\nmodel without centralizing datasets. However, using a single model to adapt to\nvarious data distributions from different sites is extremely challenging.\nPersonalized FL tackles this issue by only utilizing partial model parameters\nshared from global server, while keeping the rest to adapt to its own data\ndistribution in the local training of each site. However, most existing methods\nconcentrate on the partial parameter splitting, while do not consider the\n\\textit{inter-site in-consistencies} during the local training, which in fact\ncan facilitate the knowledge communication over sites to benefit the model\nlearning for improving the local accuracy. In this paper, we propose a\npersonalized federated framework with \\textbf{L}ocal \\textbf{C}alibration\n(LC-Fed), to leverage the inter-site in-consistencies in both \\textit{feature-\nand prediction- levels} to boost the segmentation. Concretely, as each local\nsite has its alternative attention on the various features, we first design the\ncontrastive site embedding coupled with channel selection operation to\ncalibrate the encoded features. Moreover, we propose to exploit the knowledge\nof prediction-level in-consistency to guide the personalized modeling on the\nambiguous regions, e.g., anatomical boundaries. It is achieved by computing a\ndisagreement-aware map to calibrate the prediction. Effectiveness of our method\nhas been verified on three medical image segmentation tasks with different\nmodalities, where our method consistently shows superior performance to the\nstate-of-the-art personalized FL methods. Code is available at\nhttps://github.com/jcwang123/FedLC.",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Jiacheng Wang",
      "Yueming Jin",
      "Liansheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04655"
  },
  {
    "id": "arXiv:2207.04656",
    "title": "Topic-Grained Text Representation-based Model for Document Retrieval",
    "abstract": "Document retrieval enables users to find their required documents accurately\nand quickly. To satisfy the requirement of retrieval efficiency, prevalent deep\nneural methods adopt a representation-based matching paradigm, which saves\nonline matching time by pre-storing document representations offline. However,\nthe above paradigm consumes vast local storage space, especially when storing\nthe document as word-grained representations. To tackle this, we present TGTR,\na Topic-Grained Text Representation-based Model for document retrieval.\nFollowing the representation-based matching paradigm, TGTR stores the document\nrepresentations offline to ensure retrieval efficiency, whereas it\nsignificantly reduces the storage requirements by using novel topicgrained\nrepresentations rather than traditional word-grained. Experimental results\ndemonstrate that compared to word-grained baselines, TGTR is consistently\ncompetitive with them on TREC CAR and MS MARCO in terms of retrieval accuracy,\nbut it requires less than 1/10 of the storage space required by them. Moreover,\nTGTR overwhelmingly surpasses global-grained baselines in terms of retrieval\naccuracy.",
    "descriptor": "\nComments: Accepted to ICANN2022\n",
    "authors": [
      "Mengxue Du",
      "Shasha Li",
      "Jie Yu",
      "Jun Ma",
      "Bin Ji",
      "Huijun Liu",
      "Wuhang Lin",
      "Zibo Yi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04656"
  },
  {
    "id": "arXiv:2207.04658",
    "title": "Automatic Quantization for Physics-Based Simulation",
    "abstract": "Quantization has proven effective in high-resolution and large-scale\nsimulations, which benefit from bit-level memory saving. However, identifying a\nquantization scheme that meets the requirement of both precision and memory\nefficiency requires trial and error. In this paper, we propose a novel\nframework to allow users to obtain a quantization scheme by simply specifying\neither an error bound or a memory compression rate. Based on the error\npropagation theory, our method takes advantage of auto-diff to estimate the\ncontributions of each quantization operation to the total error. We formulate\nthe task as a constrained optimization problem, which can be efficiently solved\nwith analytical formulas derived for the linearized objective function. Our\nworkflow extends the Taichi compiler and introduces dithering to improve the\nprecision of quantized simulations. We demonstrate the generality and\nefficiency of our method via several challenging examples of physics-based\nsimulation, which achieves up to 2.5x memory compression without noticeable\ndegradation of visual quality in the results. Our code and data are available\nat https://github.com/Hanke98/AutoQuantizer.",
    "descriptor": "\nComments: 15 pages. 17 figures. Published to ACM Transactions on Graphics\n",
    "authors": [
      "Jiafeng Liu",
      "Haoyang Shi",
      "Siyuan Zhang",
      "Yin Yang",
      "Chongyang Ma",
      "Weiwei Xu"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.04658"
  },
  {
    "id": "arXiv:2207.04659",
    "title": "Speaker consistency loss and step-wise optimization for semi-supervised  joint training of TTS and ASR using unpaired text data",
    "abstract": "In this paper, we investigate the semi-supervised joint training of text to\nspeech (TTS) and automatic speech recognition (ASR), where a small amount of\npaired data and a large amount of unpaired text data are available.\nConventional studies form a cycle called the TTS-ASR pipeline, where the\nmultispeaker TTS model synthesizes speech from text with a reference speech and\nthe ASR model reconstructs the text from the synthesized speech, after which\nboth models are trained with a cycle-consistency loss. However, the synthesized\nspeech does not reflect the speaker characteristics of the reference speech and\nthe synthesized speech becomes overly easy for the ASR model to recognize after\ntraining. This not only decreases the TTS model quality but also limits the ASR\nmodel improvement. To solve this problem, we propose improving the\ncycleconsistency-based training with a speaker consistency loss and step-wise\noptimization. The speaker consistency loss brings the speaker characteristics\nof the synthesized speech closer to that of the reference speech. In the\nstep-wise optimization, we first freeze the parameter of the TTS model before\nboth models are trained to avoid over-adaptation of the TTS model to the ASR\nmodel. Experimental results demonstrate the efficacy of the proposed method.",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Naoki Makishima",
      "Satoshi Suzuki",
      "Atsushi Ando",
      "Ryo Masumura"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04659"
  },
  {
    "id": "arXiv:2207.04660",
    "title": "SummScore: A Comprehensive Evaluation Metric for Summary Quality Based  on Cross-Encoder",
    "abstract": "Text summarization models are often trained to produce summaries that meet\nhuman quality requirements. However, the existing evaluation metrics for\nsummary text are only rough proxies for summary quality, suffering from low\ncorrelation with human scoring and inhibition of summary diversity. To solve\nthese problems, we propose SummScore, a comprehensive metric for summary\nquality evaluation based on CrossEncoder. Firstly, by adopting the\noriginal-summary measurement mode and comparing the semantics of the original\ntext, SummScore gets rid of the inhibition of summary diversity. With the help\nof the text-matching pre-training Cross-Encoder, SummScore can effectively\ncapture the subtle differences between the semantics of summaries. Secondly, to\nimprove the comprehensiveness and interpretability, SummScore consists of four\nfine-grained submodels, which measure Coherence, Consistency, Fluency, and\nRelevance separately. We use semi-supervised multi-rounds of training to\nimprove the performance of our model on extremely limited annotated data.\nExtensive experiments show that SummScore significantly outperforms existing\nevaluation metrics in the above four dimensions in correlation with human\nscoring. We also provide the quality evaluation results of SummScore on 16\nmainstream summarization models for later research.",
    "descriptor": "\nComments: Accept to APWeb-WAIM2022\n",
    "authors": [
      "Wuhang Lin",
      "Shasha Li",
      "Chen Zhang",
      "Bin Ji",
      "Jie Yu",
      "Jun Ma",
      "Zibo Yi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.04660"
  },
  {
    "id": "arXiv:2207.04664",
    "title": "Robust finite element discretization and solvers for distributed  elliptic optimal control problems",
    "abstract": "We consider standard tracking-type, distributed elliptic optimal control\nproblems with $L^2$ regularization, and their finite element discretization. We\nare investigating the $L^2$ error between the finite element approximation\n$u_{\\varrho h}$ of the state $u_\\varrho$ and the desired state (target)\n$\\bar{u}$ in terms of the regularization parameter $\\varrho$ and the mesh size\n$h$ that leads to the optimal choice $\\varrho = h^4$. It turns out that, for\nthis choice of the regularization parameter, we can devise simple Jacobi-like\npreconditioned MINRES or Bramble-Pasciak CG methods that allow us to solve the\nreduced discrete optimality system in asymptotically optimal complexity with\nrespect to the arithmetical operations and memory demand. The theoretical\nresults are confirmed by several benchmark problems with targets of various\nregularities including discontinuous targets.",
    "descriptor": "",
    "authors": [
      "Ulrich Langer",
      "Richard L\u00f6scher",
      "Olaf Steinbach",
      "Huidong Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04664"
  },
  {
    "id": "arXiv:2207.04666",
    "title": "Improved bounds on the gain coefficients for digital nets in prime base",
    "abstract": "We study randomized quasi-Monte Carlo integration by scrambled nets. The\nscrambled net quadrature has long gained its popularity because it is an\nunbiased estimator of the true integral, allows for a practical error\nestimation, achieves a high order decay of the variance for smooth functions,\nand works even for $L^p$-functions with any $p>1$. The variance of the\nscrambled net quadrature for $L^2$-functions can be evaluated through the set\nof the so-called gain coefficients.\nIn this paper, based on the system of Walsh functions and the concept of dual\nnets, we provide improved upper bounds on the gain coefficients for digital\nnets in general prime base. Our results explain the known bound by Owen (1997)\nfor Faure sequences, the recently improved bound by Pan and Owen (2021) for\ndigital nets in base 2 (including Sobol' sequences as a special case), and\ntheir finding that all the nonzero gain coefficients for digital nets in base 2\nmust be powers of two, all in a unified way.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Takashi Goda",
      "Kosuke Suzuki"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04666"
  },
  {
    "id": "arXiv:2207.04668",
    "title": "A Secure Fingerprinting Framework for Distributed Image Classification",
    "abstract": "The deep learning (DL) technology has been widely used for image\nclassification in many scenarios, e.g., face recognition and suspect tracking.\nSuch a highly commercialized application has given rise to intellectual\nproperty protection of its DL model. To combat that, the mainstream method is\nto embed a unique watermark into the target model during the training process.\nHowever, existing efforts focus on detecting copyright infringement for a given\nmodel, while rarely consider the problem of traitors tracking. Moreover, the\nwatermark embedding process can incur privacy issues for the training data in a\ndistributed manner. In this paper, we propose SECUREMARK-DL, a novel\nfingerprinting framework to address the above two problems in a distributed\nlearning environment. It embeds a unique fingerprint into the target model for\neach customer, which can be extracted and verified from any suspicious model\nonce a dispute arises. In addition, it adopts a new privacy partitioning\ntechnique in the training process to protect the training data privacy.\nExtensive experiments demonstrate the robustness of SECUREMARK-DL against\nvarious attacks, and its high classification accuracy (> 95%) even if a\nlong-bit (304-bit) fingerprint is embedded into an input image.",
    "descriptor": "",
    "authors": [
      "Guowen Xu",
      "Xingshuo Han",
      "Anguo Zhang",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04668"
  },
  {
    "id": "arXiv:2207.04672",
    "title": "No Language Left Behind: Scaling Human-Centered Machine Translation",
    "abstract": "Driven by the goal of eradicating language barriers on a global scale,\nmachine translation has solidified itself as a key focus of artificial\nintelligence research today. However, such efforts have coalesced around a\nsmall subset of languages, leaving behind the vast majority of mostly\nlow-resource languages. What does it take to break the 200 language barrier\nwhile ensuring safe, high quality results, all while keeping ethical\nconsiderations in mind? In No Language Left Behind, we took on this challenge\nby first contextualizing the need for low-resource language translation support\nthrough exploratory interviews with native speakers. Then, we created datasets\nand models aimed at narrowing the performance gap between low and high-resource\nlanguages. More specifically, we developed a conditional compute model based on\nSparsely Gated Mixture of Experts that is trained on data obtained with novel\nand effective data mining techniques tailored for low-resource languages. We\npropose multiple architectural and training improvements to counteract\noverfitting while training on thousands of tasks. Critically, we evaluated the\nperformance of over 40,000 different translation directions using a\nhuman-translated benchmark, Flores-200, and combined human evaluation with a\nnovel toxicity benchmark covering all languages in Flores-200 to assess\ntranslation safety. Our model achieves an improvement of 44% BLEU relative to\nthe previous state-of-the-art, laying important groundwork towards realizing a\nuniversal translation system. Finally, we open source all contributions\ndescribed in this work, accessible at\nhttps://github.com/facebookresearch/fairseq/tree/nllb.",
    "descriptor": "\nComments: 190 pages\n",
    "authors": [
      "NLLB team",
      "Marta R. Costa-juss\u00e0",
      "James Cross",
      "Onur \u00c7elebi",
      "Maha Elbayad",
      "Kenneth Heafield",
      "Kevin Heffernan",
      "Elahe Kalbassi",
      "Janice Lam",
      "Daniel Licht",
      "Jean Maillard",
      "Anna Sun",
      "Skyler Wang",
      "Guillaume Wenzek",
      "Al Youngblood",
      "Bapi Akula",
      "Loic Barrault",
      "Gabriel Mejia Gonzalez",
      "Prangthip Hansanti",
      "John Hoffman",
      "Semarley Jarrett",
      "Kaushik Ram Sadagopan",
      "Dirk Rowe",
      "Shannon Spruit",
      "Chau Tran",
      "Pierre Andrews",
      "Necip Fazil Ayan",
      "Shruti Bhosale",
      "Sergey Edunov",
      "Angela Fan",
      "Cynthia Gao",
      "Vedanuj Goswami",
      "Francisco Guzm\u00e1n",
      "Philipp Koehn",
      "Alexandre Mourachko",
      "Christophe Ropers",
      "Safiyyah Saleem",
      "Holger Schwenk",
      "Jeff Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04672"
  },
  {
    "id": "arXiv:2207.04673",
    "title": "Learning Spatial and Temporal Variations for 4D Point Cloud Segmentation",
    "abstract": "LiDAR-based 3D scene perception is a fundamental and important task for\nautonomous driving. Most state-of-the-art methods on LiDAR-based 3D recognition\ntasks focus on single frame 3D point cloud data, and the temporal information\nis ignored in those methods. We argue that the temporal information across the\nframes provides crucial knowledge for 3D scene perceptions, especially in the\ndriving scenario. In this paper, we focus on spatial and temporal variations to\nbetter explore the temporal information across the 3D frames. We design a\ntemporal variation-aware interpolation module and a temporal voxel-point\nrefiner to capture the temporal variation in the 4D point cloud. The temporal\nvariation-aware interpolation generates local features from the previous and\ncurrent frames by capturing spatial coherence and temporal variation\ninformation. The temporal voxel-point refiner builds a temporal graph on the 3D\npoint cloud sequences and captures the temporal variation with a graph\nconvolution module. The temporal voxel-point refiner also transforms the coarse\nvoxel-level predictions into fine point-level predictions. With our proposed\nmodules, the new network TVSN achieves state-of-the-art performance on\nSemanticKITTI and SemantiPOSS. Specifically, our method achieves 52.5\\% in mIoU\n(+5.5% against previous best approaches) on the multiple scan segmentation task\non SemanticKITTI, and 63.0% on SemanticPOSS (+2.8% against previous best\napproaches).",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Shi Hanyu",
      "Wei Jiacheng",
      "Wang Hao",
      "Liu Fayao",
      "Lin Guosheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04673"
  },
  {
    "id": "arXiv:2207.04674",
    "title": "CAMS: An Annotated Corpus for Causal Analysis of Mental Health Issues in  Social Media Posts",
    "abstract": "Research community has witnessed substantial growth in the detection of\nmental health issues and their associated reasons from analysis of social\nmedia. We introduce a new dataset for Causal Analysis of Mental health issues\nin Social media posts (CAMS). Our contributions for causal analysis are\ntwo-fold: causal interpretation and causal categorization. We introduce an\nannotation schema for this task of causal analysis. We demonstrate the efficacy\nof our schema on two different datasets: (i) crawling and annotating 3155\nReddit posts and (ii) re-annotating the publicly available SDCNL dataset of\n1896 instances for interpretable causal analysis. We further combine these into\nthe CAMS dataset and make this resource publicly available along with\nassociated source code: https://github.com/drmuskangarg/CAMS. We present\nexperimental results of models learned from CAMS dataset and demonstrate that a\nclassic Logistic Regression model outperforms the next best (CNN-LSTM) model by\n4.9\\% accuracy.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Muskan Garg",
      "Chandni Saxena",
      "Veena Krishnan",
      "Ruchi Joshi",
      "Sriparna Saha",
      "Vijay Mago",
      "Bonnie J Dorr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04674"
  },
  {
    "id": "arXiv:2207.04675",
    "title": "COO: Comic Onomatopoeia Dataset for Recognizing Arbitrary or Truncated  Texts",
    "abstract": "Recognizing irregular texts has been a challenging topic in text recognition.\nTo encourage research on this topic, we provide a novel comic onomatopoeia\ndataset (COO), which consists of onomatopoeia texts in Japanese comics. COO has\nmany arbitrary texts, such as extremely curved, partially shrunk texts, or\narbitrarily placed texts. Furthermore, some texts are separated into several\nparts. Each part is a truncated text and is not meaningful by itself. These\nparts should be linked to represent the intended meaning. Thus, we propose a\nnovel task that predicts the link between truncated texts. We conduct three\ntasks to detect the onomatopoeia region and capture its intended meaning: text\ndetection, text recognition, and link prediction. Through extensive\nexperiments, we analyze the characteristics of the COO. Our data and code are\navailable at \\url{https://github.com/ku21fan/COO-Comic-Onomatopoeia}.",
    "descriptor": "\nComments: Accepted at ECCV 2022. 25 pages, 16 figures\n",
    "authors": [
      "Jeonghun Baek",
      "Yusuke Matsui",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04675"
  },
  {
    "id": "arXiv:2207.04676",
    "title": "The HCCL System for the NIST SRE21",
    "abstract": "This paper describes the systems developed by the HCCL team for the NIST 2021\nspeaker recognition evaluation (NIST SRE21).We first explore various\nstate-of-the-art speaker embedding extractors combined with a novel circle loss\nto obtain discriminative deep speaker embeddings. Considering that\ncross-channel and cross-linguistic speaker recognition are the key challenges\nof SRE21, we introduce several techniques to reduce the cross-domain mismatch.\nSpecifically, Codec and speech enhancement are directly applied to the raw\nspeech to eliminate the codecs and the environment noise mismatch. We denote\nthe methods that work directly on speech to eliminate the relatively explicit\nmismatches collectively as data adaptation methods. Experiments show that data\nadaption methods achieve 15\\% improvements over our baseline. Furthermore, some\npopular back-ends domain adaptation algorithms are deployed on speaker\nembeddings to alleviate speaker performance degradation caused by the implicit\nmismatch. Score calibration is a major failure for us in SRE21. The reason is\nthat score calibration with too many parameters easily lead to overfitting\nproblems.",
    "descriptor": "\nComments: accepted by interspeech 2022\n",
    "authors": [
      "Zhuo Li",
      "Runqiu Xiao",
      "Hangting Chen",
      "Zhenduo Zhao",
      "Zihan Zhang",
      "Wenchao Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04676"
  },
  {
    "id": "arXiv:2207.04680",
    "title": "Towards Scale-Aware, Robust, and Generalizable Unsupervised Monocular  Depth Estimation by Integrating IMU Motion Dynamics",
    "abstract": "Unsupervised monocular depth and ego-motion estimation has drawn extensive\nresearch attention in recent years. Although current methods have reached a\nhigh up-to-scale accuracy, they usually fail to learn the true scale metric due\nto the inherent scale ambiguity from training with monocular sequences. In this\nwork, we tackle this problem and propose DynaDepth, a novel scale-aware\nframework that integrates information from vision and IMU motion dynamics.\nSpecifically, we first propose an IMU photometric loss and a cross-sensor\nphotometric consistency loss to provide dense supervision and absolute scales.\nTo fully exploit the complementary information from both sensors, we further\ndrive a differentiable camera-centric extended Kalman filter (EKF) to update\nthe IMU preintegrated motions when observing visual measurements. In addition,\nthe EKF formulation enables learning an ego-motion uncertainty measure, which\nis non-trivial for unsupervised methods. By leveraging IMU during training,\nDynaDepth not only learns an absolute scale, but also provides a better\ngeneralization ability and robustness against vision degradation such as\nillumination change and moving objects. We validate the effectiveness of\nDynaDepth by conducting extensive experiments and simulations on the KITTI and\nMake3D datasets.",
    "descriptor": "\nComments: Accepted to ECCV 2022. Code is released at this https URL\n",
    "authors": [
      "Sen Zhang",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04680"
  },
  {
    "id": "arXiv:2207.04683",
    "title": "Estimating the Future Need of Balancing Power Based on Long-Term Power  System Market Simulations",
    "abstract": "With increasing penetration of variable renewable energy sources (vRES) and a\nhigher rate of electrification in the society, there will be future challenges\nin maintaining a continuous balance between electricity supply and demand. To\ninvestigate the possibility of different technologies to provide balancing\nservices, to dimension future balancing services and design technical\nrequirements for future balancing services, the future need of balancing power\nmust first be known. Future power systems are often analysed by performing\nsimulations capturing the energy produced, consumed or transmitted for\ndifferent power system components with resolution of one trading period (TP),\nhere called TP energy simulations. However, these simulations do not fully\ncapture the continuous intra-TP power balance that must be kept at every time\ninstance. In this paper, we propose a model to perform high-resolution intra-TP\nsimulations to estimate the need of balancing power based on TP energy\nsimulations. The model is applied to the Swedish system operator (SO) Svenska\nkraftn\\\"at's TP energy simulations of a scenario with high vRES penetration and\na highly electrified society in year 2045. The results show that a considerable\nneed of balancing power will occur frequently, where faster ramping of\ncomponents tend to increase the need of balancing power while assuming that the\ntransmission reliability margin (TRM) is used to net imbalances clearly\ndecreases the need of balancing power.",
    "descriptor": "\nComments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Henrik Nordstr\u00f6m",
      "Lennart S\u00f6der",
      "Robert Eriksson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04683"
  },
  {
    "id": "arXiv:2207.04684",
    "title": "Deep Squared Euclidean Approximation to the Levenshtein Distance for DNA  Storage",
    "abstract": "Storing information in DNA molecules is of great interest because of its\nadvantages in longevity, high storage density, and low maintenance cost. A key\nstep in the DNA storage pipeline is to efficiently cluster the retrieved DNA\nsequences according to their similarities. Levenshtein distance is the most\nsuitable metric on the similarity between two DNA sequences, but it is inferior\nin terms of computational complexity and less compatible with mature clustering\nalgorithms. In this work, we propose a novel deep squared Euclidean embedding\nfor DNA sequences using Siamese neural network, squared Euclidean embedding,\nand chi-squared regression. The Levenshtein distance is approximated by the\nsquared Euclidean distance between the embedding vectors, which is fast\ncalculated and clustering algorithm friendly. The proposed approach is analyzed\ntheoretically and experimentally. The results show that the proposed embedding\nis efficient and robust.",
    "descriptor": "",
    "authors": [
      "Alan J.X. Guo",
      "Cong Liang",
      "Qing-Hu Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2207.04684"
  },
  {
    "id": "arXiv:2207.04685",
    "title": "Finite Element Method for a Nonlinear PML Helmholtz Equation with High  Wave Number",
    "abstract": "A nonlinear Helmholtz equation (NLH) with high wave number and Sommerfeld\nradiation condition is approximated by the perfectly matched layer (PML)\ntechnique and then discretized by the linear finite element method (FEM).\nWave-number-explicit stability and regularity estimates and the exponential\nconvergence are proved for the nonlinear truncated PML problem. Preasymptotic\nerror estimates are obtained for the FEM, where the logarithmic factors in h\nrequired by the previous results for the NLH with impedance boundary condition\nare removed in the case of two dimensions. Moreover, local quadratic\nconvergences of the Newton's methods are derived for both the NLH with PML and\nits FEM. Numerical examples are presented to verify the accuracy of the FEM,\nwhich demonstrate that the pollution errors may be greatly reduced by applying\nthe interior penalty technique with proper penalty parameters to the FEM. The\nnonlinear phenomenon of optical bistability can be successfully simulated.",
    "descriptor": "",
    "authors": [
      "Run Jiang",
      "Yonglin Li",
      "Haijun Wu",
      "Jun Zou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04685"
  },
  {
    "id": "arXiv:2207.04686",
    "title": "(Nearly) Optimal Private Linear Regression via Adaptive Clipping",
    "abstract": "We study the problem of differentially private linear regression where each\ndata point is sampled from a fixed sub-Gaussian style distribution. We propose\nand analyze a one-pass mini-batch stochastic gradient descent method\n(DP-AMBSSGD) where points in each iteration are sampled without replacement.\nNoise is added for DP but the noise standard deviation is estimated online.\nCompared to existing $(\\epsilon, \\delta)$-DP techniques which have sub-optimal\nerror bounds, DP-AMBSSGD is able to provide nearly optimal error bounds in\nterms of key parameters like dimensionality $d$, number of points $N$, and the\nstandard deviation $\\sigma$ of the noise in observations. For example, when the\n$d$-dimensional covariates are sampled i.i.d. from the normal distribution,\nthen the excess error of DP-AMBSSGD due to privacy is $\\frac{\\sigma^2\nd}{N}(1+\\frac{d}{\\epsilon^2 N})$, i.e., the error is meaningful when number of\nsamples $N= \\Omega(d \\log d)$ which is the standard operative regime for linear\nregression. In contrast, error bounds for existing efficient methods in this\nsetting are: $\\mathcal{O}\\big(\\frac{d^3}{\\epsilon^2 N^2}\\big)$, even for\n$\\sigma=0$. That is, for constant $\\epsilon$, the existing techniques require\n$N=\\Omega(d\\sqrt{d})$ to provide a non-trivial result.",
    "descriptor": "\nComments: 41 Pages, Accepted in the 35th Annual Conference on Learning Theory (COLT 2022)\n",
    "authors": [
      "Prateek Varshney",
      "Abhradeep Thakurta",
      "Prateek Jain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.04686"
  },
  {
    "id": "arXiv:2207.04690",
    "title": "Dynamic Budget Throttling in Repeated Second-Price Auctions",
    "abstract": "Throttling is one of the most popular budget control methods in today's\nonline advertising markets. When a budget-constrained advertiser employs\nthrottling, she can choose whether to participate in an auction or not after\nthe advertising platform recommends a bid. This paper focuses on the dynamic\nbudget throttling process in repeated second-price auctions from a theoretical\nview. An essential feature of the underlying problem is that the advertiser\ndoes not know the distribution of the highest competing bid upon entering the\nmarket. To model the difficulty of eliminating such uncertainty, we consider\ntwo different information structures in order. The advertiser could obtain the\nhighest competing bid in each round with full-information feedback. Meanwhile,\nwith partial information feedback, the advertiser could only obtain the highest\ncompeting bid in the auctions she participates in. We propose the OGD-CB\nalgorithm, which involves simultaneous distribution learning and revenue\noptimization facing online ad queries. In both settings, we demonstrate that\nthis algorithm guarantees an $O(\\sqrt{T\\log T})$ regret with probability $1 -\nO(1/T)$ relative to the fluid adaptive throttling benchmark. By proving a lower\nbound of $\\Omega(\\sqrt{T})$ on the minimal regret for even the hindsight\noptimum, we establish the near optimality of our algorithm. Finally, we compare\nthe fluid optimum of throttling to that of pacing, another widely adopted\nbudget control method. The numerical relationship of these benchmarks benefits\nus with further insights into the comparison of different online algorithms for\nbudget management.",
    "descriptor": "\nComments: 29 pages, 1 table\n",
    "authors": [
      "Zhaohua Chen",
      "Chang Wang",
      "Qian Wang",
      "Yuqi Pan",
      "Zhuming Shi",
      "Chuyue Tang",
      "Zheng Cai",
      "Yukun Ren",
      "Zhihua Zhu",
      "Xiaotie Deng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2207.04690"
  },
  {
    "id": "arXiv:2207.04691",
    "title": "Performance Bounds for Cooperative Localisation in the Starlink Network",
    "abstract": "Mega-constellations in Low Earth Orbit have the potential to revolutionise\nworldwide internet access. The concomitant potential of these\nmega-constellations to impact space sustainability, however, has prompted\nconcern from space actors as well as provoking concern in the ground-based\nastronomy community. Increasing the knowledge of the orbital state of\nsatellites in mega-constellations improves space situations awareness, reducing\nthe need for collision avoidance manoeuvres and allowing astronomers to prepare\nbetter observational mitigation strategies. In this paper, we create a model of\nPhase 1 of Starlink, one of the more well-studied megaconstellations, and\ninvestigate the potential of cooperative localisation using time-ofarrival\nmeasurements from the optical inter-satellite links in the constellation. To\nthis end, we study the performance of any unbiased estimator for localisation,\nby calculating the instantaneous Cram$\\acute{\\text{e}}$r-Rao bound for two\nsituations; one in which inter-satellite measurements and measurements from\nground stations were considered, and one in which only relative navigation from\ninter-satellite measurements were considered. Our results show that\nlocalisation determined from a combination of inter-satellite measurements and\nground stations can have at best an an average RMSE of approximately 10.15\nmetres over the majority of a satellite's orbit. Relative localisation using\nonly inter-satellite measurements has a slightly poorer performance with an\naverage RMSE of 10.68 metres. The results show that both anchored and\nanchorless inter-satellite cooperative localisation are dependent on the\nconstellation's geometry and the characteristics of the inter-satellite links,\nboth of which could inform the use of relative navigation in large satellite\nconstellations in future.",
    "descriptor": "\nComments: In submission\n",
    "authors": [
      "Calum Spring-Turner",
      "Raj Thilak Rajan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2207.04691"
  },
  {
    "id": "arXiv:2207.04692",
    "title": "PUF-Phenotype: A Robust and Noise-Resilient Approach to Aid  Intra-Group-based Authentication with DRAM-PUFs Using Machine Learning",
    "abstract": "As the demand for highly secure and dependable lightweight systems increases\nin the modern world, Physically Unclonable Functions (PUFs) continue to promise\na lightweight alternative to high-cost encryption techniques and secure key\nstorage. While the security features promised by PUFs are highly attractive for\nsecure system designers, they have been shown to be vulnerable to various\nsophisticated attacks - most notably Machine Learning (ML) based modelling\nattacks (ML-MA) which attempt to digitally clone the PUF behaviour and thus\nundermine their security. More recent ML-MA have even exploited publicly known\nhelper data required for PUF error correction in order to predict PUF responses\nwithout requiring knowledge of response data. In response to this, research is\nbeginning to emerge regarding the authentication of PUF devices with the\nassistance of ML as opposed to traditional PUF techniques of storage and\ncomparison of pre-known Challenge-Response pairs (CRPs). In this article, we\npropose a classification system using ML based on a novel `PUF-Phenotype'\nconcept to accurately identify the origin and determine the validity of noisy\nmemory derived (DRAM) PUF responses as an alternative to helper data-reliant\ndenoising techniques. To our best knowledge, we are the first to perform\nclassification over multiple devices per model to enable a group-based PUF\nauthentication scheme. We achieve up to 98\\% classification accuracy using a\nmodified deep convolutional neural network (CNN) for feature extraction in\nconjunction with several well-established classifiers. We also experimentally\nverified the performance of our model on a Raspberry Pi device to determine the\nsuitability of deploying our proposed model in a resource-constrained\nenvironment.",
    "descriptor": "\nComments: 13 pages main text, 7 pages supplementary material (total 20 pages), 8 figures, submitted to IEEE Transactions on Information Forensics and Security\n",
    "authors": [
      "Owen Millwood",
      "Jack Miskelly",
      "Bohao Yang",
      "Prosanta Gope",
      "Elif Kavun",
      "Chenghua Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04692"
  },
  {
    "id": "arXiv:2207.04693",
    "title": "Exploring Contextual Relationships for Cervical Abnormal Cell Detection",
    "abstract": "Cervical abnormal cell detection is a challenging task as the morphological\ndifferences between abnormal cells and normal cells are usually subtle. To\ndetermine whether a cervical cell is normal or abnormal, cytopathologists\nalways take surrounding cells as references and make careful comparison to\nidentify its abnormality. To mimic these clinical behaviors, we propose to\nexplore contextual relationships to boost the performance of cervical abnormal\ncell detection. Specifically, both contextual relationships between cells and\ncell-to-global images are exploited to enhance features of each region of\ninterest (RoI) proposals. Accordingly, two modules, termed as RoI-relationship\nattention module (RRAM) and global RoI attention module (GRAM) are developed\nand their combination strategies are also investigated. We setup strong\nbaselines by using single-head or double-head Faster R-CNN with feature pyramid\nnetwork (FPN) and integrate our RRAM and GRAM into them to validate the\neffectiveness of the proposed modules. Experiments conducted on a large\ncervical cell detection dataset consisting of 40,000 cytology images reveal\nthat the introduction of RRAM and GRAM both achieves better average precision\n(AP) than the baseline methods. Moreover, when cascading RRAM and GRAM, our\nmethod outperforms the state-of-the-art (SOTA) methods. Furthermore, we also\nshow the proposed feature enhancing scheme can facilitate the image-level and\nsmear-level classification. The code and trained models are publicly available\nat https://github.com/CVIU-CSU/CR4CACD.",
    "descriptor": "\nComments: 13 pages, 14 tables, and 3 figures\n",
    "authors": [
      "Yixiong Liang",
      "Shuo Feng",
      "Qing Liu",
      "Hulin Kuang",
      "Liyan Liao",
      "Yun Du",
      "Nanying Che",
      "Jianfeng Liu",
      "Jianxin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04693"
  },
  {
    "id": "arXiv:2207.04695",
    "title": "2D Beam Domain Statistical CSI Estimation for Massive MIMO Uplink",
    "abstract": "In this paper, we investigate the beam domain statistical channel state\ninformation (CSI) estimation for the two dimensional (2D) beam based\nstatistical channel model (BSCM) in massive MIMO systems.The problem is to\nestimate the beam domain channel power matrices (BDCPMs) based on multiple\nreceive pilot signals. A receive model shows the relation between the\nstatistical property of the receive pilot signals and the BDCPMs is derived\nfrom the 2D-BSCM. On the basis of the receive model,we formulate an\noptimization problem with the Kullback-Leibler (KL) divergence. By solving the\noptimization problem, a novel method to estimate the statistical CSI without\ninvolving instantaneous CSI is proposed. The proposed method has much lower\ncomplexity than the MMV focal underdetermined system solver (M-FOCUSS)\nalgorithm. We further reduce the complexity of the proposed method by utilizing\nthe circulant structures of particular matrices in the algorithm. We also\nshowed the generality of the proposed method by introducing another\napplication. Simulations results show that the proposed method works well and\nbring significant performance gain when used in channel estimation.",
    "descriptor": "\nComments: 28 pages, 7 figures, submitted to IEEE Trans. Wirel. Commun\n",
    "authors": [
      "An-An Lu",
      "Yan Chen",
      "Xiqi Gao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04695"
  },
  {
    "id": "arXiv:2207.04697",
    "title": "Multi-level Fusion of Wav2vec 2.0 and BERT for Multimodal Emotion  Recognition",
    "abstract": "The research and applications of multimodal emotion recognition have become\nincreasingly popular recently. However, multimodal emotion recognition faces\nthe challenge of lack of data. To solve this problem, we propose to use\ntransfer learning which leverages state-of-the-art pre-trained models including\nwav2vec 2.0 and BERT for this task. Multi-level fusion approaches including\ncoattention-based early fusion and late fusion with the models trained on both\nembeddings are explored. Also, a multi-granularity framework which extracts not\nonly frame-level speech embeddings but also segment-level embeddings including\nphone, syllable and word-level speech embeddings is proposed to further boost\nthe performance. By combining our coattention-based early fusion model and late\nfusion model with the multi-granularity feature extraction framework, we obtain\nresult that outperforms best baseline approaches by 1.3% unweighted accuracy\n(UA) on the IEMOCAP dataset.",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Zihan Zhao",
      "Yanfeng Wang",
      "Yu Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04697"
  },
  {
    "id": "arXiv:2207.04703",
    "title": "Don't Start From Scratch: Leveraging Prior Data to Automate Robotic  Reinforcement Learning",
    "abstract": "Reinforcement learning (RL) algorithms hold the promise of enabling\nautonomous skill acquisition for robotic systems. However, in practice,\nreal-world robotic RL typically requires time consuming data collection and\nfrequent human intervention to reset the environment. Moreover, robotic\npolicies learned with RL often fail when deployed beyond the carefully\ncontrolled setting in which they were learned. In this work, we study how these\nchallenges can all be tackled by effective utilization of diverse offline\ndatasets collected from previously seen tasks. When faced with a new task, our\nsystem adapts previously learned skills to quickly learn to both perform the\nnew task and return the environment to an initial state, effectively performing\nits own environment reset. Our empirical results demonstrate that incorporating\nprior data into robotic reinforcement learning enables autonomous learning,\nsubstantially improves sample-efficiency of learning, and enables better\ngeneralization.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Homer Walke",
      "Jonathan Yang",
      "Albert Yu",
      "Aviral Kumar",
      "Jedrzej Orbik",
      "Avi Singh",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04703"
  },
  {
    "id": "arXiv:2207.04706",
    "title": "What Your Wearable Devices Revealed About You and Possibilities of  Non-Cooperative 802.11 Presence Detection During Your Last IPIN Visit",
    "abstract": "The focus on privacy-related measures regarding wireless networks grew in\nlast couple of years. This is especially important with technologies like Wi-Fi\nor Bluetooth, which are all around us and our smartphones use them not just for\nconnection to the internet or other devices, but for localization purposes as\nwell. In this paper, we analyze and evaluate probe request frames of 802.11\nwireless protocol captured during the 11th international conference on Indoor\nPositioning and Indoor Navigation (IPIN) 2021. We explore the temporal\noccupancy of the conference space during four days of the conference as well as\nnon-cooperatively track the presence of devices in the proximity of the session\nrooms using 802.11 management frames, with and without using MAC address\nrandomization. We carried out this analysis without trying to identify/reveal\nthe identity of the users or in any way reverse the MAC address randomization.\nAs a result of the analysis, we detected that there are still many devices not\nadopting MAC randomization, because either it is not implemented, or users\ndisabled it. In addition, many devices can be easily tracked despite employing\nMAC randomization.",
    "descriptor": "\nComments: 7 pages, 7 figures, submitted to IPIN2022 conference\n",
    "authors": [
      "Tomas Bravenec",
      "Joaqu\u00edn Torres-Sospedra",
      "Michael Gould",
      "Tomas Fryza"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04706"
  },
  {
    "id": "arXiv:2207.04709",
    "title": "A Baselined Gated Attention Recurrent Network for Request Prediction in  Ridesharing",
    "abstract": "Ridesharing has received global popularity due to its convenience and cost\nefficiency for both drivers and passengers and its strong potential to\ncontribute to the implementation of the UN Sustainable Development Goals. As a\nresult recent years have witnessed an explosion of research interest in the\nRSODP (Origin-Destination Prediction for Ridesharing) problem with the goal of\npredicting the future ridesharing requests and providing schedules for vehicles\nahead of time. Most of existing prediction models utilise Deep Learning,\nhowever they fail to effectively consider both spatial and temporal dynamics.\nIn this paper the Baselined Gated Attention Recurrent Network (BGARN), is\nproposed, which uses graph convolution with multi-head gated attention to\nextract spatial features, a recurrent module to extract temporal features, and\na baselined transferring layer to calculate the final results. The model is\nimplemented with PyTorch and DGL (Deep Graph Library) and is experimentally\nevaluated using the New York Taxi Demand Dataset. The results show that BGARN\noutperforms all the other existing models in terms of prediction accuracy.",
    "descriptor": "\nComments: 12 pages, 6 figures, submitted to IEEE Access\n",
    "authors": [
      "Jingran Shen",
      "Nikos Tziritas",
      "Georgios Theodoropoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.04709"
  },
  {
    "id": "arXiv:2207.04712",
    "title": "On the Age of Information for AMP based Grant-Free Random Access",
    "abstract": "With the rapid development of Internet of Things (IoT), massive devices are\ndeployed, which poses severe challenges on access networks due to limited\ncommunication resources. When massive users contend for access, the information\nfreshness gets worse caused by increasing collisions. It could be fatal for\ninformation freshness sensing scenarios, such as remote monitoring systems or\nself-driving systems, in which information freshness plays a critical part. In\nthis paper, by taking the Age of Information (AoI) as the primary performance\nindicator, the information freshness using AMP-based grant-free scheme is\ninvestigated and compared with grant-based scheme. Base on the analysis, a user\nscheduling strategy with sleep threshold and forcing active threshold is\nproposed to further reduce average AoI (AAoI). Numerical results reveal that\nthe AMP-based grant-free scheme can provide sufficient access capability with\nless pilot resources, and it is robust to the fluctuation of the number of\nactive users. That ensures that the AMP-based grant-free scheme can keep the\nAAoI at a low level. It is also shown that the proposed threshold strategy can\neffectively improve the information freshness.",
    "descriptor": "\nComments: 6 pages, 6 figures, ICCC\n",
    "authors": [
      "Dongliang Zhang",
      "Jie Gong",
      "Xiang Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04712"
  },
  {
    "id": "arXiv:2207.04713",
    "title": "GMN: Generative Multi-modal Network for Practical Document Information  Extraction",
    "abstract": "Document Information Extraction (DIE) has attracted increasing attention due\nto its various advanced applications in the real world. Although recent\nliterature has already achieved competitive results, these approaches usually\nfail when dealing with complex documents with noisy OCR results or mutative\nlayouts. This paper proposes Generative Multi-modal Network (GMN) for\nreal-world scenarios to address these problems, which is a robust multi-modal\ngeneration method without predefined label categories. With the carefully\ndesigned spatial encoder and modal-aware mask module, GMN can deal with complex\ndocuments that are hard to serialized into sequential order. Moreover, GMN\ntolerates errors in OCR results and requires no character-level annotation,\nwhich is vital because fine-grained annotation of numerous documents is\nlaborious and even requires annotators with specialized domain knowledge.\nExtensive experiments show that GMN achieves new state-of-the-art performance\non several public DIE datasets and surpasses other methods by a large margin,\nespecially in realistic scenes.",
    "descriptor": "\nComments: Accepted to NAACL 2022 main conference\n",
    "authors": [
      "Haoyu Cao",
      "Jiefeng Ma",
      "Antai Guo",
      "Yiqing Hu",
      "Hao Liu",
      "Deqiang Jiang",
      "Yinsong Liu",
      "Bo Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04713"
  },
  {
    "id": "arXiv:2207.04716",
    "title": "PowerDuck: A GOOSE Data Set of Cyberattacks in Substations",
    "abstract": "Power grids worldwide are increasingly victims of cyberattacks, where\nattackers can cause immense damage to critical infrastructure. The growing\ndigitalization and networking in power grids combined with insufficient\nprotection against cyberattacks further exacerbate this trend. Hence, security\nengineers and researchers must counter these new risks by continuously\nimproving security measures. Data sets of real network traffic during\ncyberattacks play a decisive role in analyzing and understanding such attacks.\nTherefore, this paper presents PowerDuck, a publicly available security data\nset containing network traces of GOOSE communication in a physical substation\ntestbed. The data set includes recordings of various scenarios with and without\nthe presence of attacks. Furthermore, all network packets originating from the\nattacker are clearly labeled to facilitate their identification. We thus\nenvision PowerDuck improving and complementing existing data sets of\nsubstations, which are often generated synthetically, thus enhancing the\nsecurity of power grids.",
    "descriptor": "\nComments: Cyber Security Experimentation and Test Workshop (CSET 2022)\n",
    "authors": [
      "Sven Zemanek",
      "Immanuel Hacker",
      "Konrad Wolsing",
      "Eric Wagner",
      "Martin Henze",
      "Martin Serror"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04716"
  },
  {
    "id": "arXiv:2207.04718",
    "title": "Physical Attack on Monocular Depth Estimation with Optimal Adversarial  Patches",
    "abstract": "Deep learning has substantially boosted the performance of Monocular Depth\nEstimation (MDE), a critical component in fully vision-based autonomous driving\n(AD) systems (e.g., Tesla and Toyota). In this work, we develop an attack\nagainst learning-based MDE. In particular, we use an optimization-based method\nto systematically generate stealthy physical-object-oriented adversarial\npatches to attack depth estimation. We balance the stealth and effectiveness of\nour attack with object-oriented adversarial design, sensitive region\nlocalization, and natural style camouflage. Using real-world driving scenarios,\nwe evaluate our attack on concurrent MDE models and a representative downstream\ntask for AD (i.e., 3D object detection). Experimental results show that our\nmethod can generate stealthy, effective, and robust adversarial patches for\ndifferent target objects and models and achieves more than 6 meters mean depth\nestimation error and 93% attack success rate (ASR) in object detection with a\npatch of 1/9 of the vehicle's rear area. Field tests on three different driving\nroutes with a real vehicle indicate that we cause over 6 meters mean depth\nestimation error and reduce the object detection rate from 90.70% to 5.16% in\ncontinuous video frames.",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Zhiyuan Cheng",
      "James Liang",
      "Hongjun Choi",
      "Guanhong Tao",
      "Zhiwen Cao",
      "Dongfang Liu",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04718"
  },
  {
    "id": "arXiv:2207.04719",
    "title": "Identifying public values and spatial conflicts in urban planning",
    "abstract": "Identifying the diverse and often competing values of citizens, and resolving\nthe consequent public value conflicts, are of significant importance for\ninclusive and integrated urban development. Scholars have highlighted that\nrelational, value-laden urban space gives rise to many diverse conflicts that\nvary both spatially and temporally. Although notions of public value conflicts\nhave been conceived in theory, there are very few empirical studies that\nidentify such values and their conflicts in urban space. Building on public\nvalue theory and using a case-study mixed-methods approach, this paper proposes\na new approach to empirically investigate public value conflicts in urban\nspace. Using unstructured participatory data of 4,528 citizen contributions\nfrom a Public Participation Geographic Information Systems in Hamburg, Germany,\nnatural language processing and spatial clustering techniques are used to\nidentify areas of potential value conflicts. Four expert workshops assess and\ninterpret these quantitative findings. Integrating both quantitative and\nqualitative results, 19 general public values and a total of 9 archetypical\nconflicts are identified. On the basis of these results, this paper proposes a\nnew conceptual tool of Public Value Spheres that extends the theoretical notion\nof public-value conflicts and helps to further account for the value-laden\nnature of urban space.",
    "descriptor": "",
    "authors": [
      "Rico H. Herzog",
      "Juliana E. Gon\u00e7alves",
      "Geertje Slingerland",
      "Reinout Kleinhans",
      "Holger Prang",
      "Frances Brazier",
      "Trivik Verma"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04719"
  },
  {
    "id": "arXiv:2207.04721",
    "title": "Hybrid Skip: A Biologically Inspired Skip Connection for the UNet  Architecture",
    "abstract": "In this work we introduce a biologically inspired long-range skip connection\nfor the UNet architecture that relies on the perceptual illusion of hybrid\nimages, being images that simultaneously encode two images. The fusion of early\nencoder features with deeper decoder ones allows UNet models to produce\nfiner-grained dense predictions. While proven in segmentation tasks, the\nnetwork's benefits are down-weighted for dense regression tasks as these\nlong-range skip connections additionally result in texture transfer artifacts.\nSpecifically for depth estimation, this hurts smoothness and introduces false\npositive edges which are detrimental to the task due to the depth maps'\npiece-wise smooth nature. The proposed HybridSkip connections show improved\nperformance in balancing the trade-off between edge preservation, and the\nminimization of texture transfer artifacts that hurt smoothness. This is\nachieved by the proper and balanced exchange of information that Hybrid-Skip\nconnections offer between the high and low frequency, encoder and decoder\nfeatures, respectively.",
    "descriptor": "\nComments: Project page at this https URL\n",
    "authors": [
      "Nikolaos Zioulis",
      "Georgios Albanis",
      "Petros Drakoulis",
      "Federico Alvarez",
      "Dimitrios Zarpalas",
      "Petros Daras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.04721"
  },
  {
    "id": "arXiv:2207.04724",
    "title": "Interpretability by design using computer vision for behavioral sensing  in child and adolescent psychiatry",
    "abstract": "Observation is an essential tool for understanding and studying human\nbehavior and mental states. However, coding human behavior is a time-consuming,\nexpensive task, in which reliability can be difficult to achieve and bias is a\nrisk. Machine learning (ML) methods offer ways to improve reliability, decrease\ncost, and scale up behavioral coding for application in clinical and research\nsettings. Here, we use computer vision to derive behavioral codes or concepts\nof a gold standard behavioral rating system, offering familiar interpretation\nfor mental health professionals. Features were extracted from videos of\nclinical diagnostic interviews of children and adolescents with and without\nobsessive-compulsive disorder. Our computationally-derived ratings were\ncomparable to human expert ratings for negative emotions,\nactivity-level/arousal and anxiety. For the attention and positive affect\nconcepts, our ML ratings performed reasonably. However, results for gaze and\nvocalization indicate a need for improved data quality or additional data\nmodalities.",
    "descriptor": "\nComments: Presented at 2nd Workshop on Interpretable Machine Learning in Healthcare (IMLH) - International Conference on Machine Learning (ICML) 2022\n",
    "authors": [
      "Flavia D. Frumosu",
      "Nicole N. L\u00f8nfeldt",
      "A.-R. Cecilie Mora-Jensen",
      "Sneha Das",
      "Nicklas Leander Lund",
      "A. Katrine Pagsberg",
      "Line K. H. Clemmensen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04724"
  },
  {
    "id": "arXiv:2207.04726",
    "title": "On the Convergence of the Backward Reachable Sets of Robust Controlled  Invariant Sets For Discrete-time Linear Systems",
    "abstract": "This paper considers discrete-time linear systems with bounded additive\ndisturbances, and studies the convergence properties of the backward reachable\nsets of robust controlled invariant sets (RCIS). Under a simple condition, we\nprove that the backward reachable sets of an RCIS are guaranteed to converge to\nthe maximal RCIS in Hausdorff distance, with an exponential convergence rate.\nWhen all sets are represented by polytopes, this condition can be checked\nnumerically via a linear program. We discuss how the developed condition\ngeneralizes the existing conditions in the literature for (controlled)\ninvariant sets of systems without disturbances (or without control inputs).",
    "descriptor": "\nComments: 8 pages, submitted to CDC 2022\n",
    "authors": [
      "Zexiang Liu",
      "Necmiye Ozay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04726"
  },
  {
    "id": "arXiv:2207.04730",
    "title": "Multimodal Multi-objective Optimization: Comparative Study of the  State-of-the-Art",
    "abstract": "Multimodal multi-objective problems (MMOPs) commonly arise in real-world\nproblems where distant solutions in decision space correspond to very similar\nobjective values. To obtain all solutions for MMOPs, many multimodal\nmulti-objective evolutionary algorithms (MMEAs) have been proposed. For now,\nfew studies have encompassed most of the recently proposed representative MMEAs\nand made a comparative comparison. In this study, we first review the related\nworks during the last two decades. Then, we choose 12 state-of-the-art\nalgorithms that utilize different diversity-maintaining techniques and compared\ntheir performance on existing test suites. Experimental results indicate the\nstrengths and weaknesses of different techniques on different types of MMOPs,\nthus providing guidance on how to select/design MMEAs in specific scenarios.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Wenhua Li",
      "Tao Zhang",
      "Rui Wang",
      "Jing Liang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.04730"
  },
  {
    "id": "arXiv:2207.04733",
    "title": "Collaborative Load Management in Smart Home Area Network",
    "abstract": "An efficient Home Area Network (HAN) acts as a base of an Advanced Metering\nInfrastructure (AMI). A HAN not only facilitates AMI with efficient real-time\nmonitoring of the electricity consumption but also manages the load profile of\nthe whole system. However, the existing works on implementing HAN are mostly\ncentralized and suffer from well-known problems. In this work, we propose an\nIoT-based efficient decentralized strategy using synchronous transmission to\npractically realize HAN. An inter-device coordination strategy is proposed to\nminimize the peak load as well as reduce the sudden changes in the overall\nsystem without compromising the users requirements. Through experiments over\nIoT-testbeds, we demonstrate that the proposed strategy can reduce the peak\nload upto 50% and reduce the load variations upto 58% for even a high and\nrandom rate of requests for execution of power-hungry house appliances.",
    "descriptor": "",
    "authors": [
      "Jagnyashini Debadarshini",
      "Sudipta Saha"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.04733"
  },
  {
    "id": "arXiv:2207.04734",
    "title": "Cut finite element method for divergence free approximation of  incompressible flow: optimal error estimates and pressure independence",
    "abstract": "In this note we design a cut finite element method for a low order divergence\nfree element applied to a boundary value problem subject to Stokes' equations.\nFor the imposition of Dirichlet boundary conditions we consider either\nNitsche's method or a stabilized Lagrange multiplier method. In both cases the\nnormal component of the velocity is constrained using a multiplier, different\nfrom the standard pressure approximation. The divergence of the approximate\nvelocities is pointwise zero over the whole mesh domain, and we derive optimal\nerror estimates for the velocity and pressures, where the error constant is\nindependent of how of the the physical domain intersects the computational\nmesh, and of the regularity of the pressure multiplier imposing the divergence\nfree condition.",
    "descriptor": "",
    "authors": [
      "Erik Burman",
      "Peter Hansbo",
      "Mats G. Larson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04734"
  },
  {
    "id": "arXiv:2207.04735",
    "title": "A Miniature 3-DoF Flexible Parallel Robotic Wrist Using NiTi Wires for  Gastrointestinal Endoscopic Surgery",
    "abstract": "Gastrointestinal endoscopic surgery (GES) has high requirements for\ninstruments' size and distal dexterity, because of the narrow endoscopic\nchannel and long, tortuous human gastrointestinal tract. This paper utilized\nNickel-Titanium (NiTi) wires to develop a miniature 3-DoF\n(pitch-yaw-translation) flexible parallel robotic wrist (FPRW). Additionally,\nwe assembled an electric knife on the wrist's connection interface and then\nteleoperated it to perform an endoscopic submucosal dissection (ESD) on porcine\nstomachs. The effective performance in each ESD workflow proves that the\ndesigned FPRW has sufficient workspace, high distal dexterity, and high\npositioning accuracy.",
    "descriptor": "\nComments: IEEE International Conference on Robotics and Automation (ICRA) 2022 workshop: Frontiers of Endoluminal Intervention: Clinical opportunities and technical challenges\n",
    "authors": [
      "Huxin Gao",
      "Xiao xiao",
      "Xiaoxiao Yang",
      "Tao Zhang",
      "Xiuli Zuo",
      "Yanqing Li",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04735"
  },
  {
    "id": "arXiv:2207.04738",
    "title": "Robust Beamforming Design for IRS-Aided URLLC in D2D Networks",
    "abstract": "Intelligent reflecting surface (IRS) and device-to-device (D2D) communication\nare two promising technologies for improving transmission reliability between\ntransceivers in communication systems. In this paper, we consider the design of\nreliable communication between the access point (AP) and actuators for a\ndownlink multiuser multiple-input single-output (MISO) system in the industrial\nIoT (IIoT) scenario. We propose a two-stage protocol combining IRS with D2D\ncommunication so that all actuators can successfully receive the message from\nAP within a given delay. The superiority of the protocol is that the\ncommunication reliability between AP and actuators is doubly augmented by the\nIRS-aided first-stage transmission and the second-stage D2D transmission. A\njoint optimization problem of active and passive beamforming is formulated,\nwhich aims to maximize the number of actuators with successful decoding. We\nstudy the joint beamforming problem for cases where the channel state\ninformation (CSI) is perfect and imperfect. For each case, we develop efficient\nalgorithms that include convergence and complexity analysis. Simulation results\ndemonstrate the necessity and role of IRS with a well-optimized reflection\nmatrix, and the D2D network in promoting reliable communication. Moreover, the\nproposed protocol can enable reliable communication even in the presence of\nstringent latency requirements and CSI estimation errors.",
    "descriptor": "",
    "authors": [
      "Jing Cheng",
      "Chao Shen",
      "Zheng Chen",
      "Nikolaos Pappas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.04738"
  },
  {
    "id": "arXiv:2207.04744",
    "title": "The Confluence of Blockchain and 6G Network: Scenarios Analysis and  Performance Assessment",
    "abstract": "Emerging advanced applications, such as smart cities, healthcare, and virtual\nreality, demand more challenging requirements on sixth-generation (6G) mobile\nnetworks, including the need for improved secrecy, greater integrity,\nnon-repudiation, authentication, and access control. While blockchain, with its\nintrinsic features, is generally regarded as one of the most disruptive\ntechnological enablers for 6G functional standards, there is no comprehensive\nstudy of whether, when, and how blockchain will be used in 6G scenarios.\nExisting research lacks performance assessment methodology for the use of\nblockchain in 6G scenarios. Therefore, we abstract seven fine-grained 6G\npossibilities from the application layer and investigate the why, what, and\nwhen issues for 6G scenarios in this work. Moreover, we provide a methodology\nfor evaluating the performance and scalability of blockchain-based 6G\nscenarios. In conclusion, we undertake comprehensive experimental to assess the\nperformance of the Quorum blockchain and 6G scenarios. The experimental results\nshow that a consortium blockchain with the proper settings may satisfy the\nperformance and scalability requiremen",
    "descriptor": "",
    "authors": [
      "Bo Li",
      "Shuiguang Deng",
      "Xueqiang Yan",
      "Schahram Dustdar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.04744"
  },
  {
    "id": "arXiv:2207.04748",
    "title": "On Computing Relevant Features for Explaining NBCs",
    "abstract": "Despite the progress observed with model-agnostic explainable AI (XAI), it is\nthe case that model-agnostic XAI can produce incorrect explanations. One\nalternative are the so-called formal approaches to XAI, that include\nPI-explanations. Unfortunately, PI-explanations also exhibit important\ndrawbacks, the most visible of which is arguably their size. The computation of\nrelevant features serves to trade off probabilistic precision for the number of\nfeatures in an explanation. However, even for very simple classifiers, the\ncomplexity of computing sets of relevant features is prohibitive. This paper\ninvestigates the computation of relevant sets for Naive Bayes Classifiers\n(NBCs), and shows that, in practice, these are easy to compute. Furthermore,\nthe experiments confirm that succinct sets of relevant features can be obtained\nwith NBCs.",
    "descriptor": "",
    "authors": [
      "Yacine Izza",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04748"
  },
  {
    "id": "arXiv:2207.04750",
    "title": "Geometry-aware Single-image Full-body Human Relighting",
    "abstract": "Single-image human relighting aims to relight a target human under new\nlighting conditions by decomposing the input image into albedo, shape and\nlighting. Although plausible relighting results can be achieved, previous\nmethods suffer from both the entanglement between albedo and lighting and the\nlack of hard shadows, which significantly decrease the realism. To tackle these\ntwo problems, we propose a geometry-aware single-image human relighting\nframework that leverages single-image geometry reconstruction for joint\ndeployment of traditional graphics rendering and neural rendering techniques.\nFor the de-lighting, we explore the shortcomings of UNet architecture and\npropose a modified HRNet, achieving better disentanglement between albedo and\nlighting. For the relighting, we introduce a ray tracing-based per-pixel\nlighting representation that explicitly models high-frequency shadows and\npropose a learning-based shading refinement module to restore realistic shadows\n(including hard cast shadows) from the ray-traced shading maps. Our framework\nis able to generate photo-realistic high-frequency shadows such as cast shadows\nunder challenging lighting conditions. Extensive experiments demonstrate that\nour proposed method outperforms previous methods on both synthetic and real\nimages.",
    "descriptor": "\nComments: accepted by ECCV2022\n",
    "authors": [
      "Chaonan Ji",
      "Tao Yu",
      "Kaiwen Guo",
      "Jingxin Liu",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04750"
  },
  {
    "id": "arXiv:2207.04754",
    "title": "Snow Mask Guided Adaptive Residual Network for Image Snow Removal",
    "abstract": "Image restoration under severe weather is a challenging task. Most of the\npast works focused on removing rain and haze phenomena in images. However, snow\nis also an extremely common atmospheric phenomenon that will seriously affect\nthe performance of high-level computer vision tasks, such as object detection\nand semantic segmentation. Recently, some methods have been proposed for snow\nremoving, and most methods deal with snow images directly as the optimization\nobject. However, the distribution of snow location and shape is complex.\nTherefore, failure to detect snowflakes / snow streak effectively will affect\nsnow removing and limit the model performance. To solve these issues, we\npropose a Snow Mask Guided Adaptive Residual Network (SMGARN). Specifically,\nSMGARN consists of three parts, Mask-Net, Guidance-Fusion Network (GF-Net), and\nReconstruct-Net. Firstly, we build a Mask-Net with Self-pixel Attention (SA)\nand Cross-pixel Attention (CA) to capture the features of snowflakes and\naccurately localized the location of the snow, thus predicting an accurate snow\nmask. Secondly, the predicted snow mask is sent into the specially designed\nGF-Net to adaptively guide the model to remove snow. Finally, an efficient\nReconstruct-Net is used to remove the veiling effect and correct the image to\nreconstruct the final snow-free image. Extensive experiments show that our\nSMGARN numerically outperforms all existing snow removal methods, and the\nreconstructed images are clearer in visual contrast. All codes will be\navailable.",
    "descriptor": "",
    "authors": [
      "Bodong Cheng",
      "Juncheng Li",
      "Ying Chen",
      "Shuyi Zhang",
      "Tieyong Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04754"
  },
  {
    "id": "arXiv:2207.04762",
    "title": "A Late Fusion Framework with Multiple Optimization Methods for Media  Interestingness",
    "abstract": "The recent advancement in Multimedia Analytical, Computer Vision (CV), and\nArtificial Intelligence (AI) algorithms resulted in several interesting tools\nallowing an automatic analysis and retrieval of multimedia content of users'\ninterests. However, retrieving the content of interest generally involves\nanalysis and extraction of semantic features, such as emotions and\ninterestingness-level. The extraction of such meaningful information is a\ncomplex task and generally, the performance of individual algorithms is very\nlow. One way to enhance the performance of the individual algorithms is to\ncombine the predictive capabilities of multiple algorithms using fusion\nschemes. This allows the individual algorithms to complement each other,\nleading to improved performance. This paper proposes several fusion methods for\nthe media interestingness score prediction task introduced in CLEF Fusion 2022.\nThe proposed methods include both a naive fusion scheme, where all the inducers\nare treated equally and a merit-based fusion scheme where multiple weight\noptimization methods are employed to assign weights to the individual inducers.\nIn total, we used six optimization methods including a Particle Swarm\nOptimization (PSO), a Genetic Algorithm (GA), Nelder Mead, Trust Region\nConstrained (TRC), and Limited-memory Broyden Fletcher Goldfarb Shanno\nAlgorithm (LBFGSA), and Truncated Newton Algorithm (TNA). Overall better\nresults are obtained with PSO and TNA achieving 0.109 mean average precision at\n10. The task is complex and generally, scores are low. We believe the presented\nanalysis will provide a baseline for future research in the domain.",
    "descriptor": "\nComments: 10 pages, 1 figure\n",
    "authors": [
      "Maria Shoukat",
      "Khubaib Ahmad",
      "Naina Said",
      "Nasir Ahmad",
      "Mohammed Hassanuzaman",
      "Kashif Ahmad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04762"
  },
  {
    "id": "arXiv:2207.04764",
    "title": "Variational partition-of-unity localizations of space-time dual weighted  residual estimators for parabolic problems",
    "abstract": "In this work, we consider space-time goal-oriented a posteriori error\nestimation for parabolic problems. Temporal and spatial discretizations are\nbased on Galerkin finite elements of continuous and discontinuous type. The\nmain objectives are the development and analysis of space-time estimators, in\nwhich the localization is based on a weak form employing a partition-of-unity.\nThe resulting error indicators are used for temporal and spatial adaptivity.\nOur developments are substantiated with several numerical examples.",
    "descriptor": "",
    "authors": [
      "Jan Philipp Thiele",
      "Thomas Wick"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04764"
  },
  {
    "id": "arXiv:2207.04771",
    "title": "Functional Generalized Empirical Likelihood Estimation for Conditional  Moment Restrictions",
    "abstract": "Important problems in causal inference, economics, and, more generally,\nrobust machine learning can be expressed as conditional moment restrictions,\nbut estimation becomes challenging as it requires solving a continuum of\nunconditional moment restrictions. Previous works addressed this problem by\nextending the generalized method of moments (GMM) to continuum moment\nrestrictions. In contrast, generalized empirical likelihood (GEL) provides a\nmore general framework and has been shown to enjoy favorable small-sample\nproperties compared to GMM-based estimators. To benefit from recent\ndevelopments in machine learning, we provide a functional reformulation of GEL\nin which arbitrary models can be leveraged. Motivated by a dual formulation of\nthe resulting infinite dimensional optimization problem, we devise a practical\nmethod and explore its asymptotic properties. Finally, we provide kernel- and\nneural network-based implementations of the estimator, which achieve\nstate-of-the-art empirical performance on two conditional moment restriction\nproblems.",
    "descriptor": "",
    "authors": [
      "Heiner Kremer",
      "Jia-Jie Zhu",
      "Krikamol Muandet",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.04771"
  },
  {
    "id": "arXiv:2207.04772",
    "title": "Whois? Deep Author Name Disambiguation using Bibliographic Data",
    "abstract": "As the number of authors is increasing exponentially over years, the number\nof authors sharing the same names is increasing proportionally. This makes it\nchallenging to assign newly published papers to their adequate authors.\nTherefore, Author Name Ambiguity (ANA) is considered a critical open problem in\ndigital libraries. This paper proposes an Author Name Disambiguation (AND)\napproach that links author names to their real-world entities by leveraging\ntheir co-authors and domain of research. To this end, we use a collection from\nthe DBLP repository that contains more than 5 million bibliographic records\nauthored by around 2.6 million co-authors. Our approach first groups authors\nwho share the same last names and same first name initials. The author within\neach group is identified by capturing the relation with his/her co-authors and\narea of research, which is represented by the titles of the validated\npublications of the corresponding author. To this end, we train a neural\nnetwork model that learns from the representations of the co-authors and\ntitles. We validated the effectiveness of our approach by conducting extensive\nexperiments on a large dataset.",
    "descriptor": "\nComments: Accepted for publication @ TPDL2022\n",
    "authors": [
      "Zeyd Boukhers",
      "Nagaraj Asundi Bahubali"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04772"
  },
  {
    "id": "arXiv:2207.04774",
    "title": "Simple and Order-optimal Correlated Rounding Schemes for Multi-item  E-commerce Order Fulfillment",
    "abstract": "A fundamental problem faced in e-commerce is -- how can we satisfy a\nmulti-item order using a small number of fulfillment centers (FC's), while also\nrespecting long-term constraints on how frequently each item should be drawing\ninventory from each FC? In a seminal paper, Jasin and Sinha (2015) identify and\nformalize this as a correlated rounding problem, and propose a scheme for\n\\textit{randomly} assigning an FC to each item according to the frequency\nconstraints, so that the assignments are \\textit{positively correlated} and not\nmany FC's end up used. Their scheme pays at most $\\approx q/4$ times the\noptimal cost on a $q$-item order. In this paper we provide to our knowledge the\nfirst substantial improvement of their scheme, which pays only $1+\\ln(q)$ times\nthe optimal cost. We provide another scheme that pays at most $d$ times the\noptimal cost, when each item is stored in at most $d$ FC's. Our schemes are\nfast and based on an intuitive new idea -- items wait for FC's to \"open\" at\nrandom times, but observe them on \"dilated\" time scales. We also provide\nmatching lower bounds of $\\Omega(\\log q)$ and $d$ respectively for our schemes,\nby showing that the correlated rounding problem is a non-trivial generalization\nof Set Cover. Finally, we provide a new LP that solves the correlated rounding\nproblem exactly in time exponential in the number of FC's (but not in $q$).",
    "descriptor": "",
    "authors": [
      "Will Ma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.04774"
  },
  {
    "id": "arXiv:2207.04781",
    "title": "MT-Net Submission to the Waymo 3D Detection Leaderboard",
    "abstract": "In this technical report, we introduce our submission to the Waymo 3D\nDetection leaderboard. Our network is based on the Centerpoint architecture,\nbut with significant improvements. We design a 2D backbone to utilize\nmulti-scale features for better detecting objects with various sizes, together\nwith an optimal transport-based target assignment strategy, which dynamically\nassigns richer supervision signals to the detection candidates. We also apply\ntest-time augmentation and model-ensemble for further improvements. Our\nsubmission currently ranks 4th place with 78.45 mAPH on the Waymo 3D Detection\nleaderboard.",
    "descriptor": "",
    "authors": [
      "Shaoxiang Chen",
      "Zequn Jie",
      "Xiaolin Wei",
      "Lin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04781"
  },
  {
    "id": "arXiv:2207.04782",
    "title": "Exploiting Different Symmetries for Trajectory Tracking Control with  Application to Quadrotors",
    "abstract": "High performance trajectory tracking control of quadrotor vehicles is an\nimportant challenge in aerial robotics. Symmetry is a fundamental property of\nphysical systems and offers the potential to provide a tool to design\nhigh-performance control algorithms. We propose a design methodology that takes\nany given symmetry, linearises the associated error in a single set of\ncoordinates, and uses LQR design to obtain a high performance control; an\napproach we term Equivariant Regulator design. We show that quadrotor vehicles\nadmit several different symmetries: the direct product symmetry, the extended\npose symmetry and the pose and velocity symmetry, and show that each symmetry\ncan be used to define a global error. We compare the linearised systems via\nsimulation and find that the extended pose and pose and velocity symmetries\noutperform the direct product symmetry in the presence of large disturbances.\nThis suggests that choices of equivariant and group affine symmetries have\nimproved linearisation error.",
    "descriptor": "",
    "authors": [
      "Matthew Hampsey",
      "Pieter van Goor",
      "Tarek Hamel",
      "Robert Mahony"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04782"
  },
  {
    "id": "arXiv:2207.04785",
    "title": "SALSA: Attacking Lattice Cryptography with Transformers",
    "abstract": "Currently deployed public-key cryptosystems will be vulnerable to attacks by\nfull-scale quantum computers. Consequently, \"quantum resistant\" cryptosystems\nare in high demand, and lattice-based cryptosystems, based on a hard problem\nknown as Learning With Errors (LWE), have emerged as strong contenders for\nstandardization. In this work, we train transformers to perform modular\narithmetic and combine half-trained models with statistical cryptanalysis\ntechniques to propose SALSA: a machine learning attack on LWE-based\ncryptographic schemes. SALSA can fully recover secrets for small-to-mid size\nLWE instances with sparse binary secrets, and may scale to attack real-world\nLWE-based cryptosystems.",
    "descriptor": "",
    "authors": [
      "Emily Wenger",
      "Mingjie Chen",
      "Fran\u00e7ois Charton",
      "Kristin Lauter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04785"
  },
  {
    "id": "arXiv:2207.04788",
    "title": "DCCF: Deep Comprehensible Color Filter Learning Framework for  High-Resolution Image Harmonization",
    "abstract": "Image color harmonization algorithm aims to automatically match the color\ndistribution of foreground and background images captured in different\nconditions. Previous deep learning based models neglect two issues that are\ncritical for practical applications, namely high resolution (HR) image\nprocessing and model comprehensibility. In this paper, we propose a novel Deep\nComprehensible Color Filter (DCCF) learning framework for high-resolution image\nharmonization. Specifically, DCCF first downsamples the original input image to\nits low-resolution (LR) counter-part, then learns four human comprehensible\nneural filters (i.e. hue, saturation, value and attentive rendering filters) in\nan end-to-end manner, finally applies these filters to the original input image\nto get the harmonized result. Benefiting from the comprehensible neural\nfilters, we could provide a simple yet efficient handler for users to cooperate\nwith deep model to get the desired results with very little effort when\nnecessary. Extensive experiments demonstrate the effectiveness of DCCF learning\nframework and it outperforms state-of-the-art post-processing method on\niHarmony4 dataset on images' full-resolutions by achieving 7.63% and 1.69%\nrelative improvements on MSE and PSNR respectively.",
    "descriptor": "\nComments: Accepted by ECCV 2022 (Oral)\n",
    "authors": [
      "Ben Xue",
      "Shenghui Ran",
      "Quan Chen",
      "Rongfei Jia",
      "Binqiang Zhao",
      "Xing Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04788"
  },
  {
    "id": "arXiv:2207.04789",
    "title": "bloomRF: On Performing Range-Queries in Bloom-Filters with  Piecewise-Monotone Hash Functions and Prefix Hashing",
    "abstract": "We introduce bloomRF as a unified method for approximate membership testing\nthat supports both point- and range-queries. As a first core idea, bloomRF\nintroduces novel prefix hashing to efficiently encode range information in the\nhash-code of the key itself. As a second key concept, bloomRF proposes novel\npiecewise-monotone hash-functions that preserve local order and support fast\nrange-lookups with fewer memory accesses. bloomRF has near-optimal space\ncomplexity and constant query complexity. Although, bloomRF is designed for\ninteger domains, it supports floating-points, and can serve as a\nmulti-attribute filter. The evaluation in RocksDB and in a standalone library\nshows that it is more efficient and outperforms existing point-range-filters by\nup to 4x across a range of settings and distributions, while keeping the\nfalse-positive rate low.",
    "descriptor": "\nComments: Extended version. Original accepted at EDBT 2023\n",
    "authors": [
      "Bernhard M\u00f6\u00dfner",
      "Christian Riegger",
      "Arthur Bernhardt",
      "Ilia Petrov"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.04789"
  },
  {
    "id": "arXiv:2207.04791",
    "title": "Leader-Follower Dynamics in Complex Obstacle Avoidance Task",
    "abstract": "A question that many researchers in social robotics are addressing is how to\ncreate more human-like behaviour in robots to make the collaboration between a\nhuman and a robot more intuitive to the human partner. In order to develop a\nhuman-like collaborative robotic system, however, human collaboration must\nfirst be better understood. Human collaboration is something we are all\nfamiliar with, however not that much is known about it from a kinematic\nstandpoint. One dynamic that hasn't been researched thoroughly, yet naturally\noccurs in human collaboration, is for instance leader-follower dynamics. In our\nprevious study, we tackled the question of leader-follower role allocation in\nhuman dyads during a collaborative reaching task, where the results implied\nthat the subjects who performed higher in the individual experiment would\nnaturally assume the role of a leader when in physical collaboration. In this\nstudy, we build upon the leader-follower role allocation study in human dyads\nby observing how the leader-follower dynamics change when the collaborative\ntask becomes more complex. Here, the study was performed on a reaching task,\nwhere one subject in a dyad was faced with an additional task of obstacle\navoidance when performing a 2D reaching task, while their partner was not aware\nof the obstacle. We have found that subjects change their roles throughout the\ntask in order to complete it successfully, however looking at the overall task\nleader the higher-performing individual will always dominate over the\nlower-performing one, regardless of whether they are aware of the additional\ntask of obstacle avoidance or not.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Rebeka Kropiv\u0161ek Leskovar",
      "Jernej \u010camernik",
      "Tadej Petri\u010d"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04791"
  },
  {
    "id": "arXiv:2207.04792",
    "title": "Increased Complexity of a Human-Robot Collaborative Task May Increase  the Need for a Socially Competent Robot",
    "abstract": "An important factor in developing control models for human-robot\ncollaboration is how acceptable they are to their human partners. One such\nmethod for creating acceptable control models is to attempt to mimic human-like\nbehaviour in robots so that their actions appear more intuitive to humans. To\ninvestigate how task complexity affects human perception and acceptance of\ntheir robot partner, we propose a novel human-based robot control model for\nobstacle avoidance that can account for the leader-follower dynamics that\nnormally occur in human collaboration. The performance and acceptance of the\nproposed control method were evaluated using an obstacle avoidance scenario in\nwhich we compared task performance between individual tasks and collaborative\ntasks with different leader-follower dynamics roles for the robotic partner.\nThe evaluation results showed that the robot control method is able to\nreplicate human behaviour to improve the overall task performance of the\nsubject in collaboration. However, regarding the acceptance of the robotic\npartner, the participants' opinions were mixed. Compared to the results of a\nstudy with a similar control method developed for a less complex task, the new\nresults show a lower acceptance of the proposed control model, even though the\ncontrol method was adapted to the more complex task from a dynamic standpoint.\nThis suggests that the complexity of the collaborative task at hand increases\nthe need not only for a more complex control model but also a more socially\ncompetent control model.",
    "descriptor": "\nComments: 10 pages, 4 figures, accepted and published in the IEEE Advanced Robotics and its Social Impacts 2022 conference proceedings\n",
    "authors": [
      "Rebeka Kropiv\u0161ek Leskovar",
      "Tadej Petri\u010d"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.04792"
  },
  {
    "id": "arXiv:2207.04793",
    "title": "PCCT: Progressive Class-Center Triplet Loss for Imbalanced Medical Image  Classification",
    "abstract": "Imbalanced training data is a significant challenge for medical image\nclassification. In this study, we propose a novel Progressive Class-Center\nTriplet (PCCT) framework to alleviate the class imbalance issue particularly\nfor diagnosis of rare diseases, mainly by carefully designing the triplet\nsampling strategy and the triplet loss formation. Specifically, the PCCT\nframework includes two successive stages. In the first stage, PCCT trains the\ndiagnosis system via a class-balanced triplet loss to coarsely separate\ndistributions of different classes. In the second stage, the PCCT framework\nfurther improves the diagnosis system via a class-center involved triplet loss\nto cause a more compact distribution for each class. For the class-balanced\ntriplet loss, triplets are sampled equally for each class at each training\niteration, thus alleviating the imbalanced data issue. For the class-center\ninvolved triplet loss, the positive and negative samples in each triplet are\nreplaced by their corresponding class centers, which enforces data\nrepresentations of the same class closer to the class center. Furthermore, the\nclass-center involved triplet loss is extended to the pair-wise ranking loss\nand the quadruplet loss, which demonstrates the generalization of the proposed\nframework. Extensive experiments support that the PCCT framework works\neffectively for medical image classification with imbalanced training images.\nOn two skin image datasets and one chest X-ray dataset, the proposed approach\nrespectively obtains the mean F1 score 86.2, 65.2, and 90.66 over all classes\nand 81.4, 63.87, and 81.92 for rare classes, achieving state-of-the-art\nperformance and outperforming the widely used methods for the class imbalance\nissue.",
    "descriptor": "",
    "authors": [
      "Kanghao Chen",
      "Weixian Lei",
      "Rong Zhang",
      "Shen Zhao",
      "Wei-shi Zheng",
      "Ruixuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04793"
  },
  {
    "id": "arXiv:2207.04796",
    "title": "TArC: Tunisian Arabish Corpus First complete release",
    "abstract": "In this paper we present the final result of a project on Tunisian Arabic\nencoded in Arabizi, the Latin-based writing system for digital conversations.\nThe project led to the creation of two integrated and independent resources: a\ncorpus and a NLP tool created to annotate the former with various levels of\nlinguistic information: word classification, transliteration, tokenization,\nPOS-tagging, lemmatization. We discuss our choices in terms of computational\nand linguistic methodology and the strategies adopted to improve our results.\nWe report on the experiments performed in order to outline our research path.\nFinally, we explain why we believe in the potential of these resources for both\ncomputational and linguistic researches. Keywords: Tunisian Arabizi, Annotated\nCorpus, Neural Network Architecture",
    "descriptor": "\nComments: In Proceedings of the Language Resources and Evaluation Conference (LREC2022), Marseille. European Language Resources Association (pp. 1125-1136)\n",
    "authors": [
      "Elisa Gugliotta",
      "Marco Dinarelli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04796"
  },
  {
    "id": "arXiv:2207.04797",
    "title": "Decentralized Load Management in HAN: An IoT-Assisted Approach",
    "abstract": "A Home Area Network (HAN) is considered to be a significant component of\nAdvanced Metering Infrastructure (AMI) and has been studied well in many works.\nIt binds all the electrical components installed in a defined premise together\nfor their close monitoring and management. However, HAN has been realized so\nfar mostly as a centralized system. Therefore, like any other centralized\nsystem, the traditional realization of HAN also suffers from various well-known\nproblems, such as single-point-of-failure, susceptibility to attacks,\nrequirement of specialized infrastructure, inflexibility to easy expansion,\netc. To address these issues, in this work, we propose a decentralized design\nof HAN. In particular, we propose an IoT based design where instead of a\ncentral controller, the overall system operation is controlled and managed\nthrough decentralized coordination among the the electrical appliances. We\nleverage Synchronous-Transmission (ST) based data-sharing protocols in IoT to\naccomplish our goal. To demonstrate the efficacy of the proposed decentralized\nframework, we also design a real-time intra-HAN load-management strategy and\nimplement it in real IoT-devices. Evaluation of the same over emulation\nplatforms and IoT testbeds show upto 62% reduction of peak load over a wide\nvariety of load profiles.",
    "descriptor": "",
    "authors": [
      "Jagnyashini Debadarshini",
      "Sudipta Saha",
      "Subhransu Ranjan Samantaray"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.04797"
  },
  {
    "id": "arXiv:2207.04802",
    "title": "PromptEM: Prompt-tuning for Low-resource Generalized Entity Matching",
    "abstract": "Entity Matching (EM), which aims to identify whether two entity records from\ntwo relational tables refer to the same real-world entity, is one of the\nfundamental problems in data management. Traditional EM assumes that two tables\nare homogeneous with the aligned schema, while it is common that entity records\nof different formats (e.g., relational, semi-structured, or textual types)\ninvolve in practical scenarios. It is not practical to unify their schemas due\nto the different formats. To support EM on format-different entity records,\nGeneralized Entity Matching (GEM) has been proposed and gained much attention\nrecently. To do GEM, existing methods typically perform in a supervised\nlearning way, which relies on a large amount of high-quality labeled examples.\nHowever, the labeling process is extremely labor-intensive, and frustrates the\nuse of GEM. Low-resource GEM, i.e., GEM that only requires a small number of\nlabeled examples, becomes an urgent need. To this end, this paper, for the\nfirst time, focuses on the low-resource GEM and proposes a novel low-resource\nGEM method, termed as PromptEM. PromptEM has addressed three challenging issues\n(i.e., designing GEM-specific prompt-tuning, improving pseudo-labels quality,\nand running efficient self-training) in low-resource GEM. Extensive\nexperimental results on eight real benchmarks demonstrate the superiority of\nPromptEM in terms of effectiveness and efficiency.",
    "descriptor": "",
    "authors": [
      "Pengfei Wang",
      "Xiaocan Zeng",
      "Lu Chen",
      "Fan Ye",
      "Yuren Mao",
      "Junhao Zhu",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.04802"
  },
  {
    "id": "arXiv:2207.04806",
    "title": "Repairing Neural Networks by Leaving the Right Past Behind",
    "abstract": "Prediction failures of machine learning models often arise from deficiencies\nin training data, such as incorrect labels, outliers, and selection biases.\nHowever, such data points that are responsible for a given failure mode are\ngenerally not known a priori, let alone a mechanism for repairing the failure.\nThis work draws on the Bayesian view of continual learning, and develops a\ngeneric framework for both, identifying training examples that have given rise\nto the target failure, and fixing the model through erasing information about\nthem. This framework naturally allows leveraging recent advances in continual\nlearning to this new problem of model repairment, while subsuming the existing\nworks on influence functions and data deletion as specific instances.\nExperimentally, the proposed approach outperforms the baselines for both\nidentification of detrimental training data and fixing model failures in a\ngeneralisable manner.",
    "descriptor": "\nComments: 19 pages, 9 figures\n",
    "authors": [
      "Ryutaro Tanno",
      "Melanie F. Pradier",
      "Aditya Nori",
      "Yingzhen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04806"
  },
  {
    "id": "arXiv:2207.04808",
    "title": "CCPL: Contrastive Coherence Preserving Loss for Versatile Style Transfer",
    "abstract": "In this paper, we aim to devise a universally versatile style transfer method\ncapable of performing artistic, photo-realistic, and video style transfer\njointly, without seeing videos during training. Previous single-frame methods\nassume a strong constraint on the whole image to maintain temporal consistency,\nwhich could be violated in many cases. Instead, we make a mild and reasonable\nassumption that global inconsistency is dominated by local inconsistencies and\ndevise a generic Contrastive Coherence Preserving Loss (CCPL) applied to local\npatches. CCPL can preserve the coherence of the content source during style\ntransfer without degrading stylization. Moreover, it owns a neighbor-regulating\nmechanism, resulting in a vast reduction of local distortions and considerable\nvisual quality improvement. Aside from its superior performance on versatile\nstyle transfer, it can be easily extended to other tasks, such as\nimage-to-image translation. Besides, to better fuse content and style features,\nwe propose Simple Covariance Transformation (SCT) to effectively align\nsecond-order statistics of the content feature with the style feature.\nExperiments demonstrate the effectiveness of the resulting model for versatile\nstyle transfer, when armed with CCPL.",
    "descriptor": "\nComments: Accepted by ECCV2022 as an oral paper\n",
    "authors": [
      "Zijie Wu",
      "Zhen Zhu",
      "Junping Du",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04808"
  },
  {
    "id": "arXiv:2207.04809",
    "title": "Fingerprint Liveness Detection Based on Quality Measures",
    "abstract": "A new fingerprint parameterization for liveness detection based on quality\nmeasures is presented. The novel feature set is used in a complete liveness\ndetection system and tested on the development set of the LivDET competition,\ncomprising over 4,500 real and fake images acquired with three different\noptical sensors. The proposed solution proves to be robust to the multi-sensor\nscenario, and presents an overall rate of 93% of correctly classified samples.\nFurthermore, the liveness detection method presented has the added advantage\nover previously studied techniques of needing just one image from a finger to\ndecide whether it is real or fake.",
    "descriptor": "\nComments: Published at IEEE International Conference on Biometrics, Identity and Security (BIdS). arXiv admin note: substantial text overlap with arXiv:2111.01898\n",
    "authors": [
      "Javier Galbally",
      "Fernando Alonso-Fernandez",
      "Julian Fierrez",
      "Javier Ortega-Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.04809"
  },
  {
    "id": "arXiv:2207.04812",
    "title": "A clinically motivated self-supervised approach for content-based image  retrieval of CT liver images",
    "abstract": "Deep learning-based approaches for content-based image retrieval (CBIR) of CT\nliver images is an active field of research, but suffers from some critical\nlimitations. First, they are heavily reliant on labeled data, which can be\nchallenging and costly to acquire. Second, they lack transparency and\nexplainability, which limits the trustworthiness of deep CBIR systems. We\naddress these limitations by (1) proposing a self-supervised learning framework\nthat incorporates domain-knowledge into the training procedure and (2)\nproviding the first representation learning explainability analysis in the\ncontext of CBIR of CT liver images. Results demonstrate improved performance\ncompared to the standard self-supervised approach across several metrics, as\nwell as improved generalisation across datasets. Further, we conduct the first\nrepresentation learning explainability analysis in the context of CBIR, which\nreveals new insights into the feature extraction process. Lastly, we perform a\ncase study with cross-examination CBIR that demonstrates the usability of our\nproposed framework. We believe that our proposed framework could play a vital\nrole in creating trustworthy deep CBIR systems that can successfully take\nadvantage of unlabeled data.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Kristoffer Knutsen Wickstr\u00f8m",
      "Eirik Agnalt \u00d8stmo",
      "Keyur Radiya",
      "Karl \u00d8yvind Mikalsen",
      "Michael Christian Kampffmeyer",
      "Robert Jenssen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.04812"
  },
  {
    "id": "arXiv:2207.04813",
    "title": "On the vulnerability of fingerprint verification systems to fake  fingerprint attacks",
    "abstract": "A new method to generate gummy fingers is presented. A medium-size fake\nfingerprint database is described and two different fingerprint verification\nsystems are evaluated on it. Three different scenarios are considered in the\nexperiments, namely: enrollment and test with real fingerprints, enrollment and\ntest with fake fingerprints, and enrollment with real fingerprints and test\nwith fake fingerprints. Results for an optical and a thermal sweeping sensors\nare given. Both systems are shown to be vulnerable to direct attacks.",
    "descriptor": "\nComments: Published at IEEE International Carnahan Conference on Security Technology (ICCST)\n",
    "authors": [
      "Javier Galbally",
      "Julian Fierrez-Aguilar",
      "Joaquin Rodriguez-Gonzalez",
      "Fernando Alonso-Fernandez",
      "Javier Ortega-Garcia",
      "Marino Tapiador"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.04813"
  },
  {
    "id": "arXiv:2207.04814",
    "title": "High-Order Coupled Fully-Connected Tensor Network Decomposition for  Hyperspectral Image Super-Resolution",
    "abstract": "Hyperspectral image super-resolution addresses the problem of fusing a\nlow-resolution hyperspectral image (LR-HSI) and a high-resolution multispectral\nimage (HR-MSI) to produce a high-resolution hyperspectral image (HR-HSI).\nTensor analysis has been proven to be an efficient method for hyperspectral\nimage processing. However, the existing tensor-based methods of hyperspectral\nimage super-resolution like the tensor train and tensor ring decomposition only\nestablish an operation between adjacent two factors and are highly sensitive to\nthe permutation of tensor modes, leading to an inadequate and inflexible\nrepresentation. In this paper, we propose a novel method for hyperspectral\nimage super-resolution by utilizing the specific properties of high-order\ntensors in fully-connected tensor network decomposition. The proposed method\nfirst tensorizes the target HR-HSI into a high-order tensor that has multiscale\nspatial structures. Then, a coupled fully-connected tensor network\ndecomposition model is proposed to fuse the corresponding high-order tensors of\nLR-HSI and HR-MSI. Moreover, a weighted-graph regularization is imposed on the\nspectral core tensors to preserve spectral information. In the proposed model,\nthe superiorities of the fully-connected tensor network decomposition lie in\nthe outstanding capability for characterizing adequately the intrinsic\ncorrelations between any two modes of tensors and the essential invariance for\ntransposition. Experimental results on three data sets show the effectiveness\nof the proposed approach as compared to other hyperspectral image\nsuper-resolution methods.",
    "descriptor": "",
    "authors": [
      "Diyi Jin",
      "Jianjun Liu",
      "Jinlong Yang",
      "Zebin Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04814"
  },
  {
    "id": "arXiv:2207.04815",
    "title": "Improved Soft-aided Decoding of Product Codes with Adaptive  Performance-Complexity Trade-off",
    "abstract": "We propose an improved soft-aided decoding scheme for product codes that\napproaches the decoding performance of conventional soft-decision TPD with only\na 0.2 dB gap while keeping the complexity and internal decoder data flow\nsimilarly low as in hard decision decoders.",
    "descriptor": "\nComments: European Conference on Optical Communication (ECOC) 2022\n",
    "authors": [
      "Sisi Miao",
      "Lukas Rapp",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04815"
  },
  {
    "id": "arXiv:2207.04818",
    "title": "Cross-modal Prototype Driven Network for Radiology Report Generation",
    "abstract": "Radiology report generation (RRG) aims to describe automatically a radiology\nimage with human-like language and could potentially support the work of\nradiologists, reducing the burden of manual reporting. Previous approaches\noften adopt an encoder-decoder architecture and focus on single-modal feature\nlearning, while few studies explore cross-modal feature interaction. Here we\npropose a Cross-modal PROtotype driven NETwork (XPRONET) to promote cross-modal\npattern learning and exploit it to improve the task of radiology report\ngeneration. This is achieved by three well-designed, fully differentiable and\ncomplementary modules: a shared cross-modal prototype matrix to record the\ncross-modal prototypes; a cross-modal prototype network to learn the\ncross-modal prototypes and embed the cross-modal information into the visual\nand textual features; and an improved multi-label contrastive loss to enable\nand enhance multi-label prototype learning. XPRONET obtains substantial\nimprovements on the IU-Xray and MIMIC-CXR benchmarks, where its performance\nexceeds recent state-of-the-art approaches by a large margin on IU-Xray and\ncomparable performance on MIMIC-CXR.",
    "descriptor": "\nComments: Accepted to ECCV2022\n",
    "authors": [
      "Jun Wang",
      "Abhir Bhalerao",
      "Yulan He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04818"
  },
  {
    "id": "arXiv:2207.04820",
    "title": "Assessing Ranking and Effectiveness of Evolutionary Algorithm  Hyperparameters Using Global Sensitivity Analysis Methodologies",
    "abstract": "We present a comprehensive global sensitivity analysis of two\nsingle-objective and two multi-objective state-of-the-art global optimization\nevolutionary algorithms as an algorithm configuration problem. That is, we\ninvestigate the quality of influence hyperparameters have on the performance of\nalgorithms in terms of their direct effect and interaction effect with other\nhyperparameters. Using three sensitivity analysis methods, Morris LHS, Morris,\nand Sobol, to systematically analyze tunable hyperparameters of covariance\nmatrix adaptation evolutionary strategy, differential evolution, non-dominated\nsorting genetic algorithm III, and multi-objective evolutionary algorithm based\non decomposition, the framework reveals the behaviors of hyperparameters to\nsampling methods and performance metrics. That is, it answers questions like\nwhat hyperparameters influence patterns, how they interact, how much they\ninteract, and how much their direct influence is. Consequently, the ranking of\nhyperparameters suggests their order of tuning, and the pattern of influence\nreveals the stability of the algorithms.",
    "descriptor": "",
    "authors": [
      "Varun Ojha",
      "Jon Timmis",
      "Giuseppe Nicosia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04820"
  },
  {
    "id": "arXiv:2207.04821",
    "title": "Long-term Reproducibility for Neural Architecture Search",
    "abstract": "It is a sad reflection of modern academia that code is often ignored after\npublication -- there is no academic 'kudos' for bug fixes / maintenance. Code\nis often unavailable or, if available, contains bugs, is incomplete, or relies\non out-of-date / unavailable libraries. This has a significant impact on\nreproducibility and general scientific progress. Neural Architecture Search\n(NAS) is no exception to this, with some prior work in reproducibility.\nHowever, we argue that these do not consider long-term reproducibility issues.\nWe therefore propose a checklist for long-term NAS reproducibility. We evaluate\nour checklist against common NAS approaches along with proposing how we can\nretrospectively make these approaches more long-term reproducible.",
    "descriptor": "",
    "authors": [
      "David Towers",
      "Matthew Forshaw",
      "Amir Atapour-Abarghouei",
      "Andrew Stephen McGough"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04821"
  },
  {
    "id": "arXiv:2207.04823",
    "title": "Adaptive Behavioral Model Learning for Software Product Lines",
    "abstract": "Behavioral models enable the analysis of the functionality of software\nproduct lines (SPL), e.g., model checking and model-based testing. Model\nlearning aims at constructing behavioral models for software systems in some\nform of a finite state machine. Due to the commonalities among the products of\nan SPL, it is possible to reuse the previously learned models during the model\nlearning process. In this paper, an adaptive approach (the $\\text{PL}^*$\nmethod) for learning the product models of an SPL is presented based on the\nwell-known $L^*$ algorithm. In this method, after model learning of each\nproduct, the sequences in the final observation table are stored in a\nrepository which will be used to initialize the observation table of the\nremaining products to be learned. The proposed algorithm is evaluated on two\nopen-source SPLs and the total learning cost is measured in terms of the number\nof rounds, the total number of resets and input symbols. The results show that\nfor complex SPLs, the total learning cost for the $\\text{PL}^*$ method is\nsignificantly lower than that of the non-adaptive learning method in terms of\nall three metrics. Furthermore, it is observed that the order in which the\nproducts are learned affects the efficiency of the $\\text{PL}^*$ method. Based\non this observation, we introduced a heuristic to determine an ordering which\nreduces the total cost of adaptive learning in both case studies.",
    "descriptor": "\nComments: 12 pages, 10 figures, Paper accepted in the Research Track of the 26th ACM International Systems and Software Product Line Conference (SPLC 2022)\n",
    "authors": [
      "Shaghayegh Tavassoli",
      "Carlos Diego Nascimento Damasceno",
      "Ramtin Khosravi",
      "Mohammad Reza Mousavi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.04823"
  },
  {
    "id": "arXiv:2207.04827",
    "title": "Multiple-Modality Associative Memory: a framework for Learning",
    "abstract": "Drawing from memory the face of a friend you have not seen in years is a\ndifficult task. However, if you happen to cross paths, you would easily\nrecognize each other. The biological memory is equipped with an impressive\ncompression algorithm that can store the essential, and then infer the details\nto match perception. Willshaw's model of Associative memory is a likely\ncandidate for a computational model of this brain function, but its application\non real-world data is hindered by the so-called Sparse Coding Problem. Due to a\nrecently proposed sparse encoding prescription [31], which maps visual patterns\ninto binary feature maps, we were able to analyze the behavior of the Willshaw\nNetwork (WN) on real-world data and gain key insights into the strengths of the\nmodel. To further enhance the capabilities of the WN, we propose the\nMultiple-Modality architecture. In this new setting, the memory stores several\nmodalities (e.g., visual, or textual) simultaneously. After training, the model\ncan be used to infer missing modalities when just a subset is perceived, thus\nserving as a flexible framework for learning tasks. We evaluated the model on\nthe MNIST dataset. By storing both the images and labels as modalities, we were\nable to successfully perform pattern completion, classification, and generation\nwith a single model.",
    "descriptor": "\nComments: 21 pages, 15 figures\n",
    "authors": [
      "Rodrigo Simas",
      "Luis Sa-Couto",
      "Andreas Whichert"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04827"
  },
  {
    "id": "arXiv:2207.04829",
    "title": "Low-complexity Joint Phase Adjustment and Receive Beamforming for  Directional Modulation Networks via IRS",
    "abstract": "Intelligent reflecting surface (IRS) is a revolutionary and low-cost\ntechnology for boosting the spectrum and energy efficiencies in future wireless\ncommunication network. In order to create controllable multipath transmission\nin the conventional line-of-sight (LOS) wireless communication environment, an\nIRS-aided directional modulation (DM) network is considered. In this paper, to\nimprove the transmission security of the system and maximize the receive power\nsum (Max-RPS), two alternately optimizing schemes of jointly designing receive\nbeamforming (RBF) vectors and IRS phase shift matrix (PSM) are proposed:\nMax-RPS using general alternating optimization (Max-RPS-GAO) algorithm and\nMax-RPS using zero-forcing (Max-RPS-ZF) algorithm. Simulation results show\nthat, compared with the no-IRS-assisted scheme and the no-PSM optimization\nscheme, the proposed IRS-assisted Max-RPS-GAO method and Max-RPS-ZF method can\nsignificantly improve the secrecy rate (SR) performance of the DM system.\nMoreover, compared with the Max-RPS-GAO method, the proposed Max-RPS-ZF method\nhas a faster convergence speed and a certain lower computational complexity.",
    "descriptor": "",
    "authors": [
      "Rongen Dong",
      "Shaohua Jiang",
      "Xinhai Hua",
      "Yin Teng",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.04829"
  },
  {
    "id": "arXiv:2207.04834",
    "title": "Speaker Anonymization with Phonetic Intermediate Representations",
    "abstract": "In this work, we propose a speaker anonymization pipeline that leverages high\nquality automatic speech recognition and synthesis systems to generate speech\nconditioned on phonetic transcriptions and anonymized speaker embeddings. Using\nphones as the intermediate representation ensures near complete elimination of\nspeaker identity information from the input while preserving the original\nphonetic content as much as possible. Our experimental results on LibriSpeech\nand VCTK corpora reveal two key findings: 1) although automatic speech\nrecognition produces imperfect transcriptions, our neural speech synthesis\nsystem can handle such errors, making our system feasible and robust, and 2)\ncombining speaker embeddings from different resources is beneficial and their\nappropriate normalization is crucial. Overall, our final best system\noutperforms significantly the baselines provided in the Voice Privacy Challenge\n2020 in terms of privacy robustness against a lazy-informed attacker while\nmaintaining high intelligibility and naturalness of the anonymized speech.",
    "descriptor": "\nComments: Accepted at Interspeech 2022\n",
    "authors": [
      "Sarina Meyer",
      "Florian Lux",
      "Pavel Denisov",
      "Julia Koch",
      "Pascal Tilli",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04834"
  },
  {
    "id": "arXiv:2207.04837",
    "title": "RRMSE Voting Regressor: A weighting function based improvement to  ensemble regression",
    "abstract": "This paper describes the RRMSE (Relative Root Mean Square Error) based\nweights to weight the occurrences of predictive values before averaging for the\nensemble voting regression. The core idea behind ensemble regression is to\ncombine several base regression models in order to improve the prediction\nperformance in learning problems with a numeric continuous target variable. The\ndefault weights setting for the ensemble voting regression is uniform weights,\nand without domain knowledge of learning task, assigning weights for\npredictions are impossible, which makes it very difficult to improve the\npredictions. This work attempts to improve the prediction of voting regression\nby implementing the RRMSE based weighting function. Experiments show that RRMSE\nvoting regressor produces significantly better predictions than other\nstate-of-the-art ensemble regression algorithms on six popular regression\nlearning datasets.",
    "descriptor": "",
    "authors": [
      "Shikun Chen",
      "Nguyen Manh Luc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04837"
  },
  {
    "id": "arXiv:2207.04839",
    "title": "Ternary and Quaternary CNTFET Full Adders are less efficient than the  Binary Ones for Carry-Propagate Adders",
    "abstract": "In Carry Propagate Adders, carry propagation is the critical delay. The most\nefficient scheme is to generate Cout0 (Cin=0) and Cout1(Cin=1) and multiplex\nthe correct output according to Cin. For any radix, the carry output is always\n0/1. We present two versions of ternary adders with Cin = (0V, Vdd/2) and Cin =\n(0V, Vdd) and two versions of quaternary adders with Cin = (0V, Vdd/3) and Cin\n= (0V, Vdd). Using full swing Vdd for Cin reduces the propagation delays for\nternary and quaternary adders. 6-bit, 4-trit and 3-quit CPAs are then compared.",
    "descriptor": "\nComments: 13 pages, 39 figures. arXiv admin note: text overlap with arXiv:2207.01401\n",
    "authors": [
      "Daniel Etiemble"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2207.04839"
  },
  {
    "id": "arXiv:2207.04841",
    "title": "TIPS: Transaction Inclusion Protocol with Signaling in DAG-based  Blockchain",
    "abstract": "Directed Acyclic Graph (DAG) is a popular approach to achieve scalability of\nblockchain networks. Due to its high efficiency in data communication and great\nscalability, DAG has been widely adopted in many applications such as Internet\nof Things (IoT) and Decentralized Finance (DeFi). DAG-based blockchain,\nnevertheless, faces the key challenge of transaction inclusion collision due to\nthe high concurrency and the network delay. Particularly, the transaction\ninclusion collision in DAG-based blockchain leads to the revenue and throughput\ndilemmas, which would greatly degrade the system performance. In this paper, we\npropose \"TIPS\", the Transaction Inclusion Protocol with Signaling, which\nbroadcasts a signal indicating the transactions in the block. We show that with\nthe prompt broadcast of a signal, TIPS substantially reduces the transaction\ncollision and thus resolves these dilemmas. Moreover, we show that TIPS can\ndefend against both the denial-of-service and the delay-of-service attacks. We\nalso conduct intensive experiments to demonstrate the superior performance of\nthe proposed protocol.",
    "descriptor": "",
    "authors": [
      "Canhui Chen",
      "Xu Chen",
      "Zhixuan Fang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Science and Game Theory (cs.GT)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2207.04841"
  },
  {
    "id": "arXiv:2207.04843",
    "title": "Statistical Detection of Adversarial examples in Blockchain-based  Federated Forest In-vehicle Network Intrusion Detection Systems",
    "abstract": "The internet-of-Vehicle (IoV) can facilitate seamless connectivity between\nconnected vehicles (CV), autonomous vehicles (AV), and other IoV entities.\nIntrusion Detection Systems (IDSs) for IoV networks can rely on machine\nlearning (ML) to protect the in-vehicle network from cyber-attacks.\nBlockchain-based Federated Forests (BFFs) could be used to train ML models\nbased on data from IoV entities while protecting the confidentiality of the\ndata and reducing the risks of tampering with the data. However, ML models\ncreated this way are still vulnerable to evasion, poisoning, and exploratory\nattacks using adversarial examples. This paper investigates the impact of\nvarious possible adversarial examples on the BFF-IDS. We proposed integrating a\nstatistical detector to detect and extract unknown adversarial samples. By\nincluding the unknown detected samples into the dataset of the detector, we\naugment the BFF-IDS with an additional model to detect original known attacks\nand the new adversarial inputs. The statistical adversarial detector\nconfidently detected adversarial examples at the sample size of 50 and 100\ninput samples. Furthermore, the augmented BFF-IDS (BFF-IDS(AUG)) successfully\nmitigates the adversarial examples with more than 96% accuracy. With this\napproach, the model will continue to be augmented in a sandbox whenever an\nadversarial sample is detected and subsequently adopt the BFF-IDS(AUG) as the\nactive security model. Consequently, the proposed integration of the\nstatistical adversarial detector and the subsequent augmentation of the BFF-IDS\nwith detected adversarial samples provides a sustainable security framework\nagainst adversarial examples and other unknown attacks.",
    "descriptor": "",
    "authors": [
      "Ibrahim Aliyu",
      "Selinde van Engelenburg",
      "Muhammed Bashir Muazu",
      "Jinsul Kim",
      "Chang Gyoon Lim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04843"
  },
  {
    "id": "arXiv:2207.04845",
    "title": "An optimal MOO strategy",
    "abstract": "We calculated a fixed strategy that minimizes the average number of guesses\n(minimum strategy) for the number-guessing game MOO by exhaustive search.\nAlthough the minimum strategy for a similar game, mastermind, has been\nreported, this study seems to be the first to find the minimum strategy for MOO\nwith a larger search space. When two players play against each other in MOO,\nthe minimum strategy is not always the strongest fixed strategy. First, we\ncompute a fixed strategy that has the maximum winning rate when played against\nthe minimum strategy. Then we confirm that there is no fixed strategy with a\nwinning rate exceeding 0.5 against this strategy. This result shows that MOO is\na game with the strongest fixed strategy.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Tetsuro Tanaka"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.04845"
  },
  {
    "id": "arXiv:2207.04846",
    "title": "Fitness Dependent Optimizer for IoT Healthcare using Adapted Parameters:  A Case Study Implementation",
    "abstract": "This discusses a case study on Fitness Dependent Optimizer or so-called FDO\nand adapting its parameters to the Internet of Things (IoT) healthcare. The\nreproductive way is sparked by the bee swarm and the collaborative\ndecision-making of FDO. As opposed to the honey bee or artificial bee colony\nalgorithms, this algorithm has no connection to them. In FDO, the search\nagent's position is updated using speed or velocity, but it's done differently.\nIt creates weights based on the fitness function value of the problem, which\nassists lead the agents through the exploration and exploitation processes.\nOther algorithms are evaluated and compared to FDO as Genetic Algorithm (GA)\nand Particle Swarm Optimization (PSO) in the original work. The key current\nalgorithms:The Salp-Swarm Algorithms (SSA), Dragonfly Algorithm (DA), and Whale\nOptimization Algorithm (WOA) have been evaluated against FDO in terms of their\nresults. Using these FDO experimental findings, we may conclude that FDO\noutperforms the other techniques stated. There are two primary goals for this\nchapter: first, the implementation of FDO will be shown step-by-step so that\nreaders can better comprehend the algorithm method and apply FDO to solve\nreal-world applications quickly. The second issue deals with how to tweak the\nFDO settings to make the meta-heuristic evolutionary algorithm better in the\nIoT health service system at evaluating big quantities of information.\nUltimately, the target of this chapter's enhancement is to adapt the IoT\nhealthcare framework based on FDO to spawn effective IoT healthcare\napplications for reasoning out real-world optimization, aggregation,\nprediction, segmentation, and other technological problems.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Aso M. Aladdin",
      "Jaza M. Abdullah",
      "Kazhan Othman Mohammed Salih",
      "Tarik A. Rashid",
      "Rafid Sagban",
      "Abeer Alsaddon",
      "Nebojsa Bacanin",
      "Amit Chhabra",
      "S.Vimal",
      "Indradip Banerjee"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.04846"
  },
  {
    "id": "arXiv:2207.04847",
    "title": "Experimental End-To-End Delay Analysis of LTE cat-M With High-Rate  Synchrophasor Communications",
    "abstract": "Micro-Phasor Measurement Units (u-PMUs) are devices that permit monitoring\nvoltage and current in the distribution grid with high accuracy, thus enabling\na wide range of smart grid applications, such as state estimation, protection\nand control. These devices need to transmit the synchronous measurements of\nvoltage and current, also known as synchrophasors, to the power utility control\ncenter at high rate. The use of wireless networks, such as LTE, to transmit\nsynchrophasor data is becoming increasingly popular. However, synchrophasors\nare included in small frames and it would be more efficient to use low power\ncellular solutions, such as LTE cat-M. In this work, we present experimental\nresearch on the deployment of a u-PMU with the ability to connect over a\ncommercial LTE cat-M network. The deployed u-PMU is built with off-the-shelf\nhardware, such as Arduino microcontrollers, and is used to transmit\ndata-compliant with the IEEE C37.118.2 standard at a variable rate from 1\nframe/s to 80 frames/s. A detailed network performance analysis is carried out\nto show the suitability of LTE cat-M to support u-PMU communications.\nExperimental results on performance indicators, such as delay and jitter, are\nreported. The effect of the LTE cat-M access mechanism on the time distribution\nof frame arrivals is also thoroughly analyzed.",
    "descriptor": "",
    "authors": [
      "Sureel Shah",
      "Sayan Koley",
      "Filippo Malandra"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.04847"
  },
  {
    "id": "arXiv:2207.04848",
    "title": "On the Application of Agile Project Management Techniques, V-Model and  Recent Software Tools in Postgraduate Theses Supervision",
    "abstract": "Due to the nature of most postgraduate theses in control engineering and\ntheir similarities to industrial and software engineering projects, invoking\nnovel project control techniques could be effective. In recent decades, agile\ntechniques have attracted popularity thanks to their attributes in delivering\nsuccessful projects. Hence exploiting those methods in education and thesis\nsupervision of engineering topics can facilitate the process. On the other\nhand, because of the limitations imposed by the CoVid19 pandemic, the\nintegration of well-established online tools in collaborative education is\nnoteworthy. This paper proposes an application of the agile project management\nmethod for the supervision of postgraduate students' theses in the general\nfield of engineering. The study extends a Scrum technique combined with\napproved systems engineering and team working tools such as Jira Software,\nMicrosoft Teams, and Git version control (Github website). A custom designed\nV-model to nail an outstanding thesis is presented. The overall blended method\nis beneficial to provide feedback and self-assessment aid for the students and\nthe supervisors. Employing this technique has shown promising progress in\neasing the supervision of students whilst helping them to manage their\nprojects.",
    "descriptor": "",
    "authors": [
      "Pouria Sarhadi",
      "Wasif Naeem",
      "Karen Fraser",
      "David Wilson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04848"
  },
  {
    "id": "arXiv:2207.04857",
    "title": "Emergence of Novelty in Evolutionary Algorithms",
    "abstract": "One of the main problems of evolutionary algorithms is the convergence of the\npopulation to local minima. In this paper, we explore techniques that can avoid\nthis problem by encouraging a diverse behavior of the agents through a shared\nreward system. The rewards are randomly distributed in the environment, and the\nagents are only rewarded for collecting them first. This leads to an emergence\nof a novel behavior of the agents. We introduce our approach to the maze\nproblem and compare it to the previously proposed solution, denoted as Novelty\nSearch (Lehman and Stanley, 2011a). We find that our solution leads to an\nimproved performance while being significantly simpler. Building on that, we\ngeneralize the problem and apply our approach to a more advanced set of tasks,\nAtari Games, where we observe a similar performance quality with much less\ncomputational power needed.",
    "descriptor": "\nComments: ALIFE 2022, 8 pages\n",
    "authors": [
      "David Herel",
      "Dominika Zogatova",
      "Matej Kripner",
      "Tomas Mikolov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04857"
  },
  {
    "id": "arXiv:2207.04858",
    "title": "LaT: Latent Translation with Cycle-Consistency for Video-Text Retrieval",
    "abstract": "Video-text retrieval is a class of cross-modal representation learning\nproblems, where the goal is to select the video which corresponds to the text\nquery between a given text query and a pool of candidate videos. The\ncontrastive paradigm of vision-language pretraining has shown promising success\nwith large-scale datasets and unified transformer architecture, and\ndemonstrated the power of a joint latent space. Despite this, the intrinsic\ndivergence between the visual domain and textual domain is still far from being\neliminated, and projecting different modalities into a joint latent space might\nresult in the distorting of the information inside the single modality. To\novercome the above issue, we present a novel mechanism for learning the\ntranslation relationship from a source modality space $\\mathcal{S}$ to a target\nmodality space $\\mathcal{T}$ without the need for a joint latent space, which\nbridges the gap between visual and textual domains. Furthermore, to keep cycle\nconsistency between translations, we adopt a cycle loss involving both forward\ntranslations from $\\mathcal{S}$ to the predicted target space $\\mathcal{T'}$,\nand backward translations from $\\mathcal{T'}$ back to $\\mathcal{S}$. Extensive\nexperiments conducted on MSR-VTT, MSVD, and DiDeMo datasets demonstrate the\nsuperiority and effectiveness of our LaT approach compared with vanilla\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Jinbin Bai",
      "Chunhui Liu",
      "Feiyue Ni",
      "Haofan Wang",
      "Mengying Hu",
      "Xiaofeng Guo",
      "Lele Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.04858"
  },
  {
    "id": "arXiv:2207.04859",
    "title": "An Overview on IEEE 802.11bf: WLAN Sensing",
    "abstract": "With recent advancements, the wireless local area network (WLAN) or wireless\nfidelity (Wi-Fi) technology has been successfully utilized to realize sensing\nfunctionalities such as detection, localization, and recognition. However, the\nWLANs standards are developed mainly for the purpose of communication, and thus\nmay not be able to meet the stringent sensing requirements in emerging\napplications. To resolve this issue, a new Task Group (TG), namely IEEE\n802.11bf, has been established by the IEEE 802.11 working group, with the\nobjective of creating a new amendment to the WLAN standard to provide advanced\nsensing requirements while minimizing the effect on communications. This paper\nprovides a comprehensive overview on the up-to-date efforts in the IEEE\n802.11bf TG. First, we introduce the definition of the 802.11bf amendment and\nits standardization timeline. Then, we discuss the WLAN sensing procedure and\nframework used for measurement acquisition, by considering both conventional\nsensing at sub-7 GHz and directional multi-gigabit (DMG) sensing at 60 GHz,\nrespectively. Next, we present various candidate technical features for IEEE\n802.11bf, including waveform/sequence design, feedback types, quantization, as\nwell as security and privacy. Finally, we describe the methodologies used by\nthe IEEE 802.11bf TG to evaluate the alternative performance. It is desired\nthat this overview paper provide useful insights on IEEE 802.11 WLAN sensing to\npeople with great interests and promote the IEEE 802.11bf standard to be widely\ndeployed.",
    "descriptor": "",
    "authors": [
      "Rui Du",
      "Hailiang Xie",
      "Mengshi Hu",
      "Narengerile",
      "Yan Xin",
      "Stephen McCann",
      "Michael Montemurro",
      "Tony Xiao Han",
      "Jie Xu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.04859"
  },
  {
    "id": "arXiv:2207.04860",
    "title": "Risk assessment and optimal allocation of security measures under  stealthy false data injection attacks",
    "abstract": "This paper firstly addresses the problem of risk assessment under false data\ninjection attacks on uncertain control systems. We consider an adversary with\ncomplete system knowledge, injecting stealthy false data into an uncertain\ncontrol system. We then use the Value-at-Risk to characterize the risk\nassociated with the attack impact caused by the adversary. The worst-case\nattack impact is characterized by the recently proposed output-to-output gain.\nWe observe that the risk assessment problem corresponds to an infinite\nnon-convex robust optimization problem. To this end, we use dissipative system\ntheory and the scenario approach to approximate the risk-assessment problem\ninto a convex problem and also provide probabilistic certificates on\napproximation. Secondly, we consider the problem of security measure\nallocation. We consider an operator with a constraint on the security budget.\nUnder this constraint, we propose an algorithm to optimally allocate the\nsecurity measures using the calculated risk such that the resulting\nValue-at-risk is minimized. Finally, we illustrate the results through a\nnumerical example. The numerical example also illustrates that the security\nallocation using the Value-at-risk, and the impact on the nominal system may\nhave different outcomes: thereby depicting the benefit of using risk metrics.",
    "descriptor": "\nComments: Accepted for publication at 6th IEEE Conference on Control Technology and Applications (CCTA). arXiv admin note: substantial text overlap with arXiv:2106.07071\n",
    "authors": [
      "Sribalaji C. Anand",
      "Andr\u00e9 M. H. Teixeira",
      "Anders Ahl\u00e9n"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.04860"
  },
  {
    "id": "arXiv:2207.04862",
    "title": "Slot Filling for Extracting Reskilling and Upskilling Options from the  Web",
    "abstract": "Disturbances in the job market such as advances in science and technology,\ncrisis and increased competition have triggered a surge in reskilling and\nupskilling programs. Information on suitable continuing education options is\ndistributed across many sites, rendering the search, comparison and selection\nof useful programs a cumbersome task. This paper, therefore, introduces a\nknowledge extraction system that integrates reskilling and upskilling options\ninto a single knowledge graph. The system collects educational programs from\n488 different providers and uses context extraction for identifying and\ncontextualizing relevant content. Afterwards, entity recognition and entity\nlinking methods draw upon a domain ontology to locate relevant entities such as\nskills, occupations and topics. Finally, slot filling integrates entities based\non their context into the corresponding slots of the continuous education\nknowledge graph. We also introduce a German gold standard that comprises 169\ndocuments and over 3800 annotations for benchmarking the necessary content\nextraction, entity linking, entity recognition and slot filling tasks, and\nprovide an overview of the system's performance.",
    "descriptor": "\nComments: Natural Language Processing and Information Systems (NLDB 2022). This preprint has not undergone any post-submission improvements or corrections. The Version of Record of this contribution is published in \"27th International Conference on Applications of Natural Language to Information Systems (NLDB 2022), Valencia, Spain, June 15-17, 2022, Proceedings\", and is available online at this https URL\n",
    "authors": [
      "Albert Weichselbraun",
      "Roger Waldvogel",
      "Andreas Fraefel",
      "Alexander van Schie",
      "Philipp Kuntschik"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.04862"
  },
  {
    "id": "arXiv:2207.04865",
    "title": "Orchestrating Tool Chains for Model-based Systems Engineering with RCE",
    "abstract": "When using multiple software tools to analyze, visualize, or optimize models\nin MBSE, it is often tedious and error-prone to manually coordinate the\nexecution of these tools and to retain their respective input and output data\nfor later analysis. Since such tools often require expertise in their usage as\nwell as diverse run-time environments, it is not straightforward to orchestrate\ntheir execution via off-the-shelf software tools. We present RCE, an\napplication developed at the German Aerospace Center that supports engineers in\ndeveloping and orchestrating the execution of complex tool chains. This\napplication is used in numerous research and development projects in diverse\ndomains and enables and simplifies the creation, analysis, and optimization of\nmodels.",
    "descriptor": "\nComments: Preprint of work published at IEEE Aerospace 2022\n",
    "authors": [
      "Jan Flink",
      "Robert Mischke",
      "Kathrin Schaffert",
      "Dominik Schneider",
      "Alexander Weinert"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.04865"
  },
  {
    "id": "arXiv:2207.04866",
    "title": "Bayesian Optimization-based Nonlinear Adaptive PID Controller Design for  Robust Mobile Manipulation",
    "abstract": "In this paper, we propose to use a nonlinear adaptive PID controller to\nregulate the joint variables of a mobile manipulator. The motion of the mobile\nbase forces undue disturbances on the joint controllers of the manipulator. In\ndesigning a conventional PID controller, one should make a trade-off between\nthe performance and agility of the closed-loop system and its stability\nmargins. The proposed nonlinear adaptive PID controller provides a mechanism to\nrelax the need for such a compromise by adapting the gains according to the\nmagnitude of the error without expert tuning. Therefore, we can achieve agile\nperformance for the system while seeing damped overshoot in the output and\ntrack the reference as close as possible, even in the presence of external\ndisturbances and uncertainties in the modeling of the system. We have employed\na Bayesian optimization approach to choose the parameters of a nonlinear\nadaptive PID controller to achieve the best performance in tracking the\nreference input and rejecting disturbances. The results demonstrate that a\nwell-designed nonlinear adaptive PID controller can effectively regulate a\nmobile manipulator's joint variables while carrying an unspecified heavy load\nand an abrupt base movement occurs.",
    "descriptor": "\nComments: Accepted to be presented at 2022 IEEE International Conference on Automation Science and Engineering (CASE 2022)\n",
    "authors": [
      "Hadi Hajieghrary",
      "Marc Peter Deisenroth",
      "Yasemin Bekiroglu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04866"
  },
  {
    "id": "arXiv:2207.04872",
    "title": "Parameterized Complexity of Streaming Diameter and Connectivity Problems",
    "abstract": "We initiate the investigation of the parameterized complexity of Diameter and\nConnectivity in the streaming paradigm. On the positive end, we show that\nknowing a vertex cover of size $k$ allows for algorithms in the Adjacency List\n(AL) streaming model whose number of passes is constant and memory is $O(\\log\nn)$ for any fixed $k$. Underlying these algorithms is a method to execute a\nbreadth-first search in $O(k)$ passes and $O(k \\log n)$ bits of memory. On the\nnegative end, we show that many other parameters lead to lower bounds in the AL\nmodel, where $\\Omega(n/p)$ bits of memory is needed for any $p$-pass algorithm\neven for constant parameter values. In particular, this holds for graphs with a\nknown modulator (deletion set) of constant size to a graph that has no induced\nsubgraph isomorphic to a fixed graph $H$, for most $H$. For some cases, we can\nalso show one-pass, $\\Omega(n \\log n)$ bits of memory lower bounds. We also\nprove a much stronger $\\Omega(n^2/p)$ lower bound for Diameter on bipartite\ngraphs.\nFinally, using the insights we developed into streaming parameterized graph\nexploration algorithms, we show a new streaming kernelization algorithm for\ncomputing a vertex cover of size $k$. This yields a kernel of $2k$ vertices\n(with $O(k^2)$ edges) produced as a stream in $\\text{poly}(k)$ passes and only\n$O(k \\log n)$ bits of memory.",
    "descriptor": "\nComments: 37 pages, 14 figures\n",
    "authors": [
      "Jelle J. Oostveen",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2207.04872"
  },
  {
    "id": "arXiv:2207.04873",
    "title": "Hierarchical Average Precision Training for Pertinent Image Retrieval",
    "abstract": "Image Retrieval is commonly evaluated with Average Precision (AP) or\nRecall@k. Yet, those metrics, are limited to binary labels and do not take into\naccount errors' severity. This paper introduces a new hierarchical AP training\nmethod for pertinent image retrieval (HAP-PIER). HAPPIER is based on a new H-AP\nmetric, which leverages a concept hierarchy to refine AP by integrating errors'\nimportance and better evaluate rankings. To train deep models with H-AP, we\ncarefully study the problem's structure and design a smooth lower bound\nsurrogate combined with a clustering loss that ensures consistent ordering.\nExtensive experiments on 6 datasets show that HAPPIER significantly outperforms\nstate-of-the-art methods for hierarchical retrieval, while being on par with\nthe latest approaches when evaluating fine-grained ranking performances.\nFinally, we show that HAPPIER leads to better organization of the embedding\nspace, and prevents most severe failure cases of non-hierarchical methods. Our\ncode is publicly available at: https://github.com/elias-ramzi/HAPPIER.",
    "descriptor": "",
    "authors": [
      "Elias Ramzi",
      "Nicolas Audebert",
      "Nicolas Thome",
      "Cl\u00e9ment Rambour",
      "Xavier Bitot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.04873"
  },
  {
    "id": "arXiv:2207.04874",
    "title": "Hebbian Continual Representation Learning",
    "abstract": "Continual Learning aims to bring machine learning into a more realistic\nscenario, where tasks are learned sequentially and the i.i.d. assumption is not\npreserved. Although this setting is natural for biological systems, it proves\nvery difficult for machine learning models such as artificial neural networks.\nTo reduce this performance gap, we investigate the question whether\nbiologically inspired Hebbian learning is useful for tackling continual\nchallenges. In particular, we highlight a realistic and often overlooked\nunsupervised setting, where the learner has to build representations without\nany supervision. By combining sparse neural networks with Hebbian learning\nprinciple, we build a simple yet effective alternative (HebbCL) to typical\nneural network models trained via the gradient descent. Due to Hebbian\nlearning, the network have easily interpretable weights, which might be\nessential in critical application such as security or healthcare. We\ndemonstrate the efficacy of HebbCL in an unsupervised learning setting applied\nto MNIST and Omniglot datasets. We also adapt the algorithm to the supervised\nscenario and obtain promising results in the class-incremental learning.",
    "descriptor": "",
    "authors": [
      "Pawe\u0142 Morawiecki",
      "Andrii Krutsylo",
      "Maciej Wo\u0142czyk",
      "Marek \u015amieja"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04874"
  },
  {
    "id": "arXiv:2207.04875",
    "title": "State estimation with the Interacting Multiple Model (IMM) method",
    "abstract": "For model-based estimation methods, the modeling that is as close to reality\nas possible makes a vital estimation result. In simple applications, it is\nsufficient to model a system with a single state space model. However, there\nare applications in which a system changes its behavior deterministically or\nstochastically. A previously defined model then describes the behavior of the\nsystem only inaccurately or is even no longer valid. The state of the art is to\nuse more than one system models in parallel and to derive a suitable system\nestimate from them. In the literature, this is generally referred to as the\nMultiple Model (MM) method. Depending on the application and requirements,\ndifferent methods exist for this purpose, which determine a single state\nestimate from a set of models. A frequently used representative of these\nmethods is the Interacting Multiple Model (IMM) method which will be presented\nin this paper.",
    "descriptor": "",
    "authors": [
      "Sebastian Dingler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04875"
  },
  {
    "id": "arXiv:2207.04876",
    "title": "Structural Stability of Spiking Neural Networks",
    "abstract": "The past decades have witnessed an increasing interest in spiking neural\nnetworks (SNNs) due to their great potential of modeling time-dependent data.\nMany algorithms and techniques have been developed; however, theoretical\nunderstandings of many aspects of spiking neural networks are still cloudy. A\nrecent work [Zhang et al. 2021] disclosed that typical SNNs could hardly\nwithstand both internal and external perturbations due to their bifurcation\ndynamics and suggested that self-connection has to be added. In this paper, we\ninvestigate the theoretical properties of SNNs with self-connection, and\ndevelop an in-depth analysis on structural stability by specifying the lower\nand upper bounds of the maximum number of bifurcation solutions. Numerical\nexperiments conducted on simulation and practical tasks demonstrate the\neffectiveness of the proposed results.",
    "descriptor": "",
    "authors": [
      "G. Zhang",
      "S.-Q. Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04876"
  },
  {
    "id": "arXiv:2207.04880",
    "title": "SDFEst: Categorical Pose and Shape Estimation of Objects from RGB-D  using Signed Distance Fields",
    "abstract": "Rich geometric understanding of the world is an important component of many\nrobotic applications such as planning and manipulation. In this paper, we\npresent a modular pipeline for pose and shape estimation of objects from RGB-D\nimages given their category. The core of our method is a generative shape\nmodel, which we integrate with a novel initialization network and a\ndifferentiable renderer to enable 6D pose and shape estimation from a single or\nmultiple views. We investigate the use of discretized signed distance fields as\nan efficient shape representation for fast analysis-by-synthesis optimization.\nOur modular framework enables multi-view optimization and extensibility. We\ndemonstrate the benefits of our approach over state-of-the-art methods in\nseveral experiments on both synthetic and real data. We open-source our\napproach at https://github.com/roym899/sdfest.",
    "descriptor": "\nComments: Accepted to IEEE Robotics and Automation Letters (and IROS 2022). Project page: this https URL\n",
    "authors": [
      "Leonard Bruns",
      "Patric Jensfelt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04880"
  },
  {
    "id": "arXiv:2207.04881",
    "title": "Simple and complex spiking neurons: perspectives and analysis in a  simple STDP scenario",
    "abstract": "Spiking neural networks (SNNs) are largely inspired by biology and\nneuroscience and leverage ideas and theories to create fast and efficient\nlearning systems. Spiking neuron models are adopted as core processing units in\nneuromorphic systems because they enable event-based processing. The\nintegrate-and-fire (I&F) models are often adopted, with the simple Leaky I&F\n(LIF) being the most used. The reason for adopting such models is their\nefficiency and/or biological plausibility. Nevertheless, rigorous justification\nfor adopting LIF over other neuron models for use in artificial learning\nsystems has not yet been studied. This work considers various neuron models in\nthe literature and then selects computational neuron models that are\nsingle-variable, efficient, and display different types of complexities. From\nthis selection, we make a comparative study of three simple I&F neuron models,\nnamely the LIF, the Quadratic I&F (QIF) and the Exponential I&F (EIF), to\nunderstand whether the use of more complex models increases the performance of\nthe system and whether the choice of a neuron model can be directed by the task\nto be completed. Neuron models are tested within an SNN trained with\nSpike-Timing Dependent Plasticity (STDP) on a classification task on the\nN-MNIST and DVS Gestures datasets. Experimental results reveal that more\ncomplex neurons manifest the same ability as simpler ones to achieve high\nlevels of accuracy on a simple dataset (N-MNIST), albeit requiring comparably\nmore hyper-parameter tuning. However, when the data possess richer\nSpatio-temporal features, the QIF and EIF neuron models steadily achieve better\nresults. This suggests that accurately selecting the model based on the\nrichness of the feature spectrum of the data could improve the whole system's\nperformance. Finally, the code implementing the spiking neurons in the\nSpykeTorch framework is made publicly available.",
    "descriptor": "",
    "authors": [
      "Davide Liberato Manna",
      "Alex Vicente Sola",
      "Paul Kirkland",
      "Trevor Bihl",
      "Gaetano Di Caterina"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04881"
  },
  {
    "id": "arXiv:2207.04884",
    "title": "Proposal and Verification of Novel Machine Learning on Classification  Problems",
    "abstract": "This paper aims at proposing a new machine learning for classification\nproblems. The classification problem has a wide range of applications, and\nthere are many approaches such as decision trees, neural networks, and Bayesian\nnets. In this paper, we focus on the action of neurons in the brain, especially\nthe EPSP/IPSP cancellation between excitatory and inhibitory synapses, and\npropose a Machine Learning that does not belong to any conventional method. The\nfeature is to consider one neuron and give it a multivariable Xj (j = 1, 2,.)\nand its function value F(Xj) as data to the input layer. The multivariable\ninput layer and processing neuron are linked by two lines to each variable\nnode. One line is called an EPSP edge, and the other is called an IPSP edge,\nand a parameter {\\Delta}j common to each edge is introduced. The processing\nneuron is divided back and forth into two parts, and at the front side, a pulse\nhaving a width 2{\\Delta}j and a height 1 is defined around an input X . The\nlatter half of the processing neuron defines a pulse having a width 2{\\Delta}j\ncentered on the input Xj and a height F(Xj) based on a value obtained from the\ninput layer of F(Xj). This information is defined as belonging to group i. In\nother words, the group i has a width of 2{\\Delta}j centered on the input Xj, is\ndefined in a region of height F(Xj), and all outputs of xi within the variable\nrange are F(Xi). This group is learned and stored by a few minutes of the\nTeaching signals, and the output of the TEST signals is predicted by which\ngroup the TEST signals belongs to. The parameter {\\Delta}j is optimized so that\nthe accuracy of the prediction is maximized. The proposed method was applied to\nthe flower species classification problem of Iris, the rank classification\nproblem of used cars, and the ring classification problem of abalone, and the\ncalculation was compared with the neural networks.",
    "descriptor": "\nComments: 20 pages, 14 figures, 13 tables\n",
    "authors": [
      "Chikako Dozono",
      "Mina Aragaki",
      "Hana Hebishima",
      "Shin-ichi Inage"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04884"
  },
  {
    "id": "arXiv:2207.04885",
    "title": "Global Cellular Automata GCA -- A Massively Parallel Computing Model",
    "abstract": "The Global Cellular Automata (GCA) Model is a generalization of the Cellular\nAutomata (CA) Model. The GCA model consists of a collection of cells which\nchange their states depending on the states of their neighbors, like in the\nclassical CA model. In generalization of the CA model, the neighbors are no\nlonger fixed and local, they are variable and global. In the basic GCA model, a\ncell is structured into a data part and a pointer part. The pointer part\nconsists of several pointers that hold addresses to global neighbors. The data\nrule defines the new data state, and the pointer rule define the new pointer\nstates. The cell's state is synchronously or asynchronously updated using the\nnew data and new pointer states. Thereby the global neighbors can be changed\nfrom generation to generation. Similar to the CA model, only the own cell's\nstate is modified. Thereby write conflicts cannot occur, all cells can work in\nparallel which makes it a massively parallel model. The GCA model is related to\nthe CROW (concurrent read owners write) model, a specific PRAM (parallel random\naccess machine) model. Therefore many of the well-studied PRAM algorithms can\nbe transformed into GCA algorithms. Moreover, the GCA model allows to describe\na large number of data parallel applications in a suitable way. The GCA model\ncan easily be implemented in software, efficiently interpreted on standard\nparallel architectures, and synthesized / configured into special hardware\ntarget architectures. This article reviews the model, applications, and\nhardware architectures.",
    "descriptor": "\nComments: 83 pages, 34 figures\n",
    "authors": [
      "Rolf Hoffmann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Hardware Architecture (cs.AR)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2207.04885"
  },
  {
    "id": "arXiv:2207.04886",
    "title": "Bio-inspired Machine Learning: programmed death and replication",
    "abstract": "We analyze algorithmic and computational aspects of biological phenomena,\nsuch as replication and programmed death, in the context of machine learning.\nWe use two different measures of neuron efficiency to develop machine learning\nalgorithms for adding neurons to the system (i.e. replication algorithm) and\nremoving neurons from the system (i.e. programmed death algorithm). We argue\nthat the programmed death algorithm can be used for compression of neural\nnetworks and the replication algorithm can be used for improving performance of\nthe already trained neural networks. We also show that a combined algorithm of\nprogrammed death and replication can improve the learning efficiency of\narbitrary machine learning systems. The computational advantages of the\nbio-inspired algorithms are demonstrated by training feedforward neural\nnetworks on the MNIST dataset of handwritten images.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Andrey Grabovsky",
      "Vitaly Vanchurin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2207.04886"
  },
  {
    "id": "arXiv:2207.04889",
    "title": "Linear Leaky-Integrate-and-Fire Neuron Model Based Spiking Neural  Networks and Its Mapping Relationship to Deep Neural Networks",
    "abstract": "Spiking neural networks (SNNs) are brain-inspired machine learning algorithms\nwith merits such as biological plausibility and unsupervised learning\ncapability. Previous works have shown that converting Artificial Neural\nNetworks (ANNs) into SNNs is a practical and efficient approach for\nimplementing an SNN. However, the basic principle and theoretical groundwork\nare lacking for training a non-accuracy-loss SNN. This paper establishes a\nprecise mathematical mapping between the biological parameters of the Linear\nLeaky-Integrate-and-Fire model (LIF)/SNNs and the parameters of ReLU-AN/Deep\nNeural Networks (DNNs). Such mapping relationship is analytically proven under\ncertain conditions and demonstrated by simulation and real data experiments. It\ncan serve as the theoretical basis for the potential combination of the\nrespective merits of the two categories of neural networks.",
    "descriptor": "",
    "authors": [
      "Sijia Lu",
      "Feng Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04889"
  },
  {
    "id": "arXiv:2207.04892",
    "title": "Adversarial Style Augmentation for Domain Generalized Urban-Scene  Segmentation",
    "abstract": "In this paper, we consider the problem of domain generalization in semantic\nsegmentation, which aims to learn a robust model using only labeled synthetic\n(source) data. The model is expected to perform well on unseen real (target)\ndomains. Our study finds that the image style variation can largely influence\nthe model's performance and the style features can be well represented by the\nchannel-wise mean and standard deviation of images. Inspired by this, we\npropose a novel adversarial style augmentation (AdvStyle) approach, which can\ndynamically generate hard stylized images during training and thus can\neffectively prevent the model from overfitting on the source domain.\nSpecifically, AdvStyle regards the style feature as a learnable parameter and\nupdates it by adversarial training. The learned adversarial style feature is\nused to construct an adversarial image for robust model training. AdvStyle is\neasy to implement and can be readily applied to different models. Experiments\non two synthetic-to-real semantic segmentation benchmarks demonstrate that\nAdvStyle can significantly improve the model performance on unseen real domains\nand show that we can achieve the state of the art. Moreover, AdvStyle can be\nemployed to domain generalized image classification and produces a clear\nimprovement on the considered datasets.",
    "descriptor": "\nComments: This paper was first online on 29 Sept 2021. See this https URL\n",
    "authors": [
      "Zhun Zhong",
      "Yuyang Zhao",
      "Gim Hee Lee",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04892"
  },
  {
    "id": "arXiv:2207.04895",
    "title": "Bottlenecks CLUB: Unifying Information-Theoretic Trade-offs Among  Complexity, Leakage, and Utility",
    "abstract": "Bottleneck problems are an important class of optimization problems that have\nrecently gained increasing attention in the domain of machine learning and\ninformation theory. They are widely used in generative models, fair machine\nlearning algorithms, design of privacy-assuring mechanisms, and appear as\ninformation-theoretic performance bounds in various multi-user communication\nproblems. In this work, we propose a general family of optimization problems,\ntermed as complexity-leakage-utility bottleneck (CLUB) model, which (i)\nprovides a unified theoretical framework that generalizes most of the\nstate-of-the-art literature for the information-theoretic privacy models, (ii)\nestablishes a new interpretation of the popular generative and discriminative\nmodels, (iii) constructs new insights to the generative compression models, and\n(iv) can be used in the fair generative models. We first formulate the CLUB\nmodel as a complexity-constrained privacy-utility optimization problem. We then\nconnect it with the closely related bottleneck problems, namely information\nbottleneck (IB), privacy funnel (PF), deterministic IB (DIB), conditional\nentropy bottleneck (CEB), and conditional PF (CPF). We show that the CLUB model\ngeneralizes all these problems as well as most other information-theoretic\nprivacy models. Then, we construct the deep variational CLUB (DVCLUB) models by\nemploying neural networks to parameterize variational approximations of the\nassociated information quantities. Building upon these information quantities,\nwe present unified objectives of the supervised and unsupervised DVCLUB models.\nLeveraging the DVCLUB model in an unsupervised setup, we then connect it with\nstate-of-the-art generative models, such as variational auto-encoders (VAEs),\ngenerative adversarial networks (GANs), as well as the Wasserstein GAN (WGAN),\nWasserstein auto-encoder (WAE), and adversarial auto-encoder (AAE) models\nthrough the optimal transport (OT) problem. We then show that the DVCLUB model\ncan also be used in fair representation learning problems, where the goal is to\nmitigate the undesired bias during the training phase of a machine learning\nmodel. We conduct extensive quantitative experiments on colored-MNIST and\nCelebA datasets, with a public implementation available, to evaluate and\nanalyze the CLUB model.",
    "descriptor": "",
    "authors": [
      "Behrooz Razeghi",
      "Flavio P. Calmon",
      "Deniz Gunduz",
      "Slava Voloshynovskiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.04895"
  },
  {
    "id": "arXiv:2207.04896",
    "title": "Solving Bilevel AC OPF Problems by Smoothing the Complementary  Conditions -- Part I: Model Description and the Algorithm",
    "abstract": "The existing research on market price-affecting agents, i.e. price makers,\nneglects or simplifies the nature of AC power flows in the power system as it\npredominantly relies on DC power flows. This paper proposes a novel bilevel\nformulation based on the smoothing technique, where any price-affecting\nstrategic player can be modelled in the upper level, while the market clearing\nproblem in the lower level uses convex quadratic transmission AC optimal power\nflow (AC OPF), with the goal of achieving accuracy close to the one of the\nexact nonlinear formulations. Achieving convexity in the lower level is the\nfoundation for bilevel modeling since traditional single-level reduction\ntechniques do not hold for nonconvex models. The bilevel market participation\nproblem with the AC OPF formulation in the lower level is transformed into a\nsingle-level problem and solved using multiple techniques such as the\nprimal-dual counterpart, the strong duality theorem, the McCormick envelopes,\nthe complementary slackness, the penalty factor, the interaction discretization\nas well as the proposed smoothing techniques. Due to an extensive amount of\ninformation and descriptions, the overall work is presented as a two-part\npaper. This first part provides a literature overview, positions the work and\npresents the model and the solution algorithm, while the solution techniques\nand case studies are provided in the accompanying paper.",
    "descriptor": "",
    "authors": [
      "Karlo \u0160epetanc",
      "Hrvoje Pand\u017ei\u0107",
      "Tomislav Capuder"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04896"
  },
  {
    "id": "arXiv:2207.04899",
    "title": "Reinforcement Learning of a CPG-regulated Locomotion Controller for a  Soft Snake Robot",
    "abstract": "In this work, we present a learning-based goal-tracking control method for\nsoft robot snakes. Inspired by biological snakes, our controller is composed of\ntwo key modules: A reinforcement learning (RL) module for learning\ngoal-tracking behaviors given stochastic dynamics of the soft snake robot, and\na central pattern generator (CPG) system with the Matsuoka oscillators for\ngenerating stable and diverse locomotion patterns. Based on the proposed\nframework, we comprehensively discuss the maneuverability of the soft snake\nrobot, including steering and speed control during its serpentine locomotion.\nSuch maneuverability can be mapped into the control of oscillation patterns of\nthe CPG system. Through theoretical analysis of the oscillating properties of\nthe Matsuoka CPG system, this work shows that the key to realizing the free\nmobility of our soft snake robot is to properly constrain and control certain\ncoefficients of the Matsuoka CPG system, including the tonic inputs and the\nfrequency ratio. Based on this analysis, we systematically formulate the\ncontrollable coefficients of the CPG system for the RL agent to operate. With\nexperimental validation, we show that our control policy learned in the\nsimulated environment can be directly applied to control our real snake robot\nto perform goal-tracking tasks, regardless of the physical environment gap\nbetween simulation and the real world. The experiment results also show that\nour method's adaptability and robustness to the sim-to-real transition are\nsignificantly improved compared to our previous approach and a baseline RL\nmethod (PPO).",
    "descriptor": "\nComments: 18 pages, 14 figures, 4 tables\n",
    "authors": [
      "Xuan Liu",
      "Cagdas Onal",
      "Jie Fu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.04899"
  },
  {
    "id": "arXiv:2207.04900",
    "title": "UM4: Unified Multilingual Multiple Teacher-Student Model for  Zero-Resource Neural Machine Translation",
    "abstract": "Most translation tasks among languages belong to the zero-resource\ntranslation problem where parallel corpora are unavailable. Multilingual neural\nmachine translation (MNMT) enables one-pass translation using shared semantic\nspace for all languages compared to the two-pass pivot translation but often\nunderperforms the pivot-based method. In this paper, we propose a novel method,\nnamed as Unified Multilingual Multiple teacher-student Model for NMT (UM4). Our\nmethod unifies source-teacher, target-teacher, and pivot-teacher models to\nguide the student model for the zero-resource translation. The source teacher\nand target teacher force the student to learn the direct source to target\ntranslation by the distilled knowledge on both source and target sides. The\nmonolingual corpus is further leveraged by the pivot-teacher model to enhance\nthe student model. Experimental results demonstrate that our model of 72\ndirections significantly outperforms previous methods on the WMT benchmark.",
    "descriptor": "\nComments: 7 pages, 5 figures, IJCAI-ECAI 2022\n",
    "authors": [
      "Jian Yang",
      "Yuwei Yin",
      "Shuming Ma",
      "Dongdong Zhang",
      "Shuangzhi Wu",
      "Hongcheng Guo",
      "Zhoujun Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04900"
  },
  {
    "id": "arXiv:2207.04901",
    "title": "Exploring Length Generalization in Large Language Models",
    "abstract": "The ability to extrapolate from short problem instances to longer ones is an\nimportant form of out-of-distribution generalization in reasoning tasks, and is\ncrucial when learning from datasets where longer problem instances are rare.\nThese include theorem proving, solving quantitative mathematics problems, and\nreading/summarizing novels. In this paper, we run careful empirical studies\nexploring the length generalization capabilities of transformer-based language\nmodels. We first establish that naively finetuning transformers on length\ngeneralization tasks shows significant generalization deficiencies independent\nof model scale. We then show that combining pretrained large language models'\nin-context learning abilities with scratchpad prompting (asking the model to\noutput solution steps before producing an answer) results in a dramatic\nimprovement in length generalization. We run careful failure analyses on each\nof the learning modalities and identify common sources of mistakes that\nhighlight opportunities in equipping language models with the ability to\ngeneralize to longer problems.",
    "descriptor": "",
    "authors": [
      "Cem Anil",
      "Yuhuai Wu",
      "Anders Andreassen",
      "Aitor Lewkowycz",
      "Vedant Misra",
      "Vinay Ramasesh",
      "Ambrose Slone",
      "Guy Gur-Ari",
      "Ethan Dyer",
      "Behnam Neyshabur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04901"
  },
  {
    "id": "arXiv:2207.04904",
    "title": "Going the Extra Mile in Face Image Quality Assessment: A Novel Database  and Model",
    "abstract": "Computer vision models for image quality assessment (IQA) predict the\nsubjective effect of generic image degradation, such as artefacts, blurs, bad\nexposure, or colors. The scarcity of face images in existing IQA datasets\n(below 10\\%) is limiting the precision of IQA required for accurately filtering\nlow-quality face images or guiding CV models for face image processing, such as\nsuper-resolution, image enhancement, and generation. In this paper, we first\nintroduce the largest annotated IQA database to date that contains 20,000 human\nfaces (an order of magnitude larger than all existing rated datasets of faces),\nof diverse individuals, in highly varied circumstances, quality levels, and\ndistortion types. Based on the database, we further propose a novel deep\nlearning model, which re-purposes generative prior features for predicting\nsubjective face quality. By exploiting rich statistics encoded in well-trained\ngenerative models, we obtain generative prior information of the images and\nserve them as latent references to facilitate the blind IQA task. Experimental\nresults demonstrate the superior prediction accuracy of the proposed model on\nthe face IQA task.",
    "descriptor": "",
    "authors": [
      "Shaolin Su",
      "Hanhe Lin",
      "Vlad Hosu",
      "Oliver Wiedemann",
      "Jinqiu Sun",
      "Yu Zhu",
      "Hantao Liu",
      "Yanning Zhang",
      "Dietmar Saupe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04904"
  },
  {
    "id": "arXiv:2207.04906",
    "title": "High-resource Language-specific Training for Multilingual Neural Machine  Translation",
    "abstract": "Multilingual neural machine translation (MNMT) trained in multiple language\npairs has attracted considerable attention due to fewer model parameters and\nlower training costs by sharing knowledge among multiple languages.\nNonetheless, multilingual training is plagued by language interference\ndegeneration in shared parameters because of the negative interference among\ndifferent translation directions, especially on high-resource languages. In\nthis paper, we propose the multilingual translation model with the\nhigh-resource language-specific training (HLT-MT) to alleviate the negative\ninterference, which adopts the two-stage training with the language-specific\nselection mechanism. Specifically, we first train the multilingual model only\nwith the high-resource pairs and select the language-specific modules at the\ntop of the decoder to enhance the translation quality of high-resource\ndirections. Next, the model is further trained on all available corpora to\ntransfer knowledge from high-resource languages (HRLs) to low-resource\nlanguages (LRLs). Experimental results show that HLT-MT outperforms various\nstrong baselines on WMT-10 and OPUS-100 benchmarks. Furthermore, the analytic\nexperiments validate the effectiveness of our method in mitigating the negative\ninterference in multilingual training.",
    "descriptor": "\nComments: 7 pages, 7 figures, IJCAI-ECAI 2022\n",
    "authors": [
      "Jian Yang",
      "Yuwei Yin",
      "Shuming Ma",
      "Dongdong Zhang",
      "Zhoujun Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04906"
  },
  {
    "id": "arXiv:2207.04907",
    "title": "A4T: Hierarchical Affordance Detection for Transparent Objects Depth  Reconstruction and Manipulation",
    "abstract": "Transparent objects are widely used in our daily lives and therefore robots\nneed to be able to handle them. However, transparent objects suffer from light\nreflection and refraction, which makes it challenging to obtain the accurate\ndepth maps required to perform handling tasks. In this paper, we propose a\nnovel affordance-based framework for depth reconstruction and manipulation of\ntransparent objects, named A4T. A hierarchical AffordanceNet is first used to\ndetect the transparent objects and their associated affordances that encode the\nrelative positions of an object's different parts. Then, given the predicted\naffordance map, a multi-step depth reconstruction method is used to\nprogressively reconstruct the depth maps of transparent objects. Finally, the\nreconstructed depth maps are employed for the affordance-based manipulation of\ntransparent objects. To evaluate our proposed method, we construct a real-world\ndataset TRANS-AFF with affordances and depth maps of transparent objects, which\nis the first of its kind. Extensive experiments show that our proposed methods\ncan predict accurate affordance maps, and significantly improve the depth\nreconstruction of transparent objects compared to the state-of-the-art method,\nwith the Root Mean Squared Error in meters significantly decreased from 0.097\nto 0.042. Furthermore, we demonstrate the effectiveness of our proposed method\nwith a series of robotic manipulation experiments on transparent objects. See\nsupplementary video and results at\nhttps://sites.google.com/view/affordance4trans.",
    "descriptor": "\nComments: 8 pages, 9 figures, Accepted by RAL-CASE2022\n",
    "authors": [
      "Jiaqi Jiang",
      "Guanqun Cao",
      "Thanh-Toan Do",
      "Shan Luo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04907"
  },
  {
    "id": "arXiv:2207.04908",
    "title": "Detection of Condensed Vehicle Gas Exhaust in LiDAR Point Clouds",
    "abstract": "LiDAR sensors used in autonomous driving applications are negatively affected\nby adverse weather conditions. One common, but understudied effect, is the\ncondensation of vehicle gas exhaust in cold weather. This everyday phenomenon\ncan severely impact the quality of LiDAR measurements, resulting in a less\naccurate environment perception by creating artifacts like ghost object\ndetections. In the literature, the semantic segmentation of adverse weather\neffects like rain and fog is achieved using learning-based approaches. However,\nsuch methods require large sets of labeled data, which can be extremely\nexpensive and laborious to get. We address this problem by presenting a\ntwo-step approach for the detection of condensed vehicle gas exhaust. First, we\nidentify for each vehicle in a scene its emission area and detect gas exhaust\nif present. Then, isolated clouds are detected by modeling through time the\nregions of space where gas exhaust is likely to be present. We test our method\non real urban data, showing that our approach can reliably detect gas exhaust\nin different scenarios, making it appealing for offline pre-labeling and online\napplications such as ghost object detection.",
    "descriptor": "\nComments: Accepted for ITSC2022\n",
    "authors": [
      "Aldi Piroli",
      "Vinzenz Dallabetta",
      "Marc Walessa",
      "Daniel Meissner",
      "Johannes Kopp",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04908"
  },
  {
    "id": "arXiv:2207.04911",
    "title": "CougaR: Fast and Eclipse-Resilient Dissemination for Blockchain Networks",
    "abstract": "Despite their development for over a decade, a key problem blockchains are\nstill facing is scalability in terms of throughput, typically limited to a few\ntransactions per second. A fundamental factor limiting this metric is the\npropagation latency of blocks through the underlying peer-to-peer network,\nwhich is typically constructed by means of random connectivity. Disseminating\nblocks fast improves not only the transaction throughput, but also the security\nof the system as it reduces the probability of forks. In this paper we present\nCougaR: a simple yet efficient, eclipse-resistant, decentralized protocol that\nsubstantially reduces the block dissemination time in blockchain networks.\nCougaR's key advantages stem from its link selection policy, which combines a\nnetwork latency criterion with randomness to offer fast and reliable block\ndissemination to the entire network. Moreover, CougaR is eclipse-resistant by\ndesign, as nodes are protected from having all their links directly or\nindirectly imposed on them by others, which is the typical vulnerability\nexploited to deploy eclipse attacks. We rigorously evaluate CougaR by an\nextensive set of experiments, both against a wide spectrum of parameter\nsettings, and in comparison to the current state of the art.",
    "descriptor": "\nComments: 12 pages, 12 figures, The 16th ACM International Conference on Distributed and Event-Based Systems, ACM DEBS 2022\n",
    "authors": [
      "Evangelos Kolyvas",
      "Spyros Voulgaris"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.04911"
  },
  {
    "id": "arXiv:2207.04912",
    "title": "Strategic Voting in the Context of Stable-Matching of Teams",
    "abstract": "In the celebrated stable-matching problem, there are two sets of agents M and\nW, and the members of M only have preferences over the members of W and vice\nversa. It is usually assumed that each member of M and W is a single entity.\nHowever, there are many cases in which each member of M or W represents a team\nthat consists of several individuals with common interests. For example,\nstudents may need to be matched to professors for their final projects, but\neach project is carried out by a team of students. Thus, the students first\nform teams, and the matching is between teams of students and professors.\nWhen a team is considered as an agent from M or W, it needs to have a\npreference order that represents it. A voting rule is a natural mechanism for\naggregating the preferences of the team members into a single preference order.\nIn this paper, we investigate the problem of strategic voting in the context of\nstable-matching of teams. Specifically, we assume that members of each team use\nthe Borda rule for generating the preference order of the team. Then, the\nGale-Shapley algorithm is used for finding a stable-matching, where the set M\nis the proposing side. We show that the single-voter manipulation problem can\nbe solved in polynomial time, both when the team is from M and when it is from\nW. We show that the coalitional manipulation problem is computationally hard,\nbut it can be solved approximately both when the team is from M and when it is\nfrom W.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Leora Schmerler",
      "Noam Hazon",
      "Sarit Kraus"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2207.04912"
  },
  {
    "id": "arXiv:2207.04913",
    "title": "Generalizing to Unseen Domains with Wasserstein Distributional  Robustness under Limited Source Knowledge",
    "abstract": "Domain generalization aims at learning a universal model that performs well\non unseen target domains, incorporating knowledge from multiple source domains.\nIn this research, we consider the scenario where different domain shifts occur\namong conditional distributions of different classes across domains. When\nlabeled samples in the source domains are limited, existing approaches are not\nsufficiently robust. To address this problem, we propose a novel domain\ngeneralization framework called Wasserstein Distributionally Robust Domain\nGeneralization (WDRDG), inspired by the concept of distributionally robust\noptimization. We encourage robustness over conditional distributions within\nclass-specific Wasserstein uncertainty sets and optimize the worst-case\nperformance of a classifier over these uncertainty sets. We further develop a\ntest-time adaptation module leveraging optimal transport to quantify the\nrelationship between the unseen target domain and source domains to make\nadaptive inference for target data. Experiments on the Rotated MNIST, PACS and\nthe VLCS datasets demonstrate that our method could effectively balance the\nrobustness and discriminability in challenging generalization scenarios.",
    "descriptor": "",
    "authors": [
      "Jingge Wang",
      "Liyan Xie",
      "Yao Xie",
      "Shao-Lun Huang",
      "Yang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04913"
  },
  {
    "id": "arXiv:2207.04914",
    "title": "Team CERBERUS Wins the DARPA Subterranean Challenge: Technical Overview  and Lessons Learned",
    "abstract": "This article presents the CERBERUS robotic system-of-systems, which won the\nDARPA Subterranean Challenge Final Event in 2021. The Subterranean Challenge\nwas organized by DARPA with the vision to facilitate the novel technologies\nnecessary to reliably explore diverse underground environments despite the\ngrueling challenges they present for robotic autonomy. Due to their geometric\ncomplexity, degraded perceptual conditions combined with lack of GPS support,\naustere navigation conditions, and denied communications, subterranean settings\nrender autonomous operations particularly demanding. In response to this\nchallenge, we developed the CERBERUS system which exploits the synergy of\nlegged and flying robots, coupled with robust control especially for overcoming\nperilous terrain, multi-modal and multi-robot perception for localization and\nmapping in conditions of sensor degradation, and resilient autonomy through\nunified exploration path planning and local motion planning that reflects\nrobot-specific limitations. Based on its ability to explore diverse underground\nenvironments and its high-level command and control by a single human\nsupervisor, CERBERUS demonstrated efficient exploration, reliable detection of\nobjects of interest, and accurate mapping. In this article, we report results\nfrom both the preliminary runs and the final Prize Round of the DARPA\nSubterranean Challenge, and discuss highlights and challenges faced, alongside\nlessons learned for the benefit of the community.",
    "descriptor": "",
    "authors": [
      "Marco Tranzatto",
      "Mihir Dharmadhikari",
      "Lukas Bernreiter",
      "Marco Camurri",
      "Shehryar Khattak",
      "Frank Mascarich",
      "Patrick Pfreundschuh",
      "David Wisth",
      "Samuel Zimmermann",
      "Mihir Kulkarni",
      "Victor Reijgwart",
      "Benoit Casseau",
      "Timon Homberger",
      "Paolo De Petris",
      "Lionel Ott",
      "Wayne Tubby",
      "Gabriel Waibel",
      "Huan Nguyen",
      "Cesar Cadena",
      "Russell Buchanan",
      "Lorenz Wellhausen",
      "Nikhil Khedekar",
      "Olov Andersson",
      "Lintong Zhang",
      "Takahiro Miki",
      "Tung Dang",
      "Matias Mattamala",
      "Markus Montenegro",
      "Konrad Meyer",
      "Xiangyu Wu",
      "Adrien Briod",
      "Mark Mueller",
      "Maurice Fallon",
      "Roland Siegwart",
      "Marco Hutter",
      "Kostas Alexis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.04914"
  },
  {
    "id": "arXiv:2207.04915",
    "title": "Multi-agent systems with CBF-based controllers -- collision avoidance  and liveness from instability",
    "abstract": "Assuring system stability is typically a major control design objective. In\nthis paper, we present a system where instability provides a crucial benefit.\nWe consider multi-agent collision avoidance using Control Barrier Functions\n(CBF) and study trade-offs between safety and liveness -- the ability to reach\na destination without large detours or gridlock. We compare two standard\ndecentralized policies, with only the local (host) control available, to\nco-optimization policies (PCCA and CCS) where everyone's (virtual) control\naction is available. The co-optimization policies compute control for everyone\neven though they lack information about others' intentions. For comparison, we\nuse a Centralized, full information policy as the benchmark. One contribution\nof this paper is proving feasibility for the Centralized, PCCA, and CCS\npolicies. Monte Carlo simulations show that decentralized, host-only control\npolicies and CCS lack liveness while the PCCA policy performs as well as the\nCentralized. Next, we explain the observed results by considering two agents\nnegotiating the passing order through an intersection. We show that the\nstructure and stability of the resulting equilibria correlates with the\nobserved propensity to gridlock -- the policies with unstable equilibria avoid\ngridlocks while those with stable ones do not.",
    "descriptor": "\nComments: 12 pages, 13 figures. arXiv admin note: substantial text overlap with arXiv:2012.10261\n",
    "authors": [
      "Mrdjan Jankovic",
      "Mario Santillo",
      "Yan Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04915"
  },
  {
    "id": "arXiv:2207.04931",
    "title": "Online bin stretching lower bounds: Improved search of computational  proofs",
    "abstract": "Online bin stretching is an online problem where some items must be packed in\nan online fashion in a given number of bins. The items are guaranteed to be\nable to fit into the bins. However, the online aspect of this problem might\nforce the bins to be \"stretched\" to a bigger capacity in order to be able to\npack all the items. Finding lower and upper bounds on how much the bins need to\nbe stretched in the worst case can be modeled as a 2-player game. Then,\ncomputational methods can be used to find lower and upper bounds. We propose\nhere new ideas to speed up such methods to try to obtain better lower bounds.\nMore specifically, we give a way to strongly reduce the computation needed for\nlower bounds by propagating the game states that can be pruned from the search.\nWith those results, the speed and efficiency of the search for lower bounds has\nbeen increased. Moreover, three new lower bounds have been found.",
    "descriptor": "",
    "authors": [
      "Antoine Lhomme",
      "Olivier Romane",
      "Nicolas Catusse",
      "Nadia Brauner"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.04931"
  },
  {
    "id": "arXiv:2207.04933",
    "title": "Understanding the Role of External Pull Requests in the NPM Ecosystem",
    "abstract": "The risk to using third-party libraries in a software application is that\nmuch needed maintenance is solely carried out by library maintainers. These\nlibraries may rely on a core team of maintainers (who might be a single\nmaintainer that is unpaid and overworked) to serve a massive client user-base.\nOn the other hand, being open source has the benefit of receiving contributions\n(in the form of External PRs) to help fix bugs and add new features. In this\npaper, we investigate the role by which External PRs (contributions from\noutside the core team of maintainers) contribute to a library. Through a\npreliminary analysis, we find that External PRs are prevalent, and just as\nlikely to be accepted as maintainer PRs. We find that 26.75% of External PRs\nsubmitted fix existing issues. Moreover, fixes also belong to labels such as\nbreaking changes, urgent, and on-hold. Differently from Internal PRs, External\nPRs cover documentation changes (44 out of 384 PRs), while not having as much\nrefactoring (34 out of 384 PRs). On the other hand, External PRs also cover new\nfeatures (380 out of 384 PRs) and bugs (120 out of 384). Our results lay the\ngroundwork for understanding how maintainers decide which external\ncontributions they select to evolve their libraries and what role they play in\nreducing the workload.",
    "descriptor": "\nComments: Submitted to EMSE journal\n",
    "authors": [
      "Vittunyuta Maeprasart",
      "Supatsara Wattanakriengkrai",
      "Raula Gaikovina Kula",
      "Christoph Treude",
      "Kenichi Matsumoto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.04933"
  },
  {
    "id": "arXiv:2207.04945",
    "title": "SHREC'22 Track: Sketch-Based 3D Shape Retrieval in the Wild",
    "abstract": "Sketch-based 3D shape retrieval (SBSR) is an important yet challenging task,\nwhich has drawn more and more attention in recent years. Existing approaches\naddress the problem in a restricted setting, without appropriately simulating\nreal application scenarios. To mimic the realistic setting, in this track, we\nadopt large-scale sketches drawn by amateurs of different levels of drawing\nskills, as well as a variety of 3D shapes including not only CAD models but\nalso models scanned from real objects. We define two SBSR tasks and construct\ntwo benchmarks consisting of more than 46,000 CAD models, 1,700 realistic\nmodels, and 145,000 sketches in total. Four teams participated in this track\nand submitted 15 runs for the two tasks, evaluated by 7 commonly-adopted\nmetrics. We hope that, the benchmarks, the comparative results, and the\nopen-sourced evaluation code will foster future research in this direction\namong the 3D object retrieval community.",
    "descriptor": "",
    "authors": [
      "Jie Qin",
      "Shuaihang Yuan",
      "Jiaxin Chen",
      "Boulbaba Ben Amor",
      "Yi Fang",
      "Nhat Hoang-Xuan",
      "Chi-Bien Chu",
      "Khoi-Nguyen Nguyen-Ngoc",
      "Thien-Tri Cao",
      "Nhat-Khang Ngo",
      "Tuan-Luc Huynh",
      "Hai-Dang Nguyen",
      "Minh-Triet Tran",
      "Haoyang Luo",
      "Jianning Wang",
      "Zheng Zhang",
      "Zihao Xin",
      "Yang Wang",
      "Feng Wang",
      "Ying Tang",
      "Haiqin Chen",
      "Yan Wang",
      "Qunying Zhou",
      "Ji Zhang",
      "Hongyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.04945"
  },
  {
    "id": "arXiv:2207.04947",
    "title": "TweetDIS: A Large Twitter Dataset for Natural Disasters Built using Weak  Supervision",
    "abstract": "Social media is often utilized as a lifeline for communication during natural\ndisasters. Traditionally, natural disaster tweets are filtered from the Twitter\nstream using the name of the natural disaster and the filtered tweets are sent\nfor human annotation. The process of human annotation to create labeled sets\nfor machine learning models is laborious, time consuming, at times inaccurate,\nand more importantly not scalable in terms of size and real-time use. In this\nwork, we curate a silver standard dataset using weak supervision. In order to\nvalidate its utility, we train machine learning models on the weakly supervised\ndata to identify three different types of natural disasters i.e earthquakes,\nhurricanes and floods. Our results demonstrate that models trained on the\nsilver standard dataset achieved performance greater than 90% when classifying\na manually curated, gold-standard dataset. To enable reproducible research and\nadditional downstream utility, we release the silver standard dataset for the\nscientific community.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Ramya Tekumalla",
      "Juan M. Banda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04947"
  },
  {
    "id": "arXiv:2207.04950",
    "title": "Neural and gpc operator surrogates: construction and expression rate  bounds",
    "abstract": "Approximation rates are analyzed for deep surrogates of maps between\ninfinite-dimensional function spaces, arising e.g. as data-to-solution maps of\nlinear and nonlinear partial differential equations. Specifically, we study\napproximation rates for Deep Neural Operator and Generalized Polynomial Chaos\n(gpc) Operator surrogates for nonlinear, holomorphic maps between\ninfinite-dimensional, separable Hilbert spaces. Operator in- and outputs from\nfunction spaces are assumed to be parametrized by stable, affine representation\nsystems. Admissible representation systems comprise orthonormal bases, Riesz\nbases or suitable tight frames of the spaces under consideration. Algebraic\nexpression rate bounds are established for both, deep neural and gpc operator\nsurrogates acting in scales of separable Hilbert spaces containing domain and\nrange of the map to be expressed, with finite Sobolev or Besov regularity. We\nillustrate the abstract concepts by expression rate bounds for the\ncoefficient-to-solution map for a linear elliptic PDE on the torus.",
    "descriptor": "",
    "authors": [
      "Lukas Herrmann",
      "Christoph Schwab",
      "Jakob Zech"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04950"
  },
  {
    "id": "arXiv:2207.04954",
    "title": "Simple Dynamic Spanners with Near-optimal Recourse against an Adaptive  Adversary",
    "abstract": "Designing dynamic algorithms against an adaptive adversary whose performance\nmatch the ones assuming an oblivious adversary is a major research program in\nthe field of dynamic graph algorithms. One of the prominent examples whose\noblivious-vs-adaptive gap remains maximally large is the \\emph{fully dynamic\nspanner} problem; there exist algorithms assuming an oblivious adversary with\nnear-optimal size-stretch trade-off using only $\\operatorname{polylog}(n)$\nupdate time [Baswana, Khurana, and Sarkar TALG'12; Forster and Goranci STOC'19;\nBernstein, Forster, and Henzinger SODA'20], while against an adaptive\nadversary, even when we allow infinite time and only count recourse (i.e. the\nnumber of edge changes per update in the maintained spanner), all previous\nalgorithms with stretch at most $\\log^{5}(n)$ require at least $\\Omega(n)$\namortized recourse [Ausiello, Franciosa, and Italiano ESA'05].\nIn this paper, we completely close this gap with respect to recourse by\nshowing algorithms against an adaptive adversary with near-optimal size-stretch\ntrade-off and recourse. More precisely, for any $k\\ge1$, our algorithm\nmaintains a $(2k-1)$-spanner of size $O(n^{1+1/k}\\log n)$ with $O(\\log n)$\namortized recourse, which is optimal in all parameters up to a $O(\\log n)$\nfactor. As a step toward algorithms with small update time (not just recourse),\nwe show another algorithm that maintains a $3$-spanner of size $\\tilde\nO(n^{1.5})$ with $\\operatorname{polylog}(n)$ amortized recourse \\emph{and}\nsimultaneously $\\tilde O(\\sqrt{n})$ worst-case update time.",
    "descriptor": "\nComments: Accepted to ESA'22\n",
    "authors": [
      "Sayan Bhattacharya",
      "Thatchaphol Saranurak",
      "Pattara Sukprasert"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.04954"
  },
  {
    "id": "arXiv:2207.04955",
    "title": "Fair Throughput Optimization with a Dynamic Network of Drone Relays",
    "abstract": "Aiding the ground cellular network with aerial base stations carried by\ndrones has experienced an intensive raise of interest in the past years.\nReconfigurable air-to-ground channels enable aerial stations to enhance users\naccess links by means of seeking good line-of-sight connectivity while hovering\nin the air. In this paper, we propose an analytical framework for the 3D\nplacement of a fleet of coordinated drone relays. This framework optimizes\nnetwork performance in terms of user throughput fairness, expressed through the\n{\\alpha}-fairness metric. The optimization problem is formulated as a\nmixed-integer non-convex program, which is intractable. Hence, we propose an\nextremal-optimization-based algorithm, Parallelized Alpha-fair Drone\nDeployment, that solves the problem online, in low-degree polynomial time. We\nevaluate our proposal by means of numerical simulations over the real topology\nof a dense city. We discuss the advantages of integrating drone relay stations\nin current networks and test several resource scheduling approaches in both\nstatic and dynamic scenarios, including with progressively larger and denser\ncrowds.",
    "descriptor": "",
    "authors": [
      "Edgar Arribas",
      "Vincenzo Mancuso",
      "Vicent Cholvi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.04955"
  },
  {
    "id": "arXiv:2207.04957",
    "title": "Submodular Dominance and Applications",
    "abstract": "In submodular optimization we often deal with the expected value of a\nsubmodular function $f$ on a distribution $\\mathcal{D}$ over sets of elements.\nIn this work we study such submodular expectations for negatively dependent\ndistributions. We introduce a natural notion of negative dependence, which we\ncall Weak Negative Regression (WNR), that generalizes both Negative Association\nand Negative Regression. We observe that WNR distributions satisfy Submodular\nDominance, whereby the expected value of $f$ under $\\mathcal{D}$ is at least\nthe expected value of $f$ under a product distribution with the same\nelement-marginals.\nNext, we give several applications of Submodular Dominance to submodular\noptimization. In particular, we improve the best known submodular prophet\ninequalities, we develop new rounding techniques for polytopes of set systems\nthat admit negatively dependent distributions, and we prove existence of\ncontention resolution schemes for WNR distributions.",
    "descriptor": "\nComments: Appears in APPROX 2022, 21 pages, 1 figure\n",
    "authors": [
      "Frederick Qiu",
      "Sahil Singla"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.04957"
  },
  {
    "id": "arXiv:2207.04958",
    "title": "Documenting Data Production Processes: A Participatory Approach for Data  Work",
    "abstract": "The opacity of machine learning data is a significant threat to ethical data\nwork and intelligible systems. Previous research has addressed this issue by\nproposing standardized checklists to document datasets. This paper expands that\nfield of inquiry by proposing a shift of perspective: from documenting datasets\ntoward documenting data production. We draw on participatory design and\ncollaborate with data workers at two companies located in Bulgaria and\nArgentina, where the collection and annotation of data for machine learning are\noutsourced. Our investigation comprises 2.5 years of research, including 33\nsemi-structured interviews, five co-design workshops, the development of\nprototypes, and several feedback instances with participants. We identify key\nchallenges and requirements related to the integration of documentation\npractices in real-world data production scenarios. Our findings comprise\nimportant design considerations and highlight the value of designing data\ndocumentation based on the needs of data workers. We argue that a view of\ndocumentation as a boundary object, i.e., an object that can be used\ndifferently across organizations and teams but holds enough immutable content\nto maintain integrity, can be useful when designing documentation to retrieve\nheterogeneous, often distributed, contexts of data production.",
    "descriptor": "",
    "authors": [
      "Milagros Miceli",
      "Tianling Yang",
      "Adriana Alvarado Garcia",
      "Julian Posada",
      "Sonja Mei Wang",
      "Marc Pohl",
      "Alex Hanna"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.04958"
  },
  {
    "id": "arXiv:2207.04967",
    "title": "Implementing packet trimming support in hardware",
    "abstract": "Packet trimming is a primitive that has been proposed for datacenter\nnetworks: to minimize latency, switches run small queues; when the queue\noverflows, rather than dropping packets the switch trims off the packet payload\nand either forwards the header to the destination or back to the source. In\nthis way a low latency network that is largely lossless for metadata can be\nbuilt. Ideally, trimming would be implemented as a primitive in switch ASICs,\nbut hardware development cycles are slow, costly, and require demonstrated\ncustomer demand. In this paper we investigate how trimming can be implemented\nin existing programmable switches which were not designed with trimming in\nmind, with a particular focus on a P4 implementation on the Tofino switch ASIC.\nWe show that it is indeed possible to closely approximate idealized trimming\nand demonstrate that trimming can be integrated into a production-grade\ndatacenter switch software stack.",
    "descriptor": "",
    "authors": [
      "Popa Adrian",
      "Dumitrescu Dragos",
      "Handley Mark",
      "Nikolaidis Georgios",
      "Lee Jeongkeun",
      "Raiciu Costin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.04967"
  },
  {
    "id": "arXiv:2207.04969",
    "title": "From Correlation to Causation: Formalizing Interpretable Machine  Learning as a Statistical Process",
    "abstract": "Explainable AI (XAI) is a necessity in safety-critical systems such as in\nclinical diagnostics due to a high risk for fatal decisions. Currently,\nhowever, XAI resembles a loose collection of methods rather than a well-defined\nprocess. In this work, we elaborate on conceptual similarities between the\nlargest subgroup of XAI, interpretable machine learning (IML), and classical\nstatistics. Based on these similarities, we present a formalization of IML\nalong the lines of a statistical process. Adopting this statistical view allows\nus to interpret machine learning models and IML methods as sophisticated\nstatistical tools. Based on this interpretation, we infer three key questions,\nwhich we identify as crucial for the success and adoption of IML in\nsafety-critical settings. By formulating these questions, we further aim to\nspark a discussion about what distinguishes IML from classical statistics and\nwhat our perspective implies for the future of the field.",
    "descriptor": "\nComments: Accepted at IJCAI 2022 Workshop on Explainable Artificial Intelligence (XAI)\n",
    "authors": [
      "Lukas Klein",
      "Mennatallah El-Assady",
      "Paul F. J\u00e4ger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04969"
  },
  {
    "id": "arXiv:2207.04974",
    "title": "Sparsifying Binary Networks",
    "abstract": "Binary neural networks (BNNs) have demonstrated their ability to solve\ncomplex tasks with comparable accuracy as full-precision deep neural networks\n(DNNs), while also reducing computational power and storage requirements and\nincreasing the processing speed. These properties make them an attractive\nalternative for the development and deployment of DNN-based applications in\nInternet-of-Things (IoT) devices. Despite the recent improvements, they suffer\nfrom a fixed and limited compression factor that may result insufficient for\ncertain devices with very limited resources. In this work, we propose sparse\nbinary neural networks (SBNNs), a novel model and training scheme which\nintroduces sparsity in BNNs and a new quantization function for binarizing the\nnetwork's weights. The proposed SBNN is able to achieve high compression\nfactors and it reduces the number of operations and parameters at inference\ntime. We also provide tools to assist the SBNN design, while respecting\nhardware resource constraints. We study the generalization properties of our\nmethod for different compression factors through a set of experiments on linear\nand convolutional networks on three datasets. Our experiments confirm that\nSBNNs can achieve high compression rates, without compromising generalization,\nwhile further reducing the operations of BNNs, making SBNNs a viable option for\ndeploying DNNs in cheap, low-cost, limited-resources IoT devices and sensors.",
    "descriptor": "",
    "authors": [
      "Riccardo Schiavone",
      "Maria A. Zuluaga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04974"
  },
  {
    "id": "arXiv:2207.04976",
    "title": "Dual Vision Transformer",
    "abstract": "Prior works have proposed several strategies to reduce the computational cost\nof self-attention mechanism. Many of these works consider decomposing the\nself-attention procedure into regional and local feature extraction procedures\nthat each incurs a much smaller computational complexity. However, regional\ninformation is typically only achieved at the expense of undesirable\ninformation lost owing to down-sampling. In this paper, we propose a novel\nTransformer architecture that aims to mitigate the cost issue, named Dual\nVision Transformer (Dual-ViT). The new architecture incorporates a critical\nsemantic pathway that can more efficiently compress token vectors into global\nsemantics with reduced order of complexity. Such compressed global semantics\nthen serve as useful prior information in learning finer pixel level details,\nthrough another constructed pixel pathway. The semantic pathway and pixel\npathway are then integrated together and are jointly trained, spreading the\nenhanced self-attention information in parallel through both of the pathways.\nDual-ViT is henceforth able to reduce the computational complexity without\ncompromising much accuracy. We empirically demonstrate that Dual-ViT provides\nsuperior accuracy than SOTA Transformer architectures with reduced training\ncomplexity. Source code is available at\n\\url{https://github.com/YehLi/ImageNetModel}.",
    "descriptor": "\nComments: Source code is available at \\url{this https URL}\n",
    "authors": [
      "Ting Yao",
      "Yehao Li",
      "Yingwei Pan",
      "Yu Wang",
      "Xiao-Ping Zhang",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04976"
  },
  {
    "id": "arXiv:2207.04978",
    "title": "Wave-ViT: Unifying Wavelet and Transformers for Visual Representation  Learning",
    "abstract": "Multi-scale Vision Transformer (ViT) has emerged as a powerful backbone for\ncomputer vision tasks, while the self-attention computation in Transformer\nscales quadratically w.r.t. the input patch number. Thus, existing solutions\ncommonly employ down-sampling operations (e.g., average pooling) over\nkeys/values to dramatically reduce the computational cost. In this work, we\nargue that such over-aggressive down-sampling design is not invertible and\ninevitably causes information dropping especially for high-frequency components\nin objects (e.g., texture details). Motivated by the wavelet theory, we\nconstruct a new Wavelet Vision Transformer (\\textbf{Wave-ViT}) that formulates\nthe invertible down-sampling with wavelet transforms and self-attention\nlearning in a unified way. This proposal enables self-attention learning with\nlossless down-sampling over keys/values, facilitating the pursuing of a better\nefficiency-vs-accuracy trade-off. Furthermore, inverse wavelet transforms are\nleveraged to strengthen self-attention outputs by aggregating local contexts\nwith enlarged receptive field. We validate the superiority of Wave-ViT through\nextensive experiments over multiple vision tasks (e.g., image recognition,\nobject detection and instance segmentation). Its performances surpass\nstate-of-the-art ViT backbones with comparable FLOPs. Source code is available\nat \\url{https://github.com/YehLi/ImageNetModel}.",
    "descriptor": "\nComments: ECCV 2022. Source code is available at \\url{this https URL}\n",
    "authors": [
      "Ting Yao",
      "Yingwei Pan",
      "Yehao Li",
      "Chong-Wah Ngo",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04978"
  },
  {
    "id": "arXiv:2207.04979",
    "title": "Start Small, Think Big: On Hyperparameter Optimization for Large-Scale  Knowledge Graph Embeddings",
    "abstract": "Knowledge graph embedding (KGE) models are an effective and popular approach\nto represent and reason with multi-relational data. Prior studies have shown\nthat KGE models are sensitive to hyperparameter settings, however, and that\nsuitable choices are dataset-dependent. In this paper, we explore\nhyperparameter optimization (HPO) for very large knowledge graphs, where the\ncost of evaluating individual hyperparameter configurations is excessive. Prior\nstudies often avoided this cost by using various heuristics; e.g., by training\non a subgraph or by using fewer epochs. We systematically discuss and evaluate\nthe quality and cost savings of such heuristics and other low-cost\napproximation techniques. Based on our findings, we introduce GraSH, an\nefficient multi-fidelity HPO algorithm for large-scale KGEs that combines both\ngraph and epoch reduction techniques and runs in multiple rounds of increasing\nfidelities. We conducted an experimental study and found that GraSH obtains\nstate-of-the-art results on large graphs at a low cost (three complete training\nruns in total).",
    "descriptor": "",
    "authors": [
      "Adrian Kochsiek",
      "Fritz Niesel",
      "Rainer Gemulla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04979"
  },
  {
    "id": "arXiv:2207.04981",
    "title": "What AI can do for horse-racing ?",
    "abstract": "Since the 1980s, machine learning has been widely used for horse-racing\npredictions, gradually expanding to where algorithms are now playing a huge\nrole in the betting market. Machine learning has changed the horse-racing\nbetting market over the last ten years, but main changes are still to come. The\nparadigm shift of neural networks (deep learning) may not only improve our\nability to simply predict the outcome of a race, but it will also certainly\nshake our entire way of thinking about horse-racing - and maybe more generally\nabout horses. Since 2012, deep learning provided more and more state-of-the-art\nresults in computer vision and now statistical learning or game theory. We\ndescribe how the convergence of the three machine learning fields (computer\nvision, statistical learning, and game theory) will be game-changers in the\nnext decade in our ability to predict and understand horse-racing. We consider\nthat horse-racing is a real world laboratory where we can work on the\nanimal-human interaction and build a non-anthropocentric Artificial\nIntelligence. We believe that this will lead us to understand the horses better\nand the interactions between animals and humans in general.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Pierre Colle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.04981"
  },
  {
    "id": "arXiv:2207.04983",
    "title": "Better Collective Decisions via Uncertainty Reduction",
    "abstract": "We consider an agent community wishing to decide on several binary issues by\nmeans of issue-by-issue majority voting. For each issue and each agent, one of\nthe two options is better than the other. However, some of the agents may be\nconfused about some of the issues, in which case they may vote for the option\nthat is objectively worse for them. A benevolent external party wants to help\nthe agents to make better decisions, i.e., select the majority-preferred option\nfor as many issues as possible. This party may have one of the following tools\nat its disposal: (1) educating some of the agents, so as to enable them to vote\ncorrectly on all issues, (2) appointing a subset of highly competent agents to\nmake decisions on behalf of the entire group, or (3) guiding the agents on how\nto delegate their votes to other agents, in a way that is consistent with the\nagents' opinions. For each of these tools, we study the complexity of the\ndecision problem faced by this external party, obtaining both NP-hardness\nresults and fixed-parameter tractability results.",
    "descriptor": "\nComments: Appears in the 31st International Joint Conference on Artificial Intelligence (IJCAI), 2022\n",
    "authors": [
      "Shiri Alouf-Heffetz",
      "Laurent Bulteau",
      "Edith Elkind",
      "Nimrod Talmon",
      "Nicholas Teh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2207.04983"
  },
  {
    "id": "arXiv:2207.04984",
    "title": "Belief Propagation with Quantum Messages for Symmetric Classical-Quantum  Channels",
    "abstract": "Belief propagation (BP) is a classical algorithm that approximates the\nmarginal distribution associated with a factor graph by passing messages\nbetween adjacent nodes in the graph. It gained popularity in the 1990's as a\npowerful decoding algorithm for LDPC codes. In 2016, Renes introduced a belief\npropagation with quantum messages (BPQM) and described how it could be used to\ndecode classical codes defined by tree factor graphs that are sent over the\nclassical-quantum pure-state channel. In this work, we propose an extension of\nBPQM to general binary-input symmetric classical-quantum (BSCQ) channels based\non the implementation of a symmetric \"paired measurement\". While this new\npaired-measurement BPQM (PMBPQM) approach is suboptimal in general, it provides\na concrete BPQM decoder that can be implemented with local operations.",
    "descriptor": "\nComments: Extended version of submission to the 2022 Information Theory Workshop in Mumbai, India\n",
    "authors": [
      "S. Brandsen",
      "Avijit Mandal",
      "Henry D. Pfister"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.04984"
  },
  {
    "id": "arXiv:2207.04986",
    "title": "Order-Invariance in the Two-Variable Fragment of First-Order Logic",
    "abstract": "We study the expressive power of the two-variable fragment of order-invariant\nfirst-order logic. This logic departs from first-order logic in two ways:\nfirst, formulas are only allowed to quantify over two variables. Second,\nformulas can use an additional binary relation, which is interpreted in the\nstructures under scrutiny as a linear order, provided that the truth value of a\nsentence over a finite structure never depends on which linear order is chosen\non its domain. We prove that on classes of structures of bounded degree, any\nproperty expressible in this logic is definable in first-order logic. We then\nshow that the situation remains the same when we add counting quantifiers to\nthis logic.",
    "descriptor": "",
    "authors": [
      "Julien Grange"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.04986"
  },
  {
    "id": "arXiv:2207.04993",
    "title": "Embedding Recycling for Language Models",
    "abstract": "Training and inference with large neural models is expensive. However, for\nmany application domains, while new tasks and models arise frequently, the\nunderlying documents being modeled remain mostly unchanged. We study how to\ndecrease computational cost in such settings through embedding recycling (ER):\nre-using activations from previous model runs when performing training or\ninference. In contrast to prior work focusing on freezing small classification\nheads for finetuning which often leads to notable drops in performance, we\npropose caching an intermediate layer's output from a pretrained model and\nfinetuning the remaining layers for new tasks. We show that our method provides\na 100% speedup during training and a 55-86% speedup for inference, and has\nnegligible impacts on accuracy for text classification and entity recognition\ntasks in the scientific domain. For general-domain question answering tasks, ER\noffers a similar speedup and lowers accuracy by a small amount. Finally, we\nidentify several open challenges and future directions for ER.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Jon Saad-Falcon",
      "Amanpreet Singh",
      "Luca Soldaini",
      "Mike D'Arcy",
      "Arman Cohan",
      "Doug Downey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.04993"
  },
  {
    "id": "arXiv:2207.04997",
    "title": "A Closer Look at Invariances in Self-supervised Pre-training for 3D  Vision",
    "abstract": "Self-supervised pre-training for 3D vision has drawn increasing research\ninterest in recent years. In order to learn informative representations, a lot\nof previous works exploit invariances of 3D features, \\eg,\nperspective-invariance between views of the same scene, modality-invariance\nbetween depth and RGB images, format-invariance between point clouds and\nvoxels. Although they have achieved promising results, previous researches lack\na systematic and fair comparison of these invariances. To address this issue,\nour work, for the first time, introduces a unified framework, under which\nvarious pre-training methods can be investigated. We conduct extensive\nexperiments and provide a closer look at the contributions of different\ninvariances in 3D pre-training. Also, we propose a simple but effective method\nthat jointly pre-trains a 3D encoder and a depth map encoder using contrastive\nlearning. Models pre-trained with our method gain significant performance boost\nin downstream tasks. For instance, a pre-trained VoteNet outperforms previous\nmethods on SUN RGB-D and ScanNet object detection benchmarks with a clear\nmargin.",
    "descriptor": "\nComments: Accepted on ECCV 2022\n",
    "authors": [
      "Lanxiao Li",
      "Michael Heizmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04997"
  },
  {
    "id": "arXiv:2207.04998",
    "title": "Consistency is the key to further mitigating catastrophic forgetting in  continual learning",
    "abstract": "Deep neural networks struggle to continually learn multiple sequential tasks\ndue to catastrophic forgetting of previously learned tasks. Rehearsal-based\nmethods which explicitly store previous task samples in the buffer and\ninterleave them with the current task samples have proven to be the most\neffective in mitigating forgetting. However, Experience Replay (ER) does not\nperform well under low-buffer regimes and longer task sequences as its\nperformance is commensurate with the buffer size. Consistency in predictions of\nsoft-targets can assist ER in preserving information pertaining to previous\ntasks better as soft-targets capture the rich similarity structure of the data.\nTherefore, we examine the role of consistency regularization in ER framework\nunder various continual learning scenarios. We also propose to cast consistency\nregularization as a self-supervised pretext task thereby enabling the use of a\nwide variety of self-supervised learning methods as regularizers. While\nsimultaneously enhancing model calibration and robustness to natural\ncorruptions, regularizing consistency in predictions results in lesser\nforgetting across all continual learning scenarios. Among the different\nfamilies of regularizers, we find that stricter consistency constraints\npreserve previous task information in ER better.",
    "descriptor": "\nComments: Accepted at Conference on Lifelong Learning Agents (CoLLAs 2022)\n",
    "authors": [
      "Prashant Bhat",
      "Bahram Zonooz",
      "Elahe Arani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04998"
  },
  {
    "id": "arXiv:2207.05006",
    "title": "TASKOGRAPHY: Evaluating robot task planning over large 3D scene graphs",
    "abstract": "3D scene graphs (3DSGs) are an emerging description; unifying symbolic,\ntopological, and metric scene representations. However, typical 3DSGs contain\nhundreds of objects and symbols even for small environments; rendering task\nplanning on the full graph impractical. We construct TASKOGRAPHY, the first\nlarge-scale robotic task planning benchmark over 3DSGs. While most benchmarking\nefforts in this area focus on vision-based planning, we systematically study\nsymbolic planning, to decouple planning performance from visual representation\nlearning. We observe that, among existing methods, neither classical nor\nlearning-based planners are capable of real-time planning over full 3DSGs.\nEnabling real-time planning demands progress on both (a) sparsifying 3DSGs for\ntractable planning and (b) designing planners that better exploit 3DSG\nhierarchies. Towards the former goal, we propose SCRUB, a task-conditioned 3DSG\nsparsification method; enabling classical planners to match and in some cases\nsurpass state-of-the-art learning-based planners. Towards the latter goal, we\npropose SEEK, a procedure enabling learning-based planners to exploit 3DSG\nstructure, reducing the number of replanning queries required by current best\napproaches by an order of magnitude. We will open-source all code and baselines\nto spur further research along the intersections of robot task planning,\nlearning and 3DSGs.",
    "descriptor": "\nComments: Video: this https URL&ab_channel=KrishnaMurthy . Project page: this https URL . 18 pages, 7 figures. In proceedings of Conference on Robot Learning (CoRL) 2021. The first two authors contributed equally\n",
    "authors": [
      "Christopher Agia",
      "Krishna Murthy Jatavallabhula",
      "Mohamed Khodeir",
      "Ondrej Miksik",
      "Vibhav Vineet",
      "Mustafa Mukadam",
      "Liam Paull",
      "Florian Shkurti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05006"
  },
  {
    "id": "arXiv:2207.05008",
    "title": "A description of Turkish Discourse Bank 1.2 and an examination of common  dependencies in Turkish discourse",
    "abstract": "We describe Turkish Discourse Bank 1.2, the latest version of a discourse\ncorpus annotated for explicitly or implicitly conveyed discourse relations,\ntheir constitutive units, and senses in the Penn Discourse Treebank style. We\npresent an evaluation of the recently added tokens and examine three commonly\noccurring dependency patterns that hold among the constitutive units of a pair\nof adjacent discourse relations, namely, shared arguments, full embedding and\npartial containment of a discourse relation. We present three major findings:\n(a) implicitly conveyed relations occur more often than explicitly conveyed\nrelations in the data; (b) it is much more common for two adjacent implicit\ndiscourse relations to share an argument than for two adjacent explicit\nrelations to do so; (c) both full embedding and partial containment of\ndiscourse relations are pervasive in the corpus, which can be partly due to\nsubordinator connectives whose preposed subordinate clause tends to be selected\ntogether with the matrix clause rather than being selected alone. Finally, we\nbriefly discuss the implications of our findings for Turkish discourse parsing.",
    "descriptor": "\nComments: Presented in The International Conference on Agglutinative Language Technologies as a challenge of Natural Language Processing (ALTNLP) 2022. To be published\n",
    "authors": [
      "Deniz Zeyrek",
      "Mustafa Erolcan Er"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.05008"
  },
  {
    "id": "arXiv:2207.05009",
    "title": "A Learned Radiance-Field Representation for Complex Luminaires",
    "abstract": "We propose an efficient method for rendering complex luminaires using a\nhigh-quality octree-based representation of the luminaire emission. Complex\nluminaires are a particularly challenging problem in rendering, due to their\ncaustic light paths inside the luminaire. We reduce the geometric complexity of\nluminaires by using a simple proxy geometry and encode the visually-complex\nemitted light field by using a neural radiance field. We tackle the multiple\nchallenges of using NeRFs for representing luminaires, including their high\ndynamic range, high-frequency content and null-emission areas, by proposing a\nspecialized loss function. For rendering, we distill our luminaires' NeRF into\na Plenoctree, which we can be easily integrated into traditional rendering\nsystems. Our approach allows for speed-ups of up to 2 orders of magnitude in\nscenes containing complex luminaires introducing minimal error.",
    "descriptor": "\nComments: 10 pages, 7 figures. Eurographics Proceedings (EGSR 2022, Symposium-only track) (this https URL)\n",
    "authors": [
      "Jorge Condor",
      "Adri\u00e1n Jarabo"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.05009"
  },
  {
    "id": "arXiv:2207.05016",
    "title": "Capacity Management in a Pandemic with Endogenous Patient Choices and  Flows",
    "abstract": "Motivated by the experiences of a healthcare service provider during the\nCovid-19 pandemic, we aim to study the decisions of a provider that operates\nboth an Emergency Department (ED) and a medical Clinic. Patients contact the\nprovider through a phone call or may present directly at the ED: patients can\nbe COVID (suspected/confirmed) or non-COVID, and have different severities.\nDepending on the severity, patients who contact the provider may be directed to\nthe ED (to be seen in a few hours), be offered an appointment at the Clinic (to\nbe seen in a few days), or be treated via phone or telemedicine, avoiding a\nvisit to a facility. All patients make joining decisions based on comparing\ntheir own risk perceptions versus their anticipated benefits: They then choose\nto enter a facility only if it is beneficial enough. Also, after initial\ncontact, their severities may evolve, which may change their decision. The\nhospital system's objective is to allocate service capacity across facilities\nso as to minimize costs from patient deaths or defections. We model the system\nusing a fluid approximation over multiple periods, possibly with different\ndemand profiles. While the feasible space for this problem can be extremely\ncomplex, it is amenable to decomposition into different sub-regions that can be\nanalyzed individually, the global optimal solution can be reached via provably\nparsimonious computational methods over a single period and over multiple\nperiods with different demand rates. Our analytical and computational results\nindicate that endogeneity results in non-trivial and non-intuitive capacity\nallocations that do not always prioritize high severity patients, for both\nsingle and multi-period settings.",
    "descriptor": "",
    "authors": [
      "Sanyukta Deshpande",
      "Lavanya Marla",
      "Alan Scheller-Wolf",
      "Siddharth Prakash Singh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.05016"
  },
  {
    "id": "arXiv:2207.05017",
    "title": "Almost optimum $\\ell$-covering of $\\mathbb{Z}_n$",
    "abstract": "A subset $B$ of ring $\\mathbb{Z}_n$ is called a $\\ell$-covering set if $\\{ ab\n\\pmod n \\mid 0\\leq a \\leq \\ell, b\\in B\\} = \\mathbb{Z}_n$. We show there exists\na $\\ell$-covering set of $\\mathbb{Z}_n$ of size $O(\\frac{n}{\\ell}\\log n)$ for\nall $n$ and $\\ell$, and how to construct such set. We also show examples where\nany $\\ell$-covering set must have size $\\Omega(\\frac{n}{\\ell}\\frac{\\log n}{\\log\n\\log n})$. The proof uses a refined bound for relative totient function\nobtained through sieve theory, and existence of a large divisor with linear\ndivisor sum.",
    "descriptor": "",
    "authors": [
      "Ke Shi",
      "Chao Xu"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.05017"
  },
  {
    "id": "arXiv:2207.05018",
    "title": "Learning Temporally Extended Skills in Continuous Domains as Symbolic  Actions for Planning",
    "abstract": "Problems which require both long-horizon planning and continuous control\ncapabilities pose significant challenges to existing reinforcement learning\nagents. In this paper we introduce a novel hierarchical reinforcement learning\nagent which links temporally extended skills for continuous control with a\nforward model in a symbolic discrete abstraction of the environment's state for\nplanning. We term our agent SEADS for Symbolic Effect-Aware Diverse Skills. We\nformulate an objective and corresponding algorithm which leads to unsupervised\nlearning of a diverse set of skills through intrinsic motivation given a known\nstate abstraction. The skills are jointly learned with the symbolic forward\nmodel which captures the effect of skill execution in the state abstraction.\nAfter training, we can leverage the skills as symbolic actions using the\nforward model for long-horizon planning and subsequently execute the plan using\nthe learned continuous-action control skills. The proposed algorithm learns\nskills and forward models that can be used to solve complex tasks which require\nboth continuous control and long-horizon planning capabilities with high\nsuccess rate. It compares favorably with other flat and hierarchical\nreinforcement learning baseline agents and is successfully demonstrated with a\nreal robot.",
    "descriptor": "\nComments: Project website (including video) is available at this https URL\n",
    "authors": [
      "Jan Achterhold",
      "Markus Krimmel",
      "Joerg Stueckler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.05018"
  },
  {
    "id": "arXiv:2207.05020",
    "title": "Reinforcement Learning$\\unicode{x2013}$Based Transient Response Shaping  for Microgrids",
    "abstract": "This work explores the usage of a supplementary controller for improving the\ntransient performance of inverter$\\unicode{x2013}$based resources (IBR) in\nmicrogrids. The supplementary controller is trained using a reinforcement\nlearning (RL)$\\unicode{x2013}$based algorithm to minimize transients in a power\nconverter connected to a microgrid. The controller works autonomously to issue\nadaptive, intermediate set points based on the current state and trajectory of\nthe observed or tracked variable. The ability of the designed controller to\nmitigate transients is verified on a medium voltage test system using\nPSCAD/EMTDC.",
    "descriptor": "\nComments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Ashwin Venkataramanan",
      "Ali Mehrizi-Sani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.05020"
  },
  {
    "id": "arXiv:2207.05022",
    "title": "Turbocharge Interactive NLP at the Edge",
    "abstract": "Natural Language Processing (NLP) inference is seeing increasing adoption by\nmobile applications, where on-device inference is desirable for crucially\npreserving user data privacy and avoiding network roundtrips. Yet, the\nunprecedented size of an NLP model stresses both latency and memory, the two\nkey resources of a mobile device. To meet a target latency, holding the whole\nmodel in memory launches execution as soon as possible but increases one app's\nmemory footprints by several times, limiting its benefits to only a few\ninferences before being recycled by mobile memory management. On the other\nhand, loading the model from storage on demand incurs a few seconds long IO,\nfar exceeding the delay range satisfying to a user; pipelining layerwise model\nloading and execution does not hide IO either, due to the large skewness\nbetween IO and computation delays.\nTo this end, we propose Speedy Transformer Inference (STI). Built on the key\nidea of maximizing IO/compute resource utilization on the most important parts\nof a model, STI reconciles the latency/memory tension via two novel techniques.\nFirst, model sharding. STI manages model parameters as independently tunable\nshards and profiles their importance to accuracy. Second, elastic pipeline\nplanning with a preload buffer. STI instantiates an IO/computation pipeline and\nuses a small buffer for preload shards to bootstrap execution without stalling\nin early stages; it judiciously selects, tunes, and assembles shards per their\nimportance for resource-elastic execution, which maximizes inference accuracy.\nAtop two commodity SoCs, we build STI and evaluate it against a wide range of\nNLP tasks, under a practical range of target latencies, and on both CPU and\nGPU. We demonstrate that, STI delivers high accuracies with 1--2 orders of\nmagnitude lower memory, outperforming competitive baselines.",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Liwei Guo",
      "Wonkyo Choe",
      "Felix Xiaozhu Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05022"
  },
  {
    "id": "arXiv:2207.05024",
    "title": "Intra-Modal Constraint Loss For Image-Text Retrieval",
    "abstract": "Cross-modal retrieval has drawn much attention in both computer vision and\nnatural language processing domains. With the development of convolutional and\nrecurrent neural networks, the bottleneck of retrieval across image-text\nmodalities is no longer the extraction of image and text features but an\nefficient loss function learning in embedding space. Many loss functions try to\ncloser pairwise features from heterogeneous modalities. This paper proposes a\nmethod for learning joint embedding of images and texts using an intra-modal\nconstraint loss function to reduce the violation of negative pairs from the\nsame homogeneous modality. Experimental results show that our approach\noutperforms state-of-the-art bi-directional image-text retrieval methods on\nFlickr30K and Microsoft COCO datasets. Our code is publicly available:\nhttps://github.com/CanonChen/IMC.",
    "descriptor": "",
    "authors": [
      "Jianan Chen",
      "Lu Zhang",
      "Qiong Wang",
      "Cong Bai",
      "Kidiyo Kpalma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.05024"
  },
  {
    "id": "arXiv:2207.05025",
    "title": "PSP-HDRI$+$: A Synthetic Dataset Generator for Pre-Training of  Human-Centric Computer Vision Models",
    "abstract": "We introduce a new synthetic data generator PSP-HDRI$+$ that proves to be a\nsuperior pre-training alternative to ImageNet and other large-scale synthetic\ndata counterparts. We demonstrate that pre-training with our synthetic data\nwill yield a more general model that performs better than alternatives even\nwhen tested on out-of-distribution (OOD) sets. Furthermore, using ablation\nstudies guided by person keypoint estimation metrics with an off-the-shelf\nmodel architecture, we show how to manipulate our synthetic data generator to\nfurther improve model performance.",
    "descriptor": "\nComments: PSP-HDRI$+$ template Unity environment, benchmark binaries, and source code will be made available at: this https URL\n",
    "authors": [
      "Salehe Erfanian Ebadi",
      "Saurav Dhakad",
      "Sanjay Vishwakarma",
      "Chunpu Wang",
      "You-Cyuan Jhang",
      "Maciek Chociej",
      "Adam Crespi",
      "Alex Thaman",
      "Sujoy Ganguly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05025"
  },
  {
    "id": "arXiv:2207.05027",
    "title": "Unsupervised Semantic Segmentation with Self-supervised Object-centric  Representations",
    "abstract": "In this paper, we show that recent advances in self-supervised feature\nlearning enable unsupervised object discovery and semantic segmentation with a\nperformance that matches the state of the field on supervised semantic\nsegmentation 10 years ago. We propose a methodology based on unsupervised\nsaliency masks and self-supervised feature clustering to kickstart object\ndiscovery followed by training a semantic segmentation network on pseudo-labels\nto bootstrap the system on images with multiple objects. We present results on\nPASCAL VOC that go far beyond the current state of the art (47.3 mIoU), and we\nreport for the first time results on MS COCO for the whole set of 81 classes:\nour method discovers 34 categories with more than $20\\%$ IoU, while obtaining\nan average IoU of 19.6 for all 81 categories.",
    "descriptor": "",
    "authors": [
      "Andrii Zadaianchuk",
      "Matthaeus Kleindessner",
      "Yi Zhu",
      "Francesco Locatello",
      "Thomas Brox"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.05027"
  },
  {
    "id": "arXiv:2207.05041",
    "title": "Parallel Bayesian Optimization of Agent-based Transportation Simulation",
    "abstract": "MATSim (Multi-Agent Transport Simulation Toolkit) is an open source\nlarge-scale agent-based transportation planning project applied to various\nareas like road transport, public transport, freight transport, regional\nevacuation, etc. BEAM (Behavior, Energy, Autonomy, and Mobility) framework\nextends MATSim to enable powerful and scalable analysis of urban transportation\nsystems. The agents from the BEAM simulation exhibit 'mode choice' behavior\nbased on multinomial logit model. In our study, we consider eight mode choices\nviz. bike, car, walk, ride hail, driving to transit, walking to transit, ride\nhail to transit, and ride hail pooling. The 'alternative specific constants'\nfor each mode choice are critical hyperparameters in a configuration file\nrelated to a particular scenario under experimentation. We use the\n'Urbansim-10k' BEAM scenario (with 10,000 population size) for all our\nexperiments. Since these hyperparameters affect the simulation in complex ways,\nmanual calibration methods are time consuming. We present a parallel Bayesian\noptimization method with early stopping rule to achieve fast convergence for\nthe given multi-in-multi-out problem to its optimal configurations. Our model\nis based on an open source HpBandSter package. This approach combines hierarchy\nof several 1D Kernel Density Estimators (KDE) with a cheap evaluator\n(Hyperband, a single multidimensional KDE). Our model has also incorporated\nextrapolation based early stopping rule. With our model, we could achieve a 25%\nL1 norm for a large-scale BEAM simulation in fully autonomous manner. To the\nbest of our knowledge, our work is the first of its kind applied to large-scale\nmulti-agent transportation simulations. This work can be useful for surrogate\nmodeling of scenarios with very large populations.",
    "descriptor": "\nComments: LOD'2022 (Nature Springer Computer Science Proceedings - LNCS)\n",
    "authors": [
      "Kiran Chhatre",
      "Sidney Feygin",
      "Colin Sheppard",
      "Rashid Waraich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2207.05041"
  },
  {
    "id": "arXiv:2207.05042",
    "title": "Audio-Visual Segmentation",
    "abstract": "We propose to explore a new problem called audio-visual segmentation (AVS),\nin which the goal is to output a pixel-level map of the object(s) that produce\nsound at the time of the image frame. To facilitate this research, we construct\nthe first audio-visual segmentation benchmark (AVSBench), providing pixel-wise\nannotations for the sounding objects in audible videos. Two settings are\nstudied with this benchmark: 1) semi-supervised audio-visual segmentation with\na single sound source and 2) fully-supervised audio-visual segmentation with\nmultiple sound sources. To deal with the AVS problem, we propose a novel method\nthat uses a temporal pixel-wise audio-visual interaction module to inject audio\nsemantics as guidance for the visual segmentation process. We also design a\nregularization loss to encourage the audio-visual mapping during training.\nQuantitative and qualitative experiments on the AVSBench compare our approach\nto several existing methods from related tasks, demonstrating that the proposed\nmethod is promising for building a bridge between the audio and pixel-wise\nvisual semantics. Code is available at https://github.com/OpenNLPLab/AVSBench.",
    "descriptor": "\nComments: Accepted to ECCV 2022; Jinxing Zhou and Jianyuan Wang contributed equally; Meng Wang and Yiran Zhong are corresponding authors; Code is available at this https URL\n",
    "authors": [
      "Jinxing Zhou",
      "Jianyuan Wang",
      "Jiayi Zhang",
      "Weixuan Sun",
      "Jing Zhang",
      "Stan Birchfield",
      "Dan Guo",
      "Lingpeng Kong",
      "Meng Wang",
      "Yiran Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.05042"
  },
  {
    "id": "arXiv:2207.05043",
    "title": "SLAM Backends with Objects in Motion: A Unifying Framework and Tutorial",
    "abstract": "Simultaneous Localization and Mapping (SLAM) algorithms are frequently\ndeployed to support a wide range of robotics applications, such as autonomous\nnavigation in unknown environments, and scene mapping in virtual reality. Many\nof these applications require the autonomous agents performing SLAM with highly\ndynamic objects in the scene. To this end, this tutorial extends a recently\nintroduced, unifying optimization-based SLAM backend framework to environments\nwith moving objects and features. Using this framework, we consider a\nrapprochement of recent advances in dynamic SLAM. Moreover, we present a novel,\nfiltering-based dynamic SLAM algorithm, named dynamic EKF SLAM within our\nframework, and prove that it is mathematically equivalent to a direct extension\nof the classical EKF SLAM algorithm to the dynamic environment setting.\nEmpirical results with simulated data indicate that dynamic EKF SLAM can\nachieve high localization and mobile object pose estimation accuracy, as well\nas high map precision.",
    "descriptor": "",
    "authors": [
      "Chih-Yuan Chiu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.05043"
  },
  {
    "id": "arXiv:2207.05047",
    "title": "MPC for Tech Giants (GMPC): Enabling Gulliver and the Lilliputians to  Cooperate Amicably",
    "abstract": "In this work, we introduce the Gulliver multi-party computation model (GMPC).\nThe GMPC model considers a single highly powerful party, called the server or\nGulliver, that is connected to $n$ users over a star topology network\n(alternatively formulated as a full network, where the server can block any\nmessage). The users are significantly less powerful than the server, and, in\nparticular, should have both computation and communication complexities that\nare polylogarithmic in $n$. Protocols in the GMPC model should be secure\nagainst malicious adversaries that may corrupt a subset of the users and/or the\nserver.\nDesigning protocols in the GMPC model is a delicate task, since users can\nonly hold information about polylog(n) other users (and, in particular, can\nonly communicate with polylog(n) other users). In addition, the server can\nblock any message between any pair of honest parties. Thus, reaching an\nagreement becomes a challenging task. Nevertheless, we design generic protocols\nin the GMPC model, assuming that at most $\\alpha<1/6$ fraction of the users may\nbe corrupted (in addition to the server). Our main contribution is a variant of\nFeige's committee election protocol [FOCS 1999] that is secure in the GMPC\nmodel. Given this tool we show:\n1. Assuming fully homomorphic encryption (FHE), any computationally efficient\nfunction with $O\\left(n\\cdot polylog(n)\\right)$-size output can be securely\ncomputed in the GMPC model.\n2. Any function that can be computed by a circuit of $O(polylog(n))$ depth,\n$O\\left(n\\cdot polylog(n)\\right)$ size, and bounded fan-in and fan-out can be\nsecurely computed in the GMPC model without assuming FHE.\n3. In particular, sorting can be securely computed in the GMPC model without\nassuming FHE. This has important applications for the shuffle model of\ndifferential privacy, and resolves an open question of Bell et al. [CCS 2020].",
    "descriptor": "",
    "authors": [
      "Bar Alon",
      "Moni Naor",
      "Eran Omri",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.05047"
  },
  {
    "id": "arXiv:2207.05049",
    "title": "Fast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis",
    "abstract": "Video-to-Video synthesis (Vid2Vid) has achieved remarkable results in\ngenerating a photo-realistic video from a sequence of semantic maps. However,\nthis pipeline suffers from high computational cost and long inference latency,\nwhich largely depends on two essential factors: 1) network architecture\nparameters, 2) sequential data stream. Recently, the parameters of image-based\ngenerative models have been significantly compressed via more efficient network\narchitectures. Nevertheless, existing methods mainly focus on slimming network\narchitectures and ignore the size of the sequential data stream. Moreover, due\nto the lack of temporal coherence, image-based compression is not sufficient\nfor the compression of the video task. In this paper, we present a\nspatial-temporal compression framework, \\textbf{Fast-Vid2Vid}, which focuses on\ndata aspects of generative models. It makes the first attempt at time dimension\nto reduce computational resources and accelerate inference. Specifically, we\ncompress the input data stream spatially and reduce the temporal redundancy.\nAfter the proposed spatial-temporal knowledge distillation, our model can\nsynthesize key-frames using the low-resolution data stream. Finally,\nFast-Vid2Vid interpolates intermediate frames by motion compensation with\nslight latency. On standard benchmarks, Fast-Vid2Vid achieves around real-time\nperformance as 20 FPS and saves around 8x computational cost on a single V100\nGPU.",
    "descriptor": "\nComments: ECCV 2022, Project Page: this https URL , Code: this https URL\n",
    "authors": [
      "Long Zhuo",
      "Guangcong Wang",
      "Shikai Li",
      "Wayne Wu",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.05049"
  },
  {
    "id": "arXiv:2207.05050",
    "title": "A Federated Cox Model with Non-Proportional Hazards",
    "abstract": "Recent research has shown the potential for neural networks to improve upon\nclassical survival models such as the Cox model, which is widely used in\nclinical practice. Neural networks, however, typically rely on data that are\ncentrally available, whereas healthcare data are frequently held in secure\nsilos. We present a federated Cox model that accommodates this data setting and\nalso relaxes the proportional hazards assumption, allowing time-varying\ncovariate effects. In this latter respect, our model does not require explicit\nspecification of the time-varying effects, reducing upfront organisational\ncosts compared to previous works. We experiment with publicly available\nclinical datasets and demonstrate that the federated model is able to perform\nas well as a standard model.",
    "descriptor": "\nComments: Accepted for publication in Multimodal AI in Healthcare: A Paradigm Shift in Health Intelligence as part of the book series Studies in Computational Intelligence by Springer\n",
    "authors": [
      "Dekai Zhang",
      "Francesca Toni",
      "Matthew Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.05050"
  },
  {
    "id": "arXiv:2207.05053",
    "title": "Learning Continuous Grasping Function with a Dexterous Hand from Human  Demonstrations",
    "abstract": "We propose to learn to generate grasping motion for manipulation with a\ndexterous hand using implicit functions. With continuous time inputs, the model\ncan generate a continuous and smooth grasping plan. We name the proposed model\nContinuous Grasping Function (CGF). CGF is learned via generative modeling with\na Conditional Variational Autoencoder using 3D human demonstrations. We will\nfirst convert the large-scale human-object interaction trajectories to robot\ndemonstrations via motion retargeting, and then use these demonstrations to\ntrain CGF. During inference, we perform sampling with CGF to generate different\ngrasping plans in the simulator and select the successful ones to transfer to\nthe real robot. By training on diverse human data, our CGF allows\ngeneralization to manipulate multiple objects. Compared to previous planning\nalgorithms, CGF is more efficient and achieves significant improvement on\nsuccess rate when transferred to grasping with the real Allegro Hand. Our\nproject page is at https://jianglongye.com/cgf",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Jianglong Ye",
      "Jiashun Wang",
      "Binghao Huang",
      "Yuzhe Qin",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05053"
  },
  {
    "id": "arXiv:2207.05054",
    "title": "Demystifying Unsupervised Semantic Correspondence Estimation",
    "abstract": "We explore semantic correspondence estimation through the lens of\nunsupervised learning. We thoroughly evaluate several recently proposed\nunsupervised methods across multiple challenging datasets using a standardized\nevaluation protocol where we vary factors such as the backbone architecture,\nthe pre-training strategy, and the pre-training and finetuning datasets. To\nbetter understand the failure modes of these methods, and in order to provide a\nclearer path for improvement, we provide a new diagnostic framework along with\na new performance metric that is better suited to the semantic matching task.\nFinally, we introduce a new unsupervised correspondence approach which utilizes\nthe strength of pre-trained features while encouraging better matches during\ntraining. This results in significantly better matching performance compared to\ncurrent state-of-the-art methods.",
    "descriptor": "\nComments: ECCV22, project page this https URL\n",
    "authors": [
      "Mehmet Ayg\u00fcn",
      "Oisin Mac Aodha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05054"
  },
  {
    "id": "arXiv:2207.04081",
    "title": "Graph-based Multi-View Fusion and Local Adaptation: Mitigating  Within-Household Confusability for Speaker Identification",
    "abstract": "Speaker identification (SID) in the household scenario (e.g., for smart\nspeakers) is an important but challenging problem due to limited number of\nlabeled (enrollment) utterances, confusable voices, and demographic imbalances.\nConventional speaker recognition systems generalize from a large random sample\nof speakers, causing the recognition to underperform for households drawn from\nspecific cohorts or otherwise exhibiting high confusability. In this work, we\npropose a graph-based semi-supervised learning approach to improve\nhousehold-level SID accuracy and robustness with locally adapted graph\nnormalization and multi-signal fusion with multi-view graphs. Unlike other work\non household SID, fairness, and signal fusion, this work focuses on speaker\nlabel inference (scoring) and provides a simple solution to realize\nhousehold-specific adaptation and multi-signal fusion without tuning the\nembeddings or training a fusion network. Experiments on the VoxCeleb dataset\ndemonstrate that our approach consistently improves the performance across\nhouseholds with different customer cohorts and degrees of confusability.",
    "descriptor": "\nComments: To appear in Interspeech 2022. arXiv admin note: text overlap with arXiv:2106.08207\n",
    "authors": [
      "Long Chen",
      "Yixiong Meng",
      "Venkatesh Ravichandran",
      "Andreas Stolcke"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.04081"
  },
  {
    "id": "arXiv:2207.04090",
    "title": "FAIVConf: Face enhancement for AI-based Video Conference with Low  Bit-rate",
    "abstract": "Recently, high-quality video conferencing with fewer transmission bits has\nbecome a very hot and challenging problem. We propose FAIVConf, a specially\ndesigned video compression framework for video conferencing, based on the\neffective neural human face generation techniques. FAIVConf brings together\nseveral designs to improve the system robustness in real video conference\nscenarios: face-swapping to avoid artifacts in background animation; facial\nblurring to decrease transmission bit-rate and maintain the quality of\nextracted facial landmarks; and dynamic source update for face view\ninterpolation to accommodate a large range of head poses. Our method achieves a\nsignificant bit-rate reduction in the video conference and gives much better\nvisual quality under the same bit-rate compared with H.264 and H.265 coding\nschemes.",
    "descriptor": "\nComments: ICME 2022\n",
    "authors": [
      "Zhengang Li",
      "Sheng Lin",
      "Shan Liu",
      "Songnan Li",
      "Xue Lin",
      "Wei Wang",
      "Wei Jiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04090"
  },
  {
    "id": "arXiv:2207.04130",
    "title": "Multi-view Attention for gestational age at birth prediction",
    "abstract": "We present our method for gestational age at birth prediction for the SLCN\n(surface learning for clinical neuroimaging) challenge. Our method is based on\na multi-view shape analysis technique that captures 2D renderings of a 3D\nobject from different viewpoints. We render the brain features on the surface\nof the sphere and then the 2D images are analyzed via 2D CNNs and an attention\nlayer for the regression task. The regression task achieves a MAE of 1.637 +-\n1.3 on the Native space and MAE of 1.38 +- 1.14 on the template space. The\nsource code for this project is available in our github repository\nhttps://github.com/MathieuLeclercq/SLCN_challenge_UNC",
    "descriptor": "\nComments: 7 pages, 5 figures, 1 table\n",
    "authors": [
      "Mathieu Leclercq",
      "Martin Styner",
      "Juan Carlos Prieto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04130"
  },
  {
    "id": "arXiv:2207.04173",
    "title": "Stochastic approximation with decision-dependent distributions:  asymptotic normality and optimality",
    "abstract": "We analyze a stochastic approximation algorithm for decision-dependent\nproblems, wherein the data distribution used by the algorithm evolves along the\niterate sequence. The primary examples of such problems appear in performative\nprediction and its multiplayer extensions. We show that under mild assumptions,\nthe deviation between the average iterate of the algorithm and the solution is\nasymptotically normal, with a covariance that nicely decouples the effects of\nthe gradient noise and the distributional shift. Moreover, building on the work\nof H\\'ajek and Le Cam, we show that the asymptotic performance of the algorithm\nis locally minimax optimal.",
    "descriptor": "\nComments: 35 pages, 1 figure\n",
    "authors": [
      "Joshua Cutler",
      "Mateo D\u00edaz",
      "Dmitriy Drusvyatskiy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.04173"
  },
  {
    "id": "arXiv:2207.04176",
    "title": "Internal Language Model Estimation based Language Model Fusion for  Cross-Domain Code-Switching Speech Recognition",
    "abstract": "Internal Language Model Estimation (ILME) based language model (LM) fusion\nhas been shown significantly improved recognition results over conventional\nshallow fusion in both intra-domain and cross-domain speech recognition tasks.\nIn this paper, we attempt to apply our ILME method to cross-domain\ncode-switching speech recognition (CSSR) work. Specifically, our curiosity\ncomes from several aspects. First, we are curious about how effective the\nILME-based LM fusion is for both intra-domain and cross-domain CSSR tasks. We\nverify this with or without merging two code-switching domains. More\nimportantly, we train an end-to-end (E2E) speech recognition model by means of\nmerging two monolingual data sets and observe the efficacy of the proposed\nILME-based LM fusion for CSSR. Experimental results on SEAME that is from\nSoutheast Asian and another Chinese Mainland CS data set demonstrate the\neffectiveness of the proposed ILME-based LM fusion method.",
    "descriptor": "\nComments: 5 pages. Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Yizhou Peng",
      "Yufei Liu",
      "Jicheng Zhang",
      "Haihua Xu",
      "Yi He",
      "Hao Huang",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.04176"
  },
  {
    "id": "arXiv:2207.04177",
    "title": "Intermediate-layer output Regularization for Attention-based Speech  Recognition with Shared Decoder",
    "abstract": "Intermediate layer output (ILO) regularization by means of multitask training\non encoder side has been shown to be an effective approach to yielding improved\nresults on a wide range of end-to-end ASR frameworks. In this paper, we propose\na novel method to do ILO regularized training differently. Instead of using\nconventional multitask methods that entail more training overhead, we directly\nmake the intermediate layer output as input to the decoder, that is, our\ndecoder not only accepts the output of the final encoder layer as input, it\nalso takes the output of the encoder ILO as input during training. With the\nproposed method, as both encoder and decoder are simultaneously \"regularized\",\nthe network is more sufficiently trained, consistently leading to improved\nresults, over the ILO-based CTC method, as well as over the original\nattention-based modeling method without the proposed method employed.",
    "descriptor": "\nComments: 5 pages. Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Jicheng Zhang",
      "Yizhou Peng",
      "Haihua Xu",
      "Yi He",
      "Eng Siong Chng",
      "Hao Huang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.04177"
  },
  {
    "id": "arXiv:2207.04212",
    "title": "COVID-19 Disease Identification on Chest-CT images using CNN and VGG16",
    "abstract": "A newly identified coronavirus disease called COVID-19 mainly affects the\nhuman respiratory system. COVID-19 is an infectious disease caused by a virus\noriginating in Wuhan, China, in December 2019. Early diagnosis is the primary\nchallenge of health care providers. In the earlier stage, medical organizations\nwere dazzled because there were no proper health aids or medicine to detect a\nCOVID-19. A new diagnostic tool RT-PCR (Reverse Transcription Polymerase Chain\nReaction), was introduced. It collects swab specimens from the patient's nose\nor throat, where the COVID-19 virus gathers. This method has some limitations\nrelated to accuracy and testing time. Medical experts suggest an alternative\napproach called CT (Computed Tomography) that can quickly diagnose the infected\nlung areas and identify the COVID-19 in an earlier stage. Using chest CT\nimages, computer researchers developed several deep learning models identifying\nthe COVID-19 disease. This study presents a Convolutional Neural Network (CNN)\nand VGG16-based model for automated COVID-19 identification on chest CT images.\nThe experimental results using a public dataset of 14320 CT images showed a\nclassification accuracy of 96.34% and 96.99% for CNN and VGG16, respectively.",
    "descriptor": "",
    "authors": [
      "Briskline Kiruba S",
      "Petchiammal A",
      "D. Murugan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04212"
  },
  {
    "id": "arXiv:2207.04248",
    "title": "A Statistically-Based Approach to Feedforward Neural Network Model  Selection",
    "abstract": "Feedforward neural networks (FNNs) can be viewed as non-linear regression\nmodels, where covariates enter the model through a combination of weighted\nsummations and non-linear functions. Although these models have some\nsimilarities to the models typically used in statistical modelling, the\nmajority of neural network research has been conducted outside of the field of\nstatistics. This has resulted in a lack of statistically-based methodology,\nand, in particular, there has been little emphasis on model parsimony.\nDetermining the input layer structure is analogous to variable selection, while\nthe structure for the hidden layer relates to model complexity. In practice,\nneural network model selection is often carried out by comparing models using\nout-of-sample performance. However, in contrast, the construction of an\nassociated likelihood function opens the door to information-criteria-based\nvariable and architecture selection. A novel model selection method, which\nperforms both input- and hidden-node selection, is proposed using the Bayesian\ninformation criterion (BIC) for FNNs. The choice of BIC over out-of-sample\nperformance as the model selection objective function leads to an increased\nprobability of recovering the true model, while parsimoniously achieving\nfavourable out-of-sample performance. Simulation studies are used to evaluate\nand justify the proposed method, and applications on real data are\ninvestigated.",
    "descriptor": "",
    "authors": [
      "Andrew McInerney",
      "Kevin Burke"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04248"
  },
  {
    "id": "arXiv:2207.04261",
    "title": "Fuzzy Clustering by Hyperbolic Smoothing",
    "abstract": "We propose a novel method for building fuzzy clusters of large data sets,\nusing a smoothing numerical approach. The usual sum-of-squares criterion is\nrelaxed so the search for good fuzzy partitions is made on a continuous space,\nrather than a combinatorial space as in classical methods \\cite{Hartigan}. The\nsmoothing allows a conversion from a strongly non-differentiable problem into\ndifferentiable subproblems of optimization without constraints of low\ndimension, by using a differentiable function of infinite class. For the\nimplementation of the algorithm we used the statistical software $R$ and the\nresults obtained were compared to the traditional fuzzy $C$--means method,\nproposed by Bezdek.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "David Masis",
      "Esteban Segura",
      "Javier Trejos",
      "Adilson Xavier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04261"
  },
  {
    "id": "arXiv:2207.04266",
    "title": "Rank-Enhanced Low-Dimensional Convolution Set for Hyperspectral Image  Denoising",
    "abstract": "This paper tackles the challenging problem of hyperspectral (HS) image\ndenoising. Unlike existing deep learning-based methods usually adopting\ncomplicated network architectures or empirically stacking off-the-shelf modules\nto pursue performance improvement, we focus on the efficient and effective\nfeature extraction manner for capturing the high-dimensional characteristics of\nHS images. To be specific, based on the theoretical analysis that increasing\nthe rank of the matrix formed by the unfolded convolutional kernels can promote\nfeature diversity, we propose rank-enhanced low-dimensional convolution set\n(Re-ConvSet), which separately performs 1-D convolution along the three\ndimensions of an HS image side-by-side, and then aggregates the resulting\nspatial-spectral embeddings via a learnable compression layer. Re-ConvSet not\nonly learns the diverse spatial-spectral features of HS images, but also\nreduces the parameters and complexity of the network. We then incorporate\nRe-ConvSet into the widely-used U-Net architecture to construct an HS image\ndenoising method. Surprisingly, we observe such a concise framework outperforms\nthe most recent method to a large extent in terms of quantitative metrics,\nvisual results, and efficiency. We believe our work may shed light on deep\nlearning-based HS image processing and analysis.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Jinhui Hou",
      "Zhiyu Zhu",
      "Hui Liu",
      "Junhui Hou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04266"
  },
  {
    "id": "arXiv:2207.04289",
    "title": "Bit complexity for computing one point in each connected component of a  smooth real algebraic set",
    "abstract": "We analyze the bit complexity of an algorithm for the computation of at least\none point in each connected component of a smooth real algebraic set. This work\nis a continuation of our analysis of the hypersurface case (On the bit\ncomplexity of finding points in connected components of a smooth real\nhypersurface, ISSAC'20). In this paper, we extend the analysis to more general\ncases.\nLet $F=(f_1,..., f_p)$ in $\\mathbb{Z}[X_1, ... , X_n]^p$ be a sequence of\npolynomials with $V = V(F) \\subset \\mathbb{C}^n$ a smooth and equidimensional\nvariety and $\\langle F \\rangle \\subset \\mathbb{C}[X_1, ..., X_n]$ a radical\nideal. To compute at least one point in each connected component of $V \\cap\n\\mathbb{R}^n$, our starting point is an algorithm by Safey El Din and Schost\n(Polar varieties and computation of one point in each connected component of a\nsmooth real algebraic set, ISSAC'03). This algorithm uses random changes of\nvariables that are proven to generically ensure certain desirable geometric\nproperties. The cost of the algorithm was given in an algebraic complexity\nmodel; here, we analyze the bit complexity and the error probability, and we\nprovide a quantitative analysis of the genericity statements. In particular, we\nare led to use Lagrange systems to describe polar varieties, as they make it\nsimpler to rely on techniques such as weak transversality and an effective\nNullstellensatz.",
    "descriptor": "\nComments: Journal of Symbolic Computation, to appear\n",
    "authors": [
      "Jesse Elliott",
      "Mark Giesbrecht",
      "Eric Schost"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2207.04289"
  },
  {
    "id": "arXiv:2207.04324",
    "title": "Video Coding Using Learned Latent GAN Compression",
    "abstract": "We propose in this paper a new paradigm for facial video compression. We\nleverage the generative capacity of GANs such as StyleGAN to represent and\ncompress a video, including intra and inter compression. Each frame is inverted\nin the latent space of StyleGAN, from which the optimal compression is learned.\nTo do so, a diffeomorphic latent representation is learned using a normalizing\nflows model, where an entropy model can be optimized for image coding. In\naddition, we propose a new perceptual loss that is more efficient than other\ncounterparts. Finally, an entropy model for video inter coding with residual is\nalso learned in the previously constructed latent representation. Our method\n(SGANC) is simple, faster to train, and achieves better results for image and\nvideo coding compared to state-of-the-art codecs such as VTM, AV1, and recent\ndeep learning techniques. In particular, it drastically minimizes perceptual\ndistortion at low bit rates.",
    "descriptor": "\nComments: Accepted at ACM Multimedia 2022\n",
    "authors": [
      "Mustafa Shukor",
      "Bharath Bushan Damodaran",
      "Xu Yao",
      "Pierre Hellier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.04324"
  },
  {
    "id": "arXiv:2207.04333",
    "title": "Emerging Patterns in the Continuum Representation of Protein-Lipid  Fingerprints",
    "abstract": "Capturing intricate biological phenomena often requires multiscale modeling\nwhere coarse and inexpensive models are developed using limited components of\nexpensive and high-fidelity models. Here, we consider such a multiscale\nframework in the context of cancer biology and address the challenge of\nevaluating the descriptive capabilities of a continuum model developed using\n1-dimensional statistics from a molecular dynamics model. Using deep learning,\nwe develop a highly predictive classification model that identifies complex and\nemergent behavior from the continuum model. With over 99.9% accuracy\ndemonstrated for two simulations, our approach confirms the existence of\nprotein-specific \"lipid fingerprints\", i.e. spatial rearrangements of lipids in\nresponse to proteins of interest. Through this demonstration, our model also\nprovides external validation of the continuum model, affirms the value of such\nmultiscale modeling, and can foster new insights through further analysis of\nthese fingerprints.",
    "descriptor": "",
    "authors": [
      "Konstantia Georgouli",
      "Helgi I Ing\u00f3lfsson",
      "Fikret Aydin",
      "Mark Heimann",
      "Felice C Lightstone",
      "Peer-Timo Bremer",
      "Harsh Bhatia"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04333"
  },
  {
    "id": "arXiv:2207.04334",
    "title": "Polyhedral Estimation of L-1 and L-infinity Incremental Gains of  Nonlinear Systems",
    "abstract": "We provide novel dissipativity conditions for bounding the incremental L-1\ngain of systems. Moreover, we adapt existing results on the L-infinity gain to\nthe incremental setting and relate the incremental L-1 and L-infinity gain\nbounds through system adjoints. Building on work on optimization based\napproaches to constructing polyhedral Lyapunov functions, we make use of these\nconditions to obtain a Linear Programming based algorithm that can provide\nincreasingly sharp bounds on the gains as a function of a given candidate\npolyhedral storage function or polyhedral set. The algorithm is also extended\nto allow for the design of linear feedback controllers for performance, as\nmeasured by the bounds on the incremental gains. We apply the algorithm to a\ncouple of numerical examples to illustrate the power, as well as some\nlimitations, of this approach.",
    "descriptor": "",
    "authors": [
      "Dimitris Kousoulidis",
      "Fulvio Forni"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04334"
  },
  {
    "id": "arXiv:2207.04345",
    "title": "Segmentation of Blood Vessels, Optic Disc Localization, Detection of  Exudates and Diabetic Retinopathy Diagnosis from Digital Fundus Images",
    "abstract": "Diabetic Retinopathy (DR) is a complication of long-standing, unchecked\ndiabetes and one of the leading causes of blindness in the world. This paper\nfocuses on improved and robust methods to extract some of the features of DR,\nviz. Blood Vessels and Exudates. Blood vessels are segmented using multiple\nmorphological and thresholding operations. For the segmentation of exudates,\nk-means clustering and contour detection on the original images are used.\nExtensive noise reduction is performed to remove false positives from the\nvessel segmentation algorithm's results. The localization of Optic Disc using\nk-means clustering and template matching is also performed. Lastly, this paper\npresents a Deep Convolutional Neural Network (DCNN) model with 14 Convolutional\nLayers and 2 Fully Connected Layers, for the automatic, binary diagnosis of DR.\nThe vessel segmentation, optic disc localization and DCNN achieve accuracies of\n95.93%, 98.77% and 75.73% respectively. The source code and pre-trained model\nare available https://github.com/Sohambasu07/DR_2021",
    "descriptor": "\nComments: RAAI 2020, 11 pages, 12 figures, 2 tables\n",
    "authors": [
      "Soham Basu",
      "Sayantan Mukherjee",
      "Ankit Bhattacharya",
      "Anindya Sen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04345"
  },
  {
    "id": "arXiv:2207.04387",
    "title": "Bregman Proximal Langevin Monte Carlo via Bregman--Moreau Envelopes",
    "abstract": "We propose efficient Langevin Monte Carlo algorithms for sampling\ndistributions with nonsmooth convex composite potentials, which is the sum of a\ncontinuously differentiable function and a possibly nonsmooth function. We\ndevise such algorithms leveraging recent advances in convex analysis and\noptimization methods involving Bregman divergences, namely the Bregman--Moreau\nenvelopes and the Bregman proximity operators, and in the Langevin Monte Carlo\nalgorithms reminiscent of mirror descent. The proposed algorithms extend\nexisting Langevin Monte Carlo algorithms in two aspects -- the ability to\nsample nonsmooth distributions with mirror descent-like algorithms, and the use\nof the more general Bregman--Moreau envelope in place of the Moreau envelope as\na smooth approximation of the nonsmooth part of the potential. A particular\ncase of the proposed scheme is reminiscent of the Bregman proximal gradient\nalgorithm. The efficiency of the proposed methodology is illustrated with\nvarious sampling tasks at which existing Langevin Monte Carlo methods are known\nto perform poorly.",
    "descriptor": "\nComments: Proceeding of the 39th International Conference on Machine Learning (ICML), Baltimore, Maryland, USA, PMLR 162, 2022\n",
    "authors": [
      "Tim Tsz-Kit Lau",
      "Han Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.04387"
  },
  {
    "id": "arXiv:2207.04413",
    "title": "A numerical analysis of planar central and balanced configurations in  the (n+1)-body problem with a small mass",
    "abstract": "Two numerical algorithms for analyzing planar central and balanced\nconfigurations in the $(n+1)$-body problem with a small mass are presented. The\nfirst one relies on a direct solution method of the $(n+1)$-body problem by\nusing a stochastic optimization approach, while the second one relies on an\nanalytic-continuation method, which involves the solutions of the $n$-body and\nthe restricted $(n+1)$-body problem, and the application of a local search\nprocedure to compute the final $(n+1)$-body configuration in the neighborhood\nof the configuration obtained at the first two steps. Some exemplary central\nand balanced configurations in the cases $n=4,5,6$ are shown.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Alexandru Doicu",
      "Lei Zhao",
      "Adrian Doicu"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04413"
  },
  {
    "id": "arXiv:2207.04475",
    "title": "Finite-time High-probability Bounds for Polyak-Ruppert Averaged Iterates  of Linear Stochastic Approximation",
    "abstract": "This paper provides a finite-time analysis of linear stochastic approximation\n(LSA) algorithms with fixed step size, a core method in statistics and machine\nlearning. LSA is used to compute approximate solutions of a $d$-dimensional\nlinear system $\\bar{\\mathbf{A}} \\theta = \\bar{\\mathbf{b}}$, for which\n$(\\bar{\\mathbf{A}}, \\bar{\\mathbf{b}})$ can only be estimated through\n(asymptotically) unbiased observations\n$\\{(\\mathbf{A}(Z_n),\\mathbf{b}(Z_n))\\}_{n \\in \\mathbb{N}}$. We consider here\nthe case where $\\{Z_n\\}_{n \\in \\mathbb{N}}$ is an i.i.d. sequence or a\nuniformly geometrically ergodic Markov chain, and derive $p$-moments inequality\nand high probability bounds for the iterates defined by LSA and its\nPolyak-Ruppert averaged version. More precisely, we establish bounds of order\n$(p \\alpha t_{\\operatorname{mix}})^{1/2}d^{1/p}$ on the $p$-th moment of the\nlast iterate of LSA. In this formula $\\alpha$ is the step size of the procedure\nand $t_{\\operatorname{mix}}$ is the mixing time of the underlying chain\n($t_{\\operatorname{mix}}=1$ in the i.i.d. setting). We then prove finite-time\ninstance-dependent bounds on the Polyak-Ruppert averaged sequence of iterates.\nThese results are sharp in the sense that the leading term we obtain matches\nthe local asymptotic minimax limit, including tight dependence on the\nparameters $(d,t_{\\operatorname{mix}})$ in the higher order terms.",
    "descriptor": "",
    "authors": [
      "Alain Durmus",
      "Eric Moulines",
      "Alexey Naumov",
      "Sergey Samsonov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.04475"
  },
  {
    "id": "arXiv:2207.04480",
    "title": "Strategic Choices of Migrants and Smugglers in the Central Mediterranean  Sea",
    "abstract": "The sea crossing from Libya to Italy is one of the world's most dangerous and\npolitically contentious migration routes, and yet over half a million people\nhave attempted the crossing since 2014. Leveraging data on aggregate migration\nflows and individual migration incidents, we estimate how migrants and\nsmugglers have reacted to changes in border enforcement, namely the rise in\ninterceptions by the Libyan Coast Guard starting in 2017 and the corresponding\ndecrease in the probability of rescue at sea. We find support for a deterrence\neffect in which attempted crossings along the Central Mediterranean route\ndeclined, and a diversion effect in which some migrants substituted to the\nWestern Mediterranean route. At the same time, smugglers adapted their tactics.\nUsing a strategic model of the smuggler's choice of boat size, we estimate how\nsmugglers trade off between the short-run payoffs to launching overcrowded\nboats and the long-run costs of making less successful crossing attempts under\ndifferent levels of enforcement. Taken together, these analyses shed light on\nhow the integration of incident- and flow-level datasets can inform ongoing\nmigration policy debates and identify potential consequences of changing\nenforcement regimes.",
    "descriptor": "",
    "authors": [
      "Katherine Hoffmann Pham",
      "Junpei Komiyama"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.04480"
  },
  {
    "id": "arXiv:2207.04487",
    "title": "Automatic differentiation and the optimization of differential equation  models in biology",
    "abstract": "A computational revolution unleashed the power of artificial neural networks.\nAt the heart of that revolution is automatic differentiation, which calculates\nthe derivative of a performance measure relative to a large number of\nparameters. Differentiation enhances the discovery of improved performance in\nlarge models, an achievement that was previously difficult or impossible.\nRecently, a second computational advance optimizes the temporal trajectories\ntraced by differential equations. Optimization requires differentiating a\nmeasure of performance over a trajectory, such as the closeness of tracking the\nenvironment, with respect to the parameters of the differential equations.\nBecause model trajectories are usually calculated numerically by multistep\nalgorithms, such as Runge-Kutta, the automatic differentiation must be passed\nthrough the numerical algorithm. This article explains how such automatic\ndifferentiation of trajectories is achieved. It also discusses why such\ncomputational breakthroughs are likely to advance theoretical and statistical\nstudies of biological problems, in which one can consider variables as dynamic\npaths over time and space. Many common problems arise between improving success\nin computational learning models over performance landscapes, improving\nevolutionary fitness over adaptive landscapes, and improving statistical fits\nto data over information landscapes.",
    "descriptor": "",
    "authors": [
      "Steven A. Frank"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04487"
  },
  {
    "id": "arXiv:2207.04492",
    "title": "On finite termination of the generalized Newton method for solving  absolute value equations",
    "abstract": "Motivated by the framework constructed by Brugnano and Casulli $[$SIAM J.\nSci. Comput. 30: 463--472, 2008$]$, we analyze the finite termination property\nof the generalized Netwon method (GNM) for solving the absolute value equation\n(AVE). More precisely, for some special matrices, GNM is terminated in at most\n$2n + 2$ iterations. A new result for the unique solvability and unsolvability\nof the AVE is obtained. Numerical experiments are given to demonstrate the\ntheoretical analysis.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Jia Tang",
      "Wenli Zheng",
      "Cairong Chen",
      "Dongmei Yu",
      "Deren Han"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04492"
  },
  {
    "id": "arXiv:2207.04496",
    "title": "A Forward Propagation Algorithm for Online Optimization of Nonlinear  Stochastic Differential Equations",
    "abstract": "Optimizing over the stationary distribution of stochastic differential\nequations (SDEs) is computationally challenging. A new forward propagation\nalgorithm has been recently proposed for the online optimization of SDEs. The\nalgorithm solves an SDE, derived using forward differentiation, which provides\na stochastic estimate for the gradient. The algorithm continuously updates the\nSDE model's parameters and the gradient estimate simultaneously. This paper\nstudies the convergence of the forward propagation algorithm for nonlinear\ndissipative SDEs. We leverage the ergodicity of this class of nonlinear SDEs to\ncharacterize the convergence rate of the transition semi-group and its\nderivatives. Then, we prove bounds on the solution of a Poisson partial\ndifferential equation (PDE) for the expected time integral of the algorithm's\nstochastic fluctuations around the direction of steepest descent. We then\nre-write the algorithm using the PDE solution, which allows us to characterize\nthe parameter evolution around the direction of steepest descent. Our main\nresult is a convergence theorem for the forward propagation algorithm for\nnonlinear dissipative SDEs.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2202.06637\n",
    "authors": [
      "Ziheng Wang",
      "Justin Sirignano"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.04496"
  },
  {
    "id": "arXiv:2207.04514",
    "title": "Large independent sets in Markov random graphs",
    "abstract": "Computing the maximum size of an independent set in a graph is a famously\nhard combinatorial problem. There have been many analyses for the classical\nbinomial random graph model of Erd\\\"os-R\\'enyi-Gilbert and as a result, tight\nasymptotic bounds are known for these graphs. However, this classical model\ndoes not capture any dependency structure between edges that is widely\nprevalent in real-world networks. We initiate study in this direction by\nconsidering random graphs whose existence of edges is determined by a Markov\nprocess that is also governed by a decay parameter $\\delta\\in(0,1]$. We prove\nthat the maximum size of an independent set in such an $n$-vertex random graph\nis with high probability lower bounded by $(\\frac{1-\\delta}{2+\\epsilon})\n\\pi(n)$ for arbitrary $\\epsilon > 0$, where $\\pi(n)$ is the prime-counting\nfunction, and upper bounded by $c_{\\delta} n$, where $c_{\\delta} := e^{-\\delta}\n+ \\delta/10$ is an explicit constant. Since our random graph model collapses to\nthe classical binomial random graph model when there is no decay (i.e.,\n$\\delta=1$) and the latter are known to have independent sets roughly be of\nsize no more than $\\log{n}$, it follows from our lower bound that having even\nthe slightest bit of dependency in the random graph construction leads to the\npresence of large independent sets and thus our random model has a phase\ntransition at its boundary value. We also prove that a greedy algorithm for\nfinding a maximal independent set gives w.h.p. an output of size\n$\\Omega(n^{1/(1+\\tau)})$ where $\\tau=\\lceil 1/(1-\\delta) \\rceil$.",
    "descriptor": "",
    "authors": [
      "Akshay Gupte",
      "Yiran Zhu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2207.04514"
  },
  {
    "id": "arXiv:2207.04520",
    "title": "Local Area Routes for Vehicle Routing Problems",
    "abstract": "We consider an approach for improving the efficiency of column generation\n(CG) methods for solving vehicle routing problems. We introduce Local Area (LA)\nroute relaxations, an alternative/complement to the commonly used ng-route\nrelaxations and Decremental State Space Relaxations (DSSR) inside of CG\nformulations. LA routes are a subset of ng-routes and a super-set of elementary\nroutes. Normally, the pricing stage of CG must produce elementary routes, which\nare routes without repeated customers, using processes which can be\ncomputationally expensive. Non-elementary routes visit at least one customer\nmore than once, creating a cycle. LA routes relax the constraint of being an\nelementary route in such a manner as to permit efficient pricing. LA routes are\nbest understood in terms of ng-route relaxations. Ng-routes are routes which\nare permitted to have non-localized cycles in space; this means that at least\none intermediate customer (called a breaker) in the cycle must consider the\nstarting customer in the cycle to be spatially far away. LA routes are\ndescribed using a set of special indexes corresponding to customers on the\nroute ordered from the start to the end of the route. LA route relaxations\nfurther restrict the set of permitted cycles beyond that of ng-routes by\nadditionally enforcing that the breaker must be a located at a special index\nwhere the set of special indexes is defined recursively as follows. The first\nspecial index in the route is at index 1 meaning that it is associated with the\nfirst customer in the route. The k'th special index corresponds to the first\ncustomer after the k-1'th special index, that is not considered to be a\nneighbor of (considered spatially far from) the customer located at the k-1'th\nspecial index. We demonstrate that LA route relaxations can significantly\nimprove the computational speed of pricing when compared to the standard DSSR.",
    "descriptor": "",
    "authors": [
      "Udayan Mandal",
      "Amelia Regan",
      "Julian Yarkony"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04520"
  },
  {
    "id": "arXiv:2207.04540",
    "title": "Multi-Frequency Information Enhanced Channel Attention Module for  Speaker Representation Learning",
    "abstract": "Recently, attention mechanisms have been applied successfully in neural\nnetwork-based speaker verification systems. Incorporating the\nSqueeze-and-Excitation block into convolutional neural networks has achieved\nremarkable performance. However, it uses global average pooling (GAP) to simply\naverage the features along time and frequency dimensions, which is incapable of\npreserving sufficient speaker information in the feature maps. In this study,\nwe show that GAP is a special case of a discrete cosine transform (DCT) on\ntime-frequency domain mathematically using only the lowest frequency component\nin frequency decomposition. To strengthen the speaker information extraction\nability, we propose to utilize multi-frequency information and design two novel\nand effective attention modules, called Single-Frequency Single-Channel (SFSC)\nattention module and Multi-Frequency Single-Channel (MFSC) attention module.\nThe proposed attention modules can effectively capture more speaker information\nfrom multiple frequency components on the basis of DCT. We conduct\ncomprehensive experiments on the VoxCeleb datasets and a probe evaluation on\nthe 1st 48-UTD forensic corpus. Experimental results demonstrate that our\nproposed SFSC and MFSC attention modules can efficiently generate more\ndiscriminative speaker representations and outperform ResNet34-SE and\nECAPA-TDNN systems with relative 20.9% and 20.2% reduction in EER, without\nadding extra network parameters.",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Mufan Sang",
      "John H.L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.04540"
  },
  {
    "id": "arXiv:2207.04550",
    "title": "Learning to Order for Inventory Systems with Lost Sales and Uncertain  Supplies",
    "abstract": "We consider a stochastic lost-sales inventory control system with a lead time\n$L$ over a planning horizon $T$. Supply is uncertain, and is a function of the\norder quantity (due to random yield/capacity, etc). We aim to minimize the\n$T$-period cost, a problem that is known to be computationally intractable even\nunder known distributions of demand and supply. In this paper, we assume that\nboth the demand and supply distributions are unknown and develop a\ncomputationally efficient online learning algorithm. We show that our algorithm\nachieves a regret (i.e. the performance gap between the cost of our algorithm\nand that of an optimal policy over $T$ periods) of $O(L+\\sqrt{T})$ when\n$L\\geq\\log(T)$. We do so by 1) showing our algorithm cost is higher by at most\n$O(L+\\sqrt{T})$ for any $L\\geq 0$ compared to an optimal constant-order policy\nunder complete information (a well-known and widely-used algorithm) and 2)\nleveraging its known performance guarantee from the existing literature. To the\nbest of our knowledge, a finite-sample $O(\\sqrt{T})$ (and polynomial in $L$)\nregret bound when benchmarked against an optimal policy is not known before in\nthe online inventory control literature. A key challenge in this learning\nproblem is that both demand and supply data can be censored; hence only\ntruncated values are observable. We circumvent this challenge by showing that\nthe data generated under an order quantity $q^2$ allows us to simulate the\nperformance of not only $q^2$ but also $q^1$ for all $q^1<q^2$, a key\nobservation to obtain sufficient information even under data censoring. By\nestablishing a high probability coupling argument, we are able to evaluate and\ncompare the performance of different order policies at their steady state\nwithin a finite time horizon. Since the problem lacks convexity, we develop an\nactive elimination method that adaptively rules out suboptimal solutions.",
    "descriptor": "",
    "authors": [
      "Boxiao Chen",
      "Jiashuo Jiang",
      "Jiawei Zhang",
      "Zhengyuan Zhou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04550"
  },
  {
    "id": "arXiv:2207.04565",
    "title": "Automating Detection of Papilledema in Pediatric Fundus Images with  Explainable Machine Learning",
    "abstract": "Papilledema is an ophthalmic neurologic disorder in which increased\nintracranial pressure leads to swelling of the optic nerves. Undiagnosed\npapilledema in children may lead to blindness and may be a sign of\nlife-threatening conditions, such as brain tumors. Robust and accurate clinical\ndiagnosis of this syndrome can be facilitated by automated analysis of fundus\nimages using deep learning, especially in the presence of challenges posed by\npseudopapilledema that has similar fundus appearance but distinct clinical\nimplications. We present a deep learning-based algorithm for the automatic\ndetection of pediatric papilledema. Our approach is based on optic disc\nlocalization and detection of explainable papilledema indicators through data\naugmentation. Experiments on real-world clinical data demonstrate that our\nproposed method is effective with a diagnostic accuracy comparable to expert\nophthalmologists.",
    "descriptor": "\nComments: 5 pages, 4 figures, 2 tables, 2022 IEEE International Conference on Image Processing (ICIP)\n",
    "authors": [
      "Kleanthis Avramidis",
      "Mohammad Rostami",
      "Melinda Chang",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04565"
  },
  {
    "id": "arXiv:2207.04588",
    "title": "Multi-Study Boosting: Theoretical Considerations for Merging vs.  Ensembling",
    "abstract": "Cross-study replicability is a powerful model evaluation criterion that\nemphasizes generalizability of predictions. When training cross-study\nreplicable prediction models, it is critical to decide between merging and\ntreating the studies separately. We study boosting algorithms in the presence\nof potential heterogeneity in predictor-outcome relationships across studies\nand compare two multi-study learning strategies: 1) merging all the studies and\ntraining a single model, and 2) multi-study ensembling, which involves training\na separate model on each study and ensembling the resulting predictions. In the\nregression setting, we provide theoretical guidelines based on an analytical\ntransition point to determine whether it is more beneficial to merge or to\nensemble for boosting with linear learners. In addition, we characterize a\nbias-variance decomposition of estimation error for boosting with\ncomponent-wise linear learners. We verify the theoretical transition point\nresult in simulation and illustrate how it can guide the decision on merging\nvs. ensembling in an application to breast cancer gene expression data.",
    "descriptor": "",
    "authors": [
      "Cathy Shyr",
      "Pragya Sur",
      "Giovanni Parmigiani",
      "Prasad Patil"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04588"
  },
  {
    "id": "arXiv:2207.04589",
    "title": "Learned Video Compression via Heterogeneous Deformable Compensation  Network",
    "abstract": "Learned video compression has recently emerged as an essential research topic\nin developing advanced video compression technologies, where motion\ncompensation is considered one of the most challenging issues. In this paper,\nwe propose a learned video compression framework via heterogeneous deformable\ncompensation strategy (HDCVC) to tackle the problems of unstable compression\nperformance caused by single-size deformable kernels in downsampled feature\ndomain. More specifically, instead of utilizing optical flow warping or\nsingle-size-kernel deformable alignment, the proposed algorithm extracts\nfeatures from the two adjacent frames to estimate content-adaptive\nheterogeneous deformable (HetDeform) kernel offsets. Then we transform the\nreference features with the HetDeform convolution to accomplish motion\ncompensation. Moreover, we design a Spatial-Neighborhood-Conditioned Divisive\nNormalization (SNCDN) to achieve more effective data Gaussianization combined\nwith the Generalized Divisive Normalization. Furthermore, we propose a\nmulti-frame enhanced reconstruction module for exploiting context and temporal\ninformation for final quality enhancement. Experimental results indicate that\nHDCVC achieves superior performance than the recent state-of-the-art learned\nvideo compression approaches.",
    "descriptor": "",
    "authors": [
      "Huairui Wang",
      "Zhenzhong Chen",
      "Chang Wen Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.04589"
  },
  {
    "id": "arXiv:2207.04600",
    "title": "Optimal Clustering by Lloyd Algorithm for Low-Rank Mixture Model",
    "abstract": "This paper investigates the computational and statistical limits in\nclustering matrix-valued observations. We propose a low-rank mixture model\n(LrMM), adapted from the classical Gaussian mixture model (GMM) to treat\nmatrix-valued observations, which assumes low-rankness for population center\nmatrices. A computationally efficient clustering method is designed by\nintegrating Lloyd algorithm and low-rank approximation. Once well-initialized,\nthe algorithm converges fast and achieves an exponential-type clustering error\nrate that is minimax optimal. Meanwhile, we show that a tensor-based spectral\nmethod delivers a good initial clustering. Comparable to GMM, the minimax\noptimal clustering error rate is decided by the separation strength, i.e, the\nminimal distance between population center matrices. By exploiting\nlow-rankness, the proposed algorithm is blessed with a weaker requirement on\nseparation strength. Unlike GMM, however, the statistical and computational\ndifficulty of LrMM is characterized by the signal strength, i.e, the smallest\nnon-zero singular values of population center matrices. Evidences are provided\nshowing that no polynomial-time algorithm is consistent if the signal strength\nis not strong enough, even though the separation strength is strong. The\nperformance of our low-rank Lloyd algorithm is further demonstrated under\nsub-Gaussian noise. Intriguing differences between estimation and clustering\nunder LrMM are discussed. The merits of low-rank Lloyd algorithm are confirmed\nby comprehensive simulation experiments. Finally, our method outperforms others\nin the literature on real-world datasets.",
    "descriptor": "",
    "authors": [
      "Zhongyuan Lyu",
      "Dong Xia"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2207.04600"
  },
  {
    "id": "arXiv:2207.04663",
    "title": "An Ultra-low Power TinyML System for Real-time Visual Processing at Edge",
    "abstract": "Tiny machine learning (TinyML), executing AI workloads on resource and power\nstrictly restricted systems, is an important and challenging topic. This brief\nfirstly presents an extremely tiny backbone to construct high efficiency CNN\nmodels for various visual tasks. Then, a specially designed neural co-processor\n(NCP) is interconnected with MCU to build an ultra-low power TinyML system,\nwhich stores all features and weights on chip and completely removes both of\nlatency and power consumption in off-chip memory access. Furthermore, an\napplication specific instruction-set is further presented for realizing agile\ndevelopment and rapid deployment. Extensive experiments demonstrate that the\nproposed TinyML system based on our model, NCP and instruction set yields\nconsiderable accuracy and achieves a record ultra-low power of 160mW while\nimplementing object detection and recognition at 30FPS. The demo video is\navailable on \\url{https://www.youtube.com/watch?v=mIZPxtJ-9EY}.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Kunran Xu",
      "Huawei Zhang",
      "Yishi Li",
      "Yuhao Zhang",
      "Rui Lai",
      "Yi Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04663"
  },
  {
    "id": "arXiv:2207.04710",
    "title": "Weighted simplicial complexes and their representation power of  higher-order network data and topology",
    "abstract": "Hypergraphs and simplical complexes both capture the higher-order\ninteractions of complex systems, ranging from higher-order collaboration\nnetworks to brain networks. One open problem in the field is what should drive\nthe choice of the adopted mathematical framework to describe higher-order\nnetworks starting from data of higher-order interactions. Unweighted simplicial\ncomplexes typically involve a loss of information of the data, though having\nthe benefit to capture the higher-order topology of the data. In this work we\nshow that weighted simplicial complexes allow to circumvent all the limitations\nof unweighted simplicial complexes to represent higher-order interactions. In\nparticular, weighted simplicial complexes can represent higher-order networks\nwithout loss of information, allowing at the same time to capture the weighted\ntopology of the data. The higher-order topology is probed by studying the\nspectral properties of suitably defined weighted Hodge Laplacians displaying a\nnormalized spectrum. The higher-order spectrum of (weighted) normalized Hodge\nLaplacians is here studied combining cohomology theory with information theory.\nIn the proposed framework, we quantify and compare the information content of\nhigher-order spectra of different dimension using higher-order spectral\nentropies and spectral relative entropies. The proposed methodology is tested\non real higher-order collaboration networks and on the weighted version of the\nsimplicial complex model \"Network Geometry with Flavor\".",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Federica Baccini",
      "Filippo Geraci",
      "Ginestra Bianconi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.04710"
  },
  {
    "id": "arXiv:2207.04711",
    "title": "Matching Normalizing Flows and Probability Paths on Manifolds",
    "abstract": "Continuous Normalizing Flows (CNFs) are a class of generative models that\ntransform a prior distribution to a model distribution by solving an ordinary\ndifferential equation (ODE). We propose to train CNFs on manifolds by\nminimizing probability path divergence (PPD), a novel family of divergences\nbetween the probability density path generated by the CNF and a target\nprobability density path. PPD is formulated using a logarithmic mass\nconservation formula which is a linear first order partial differential\nequation relating the log target probabilities and the CNF's defining vector\nfield. PPD has several key benefits over existing methods: it sidesteps the\nneed to solve an ODE per iteration, readily applies to manifold data, scales to\nhigh dimensions, and is compatible with a large family of target paths\ninterpolating pure noise and data in finite time. Theoretically, PPD is shown\nto bound classical probability divergences. Empirically, we show that CNFs\nlearned by minimizing PPD achieve state-of-the-art results in likelihoods and\nsample quality on existing low-dimensional manifold benchmarks, and is the\nfirst example of a generative model to scale to moderately high dimensional\nmanifolds.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Heli Ben-Hamu",
      "Samuel Cohen",
      "Joey Bose",
      "Brandon Amos",
      "Aditya Grover",
      "Maximilian Nickel",
      "Ricky T.Q. Chen",
      "Yaron Lipman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04711"
  },
  {
    "id": "arXiv:2207.04717",
    "title": "Analysis of risk propagation using the world trade network",
    "abstract": "An economic system is an exemplar of a complex system in which all agents\ninteract simultaneously. Interactions between countries have generally been\nstudied using the flow of resources across diverse trade networks, in which the\ndegree of dependence between two countries is typically measured based on the\ntrade volume. However, indirect influences may not be immediately apparent.\nHerein, we compared a direct trade network to a trade network constructed using\nthe personalized PageRank (PPR) encompassing indirect influences. By analyzing\nthe correlation of the gross domestic product (GDP) between countries, we\ndiscovered that the PPR trade network has greater explanatory power on the\npropagation of economic events than direct trade by analyzing the GDP\ncorrelation between countries. To further validate our observations, an\nagent-based model of the spreading economic crisis was implemented for the\nRussia-Ukraine war of 2022. The model also demonstrates that the PPR explains\nthe actual impact more effectively than the direct trade network. Our research\nhighlights the significance of indirect and long-range relationships, which\nhave often been overlooked",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Sungyong Kim",
      "Jinhyuk Yun"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.04717"
  },
  {
    "id": "arXiv:2207.04736",
    "title": "Randomized Kaczmarz Method for Single Particle X-ray Image Phase  Retrieval",
    "abstract": "In this paper, we investigate phase retrieval algorithm for the single\nparticle X-ray imaging data. We present a variance-reduced randomized Kaczmarz\n(VR-RK) algorithm for phase retrieval. The VR-RK algorithm is inspired by the\nrandomized Kaczmarz method and the Stochastic Variance Reduce Gradient Descent\n(SVRG) algorithm. Numerical experiments show that the VR-RK algorithm has a\nfaster convergence rate than randomized Kaczmarz algorithm and the iterative\nprojection phase retrieval methods, such as the hybrid input output (HIO) and\nthe relaxed averaged alternating reflections (RAAR) methods. The VR-RK\nalgorithm can recover the phases with higher accuracy, and is robust at the\npresence of noise. Experimental results on the scattering data from individual\nparticles show that the VR-RK algorithm can recover phases and improve the\nsingle particle image identification.",
    "descriptor": "",
    "authors": [
      "Y. Xian",
      "H. Liu",
      "X. Tai",
      "Y. Wang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Image and Video Processing (eess.IV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04736"
  },
  {
    "id": "arXiv:2207.04749",
    "title": "DeepSNR: A deep learning foundation for offline gravitational wave  detection",
    "abstract": "All scientific claims of gravitational wave discovery to date rely on the\noffline statistical analysis of candidate observations in order to quantify\nsignificance relative to background processes. The current foundation in such\noffline detection pipelines in experiments at LIGO is the matched-filter\nalgorithm, which produces a signal-to-noise-ratio-based statistic for ranking\ncandidate observations. Existing deep-learning-based attempts to detect\ngravitational waves, which have shown promise in both signal sensitivity and\ncomputational efficiency, output probability scores. However, probability\nscores are not easily integrated into discovery workflows, limiting the use of\ndeep learning thus far to non-discovery-oriented applications. In this paper,\nthe Deep Learning Signal-to-Noise Ratio (DeepSNR) detection pipeline, which\nuses a novel method for generating a signal-to-noise ratio ranking statistic\nfrom deep learning classifiers, is introduced, providing the first foundation\nfor the use of deep learning algorithms in discovery-oriented pipelines. The\nperformance of DeepSNR is demonstrated by identifying binary black hole merger\ncandidates versus noise sources in open LIGO data from the first observation\nrun. High-fidelity simulations of the LIGO detector responses are used to\npresent the first sensitivity estimates of deep learning models in terms of\nphysical observables. The robustness of DeepSNR under various experimental\nconsiderations is also investigated. The results pave the way for DeepSNR to be\nused in the scientific discovery of gravitational waves and rare signals in\nbroader contexts, potentially enabling the detection of fainter signals and\nnever-before-observed phenomena.",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Michael Andrews",
      "Manfred Paulini",
      "Luke Sellers",
      "Alexey Bobrick",
      "Gianni Martire",
      "Haydn Vestal"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04749"
  },
  {
    "id": "arXiv:2207.04825",
    "title": "Forward Error Correction applied to JPEG-XS codestreams",
    "abstract": "JPEG-XS offers low complexity image compression for applications with\nconstrained but reasonable bit-rate, and low latency. Our paper explores the\ndeployment of JPEG-XS on lossy packet networks. To preserve low latency,\nForward Error Correction (FEC) is envisioned as the protection mechanism of\ninterest. Despite the JPEG-XS codestream is not scalable in essence, we observe\nthat the loss of a codestream fraction impacts the decoded image quality\ndifferently, depending on whether this codestream fraction corresponds to\ncodestream headers, to coefficients significance information, or to low/high\nfrequency data, respectively. Hence, we propose a rate-distortion optimal\nunequal error protection scheme that adapts the redundancy level of\nReed-Solomon codes according to the rate of channel losses and the type of\ninformation protected by the code. Our experiments demonstrate that, at 5% loss\nrates, it reduces the Mean Squared Error by up to 92% and 65%, compared to a\ntransmission without and with optimal but equal protection, respectively.",
    "descriptor": "",
    "authors": [
      "Antoine Legrand",
      "Beno\u00eet Macq",
      "Christophe De Vleeschouwer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.04825"
  },
  {
    "id": "arXiv:2207.04867",
    "title": "The Lepto-Variance of Stock Returns",
    "abstract": "The Regression Tree (RT) sorts the samples using a specific feature and finds\nthe split point that produces the maximum variance reduction from a node to its\nchildren. Our key observation is that the best factor to use (in terms of MSE\ndrop) is always the target itself, as this most clearly separates the target.\nThus using the target as the splitting factor provides an upper bound on MSE\ndrop (or lower bound on the residual children MSE). Based on this observation,\nwe define the k-bit lepto-variance ${\\lambda}k^2$ of a target variable (or\nequivalently the lepto-variance at a specific depth k) as the variance that\ncannot be removed by any regression tree of a depth equal to k. As the upper\nbound performance for any feature, we believe ${\\lambda}k^2$ to be an\ninteresting statistical concept related to the underlying structure of the\nsample as it quantifies the resolving power of the RT for the sample. The max\nvariance that may be explained using RTs of depth up to k is called the sample\nk-bit macro-variance. At any depth, total sample variance is thus decomposed\ninto lepto-variance ${\\lambda}^2$ and macro-variance ${\\mu}^2$. We demonstrate\nthe concept, by performing 1- and 2-bit RT based lepto-structure analysis for\ndaily IBM stock returns.",
    "descriptor": "",
    "authors": [
      "Vassilis Polimenis"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2207.04867"
  },
  {
    "id": "arXiv:2207.04869",
    "title": "Graph-based Molecular Representation Learning",
    "abstract": "Molecular representation learning (MRL) is a key step to build the connection\nbetween machine learning and chemical science. In particular, it encodes\nmolecules as numerical vectors preserving the molecular structures and\nfeatures, on top of which the downstream tasks (e.g., property prediction) can\nbe performed. Recently, MRL has achieved considerable progress, especially in\ndeep molecular graph learning-based methods. In this survey, we systematically\nreview these graph-based molecular representation techniques. Specifically, we\nfirst introduce the data and features of the 2D and 3D graph molecular\ndatasets. Then we summarize the methods specially designed for MRL and\ncategorize them into four strategies. Furthermore, we discuss some typical\nchemical applications supported by MRL. To facilitate studies in this\nfast-developing area, we also list the benchmarks and commonly used datasets in\nthe paper. Finally, we share our thoughts on future research directions.",
    "descriptor": "",
    "authors": [
      "Zhichun Guo",
      "Bozhao Nan",
      "Yijun Tian",
      "Olaf Wiest",
      "Chuxu Zhang",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04869"
  },
  {
    "id": "arXiv:2207.04878",
    "title": "Stacked Autoencoder Based Multi-Omics Data Integration for Cancer  Survival Prediction",
    "abstract": "Cancer survival prediction is important for developing personalized\ntreatments and inducing disease-causing mechanisms. Multi-omics data\nintegration is attracting widespread interest in cancer research for providing\ninformation for understanding cancer progression at multiple genetic levels.\nMany works, however, are limited because of the high dimensionality and\nheterogeneity of multi-omics data. In this paper, we propose a novel method to\nintegrate multi-omics data for cancer survival prediction, called Stacked\nAutoEncoder-based Survival Prediction Neural Network (SAEsurv-net). In the\ncancer survival prediction for TCGA cases, SAEsurv-net addresses the curse of\ndimensionality with a two-stage dimensionality reduction strategy and handles\nmulti-omics heterogeneity with a stacked autoencoder model. The two-stage\ndimensionality reduction strategy achieves a balance between computation\ncomplexity and information exploiting. The stacked autoencoder model removes\nmost heterogeneities such as data's type and size in the first group of\nautoencoders, and integrates multiple omics data in the second autoencoder. The\nexperiments show that SAEsurv-net outperforms models based on a single type of\ndata as well as other state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Xing Wu",
      "Qiulian Fang"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2207.04878"
  },
  {
    "id": "arXiv:2207.04887",
    "title": "A note on VIX for postprocessing quantitative strategies",
    "abstract": "In this note, we introduce how to use Volatility Index (VIX) for\npostprocessing quantitative strategies so as to increase the Sharpe ratio and\nreduce trading risks. The signal from this procedure is an indicator of trading\nor not on a daily basis. Finally, we analyze this procedure on SH510300 and\nSH510050 assets. The strategies are evaluated by measurements of Sharpe ratio,\nmax drawdown, and Calmar ratio. However, there is always a risk of loss in\ntrading. The results from the tests are just examples of how the method works;\nno claim is made on the suggestion of real market positions.",
    "descriptor": "",
    "authors": [
      "Jun Lu",
      "Minhui Wu"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04887"
  },
  {
    "id": "arXiv:2207.04890",
    "title": "The Mean Dimension of Neural Networks -- What causes the interaction  effects?",
    "abstract": "Owen and Hoyt recently showed that the effective dimension offers key\nstructural information about the input-output mapping underlying an artificial\nneural network. Along this line of research, this work proposes an estimation\nprocedure that allows the calculation of the mean dimension from a given\ndataset, without resampling from external distributions. The design yields\ntotal indices when features are independent and a variant of total indices when\nfeatures are correlated. We show that this variant possesses the zero\nindependence property. With synthetic datasets, we analyse how the mean\ndimension evolves layer by layer and how the activation function impacts the\nmagnitude of interactions. We then use the mean dimension to study some of the\nmost widely employed convolutional architectures for image recognition (LeNet,\nResNet, DenseNet). To account for pixel correlations, we propose calculating\nthe mean dimension after the addition of an inverse PCA layer that allows one\nto work on uncorrelated PCA-transformed features, without the need to retrain\nthe neural network. We use the generalized total indices to produce heatmaps\nfor post-hoc explanations, and we employ the mean dimension on the\nPCA-transformed features for cross comparisons of the artificial neural\nnetworks structures. Results provide several insights on the difference in\nmagnitude of interactions across the architectures, as well as indications on\nhow the mean dimension evolves during training.",
    "descriptor": "",
    "authors": [
      "Roman Hahn",
      "Christoph Feinauer",
      "Emanuele Borgonovo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04890"
  },
  {
    "id": "arXiv:2207.04922",
    "title": "On uniform-in-time diffusion approximation for stochastic gradient  descent",
    "abstract": "The diffusion approximation of stochastic gradient descent (SGD) in current\nliterature is only valid on a finite time interval. In this paper, we establish\nthe uniform-in-time diffusion approximation of SGD, by only assuming that the\nexpected loss is strongly convex and some other mild conditions, without\nassuming the convexity of each random loss function. The main technique is to\nestablish the exponential decay rates of the derivatives of the solution to the\nbackward Kolmogorov equation. The uniform-in-time approximation allows us to\nstudy asymptotic behaviors of SGD via the continuous stochastic differential\nequation (SDE) even when the random objective function $f(\\cdot;\\xi)$ is not\nstrongly convex.",
    "descriptor": "",
    "authors": [
      "Lei Li",
      "Yuliang Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04922"
  },
  {
    "id": "arXiv:2207.04923",
    "title": "Killing a Vortex",
    "abstract": "The Structural Theorem of the Graph Minors series of Robertson and Seymour\nasserts that, for every $t\\in\\mathbb{N},$ there exists some constant $c_{t}$\nsuch that every $K_{t}$-minor-free graph admits a tree decomposition whose\ntorsos can be transformed, by the removal of at most $c_{t}$ vertices, to\ngraphs that can be seen as the union of some graph that is embeddable to some\nsurface of Euler genus at most $c_{t}$ and \"at most $c_{t}$ vortices of depth\n$c_{t}$\". Our main combinatorial result is a \"vortex-free\" refinement of the\nabove structural theorem as follows: we identify a (parameterized) graph\n$H_{t}$, called shallow vortex grid, and we prove that if in the above\nstructural theorem we replace $K_{t}$ by $H_{t},$ then the resulting\ndecomposition becomes \"vortex-free\". Up to now, the most general classes of\ngraphs admitting such a result were either bounded Euler genus graphs or the so\ncalled single-crossing minor-free graphs. Our result is tight in the sense\nthat, whenever we minor-exclude a graph that is not a minor of some $H_{t},$\nthe appearance of vortices is unavoidable. Using the above decomposition\ntheorem, we design an algorithm that, given an $H_{t}$-minor-free graph $G$,\ncomputes the generating function of all perfect matchings of $G$ in polynomial\ntime. This algorithm yields, on $H_{t}$-minor-free graphs, polynomial\nalgorithms for computational problems such as the {dimer problem, the exact\nmatching problem}, and the computation of the permanent. Our results, combined\nwith known complexity results, imply a complete characterization of\nminor-closed graphs classes where the number of perfect matchings is\npolynomially computable: They are exactly those graph classes that do not\ncontain every $H_{t}$ as a minor. This provides a sharp complexity dichotomy\nfor the problem of counting perfect matchings in minor-closed classes.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.12397 by other authors\n",
    "authors": [
      "Dimitrios M. Thilikos",
      "Sebastian Wiederrecht"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.04923"
  },
  {
    "id": "arXiv:2207.04932",
    "title": "On the Stochastic Gradient Descent and Inverse Variance-flatness  Relation in Artificial Neural Networks",
    "abstract": "Stochastic gradient descent (SGD), a widely used algorithm in deep-learning\nneural networks has attracted continuing studies for the theoretical principles\nbehind its success. A recent work uncovered a generic inverse variance-flatness\n(IVF) relation between the variance of neural weights and the landscape\nflatness of loss function near solutions under SGD [Feng & Tu, PNAS 118,0027\n(2021)]. To investigate this seemly violation of statistical principle, we\ndeploy a stochastic decomposition to analyze the dynamical properties of SGD.\nThe method constructs the true \"energy\" function which can be used by Boltzmann\ndistribution. The new energy differs from the usual cost function and explains\nthe IVF relation under SGD. We further verify the scaling relation identified\nin Feng's work. Our approach may bridge the gap between the classical\nstatistical mechanics and the emerging discipline of artificial intelligence,\nwith potential for better algorithm to the latter.",
    "descriptor": "",
    "authors": [
      "Xia Xiong",
      "Yong-Cong Chen",
      "Chunxiao Shi",
      "Ping Ao"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04932"
  },
  {
    "id": "arXiv:2207.04934",
    "title": "Multi-level Geometric Optimization for Regularised Constrained Linear  Inverse Problems",
    "abstract": "We present a geometric multi-level optimization approach that smoothly\nincorporates box constraints. Given a box constrained optimization problem, we\nconsider a hierarchy of models with varying discretization levels. Finer models\nare accurate but expensive to compute, while coarser models are less accurate\nbut cheaper to compute. When working at the fine level, multi-level\noptimisation computes the search direction based on a coarser model which\nspeeds up updates at the fine level. Moreover, exploiting geometry induced by\nthe hierarchy the feasibility of the updates is preserved. In particular, our\napproach extends classical components of multigrid methods like restriction and\nprolongation to the Riemannian structure of our constraints.",
    "descriptor": "\nComments: 26 pages, 6 figures\n",
    "authors": [
      "Sebastian M\u00fcller",
      "Stefania Petra",
      "Matthias Zisler"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2207.04934"
  },
  {
    "id": "arXiv:2207.04941",
    "title": "Wavelet Conditional Renormalization Group",
    "abstract": "We develop a multiscale approach to estimate high-dimensional probability\ndistributions from a dataset of physical fields or configurations observed in\nexperiments or simulations. In this way we can estimate energy functions (or\nHamiltonians) and efficiently generate new samples of many-body systems in\nvarious domains, from statistical physics to cosmology. Our method -- the\nWavelet Conditional Renormalization Group (WC-RG) -- proceeds scale by scale,\nestimating models for the conditional probabilities of \"fast degrees of\nfreedom\" conditioned by coarse-grained fields. These probability distributions\nare modeled by energy functions associated with scale interactions, and are\nrepresented in an orthogonal wavelet basis. WC-RG decomposes the microscopic\nenergy function as a sum of interaction energies at all scales and can\nefficiently generate new samples by going from coarse to fine scales. Near\nphase transitions, it avoids the \"critical slowing down\" of direct estimation\nand sampling algorithms. This is explained theoretically by combining results\nfrom RG and wavelet theories, and verified numerically for the Gaussian and\n$\\varphi^4$ field theories. We show that multiscale WC-RG energy-based models\nare more general than local potential models and can capture the physics of\ncomplex many-body interacting systems at all length scales. This is\ndemonstrated for weak-gravitational-lensing fields reflecting dark matter\ndistributions in cosmology, which include long-range interactions with\nlong-tail probability distributions. WC-RG has a large number of potential\napplications in non-equilibrium systems, where the underlying distribution is\nnot known {\\it a priori}. Finally, we discuss the connection between WC-RG and\ndeep network architectures.",
    "descriptor": "\nComments: 36 pages, 21 figures\n",
    "authors": [
      "Tanguy Marchand",
      "Misaki Ozawa",
      "Giulio Biroli",
      "St\u00e9phane Mallat"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2207.04941"
  },
  {
    "id": "arXiv:2207.04949",
    "title": "pMCT: Patched Multi-Condition Training for Robust Speech Recognition",
    "abstract": "We propose a novel Patched Multi-Condition Training (pMCT) method for robust\nAutomatic Speech Recognition (ASR). pMCT employs Multi-condition Audio\nModification and Patching (MAMP) via mixing {\\it patches} of the same utterance\nextracted from clean and distorted speech. Training using patch-modified\nsignals improves robustness of models in noisy reverberant scenarios. Our\nproposed pMCT is evaluated on the LibriSpeech dataset showing improvement over\nusing vanilla Multi-Condition Training (MCT). For analyses on robust ASR, we\nemployed pMCT on the VOiCES dataset which is a noisy reverberant dataset\ncreated using utterances from LibriSpeech. In the analyses, pMCT achieves 23.1%\nrelative WER reduction compared to the MCT.",
    "descriptor": "\nComments: Accepted at Interspeech 2022\n",
    "authors": [
      "Pablo Peso Parada",
      "Agnieszka Dobrowolska",
      "Karthikeyan Saravanan",
      "Mete Ozay"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.04949"
  },
  {
    "id": "arXiv:2207.04962",
    "title": "Structural Inference of Networked Dynamical Systems with Universal  Differential Equations",
    "abstract": "Networked dynamical systems are common throughout science in engineering;\ne.g., biological networks, reaction networks, power systems, and the like. For\nmany such systems, nonlinearity drives populations of identical (or\nnear-identical) units to exhibit a wide range of nontrivial behaviors, such as\nthe emergence of coherent structures (e.g., waves and patterns) or otherwise\nnotable dynamics (e.g., synchrony and chaos). In this work, we seek to infer\n(i) the intrinsic physics of a base unit of a population, (ii) the underlying\ngraphical structure shared between units, and (iii) the coupling physics of a\ngiven networked dynamical system given observations of nodal states. These\ntasks are formulated around the notion of the Universal Differential Equation,\nwhereby unknown dynamical systems can be approximated with neural networks,\nmathematical terms known a priori (albeit with unknown parameterizations), or\ncombinations of the two. We demonstrate the value of these inference tasks by\ninvestigating not only future state predictions but also the inference of\nsystem behavior on varied network topologies. The effectiveness and utility of\nthese methods is shown with their application to canonical networked nonlinear\ncoupled oscillators.",
    "descriptor": "",
    "authors": [
      "James Koch",
      "Zhao Chen",
      "Aaron Tuor",
      "Jan Drgona",
      "Draguna Vrabie"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04962"
  },
  {
    "id": "arXiv:2207.04994",
    "title": "Uncertainty-aware Mixed-variable Machine Learning for Materials Design",
    "abstract": "Data-driven design shows the promise of accelerating materials discovery but\nis challenging due to the prohibitive cost of searching the vast design space\nof chemistry, structure, and synthesis methods. Bayesian Optimization (BO)\nemploys uncertainty-aware machine learning models to select promising designs\nto evaluate, hence reducing the cost. However, BO with mixed numerical and\ncategorical variables, which is of particular interest in materials design, has\nnot been well studied. In this work, we survey frequentist and Bayesian\napproaches to uncertainty quantification of machine learning with mixed\nvariables. We then conduct a systematic comparative study of their performances\nin BO using a popular representative model from each group, the random\nforest-based Lolo model (frequentist) and the latent variable Gaussian process\nmodel (Bayesian). We examine the efficacy of the two models in the optimization\nof mathematical functions, as well as properties of structural and functional\nmaterials, where we observe performance differences as related to problem\ndimensionality and complexity. By investigating the machine learning models'\npredictive and uncertainty estimation capabilities, we provide interpretations\nof the observed performance differences. Our results provide practical guidance\non choosing between frequentist and Bayesian uncertainty-aware machine learning\nmodels for mixed-variable BO in materials design.",
    "descriptor": "",
    "authors": [
      "Hengrui Zhang",
      "Wei \"Wayne\" Chen",
      "Akshay Iyer",
      "Daniel W. Apley",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04994"
  },
  {
    "id": "arXiv:2207.04996",
    "title": "Construction of non-CSS quantum codes using measurements on cluster  states",
    "abstract": "Measurement-based quantum computation provides an alternate model for quantum\ncomputation compared to the well-known gate-based model. It uses qubits\nprepared in a specific state followed by single-qubit measurements. The\nstabilizers of cluster states are well defined because of their graph\nstructure. We exploit this graph structure to design non-CSS codes using\nmeasurements on cluster states. The procedure is general and can be used as an\nencoding technique to design arbitrary non-CSS codes with one logical qubit.",
    "descriptor": "\nComments: 6 Pages, 4 Figures, Two Algorithms, One table\n",
    "authors": [
      "Swayangprabha Shaw",
      "Harsh Gupta",
      "Shahid M Shah",
      "Ankur Raina"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04996"
  },
  {
    "id": "arXiv:2207.05013",
    "title": "Boosting Heterogeneous Catalyst Discovery by Structurally Constrained  Deep Learning Models",
    "abstract": "The discovery of new catalysts is one of the significant topics of\ncomputational chemistry as it has the potential to accelerate the adoption of\nrenewable energy sources. Recently developed deep learning approaches such as\ngraph neural networks (GNNs) open new opportunity to significantly extend scope\nfor modelling novel high-performance catalysts. Nevertheless, the graph\nrepresentation of particular crystal structure is not a straightforward task\ndue to the ambiguous connectivity schemes and numerous embeddings of nodes and\nedges. Here we present embedding improvement for GNN that has been modified by\nVoronoi tesselation and is able to predict the energy of catalytic systems\nwithin Open Catalyst Project dataset. Enrichment of the graph was calculated\nvia Voronoi tessellation and the corresponding contact solid angles and types\n(direct or indirect) were considered as features of edges and Voronoi volumes\nwere used as node characteristics. The auxiliary approach was enriching node\nrepresentation by intrinsic atomic properties (electronegativity, period and\ngroup position). Proposed modifications allowed us to improve the mean absolute\nerror of the original model and the final error equals to 651 meV per atom on\nthe Open Catalyst Project dataset and 6 meV per atom on the intermetallics\ndataset. Also, by consideration of additional dataset, we show that a sensible\nchoice of data can decrease the error to values above physically-based 20 meV\nper atom threshold.",
    "descriptor": "",
    "authors": [
      "Alexey N. Korovin",
      "Innokentiy S. Humonen",
      "Artem I. Samtsevich",
      "Roman A. Eremin",
      "Artem I. Vasilyev",
      "Vladimir D. Lazarev",
      "Semen A. Budennyy"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05013"
  },
  {
    "id": "arXiv:2207.05014",
    "title": "On SOCP-based disjunctive cuts for solving a class of integer bilevel  nonlinear programs",
    "abstract": "We study a class of integer bilevel programs with second-order cone\nconstraints at the upper-level and a convex-quadratic objective function and\nlinear constraints at the lower-level. We develop disjunctive cuts (DCs) to\nseparate bilevel-infeasible solutions using a second-order-cone-based\ncut-generating procedure. We propose DC separation strategies and consider\nseveral approaches for removing redundant disjunctions and normalization. Using\nthese DCs, we propose a branch-and-cut algorithm for the problem class we\nstudy, and a cutting-plane method for the problem variant with only binary\nvariables.\nWe present an extensive computational study on a diverse set of instances,\nincluding instances with binary and with integer variables, and instances with\na single and with multiple linking constraints. Our computational study\ndemonstrates that the proposed enhancements of our solution approaches are\neffective for improving the performance. Moreover, both of our approaches\noutperform a state-of-the-art generic solver for mixed-integer bilevel linear\nprograms that is able to solve a linearized version of our binary instances.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.06824\n",
    "authors": [
      "Elisabeth Gaar",
      "Jon Lee",
      "Ivana Ljubi\u0107",
      "Markus Sinnl",
      "K\u00fcbra Tan\u0131nm\u0131\u015f"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2207.05014"
  },
  {
    "id": "arXiv:2207.05046",
    "title": "Dynamic random graphs with vertex removal",
    "abstract": "We introduce and analyse a Dynamic Random Graph with Vertex Removal (DRGVR)\ndefined as follows. At every step, with probability $p > 1/2$ a new vertex is\nintroduced, and with probability $1-p$ a vertex, chosen uniformly at random\namong the present ones (if any), is removed from the graph together with all\nedges adjacent to it. In the former case, the new vertex connects by an edge to\nevery other vertex with probability proportional to the number of vertices\nalready present.\nWe prove that the DRGVR converges to a local limit and determine this limit.\nMoreover, we analyse its component structure and distinguish a subcritical and\na supercritical regime with respect to the existence of a giant component. As a\nbyproduct of this analysis, we obtain upper and lower bounds for the critical\nparameter. Furthermore, we provide precise expression of the maximum degree (as\nwell as in- and out-degree for a natural orientation of the DRGVR). Several\nconcentration and stability results complete the study.",
    "descriptor": "\nComments: 50 pages, 1 figure\n",
    "authors": [
      "Josep D\u00edaz",
      "Lyuben Lichev",
      "Bas Lodewijks"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.05046"
  },
  {
    "id": "arXiv:1511.07042",
    "title": "The Bootstrap Multigrid Eigensolver",
    "abstract": "The Bootstrap Multigrid Eigensolver",
    "descriptor": "",
    "authors": [
      "James Brannick",
      "Shuhao Cao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1511.07042"
  },
  {
    "id": "arXiv:1808.03137",
    "title": "A Survey on Sentiment and Emotion Analysis for Computational Literary  Studies",
    "abstract": "Comments: Published in ZFDG: this https URL",
    "descriptor": "\nComments: Published in ZFDG: this https URL\n",
    "authors": [
      "Evgeny Kim",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1808.03137"
  },
  {
    "id": "arXiv:1809.04441",
    "title": "An empirical learning-based validation procedure for simulation workflow",
    "abstract": "Comments: This paper has not been published or updated. I withdraw it only because it is out of date",
    "descriptor": "\nComments: This paper has not been published or updated. I withdraw it only because it is out of date\n",
    "authors": [
      "Zhuqing Liu",
      "Liyuanjun Lai",
      "Lin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1809.04441"
  },
  {
    "id": "arXiv:1901.04059",
    "title": "GAN-based Virtual Re-Staining: A Promising Solution for Whole Slide  Image Analysis",
    "abstract": "GAN-based Virtual Re-Staining: A Promising Solution for Whole Slide  Image Analysis",
    "descriptor": "",
    "authors": [
      "Zhaoyang Xu",
      "Xingru Huang",
      "Carlos Fern\u00e1ndez Moro",
      "B\u00e9la Boz\u00f3ky",
      "Qianni Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1901.04059"
  },
  {
    "id": "arXiv:1904.07404",
    "title": "swTVM: Towards Optimized Tensor Code Generation for Deep Learning on  Sunway Many-Core Processor",
    "abstract": "swTVM: Towards Optimized Tensor Code Generation for Deep Learning on  Sunway Many-Core Processor",
    "descriptor": "",
    "authors": [
      "Mingzhen Li",
      "Changxi Liu",
      "Jianjin Liao",
      "Xuegui Zheng",
      "Hailong Yang",
      "Rujun Sun",
      "Jun Xu",
      "Lin Gan",
      "Guangwen Yang",
      "Zhongzhi Luan",
      "Depei Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1904.07404"
  },
  {
    "id": "arXiv:1908.08144",
    "title": "They may look and look, yet not see: BMDs cannot be tested adequately",
    "abstract": "They may look and look, yet not see: BMDs cannot be tested adequately",
    "descriptor": "",
    "authors": [
      "Philip B. Stark",
      "Ran Xie"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/1908.08144"
  },
  {
    "id": "arXiv:1908.11221",
    "title": "Multi-Channel Deep Networks for Block-Based Image Compressive Sensing",
    "abstract": "Comments: 14 pages, 10 figures",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Siwang Zhou",
      "Yan He",
      "Yonghe Liu",
      "Chengqing Li",
      "Jianming Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1908.11221"
  },
  {
    "id": "arXiv:1910.04183",
    "title": "Robust Dynamic Assortment Optimization in the Presence of Outlier  Customers",
    "abstract": "Robust Dynamic Assortment Optimization in the Presence of Outlier  Customers",
    "descriptor": "",
    "authors": [
      "Xi Chen",
      "Akshay Krishnamurthy",
      "Yining Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.04183"
  },
  {
    "id": "arXiv:2001.01385",
    "title": "Identifying and Compensating for Feature Deviation in Imbalanced Deep  Learning",
    "abstract": "Identifying and Compensating for Feature Deviation in Imbalanced Deep  Learning",
    "descriptor": "",
    "authors": [
      "Han-Jia Ye",
      "Hong-You Chen",
      "De-Chuan Zhan",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.01385"
  },
  {
    "id": "arXiv:2002.05777",
    "title": "Semi-Structured Distributional Regression -- Extending Structured  Additive Models by Arbitrary Deep Neural Networks and Data Modalities",
    "abstract": "Semi-Structured Distributional Regression -- Extending Structured  Additive Models by Arbitrary Deep Neural Networks and Data Modalities",
    "descriptor": "",
    "authors": [
      "David R\u00fcgamer",
      "Chris Kolb",
      "Nadja Klein"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2002.05777"
  },
  {
    "id": "arXiv:2002.08232",
    "title": "CoLES: Contrastive Learning for Event Sequences with Self-Supervision",
    "abstract": "Comments: SIGMOD'22",
    "descriptor": "\nComments: SIGMOD'22\n",
    "authors": [
      "Dmitrii Babaev",
      "Ivan Kireev",
      "Nikita Ovsov",
      "Mariya Ivanova",
      "Gleb Gusev",
      "Ivan Nazarov",
      "Alexander Tuzhilin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.08232"
  },
  {
    "id": "arXiv:2003.06536",
    "title": "The p-AAA algorithm for data driven modeling of parametric dynamical  systems",
    "abstract": "The p-AAA algorithm for data driven modeling of parametric dynamical  systems",
    "descriptor": "",
    "authors": [
      "Andrea Carracedo Rodriguez",
      "Linus Balicki",
      "Serkan Gugercin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2003.06536"
  },
  {
    "id": "arXiv:2007.00903",
    "title": "Optimality of the coordinate-wise median mechanism for strategyproof  facility location in two dimensions",
    "abstract": "Comments: 25 pages, SAGT 2022",
    "descriptor": "\nComments: 25 pages, SAGT 2022\n",
    "authors": [
      "Sumit Goel",
      "Wade Hann-Caruthers"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2007.00903"
  },
  {
    "id": "arXiv:2007.06753",
    "title": "From Symmetry to Geometry: Tractable Nonconvex Problems",
    "abstract": "Comments: review paper, 38 pages, 10 figures, revision: correction of typos, adding more discussion on recent advances on deep learning",
    "descriptor": "\nComments: review paper, 38 pages, 10 figures, revision: correction of typos, adding more discussion on recent advances on deep learning\n",
    "authors": [
      "Yuqian Zhang",
      "Qing Qu",
      "John Wright"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.06753"
  },
  {
    "id": "arXiv:2008.08157",
    "title": "Heteroscedastic Uncertainty for Robust Generative Latent Dynamics",
    "abstract": "Comments: In IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE International Conference on Intelligent Robots and Systems (IROS'20), Las Vegas, USA, October 25-29, 2020",
    "descriptor": "\nComments: In IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE International Conference on Intelligent Robots and Systems (IROS'20), Las Vegas, USA, October 25-29, 2020\n",
    "authors": [
      "Oliver Limoyo",
      "Bryan Chan",
      "Filip Mari\u0107",
      "Brandon Wagstaff",
      "Rupam Mahmood",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.08157"
  },
  {
    "id": "arXiv:2008.09864",
    "title": "Tackling Over-Smoothing for General Graph Convolutional Networks",
    "abstract": "Comments: Submitted to TPAMI, 15 pages",
    "descriptor": "\nComments: Submitted to TPAMI, 15 pages\n",
    "authors": [
      "Wenbing Huang",
      "Yu Rong",
      "Tingyang Xu",
      "Fuchun Sun",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.09864"
  },
  {
    "id": "arXiv:2008.10916",
    "title": "Towards End-to-end Car License Plate Location and Recognition in  Unconstrained Scenarios",
    "abstract": "Towards End-to-end Car License Plate Location and Recognition in  Unconstrained Scenarios",
    "descriptor": "",
    "authors": [
      "Shuxin Qin",
      "Sijiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.10916"
  },
  {
    "id": "arXiv:2009.00150",
    "title": "Exactly Optimal Bayesian Quickest Change Detection for Hidden Markov  Models",
    "abstract": "Exactly Optimal Bayesian Quickest Change Detection for Hidden Markov  Models",
    "descriptor": "",
    "authors": [
      "Jason J. Ford",
      "Jasmin James",
      "Timothy L. Molloy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.00150"
  },
  {
    "id": "arXiv:2009.02540",
    "title": "A Survey of Deep Learning Architectures for Intelligent Reflecting  Surfaces",
    "abstract": "Comments: 7 pages and 5 figures. This work has been submitted to the IEEE for publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 7 pages and 5 figures. This work has been submitted to the IEEE for publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ahmet M. Elbir",
      "Kumar Vijay Mishra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.02540"
  },
  {
    "id": "arXiv:2009.14393",
    "title": "TensorBNN: Bayesian Inference for Neural Networks using Tensorflow",
    "abstract": "TensorBNN: Bayesian Inference for Neural Networks using Tensorflow",
    "descriptor": "",
    "authors": [
      "Braden Kronheim",
      "Michelle Kuchera",
      "Harrison Prosper"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.14393"
  },
  {
    "id": "arXiv:2009.14742",
    "title": "A Generalization of Bohr-Mollerup's Theorem for Higher Order Convex  Functions",
    "abstract": "A Generalization of Bohr-Mollerup's Theorem for Higher Order Convex  Functions",
    "descriptor": "",
    "authors": [
      "Jean-Luc Marichal",
      "Na\u00efm Zena\u00efdi"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2009.14742"
  },
  {
    "id": "arXiv:2010.10028",
    "title": "Towards an Ethical Framework in the Complex Digital Era",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2003.06530",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2003.06530\n",
    "authors": [
      "David Pastor-Escuredo",
      "Ricardo Vinuesa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2010.10028"
  },
  {
    "id": "arXiv:2010.13175",
    "title": "Amodal Segmentation through Out-of-Task and Out-of-Distribution  Generalization with a Bayesian Model",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Yihong Sun",
      "Adam Kortylewski",
      "Alan Yuille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.13175"
  },
  {
    "id": "arXiv:2010.16243",
    "title": "Language for Description of Worlds",
    "abstract": "Language for Description of Worlds",
    "descriptor": "",
    "authors": [
      "Dimiter Dobrev"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.16243"
  },
  {
    "id": "arXiv:2011.14382",
    "title": "Sequential Fair Allocation of Limited Resources under Stochastic Demands",
    "abstract": "Comments: See arXiv:2105.05308 for an updated version. 36 pages, 6 figures",
    "descriptor": "\nComments: See arXiv:2105.05308 for an updated version. 36 pages, 6 figures\n",
    "authors": [
      "Sean R. Sinclair",
      "Gauri Jain",
      "Siddhartha Banerjee",
      "Christina Lee Yu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.14382"
  },
  {
    "id": "arXiv:2012.15685",
    "title": "A Survey on Deep Learning-based Single Image Crowd Counting: Network  Design, Loss Function and Supervisory Signal",
    "abstract": "Comments: Neurocomputing minor revision. Project page is at this https URL",
    "descriptor": "\nComments: Neurocomputing minor revision. Project page is at this https URL\n",
    "authors": [
      "Haoyue Bai",
      "Jiageng Mao",
      "S.-H. Gary Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.15685"
  },
  {
    "id": "arXiv:2101.00436",
    "title": "Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval",
    "abstract": "Comments: NeurIPS 2021 (Spotlight)",
    "descriptor": "\nComments: NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Omar Khattab",
      "Christopher Potts",
      "Matei Zaharia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2101.00436"
  },
  {
    "id": "arXiv:2101.04378",
    "title": "Rethinking Interactive Image Segmentation: Feature Space Annotation",
    "abstract": "Rethinking Interactive Image Segmentation: Feature Space Annotation",
    "descriptor": "",
    "authors": [
      "Jord{\u00e3}o Bragantini",
      "Alexandre X Falc{\u00e3}o",
      "Laurent Najman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.04378"
  },
  {
    "id": "arXiv:2101.07768",
    "title": "Assets in Software Engineering: What are they after all?",
    "abstract": "Comments: Manuscript submitted to the Journal of Systems and Software",
    "descriptor": "\nComments: Manuscript submitted to the Journal of Systems and Software\n",
    "authors": [
      "Ehsan Zabardast",
      "Julian Frattini",
      "Javier Gonzalez-Huerta",
      "Daniel Mendez",
      "Tony Gorschek",
      "Krzysztof Wnuk"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2101.07768"
  },
  {
    "id": "arXiv:2101.10092",
    "title": "Beyond cost reduction: Improving the value of energy storage in  electricity systems",
    "abstract": "Comments: 17 pages, 10 figures",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Maximilian Parzen",
      "Fabian Neumann",
      "Addrian H. Van Der Weijde",
      "Daniel Friedrich",
      "Aristides Kiprakis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)",
      "Portfolio Management (q-fin.PM)"
    ],
    "url": "https://arxiv.org/abs/2101.10092"
  },
  {
    "id": "arXiv:2101.10710",
    "title": "Visual explanation of black-box model: Similarity Difference and  Uniqueness (SIDU) method",
    "abstract": "Visual explanation of black-box model: Similarity Difference and  Uniqueness (SIDU) method",
    "descriptor": "",
    "authors": [
      "Satya M. Muddamsetty",
      "Mohammad N. S. Jahromi",
      "Andreea E. Ciontos",
      "Laura M. Fenoy",
      "Thomas B. Moeslund"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.10710"
  },
  {
    "id": "arXiv:2102.04270",
    "title": "Enabling Binary Neural Network Training on the Edge",
    "abstract": "Enabling Binary Neural Network Training on the Edge",
    "descriptor": "",
    "authors": [
      "Erwei Wang",
      "James J. Davis",
      "Daniele Moro",
      "Piotr Zielinski",
      "Jia Jie Lim",
      "Claudionor Coelho",
      "Satrajit Chatterjee",
      "Peter Y. K. Cheung",
      "George A. Constantinides"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2102.04270"
  },
  {
    "id": "arXiv:2102.04341",
    "title": "Learned Camera Gain and Exposure Control for Improved Visual Feature  Detection and Matching",
    "abstract": "Comments: In IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE International Conference on Robotics and Automation (ICRA'21), Xi'an, China, May 30-Jun. 5, 2021",
    "descriptor": "\nComments: In IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE International Conference on Robotics and Automation (ICRA'21), Xi'an, China, May 30-Jun. 5, 2021\n",
    "authors": [
      "Justin Tomasi",
      "Brandon Wagstaff",
      "Steven L. Waslander",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.04341"
  },
  {
    "id": "arXiv:2102.06289",
    "title": "When and How Mixup Improves Calibration",
    "abstract": "Comments: Accepted for ICML 2022",
    "descriptor": "\nComments: Accepted for ICML 2022\n",
    "authors": [
      "Linjun Zhang",
      "Zhun Deng",
      "Kenji Kawaguchi",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06289"
  },
  {
    "id": "arXiv:2102.10955",
    "title": "Learning Purified Feature Representations from Task-irrelevant Labels",
    "abstract": "Comments: Accepted by IJCNN 2022. arXiv admin note: substantial text overlap with arXiv:2011.08470",
    "descriptor": "\nComments: Accepted by IJCNN 2022. arXiv admin note: substantial text overlap with arXiv:2011.08470\n",
    "authors": [
      "Yinghui Li",
      "Chen Wang",
      "Yangning Li",
      "Hai-Tao Zheng",
      "Ying Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.10955"
  },
  {
    "id": "arXiv:2102.12238",
    "title": "Inductive Bias of Multi-Channel Linear Convolutional Networks with  Bounded Weight Norm",
    "abstract": "Comments: Appeared at COLT 2022",
    "descriptor": "\nComments: Appeared at COLT 2022\n",
    "authors": [
      "Meena Jagadeesan",
      "Ilya Razenshteyn",
      "Suriya Gunasekar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12238"
  },
  {
    "id": "arXiv:2103.01148",
    "title": "E$^2$CM: Early Exit via Class Means for Efficient Supervised and  Unsupervised Learning",
    "abstract": "Comments: 8 pages, 4 figures, 2 tables. Accepted to IJCNN 2022 (WCCI2022)",
    "descriptor": "\nComments: 8 pages, 4 figures, 2 tables. Accepted to IJCNN 2022 (WCCI2022)\n",
    "authors": [
      "Alperen G\u00f6rmez",
      "Venkat R. Dasari",
      "Erdem Koyuncu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.01148"
  },
  {
    "id": "arXiv:2103.14198",
    "title": "Exploiting Playbacks in Unsupervised Domain Adaptation for 3D Object  Detection",
    "abstract": "Comments: Accepted by ICRA 2022",
    "descriptor": "\nComments: Accepted by ICRA 2022\n",
    "authors": [
      "Yurong You",
      "Carlos Andres Diaz-Ruiz",
      "Yan Wang",
      "Wei-Lun Chao",
      "Bharath Hariharan",
      "Mark Campbell",
      "Kilian Q Weinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14198"
  },
  {
    "id": "arXiv:2104.00773",
    "title": "MultiWOZ 2.4: A Multi-Domain Task-Oriented Dialogue Dataset with  Essential Annotation Corrections to Improve State Tracking Evaluation",
    "abstract": "Comments: Accepted to SIGDIAL 2022 (this https URL)",
    "descriptor": "\nComments: Accepted to SIGDIAL 2022 (this https URL)\n",
    "authors": [
      "Fanghua Ye",
      "Jarana Manotumruksa",
      "Emine Yilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.00773"
  },
  {
    "id": "arXiv:2104.01214",
    "title": "Modeling Censored Mobility Demand through Quantile Regression Neural  Networks",
    "abstract": "Comments: 13 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 13 pages, 9 figures, 5 tables\n",
    "authors": [
      "Frederik Boe H\u00fcttel",
      "Inon Peled",
      "Filipe Rodrigues",
      "Francisco C. Pereira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.01214"
  },
  {
    "id": "arXiv:2104.01678",
    "title": "Understanding Continual Learning Settings with Data Distribution Drift  Analysis",
    "abstract": "Understanding Continual Learning Settings with Data Distribution Drift  Analysis",
    "descriptor": "",
    "authors": [
      "Timoth\u00e9e Lesort",
      "Massimo Caccia",
      "Irina Rish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.01678"
  },
  {
    "id": "arXiv:2104.04004",
    "title": "ACERAC: Efficient reinforcement learning in fine time discretization",
    "abstract": "Comments: Submitted to IEEE Transactions on Neural Networks and Learning Systems. arXiv admin note: text overlap with arXiv:2009.04777",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Neural Networks and Learning Systems. arXiv admin note: text overlap with arXiv:2009.04777\n",
    "authors": [
      "Jakub \u0141yskawa",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04004"
  },
  {
    "id": "arXiv:2104.04099",
    "title": "A Cardinality Minimization Approach to Security-Constrained Economic  Dispatch",
    "abstract": "A Cardinality Minimization Approach to Security-Constrained Economic  Dispatch",
    "descriptor": "",
    "authors": [
      "David Troxell",
      "Miju Ahn",
      "Harsha Gangammanavar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.04099"
  },
  {
    "id": "arXiv:2104.04797",
    "title": "Coupling streaming AI and HPC ensembles to achieve 100-1000x faster  biomolecular simulations",
    "abstract": "Coupling streaming AI and HPC ensembles to achieve 100-1000x faster  biomolecular simulations",
    "descriptor": "",
    "authors": [
      "Alexander Brace",
      "Igor Yakushin",
      "Heng Ma",
      "Anda Trifan",
      "Todd Munson",
      "Ian Foster",
      "Arvind Ramanathan",
      "Hyungro Lee",
      "Matteo Turilli",
      "Shantenu Jha"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04797"
  },
  {
    "id": "arXiv:2104.06401",
    "title": "Self-supervised object detection from audio-visual correspondence",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Triantafyllos Afouras",
      "Yuki M. Asano",
      "Francois Fagan",
      "Andrea Vedaldi",
      "Florian Metze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.06401"
  },
  {
    "id": "arXiv:2104.06706",
    "title": "Towards Off-the-grid Algorithms for Total Variation Regularized Inverse  Problems",
    "abstract": "Comments: For the short conference version see arXiv:2104.06706v2. For the long journal version see arXiv:2104.06706v5",
    "descriptor": "\nComments: For the short conference version see arXiv:2104.06706v2. For the long journal version see arXiv:2104.06706v5\n",
    "authors": [
      "Yohann de Castro",
      "Vincent Duval",
      "Romain Petit"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.06706"
  },
  {
    "id": "arXiv:2104.10003",
    "title": "An Exact Hypergraph Matching Algorithm for Nuclear Identification in  Embryonic Caenorhabditis elegans",
    "abstract": "Comments: 20 pages, 11 figures",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Andrew Lauziere",
      "Ryan Christensen",
      "Hari Shroff",
      "Radu Balan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.10003"
  },
  {
    "id": "arXiv:2104.10611",
    "title": "FourierNets enable the design of highly non-local optical encoders for  computational imaging",
    "abstract": "Comments: Revision with experimental PSF",
    "descriptor": "\nComments: Revision with experimental PSF\n",
    "authors": [
      "Diptodip Deb",
      "Zhenfei Jiao",
      "Ruth Sims",
      "Alex B. Chen",
      "Michael Broxton",
      "Misha B. Ahrens",
      "Kaspar Podgorski",
      "Srinivas C. Turaga"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.10611"
  },
  {
    "id": "arXiv:2104.13482",
    "title": "Stochastic Neural Networks for Automatic Cell Tracking in Microscopy  Image Sequences of Bacterial Colonies",
    "abstract": "Comments: 35 pages, 8 figures, 7 tables",
    "descriptor": "\nComments: 35 pages, 8 figures, 7 tables\n",
    "authors": [
      "Sorena Sarmadi",
      "James J. Winkle",
      "Razan N. Alnahhas",
      "Matthew R. Bennett",
      "Kre\u0161imir Josi\u0107",
      "Andreas Mang",
      "Robert Azencott"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.13482"
  },
  {
    "id": "arXiv:2105.01303",
    "title": "Personalized Algorithm Generation: A Case Study in Learning ODE  Integrators",
    "abstract": "Personalized Algorithm Generation: A Case Study in Learning ODE  Integrators",
    "descriptor": "",
    "authors": [
      "Yue Guo",
      "Felix Dietrich",
      "Tom Bertalan",
      "Danimir T. Doncevic",
      "Manuel Dahmen",
      "Ioannis G. Kevrekidis",
      "Qianxiao Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.01303"
  },
  {
    "id": "arXiv:2105.07608",
    "title": "Hamiltonian Cycle Problem is in P",
    "abstract": "Comments: 40 pages, 9 figures",
    "descriptor": "\nComments: 40 pages, 9 figures\n",
    "authors": [
      "Aimin Hou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.07608"
  },
  {
    "id": "arXiv:2105.09560",
    "title": "Objective-aware Traffic Simulation via Inverse Reinforcement Learning",
    "abstract": "Comments: Accepted for publication by IJCAI 2021",
    "descriptor": "\nComments: Accepted for publication by IJCAI 2021\n",
    "authors": [
      "Guanjie Zheng",
      "Hanyang Liu",
      "Kai Xu",
      "Zhenhui Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.09560"
  },
  {
    "id": "arXiv:2105.11688",
    "title": "A generalized configuration model with triadic closure",
    "abstract": "A generalized configuration model with triadic closure",
    "descriptor": "",
    "authors": [
      "Ruhui Chang",
      "Duan-Shin Lee",
      "Cheng-Shang Chang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.11688"
  },
  {
    "id": "arXiv:2105.12837",
    "title": "Fooling Partial Dependence via Data Poisoning",
    "abstract": "Comments: Accepted at ECML PKDD 2022",
    "descriptor": "\nComments: Accepted at ECML PKDD 2022\n",
    "authors": [
      "Hubert Baniecki",
      "Wojciech Kretowicz",
      "Przemyslaw Biecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.12837"
  },
  {
    "id": "arXiv:2105.14805",
    "title": "Circulant decomposition of a matrix and the eigenvalues of Toeplitz type  matrices",
    "abstract": "Circulant decomposition of a matrix and the eigenvalues of Toeplitz type  matrices",
    "descriptor": "",
    "authors": [
      "Hariprasad M.",
      "Murugesan Venkatapathi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14805"
  },
  {
    "id": "arXiv:2106.03500",
    "title": "Density estimation on smooth manifolds with normalizing flows",
    "abstract": "Density estimation on smooth manifolds with normalizing flows",
    "descriptor": "",
    "authors": [
      "Dimitris Kalatzis",
      "Johan Ziruo Ye",
      "Alison Pouplin",
      "Jesper Wohlert",
      "S\u00f8ren Hauberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03500"
  },
  {
    "id": "arXiv:2106.03847",
    "title": "GAN Cocktail: mixing GANs without dataset access",
    "abstract": "Comments: ECCV 2022. Project page is available at: this https URL",
    "descriptor": "\nComments: ECCV 2022. Project page is available at: this https URL\n",
    "authors": [
      "Omri Avrahami",
      "Dani Lischinski",
      "Ohad Fried"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.03847"
  },
  {
    "id": "arXiv:2106.04007",
    "title": "On the Coupling of Depth and Egomotion Networks for Self-Supervised  Structure from Motion",
    "abstract": "Comments: In IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'22), Kyoto, Japan, Oct. 23-27, 2022",
    "descriptor": "\nComments: In IEEE Robotics and Automation Letters (RA-L) and presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'22), Kyoto, Japan, Oct. 23-27, 2022\n",
    "authors": [
      "Brandon Wagstaff",
      "Valentin Peretroukhin",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.04007"
  },
  {
    "id": "arXiv:2106.06907",
    "title": "ADVERT: An Adaptive and Data-Driven Attention Enhancement Mechanism for  Phishing Prevention",
    "abstract": "ADVERT: An Adaptive and Data-Driven Attention Enhancement Mechanism for  Phishing Prevention",
    "descriptor": "",
    "authors": [
      "Linan Huang",
      "Shumeng Jia",
      "Emily Balcetis",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06907"
  },
  {
    "id": "arXiv:2106.06927",
    "title": "Inverting Adversarially Robust Networks for Image Synthesis",
    "abstract": "Inverting Adversarially Robust Networks for Image Synthesis",
    "descriptor": "",
    "authors": [
      "Renan A. Rojas-Gomez",
      "Raymond A. Yeh",
      "Minh N. Do",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.06927"
  },
  {
    "id": "arXiv:2106.10444",
    "title": "On the Ergodic Capacity of Reconfigurable Intelligent Surface  (RIS)-Aided MIMO Channels",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Chongjun Ouyang",
      "Hao Xu",
      "Xujie Zang",
      "Hongwen Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.10444"
  },
  {
    "id": "arXiv:2106.12142",
    "title": "IQ-Learn: Inverse soft-Q Learning for Imitation",
    "abstract": "Comments: Spotlight in NeurIPS 2021. Winner of '21 MineRL BASALT Challenge. Website: this https URL",
    "descriptor": "\nComments: Spotlight in NeurIPS 2021. Winner of '21 MineRL BASALT Challenge. Website: this https URL\n",
    "authors": [
      "Divyansh Garg",
      "Shuvam Chakraborty",
      "Chris Cundy",
      "Jiaming Song",
      "Matthieu Geist",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.12142"
  },
  {
    "id": "arXiv:2106.14490",
    "title": "Making Images Real Again: A Comprehensive Survey on Deep Image  Composition",
    "abstract": "Making Images Real Again: A Comprehensive Survey on Deep Image  Composition",
    "descriptor": "",
    "authors": [
      "Li Niu",
      "Wenyan Cong",
      "Liu Liu",
      "Yan Hong",
      "Bo Zhang",
      "Jing Liang",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14490"
  },
  {
    "id": "arXiv:2106.15961",
    "title": "On Tree Equilibria in Max-Distance Network Creation Games",
    "abstract": "On Tree Equilibria in Max-Distance Network Creation Games",
    "descriptor": "",
    "authors": [
      "Qian Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.15961"
  },
  {
    "id": "arXiv:2106.16245",
    "title": "How to Train Your MAML to Excel in Few-Shot Classification",
    "abstract": "Comments: Accepted to International Conference on Learning Representations 2022 (ICLR 2022)",
    "descriptor": "\nComments: Accepted to International Conference on Learning Representations 2022 (ICLR 2022)\n",
    "authors": [
      "Han-Jia Ye",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16245"
  },
  {
    "id": "arXiv:2107.00197",
    "title": "Few-Shot Learning with a Strong Teacher",
    "abstract": "Comments: Accepted to publish on IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",
    "descriptor": "\nComments: Accepted to publish on IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\n",
    "authors": [
      "Han-Jia Ye",
      "Lu Ming",
      "De-Chuan Zhan",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00197"
  },
  {
    "id": "arXiv:2107.00778",
    "title": "On Bridging Generic and Personalized Federated Learning for Image  Classification",
    "abstract": "Comments: Accepted to International Conference on Learning Representations 2022 (ICLR 2022)",
    "descriptor": "\nComments: Accepted to International Conference on Learning Representations 2022 (ICLR 2022)\n",
    "authors": [
      "Hong-You Chen",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.00778"
  },
  {
    "id": "arXiv:2107.01999",
    "title": "FINT: Field-aware INTeraction Neural Network For CTR Prediction",
    "abstract": "Comments: 5 pages, accepted by ICASSP 2022",
    "descriptor": "\nComments: 5 pages, accepted by ICASSP 2022\n",
    "authors": [
      "Zhishan Zhao",
      "Sen Yang",
      "Guohui Liu",
      "Dawei Feng",
      "Kele Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01999"
  },
  {
    "id": "arXiv:2107.05274",
    "title": "TransAttUnet: Multi-level Attention-guided U-Net with Transformer for  Medical Image Segmentation",
    "abstract": "TransAttUnet: Multi-level Attention-guided U-Net with Transformer for  Medical Image Segmentation",
    "descriptor": "",
    "authors": [
      "Bingzhi Chen",
      "Yishu Liu",
      "Zheng Zhang",
      "Guangming Lu",
      "Adams Wai Kin Kong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05274"
  },
  {
    "id": "arXiv:2107.05749",
    "title": "Resurrecting Address Clustering in Bitcoin",
    "abstract": "Comments: Financial Cryptography and Data Security, 2022",
    "descriptor": "\nComments: Financial Cryptography and Data Security, 2022\n",
    "authors": [
      "Malte M\u00f6ser",
      "Arvind Narayanan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.05749"
  },
  {
    "id": "arXiv:2107.06708",
    "title": "MDE4QAI: Towards Model-Driven Engineering for Quantum Artificial  Intelligence",
    "abstract": "Comments: GI Quantum Computing Workshop - INFORMATIK 2022",
    "descriptor": "\nComments: GI Quantum Computing Workshop - INFORMATIK 2022\n",
    "authors": [
      "Armin Moin",
      "Moharram Challenger",
      "Atta Badii",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2107.06708"
  },
  {
    "id": "arXiv:2107.13068",
    "title": "End-to-End Balancing for Causal Continuous Treatment-Effect Estimation",
    "abstract": "Comments: To be presented in ICML 2022",
    "descriptor": "\nComments: To be presented in ICML 2022\n",
    "authors": [
      "Mohammad Taha Bahadori",
      "Eric Tchetgen Tchetgen",
      "David E. Heckerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.13068"
  },
  {
    "id": "arXiv:2107.13309",
    "title": "$(1+\u03b5)$-Approximate Shortest Paths in Dynamic Streams",
    "abstract": "$(1+\u03b5)$-Approximate Shortest Paths in Dynamic Streams",
    "descriptor": "",
    "authors": [
      "Michael Elkin",
      "Chhaya Trehan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.13309"
  },
  {
    "id": "arXiv:2108.00781",
    "title": "Generalization Bounds using Lower Tail Exponents in Stochastic  Optimizers",
    "abstract": "Comments: 22 pages, 6 figures",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Liam Hodgkinson",
      "Umut \u015eim\u015fekli",
      "Rajiv Khanna",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.00781"
  },
  {
    "id": "arXiv:2108.03002",
    "title": "Two New Low Rank Tensor Completion Methods Based on Sum Nuclear Norm",
    "abstract": "Two New Low Rank Tensor Completion Methods Based on Sum Nuclear Norm",
    "descriptor": "",
    "authors": [
      "Hongbing Zhang",
      "Xinyi Liu",
      "Hongtao Fan",
      "Yajing Li",
      "Yinlin Ye"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.03002"
  },
  {
    "id": "arXiv:2108.04552",
    "title": "The Benefits of Implicit Regularization from SGD in Least Squares  Problems",
    "abstract": "Comments: 33 pages, 1 figure. In NeurIPS 2021",
    "descriptor": "\nComments: 33 pages, 1 figure. In NeurIPS 2021\n",
    "authors": [
      "Difan Zou",
      "Jingfeng Wu",
      "Vladimir Braverman",
      "Quanquan Gu",
      "Dean P. Foster",
      "Sham M. Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.04552"
  },
  {
    "id": "arXiv:2108.12851",
    "title": "Lower Bounds for the MMSE via Neural Network Estimation and Their  Applications to Privacy",
    "abstract": "Comments: 42 pages",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Mario Diaz",
      "Peter Kairouz",
      "Lalitha Sankar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.12851"
  },
  {
    "id": "arXiv:2108.13097",
    "title": "A theory of representation learning in deep neural networks gives a deep  generalisation of kernel methods",
    "abstract": "A theory of representation learning in deep neural networks gives a deep  generalisation of kernel methods",
    "descriptor": "",
    "authors": [
      "Adam X. Yang",
      "Maxime Robeyns",
      "Edward Milsom",
      "Nandi Schoots",
      "Laurence Aitchison"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13097"
  },
  {
    "id": "arXiv:2109.04178",
    "title": "Multiple Oracle Algorithm to Solve Continuous Games",
    "abstract": "Multiple Oracle Algorithm to Solve Continuous Games",
    "descriptor": "",
    "authors": [
      "T. Kroupa",
      "T. Votroubek"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.04178"
  },
  {
    "id": "arXiv:2109.08913",
    "title": "Intelligent Reflecting Surface Aided MIMO with Cascaded LoS Links:  Channel Modelling and Full Multiplexing Region",
    "abstract": "Intelligent Reflecting Surface Aided MIMO with Cascaded LoS Links:  Channel Modelling and Full Multiplexing Region",
    "descriptor": "",
    "authors": [
      "Mingchen Zhang",
      "Xiaojun Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.08913"
  },
  {
    "id": "arXiv:2109.09195",
    "title": "Investigating Crowdsourcing Protocols for Evaluating the Factual  Consistency of Summaries",
    "abstract": "Investigating Crowdsourcing Protocols for Evaluating the Factual  Consistency of Summaries",
    "descriptor": "",
    "authors": [
      "Xiangru Tang",
      "Alexander Fabbri",
      "Haoran Li",
      "Ziming Mao",
      "Griffin Thomas Adams",
      "Borui Wang",
      "Asli Celikyilmaz",
      "Yashar Mehdad",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.09195"
  },
  {
    "id": "arXiv:2109.10255",
    "title": "Multi-Task Learning with Sentiment, Emotion, and Target Detection to  Recognize Hate Speech and Offensive Language",
    "abstract": "Comments: publication at FIRE 2021 as system description paper in the HASOC-FIRE shared task on hate speech and offensive language detection. The original publication can be found at this http URL",
    "descriptor": "\nComments: publication at FIRE 2021 as system description paper in the HASOC-FIRE shared task on hate speech and offensive language detection. The original publication can be found at this http URL\n",
    "authors": [
      "Flor Miriam Plaza-del-Arco",
      "Sercan Halat",
      "Sebastian Pad\u00f3",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.10255"
  },
  {
    "id": "arXiv:2109.10552",
    "title": "MEPG: A Minimalist Ensemble Policy Gradient Framework for Deep  Reinforcement Learning",
    "abstract": "Comments: 19 pages, 7 figures",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Qiang He",
      "Huangyuan Su",
      "Chen Gong",
      "Xinwen Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.10552"
  },
  {
    "id": "arXiv:2109.12257",
    "title": "Tensor Full Feature Measure and Its Nonconvex Relaxation Applications to  Tensor Recovery",
    "abstract": "Comments: 13 pages, 6 figures, 5 tables",
    "descriptor": "\nComments: 13 pages, 6 figures, 5 tables\n",
    "authors": [
      "Hongbing Zhang",
      "Xinyi Liu",
      "Hongtao Fan",
      "Yajing Li",
      "Yinlin Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.12257"
  },
  {
    "id": "arXiv:2109.13492",
    "title": "Following the Data, Not the Function: Rethinking Function Orchestration  in Serverless Computing",
    "abstract": "Following the Data, Not the Function: Rethinking Function Orchestration  in Serverless Computing",
    "descriptor": "",
    "authors": [
      "Minchen Yu",
      "Tingjia Cao",
      "Wei Wang",
      "Ruichuan Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.13492"
  },
  {
    "id": "arXiv:2110.01072",
    "title": "Active Learning for Contextual Search with Binary Feedbacks",
    "abstract": "Active Learning for Contextual Search with Binary Feedbacks",
    "descriptor": "",
    "authors": [
      "Xi Chen",
      "Quanquan Liu",
      "Yining Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01072"
  },
  {
    "id": "arXiv:2110.02584",
    "title": "EdiTTS: Score-based Editing for Controllable Text-to-Speech",
    "abstract": "Comments: 4 pages, 3 figures, 3 tables, INTERSPEECH 2022",
    "descriptor": "\nComments: 4 pages, 3 figures, 3 tables, INTERSPEECH 2022\n",
    "authors": [
      "Jaesung Tae",
      "Hyeongju Kim",
      "Taesu Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02584"
  },
  {
    "id": "arXiv:2110.03427",
    "title": "Is Attention always needed? A Case Study on Language Identification from  Speech",
    "abstract": "Is Attention always needed? A Case Study on Language Identification from  Speech",
    "descriptor": "",
    "authors": [
      "Atanu Mandal",
      "Santanu Pal",
      "Indranil Dutta",
      "Mahidas Bhattacharya",
      "Sudip Kumar Naskar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.03427"
  },
  {
    "id": "arXiv:2110.05679",
    "title": "Large Language Models Can Be Strong Differentially Private Learners",
    "abstract": "Comments: 31 pages; ICLR 2022 camera ready with additional writing clarification and no \\vspace!",
    "descriptor": "\nComments: 31 pages; ICLR 2022 camera ready with additional writing clarification and no \\vspace!\n",
    "authors": [
      "Xuechen Li",
      "Florian Tram\u00e8r",
      "Percy Liang",
      "Tatsunori Hashimoto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.05679"
  },
  {
    "id": "arXiv:2110.06198",
    "title": "Last Iterate Risk Bounds of SGD with Decaying Stepsize for  Overparameterized Linear Regression",
    "abstract": "Comments: 35 pages, 2 figures, 1 table. In ICML 2022",
    "descriptor": "\nComments: 35 pages, 2 figures, 1 table. In ICML 2022\n",
    "authors": [
      "Jingfeng Wu",
      "Difan Zou",
      "Vladimir Braverman",
      "Quanquan Gu",
      "Sham M. Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06198"
  },
  {
    "id": "arXiv:2110.07098",
    "title": "Finding Local Minimax Points via (Stochastic) Cubic-Regularized GDA:  Global Convergence and Complexity",
    "abstract": "Comments: 22 pages, no figures. arXiv admin note: text overlap with arXiv:2102.04653. The original title is \"Escaping Saddle Points in Nonconvex Minimax Optimization via Cubic-Regularized Gradient Descent-Ascent\"",
    "descriptor": "\nComments: 22 pages, no figures. arXiv admin note: text overlap with arXiv:2102.04653. The original title is \"Escaping Saddle Points in Nonconvex Minimax Optimization via Cubic-Regularized Gradient Descent-Ascent\"\n",
    "authors": [
      "Ziyi Chen",
      "Qunwei Li",
      "Yi Zhou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07098"
  },
  {
    "id": "arXiv:2110.07448",
    "title": "Human-robot collaboration and machine learning: a systematic review of  recent research",
    "abstract": "Human-robot collaboration and machine learning: a systematic review of  recent research",
    "descriptor": "",
    "authors": [
      "Francesco Semeraro",
      "Alexander Griffiths",
      "Angelo Cangelosi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07448"
  },
  {
    "id": "arXiv:2110.08248",
    "title": "Probabilistic Time Series Forecasts with Autoregressive Transformation  Models",
    "abstract": "Probabilistic Time Series Forecasts with Autoregressive Transformation  Models",
    "descriptor": "",
    "authors": [
      "David R\u00fcgamer",
      "Philipp F.M. Baumann",
      "Thomas Kneib",
      "Torsten Hothorn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08248"
  },
  {
    "id": "arXiv:2110.08488",
    "title": "Lifelong Topological Visual Navigation",
    "abstract": "Comments: This paper has been accepted to IEEE Robotics and Automation Letters (RA-L) and International Conference on Intelligent Robots and Systems (IROS) 2022. Project page: this https URL",
    "descriptor": "\nComments: This paper has been accepted to IEEE Robotics and Automation Letters (RA-L) and International Conference on Intelligent Robots and Systems (IROS) 2022. Project page: this https URL\n",
    "authors": [
      "Rey Reza Wiyatno",
      "Anqi Xu",
      "Liam Paull"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08488"
  },
  {
    "id": "arXiv:2110.12118",
    "title": "Bandits with Dynamic Arm-acquisition Costs",
    "abstract": "Bandits with Dynamic Arm-acquisition Costs",
    "descriptor": "",
    "authors": [
      "Anand Kalvit",
      "Assaf Zeevi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12118"
  },
  {
    "id": "arXiv:2110.12328",
    "title": "Improving Spectral Clustering Using Spectrum-Preserving Node Aggregation",
    "abstract": "Improving Spectral Clustering Using Spectrum-Preserving Node Aggregation",
    "descriptor": "",
    "authors": [
      "Yongyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12328"
  },
  {
    "id": "arXiv:2110.12379",
    "title": "Variational quantum algorithm for Gaussian discrete solitons and their  boson sampling",
    "abstract": "Comments: Minor changes. 21 figures and 20 pages",
    "descriptor": "\nComments: Minor changes. 21 figures and 20 pages\n",
    "authors": [
      "Claudio Conti"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2110.12379"
  },
  {
    "id": "arXiv:2110.13424",
    "title": "Phish-Defence: Phishing Detection Using Deep Recurrent Neural Networks",
    "abstract": "Comments: 9 pages, 10 figures, 2 tables",
    "descriptor": "\nComments: 9 pages, 10 figures, 2 tables\n",
    "authors": [
      "Aman Rangapur",
      "Tarun Kanakam",
      "Dr Ajith Jubilson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.13424"
  },
  {
    "id": "arXiv:2110.13473",
    "title": "CTRN: Class-Temporal Relational Network for Action Detection",
    "abstract": "CTRN: Class-Temporal Relational Network for Action Detection",
    "descriptor": "",
    "authors": [
      "Rui Dai",
      "Srijan Das",
      "Francois Bremond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.13473"
  },
  {
    "id": "arXiv:2110.14066",
    "title": "Towards Model Reduction for Power System Transients with  Physics-Informed PDE",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Laurent Pagnier",
      "Michael Chertkov",
      "Julian Fritzsch",
      "Philippe Jacquod"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.14066"
  },
  {
    "id": "arXiv:2110.15547",
    "title": "Does Momentum Help? A Sample Complexity Analysis",
    "abstract": "Does Momentum Help? A Sample Complexity Analysis",
    "descriptor": "",
    "authors": [
      "Swetha Ganesh",
      "Rohan Deb",
      "Gugan Thoppe",
      "Amarjit Budhiraja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15547"
  },
  {
    "id": "arXiv:2111.02355",
    "title": "A Theoretical Analysis on Independence-driven Importance Weighting for  Covariate-shift Generalization",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Renzhe Xu",
      "Xingxuan Zhang",
      "Zheyan Shen",
      "Tong Zhang",
      "Peng Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.02355"
  },
  {
    "id": "arXiv:2111.03438",
    "title": "IPAL: Breaking up Silos of Protocol-dependent and Domain-specific  Industrial Intrusion Detection Systems",
    "abstract": "IPAL: Breaking up Silos of Protocol-dependent and Domain-specific  Industrial Intrusion Detection Systems",
    "descriptor": "",
    "authors": [
      "Konrad Wolsing",
      "Eric Wagner",
      "Antoine Saillard",
      "Martin Henze"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.03438"
  },
  {
    "id": "arXiv:2111.04858",
    "title": "Simple odd $\u03b2$-cycle inequalities for binary polynomial optimization",
    "abstract": "Comments: 16 pages, 1 figure, 2 tables",
    "descriptor": "\nComments: 16 pages, 1 figure, 2 tables\n",
    "authors": [
      "Alberto Del Pia",
      "Matthias Walter"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.04858"
  },
  {
    "id": "arXiv:2111.04867",
    "title": "TACCL: Guiding Collective Algorithm Synthesis using Communication  Sketches",
    "abstract": "Comments: Accepted at NSDI'23. Contains 17 pages, 11 figures, including Appendix",
    "descriptor": "\nComments: Accepted at NSDI'23. Contains 17 pages, 11 figures, including Appendix\n",
    "authors": [
      "Aashaka Shah",
      "Vijay Chidambaram",
      "Meghan Cowan",
      "Saeed Maleki",
      "Madan Musuvathi",
      "Todd Mytkowicz",
      "Jacob Nelson",
      "Olli Saarikivi",
      "Rachee Singh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.04867"
  },
  {
    "id": "arXiv:2111.05408",
    "title": "Robust deep learning-based semantic organ segmentation in hyperspectral  images",
    "abstract": "Comments: The first two authors (Silvia Seidlitz and Jan Sellner) contributed equally to this paper",
    "descriptor": "\nComments: The first two authors (Silvia Seidlitz and Jan Sellner) contributed equally to this paper\n",
    "authors": [
      "Silvia Seidlitz",
      "Jan Sellner",
      "Jan Odenthal",
      "Berkin \u00d6zdemir",
      "Alexander Studier-Fischer",
      "Samuel Kn\u00f6dler",
      "Leonardo Ayala",
      "Tim J. Adler",
      "Hannes G. Kenngott",
      "Minu Tizabi",
      "Martin Wagner",
      "Felix Nickel",
      "Beat P. M\u00fcller-Stich",
      "Lena Maier-Hein"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05408"
  },
  {
    "id": "arXiv:2111.06425",
    "title": "Multiple Hypothesis Hypergraph Tracking for Posture Identification in  Embryonic Caenorhabditis elegans",
    "abstract": "Multiple Hypothesis Hypergraph Tracking for Posture Identification in  Embryonic Caenorhabditis elegans",
    "descriptor": "",
    "authors": [
      "Andrew Lauziere",
      "Evan Ardiel",
      "Stephen Xu",
      "Hari Shroff"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Cell Behavior (q-bio.CB)"
    ],
    "url": "https://arxiv.org/abs/2111.06425"
  },
  {
    "id": "arXiv:2111.07993",
    "title": "CoLLIE: Continual Learning of Language Grounding from Language-Image  Embeddings",
    "abstract": "Comments: Published in Journal of Artificial Intelligence Research (JAIR)",
    "descriptor": "\nComments: Published in Journal of Artificial Intelligence Research (JAIR)\n",
    "authors": [
      "Gabriel Skantze",
      "Bram Willemsen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.07993"
  },
  {
    "id": "arXiv:2111.08974",
    "title": "Pedestrian Detection by Exemplar-Guided Contrastive Learning",
    "abstract": "Pedestrian Detection by Exemplar-Guided Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Zebin Lin",
      "Wenjie Pei",
      "Fanglin Chen",
      "David Zhang",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.08974"
  },
  {
    "id": "arXiv:2111.10205",
    "title": "Control-sharing Control Barrier Functions for Intersection Automation  under Input Constraints",
    "abstract": "Comments: Accepted paper at European Control Conference 2022, London, UK",
    "descriptor": "\nComments: Accepted paper at European Control Conference 2022, London, UK\n",
    "authors": [
      "Alexander Katriniok"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10205"
  },
  {
    "id": "arXiv:2111.11191",
    "title": "Deep Learning Based Automated COVID-19 Classification from Computed  Tomography Images",
    "abstract": "Deep Learning Based Automated COVID-19 Classification from Computed  Tomography Images",
    "descriptor": "",
    "authors": [
      "Kenan Morani",
      "Devrim Unay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11191"
  },
  {
    "id": "arXiv:2111.14580",
    "title": "Amortized Implicit Differentiation for Stochastic Bilevel Optimization",
    "abstract": "Amortized Implicit Differentiation for Stochastic Bilevel Optimization",
    "descriptor": "",
    "authors": [
      "Michael Arbel",
      "Julien Mairal"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14580"
  },
  {
    "id": "arXiv:2111.14792",
    "title": "Classification-Regression for Chart Comprehension",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Matan Levy",
      "Rami Ben-Ari",
      "Dani Lischinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14792"
  },
  {
    "id": "arXiv:2111.15240",
    "title": "Verifying and Optimizing Compact NUMA-Aware Locks on Weak Memory Models",
    "abstract": "Verifying and Optimizing Compact NUMA-Aware Locks on Weak Memory Models",
    "descriptor": "",
    "authors": [
      "Antonio Paolillo",
      "Hern\u00e1n Ponce-de-Le\u00f3n",
      "Thomas Haas",
      "Diogo Behrens",
      "Rafael Chehab",
      "Ming Fu",
      "Roland Meyer"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2111.15240"
  },
  {
    "id": "arXiv:2112.00885",
    "title": "DOPE: Doubly Optimistic and Pessimistic Exploration for Safe  Reinforcement Learning",
    "abstract": "DOPE: Doubly Optimistic and Pessimistic Exploration for Safe  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Archana Bura",
      "Aria HasanzadeZonuzy",
      "Dileep Kalathil",
      "Srinivas Shakkottai",
      "Jean-Francois Chamberland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00885"
  },
  {
    "id": "arXiv:2112.01488",
    "title": "ColBERTv2: Effective and Efficient Retrieval via Lightweight Late  Interaction",
    "abstract": "Comments: NAACL 2022. Omar and Keshav contributed equally to this work",
    "descriptor": "\nComments: NAACL 2022. Omar and Keshav contributed equally to this work\n",
    "authors": [
      "Keshav Santhanam",
      "Omar Khattab",
      "Jon Saad-Falcon",
      "Christopher Potts",
      "Matei Zaharia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01488"
  },
  {
    "id": "arXiv:2112.01759",
    "title": "NeRF-SR: High-Quality Neural Radiance Fields using Super-Sampling",
    "abstract": "Comments: Accepted to MM 2022. Project Page: this https URL",
    "descriptor": "\nComments: Accepted to MM 2022. Project Page: this https URL\n",
    "authors": [
      "Chen Wang",
      "Xian Wu",
      "Yuan-Chen Guo",
      "Song-Hai Zhang",
      "Yu-Wing Tai",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.01759"
  },
  {
    "id": "arXiv:2112.02478",
    "title": "Classification of COVID-19 on chest X-Ray images using Deep Learning  model with Histogram Equalization and Lungs Segmentation",
    "abstract": "Comments: Total number of words of the manuscript- 6577 The number of words of the abstract- 238 The number of figures- 8 The number of tables- 10",
    "descriptor": "\nComments: Total number of words of the manuscript- 6577 The number of words of the abstract- 238 The number of figures- 8 The number of tables- 10\n",
    "authors": [
      "Aman Swaraj",
      "Karan Verma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02478"
  },
  {
    "id": "arXiv:2112.02856",
    "title": "Doubly Optimal No-Regret Online Learning in Strongly Monotone Games with  Bandit Feedback",
    "abstract": "Comments: 52 pages, 3 figures",
    "descriptor": "\nComments: 52 pages, 3 figures\n",
    "authors": [
      "Tianyi Lin",
      "Zhengyuan Zhou",
      "Wenjia Ba",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.02856"
  },
  {
    "id": "arXiv:2112.03212",
    "title": "Physically Consistent Neural Networks for building thermal modeling:  theory and analysis",
    "abstract": "Comments: Preprint submitted to Applied Energy. 13 pages in the main text + 5 in appendix, 11 figures",
    "descriptor": "\nComments: Preprint submitted to Applied Energy. 13 pages in the main text + 5 in appendix, 11 figures\n",
    "authors": [
      "Loris Di Natale",
      "Bratislav Svetozarevic",
      "Philipp Heer",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03212"
  },
  {
    "id": "arXiv:2112.03258",
    "title": "DoodleFormer: Creative Sketch Drawing with Transformers",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Ankan Kumar Bhunia",
      "Salman Khan",
      "Hisham Cholakkal",
      "Rao Muhammad Anwer",
      "Fahad Shahbaz Khan",
      "Jorma Laaksonen",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.03258"
  },
  {
    "id": "arXiv:2112.04108",
    "title": "Fully Attentional Network for Semantic Segmentation",
    "abstract": "Comments: Accepted by AAAI 2022",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Qi Song",
      "Jie Li",
      "Chenghong Li",
      "Hao Guo",
      "Rui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04108"
  },
  {
    "id": "arXiv:2112.05935",
    "title": "Nonsmooth Control Barrier Function Design of Continuous Constraints for  Network Connectivity Maintenance",
    "abstract": "Comments: submitted to Automatica",
    "descriptor": "\nComments: submitted to Automatica\n",
    "authors": [
      "Pio Ong",
      "Beatrice Capelli",
      "Lorenzo Sabattini",
      "Jorge Cortes"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.05935"
  },
  {
    "id": "arXiv:2112.05941",
    "title": "Learning Efficient Policies for Picking Entangled Wire Harnesses: A  Solution to Industrial Bin Picking",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Xinyi Zhang",
      "Yukiyasu Domae",
      "Weiwei Wan",
      "Kensuke Harada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.05941"
  },
  {
    "id": "arXiv:2112.06319",
    "title": "On sketching approximations for symmetric Boolean CSPs",
    "abstract": "Comments: 27 pages; same results but significant changes in presentation",
    "descriptor": "\nComments: 27 pages; same results but significant changes in presentation\n",
    "authors": [
      "Joanna Boyland",
      "Michael Hwang",
      "Tarun Prasad",
      "Noah Singer",
      "Santhoshini Velusamy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.06319"
  },
  {
    "id": "arXiv:2112.06652",
    "title": "DriPP: Driven Point Processes to Model Stimuli Induced Patterns in M/EEG  Signals",
    "abstract": "DriPP: Driven Point Processes to Model Stimuli Induced Patterns in M/EEG  Signals",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Allain",
      "Alexandre Gramfort",
      "Thomas Moreau"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.06652"
  },
  {
    "id": "arXiv:2112.07648",
    "title": "On the Use of External Data for Spoken Named Entity Recognition",
    "abstract": "Comments: Accepted at NAACL 2022. Codebase available at this https URL",
    "descriptor": "\nComments: Accepted at NAACL 2022. Codebase available at this https URL\n",
    "authors": [
      "Ankita Pasad",
      "Felix Wu",
      "Suwon Shon",
      "Karen Livescu",
      "Kyu J. Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07648"
  },
  {
    "id": "arXiv:2112.08547",
    "title": "Learning Rich Representation of Keyphrases from Text",
    "abstract": "Learning Rich Representation of Keyphrases from Text",
    "descriptor": "",
    "authors": [
      "Mayank Kulkarni",
      "Debanjan Mahata",
      "Ravneet Arora",
      "Rajarshi Bhowmik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08547"
  },
  {
    "id": "arXiv:2112.08548",
    "title": "Isochrony-Aware Neural Machine Translation for Automatic Dubbing",
    "abstract": "Comments: Published at InterSpeech 2022 (this https URL) - scheduled for September 18-22 2022, Incheon Korea",
    "descriptor": "\nComments: Published at InterSpeech 2022 (this https URL) - scheduled for September 18-22 2022, Incheon Korea\n",
    "authors": [
      "Derek Tam",
      "Surafel M. Lakew",
      "Yogesh Virkar",
      "Prashant Mathur",
      "Marcello Federico"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08548"
  },
  {
    "id": "arXiv:2112.08565",
    "title": "An adaptive finite element method for two-dimensional elliptic equations  with line Dirac sources",
    "abstract": "Comments: 30 pages, 15 figures, 3 tables",
    "descriptor": "\nComments: 30 pages, 15 figures, 3 tables\n",
    "authors": [
      "Huihui Cao",
      "Hengguang Li",
      "Nianyu Yi",
      "Peimeng Yin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.08565"
  },
  {
    "id": "arXiv:2112.08713",
    "title": "CONFIT: Toward Faithful Dialogue Summarization with  Linguistically-Informed Contrastive Fine-tuning",
    "abstract": "CONFIT: Toward Faithful Dialogue Summarization with  Linguistically-Informed Contrastive Fine-tuning",
    "descriptor": "",
    "authors": [
      "Xiangru Tang",
      "Arjun Nair",
      "Borui Wang",
      "Bingyao Wang",
      "Jai Desai",
      "Aaron Wade",
      "Haoran Li",
      "Asli Celikyilmaz",
      "Yashar Mehdad",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08713"
  },
  {
    "id": "arXiv:2112.12002",
    "title": "Looking Beyond Corners: Contrastive Learning of Visual Representations  for Keypoint Detection and Description Extraction",
    "abstract": "Comments: Accepted at IEEE WCCI 2022",
    "descriptor": "\nComments: Accepted at IEEE WCCI 2022\n",
    "authors": [
      "Henrique Siqueira",
      "Patrick Ruhkamp",
      "Ibrahim Halfaoui",
      "Markus Karmann",
      "Onay Urfalioglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12002"
  },
  {
    "id": "arXiv:2112.12542",
    "title": "How Much of the Chemical Space Has Been Explored? Selecting the Right  Exploration Measure for Drug Discovery",
    "abstract": "How Much of the Chemical Space Has Been Explored? Selecting the Right  Exploration Measure for Drug Discovery",
    "descriptor": "",
    "authors": [
      "Yutong Xie",
      "Ziqiao Xu",
      "Jiaqi Ma",
      "Qiaozhu Mei"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12542"
  },
  {
    "id": "arXiv:2112.13826",
    "title": "Last-Iterate Convergence of Saddle Point Optimizers via High-Resolution  Differential Equations",
    "abstract": "Last-Iterate Convergence of Saddle Point Optimizers via High-Resolution  Differential Equations",
    "descriptor": "",
    "authors": [
      "Tatjana Chavdarova",
      "Michael I. Jordan",
      "Manolis Zampetakis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.13826"
  },
  {
    "id": "arXiv:2112.13889",
    "title": "Free-Viewpoint RGB-D Human Performance Capture and Rendering",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Phong Nguyen",
      "Nikolaos Sarafianos",
      "Christoph Lassner",
      "Janne Heikkila",
      "Tony Tung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.13889"
  },
  {
    "id": "arXiv:2112.14771",
    "title": "Gas Gauge: A Security Analysis Tool for Smart Contract Out-of-Gas  Vulnerabilities",
    "abstract": "Comments: 13 pages, 12 figures",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Behkish Nassirzadeh",
      "Huaiying Sun",
      "Sebastian Banescu",
      "Vijay Ganesh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.14771"
  },
  {
    "id": "arXiv:2201.00707",
    "title": "Data Driven Safe Gain-Scheduling Control",
    "abstract": "Data Driven Safe Gain-Scheduling Control",
    "descriptor": "",
    "authors": [
      "Amir Modares",
      "Nasser Sadati",
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.00707"
  },
  {
    "id": "arXiv:2201.00850",
    "title": "Selective Inhibition and Recruitment of Linear-Threshold Thalamocortical  Networks",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Michael McCreesh",
      "Jorge Cort\u00e9s"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.00850"
  },
  {
    "id": "arXiv:2201.02381",
    "title": "Offline Reinforcement Learning for Road Traffic Control",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Mayuresh Kunjir",
      "Sanjay Chawla"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.02381"
  },
  {
    "id": "arXiv:2201.02662",
    "title": "Imagined versus Remembered Stories: Quantifying Differences in Narrative  Flow",
    "abstract": "Comments: Equal contribution from Sap and Jafarpour; in review; version 2",
    "descriptor": "\nComments: Equal contribution from Sap and Jafarpour; in review; version 2\n",
    "authors": [
      "Maarten Sap",
      "Anna Jafarpour",
      "Yejin Choi",
      "Noah A. Smith",
      "James W. Pennebaker",
      "Eric Horvitz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.02662"
  },
  {
    "id": "arXiv:2201.03310",
    "title": "Minimax Flow over Acyclic Networks: Distributed Algorithms and Microgrid  Application",
    "abstract": "Minimax Flow over Acyclic Networks: Distributed Algorithms and Microgrid  Application",
    "descriptor": "",
    "authors": [
      "Marco Coraggio",
      "Saber Jafarpour",
      "Francesco Bullo",
      "Mario di Bernardo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.03310"
  },
  {
    "id": "arXiv:2201.08169",
    "title": "Secure Rate-Splitting for MIMO Broadcast Channel with Imperfect CSIT and  a Jammer",
    "abstract": "Comments: 6 pages, 3 figures",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Tong Zhang",
      "Dongsheng Chen",
      "Na Li",
      "Yufan Zhuang",
      "Bojie Lv",
      "Rui Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.08169"
  },
  {
    "id": "arXiv:2201.08284",
    "title": "Entropies of sums of independent gamma random variables",
    "abstract": "Entropies of sums of independent gamma random variables",
    "descriptor": "",
    "authors": [
      "Giorgos Chasapis",
      "Salil Singh",
      "Tomasz Tkocz"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.08284"
  },
  {
    "id": "arXiv:2201.09490",
    "title": "Dual Preference Distribution Learning for Explainable Item  Recommendation",
    "abstract": "Comments: 11 pages, 5 figures. This manuscript has been submitted to ACM TOIS",
    "descriptor": "\nComments: 11 pages, 5 figures. This manuscript has been submitted to ACM TOIS\n",
    "authors": [
      "Xue Dong",
      "Xuemeng Song",
      "Na Zheng",
      "Yinwei Wei",
      "Zhongzhou Zhao",
      "Hongjun Dai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.09490"
  },
  {
    "id": "arXiv:2201.10432",
    "title": "Parameterized Analysis of Reconfigurable Broadcast Networks (Long  Version)",
    "abstract": "Comments: This is the long version of a paper accepted at FoSSaCS 2022. Erratum: The proof of Theorem 2 contains a mistake, kindly pointed out by Nicolas Waldburger. We are working on a solution",
    "descriptor": "\nComments: This is the long version of a paper accepted at FoSSaCS 2022. Erratum: The proof of Theorem 2 contains a mistake, kindly pointed out by Nicolas Waldburger. We are working on a solution\n",
    "authors": [
      "A. R. Balasubramanian",
      "Lucie Guillou",
      "Chana Weil-Kennedy"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.10432"
  },
  {
    "id": "arXiv:2201.10460",
    "title": "Conditional entropy minimization principle for learning domain invariant  representation features",
    "abstract": "Comments: 10 pages, this paper was accepted at 26th International Conference on Pattern Recognition (ICPR-2022)",
    "descriptor": "\nComments: 10 pages, this paper was accepted at 26th International Conference on Pattern Recognition (ICPR-2022)\n",
    "authors": [
      "Thuan Nguyen",
      "Boyang Lyu",
      "Prakash Ishwar",
      "Matthias Scheutz",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.10460"
  },
  {
    "id": "arXiv:2201.12091",
    "title": "Linear Adversarial Concept Erasure",
    "abstract": "Comments: Accepted in ICML 2022",
    "descriptor": "\nComments: Accepted in ICML 2022\n",
    "authors": [
      "Shauli Ravfogel",
      "Michael Twiton",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12091"
  },
  {
    "id": "arXiv:2201.12165",
    "title": "ReGAE: Graph autoencoder based on recursive neural networks",
    "abstract": "ReGAE: Graph autoencoder based on recursive neural networks",
    "descriptor": "",
    "authors": [
      "Adam Ma\u0142kowski",
      "Jakub Grzechoci\u0144ski",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12165"
  },
  {
    "id": "arXiv:2201.12709",
    "title": "Tensor Recovery Based on Tensor Equivalent Minimax-Concave Penalty",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2109.12257",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.12257\n",
    "authors": [
      "Hongbing Zhang",
      "Xinyi Liu",
      "Hongtao Fan",
      "Yajing Li",
      "Yinlin Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12709"
  },
  {
    "id": "arXiv:2202.03323",
    "title": "Motion-Plane-Adaptive Inter Prediction in 360-Degree Video Coding",
    "abstract": "Comments: 14 pages, 12 figures, 6 tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 14 pages, 12 figures, 6 tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Andy Regensky",
      "Christian Herglotz",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03323"
  },
  {
    "id": "arXiv:2202.03825",
    "title": "skrl: Modular and Flexible Library for Reinforcement Learning",
    "abstract": "Comments: 6 pages, 8 figures",
    "descriptor": "\nComments: 6 pages, 8 figures\n",
    "authors": [
      "Antonio Serrano-Mu\u00f1oz",
      "Dimitris Chrysostomou",
      "Simon B\u00f8gh",
      "Nestor Arana-Arexolaleiba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03825"
  },
  {
    "id": "arXiv:2202.04124",
    "title": "An Adaptive Mini-Block Fisher Method for Deep Neural Networks",
    "abstract": "An Adaptive Mini-Block Fisher Method for Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Achraf Bahamou",
      "Donald Goldfarb",
      "Yi Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04124"
  },
  {
    "id": "arXiv:2202.04278",
    "title": "An algebra of alignment for relational verification",
    "abstract": "Comments: v2 adds examples and an undecidability result",
    "descriptor": "\nComments: v2 adds examples and an undecidability result\n",
    "authors": [
      "Timos Antonopoulos",
      "Eric Koskinen",
      "Ton Chanh Le",
      "Ramana Nagasamudram",
      "David A. Naumann",
      "Minh Ngo"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.04278"
  },
  {
    "id": "arXiv:2202.04295",
    "title": "On Almost Sure Convergence Rates of Stochastic Gradient Methods",
    "abstract": "Comments: 21 pages, published in the Proceedings of Thirty Fifth Conference on Learning Theory (COLT 2022)",
    "descriptor": "\nComments: 21 pages, published in the Proceedings of Thirty Fifth Conference on Learning Theory (COLT 2022)\n",
    "authors": [
      "Jun Liu",
      "Ye Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04295"
  },
  {
    "id": "arXiv:2202.05274",
    "title": "Motion Puzzle: Arbitrary Motion Style Transfer by Body Part",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Deok-Kyeong Jang",
      "Soomin Park",
      "Sung-Hee Lee"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05274"
  },
  {
    "id": "arXiv:2202.05946",
    "title": "Adaptive Algorithms, Tacit Collusion, and Design for Competition",
    "abstract": "Comments: 42 pages, 7 figures",
    "descriptor": "\nComments: 42 pages, 7 figures\n",
    "authors": [
      "Martino Banchio",
      "Giacomo Mantegazza"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.05946"
  },
  {
    "id": "arXiv:2202.06060",
    "title": "Depth-Cooperated Trimodal Network for Video Salient Object Detection",
    "abstract": "Comments: 5 pages, 3 figures, Accepted at ICIP-2022",
    "descriptor": "\nComments: 5 pages, 3 figures, Accepted at ICIP-2022\n",
    "authors": [
      "Yukang Lu",
      "Dingyao Min",
      "Keren Fu",
      "Qijun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06060"
  },
  {
    "id": "arXiv:2202.07054",
    "title": "Universal Adversarial Examples in Remote Sensing: Methodology and  Benchmark",
    "abstract": "Universal Adversarial Examples in Remote Sensing: Methodology and  Benchmark",
    "descriptor": "",
    "authors": [
      "Yonghao Xu",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07054"
  },
  {
    "id": "arXiv:2202.07428",
    "title": "Learning Contextually Fused Audio-visual Representations for  Audio-visual Speech Recognition",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Zi-Qiang Zhang",
      "Jie Zhang",
      "Jian-Shu Zhang",
      "Ming-Hui Wu",
      "Xin Fang",
      "Li-Rong Dai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07428"
  },
  {
    "id": "arXiv:2202.08333",
    "title": "Self-Supervised Representation Learning via Latent Graph Prediction",
    "abstract": "Comments: 18 pages, 2 figures, supplement included. Accepted by ICML 2022",
    "descriptor": "\nComments: 18 pages, 2 figures, supplement included. Accepted by ICML 2022\n",
    "authors": [
      "Yaochen Xie",
      "Zhao Xu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08333"
  },
  {
    "id": "arXiv:2202.09275",
    "title": "Rethinking Pareto Frontier for Performance Evaluation of Deep Neural  Networks",
    "abstract": "Rethinking Pareto Frontier for Performance Evaluation of Deep Neural  Networks",
    "descriptor": "",
    "authors": [
      "Vahid Partovi Nia",
      "Alireza Ghaffari",
      "Mahdi Zolnouri",
      "Yvon Savaria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.09275"
  },
  {
    "id": "arXiv:2202.09704",
    "title": "MANet: Improving Video Denoising with a Multi-Alignment Network",
    "abstract": "Comments: 5 pages, 5 figures",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Yaping Zhao",
      "Haitian Zheng",
      "Zhongrui Wang",
      "Jiebo Luo",
      "Edmund Y. Lam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09704"
  },
  {
    "id": "arXiv:2202.09741",
    "title": "Visual Attention Network",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Meng-Hao Guo",
      "Cheng-Ze Lu",
      "Zheng-Ning Liu",
      "Ming-Ming Cheng",
      "Shi-Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09741"
  },
  {
    "id": "arXiv:2202.09981",
    "title": "Berman Codes: A Generalization of Reed-Muller Codes that Achieve BEC  Capacity",
    "abstract": "Comments: Parts of this paper were presented at ISIT 2022 (IEEE International Symposium on Information Theory) and NCC 2022 (National Conference on Communications). Changes with respect to v1: Improved the notation in Sections II-D and II-E. No changes in technical results",
    "descriptor": "\nComments: Parts of this paper were presented at ISIT 2022 (IEEE International Symposium on Information Theory) and NCC 2022 (National Conference on Communications). Changes with respect to v1: Improved the notation in Sections II-D and II-E. No changes in technical results\n",
    "authors": [
      "Lakshmi Prasad Natarajan",
      "Prasad Krishnan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.09981"
  },
  {
    "id": "arXiv:2202.10005",
    "title": "On Grid Codes",
    "abstract": "On Grid Codes",
    "descriptor": "",
    "authors": [
      "E. J. Garc\u00eda-Claro",
      "I. S. Guti\u00e9rrez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.10005"
  },
  {
    "id": "arXiv:2202.10408",
    "title": "Embarrassingly Simple Performance Prediction for Abductive Natural  Language Inference",
    "abstract": "Comments: Published at NAACL 2022 at this https URL Please cite according to this https URL",
    "descriptor": "\nComments: Published at NAACL 2022 at this https URL Please cite according to this https URL\n",
    "authors": [
      "Em\u012bls Kadi\u0137is",
      "Vaibhav Srivastav",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.10408"
  },
  {
    "id": "arXiv:2202.10851",
    "title": "Deep learning classification of large-scale point clouds: A case study  on cuneiform tablets",
    "abstract": "Comments: 5 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 5 pages, 5 figures, 3 tables\n",
    "authors": [
      "Frederik Hagelskjaer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10851"
  },
  {
    "id": "arXiv:2202.11453",
    "title": "Bitwidth Heterogeneous Federated Learning with Progressive Weight  Dequantization",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Jaehong Yoon",
      "Geon Park",
      "Wonyong Jeong",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.11453"
  },
  {
    "id": "arXiv:2202.12838",
    "title": "RelMobNet: End-to-end relative camera pose estimation using a robust  two-stage training",
    "abstract": "Comments: 15 pages, 7 figures, 2 tables - RelMobNet revised draft",
    "descriptor": "\nComments: 15 pages, 7 figures, 2 tables - RelMobNet revised draft\n",
    "authors": [
      "Praveen Kumar Rajendran",
      "Sumit Mishra",
      "Luiz Felipe Vecchietti",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.12838"
  },
  {
    "id": "arXiv:2202.13056",
    "title": "Automated Identification of Toxic Code Reviews Using ToxiCR",
    "abstract": "Automated Identification of Toxic Code Reviews Using ToxiCR",
    "descriptor": "",
    "authors": [
      "Jaydeb Sarker",
      "Asif Kamal Turzo",
      "Ming Dong",
      "Amiangshu Bosu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.13056"
  },
  {
    "id": "arXiv:2202.13485",
    "title": "Pareto-Rational Verification",
    "abstract": "Comments: 38 pages, 10 figures, 2 tables",
    "descriptor": "\nComments: 38 pages, 10 figures, 2 tables\n",
    "authors": [
      "V\u00e9ronique Bruy\u00e8re",
      "Jean-Fran\u00e7ois Raskin",
      "Cl\u00e9ment Tamines"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.13485"
  },
  {
    "id": "arXiv:2202.13487",
    "title": "Point Label Aware Superpixels for Multi-species Segmentation of  Underwater Imagery",
    "abstract": "Point Label Aware Superpixels for Multi-species Segmentation of  Underwater Imagery",
    "descriptor": "",
    "authors": [
      "Scarlett Raine",
      "Ross Marchant",
      "Brano Kusy",
      "Frederic Maire",
      "Tobias Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.13487"
  },
  {
    "id": "arXiv:2202.13675",
    "title": "A Survey on Recent Advances and Challenges in Reinforcement Learning  Methods for Task-Oriented Dialogue Policy Learning",
    "abstract": "A Survey on Recent Advances and Challenges in Reinforcement Learning  Methods for Task-Oriented Dialogue Policy Learning",
    "descriptor": "",
    "authors": [
      "Wai-Chung Kwan",
      "Hongru Wang",
      "Huimin Wang",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.13675"
  },
  {
    "id": "arXiv:2202.13691",
    "title": "On the quadrature exactness in hyperinterpolation",
    "abstract": "Comments: 16 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 16 pages, 5 figures, 1 table\n",
    "authors": [
      "Congpei An",
      "Hao-Ning Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.13691"
  },
  {
    "id": "arXiv:2203.00300",
    "title": "Towards Decentralized Identity Management in Multi-stakeholder 6G  Networks",
    "abstract": "Comments: Published at the 1st International Conference on 6G Networking (6GNet 2022) in Paris, France",
    "descriptor": "\nComments: Published at the 1st International Conference on 6G Networking (6GNet 2022) in Paris, France\n",
    "authors": [
      "Sandro Rodriguez Garzon",
      "Hakan Yildiz",
      "Axel K\u00fcpper"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.00300"
  },
  {
    "id": "arXiv:2203.00887",
    "title": "Sampling Random Group Fair Rankings",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Sruthi Gorantla",
      "Amit Deshpande",
      "Anand Louis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.00887"
  },
  {
    "id": "arXiv:2203.01074",
    "title": "Continual BatchNorm Adaptation (CBNA) for Semantic Segmentation",
    "abstract": "Comments: Accepted to IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Marvin Klingner",
      "Mouadh Ayache",
      "Tim Fingscheidt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01074"
  },
  {
    "id": "arXiv:2203.01322",
    "title": "Recent, rapid advancement in visual question answering architecture: a  review",
    "abstract": "Comments: 8 pages. Accepted to EIT2022 conference and posted on ArXiv in accordance with IEEE policy",
    "descriptor": "\nComments: 8 pages. Accepted to EIT2022 conference and posted on ArXiv in accordance with IEEE policy\n",
    "authors": [
      "Venkat Kodali",
      "Daniel Berleant"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.01322"
  },
  {
    "id": "arXiv:2203.01474",
    "title": "Spatio-Temporal Gating-Adjacency GCN for Human Motion Prediction",
    "abstract": "Comments: We declare that the evaluation metric we used is following STSGCN, that is, the average error over frames (denoted by *), which we only found when we checked their test code on July 9, 2022",
    "descriptor": "\nComments: We declare that the evaluation metric we used is following STSGCN, that is, the average error over frames (denoted by *), which we only found when we checked their test code on July 9, 2022\n",
    "authors": [
      "Chongyang Zhong",
      "Lei Hu",
      "Zihao Zhang",
      "Yongjing Ye",
      "Shihong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01474"
  },
  {
    "id": "arXiv:2203.02651",
    "title": "Ensemble Knowledge Guided Sub-network Search and Fine-tuning for Filter  Pruning",
    "abstract": "Comments: accepted to ECCV2022",
    "descriptor": "\nComments: accepted to ECCV2022\n",
    "authors": [
      "Seunghyun Lee",
      "Byung Cheol Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02651"
  },
  {
    "id": "arXiv:2203.03005",
    "title": "Semantic-Aware Latent Space Exploration for Face Image Restoration",
    "abstract": "Semantic-Aware Latent Space Exploration for Face Image Restoration",
    "descriptor": "",
    "authors": [
      "Yanhui Guo",
      "Fangzhou Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03005"
  },
  {
    "id": "arXiv:2203.03605",
    "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection",
    "abstract": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection",
    "descriptor": "",
    "authors": [
      "Hao Zhang",
      "Feng Li",
      "Shilong Liu",
      "Lei Zhang",
      "Hang Su",
      "Jun Zhu",
      "Lionel M. Ni",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03605"
  },
  {
    "id": "arXiv:2203.03952",
    "title": "EdgeFormer: Improving Light-weight ConvNets by Learning from Vision  Transformers",
    "abstract": "Comments: This paper has been acccpted by ECCV 2022. Code is available at this https URL",
    "descriptor": "\nComments: This paper has been acccpted by ECCV 2022. Code is available at this https URL\n",
    "authors": [
      "Haokui Zhang",
      "Wenze Hu",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03952"
  },
  {
    "id": "arXiv:2203.04559",
    "title": "Source-free Video Domain Adaptation by Learning Temporal Consistency for  Action Recognition",
    "abstract": "Comments: Accepted by ECCV 2022, update to camera-ready version with updated title. 22 pages, 5 figures, 7 tables",
    "descriptor": "\nComments: Accepted by ECCV 2022, update to camera-ready version with updated title. 22 pages, 5 figures, 7 tables\n",
    "authors": [
      "Yuecong Xu",
      "Jianfei Yang",
      "Haozhi Cao",
      "Keyu Wu",
      "Wu Min",
      "Zhenghua Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04559"
  },
  {
    "id": "arXiv:2203.04608",
    "title": "Modular Probabilistic Models via Algebraic Effects",
    "abstract": "Modular Probabilistic Models via Algebraic Effects",
    "descriptor": "",
    "authors": [
      "Minh Nguyen",
      "Roly Perera",
      "Meng Wang",
      "Nicolas Wu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.04608"
  },
  {
    "id": "arXiv:2203.04845",
    "title": "Coarse-to-Fine Sparse Transformer for Hyperspectral Image Reconstruction",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Yuanhao Cai",
      "Jing Lin",
      "Xiaowan Hu",
      "Haoqian Wang",
      "Xin Yuan",
      "Yulun Zhang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04845"
  },
  {
    "id": "arXiv:2203.04925",
    "title": "Correlated quantization for distributed mean estimation and optimization",
    "abstract": "Correlated quantization for distributed mean estimation and optimization",
    "descriptor": "",
    "authors": [
      "Ananda Theertha Suresh",
      "Ziteng Sun",
      "Jae Hun Ro",
      "Felix Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.04925"
  },
  {
    "id": "arXiv:2203.05823",
    "title": "Learning Discriminative Representations and Decision Boundaries for Open  Intent Detection",
    "abstract": "Comments: 13 pages, 7 figures",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Hanlei Zhang",
      "Hua Xu",
      "Shaojie Zhao",
      "Qianrui Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05823"
  },
  {
    "id": "arXiv:2203.06311",
    "title": "ELLE: Efficient Lifelong Pre-training for Emerging Data",
    "abstract": "Comments: Findings of ACL 2022",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Yujia Qin",
      "Jiajie Zhang",
      "Yankai Lin",
      "Zhiyuan Liu",
      "Peng Li",
      "Maosong Sun",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.06311"
  },
  {
    "id": "arXiv:2203.06911",
    "title": "Non-Parametric Modeling of Spatio-Temporal Human Activity Based on  Mobile Robot Observations",
    "abstract": "Comments: Accepted for publication at 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)",
    "descriptor": "\nComments: Accepted for publication at 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Marvin Stuede",
      "Moritz Schappler"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.06911"
  },
  {
    "id": "arXiv:2203.07061",
    "title": "On the Skolem Problem for Reversible Sequences",
    "abstract": "Comments: 15 pages, accepted for publication at MFCS 2022",
    "descriptor": "\nComments: 15 pages, accepted for publication at MFCS 2022\n",
    "authors": [
      "George Kenison"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.07061"
  },
  {
    "id": "arXiv:2203.07322",
    "title": "Efficient Model-based Multi-agent Reinforcement Learning via Optimistic  Equilibrium Computation",
    "abstract": "Efficient Model-based Multi-agent Reinforcement Learning via Optimistic  Equilibrium Computation",
    "descriptor": "",
    "authors": [
      "Pier Giuseppe Sessa",
      "Maryam Kamgarpour",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.07322"
  },
  {
    "id": "arXiv:2203.07471",
    "title": "Robust Dynamic Walking for a 3D Dual-SLIP Model under One-Step  Unilateral Stiffness Perturbations: Towards Bipedal Locomotion over Compliant  Terrain",
    "abstract": "Comments: This work was published in the 30th Mediterranean Conference on Control and Automation, MED'22",
    "descriptor": "\nComments: This work was published in the 30th Mediterranean Conference on Control and Automation, MED'22\n",
    "authors": [
      "Chrysostomos Karakasis",
      "Ioannis Poulakakis",
      "Panagiotis Artemiadis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.07471"
  },
  {
    "id": "arXiv:2203.07756",
    "title": "Multi-Curve Translator for High-Resolution Photorealistic Image  Translation",
    "abstract": "Multi-Curve Translator for High-Resolution Photorealistic Image  Translation",
    "descriptor": "",
    "authors": [
      "Yuda Song",
      "Hui Qian",
      "Xin Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07756"
  },
  {
    "id": "arXiv:2203.08245",
    "title": "Reconstructing Missing EHRs Using Time-Aware Within- and Cross-Visit  Information for Septic Shock Early Prediction",
    "abstract": "Comments: 12 pages, accepted at IEEE ICHI'22",
    "descriptor": "\nComments: 12 pages, accepted at IEEE ICHI'22\n",
    "authors": [
      "Ge Gao",
      "Farzaneh Khoshnevisan",
      "Min Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.08245"
  },
  {
    "id": "arXiv:2203.09513",
    "title": "On Multi-Domain Long-Tailed Recognition, Imbalanced Domain  Generalization and Beyond",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Yuzhe Yang",
      "Hao Wang",
      "Dina Katabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09513"
  },
  {
    "id": "arXiv:2203.10114",
    "title": "Seamless lightning nowcasting with recurrent-convolutional deep learning",
    "abstract": "Comments: 21 pages, 9 figures. Submitted to Artificial Intelligence for the Earth Sciences. Changes after the previous version are in response to the comments received from three anonymous reviewers. Transferred from Weather and Forecasting",
    "descriptor": "\nComments: 21 pages, 9 figures. Submitted to Artificial Intelligence for the Earth Sciences. Changes after the previous version are in response to the comments received from three anonymous reviewers. Transferred from Weather and Forecasting\n",
    "authors": [
      "Jussi Leinonen",
      "Ulrich Hamann",
      "Urs Germann"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.10114"
  },
  {
    "id": "arXiv:2203.10533",
    "title": "Strategic Analysis of Griefing Attack in Lightning Network",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Subhra Mazumdar",
      "Prabal Banerjee",
      "Abhinandan Sinha",
      "Sushmita Ruj",
      "Bimal Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.10533"
  },
  {
    "id": "arXiv:2203.10681",
    "title": "Online Continual Learning for Embedded Devices",
    "abstract": "Comments: To appear in the Conference on Lifelong Learning Agents (CoLLAs-2022)",
    "descriptor": "\nComments: To appear in the Conference on Lifelong Learning Agents (CoLLAs-2022)\n",
    "authors": [
      "Tyler L. Hayes",
      "Christopher Kanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.10681"
  },
  {
    "id": "arXiv:2203.11805",
    "title": "Robust Classification using Contractive Hamiltonian Neural ODEs",
    "abstract": "Robust Classification using Contractive Hamiltonian Neural ODEs",
    "descriptor": "",
    "authors": [
      "Muhammad Zakwan",
      "Liang Xu",
      "Giancarlo Ferrari-Trecate"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11805"
  },
  {
    "id": "arXiv:2203.12044",
    "title": "Data-Driven Optimal Control of Affine Systems: A Linear Programming  Perspective",
    "abstract": "Data-Driven Optimal Control of Affine Systems: A Linear Programming  Perspective",
    "descriptor": "",
    "authors": [
      "Andrea Martinelli",
      "Matilde Gargiani",
      "Marina Draskovic",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.12044"
  },
  {
    "id": "arXiv:2203.15379",
    "title": "VoiceMe: Personalized voice generation in TTS",
    "abstract": "Comments: Accepted to Interspeech'22. Audio and video samples are available at: this https URL",
    "descriptor": "\nComments: Accepted to Interspeech'22. Audio and video samples are available at: this https URL\n",
    "authors": [
      "Pol van Rijn",
      "Silvan Mertes",
      "Dominik Schiller",
      "Piotr Dura",
      "Hubert Siuzdak",
      "Peter M. C. Harrison",
      "Elisabeth Andr\u00e9",
      "Nori Jacoby"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.15379"
  },
  {
    "id": "arXiv:2203.15418",
    "title": "Comparative Evaluations of Visualization Onboarding Methods",
    "abstract": "Comparative Evaluations of Visualization Onboarding Methods",
    "descriptor": "",
    "authors": [
      "Christina Stoiber",
      "Conny Walchshofer",
      "Margit Pohl",
      "Benjamin Potzmann",
      "Florian Grassinger",
      "Holger Stitz",
      "Marc Streit",
      "Wolfgang Aigner"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15418"
  },
  {
    "id": "arXiv:2203.16773",
    "title": "SpeechPrompt: An Exploration of Prompt Tuning on Generative Spoken  Language Model for Speech Processing Tasks",
    "abstract": "Comments: Accepted to be published in the Proceedings of Interspeech 2022",
    "descriptor": "\nComments: Accepted to be published in the Proceedings of Interspeech 2022\n",
    "authors": [
      "Kai-Wei Chang",
      "Wei-Cheng Tseng",
      "Shang-Wen Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.16773"
  },
  {
    "id": "arXiv:2203.16930",
    "title": "WavThruVec: Latent speech representation as intermediate features for  neural speech synthesis",
    "abstract": "Comments: Accepted to INTERSPEECH 2022. Audio samples are available at: this https URL",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022. Audio samples are available at: this https URL\n",
    "authors": [
      "Hubert Siuzdak",
      "Piotr Dura",
      "Pol van Rijn",
      "Nori Jacoby"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16930"
  },
  {
    "id": "arXiv:2203.17041",
    "title": "On the Population Monotonicity of Independent Set Games",
    "abstract": "On the Population Monotonicity of Independent Set Games",
    "descriptor": "",
    "authors": [
      "Libing Wang",
      "Han Xiao",
      "Donglei Du",
      "Dachuan Xu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.17041"
  },
  {
    "id": "arXiv:2203.17139",
    "title": "Prefix Filter: Practically and Theoretically Better Than Bloom",
    "abstract": "Comments: Full version of VLDB'22 paper",
    "descriptor": "\nComments: Full version of VLDB'22 paper\n",
    "authors": [
      "Tomer Even",
      "Guy Even",
      "Adam Morrison"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.17139"
  },
  {
    "id": "arXiv:2203.17144",
    "title": "Instability of backoff protocols with arbitrary arrival rates",
    "abstract": "Instability of backoff protocols with arbitrary arrival rates",
    "descriptor": "",
    "authors": [
      "Leslie Ann Goldberg",
      "John Lapinskas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Networking and Internet Architecture (cs.NI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.17144"
  },
  {
    "id": "arXiv:2204.00298",
    "title": "Unitail: Detecting, Reading, and Matching in Retail Scene",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Fangyi Chen",
      "Han Zhang",
      "Zaiwang Li",
      "Jiachen Dou",
      "Shentong Mo",
      "Hao Chen",
      "Yongxin Zhang",
      "Uzair Ahmed",
      "Chenchen Zhu",
      "Marios Savvides"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00298"
  },
  {
    "id": "arXiv:2204.00466",
    "title": "Improved Soft-aided Decoding of Product Codes with Dynamic Reliability  Scores",
    "abstract": "Comments: Revised version",
    "descriptor": "\nComments: Revised version\n",
    "authors": [
      "Sisi Miao",
      "Lukas Rapp",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.00466"
  },
  {
    "id": "arXiv:2204.00657",
    "title": "Multimodal Clustering with Role Induced Constraints for Speaker  Diarization",
    "abstract": "Comments: To appear at Interspeech 2022",
    "descriptor": "\nComments: To appear at Interspeech 2022\n",
    "authors": [
      "Nikolaos Flemotomos",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.00657"
  },
  {
    "id": "arXiv:2204.02128",
    "title": "Computing in Anonymous Dynamic Networks Is Linear",
    "abstract": "Comments: 34 pages, 8 figures",
    "descriptor": "\nComments: 34 pages, 8 figures\n",
    "authors": [
      "Giuseppe A. Di Luna",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.02128"
  },
  {
    "id": "arXiv:2204.02242",
    "title": "Normalizing Flow-based Day-Ahead Wind Power Scenario Generation for  Profitable and Reliable Delivery Commitments by Wind Farm Operators",
    "abstract": "Comments: manuscript (18 pages, 7 figures, 6 tables), supporting information (2 pages, 1 figure, 1 table)",
    "descriptor": "\nComments: manuscript (18 pages, 7 figures, 6 tables), supporting information (2 pages, 1 figure, 1 table)\n",
    "authors": [
      "Eike Cramer",
      "Leonard Paeleke",
      "Alexander Mitsos",
      "Manuel Dahmen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02242"
  },
  {
    "id": "arXiv:2204.02426",
    "title": "OccamNets: Mitigating Dataset Bias by Favoring Simpler Hypotheses",
    "abstract": "OccamNets: Mitigating Dataset Bias by Favoring Simpler Hypotheses",
    "descriptor": "",
    "authors": [
      "Robik Shrestha",
      "Kushal Kafle",
      "Christopher Kanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02426"
  },
  {
    "id": "arXiv:2204.02779",
    "title": "A Dempster-Shafer approach to trustworthy AI with application to fetal  brain MRI segmentation",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Lucas Fidon",
      "Michael Aertsen",
      "Florian Kofler",
      "Andrea Bink",
      "Anna L. David",
      "Thomas Deprest",
      "Doaa Emam",
      "Fr\u00e9d\u00e9ric Guffens",
      "Andr\u00e1s Jakab",
      "Gregor Kasprian",
      "Patric Kienast",
      "Andrew Melbourne",
      "Bjoern Menze",
      "Nada Mufti",
      "Ivana Pogledic",
      "Daniela Prayer",
      "Marlene Stuempflen",
      "Esther Van Elslander",
      "S\u00e9bastien Ourselin",
      "Jan Deprest",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02779"
  },
  {
    "id": "arXiv:2204.04654",
    "title": "Fashionformer: A simple, Effective and Unified Baseline for Human  Fashion Segmentation and Recognition",
    "abstract": "Comments: ECCV-2022",
    "descriptor": "\nComments: ECCV-2022\n",
    "authors": [
      "Shilin Xu",
      "Xiangtai Li",
      "Jingbo Wang",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04654"
  },
  {
    "id": "arXiv:2204.04655",
    "title": "Panoptic-PartFormer: Learning a Unified Model for Panoptic Part  Segmentation",
    "abstract": "Comments: ECCV-2022",
    "descriptor": "\nComments: ECCV-2022\n",
    "authors": [
      "Xiangtai Li",
      "Shilin Xu",
      "Yibo Yang",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04655"
  },
  {
    "id": "arXiv:2204.06119",
    "title": "Do you know \"saudade\"? The importance of a cultural and language-based  emotion approach for HCI",
    "abstract": "Comments: Position Paper accepted to The Future of Emotion in Human-Computer Interaction Workshop at ACM CHI 2022",
    "descriptor": "\nComments: Position Paper accepted to The Future of Emotion in Human-Computer Interaction Workshop at ACM CHI 2022\n",
    "authors": [
      "Diogo Cortiz",
      "Paulo Boggio"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.06119"
  },
  {
    "id": "arXiv:2204.06187",
    "title": "Calibrating Class Weights with Multi-Modal Information for Partial Video  Domain Adaptation",
    "abstract": "Comments: Accepted by ACM Multimedia (ACMMM) 2022, update to camera-ready version. 8 pages of text, 5 figures, 2 tables",
    "descriptor": "\nComments: Accepted by ACM Multimedia (ACMMM) 2022, update to camera-ready version. 8 pages of text, 5 figures, 2 tables\n",
    "authors": [
      "Xiyu Wang",
      "Yuecong Xu",
      "Kezhi Mao",
      "Jianfei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.06187"
  },
  {
    "id": "arXiv:2204.06520",
    "title": "Bayesian Negative Sampling for Recommendation",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Bin Liu",
      "Bang Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.06520"
  },
  {
    "id": "arXiv:2204.07143",
    "title": "Neighborhood Attention Transformer",
    "abstract": "Neighborhood Attention Transformer",
    "descriptor": "",
    "authors": [
      "Ali Hassani",
      "Steven Walton",
      "Jiachen Li",
      "Shen Li",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07143"
  },
  {
    "id": "arXiv:2204.07682",
    "title": "Data-Centric Distrust Quantification for Responsible AI: When  Data-driven Outcomes Are Not Reliable",
    "abstract": "Data-Centric Distrust Quantification for Responsible AI: When  Data-driven Outcomes Are Not Reliable",
    "descriptor": "",
    "authors": [
      "Nima Shahbazi",
      "Abolfazl Asudeh"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.07682"
  },
  {
    "id": "arXiv:2204.11190",
    "title": "Knowledge-aware Document Summarization: A Survey of Knowledge, Embedding  Methods and Architectures",
    "abstract": "Comments: 29 pages, 3 figures",
    "descriptor": "\nComments: 29 pages, 3 figures\n",
    "authors": [
      "Yutong Qu",
      "Wei Emma Zhang",
      "Jian Yang",
      "Lingfei Wu",
      "Jia Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11190"
  },
  {
    "id": "arXiv:2204.13630",
    "title": "Rotationally Equivariant 3D Object Detection",
    "abstract": "Comments: CVPR 2022, project website: this https URL",
    "descriptor": "\nComments: CVPR 2022, project website: this https URL\n",
    "authors": [
      "Hong-Xing Yu",
      "Jiajun Wu",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.13630"
  },
  {
    "id": "arXiv:2204.13990",
    "title": "Particle Swarm Optimization Based Demand Response Using Artificial  Neural Network Based Load Prediction",
    "abstract": "Particle Swarm Optimization Based Demand Response Using Artificial  Neural Network Based Load Prediction",
    "descriptor": "",
    "authors": [
      "Nasrin Bayat"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.13990"
  },
  {
    "id": "arXiv:2205.00303",
    "title": "Composition-aware Graphic Layout GAN for Visual-textual Presentation  Designs",
    "abstract": "Comments: Accepted by IJCAI 2022 (AI, THE ARTS AND CREATIVITY TRACK)",
    "descriptor": "\nComments: Accepted by IJCAI 2022 (AI, THE ARTS AND CREATIVITY TRACK)\n",
    "authors": [
      "Min Zhou",
      "Chenchen Xu",
      "Ye Ma",
      "Tiezheng Ge",
      "Yuning Jiang",
      "Weiwei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.00303"
  },
  {
    "id": "arXiv:2205.01242",
    "title": "Physics-Based Inverse Rendering using Combined Implicit and Explicit  Geometries",
    "abstract": "Physics-Based Inverse Rendering using Combined Implicit and Explicit  Geometries",
    "descriptor": "",
    "authors": [
      "Guangyan Cai",
      "Kai Yan",
      "Zhao Dong",
      "Ioannis Gkioulekas",
      "Shuang Zhao"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.01242"
  },
  {
    "id": "arXiv:2205.01271",
    "title": "Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Yihan Wang",
      "Muyang Li",
      "Han Cai",
      "Wei-Ming Chen",
      "Song Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01271"
  },
  {
    "id": "arXiv:2205.01289",
    "title": "On Ranking Consistency of Pre-ranking Stage",
    "abstract": "Comments: 9 pagees, 5 figures",
    "descriptor": "\nComments: 9 pagees, 5 figures\n",
    "authors": [
      "Siyu Gu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.01289"
  },
  {
    "id": "arXiv:2205.01388",
    "title": "Restarted randomized surrounding methods for solving large linear  equations",
    "abstract": "Restarted randomized surrounding methods for solving large linear  equations",
    "descriptor": "",
    "authors": [
      "Junfeng Yin",
      "Nan Li",
      "Ning Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.01388"
  },
  {
    "id": "arXiv:2205.02683",
    "title": "Low-complexity Beam Selection algorithms based on SVD for MmWave Massive  MIMO Systems",
    "abstract": "Low-complexity Beam Selection algorithms based on SVD for MmWave Massive  MIMO Systems",
    "descriptor": "",
    "authors": [
      "Jinxing Yang",
      "Jihong Yu",
      "Shuai Wang",
      "Hao Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.02683"
  },
  {
    "id": "arXiv:2205.02944",
    "title": "A Deep Bayesian Bandits Approach for Anticancer Therapy: Exploration via  Functional Prior",
    "abstract": "A Deep Bayesian Bandits Approach for Anticancer Therapy: Exploration via  Functional Prior",
    "descriptor": "",
    "authors": [
      "Mingyu Lu",
      "Yifang Chen",
      "Su-In Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02944"
  },
  {
    "id": "arXiv:2205.02974",
    "title": "Generate and Edit Your Own Character in a Canonical View",
    "abstract": "Comments: AI for Content Creation Workshop at CVPR 2022",
    "descriptor": "\nComments: AI for Content Creation Workshop at CVPR 2022\n",
    "authors": [
      "Jeong-gi Kwak",
      "Yuanming Li",
      "Dongsik Yoon",
      "David Han",
      "Hanseok Ko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.02974"
  },
  {
    "id": "arXiv:2205.04198",
    "title": "Towards Development with Multi-Version Models: Detecting Merge Conflicts  and Checking Well-Formedness",
    "abstract": "Comments: 15th International Conference on Graph Transformation",
    "descriptor": "\nComments: 15th International Conference on Graph Transformation\n",
    "authors": [
      "Matthias Barkowsky",
      "Holger Giese"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.04198"
  },
  {
    "id": "arXiv:2205.04382",
    "title": "FlowBot3D: Learning 3D Articulation Flow to Manipulate Articulated  Objects",
    "abstract": "Comments: Accepted to Robotics Science and Systems (RSS) 2022",
    "descriptor": "\nComments: Accepted to Robotics Science and Systems (RSS) 2022\n",
    "authors": [
      "Ben Eisner",
      "Harry Zhang",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.04382"
  },
  {
    "id": "arXiv:2205.04550",
    "title": "A for-loop is all you need. For solving the inverse problem in the case  of personalized tumor growth modeling",
    "abstract": "A for-loop is all you need. For solving the inverse problem in the case  of personalized tumor growth modeling",
    "descriptor": "",
    "authors": [
      "Ivan Ezhov",
      "Marcel Rosier",
      "Lucas Zimmer",
      "Florian Kofler",
      "Suprosanna Shit",
      "Johannes Paetzold",
      "Kevin Scibilia",
      "Leon Maechler",
      "Katharina Franitza",
      "Tamaz Amiranashvili",
      "Martin J. Menten",
      "Marie Metz",
      "Sailesh Conjeti",
      "Benedikt Wiestler",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.04550"
  },
  {
    "id": "arXiv:2205.05178",
    "title": "Magnitude and topological entropy of digraphs",
    "abstract": "Comments: Accepted to ACT 2022; cleaned up results re: flow graphs (and in process fixed a subtle and pointless error)",
    "descriptor": "\nComments: Accepted to ACT 2022; cleaned up results re: flow graphs (and in process fixed a subtle and pointless error)\n",
    "authors": [
      "Steve Huntsman"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.05178"
  },
  {
    "id": "arXiv:2205.05838",
    "title": "Orthogonal Gromov-Wasserstein Discrepancy with Efficient Lower Bound",
    "abstract": "Comments: Published as a conference paper in UAI 2022",
    "descriptor": "\nComments: Published as a conference paper in UAI 2022\n",
    "authors": [
      "Hongwei Jin",
      "Zishun Yu",
      "Xinhua Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05838"
  },
  {
    "id": "arXiv:2205.06237",
    "title": "Knowledge Distillation for Multi-Target Domain Adaptation in Real-Time  Person Re-Identification",
    "abstract": "Comments: 4 pages, 2 figures, submitted to ICIP2022",
    "descriptor": "\nComments: 4 pages, 2 figures, submitted to ICIP2022\n",
    "authors": [
      "F\u00e9lix Remigereau",
      "Djebril Mekhazni",
      "Sajjad Abdoli",
      "Le Thanh Nguyen-Meidine",
      "Rafael M. O. Cruz",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.06237"
  },
  {
    "id": "arXiv:2205.06811",
    "title": "Nearly Optimal Algorithms for Linear Contextual Bandits with Adversarial  Corruptions",
    "abstract": "Comments: 25 pages, 1 table. This version simplifies the proof of the regret upper bound in Version 1, and provides a stronger result for the lower bound",
    "descriptor": "\nComments: 25 pages, 1 table. This version simplifies the proof of the regret upper bound in Version 1, and provides a stronger result for the lower bound\n",
    "authors": [
      "Jiafan He",
      "Dongruo Zhou",
      "Tong Zhang",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.06811"
  },
  {
    "id": "arXiv:2205.07401",
    "title": "Statistical Modeling and Forecasting of Automatic Generation Control  Signals",
    "abstract": "Comments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada",
    "descriptor": "\nComments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Sarnaduti Brahma",
      "Hamid R. Ossareh",
      "Mads R. Almassalkhi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.07401"
  },
  {
    "id": "arXiv:2205.08579",
    "title": "The Power of Fragmentation: A Hierarchical Transformer Model for  Structural Segmentation in Symbolic Music Generation",
    "abstract": "The Power of Fragmentation: A Hierarchical Transformer Model for  Structural Segmentation in Symbolic Music Generation",
    "descriptor": "",
    "authors": [
      "Guowei Wu",
      "Shipei Liu",
      "Xiaoya Fan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.08579"
  },
  {
    "id": "arXiv:2205.08980",
    "title": "Sparse superposition codes with rotational invariant coding matrices for  memoryless channels",
    "abstract": "Comments: Submitted to the The IEEE Information Theory Workshop (ITW 2022)",
    "descriptor": "\nComments: Submitted to the The IEEE Information Theory Workshop (ITW 2022)\n",
    "authors": [
      "YuHao Liu",
      "Teng Fu",
      "Jean Barbier",
      "TianQi Hou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ],
    "url": "https://arxiv.org/abs/2205.08980"
  },
  {
    "id": "arXiv:2205.10721",
    "title": "System-Level Evaluation of Beam Hopping in NR-Based LEO Satellite  Communication System",
    "abstract": "Comments: 6 pages, 13 figures",
    "descriptor": "\nComments: 6 pages, 13 figures\n",
    "authors": [
      "Jingwei Zhang",
      "Dali Qin",
      "Chuili Kong",
      "Feiran Zhao",
      "Rong Li",
      "Jun Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.10721"
  },
  {
    "id": "arXiv:2205.11680",
    "title": "HiPAL: A Deep Framework for Physician Burnout Prediction Using Activity  Logs in Electronic Health Records",
    "abstract": "Comments: 11 pages including appendices. Accepted by KDD'22",
    "descriptor": "\nComments: 11 pages including appendices. Accepted by KDD'22\n",
    "authors": [
      "Hanyang Liu",
      "Sunny S. Lou",
      "Benjamin C. Warner",
      "Derek R. Harford",
      "Thomas Kannampallil",
      "Chenyang Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11680"
  },
  {
    "id": "arXiv:2205.12029",
    "title": "VLCDoC: Vision-Language Contrastive Pre-Training Model for Cross-Modal  Document Classification",
    "abstract": "Comments: Preprint submitted to Pattern Recognition",
    "descriptor": "\nComments: Preprint submitted to Pattern Recognition\n",
    "authors": [
      "Souhail Bakkali",
      "Zuheng Ming",
      "Mickael Coustaty",
      "Mar\u00e7al Rusi\u00f1ol",
      "Oriol Ramos Terrades"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12029"
  },
  {
    "id": "arXiv:2205.12073",
    "title": "Edge Semantic Cognitive Intelligence for 6G Networks: Novel Theoretical  Models, Enabling Framework, and Typical Applications",
    "abstract": "Comments: 9 pages, 7 figures, accepted by China Communications as an invited paper",
    "descriptor": "\nComments: 9 pages, 7 figures, accepted by China Communications as an invited paper\n",
    "authors": [
      "Peihao Dong",
      "Qihui Wu",
      "Xiaofei Zhang",
      "Guoru Ding"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.12073"
  },
  {
    "id": "arXiv:2205.12089",
    "title": "Sim-To-Real Transfer of Visual Grounding for Human-Aided Ambiguity  Resolution",
    "abstract": "Comments: Accepted CoLLAs 2022",
    "descriptor": "\nComments: Accepted CoLLAs 2022\n",
    "authors": [
      "Georgios Tziafas",
      "Hamidreza Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12089"
  },
  {
    "id": "arXiv:2205.12402",
    "title": "Loop Closure Prioritization for Efficient and Scalable Multi-Robot SLAM",
    "abstract": "Comments: 8 pages, Accepted to RA-L/IROS 2022",
    "descriptor": "\nComments: 8 pages, Accepted to RA-L/IROS 2022\n",
    "authors": [
      "Christopher E. Denniston",
      "Yun Chang",
      "Andrzej Reinke",
      "Kamak Ebadi",
      "Gaurav S. Sukhatme",
      "Luca Carlone",
      "Benjamin Morrell",
      "Ali-akbar Agha-mohammadi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.12402"
  },
  {
    "id": "arXiv:2205.12411",
    "title": "Linear Connectivity Reveals Generalization Strategies",
    "abstract": "Linear Connectivity Reveals Generalization Strategies",
    "descriptor": "",
    "authors": [
      "Jeevesh Juneja",
      "Rachit Bansal",
      "Kyunghyun Cho",
      "Jo\u00e3o Sedoc",
      "Naomi Saphra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12411"
  },
  {
    "id": "arXiv:2205.12454",
    "title": "Recipe for a General, Powerful, Scalable Graph Transformer",
    "abstract": "Recipe for a General, Powerful, Scalable Graph Transformer",
    "descriptor": "",
    "authors": [
      "Ladislav Ramp\u00e1\u0161ek",
      "Mikhail Galkin",
      "Vijay Prakash Dwivedi",
      "Anh Tuan Luu",
      "Guy Wolf",
      "Dominique Beaini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12454"
  },
  {
    "id": "arXiv:2205.13038",
    "title": "Improving Subgraph Representation Learning via Multi-View Augmentation",
    "abstract": "Improving Subgraph Representation Learning via Multi-View Augmentation",
    "descriptor": "",
    "authors": [
      "Yili Shen",
      "Jiaxu Yan",
      "Cheng-Wei Ju",
      "Jun Yi",
      "Zhou Lin",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13038"
  },
  {
    "id": "arXiv:2205.13135",
    "title": "LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging  Large-Scale Underground Environments",
    "abstract": "LAMP 2.0: A Robust Multi-Robot SLAM System for Operation in Challenging  Large-Scale Underground Environments",
    "descriptor": "",
    "authors": [
      "Yun Chang",
      "Kamak Ebadi",
      "Christopher E. Denniston",
      "Muhammad Fadhil Ginting",
      "Antoni Rosinol",
      "Andrzej Reinke",
      "Matteo Palieri",
      "Jingnan Shi",
      "Arghya Chatterjee",
      "Benjamin Morrell",
      "Ali-akbar Agha-mohammadi",
      "Luca Carlone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.13135"
  },
  {
    "id": "arXiv:2205.15219",
    "title": "Automatic Short Math Answer Grading via In-context Meta-learning",
    "abstract": "Comments: To appear EDM 2022",
    "descriptor": "\nComments: To appear EDM 2022\n",
    "authors": [
      "Mengxue Zhang",
      "Sami Baral",
      "Neil Heffernan",
      "Andrew Lan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15219"
  },
  {
    "id": "arXiv:2205.15234",
    "title": "Few-Shot Adaptation of Pre-Trained Networks for Domain Shift",
    "abstract": "Comments: Accepted to IJCAI 2022",
    "descriptor": "\nComments: Accepted to IJCAI 2022\n",
    "authors": [
      "Wenyu Zhang",
      "Li Shen",
      "Wanyue Zhang",
      "Chuan-Sheng Foo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15234"
  },
  {
    "id": "arXiv:2206.00582",
    "title": "The elements of flexibility for task-performing systems",
    "abstract": "The elements of flexibility for task-performing systems",
    "descriptor": "",
    "authors": [
      "Sebastian Mayer",
      "Leo Francoso Dal Piccol Sotto",
      "Jochen Garcke"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.00582"
  },
  {
    "id": "arXiv:2206.00995",
    "title": "On the Lie complexity of Sturmian words",
    "abstract": "Comments: 6 pages, submitted to Theoretical Computer Science",
    "descriptor": "\nComments: 6 pages, submitted to Theoretical Computer Science\n",
    "authors": [
      "Alessandro De Luca",
      "Gabriele Fici"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.00995"
  },
  {
    "id": "arXiv:2206.02274",
    "title": "An information upper bound for probability sensitivity",
    "abstract": "Comments: 18 pages, 5 figures, for the datasets generated during and/or analysed during the current study, see this http URL",
    "descriptor": "\nComments: 18 pages, 5 figures, for the datasets generated during and/or analysed during the current study, see this http URL\n",
    "authors": [
      "Jiannan Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2206.02274"
  },
  {
    "id": "arXiv:2206.03322",
    "title": "Deep Learning-based Finite Element Analysis (FEA) surrogate for sub-sea  pressure vessel",
    "abstract": "Deep Learning-based Finite Element Analysis (FEA) surrogate for sub-sea  pressure vessel",
    "descriptor": "",
    "authors": [
      "Harsh Vardhan",
      "Janos Sztipanovits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03322"
  },
  {
    "id": "arXiv:2206.03493",
    "title": "DeepCAVE: An Interactive Analysis Tool for Automated Machine Learning",
    "abstract": "Comments: Workshop on Adaptive Experimental Design and Active Learning in the Real World (ReALML@ICML'22)",
    "descriptor": "\nComments: Workshop on Adaptive Experimental Design and Active Learning in the Real World (ReALML@ICML'22)\n",
    "authors": [
      "Ren\u00e9 Sass",
      "Eddie Bergman",
      "Andr\u00e9 Biedenkapp",
      "Frank Hutter",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03493"
  },
  {
    "id": "arXiv:2206.04459",
    "title": "SDQ: Stochastic Differentiable Quantization with Mixed Precision",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Xijie Huang",
      "Zhiqiang Shen",
      "Shichao Li",
      "Zechun Liu",
      "Xianghong Hu",
      "Jeffry Wicaksana",
      "Eric Xing",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.04459"
  },
  {
    "id": "arXiv:2206.04771",
    "title": "Joint Entropy Search For Maximally-Informed Bayesian Optimization",
    "abstract": "Comments: 10 pages, 8 figures",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Carl Hvarfner",
      "Frank Hutter",
      "Luigi Nardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04771"
  },
  {
    "id": "arXiv:2206.05431",
    "title": "Learned reconstruction methods with convergence guarantees",
    "abstract": "Learned reconstruction methods with convergence guarantees",
    "descriptor": "",
    "authors": [
      "Subhadip Mukherjee",
      "Andreas Hauptmann",
      "Ozan \u00d6ktem",
      "Marcelo Pereyra",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05431"
  },
  {
    "id": "arXiv:2206.05728",
    "title": "Arena-Bench: A Benchmarking Suite for Obstacle Avoidance Approaches in  Highly Dynamic Environments",
    "abstract": "Comments: Robotics and Automation Letters (RA-L), 2022, 8 pages, 6 figures",
    "descriptor": "\nComments: Robotics and Automation Letters (RA-L), 2022, 8 pages, 6 figures\n",
    "authors": [
      "Linh K\u00e4stner",
      "Teham Bhuiyan",
      "Tuan Anh Le",
      "Elias Treis",
      "Johannes Cox",
      "Boris Meinardus",
      "Jacek Kmiecik",
      "Reyk Carstens",
      "Duc Pichel",
      "Bassel Fatloun",
      "Niloufar Khorsandi",
      "Jens Lambrecht"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.05728"
  },
  {
    "id": "arXiv:2206.06575",
    "title": "Med-DANet: Dynamic Architecture Network for Efficient Medical Volumetric  Segmentation",
    "abstract": "Med-DANet: Dynamic Architecture Network for Efficient Medical Volumetric  Segmentation",
    "descriptor": "",
    "authors": [
      "Wenxuan Wang",
      "Chen Chen",
      "Jing Wang",
      "Sen Zha",
      "Yan Zhang",
      "Jiangyun Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06575"
  },
  {
    "id": "arXiv:2206.06988",
    "title": "The Complexity of Finding Fair Many-to-One Matchings",
    "abstract": "Comments: Accepted to ICALP'22",
    "descriptor": "\nComments: Accepted to ICALP'22\n",
    "authors": [
      "Niclas Boehmer",
      "Tomohiro Koana"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.06988"
  },
  {
    "id": "arXiv:2206.07155",
    "title": "Self-Supervision on Images and Text Reduces Reliance on Visual Shortcut  Features",
    "abstract": "Comments: 4 pages, 2 figures, spotlight talk at SCIS workshop, ICML 2022",
    "descriptor": "\nComments: 4 pages, 2 figures, spotlight talk at SCIS workshop, ICML 2022\n",
    "authors": [
      "Anil Palepu",
      "Andrew L Beam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07155"
  },
  {
    "id": "arXiv:2206.07634",
    "title": "Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with  Occlusion Handling for 3D Detection and Segmentation",
    "abstract": "Comments: Submitted on 15th June 2022 to IEEE RA-L journal",
    "descriptor": "\nComments: Submitted on 15th June 2022 to IEEE RA-L journal\n",
    "authors": [
      "Petr \u0160ebek",
      "\u0160imon Pokorn\u00fd",
      "Patrik Vacek",
      "Tom\u00e1\u0161 Svoboda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07634"
  },
  {
    "id": "arXiv:2206.08127",
    "title": "Random Access Concatenated Libraries and dd enable a short-latency  high-content website on an inexpensive shared server",
    "abstract": "Comments: 16 pages, 9 figures",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Don Krieger"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.08127"
  },
  {
    "id": "arXiv:2206.08138",
    "title": "Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone  fine-tuning without episodic meta-learning dominates for few-shot learning  image classification",
    "abstract": "Comments: version 2 is the correct version, including supplementary material at the end",
    "descriptor": "\nComments: version 2 is the correct version, including supplementary material at the end\n",
    "authors": [
      "Adrian El Baz",
      "Ihsan Ullah",
      "Edesio Alcoba\u00e7a",
      "Andr\u00e9 C. P. L. F. Carvalho",
      "Hong Chen",
      "Fabio Ferreira",
      "Henry Gouk",
      "Chaoyu Guan",
      "Isabelle Guyon",
      "Timothy Hospedales",
      "Shell Hu",
      "Mike Huisman",
      "Frank Hutter",
      "Zhengying Liu",
      "Felix Mohr",
      "Ekrem \u00d6zt\u00fcrk",
      "Jan N. van Rijn",
      "Haozhe Sun",
      "Xin Wang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.08138"
  },
  {
    "id": "arXiv:2206.08413",
    "title": "Recursion does not always help",
    "abstract": "Recursion does not always help",
    "descriptor": "",
    "authors": [
      "Gordon Plotkin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.08413"
  },
  {
    "id": "arXiv:2206.08496",
    "title": "Self-Supervised Contrastive Pre-Training For Time Series via  Time-Frequency Consistency",
    "abstract": "Comments: Under review; the anonymouse code repo link will be made non-anonymous after acceptance; 24 pages (13 pages main paper + 11 pages supplementary materials)",
    "descriptor": "\nComments: Under review; the anonymouse code repo link will be made non-anonymous after acceptance; 24 pages (13 pages main paper + 11 pages supplementary materials)\n",
    "authors": [
      "Xiang Zhang",
      "Ziyuan Zhao",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.08496"
  },
  {
    "id": "arXiv:2206.08558",
    "title": "How You Start Matters for Generalization",
    "abstract": "How You Start Matters for Generalization",
    "descriptor": "",
    "authors": [
      "Sameera Ramasinghe",
      "Lachlan MacDonald",
      "Moshiur Farazi",
      "Hemanth Saratchandran",
      "Simon Lucey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08558"
  },
  {
    "id": "arXiv:2206.09262",
    "title": "Motley: Benchmarking Heterogeneity and Personalization in Federated  Learning",
    "abstract": "Comments: 36 pages, 9 figures, 5 tables. Code: this https URL",
    "descriptor": "\nComments: 36 pages, 9 figures, 5 tables. Code: this https URL\n",
    "authors": [
      "Shanshan Wu",
      "Tian Li",
      "Zachary Charles",
      "Yu Xiao",
      "Ziyu Liu",
      "Zheng Xu",
      "Virginia Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.09262"
  },
  {
    "id": "arXiv:2206.10088",
    "title": "Renormalized Sparse Neural Network Pruning",
    "abstract": "Renormalized Sparse Neural Network Pruning",
    "descriptor": "",
    "authors": [
      "Michael G. Rawson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.10088"
  },
  {
    "id": "arXiv:2206.10257",
    "title": "Satoshi Nakamoto and the Origins of Bitcoin -- Narratio in Nomine, Datis  et Numeris",
    "abstract": "Comments: Main text:44 pages Number of references: 566 Appendix: 6 pages",
    "descriptor": "\nComments: Main text:44 pages Number of references: 566 Appendix: 6 pages\n",
    "authors": [
      "Jens Ducr\u00e9e"
    ],
    "subjectives": [
      "General Literature (cs.GL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10257"
  },
  {
    "id": "arXiv:2206.10421",
    "title": "Rethinking Audio-visual Synchronization for Active Speaker Detection",
    "abstract": "Comments: Accepted by IEEE International Workshop on Machine Learning for Signal Processing (MLSP 2022)",
    "descriptor": "\nComments: Accepted by IEEE International Workshop on Machine Learning for Signal Processing (MLSP 2022)\n",
    "authors": [
      "Abudukelimu Wuerkaixi",
      "You Zhang",
      "Zhiyao Duan",
      "Changshui Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.10421"
  },
  {
    "id": "arXiv:2206.10728",
    "title": "Mobile Mental Health Apps: Alternative Intervention or Intrusion?",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Shalini Saini",
      "Dhiral Panjwani",
      "Nitesh Saxena"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.10728"
  },
  {
    "id": "arXiv:2206.11699",
    "title": "The SJTU X-LANCE Lab System for CNSRC 2022",
    "abstract": "The SJTU X-LANCE Lab System for CNSRC 2022",
    "descriptor": "",
    "authors": [
      "Zhengyang Chen",
      "Bei Liu",
      "Bing Han",
      "Leying Zhang",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.11699"
  },
  {
    "id": "arXiv:2206.12790",
    "title": "APPFLChain: A Privacy Protection Distributed Artificial-Intelligence  Architecture Based on Federated Learning and Consortium Blockchain",
    "abstract": "Comments: We found that the simulation part in section V is not completed. We need to add more experiments to support it",
    "descriptor": "\nComments: We found that the simulation part in section V is not completed. We need to add more experiments to support it\n",
    "authors": [
      "Jun-Teng Yang",
      "Wen-Yuan Chen",
      "Che-Hua Li",
      "Scott C.-H. Huang",
      "Hsiao-Chun Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12790"
  },
  {
    "id": "arXiv:2206.12901",
    "title": "Noise-aware Physics-informed Machine Learning for Robust PDE Discovery",
    "abstract": "Comments: 13 pages, 8 figures, v2: corrected typos, v3: corrected author names, corrected typos, v4: improved notations",
    "descriptor": "\nComments: 13 pages, 8 figures, v2: corrected typos, v3: corrected author names, corrected typos, v4: improved notations\n",
    "authors": [
      "Pongpisit Thanasutives",
      "Takashi Morita",
      "Masayuki Numao",
      "Ken-ichi Fukui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.12901"
  },
  {
    "id": "arXiv:2206.12925",
    "title": "Vision Transformer for Contrastive Clustering",
    "abstract": "Vision Transformer for Contrastive Clustering",
    "descriptor": "",
    "authors": [
      "Hua-Bao Ling",
      "Bowen Zhu",
      "Dong Huang",
      "Ding-Hua Chen",
      "Chang-Dong Wang",
      "Jian-Huang Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12925"
  },
  {
    "id": "arXiv:2206.13011",
    "title": "Efficient Private SCO for Heavy-Tailed Data via Clipping",
    "abstract": "Efficient Private SCO for Heavy-Tailed Data via Clipping",
    "descriptor": "",
    "authors": [
      "Chenhan Jin",
      "Kaiwen Zhou",
      "Bo Han",
      "Ming-Chang Yang",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.13011"
  },
  {
    "id": "arXiv:2206.13298",
    "title": "Deep Active Learning for Regression Using $\u03b5$-weighted Hybrid  Query Strategy",
    "abstract": "Deep Active Learning for Regression Using $\u03b5$-weighted Hybrid  Query Strategy",
    "descriptor": "",
    "authors": [
      "Harsh Vardhan",
      "Janos Sztipanovits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.13298"
  },
  {
    "id": "arXiv:2206.13497",
    "title": "Robustness Implies Generalization via Data-Dependent Generalization  Bounds",
    "abstract": "Comments: Accepted by ICML 2022, and selected for ICML long presentation (top 2% of submissions)",
    "descriptor": "\nComments: Accepted by ICML 2022, and selected for ICML long presentation (top 2% of submissions)\n",
    "authors": [
      "Kenji Kawaguchi",
      "Zhun Deng",
      "Kyle Luh",
      "Jiaoyang Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13497"
  },
  {
    "id": "arXiv:2206.13703",
    "title": "Kwame for Science: An AI Teaching Assistant Based on Sentence-BERT for  Science Education in West Africa",
    "abstract": "Comments: 5 pages, Accepted at the Fourth Workshop on Intelligent Textbooks (iTextbooks) at the 23th International Conference on Artificial Intelligence in Education (AIED 2022)",
    "descriptor": "\nComments: 5 pages, Accepted at the Fourth Workshop on Intelligent Textbooks (iTextbooks) at the 23th International Conference on Artificial Intelligence in Education (AIED 2022)\n",
    "authors": [
      "George Boateng",
      "Samuel John",
      "Andrew Glago",
      "Samuel Boateng",
      "Victor Kumbol"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.13703"
  },
  {
    "id": "arXiv:2206.14282",
    "title": "Neural Integro-Differential Equations",
    "abstract": "Comments: 15 pages (including 4 pages Appendix), 8 figures and 4 tables",
    "descriptor": "\nComments: 15 pages (including 4 pages Appendix), 8 figures and 4 tables\n",
    "authors": [
      "Emanuele Zappala",
      "Antonio Henrique de Oliveira Fonseca",
      "Andrew Henry Moberly",
      "Michael James Higley",
      "Chadi Abdallah",
      "Jessica Cardin",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14282"
  },
  {
    "id": "arXiv:2206.14406",
    "title": "Standard Dual Quaternion Optimization and Its Application in Hand-Eye  Calibration",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2204.01229",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.01229\n",
    "authors": [
      "Liqun Qi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.14406"
  },
  {
    "id": "arXiv:2206.14882",
    "title": "LIDL: Local Intrinsic Dimension Estimation Using Approximate Likelihood",
    "abstract": "Comments: ICML 2022",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Piotr Tempczyk",
      "Rafa\u0142 Michaluk",
      "\u0141ukasz Garncarek",
      "Przemys\u0142aw Spurek",
      "Jacek Tabor",
      "Adam Goli\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14882"
  },
  {
    "id": "arXiv:2206.15398",
    "title": "PolarFormer: Multi-camera 3D Object Detection with Polar Transformers",
    "abstract": "PolarFormer: Multi-camera 3D Object Detection with Polar Transformers",
    "descriptor": "",
    "authors": [
      "Yanqin Jiang",
      "Li Zhang",
      "Zhenwei Miao",
      "Xiatian Zhu",
      "Jin Gao",
      "Weiming Hu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.15398"
  },
  {
    "id": "arXiv:2207.00010",
    "title": "Continual Learning for Human State Monitoring",
    "abstract": "Comments: 6 pages, 4 figures, 2 tables, Accepted as oral at ESANN 2022",
    "descriptor": "\nComments: 6 pages, 4 figures, 2 tables, Accepted as oral at ESANN 2022\n",
    "authors": [
      "Federico Matteoni",
      "Andrea Cossu",
      "Claudio Gallicchio",
      "Vincenzo Lomonaco",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.00010"
  },
  {
    "id": "arXiv:2207.00160",
    "title": "When Does Differentially Private Learning Not Suffer in High Dimensions?",
    "abstract": "Comments: 25 pages; v2 fixes typos and formatting",
    "descriptor": "\nComments: 25 pages; v2 fixes typos and formatting\n",
    "authors": [
      "Xuechen Li",
      "Daogao Liu",
      "Tatsunori Hashimoto",
      "Huseyin A. Inan",
      "Janardhan Kulkarni",
      "Yin Tat Lee",
      "Abhradeep Guha Thakurta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.00160"
  },
  {
    "id": "arXiv:2207.00198",
    "title": "Comprehensive Reactive Safety: No Need For A Trajectory If You Have A  Strategy",
    "abstract": "Comments: Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)",
    "descriptor": "\nComments: Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Fang Da"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2207.00198"
  },
  {
    "id": "arXiv:2207.00237",
    "title": "Improving Speech Enhancement through Fine-Grained Speech Characteristics",
    "abstract": "Comments: Accepted at InterSpeech 2022",
    "descriptor": "\nComments: Accepted at InterSpeech 2022\n",
    "authors": [
      "Muqiao Yang",
      "Joseph Konan",
      "David Bick",
      "Anurag Kumar",
      "Shinji Watanabe",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.00237"
  },
  {
    "id": "arXiv:2207.00506",
    "title": "How Far Can I Go ? : A Self-Supervised Approach for Deterministic Video  Depth Forecasting",
    "abstract": "Comments: Accepted in ML4AD Workshop, NeurIPS 2021",
    "descriptor": "\nComments: Accepted in ML4AD Workshop, NeurIPS 2021\n",
    "authors": [
      "Sauradip Nag",
      "Nisarg Shah",
      "Anran Qi",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2207.00506"
  },
  {
    "id": "arXiv:2207.00718",
    "title": "Triangle-oriented Community Detection considering Node Features and  Network Topology",
    "abstract": "Triangle-oriented Community Detection considering Node Features and  Network Topology",
    "descriptor": "",
    "authors": [
      "Guangliang Gao",
      "Weichao Liang",
      "Ming Yuan",
      "Hanwei Qian",
      "Qun Wang",
      "Jie Cao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.00718"
  },
  {
    "id": "arXiv:2207.00769",
    "title": "Test-time Adaptation with Calibration of Medical Image Classification  Nets for Label Distribution Shift",
    "abstract": "Comments: This paper has been accepted by MICCAI 2022",
    "descriptor": "\nComments: This paper has been accepted by MICCAI 2022\n",
    "authors": [
      "Wenao Ma",
      "Cheng Chen",
      "Shuang Zheng",
      "Jing Qin",
      "Huimao Zhang",
      "Qi Dou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.00769"
  },
  {
    "id": "arXiv:2207.01018",
    "title": "Symbolic Regression is NP-hard",
    "abstract": "Comments: corrected citation Abbass 2002 -&gt; Cramer 1985",
    "descriptor": "\nComments: corrected citation Abbass 2002 -&gt; Cramer 1985\n",
    "authors": [
      "Marco Virgolin",
      "Solon P. Pissis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.01018"
  },
  {
    "id": "arXiv:2207.01077",
    "title": "Can Language Understand Depth?",
    "abstract": "Can Language Understand Depth?",
    "descriptor": "",
    "authors": [
      "Renrui Zhang",
      "Ziyao Zeng",
      "Ziyu Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.01077"
  },
  {
    "id": "arXiv:2207.01079",
    "title": "DiSCoMaT: Distantly Supervised Composition Extraction from Tables in  Materials Science Articles",
    "abstract": "DiSCoMaT: Distantly Supervised Composition Extraction from Tables in  Materials Science Articles",
    "descriptor": "",
    "authors": [
      "Tanishq Gupta",
      "Mohd Zaki",
      "N. M. Anoop Krishnan",
      "Mausam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.01079"
  },
  {
    "id": "arXiv:2207.01127",
    "title": "DecisioNet: A Binary-Tree Structured Neural Network",
    "abstract": "Comments: This paper is under review of a conference, hence the code may not be published yet. It will be publicly available on github after the paper is published",
    "descriptor": "\nComments: This paper is under review of a conference, hence the code may not be published yet. It will be publicly available on github after the paper is published\n",
    "authors": [
      "Noam Gottlieb",
      "Michael Werman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.01127"
  },
  {
    "id": "arXiv:2207.01129",
    "title": "A Gray Code of Ordered Trees",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Shin-ichi Nakano"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2207.01129"
  },
  {
    "id": "arXiv:2207.01294",
    "title": "A New Index for Clustering Evaluation Based on Density Estimation",
    "abstract": "A New Index for Clustering Evaluation Based on Density Estimation",
    "descriptor": "",
    "authors": [
      "Gangli Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.01294"
  },
  {
    "id": "arXiv:2207.01377",
    "title": "Detection of ADHD based on Eye Movements during Natural Viewing",
    "abstract": "Comments: Pre-print for Proceedings of the European Conference on Machine Learning, 2022",
    "descriptor": "\nComments: Pre-print for Proceedings of the European Conference on Machine Learning, 2022\n",
    "authors": [
      "Shuwen Deng",
      "Paul Prasse",
      "David R. Reich",
      "Sabine Dziemian",
      "Maja Stegenwallner-Sch\u00fctz",
      "Daniel Krakowczyk",
      "Silvia Makowski",
      "Nicolas Langer",
      "Tobias Scheffer",
      "Lena A. J\u00e4ger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.01377"
  },
  {
    "id": "arXiv:2207.01395",
    "title": "Memory Efficient Patch-based Training for INR-based GANs",
    "abstract": "Comments: 5 pages, 4 figures, arXiv preprint",
    "descriptor": "\nComments: 5 pages, 4 figures, arXiv preprint\n",
    "authors": [
      "Namwoo Lee",
      "Hyunsu Kim",
      "Gayoung Lee",
      "Sungjoo Yoo",
      "Yunjey Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.01395"
  },
  {
    "id": "arXiv:2207.01424",
    "title": "On Constructions of New MDS Codes with Arbitrary-Dimensional Galois  Hulls",
    "abstract": "Comments: 28 pages,4 tables,arbitrary dimension Galois hull MDS codes can be constructed from (extend) GRS codes",
    "descriptor": "\nComments: 28 pages,4 tables,arbitrary dimension Galois hull MDS codes can be constructed from (extend) GRS codes\n",
    "authors": [
      "Yang Li",
      "Shixin Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.01424"
  },
  {
    "id": "arXiv:2207.01886",
    "title": "WeSinger 2: Fully Parallel Singing Voice Synthesis via Multi-Singer  Conditional Adversarial Training",
    "abstract": "Comments: update writing",
    "descriptor": "\nComments: update writing\n",
    "authors": [
      "Zewang Zhang",
      "Yibin Zheng",
      "Xinhui Li",
      "Li Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.01886"
  },
  {
    "id": "arXiv:2207.01902",
    "title": "Identification of Threat Regions From a Dynamic Occupancy Grid Map for  Situation-Aware Environment Perception",
    "abstract": "Comments: Accepted for publication at the 25th IEEE International Conference on Intelligent Transportation Systems 2022. DOI to be provided shortly. V2: added IEEE copyright notice",
    "descriptor": "\nComments: Accepted for publication at the 25th IEEE International Conference on Intelligent Transportation Systems 2022. DOI to be provided shortly. V2: added IEEE copyright notice\n",
    "authors": [
      "Matti Henning",
      "Jan Strohbeck",
      "Michael Buchholz",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.01902"
  },
  {
    "id": "arXiv:2207.01964",
    "title": "Quantum Circuit Compiler for a Shuttling-Based Trapped-Ion Quantum  Computer",
    "abstract": "Comments: 22 pages, 19 figures",
    "descriptor": "\nComments: 22 pages, 19 figures\n",
    "authors": [
      "Fabian Kreppel",
      "Christian Melzer",
      "Janis Wagner",
      "Janine Hilder",
      "Ulrich Poschinger",
      "Ferdinand Schmidt-Kaler",
      "Andr\u00e9 Brinkmann"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computation and Language (cs.CL)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2207.01964"
  },
  {
    "id": "arXiv:2207.02013",
    "title": "Multiview Detection with Cardboard Human Modeling",
    "abstract": "Comments: The thesis is not perfect enough",
    "descriptor": "\nComments: The thesis is not perfect enough\n",
    "authors": [
      "Jiahao Ma",
      "Zicheng Duan",
      "Yunzhong Hou",
      "Liang Zheng",
      "Chuong Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.02013"
  },
  {
    "id": "arXiv:2207.02026",
    "title": "Fine-Grained Modeling and Optimization for Intelligent Resource  Management in Big Data Processing",
    "abstract": "Fine-Grained Modeling and Optimization for Intelligent Resource  Management in Big Data Processing",
    "descriptor": "",
    "authors": [
      "Chenghao Lyu",
      "Qi Fan",
      "Fei Song",
      "Arnab Sinha",
      "Yanlei Diao",
      "Wei Chen",
      "Li Ma",
      "Yihui Feng",
      "Yaliang Li",
      "Kai Zeng",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.02026"
  },
  {
    "id": "arXiv:2207.02152",
    "title": "UniCR: Universally Approximated Certified Robustness via Randomized  Smoothing",
    "abstract": "Comments: Accepted by ECCV2022",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Hanbin Hong",
      "Binghui Wang",
      "Yuan Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02152"
  },
  {
    "id": "arXiv:2207.02327",
    "title": "TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis  Framework Using Spectral Embedding and Vision Transformers",
    "abstract": "Comments: 11 pages. 5 figures, MICCAI 2022",
    "descriptor": "\nComments: 11 pages. 5 figures, MICCAI 2022\n",
    "authors": [
      "Fan Zhang",
      "Tengfei Xue",
      "Weidong Cai",
      "Yogesh Rathi",
      "Carl-Fredrik Westin",
      "Lauren J O'Donnell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02327"
  },
  {
    "id": "arXiv:2207.02504",
    "title": "Two-stage Decision Improves Open-Set Panoptic Segmentation",
    "abstract": "Two-stage Decision Improves Open-Set Panoptic Segmentation",
    "descriptor": "",
    "authors": [
      "Hai-Ming Xu",
      "Hao Chen",
      "Lingqiao Liu",
      "Yufei Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.02504"
  },
  {
    "id": "arXiv:2207.02543",
    "title": "AI-enhanced iterative solvers for accelerating the solution of large  scale parametrized linear systems of equations",
    "abstract": "AI-enhanced iterative solvers for accelerating the solution of large  scale parametrized linear systems of equations",
    "descriptor": "",
    "authors": [
      "Stefanos Nikolopoulos",
      "Ioannis Kalogeris",
      "Vissarion Papadopoulos",
      "George Stavroulakis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02543"
  },
  {
    "id": "arXiv:2207.02565",
    "title": "voxel2vec: A Natural Language Processing Approach to Learning  Distributed Representations for Scientific Data",
    "abstract": "Comments: Accepted by IEEE Transaction on Visualization and Computer Graphics (TVCG)",
    "descriptor": "\nComments: Accepted by IEEE Transaction on Visualization and Computer Graphics (TVCG)\n",
    "authors": [
      "Xiangyang He",
      "Yubo Tao",
      "Shuoliu Yang",
      "Haoran Dai",
      "and Hai Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02565"
  },
  {
    "id": "arXiv:2207.02583",
    "title": "PIC 4th Challenge: Semantic-Assisted Multi-Feature Encoding and  Multi-Head Decoding for Dense Video Captioning",
    "abstract": "Comments: 5 pages, 2 figures, report of PIC 4th Challenge",
    "descriptor": "\nComments: 5 pages, 2 figures, report of PIC 4th Challenge\n",
    "authors": [
      "Yifan Lu",
      "Ziqi Zhang",
      "Yuxin Chen",
      "Chunfeng Yuan",
      "Bing Li",
      "Weiming Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.02583"
  },
  {
    "id": "arXiv:2207.02912",
    "title": "Towards Substantive Conceptions of Algorithmic Fairness: Normative  Guidance from Equal Opportunity Doctrines",
    "abstract": "Towards Substantive Conceptions of Algorithmic Fairness: Normative  Guidance from Equal Opportunity Doctrines",
    "descriptor": "",
    "authors": [
      "Falaah Arif Khan",
      "Eleni Manis",
      "Julia Stoyanovich"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02912"
  },
  {
    "id": "arXiv:2207.02976",
    "title": "Semi-supervised Human Pose Estimation in Art-historical Images",
    "abstract": "Semi-supervised Human Pose Estimation in Art-historical Images",
    "descriptor": "",
    "authors": [
      "Matthias Springstein",
      "Stefanie Schneider",
      "Christian Althaus",
      "Ralph Ewerth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.02976"
  },
  {
    "id": "arXiv:2207.02995",
    "title": "An Overview on Designs and Applications of Context-Aware Automation  Systems",
    "abstract": "Comments: 10 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 10 pages, 5 figures, 1 table\n",
    "authors": [
      "Nada Sahlab",
      "Nasser Jazdi",
      "Michael Weyrich"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.02995"
  },
  {
    "id": "arXiv:2207.03112",
    "title": "Design of Human Machine Interface through vision-based low-cost Hand  Gesture Recognition system based on deep CNN",
    "abstract": "Design of Human Machine Interface through vision-based low-cost Hand  Gesture Recognition system based on deep CNN",
    "descriptor": "",
    "authors": [
      "Abir Sen",
      "Tapas Kumar Mishra",
      "Ratnakar Dash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.03112"
  },
  {
    "id": "arXiv:2207.03116",
    "title": "Equivariant Representation Learning via Class-Pose Decomposition",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Giovanni Luca Marchetti",
      "Gustaf Tegn\u00e9r",
      "Anastasiia Varava",
      "Danica Kragic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.03116"
  },
  {
    "id": "arXiv:2207.03163",
    "title": "Star Product PIR Schemes with Colluding Servers over Small Fields",
    "abstract": "Comments: 23 pages, Singleton type bound for star product PIR schemes.When the storage code is RM, the best choice of retrieval code is not always RM",
    "descriptor": "\nComments: 23 pages, Singleton type bound for star product PIR schemes.When the storage code is RM, the best choice of retrieval code is not always RM\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.03163"
  },
  {
    "id": "arXiv:2207.03352",
    "title": "Market Making with Scaled Beta Policies",
    "abstract": "Market Making with Scaled Beta Policies",
    "descriptor": "",
    "authors": [
      "Joseph Jerome",
      "Gregory Palmer",
      "Rahul Savani"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.03352"
  },
  {
    "id": "arXiv:2207.03456",
    "title": "Stochastic optimal well control in subsurface reservoirs using  reinforcement learning",
    "abstract": "Stochastic optimal well control in subsurface reservoirs using  reinforcement learning",
    "descriptor": "",
    "authors": [
      "Atish Dixit",
      "Ahmed H. ElSheikh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.03456"
  },
  {
    "id": "arXiv:2207.03824",
    "title": "Boosting Zero-shot Learning via Contrastive Optimization of Attribute  Representations",
    "abstract": "Boosting Zero-shot Learning via Contrastive Optimization of Attribute  Representations",
    "descriptor": "",
    "authors": [
      "Yu Du",
      "Miaojing Shi",
      "Fangyun Wei",
      "Guoqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.03824"
  },
  {
    "id": "arXiv:2207.03936",
    "title": "Search by triplet: An efficient local track reconstruction algorithm for  parallel architectures",
    "abstract": "Search by triplet: An efficient local track reconstruction algorithm for  parallel architectures",
    "descriptor": "",
    "authors": [
      "Daniel Hugo C\u00e1mpora P\u00e9rez",
      "Niko Neufeld",
      "Agust\u00edn Riscos N\u00fa\u00f1ez"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.03936"
  },
  {
    "id": "arXiv:2207.04007",
    "title": "Event Collapse in Contrast Maximization Frameworks",
    "abstract": "Comments: 19 pages, 8 figures, 3 tables",
    "descriptor": "\nComments: 19 pages, 8 figures, 3 tables\n",
    "authors": [
      "Shintaro Shiba",
      "Yoshimitsu Aoki",
      "Guillermo Gallego"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2207.04007"
  }
]
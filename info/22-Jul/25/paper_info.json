[
  {
    "id": "arXiv:2207.10668",
    "title": "Improved Generalization Guarantees in Restricted Data Models",
    "abstract": "Differential privacy is known to protect against threats to validity incurred\ndue to adaptive, or exploratory, data analysis -- even when the analyst\nadversarially searches for a statistical estimate that diverges from the true\nvalue of the quantity of interest on the underlying population. The cost of\nthis protection is the accuracy loss incurred by differential privacy. In this\nwork, inspired by standard models in the genomics literature, we consider data\nmodels in which individuals are represented by a sequence of attributes with\nthe property that where distant attributes are only weakly correlated. We show\nthat, under this assumption, it is possible to \"re-use\" privacy budget on\ndifferent portions of the data, significantly improving accuracy without\nincreasing the risk of overfitting.",
    "descriptor": "\nComments: 13 pages, published in FORC 2022\n",
    "authors": [
      "Elbert Du",
      "Cynthia Dwork"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10668"
  },
  {
    "id": "arXiv:2207.10670",
    "title": "ME-GAN: Learning Panoptic Electrocardio Representations for Multi-view  ECG Synthesis Conditioned on Heart Diseases",
    "abstract": "Electrocardiogram (ECG) is a widely used non-invasive diagnostic tool for\nheart diseases. Many studies have devised ECG analysis models (e.g.,\nclassifiers) to assist diagnosis. As an upstream task, researches have built\ngenerative models to synthesize ECG data, which are beneficial to providing\ntraining samples, privacy protection, and annotation reduction. However,\nprevious generative methods for ECG often neither synthesized multi-view data,\nnor dealt with heart disease conditions. In this paper, we propose a novel\ndisease-aware generative adversarial network for multi-view ECG synthesis\ncalled ME-GAN, which attains panoptic electrocardio representations conditioned\non heart diseases and projects the representations onto multiple standard views\nto yield ECG signals. Since ECG manifestations of heart diseases are often\nlocalized in specific waveforms, we propose a new \"mixup normalization\" to\ninject disease information precisely into suitable locations. In addition, we\npropose a view discriminator to revert disordered ECG views into a\npre-determined order, supervising the generator to obtain ECG representing\ncorrect view characteristics. Besides, a new metric, rFID, is presented to\nassess the quality of the synthesized ECG signals. Comprehensive experiments\nverify that our ME-GAN performs well on multi-view ECG signal synthesis with\ntrusty morbid manifestations.",
    "descriptor": "",
    "authors": [
      "Jintai Chen",
      "Kuanlun Liao",
      "Kun Wei",
      "Haochao Ying",
      "Danny Z. Chen",
      "Jian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10670"
  },
  {
    "id": "arXiv:2207.10690",
    "title": "R2P: A Deep Learning Model from mmWave Radar to Point Cloud",
    "abstract": "Recent research has shown the effectiveness of mmWave radar sensing for\nobject detection in low visibility environments, which makes it an ideal\ntechnique in autonomous navigation systems. In this paper, we introduce Radar\nto Point Cloud (R2P), a deep learning model that generates smooth, dense, and\nhighly accurate point cloud representation of a 3D object with fine geometry\ndetails, based on rough and sparse point clouds with incorrect points obtained\nfrom mmWave radar. These input point clouds are converted from the 2D depth\nimages that are generated from raw mmWave radar sensor data, characterized by\ninconsistency, and orientation and shape errors. R2P utilizes an architecture\nof two sequential deep learning encoder-decoder blocks to extract the essential\nfeatures of those radar-based input point clouds of an object when observed\nfrom multiple viewpoints, and to ensure the internal consistency of a generated\noutput point cloud and its accurate and detailed shape reconstruction of the\noriginal object. We implement R2P to replace Stage 2 of our recently proposed\n3DRIMR (3D Reconstruction and Imaging via mmWave Radar) system. Our experiments\ndemonstrate the significant performance improvement of R2P over the popular\nexisting methods such as PointNet, PCN, and the original 3DRIMR design.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.09188\n",
    "authors": [
      "Yue Sun",
      "Honggang Zhang",
      "Zhuoming Huang",
      "Benyuan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10690"
  },
  {
    "id": "arXiv:2207.10693",
    "title": "Trajectory Optimization and Following for a Three Degrees of Freedom  Overactuated Floating Platform",
    "abstract": "Space robotics applications, such as Active Space Debris Removal (ASDR),\nrequire representative testing before launch. A commonly used approach to\nemulate the microgravity environment in space is air-bearing based platforms on\nflat-floors, such as the European Space Agency's Orbital Robotics and GNC Lab\n(ORGL). This work proposes a control architecture for a floating platform at\nthe ORGL, equipped with eight solenoid-valve-based thrusters and one reaction\nwheel. The control architecture consists of two main components: a trajectory\nplanner that finds optimal trajectories connecting two states and a trajectory\nfollower that follows any physically feasible trajectory. The controller is\nfirst evaluated within an introduced simulation, achieving a 100 % success rate\nat finding and following trajectories to the origin within a Monte-Carlo test.\nIndividual trajectories are also successfully followed by the physical system.\nIn this work, we showcase the ability of the controller to reject disturbances\nand follow a straight-line trajectory within tens of centimeters.",
    "descriptor": "\nComments: Accepted to IROS2022, code at this https URL\n",
    "authors": [
      "Anton Bredenbeck",
      "Shubham Vyas",
      "Martin Zwick",
      "Dorit Borrmann",
      "Miguel Olivares-Mendez",
      "Andreas N\u00fcchter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10693"
  },
  {
    "id": "arXiv:2207.10702",
    "title": "Efficient model compression with Random Operation Access Specific Tile  (ROAST) hashing",
    "abstract": "Advancements in deep learning are often associated with increasing model\nsizes. The model size dramatically affects the deployment cost and latency of\ndeep models. For instance, models like BERT cannot be deployed on edge devices\nand mobiles due to their sheer size. As a result, most advances in Deep\nLearning are yet to reach the edge. Model compression has sought much-deserved\nattention in literature across natural language processing, vision, and\nrecommendation domains. This paper proposes a model-agnostic, cache-friendly\nmodel compression approach: Random Operation Access Specific Tile (ROAST)\nhashing. ROAST collapses the parameters by clubbing them through a lightweight\nmapping. Notably, while clubbing these parameters, ROAST utilizes cache\nhierarchies by aligning the memory access pattern with the parameter access\npattern. ROAST is up to $\\sim 25 \\times$ faster to train and $\\sim 50 \\times$\nfaster to infer than the popular parameter sharing method HashedNet.\nAdditionally, ROAST introduces global weight sharing, which is empirically and\ntheoretically superior to local weight sharing in HashedNet, and can be of\nindependent interest in itself. With ROAST, we present the first compressed\nBERT, which is $100\\times - 1000\\times$ smaller but does not result in quality\ndegradation. These compression levels on universal architecture like\ntransformers are promising for the future of SOTA model deployment on\nresource-constrained devices like mobile and edge devices",
    "descriptor": "",
    "authors": [
      "Aditya Desai",
      "Keren Zhou",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10702"
  },
  {
    "id": "arXiv:2207.10703",
    "title": "Optimal Algorithms for Free Order Multiple-Choice Secretary",
    "abstract": "Suppose we are given integer $k \\leq n$ and $n$ boxes labeled $1,\\ldots, n$\nby an adversary, each containing a number chosen from an unknown distribution.\nWe have to choose an order to sequentially open these boxes, and each time we\nopen the next box in this order, we learn its number. If we reject a number in\na box, the box cannot be recalled. Our goal is to accept the $k$ largest of\nthese numbers, without necessarily opening all boxes. This is the free order\nmultiple-choice secretary problem. Free order variants were studied extensively\nfor the secretary and prophet problems. Kesselheim, Kleinberg, and Niazadeh KKN\n(STOC'15) initiated a study of randomness-efficient algorithms (with the\ncheapest order in terms of used random bits) for the free order secretary\nproblems.\nWe present an algorithm for free order multiple-choice secretary, which is\nsimultaneously optimal for the competitive ratio and used amount of randomness.\nI.e., we construct a distribution on orders with optimal entropy\n$\\Theta(\\log\\log n)$ such that a deterministic multiple-threshold algorithm is\n$1-O(\\sqrt{\\log k/k})$-competitive. This improves in three ways the previous\nbest construction by KKN, whose competitive ratio is $1 - O(1/k^{1/3}) - o(1)$.\nOur competitive ratio is (near)optimal for the multiple-choice secretary\nproblem; it works for exponentially larger parameter $k$; and our algorithm is\na simple deterministic multiple-threshold algorithm, while that in KKN is\nrandomized. We also prove a corresponding lower bound on the entropy of optimal\nsolutions for the multiple-choice secretary problem, matching entropy of our\nalgorithm, where no such previous lower bound was known.\nWe obtain our algorithmic results with a host of new techniques, and with\nthese techniques we also improve significantly the previous results of KKN\nabout constructing entropy-optimal distributions for the classic free order\nsecretary.",
    "descriptor": "",
    "authors": [
      "Mohammad Taghi Hajiaghayi",
      "Dariusz R. Kowalski",
      "Piotr Krysta",
      "Jan Olkowski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.10703"
  },
  {
    "id": "arXiv:2207.10716",
    "title": "JAWS: Predictive Inference Under Covariate Shift",
    "abstract": "We propose \\textbf{JAWS}, a series of wrapper methods for distribution-free\nuncertainty quantification tasks under covariate shift, centered on our core\nmethod \\textbf{JAW}, the \\textbf{JA}ckknife+ \\textbf{W}eighted with\nlikelihood-ratio weights. JAWS also includes computationally efficient\n\\textbf{A}pproximations of JAW using higher-order influence functions:\n\\textbf{JAWA}. Theoretically, we show that JAW relaxes the jackknife+'s\nassumption of data exchangeability to achieve the same finite-sample coverage\nguarantee even under covariate shift. JAWA further approaches the JAW guarantee\nin the limit of either the sample size or the influence function order under\nmild assumptions. Moreover, we propose a general approach to repurposing any\ndistribution-free uncertainty quantification method and its guarantees to the\ntask of risk assessment: a task that generates the estimated probability that\nthe true label lies within a user-specified interval. We then propose\n\\textbf{JAW-R} and \\textbf{JAWA-R} as the repurposed versions of proposed\nmethods for \\textbf{R}isk assessment. Practically, JAWS outperform the\nstate-of-the-art predictive inference baselines in a variety of biased real\nworld data sets for both interval-generation and risk-assessment auditing\ntasks.",
    "descriptor": "",
    "authors": [
      "Drew Prinster",
      "Anqi Liu",
      "Suchi Saria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.10716"
  },
  {
    "id": "arXiv:2207.10719",
    "title": "Synthetic Dataset Generation for Adversarial Machine Learning Research",
    "abstract": "Existing adversarial example research focuses on digitally inserted\nperturbations on top of existing natural image datasets. This construction of\nadversarial examples is not realistic because it may be difficult, or even\nimpossible, for an attacker to deploy such an attack in the real-world due to\nsensing and environmental effects. To better understand adversarial examples\nagainst cyber-physical systems, we propose approximating the real-world through\nsimulation. In this paper we describe our synthetic dataset generation tool\nthat enables scalable collection of such a synthetic dataset with realistic\nadversarial examples. We use the CARLA simulator to collect such a dataset and\ndemonstrate simulated attacks that undergo the same environmental transforms\nand processing as real-world images. Our tools have been used to collect\ndatasets to help evaluate the efficacy of adversarial examples, and can be\nfound at https://github.com/carla-simulator/carla/pull/4992.",
    "descriptor": "",
    "authors": [
      "Xiruo Liu",
      "Shibani Singh",
      "Cory Cornelius",
      "Colin Busho",
      "Mike Tan",
      "Anindya Paul",
      "Jason Martin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10719"
  },
  {
    "id": "arXiv:2207.10720",
    "title": "Fusing Frame and Event Vision for High-speed Optical Flow for Edge  Application",
    "abstract": "Optical flow computation with frame-based cameras provides high accuracy but\nthe speed is limited either by the model size of the algorithm or by the frame\nrate of the camera. This makes it inadequate for high-speed applications. Event\ncameras provide continuous asynchronous event streams overcoming the frame-rate\nlimitation. However, the algorithms for processing the data either borrow frame\nlike setup limiting the speed or suffer from lower accuracy. We fuse the\ncomplementary accuracy and speed advantages of the frame and event-based\npipelines to provide high-speed optical flow while maintaining a low error\nrate. Our bio-mimetic network is validated with the MVSEC dataset showing 19%\nerror degradation at 4x speed up. We then demonstrate the system with a\nhigh-speed drone flight scenario where a high-speed event camera computes the\nflow even before the optical camera sees the drone making it suited for\napplications like tracking and segmentation. This work shows the fundamental\ntrade-offs in frame-based processing may be overcome by fusing data from other\nmodalities.",
    "descriptor": "",
    "authors": [
      "Ashwin Sanjay Lele",
      "Arijit Raychowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.10720"
  },
  {
    "id": "arXiv:2207.10721",
    "title": "Heterogeneous Ensemble Learning for Enhanced Crash Forecasts -- A  Frequentest and Machine Learning based Stacking Framework",
    "abstract": "A variety of statistical and machine learning methods are used to model crash\nfrequency on specific roadways with machine learning methods generally having a\nhigher prediction accuracy. Recently, heterogeneous ensemble methods (HEM),\nincluding stacking, have emerged as more accurate and robust intelligent\ntechniques and are often used to solve pattern recognition problems by\nproviding more reliable and accurate predictions. In this study, we apply one\nof the key HEM methods, Stacking, to model crash frequency on five lane\nundivided segments (5T) of urban and suburban arterials. The prediction\nperformance of Stacking is compared with parametric statistical models (Poisson\nand negative binomial) and three state of the art machine learning techniques\n(Decision tree, random forest, and gradient boosting), each of which is termed\nas the base learner. By employing an optimal weight scheme to combine\nindividual base learners through stacking, the problem of biased predictions in\nindividual base-learners due to differences in specifications and prediction\naccuracies is avoided. Data including crash, traffic, and roadway inventory\nwere collected and integrated from 2013 to 2017. The data are split into\ntraining, validation, and testing datasets. Estimation results of statistical\nmodels reveal that besides other factors, crashes increase with density (number\nper mile) of different types of driveways. Comparison of out-of-sample\npredictions of various models confirms the superiority of Stacking over the\nalternative methods considered. From a practical standpoint, stacking can\nenhance prediction accuracy (compared to using only one base learner with a\nparticular specification). When applied systemically, stacking can help\nidentify more appropriate countermeasures.",
    "descriptor": "\nComments: This paper was presented at the 101st Transportation Research Board Annual Meeting (TRBAM) by National Academy of Sciences in January 2022 in Washington D.C. The paper is currently under review for potential publication in an Impact Factor Journal\n",
    "authors": [
      "Numan Ahmad",
      "Behram Wali",
      "Asad J. Khattak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2207.10721"
  },
  {
    "id": "arXiv:2207.10722",
    "title": "Indicating interdisciplinarity: A multidimensional framework to  characterize Interdisciplinary Knowledge Flow (IKF)",
    "abstract": "This study contributes to the recent discussions on indicating\ninterdisciplinarity, i.e., going beyond mere metrics of interdisciplinarity. We\npropose a multi-dimensional and contextual framework to improve the granularity\nand usability of the existing methodology for quantifying the interdisciplinary\nknowledge flow (IKF) in which scientific disciplines import and export\nknowledge from/to other disciplines. To characterize the knowledge exchange\nbetween disciplines, we recognize three dimensions under this framework,\nnamely, broadness, intensity, and heterogeneity. We show that each dimension\ncovers a different aspect of IKF, especially between disciplines with the\nlargest volume of IKF, and can assist in uncovering different types of\ninterdisciplinarity. We apply this framework in two use cases, one at the level\nof disciplines and one at the level of journals, to show how it can offer a\nmore holistic and detailed viewpoint on the interdisciplinarity of scientific\nentities than plain citation counts. We further compare our proposed framework,\nan indicating process, with established indicators and discuss how such\ninformation tools on interdisciplinarity can assist science policy practices\nsuch as performance-based research funding systems and panel-based peer review\nprocesses.",
    "descriptor": "",
    "authors": [
      "Hongyu Zhou",
      "Raf Guns",
      "Tim C. E. Engels"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.10722"
  },
  {
    "id": "arXiv:2207.10723",
    "title": "Hardware-Efficient Template-Based Deep CNNs Accelerator Design",
    "abstract": "Acceleration of Convolutional Neural Network (CNN) on edge devices has\nrecently achieved a remarkable performance in image classification and object\ndetection applications. This paper proposes an efficient and scalable CNN-based\nSoC-FPGA accelerator design that takes pre-trained weights with a 16-bit\nfixed-point quantization and target hardware specification to generate an\noptimized template capable of achieving higher performance versus resource\nutilization trade-off. The template analyzed the computational workload, data\ndependency, and external memory bandwidth and utilized loop tiling\ntransformation along with dataflow modeling to convert convolutional and fully\nconnected layers into vector multiplication between input and output feature\nmaps, which resulted in a single compute unit on-chip. Furthermore, the\naccelerator was examined among AlexNet, VGG16, and LeNet networks and ran at\n200-MHz with a peak performance of 230 GOP/s depending on ZYNQ boards and\nstate-space exploration of different compute unit configurations during\nsimulation and synthesis. Lastly, our proposed methodology was benchmarked\nagainst the previous development on Ultra96 for higher performance measurement.",
    "descriptor": "\nComments: 4 pages, 4 figures, 16th IEEE International Conference on Networking, Architecture, and Storage (IEEE NAS 2022), 3-4 October 2022\n",
    "authors": [
      "Azzam Alhussain",
      "Mingjie lin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.10723"
  },
  {
    "id": "arXiv:2207.10725",
    "title": "A Deep Neural Network/Meshfree Method for Solving Dynamic Two-phase  Interface Problems",
    "abstract": "In this paper, a meshfree method using the deep neural network (DNN) approach\nis developed for solving two kinds of dynamic two-phase interface problems\ngoverned by different dynamic partial differential equations on either side of\nthe stationary interface with the jump and high-contrast coefficients. The\nfirst type of two-phase interface problem to be studied is the fluid-fluid\n(two-phase flow) interface problem modeled by Navier-Stokes equations with\nhigh-contrast physical parameters across the interface. The second one belongs\nto fluid-structure interaction (FSI) problems modeled by Navier-Stokes\nequations on one side of the interface and the structural equation on the other\nside of the interface, both the fluid and the structure interact with each\nother via the kinematic- and the dynamic interface conditions across the\ninterface. The DNN/meshfree method is respectively developed for the above\ntwo-phase interface problems by representing solutions of PDEs using the DNNs'\nstructure and reformulating the dynamic interface problem as a least-squares\nminimization problem based upon a space-time sampling point set. Approximation\nerror analyses are also carried out for each kind of interface problem, which\nreveals an intrinsic strategy about how to efficiently build a sampling-point\ntraining dataset to obtain a more accurate DNNs' approximation. In addition,\ncompared with traditional discretization approaches, the proposed DNN/meshfree\nmethod and its error analysis technique can be smoothly extended to many other\ndynamic interface problems with fixed interfaces. Numerical experiments are\nconducted to illustrate the accuracies of the proposed DNN/meshfree method for\nthe presented two-phase interface problems. Theoretical results are validated\nto some extent through three numerical examples.",
    "descriptor": "",
    "authors": [
      "Xingwen Zhu",
      "Xiaozhe Hu",
      "Pengtao Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10725"
  },
  {
    "id": "arXiv:2207.10727",
    "title": "Federated Semi-Supervised Domain Adaptation via Knowledge Transfer",
    "abstract": "Given the rapidly changing machine learning environments and expensive data\nlabeling, semi-supervised domain adaptation (SSDA) is imperative when the\nlabeled data from the source domain is statistically different from the\npartially labeled data from the target domain. Most prior SSDA research is\ncentrally performed, requiring access to both source and target data. However,\ndata in many fields nowadays is generated by distributed end devices. Due to\nprivacy concerns, the data might be locally stored and cannot be shared,\nresulting in the ineffectiveness of existing SSDA research. This paper proposes\nan innovative approach to achieve SSDA over multiple distributed and\nconfidential datasets, named by Federated Semi-Supervised Domain Adaptation\n(FSSDA). FSSDA integrates SSDA with federated learning based on strategically\ndesigned knowledge distillation techniques, whose efficiency is improved by\nperforming source and target training in parallel. Moreover, FSSDA controls the\namount of knowledge transferred across domains by properly selecting a key\nparameter, i.e., the imitation parameter. Further, the proposed FSSDA can be\neffectively generalized to multi-source domain adaptation scenarios. Extensive\nexperiments are conducted to demonstrate the effectiveness and efficiency of\nFSSDA design.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Madhureeta Das",
      "Xianhao Chen",
      "Xiaoyong Yuan",
      "Lan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10727"
  },
  {
    "id": "arXiv:2207.10728",
    "title": "Decision-Feedback Detection for Bidirectional Molecular Relaying with  Direct Links",
    "abstract": "In this paper, we consider bidirectional relaying between two diffusion-based\nmolecular transceivers (bio-nodes). As opposed to existing literature, we\nincorporate the effect of direct diffusion links between the nodes and leverage\nit to improve performance. Assuming network coding type operation at the relay,\nwe devise a detection strategy, based on the maximum-likelihood principle, that\ncombines the signal received from the relay and that received from the direct\nlink. At the same time, since a diffusion-based molecular communication channel\nis characterized by high inter-symbol interference (ISI), we utilize a decision\nfeedback mechanism to mitigate its effect. Simulation results indicate that the\nproposed setup incorporating the direct link can achieve notable improvement in\nerror performance over conventional detection schemes that do not exploit the\ndirect link and/or do not attempt to mitigate the effect of ISI.",
    "descriptor": "",
    "authors": [
      "Maryam Khalid",
      "Momin Uppal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10728"
  },
  {
    "id": "arXiv:2207.10731",
    "title": "The trade-offs of model size in large recommendation models : A 10000  $\\times$ compressed criteo-tb DLRM model (100 GB parameters to mere 10MB)",
    "abstract": "Embedding tables dominate industrial-scale recommendation model sizes, using\nup to terabytes of memory. A popular and the largest publicly available machine\nlearning MLPerf benchmark on recommendation data is a Deep Learning\nRecommendation Model (DLRM) trained on a terabyte of click-through data. It\ncontains 100GB of embedding memory (25+Billion parameters). DLRMs, due to their\nsheer size and the associated volume of data, face difficulty in training,\ndeploying for inference, and memory bottlenecks due to large embedding tables.\nThis paper analyzes and extensively evaluates a generic parameter sharing setup\n(PSS) for compressing DLRM models. We show theoretical upper bounds on the\nlearnable memory requirements for achieving $(1 \\pm \\epsilon)$ approximations\nto the embedding table. Our bounds indicate exponentially fewer parameters\nsuffice for good accuracy. To this end, we demonstrate a PSS DLRM reaching\n10000$\\times$ compression on criteo-tb without losing quality. Such a\ncompression, however, comes with a caveat. It requires 4.5 $\\times$ more\niterations to reach the same saturation quality. The paper argues that this\ntradeoff needs more investigations as it might be significantly favorable.\nLeveraging the small size of the compressed model, we show a 4.3$\\times$\nimprovement in training latency leading to similar overall training times.\nThus, in the tradeoff between system advantage of a small DLRM model vs. slower\nconvergence, we show that scales are tipped towards having a smaller DLRM\nmodel, leading to faster inference, easier deployment, and similar training\ntimes.",
    "descriptor": "",
    "authors": [
      "Aditya Desai",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.10731"
  },
  {
    "id": "arXiv:2207.10733",
    "title": "GreenDB -- A Dataset and Benchmark for Extraction of Sustainability  Information of Consumer Goods",
    "abstract": "The production, shipping, usage, and disposal of consumer goods have a\nsubstantial impact on greenhouse gas emissions and the depletion of resources.\nMachine Learning (ML) can help to foster sustainable consumption patterns by\naccounting for sustainability aspects in product search or recommendations of\nmodern retail platforms. However, the lack of large high quality publicly\navailable product data with trustworthy sustainability information impedes the\ndevelopment of ML technology that can help to reach our sustainability goals.\nHere we present GreenDB, a database that collects products from European online\nshops on a weekly basis. As proxy for the products' sustainability, it relies\non sustainability labels, which are evaluated by experts. The GreenDB schema\nextends the well-known schema.org Product definition and can be readily\nintegrated into existing product catalogs. We present initial results\ndemonstrating that ML models trained with our data can reliably (F1 score 96%)\npredict the sustainability label of products. These contributions can help to\ncomplement existing e-commerce experiences and ultimately encourage users to\nmore sustainable consumption patterns.",
    "descriptor": "\nComments: Presented at DataPerf Workshop at the 39th International Conference on Machine Learning, Baltimore, Maryland, USA, 2022\n",
    "authors": [
      "Alexander Flick",
      "Sebastian Jaeger",
      "Jessica Adriana Sanchez Garcia",
      "Kaspar von den Driesch",
      "Karl Brendel",
      "Felix Biessmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.10733"
  },
  {
    "id": "arXiv:2207.10737",
    "title": "A Node Elimination Algorithm for Cubature of High-Dimensional Polytopes",
    "abstract": "Node elimination is a numerical approach to obtain cubature rules for the\napproximation of multivariate integrals. Beginning with a known cubature rule,\nnodes are selected for elimination, and a new, more efficient rule is\nconstructed by iteratively solving the moment equations. This paper introduces\na new criterion for selecting which nodes to eliminate that is based on a\nlinearization of the moment equation. In addition, a penalized iterative solver\nis introduced, that ensures that weights are positive and nodes are inside the\nintegration domain. A strategy for constructing an initial quadrature rule for\nvarious polytopes in several space dimensions is described. High efficiency\nrules are presented for two, three and four dimensional polytopes. The new\nrules are compared with rules that are obtained by combining tensor products of\none dimensional quadrature rules and domain transformations, as well as with\nknown analytically constructed cubature rules.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Arkadijs Slobodkins",
      "Johannes Tausch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10737"
  },
  {
    "id": "arXiv:2207.10739",
    "title": "BigIssue: A Realistic Bug Localization Benchmark",
    "abstract": "As machine learning tools progress, the inevitable question arises: How can\nmachine learning help us write better code? With significant progress being\nachieved in natural language processing with models like GPT-3 and Bert, the\napplications of natural language processing techniques to code are starting to\nbe explored. Most of the research has been focused on automatic program repair\n(APR), and while the results on synthetic or highly filtered datasets are\npromising, such models are hard to apply in real-world scenarios because of\ninadequate bug localization. We propose BigIssue: a benchmark for realistic bug\nlocalization. The goal of the benchmark is two-fold. We provide (1) a general\nbenchmark with a diversity of real and synthetic Java bugs and (2) a motivation\nto improve bug localization capabilities of models through attention to the\nfull repository context. With the introduction of BigIssue, we hope to advance\nthe state of the art in bug localization, in turn improving APR performance and\nincreasing its applicability to the modern development cycle.",
    "descriptor": "",
    "authors": [
      "Paul Kassianik",
      "Erik Nijkamp",
      "Bo Pang",
      "Yingbo Zhou",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.10739"
  },
  {
    "id": "arXiv:2207.10741",
    "title": "Irrelevant Pixels are Everywhere: Find and Exclude Them for More  Efficient Computer Vision",
    "abstract": "Computer vision is often performed using Convolutional Neural Networks\n(CNNs). CNNs are compute-intensive and challenging to deploy on\npower-contrained systems such as mobile and Internet-of-Things (IoT) devices.\nCNNs are compute-intensive because they indiscriminately compute many features\non all pixels of the input image. We observe that, given a computer vision\ntask, images often contain pixels that are irrelevant to the task. For example,\nif the task is looking for cars, pixels in the sky are not very useful.\nTherefore, we propose that a CNN be modified to only operate on relevant pixels\nto save computation and energy. We propose a method to study three popular\ncomputer vision datasets, finding that 48% of pixels are irrelevant. We also\npropose the focused convolution to modify a CNN's convolutional layers to\nreject the pixels that are marked irrelevant. On an embedded device, we observe\nno loss in accuracy, while inference latency, energy consumption, and\nmultiply-add count are all reduced by about 45%.",
    "descriptor": "",
    "authors": [
      "Caleb Tung",
      "Abhinav Goel",
      "Xiao Hu",
      "Nicholas Eliopoulos",
      "Emmanuel Amobi",
      "George K. Thiruvathukal",
      "Vipin Chaudhary",
      "Yung-Hsiang Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10741"
  },
  {
    "id": "arXiv:2207.10746",
    "title": "Templating Shuffles",
    "abstract": "Cloud data centers are rapidly evolving. At the same time, large-scale data\nanalytics applications require non-trivial performance tuning that is often\nspecific to the applications, workloads, and data center infrastructure. We\npropose TeShu, which makes network shuffling an extensible unified service\nlayer common to all data analytics. Since an optimal shuffle depends on a\nmyriad of factors, TeShu introduces parameterized shuffle templates,\ninstantiated by accurate and efficient sampling that enables TeShu to\ndynamically adapt to different application workloads and data center layouts.\nOur experimental results with real-world graph workloads show that TeShu\nefficiently enables shuffling optimizations that improve performance and adapt\nto a variety of scenarios.",
    "descriptor": "\nComments: The technical report of TeShu\n",
    "authors": [
      "Qizhen Zhang",
      "Jiacheng Wu",
      "Ang Chen",
      "Vincent Liu",
      "Boon Thau Loo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.10746"
  },
  {
    "id": "arXiv:2207.10748",
    "title": "STARS Enabled Integrated Sensing and Communications",
    "abstract": "A simultaneously transmitting and reflecting intelligent surface (STARS)\nenabled integrated sensing and communications (ISAC) framework is proposed,\nwhere the whole space is divided by STARS into a sensing space and a\ncommunication space. A novel sensing-at-STARS structure, where dedicated\nsensors are installed at the STARS, is proposed to address the significant path\nloss and clutter interference for sensing. The Cramer-Rao bound (CRB) of the\n2-dimension (2D) direction-of-arrivals (DOAs) estimation of the sensing target\nis derived, which is then minimized subject to the minimum communication\nrequirement. A novel approach is proposed to transform the complicated CRB\nminimization problem into a trackable modified Fisher information matrix (FIM)\noptimization problem. Both independent and coupled phase-shift models of STARS\nare investigated: 1) For the independent phase-shift model, to address the\ncoupling of ISAC waveform and STARS coefficient in the modified FIM, an\nefficient double-loop iterative algorithm based on the penalty dual\ndecomposition (PDD) framework is conceived; 2) For the coupled phase-shift\nmodel, based on the PDD framework, a low complexity alternating optimization\nalgorithm is proposed to tackle coupled phase-shift constants by alternatively\noptimizing amplitude and phase-shift coefficients in closed-form. Finally, the\nnumerical results demonstrate that: 1) STARS significantly outperforms the\nconventional RIS in CRB under the communication constraints; 2) The coupled\nphase-shift model achieves comparable performance to the independent one for\nlow communication requirements or sufficient STARS elements; 3) It is more\nefficient to increase the number of passive elements of STARS rather than the\nactive elements of the sensor; 4) High sensing accuracy can be achieved by\nSTARS using the practical 2D maximum likelihood estimator compared with the\nconventional RIS.",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Zhaolin Wang",
      "Xidong Mu",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10748"
  },
  {
    "id": "arXiv:2207.10751",
    "title": "Federated Learning on Adaptively Weighted Nodes by Bilevel Optimization",
    "abstract": "We propose a federated learning method with weighted nodes in which the\nweights can be modified to optimize the model's performance on a separate\nvalidation set. The problem is formulated as a bilevel optimization where the\ninner problem is a federated learning problem with weighted nodes and the outer\nproblem focuses on optimizing the weights based on the validation performance\nof the model returned from the inner problem. A communication-efficient\nfederated optimization algorithm is designed to solve this bilevel optimization\nproblem. Under an error-bound assumption, we analyze the generalization\nperformance of the output model and identify scenarios when our method is in\ntheory superior to training a model only locally and to federated learning with\nstatic and evenly distributed weights.",
    "descriptor": "",
    "authors": [
      "Yankun Huang",
      "Qihang Lin",
      "Nick Street",
      "Stephen Baek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10751"
  },
  {
    "id": "arXiv:2207.10758",
    "title": "DEVIANT: Depth EquiVarIAnt NeTwork for Monocular 3D Object Detection",
    "abstract": "Modern neural networks use building blocks such as convolutions that are\nequivariant to arbitrary 2D translations. However, these vanilla blocks are not\nequivariant to arbitrary 3D translations in the projective manifold. Even then,\nall monocular 3D detectors use vanilla blocks to obtain the 3D coordinates, a\ntask for which the vanilla blocks are not designed for. This paper takes the\nfirst step towards convolutions equivariant to arbitrary 3D translations in the\nprojective manifold. Since the depth is the hardest to estimate for monocular\ndetection, this paper proposes Depth EquiVarIAnt NeTwork (DEVIANT) built with\nexisting scale equivariant steerable blocks. As a result, DEVIANT is\nequivariant to the depth translations in the projective manifold whereas\nvanilla networks are not. The additional depth equivariance forces the DEVIANT\nto learn consistent depth estimates, and therefore, DEVIANT achieves\nstate-of-the-art monocular 3D detection results on KITTI and Waymo datasets in\nthe image-only category and performs competitively to methods using extra\ninformation. Moreover, DEVIANT works better than vanilla networks in\ncross-dataset evaluation. Code and models at\nhttps://github.com/abhi1kumar/DEVIANT",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Abhinav Kumar",
      "Garrick Brazil",
      "Enrique Corona",
      "Armin Parchami",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10758"
  },
  {
    "id": "arXiv:2207.10760",
    "title": "A Proposal for Foley Sound Synthesis Challenge",
    "abstract": "\"Foley\" refers to sound effects that are added to multimedia during\npost-production to enhance its perceived acoustic properties, e.g., by\nsimulating the sounds of footsteps, ambient environmental sounds, or visible\nobjects on the screen. While foley is traditionally produced by foley artists,\nthere is increasing interest in automatic or machine-assisted techniques\nbuilding upon recent advances in sound synthesis and generative models. To\nfoster more participation in this growing research area, we propose a challenge\nfor automatic foley synthesis. Through case studies on successful previous\nchallenges in audio and machine learning, we set the goals of the proposed\nchallenge: rigorous, unified, and efficient evaluation of different foley\nsynthesis systems, with an overarching goal of drawing active participation\nfrom the research community. We outline the details and design considerations\nof a foley sound synthesis challenge, including task definition, dataset\nrequirements, and evaluation criteria.",
    "descriptor": "",
    "authors": [
      "Keunwoo Choi",
      "Sangshin Oh",
      "Minsung Kang",
      "Brian McFee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10760"
  },
  {
    "id": "arXiv:2207.10761",
    "title": "TIDEE: Tidying Up Novel Rooms using Visuo-Semantic Commonsense Priors",
    "abstract": "We introduce TIDEE, an embodied agent that tidies up a disordered scene based\non learned commonsense object placement and room arrangement priors. TIDEE\nexplores a home environment, detects objects that are out of their natural\nplace, infers plausible object contexts for them, localizes such contexts in\nthe current scene, and repositions the objects. Commonsense priors are encoded\nin three modules: i) visuo-semantic detectors that detect out-of-place objects,\nii) an associative neural graph memory of objects and spatial relations that\nproposes plausible semantic receptacles and surfaces for object repositions,\nand iii) a visual search network that guides the agent's exploration for\nefficiently localizing the receptacle-of-interest in the current scene to\nreposition the object. We test TIDEE on tidying up disorganized scenes in the\nAI2THOR simulation environment. TIDEE carries out the task directly from pixel\nand raw depth input without ever having observed the same room beforehand,\nrelying only on priors learned from a separate set of training houses. Human\nevaluations on the resulting room reorganizations show TIDEE outperforms\nablative versions of the model that do not use one or more of the commonsense\npriors. On a related room rearrangement benchmark that allows the agent to view\nthe goal state prior to rearrangement, a simplified version of our model\nsignificantly outperforms a top-performing method by a large margin. Code and\ndata are available at the project website: https://tidee-agent.github.io/.",
    "descriptor": "",
    "authors": [
      "Gabriel Sarch",
      "Zhaoyuan Fang",
      "Adam W. Harley",
      "Paul Schydlo",
      "Michael J. Tarr",
      "Saurabh Gupta",
      "Katerina Fragkiadaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10761"
  },
  {
    "id": "arXiv:2207.10762",
    "title": "MeshLoc: Mesh-Based Visual Localization",
    "abstract": "Visual localization, i.e., the problem of camera pose estimation, is a\ncentral component of applications such as autonomous robots and augmented\nreality systems. A dominant approach in the literature, shown to scale to large\nscenes and to handle complex illumination and seasonal changes, is based on\nlocal features extracted from images. The scene representation is a sparse\nStructure-from-Motion point cloud that is tied to a specific local feature.\nSwitching to another feature type requires an expensive feature matching step\nbetween the database images used to construct the point cloud. In this work, we\nthus explore a more flexible alternative based on dense 3D meshes that does not\nrequire features matching between database images to build the scene\nrepresentation. We show that this approach can achieve state-of-the-art\nresults. We further show that surprisingly competitive results can be obtained\nwhen extracting features on renderings of these meshes, without any neural\nrendering stage, and even when rendering raw scene geometry without color or\ntexture. Our results show that dense 3D model-based representations are a\npromising alternative to existing representations and point to interesting and\nchallenging directions for future research.",
    "descriptor": "\nComments: to be published in the proceedings of ECCV 2022\n",
    "authors": [
      "Vojtech Panek",
      "Zuzana Kukelova",
      "Torsten Sattler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10762"
  },
  {
    "id": "arXiv:2207.10763",
    "title": "Sim-to-real Deep Reinforcement Learning for Comparing Low-cost  High-Resolution Robot Touch",
    "abstract": "High-resolution optical tactile sensors are increasingly used in robotic\nlearning environments due to their ability to capture large amounts of data\ndirectly relating to agent-environment interaction. However, there is a high\nbarrier of entry to research in this area due to the high cost of tactile robot\nplatforms, specialised simulation software, and sim-to-real methods that lack\ngenerality across different sensors. In this letter we extend the Tactile Gym\nsimulator to include three new optical tactile sensors (TacTip, DIGIT and\nDigiTac) of the two most popular types, Gelsight-style (image-shading based)\nand TacTip-style (marker based). We demonstrate that a single sim-to-real\napproach can be used with these three different sensors to achieve strong\nreal-world performance despite the significant differences between real tactile\nimages. Additionally, we lower the barrier of entry to the proposed tasks by\nadapting them to an inexpensive 4-DoF robot arm, further enabling the\ndissemination of this benchmark. We validate the extended environment on three\nphysically-interactive tasks requiring a sense of touch: object pushing, edge\nfollowing and surface following. The results of our experimental validation\nhighlight some differences between these sensors, which may help future\nresearchers select and customize the physical characteristics of tactile\nsensors for different manipulations scenarios.",
    "descriptor": "",
    "authors": [
      "Yijiong Lin",
      "John Lloyd",
      "Alex Church",
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10763"
  },
  {
    "id": "arXiv:2207.10765",
    "title": "Towards Interpretable Video Super-Resolution via Alternating  Optimization",
    "abstract": "In this paper, we study a practical space-time video super-resolution (STVSR)\nproblem which aims at generating a high-framerate high-resolution sharp video\nfrom a low-framerate low-resolution blurry video. Such problem often occurs\nwhen recording a fast dynamic event with a low-framerate and low-resolution\ncamera, and the captured video would suffer from three typical issues: i)\nmotion blur occurs due to object/camera motions during exposure time; ii)\nmotion aliasing is unavoidable when the event temporal frequency exceeds the\nNyquist limit of temporal sampling; iii) high-frequency details are lost\nbecause of the low spatial sampling rate. These issues can be alleviated by a\ncascade of three separate sub-tasks, including video deblurring, frame\ninterpolation, and super-resolution, which, however, would fail to capture the\nspatial and temporal correlations among video sequences. To address this, we\npropose an interpretable STVSR framework by leveraging both model-based and\nlearning-based methods. Specifically, we formulate STVSR as a joint video\ndeblurring, frame interpolation, and super-resolution problem, and solve it as\ntwo sub-problems in an alternate way. For the first sub-problem, we derive an\ninterpretable analytical solution and use it as a Fourier data transform layer.\nThen, we propose a recurrent video enhancement layer for the second sub-problem\nto further recover high-frequency details. Extensive experiments demonstrate\nthe superiority of our method in terms of quantitative metrics and visual\nquality.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Jiezhang Cao",
      "Jingyun Liang",
      "Kai Zhang",
      "Wenguan Wang",
      "Qin Wang",
      "Yulun Zhang",
      "Hao Tang",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10765"
  },
  {
    "id": "arXiv:2207.10767",
    "title": "Modeling User Behavior With Interaction Networks for Spam Detection",
    "abstract": "Spam is a serious problem plaguing web-scale digital platforms which\nfacilitate user content creation and distribution. It compromises platform's\nintegrity, performance of services like recommendation and search, and overall\nbusiness. Spammers engage in a variety of abusive and evasive behavior which\nare distinct from non-spammers. Users' complex behavior can be well represented\nby a heterogeneous graph rich with node and edge attributes. Learning to\nidentify spammers in such a graph for a web-scale platform is challenging\nbecause of its structural complexity and size. In this paper, we propose SEINE\n(Spam DEtection using Interaction NEtworks), a spam detection model over a\nnovel graph framework. Our graph simultaneously captures rich users' details\nand behavior and enables learning on a billion-scale graph. Our model considers\nneighborhood along with edge types and attributes, allowing it to capture a\nwide range of spammers. SEINE, trained on a real dataset of tens of millions of\nnodes and billions of edges, achieves a high performance of 80% recall with 1%\nfalse positive rate. SEINE achieves comparable performance to the\nstate-of-the-art techniques on a public dataset while being pragmatic to be\nused in a large-scale production system.",
    "descriptor": "\nComments: 6 pages, 2 figures, accepted to SIGIR 2022\n",
    "authors": [
      "Prabhat Agarwal",
      "Manisha Srivastava",
      "Vishwakarma Singh",
      "Charles Rosenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10767"
  },
  {
    "id": "arXiv:2207.10774",
    "title": "Focused Decoding Enables 3D Anatomical Detection by Transformers",
    "abstract": "Detection Transformers represent end-to-end object detection approaches based\non a Transformer encoder-decoder architecture, exploiting the attention\nmechanism for global relation modeling. Although Detection Transformers deliver\nresults on par with or even superior to their highly optimized CNN-based\ncounterparts operating on 2D natural images, their success is closely coupled\nto access to a vast amount of training data. This, however, restricts the\nfeasibility of employing Detection Transformers in the medical domain, as\naccess to annotated data is typically limited. To tackle this issue and\nfacilitate the advent of medical Detection Transformers, we propose a novel\nDetection Transformer for 3D anatomical structure detection, dubbed Focused\nDecoder. Focused Decoder leverages information from an anatomical region atlas\nto simultaneously deploy query anchors and restrict the cross-attention's field\nof view to regions of interest, which allows for a precise focus on relevant\nanatomical structures. We evaluate our proposed approach on two publicly\navailable CT datasets and demonstrate that Focused Decoder not only provides\nstrong detection results and thus alleviates the need for a vast amount of\nannotated data but also exhibits exceptional and highly intuitive\nexplainability of results via attention weights. Code for Focused Decoder is\navailable in our medical Vision Transformer library\ngithub.com/bwittmann/transoar.",
    "descriptor": "",
    "authors": [
      "Bastian Wittmann",
      "Fernando Navarro",
      "Suprosanna Shit",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10774"
  },
  {
    "id": "arXiv:2207.10776",
    "title": "Auto-regressive Image Synthesis with Integrated Quantization",
    "abstract": "Deep generative models have achieved conspicuous progress in realistic image\nsynthesis with multifarious conditional inputs, while generating diverse yet\nhigh-fidelity images remains a grand challenge in conditional image generation.\nThis paper presents a versatile framework for conditional image generation\nwhich incorporates the inductive bias of CNNs and powerful sequence modeling of\nauto-regression that naturally leads to diverse image generation. Instead of\nindependently quantizing the features of multiple domains as in prior research,\nwe design an integrated quantization scheme with a variational regularizer that\nmingles the feature discretization in multiple domains, and markedly boosts the\nauto-regressive modeling performance. Notably, the variational regularizer\nenables to regularize feature distributions in incomparable latent spaces by\npenalizing the intra-domain variations of distributions. In addition, we design\na Gumbel sampling strategy that allows to incorporate distribution uncertainty\ninto the auto-regressive training procedure. The Gumbel sampling substantially\nmitigates the exposure bias that often incurs misalignment between the training\nand inference stages and severely impairs the inference performance. Extensive\nexperiments over multiple conditional image generation tasks show that our\nmethod achieves superior diverse image generation performance qualitatively and\nquantitatively as compared with the state-of-the-art.",
    "descriptor": "\nComments: Accepted to ECCV 2022 as Oral Presentation\n",
    "authors": [
      "Fangneng Zhan",
      "Yingchen Yu",
      "Rongliang Wu",
      "Jiahui Zhang",
      "Kaiwen Cui",
      "Changgong Zhang",
      "Shijian Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10776"
  },
  {
    "id": "arXiv:2207.10777",
    "title": "An advanced combination of semi-supervised Normalizing Flow & Yolo  (YoloNF) to detect and recognize vehicle license plates",
    "abstract": "Fully Automatic License Plate Recognition (ALPR) has been a frequent research\ntopic due to several practical applications. However, many of the current\nsolutions are still not robust enough in real situations, commonly depending on\nmany constraints. This paper presents a robust and efficient ALPR system based\non the state-of-the-art YOLO object detector and Normalizing flows. The model\nuses two new strategies. Firstly, a two-stage network using YOLO and a\nnormalization flow-based model for normalization to detect Licenses Plates (LP)\nand recognize the LP with numbers and Arabic characters. Secondly, Multi-scale\nimage transformations are implemented to provide a solution to the problem of\nthe YOLO cropped LP detection including significant background noise.\nFurthermore, extensive experiments are led on a new dataset with realistic\nscenarios, we introduce a larger public annotated dataset collected from\nMoroccan plates. We demonstrate that our proposed model can learn on a small\nnumber of samples free of single or multiple characters. The dataset will also\nbe made publicly available to encourage further studies and research on plate\ndetection and recognition.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1802.09567 by other authors; text overlap with arXiv:2012.06737 by other authors without attribution\n",
    "authors": [
      "Khalid Oublal",
      "Xinyi Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10777"
  },
  {
    "id": "arXiv:2207.10780",
    "title": "Cryptographic and Financial Fairness",
    "abstract": "A recent trend in multi-party computation is to achieve cryptographic\nfairness via monetary penalties, i.e. each honest player either obtains the\noutput or receives a compensation in the form of a cryptocurrency. We pioneer\nanother type of fairness, financial fairness, that is closer to the real-world\nvaluation of financial transactions. Intuitively, a penalty protocol is\nfinancially fair if the net present cost of participation (the total value of\ncash inflows less cash outflows, weighted by the relative discount rate) is the\nsame for all honest participants, even when some parties cheat.\nWe formally define the notion, show several impossibility results based on\ngame theory, and analyze the practical effects of (lack of) financial fairness\nif one was to run the protocols for real on Bitcoin using Bloomberg's dark pool\ntrading.\nFor example, we show that the ladder protocol (CRYPTO'14), and its variants\n(CCS'15 and CCS'16), fail to achieve financial fairness both in theory and in\npractice, while the penalty protocols of Kumaresan and Bentov (CCS'14) and\nBaum, David and Dowsley (FC'20) are financially fair.\nThis version contains formal definitions, detailed security proofs, demos and\nexperimental data in the appendix.",
    "descriptor": "",
    "authors": [
      "Daniele Friolo",
      "Fabio Massacci",
      "Chan Nam Ngo",
      "Daniele Venturi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10780"
  },
  {
    "id": "arXiv:2207.10782",
    "title": "Learning Deep SDF Maps Online for Robot Navigation and Exploration",
    "abstract": "We propose an algorithm to (i) learn online a deep signed distance function\n(SDF) with a LiDAR-equipped robot to represent the 3D environment geometry, and\n(ii) plan collision-free trajectories given this deep learned map. Our\nalgorithm takes a stream of incoming LiDAR scans and continually optimizes a\nneural network to represent the SDF of the environment around its current\nvicinity. When the SDF network quality saturates, we cache a copy of the\nnetwork, along with a learned confidence metric, and initialize a new SDF\nnetwork to continue mapping new regions of the environment. We then concatenate\nall the cached local SDFs through a confidence-weighted scheme to give a global\nSDF for planning. For planning, we make use of a sequential convex model\npredictive control (MPC) algorithm. The MPC planner optimizes a dynamically\nfeasible trajectory for the robot while enforcing no collisions with obstacles\nmapped in the global SDF. We show that our online mapping algorithm produces\nhigher-quality maps than existing methods for online SDF training. In the\nWeBots simulator, we further showcase the combined mapper and planner running\nonline -- navigating autonomously and without collisions in an unknown\nenvironment.",
    "descriptor": "",
    "authors": [
      "Gadiel Sznaier Camps",
      "Robert Dyro",
      "Marco Pavone",
      "Mac Schwager"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10782"
  },
  {
    "id": "arXiv:2207.10783",
    "title": "Heuristic Rating Estimation Method for the incomplete pairwise  comparisons matrices",
    "abstract": "The Heuristic Rating Estimation Method enables decision-makers to decide\nbased on existing ranking data and expert comparisons. In this approach, the\nranking values of selected alternatives are known in advance, while these\nvalues have to be calculated for the remaining ones. Their calculation can be\nperformed using either an additive or a multiplicative method. Both methods\nassumed that the pairwise comparison sets involved in the computation were\ncomplete. In this paper, we show how these algorithms can be extended so that\nthe experts do not need to compare all alternatives pairwise. Thanks to the\nshortening of the work of experts, the presented, improved methods will reduce\nthe costs of the decision-making procedure and facilitate and shorten the stage\nof collecting decision-making data.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Konrad Ku\u0142akowski",
      "Anna K\u0119dzior"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2207.10783"
  },
  {
    "id": "arXiv:2207.10784",
    "title": "Strategising template-guided needle placement for MR-targeted prostate  biopsy",
    "abstract": "Clinically significant prostate cancer has a better chance to be sampled\nduring ultrasound-guided biopsy procedures, if suspected lesions found in\npre-operative magnetic resonance (MR) images are used as targets. However, the\ndiagnostic accuracy of the biopsy procedure is limited by the\noperator-dependent skills and experience in sampling the targets, a sequential\ndecision making process that involves navigating an ultrasound probe and\nplacing a series of sampling needles for potentially multiple targets. This\nwork aims to learn a reinforcement learning (RL) policy that optimises the\nactions of continuous positioning of 2D ultrasound views and biopsy needles\nwith respect to a guiding template, such that the MR targets can be sampled\nefficiently and sufficiently. We first formulate the task as a Markov decision\nprocess (MDP) and construct an environment that allows the targeting actions to\nbe performed virtually for individual patients, based on their anatomy and\nlesions derived from MR images. A patient-specific policy can thus be\noptimised, before each biopsy procedure, by rewarding positive sampling in the\nMDP environment. Experiment results from fifty four prostate cancer patients\nshow that the proposed RL-learned policies obtained a mean hit rate of 93% and\nan average cancer core length of 11 mm, which compared favourably to two\nalternative baseline strategies designed by humans, without hand-engineered\nrewards that directly maximise these clinically relevant metrics. Perhaps more\ninterestingly, it is found that the RL agents learned strategies that were\nadaptive to the lesion size, where spread of the needles was prioritised for\nsmaller lesions. Such a strategy has not been previously reported or commonly\nadopted in clinical practice, but led to an overall superior targeting\nperformance when compared with intuitively designed strategies.",
    "descriptor": "\nComments: Paper submitted and accepted to CaPTion (Cancer Prevention through early detecTion) @ MICCAI 2022 Workshop\n",
    "authors": [
      "Iani JMB Gayo",
      "Shaheer U. Saeed",
      "Dean C. Barratt",
      "Matthew J. Clarkson",
      "Yipeng Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.10784"
  },
  {
    "id": "arXiv:2207.10785",
    "title": "Inductive and Transductive Few-Shot Video Classification via Appearance  and Temporal Alignments",
    "abstract": "We present a novel method for few-shot video classification, which performs\nappearance and temporal alignments. In particular, given a pair of query and\nsupport videos, we conduct appearance alignment via frame-level feature\nmatching to achieve the appearance similarity score between the videos, while\nutilizing temporal order-preserving priors for obtaining the temporal\nsimilarity score between the videos. Moreover, we introduce a few-shot video\nclassification framework that leverages the above appearance and temporal\nsimilarity scores across multiple steps, namely prototype-based training and\ntesting as well as inductive and transductive prototype refinement. To the best\nof our knowledge, our work is the first to explore transductive few-shot video\nclassification. Extensive experiments on both Kinetics and Something-Something\nV2 datasets show that both appearance and temporal alignments are crucial for\ndatasets with temporal order sensitivity such as Something-Something V2. Our\napproach achieves similar or better results than previous methods on both\ndatasets. Our code is available at https://github.com/VinAIResearch/fsvc-ata.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Khoi D. Nguyen",
      "Quoc-Huy Tran",
      "Khoi Nguyen",
      "Binh-Son Hua",
      "Rang Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10785"
  },
  {
    "id": "arXiv:2207.10786",
    "title": "Delayed Feedback in Generalised Linear Bandits Revisited",
    "abstract": "The stochastic generalised linear bandit is a well-understood model for\nsequential decision-making problems, with many algorithms achieving\nnear-optimal regret guarantees under immediate feedback. However, in many real\nworld settings, the requirement that the reward is observed immediately is not\napplicable. In this setting, standard algorithms are no longer theoretically\nunderstood. We study the phenomenon of delayed rewards in a theoretical manner\nby introducing a delay between selecting an action and receiving the reward.\nSubsequently, we show that an algorithm based on the optimistic principle\nimproves on existing approaches for this setting by eliminating the need for\nprior knowledge of the delay distribution and relaxing assumptions on the\ndecision set and the delays. This also leads to improving the regret guarantees\nfrom $ \\widetilde O(\\sqrt{dT}\\sqrt{d + \\mathbb{E}[\\tau]})$ to $ \\widetilde\nO(d\\sqrt{T} + d^{3/2}\\mathbb{E}[\\tau])$, where $\\mathbb{E}[\\tau]$ denotes the\nexpected delay, $d$ is the dimension and $T$ the time horizon and we have\nsuppressed logarithmic terms. We verify our theoretical results through\nexperiments on simulated data.",
    "descriptor": "",
    "authors": [
      "Benjamin Howson",
      "Ciara Pike-Burke",
      "Sarah Filippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.10786"
  },
  {
    "id": "arXiv:2207.10789",
    "title": "Authentication and Billing Scheme for The Electric Vehicles: EVABS",
    "abstract": "The need for different energy sources has increased due to the decrease in\nthe amount and the harm caused to the environment by its usage. Today, fossil\nfuels used as an energy source in land, sea or air vehicles are rapidly being\nreplaced by different energy sources. The number and types of vehicles using\nenergy sources other than fossil fuels are also increasing. Electricity stands\nout among the energy sources used. The possibility of generating electricity\nthat is renewable, compatible with nature and at a lower cost provides a great\nadvantage. For all these reasons, the use of electric vehicles is increasing\nday by day. Various solutions continue to be developed for the charging systems\nand post-charge billing processes of these vehicles. As a result of these\nsolutions, the standards have not yet been fully formed. In this study, an\nauthentication and billing scheme is proposed for charging and post-charging\nbilling processes of electric land vehicles keeping security and privacy in the\nforeground. This scheme is named EVABS, which derives from the phrase \"Electric\nVehicle Authentication and Billing Scheme\". An authentication and billing\nscheme is proposed where data communication is encrypted, payment transactions\nare handled securely and parties can authenticate over wired or wireless. The\nsecurity of the proposed scheme has been examined theoretically and it has been\ndetermined that it is secure against known attacks.",
    "descriptor": "",
    "authors": [
      "Omer Aydin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10789"
  },
  {
    "id": "arXiv:2207.10791",
    "title": "ATOM: A Generalizable Technique for Inferring Tracker-Advertiser Data  Sharing in the Online Behavioral Advertising Ecosystem",
    "abstract": "Data sharing between online trackers and advertisers is a key component in\nonline behavioral advertising. This sharing can be facilitated through a\nvariety of processes, including those not observable to the user's browser. The\nunobservability of these processes limits the ability of researchers and\nauditors seeking to verify compliance with regulations which require complete\ndisclosure of data sharing partners. Unfortunately, the applicability of\nexisting techniques to make inferences about unobservable data sharing\nrelationships is limited due to their dependence on protocol- or case-specific\nartifacts of the online behavioral advertising ecosystem (e.g., they work only\nwhen client-side header bidding is used for ad delivery or when advertisers\nperform ad retargeting). As behavioral advertising technologies continue to\nevolve rapidly, the availability of these artifacts and the effectiveness of\ntransparency solutions dependent on them remain ephemeral. In this paper, we\npropose a generalizable technique, called ATOM, to infer data sharing\nrelationships between online trackers and advertisers. ATOM is different from\nprior work in that it is universally applicable -- i.e., independent of ad\ndelivery protocols or availability of artifacts. ATOM leverages the insight\nthat by the very nature of behavioral advertising, ad creatives themselves can\nbe used to infer data sharing between trackers and advertisers -- after all,\nthe topics and brands showcased in an ad are dependent on the data available to\nthe advertiser. Therefore, by selectively blocking trackers and monitoring\nchanges in the characteristics of ads delivered by advertisers, ATOM is able to\nidentify data sharing relationships between trackers and advertisers. The\nrelationships discovered by our implementation of ATOM include those not found\nusing prior approaches and are validated by external sources.",
    "descriptor": "\nComments: Accepted at PETS'22 16 Pages 3 Tables 2 Figures\n",
    "authors": [
      "Maaz Bin Musa",
      "Rishab Nithyanand"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10791"
  },
  {
    "id": "arXiv:2207.10792",
    "title": "Test-Time Adaptation via Self-Training with Nearest Neighbor Information",
    "abstract": "Adapting trained classifiers using only online test data is important since\nit is difficult to access training data or future test data during test time.\nOne of the popular approaches for test-time adaptation is self-training, which\nfine-tunes the trained classifiers using the classifier predictions of the test\ndata as pseudo labels. However, under the test-time domain shift, self-training\nmethods have a limitation that learning with inaccurate pseudo labels greatly\ndegrades the performance of the adapted classifiers. To overcome this\nlimitation, we propose a novel test-time adaptation method Test-time Adaptation\nvia Self-Training with nearest neighbor information (TAST). Based on the idea\nthat a test data and its nearest neighbors in the embedding space of the\ntrained classifier are more likely to have the same label, we adapt the trained\nclassifier with the following two steps: (1) generate the pseudo label for the\ntest data using its nearest neighbors from a set composed of previous test\ndata, and (2) fine-tune the trained classifier with the pseudo label. Our\nexperiments on two standard benchmarks, i.e., domain generalization and image\ncorruption benchmarks, show that TAST outperforms the current state-of-the-art\ntest-time adaptation methods.",
    "descriptor": "",
    "authors": [
      "Minguk Jang",
      "Sae-Young Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10792"
  },
  {
    "id": "arXiv:2207.10793",
    "title": "The Dirty Secret of SSDs: Embodied Carbon",
    "abstract": "Scalable Solid-State Drives (SSDs) have revolutionized the way we store and\naccess our data across datacenters and handheld devices. Unfortunately, scaling\ntechnology can have a significant environmental impact. Across the globe, most\nsemiconductor manufacturing use electricity that is generated from coal and\nnatural gas. For instance, manufacturing a Gigabyte of Flash emits 0.16 Kg\nCO$_2$ and is a significant fraction of the total carbon emission in the\nsystem. We estimate that manufacturing storage devices has resulted in 20\nmillion metric tonnes of CO$_2$ emissions in 2021 alone. To better understand\nthis concern, this paper compares the sustainability trade-offs between Hard\nDisk Drives (HDDs) and SSDs and recommends methodologies to estimate the\nembodied carbon costs of the storage system. In this paper, we outline four\npossible strategies to make storage systems sustainable. First, this paper\nrecommends directions that help select the right medium of storage (SSD vs\nHDD). Second, this paper proposes lifetime extension techniques for SSDs.\nThird, this paper advocates for effective and efficient recycling and reuse of\nhigh-density multi-level cell-based SSDs. Fourth, specifically for hand-held\ndevices, this paper recommends leveraging elasticity in cloud storage.",
    "descriptor": "\nComments: In the proceedings of the 1st Workshop on Sustainable Computer Systems Design and Implementation (HotCarbon 2022)\n",
    "authors": [
      "Swamit Tannu",
      "Prashant J. Nair"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.10793"
  },
  {
    "id": "arXiv:2207.10795",
    "title": "DJI drone IDs are not encrypted",
    "abstract": "Drones are widely used in the energy, construction, agriculture,\ntransportation, warehousing, real estate and movie industries. Key applications\ninclude surveys, inspections, deliveries and cinematography. With approximately\n70-80% of the global market share of commercial off-the-shelf drones, Da-Jiang\nInnovations (DJI), headquartered in Shenzhen, China, essentially monopolizes\nthe drone market. As commercial-off-the-shelf drone sales steadily rise, the\nFederal Aviation Administration has instituted regulations to protect the\nfederal airspace. DJI has become a pioneer in developing remote identification\ntechnology in the form of drone ID (also known as AeroScope signals). Despite\nclaims from the company touting its implementation of drone ID technology as\n\"encrypted\" yet later being proved incorrect for the claim, it remains a\nmystery on how one can grab and decode drone IDs over the air with low-cost\nradio frequency hardware in real-time. This research paper discusses a\nmethodology using radio software and hardware to detect both Enhanced Wi-Fi and\nOcuSync drone IDs, the three types of drone ID packet structures and a\nfunctioning prototype of a DJI OcuSync detection system equipped with two\nHackRF Ones.",
    "descriptor": "\nComments: 13 pages, 15 figures, 5 tables, 10 algorithms\n",
    "authors": [
      "Conner Bender"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10795"
  },
  {
    "id": "arXiv:2207.10796",
    "title": "Multiple Robust Learning for Recommendation",
    "abstract": "In recommender systems, a common problem is the presence of various biases in\nthe collected data, which deteriorates the generalization ability of the\nrecommendation models and leads to inaccurate predictions. Doubly robust (DR)\nlearning has been studied in many tasks in RS, with the advantage that unbiased\nlearning can be achieved when either a single imputation or a single propensity\nmodel is accurate. In this paper, we propose a multiple robust (MR) estimator\nthat can take the advantage of multiple candidate imputation and propensity\nmodels to achieve unbiasedness. Specifically, the MR estimator is unbiased when\nany of the imputation or propensity models, or a linear combination of these\nmodels is accurate. Theoretical analysis shows that the proposed MR is an\nenhanced version of DR when only having a single imputation and propensity\nmodel, and has a smaller bias. Inspired by the generalization error bound of\nMR, we further propose a novel multiple robust learning approach with\nstabilization. We conduct extensive experiments on real-world and\nsemi-synthetic datasets, which demonstrates the superiority of the proposed\napproach over state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Haoxuan Li",
      "Quanyu Dai",
      "Yuru Li",
      "Yan Lyu",
      "Zhenhua Dong",
      "Peng Wu",
      "Xiao-Hua Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.10796"
  },
  {
    "id": "arXiv:2207.10797",
    "title": "IDPS Signature Classification with a Reject Option and the Incorporation  of Expert Knowledge",
    "abstract": "As the importance of intrusion detection and prevention systems (IDPSs)\nincreases, great costs are incurred to manage the signatures that are generated\nby malicious communication pattern files. Experts in network security need to\nclassify signatures by importance for an IDPS to work. We propose and evaluate\na machine learning signature classification model with a reject option (RO) to\nreduce the cost of setting up an IDPS. To train the proposed model, it is\nessential to design features that are effective for signature classification.\nExperts classify signatures with predefined if-then rules. An if-then rule\nreturns a label of low, medium, high, or unknown importance based on keyword\nmatching of the elements in the signature. Therefore, we first design two types\nof features, symbolic features (SFs) and keyword features (KFs), which are used\nin keyword matching for the if-then rules. Next, we design web information and\nmessage features (WMFs) to capture the properties of signatures that do not\nmatch the if-then rules. The WMFs are extracted as term frequency-inverse\ndocument frequency (TF-IDF) features of the message text in the signatures. The\nfeatures are obtained by web scraping from the referenced external attack\nidentification systems described in the signature. Because failure needs to be\nminimized in the classification of IDPS signatures, as in the medical field, we\nconsider introducing a RO in our proposed model. The effectiveness of the\nproposed classification model is evaluated in experiments with two real\ndatasets composed of signatures labeled by experts: a dataset that can be\nclassified with if-then rules and a dataset with elements that do not match an\nif-then rule. In the experiment, the proposed model is evaluated. In both\ncases, the combined SFs and WMFs performed better than the combined SFs and\nKFs. In addition, we also performed feature analysis.",
    "descriptor": "\nComments: 9 pages, 5 figures, 3 tables\n",
    "authors": [
      "Hidetoshi Kawaguchi",
      "Yuichi Nakatani",
      "Shogo Okada"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10797"
  },
  {
    "id": "arXiv:2207.10798",
    "title": "Security Challenges when Space Merges with Cyberspace",
    "abstract": "Spaceborne systems, such as communication satellites, sensory, surveillance,\nGPS and a multitude of other functionalities, form an integral part of global\nICT cyberinfrastructures. However, a focussed discourse highlighting the\ndistinctive threats landscape of these spaceborne assets is conspicuous by its\nabsence. This position paper specifically considers the interplay of Space and\nCyberspace to highlight security challenges that warrant dedicated attention in\nsecuring these complex infrastructures. The opinion piece additionally adds\nsummary opinions on (a) emerging technology trends and (b) advocacy on\ntechnological and policy issues needed to support security responsiveness and\nmitigation.",
    "descriptor": "",
    "authors": [
      "Vijay Varadharajan",
      "Neeraj Suri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10798"
  },
  {
    "id": "arXiv:2207.10800",
    "title": "Understanding High Dimensional Spaces through Visual Means Employing  Multidimensional Projections",
    "abstract": "Data visualisation helps understanding data represented by multiple\nvariables, also called features, stored in a large matrix where individuals are\nstored in lines and variable values in columns. These data structures are\nfrequently called multidimensional spaces.In this paper, we illustrate ways of\nemploying the visual results of multidimensional projection algorithms to\nunderstand and fine-tune the parameters of their mathematical framework. Some\nof the common mathematical common to these approaches are Laplacian matrices,\nEuclidian distance, Cosine distance, and statistical methods such as\nKullback-Leibler divergence, employed to fit probability distributions and\nreduce dimensions. Two of the relevant algorithms in the data visualisation\nfield are t-distributed stochastic neighbourhood embedding (t-SNE) and\nLeast-Square Projection (LSP). These algorithms can be used to understand\nseveral ranges of mathematical functions including their impact on datasets. In\nthis article, mathematical parameters of underlying techniques such as\nPrincipal Component Analysis (PCA) behind t-SNE and mesh reconstruction methods\nbehind LSP are adjusted to reflect the properties afforded by the mathematical\nformulation. The results, supported by illustrative methods of the processes of\nLSP and t-SNE, are meant to inspire students in understanding the mathematics\nbehind such methods, in order to apply them in effective data analysis tasks in\nmultiple applications.",
    "descriptor": "",
    "authors": [
      "Haseeb Younis",
      "Paul Trust",
      "Rosane Minghim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10800"
  },
  {
    "id": "arXiv:2207.10801",
    "title": "PhishSim: Aiding Phishing Website Detection with a Feature-Free Tool",
    "abstract": "In this paper, we propose a feature-free method for detecting phishing\nwebsites using the Normalized Compression Distance (NCD), a parameter-free\nsimilarity measure which computes the similarity of two websites by compressing\nthem, thus eliminating the need to perform any feature extraction. It also\nremoves any dependence on a specific set of website features. This method\nexamines the HTML of webpages and computes their similarity with known phishing\nwebsites, in order to classify them. We use the Furthest Point First algorithm\nto perform phishing prototype extractions, in order to select instances that\nare representative of a cluster of phishing webpages. We also introduce the use\nof an incremental learning algorithm as a framework for continuous and adaptive\ndetection without extracting new features when concept drift occurs. On a large\ndataset, our proposed method significantly outperforms previous methods in\ndetecting phishing websites, with an AUC score of 98.68%, a high true positive\nrate (TPR) of around 90%, while maintaining a low false positive rate (FPR) of\n0.58%. Our approach uses prototypes, eliminating the need to retain long term\ndata in the future, and is feasible to deploy in real systems with a processing\ntime of roughly 0.3 seconds.",
    "descriptor": "\nComments: 34 pages, 20 figures\n",
    "authors": [
      "Rizka Purwanto",
      "Arindam Pal",
      "Alan Blair",
      "Sanjay Jha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10801"
  },
  {
    "id": "arXiv:2207.10802",
    "title": "Active Data Pattern Extraction Attacks on Generative Language Models",
    "abstract": "With the wide availability of large pre-trained language model checkpoints,\nsuch as GPT-2 and BERT, the recent trend has been to fine-tune them on a\ndownstream task to achieve the state-of-the-art performance with a small\ncomputation overhead. One natural example is the Smart Reply application where\na pre-trained model is fine-tuned for suggesting a number of responses given a\nquery message. In this work, we set out to investigate potential information\nleakage vulnerabilities in a typical Smart Reply pipeline and show that it is\npossible for an adversary, having black-box or gray-box access to a Smart Reply\nmodel, to extract sensitive user information present in the training data. We\nfurther analyse the privacy impact of specific components, e.g. the decoding\nstrategy, pertained to this application through our attack settings. We explore\npotential mitigation strategies and demonstrate how differential privacy can be\na strong defense mechanism to such data extraction attacks.",
    "descriptor": "",
    "authors": [
      "Bargav Jayaraman",
      "Esha Ghosh",
      "Huseyin Inan",
      "Melissa Chase",
      "Sambuddha Roy",
      "Wei Dai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10802"
  },
  {
    "id": "arXiv:2207.10803",
    "title": "NFDLM: A Lightweight Network Flow based Deep Learning Model for DDoS  Attack Detection in IoT Domains",
    "abstract": "In the recent years, Distributed Denial of Service (DDoS) attacks on Internet\nof Things (IoT) devices have become one of the prime concerns to Internet users\naround the world. One of the sources of the attacks on IoT ecosystems are\nbotnets. Intruders force IoT devices to become unavailable for its legitimate\nusers by sending large number of messages within a short interval. This study\nproposes NFDLM, a lightweight and optimised Artificial Neural Network (ANN)\nbased Distributed Denial of Services (DDoS) attack detection framework with\nmutual correlation as feature selection method which produces a superior result\nwhen compared with Long Short Term Memory (LSTM) and simple ANN. Overall, the\ndetection performance achieves approximately 99\\% accuracy for the detection of\nattacks from botnets. In this work, we have designed and compared four\ndifferent models where two are based on ANN and the other two are based on LSTM\nto detect the attack types of DDoS.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Kumar Saurabh",
      "Tanuj Kumar",
      "Uphar Singh",
      "O.P. Vyas",
      "Rahamatullah Khondoker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10803"
  },
  {
    "id": "arXiv:2207.10804",
    "title": "Suppressing Poisoning Attacks on Federated Learning for Medical Imaging",
    "abstract": "Collaboration among multiple data-owning entities (e.g., hospitals) can\naccelerate the training process and yield better machine learning models due to\nthe availability and diversity of data. However, privacy concerns make it\nchallenging to exchange data while preserving confidentiality. Federated\nLearning (FL) is a promising solution that enables collaborative training\nthrough exchange of model parameters instead of raw data. However, most\nexisting FL solutions work under the assumption that participating clients are\n\\emph{honest} and thus can fail against poisoning attacks from malicious\nparties, whose goal is to deteriorate the global model performance. In this\nwork, we propose a robust aggregation rule called Distance-based Outlier\nSuppression (DOS) that is resilient to byzantine failures. The proposed method\ncomputes the distance between local parameter updates of different clients and\nobtains an outlier score for each client using Copula-based Outlier Detection\n(COPOD). The resulting outlier scores are converted into normalized weights\nusing a softmax function, and a weighted average of the local parameters is\nused for updating the global model. DOS aggregation can effectively suppress\nparameter updates from malicious clients without the need for any\nhyperparameter selection, even when the data distributions are heterogeneous.\nEvaluation on two medical imaging datasets (CheXpert and HAM10000) demonstrates\nthe higher robustness of DOS method against a variety of poisoning attacks in\ncomparison to other state-of-the-art methods. The code can be found here\nhttps://github.com/Naiftt/SPAFD.",
    "descriptor": "",
    "authors": [
      "Naif Alkhunaizi",
      "Dmitry Kamzolov",
      "Martin Tak\u00e1\u010d",
      "Karthik Nandakumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.10804"
  },
  {
    "id": "arXiv:2207.10805",
    "title": "PowerFDNet: Deep Learning-Based Stealthy False Data Injection Attack  Detection for AC-model Transmission Systems",
    "abstract": "Recent studies have demonstrated that smart grids are vulnerable to stealthy\nfalse data injection attacks (SFDIAs), as SFDIAs can bypass residual-based bad\ndata detection mechanisms. The SFDIA detection has become one of the focuses of\nsmart grid research. Methods based on deep learning technology have shown\npromising accuracy in the detection of SFDIAs. However, most existing methods\nrely on the temporal structure of a sequence of measurements but do not take\naccount of the spatial structure between buses and transmission lines. To\naddress this issue, we propose a spatiotemporal deep network, PowerFDNet, for\nthe SFDIA detection in AC-model power grids. The PowerFDNet consists of two\nsub-architectures: spatial architecture (SA) and temporal architecture (TA).\nThe SA is aimed at extracting representations of bus/line measurements and\nmodeling the spatial structure based on their representations. The TA is aimed\nat modeling the temporal structure of a sequence of measurements. Therefore,\nthe proposed PowerFDNet can effectively model the spatiotemporal structure of\nmeasurements. Case studies on the detection of SFDIAs on the benchmark smart\ngrids show that the PowerFDNet achieved significant improvement compared with\nthe state-of-the-art SFDIA detection methods. In addition, an IoT-oriented\nlightweight prototype of size 52 MB is implemented and tested for mobile\ndevices, which demonstrates the potential applications on mobile devices. The\ntrained model will be available at\n\\textit{https://github.com/FrankYinXF/PowerFDNet}.",
    "descriptor": "",
    "authors": [
      "Xuefei Yin",
      "Yanming Zhu",
      "Yi Xie",
      "Jiankun Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10805"
  },
  {
    "id": "arXiv:2207.10806",
    "title": "WordSig: QR streams enabling platform-independent self-identification  that's impossible to deepfake",
    "abstract": "Deepfakes can degrade the fabric of society by limiting our ability to trust\nvideo content from leaders, authorities, and even friends. Cryptographically\nsecure digital signatures may be used by video streaming platforms to endorse\ncontent, but these signatures are applied by the content distributor rather\nthan the participants in the video. We introduce WordSig, a simple protocol\nallowing video participants to digitally sign the words they speak using a\nstream of QR codes, and allowing viewers to verify the consistency of\nsignatures across videos. This allows establishing a trusted connection between\nthe viewer and the participant that is not mediated by the content distributor.\nGiven the widespread adoption of QR codes for distributing hyperlinks and\nvaccination records, and the increasing prevalence of celebrity deepfakes, 2022\nor later may be a good time for public figures to begin using and promoting\nQR-based self-authentication tools.",
    "descriptor": "",
    "authors": [
      "Andrew Critch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.10806"
  },
  {
    "id": "arXiv:2207.10807",
    "title": "A Machine Learning Approach for Driver Identification Based on CAN-BUS  Sensor Data",
    "abstract": "Driver identification is a momentous field of modern decorated vehicles in\nthe controller area network (CAN-BUS) perspective. Many conventional systems\nare used to identify the driver. One step ahead, most of the researchers use\nsensor data of CAN-BUS but there are some difficulties because of the variation\nof the protocol of different models of vehicle. Our aim is to identify the\ndriver through supervised learning algorithms based on driving behavior\nanalysis. To determine the driver, a driver verification technique is proposed\nthat evaluate driving pattern using the measurement of CAN sensor data. In this\npaper on-board diagnostic (OBD-II) is used to capture the data from the CAN-BUS\nsensor and the sensors are listed under SAE J1979 statement. According to the\nservice of OBD-II, drive identification is possible. However, we have gained\ntwo types of accuracy on a complete data set with 10 drivers and a partial data\nset with two drivers. The accuracy is good with less number of drivers compared\nto the higher number of drivers. We have achieved statistically significant\nresults in terms of accuracy in contrast to the baseline algorithm",
    "descriptor": "",
    "authors": [
      "Md. Abbas Ali Khan",
      "Mphammad Hanif Ali",
      "AKM Fazlul Haque",
      "Md. Tarek Habib"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10807"
  },
  {
    "id": "arXiv:2207.10809",
    "title": "Security and Safety Aspects of AI in Industry Applications",
    "abstract": "In this relatively informal discussion-paper we summarise issues in the\ndomains of safety and security in machine learning that will affect industry\nsectors in the next five to ten years. Various products using neural network\nclassification, most often in vision related applications but also in\npredictive maintenance, have been researched and applied in real-world\napplications in recent years. Nevertheless, reports of underlying problems in\nboth safety and security related domains, for instance adversarial attacks have\nunsettled early adopters and are threatening to hinder wider scale adoption of\nthis technology. The problem for real-world applicability lies in being able to\nassess the risk of applying these technologies. In this discussion-paper we\ndescribe the process of arriving at a machine-learnt neural network classifier\npointing out safety and security vulnerabilities in that workflow, citing\nrelevant research where appropriate.",
    "descriptor": "\nComments: As presented at the Embedded World Conference, Nuremberg, 2022\n",
    "authors": [
      "Hans Dermot Doran"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10809"
  },
  {
    "id": "arXiv:2207.10810",
    "title": "A Convolutional Attention Based Deep Network Solution for UAV Network  Attack Recognition over Fading Channels and Interference",
    "abstract": "When users exchange data with Unmanned Aerial vehicles - (UAVs) over\nair-to-ground (A2G) wireless communication networks, they expose the link to\nattacks that could increase packet loss and might disrupt connectivity. For\nexample, in emergency deliveries, losing control information (i.e data related\nto the UAV control communication) might result in accidents that cause UAV\ndestruction and damage to buildings or other elements in a city. To prevent\nthese problems, these issues must be addressed in 5G and 6G scenarios. This\nresearch offers a deep learning (DL) approach for detecting attacks in UAVs\nequipped with orthogonal frequency division multiplexing (OFDM) receivers on\nClustered Delay Line (CDL) channels in highly complex scenarios involving\nauthenticated terrestrial users, as well as attackers in unknown locations. We\nuse the two observable parameters available in 5G UAV connections: the Received\nSignal Strength Indicator (RSSI) and the Signal to Interference plus Noise\nRatio (SINR). The prospective algorithm is generalizable regarding attack\nidentification, which does not occur during training. Further, it can identify\nall the attackers in the environment with 20 terrestrial users. A deeper\ninvestigation into the timing requirements for recognizing attacks show that\nafter training, the minimum time necessary after the attack begins is 100 ms,\nand the minimum attack power is 2 dBm, which is the same power that the\nauthenticated UAV uses. Our algorithm also detects moving attackers from a\ndistance of 500 m.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Joseanne Viana",
      "Hamed Farkhari",
      "Luis Miguel Campos",
      "Pedro Sebastiao",
      "Katerina Koutlia",
      "Sandra Lagen",
      "Luis Bernardo",
      "Rui Dinis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.10810"
  },
  {
    "id": "arXiv:2207.10811",
    "title": "Smart speaker design and implementation with biometric authentication  and advanced voice interaction capability",
    "abstract": "Advancements in semiconductor technology have reduced dimensions and cost\nwhile improving the performance and capacity of chipsets. In addition,\nadvancement in the AI frameworks and libraries brings possibilities to\naccommodate more AI at the resource-constrained edge of consumer IoT devices.\nSensors are nowadays an integral part of our environment which provide\ncontinuous data streams to build intelligent applications. An example could be\na smart home scenario with multiple interconnected devices. In such smart\nenvironments, for convenience and quick access to web-based service and\npersonal information such as calendars, notes, emails, reminders, banking, etc,\nusers link third-party skills or skills from the Amazon store to their smart\nspeakers. Also, in current smart home scenarios, several smart home products\nsuch as smart security cameras, video doorbells, smart plugs, smart carbon\nmonoxide monitors, and smart door locks, etc. are interlinked to a modern smart\nspeaker via means of custom skill addition. Since smart speakers are linked to\nsuch services and devices via the smart speaker user's account. They can be\nused by anyone with physical access to the smart speaker via voice commands. If\ndone so, the data privacy, home security and other aspects of the user get\ncompromised. Recently launched, Tensor Cam's AI Camera, Toshiba's Symbio,\nFacebook's Portal are camera-enabled smart speakers with AI functionalities.\nAlthough they are camera-enabled, yet they do not have an authentication scheme\nin addition to calling out the wake-word. This paper provides an overview of\ncybersecurity risks faced by smart speaker users due to lack of authentication\nscheme and discusses the development of a state-of-the-art camera-enabled,\nmicrophone array-based modern Alexa smart speaker prototype to address these\nrisks.",
    "descriptor": "",
    "authors": [
      "Bharath Sudharsan",
      "Peter Corcoran",
      "Muhammad Intizar Ali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10811"
  },
  {
    "id": "arXiv:2207.10812",
    "title": "RSU-Based Online Intrusion Detection and Mitigation for VANET",
    "abstract": "Secure vehicular communication is a critical factor for secure traffic\nmanagement. Effective security in intelligent transportation systems (ITS)\nrequires effective and timely intrusion detection systems (IDS). In this paper,\nwe consider false data injection attacks and distributed denial-of-service\n(DDoS) attacks, especially the stealthy DDoS attacks, targeting the integrity\nand availability, respectively, in vehicular ad-hoc networks (VANET). Novel\nstatistical intrusion detection and mitigation techniques based on centralized\ncommunications through roadside units (RSU) are proposed for the considered\nattacks. The performance of the proposed methods are evaluated using a traffic\nsimulator and a real traffic dataset. Comparisons with the state-of-the-art\nsolutions clearly demonstrate the superior performance of the proposed methods\nin terms of quick and accurate detection and localization of cyberattacks.",
    "descriptor": "",
    "authors": [
      "Ammar Haydari",
      "Yasin Yilmaz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10812"
  },
  {
    "id": "arXiv:2207.10814",
    "title": "Supervised Contrastive ResNet and Transfer Learning for the In-vehicle  Intrusion Detection System",
    "abstract": "High-end vehicles have been furnished with a number of electronic control\nunits (ECUs), which provide upgrading functions to enhance the driving\nexperience. The controller area network (CAN) is a well-known protocol that\nconnects these ECUs because of its modesty and efficiency. However, the CAN bus\nis vulnerable to various types of attacks. Although the intrusion detection\nsystem (IDS) is proposed to address the security problem of the CAN bus, most\nprevious studies only provide alerts when attacks occur without knowing the\nspecific type of attack. Moreover, an IDS is designed for a specific car model\ndue to diverse car manufacturers. In this study, we proposed a novel deep\nlearning model called supervised contrastive (SupCon) ResNet, which can handle\nmultiple attack identification on the CAN bus. Furthermore, the model can be\nused to improve the performance of a limited-size dataset using a transfer\nlearning technique. The capability of the proposed model is evaluated on two\nreal car datasets. When tested with the car hacking dataset, the experiment\nresults show that the SupCon ResNet model improves the overall false-negative\nrates of four types of attack by four times on average, compared to other\nmodels. In addition, the model achieves the highest F1 score at 0.9994 on the\nsurvival dataset by utilizing transfer learning. Finally, the model can adapt\nto hardware constraints in terms of memory size and running time.",
    "descriptor": "",
    "authors": [
      "Thien-Nu Hoang",
      "Daehee Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10814"
  },
  {
    "id": "arXiv:2207.10816",
    "title": "Mathematical Model of Strong Physically Unclonable Functions Based on  Hybrid Boolean Networks",
    "abstract": "We introduce a mathematical framework for simulating Hybrid Boolean Network\n(HBN) Physically Unclonable Functions (PUFs, HBN-PUFs). We verify that the\nmodel is able to reproduce the experimentally observed PUF statistics for\nuniqueness $\\mu_{inter}$ and reliability $\\mu_{intra}$ obtained from\nexperiments of HBN-PUFs on Cyclone V FPGAs. Our results suggest that the\nHBN-PUF is a true `strong' PUF in the sense that its security properties depend\nexponentially on both the manufacturing variation and the challenge-response\nspace. Our Python simulation methods are open-source and available at\nhttps://github.com/Noeloikeau/networkm.",
    "descriptor": "\nComments: Presented at HOST 2022 conference. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Noeloikeau Charlot",
      "Daniel J. Gauthier",
      "Daniel Canaday",
      "Andrew Pomerance"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10816"
  },
  {
    "id": "arXiv:2207.10817",
    "title": "End-to-End and Self-Supervised Learning for ComParE 2022 Stuttering  Sub-Challenge",
    "abstract": "In this paper, we present end-to-end and speech embedding based systems\ntrained in a self-supervised fashion to participate in the ACM Multimedia 2022\nComParE Challenge, specifically the stuttering sub-challenge. In particular, we\nexploit the embeddings from the pre-trained Wav2Vec2.0 model for stuttering\ndetection (SD) on the KSoF dataset. After embedding extraction, we benchmark\nwith several methods for SD. Our proposed self-supervised based SD system\nachieves a UAR of 36.9% and 41.0% on validation and test sets respectively,\nwhich is 31.32% (validation set) and 1.49% (test set) higher than the best\n(DeepSpectrum) challenge baseline (CBL). Moreover, we show that concatenating\nlayer embeddings with Mel-frequency cepstral coefficients (MFCCs) features\nfurther improves the UAR of 33.81% and 5.45% on validation and test sets\nrespectively over the CBL. Finally, we demonstrate that the summing information\nacross all the layers of Wav2Vec2.0 surpasses the CBL by a relative margin of\n45.91% and 5.69% on validation and test sets respectively. Grand-challenge:\nComputational Paralinguistics ChallengE",
    "descriptor": "\nComments: Accepted in ACM MM 2022 Conference : Grand Challenges, \"\\c{opyright} {Owner/Author | ACM} {2022}. This is the author's version of the work. It is posted here for your personal use. Not for redistribution\n",
    "authors": [
      "Shakeel Ahmad Sheikh",
      "Md Sahidullah",
      "Fabrice Hirsch",
      "Slim Ouni"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10817"
  },
  {
    "id": "arXiv:2207.10819",
    "title": "A Non-intrusive Approach for Physics-constrained Learning with  Application to Fuel Cell Modeling",
    "abstract": "A data-driven model augmentation framework, referred to as Weakly-coupled\nIntegrated Inference and Machine Learning (IIML), is presented to improve the\npredictive accuracy of physical models. In contrast to parameter calibration,\nthis work seeks corrections to the structure of the model by a) inferring\naugmentation fields that are consistent with the underlying model, and b)\ntransforming these fields into corrective model forms. The proposed approach\ncouples the inference and learning steps in a weak sense via an alternating\noptimization approach. This coupling ensures that the augmentation fields\nremain learnable and maintain consistent functional relationships with local\nmodeled quantities across the training dataset. An iterative solution procedure\nis presented in this paper, removing the need to embed the augmentation\nfunction during the inference process. This framework is used to infer an\naugmentation introduced within a Polymer electrolyte membrane fuel cell (PEMFC)\nmodel using a small amount of training data (from only 14 training cases.)\nThese training cases belong to a dataset consisting of high-fidelity simulation\ndata obtained from a high-fidelity model of a first generation Toyota Mirai.\nAll cases in this dataset are characterized by different inflow and outflow\nconditions on the same geometry. When tested on 1224 different configurations,\nthe inferred augmentation significantly improves the predictive accuracy for a\nwide range of physical conditions. Predictions and available data for the\ncurrent density distribution are also compared to demonstrate the predictive\ncapability of the model for quantities of interest which were not involved in\nthe inference process. The results demonstrate that the weakly-coupled IIML\nframework offers sophisticated and robust model augmentation capabilities\nwithout requiring extensive changes to the numerical solver.",
    "descriptor": "",
    "authors": [
      "Vishal Srivastava",
      "Valentin Sulzer",
      "Peyman Mohtat",
      "Jason B. Siegel",
      "Karthik Duraisamy"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2207.10819"
  },
  {
    "id": "arXiv:2207.10821",
    "title": "Rethinking Sim2Real: Lower Fidelity Simulation Leads to Higher Sim2Real  Transfer in Navigation",
    "abstract": "If we want to train robots in simulation before deploying them in reality, it\nseems natural and almost self-evident to presume that reducing the sim2real gap\ninvolves creating simulators of increasing fidelity (since reality is what it\nis). We challenge this assumption and present a contrary hypothesis -- sim2real\ntransfer of robots may be improved with lower (not higher) fidelity simulation.\nWe conduct a systematic large-scale evaluation of this hypothesis on the\nproblem of visual navigation -- in the real world, and on 2 different\nsimulators (Habitat and iGibson) using 3 different robots (A1, AlienGo, Spot).\nOur results show that, contrary to expectation, adding fidelity does not help\nwith learning; performance is poor due to slow simulation speed (preventing\nlarge-scale learning) and overfitting to inaccuracies in simulation physics.\nInstead, building simple models of the robot motion using real-world data can\nimprove learning and generalization.",
    "descriptor": "",
    "authors": [
      "Joanne Truong",
      "Max Rudolph",
      "Naoki Yokoyama",
      "Sonia Chernova",
      "Dhruv Batra",
      "Akshara Rai"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10821"
  },
  {
    "id": "arXiv:2207.10823",
    "title": "A Sealed-bid Auction with Fund Binding: Preventing Maximum Bidding Price  Leakage",
    "abstract": "In an open-bid auction, a bidder can know the budgets of other bidders. Thus,\na sealed-bid auction that hides bidding prices is desirable. However, in\nprevious sealed-bid auction protocols, it has been difficult to provide a\n``fund binding'' property, which would guarantee that a bidder has funds more\nthan or equal to the bidding price and that the funds are forcibly withdrawn\nwhen the bidder wins. Thus, such protocols are vulnerable to false bidding. As\na solution, many protocols employ a simple deposit method in which each bidder\nsends a deposit to a smart contract, which is greater than or equal to the\nbidding price, before the bidding phase. However, this deposit reveals the\nmaximum bidding price, and it is preferable to hide this information.\nIn this paper, we propose a sealed-bid auction protocol that provides a fund\nbinding property. Our protocol not only hides the bidding price and a maximum\nbidding price, but also provides fund binding, simultaneously. For hiding the\nmaximum bidding price, we pay attention to the fact that usual Ethereum\ntransactions and transactions for sending funds to a one-time address have the\nsame transaction structure, and it seems that they are indistinguishable. We\ndiscuss how much bidding transactions are hidden. We also employ DECO (Zhang et\nal,. CCS 2020) that proves the validity of the data to a verifier in which the\ndata are taken from a source without showing the data itself. Finally, we give\nour implementation which shows transaction fees required and compare it to a\nsealed-bid auction protocol employing the simple deposit method.",
    "descriptor": "",
    "authors": [
      "Kota Chin",
      "Keita Emura",
      "Kazumasa Omote",
      "Shingo Sato"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.10823"
  },
  {
    "id": "arXiv:2207.10825",
    "title": "Just Rotate it: Deploying Backdoor Attacks via Rotation Transformation",
    "abstract": "Recent works have demonstrated that deep learning models are vulnerable to\nbackdoor poisoning attacks, where these attacks instill spurious correlations\nto external trigger patterns or objects (e.g., stickers, sunglasses, etc.). We\nfind that such external trigger signals are unnecessary, as highly effective\nbackdoors can be easily inserted using rotation-based image transformation. Our\nmethod constructs the poisoned dataset by rotating a limited amount of objects\nand labeling them incorrectly; once trained with it, the victim's model will\nmake undesirable predictions during run-time inference. It exhibits a\nsignificantly high attack success rate while maintaining clean performance\nthrough comprehensive empirical studies on image classification and object\ndetection tasks. Furthermore, we evaluate standard data augmentation techniques\nand four different backdoor defenses against our attack and find that none of\nthem can serve as a consistent mitigation approach. Our attack can be easily\ndeployed in the real world since it only requires rotating the object, as we\nshow in both image classification and object detection applications. Overall,\nour work highlights a new, simple, physically realizable, and highly effective\nvector for backdoor attacks. Our video demo is available at\nhttps://youtu.be/6JIF8wnX34M.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Tong Wu",
      "Tianhao Wang",
      "Vikash Sehwag",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10825"
  },
  {
    "id": "arXiv:2207.10827",
    "title": "Learn and Control while Switching: with Guaranteed Stability and  Sublinear Regret",
    "abstract": "Over-actuated systems often make it possible to achieve specific performances\nby switching between different subsets of actuators. However, when the system\nparameters are unknown, transferring authority to different subsets of\nactuators is challenging due to stability and performance efficiency concerns.\nThis paper presents an efficient algorithm to tackle the so-called \"learn and\ncontrol while switching between different actuating modes\" problem in the\nLinear Quadratic (LQ) setting. Our proposed strategy is constructed upon\nOptimism in the Face of Uncertainty (OFU) based algorithm equipped with a\nprojection toolbox to keep the algorithm efficient, regret-wise. Along the way,\nwe derive an optimum duration for the warm-up phase, thanks to the existence of\na stabilizing neighborhood. The stability of the switched system is also\nguaranteed by designing a minimum average dwell time. The proposed strategy is\nproved to have a regret bound of\n$\\mathcal{\\bar{O}}\\big(\\sqrt{T}\\big)+\\mathcal{O}\\big(ns\\sqrt{T}\\big)$ in\nhorizon $T$ with $(ns)$ number of switches, provably outperforming naively\napplying the basic OFU algorithm.",
    "descriptor": "",
    "authors": [
      "Jafar Abbaszadeh Chekan",
      "C\u00e9dric Langbort"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10827"
  },
  {
    "id": "arXiv:2207.10828",
    "title": "Tell Me How You Feel: Designing Emotion-Aware Voicebots to Ease Pandemic  Anxiety In Aging Citizens",
    "abstract": "The feeling of anxiety and loneliness among aging population has been\nrecently amplified by the COVID-19 related lockdowns. Emotion-aware multimodal\nbot application combining voice and visual interface was developed to address\nthe problem in the group of older citizens. The application is novel as it\ncombines three main modules: information, emotion selection and psychological\nintervention, with the aim of improving human well-being. The preliminary study\nwith target group confirmed that multimodality improves usability and that the\ninformation module is essential for participating in a psychological\nintervention. The solution is universal and can also be applied to areas not\ndirectly related to COVID-19 pandemic.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "W. Mieleszczenko-Kowszewicz",
      "K. Warpechowski",
      "K. Zieli\u0144ski",
      "R. Nielek",
      "A. Wierzbicki"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.10828"
  },
  {
    "id": "arXiv:2207.10830",
    "title": "Automated Dilated Spatio-Temporal Synchronous Graph Modeling for Traffic  Prediction",
    "abstract": "Accurate traffic prediction is a challenging task in intelligent\ntransportation systems because of the complex spatio-temporal dependencies in\ntransportation networks. Many existing works utilize sophisticated temporal\nmodeling approaches to incorporate with graph convolution networks (GCNs) for\ncapturing short-term and long-term spatio-temporal dependencies. However, these\nseparated modules with complicated designs could restrict effectiveness and\nefficiency of spatio-temporal representation learning. Furthermore, most\nprevious works adopt the fixed graph construction methods to characterize the\nglobal spatio-temporal relations, which limits the learning capability of the\nmodel for different time periods and even different data scenarios. To overcome\nthese limitations, we propose an automated dilated spatio-temporal synchronous\ngraph network, named Auto-DSTSGN for traffic prediction. Specifically, we\ndesign an automated dilated spatio-temporal synchronous graph (Auto-DSTSG)\nmodule to capture the short-term and long-term spatio-temporal correlations by\nstacking deeper layers with dilation factors in an increasing order. Further,\nwe propose a graph structure search approach to automatically construct the\nspatio-temporal synchronous graph that can adapt to different data scenarios.\nExtensive experiments on four real-world datasets demonstrate that our model\ncan achieve about 10% improvements compared with the state-of-art methods.\nSource codes are available at https://github.com/jinguangyin/Auto-DSTSGN.",
    "descriptor": "",
    "authors": [
      "Guangyin Jin",
      "Fuxian Li",
      "Jinlei Zhang",
      "Mudan Wang",
      "Jincai Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10830"
  },
  {
    "id": "arXiv:2207.10833",
    "title": "Few-shot Image Generation Using Discrete Content Representation",
    "abstract": "Few-shot image generation and few-shot image translation are two related\ntasks, both of which aim to generate new images for an unseen category with\nonly a few images. In this work, we make the first attempt to adapt few-shot\nimage translation method to few-shot image generation task. Few-shot image\ntranslation disentangles an image into style vector and content map. An unseen\nstyle vector can be combined with different seen content maps to produce\ndifferent images. However, it needs to store seen images to provide content\nmaps and the unseen style vector may be incompatible with seen content maps. To\nadapt it to few-shot image generation task, we learn a compact dictionary of\nlocal content vectors via quantizing continuous content maps into discrete\ncontent maps instead of storing seen images. Furthermore, we model the\nautoregressive distribution of discrete content map conditioned on style\nvector, which can alleviate the incompatibility between content map and style\nvector. Qualitative and quantitative results on three real datasets demonstrate\nthat our model can produce images of higher diversity and fidelity for unseen\ncategories than previous methods.",
    "descriptor": "\nComments: This paper is accepted by ACM MM 2022\n",
    "authors": [
      "Yan Hong",
      "Li Niu",
      "Jianfu Zhang",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10833"
  },
  {
    "id": "arXiv:2207.10835",
    "title": "Characterizing Coherent Integrated Photonic Neural Networks under  Imperfections",
    "abstract": "Integrated photonic neural networks (IPNNs) are emerging as promising\nsuccessors to conventional electronic AI accelerators as they offer substantial\nimprovements in computing speed and energy efficiency. In particular, coherent\nIPNNs use arrays of Mach-Zehnder interferometers (MZIs) for unitary\ntransformations to perform energy-efficient matrix-vector multiplication.\nHowever, the underlying MZI devices in IPNNs are susceptible to uncertainties\nstemming from optical lithographic variations and thermal crosstalk and can\nexperience imprecisions due to non-uniform MZI insertion loss and quantization\nerrors due to low-precision encoding in the tuned phase angles. In this paper,\nwe, for the first time, systematically characterize the impact of such\nuncertainties and imprecisions (together referred to as imperfections) in IPNNs\nusing a bottom-up approach. We show that their impact on IPNN accuracy can vary\nwidely based on the tuned parameters (e.g., phase angles) of the affected\ncomponents, their physical location, and the nature and distribution of the\nimperfections. To improve reliability measures, we identify critical IPNN\nbuilding blocks that, under imperfections, can lead to catastrophic degradation\nin the classification accuracy. We show that under multiple simultaneous\nimperfections, the IPNN inferencing accuracy can degrade by up to 46%, even\nwhen the imperfection parameters are restricted within a small range. Our\nresults also indicate that the inferencing accuracy is sensitive to\nimperfections affecting the MZIs in the linear layers next to the input layer\nof the IPNN.",
    "descriptor": "\nComments: This paper has been accepted for publication in the IEEE Journal of Lightwave Technology (JLT)\n",
    "authors": [
      "Sanmitra Banerjee",
      "Mahdi Nikdast",
      "Krishnendu Chakrabarty"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10835"
  },
  {
    "id": "arXiv:2207.10836",
    "title": "Soft-input, soft-output joint detection and GRAND",
    "abstract": "Guessing random additive noise decoding (GRAND) is a maximum likelihood (ML)\ndecoding method that identifies the noise effects corrupting code-words of\narbitrary code-books. In a joint detection and decoding framework, this work\ndemonstrates how GRAND can leverage crude soft information in received symbols\nand channel state information to generate, through guesswork, soft bit\nreliability outputs in log-likelihood ratios (LLRs). The LLRs are generated via\nsuccessive computations of Euclidean-distance metrics corresponding to\ncandidate noise-recovered words. Noting that the entropy of noise is much\nsmaller than that of information bits, a small number of noise effect guesses\ngenerally suffices to hit a code-word, which allows generating LLRs for\ncritical bits; LLR saturation is applied to the remaining bits. In an iterative\n(turbo) mode, the generated LLRs at a given soft-input, soft-output GRAND\niteration serve as enhanced a priori information that adapts noise-sequence\nguess ordering in a subsequent iteration. Simulations demonstrate that a few\nturbo-GRAND iterations match the performance of ML-detection-based soft-GRAND\nin both AWGN and Rayleigh fading channels at a complexity cost that, on\naverage, grows linearly (instead of exponentially) with the number of symbols.",
    "descriptor": "",
    "authors": [
      "Hadi Sarieddeen",
      "Muriel M\u00e9dard",
      "Ken. R. Duffy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.10836"
  },
  {
    "id": "arXiv:2207.10838",
    "title": "Quantum-inspired variational algorithms for partial differential  equations: Application to financial derivative pricing",
    "abstract": "Variational quantum Monte Carlo (VMC) combined with neural-network quantum\nstates offers a novel angle of attack on the curse-of-dimensionality\nencountered in a particular class of partial differential equations (PDEs);\nnamely, the real- and imaginary time-dependent Schr\\\"odinger equation. In this\npaper, we present a simple generalization of VMC applicable to arbitrary\ntime-dependent PDEs, showcasing the technique in the multi-asset Black-Scholes\nPDE for pricing European options contingent on many correlated underlying\nassets.",
    "descriptor": "",
    "authors": [
      "Tianchen Zhao",
      "Chuhao Sun",
      "Asaf Cohen",
      "James Stokes",
      "Shravan Veerapaneni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10838"
  },
  {
    "id": "arXiv:2207.10839",
    "title": "Robust Knowledge Adaptation for Dynamic Graph Neural Networks",
    "abstract": "Graph structured data often possess dynamic characters in nature, e.g., the\naddition of links and nodes, in many real-world applications. Recent years have\nwitnessed the increasing attentions paid to dynamic graph neural networks for\nmodelling such graph data, where almost all the existing approaches assume that\nwhen a new link is built, the embeddings of the neighbor nodes should be\nupdated by learning the temporal dynamics to propagate new information.\nHowever, such approaches suffer from the limitation that if the node introduced\nby a new connection contains noisy information, propagating its knowledge to\nother nodes is not reliable and even leads to the collapse of the model. In\nthis paper, we propose AdaNet: a robust knowledge Adaptation framework via\nreinforcement learning for dynamic graph neural Networks. In contrast to\nprevious approaches immediately updating the embeddings of the neighbor nodes\nonce adding a new link, AdaNet attempts to adaptively determine which nodes\nshould be updated because of the new link involved. Considering that the\ndecision whether to update the embedding of one neighbor node will have great\nimpact on other neighbor nodes, we thus formulate the selection of node update\nas a sequence decision problem, and address this problem via reinforcement\nlearning. By this means, we can adaptively propagate knowledge to other nodes\nfor learning robust node embedding representations. To the best of our\nknowledge, our approach constitutes the first attempt to explore robust\nknowledge adaptation via reinforcement learning for dynamic graph neural\nnetworks. Extensive experiments on three benchmark datasets demonstrate that\nAdaNet achieves the state-of-the-art performance. In addition, we perform the\nexperiments by adding different degrees of noise into the dataset,\nquantitatively and qualitatively illustrating the robustness of AdaNet.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Hanjie Li",
      "Changsheng Li",
      "Kaituo Feng",
      "Ye Yuan",
      "Guoren Wang",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10839"
  },
  {
    "id": "arXiv:2207.10840",
    "title": "Robust and Safe Autonomous Navigation for Systems with Learned SE(3)  Hamiltonian Dynamics",
    "abstract": "Stability and safety are critical properties for successful deployment of\nautomatic control systems. As a motivating example, consider autonomous mobile\nrobot navigation in a complex environment. A control design that generalizes to\ndifferent operational conditions requires a model of the system dynamics,\nrobustness to modeling errors, and satisfaction of safety \\NEWZL{constraints},\nsuch as collision avoidance. This paper develops a neural ordinary differential\nequation network to learn the dynamics of a Hamiltonian system from trajectory\ndata. The learned Hamiltonian model is used to synthesize an energy-shaping\npassivity-based controller and analyze its \\emph{robustness} to uncertainty in\nthe learned model and its \\emph{safety} with respect to constraints imposed by\nthe environment. Given a desired reference path for the system, we extend our\ndesign using a virtual reference governor to achieve tracking control. The\ngovernor state serves as a regulation point that moves along the reference path\nadaptively, balancing the system energy level, model uncertainty bounds, and\ndistance to safety violation to guarantee robustness and safety. Our\nHamiltonian dynamics learning and tracking control techniques are demonstrated\non \\Revised{simulated hexarotor and quadrotor robots} navigating in cluttered\n3D environments.",
    "descriptor": "",
    "authors": [
      "Zhichao Li",
      "Thai Duong",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10840"
  },
  {
    "id": "arXiv:2207.10842",
    "title": "GRAND for Fading Channels using Pseudo-soft Information",
    "abstract": "Guessing random additive noise decoding (GRAND) is a universal\nmaximum-likelihood decoder that recovers code-words by guessing rank-ordered\nputative noise sequences and inverting their effect until one or more valid\ncode-words are obtained. This work explores how GRAND can leverage\nadditive-noise statistics and channel-state information in fading channels.\nInstead of computing per-bit reliability information in detectors and passing\nthis information to the decoder, we propose leveraging the colored noise\nstatistics following channel equalization as pseudo-soft information for\nsorting noise sequences. We investigate the efficacy of pseudo-soft information\nextracted from linear zero-forcing and minimum mean square error equalization\nwhen fed to a hardware-friendly soft-GRAND (ORBGRAND). We demonstrate that the\nproposed pseudo-soft GRAND schemes approximate the performance of\nstate-of-the-art decoders of CA-Polar and BCH codes that avail of complete soft\ninformation. Compared to hard-GRAND, pseudo-soft ORBGRAND introduces up to 10dB\nSNR gains for a target 10^-3 block-error rate.",
    "descriptor": "",
    "authors": [
      "Hadi Sarieddeen",
      "Muriel M\u00e9dard",
      "Ken. R. Duffy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.10842"
  },
  {
    "id": "arXiv:2207.10849",
    "title": "ASR Error Detection via Audio-Transcript entailment",
    "abstract": "Despite improved performances of the latest Automatic Speech Recognition\n(ASR) systems, transcription errors are still unavoidable. These errors can\nhave a considerable impact in critical domains such as healthcare, when used to\nhelp with clinical documentation. Therefore, detecting ASR errors is a critical\nfirst step in preventing further error propagation to downstream applications.\nTo this end, we propose a novel end-to-end approach for ASR error detection\nusing audio-transcript entailment. To the best of our knowledge, we are the\nfirst to frame this problem as an end-to-end entailment task between the audio\nsegment and its corresponding transcript segment. Our intuition is that there\nshould be a bidirectional entailment between audio and transcript when there is\nno recognition error and vice versa. The proposed model utilizes an acoustic\nencoder and a linguistic encoder to model the speech and transcript\nrespectively. The encoded representations of both modalities are fused to\npredict the entailment. Since doctor-patient conversations are used in our\nexperiments, a particular emphasis is placed on medical terms. Our proposed\nmodel achieves classification error rates (CER) of 26.2% on all transcription\nerrors and 23% on medical errors specifically, leading to improvements upon a\nstrong baseline by 12% and 15.4%, respectively.",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Nimshi Venkat Meripo",
      "Sandeep Konam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.10849"
  },
  {
    "id": "arXiv:2207.10851",
    "title": "Uncertainty-aware Multi-modal Learning via Cross-modal Random Network  Prediction",
    "abstract": "Multi-modal learning focuses on training models by equally combining multiple\ninput data modalities during the prediction process. However, this equal\ncombination can be detrimental to the prediction accuracy because different\nmodalities are usually accompanied by varying levels of uncertainty. Using such\nuncertainty to combine modalities has been studied by a couple of approaches,\nbut with limited success because these approaches are either designed to deal\nwith specific classification or segmentation problems and cannot be easily\ntranslated into other tasks, or suffer from numerical instabilities. In this\npaper, we propose a new Uncertainty-aware Multi-modal Learner that estimates\nuncertainty by measuring feature density via Cross-modal Random Network\nPrediction (CRNP). CRNP is designed to require little adaptation to translate\nbetween different prediction tasks, while having a stable training process.\nFrom a technical point of view, CRNP is the first approach to explore random\nnetwork prediction to estimate uncertainty and to combine multi-modal data.\nExperiments on two 3D multi-modal medical image segmentation tasks and three 2D\nmulti-modal computer vision classification tasks show the effectiveness,\nadaptability and robustness of CRNP. Also, we provide an extensive discussion\non different fusion functions and visualization to validate the proposed model.",
    "descriptor": "",
    "authors": [
      "Hu Wang",
      "Jianpeng Zhang",
      "Yuanhong Chen",
      "Congbo Ma",
      "Jodie Avery",
      "Louise Hull",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10851"
  },
  {
    "id": "arXiv:2207.10852",
    "title": "Spatio-Temporal Deformable Attention Network for Video Deblurring",
    "abstract": "The key success factor of the video deblurring methods is to compensate for\nthe blurry pixels of the mid-frame with the sharp pixels of the adjacent video\nframes. Therefore, mainstream methods align the adjacent frames based on the\nestimated optical flows and fuse the alignment frames for restoration. However,\nthese methods sometimes generate unsatisfactory results because they rarely\nconsider the blur levels of pixels, which may introduce blurry pixels from\nvideo frames. Actually, not all the pixels in the video frames are sharp and\nbeneficial for deblurring. To address this problem, we propose the\nspatio-temporal deformable attention network (STDANet) for video delurring,\nwhich extracts the information of sharp pixels by considering the pixel-wise\nblur levels of the video frames. Specifically, STDANet is an encoder-decoder\nnetwork combined with the motion estimator and spatio-temporal deformable\nattention (STDA) module, where motion estimator predicts coarse optical flows\nthat are used as base offsets to find the corresponding sharp pixels in STDA\nmodule. Experimental results indicate that the proposed STDANet performs\nfavorably against state-of-the-art methods on the GoPro, DVD, and BSD datasets.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Huicong Zhang",
      "Haozhe Xie",
      "Hongxun Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10852"
  },
  {
    "id": "arXiv:2207.10853",
    "title": "Error Estimate of Multiscale Finite Element Method for Periodic Media  Revisited",
    "abstract": "We derive the optimal energy error estimate for multiscale finite element\nmethod with oversampling technique applying to elliptic system with rapidly\noscillating periodic coefficients under the assumption that the coefficients\nare bounded and measurable, which may admit rough microstructures. As a\nby-product of the energy estimate, we derive the rate of convergence in\nL$^{d/(d-1)}-$norm.",
    "descriptor": "",
    "authors": [
      "Pingbing Ming",
      "Siqi Song"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10853"
  },
  {
    "id": "arXiv:2207.10856",
    "title": "Prototype-Guided Continual Adaptation for Class-Incremental Unsupervised  Domain Adaptation",
    "abstract": "This paper studies a new, practical but challenging problem, called\nClass-Incremental Unsupervised Domain Adaptation (CI-UDA), where the labeled\nsource domain contains all classes, but the classes in the unlabeled target\ndomain increase sequentially. This problem is challenging due to two\ndifficulties. First, source and target label sets are inconsistent at each time\nstep, which makes it difficult to conduct accurate domain alignment. Second,\nprevious target classes are unavailable in the current step, resulting in the\nforgetting of previous knowledge. To address this problem, we propose a novel\nPrototype-guided Continual Adaptation (ProCA) method, consisting of two\nsolution strategies. 1) Label prototype identification: we identify target\nlabel prototypes by detecting shared classes with cumulative prediction\nprobabilities of target samples. 2) Prototype-based alignment and replay: based\non the identified label prototypes, we align both domains and enforce the model\nto retain previous knowledge. With these two strategies, ProCA is able to adapt\nthe source model to a class-incremental unlabeled target domain effectively.\nExtensive experiments demonstrate the effectiveness and superiority of ProCA in\nresolving CI-UDA. The source code is available at\nhttps://github.com/Hongbin98/ProCA.git",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Hongbin Lin",
      "Yifan Zhang",
      "Zhen Qiu",
      "Shuaicheng Niu",
      "Chuang Gan",
      "Yanxia Liu",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10856"
  },
  {
    "id": "arXiv:2207.10858",
    "title": "Two-Stage Fine-Tuning: A Novel Strategy for Learning Class-Imbalanced  Data",
    "abstract": "Classification on long-tailed distributed data is a challenging problem,\nwhich suffers from serious class-imbalance and hence poor performance on tail\nclasses with only a few samples. Owing to this paucity of samples, learning on\nthe tail classes is especially challenging for the fine-tuning when\ntransferring a pretrained model to a downstream task. In this work, we present\na simple modification of standard fine-tuning to cope with these challenges.\nSpecifically, we propose a two-stage fine-tuning: we first fine-tune the final\nlayer of the pretrained model with class-balanced reweighting loss, and then we\nperform the standard fine-tuning. Our modification has several benefits: (1) it\nleverages pretrained representations by only fine-tuning a small portion of the\nmodel parameters while keeping the rest untouched; (2) it allows the model to\nlearn an initial representation of the specific task; and importantly (3) it\nprotects the learning of tail classes from being at a disadvantage during the\nmodel updating. We conduct extensive experiments on synthetic datasets of both\ntwo-class and multi-class tasks of text classification as well as a real-world\napplication to ADME (i.e., absorption, distribution, metabolism, and excretion)\nsemantic labeling. The experimental results show that the proposed two-stage\nfine-tuning outperforms both fine-tuning with conventional loss and fine-tuning\nwith a reweighting loss on the above datasets.",
    "descriptor": "\nComments: 20 pages, 6 figures\n",
    "authors": [
      "Taha ValizadehAslani",
      "Yiwen Shi",
      "Jing Wang",
      "Ping Ren",
      "Yi Zhang",
      "Meng Hu",
      "Liang Zhao",
      "Hualou Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10858"
  },
  {
    "id": "arXiv:2207.10859",
    "title": "Geodesic-Former: a Geodesic-Guided Few-shot 3D Point Cloud Instance  Segmenter",
    "abstract": "This paper introduces a new problem in 3D point cloud: few-shot instance\nsegmentation. Given a few annotated point clouds exemplified a target class,\nour goal is to segment all instances of this target class in a query point\ncloud. This problem has a wide range of practical applications where point-wise\ninstance segmentation annotation is prohibitively expensive to collect. To\naddress this problem, we present Geodesic-Former -- the first geodesic-guided\ntransformer for 3D point cloud instance segmentation. The key idea is to\nleverage the geodesic distance to tackle the density imbalance of LiDAR 3D\npoint clouds. The LiDAR 3D point clouds are dense near the object surface and\nsparse or empty elsewhere making the Euclidean distance less effective to\ndistinguish different objects. The geodesic distance, on the other hand, is\nmore suitable since it encodes the scene's geometry which can be used as a\nguiding signal for the attention mechanism in a transformer decoder to generate\nkernels representing distinct features of instances. These kernels are then\nused in a dynamic convolution to obtain the final instance masks. To evaluate\nGeodesic-Former on the new task, we propose new splits of the two common 3D\npoint cloud instance segmentation datasets: ScannetV2 and S3DIS.\nGeodesic-Former consistently outperforms strong baselines adapted from\nstate-of-the-art 3D point cloud instance segmentation approaches with a\nsignificant margin. Code is available at\nhttps://github.com/VinAIResearch/GeoFormer.",
    "descriptor": "",
    "authors": [
      "Tuan Ngo",
      "Khoi Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10859"
  },
  {
    "id": "arXiv:2207.10860",
    "title": "Transformer with Implicit Edges for Particle-based Physics Simulation",
    "abstract": "Particle-based systems provide a flexible and unified way to simulate physics\nsystems with complex dynamics. Most existing data-driven simulators for\nparticle-based systems adopt graph neural networks (GNNs) as their network\nbackbones, as particles and their interactions can be naturally represented by\ngraph nodes and graph edges. However, while particle-based systems usually\ncontain hundreds even thousands of particles, the explicit modeling of particle\ninteractions as graph edges inevitably leads to a significant computational\noverhead, due to the increased number of particle interactions. Consequently,\nin this paper we propose a novel Transformer-based method, dubbed as\nTransformer with Implicit Edges (TIE), to capture the rich semantics of\nparticle interactions in an edge-free manner. The core idea of TIE is to\ndecentralize the computation involving pair-wise particle interactions into\nper-particle updates. This is achieved by adjusting the self-attention module\nto resemble the update formula of graph edges in GNN. To improve the\ngeneralization ability of TIE, we further amend TIE with learnable\nmaterial-specific abstract particles to disentangle global material-wise\nsemantics from local particle-wise semantics. We evaluate our model on diverse\ndomains of varying complexity and materials. Compared with existing GNN-based\nmethods, without bells and whistles, TIE achieves superior performance and\ngeneralization across all these domains. Codes and models are available at\nhttps://github.com/ftbabi/TIE_ECCV2022.git.",
    "descriptor": "\nComments: Accepted by ECCV2022, 14 pages\n",
    "authors": [
      "Yidi Shao",
      "Chen Change Loy",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.10860"
  },
  {
    "id": "arXiv:2207.10862",
    "title": "On Higher Adversarial Susceptibility of Contrastive Self-Supervised  Learning",
    "abstract": "Contrastive self-supervised learning (CSL) has managed to match or surpass\nthe performance of supervised learning in image and video classification.\nHowever, it is still largely unknown if the nature of the representation\ninduced by the two learning paradigms is similar. We investigate this under the\nlens of adversarial robustness. Our analytical treatment of the problem reveals\nintrinsic higher sensitivity of CSL over supervised learning. It identifies the\nuniform distribution of data representation over a unit hypersphere in the CSL\nrepresentation space as the key contributor to this phenomenon. We establish\nthat this increases model sensitivity to input perturbations in the presence of\nfalse negatives in the training data. Our finding is supported by extensive\nexperiments for image and video classification using adversarial perturbations\nand other input corruptions. Building on the insights, we devise strategies\nthat are simple, yet effective in improving model robustness with CSL training.\nWe demonstrate up to 68% reduction in the performance gap between adversarially\nattacked CSL and its supervised counterpart. Finally, we contribute to robust\nCSL paradigm by incorporating our findings in adversarial self-supervised\nlearning. We demonstrate an average gain of about 5% over two different\nstate-of-the-art methods in this domain.",
    "descriptor": "",
    "authors": [
      "Rohit Gupta",
      "Naveed Akhtar",
      "Ajmal Mian",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10862"
  },
  {
    "id": "arXiv:2207.10864",
    "title": "Ladder Matrix Recovery from Permutations",
    "abstract": "We give unique recovery guarantees for matrices of bounded rank that have\nundergone permutations of their entries. We even do this for a more general\nmatrix structure that we call ladder matrices. We use methods and results of\ncommutative algebra and algebraic geometry, for which we include a preparation\nas needed for a general audience.",
    "descriptor": "\nComments: 14 double-column pages\n",
    "authors": [
      "Manolis C. Tsakiris"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2207.10864"
  },
  {
    "id": "arXiv:2207.10866",
    "title": "Cost Aggregation with 4D Convolutional Swin Transformer for Few-Shot  Segmentation",
    "abstract": "This paper presents a novel cost aggregation network, called Volumetric\nAggregation with Transformers (VAT), for few-shot segmentation. The use of\ntransformers can benefit correlation map aggregation through self-attention\nover a global receptive field. However, the tokenization of a correlation map\nfor transformer processing can be detrimental, because the discontinuity at\ntoken boundaries reduces the local context available near the token edges and\ndecreases inductive bias. To address this problem, we propose a 4D\nConvolutional Swin Transformer, where a high-dimensional Swin Transformer is\npreceded by a series of small-kernel convolutions that impart local context to\nall pixels and introduce convolutional inductive bias. We additionally boost\naggregation performance by applying transformers within a pyramidal structure,\nwhere aggregation at a coarser level guides aggregation at a finer level. Noise\nin the transformer output is then filtered in the subsequent decoder with the\nhelp of the query's appearance embedding. With this model, a new\nstate-of-the-art is set for all the standard benchmarks in few-shot\nsegmentation. It is shown that VAT attains state-of-the-art performance for\nsemantic correspondence as well, where cost aggregation also plays a central\nrole.",
    "descriptor": "\nComments: Code and trained models are available at this https URL . This is ECCV'22 camera-ready version, which is revised from arXiv:2112.11685\n",
    "authors": [
      "Sunghwan Hong",
      "Seokju Cho",
      "Jisu Nam",
      "Stephen Lin",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10866"
  },
  {
    "id": "arXiv:2207.10868",
    "title": "On the Spatial Pattern of Input-Output Metrics for a Network  Synchronization Process",
    "abstract": "A graph-theoretic analysis is undertaken for a compendium of input-output\n(transfer) metrics of a standard discrete-time linear synchronization model,\nincluding lp gains, frequency responses, frequency-band energy, and Markov\nparameters. We show that these transfer metrics exhibit a spatial degradation,\nsuch that they are monotonically nonincreasing along vertex cutsets away from\nan exogenous input. We use this spatial analysis to characterize\nsignal-to-noise ratios (SNRs) in diffusive networks driven by process noise,\nand to develop a notion of propagation stability for dynamical networks.\nFinally, the formal results are illustrated through an example.",
    "descriptor": "",
    "authors": [
      "Subir Sarker",
      "Sandip Roy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10868"
  },
  {
    "id": "arXiv:2207.10872",
    "title": "Assessing mortality prediction through different representation models  based on concepts extracted from clinical notes",
    "abstract": "Recent years have seen particular interest in using electronic medical\nrecords (EMRs) for secondary purposes to enhance the quality and safety of\nhealthcare delivery. EMRs tend to contain large amounts of valuable clinical\nnotes. Learning of embedding is a method for converting notes into a format\nthat makes them comparable. Transformer-based representation models have\nrecently made a great leap forward. These models are pre-trained on large\nonline datasets to understand natural language texts effectively. The quality\nof a learning embedding is influenced by how clinical notes are used as input\nto representation models. A clinical note has several sections with different\nlevels of information value. It is also common for healthcare providers to use\ndifferent expressions for the same concept. Existing methods use clinical notes\ndirectly or with an initial preprocessing as input to representation models.\nHowever, to learn a good embedding, we identified the most essential clinical\nnotes section. We then mapped the extracted concepts from selected sections to\nthe standard names in the Unified Medical Language System (UMLS). We used the\nstandard phrases corresponding to the unique concepts as input for clinical\nmodels. We performed experiments to measure the usefulness of the learned\nembedding vectors in the task of hospital mortality prediction on a subset of\nthe publicly available Medical Information Mart for Intensive Care (MIMIC-III)\ndataset. According to the experiments, clinical transformer-based\nrepresentation models produced better results with getting input generated by\nstandard names of extracted unique concepts compared to other input formats.\nThe best-performing models were BioBERT, PubMedBERT, and UmlsBERT,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Hoda Memarzadeh",
      "Nasser Ghadiri",
      "Maryam Lotfi Shahreza"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10872"
  },
  {
    "id": "arXiv:2207.10878",
    "title": "An Ensemble Approach for Multiple Emotion Descriptors Estimation Using  Multi-task Learning",
    "abstract": "This paper illustrates our submission method to the fourth Affective Behavior\nAnalysis in-the-Wild (ABAW) Competition. The method is used for the Multi-Task\nLearning Challenge. Instead of using only face information, we employ full\ninformation from a provided dataset containing face and the context around the\nface. We utilized the InceptionNet V3 model to extract deep features then we\napplied the attention mechanism to refine the features. After that, we put\nthose features into the transformer block and multi-layer perceptron networks\nto get the final multiple kinds of emotion. Our model predicts arousal and\nvalence, classifies the emotional expression and estimates the action units\nsimultaneously. The proposed system achieves the performance of 0.917 on the\nMTL Challenge validation dataset.",
    "descriptor": "",
    "authors": [
      "Irfan Haider",
      "Minh-Trieu Tran",
      "Soo-Hyung Kim",
      "Hyung-Jeong Yang",
      "Guee-Sang Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10878"
  },
  {
    "id": "arXiv:2207.10883",
    "title": "My View is the Best View: Procedure Learning from Egocentric Videos",
    "abstract": "Procedure learning involves identifying the key-steps and determining their\nlogical order to perform a task. Existing approaches commonly use third-person\nvideos for learning the procedure, making the manipulated object small in\nappearance and often occluded by the actor, leading to significant errors. In\ncontrast, we observe that videos obtained from first-person (egocentric)\nwearable cameras provide an unobstructed and clear view of the action. However,\nprocedure learning from egocentric videos is challenging because (a) the camera\nview undergoes extreme changes due to the wearer's head motion, and (b) the\npresence of unrelated frames due to the unconstrained nature of the videos. Due\nto this, current state-of-the-art methods' assumptions that the actions occur\nat approximately the same time and are of the same duration, do not hold.\nInstead, we propose to use the signal provided by the temporal correspondences\nbetween key-steps across videos. To this end, we present a novel\nself-supervised Correspond and Cut (CnC) framework for procedure learning. CnC\nidentifies and utilizes the temporal correspondences between the key-steps\nacross multiple videos to learn the procedure. Our experiments show that CnC\noutperforms the state-of-the-art on the benchmark ProceL and CrossTask datasets\nby 5.2% and 6.3%, respectively. Furthermore, for procedure learning using\negocentric videos, we propose the EgoProceL dataset consisting of 62 hours of\nvideos captured by 130 subjects performing 16 tasks. The source code and the\ndataset are available on the project page https://sid2697.github.io/egoprocel/.",
    "descriptor": "\nComments: 25 pages, 6 figures, Accepted in European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Siddhant Bansal",
      "Chetan Arora",
      "C.V. Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10883"
  },
  {
    "id": "arXiv:2207.10887",
    "title": "Geolocated Social Media Posts are Happier: Understanding the  Characteristics of Check-in Posts on Twitter",
    "abstract": "The increasing prevalence of location-sharing features on social media has\nenabled researchers to ground computational social science research using\ngeolocated data, affording opportunities to study human mobility, the impact of\nreal-world events, and more. This paper analyzes what crucially separates posts\nwith geotags from those without. We find that users who share location are not\nrepresentative of the social media user population at large, jeopardizing the\ngeneralizability of research that uses only geolocated data.We consider three\naspects: affect -- sentiment and emotions, content -- textual and non-textual,\nand audience engagement. By comparing a dataset of 1.3 million geotagged tweets\nwith a random dataset of the same size, we show that geotagged posts on Twitter\nexhibit significantly more positivity, are often about joyous and special\nevents such as weddings or graduations, convey more collectivism rather than\nindividualism, and contain more additional features such as hashtags or objects\nin images, but at the same time generate substantially less engagement. These\nfindings suggest there exist significant differences in the messages conveyed\nin geotagged posts. Our research carries important implications for future\nresearch utilizing geolocation social media data.",
    "descriptor": "\nComments: 11 pages, 10 figures, 2 tables\n",
    "authors": [
      "Julie Jiang",
      "Jesse Thomason",
      "Francesco Barbieri",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10887"
  },
  {
    "id": "arXiv:2207.10888",
    "title": "FairGRAPE: Fairness-aware GRAdient Pruning mEthod for Face Attribute  Classification",
    "abstract": "Existing pruning techniques preserve deep neural networks' overall ability to\nmake correct predictions but may also amplify hidden biases during the\ncompression process. We propose a novel pruning method, Fairness-aware GRAdient\nPruning mEthod (FairGRAPE), that minimizes the disproportionate impacts of\npruning on different sub-groups. Our method calculates the per-group importance\nof each model weight and selects a subset of weights that maintain the relative\nbetween-group total importance in pruning. The proposed method then prunes\nnetwork edges with small importance values and repeats the procedure by\nupdating importance values. We demonstrate the effectiveness of our method on\nfour different datasets, FairFace, UTKFace, CelebA, and ImageNet, for the tasks\nof face attribute classification where our method reduces the disparity in\nperformance degradation by up to 90% compared to the state-of-the-art pruning\nalgorithms. Our method is substantially more effective in a setting with a high\npruning rate (99%). The code and dataset used in the experiments are available\nat https://github.com/Bernardo1998/FairGRAPE",
    "descriptor": "\nComments: To appear in ECCV 2022\n",
    "authors": [
      "Xiaofeng Lin",
      "Seungbae Kim",
      "Jungseock Joo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10888"
  },
  {
    "id": "arXiv:2207.10889",
    "title": "Correlation Clustering with Sherali-Adams",
    "abstract": "Given a complete graph $G = (V, E)$ where each edge is labeled $+$ or $-$,\nthe Correlation Clustering problem asks to partition $V$ into clusters to\nminimize the number of $+$edges between different clusters plus the number of\n$-$edges within the same cluster. Correlation Clustering has been used to model\na large number of clustering problems in practice, making it one of the most\nwidely studied clustering formulations. The approximability of Correlation\nClustering has been actively investigated [BBC04, CGW05, ACN08], culminating in\na $2.06$-approximation algorithm [CMSY15], based on rounding the standard LP\nrelaxation. Since the integrality gap for this formulation is 2, it has\nremained a major open question to determine if the approximation factor of 2\ncan be reached, or even breached.\nIn this paper, we answer this question affirmatively by showing that there\nexists a $(1.994 + \\epsilon)$-approximation algorithm based on\n$O(1/\\epsilon^2$) rounds of the Sherali-Adams hierarchy. In order to round a\nsolution to the Sherali-Adams relaxation, we adapt the {\\em correlated\nrounding} originally developed for CSPs [BRS11, GS11, RT12]. With this tool, we\nreach an approximation ratio of $2+\\epsilon$ for Correlation Clustering. To\nbreach this ratio, we go beyond the traditional triangle-based analysis by\nemploying a global charging scheme that amortizes the total cost of the\nrounding across different triangles.",
    "descriptor": "",
    "authors": [
      "Vincent Cohen-Addad",
      "Euiwoong Lee",
      "Alantha Newman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.10889"
  },
  {
    "id": "arXiv:2207.10891",
    "title": "Cell-Free Massive MIMO with Multi-Antenna Users over Weichselberger  Rician Channels",
    "abstract": "We consider a cell-free massive multiple-input multiple-output (MIMO) system\nwith multi-antenna access points and user equipments (UEs) over Weichselberger\nRician fading channels with random phase-shifts. More specifically, we\ninvestigate the uplink spectral efficiency (SE) for two pragmatic processing\nschemes: 1) the fully centralized processing scheme with global minimum mean\nsquare error (MMSE) or maximum ratio (MR) combining; 2) the large-scale fading\ndecoding (LSFD) scheme with local MMSE or MR combining. To improve the system\nSE performance, we propose a practical uplink precoding scheme based on only\nthe eigenbasis of the UE-side correlation matrices. Moreover, we derive novel\nclosed-form SE expressions for characterizing the LSFD scheme with the MR\ncombining. Numerical results validate the accuracy of our derived expressions\nand show that the proposed precoding scheme can significantly improve the SE\nperformance compared with the scenario without any precoding scheme.",
    "descriptor": "\nComments: 14 pages, 5 figures, to appear in IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Xin Li",
      "Jiayi Zhang",
      "Zhe Wang",
      "Bo Ai",
      "Derrick Wing Kwan Ng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10891"
  },
  {
    "id": "arXiv:2207.10892",
    "title": "Bi-directional Contrastive Learning for Domain Adaptive Semantic  Segmentation",
    "abstract": "We present a novel unsupervised domain adaptation method for semantic\nsegmentation that generalizes a model trained with source images and\ncorresponding ground-truth labels to a target domain. A key to domain adaptive\nsemantic segmentation is to learn domain-invariant and discriminative features\nwithout target ground-truth labels. To this end, we propose a bi-directional\npixel-prototype contrastive learning framework that minimizes intra-class\nvariations of features for the same object class, while maximizing inter-class\nvariations for different ones, regardless of domains. Specifically, our\nframework aligns pixel-level features and a prototype of the same object class\nin target and source images (i.e., positive pairs), respectively, sets them\napart for different classes (i.e., negative pairs), and performs the alignment\nand separation processes toward the other direction with pixel-level features\nin the source image and a prototype in the target image. The cross-domain\nmatching encourages domain-invariant feature representations, while the\nbidirectional pixel-prototype correspondences aggregate features for the same\nobject class, providing discriminative features. To establish training pairs\nfor contrastive learning, we propose to generate dynamic pseudo labels of\ntarget images using a non-parametric label transfer, that is, pixel-prototype\ncorrespondences across different domains. We also present a calibration method\ncompensating class-wise domain biases of prototypes gradually during training.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Geon Lee",
      "Chanho Eom",
      "Wonkyung Lee",
      "Hyekang Park",
      "Bumsub Ham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10892"
  },
  {
    "id": "arXiv:2207.10894",
    "title": "What are Your Pronouns? Examining Gender Pronoun Usage on Twitter",
    "abstract": "Stating your gender pronouns, along with your name, is becoming the new norm\nof self-introductions at school, at the workplace, and online. The increasing\nprevalence and awareness of nonconforming gender identities put discussions of\ndeveloping gender-inclusive language at the forefront. This work presents the\nfirst empirical research on gender pronoun usage on large-scale social media.\nLeveraging a Twitter dataset of over 2 billion tweets collected continuously\nover two years, we find that the public declaration of gender pronouns is on\nthe rise, with most people declaring as using she series pronouns, followed by\nhe series pronouns, and a smaller but considerable amount of non-binary\npronouns. From analyzing Twitter posts and sharing activities, we can discern\nusers who use gender pronouns from those who do not and also distinguish users\nof various gender identities. We further illustrate the relationship between\nexplicit forms of social network exposure to gender pronouns and their eventual\ngender pronoun adoption. This work carries crucial implications for\ngender-identity studies and initiates new research directions in gender-related\nfairness and inclusion, as well as support against online harassment and\ndiscrimination on social media.",
    "descriptor": "\nComments: 23 pages, 11 figures, 2 tables\n",
    "authors": [
      "Julie Jiang",
      "Emily Chen",
      "Luca Luceri",
      "Goran Muri\u0107",
      "Francesco Pierri",
      "Ho-Chun Herbert Chang",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10894"
  },
  {
    "id": "arXiv:2207.10895",
    "title": "3D Random Occlusion and Multi-Layer Projection for Deep Multi-Camera  Pedestrian Localization",
    "abstract": "Although deep-learning based methods for monocular pedestrian detection have\nmade great progress, they are still vulnerable to heavy occlusions. Using\nmulti-view information fusion is a potential solution but has limited\napplications, due to the lack of annotated training samples in existing\nmulti-view datasets, which increases the risk of overfitting. To address this\nproblem, a data augmentation method is proposed to randomly generate 3D\ncylinder occlusions, on the ground plane, which are of the average size of\npedestrians and projected to multiple views, to relieve the impact of\noverfitting in the training. Moreover, the feature map of each view is\nprojected to multiple parallel planes at different heights, by using\nhomographies, which allows the CNNs to fully utilize the features across the\nheight of each pedestrian to infer the locations of pedestrians on the ground\nplane. The proposed 3DROM method has a greatly improved performance in\ncomparison with the state-of-the-art deep-learning based methods for multi-view\npedestrian detection.",
    "descriptor": "",
    "authors": [
      "Rui Qiu",
      "Ming Xu",
      "Yuyao Yan",
      "Jeremy S. Smith",
      "Xi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10895"
  },
  {
    "id": "arXiv:2207.10896",
    "title": "Privacy and Transparency in Graph Machine Learning: A Unified  Perspective",
    "abstract": "Graph Machine Learning (GraphML), whereby classical machine learning is\ngeneralized to irregular graph domains, has enjoyed a recent renaissance,\nleading to a dizzying array of models and their applications in several\ndomains. With its growing applicability to sensitive domains and regulations by\ngovernment agencies for trustworthy AI systems, researchers have started\nlooking into the issues of transparency and privacy of graph learning. However,\nthese topics have been mainly investigated independently. In this position\npaper, we provide a unified perspective on the interplay of privacy and\ntransparency in GraphML.",
    "descriptor": "",
    "authors": [
      "Megha Khosla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10896"
  },
  {
    "id": "arXiv:2207.10897",
    "title": "Efficient Modeling of Future Context for Image Captioning",
    "abstract": "Existing approaches to image captioning usually generate the sentence\nword-by-word from left to right, with the constraint of conditioned on local\ncontext including the given image and history generated words. There have been\nmany studies target to make use of global information during decoding, e.g.,\niterative refinement. However, it is still under-explored how to effectively\nand efficiently incorporate the future context. To respond to this issue,\ninspired by that Non-Autoregressive Image Captioning (NAIC) can leverage\ntwo-side relation with modified mask operation, we aim to graft this advance to\nthe conventional Autoregressive Image Captioning (AIC) model while maintaining\nthe inference efficiency without extra time cost. Specifically, AIC and NAIC\nmodels are first trained combined with shared visual encoders, forcing the\nvisual encoder to contain sufficient and valid future context; then the AIC\nmodel is encouraged to capture the causal dynamics of cross-layer interchanging\nfrom NAIC model on its unconfident words, which follows a teacher-student\nparadigm and optimized with the distribution calibration training objective.\nEmpirical evidences demonstrate that our proposed approach clearly surpass the\nstate-of-the-art baselines in both automatic metrics and human evaluations on\nthe MS COCO benchmark. The source code is available at:\nhttps://github.com/feizc/Future-Caption.",
    "descriptor": "\nComments: ACM Multimedia 2022\n",
    "authors": [
      "Zhengcong Fei",
      "Junshi Huang",
      "Xiaoming Wei",
      "Xiaolin Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10897"
  },
  {
    "id": "arXiv:2207.10898",
    "title": "Impact of RoCE Congestion Control Policies on Distributed Training of  DNNs",
    "abstract": "RDMA over Converged Ethernet (RoCE) has gained significant attraction for\ndatacenter networks due to its compatibility with conventional Ethernet-based\nfabric. However, the RDMA protocol is efficient only on (nearly) lossless\nnetworks, emphasizing the vital role of congestion control on RoCE networks.\nUnfortunately, the native RoCE congestion control scheme, based on Priority\nFlow Control (PFC), suffers from many drawbacks such as unfairness,\nhead-of-line-blocking, and deadlock. Therefore, in recent years many schemes\nhave been proposed to provide additional congestion control for RoCE networks\nto minimize PFC drawbacks. However, these schemes are proposed for general\ndatacenter environments. In contrast to the general datacenters that are built\nusing commodity hardware and run general-purpose workloads, high-performance\ndistributed training platforms deploy high-end accelerators and network\ncomponents and exclusively run training workloads using collectives\n(All-Reduce, All-To-All) communication libraries for communication.\nFurthermore, these platforms usually have a private network, separating their\ncommunication traffic from the rest of the datacenter traffic. Scalable\ntopology-aware collective algorithms are inherently designed to avoid incast\npatterns and balance traffic optimally. These distinct features necessitate\nrevisiting previously proposed congestion control schemes for general-purpose\ndatacenter environments. In this paper, we thoroughly analyze some of the SOTA\nRoCE congestion control schemes vs. PFC when running on distributed training\nplatforms. Our results indicate that previously proposed RoCE congestion\ncontrol schemes have little impact on the end-to-end performance of training\nworkloads, motivating the necessity of designing an optimized, yet\nlow-overhead, congestion control scheme based on the characteristics of\ndistributed training platforms and workloads.",
    "descriptor": "",
    "authors": [
      "Tarannum Khan",
      "Saeed Rashidi",
      "Srinivas Sridharan",
      "Pallavi Shurpali",
      "Aditya Akella",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10898"
  },
  {
    "id": "arXiv:2207.10899",
    "title": "Decoupled Adversarial Contrastive Learning for Self-supervised  Adversarial Robustness",
    "abstract": "Adversarial training (AT) for robust representation learning and\nself-supervised learning (SSL) for unsupervised representation learning are two\nactive research fields. Integrating AT into SSL, multiple prior works have\naccomplished a highly significant yet challenging task: learning robust\nrepresentation without labels. A widely used framework is adversarial\ncontrastive learning which couples AT and SSL, and thus constitute a very\ncomplex optimization problem. Inspired by the divide-and-conquer philosophy, we\nconjecture that it might be simplified as well as improved by solving two\nsub-problems: non-robust SSL and pseudo-supervised AT. This motivation shifts\nthe focus of the task from seeking an optimal integrating strategy for a\ncoupled problem to finding sub-solutions for sub-problems. With this said, this\nwork discards prior practices of directly introducing AT to SSL frameworks and\nproposed a two-stage framework termed Decoupled Adversarial Contrastive\nLearning (DeACL). Extensive experimental results demonstrate that our DeACL\nachieves SOTA self-supervised adversarial robustness while significantly\nreducing the training time, which validates its effectiveness and efficiency.\nMoreover, our DeACL constitutes a more explainable solution, and its success\nalso bridges the gap with semi-supervised AT for exploiting unlabeled samples\nfor robust representation learning. The code is publicly accessible at\nhttps://github.com/pantheon5100/DeACL.",
    "descriptor": "\nComments: Accepted by ECCV 2022 oral presentation\n",
    "authors": [
      "Chaoning Zhang",
      "Kang Zhang",
      "Chenshuang Zhang",
      "Axi Niu",
      "Jiu Feng",
      "Chang D. Yoo",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10899"
  },
  {
    "id": "arXiv:2207.10909",
    "title": "DBQ-SSD: Dynamic Ball Query for Efficient 3D Object Detection",
    "abstract": "Many point-based 3D detectors adopt point-feature sampling strategies to drop\nsome points for efficient inference. These strategies are typically based on\nfixed and handcrafted rules, making difficult to handle complicated scenes.\nDifferent from them, we propose a Dynamic Ball Query (DBQ) network to\nadaptively select a subset of input points according to the input features, and\nassign the feature transform with suitable receptive field for each selected\npoint. It can be embedded into some state-of-the-art 3D detectors and trained\nin an end-to-end manner, which significantly reduces the computational cost.\nExtensive experiments demonstrate that our method can reduce latency by 30%-60%\non KITTI and Waymo datasets. Specifically, the inference speed of our detector\ncan reach 162 FPS and 30 FPS with negligible performance degradation on KITTI\nand Waymo datasets, respectively.",
    "descriptor": "",
    "authors": [
      "Jinrong Yang",
      "Lin Song",
      "Songtao Liu",
      "Zeming Li",
      "Xiaoping Li",
      "Hongbin Sun",
      "Jian Sun",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10909"
  },
  {
    "id": "arXiv:2207.10910",
    "title": "Delay-Doppler Reversal for OTFS System in Doubly-selective Fading  Channels",
    "abstract": "The recent proposed orthogonal time frequency space (OTFS) modulation shows\nsignifcant advantages than conventional orthogonal frequency division\nmultiplexing (OFDM) for high mobility wireless communications. However, a\nchallenging problem is the development of effcient receivers for practical OTFS\nsystems with low complexity. In this paper, we propose a novel delay-Doppler\nreversal (DDR) technology for OTFS system with desired performance and low\ncomplexity. We present the DDR technology from a perspective of two-dimensional\ncascaded channel model, analyze its computational complexity and also analyze\nits performance gain compared to the direct processing (DP) receiver without\nDDR. Simulation results demonstrate that our proposed DDR receiver outperforms\ntraditional receivers in doubly-selective fading channels.",
    "descriptor": "",
    "authors": [
      "Xiangxiang Li",
      "Haiyan Wang",
      "Yao Ge",
      "Xiaohong Shen",
      "Yuanyuan Lei"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.10910"
  },
  {
    "id": "arXiv:2207.10915",
    "title": "Optimization of Forcemyography Sensor Placement for Arm Movement  Recognition",
    "abstract": "How to design an optimal wearable device for human movement recognition is\nvital to reliable and accurate human-machine collaboration. Previous works\nmainly fabricate wearable devices heuristically. Instead, this paper raises an\nacademic question: can we design an optimization algorithm to optimize the\nfabrication of wearable devices such as figuring out the best sensor\narrangement automatically? Specifically, this work focuses on optimizing the\nplacement of Forcemyography (FMG) sensors for FMG armbands in the application\nof arm movement recognition. Firstly, based on graph theory, the armband is\nmodeled considering sensors' signals and connectivity. Then, a Graph-based\nArmband Modeling Network (GAM-Net) is introduced for arm movement recognition.\nAfterward, the sensor placement optimization for FMG armbands is formulated and\nan optimization algorithm with greedy local search is proposed. To study the\neffectiveness of our optimization algorithm, a dataset for mechanical\nmaintenance tasks using FMG armbands with 16 sensors is collected. Our\nexperiments show that using only 4 sensors optimized with our algorithm can\nhelp maintain a comparable recognition accuracy to using all sensors. Finally,\nthe optimized sensor placement result is verified from a physiological view.\nThis work would like to shed light on the automatic fabrication of wearable\ndevices considering downstream tasks, such as human biological signal\ncollection and movement recognition. Our code and dataset are available at\nhttps://github.com/JerryX1110/IROS22-FMG-Sensor-Optimization",
    "descriptor": "\nComments: 6 pages, 10 figures, Accepted by IROS22 (The 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Xiaohao Xu",
      "Zihao Du",
      "Huaxin Zhang",
      "Ruichao Zhang",
      "Zihan Hong",
      "Qin Huang",
      "Bin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10915"
  },
  {
    "id": "arXiv:2207.10916",
    "title": "PLD-SLAM: A Real-Time Visual SLAM Using Points and Line Segments in  Dynamic Scenes",
    "abstract": "In this paper, we consider the problems in the practical application of\nvisual simultaneous localization and mapping (SLAM). With the popularization\nand application of the technology in wide scope, the practicability of SLAM\nsystem has become a new hot topic after the accuracy and robustness, e.g., how\nto keep the stability of the system and achieve accurate pose estimation in the\nlow-texture and dynamic environment, and how to improve the universality and\nreal-time performance of the system in the real scenes, etc. This paper\nproposes a real-time stereo indirect visual SLAM system, PLD-SLAM, which\ncombines point and line features, and avoid the impact of dynamic objects in\nhighly dynamic environments. We also present a novel global gray similarity\n(GGS) algorithm to achieve reasonable keyframe selection and efficient loop\nclosure detection (LCD). Benefiting from the GGS, PLD-SLAM can realize\nreal-time accurate pose estimation in most real scenes without pre-training and\nloading a huge feature dictionary model. To verify the performance of the\nproposed system, we compare it with existing state-of-the-art (SOTA) methods on\nthe public datasets KITTI, EuRoC MAV, and the indoor stereo datasets provided\nby us, etc. The experiments show that the PLD-SLAM has better real-time\nperformance while ensuring stability and accuracy in most scenarios. In\naddition, through the analysis of the experimental results of the GGS, we can\nfind it has excellent performance in the keyframe selection and LCD.",
    "descriptor": "",
    "authors": [
      "BaoSheng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10916"
  },
  {
    "id": "arXiv:2207.10929",
    "title": "Static Hovering Realization for Multirotor Aerial Vehicles with Tiltable  Propellers",
    "abstract": "This paper presents a theoretical study on the ability of multi-rotor aerial\nvehicles (MRAVs) with tiltable propellers to achieve and sustain static\nhovering at different orientations. To analyze the ability of MRAVs with\ntiltable propellers to achieve static hovering, a novel linear map between the\nplatform's control inputs and applied forces and moments is introduced. The\nrelation between the introduced map and the platform's ability to hover at\ndifferent orientations is developed. Correspondingly, the conditions for MRAVs\nwith tiltable propellers to realize and sustain static hovering are detailed. A\nnumerical metric is then introduced, which reflects the ability of MRAVs to\nsustain static hovering at different orientations. A subclass of MRAVs with\ntiltable propellers is defined as the Critically Statically Hoverable platforms\n(CSH), where CSH platforms are MRAVs that cannot sustain static hovering with\nfixed propellers, but can achieve static hovering with tilting propellers.\nFinally, extensive simulations are conducted to test and validate the above\nfindings, and to demonstrate the effect of the proposed numerical metric on the\nplatform's dynamics.",
    "descriptor": "",
    "authors": [
      "Mahmoud Hamandi",
      "Lakmal Seneviratne",
      "Yahya Zweiri"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10929"
  },
  {
    "id": "arXiv:2207.10931",
    "title": "What's in the laundromat? Mapping and characterising offshore owned  domestic property in London",
    "abstract": "The UK, particularly London, is a global hub for money laundering, a\nsignificant portion of which uses domestic property. However, understanding the\ndistribution and characteristics of offshore domestic property in the UK is\nchallenging due to data availability. This paper attempts to remedy that\nsituation by enhancing a publicly available dataset of UK property owned by\noffshore companies. We create a data processing pipeline which draws on several\ndatasets and machine learning techniques to create a parsed set of addresses\nclassified into six use classes. The enhanced dataset contains 138,000\nproperties 44,000 more than the original dataset. The majority are domestic\n(95k), with a disproportionate amount of those in London (42k). The average\noffshore domestic property in London is worth 1.33 million GBP collectively\nthis amounts to approximately 56 Billion GBP. We perform an in-depth analysis\nof the offshore domestic property in London, comparing the price, distribution\nand entropy/concentration with Airbnb property, low-use/empty property and\nconventional domestic property. We estimate that the total amount of offshore,\nlow-use and airbnb property in London is between 144,000 and 164,000 and that\nthey are collectively worth between 145-174 billion GBP. Furthermore, offshore\ndomestic property is more expensive and has higher entropy/concentration than\nall other property types. In addition, we identify two different types of\noffshore property, nested and individual, which have different price and\ndistribution characteristics. Finally, we release the enhanced offshore\nproperty dataset, the complete low-use London dataset and the pipeline for\ncreating the enhanced dataset to reduce the barriers to studying this topic.",
    "descriptor": "\nComments: 27 pages, 7 figures, 7 tables\n",
    "authors": [
      "Jonathan Bourne",
      "Andrea Ingianni",
      "Rex McKenzie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10931"
  },
  {
    "id": "arXiv:2207.10936",
    "title": "Long-tailed Instance Segmentation using Gumbel Optimized Loss",
    "abstract": "Major advancements have been made in the field of object detection and\nsegmentation recently. However, when it comes to rare categories, the\nstate-of-the-art methods fail to detect them, resulting in a significant\nperformance gap between rare and frequent categories. In this paper, we\nidentify that Sigmoid or Softmax functions used in deep detectors are a major\nreason for low performance and are sub-optimal for long-tailed detection and\nsegmentation. To address this, we develop a Gumbel Optimized Loss (GOL), for\nlong-tailed detection and segmentation. It aligns with the Gumbel distribution\nof rare classes in imbalanced datasets, considering the fact that most classes\nin long-tailed detection have low expected probability. The proposed GOL\nsignificantly outperforms the best state-of-the-art method by 1.1% on AP , and\nboosts the overall segmentation by 9.0% and detection by 8.0%, particularly\nimproving detection of rare classes by 20.3%, compared to Mask-RCNN, on LVIS\ndataset. Code available at: https://github.com/kostas1515/GOL",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Konstantinos Panagiotis Alexandridis",
      "Jiankang Deng",
      "Anh Nguyen",
      "Shan Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10936"
  },
  {
    "id": "arXiv:2207.10937",
    "title": "Physics-informed convolutional neural network with bicubic spline  interpolation for sound field estimation",
    "abstract": "A sound field estimation method based on a physics-informed convolutional\nneural network (PICNN) using spline interpolation is proposed. Most of the\nsound field estimation methods are based on wavefunction expansion, making the\nestimated function satisfy the Helmholtz equation. However, these methods rely\nonly on physical properties; thus, they suffer from a significant deterioration\nof accuracy when the number of measurements is small. Recent learning-based\nmethods based on neural networks have advantages in estimating from sparse\nmeasurements when training data are available. However, since physical\nproperties are not taken into consideration, the estimated function can be a\nphysically infeasible solution. We propose the application of PICNN to the\nsound field estimation problem by using a loss function that penalizes\ndeviation from the Helmholtz equation. Since the output of CNN is a spatially\ndiscretized pressure distribution, it is difficult to directly evaluate the\nHelmholtz-equation loss function. Therefore, we incorporate bicubic spline\ninterpolation in the PICNN framework. Experimental results indicated that\naccurate and physically feasible estimation from sparse measurements can be\nachieved with the proposed method.",
    "descriptor": "\nComments: Accepted to International Workshop on Acoustic Signal Enhancement (IWAENC) 2022\n",
    "authors": [
      "Kazuhide Shigemi",
      "Shoichi Koyama",
      "Tomohiko Nakamura",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10937"
  },
  {
    "id": "arXiv:2207.10940",
    "title": "Dense RGB-D-Inertial SLAM with Map Deformations",
    "abstract": "While dense visual SLAM methods are capable of estimating dense\nreconstructions of the environment, they suffer from a lack of robustness in\ntheir tracking step, especially when the optimisation is poorly initialised.\nSparse visual SLAM systems have attained high levels of accuracy and robustness\nthrough the inclusion of inertial measurements in a tightly-coupled fusion.\nInspired by this performance, we propose the first tightly-coupled dense\nRGB-D-inertial SLAM system.\nOur system has real-time capability while running on a GPU. It jointly\noptimises for the camera pose, velocity, IMU biases and gravity direction while\nbuilding up a globally consistent, fully dense surfel-based 3D reconstruction\nof the environment. Through a series of experiments on both synthetic and real\nworld datasets, we show that our dense visual-inertial SLAM system is more\nrobust to fast motions and periods of low texture and low geometric variation\nthan a related RGB-D-only SLAM system.",
    "descriptor": "\nComments: Accepted at IROS 2017; supplementary video available at this https URL\n",
    "authors": [
      "Tristan Laidlow",
      "Michael Bloesch",
      "Wenbin Li",
      "Stefan Leutenegger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10940"
  },
  {
    "id": "arXiv:2207.10941",
    "title": "Respecting Time Series Properties Makes Deep Time Series Forecasting  Perfect",
    "abstract": "How to handle time features shall be the core question of any time series\nforecasting model. Ironically, it is often ignored or misunderstood by\ndeep-learning based models, even those baselines which are state-of-the-art.\nThis behavior makes their inefficient, untenable and unstable. In this paper,\nwe rigorously analyze three prevalent but deficient/unfounded deep time series\nforecasting mechanisms or methods from the view of time series properties,\nincluding normalization methods, multivariate forecasting and input sequence\nlength. Corresponding corollaries and solutions are given on both empirical and\ntheoretical basis. We thereby propose a novel time series forecasting network,\ni.e. RTNet, on the basis of aforementioned analysis. It is general enough to be\ncombined with both supervised and self-supervised forecasting format. Thanks to\nthe core idea of respecting time series properties, no matter in which\nforecasting format, RTNet shows obviously superior forecasting performances\ncompared with dozens of other SOTA time series forecasting baselines in three\nreal-world benchmark datasets. By and large, it even occupies less time\ncomplexity and memory usage while acquiring better forecasting accuracy. The\nsource code is available at https://github.com/OrigamiSL/RTNet.",
    "descriptor": "",
    "authors": [
      "Li Shen",
      "Yuning Wei",
      "Yangzhu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10941"
  },
  {
    "id": "arXiv:2207.10942",
    "title": "Efficient Testing of Deep Neural Networks via Decision Boundary Analysis",
    "abstract": "Deep learning plays a more and more important role in our daily life due to\nits competitive performance in multiple industrial application domains. As the\ncore of DL-enabled systems, deep neural networks automatically learn knowledge\nfrom carefully collected and organized training data to gain the ability to\npredict the label of unseen data. Similar to the traditional software systems\nthat need to be comprehensively tested, DNNs also need to be carefully\nevaluated to make sure the quality of the trained model meets the demand. In\npractice, the de facto standard to assess the quality of DNNs in industry is to\ncheck their performance (accuracy) on a collected set of labeled test data.\nHowever, preparing such labeled data is often not easy partly because of the\nhuge labeling effort, i.e., data labeling is labor-intensive, especially with\nthe massive new incoming unlabeled data every day. Recent studies show that\ntest selection for DNN is a promising direction that tackles this issue by\nselecting minimal representative data to label and using these data to assess\nthe model. However, it still requires human effort and cannot be automatic. In\nthis paper, we propose a novel technique, named Aries, that can estimate the\nperformance of DNNs on new unlabeled data using only the information obtained\nfrom the original test data. The key insight behind our technique is that the\nmodel should have similar prediction accuracy on the data which have similar\ndistances to the decision boundary. We performed a large-scale evaluation of\nour technique on 13 types of data transformation methods. The results\ndemonstrate the usefulness of our technique that the estimated accuracy by\nAries is only 0.03% -- 2.60% (on average 0.61%) off the true accuracy. Besides,\nAries also outperforms the state-of-the-art selection-labeling-based methods in\nmost (96 out of 128) cases.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Qiang Hu",
      "Yuejun Guo",
      "Xiaofei Xie",
      "Maxime Cordy",
      "Lei Ma",
      "Mike Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10942"
  },
  {
    "id": "arXiv:2207.10947",
    "title": "Multilabel Prototype Generation for Data Reduction in k-Nearest  Neighbour classification",
    "abstract": "Prototype Generation (PG) methods are typically considered for improving the\nefficiency of the $k$-Nearest Neighbour ($k$NN) classifier when tackling\nhigh-size corpora. Such approaches aim at generating a reduced version of the\ncorpus without decreasing the classification performance when compared to the\ninitial set. Despite their large application in multiclass scenarios, very few\nworks have addressed the proposal of PG methods for the multilabel space. In\nthis regard, this work presents the novel adaptation of four multiclass PG\nstrategies to the multilabel case. These proposals are evaluated with three\nmultilabel $k$NN-based classifiers, 12 corpora comprising a varied range of\ndomains and corpus sizes, and different noise scenarios artificially induced in\nthe data. The results obtained show that the proposed adaptations are capable\nof significantly improving -- both in terms of efficiency and classification\nperformance -- the only reference multilabel PG work in the literature as well\nas the case in which no PG method is applied, also presenting a statistically\nsuperior robustness in noisy scenarios. Moreover, these novel PG strategies\nallow prioritising either the efficiency or efficacy criteria through its\nconfiguration depending on the target scenario, hence covering a wide area in\nthe solution space not previously filled by other works.",
    "descriptor": "",
    "authors": [
      "Jose J. Valero-Mas",
      "Antonio Javier Gallego",
      "Pablo Alonso-Jim\u00e9nez",
      "Xavier Serra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10947"
  },
  {
    "id": "arXiv:2207.10948",
    "title": "Dynamic Local Aggregation Network with Adaptive Clusterer for Anomaly  Detection",
    "abstract": "Existing methods for anomaly detection based on memory-augmented autoencoder\n(AE) have the following drawbacks: (1) Establishing a memory bank requires\nadditional memory space. (2) The fixed number of prototypes from subjective\nassumptions ignores the data feature differences and diversity. To overcome\nthese drawbacks, we introduce DLAN-AC, a Dynamic Local Aggregation Network with\nAdaptive Clusterer, for anomaly detection. First, The proposed DLAN can\nautomatically learn and aggregate high-level features from the AE to obtain\nmore representative prototypes, while freeing up extra memory space. Second,\nThe proposed AC can adaptively cluster video data to derive initial prototypes\nwith prior information. In addition, we also propose a dynamic redundant\nclustering strategy (DRCS) to enable DLAN for automatically eliminating feature\nclusters that do not contribute to the construction of prototypes. Extensive\nexperiments on benchmarks demonstrate that DLAN-AC outperforms most existing\nmethods, validating the effectiveness of our method. Our code is publicly\navailable at https://github.com/Beyond-Zw/DLAN-AC.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Zhiwei Yang",
      "Peng Wu",
      "Jing Liu",
      "Xiaotao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10948"
  },
  {
    "id": "arXiv:2207.10949",
    "title": "Maximizing Nash Social Welfare in 2-Value Instances: The Half-Integer  Case",
    "abstract": "We consider the problem of maximizing the Nash social welfare when allocating\na set $G$ of indivisible goods to a set $N$ of agents. We study instances, in\nwhich all agents have 2-value additive valuations: The value of a good $g \\in\nG$ for an agent $i \\in N$ is either $1$ or $s$, where $s$ is an odd multiple of\n$\\frac{1}{2}$ larger than one. We show that the problem is solvable in\npolynomial time. Akrami et at. showed that this problem is solvable in\npolynomial time if $s$ is integral and is NP-hard whenever $s = \\frac{p}{q}$,\n$p \\in \\mathbb{N}$ and $q\\in \\mathbb{N}$ are co-prime and $p > q \\ge 3$. For\nthe latter situation, an approximation algorithm was also given. It obtains an\napproximation ratio of at most $1.0345$. Moreover, the problem is APX-hard,\nwith a lower bound of $1.000015$ achieved at $\\frac{p}{q} = \\frac{5}{4}$. The\ncase $q = 2$ and odd $p$ was left open.\nIn the case of integral $s$, the problem is separable in the sense that the\noptimal allocation of the heavy goods (= value $s$ for some agent) is\nindependent of the number of light goods (= value $1$ for all agents). This\nleads to an algorithm that first computes an optimal allocation of the heavy\ngoods and then adds the light goods greedily. This separation no longer holds\nfor $s = \\frac{3}{2}$; a simple example is given in the introduction. Thus an\nalgorithm has to consider heavy and light goods together. This complicates\nmatters considerably. Our algorithm is based on a collection of improvement\nrules that transfers any allocation into an optimal allocation and exploits a\nconnection to matchings with parity constraints.",
    "descriptor": "",
    "authors": [
      "Hannaneh Akrami",
      "Bhaskar Ray Chaudhury",
      "Martin Hoefer",
      "Kurt Mehlhorn",
      "Marco Schmalhofer",
      "Golnoosh Shahkarami",
      "Giovanna Varricchio",
      "Quentin Vermande",
      "Ernest van Wijland"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.10949"
  },
  {
    "id": "arXiv:2207.10950",
    "title": "Scale dependant layer for self-supervised nuclei encoding",
    "abstract": "Recent developments in self-supervised learning give us the possibility to\nfurther reduce human intervention in multi-step pipelines where the focus\nevolves around particular objects of interest. In the present paper, the focus\nlays in the nuclei in histopathology images. In particular we aim at extracting\ncellular information in an unsupervised manner for a downstream task. As nuclei\npresent themselves in a variety of sizes, we propose a new Scale-dependant\nconvolutional layer to bypass scaling issues when resizing nuclei. On three\nnuclei datasets, we benchmark the following methods: handcrafted, pre-trained\nResNet, supervised ResNet and self-supervised features. We show that the\nproposed convolution layer boosts performance and that this layer combined with\nBarlows-Twins allows for better nuclei encoding compared to the supervised\nparadigm in the low sample setting and outperforms all other proposed\nunsupervised methods. In addition, we extend the existing TNBC dataset to\nincorporate nuclei class annotation in order to enrich and publicly release a\nsmall sample setting dataset for nuclei segmentation and classification.",
    "descriptor": "\nComments: 13 pages, 6 figures, 2 tables\n",
    "authors": [
      "Peter Naylor",
      "Yao-Hung Hubert Tsai",
      "Marick La\u00e9",
      "Makoto Yamada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10950"
  },
  {
    "id": "arXiv:2207.10951",
    "title": "Hyper-Representations for Pre-Training and Transfer Learning",
    "abstract": "Learning representations of neural network weights given a model zoo is an\nemerging and challenging area with many potential applications from model\ninspection, to neural architecture search or knowledge distillation. Recently,\nan autoencoder trained on a model zoo was able to learn a hyper-representation,\nwhich captures intrinsic and extrinsic properties of the models in the zoo. In\nthis work, we extend hyper-representations for generative use to sample new\nmodel weights as pre-training. We propose layer-wise loss normalization which\nwe demonstrate is key to generate high-performing models and a sampling method\nbased on the empirical density of hyper-representations. The models generated\nusing our methods are diverse, performant and capable to outperform\nconventional baselines for transfer learning. Our results indicate the\npotential of knowledge aggregation from model zoos to new models via\nhyper-representations thereby paving the avenue for novel research directions.",
    "descriptor": "",
    "authors": [
      "Konstantin Sch\u00fcrholt",
      "Boris Knyazev",
      "Xavier Gir\u00f3-i-Nieto",
      "Damian Borth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10951"
  },
  {
    "id": "arXiv:2207.10952",
    "title": "Vision-based Human Fall Detection Systems using Deep Learning: A Review",
    "abstract": "Human fall is one of the very critical health issues, especially for elders\nand disabled people living alone. The number of elder populations is increasing\nsteadily worldwide. Therefore, human fall detection is becoming an effective\ntechnique for assistive living for those people. For assistive living, deep\nlearning and computer vision have been used largely. In this review article, we\ndiscuss deep learning (DL)-based state-of-the-art non-intrusive (vision-based)\nfall detection techniques. We also present a survey on fall detection benchmark\ndatasets. For a clear understanding, we briefly discuss different metrics which\nare used to evaluate the performance of the fall detection systems. This\narticle also gives a future direction on vision-based human fall detection\ntechniques.",
    "descriptor": "",
    "authors": [
      "Ekram Alam",
      "Abu Sufian",
      "Paramartha Dutta",
      "Marco Leo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10952"
  },
  {
    "id": "arXiv:2207.10953",
    "title": "Visible and Near Infrared Image Fusion Based on Texture Information",
    "abstract": "Multi-sensor fusion is widely used in the environment perception system of\nthe autonomous vehicle. It solves the interference caused by environmental\nchanges and makes the whole driving system safer and more reliable. In this\npaper, a novel visible and near-infrared fusion method based on texture\ninformation is proposed to enhance unstructured environmental images. It aims\nat the problems of artifact, information loss and noise in traditional visible\nand near infrared image fusion methods. Firstly, the structure information of\nthe visible image (RGB) and the near infrared image (NIR) after texture removal\nis obtained by relative total variation (RTV) calculation as the base layer of\nthe fused image; secondly, a Bayesian classification model is established to\ncalculate the noise weight and the noise information and the noise information\nin the visible image is adaptively filtered by joint bilateral filter; finally,\nthe fused image is acquired by color space conversion. The experimental results\ndemonstrate that the proposed algorithm can preserve the spectral\ncharacteristics and the unique information of visible and near-infrared images\nwithout artifacts and color distortion, and has good robustness as well as\npreserving the unique texture.",
    "descriptor": "\nComments: 10 pages,11 figures\n",
    "authors": [
      "Guanyu Zhang",
      "Beichen Sun",
      "Yuehan Qi",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10953"
  },
  {
    "id": "arXiv:2207.10955",
    "title": "Faster VoxelPose: Real-time 3D Human Pose Estimation by Orthographic  Projection",
    "abstract": "While the voxel-based methods have achieved promising results for\nmulti-person 3D pose estimation from multi-cameras, they suffer from heavy\ncomputation burdens, especially for large scenes. We present Faster VoxelPose\nto address the challenge by re-projecting the feature volume to the three\ntwo-dimensional coordinate planes and estimating X, Y, Z coordinates from them\nseparately. To that end, we first localize each person by a 3D bounding box by\nestimating a 2D box and its height based on the volume features projected to\nthe xy-plane and z-axis, respectively. Then for each person, we estimate\npartial joint coordinates from the three coordinate planes separately which are\nthen fused to obtain the final 3D pose. The method is free from costly 3D-CNNs\nand improves the speed of VoxelPose by ten times and meanwhile achieves\ncompetitive accuracy as the state-of-the-art methods, proving its potential in\nreal-time applications.",
    "descriptor": "\nComments: 22 pages, 7 figures, submitted to ECCV 2022\n",
    "authors": [
      "Hang Ye",
      "Wentao Zhu",
      "Chunyu Wang",
      "Rujie Wu",
      "Yizhou Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10955"
  },
  {
    "id": "arXiv:2207.10959",
    "title": "QueryProp: Object Query Propagation for High-Performance Video Object  Detection",
    "abstract": "Video object detection has been an important yet challenging topic in\ncomputer vision. Traditional methods mainly focus on designing the image-level\nor box-level feature propagation strategies to exploit temporal information.\nThis paper argues that with a more effective and efficient feature propagation\nframework, video object detectors can gain improvement in terms of both\naccuracy and speed. For this purpose, this paper studies object-level feature\npropagation, and proposes an object query propagation (QueryProp) framework for\nhigh-performance video object detection. The proposed QueryProp contains two\npropagation strategies: 1) query propagation is performed from sparse key\nframes to dense non-key frames to reduce the redundant computation on non-key\nframes; 2) query propagation is performed from previous key frames to the\ncurrent key frame to improve feature representation by temporal context\nmodeling. To further facilitate query propagation, an adaptive propagation gate\nis designed to achieve flexible key frame selection. We conduct extensive\nexperiments on the ImageNet VID dataset. QueryProp achieves comparable accuracy\nwith state-of-the-art methods and strikes a decent accuracy/speed trade-off.\nCode is available at https://github.com/hf1995/QueryProp.",
    "descriptor": "\nComments: This paper is accepted to AAAI2022\n",
    "authors": [
      "Fei He",
      "Naiyu Gao",
      "Jian Jia",
      "Xin Zhao",
      "Kaiqi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10959"
  },
  {
    "id": "arXiv:2207.10960",
    "title": "Principal Geodesic Analysis of Merge Trees (and Persistence Diagrams)",
    "abstract": "This paper presents a computational framework for the Principal Geodesic\nAnalysis of merge trees (MT-PGA), a novel adaptation of the celebrated\nPrincipal Component Analysis (PCA) framework [87] to the Wasserstein metric\nspace of merge trees [92]. We formulate MT-PGA computation as a constrained\noptimization problem, aiming at adjusting a basis of orthogonal geodesic axes,\nwhile minimizing a fitting energy. We introduce an efficient, iterative\nalgorithm which exploits shared-memory parallelism, as well as an analytic\nexpression of the fitting energy gradient, to ensure fast iterations. Our\napproach also trivially extends to extremum persistence diagrams. Extensive\nexperiments on public ensembles demonstrate the efficiency of our approach -\nwith MT-PGA computations in the orders of minutes for the largest examples. We\nshow the utility of our contributions by extending to merge trees two typical\nPCA applications. First, we apply MT-PGA to data reduction and reliably\ncompress merge trees by concisely representing them by their first coordinates\nin the MT-PGA basis. Second, we present a dimensionality reduction framework\nexploiting the first two directions of the MT-PGA basis to generate\ntwo-dimensional layouts of the ensemble. We augment these layouts with\npersistence correlation views, enabling global and local visual inspections of\nthe feature variability in the ensemble. In both applications, quantitative\nexperiments assess the relevance of our framework. Finally, we provide a\nlightweight C++ implementation that can be used to reproduce our results.",
    "descriptor": "",
    "authors": [
      "Mathieu Pont",
      "Jules Vidal",
      "Julien Tierny"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10960"
  },
  {
    "id": "arXiv:2207.10967",
    "title": "Head-Related Transfer Function Interpolation from Spatially Sparse  Measurements Using Autoencoder with Source Position Conditioning",
    "abstract": "We propose a method of head-related transfer function (HRTF) interpolation\nfrom sparsely measured HRTFs using an autoencoder with source position\nconditioning. The proposed method is drawn from an analogy between an HRTF\ninterpolation method based on regularized linear regression (RLR) and an\nautoencoder. Through this analogy, we found the key feature of the RLR-based\nmethod that HRTFs are decomposed into source-position-dependent and\nsource-position-independent factors. On the basis of this finding, we design\nthe encoder and decoder so that their weights and biases are generated from\nsource positions. Furthermore, we introduce an aggregation module that reduces\nthe dependence of latent variables on source position for obtaining a\nsource-position-independent representation of each subject. Numerical\nexperiments show that the proposed method can work well for unseen subjects and\nachieve an interpolation performance with only one-eighth measurements\ncomparable to that of the RLR-based method.",
    "descriptor": "\nComments: Accepted to International Workshop on Acoustic Signal Enhancement (IWAENC) 2022\n",
    "authors": [
      "Yuki Ito",
      "Tomohiko Nakamura",
      "Shoichi Koyama",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10967"
  },
  {
    "id": "arXiv:2207.10970",
    "title": "Opportunistic hip fracture risk prediction in Men from X-ray: Findings  from the Osteoporosis in Men (MrOS) Study",
    "abstract": "Osteoporosis is a common disease that increases fracture risk. Hip fractures,\nespecially in elderly people, lead to increased morbidity, decreased quality of\nlife and increased mortality. Being a silent disease before fracture,\nosteoporosis often remains undiagnosed and untreated. Areal bone mineral\ndensity (aBMD) assessed by dual-energy X-ray absorptiometry (DXA) is the\ngold-standard method for osteoporosis diagnosis and hence also for future\nfracture prediction (prognostic). However, the required special equipment is\nnot broadly available everywhere, in particular not to patients in developing\ncountries. We propose a deep learning classification model (FORM) that can\ndirectly predict hip fracture risk from either plain radiographs (X-ray) or 2D\nprojection images of computed tomography (CT) data. Our method is fully\nautomated and therefore well suited for opportunistic screening settings,\nidentifying high risk patients in a broader population without additional\nscreening. FORM was trained and evaluated on X-rays and CT projections from the\nOsteoporosis in Men (MrOS) study. 3108 X-rays (89 incident hip fractures) or\n2150 CTs (80 incident hip fractures) with a 80/20 split were used. We show that\nFORM can correctly predict the 10-year hip fracture risk with a validation AUC\nof 81.44 +- 3.11% / 81.04 +- 5.54% (mean +- STD) including additional\ninformation like age, BMI, fall history and health background across a 5-fold\ncross validation on the X-ray and CT cohort, respectively. Our approach\nsignificantly (p < 0.01) outperforms previous methods like Cox\nProportional-Hazards Model and \\frax with 70.19 +- 6.58 and 74.72 +- 7.21\nrespectively on the X-ray cohort. Our model outperform on both cohorts hip aBMD\nbased predictions. We are confident that FORM can contribute on improving\nosteoporosis diagnosis at an early stage.",
    "descriptor": "\nComments: Accepted at MICCAI 2022 Workshop (PRIME)\n",
    "authors": [
      "Lars Schmarje",
      "Stefan Reinhold",
      "Timo Damm",
      "Eric Orwoll",
      "Claus-C. Gl\u00fcer",
      "Reinhard Koch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10970"
  },
  {
    "id": "arXiv:2207.10971",
    "title": "Learning Human Kinematics by Modeling Temporal Correlations between  Joints for Video-based Human Pose Estimation",
    "abstract": "Estimating human poses from videos is critical in human-computer interaction.\nBy precisely estimating human poses, the robot can provide an appropriate\nresponse to the human. Most existing approaches use the optical flow, RNNs, or\nCNNs to extract temporal features from videos. Despite the positive results of\nthese attempts, most of them only straightforwardly integrate features along\nthe temporal dimension, ignoring temporal correlations between joints. In\ncontrast to previous methods, we propose a plug-and-play kinematics modeling\nmodule (KMM) based on the domain-cross attention mechanism to model the\ntemporal correlation between joints across different frames explicitly.\nSpecifically, the proposed KMM models the temporal correlation between any two\njoints by calculating their temporal similarity. In this way, KMM can learn the\nmotion cues of each joint. Using the motion cues (temporal domain) and\nhistorical positions of joints (spatial domain), KMM can infer the initial\npositions of joints in the current frame in advance. In addition, we present a\nkinematics modeling network (KIMNet) based on the KMM for obtaining the final\npositions of joints by combining pose features and initial positions of joints.\nBy explicitly modeling temporal correlations between joints, KIMNet can infer\nthe occluded joints at present according to all joints at the previous moment.\nFurthermore, the KMM is achieved through an attention mechanism, which allows\nit to maintain the high resolution of features. Therefore, it can transfer rich\nhistorical pose information to the current frame, which provides effective pose\ninformation for locating occluded joints. Our approach achieves\nstate-of-the-art results on two standard video-based pose estimation\nbenchmarks. Moreover, the proposed KIMNet shows some robustness to the\nocclusion, demonstrating the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Yonghao Dang",
      "Jianqin Yin",
      "Shaojie Zhang",
      "Jiping Liu",
      "Yanzhu Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10971"
  },
  {
    "id": "arXiv:2207.10974",
    "title": "Open data hackathon as a tool for increased engagement of Generation Z:  to hack or not to hack?",
    "abstract": "A hackathon is known as a form of civic innovation in which participants\nrepresenting citizens can point out existing problems or social needs and\npropose a solution. Given the high social, technical, and economic potential of\nopen government data, the concept of open data hackathons is becoming popular\naround the world. This concept has become popular in Latvia with the annual\nhackathons organized for a specific cluster of citizens called Generation Z.\nContrary to the general opinion, the organizer suggests that the main goal of\nopen data hackathons to raise an awareness of OGD has been achieved, and there\nhas been a debate about the need to continue them. This study presents the\nlatest findings on the role of open data hackathons and the benefits that they\ncan bring to both the society, participants, and government.",
    "descriptor": "",
    "authors": [
      "Anastasija Nikiforova"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10974"
  },
  {
    "id": "arXiv:2207.10975",
    "title": "Bound-preserving finite element approximations of the Keller-Segel  equations",
    "abstract": "This paper aims to develop numerical approximations of the Keller--Segel\nequations that mimic at the discrete level the lower bounds and the energy law\nof the continuous problem. We solve these equations for two unknowns: the\norganism (or cell) density, which is a positive variable, and the\nchemoattractant density, which is a nonnegative variable. We propose two\nalgorithms, which combine a stabilized finite element method and a\nsemi-implicit time integration. The stabilization consists of a nonlinear\nartificial diffusion that employs a graph-Laplacian operator and a shock\ndetector that localizes local extrema. As a result, both algorithms turn out to\nbe nonlinear.Both algorithms can generate cell and chemoattractant numerical\ndensities fulfilling lower bounds. However, the first algorithm requires a\nsuitable constraint between the space and time discrete parameters, whereas the\nsecond one does not. We design the latter to attain a discrete energy law on\nacute meshes. We report some numerical experiments to validate the theoretical\nresults on blowup and non-blowup phenomena. In the blowup setting, we identify\na \\textit{locking} phenomenon that relates the $L^\\infty(\\Omega)$-norm to the\n$L^1(\\Omega)$-norm limiting the growth of the singularity when supported on a\nmacroelement.",
    "descriptor": "\nComments: 27 pages, 22 figures\n",
    "authors": [
      "Santiago Badia",
      "Jes\u00fas Bonilla",
      "Juan Vicente Guti\u00e9rrez-Santacreu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10975"
  },
  {
    "id": "arXiv:2207.10978",
    "title": "On the stability of totally upwind schemes for the hyperbolic initial  boundary value problem",
    "abstract": "In this paper, we present a numerical strategy to check the strong stability\n(or GKS-stability) of one-step explicit totally upwind scheme in 1D with\nnumerical boundary conditions. The underlying approximated continuous problem\nis a hyperbolic partial differential equation. Our approach is based on the\nUniform Kreiss-Lopatinskii Condition, using linear algebra and complex analysis\nto count the number of zeros of the associated determinant. The study is\nillustrated with the Beam-Warming scheme together with the simplified inverse\nLax-Wendroff procedure at the boundary.",
    "descriptor": "",
    "authors": [
      "Benjamin Boutin",
      "Pierre Le Barbenchon",
      "Nicolas Seguin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10978"
  },
  {
    "id": "arXiv:2207.10979",
    "title": "Cryptanalysis of a system based on Twisted Dihedral Group Algebras",
    "abstract": "Several cryptographic protocols constructed based on less-known algorithmic\nproblems, such as those in non-commutative groups, group rings, semigroups,\netc., which claim quantum security, have been broken through classical\nreduction methods within their specific proposed platforms. A rigorous\nexamination of the complexity of these algorithmic problems is therefore an\nimportant topic of research. In this paper, we present a cryptanalysis of a\npublic key exchange system based on a decomposition-type problem in the\nso-called twisted group algebras of the dihedral group $D_{2n}$ over a finite\nfield $\\fq$. Our method of analysis relies on an algebraic reduction of the\noriginal problem to a set of equations over $\\fq$ involving circulant matrices,\nand a subsequent solution to these equations. Our attack runs in polynomial\ntime and succeeds with probability at least $90$ percent for the parameter\nvalues provided by the authors. We also show that the underlying algorithmic\nproblem, while based on a non-commutative structure, may be formulated as a\ncommutative semigroup action problem.",
    "descriptor": "",
    "authors": [
      "Simran Tinani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2207.10979"
  },
  {
    "id": "arXiv:2207.10982",
    "title": "WRHT: Efficient All-reduce for Distributed DNN Training in Optical  Interconnect System",
    "abstract": "Communication efficiency plays an important role in accelerating the\ndistributed training of Deep Neural Networks (DNN). All-reduce is the key\ncommunication primitive to reduce model parameters in distributed DNN training.\nMost existing all-reduce algorithms are designed for traditional electrical\ninterconnect systems, which cannot meet the communication requirements for\ndistributed training of large DNNs. One of the promising alternatives for\nelectrical interconnect is optical interconnect, which can provide high\nbandwidth, low transmission delay, and low power cost. We propose an efficient\nscheme called WRHT (Wavelength Reused Hierarchical Tree) for implementing\nall-reduce operation in optical interconnect system, which can take advantage\nof WDM (Wavelength Division Multiplexing) to reduce the communication time of\ndistributed data-parallel DNN training. We further derive the minimum number of\ncommunication steps and communication time to realize the all-reduce using\nWRHT. Simulation results show that the communication time of WRHT is reduced by\n75.59%, 49.25%, and 70.1% respectively compared with three traditional\nall-reduce algorithms simulated in optical interconnect system. Simulation\nresults also show that WRHT can reduce the communication time for all-reduce\noperation by 86.69% and 84.71% in comparison with two existing all-reduce\nalgorithms in electrical interconnect system.",
    "descriptor": "\nComments: This paper is under the submission of GLOBECOM 2022\n",
    "authors": [
      "Fei Dai",
      "Yawen Chen",
      "Zhiyi Huang",
      "Haibo Zhang",
      "Fangfang Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2207.10982"
  },
  {
    "id": "arXiv:2207.10983",
    "title": "Two-Port Feedback Analysis On Miller-Compensated Amplifiers",
    "abstract": "In this paper, various Miller-compensated amplifiers are analyzed by using\nthe two-port feedback analysis together with the root-locus diagram. The\nproposed analysis solves problems of Miller theorem/approximation that fail to\npredict a pole-splitting and that require an impractical assumption that an\ninitial lower frequency pole before connecting a Miller capacitor in a\ntwo-stage amplifier should be associated with the input of the amplifier. Since\nthe proposed analysis sheds light on how the closed-loop poles originate from\nthe open-loop poles in the s-plane, it allows the association of the\nclosed-loop poles with the circuit components and thus provides a design\ninsight for frequency compensation. The circuits analyzed are two-stage\nMiller-compensated amplifiers with and without a current buffer and a\nthree-stage nested Miller-compensated amplifier.",
    "descriptor": "",
    "authors": [
      "Myungjun Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10983"
  },
  {
    "id": "arXiv:2207.10985",
    "title": "NeurAR: Neural Uncertainty for Autonomous 3D Reconstruction",
    "abstract": "Implicit neural representations have shown compelling results in offline 3D\nreconstruction and also recently demonstrated the potential for online SLAM\nsystems. However, applying them to autonomous 3D reconstruction, where robots\nare required to explore a scene and plan a view path for the reconstruction,\nhas not been studied. In this paper, we explore for the first time the\npossibility of using implicit neural representations for autonomous 3D scene\nreconstruction by addressing two key challenges: 1) seeking a criterion to\nmeasure the quality of the candidate viewpoints for the view planning based on\nthe new representations, and 2) learning the criterion from data that can\ngeneralize to different scenes instead of hand-crafting one. For the first\nchallenge, a proxy of Peak Signal-to-Noise Ratio (PSNR) is proposed to quantify\na viewpoint quality. The proxy is acquired by treating the color of a spatial\npoint in a scene as a random variable under a Gaussian distribution rather than\na deterministic one; the variance of the distribution quantifies the\nuncertainty of the reconstruction and composes the proxy. For the second\nchallenge, the proxy is optimized jointly with the parameters of an implicit\nneural network for the scene. With the proposed view quality criterion, we can\nthen apply the new representations to autonomous 3D reconstruction. Our method\ndemonstrates significant improvements on various metrics for the rendered image\nquality and the geometry quality of the reconstructed 3D models when compared\nwith variants using TSDF or reconstruction without view planning.",
    "descriptor": "\nComments: 8 pages, 6 figures, 2 tables\n",
    "authors": [
      "Yunlong Ran",
      "Jing Zeng",
      "Shibo He",
      "Lincheng Li",
      "Yingfeng Chen",
      "Gimhee Lee",
      "Jiming Chen",
      "Qi Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10985"
  },
  {
    "id": "arXiv:2207.10988",
    "title": "Few-shot Object Counting and Detection",
    "abstract": "We tackle a new task of few-shot object counting and detection. Given a few\nexemplar bounding boxes of a target object class, we seek to count and detect\nall objects of the target class. This task shares the same supervision as the\nfew-shot object counting but additionally outputs the object bounding boxes\nalong with the total object count. To address this challenging problem, we\nintroduce a novel two-stage training strategy and a novel uncertainty-aware\nfew-shot object detector: Counting-DETR. The former is aimed at generating\npseudo ground-truth bounding boxes to train the latter. The latter leverages\nthe pseudo ground-truth provided by the former but takes the necessary steps to\naccount for the imperfection of pseudo ground-truth. To validate the\nperformance of our method on the new task, we introduce two new datasets named\nFSCD-147 and FSCD-LVIS. Both datasets contain images with complex scenes,\nmultiple object classes per image, and a huge variation in object shapes,\nsizes, and appearance. Our proposed approach outperforms very strong baselines\nadapted from few-shot object counting and few-shot object detection with a\nlarge margin in both counting and detection metrics. The code and models are\navailable at \\url{https://github.com/VinAIResearch/Counting-DETR}.",
    "descriptor": "\nComments: Accepted to ECCV 2020; The first two authors contributed equally\n",
    "authors": [
      "Thanh Nguyen",
      "Chau Pham",
      "Khoi Nguyen",
      "Minh Hoai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10988"
  },
  {
    "id": "arXiv:2207.10991",
    "title": "Algorithmic Fairness in Business Analytics: Directions for Research and  Practice",
    "abstract": "The extensive adoption of business analytics (BA) has brought financial gains\nand increased efficiencies. However, these advances have simultaneously drawn\nattention to rising legal and ethical challenges when BA inform decisions with\nfairness implications. As a response to these concerns, the emerging study of\nalgorithmic fairness deals with algorithmic outputs that may result in\ndisparate outcomes or other forms of injustices for subgroups of the\npopulation, especially those who have been historically marginalized. Fairness\nis relevant on the basis of legal compliance, social responsibility, and\nutility; if not adequately and systematically addressed, unfair BA systems may\nlead to societal harms and may also threaten an organization's own survival,\nits competitiveness, and overall performance. This paper offers a\nforward-looking, BA-focused review of algorithmic fairness. We first review the\nstate-of-the-art research on sources and measures of bias, as well as bias\nmitigation algorithms. We then provide a detailed discussion of the\nutility-fairness relationship, emphasizing that the frequent assumption of a\ntrade-off between these two constructs is often mistaken or short-sighted.\nFinally, we chart a path forward by identifying opportunities for business\nscholars to address impactful, open challenges that are key to the effective\nand responsible deployment of BA.",
    "descriptor": "",
    "authors": [
      "Maria De-Arteaga",
      "Stefan Feuerriegel",
      "Maytal Saar-Tsechansky"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10991"
  },
  {
    "id": "arXiv:2207.10992",
    "title": "Taguchi based Design of Sequential Convolution Neural Network for  Classification of Defective Fasteners",
    "abstract": "Fasteners play a critical role in securing various parts of machinery.\nDeformations such as dents, cracks, and scratches on the surface of fasteners\nare caused by material properties and incorrect handling of equipment during\nproduction processes. As a result, quality control is required to ensure safe\nand reliable operations. The existing defect inspection method relies on manual\nexamination, which consumes a significant amount of time, money, and other\nresources; also, accuracy cannot be guaranteed due to human error. Automatic\ndefect detection systems have proven impactful over the manual inspection\ntechnique for defect analysis. However, computational techniques such as\nconvolutional neural networks (CNN) and deep learning-based approaches are\nevolutionary methods. By carefully selecting the design parameter values, the\nfull potential of CNN can be realised. Using Taguchi-based design of\nexperiments and analysis, an attempt has been made to develop a robust\nautomatic system in this study. The dataset used to train the system has been\ncreated manually for M14 size nuts having two labeled classes: Defective and\nNon-defective. There are a total of 264 images in the dataset. The proposed\nsequential CNN comes up with a 96.3% validation accuracy, 0.277 validation loss\nat 0.001 learning rate.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Manjeet Kaur",
      "Krishan Kumar Chauhan",
      "Tanya Aggarwal",
      "Pushkar Bharadwaj",
      "Renu Vig",
      "Isibor Kennedy Ihianle",
      "Garima Joshi",
      "Kayode Owa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10992"
  },
  {
    "id": "arXiv:2207.10993",
    "title": "Wentzel--Kramers--Brillouin Expansions and Generalized Impedance  Transmission Conditions for Thin-Layer Problems in Electromagnetism with  Application to Biological Cells",
    "abstract": "In this work we derive a WKB expansion for the electromagnetic fields\nsolution of the time-harmonic Maxwell equations set in a domain with a thin\nlayer. As a by-product of this expansion we obtain new second order asymptotic\nmodels with generalized impedance transmission conditions that turn out to\ndepend on the mean curvature of the boundary of the subdomain surrounded by the\nthin layer. We show that these models can be easily integrated in finite\nelement methods by developing mixed variational formulations. One application\nof this work concerns the computation of the electromagnetic field in\nbiological cells.",
    "descriptor": "",
    "authors": [
      "Victor P\u00e9ron"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10993"
  },
  {
    "id": "arXiv:2207.10994",
    "title": "Learning Generalized Non-Rigid Multimodal Biomedical Image Registration  from Generic Point Set Data",
    "abstract": "Free Point Transformer (FPT) has been proposed as a data-driven, non-rigid\npoint set registration approach using deep neural networks. As FPT does not\nassume constraints based on point vicinity or correspondence, it may be trained\nsimply and in a flexible manner by minimizing an unsupervised loss based on the\nChamfer Distance. This makes FPT amenable to real-world medical imaging\napplications where ground-truth deformations may be infeasible to obtain, or in\nscenarios where only a varying degree of completeness in the point sets to be\naligned is available. To test the limit of the correspondence finding ability\nof FPT and its dependency on training data sets, this work explores the\ngeneralizability of the FPT from well-curated non-medical data sets to medical\nimaging data sets. First, we train FPT on the ModelNet40 dataset to demonstrate\nits effectiveness and the superior registration performance of FPT over\niterative and learning-based point set registration methods. Second, we\ndemonstrate superior performance in rigid and non-rigid registration and\nrobustness to missing data. Last, we highlight the interesting generalizability\nof the ModelNet-trained FPT by registering reconstructed freehand ultrasound\nscans of the spine and generic spine models without additional training,\nwhereby the average difference to the ground truth curvatures is 1.3 degrees,\nacross 13 patients.",
    "descriptor": "\nComments: Accepted to ASMUS 2022 Workshop at MICCAI\n",
    "authors": [
      "Zachary MC Baum",
      "Tamas Ungi",
      "Christopher Schlenger",
      "Yipeng Hu",
      "Dean C Barratt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10994"
  },
  {
    "id": "arXiv:2207.10996",
    "title": "Meta-Registration: Learning Test-Time Optimization for Single-Pair Image  Registration",
    "abstract": "Neural networks have been proposed for medical image registration by\nlearning, with a substantial amount of training data, the optimal\ntransformations between image pairs. These trained networks can further be\noptimized on a single pair of test images - known as test-time optimization.\nThis work formulates image registration as a meta-learning algorithm. Such\nnetworks can be trained by aligning the training image pairs while\nsimultaneously improving test-time optimization efficacy; tasks which were\npreviously considered two independent training and optimization processes. The\nproposed meta-registration is hypothesized to maximize the efficiency and\neffectiveness of the test-time optimization in the \"outer\" meta-optimization of\nthe networks. For image guidance applications that often are time-critical yet\nlimited in training data, the potentially gained speed and accuracy are\ncompared with classical registration algorithms, registration networks without\nmeta-learning, and single-pair optimization without test-time optimization\ndata. Experiments are presented in this paper using clinical transrectal\nultrasound image data from 108 prostate cancer patients. These experiments\ndemonstrate the effectiveness of a meta-registration protocol, which yields\nsignificantly improved performance relative to existing learning-based methods.\nFurthermore, the meta-registration achieves comparable results to classical\niterative methods in a fraction of the time, owing to its rapid test-time\noptimization process.",
    "descriptor": "\nComments: Accepted to ASMUS 2022 Workshop at MICCAI\n",
    "authors": [
      "Zachary MC Baum",
      "Yipeng Hu",
      "Dean C Barratt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10996"
  },
  {
    "id": "arXiv:2207.10999",
    "title": "Applying Machine Learning on RSRP-based Features for False Base Station  Detection",
    "abstract": "False base stations -- IMSI catchers, Stingrays -- are devices that\nimpersonate legitimate base stations, as a part of malicious activities like\nunauthorized surveillance or communication sabotage. Detecting them on the\nnetwork side using 3GPP standardized measurement reports is a promising\ntechnique. While applying predetermined detection rules works well when an\nattacker operates a false base station with an illegitimate Physical Cell\nIdentifiers (PCI), the detection will produce false negatives when a more\nresourceful attacker operates the false base station with one of the legitimate\nPCIs obtained by scanning the neighborhood first. In this paper, we show how\nMachine Learning (ML) can be applied to alleviate such false negatives. We\ndemonstrate our approach by conducting experiments in a simulation setup using\nthe ns-3 LTE module. We propose three robust ML features (COL, DIST, XY) based\non Reference Signal Received Power (RSRP) contained in measurement reports and\ncell locations. We evaluate four ML models (Regression Clustering, Anomaly\nDetection Forest, Autoencoder, and RCGAN) and show that several of them have a\nhigh precision in detection even when the false base station is using a\nlegitimate PCI. In our experiments with a layout of 12 cells, where one cell\nacts as a moving false cell, between 75-95\\% of the false positions are\ndetected by the best model at a cost of 0.5\\% false positives.",
    "descriptor": "\nComments: 9 pages,5 figure, 3 tables, 2 algorithms\n",
    "authors": [
      "Prajwol Kumar Nakarmi",
      "Jakob Sternby",
      "Ikram Ullah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10999"
  },
  {
    "id": "arXiv:2207.11000",
    "title": "Natural Colors of Infinite Words",
    "abstract": "While finite automata have minimal DFAs as a simple and natural normal form,\ndeterministic omega-automata do not currently have anything similar. One reason\nfor this is that a normal form for omega-regular languages has to speak about\nmore than acceptance - for example, to have a normal form for a parity\nlanguage, it should relate every infinite word to some natural color for this\nlanguage. This raises the question of whether or not a concept such as a\nnatural color of an infinite word (for a given language) exists, and, if it\ndoes, how it relates back to automata.\nWe define the natural color of a word purely based on an omega-regular\nlanguage, and show how this natural color can be traced back from any\ndeterministic parity automaton after two cheap and simple automaton\ntransformations. The resulting streamlined automaton does not necessarily\naccept every word with its natural color, but it has a 'co-run', which is like\na run, but can once move to a language equivalent state, whose color is the\nnatural color, and no co-run with a higher color exists.\nThe streamlined automaton defines, for every color c, a good-for-games\nco-B\\\"uchi automaton that recognizes the words whose natural colors w.r.t. the\nrepresented language are at least c. This provides a canonical representation\nfor every $\\omega$-regular language, because good-for-games co-B\\\"uchi automata\nhave a canonical minimal (and cheap to obtain) representation for every\nco-B\\\"uchi language.",
    "descriptor": "",
    "authors": [
      "R\u00fcdiger Ehlers",
      "Sven Schewe"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.11000"
  },
  {
    "id": "arXiv:2207.11001",
    "title": "POP: Mining POtential Performance of new fashion products via webly  cross-modal query expansion",
    "abstract": "We propose a data-centric pipeline able to generate exogenous observation\ndata for the New Fashion Product Performance Forecasting (NFPPF) problem, i.e.,\npredicting the performance of a brand-new clothing probe with no available past\nobservations. Our pipeline manufactures the missing past starting from a\nsingle, available image of the clothing probe. It starts by expanding textual\ntags associated with the image, querying related fashionable or unfashionable\nimages uploaded on the web at a specific time in the past. A binary classifier\nis robustly trained on these web images by confident learning, to learn what\nwas fashionable in the past and how much the probe image conforms to this\nnotion of fashionability. This compliance produces the POtential Performance\n(POP) time series, indicating how performing the probe could have been if it\nwere available earlier. POP proves to be highly predictive for the probe's\nfuture performance, ameliorating the sales forecasts of all state-of-the-art\nmodels on the recent VISUELLE fast-fashion dataset. We also show that POP\nreflects the ground-truth popularity of new styles (ensembles of clothing\nitems) on the Fashion Forward benchmark, demonstrating that our webly-learned\nsignal is a truthful expression of popularity, accessible by everyone and\ngeneralizable to any time of analysis. Forecasting code, data and the POP time\nseries are available at:\nhttps://github.com/HumaticsLAB/POP-Mining-POtential-Performance",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Christian Joppi",
      "Geri Skenderi",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11001"
  },
  {
    "id": "arXiv:2207.11005",
    "title": "Revisiting Parameter Reuse to Overcome Catastrophic Forgetting in Neural  Networks",
    "abstract": "Neural networks tend to forget previously learned knowledge when continuously\nlearning on datasets with varying distributions, a phenomenon known as\ncatastrophic forgetting. More significant distribution shifts among datasets\nlead to more forgetting. Recently, parameter-isolation-based approaches have\nshown great potential in overcoming forgetting with significant distribution\nshifts. However, they suffer from poor generalization as they fix the neural\npath for each dataset during training and require dataset labels during\ninference. In addition, they do not support backward knowledge transfer as they\nprioritize past data over future ones. In this paper, we propose a new adaptive\nlearning method, named AdaptCL, that fully reuses and grows on learned\nparameters to overcome catastrophic forgetting and allows the positive backward\ntransfer without requiring dataset labels. Our proposed technique adaptively\ngrows on the same neural path by allowing optimal reuse of frozen parameters.\nBesides, it uses parameter-level data-driven pruning to assign equal priority\nto the data. We conduct extensive experiments on MNIST Variants, DomainNet, and\nFood Freshness Detection datasets under different intensities of distribution\nshifts without requiring dataset labels. Results demonstrate that our proposed\nmethod is superior to alternative baselines in minimizing forgetting and\nenabling positive backward knowledge transfer.",
    "descriptor": "",
    "authors": [
      "Yuqing Zhao",
      "Divya Saxena",
      "Jiannong Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11005"
  },
  {
    "id": "arXiv:2207.11007",
    "title": "Gradual Drift Detection in Process Models Using Conformance Metrics",
    "abstract": "Changes, planned or unexpected, are common during the execution of real-life\nprocesses. Detecting these changes is a must for optimizing the performance of\norganizations running such processes. Most of the algorithms present in the\nstate-of-the-art focus on the detection of sudden changes, leaving aside other\ntypes of changes. In this paper, we will focus on the automatic detection of\ngradual drifts, a special type of change, in which the cases of two models\noverlap during a period of time. The proposed algorithm relies on conformance\nchecking metrics to carry out the automatic detection of the changes,\nperforming also a fully automatic classification of these changes into sudden\nor gradual. The approach has been validated with a synthetic dataset consisting\nof 120 logs with different distributions of changes, getting better results in\nterms of detection and classification accuracy, delay and change region\noverlapping than the main state-of-the-art algorithms.",
    "descriptor": "",
    "authors": [
      "Victor Gallego-Fontenla",
      "Juan C. Vidal",
      "Manuel Lama"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.11007"
  },
  {
    "id": "arXiv:2207.11012",
    "title": "Fact sheet: Automatic Self-Reported Personality Recognition Track",
    "abstract": "We propose an informed baseline to help disentangle the various contextual\nfactors of influence in this type of case studies. For this purpose, we\nanalysed the correlation between the given metadata and the self-assigned\npersonality trait scores and developed a model based solely on this\ninformation. Further, we compared the performance of this informed baseline\nwith models based on state-of-the-art visual, linguistic and audio features.\nFor the present dataset, a model trained solely on simple metadata features\n(age, gender and number of sessions) proved to have superior or similar\nperformance when compared with simple audio, linguistic or visual\nfeatures-based systems.",
    "descriptor": "",
    "authors": [
      "Francisca Pessanha",
      "Gizem Sogancioglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11012"
  },
  {
    "id": "arXiv:2207.11015",
    "title": "A new class of negabent functions",
    "abstract": "Negabent functions were introduced as a generalization of bent functions,\nwhich have applications in coding theory and cryptography. In this paper, we\nhave extended the notion of negabent functions to the functions defined from\n$\\mathbb{Z}_q^n$ to $\\mathbb{Z}_{2q}$ ($2q$-negabent), where $q \\geq 2$ is a\npositive integer and $\\mathbb{Z}_q$ is the ring of integers modulo $q$. For\nthis, a new unitary transform (the nega-Hadamard transform) is introduced in\nthe current set up, and some of its properties are discussed. Some results\nrelated to $2q$-negabent functions are presented. We present two constructions\nof $2q$-negabent functions. In the first construction, $2q$-negabent functions\non $n$ variables are constructed when $q$ is an even positive integer. In the\nsecond construction, $2q$-negabent functions on two variables are constructed\nfor arbitrary positive integer $q \\ge 2$. Some examples of $2q$-negabent\nfunctions for different values of $q$ and $n$ are also presented.",
    "descriptor": "",
    "authors": [
      "Deep Singh",
      "Maheshanand Bhaintwal"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.11015"
  },
  {
    "id": "arXiv:2207.11016",
    "title": "Search-based Software Testing Driven by Automatically Generated and  Manually Defined Fitness Functions",
    "abstract": "Search-based software testing (SBST) typically relies on fitness functions to\nguide the search exploration toward software failures. There are two main\ntechniques to define fitness functions: (a) automated fitness function\ncomputation from the specification of the system requirements and (b) manual\nfitness function design. Both techniques have advantages. The former uses\ninformation from the system requirements to guide the search toward portions of\nthe input domain that are more likely to contain failures. The latter uses the\nengineers' domain knowledge. We propose ATheNA, a novel SBST framework that\ncombines fitness functions that are automatically generated from requirements\nspecifications and manually defined by engineers. We design and implement\nATheNA-S, an instance of ATheNA that targets Simulink models. We evaluate\nATheNA-S by considering a large set of models and requirements from different\ndomains. We compare our solution with an SBST baseline tool that supports\nautomatically generated fitness functions, and another one that supports\nmanually defined fitness functions. Our results show that ATheNA-S generates\nmore failure-revealing test cases than the baseline tools and that the\ndifference between the performance of ATheNA-S and the baseline tools is not\nstatistically significant. We also assess whether ATheNA-S could generate\nfailure-revealing test cases when applied to a large case study from the\nautomotive domain. Our results show that ATheNA-S successfully revealed a\nrequirement violation in our case study.",
    "descriptor": "",
    "authors": [
      "Federico Formica",
      "Mehrnoosh Askarpour",
      "Claudio Menghi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.11016"
  },
  {
    "id": "arXiv:2207.11018",
    "title": "Learning from what we know: How to perform vulnerability prediction  using noisy historical data",
    "abstract": "Vulnerability prediction refers to the problem of identifying system\ncomponents that are most likely to be vulnerable. Typically, this problem is\ntackled by training binary classifiers on historical data. Unfortunately,\nrecent research has shown that such approaches underperform due to the\nfollowing two reasons: a) the imbalanced nature of the problem, and b) the\ninherently noisy historical data, i.e., most vulnerabilities are discovered\nmuch later than they are introduced. This misleads classifiers as they learn to\nrecognize actual vulnerable components as non-vulnerable. To tackle these\nissues, we propose TROVON, a technique that learns from known vulnerable\ncomponents rather than from vulnerable and non-vulnerable components, as\ntypically performed. We perform this by contrasting the known vulnerable, and\ntheir respective fixed components. This way, TROVON manages to learn from the\nthings we know, i.e., vulnerabilities, hence reducing the effects of noisy and\nunbalanced data. We evaluate TROVON by comparing it with existing techniques on\nthree security-critical open source systems, i.e., Linux Kernel, OpenSSL, and\nWireshark, with historical vulnerabilities that have been reported in the\nNational Vulnerability Database (NVD). Our evaluation demonstrates that the\nprediction capability of TROVON significantly outperforms existing\nvulnerability prediction techniques such as Software Metrics, Imports, Function\nCalls, Text Mining, Devign, LSTM, and LSTM-RF with an improvement of 40.84% in\nMatthews Correlation Coefficient (MCC) score under Clean Training Data\nSettings, and an improvement of 35.52% under Realistic Training Data Settings.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.11701\n",
    "authors": [
      "Aayush Garg",
      "Renzo Degiovanni",
      "Matthieu Jimenez",
      "Maxime Cordy",
      "Mike Papadakis",
      "Yves LeTraon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.11018"
  },
  {
    "id": "arXiv:2207.11019",
    "title": "Layer-Wise Partitioning and Merging for Efficient and Scalable Deep  Learning",
    "abstract": "Deep Neural Network (DNN) models are usually trained sequentially from one\nlayer to another, which causes forward, backward and update locking's problems,\nleading to poor performance in terms of training time. The existing parallel\nstrategies to mitigate these problems provide suboptimal runtime performance.\nIn this work, we have proposed a novel layer-wise partitioning and merging,\nforward and backward pass parallel framework to provide better training\nperformance. The novelty of the proposed work consists of 1) a layer-wise\npartition and merging model which can minimise communication overhead between\ndevices without the memory cost of existing strategies during the training\nprocess; 2) a forward pass and backward pass parallelisation and optimisation\nto address the update locking problem and minimise the total training cost. The\nexperimental evaluation on real use cases shows that the proposed method\noutperforms the state-of-the-art approaches in terms of training speed; and\nachieves almost linear speedup without compromising the accuracy performance of\nthe non-parallel approach.",
    "descriptor": "",
    "authors": [
      "Samson B. Akintoye",
      "Liangxiu Han",
      "Huw Lloyd",
      "Xin Zhang",
      "Darren Dancey",
      "Haoming Chen",
      "Daoqiang Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11019"
  },
  {
    "id": "arXiv:2207.11020",
    "title": "Open video data sharing in developmental and behavioural science",
    "abstract": "Video recording is a widely used method for documenting infant and child\nbehaviours in research and clinical practice. Video data has rarely been shared\ndue to ethical concerns of confidentiality, although the need of shared\nlarge-scaled datasets remains increasing. This demand is even more imperative\nwhen data-driven computer-based approaches are involved, such as screening\ntools to complement clinical assessments. To share data while abiding by\nprivacy protection rules, a critical question arises whether efforts at data\nde-identification reduce data utility? We addressed this question by showcasing\nthe Prechtl's general movements assessment (GMA), an established and globally\npractised video-based diagnostic tool in early infancy for detecting\nneurological deficits, such as cerebral palsy. To date, no shared\nexpert-annotated large data repositories for infant movement analyses exist.\nSuch datasets would massively benefit training and recalibration of human\nassessors and the development of computer-based approaches. In the current\nstudy, sequences from a prospective longitudinal infant cohort with a total of\n19451 available general movements video snippets were randomly selected for\nhuman clinical reasoning and computer-based analysis. We demonstrated for the\nfirst time that pseudonymisation by face-blurring video recordings is a viable\napproach. The video redaction did not affect classification accuracy for either\nhuman assessors or computer vision methods, suggesting an adequate and\neasy-to-apply solution for sharing movement video data. We call for further\nexplorations into efficient and privacy rule-conforming approaches for\ndeidentifying video data in scientific and clinical fields beyond movement\nassessments. These approaches shall enable sharing and merging stand-alone\nvideo datasets into large data pools to advance science and public health.",
    "descriptor": "",
    "authors": [
      "Peter B Marschik",
      "Tomas Kulvicius",
      "Sarah Fl\u00fcgge",
      "Claudius Widmann",
      "Karin Nielsen-Saines",
      "Martin Schulte-R\u00fcther",
      "Britta H\u00fcning",
      "Sven B\u00f6lte",
      "Luise Poustka",
      "Jeff Sigafoos",
      "Florentin W\u00f6rg\u00f6tter",
      "Christa Einspieler",
      "Dajie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.11020"
  },
  {
    "id": "arXiv:2207.11025",
    "title": "Custom Structure Preservation in Face Aging",
    "abstract": "In this work, we propose a novel architecture for face age editing that can\nproduce structural modifications while maintaining relevant details present in\nthe original image. We disentangle the style and content of the input image and\npropose a new decoder network that adopts a style-based strategy to combine the\nstyle and content representations of the input image while conditioning the\noutput on the target age. We go beyond existing aging methods allowing users to\nadjust the degree of structure preservation in the input image during\ninference. To this purpose, we introduce a masking mechanism, the CUstom\nStructure Preservation module, that distinguishes relevant regions in the input\nimage from those that should be discarded. CUSP requires no additional\nsupervision. Finally, our quantitative and qualitative analysis which include a\nuser study, show that our method outperforms prior art and demonstrates the\neffectiveness of our strategy regarding image editing and adjustable structure\npreservation. Code and pretrained models are available at\nhttps://github.com/guillermogotre/CUSP.",
    "descriptor": "\nComments: 36 pages, 21 figures\n",
    "authors": [
      "Guillermo Gomez-Trenado",
      "St\u00e9phane Lathuili\u00e8re",
      "Pablo Mesejo",
      "\u00d3scar Cord\u00f3n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11025"
  },
  {
    "id": "arXiv:2207.11030",
    "title": "A Transferable Intersection Reconstruction Network for Traffic Speed  Prediction",
    "abstract": "Traffic speed prediction is the key to many valuable applications, and it is\nalso a challenging task because of its various influencing factors. Recent work\nattempts to obtain more information through various hybrid models, thereby\nimproving the prediction accuracy. However, the spatial information acquisition\nschemes of these methods have two-level differentiation problems. Either the\nmodeling is simple but contains little spatial information, or the modeling is\ncomplete but lacks flexibility. In order to introduce more spatial information\non the basis of ensuring flexibility, this paper proposes IRNet (Transferable\nIntersection Reconstruction Network). First, this paper reconstructs the\nintersection into a virtual intersection with the same structure, which\nsimplifies the topology of the road network. Then, the spatial information is\nsubdivided into intersection information and sequence information of traffic\nflow direction, and spatiotemporal features are obtained through various\nmodels. Third, a self-attention mechanism is used to fuse spatiotemporal\nfeatures for prediction. In the comparison experiment with the baseline, not\nonly the prediction effect, but also the transfer performance has obvious\nadvantages.",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Pengyu Fu",
      "Liang Chu",
      "Zhuoran Hou",
      "Jincheng Hu",
      "Yanjun Huang",
      "Yuanjian Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11030"
  },
  {
    "id": "arXiv:2207.11031",
    "title": "MobileDenseNet: A new approach to object detection on mobile devices",
    "abstract": "Object detection problem solving has developed greatly within the past few\nyears. There is a need for lighter models in instances where hardware\nlimitations exist, as well as a demand for models to be tailored to mobile\ndevices. In this article, we will assess the methods used when creating\nalgorithms that address these issues. The main goal of this article is to\nincrease accuracy in state-of-the-art algorithms while maintaining speed and\nreal-time efficiency. The most significant issues in one-stage object detection\npertains to small objects and inaccurate localization. As a solution, we\ncreated a new network by the name of MobileDenseNet suitable for embedded\nsystems. We also developed a light neck FCPNLite for mobile devices that will\naid with the detection of small objects. Our research revealed that very few\npapers cited necks in embedded systems. What differentiates our network from\nothers is our use of concatenation features. A small yet significant change to\nthe head of the network amplified accuracy without increasing speed or limiting\nparameters. In short, our focus on the challenging CoCo and Pascal VOC datasets\nwere 24.8 and 76.8 in percentage terms respectively - a rate higher than that\nrecorded by other state-of-the-art systems thus far. Our network is able to\nincrease accuracy while maintaining real-time efficiency on mobile devices. We\ncalculated operational speed on Pixel 3 (Snapdragon 845) to 22.8 fps. The\nsource code of this research is available on\nhttps://github.com/hajizadeh/MobileDenseNet.",
    "descriptor": "",
    "authors": [
      "Mohammad Hajizadeh",
      "Mohammad Sabokrou",
      "Adel Rahmani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.11031"
  },
  {
    "id": "arXiv:2207.11033",
    "title": "GesSure -- A Robust Face-Authentication enabled Dynamic Gesture  Recognition GUI Application",
    "abstract": "Using physical interactive devices like mouse and keyboards hinders\nnaturalistic human-machine interaction and increases the probability of surface\ncontact during a pandemic. Existing gesture-recognition systems do not possess\nuser authentication, making them unreliable. Static gestures in current\ngesture-recognition technology introduce long adaptation periods and reduce\nuser compatibility. Our technology places a strong emphasis on user recognition\nand safety. We use meaningful and relevant gestures for task operation,\nresulting in a better user experience. This paper aims to design a robust,\nface-verification-enabled gesture recognition system that utilizes a graphical\nuser interface and primarily focuses on security through user recognition and\nauthorization. The face model uses MTCNN and FaceNet to verify the user, and\nour LSTM-CNN architecture for gesture recognition, achieving an accuracy of 95%\nwith five classes of gestures. The prototype developed through our research has\nsuccessfully executed context-dependent tasks like save, print, control\nvideo-player operations and exit, and context-free operating system tasks like\nsleep, shut-down, and unlock intuitively. Our application and dataset are\navailable as open source.",
    "descriptor": "\nComments: Accepted at International Conference on Artificial Intelligence Advances (AIAD 2022)\n",
    "authors": [
      "Ankit Jha",
      "Ishita Pratham G. Shenwai",
      "Ayush Batra",
      "Siddharth Kotian",
      "Piyush Modi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11033"
  },
  {
    "id": "arXiv:2207.11034",
    "title": "Spatial-Temporal Feature Extraction and Evaluation Network for Citywide  Traffic Condition Prediction",
    "abstract": "Traffic prediction plays an important role in the realization of traffic\ncontrol and scheduling tasks in intelligent transportation systems. With the\ndiversification of data sources, reasonably using rich traffic data to model\nthe complex spatial-temporal dependence and nonlinear characteristics in\ntraffic flow are the key challenge for intelligent transportation system. In\naddition, clearly evaluating the importance of spatial-temporal features\nextracted from different data becomes a challenge. A Double Layer - Spatial\nTemporal Feature Extraction and Evaluation (DL-STFEE) model is proposed. The\nlower layer of DL-STFEE is spatial-temporal feature extraction layer. The\nspatial and temporal features in traffic data are extracted by multi-graph\ngraph convolution and attention mechanism, and different combinations of\nspatial and temporal features are generated. The upper layer of DL-STFEE is the\nspatial-temporal feature evaluation layer. Through the attention score matrix\ngenerated by the high-dimensional self-attention mechanism, the\nspatial-temporal features combinations are fused and evaluated, so as to get\nthe impact of different combinations on prediction effect. Three sets of\nexperiments are performed on actual traffic datasets to show that DL-STFEE can\neffectively capture the spatial-temporal features and evaluate the importance\nof different spatial-temporal feature combinations.",
    "descriptor": "\nComments: 39 pages, 14 figures, 5 tables\n",
    "authors": [
      "Shilin Pu",
      "Liang Chu",
      "Zhuoran Hou",
      "Jincheng Hu",
      "Yanjun Huang",
      "Yuanjian Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11034"
  },
  {
    "id": "arXiv:2207.11036",
    "title": "NISTT: A Non-Intrusive SystemC-TLM 2.0 Tracing Tool",
    "abstract": "The increasing complexity of systems-on-a-chip requires the continuous\ndevelopment of electronic design automation tools. Nowadays, the simulation of\nsystems-on-a-chip using virtual platforms is common. Virtual platforms enable\nhardware/software co-design to shorten the time to market, offer insights into\nthe models, and allow debugging of the simulated hardware. Profiling tools are\nrequired to improve the usability of virtual platforms. During simulation,\nthese tools capture data that are evaluated afterward. Those data can reveal\ninformation about the simulation itself and the software executed on the\nplatform. This work presents the tracing tool NISTT that can profile\nSystemC-TLM-2.0-based virtual platforms. NISTT is implemented in a completely\nnon-intrusive way. That means no changes in the simulation are needed, the\nsource code of the simulation is not required, and the traced simulation does\nnot need to contain debug symbols. The standardized SystemC application\nprogramming interface guarantees the compatibility of NISTT with other\nsimulations. The strengths of NISTT are demonstrated in a case study. Here,\nNISTT is connected to a virtual platform and traces the boot process of Linux.\nAfter the simulation, the database created by NISTT is evaluated, and the\nresults are visualized. Furthermore, the overhead of NISTT is quantified. It is\nshown that NISTT has only a minor influence on the overall simulation\nperformance.",
    "descriptor": "\nComments: PREPRINT - accepted by 30th IFIP/IEEE International Conference on Very Large Scale Integration 2022 (VLSI-SoC 2022)\n",
    "authors": [
      "Nils Bosbach",
      "Lukas J\u00fcnger",
      "Jan Moritz Joseph",
      "Rainer Leupers"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2207.11036"
  },
  {
    "id": "arXiv:2207.11042",
    "title": "Strong c-concavity and stability in optimal transport",
    "abstract": "The stability of solutions to optimal transport problems under variation of\nthe measures is fundamental from a mathematical viewpoint: it is closely\nrelated to the convergence of numerical approaches to solve optimal transport\nproblems and justifies many of the applications of optimal transport. In this\narticle, we introduce the notion of strong c-concavity, and we show that it\nplays an important role for proving stability results in optimal transport for\ngeneral cost functions c. We then introduce a differential criterion for\nproving that a function is strongly c-concave, under an hypothesis on the cost\nintroduced originally by Ma-Trudinger-Wang for establishing regularity of\noptimal transport maps. Finally, we provide two examples where this stability\nresult can be applied, for cost functions taking value +$\\infty$ on the sphere:\nthe reflector problem and the Gaussian curvature measure prescription problem.",
    "descriptor": "",
    "authors": [
      "Anatole Gallou\u00ebt",
      "Quentin M\u00e9rigot",
      "Boris Thibert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.11042"
  },
  {
    "id": "arXiv:2207.11048",
    "title": "Quantized Sparse Weight Decomposition for Neural Network Compression",
    "abstract": "In this paper, we introduce a novel method of neural network weight\ncompression. In our method, we store weight tensors as sparse, quantized matrix\nfactors, whose product is computed on the fly during inference to generate the\ntarget model's weights. We use projected gradient descent methods to find\nquantized and sparse factorization of the weight tensors. We show that this\napproach can be seen as a unification of weight SVD, vector quantization, and\nsparse PCA. Combined with end-to-end fine-tuning our method exceeds or is on\npar with previous state-of-the-art methods in terms of the trade-off between\naccuracy and model size. Our method is applicable to both moderate compression\nregimes, unlike vector quantization, and extreme compression regimes.",
    "descriptor": "",
    "authors": [
      "Andrey Kuzmin",
      "Mart van Baalen",
      "Markus Nagel",
      "Arash Behboodi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11048"
  },
  {
    "id": "arXiv:2207.11056",
    "title": "Energy-Aware Planning-Scheduling for Autonomous Aerial Robots",
    "abstract": "In this paper, we present an online planning-scheduling approach for\nbattery-powered autonomous aerial robots. The approach consists of\nsimultaneously planning a coverage path and scheduling onboard computational\ntasks. We further derive a novel variable coverage motion robust to airborne\nconstraints and an empirically motivated energy model. The model includes the\nenergy contribution of the schedule based on an automatic computational energy\nmodeling tool. Our experiments show how an initial flight plan is adjusted\nonline as a function of the available battery, accounting for uncertainty. Our\napproach remedies possible in-flight failure in case of unexpected battery\ndrops, e.g., due to adverse atmospheric conditions, and increases the overall\nfault tolerance.",
    "descriptor": "\nComments: 8 pages, 6 figures, IROS'22\n",
    "authors": [
      "Adam Seewald",
      "H\u00e9ctor Garc\u00eda de Marina",
      "Henrik Skov Midtiby",
      "Ulrik Pagh Schultz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.11056"
  },
  {
    "id": "arXiv:2207.11057",
    "title": "Efficient Prior Publication Identification for Open Source Code",
    "abstract": "Free/Open Source Software (FOSS) enables large-scale reuse of preexisting\nsoftware components. The main drawback is increased complexity in software\nsupply chain management. A common approach to tame such complexity is automated\nopen source compliance, which consists in automating the verication of\nadherence to various open source management best practices about license\nobligation fulllment, vulnerability tracking, software composition analysis,\nand nearby concerns.We consider the problem of auditing a source code base to\ndetermine which of its parts have been published before, which is an important\nbuilding block of automated open source compliance toolchains. Indeed, if\nsource code allegedly developed in house is recognized as having been\npreviously published elsewhere, alerts should be raised to investigate where it\ncomes from and whether this entails that additional obligations shall be\nfullled before product shipment.We propose an ecient approach for prior\npublication identication that relies on a knowledge base of known source code\nartifacts linked together in a global Merkle direct acyclic graph and a\ndedicated discovery protocol. We introduce swh-scanner, a source code scanner\nthat realizes the proposed approach in practice using as knowledge base\nSoftware Heritage, the largest public archive of source code artifacts. We\nvalidate experimentally the proposed approach, showing its eciency in both\nabstract (number of queries) and concrete terms (wall-clock time), performing\nbenchmarks on 16 845 real-world public code bases of various sizes, from small\nto very large.",
    "descriptor": "",
    "authors": [
      "Daniele Serafini",
      "Stefano Zacchiroli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.11057"
  },
  {
    "id": "arXiv:2207.11061",
    "title": "3D Interacting Hand Pose Estimation by Hand De-occlusion and Removal",
    "abstract": "Estimating 3D interacting hand pose from a single RGB image is essential for\nunderstanding human actions. Unlike most previous works that directly predict\nthe 3D poses of two interacting hands simultaneously, we propose to decompose\nthe challenging interacting hand pose estimation task and estimate the pose of\neach hand separately. In this way, it is straightforward to take advantage of\nthe latest research progress on the single-hand pose estimation system.\nHowever, hand pose estimation in interacting scenarios is very challenging, due\nto (1) severe hand-hand occlusion and (2) ambiguity caused by the homogeneous\nappearance of hands. To tackle these two challenges, we propose a novel Hand\nDe-occlusion and Removal (HDR) framework to perform hand de-occlusion and\ndistractor removal. We also propose the first large-scale synthetic amodal hand\ndataset, termed Amodal InterHand Dataset (AIH), to facilitate model training\nand promote the development of the related research. Experiments show that the\nproposed method significantly outperforms previous state-of-the-art interacting\nhand pose estimation approaches. Codes and data are available at\nhttps://github.com/MengHao666/HDR.",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Hao Meng",
      "Sheng Jin",
      "Wentao Liu",
      "Chen Qian",
      "Mengxiang Lin",
      "Wanli Ouyang",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11061"
  },
  {
    "id": "arXiv:2207.11067",
    "title": "Latent Space Unsupervised Semantic Segmentation",
    "abstract": "The development of compact and energy-efficient wearable sensors has led to\nan increase in the availability of biosignals. To analyze these continuously\nrecorded, and often multidimensional, time series at scale, being able to\nconduct meaningful unsupervised data segmentation is an auspicious target. A\ncommon way to achieve this is to identify change-points within the time series\nas the segmentation basis. However, traditional change-point detection\nalgorithms often come with drawbacks, limiting their real-world applicability.\nNotably, they generally rely on the complete time series to be available and\nthus cannot be used for real-time applications. Another common limitation is\nthat they poorly (or cannot) handle the segmentation of multidimensional time\nseries. Consequently, the main contribution of this work is to propose a novel\nunsupervised segmentation algorithm for multidimensional time series named\nLatent Space Unsupervised Semantic Segmentation (LS-USS), which was designed to\nwork easily with both online and batch data. When comparing LS-USS against\nother state-of-the-art change-point detection algorithms on a variety of\nreal-world datasets, in both the offline and real-time setting, LS-USS\nsystematically achieves on par or better performances.",
    "descriptor": "\nComments: Ongoing peer-review process 16 pages, 10 Figures, 7 Tables\n",
    "authors": [
      "Knut J. Str\u00f8mmen",
      "Jim T\u00f8rresen",
      "Ulysse C\u00f4t\u00e9-Allard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.11067"
  },
  {
    "id": "arXiv:2207.11068",
    "title": "Matching Triangles and Triangle Collection: Hardness based on a Weak  Quantum Conjecture",
    "abstract": "Classically, for many computational problems one can conclude time lower\nbounds conditioned on the hardness of one or more of key problems: k-SAT, 3SUM\nand APSP. More recently, similar results have been derived in the quantum\nsetting conditioned on the hardness of k-SAT and 3SUM. This is done using\nfine-grained reductions, where the approach is to (1) select a key problem $X$\nthat, for some function $T$, is conjectured to not be solvable by any\n$O(T(n)^{1-\\epsilon})$ time algorithm for any constant $\\epsilon > 0$ (in a\nfixed model of computation), and (2) reduce $X$ in a fine-grained way to these\ncomputational problems, thus giving (mostly) tight conditional time lower\nbounds for them.\nInterestingly, for Delta-Matching Triangles and Triangle Collection,\nclassical hardness results have been derived conditioned on hardness of all\nthree mentioned key problems. More precisely, it is proven that an\n$n^{3-\\epsilon}$ time classical algorithm for either of these two graph\nproblems would imply faster classical algorithms for k-SAT, 3SUM and APSP,\nwhich makes Delta-Matching Triangles and Triangle Collection worthwhile to\nstudy.\nIn this paper, we show that an $n^{1.5-\\epsilon}$ time quantum algorithm for\neither of these two graph problems would imply faster quantum algorithms for\nk-SAT, 3SUM, and APSP. We first formulate a quantum hardness conjecture for\nAPSP and then present quantum reductions from k-SAT, 3SUM, and APSP to\nDelta-Matching Triangles and Triangle Collection. Additionally, based on the\nquantum APSP conjecture, we are also able to prove quantum lower bounds for a\nmatrix problem and many graph problems. The matching upper bounds follow\ntrivially for most of them, except for Delta-Matching Triangles and Triangle\nCollection for which we present quantum algorithms that require careful use of\ndata structures and Ambainis' variable time search.",
    "descriptor": "",
    "authors": [
      "Andris Ambainis",
      "Harry Buhrman",
      "Koen Leijnse",
      "Subhasree Patro",
      "Florian Speelman"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.11068"
  },
  {
    "id": "arXiv:2207.11071",
    "title": "PPSZ is better than you think",
    "abstract": "PPSZ, for long time the fastest known algorithm for $k$-SAT, works by going\nthrough the variables of the input formula in random order; each variable is\nthen set randomly to $0$ or $1$, unless the correct value can be inferred by an\nefficiently implementable rule (like small-width resolution; or being implied\nby a small set of clauses).\nWe show that PPSZ performs exponentially better than previously known, for\nall $k \\geq 3$. For Unique-$3$-SAT we bound its running time by\n$O(1.306973^{n})$, which is somewhat better than the algorithm of Hansen,\nKaplan, Zamir, and Zwick, which runs in time $O(1.306995^n)$. Before that, the\nbest known upper bound for Unique-$3$-SAT was $O(1.3070319^n)$.\nAll improvements are achieved without changing the original PPSZ. The core\nidea is to pretend that PPSZ does not process the variables in uniformly random\norder, but according to a carefully designed distribution. We write \"pretend\"\nsince this can be done without any actual change to the algorithm.",
    "descriptor": "",
    "authors": [
      "Dominik Scheder"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.11071"
  },
  {
    "id": "arXiv:2207.11075",
    "title": "RealFlow: EM-based Realistic Optical Flow Dataset Generation from Videos",
    "abstract": "Obtaining the ground truth labels from a video is challenging since the\nmanual annotation of pixel-wise flow labels is prohibitively expensive and\nlaborious. Besides, existing approaches try to adapt the trained model on\nsynthetic datasets to authentic videos, which inevitably suffers from domain\ndiscrepancy and hinders the performance for real-world applications. To solve\nthese problems, we propose RealFlow, an Expectation-Maximization based\nframework that can create large-scale optical flow datasets directly from any\nunlabeled realistic videos. Specifically, we first estimate optical flow\nbetween a pair of video frames, and then synthesize a new image from this pair\nbased on the predicted flow. Thus the new image pairs and their corresponding\nflows can be regarded as a new training set. Besides, we design a Realistic\nImage Pair Rendering (RIPR) module that adopts softmax splatting and\nbi-directional hole filling techniques to alleviate the artifacts of the image\nsynthesis. In the E-step, RIPR renders new images to create a large quantity of\ntraining data. In the M-step, we utilize the generated training data to train\nan optical flow network, which can be used to estimate optical flows in the\nnext E-step. During the iterative learning steps, the capability of the flow\nnetwork is gradually improved, so is the accuracy of the flow, as well as the\nquality of the synthesized dataset. Experimental results show that RealFlow\noutperforms previous dataset generation methods by a considerably large margin.\nMoreover, based on the generated dataset, our approach achieves\nstate-of-the-art performance on two standard benchmarks compared with both\nsupervised and unsupervised optical flow methods. Our code and dataset are\navailable at https://github.com/megvii-research/RealFlow",
    "descriptor": "\nComments: ECCV 2022 Oral\n",
    "authors": [
      "Yunhui Han",
      "Kunming Luo",
      "Ao Luo",
      "Jiangyu Liu",
      "Haoqiang Fan",
      "Guiming Luo",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11075"
  },
  {
    "id": "arXiv:2207.11076",
    "title": "Multi-Level Fine-Tuning, Data Augmentation, and Few-Shot Learning for  Specialized Cyber Threat Intelligence",
    "abstract": "Gathering cyber threat intelligence from open sources is becoming\nincreasingly important for maintaining and achieving a high level of security\nas systems become larger and more complex. However, these open sources are\noften subject to information overload. It is therefore useful to apply machine\nlearning models that condense the amount of information to what is necessary.\nYet, previous studies and applications have shown that existing classifiers are\nnot able to extract specific information about emerging cybersecurity events\ndue to their low generalization ability. Therefore, we propose a system to\novercome this problem by training a new classifier for each new incident. Since\nthis requires a lot of labelled data using standard training methods, we\ncombine three different low-data regime techniques - transfer learning, data\naugmentation, and few-shot learning - to train a high-quality classifier from\nvery few labelled instances. We evaluated our approach using a novel dataset\nderived from the Microsoft Exchange Server data breach of 2021 which was\nlabelled by three experts. Our findings reveal an increase in F1 score of more\nthan 21 points compared to standard training methods and more than 18 points\ncompared to a state-of-the-art method in few-shot learning. Furthermore, the\nclassifier trained with this method and 32 instances is only less than 5 F1\nscore points worse than a classifier trained with 1800 instances.",
    "descriptor": "",
    "authors": [
      "Markus Bayer",
      "Tobias Frey",
      "Christian Reuter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.11076"
  },
  {
    "id": "arXiv:2207.11079",
    "title": "New Decoding of Reed-Solomon Codes Based on FFT and Modular Approach",
    "abstract": "Decoding algorithms for Reed--Solomon (RS) codes are of great interest for\nboth practical and theoretical reasons. In this paper, an efficient algorithm,\ncalled the modular approach (MA), is devised for solving the Welch--Berlekamp\n(WB) key equation. By taking the MA as the key equation solver, we propose a\nnew decoding algorithm for systematic RS codes. For $(n,k)$ RS codes, where $n$\nis the code length and $k$ is the code dimension, the proposed decoding\nalgorithm has both the best asymptotic computational complexity $O(n\\log(n-k) +\n(n-k)\\log^2(n-k))$ and the smallest constant factor achieved to date. By\ncomparing the number of field operations required, we show that when decoding\npractical RS codes, the new algorithm is significantly superior to the existing\nmethods in terms of computational complexity. When decoding the $(4096, 3584)$\nRS code defined over $\\mathbb{F}_{2^{12}}$, the new algorithm is 10 times\nfaster than a conventional syndrome-based method. Furthermore, the new\nalgorithm has a regular architecture and is thus suitable for hardware\nimplementation.",
    "descriptor": "",
    "authors": [
      "Nianqi Tang",
      "Yunghsiang S. Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.11079"
  },
  {
    "id": "arXiv:2207.11081",
    "title": "Facial Expression Recognition using Vanilla ViT backbones with MAE  Pretraining",
    "abstract": "Humans usually convey emotions voluntarily or involuntarily by facial\nexpressions. Automatically recognizing the basic expression (such as happiness,\nsadness, and neutral) from a facial image, i.e., facial expression recognition\n(FER), is extremely challenging and attracts much research interests. Large\nscale datasets and powerful inference models have been proposed to address the\nproblem. Though considerable progress has been made, most of the state of the\narts employing convolutional neural networks (CNNs) or elaborately modified\nVision Transformers (ViTs) depend heavily on upstream supervised pretraining.\nTransformers are taking place the domination of CNNs in more and more computer\nvision tasks. But they usually need much more data to train, since they use\nless inductive biases compared with CNNs. To explore whether a vanilla ViT\nwithout extra training samples from upstream tasks is able to achieve\ncompetitive accuracy, we use a plain ViT with MAE pretraining to perform the\nFER task. Specifically, we first pretrain the original ViT as a Masked\nAutoencoder (MAE) on a large facial expression dataset without expression\nlabels. Then, we fine-tune the ViT on popular facial expression datasets with\nexpression labels. The presented method is quite competitive with 90.22\\% on\nRAF-DB, 61.73\\% on AfectNet and can serve as a simple yet strong ViT-based\nbaseline for FER studies.",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "Jia Li",
      "Ziyang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11081"
  },
  {
    "id": "arXiv:2207.11082",
    "title": "Test-based Patch Clustering for Automatically-Generated Patches  Assessment",
    "abstract": "Previous studies have shown that Automated Program Repair (APR) techniques\nsuffer from the overfitting problem. Overfitting happens when a patch is run\nand the test suite does not reveal any error, but the patch actually does not\nfix the underlying bug or it introduces a new defect that is not covered by the\ntest suite. Therefore, the patches generated by APR tools need to be validated\nby human programmers, which can be very costly, and prevents APR tools adoption\nin practice.Our work aims at increasing developer trust in automated patch\ngeneration by minimizing the number of plausible patches that they have to\nreview, thereby reducing the time required to find a correct patch. We\nintroduce a novel light-weight test-based patch clustering approach called\nxTestCluster, which clusters patches based on their dynamic behavior.\nxTestCluster is applied after the patch generation phase in order to analyze\nthe generated patches from one or more repair tools. The novelty of\nxTestCluster lies in using information from execution of newly generated test\ncases to cluster patches generated by multiple APR approaches. A cluster is\nformed with patches that fail on the same generated test cases. The output from\nxTestCluster gives developers a) a way of reducing the number of patches to\nanalyze, as they can focus on analyzing a sample of patches from each cluster,\nb) additional information attached to each patch. After analyzing 1910\nplausible patches from 25 Java APR tools, our results show that xTestCluster is\nable to reduce the number of patches to review and analyze with a median of\n50%. xTestCluster can save a significant amount of time for developers that\nhave to review the multitude of patches generated by APR tools, and provides\nthem with new test cases that show the differences in behavior between\ngenerated patches.",
    "descriptor": "",
    "authors": [
      "Matias Martinez",
      "Maria Kechagia",
      "Anjana Perera",
      "Justyna Petke",
      "Federica Sarro",
      "Aldeida Aleti"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.11082"
  },
  {
    "id": "arXiv:2207.11088",
    "title": "Layer-refined Graph Convolutional Networks for Recommendation",
    "abstract": "Recommendation models utilizing Graph Convolutional Networks (GCNs) have\nachieved state-of-the-art performance, as they can integrate both the node\ninformation and the topological structure of the user-item interaction graph.\nHowever, these GCN-based recommendation models not only suffer from\nover-smoothing when stacking too many layers but also bear performance\ndegeneration resulting from the existence of noise in user-item interactions.\nIn this paper, we first identify a recommendation dilemma of over-smoothing and\nsolution collapsing in current GCN-based models. Specifically, these models\nusually aggregate all layer embeddings for node updating and achieve their best\nrecommendation performance within a few layers because of over-smoothing.\nConversely, if we place learnable weights on layer embeddings for node\nupdating, the weight space will always collapse to a fixed point, at which the\nweighting of the ego layer almost holds all. We propose a layer-refined GCN\nmodel, dubbed LayerGCN, that refines layer representations during information\npropagation and node updating of GCN. Moreover, previous GCN-based\nrecommendation models aggregate all incoming information from neighbors without\ndistinguishing the noise nodes, which deteriorates the recommendation\nperformance. Our model further prunes the edges of the user-item interaction\ngraph following a degree-sensitive probability instead of the uniform\ndistribution. Experimental results show that the proposed model outperforms the\nstate-of-the-art models significantly on four public datasets with fast\ntraining convergence. The implementation code of the proposed method is\navailable at https://github.com/enoche/ImRec.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Xin Zhou",
      "Donghui Lin",
      "Yong Liu",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.11088"
  },
  {
    "id": "arXiv:2207.11089",
    "title": "Do Artificial Intelligence Systems Understand?",
    "abstract": "Are intelligent machines really intelligent? Is the underlying philosophical\nconcept of intelligence satisfactory for describing how the present systems\nwork? Is understanding a necessary and sufficient condition for intelligence?\nIf a machine could understand, should we attribute subjectivity to it? This\npaper addresses the problem of deciding whether the so-called \"intelligent\nmachines\" are capable of understanding, instead of merely processing signs. It\ndeals with the relationship between syntaxis and semantics. The main thesis\nconcerns the inevitability of semantics for any discussion about the\npossibility of building conscious machines, condensed into the following two\ntenets: \"If a machine is capable of understanding (in the strong sense), then\nit must be capable of combining rules and intuitions\"; \"If semantics cannot be\nreduced to syntaxis, then a machine cannot understand.\" Our conclusion states\nthat it is not necessary to attribute understanding to a machine in order to\nexplain its exhibited \"intelligent\" behavior; a merely syntactic and\nmechanistic approach to intelligence as a task-solving tool suffices to justify\nthe range of operations that it can display in the current state of\ntechnological development.",
    "descriptor": "",
    "authors": [
      "Eduardo C. Garrido-Merch\u00e1n",
      "Carlos Blanco"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11089"
  },
  {
    "id": "arXiv:2207.11091",
    "title": "Classification via score-based generative modelling",
    "abstract": "In this work, we investigated the application of score-based gradient\nlearning in discriminative and generative classification settings. Score\nfunction can be used to characterize data distribution as an alternative to\ndensity. It can be efficiently learned via score matching, and used to flexibly\ngenerate credible samples to enhance discriminative classification quality, to\nrecover density and to build generative classifiers. We analysed the decision\ntheories involving score-based representations, and performed experiments on\nsimulated and real-world datasets, demonstrating its effectiveness in achieving\nand improving binary classification performance, and robustness to\nperturbations, particularly in high dimensions and imbalanced situations.",
    "descriptor": "",
    "authors": [
      "Yongchao Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.11091"
  },
  {
    "id": "arXiv:2207.11094",
    "title": "Visual Speech-Aware Perceptual 3D Facial Expression Reconstruction from  Videos",
    "abstract": "The recent state of the art on monocular 3D face reconstruction from image\ndata has made some impressive advancements, thanks to the advent of Deep\nLearning. However, it has mostly focused on input coming from a single RGB\nimage, overlooking the following important factors: a) Nowadays, the vast\nmajority of facial image data of interest do not originate from single images\nbut rather from videos, which contain rich dynamic information. b) Furthermore,\nthese videos typically capture individuals in some form of verbal communication\n(public talks, teleconferences, audiovisual human-computer interactions,\ninterviews, monologues/dialogues in movies, etc). When existing 3D face\nreconstruction methods are applied in such videos, the artifacts in the\nreconstruction of the shape and motion of the mouth area are often severe,\nsince they do not match well with the speech audio.\nTo overcome the aforementioned limitations, we present the first method for\nvisual speech-aware perceptual reconstruction of 3D mouth expressions. We do\nthis by proposing a \"lipread\" loss, which guides the fitting process so that\nthe elicited perception from the 3D reconstructed talking head resembles that\nof the original video footage. We demonstrate that, interestingly, the lipread\nloss is better suited for 3D reconstruction of mouth movements compared to\ntraditional landmark losses, and even direct 3D supervision. Furthermore, the\ndevised method does not rely on any text transcriptions or corresponding audio,\nrendering it ideal for training in unlabeled datasets. We verify the efficiency\nof our method through exhaustive objective evaluations on three large-scale\ndatasets, as well as subjective evaluation with two web-based user studies.",
    "descriptor": "",
    "authors": [
      "Panagiotis P. Filntisis",
      "George Retsinas",
      "Foivos Paraperas-Papantoniou",
      "Athanasios Katsamanis",
      "Anastasios Roussos",
      "Petros Maragos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11094"
  },
  {
    "id": "arXiv:2207.11100",
    "title": "Zero-Shot Video Captioning with Evolving Pseudo-Tokens",
    "abstract": "We introduce a zero-shot video captioning method that employs two frozen\nnetworks: the GPT-2 language model and the CLIP image-text matching model. The\nmatching score is used to steer the language model toward generating a sentence\nthat has a high average matching score to a subset of the video frames. Unlike\nzero-shot image captioning methods, our work considers the entire sentence at\nonce. This is achieved by optimizing, during the generation process, part of\nthe prompt from scratch, by modifying the representation of all other tokens in\nthe prompt, and by repeating the process iteratively, gradually improving the\nspecificity and comprehensiveness of the generated sentence. Our experiments\nshow that the generated captions are coherent and display a broad range of\nreal-world knowledge. Our code is available at:\nhttps://github.com/YoadTew/zero-shot-video-to-text",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Yoad Tewel",
      "Yoav Shalev",
      "Roy Nadler",
      "Idan Schwartz",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11100"
  },
  {
    "id": "arXiv:2207.11103",
    "title": "DeVIS: Making Deformable Transformers Work for Video Instance  Segmentation",
    "abstract": "Video Instance Segmentation (VIS) jointly tackles multi-object detection,\ntracking, and segmentation in video sequences. In the past, VIS methods\nmirrored the fragmentation of these subtasks in their architectural design,\nhence missing out on a joint solution. Transformers recently allowed to cast\nthe entire VIS task as a single set-prediction problem. Nevertheless, the\nquadratic complexity of existing Transformer-based methods requires long\ntraining times, high memory requirements, and processing of low-single-scale\nfeature maps. Deformable attention provides a more efficient alternative but\nits application to the temporal domain or the segmentation task have not yet\nbeen explored.\nIn this work, we present Deformable VIS (DeVIS), a VIS method which\ncapitalizes on the efficiency and performance of deformable Transformers. To\nreason about all VIS subtasks jointly over multiple frames, we present temporal\nmulti-scale deformable attention with instance-aware object queries. We further\nintroduce a new image and video instance mask head with multi-scale features,\nand perform near-online video processing with multi-cue clip tracking. DeVIS\nreduces memory as well as training time requirements, and achieves\nstate-of-the-art results on the YouTube-VIS 2021, as well as the challenging\nOVIS dataset.\nCode is available at https://github.com/acaelles97/DeVIS.",
    "descriptor": "",
    "authors": [
      "Adri\u00e0 Caelles",
      "Tim Meinhardt",
      "Guillem Bras\u00f3",
      "Laura Leal-Taix\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.11103"
  },
  {
    "id": "arXiv:2207.11104",
    "title": "CARBON: A Counterfactual Reasoning based Framework for Neural Code  Comprehension Debiasing",
    "abstract": "Previous studies have demonstrated that code intelligence models are\nsensitive to program transformation among which identifier renaming is\nparticularly easy to apply and effective. By simply renaming one identifier in\nsource code, the models would output completely different results. The prior\nresearch generally mitigates the problem by generating more training samples.\nSuch an approach is less than ideal since its effectiveness depends on the\nquantity and quality of the generated samples. Different from these studies, we\nare devoted to adjusting models for explicitly distinguishing the influence of\nidentifier names on the results, called naming bias in this paper, and thereby\nmaking the models robust to identifier renaming. Specifically, we formulate the\nnaming bias with a structural causal model (SCM), and propose a counterfactual\nreasoning based framework named CARBON for eliminating the naming bias in\nneural code comprehension. CARBON explicitly captures the naming bias through\nmulti-task learning in the training stage, and reduces the bias by\ncounterfactual inference in the inference stage. We evaluate CARBON on three\nneural code comprehension tasks, including function naming, defect detection\nand code classification. Experiment results show that CARBON achieves\nrelatively better performance (e.g., +0.5% on the function naming task at F1\nscore) than the baseline models on the original benchmark datasets, and\nsignificantly improvement (e.g., +37.9% on the function naming task at F1\nscore) on the datasets with identifiers renamed. The proposed framework\nprovides a causal view for improving the robustness of code intelligence\nmodels.",
    "descriptor": "",
    "authors": [
      "Shuzheng Gao",
      "Cuiyun Gao",
      "Chaozheng Wang",
      "Jun Sun",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.11104"
  },
  {
    "id": "arXiv:2207.11108",
    "title": "Inference skipping for more efficient real-time speech enhancement with  parallel RNNs",
    "abstract": "Deep neural network (DNN) based speech enhancement models have attracted\nextensive attention due to their promising performance. However, it is\ndifficult to deploy a powerful DNN in real-time applications because of its\nhigh computational cost. Typical compression methods such as pruning and\nquantization do not make good use of the data characteristics. In this paper,\nwe introduce the Skip-RNN strategy into speech enhancement models with parallel\nRNNs. The states of the RNNs update intermittently without interrupting the\nupdate of the output mask, which leads to significant reduction of\ncomputational load without evident audio artifacts. To better leverage the\ndifference between the voice and the noise, we further regularize the skipping\nstrategy with voice activity detection (VAD) guidance, saving more\ncomputational load. Experiments on a high-performance speech enhancement model,\ndual-path convolutional recurrent network (DPCRN), show the superiority of our\nstrategy over strategies like network pruning or directly training a smaller\nmodel. We also validate the generalization of the proposed strategy on two\nother competitive speech enhancement models.",
    "descriptor": "\nComments: 11 pages, 8 figures, accepted by IEEE/ACM TASLP\n",
    "authors": [
      "Xiaohuai Le",
      "Tong Lei",
      "Kai Chen",
      "Jing Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.11108"
  },
  {
    "id": "arXiv:2207.11116",
    "title": "Citation models and research evaluation",
    "abstract": "Citations in science are being studied from several perspectives. On the one\nhand, there are approaches such as scientometrics and the science of science,\nwhich take a more quantitative perspective. In this chapter I briefly review\nsome of the literature on citations, citation distributions and models of\ncitations. These citations feature prominently in another part of the\nliterature which is dealing with research evaluation and the role of metrics\nand indicators in that process. Here I briefly review part of the discussion in\nresearch evaluation. This also touches on the subject of how citations relate\nto peer review. Finally, I try to integrate the two literatures with the aim of\nclarifying what I believe the two can learn from each other. The fundamental\nproblem in research evaluation is that research quality is unobservable. This\nhas consequences for conclusions that we can draw from quantitative studies of\ncitations and citation models. The term \"indicators\" is a relevant concept in\nthis context, which I try to clarify. Causality is important for properly\nunderstanding indicators, especially when indicators are used in practice: when\nwe act on indicators, we enter causal territory. Even when an indicator might\nhave been valid, through its very use, the consequences of its use may\ninvalidate it. By combining citation models with proper causal reasoning and\nacknowledging the fundamental problem about unobservable research quality, we\nmay hope to make progress.",
    "descriptor": "\nComments: This is a draft. The final version will be available in Handbook of Computational Social Science edited by Taha Yasseri, forthcoming 2023, Edward Elgar Publishing Ltd\n",
    "authors": [
      "V.A. Traag"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2207.11116"
  },
  {
    "id": "arXiv:2207.11117",
    "title": "Near Real-Time Distributed State Estimation via AI/ML-Empowered 5G  Networks",
    "abstract": "Fifth-Generation (5G) networks have a potential to accelerate power system\ntransition to a flexible, softwarized, data-driven, and intelligent grid. With\ntheir evolving support for Machine Learning (ML)/Artificial Intelligence (AI)\nfunctions, 5G networks are expected to enable novel data-centric Smart Grid\n(SG) services. In this paper, we explore how data-driven SG services could be\nintegrated with ML/AI-enabled 5G networks in a symbiotic relationship. We focus\non the State Estimation (SE) function as a key element of the energy management\nsystem and focus on two main questions. Firstly, in a tutorial fashion, we\npresent an overview on how distributed SE can be integrated with the elements\nof the 5G core network and radio access network architecture. Secondly, we\npresent and compare two powerful distributed SE methods based on: i) graphical\nmodels and belief propagation, and ii) graph neural networks. We discuss their\nperformance and capability to support a near real-time distributed SE via 5G\nnetwork, taking into account communication delays.",
    "descriptor": "",
    "authors": [
      "Ognjen Kundacina",
      "Miodrag Forcan",
      "Mirsad Cosovic",
      "Darijo Raca",
      "Merim Dzaferagic",
      "Dragisa Miskovic",
      "Mirjana Maksimovic",
      "Dejan Vukobratovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.11117"
  },
  {
    "id": "arXiv:2207.11118",
    "title": "Rethinking the Reference-based Distinctive Image Captioning",
    "abstract": "Distinctive Image Captioning (DIC) -- generating distinctive captions that\ndescribe the unique details of a target image -- has received considerable\nattention over the last few years. A recent DIC work proposes to generate\ndistinctive captions by comparing the target image with a set of\nsemantic-similar reference images, i.e., reference-based DIC (Ref-DIC). It aims\nto make the generated captions can tell apart the target and reference images.\nUnfortunately, reference images used by existing Ref-DIC works are easy to\ndistinguish: these reference images only resemble the target image at\nscene-level and have few common objects, such that a Ref-DIC model can\ntrivially generate distinctive captions even without considering the reference\nimages. To ensure Ref-DIC models really perceive the unique objects (or\nattributes) in target images, we first propose two new Ref-DIC benchmarks.\nSpecifically, we design a two-stage matching mechanism, which strictly controls\nthe similarity between the target and reference images at object-/attribute-\nlevel (vs. scene-level). Secondly, to generate distinctive captions, we develop\na strong Transformer-based Ref-DIC baseline, dubbed as TransDIC. It not only\nextracts visual features from the target image, but also encodes the\ndifferences between objects in the target and reference images. Finally, for\nmore trustworthy benchmarking, we propose a new evaluation metric named\nDisCIDEr for Ref-DIC, which evaluates both the accuracy and distinctiveness of\nthe generated captions. Experimental results demonstrate that our TransDIC can\ngenerate distinctive captions. Besides, it outperforms several state-of-the-art\nmodels on the two new benchmarks over different metrics.",
    "descriptor": "\nComments: ACM MM 2022\n",
    "authors": [
      "Yangjun Mao",
      "Long Chen",
      "Zhihong Jiang",
      "Dong Zhang",
      "Zhimeng Zhang",
      "Jian Shao",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11118"
  },
  {
    "id": "arXiv:2207.11120",
    "title": "On Controller Tuning with Time-Varying Bayesian Optimization",
    "abstract": "Changing conditions or environments can cause system dynamics to vary over\ntime. To ensure optimal control performance, controllers should adapt to these\nchanges. When the underlying cause and time of change is unknown, we need to\nrely on online data for this adaptation. In this paper, we will use\ntime-varying Bayesian optimization (TVBO) to tune controllers online in\nchanging environments using appropriate prior knowledge on the control\nobjective and its changes. Two properties are characteristic of many online\ncontroller tuning problems: First, they exhibit incremental and lasting changes\nin the objective due to changes to the system dynamics, e.g., through wear and\ntear. Second, the optimization problem is convex in the tuning parameters.\nCurrent TVBO methods do not explicitly account for these properties, resulting\nin poor tuning performance and many unstable controllers through\nover-exploration of the parameter space. We propose a novel TVBO forgetting\nstrategy using Uncertainty-Injection (UI), which incorporates the assumption of\nincremental and lasting changes. The control objective is modeled as a\nspatio-temporal Gaussian process (GP) with UI through a Wiener process in the\ntemporal domain. Further, we explicitly model the convexity assumptions in the\nspatial dimension through GP models with linear inequality constraints. In\nnumerical experiments, we show that our model outperforms the state-of-the-art\nmethod in TVBO, exhibiting reduced regret and fewer unstable parameter\nconfigurations.",
    "descriptor": "\nComments: To appear in the proceedings of the 61st IEEE Conference on Decision and Control\n",
    "authors": [
      "Paul Brunzema",
      "Alexander von Rohr",
      "Sebastian Trimpe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.11120"
  },
  {
    "id": "arXiv:2207.11123",
    "title": "Adaptive Graph-Based Feature Normalization for Facial Expression  Recognition",
    "abstract": "Facial Expression Recognition (FER) suffers from data uncertainties caused by\nambiguous facial images and annotators' subjectiveness, resulting in excursive\nsemantic and feature covariate shifting problem. Existing works usually correct\nmislabeled data by estimating noise distribution, or guide network training\nwith knowledge learned from clean data, neglecting the associative relations of\nexpressions. In this work, we propose an Adaptive Graph-based Feature\nNormalization (AGFN) method to protect FER models from data uncertainties by\nnormalizing feature distributions with the association of expressions.\nSpecifically, we propose a Poisson graph generator to adaptively construct\ntopological graphs for samples in each mini-batches via a sampling process, and\ncorrespondingly design a coordinate descent strategy to optimize proposed\nnetwork. Our method outperforms state-of-the-art works with accuracies of\n91.84% and 91.11% on the benchmark datasets FERPlus and RAF-DB, respectively,\nand when the percentage of mislabeled data increases (e.g., to 20%), our\nnetwork surpasses existing works significantly by 3.38% and 4.52%.",
    "descriptor": "",
    "authors": [
      "Yangtao Du",
      "Qingqing Wang",
      "Yujie Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11123"
  },
  {
    "id": "arXiv:2207.11126",
    "title": "Optimism in Face of a Context: Regret Guarantees for Stochastic  Contextual MDP",
    "abstract": "We present regret minimization algorithms for stochastic contextual MDPs\nunder minimum reachability assumption, using an access to an offline least\nsquare regression oracle. We analyze three different settings: where the\ndynamics is known, where the dynamics is unknown but independent of the context\nand the most challenging setting where the dynamics is unknown and\ncontext-dependent. For the latter, our algorithm obtains $\n\\tilde{O}\\left(\n\\max\\{H,{1}/{p_{min}}\\}H|S|^{3/2}\\sqrt{|A|T\\log(\\max\\{|\\mathcal{F}|,|\\mathcal{P}|\\}/\\delta)}\n\\right)$ regret bound, with probability $1-\\delta$, where $\\mathcal{P}$ and\n$\\mathcal{F}$ are finite and realizable function classes used to approximate\nthe dynamics and rewards respectively, $p_{min}$ is the minimum reachability\nparameter, $S$ is the set of states, $A$ the set of actions, $H$ the horizon,\nand $T$ the number of episodes. To our knowledge, our approach is the first\noptimistic approach applied to contextual MDPs with general function\napproximation (i.e., without additional knowledge regarding the function class,\nsuch as it being linear and etc.). In addition, we present a lower bound of\n$\\Omega(\\sqrt{T H |S| |A| \\ln(|\\mathcal{F}|/|S|)/\\ln(|A|)})$, on the expected\nregret which holds even in the case of known dynamics.",
    "descriptor": "",
    "authors": [
      "Orin Levy",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11126"
  },
  {
    "id": "arXiv:2207.11128",
    "title": "Integral surface based Second Order Sliding Mode Controller design for  Inverted Pendulum with PD SMC Compensation",
    "abstract": "Stabilization of a nonlinear single stage inverted pendulum is a complicated\ncontrol problem, as nonlinearity is present inherently and external factors\naffect the equilibrium position. In this paper, a PD sliding mode controller is\nconnected with Second order PI (Proportional+Integral) sliding mode controller,\nwhich is designed to improve the performance for nonlinear state differential\nequations with unknown parameters. This paper throws light on the sliding\nsurface design and highlights the important features of multiplexing sliding\nmode control inputs resulting in robustness and higher convergence of output,\nthrough extensive mathematical modeling. Simulations and experimental\napplication is done on the system to evaluate the controller for performance,\ncomplexity of implementation and also on the impact of the nonlinear IP system\non its stability.",
    "descriptor": "",
    "authors": [
      "Kirtiman Singh",
      "Prabin Kumar Padhy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.11128"
  },
  {
    "id": "arXiv:2207.11129",
    "title": "Design of Sliding Mode PID Controller with Improved reaching laws for  Nonlinear Systems",
    "abstract": "In this thesis, advanced design technique in sliding mode control (SMC) is\npresented with focus on PID (Proportional-Integral-Derivative) type Sliding\nsurfaces based Sliding mode control with improved power rate exponential\nreaching law for Non-linear systems using Modified Particle Swarm Optimization\n(MPSO). To handle large non-linearities directly, sliding mode controller based\non PID-type sliding surface has been designed in this work, where Integral term\nensures fast finite convergence time. The controller parameter for various\nmodified structures can be estimated using Modified PSO, which is used as an\noffline optimization technique. Various reaching law were implemented leading\nto the proposed improved exponential power rate reaching law, which also\nimproves the finite convergence time. To implement the proposed algorithm,\nnonlinear mathematical model has to be decrypted without linearizing, and used\nfor the simulation purposes. Their performance is studied using simulations to\nprove the proposed behavior. The problem of chattering has been overcome by\nusing boundary method and also second order sliding mode method. PI-type\nsliding surface based second order sliding mode controller with PD surface\nbased SMC compensation is also proposed and implemented. The proposed\nalgorithms have been analyzed using Lyapunov stability criteria. The robustness\nof the method is provided using simulation results including disturbance and\n10% variation in system parameters. Finally process control based hardware is\nimplemented (conical tank system).",
    "descriptor": "",
    "authors": [
      "Kirtiman Singh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.11129"
  },
  {
    "id": "arXiv:2207.11130",
    "title": "Reduced-order modeling for Ablowitz-Ladik equation",
    "abstract": "In this paper, reduced-order models (ROMs) are constructed for the\nAblowitz-Ladik equation (ALE), an integrable semi-discretization of the\nnonlinear Schr\\\"{o}dinger equation (NLSE) with and without damping. Both ALEs\nare non-canonical conservative and dissipative Hamiltonian systems with the\nPoisson matrix, depending quadratically on the state variables and with\nquadratic Hamiltonian. The full-order solutions are obtained with the energy\npreserving midpoint rule for the conservative ALE and exponential midpoint rule\nfor the dissipative ALE. The reduced-order solutions are constructed\nintrusively by preserving the skew-symmetric structure of the reduced\nnon-canonical Hamiltonian system by applying proper orthogonal decomposition\nwith the Galerkin projection. For an efficient offline-online decomposition of\nthe ROMs, the quadratic nonlinear terms of the Poisson matrix are approximated\nby the discrete empirical interpolation method. The computation of the\nreduced-order solutions is further accelerated by the use of tensor techniques.\nPreservation of the Hamiltonian and momentum for the conservative ALE, and\npreservation of dissipation properties of the dissipative ALE, guarantee the\nlong-term stability of soliton solutions.",
    "descriptor": "",
    "authors": [
      "Murat Uzunca",
      "B\u00fclent Karas\u00f6zen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.11130"
  },
  {
    "id": "arXiv:2207.11132",
    "title": "Proactive Distributed Constraint Optimization of Heterogeneous Incident  Vehicle Teams",
    "abstract": "Traditionally, traffic incident management (TIM) programs coordinate the\ndeployment of emergency resources to immediate incident requests without\naccommodating the interdependencies on incident evolutions in the environment.\nHowever, ignoring inherent interdependencies on the evolution of incidents in\nthe environment while making current deployment decisions is shortsighted, and\nthe resulting naive deployment strategy can significantly worsen the overall\nincident delay impact on the network. The interdependencies on incident\nevolution in the environment, including those between incident occurrences, and\nthose between resource availability in near-future requests and the anticipated\nduration of the immediate incident request, should be considered through a\nlook-ahead model when making current-stage deployment decisions. This study\ndevelops a new proactive framework based on the distributed constraint\noptimization problem (DCOP) to address the above limitations, overcoming\nconventional TIM models that cannot accommodate the dependencies in the TIM\nproblem. Furthermore, the optimization objective is formulated to incorporate\nUnmanned Aerial Vehicles (UAVs). The UAVs' role in TIM includes exploring\nuncertain traffic conditions, detecting unexpected events, and augmenting\ninformation from roadway traffic sensors. Robustness analysis of our model for\nmultiple TIM scenarios shows satisfactory performance using local search\nexploration heuristics. Overall, our model reports a significant reduction in\ntotal incident delay compared to conventional TIM models. With UAV support, we\ndemonstrate a further decrease in the overall incident delay through the\nshorter response time of emergency vehicles, and a reduction in uncertainties\nassociated with the estimated incident delay impact.",
    "descriptor": "\nComments: 14 pages, 13 figures, 2 tables, journal\n",
    "authors": [
      "Justice Darko",
      "Hyoshin Park"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2207.11132"
  },
  {
    "id": "arXiv:2207.11133",
    "title": "Numerical convergence of a Telegraph Predator-Prey System",
    "abstract": "The numerical convergence of a Telegraph Predator-Prey system is studied.\nThis system of partial differential equations (PDEs) can describe various\nbiological systems with reactive, diffusive and delay effects. Initially, our\nproblem is mathematically modeled. Then, the PDEs system is discretized using\nthe Finite Difference method, obtaining a system of equations in the explicit\nform in time and implicit form in space. The consistency of the Telegraph\nPredator-Prey system discretization was verified. Next, the von Neumann\nstability conditions were calculated for a Predator-Prey system with reactive\nterms and for a Telegraph system with delay. For our Telegraph Predator-Prey\nsystem, through numerical experiments, it was verified tat the mesh refinement\nand the model parameters (reactive constants, diffusion coefficient and delay\nterm) determine the stability/instability conditions of the model.\nKeywords: Telegraph-Diffusive-Reactive System. Maxwell-Cattaneo Delay.\nDiscretization Consistency. Von Neumann Stability. Numerical Experimentation.",
    "descriptor": "\nComments: Submited to journal \"Semina: Exact and Technological Sciences\"\n",
    "authors": [
      "Kariston Stevan Luiz",
      "Juniormar Organista",
      "Eliandro Rodrigues Cirilo",
      "Neyva Maria Lopes Romeiro",
      "Paulo Laerte Natti"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.11133"
  },
  {
    "id": "arXiv:2207.11134",
    "title": "Development of monitoring systems for anomaly detection using ASTD  specifications",
    "abstract": "Anomaly-based intrusion detection systems are essential defenses against\ncybersecurity threats because they can identify anomalies in current\nactivities. However, these systems have difficulties providing entity\nprocessing independence through a programming language. In addition, a\ndegradation of the detection process is caused by the complexity of scheduling\nthe training and detection processes, which are required to keep the anomaly\ndetection system continuously updated. This paper shows how to use the\nalgebraic state-transition diagram (ASTD) language to develop flexible anomaly\ndetection systems. This paper provides a model for detecting point anomalies\nusing the unsupervised non-parametric technique Kernel Density Estimation to\nestimate the probability density of event occurrence. The proposed model caters\nfor both the training and the detection phase continuously. The ASTD language\nstreamlines the modeling of detection systems thanks to its process algebraic\noperators that provide a solution to overcome these challenges. By delegating\nthe combination of anomaly-based detection processes to the ASTD language, the\neffort and complexity are reduced during detection models development. Finally,\nusing a qualitative evaluation, this study demonstrates that the algebraic\noperators in the ASTD specification language overcome these challenges.",
    "descriptor": "",
    "authors": [
      "El Jabri Chaymae",
      "Frappier Marc",
      "Ecarot Thibaud",
      "Tardif Pierre-Martin"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2207.11134"
  },
  {
    "id": "arXiv:2207.11136",
    "title": "Motion Planning and Control for Multi Vehicle Autonomous Racing at High  Speeds",
    "abstract": "This paper presents a multi-layer motion planning and control architecture\nfor autonomous racing, capable of avoiding static obstacles, performing active\novertakes, and reaching velocities above 75 $m/s$. The used offline global\ntrajectory generation and the online model predictive controller are highly\nbased on optimization and dynamic models of the vehicle, where the tires and\ncamber effects are represented in an extended version of the basic Pacejka\nMagic Formula. The proposed single-track model is identified and validated\nusing multi-body motorsport libraries which allow simulating the vehicle\ndynamics properly, especially useful when real experimental data are missing.\nThe fundamental regularization terms and constraints of the controller are\ntuned to reduce the rate of change of the inputs while assuring an acceptable\nvelocity and path tracking. The motion planning strategy consists of a\nFren\\'et-Frame-based planner which considers a forecast of the opponent\nproduced by a Kalman filter. The planner chooses the collision-free path and\nvelocity profile to be tracked on a 3 seconds horizon to realize different\ngoals such as following and overtaking. The proposed solution has been applied\non a Dallara AV-21 racecar and tested at oval race tracks achieving lateral\naccelerations up to 25 $m/s^{2}$.",
    "descriptor": "\nComments: Accepted to the 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022)\n",
    "authors": [
      "Ayoub Raji",
      "Alexander Liniger",
      "Andrea Giove",
      "Alessandro Toschi",
      "Nicola Musiu",
      "Daniele Morra",
      "Micaela Verucchi",
      "Danilo Caporale",
      "Marko Bertogna"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.11136"
  },
  {
    "id": "arXiv:2207.11143",
    "title": "Towards Global Optimality in Cooperative MARL with Sequential  Transformation",
    "abstract": "Policy learning in multi-agent reinforcement learning (MARL) is challenging\ndue to the exponential growth of joint state-action space with respect to the\nnumber of agents. To achieve higher scalability, the paradigm of centralized\ntraining with decentralized execution (CTDE) is broadly adopted with factorized\nstructure in MARL. However, we observe that existing CTDE algorithms in\ncooperative MARL cannot achieve optimality even in simple matrix games. To\nunderstand this phenomenon, we introduce a framework of Generalized Multi-Agent\nActor-Critic with Policy Factorization (GPF-MAC), which characterizes the\nlearning of factorized joint policies, i.e., each agent's policy only depends\non its own observation-action history. We show that most popular CTDE MARL\nalgorithms are special instances of GPF-MAC and may be stuck in a suboptimal\njoint policy. To address this issue, we present a novel transformation\nframework that reformulates a multi-agent MDP as a special \"single-agent\" MDP\nwith a sequential structure and can allow employing off-the-shelf single-agent\nreinforcement learning (SARL) algorithms to efficiently learn corresponding\nmulti-agent tasks. This transformation retains the optimality guarantee of SARL\nalgorithms into cooperative MARL. To instantiate this transformation framework,\nwe propose a Transformed PPO, called T-PPO, which can theoretically perform\noptimal policy learning in the finite multi-agent MDPs and shows significant\noutperformance on a large set of cooperative multi-agent tasks.",
    "descriptor": "",
    "authors": [
      "Jianing Ye",
      "Chenghao Li",
      "Jianhao Wang",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11143"
  },
  {
    "id": "arXiv:2207.11146",
    "title": "VTrackIt: A Synthetic Self-Driving Dataset with Infrastructure and  Pooled Vehicle Information",
    "abstract": "Artificial intelligence solutions for Autonomous Vehicles (AVs) have been\ndeveloped using publicly available datasets such as Argoverse, ApolloScape,\nLevel5, and NuScenes. One major limitation of these datasets is the absence of\ninfrastructure and/or pooled vehicle information like lane line type, vehicle\nspeed, traffic signs, and intersections. Such information is necessary and not\ncomplementary to eliminating high-risk edge cases. The rapid advancements in\nVehicle-to-Infrastructure and Vehicle-to-Vehicle technologies show promise that\ninfrastructure and pooled vehicle information will soon be accessible in near\nreal-time. Taking a leap in the future, we introduce the first comprehensive\nsynthetic dataset with intelligent infrastructure and pooled vehicle\ninformation for advancing the next generation of AVs, named VTrackIt. We also\nintroduce the first deep learning model (InfraGAN) for trajectory predictions\nthat considers such information. Our experiments with InfraGAN show that the\ncomprehensive information offered by VTrackIt reduces the number of high-risk\nedge cases. The VTrackIt dataset is available upon request under the Creative\nCommons CC BY-NC-SA 4.0 license at this http URL",
    "descriptor": "",
    "authors": [
      "Mayuresh Savargaonkar",
      "Abdallah Chehade"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.11146"
  },
  {
    "id": "arXiv:2207.11148",
    "title": "InfiniteNature-Zero: Learning Perpetual View Generation of Natural  Scenes from Single Images",
    "abstract": "We present a method for learning to generate unbounded flythrough videos of\nnatural scenes starting from a single view, where this capability is learned\nfrom a collection of single photographs, without requiring camera poses or even\nmultiple views of each scene. To achieve this, we propose a novel\nself-supervised view generation training paradigm, where we sample and\nrendering virtual camera trajectories, including cyclic ones, allowing our\nmodel to learn stable view generation from a collection of single views. At\ntest time, despite never seeing a video during training, our approach can take\na single image and generate long camera trajectories comprised of hundreds of\nnew views with realistic and diverse content. We compare our approach with\nrecent state-of-the-art supervised view generation methods that require posed\nmulti-view videos and demonstrate superior performance and synthesis quality.",
    "descriptor": "\nComments: ECCV 2022 (Oral Presentation)\n",
    "authors": [
      "Zhengqi Li",
      "Qianqian Wang",
      "Noah Snavely",
      "Angjoo Kanazawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11148"
  },
  {
    "id": "arXiv:2207.11149",
    "title": "Block turbo decoding with ORBGRAND",
    "abstract": "Guessing Random Additive Noise Decoding (GRAND) is a family of universal\ndecoding algorithms suitable for decoding any moderate redundancy code of any\nlength. We establish that, through the use of list decoding, soft-input\nvariants of GRAND can replace the Chase algorithm as the component decoder in\nthe turbo decoding of product codes. In addition to being able to decode\narbitrary product codes, rather than just those with dedicated hard-input\ncomponent code decoders, results show that ORBGRAND achieves a coding gain of\nup to 0.2dB over the Chase algorithm as a turbo component decoder, for a\nselection of product codes.",
    "descriptor": "",
    "authors": [
      "Kevin Galligan",
      "Muriel M\u00e9dard",
      "Ken R. Duffy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.11149"
  },
  {
    "id": "arXiv:2207.11155",
    "title": "CQE in OWL 2 QL: A \"Longest Honeymoon\" Approach (extended version)",
    "abstract": "Controlled Query Evaluation (CQE) has been recently studied in the context of\nSemantic Web ontologies. The goal of CQE is concealing some query answers so as\nto prevent external users from inferring confidential information. In general,\nthere exist multiple, mutually incomparable ways of concealing answers, and\nprevious CQE approaches choose in advance which answers are visible and which\nare not. In this paper, instead, we study a dynamic CQE method, namely, we\npropose to alter the answer to the current query based on the evaluation of\nprevious ones. We aim at a system that, besides being able to protect\nconfidential data, is maximally cooperative, which intuitively means that it\nanswers affirmatively to as many queries as possible; it achieves this goal by\ndelaying answer modifications as much as possible. We also show that the\nbehavior we get cannot be intensionally simulated through a static approach,\nindependent of query history. Interestingly, for OWL 2 QL ontologies and policy\nexpressed through denials, query evaluation under our semantics is first-order\nrewritable, and thus in AC0 in data complexity. This paves the way for the\ndevelopment of practical algorithms, which we also preliminarily discuss in the\npaper.",
    "descriptor": "\nComments: This paper is the extended version of \"P.Bonatti, G.Cima, D.Lembo, L.Marconi, R.Rosati, L.Sauro, and D.F.Savo. Controlled query evaluation in OWL 2 QL: A \"Longest Honeymoon\" approach\" accepted for publication at ISWC 2022\n",
    "authors": [
      "Piero Bonatti",
      "Gianluca Cima",
      "Domenico Lembo",
      "Lorenzo Marconi",
      "Riccardo Rosati",
      "Luigi Sauro",
      "Domenico Fabio Savo"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.11155"
  },
  {
    "id": "arXiv:2207.11157",
    "title": "A Hybrid Numerical Algorithm for Evaluating n-th Order Tridiagonal  Determinants",
    "abstract": "The principal minors of a tridiagonal matrix satisfy two-term and three-term\nrecurrences [1, 2]. Based on these facts, the current article presents a new\nefficient and reliable hybrid numerical algorithm for evaluating general n-th\norder tridiagonal determinants in linear time. The hybrid numerical algorithm\navoid all symbolic computations. The algorithm is suited for implementation\nusing computer languages such as FORTRAN, PASCAL, ALGOL, MAPLE, MACSYMA and\nMATHEMATICA. Some illustrative examples are given. Test results indicate the\nsuperiority of the hybrid numerical algorithm.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Moawwad El-Mikkawy",
      "AbdelRahman Karawia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.11157"
  },
  {
    "id": "arXiv:2207.11161",
    "title": "Lagrangian Method for Q-Function Learning (with Applications to Machine  Translation)",
    "abstract": "This paper discusses a new approach to the fundamental problem of learning\noptimal Q-functions. In this approach, optimal Q-functions are formulated as\nsaddle points of a nonlinear Lagrangian function derived from the classic\nBellman optimality equation. The paper shows that the Lagrangian enjoys strong\nduality, in spite of its nonlinearity, which paves the way to a general\nLagrangian method to Q-function learning. As a demonstration, the paper\ndevelops an imitation learning algorithm based on the duality theory, and\napplies the algorithm to a state-of-the-art machine translation benchmark. The\npaper then turns to demonstrate a symmetry breaking phenomenon regarding the\noptimality of the Lagrangian saddle points, which justifies a largely\noverlooked direction in developing the Lagrangian method.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Huang Bojun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.11161"
  },
  {
    "id": "arXiv:2207.11163",
    "title": "Adaptive Soft Contrastive Learning",
    "abstract": "Self-supervised learning has recently achieved great success in\nrepresentation learning without human annotations. The dominant method -- that\nis contrastive learning, is generally based on instance discrimination tasks,\ni.e., individual samples are treated as independent categories. However,\npresuming all the samples are different contradicts the natural grouping of\nsimilar samples in common visual datasets, e.g., multiple views of the same\ndog. To bridge the gap, this paper proposes an adaptive method that introduces\nsoft inter-sample relations, namely Adaptive Soft Contrastive Learning (ASCL).\nMore specifically, ASCL transforms the original instance discrimination task\ninto a multi-instance soft discrimination task, and adaptively introduces\ninter-sample relations. As an effective and concise plug-in module for existing\nself-supervised learning frameworks, ASCL achieves the best performance on\nseveral benchmarks in terms of both performance and efficiency. Code is\navailable at https://github.com/MrChenFeng/ASCL_ICPR2022.",
    "descriptor": "\nComments: Accepted to ICPR2022\n",
    "authors": [
      "Chen Feng",
      "Ioannis Patras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11163"
  },
  {
    "id": "arXiv:2207.11166",
    "title": "METER-ML: A Multi-sensor Earth Observation Benchmark for Automated  Methane Source Mapping",
    "abstract": "Reducing methane emissions is essential for mitigating global warming. To\nattribute methane emissions to their sources, a comprehensive dataset of\nmethane source infrastructure is necessary. Recent advancements with deep\nlearning on remotely sensed imagery have the potential to identify the\nlocations and characteristics of methane sources, but there is a substantial\nlack of publicly available data to enable machine learning researchers and\npractitioners to build automated mapping approaches. To help fill this gap, we\nconstruct a multi-sensor dataset called METER-ML containing 86,625\ngeoreferenced NAIP, Sentinel-1, and Sentinel-2 images in the U.S. labeled for\nthe presence or absence of methane source facilities including concentrated\nanimal feeding operations, coal mines, landfills, natural gas processing\nplants, oil refineries and petroleum terminals, and wastewater treatment\nplants. We experiment with a variety of models that leverage different spatial\nresolutions, spatial footprints, image products, and spectral bands. We find\nthat our best model achieves an area under the precision recall curve of 0.915\nfor identifying concentrated animal feeding operations and 0.821 for oil\nrefineries and petroleum terminals on an expert-labeled test set, suggesting\nthe potential for large-scale mapping. We make METER-ML freely available at\nhttps://stanfordmlgroup.github.io/projects/meter-ml/ to support future work on\nautomated methane source mapping.",
    "descriptor": "\nComments: Workshop on Complex Data Challenges in Earth Observation at IJCAI-ECAI 2022\n",
    "authors": [
      "Bryan Zhu",
      "Nicholas Lui",
      "Jeremy Irvin",
      "Jimmy Le",
      "Sahil Tadwalkar",
      "Chenghao Wang",
      "Zutao Ouyang",
      "Frankie Y. Liu",
      "Andrew Y. Ng",
      "Robert B. Jackson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11166"
  },
  {
    "id": "arXiv:2207.11167",
    "title": "Ten Lessons for Data Sharing With a Data Commons",
    "abstract": "A data commons is a cloud-based data platform with a governance structure\nthat allows a community to manage, analyze and share its data. Data commons\nprovide a research community with the ability to manage and analyze large\ndatasets using the elastic scalability provided by cloud computing and to share\ndata securely and compliantly, and, in this way, accelerate the pace of\nresearch. Over the past decade, a number of data commons have been developed\nand we discuss some of the lessons learned from this effort.",
    "descriptor": "",
    "authors": [
      "Robert L. Grossman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.11167"
  },
  {
    "id": "arXiv:2207.11169",
    "title": "Rethinking Few-Shot Object Detection on a Multi-Domain Benchmark",
    "abstract": "Most existing works on few-shot object detection (FSOD) focus on a setting\nwhere both pre-training and few-shot learning datasets are from a similar\ndomain. However, few-shot algorithms are important in multiple domains; hence\nevaluation needs to reflect the broad applications. We propose a Multi-dOmain\nFew-Shot Object Detection (MoFSOD) benchmark consisting of 10 datasets from a\nwide range of domains to evaluate FSOD algorithms. We comprehensively analyze\nthe impacts of freezing layers, different architectures, and different\npre-training datasets on FSOD performance. Our empirical results show several\nkey factors that have not been explored in previous works: 1) contrary to\nprevious belief, on a multi-domain benchmark, fine-tuning (FT) is a strong\nbaseline for FSOD, performing on par or better than the state-of-the-art (SOTA)\nalgorithms; 2) utilizing FT as the baseline allows us to explore multiple\narchitectures, and we found them to have a significant impact on down-stream\nfew-shot tasks, even with similar pre-training performances; 3) by decoupling\npre-training and few-shot learning, MoFSOD allows us to explore the impact of\ndifferent pre-training datasets, and the right choice can boost the performance\nof the down-stream tasks significantly. Based on these findings, we list\npossible avenues of investigation for improving FSOD performance and propose\ntwo simple modifications to existing algorithms that lead to SOTA performance\non the MoFSOD benchmark. The code is available at\nhttps://github.com/amazon-research/few-shot-object-detection-benchmark.",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Kibok Lee",
      "Hao Yang",
      "Satyaki Chakraborty",
      "Zhaowei Cai",
      "Gurumurthy Swaminathan",
      "Avinash Ravichandran",
      "Onkar Dabeer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11169"
  },
  {
    "id": "arXiv:2207.11171",
    "title": "Silent Spring: Prototype Pollution Leads to Remote Code Execution in  Node.js",
    "abstract": "Prototype pollution is a dangerous vulnerability affecting prototype-based\nlanguages like JavaScript and the Node.js platform. It refers to the ability of\nan attacker to inject properties into an object's root prototype at runtime and\nsubsequently trigger the execution of legitimate code gadgets that access these\nproperties on the object's prototype, leading to attacks such as DoS, privilege\nescalation, and remote code execution (RCE). While there is anecdotal evidence\nthat prototype pollution leads to RCE, current research does not tackle the\nchallenge of gadget detection, thus only showing feasibility of DoS attacks\nagainst Node.js libraries.\nIn this paper, we set out to study the problem in a holistic way, from the\ndetection of prototype pollution to detection of gadgets, with the ambitious\ngoal of finding end-to-end exploits beyond DoS, in full-fledged Node.js\napplications. We build the first multi-staged framework that uses multi-label\nstatic taint analysis to identify prototype pollution in Node.js libraries and\napplications, as well as a hybrid approach to detect universal gadgets,\nnotably, by analyzing the Node.js source code. We implement our framework on\ntop of GitHub's static analysis framework CodeQL to find 11 universal gadgets\nin core Node.js APIs, leading to code execution. Furthermore, we use our\nmethodology in a study of 15 popular Node.js applications to identify prototype\npollutions and gadgets. We manually exploit RCE in two high-profile\napplications. Our results provide alarming evidence that prototype pollution in\ncombination with powerful universal gadgets lead to RCE in Node.js.",
    "descriptor": "\nComments: To appear at USENIX Security'23\n",
    "authors": [
      "Mikhail Shcherbakov",
      "Musard Balliu",
      "Cristian-Alexandru Staicu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.11171"
  },
  {
    "id": "arXiv:2207.11172",
    "title": "Decentralized scheduling through an adaptive, trading-based multi-agent  system",
    "abstract": "In multi-agent reinforcement learning systems, the actions of one agent can\nhave a negative impact on the rewards of other agents. One way to combat this\nproblem is to let agents trade their rewards amongst each other. Motivated by\nthis, this work applies a trading approach to a simulated scheduling\nenvironment, where the agents are responsible for the assignment of incoming\njobs to compute cores. In this environment, reinforcement learning agents learn\nto trade successfully. The agents can trade the usage right of computational\ncores to process high-priority, high-reward jobs faster than low-priority,\nlow-reward jobs. However, due to combinatorial effects, the action and\nobservation spaces of a simple reinforcement learning agent in this environment\nscale exponentially with key parameters of the problem size. However, the\nexponential scaling behavior can be transformed into a linear one if the agent\nis split into several independent sub-units. We further improve this\ndistributed architecture using agent-internal parameter sharing. Moreover, it\ncan be extended to set the exchange prices autonomously. We show that in our\nscheduling environment, the advantages of a distributed agent architecture\nclearly outweigh more aggregated approaches. We demonstrate that the\ndistributed agent architecture becomes even more performant using\nagent-internal parameter sharing. Finally, we investigate how two different\nreward functions affect autonomous pricing and the corresponding scheduling.",
    "descriptor": "\nComments: Accepted at ABMHuB 2022 workshop\n",
    "authors": [
      "Michael K\u00f6lle",
      "Lennart Rietdorf",
      "Kyrill Schmid"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11172"
  },
  {
    "id": "arXiv:2207.11175",
    "title": "Explaining Dynamic Graph Neural Networks via Relevance Back-propagation",
    "abstract": "Graph Neural Networks (GNNs) have shown remarkable effectiveness in capturing\nabundant information in graph-structured data. However, the black-box nature of\nGNNs hinders users from understanding and trusting the models, thus leading to\ndifficulties in their applications. While recent years witness the prosperity\nof the studies on explaining GNNs, most of them focus on static graphs, leaving\nthe explanation of dynamic GNNs nearly unexplored. It is challenging to explain\ndynamic GNNs, due to their unique characteristic of time-varying graph\nstructures. Directly using existing models designed for static graphs on\ndynamic graphs is not feasible because they ignore temporal dependencies among\nthe snapshots. In this work, we propose DGExplainer to provide reliable\nexplanation on dynamic GNNs. DGExplainer redistributes the output activation\nscore of a dynamic GNN to the relevances of the neurons of its previous layer,\nwhich iterates until the relevance scores of the input neuron are obtained. We\nconduct quantitative and qualitative experiments on real-world datasets to\ndemonstrate the effectiveness of the proposed framework for identifying\nimportant nodes for link prediction and node regression for dynamic GNNs.",
    "descriptor": "",
    "authors": [
      "Jiaxuan Xie",
      "Yezi Liu",
      "Yanning Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11175"
  },
  {
    "id": "arXiv:2207.11177",
    "title": "Training Certifiably Robust Neural Networks Against Semantic  Perturbations",
    "abstract": "Semantic image perturbations, such as scaling and rotation, have been shown\nto easily deceive deep neural networks (DNNs). Hence, training DNNs to be\ncertifiably robust to these perturbations is critical. However, no prior work\nhas been able to incorporate the objective of deterministic semantic robustness\ninto the training procedure, as existing deterministic semantic verifiers are\nexceedingly slow. To address these challenges, we propose Certified Semantic\nTraining (CST), the first training framework for deterministic certified\nrobustness against semantic image perturbations. Our framework leverages a\nnovel GPU-optimized verifier that, unlike existing works, is fast enough for\nuse in training. Our results show that networks trained via CST consistently\nachieve both better provable semantic robustness and clean accuracy, compared\nto networks trained via baselines based on existing works.",
    "descriptor": "",
    "authors": [
      "Rem Yang",
      "Jacob Laurel",
      "Sasa Misailovic",
      "Gagandeep Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11177"
  },
  {
    "id": "arXiv:2207.11181",
    "title": "Secure and Lightweight Strong PUF Challenge Obfuscation with Keyed  Non-linear FSR",
    "abstract": "We propose a secure and lightweight key based challenge obfuscation for\nstrong PUFs. Our architecture is designed to be resilient against learning\nattacks. Our obfuscation mechanism uses non-linear feedback shift registers\n(NLFSRs). Responses are directly provided to the user, without error correction\nor extra post-processing steps. We also discuss the cost of protecting our\narchitecture against power analysis attacks with clock randomization, and\nBoolean masking. Security against learning attacks is assessed using avalanche\ncriterion, and deep-neural network attacks. We designed a testchip in 65 nm\nCMOS. When compared to the baseline arbiter PUF implementation, the cost\nincrease of our proposed architecture is 1.27x, and 2.2x when using clock\nrandomization, and Boolean masking, respectively.",
    "descriptor": "",
    "authors": [
      "Kleber Stangherlin",
      "Zhuanhao Wu",
      "Hiren Patel",
      "Manoj Sachdev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.11181"
  },
  {
    "id": "arXiv:2207.11184",
    "title": "Multi-Faceted Distillation of Base-Novel Commonality for Few-shot Object  Detection",
    "abstract": "Most of existing methods for few-shot object detection follow the fine-tuning\nparadigm, which potentially assumes that the class-agnostic generalizable\nknowledge can be learned and transferred implicitly from base classes with\nabundant samples to novel classes with limited samples via such a two-stage\ntraining strategy. However, it is not necessarily true since the object\ndetector can hardly distinguish between class-agnostic knowledge and\nclass-specific knowledge automatically without explicit modeling. In this work\nwe propose to learn three types of class-agnostic commonalities between base\nand novel classes explicitly: recognition-related semantic commonalities,\nlocalization-related semantic commonalities and distribution commonalities. We\ndesign a unified distillation framework based on a memory bank, which is able\nto perform distillation of all three types of commonalities jointly and\nefficiently. Extensive experiments demonstrate that our method can be readily\nintegrated into most of existing fine-tuning based methods and consistently\nimprove the performance by a large margin.",
    "descriptor": "",
    "authors": [
      "Shuang Wu",
      "Wenjie Pei",
      "Dianwen Mei",
      "Fanglin Chen",
      "Jiandong Tian",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11184"
  },
  {
    "id": "arXiv:2207.11186",
    "title": "Learning to identify cracks on wind turbine blade surfaces using  drone-based inspection images",
    "abstract": "Wind energy is expected to be one of the leading ways to achieve the goals of\nthe Paris Agreement but it in turn heavily depends on effective management of\nits operations and maintenance (O&M) costs. Blade failures account for\none-third of all O&M costs thus making accurate detection of blade damages,\nespecially cracks, very important for sustained operations and cost savings.\nTraditionally, damage inspection has been a completely manual process thus\nmaking it subjective, error-prone, and time-consuming. Hence in this work, we\nbring more objectivity, scalability, and repeatability in our damage inspection\nprocess, using deep learning, to miss fewer cracks. We build a deep learning\nmodel trained on a large dataset of blade damages, collected by our drone-based\ninspection, to correctly detect cracks. Our model is already in production and\nhas processed more than a million damages with a recall of 0.96. We also focus\non model interpretability using class activation maps to get a peek into the\nmodel workings. The model not only performs as good as human experts but also\nbetter in certain tricky cases. Thus, in this work, we aim to increase wind\nenergy adoption by decreasing one of its major hurdles - the O\\&M costs\nresulting from missing blade failures like cracks.",
    "descriptor": "\nComments: NeurIPS 2021 Workshop on Tackling Climate Change with Machine Learning\n",
    "authors": [
      "Akshay Iyer",
      "Linh Nguyen",
      "Shweta Khushu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.11186"
  },
  {
    "id": "arXiv:2207.11187",
    "title": "TaDaa: real time Ticket Assignment Deep learning Auto Advisor for  customer support, help desk, and issue ticketing systems",
    "abstract": "This paper proposes TaDaa: Ticket Assignment Deep learning Auto Advisor,\nwhich leverages the latest Transformers models and machine learning techniques\nquickly assign issues within an organization, like customer support, help desk\nand alike issue ticketing systems. The project provides functionality to 1)\nassign an issue to the correct group, 2) assign an issue to the best resolver,\nand 3) provide the most relevant previously solved tickets to resolvers. We\nleverage one ticketing system sample dataset, with over 3k+ groups and over\n10k+ resolvers to obtain a 95.2% top 3 accuracy on group suggestions and a\n79.0% top 5 accuracy on resolver suggestions. We hope this research will\ngreatly improve average issue resolution time on customer support, help desk,\nand issue ticketing systems.",
    "descriptor": "",
    "authors": [
      "Leon Feng",
      "Jnana Senapati",
      "Bill Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11187"
  },
  {
    "id": "arXiv:2207.11191",
    "title": "Self-Supervised-RCNN for Medical Image Segmentation with Limited Data  Annotation",
    "abstract": "Many successful methods developed for medical image analysis that are based\non machine learning use supervised learning approaches, which often require\nlarge datasets annotated by experts to achieve high accuracy. However, medical\ndata annotation is time-consuming and expensive, especially for segmentation\ntasks. To solve the problem of learning with limited labeled medical image\ndata, an alternative deep learning training strategy based on self-supervised\npretraining on unlabeled MRI scans is proposed in this work. Our pretraining\napproach first, randomly applies different distortions to random areas of\nunlabeled images and then predicts the type of distortions and loss of\ninformation. To this aim, an improved version of Mask-RCNN architecture has\nbeen adapted to localize the distortion location and recover the original image\npixels. The effectiveness of the proposed method for segmentation tasks in\ndifferent pre-training and fine-tuning scenarios is evaluated based on the\nOsteoarthritis Initiative dataset. Using this self-supervised pretraining\nmethod improved the Dice score by 20% compared to training from scratch. The\nproposed self-supervised learning is simple, effective, and suitable for\ndifferent ranges of medical image analysis tasks including anomaly detection,\nsegmentation, and classification.",
    "descriptor": "",
    "authors": [
      "Banafshe Felfeliyan",
      "Abhilash Hareendranathan",
      "Gregor Kuntze",
      "David Cornell",
      "Nils D. Forkert",
      "Jacob L. Jaremko",
      "Janet L. Ronsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11191"
  },
  {
    "id": "arXiv:2207.11192",
    "title": "Progressive Deblurring of Diffusion Models for Coarse-to-Fine Image  Synthesis",
    "abstract": "Recently, diffusion models have shown remarkable results in image synthesis\nby gradually removing noise and amplifying signals. Although the simple\ngenerative process surprisingly works well, is this the best way to generate\nimage data? For instance, despite the fact that human perception is more\nsensitive to the low frequencies of an image, diffusion models themselves do\nnot consider any relative importance of each frequency component. Therefore, to\nincorporate the inductive bias for image data, we propose a novel generative\nprocess that synthesizes images in a coarse-to-fine manner. First, we\ngeneralize the standard diffusion models by enabling diffusion in a rotated\ncoordinate system with different velocities for each component of the vector.\nWe further propose a blur diffusion as a special case, where each frequency\ncomponent of an image is diffused at different speeds. Specifically, the\nproposed blur diffusion consists of a forward process that blurs an image and\nadds noise gradually, after which a corresponding reverse process deblurs an\nimage and removes noise progressively. Experiments show that the proposed model\noutperforms the previous method in FID on LSUN bedroom and church datasets.\nCode is available at https://github.com/sangyun884/blur-diffusion.",
    "descriptor": "",
    "authors": [
      "Sangyun Lee",
      "Hyungjin Chung",
      "Jaehyeon Kim",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11192"
  },
  {
    "id": "arXiv:2207.11196",
    "title": "Learning to Singulate Layers of Cloth using Tactile Feedback",
    "abstract": "Robotic manipulation of cloth has applications ranging from fabrics\nmanufacturing to handling blankets and laundry. Cloth manipulation is\nchallenging for robots largely due to their high degrees of freedom, complex\ndynamics, and severe self-occlusions when in folded or crumpled configurations.\nPrior work on robotic manipulation of cloth relies primarily on vision sensors\nalone, which may pose challenges for fine-grained manipulation tasks such as\ngrasping a desired number of cloth layers from a stack of cloth. In this paper,\nwe propose to use tactile sensing for cloth manipulation; we attach a tactile\nsensor (ReSkin) to one of the two fingertips of a Franka robot and train a\nclassifier to determine whether the robot is grasping a specific number of\ncloth layers. During test-time experiments, the robot uses this classifier as\npart of its policy to grasp one or two cloth layers using tactile feedback to\ndetermine suitable grasping points. Experimental results over 180 physical\ntrials suggest that the proposed method outperforms baselines that do not use\ntactile feedback and has better generalization to unseen cloth compared to\nmethods that use image classifiers. Code, data, and videos are available at\nhttps://sites.google.com/view/reskin-cloth.",
    "descriptor": "\nComments: IROS 2022. See this https URL for supplementary material\n",
    "authors": [
      "Sashank Tirumala",
      "Thomas Weng",
      "Daniel Seita",
      "Oliver Kroemer",
      "Zeynep Temel",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.11196"
  },
  {
    "id": "arXiv:2207.11198",
    "title": "Fault Tolerant Coloring of the Asynchronous Cycle",
    "abstract": "We present a wait-free algorithm for proper coloring the n nodes of the\nasynchronous cycle $C_n$, where each crash-prone node starts with its (unique)\nidentifier as input. The algorithm is independent of $n \\geq 3$, and runs in\n$\\mathrm{O}(\\log^* n)$ rounds in $C_n$. This round-complexity is optimal thanks\nto a known matching lower bound, which applies even to synchronous\n(failure-free) executions. The range of colors used by our algorithm, namely\n$\\{0, ..., 4\\}$, is optimal too, thanks to a known lower bound on the minimum\nnumber of names for which renaming is solvable wait-free in shared-memory\nsystems, whenever $n$ is a power of a prime. Indeed, our model coincides with\nthe shared-memory model whenever $n = 3$, and the minimum number of names for\nwhich renaming is possible in 3-process shared-memory systems is 5.",
    "descriptor": "",
    "authors": [
      "Pierre Fraigniaud",
      "Patrick Lambein-Monette",
      "Mika\u00ebl Rabie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.11198"
  },
  {
    "id": "arXiv:2207.11201",
    "title": "Target-Driven Structured Transformer Planner for Vision-Language  Navigation",
    "abstract": "Vision-language navigation is the task of directing an embodied agent to\nnavigate in 3D scenes with natural language instructions. For the agent,\ninferring the long-term navigation target from visual-linguistic clues is\ncrucial for reliable path planning, which, however, has rarely been studied\nbefore in literature. In this article, we propose a Target-Driven Structured\nTransformer Planner (TD-STP) for long-horizon goal-guided and room layout-aware\nnavigation. Specifically, we devise an Imaginary Scene Tokenization mechanism\nfor explicit estimation of the long-term target (even located in unexplored\nenvironments). In addition, we design a Structured Transformer Planner which\nelegantly incorporates the explored room layout into a neural attention\narchitecture for structured and global planning. Experimental results\ndemonstrate that our TD-STP substantially improves previous best methods'\nsuccess rate by 2% and 5% on the test set of R2R and REVERIE benchmarks,\nrespectively. Our code is available at https://github.com/YushengZhao/TD-STP .",
    "descriptor": "",
    "authors": [
      "Yusheng Zhao",
      "Jinyu Chen",
      "Chen Gao",
      "Wenguan Wang",
      "Lirong Yang",
      "Haibing Ren",
      "Huaxia Xia",
      "Si Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11201"
  },
  {
    "id": "arXiv:2207.11205",
    "title": "Toward a Generic Mapping Language for Transformations between RDF and  Data Interchange Formats",
    "abstract": "While there exist approaches to integrate heterogeneous data using semantic\nmodels, such semantic models can typically not be used by existing software\ntools. Many software tools - especially in engineering - only have options to\nimport and export data in more established data interchange formats such as XML\nor JSON. Thus, if an information which is included in a semantic model needs to\nbe used in a such a software tool, automatic approaches for mapping semantic\ninformation into an interchange format are needed. We aim to develop a generic\nmapping approach that allows users to create transformations of semantic\ninformation into a data interchange format with an arbitrary structure which\ncan be defined by a user. This mapping approach is currently being elaborated.\nIn this contribution, we report our initial steps targeted to transformations\nfrom RDF into XML. At first, a mapping language is introduced which allows to\ndefine automated mappings from ontologies to XML. Furthermore, a mapping\nalgorithm capable of executing mappings defined in this language is presented.\nAn evaluation is done with a use case in which engineering information needs to\nbe used in a 3D modeling tool.",
    "descriptor": "",
    "authors": [
      "Aljosha K\u00f6cher",
      "Artan Markaj",
      "Alexander Fay"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.11205"
  },
  {
    "id": "arXiv:2207.11209",
    "title": "Divide and Conquer: 3D Point Cloud Instance Segmentation With Point-Wise  Binarization",
    "abstract": "Instance segmentation on point clouds is crucially important for 3D scene\nunderstanding. Distance clustering is commonly used in state-of-the-art methods\n(SOTAs), which is typically effective but does not perform well in segmenting\nadjacent objects with the same semantic label (especially when they share\nneighboring points). Due to the uneven distribution of offset points, these\nexisting methods can hardly cluster all instance points. To this end, we design\na novel divide and conquer strategy and propose an end-to-end network named\nPBNet that binarizes each point and clusters them separately to segment\ninstances. PBNet divides offset instance points into two categories: high and\nlow density points (HPs vs.LPs), which are then conquered separately. Adjacent\nobjects can be clearly separated by removing LPs, and then be completed and\nrefined by assigning LPs via a neighbor voting method. To further reduce\nclustering errors, we develop an iterative merging algorithm based on mean size\nto aggregate fragment instances. Experiments on ScanNetV2 and S3DIS datasets\nindicate the superiority of our model. In particular, PBNet achieves so far the\nbest AP50 and AP25 on the ScanNetV2 official benchmark challenge (Validation\nSet) while demonstrating high efficiency.",
    "descriptor": "",
    "authors": [
      "Weiguang Zhao",
      "Yuyao Yan",
      "Chaolong Yang",
      "Jianan Ye",
      "Xi Yang",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11209"
  },
  {
    "id": "arXiv:2207.11211",
    "title": "Improving Predictive Performance and Calibration by Weight Fusion in  Semantic Segmentation",
    "abstract": "Averaging predictions of a deep ensemble of networks is apopular and\neffective method to improve predictive performance andcalibration in various\nbenchmarks and Kaggle competitions. However, theruntime and training cost of\ndeep ensembles grow linearly with the size ofthe ensemble, making them\nunsuitable for many applications. Averagingensemble weights instead of\npredictions circumvents this disadvantageduring inference and is typically\napplied to intermediate checkpoints ofa model to reduce training cost. Albeit\neffective, only few works haveimproved the understanding and the performance of\nweight averaging.Here, we revisit this approach and show that a simple weight\nfusion (WF)strategy can lead to a significantly improved predictive performance\nandcalibration. We describe what prerequisites the weights must meet interms of\nweight space, functional space and loss. Furthermore, we presenta new test\nmethod (called oracle test) to measure the functional spacebetween weights. We\ndemonstrate the versatility of our WF strategy acrossstate of the art\nsegmentation CNNs and Transformers as well as real worlddatasets such as\nBDD100K and Cityscapes. We compare WF with similarapproaches and show our\nsuperiority for in- and out-of-distribution datain terms of predictive\nperformance and calibration.",
    "descriptor": "",
    "authors": [
      "Timo S\u00e4mann",
      "Ahmed Mostafa Hammam",
      "Andrei Bursuc",
      "Christoph Stiller",
      "Horst-Michael Gro\u00df"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11211"
  },
  {
    "id": "arXiv:2207.11212",
    "title": "Target Identification and Bayesian Model Averaging with Probabilistic  Hierarchical Factor Probabilities",
    "abstract": "Target detection in hyperspectral imagery is the process of locating pixels\nfrom an image which are likely to contain target, typically done by comparing\none or more spectra for the desired target material to each pixel in the image.\nTarget identification is the process of target detection incorporating an\nadditional process to identify more specifically the material that is present\nin each pixel that scored high in detection. Detection is generally a 2-class\nproblem of target vs. background, and identification is a many class problem\nincluding target, background, and additional know materials. The identification\nprocess we present is probabilistic and hierarchical which provides\ntransparency to the process and produces trustworthy output. In this paper we\nshow that target identification has a much lower false alarm rate than\ndetection alone, and provide a detailed explanation of a robust identification\nmethod using probabilistic hierarchical classification that handles the vague\ncategories of materials that depend on users which are different than the\nspecific physical categories of chemical constituents. Identification is often\ndone by comparing mixtures of materials including the target spectra to\nmixtures of materials that do not include the target spectra, possibly with\nother steps. (band combinations, feature checking, background removal, etc.)\nStandard linear regression does not handle these problems well because the\nnumber of regressors (identification spectra) is greater than the number of\nfeature variables (bands), and there are multiple correlated spectra. Our\nproposed method handles these challenges efficiently and provides additional\nimportant practical information in the form of hierarchical probabilities\ncomputed from Bayesian model averaging.",
    "descriptor": "",
    "authors": [
      "William Basener"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2207.11212"
  },
  {
    "id": "arXiv:2207.11213",
    "title": "Few-Shot Class-Incremental Learning via Entropy-Regularized Data-Free  Replay",
    "abstract": "Few-shot class-incremental learning (FSCIL) has been proposed aiming to\nenable a deep learning system to incrementally learn new classes with limited\ndata. Recently, a pioneer claims that the commonly used replay-based method in\nclass-incremental learning (CIL) is ineffective and thus not preferred for\nFSCIL. This has, if truth, a significant influence on the fields of FSCIL. In\nthis paper, we show through empirical results that adopting the data replay is\nsurprisingly favorable. However, storing and replaying old data can lead to a\nprivacy concern. To address this issue, we alternatively propose using\ndata-free replay that can synthesize data by a generator without accessing real\ndata. In observing the the effectiveness of uncertain data for knowledge\ndistillation, we impose entropy regularization in the generator training to\nencourage more uncertain examples. Moreover, we propose to relabel the\ngenerated data with one-hot-like labels. This modification allows the network\nto learn by solely minimizing the cross-entropy loss, which mitigates the\nproblem of balancing different objectives in the conventional knowledge\ndistillation approach. Finally, we show extensive experimental results and\nanalysis on CIFAR-100, miniImageNet and CUB-200 to demonstrate the\neffectiveness of our proposed one.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Huan Liu",
      "Li Gu",
      "Zhixiang Chi",
      "Yang Wang",
      "Yuanhao Yu",
      "Jun Chen",
      "Jin Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11213"
  },
  {
    "id": "arXiv:2207.11215",
    "title": "Numerical integration of stochastic contact Hamiltonian systems via  stochastic Herglotz variational principle",
    "abstract": "In this work we construct a stochastic contact variational integrator and its\ndiscrete version via stochastic Herglotz variational principle for stochastic\ncontact Hamiltonian systems. A general structure-preserving stochastic contact\nmethod is devised, and the stochastic contact variational integrators are\nestablished. The implementation of this approach is validated by the numerical\nexperiments.",
    "descriptor": "\nComments: 24 pages,15 figures\n",
    "authors": [
      "Qingyi Zhan",
      "Jinqiao Duan",
      "Xiaofan Li",
      "Yuhong Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.11215"
  },
  {
    "id": "arXiv:2207.11221",
    "title": "Domain Generalization for Activity Recognition via Adaptive Feature  Fusion",
    "abstract": "Human activity recognition requires the efforts to build a generalizable\nmodel using the training datasets with the hope to achieve good performance in\ntest datasets. However, in real applications, the training and testing datasets\nmay have totally different distributions due to various reasons such as\ndifferent body shapes, acting styles, and habits, damaging the model's\ngeneralization performance. While such a distribution gap can be reduced by\nexisting domain adaptation approaches, they typically assume that the test data\ncan be accessed in the training stage, which is not realistic. In this paper,\nwe consider a more practical and challenging scenario: domain-generalized\nactivity recognition (DGAR) where the test dataset \\emph{cannot} be accessed\nduring training. To this end, we propose \\emph{Adaptive Feature Fusion for\nActivity Recognition~(AFFAR)}, a domain generalization approach that learns to\nfuse the domain-invariant and domain-specific representations to improve the\nmodel's generalization performance. AFFAR takes the best of both worlds where\ndomain-invariant representations enhance the transferability across domains and\ndomain-specific representations leverage the model discrimination power from\neach domain. Extensive experiments on three public HAR datasets show its\neffectiveness. Furthermore, we apply AFFAR to a real application, i.e., the\ndiagnosis of Children's Attention Deficit Hyperactivity Disorder~(ADHD), which\nalso demonstrates the superiority of our approach.",
    "descriptor": "\nComments: Accepted by ACM Transactions on Intelligent Systems and Technology (TIST) 2022; Code: this https URL\n",
    "authors": [
      "Xin Qin",
      "Jindong Wang",
      "Yiqiang Chen",
      "Wang Lu",
      "Xinlong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11221"
  },
  {
    "id": "arXiv:2207.11222",
    "title": "Forest and Water Bodies Segmentation Through Satellite Images Using  U-Net",
    "abstract": "Global environment monitoring is a task that requires additional attention in\nthe contemporary rapid climate change environment. This includes monitoring the\nrate of deforestation and areas affected by flooding. Satellite imaging has\ngreatly helped monitor the earth, and deep learning techniques have helped to\nautomate this monitoring process. This paper proposes a solution for observing\nthe area covered by the forest and water. To achieve this task UNet model has\nbeen proposed, which is an image segmentation model. The model achieved a\nvalidation accuracy of 82.55% and 82.92% for the segmentation of areas covered\nby forest and water, respectively.",
    "descriptor": "",
    "authors": [
      "Dmytro Filatov",
      "Ghulam Nabi Ahmad Hassan Yar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.11222"
  },
  {
    "id": "arXiv:2207.11224",
    "title": "Humans plan for the near future to walk economically on uneven terrain",
    "abstract": "Humans experience small fluctuations in their gait when walking on uneven\nterrain. The fluctuations deviate from the steady, energy-minimizing pattern\nfor level walking, and have no obvious organization. But humans often look\nahead when they walk, and could potentially plan anticipatory fluctuations for\nthe terrain. Such planning is only sensible if it serves some an objective\npurpose, such as maintaining constant speed or reducing energy expenditure,\nthat is also attainable within finite planning capacity. Here we show that\nhumans do plan and perform optimal control strategies on uneven terrain. Rather\nthan maintain constant speed, they make purposeful, anticipatory speed\nadjustments that are consistent with minimizing energy expenditure. A simple\noptimal control model predicts economical speed fluctuations that agree well\nwith experiments with humans (N = 12) walking on seven different terrain\nprofiles (correlated with model r = 0.517 std. 0.109, P < 0.05 all terrains).\nParticipants made repeatable speed fluctuations starting about seven to eight\nsteps ahead of each terrain feature (up to 7.5 cm height difference each step,\nup to 16 consecutive features). They need not plan farther ahead, because each\nleg collision with ground dissipates energy, preventing momentum from\npersisting indefinitely. About seven to eight steps of continuous look-ahead\nand working memory thus suffice to practically optimize for any length of\nterrain. Humans reason about walking in the near future to plan complex optimal\ncontrol sequences.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Osman Darici",
      "Arthur D. Kuo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2207.11224"
  },
  {
    "id": "arXiv:2207.11226",
    "title": "FewGAN: Generating from the Joint Distribution of a Few Images",
    "abstract": "We introduce FewGAN, a generative model for generating novel, high-quality\nand diverse images whose patch distribution lies in the joint patch\ndistribution of a small number of N>1 training samples. The method is, in\nessence, a hierarchical patch-GAN that applies quantization at the first coarse\nscale, in a similar fashion to VQ-GAN, followed by a pyramid of residual fully\nconvolutional GANs at finer scales. Our key idea is to first use quantization\nto learn a fixed set of patch embeddings for training images. We then use a\nseparate set of side images to model the structure of generated images using an\nautoregressive model trained on the learned patch embeddings of training\nimages. Using quantization at the coarsest scale allows the model to generate\nboth conditional and unconditional novel images. Subsequently, a patch-GAN\nrenders the fine details, resulting in high-quality images. In an extensive set\nof experiments, it is shown that FewGAN outperforms baselines both\nquantitatively and qualitatively.",
    "descriptor": "",
    "authors": [
      "Lior Ben-Moshe",
      "Sagie Benaim",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11226"
  },
  {
    "id": "arXiv:2207.11227",
    "title": "Face editing with GAN -- A Review",
    "abstract": "In recent years, Generative Adversarial Networks (GANs) have become a hot\ntopic among researchers and engineers that work with deep learning. It has been\na ground-breaking technique which can generate new pieces of content of data in\na consistent way. The topic of GANs has exploded in popularity due to its\napplicability in fields like image generation and synthesis, and music\nproduction and composition. GANs have two competing neural networks: a\ngenerator and a discriminator. The generator is used to produce new samples or\npieces of content, while the discriminator is used to recognize whether the\npiece of content is real or generated. What makes it different from other\ngenerative models is its ability to learn unlabeled samples. In this review\npaper, we will discuss the evolution of GANs, several improvements proposed by\nthe authors and a brief comparison between the different models. Index Terms\ngenerative adversarial networks, unsupervised learning, deep learning.",
    "descriptor": "",
    "authors": [
      "Parthak Mehta",
      "Sarthak Mishra",
      "Nikhil Chouhan",
      "Neel Pethani",
      "Ishani Saha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.11227"
  },
  {
    "id": "arXiv:2207.11228",
    "title": "Classifying Crop Types using Gaussian Bayesian Models and Neural  Networks on GHISACONUS USGS data from NASA Hyperspectral Satellite Imagery",
    "abstract": "Hyperspectral Imagining is a type of digital imaging in which each pixel\ncontains typically hundreds of wavelengths of light providing spectroscopic\ninformation about the materials present in the pixel. In this paper we provide\nclassification methods for determining crop type in the USGS GHISACONUS data,\nwhich contains around 7,000 pixel spectra from the five major U.S. agricultural\ncrops (winter wheat, rice, corn, soybeans, and cotton) collected by the NASA\nHyperion satellite, and includes the spectrum, geolocation, crop type, and\nstage of growth for each pixel. We apply standard LDA and QDA as well as\nBayesian custom versions that compute the joint probability of crop type and\nstage, and then the marginal probability for crop type, outperforming the\nnon-Bayesian methods. We also test a single layer neural network with dropout\non the data, which performs comparable to LDA and QDA but not as well as the\nBayesian methods.",
    "descriptor": "",
    "authors": [
      "Bill Basener"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.11228"
  },
  {
    "id": "arXiv:2207.11229",
    "title": "Flow Moods: Recommending Music by Moods on Deezer",
    "abstract": "The music streaming service Deezer extensively relies on its Flow algorithm,\nwhich generates personalized radio-style playlists of songs, to help users\ndiscover musical content. Nonetheless, despite promising results over the past\nyears, Flow used to ignore the moods of users when providing recommendations.\nIn this paper, we present Flow Moods, an improved version of Flow that\naddresses this limitation. Flow Moods leverages collaborative filtering, audio\ncontent analysis, and mood annotations from professional music curators to\ngenerate personalized mood-specific playlists at scale. We detail the\nmotivations, the development, and the deployment of this system on Deezer.\nSince its release in 2021, Flow Moods has been recommending music by moods to\nmillions of users every day.",
    "descriptor": "\nComments: 16th ACM Conference on Recommender Systems (RecSys 2022) - Industry paper\n",
    "authors": [
      "Th\u00e9o Bontempelli",
      "Benjamin Chapus",
      "Fran\u00e7ois Rigaud",
      "Mathieu Morlon",
      "Marin Lorant",
      "Guillaume Salha-Galvan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11229"
  },
  {
    "id": "arXiv:2207.11230",
    "title": "You Actually Look Twice At it (YALTAi): using an object detection  approach instead of region segmentation within the Kraken engine",
    "abstract": "Layout Analysis (the identification of zones and their classification) is the\nfirst step along line segmentation in Optical Character Recognition and similar\ntasks. The ability of identifying main body of text from marginal text or\nrunning titles makes the difference between extracting the work full text of a\ndigitized book and noisy outputs. We show that most segmenters focus on pixel\nclassification and that polygonization of this output has not been used as a\ntarget for the latest competition on historical document (ICDAR 2017 and\nonwards), despite being the focus in the early 2010s. We propose to shift, for\nefficiency, the task from a pixel classification-based polygonization to an\nobject detection using isothetic rectangles. We compare the output of Kraken\nand YOLOv5 in terms of segmentation and show that the later severely\noutperforms the first on small datasets (1110 samples and below). We release\ntwo datasets for training and evaluation on historical documents as well as a\nnew package, YALTAi, which injects YOLOv5 in the segmentation pipeline of\nKraken 4.1.",
    "descriptor": "",
    "authors": [
      "Thibault Cl\u00e9rice"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.11230"
  },
  {
    "id": "arXiv:2207.11231",
    "title": "Learning Unsupervised Hierarchies of Audio Concepts",
    "abstract": "Music signals are difficult to interpret from their low-level features,\nperhaps even more than images: e.g. highlighting part of a spectrogram or an\nimage is often insufficient to convey high-level ideas that are genuinely\nrelevant to humans. In computer vision, concept learning was therein proposed\nto adjust explanations to the right abstraction level (e.g. detect clinical\nconcepts from radiographs). These methods have yet to be used for MIR.\nIn this paper, we adapt concept learning to the realm of music, with its\nparticularities. For instance, music concepts are typically non-independent and\nof mixed nature (e.g. genre, instruments, mood), unlike previous work that\nassumed disentangled concepts. We propose a method to learn numerous music\nconcepts from audio and then automatically hierarchise them to expose their\nmutual relationships. We conduct experiments on datasets of playlists from a\nmusic streaming service, serving as a few annotated examples for diverse\nconcepts. Evaluations show that the mined hierarchies are aligned with both\nground-truth hierarchies of concepts -- when available -- and with proxy\nsources of concept similarity in the general case.",
    "descriptor": "\nComments: ISMIR 2022\n",
    "authors": [
      "Darius Afchar",
      "Romain Hennequin",
      "Vincent Guigue"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.11231"
  },
  {
    "id": "arXiv:2207.11232",
    "title": "Seeing 3D Objects in a Single Image via Self-Supervised Static-Dynamic  Disentanglement",
    "abstract": "Human perception reliably identifies movable and immovable parts of 3D\nscenes, and completes the 3D structure of objects and background from\nincomplete observations. We learn this skill not via labeled examples, but\nsimply by observing objects move. In this work, we propose an approach that\nobserves unlabeled multi-view videos at training time and learns to map a\nsingle image observation of a complex scene, such as a street with cars, to a\n3D neural scene representation that is disentangled into movable and immovable\nparts while plausibly completing its 3D structure. We separately parameterize\nmovable and immovable scene parts via 2D neural ground plans. These ground\nplans are 2D grids of features aligned with the ground plane that can be\nlocally decoded into 3D neural radiance fields. Our model is trained\nself-supervised via neural rendering. We demonstrate that the structure\ninherent to our disentangled 3D representation enables a variety of downstream\ntasks in street-scale 3D scenes using simple heuristics, such as extraction of\nobject-centric 3D representations, novel view synthesis, instance segmentation,\nand 3D bounding box prediction, highlighting its value as a backbone for\ndata-efficient 3D scene understanding models. This disentanglement further\nenables scene editing via object manipulation such as deletion, insertion, and\nrigid-body motion.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Prafull Sharma",
      "Ayush Tewari",
      "Yilun Du",
      "Sergey Zakharov",
      "Rares Ambrus",
      "Adrien Gaidon",
      "William T. Freeman",
      "Fredo Durand",
      "Joshua B. Tenenbaum",
      "Vincent Sitzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11232"
  },
  {
    "id": "arXiv:2207.11233",
    "title": "E2N: Error Estimation Networks for Goal-Oriented Mesh Adaptation",
    "abstract": "Given a partial differential equation (PDE), goal-oriented error estimation\nallows us to understand how errors in a diagnostic quantity of interest (QoI),\nor goal, occur and accumulate in a numerical approximation, for example using\nthe finite element method. By decomposing the error estimates into\ncontributions from individual elements, it is possible to formulate adaptation\nmethods, which modify the mesh with the objective of minimising the resulting\nQoI error. However, the standard error estimate formulation involves the true\nadjoint solution, which is unknown in practice. As such, it is common practice\nto approximate it with an 'enriched' approximation (e.g. in a higher order\nspace or on a refined mesh). Doing so generally results in a significant\nincrease in computational cost, which can be a bottleneck compromising the\ncompetitiveness of (goal-oriented) adaptive simulations. The central idea of\nthis paper is to develop a \"data-driven\" goal-oriented mesh adaptation approach\nthrough the selective replacement of the expensive error estimation step with\nan appropriately configured and trained neural network. In doing so, the error\nestimator may be obtained without even constructing the enriched spaces. An\nelement-by-element construction is employed here, whereby local values of\nvarious parameters related to the mesh geometry and underlying problem physics\nare taken as inputs, and the corresponding contribution to the error estimator\nis taken as output. We demonstrate that this approach is able to obtain the\nsame accuracy with a reduced computational cost, for adaptive mesh test cases\nrelated to flow around tidal turbines, which interact via their downstream\nwakes, and where the overall power output of the farm is taken as the QoI.\nMoreover, we demonstrate that the element-by-element approach implies\nreasonably low training costs.",
    "descriptor": "\nComments: 27 pages, 14 figures\n",
    "authors": [
      "Joseph G. Wallwork",
      "Jingyi Lu",
      "Mingrui Zhang",
      "Matthew D. Piggott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.11233"
  },
  {
    "id": "arXiv:2207.11234",
    "title": "A System-driven Automatic Ground Truth Generation Method for DL  Inner-City Driving Corridor Detectors",
    "abstract": "Data-driven perception approaches are well-established in automated driving\nsystems. In many fields even super-human performance is reached. Unlike\nprediction and planning approaches, mainly supervised learning algorithms are\nused for the perception domain. Therefore, a major remaining challenge is the\nefficient generation of ground truth data. As perception modules are positioned\nclose to the sensor, they typically run on raw sensor data of high bandwidth.\nDue to that, the generation of ground truth labels typically causes a\nsignificant manual effort, which leads to high costs for the labelling itself\nand the necessary quality control. In this contribution, we propose an\nautomatic labeling approach for semantic segmentation of the drivable ego\ncorridor that reduces the manual effort by a factor of 150 and more. The\nproposed holistic approach could be used in an automated data loop, allowing a\ncontinuous improvement of the depending perception modules.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Jona Ruthardt",
      "Thomas Michalke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.11234"
  },
  {
    "id": "arXiv:2207.11236",
    "title": "Twitmo: A Twitter Data Topic Modeling and Visualization Package for R",
    "abstract": "We present Twitmo, a package that provides a broad range of methods to\ncollect, pre-process, analyze and visualize geo-tagged Twitter data. Twitmo\nenables the user to collect geo-tagged Tweets from Twitter and and provides a\ncomprehensive and user-friendly toolbox to generate topic distributions from\nLatent Dirichlet Allocations (LDA), correlated topic models (CTM) and\nstructural topic models (STM). Functions are included for pre-processing of\ntext, model building and prediction. In addition, one of the innovations of the\npackage is the automatic pooling of Tweets into longer pseudo-documents using\nhashtags and cosine similarities for better topic coherence. The package\nadditionally comes with functionality to visualize collected data sets and\nfitted models in static as well as interactive ways and offers built-in support\nfor model visualizations via LDAvis providing great convenience for researchers\nin this area. The Twitmo package is an innovative toolbox that can be used to\nanalyze public discourse of various topics, political parties or persons of\ninterest in space and time.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Andreas Buchm\u00fcller",
      "Gillian Kant",
      "Christoph Weisser",
      "Benjamin S\u00e4fken",
      "Krisztina Kis-Katos",
      "Thomas Kneib"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.11236"
  },
  {
    "id": "arXiv:2207.11237",
    "title": "Defending Substitution-Based Profile Pollution Attacks on Sequential  Recommenders",
    "abstract": "While sequential recommender systems achieve significant improvements on\ncapturing user dynamics, we argue that sequential recommenders are vulnerable\nagainst substitution-based profile pollution attacks. To demonstrate our\nhypothesis, we propose a substitution-based adversarial attack algorithm, which\nmodifies the input sequence by selecting certain vulnerable elements and\nsubstituting them with adversarial items. In both untargeted and targeted\nattack scenarios, we observe significant performance deterioration using the\nproposed profile pollution algorithm. Motivated by such observations, we design\nan efficient adversarial defense method called Dirichlet neighborhood sampling.\nSpecifically, we sample item embeddings from a convex hull constructed by\nmulti-hop neighbors to replace the original items in input sequences. During\nsampling, a Dirichlet distribution is used to approximate the probability\ndistribution in the neighborhood such that the recommender learns to combat\nlocal perturbations. Additionally, we design an adversarial training method\ntailored for sequential recommender systems. In particular, we represent\nselected items with one-hot encodings and perform gradient ascent on the\nencodings to search for the worst case linear combination of item embeddings in\ntraining. As such, the embedding function learns robust item representations\nand the trained recommender is resistant to test-time adversarial examples.\nExtensive experiments show the effectiveness of both our attack and defense\nmethods, which consistently outperform baselines by a significant margin across\nmodel architectures and datasets.",
    "descriptor": "\nComments: Accepted to RecSys 2022\n",
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Ziyi Kou",
      "Lanyu Shang",
      "Dong Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11237"
  },
  {
    "id": "arXiv:2207.11238",
    "title": "Improved lightweight identification of agricultural diseases based on  MobileNetV3",
    "abstract": "At present, the identification of agricultural pests and diseases has the\nproblem that the model is not lightweight enough and difficult to apply. Based\non MobileNetV3, this paper introduces the Coordinate Attention block. The\nparameters of MobileNetV3-large are reduced by 22%, the model size is reduced\nby 19.7%, and the accuracy is improved by 0.92%. The parameters of\nMobileNetV3-small are reduced by 23.4%, the model size is reduced by 18.3%, and\nthe accuracy is increased by 0.40%. In addition, the improved MobileNetV3-small\nwas migrated to Jetson Nano for testing. The accuracy increased by 2.48% to\n98.31%, and the inference speed increased by 7.5%. It provides a reference for\ndeploying the agricultural pest identification model to embedded devices.",
    "descriptor": "\nComments: Accepted by CAIBDA 2022\n",
    "authors": [
      "Yuhang Jiang",
      "Wenping Tong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.11238"
  },
  {
    "id": "arXiv:2207.11239",
    "title": "Machine learning approach in the development of building occupant  personas",
    "abstract": "The user persona is a communication tool for designers to generate a mental\nmodel that describes the archetype of users. Developing building occupant\npersonas is proven to be an effective method for human-centered smart building\ndesign, which considers occupant comfort, behavior, and energy consumption.\nOptimization of building energy consumption also requires a deep understanding\nof occupants' preferences and behaviors. The current approaches to developing\nbuilding occupant personas face a major obstruction of manual data processing\nand analysis. In this study, we propose and evaluate a machine learning-based\nsemi-automated approach to generate building occupant personas. We investigate\nthe 2015 Residential Energy Consumption Dataset with five machine learning\ntechniques - Linear Discriminant Analysis, K Nearest Neighbors, Decision Tree\n(Random Forest), Support Vector Machine, and AdaBoost classifier - for the\nprediction of 16 occupant characteristics, such as age, education, and, thermal\ncomfort. The models achieve an average accuracy of 61% and accuracy over 90%\nfor attributes including the number of occupants in the household, their age\ngroup, and preferred usage of heating or cooling equipment. The results of the\nstudy show the feasibility of using machine learning techniques for the\ndevelopment of building occupant persona to minimize human effort.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Sheik Murad Hassan Anik",
      "Xinghua Gao",
      "Na Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.11239"
  },
  {
    "id": "arXiv:2207.11240",
    "title": "Discrete Key-Value Bottleneck",
    "abstract": "Deep neural networks perform well on prediction and classification tasks in\nthe canonical setting where data streams are i.i.d., labeled data is abundant,\nand class labels are balanced. Challenges emerge with distribution shifts,\nincluding non-stationary or imbalanced data streams. One powerful approach that\nhas addressed this challenge involves self-supervised pretraining of large\nencoders on volumes of unlabeled data, followed by task-specific tuning. Given\na new task, updating the weights of these encoders is challenging as a large\nnumber of weights needs to be fine-tuned, and as a result, they forget\ninformation about the previous tasks. In the present work, we propose a model\narchitecture to address this issue, building upon a discrete bottleneck\ncontaining pairs of separate and learnable (key, value) codes. In this setup,\nwe follow the encode; process the representation via a discrete bottleneck; and\ndecode paradigm, where the input is fed to the pretrained encoder, the output\nof the encoder is used to select the nearest keys, and the corresponding values\nare fed to the decoder to solve the current task. The model can only fetch and\nre-use a limited number of these (key, value) pairs during inference, enabling\nlocalized and context-dependent model updates. We theoretically investigate the\nability of the proposed model to minimize the effect of the distribution shifts\nand show that such a discrete bottleneck with (key, value) pairs reduces the\ncomplexity of the hypothesis class. We empirically verified the proposed\nmethods' benefits under challenging distribution shift scenarios across various\nbenchmark datasets and show that the proposed model reduces the common\nvulnerability to non-i.i.d. and non-stationary training distributions compared\nto various other baselines.",
    "descriptor": "",
    "authors": [
      "Frederik Tr\u00e4uble",
      "Anirudh Goyal",
      "Nasim Rahaman",
      "Michael Mozer",
      "Kenji Kawaguchi",
      "Yoshua Bengio",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.11240"
  },
  {
    "id": "arXiv:2207.11243",
    "title": "Multiface: A Dataset for Neural Face Rendering",
    "abstract": "Photorealistic avatars of human faces have come a long way in recent years,\nyet research along this area is limited by a lack of publicly available,\nhigh-quality datasets covering both, dense multi-view camera captures, and rich\nfacial expressions of the captured subjects. In this work, we present\nMultiface, a new multi-view, high-resolution human face dataset collected from\n13 identities at Reality Labs Research for neural face rendering. We introduce\nMugsy, a large scale multi-camera apparatus to capture high-resolution\nsynchronized videos of a facial performance. The goal of Multiface is to close\nthe gap in accessibility to high quality data in the academic community and to\nenable research in VR telepresence. Along with the release of the dataset, we\nconduct ablation studies on the influence of different model architectures\ntoward the model's interpolation capacity of novel viewpoint and expressions.\nWith a conditional VAE model serving as our baseline, we found that adding\nspatial bias, texture warp field, and residual connections improves performance\non novel view synthesis. Our code and data is available at:\nhttps://github.com/facebookresearch/multiface",
    "descriptor": "",
    "authors": [
      "Cheng-hsin Wuu",
      "Ningyuan Zheng",
      "Scott Ardisson",
      "Rohan Bali",
      "Danielle Belko",
      "Eric Brockmeyer",
      "Lucas Evans",
      "Timothy Godisart",
      "Hyowon Ha",
      "Alexander Hypes",
      "Taylor Koska",
      "Steven Krenn",
      "Stephen Lombardi",
      "Xiaomin Luo",
      "Kevyn McPhail",
      "Laura Millerschoen",
      "Michal Perdoch",
      "Mark Pitts",
      "Alexander Richard",
      "Jason Saragih",
      "Junko Saragih",
      "Takaaki Shiratori",
      "Tomas Simon",
      "Matt Stewart",
      "Autumn Trimble",
      "Xinshuo Weng",
      "David Whitewolf",
      "Chenglei Wu",
      "Shoou-I Yu",
      "Yaser Sheikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.11243"
  },
  {
    "id": "arXiv:2207.11244",
    "title": "Deep Learning Hyperparameter Optimization for Breast Mass Detection in  Mammograms",
    "abstract": "Accurate breast cancer diagnosis through mammography has the potential to\nsave millions of lives around the world. Deep learning (DL) methods have shown\nto be very effective for mass detection in mammograms. Additional improvements\nof current DL models will further improve the effectiveness of these methods. A\ncritical issue in this context is how to pick the right hyperparameters for DL\nmodels. In this paper, we present GA-E2E, a new approach for tuning the\nhyperparameters of DL models for brest cancer detection using Genetic\nAlgorithms (GAs). Our findings reveal that differences in parameter values can\nconsiderably alter the area under the curve (AUC), which is used to determine a\nclassifier's performance.",
    "descriptor": "",
    "authors": [
      "Adarsh Sehgal",
      "Muskan Sehgal",
      "Hung Manh La",
      "George Bebis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11244"
  },
  {
    "id": "arXiv:2207.11247",
    "title": "Panoptic Scene Graph Generation",
    "abstract": "Existing research addresses scene graph generation (SGG) -- a critical\ntechnology for scene understanding in images -- from a detection perspective,\ni.e., objects are detected using bounding boxes followed by prediction of their\npairwise relationships. We argue that such a paradigm causes several problems\nthat impede the progress of the field. For instance, bounding box-based labels\nin current datasets usually contain redundant classes like hairs, and leave out\nbackground information that is crucial to the understanding of context. In this\nwork, we introduce panoptic scene graph generation (PSG), a new problem task\nthat requires the model to generate a more comprehensive scene graph\nrepresentation based on panoptic segmentations rather than rigid bounding\nboxes. A high-quality PSG dataset, which contains 49k well-annotated\noverlapping images from COCO and Visual Genome, is created for the community to\nkeep track of its progress. For benchmarking, we build four two-stage\nbaselines, which are modified from classic methods in SGG, and two one-stage\nbaselines called PSGTR and PSGFormer, which are based on the efficient\nTransformer-based detector, i.e., DETR. While PSGTR uses a set of queries to\ndirectly learn triplets, PSGFormer separately models the objects and relations\nin the form of queries from two Transformer decoders, followed by a\nprompting-like relation-object matching mechanism. In the end, we share\ninsights on open challenges and future directions.",
    "descriptor": "\nComments: Accepted to ECCV'22 (Paper ID #222, Final Score 2222). Project Page: this https URL OpenPSG Codebase: this https URL\n",
    "authors": [
      "Jingkang Yang",
      "Yi Zhe Ang",
      "Zujin Guo",
      "Kaiyang Zhou",
      "Wayne Zhang",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.11247"
  },
  {
    "id": "arXiv:2207.06462",
    "title": "Quantum Metropolis Solver: A Quantum Walks Approach to Optimization  Problems",
    "abstract": "The efficient resolution of optimization problems is one of the key issues in\ntoday's industry. This task relies mainly on classical algorithms that present\nscalability problems and processing limitations. Quantum computing has emerged\nto challenge these types of problems. In this paper, we focus on the\nMetropolis-Hastings quantum algorithm that is based on quantum walks. We use\nthis algorithm to build a quantum software tool called Quantum Metropolis\nSolver (QMS). We validate QMS with the N-Queen problem to show a potential\nquantum advantage in an example that can be easily extrapolated to an\nArtificial Intelligence domain. We carry out different simulations to validate\nthe performance of QMS and its configuration.",
    "descriptor": "\nComments: RevTex 4.2, 6 color figures, 4 tables\n",
    "authors": [
      "Roberto Campos",
      "Pablo A M Casares",
      "M A Martin-Delgado"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.06462"
  },
  {
    "id": "arXiv:2207.07680",
    "title": "Network structural origin of instabilities in large complex systems",
    "abstract": "A central issue in the study of large complex network systems, such as power\ngrids, financial networks, and ecological systems, is to understand their\nresponse to dynamical perturbations. Recent studies recognize that many real\nnetworks show nonnormality and that nonnormality can give rise to\nreactivity--the capacity of a linearly stable system to amplify its response to\nperturbations, oftentimes exciting nonlinear instabilities. Here, we identify\nnetwork structural properties underlying the pervasiveness of nonnormality and\nreactivity in real directed networks, which we establish using the most\nextensive data set of such networks studied in this context to date. The\nidentified properties are imbalances between incoming and outgoing network\nlinks and paths at each node. Based on this characterization, we develop a\ntheory that quantitatively predicts nonnormality and reactivity and explains\nthe observed pervasiveness. We suggest that these results can be used to\ndesign, upgrade, control, and manage networks to avoid or promote network\ninstabilities.",
    "descriptor": "\nComments: Includes Supplementary Materials\n",
    "authors": [
      "Chao Duan",
      "Takashi Nishikawa",
      "Deniz Eroglu",
      "Adilson E. Motter"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.07680"
  },
  {
    "id": "arXiv:2207.10673",
    "title": "Correcting Model Bias with Sparse Implicit Processes",
    "abstract": "Model selection in machine learning (ML) is a crucial part of the Bayesian\nlearning procedure. Model choice may impose strong biases on the resulting\npredictions, which can hinder the performance of methods such as Bayesian\nneural networks and neural samplers. On the other hand, newly proposed\napproaches for Bayesian ML exploit features of approximate inference in\nfunction space with implicit stochastic processes (a generalization of Gaussian\nprocesses). The approach of Sparse Implicit Processes (SIP) is particularly\nsuccessful in this regard, since it is fully trainable and achieves flexible\npredictions. Here, we expand on the original experiments to show that SIP is\ncapable of correcting model bias when the data generating mechanism differs\nstrongly from the one implied by the model. We use synthetic datasets to show\nthat SIP is capable of providing predictive distributions that reflect the data\nbetter than the exact predictions of the initial, but wrongly assumed model.",
    "descriptor": "\nComments: 4 pages, 1 double figure. Included in ICML 2022 workshop \"Beyond Bayes: Paths Towards Universal Reasoning Systems\". Extension of previous work on Sparse Implicit Processes (arXiv:2110.07618)\n",
    "authors": [
      "Sim\u00f3n Rodr\u00edguez Santana",
      "Luis A. Ortega Andr\u00e9s",
      "Daniel Hern\u00e1ndez-Lobato",
      "Bryan Zald\u00edvar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.10673"
  },
  {
    "id": "arXiv:2207.10698",
    "title": "A machine learning based approach to gravitational lens identification  with the International LOFAR Telescope",
    "abstract": "We present a novel machine learning based approach for detecting galaxy-scale\ngravitational lenses from interferometric data, specifically those taken with\nthe International LOFAR Telescope (ILT), which is observing the northern radio\nsky at a frequency of 150 MHz, an angular resolution of 350 mas and a\nsensitivity of 90 uJy beam-1 (1 sigma). We develop and test several\nConvolutional Neural Networks to determine the probability and uncertainty of a\ngiven sample being classified as a lensed or non-lensed event. By training and\ntesting on a simulated interferometric imaging data set that includes realistic\nlensed and non-lensed radio sources, we find that it is possible to recover\n95.3 per cent of the lensed samples (true positive rate), with a contamination\nof just 0.008 per cent from non-lensed samples (false positive rate). Taking\nthe expected lensing probability into account results in a predicted sample\npurity for lensed events of 92.2 per cent. We find that the network structure\nis most robust when the maximum image separation between the lensed images is\ngreater than 3 times the synthesized beam size, and the lensed images have a\ntotal flux density that is equivalent to at least a 20 sigma (point-source)\ndetection. For the ILT, this corresponds to a lens sample with Einstein radii\ngreater than 0.5 arcsec and a radio source population with 150 MHz flux\ndensities more than 2 mJy. By applying these criteria and our lens detection\nalgorithm we expect to discover the vast majority of galaxy-scale gravitational\nlens systems contained within the LOFAR Two Metre Sky Survey.",
    "descriptor": "\nComments: Accepted to be published by MNRAS\n",
    "authors": [
      "S.Rezaei",
      "J. P. McKean",
      "M. Biehl",
      "W. de Roo1",
      "A. Lafontaine"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10698"
  },
  {
    "id": "arXiv:2207.10710",
    "title": "Learning Physics from the Machine: An Interpretable Boosted Decision  Tree Analysis for the Majorana Demonstrator",
    "abstract": "The Majorana Demonstrator is a leading experiment searching for neutrinoless\ndouble-beta decay with high purity germanium detectors (HPGe). Machine learning\nprovides a new way to maximize the amount of information provided by these\ndetectors, but the data-driven nature makes it less interpretable compared to\ntraditional analysis. An interpretability study reveals the machine's\ndecision-making logic, allowing us to learn from the machine to feedback to the\ntraditional analysis. In this work, we have presented the first machine\nlearning analysis of the data from the Majorana Demonstrator; this is also the\nfirst interpretable machine learning analysis of any germanium detector\nexperiment. Two gradient boosted decision tree models are trained to learn from\nthe data, and a game-theory-based model interpretability study is conducted to\nunderstand the origin of the classification power. By learning from data, this\nanalysis recognizes the correlations among reconstruction parameters to further\nenhance the background rejection performance. By learning from the machine,\nthis analysis reveals the importance of new background categories to\nreciprocally benefit the standard Majorana analysis. This model is highly\ncompatible with next-generation germanium detector experiments like LEGEND\nsince it can be simultaneously trained on a large number of detectors.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "I.J. Arnquist",
      "F.T. Avignone III",
      "A.S. Barabash",
      "C.J. Barton",
      "K.H. Bhimani",
      "E. Blalock",
      "B. Bos",
      "M. Busch",
      "M. Buuck",
      "T.S. Caldwell",
      "Y-D. Chan",
      "C.D. Christofferson",
      "P.-H. Chu",
      "M.L. Clark",
      "C. Cuesta",
      "J.A. Detwiler",
      "Yu. Efremenko",
      "S.R. Elliott",
      "G.K. Giovanetti",
      "M.P. Green",
      "J. Gruszko",
      "I.S. Guinn",
      "V.E. Guiseppe",
      "C.R. Haufe",
      "R. Henning",
      "D. Hervas Aguilar",
      "E.W. Hoppe",
      "A. Hostiuc",
      "M.F. Kidd",
      "I. Kim",
      "R.T. Kouzes",
      "T.E. Lannen V",
      "A. Li",
      "J.M. Lopez-Castano",
      "E.L. Martin",
      "R.D. Martin",
      "R. Massarczyk",
      "S.J. Meijer",
      "T.K. Oli",
      "G. Othman",
      "L.S. Paudel",
      "W. Pettus",
      "A.W.P. Poon",
      "D.C. Radford",
      "A.L. Reine",
      "K. Rielage",
      "N.W. Ruof",
      "D.C. Schaper",
      "D. Tedeschi",
      "R.L. Varner",
      "S. Vasilyev",
      "J.F. Wilkerson",
      "C. Wiseman",
      "W. Xu",
      "C.-H. Yu"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "Nuclear Experiment (nucl-ex)"
    ],
    "url": "https://arxiv.org/abs/2207.10710"
  },
  {
    "id": "arXiv:2207.10732",
    "title": "Explainable AI Algorithms for Vibration Data-based Fault Detection: Use  Case-adadpted Methods and Critical Evaluation",
    "abstract": "Analyzing vibration data using deep neural network algorithms is an effective\nway to detect damages in rotating machinery at an early stage. However, the\nblack-box approach of these methods often does not provide a satisfactory\nsolution because the cause of classifications is not comprehensible to humans.\nTherefore, this work investigates the application of explainable AI (XAI)\nalgorithms to convolutional neural networks for vibration-based condition\nmonitoring. For this, various XAI algorithms are applied to classifications\nbased on the Fourier transform as well as the order analysis of the vibration\nsignal. The results are visualized as a function of the revolutions per minute\n(RPM), in the shape of frequency-RPM maps and order-RPM maps. This allows to\nassess the saliency given to features which depend on the rotation speed and\nthose with constant frequency. To compare the explanatory power of the XAI\nmethods, investigations are first carried out with a synthetic data set with\nknown class-specific characteristics. Then a real-world data set for\nvibration-based imbalance classification on an electric motor, which runs at a\nbroad range of rotation speeds, is used. A special focus is put on the\nconsistency for variable periodicity of the data, which translates to a varying\nrotation speed of a real-world machine. This work aims to show the different\nstrengths and weaknesses of the methods for this use case: GradCAM, LRP and\nLIME with a new perturbation strategy.",
    "descriptor": "",
    "authors": [
      "Oliver Mey",
      "Deniz Neufeld"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10732"
  },
  {
    "id": "arXiv:2207.10747",
    "title": "A Transferable Recommender Approach for Selecting the Best Density  Functional Approximations in Chemical Discovery",
    "abstract": "Approximate density functional theory (DFT) has become indispensable owing to\nits cost-accuracy trade-off in comparison to more computationally demanding but\naccurate correlated wavefunction theory. To date, however, no single density\nfunctional approximation (DFA) with universal accuracy has been identified,\nleading to uncertainty in the quality of data generated from DFT. With electron\ndensity fitting and transfer learning, we build a DFA recommender that selects\nthe DFA with the lowest expected error with respect to gold standard but\ncost-prohibitive coupled cluster theory in a system-specific manner. We\ndemonstrate this recommender approach on vertical spin-splitting energy\nevaluation for challenging transition metal complexes. Our recommender predicts\ntop-performing DFAs and yields excellent accuracy (ca. 2 kcal/mol) for chemical\ndiscovery, outperforming both individual transfer learning models and the\nsingle best functional in a set of 48 DFAs. We demonstrate the transferability\nof the DFA recommender to experimentally synthesized compounds with distinct\nchemistry.",
    "descriptor": "",
    "authors": [
      "Chenru Duan",
      "Aditya Nandy",
      "Ralf Meyer",
      "Naveen Arunachalam",
      "Heather J. Kulik"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10747"
  },
  {
    "id": "arXiv:2207.10770",
    "title": "Quantum search in sets with prior knowledge",
    "abstract": "Quantum Search Algorithm made a big impact by being able to solve the search\nproblem for a set with $N$ elements using only $O(\\sqrt{N})$ steps.\nUnfortunately, it is impossible to reduce the order of the complexity of this\nproblem, however, it is possible to make improvements by a constant factor. In\nthis paper we pursued such improvements for search problem in sets with known\nprobability distributions. We have shown that by using a modified version of\nquantum search algorithm, it is possible to decrease the expected number of\niterations for such sets.",
    "descriptor": "",
    "authors": [
      "Umut \u00c7al\u0131ky\u0131lmaz",
      "Sadi Turgut"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.10770"
  },
  {
    "id": "arXiv:2207.10771",
    "title": "Reticula: A temporal network and hypergraph analysis software package",
    "abstract": "In the last decade, temporal networks and static and temporal hypergraphs\nhave enabled modelling connectivity and spreading processes in a wide array of\nreal-world complex systems such as economic transactions, information\nspreading, brain activity and disease spreading. In this manuscript, we present\nthe Reticula C++ library and Python package: A comprehensive suite of tools for\nworking with real-world and synthetic static and temporal networks and\nhypergraphs. This includes various methods of creating synthetic networks and\nrandomised null models based on real-world data, calculating reachability and\nsimulating compartmental models on networks. The library is designed\nprincipally on an extensible, cache-friendly representation of networks, with\nan aim of easing multi-thread use in the high-performance computing\nenvironment.",
    "descriptor": "",
    "authors": [
      "Arash Badie-Modiri",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10771"
  },
  {
    "id": "arXiv:2207.10772",
    "title": "Deep Sufficient Representation Learning via Mutual Information",
    "abstract": "We propose a mutual information-based sufficient representation learning\n(MSRL) approach, which uses the variational formulation of the mutual\ninformation and leverages the approximation power of deep neural networks. MSRL\nlearns a sufficient representation with the maximum mutual information with the\nresponse and a user-selected distribution. It can easily handle\nmulti-dimensional continuous or categorical response variables. MSRL is shown\nto be consistent in the sense that the conditional probability density function\nof the response variable given the learned representation converges to the\nconditional probability density function of the response variable given the\npredictor. Non-asymptotic error bounds for MSRL are also established under\nsuitable conditions. To establish the error bounds, we derive a generalized\nDudley's inequality for an order-two U-process indexed by deep neural networks,\nwhich may be of independent interest. We discuss how to determine the intrinsic\ndimension of the underlying data distribution. Moreover, we evaluate the\nperformance of MSRL via extensive numerical experiments and real data analysis\nand demonstrate that MSRL outperforms some existing nonlinear sufficient\ndimension reduction methods.",
    "descriptor": "\nComments: 43 pages, 6 figures and 5 tables\n",
    "authors": [
      "Siming Zheng",
      "Yuanyuan Lin",
      "Jian Huang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10772"
  },
  {
    "id": "arXiv:2207.10781",
    "title": "Data-Driven Stochastic AC-OPF using Gaussian Processes",
    "abstract": "In recent years, electricity generation has been responsible for more than a\nquarter of the greenhouse gas emissions in the US. Integrating a significant\namount of renewables into a power grid is probably the most accessible way to\nreduce carbon emissions from power grids and slow down climate change.\nUnfortunately, the most accessible renewable power sources, such as wind and\nsolar, are highly fluctuating and thus bring a lot of uncertainty to power grid\noperations and challenge existing optimization and control policies. The\nchance-constrained alternating current (AC) optimal power flow (OPF) framework\nfinds the minimum cost generation dispatch maintaining the power grid\noperations within security limits with a prescribed probability. Unfortunately,\nthe AC-OPF problem's chance-constrained extension is non-convex,\ncomputationally challenging, and requires knowledge of system parameters and\nadditional assumptions on the behavior of renewable distribution. Known linear\nand convex approximations to the above problems, though tractable, are too\nconservative for operational practice and do not consider uncertainty in system\nparameters. This paper presents an alternative data-driven approach based on\nGaussian process (GP) regression to close this gap. The GP approach learns a\nsimple yet non-convex data-driven approximation to the AC power flow equations\nthat can incorporate uncertainty inputs. The latter is then used to determine\nthe solution of CC-OPF efficiently, by accounting for both input and parameter\nuncertainty. The practical efficiency of the proposed approach using different\napproximations for GP-uncertainty propagation is illustrated over numerous IEEE\ntest cases.",
    "descriptor": "\nComments: 29 pages, 5 figures\n",
    "authors": [
      "Mile Mitrovic",
      "Aleksandr Lukashevich",
      "Petr Vorobev",
      "Vladimir Terzija",
      "Semen Budenny",
      "Yury Maximov",
      "Deepjoyti Deka"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10781"
  },
  {
    "id": "arXiv:2207.10794",
    "title": "Neuroimaging Feature Extraction using a Neural Network Classifier for  Imaging Genetics",
    "abstract": "A major issue in the association of genes to neuroimaging phenotypes is the\nhigh dimension of both genetic data and neuroimaging data. In this article, we\ntackle the latter problem with an eye toward developing solutions that are\nrelevant for disease prediction. Supported by a vast literature on the\npredictive power of neural networks, our proposed solution uses neural networks\nto extract from neuroimaging data features that are relevant for predicting\nAlzheimer's Disease (AD) for subsequent relation to genetics. Our\nneuroimaging-genetic pipeline is comprised of image processing, neuroimaging\nfeature extraction and genetic association steps. We propose a neural network\nclassifier for extracting neuroimaging features that are related with disease\nand a multivariate Bayesian group sparse regression model for genetic\nassociation. We compare the predictive power of these features to expert\nselected features and take a closer look at the SNPs identified with the new\nneuroimaging features.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "C\u00e9dric Beaulac",
      "Sidi Wu",
      "Erin Gibson",
      "Michelle F. Miranda",
      "Jiguo Cao",
      "Leno Rocha",
      "Mirza Faisal Beg",
      "Farouk S. Nathoo"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10794"
  },
  {
    "id": "arXiv:2207.10850",
    "title": "A simple and sharper proof of the hypergraph Moore bound",
    "abstract": "The hypergraph Moore bound is an elegant statement that characterizes the\nextremal trade-off between the girth - the number of hyperedges in the smallest\ncycle or even cover (a subhypergraph with all degrees even) and size - the\nnumber of hyperedges in a hypergraph. For graphs (i.e., $2$-uniform\nhypergraphs), a bound tight up to the leading constant was proven in a\nclassical work of Alon, Hoory and Linial [AHL02]. For hypergraphs of uniformity\n$k>2$, an appropriate generalization was conjectured by Feige [Fei08]. The\nconjecture was settled up to an additional $\\log^{4k+1} n$ factor in the size\nin a recent work of Guruswami, Kothari and Manohar [GKM21]. Their argument\nrelies on a connection between the existence of short even covers and the\nspectrum of a certain randomly signed Kikuchi matrix. Their analysis,\nespecially for the case of odd $k$, is significantly complicated.\nIn this work, we present a substantially simpler and shorter proof of the\nhypergraph Moore bound. Our key idea is the use of a new reweighted Kikuchi\nmatrix and an edge deletion step that allows us to drop several involved steps\nin [GKM21]'s analysis such as combinatorial bucketing of rows of the Kikuchi\nmatrix and the use of the Schudy-Sviridenko polynomial concentration. Our\nsimpler proof also obtains tighter parameters: in particular, the argument\ngives a new proof of the classical Moore bound of [AHL02] with no loss (the\nproof in [GKM21] loses a $\\log^3 n$ factor), and loses only a single\nlogarithmic factor for all $k>2$-uniform hypergraphs.\nAs in [GKM21], our ideas naturally extend to yield a simpler proof of the\nfull trade-off for strongly refuting smoothed instances of constraint\nsatisfaction problems with similarly improved parameters.",
    "descriptor": "",
    "authors": [
      "Jun-Ting Hsieh",
      "Pravesh K. Kothari",
      "Sidhanth Mohanty"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.10850"
  },
  {
    "id": "arXiv:2207.10869",
    "title": "Optimizing Image Compression via Joint Learning with Denoising",
    "abstract": "High levels of noise usually exist in today's captured images due to the\nrelatively small sensors equipped in the smartphone cameras, where the noise\nbrings extra challenges to lossy image compression algorithms. Without the\ncapacity to tell the difference between image details and noise, general image\ncompression methods allocate additional bits to explicitly store the undesired\nimage noise during compression and restore the unpleasant noisy image during\ndecompression. Based on the observations, we optimize the image compression\nalgorithm to be noise-aware as joint denoising and compression to resolve the\nbits misallocation problem. The key is to transform the original noisy images\nto noise-free bits by eliminating the undesired noise during compression, where\nthe bits are later decompressed as clean images. Specifically, we propose a\nnovel two-branch, weight-sharing architecture with plug-in feature denoisers to\nallow a simple and effective realization of the goal with little computational\ncost. Experimental results show that our method gains a significant improvement\nover the existing baseline methods on both the synthetic and real-world\ndatasets. Our source code is available at\nhttps://github.com/felixcheng97/DenoiseCompression.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Ka Leong Cheng",
      "Yueqi Xie",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10869"
  },
  {
    "id": "arXiv:2207.10871",
    "title": "Elimination and cut-elimination in multiplicative linear logic",
    "abstract": "We associate to every proof structure in multiplicative linear logic an ideal\nwhich represents the logical content of the proof as polynomial equations. We\nshow how cut-elimination in multiplicative proof nets corresponds to instances\nof the Buchberger algorithm for computing Gr\\\"obner bases in elimination\ntheory.",
    "descriptor": "",
    "authors": [
      "Daniel Murfet",
      "William Troiani"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.10871"
  },
  {
    "id": "arXiv:2207.10885",
    "title": "XAI based Performance Preserving Adaptive Image Compression for  Efficient Satellite Communication",
    "abstract": "In the era of multinational cooperation, gathering and analyzing the\nsatellite images are getting easier and more important. Typical procedure of\nthe satellite image analysis include transmission of the bulky image data from\nsatellite to the ground producing significant overhead. To reduce the amount of\nthe transmission overhead while making no harm to the analysis result, we\npropose a novel image compression scheme RDIC in this paper. RDIC is a\nreasoning based image compression scheme that compresses an image according to\nthe pixel importance score acquired from the analysis model itself. From the\nexperimental results we showed that our RDIC scheme successfully captures the\nimportant regions in an image showing high compression rate and low accuracy\nloss.",
    "descriptor": "",
    "authors": [
      "KyungChae Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10885"
  },
  {
    "id": "arXiv:2207.10911",
    "title": "Jacobi polynomials and design theory I",
    "abstract": "In this paper, we introduce the notion of Jacobi polynomials with multiple\nreference vectors of a code, and give the MacWilliams type identity for it.\nMoreover, we derive a formula to obtain the Jacobi polynomials using the\nAronhold polarization operator. Finally, we describe some facts obtained from\nType III and Type IV codes that interpret the relation between the Jacobi\npolynomials and designs.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Himadri Shekhar Chakraborty",
      "Tsuyoshi Miezaki",
      "Manabu Oura",
      "Yuuho Tanaka"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)",
      "Group Theory (math.GR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.10911"
  },
  {
    "id": "arXiv:2207.10924",
    "title": "Evolution of the public opinion on COVID-19 vaccination in Japan",
    "abstract": "Vaccines are promising tools to control the spread of COVID-19. An effective\nvaccination campaign requires government policies and community engagement,\nsharing experiences for social support, and voicing concerns to vaccine safety\nand efficiency. The increasing use of online social platforms allows us to\ntrace large-scale communication and infer public opinion in real-time. We\ncollected more than 100 million vaccine-related tweets posted by 8 million\nusers and used the Latent Dirichlet Allocation model to perform automated topic\nmodeling of tweet texts during the vaccination campaign in Japan. We identified\n15 topics grouped into 4 themes on Personal issue, Breaking news, Politics, and\nConspiracy and humour. The evolution of the popularity of themes revealed a\nshift in public opinion, initially sharing the attention over personal issues\n(individual aspect), collecting information from the news (knowledge\nacquisition), and government criticisms, towards personal experiences once\nconfidence in the vaccination campaign was established. An interrupted time\nseries regression analysis showed that the Tokyo Olympic Games affected public\nopinion more than other critical events but not the course of the vaccination.\nPublic opinion on politics was significantly affected by various events,\npositively shifting the attention in the early stages of the vaccination\ncampaign and negatively later. Tweets about personal issues were mostly\nretweeted when the vaccination reached the younger population. The associations\nbetween the vaccination campaign stages and tweet themes suggest that the\npublic engagement in the social platform contributed to speedup vaccine uptake\nby reducing anxiety via social learning and support.",
    "descriptor": "",
    "authors": [
      "Yuri Nakayama",
      "Yuka Takedomi",
      "Towa Suda",
      "Takeaki Uno",
      "Takako Hashimoto",
      "Masashi Toyoda",
      "Naoki Yoshinaga",
      "Masaru Kitsuregawa",
      "Luis E.C. Rocha",
      "Ryota Kobayashi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10924"
  },
  {
    "id": "arXiv:2207.10934",
    "title": "DNN-Free Low-Latency Adaptive Speech Enhancement Based on Frame-Online  Beamforming Powered by Block-Online FastMNMF",
    "abstract": "This paper describes a practical dual-process speech enhancement system that\nadapts environment-sensitive frame-online beamforming (front-end) with help\nfrom environment-free block-online source separation (back-end). To use minimum\nvariance distortionless response (MVDR) beamforming, one may train a deep\nneural network (DNN) that estimates time-frequency masks used for computing the\ncovariance matrices of sources (speech and noise). Backpropagation-based\nrun-time adaptation of the DNN was proposed for dealing with the mismatched\ntraining-test conditions. Instead, one may try to directly estimate the source\ncovariance matrices with a state-of-the-art blind source separation method\ncalled fast multichannel non-negative matrix factorization (FastMNMF). In\npractice, however, neither the DNN nor the FastMNMF can be updated in a\nframe-online manner due to its computationally-expensive iterative nature. Our\nDNN-free system leverages the posteriors of the latest source spectrograms\ngiven by block-online FastMNMF to derive the current source covariance matrices\nfor frame-online beamforming. The evaluation shows that our frame-online system\ncan quickly respond to scene changes caused by interfering speaker movements\nand outperformed an existing block-online system with DNN-based beamforming by\n5.0 points in terms of the word error rate.",
    "descriptor": "\nComments: IWAENC 2022\n",
    "authors": [
      "Aditya Arie Nugraha",
      "Kouhei Sekiguchi",
      "Mathieu Fontaine",
      "Yoshiaki Bando",
      "Kazuyoshi Yoshii"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.10934"
  },
  {
    "id": "arXiv:2207.10939",
    "title": "Statistical Hypothesis Testing Based on Machine Learning: Large  Deviations Analysis",
    "abstract": "We study the performance -- and specifically the rate at which the error\nprobability converges to zero -- of Machine Learning (ML) classification\ntechniques. Leveraging the theory of large deviations, we provide the\nmathematical conditions for a ML classifier to exhibit error probabilities that\nvanish exponentially, say $\\sim \\exp\\left(-n\\,I + o(n) \\right)$, where $n$ is\nthe number of informative observations available for testing (or another\nrelevant parameter, such as the size of the target in an image) and $I$ is the\nerror rate. Such conditions depend on the Fenchel-Legendre transform of the\ncumulant-generating function of the Data-Driven Decision Function (D3F, i.e.,\nwhat is thresholded before the final binary decision is made) learned in the\ntraining phase. As such, the D3F and, consequently, the related error rate $I$,\ndepend on the given training set, which is assumed of finite size.\nInterestingly, these conditions can be verified and tested numerically\nexploiting the available dataset, or a synthetic dataset, generated according\nto the available information on the underlying statistical model. In other\nwords, the classification error probability convergence to zero and its rate\ncan be computed on a portion of the dataset available for training. Coherently\nwith the large deviations theory, we can also establish the convergence, for\n$n$ large enough, of the normalized D3F statistic to a Gaussian distribution.\nThis property is exploited to set a desired asymptotic false alarm probability,\nwhich empirically turns out to be accurate even for quite realistic values of\n$n$. Furthermore, approximate error probability curves $\\sim \\zeta_n\n\\exp\\left(-n\\,I \\right)$ are provided, thanks to the refined asymptotic\nderivation (often referred to as exact asymptotics), where $\\zeta_n$ represents\nthe most representative sub-exponential terms of the error probabilities.",
    "descriptor": "",
    "authors": [
      "Paolo Braca",
      "Leonardo M. Millefiori",
      "Augusto Aubry",
      "Stefano Marano",
      "Antonio De Maio",
      "Peter Willett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Probability (math.PR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2207.10939"
  },
  {
    "id": "arXiv:2207.10944",
    "title": "On the Accessibility and Controllability of Statistical Linearization  for Stochastic Control: Algebraic Rank Conditions and their Genericity",
    "abstract": "Statistical linearization has recently seen a particular surge of interest as\na numerically cheap method for robust control of stochastic differential\nequations. Although it has already been successfully applied to control complex\nstochastic systems, accessibility and controllability properties of statistical\nlinearization, which are key to make the robust control problem well-posed,\nhave not been investigated yet. In this paper, we bridge this gap by providing\nsufficient conditions for the accessibility and controllability of statistical\nlinearization. Specifically, we establish simple sufficient algebraic\nconditions for the accessibility and controllability of statistical\nlinearization, which involve the rank of the Lie algebra generated by the drift\nonly. In addition, we show these latter algebraic conditions are essentially\nsharp, by means of a counterexample, and that they are generic with respect to\nthe drift and the initial condition.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Riccardo Bonalli",
      "Clara Leparoux",
      "Bruno H\u00e9riss\u00e9",
      "Fr\u00e9d\u00e9ric Jean"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10944"
  },
  {
    "id": "arXiv:2207.10998",
    "title": "Rapid Lung Ultrasound COVID-19 Severity Scoring with Resource-Efficient  Deep Feature Extraction",
    "abstract": "Artificial intelligence-based analysis of lung ultrasound imaging has been\ndemonstrated as an effective technique for rapid diagnostic decision support\nthroughout the COVID-19 pandemic. However, such techniques can require days- or\nweeks-long training processes and hyper-parameter tuning to develop intelligent\ndeep learning image analysis models. This work focuses on leveraging\n'off-the-shelf' pre-trained models as deep feature extractors for scoring\ndisease severity with minimal training time. We propose using pre-trained\ninitializations of existing methods ahead of simple and compact neural networks\nto reduce reliance on computational capacity. This reduction of computational\ncapacity is of critical importance in time-limited or resource-constrained\ncircumstances, such as the early stages of a pandemic. On a dataset of 49\npatients, comprising over 20,000 images, we demonstrate that the use of\nexisting methods as feature extractors results in the effective classification\nof COVID-19-related pneumonia severity while requiring only minutes of training\ntime. Our methods can achieve an accuracy of over 0.93 on a 4-level severity\nscore scale and provides comparable per-patient region and global scores\ncompared to expert annotated ground truths. These results demonstrate the\ncapability for rapid deployment and use of such minimally-adapted methods for\nprogress monitoring, patient stratification and management in clinical practice\nfor COVID-19 patients, and potentially in other respiratory diseases.",
    "descriptor": "\nComments: Accepted to ASMUS 2022 Workshop at MICCAI\n",
    "authors": [
      "Pierre Raillard",
      "Lorenzo Cristoni",
      "Andrew Walden",
      "Roberto Lazzari",
      "Thomas Pulimood",
      "Louis Grandjean",
      "Claudia AM Gandini Wheeler-Kingshott",
      "Yipeng Hu",
      "Zachary MC Baum"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10998"
  },
  {
    "id": "arXiv:2207.11014",
    "title": "Preparing Many Copies of a Quantum State in the Black-Box Model",
    "abstract": "We describe a simple quantum algorithm for preparing $K$ copies of an\n$N$-dimensional quantum state whose amplitudes are given by a quantum oracle.\nOur result extends a previous work of Grover, who showed how to prepare one\ncopy in time $O(\\sqrt{N})$. In comparison with the naive $O(K\\sqrt{N})$\nsolution obtained by repeating this procedure~$K$ times, our algorithm achieves\nthe optimal running time of $\\theta(\\sqrt{KN})$. Our technique uses a\nrefinement of the quantum rejection sampling method employed by Grover. As a\ndirect application, we obtain a similar speed-up for obtaining $K$ independent\nsamples from a distribution whose probability vector is given by a quantum\noracle.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Yassine Hamoudi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.11014"
  },
  {
    "id": "arXiv:2207.11049",
    "title": "Context-aware controller inference for stabilizing dynamical systems  from scarce data",
    "abstract": "This work introduces a data-driven control approach for stabilizing\nhigh-dimensional dynamical systems from scarce data. The proposed context-aware\ncontroller inference approach is based on the observation that controllers need\nto act locally only on the unstable dynamics to stabilize systems. This means\nit is sufficient to learn the unstable dynamics alone, which are typically\nconfined to much lower dimensional spaces than the high-dimensional state\nspaces of all system dynamics and thus few data samples are sufficient to\nidentify them. Numerical experiments demonstrate that context-aware controller\ninference learns stabilizing controllers from orders of magnitude fewer data\nsamples than traditional data-driven control techniques and variants of\nreinforcement learning. The experiments further show that the low data\nrequirements of context-aware controller inference are especially beneficial in\ndata-scarce engineering problems with complex physics, for which learning\ncomplete system dynamics is often intractable in terms of data and training\ncosts.",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Steffen W. R. Werner",
      "Benjamin Peherstorfer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.11049"
  },
  {
    "id": "arXiv:2207.11050",
    "title": "Graph Spatio-Spectral Total Variation Model for Hyperspectral Image  Denoising",
    "abstract": "The spatio-spectral total variation (SSTV) model has been widely used as an\neffective regularization of hyperspectral images (HSI) for various applications\nsuch as mixed noise removal. However, since SSTV computes local spatial\ndifferences uniformly, it is difficult to remove noise while preserving complex\nspatial structures with fine edges and textures, especially in situations of\nhigh noise intensity. To solve this problem, we propose a new TV-type\nregularization called Graph-SSTV (GSSTV), which generates a graph explicitly\nreflecting the spatial structure of the target HSI from noisy HSIs and\nincorporates a weighted spatial difference operator designed based on this\ngraph. Furthermore, we formulate the mixed noise removal problem as a convex\noptimization problem involving GSSTV and develop an efficient algorithm based\non the primal-dual splitting method to solve this problem. Finally, we\ndemonstrate the effectiveness of GSSTV compared with existing HSI\nregularization models through experiments on mixed noise removal. The source\ncode will be available at https://www.mdi.c.titech.ac.jp/publications/gsstv.",
    "descriptor": "\nComments: Accepted to IEEE Geoscience and Remote Sensing Letters. The code is available at this https URL\n",
    "authors": [
      "Shingo Takemoto",
      "Kazuki Naganuma",
      "Shunsuke Ono"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11050"
  },
  {
    "id": "arXiv:2207.11095",
    "title": "Multi-temporal speckle reduction with self-supervised deep neural  networks",
    "abstract": "Speckle filtering is generally a prerequisite to the analysis of synthetic\naperture radar (SAR) images. Tremendous progress has been achieved in the\ndomain of single-image despeckling. Latest techniques rely on deep neural\nnetworks to restore the various structures and textures peculiar to SAR images.\nThe availability of time series of SAR images offers the possibility of\nimproving speckle filtering by combining different speckle realizations over\nthe same area. The supervised training of deep neural networks requires\nground-truth speckle-free images. Such images can only be obtained indirectly\nthrough some form of averaging, by spatial or temporal integration, and are\nimperfect. Given the potential of very high quality restoration reachable by\nmulti-temporal speckle filtering, the limitations of ground-truth images need\nto be circumvented. We extend a recent self-supervised training strategy for\nsingle-look complex SAR images, called MERLIN, to the case of multi-temporal\nfiltering. This requires modeling the sources of statistical dependencies in\nthe spatial and temporal dimensions as well as between the real and imaginary\ncomponents of the complex amplitudes. Quantitative analysis on datasets with\nsimulated speckle indicates a clear improvement of speckle reduction when\nadditional SAR images are included. Our method is then applied to stacks of\nTerraSAR-X images and shown to outperform competing multi-temporal speckle\nfiltering approaches. The code of the trained models is made freely available\non the\n$\\href{https://gitlab.telecom-paris.fr/ring/multi-temporal-merlin/}{\\text{GitLab}}$\nof the IMAGES team of the LTCI Lab, T\\'el\\'ecom Paris Institut Polytechnique de\nParis.",
    "descriptor": "",
    "authors": [
      "In\u00e8s Meraoumia",
      "Emanuele Dalsasso",
      "Lo\u00efc Denis",
      "R\u00e9my Abergel",
      "Florence Tupin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11095"
  },
  {
    "id": "arXiv:2207.11102",
    "title": "Physiology-based simulation of the retinal vasculature enables  annotation-free segmentation of OCT angiographs",
    "abstract": "Optical coherence tomography angiography (OCTA) can non-invasively image the\neye's circulatory system. In order to reliably characterize the retinal\nvasculature, there is a need to automatically extract quantitative metrics from\nthese images. The calculation of such biomarkers requires a precise semantic\nsegmentation of the blood vessels. However, deep-learning-based methods for\nsegmentation mostly rely on supervised training with voxel-level annotations,\nwhich are costly to obtain. In this work, we present a pipeline to synthesize\nlarge amounts of realistic OCTA images with intrinsically matching ground truth\nlabels; thereby obviating the need for manual annotation of training data. Our\nproposed method is based on two novel components: 1) a physiology-based\nsimulation that models the various retinal vascular plexuses and 2) a suite of\nphysics-based image augmentations that emulate the OCTA image acquisition\nprocess including typical artifacts. In extensive benchmarking experiments, we\ndemonstrate the utility of our synthetic data by successfully training retinal\nvessel segmentation algorithms. Encouraged by our method's competitive\nquantitative and superior qualitative performance, we believe that it\nconstitutes a versatile tool to advance the quantitative analysis of OCTA\nimages.",
    "descriptor": "\nComments: Accepted at MICCAI 2022\n",
    "authors": [
      "Martin J. Menten",
      "Johannes C. Paetzold",
      "Alina Dima",
      "Bjoern H. Menze",
      "Benjamin Knier",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11102"
  },
  {
    "id": "arXiv:2207.11111",
    "title": "Fast strategies for multi-temporal speckle reduction of Sentinel-1 GRD  images",
    "abstract": "Reducing speckle and limiting the variations of the physical parameters in\nSynthetic Aperture Radar (SAR) images is often a key-step to fully exploit the\npotential of such data. Nowadays, deep learning approaches produce state of the\nart results in single-image SAR restoration. Nevertheless, huge multi-temporal\nstacks are now often available and could be efficiently exploited to further\nimprove image quality. This paper explores two fast strategies employing a\nsingle-image despeckling algorithm, namely SAR2SAR, in a multi-temporal\nframework. The first one is based on Quegan filter and replaces the local\nreflectivity pre-estimation by SAR2SAR. The second one uses SAR2SAR to suppress\nspeckle from a ratio image encoding the multi-temporal information under the\nform of a \"super-image\", i.e. the temporal arithmetic mean of a time series.\nExperimental results on Sentinel-1 GRD data show that these two multi-temporal\nstrategies provide improved filtering results while adding a limited\ncomputational cost.",
    "descriptor": "",
    "authors": [
      "In\u00e8s Meraoumia",
      "Emanuele Dalsasso",
      "Lo\u00efc Denis",
      "Florence Tupin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11111"
  },
  {
    "id": "arXiv:2207.11122",
    "title": "Solving the Batch Stochastic Bin Packing Problem in Cloud: A  Chance-constrained Optimization Approach",
    "abstract": "This paper investigates a critical resource allocation problem in the first\nparty cloud: scheduling containers to machines. There are tens of services and\neach service runs a set of homogeneous containers with dynamic resource usage;\ncontainers of a service are scheduled daily in a batch fashion. This problem\ncan be naturally formulated as Stochastic Bin Packing Problem (SBPP). However,\ntraditional SBPP research often focuses on cases of empty machines, whose\nobjective, i.e., to minimize the number of used machines, is not well-defined\nfor the more common reality with nonempty machines. This paper aims to close\nthis gap. First, we define a new objective metric, Used Capacity at Confidence\n(UCaC), which measures the maximum used resources at a probability and is\nproved to be consistent for both empty and nonempty machines, and reformulate\nthe SBPP under chance constraints. Second, by modeling the container resource\nusage distribution in a generative approach, we reveal that UCaC can be\napproximated with Gaussian, which is verified by trace data of real-world\napplications. Third, we propose an exact solver by solving the equivalent\ncutting stock variant as well as two heuristics-based solvers -- UCaC best fit,\nbi-level heuristics. We experimentally evaluate these solvers on both synthetic\ndatasets and real application traces, demonstrating our methodology's advantage\nover traditional SBPP optimal solver minimizing the number of used machines,\nwith a low rate of resource violations.",
    "descriptor": "\nComments: To appear in SIGKDD 2022 as Research Track paper\n",
    "authors": [
      "Jie Yan",
      "Yunlei Lu",
      "Liting Chen",
      "Si Qin",
      "Yixin Fang",
      "Qingwei Lin",
      "Thomas Moscibroda",
      "Saravan Rajmohan",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.11122"
  },
  {
    "id": "arXiv:2207.11124",
    "title": "Predictors for high frequency processes based on rational polynomials  approximation of periodic exponentials",
    "abstract": "The paper presents time-invariant linear integral predictors for continuous\ntime high-frequency processes with a finite spectrum gap. The predictors are\nbased on approximation of complex valued periodic exponentials (complex\nsinusoid) by rational polynomials. The paper presents time-invariant linear\nintegral predictors for continuous time high-frequency processes with a finite\nspectrum gap. The predictors are based on approximation of complex valued\nperiodic exponentials (complex sinusoid) by rational polynomials.",
    "descriptor": "",
    "authors": [
      "Nikolai Dokuchaev"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.11124"
  },
  {
    "id": "arXiv:2207.11141",
    "title": "Deep learning of diffeomorphisms for optimal reparametrizations of  shapes",
    "abstract": "In shape analysis, one of the fundamental problems is to align curves or\nsurfaces before computing a (geodesic) distance between these shapes. To find\nthe optimal reparametrization realizing this alignment is a computationally\ndemanding task which leads to an optimization problem on the diffeomorphism\ngroup. In this paper, we construct approximations of orientation-preserving\ndiffeomorphisms by composition of elementary diffeomorphisms to solve the\napproximation problem. We propose a practical algorithm implemented in PyTorch\nwhich is applicable both to unparametrized curves and surfaces. We derive\nuniversal approximation results and obtain bounds for the Lipschitz constant of\nthe obtained compositions of diffeomorphisms.",
    "descriptor": "\nComments: 26 pages, 11 figures. Submitted to SIAM Journal of Scientific Computing\n",
    "authors": [
      "Elena Celledoni",
      "Helge Gl\u00f6ckner",
      "J\u00f8rgen Riseth",
      "Alexander Schmeding"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2207.11141"
  },
  {
    "id": "arXiv:2207.11152",
    "title": "Learn Continuously, Act Discretely: Hybrid Action-Space Reinforcement  Learning For Optimal Execution",
    "abstract": "Optimal execution is a sequential decision-making problem for cost-saving in\nalgorithmic trading. Studies have found that reinforcement learning (RL) can\nhelp decide the order-splitting sizes. However, a problem remains unsolved: how\nto place limit orders at appropriate limit prices? The key challenge lies in\nthe \"continuous-discrete duality\" of the action space. On the one hand, the\ncontinuous action space using percentage changes in prices is preferred for\ngeneralization. On the other hand, the trader eventually needs to choose limit\nprices discretely due to the existence of the tick size, which requires\nspecialization for every single stock with different characteristics (e.g., the\nliquidity and the price range). So we need continuous control for\ngeneralization and discrete control for specialization. To this end, we propose\na hybrid RL method to combine the advantages of both of them. We first use a\ncontinuous control agent to scope an action subset, then deploy a fine-grained\nagent to choose a specific limit price. Extensive experiments show that our\nmethod has higher sample efficiency and better training stability than existing\nRL algorithms and significantly outperforms previous learning-based methods for\norder execution.",
    "descriptor": "",
    "authors": [
      "Feiyang Pan",
      "Tongzhe Zhang",
      "Ling Luo",
      "Jia He",
      "Shuoling Liu"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11152"
  },
  {
    "id": "arXiv:2207.11158",
    "title": "SPRT-based Efficient Best Arm Identification in Stochastic Bandits",
    "abstract": "This paper investigates the best arm identification (BAI) problem in\nstochastic multi-armed bandits in the fixed confidence setting. The general\nclass of the exponential family of bandits is considered. The state-of-the-art\nalgorithms for the exponential family of bandits face computational challenges.\nTo mitigate these challenges, a novel framework is proposed, which views the\nBAI problem as sequential hypothesis testing, and is amenable to tractable\nanalysis for the exponential family of bandits. Based on this framework, a BAI\nalgorithm is designed that leverages the canonical sequential probability ratio\ntests. This algorithm has three features for both settings: (1) its sample\ncomplexity is asymptotically optimal, (2) it is guaranteed to be $\\delta-$PAC,\nand (3) it addresses the computational challenge of the state-of-the-art\napproaches. Specifically, these approaches, which are focused only on the\nGaussian setting, require Thompson sampling from the arm that is deemed the\nbest and a challenger arm. This paper analytically shows that identifying the\nchallenger is computationally expensive and that the proposed algorithm\ncircumvents it. Finally, numerical experiments are provided to support the\nanalysis.",
    "descriptor": "",
    "authors": [
      "Arpan Mukherjee",
      "Ali Tajer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11158"
  },
  {
    "id": "arXiv:2207.11159",
    "title": "Fairness-aware Network Revenue Management with Demand Learning",
    "abstract": "In addition to maximizing the total revenue, decision-makers in lots of\nindustries would like to guarantee fair consumption across different resources\nand avoid saturating certain resources. Motivated by these practical needs,\nthis paper studies the price-based network revenue management problem with both\ndemand learning and fairness concern about the consumption across different\nresources. We introduce the regularized revenue, i.e., the total revenue with a\nfairness regularization, as our objective to incorporate fairness into the\nrevenue maximization goal. We propose a primal-dual-type online policy with the\nUpper-Confidence-Bound (UCB) demand learning method to maximize the regularized\nrevenue. We adopt several innovative techniques to make our algorithm a unified\nand computationally efficient framework for the continuous price set and a wide\nclass of fairness regularizers. Our algorithm achieves a worst-case regret of\n$\\tilde O(N^{5/2}\\sqrt{T})$, where $N$ denotes the number of products and $T$\ndenotes the number of time periods. Numerical experiments in a few NRM examples\ndemonstrate the effectiveness of our algorithm for balancing revenue and\nfairness.",
    "descriptor": "",
    "authors": [
      "Xi Chen",
      "Jiameng Lyu",
      "Yining Wang",
      "Yuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11159"
  },
  {
    "id": "arXiv:2207.11164",
    "title": "Generalized Identifiability Bounds for Mixture Models with Grouped  Samples",
    "abstract": "Recent work has shown that finite mixture models with $m$ components are\nidentifiable, while making no assumptions on the mixture components, so long as\none has access to groups of samples of size $2m-1$ which are known to come from\nthe same mixture component. In this work we generalize that result and show\nthat, if every subset of $k$ mixture components of a mixture model are linearly\nindependent, then that mixture model is identifiable with only $(2m-1)/(k-1)$\nsamples per group. We further show that this value cannot be improved. We prove\nan analogous result for a stronger form of identifiability known as\n\"determinedness\" along with a corresponding lower bound. This independence\nassumption almost surely holds if mixture components are chosen randomly from a\n$k$-dimensional space. We describe some implications of our results for\nmultinomial mixture models and topic modeling.",
    "descriptor": "",
    "authors": [
      "Robert A. Vandermeulen",
      "Ren\u00e9 Saitenmacher"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.11164"
  },
  {
    "id": "arXiv:2207.11165",
    "title": "High dimensional stochastic linear contextual bandit with missing  covariates",
    "abstract": "Recent works in bandit problems adopted lasso convergence theory in the\nsequential decision-making setting. Even with fully observed contexts, there\nare technical challenges that hinder the application of existing lasso\nconvergence theory: 1) proving the restricted eigenvalue condition under\nconditionally sub-Gaussian noise and 2) accounting for the dependence between\nthe context variables and the chosen actions. This paper studies the effect of\nmissing covariates on regret for stochastic linear bandit algorithms. Our work\nprovides a high-probability upper bound on the regret incurred by the proposed\nalgorithm in terms of covariate sampling probabilities, showing that the regret\ndegrades due to missingness by at most $\\zeta_{min}^2$, where $\\zeta_{min}$ is\nthe minimum probability of observing covariates in the context vector. We\nillustrate our algorithm for the practical application of experimental design\nfor collecting gene expression data by a sequential selection of class\ndiscriminating DNA probes.",
    "descriptor": "\nComments: Accepted in MLSP 2022\n",
    "authors": [
      "Byoungwook Jang",
      "Julia Nepper",
      "Marc Chevrette",
      "Jo Handelsman",
      "Alfred O. Hero III"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11165"
  },
  {
    "id": "arXiv:2207.11173",
    "title": "Verifying Fairness in Quantum Machine Learning",
    "abstract": "Due to the beyond-classical capability of quantum computing, quantum machine\nlearning is applied independently or embedded in classical models for decision\nmaking, especially in the field of finance. Fairness and other ethical issues\nare often one of the main concerns in decision making. In this work, we define\na formal framework for the fairness verification and analysis of quantum\nmachine learning decision models, where we adopt one of the most popular\nnotions of fairness in the literature based on the intuition -- any two similar\nindividuals must be treated similarly and are thus unbiased. We show that\nquantum noise can improve fairness and develop an algorithm to check whether a\n(noisy) quantum machine learning model is fair. In particular, this algorithm\ncan find bias kernels of quantum data (encoding individuals) during checking.\nThese bias kernels generate infinitely many bias pairs for investigating the\nunfairness of the model. Our algorithm is designed based on a highly efficient\ndata structure -- Tensor Networks -- and implemented on Google's TensorFlow\nQuantum. The utility and effectiveness of our algorithm are confirmed by the\nexperimental results, including income prediction and credit scoring on\nreal-world data, for a class of random (noisy) quantum decision models with 27\nqubits ($2^{27}$-dimensional state space) tripling ($2^{18}$ times more than)\nthat of the state-of-the-art algorithms for verifying quantum machine learning\nmodels.",
    "descriptor": "",
    "authors": [
      "Ji Guan",
      "Wang Fang",
      "Mingsheng Ying"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11173"
  },
  {
    "id": "arXiv:2207.11174",
    "title": "Low cost prediction of probability distributions of molecular properties  for early virtual screening",
    "abstract": "While there is a general focus on predictions of values, mathematically more\nappropriate is prediction of probability distributions: with additional\npossibilities like prediction of uncertainty, higher moments and quantiles. For\nthe purpose of the computer-aided drug design field, this article applies\nHierarchical Correlation Reconstruction approach, previously applied in the\nanalysis of demographic, financial and astronomical data. Instead of a single\nlinear regression to predict values, it uses multiple linear regressions to\nindependently predict multiple moments, finally combining them into predicted\nprobability distribution, here of several ADMET properties based on\nsubstructural fingerprint developed by Klekota\\&Roth. Discussed application\nexample is inexpensive selection of a percentage of molecules with properties\nnearly certain to be in a predicted or chosen range during virtual screening.\nSuch an approach can facilitate the interpretation of the results as the\npredictions characterized by high rate of uncertainty are automatically\ndetected. In addition, for each of the investigated predictive problems, we\ndetected crucial structural features, which should be carefully considered when\noptimizing compounds towards particular property. The whole methodology\ndeveloped in the study constitutes therefore a great support for medicinal\nchemists, as it enable fast rejection of compounds with the lowest potential of\ndesired physicochemical/ADMET characteristic and guides the compound\noptimization process.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Jarek Duda",
      "Sabina Podlewska"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2207.11174"
  },
  {
    "id": "arXiv:2207.11203",
    "title": "Human Treelike Tubular Structure Segmentation: A Comprehensive Review  and Future Perspectives",
    "abstract": "Various structures in human physiology follow a treelike morphology, which\noften expresses complexity at very fine scales. Examples of such structures are\nintrathoracic airways, retinal blood vessels, and hepatic blood vessels. Large\ncollections of 2D and 3D images have been made available by medical imaging\nmodalities such as magnetic resonance imaging (MRI), computed tomography (CT),\nOptical coherence tomography (OCT) and ultrasound in which the spatial\narrangement can be observed. Segmentation of these structures in medical\nimaging is of great importance since the analysis of the structure provides\ninsights into disease diagnosis, treatment planning, and prognosis. Manually\nlabelling extensive data by radiologists is often time-consuming and\nerror-prone. As a result, automated or semi-automated computational models have\nbecome a popular research field of medical imaging in the past two decades, and\nmany have been developed to date. In this survey, we aim to provide a\ncomprehensive review of currently publicly available datasets, segmentation\nalgorithms, and evaluation metrics. In addition, current challenges and future\nresearch directions are discussed.",
    "descriptor": "\nComments: 30 pages, 19 figures, submitted to CBM journal\n",
    "authors": [
      "Hao Li",
      "Zeyu Tang",
      "Yang Nan",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.11203"
  },
  {
    "id": "arXiv:2207.11208",
    "title": "Statistical and Computational Trade-offs in Variational Inference: A  Case Study in Inferential Model Selection",
    "abstract": "Variational inference has recently emerged as a popular alternative to the\nclassical Markov chain Monte Carlo (MCMC) in large-scale Bayesian inference.\nThe core idea of variational inference is to trade statistical accuracy for\ncomputational efficiency. It aims to approximate the posterior, reducing\ncomputation costs but potentially compromising its statistical accuracy. In\nthis work, we study this statistical and computational trade-off in variational\ninference via a case study in inferential model selection. Focusing on Gaussian\ninferential models (a.k.a. variational approximating families) with diagonal\nplus low-rank precision matrices, we initiate a theoretical study of the\ntrade-offs in two aspects, Bayesian posterior inference error and frequentist\nuncertainty quantification error. From the Bayesian posterior inference\nperspective, we characterize the error of the variational posterior relative to\nthe exact posterior. We prove that, given a fixed computation budget, a\nlower-rank inferential model produces variational posteriors with a higher\nstatistical approximation error, but a lower computational error; it reduces\nvariances in stochastic optimization and, in turn, accelerates convergence.\nFrom the frequentist uncertainty quantification perspective, we consider the\nprecision matrix of the variational posterior as an uncertainty estimate. We\nfind that, relative to the true asymptotic precision, the variational\napproximation suffers from an additional statistical error originating from the\nsampling uncertainty of the data. Moreover, this statistical error becomes the\ndominant factor as the computation budget increases. As a consequence, for\nsmall datasets, the inferential model need not be full-rank to achieve optimal\nestimation error. We finally demonstrate these statistical and computational\ntrade-offs inference across empirical studies, corroborating the theoretical\nfindings.",
    "descriptor": "\nComments: 56 pages, 8 figures\n",
    "authors": [
      "Kush Bhatia",
      "Nikki Lijing Kuang",
      "Yi-An Ma",
      "Yixin Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11208"
  },
  {
    "id": "arXiv:2207.11210",
    "title": "A Locally Corrected Multiblob Method with Hydrodynamically Matched Grids  for the Stokes Mobility Problem",
    "abstract": "Inexpensive numerical methods are key to enable simulations of systems of a\nlarge number of particles of different shapes in Stokes flow. Several\napproximate methods have been introduced for this purpose. We study the\naccuracy of the multiblob method for solving the Stokes mobility problem in\nfree space, where the 3D geometry of a particle surface is discretised with\nspherical blobs and the pair-wise interaction between blobs is described by the\nRPY-tensor. The paper aims to investigate and improve on the magnitude of the\nerror in the solution velocities of the Stokes mobility problem using a\ncombination of two different techniques: an optimally chosen grid of blobs and\na pair-correction inspired by Stokesian dynamics. Optimisation strategies to\ndetermine a grid with a certain number of blobs are presented with the aim of\nmatching the hydrodynamic response of a single accurately described ideal\nparticle, alone in the fluid. Small errors in this self-interaction are\nessential as they determine the basic error level in a system of well-separated\nparticles. With a good match, reasonable accuracy can be obtained even with\ncoarse blob-resolutions of the particle surfaces. The error in the\nself-interaction is however sensitive to the exact choice of grid parameters\nand simply hand-picking a suitable blob geometry can lead to errors several\norders of magnitude larger in size. The pair-correction is local and cheap to\napply, and reduces on the error for more closely interacting particles. Two\ndifferent types of geometries are considered: spheres and axisymmetric rods\nwith smooth caps. The error in solutions to mobility problems is quantified for\nparticles of varying inter-particle distances for systems containing a few\nparticles, comparing to an accurate solution based on a second kind\nBIE-formulation where the quadrature error is controlled by employing\nquadrature by expansion (QBX).",
    "descriptor": "\nComments: 49 pages, 37 figures\n",
    "authors": [
      "Anna Broms",
      "Mattias Sandberg",
      "Anna-Karin Tornberg"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.11210"
  },
  {
    "id": "arXiv:2207.11220",
    "title": "Stochastic algebraic Riccati equations are almost as easy as  deterministic ones",
    "abstract": "Stochastic algebraic Riccati equations, a.k.a. rational algebraic Riccati\nequations, arising in linear-quadratic optimal control for stochastic linear\ntime-invariant systems, were considered to be not easy to solve.\nThe-state-of-art numerical methods most rely on differentiability or\ncontinuity, such as Newton-type method, LMI method, or homotopy method. In this\npaper, we will build a novel theoretical framework and reveal the intrinsic\nalgebraic structure appearing in this kind of algebraic Riccati equations. This\nstructure guarantees that to solve them is almost as easy as to solve\ndeterministic/classical ones, which will shed light on the theoretical analysis\nand numerical algorithm design for this topic.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Zhen-Chen Guo",
      "Xin Liang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.11220"
  },
  {
    "id": "arXiv:2207.11223",
    "title": "Improved $\u03b1$-GAN architecture for generating 3D connected volumes  with an application to radiosurgery treatment planning",
    "abstract": "Generative Adversarial Networks (GANs) have gained significant attention in\nseveral computer vision tasks for generating high-quality synthetic data.\nVarious medical applications including diagnostic imaging and radiation therapy\ncan benefit greatly from synthetic data generation due to data scarcity in the\ndomain. However, medical image data is typically kept in 3D space, and\ngenerative models suffer from the curse of dimensionality issues in generating\nsuch synthetic data. In this paper, we investigate the potential of GANs for\ngenerating connected 3D volumes. We propose an improved version of 3D\n$\\alpha$-GAN by incorporating various architectural enhancements. On a\nsynthetic dataset of connected 3D spheres and ellipsoids, our model can\ngenerate fully connected 3D shapes with similar geometrical characteristics to\nthat of training data. We also show that our 3D GAN model can successfully\ngenerate high-quality 3D tumor volumes and associated treatment specifications\n(e.g., isocenter locations). Similar moment invariants to the training data as\nwell as fully connected 3D shapes confirm that improved 3D $\\alpha$-GAN\nimplicitly learns the training data distribution, and generates\nrealistic-looking samples. The capability of improved 3D $\\alpha$-GAN makes it\na valuable source for generating synthetic medical image data that can help\nfuture research in this domain.",
    "descriptor": "",
    "authors": [
      "Sanaz Mohammadjafari",
      "Mucahit Cevik",
      "Ayse Basar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11223"
  },
  {
    "id": "arXiv:2207.11225",
    "title": "Large-Kernel Attention for 3D Medical Image Segmentation",
    "abstract": "Automatic segmentation of multiple organs and tumors from 3D medical images\nsuch as magnetic resonance imaging (MRI) and computed tomography (CT) scans\nusing deep learning methods can aid in diagnosing and treating cancer. However,\norgans often overlap and are complexly connected, characterized by extensive\nanatomical variation and low contrast. In addition, the diversity of tumor\nshape, location, and appearance, coupled with the dominance of background\nvoxels, makes accurate 3D medical image segmentation difficult. In this paper,\na novel large-kernel (LK) attention module is proposed to address these\nproblems to achieve accurate multi-organ segmentation and tumor segmentation.\nThe advantages of convolution and self-attention are combined in the proposed\nLK attention module, including local contextual information, long-range\ndependence, and channel adaptation. The module also decomposes the LK\nconvolution to optimize the computational cost and can be easily incorporated\ninto FCNs such as U-Net. Comprehensive ablation experiments demonstrated the\nfeasibility of convolutional decomposition and explored the most efficient and\neffective network design. Among them, the best Mid-type LK attention-based\nU-Net network was evaluated on CT-ORG and BraTS 2020 datasets, achieving\nstate-of-the-art segmentation performance. The performance improvement due to\nthe proposed LK attention module was also statistically validated.",
    "descriptor": "\nComments: 22 pages, 5 figures, submitted to Cognitive Computation\n",
    "authors": [
      "Hao Li",
      "Yang Nan",
      "Javier Del Ser",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11225"
  },
  {
    "id": "arXiv:1901.07820",
    "title": "The Size-Change Principle for Mixed Inductive and Coinductive types",
    "abstract": "The Size-Change Principle for Mixed Inductive and Coinductive types",
    "descriptor": "",
    "authors": [
      "Pierre Hyvernat"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1901.07820"
  },
  {
    "id": "arXiv:1907.05878",
    "title": "Composing Neural Learning and Symbolic Reasoning with an Application to  Visual Discrimination",
    "abstract": "Comments: Published at IJCAI 2022",
    "descriptor": "\nComments: Published at IJCAI 2022\n",
    "authors": [
      "Adithya Murali",
      "Atharva Sehgal",
      "Paul Krogmeier",
      "P. Madhusudan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1907.05878"
  },
  {
    "id": "arXiv:1911.03324",
    "title": "Transforming Wikipedia into Augmented Data for Query-Focused  Summarization",
    "abstract": "Comments: Accepted by IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)",
    "descriptor": "\nComments: Accepted by IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)\n",
    "authors": [
      "Haichao Zhu",
      "Li Dong",
      "Furu Wei",
      "Bing Qin",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1911.03324"
  },
  {
    "id": "arXiv:1912.03207",
    "title": "NASA: Neural Articulated Shape Approximation",
    "abstract": "Comments: ECCV 2020; Project Page: this https URL",
    "descriptor": "\nComments: ECCV 2020; Project Page: this https URL\n",
    "authors": [
      "Boyang Deng",
      "JP Lewis",
      "Timothy Jeruzalski",
      "Gerard Pons-Moll",
      "Geoffrey Hinton",
      "Mohammad Norouzi",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.03207"
  },
  {
    "id": "arXiv:1912.08157",
    "title": "Generalized perron roots and solvability of the absolute value equation",
    "abstract": "Comments: 19 pages, 2 figures",
    "descriptor": "\nComments: 19 pages, 2 figures\n",
    "authors": [
      "Manuel Radons",
      "Josu\u00e9 Tonelli-Cueto"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1912.08157"
  },
  {
    "id": "arXiv:2002.08232",
    "title": "CoLES: Contrastive Learning for Event Sequences with Self-Supervision",
    "abstract": "Comments: SIGMOD'22",
    "descriptor": "\nComments: SIGMOD'22\n",
    "authors": [
      "Dmitrii Babaev",
      "Ivan Kireev",
      "Nikita Ovsov",
      "Mariya Ivanova",
      "Gleb Gusev",
      "Ivan Nazarov",
      "Alexander Tuzhilin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.08232"
  },
  {
    "id": "arXiv:2007.06552",
    "title": "Relaxing the I.I.D. Assumption: Adaptively Minimax Optimal Regret via  Root-Entropic Regularization",
    "abstract": "Comments: 71 pages, 3 figures. Blair Bilodeau and Jeffrey Negrea are equal-contribution authors; order was determined randomly",
    "descriptor": "\nComments: 71 pages, 3 figures. Blair Bilodeau and Jeffrey Negrea are equal-contribution authors; order was determined randomly\n",
    "authors": [
      "Blair Bilodeau",
      "Jeffrey Negrea",
      "Daniel M. Roy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.06552"
  },
  {
    "id": "arXiv:2008.00584",
    "title": "Optimal rates of convergence and error localization of Gegenbauer  projections",
    "abstract": "Comments: IMA J. Numer. Anal., to appear",
    "descriptor": "\nComments: IMA J. Numer. Anal., to appear\n",
    "authors": [
      "Haiyong Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2008.00584"
  },
  {
    "id": "arXiv:2008.03533",
    "title": "How Trustworthy are Performance Evaluations for Basic Vision Tasks?",
    "abstract": "Comments: Tran Thien Dat Nguyen and Hamid Rezatofighi have contributed equally",
    "descriptor": "\nComments: Tran Thien Dat Nguyen and Hamid Rezatofighi have contributed equally\n",
    "authors": [
      "Tran Thien Dat Nguyen",
      "Hamid Rezatofighi",
      "Ba-Ngu Vo",
      "Ba-Tuong Vo",
      "Silvio Savarese",
      "Ian Reid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.03533"
  },
  {
    "id": "arXiv:2008.07898",
    "title": "Minimum Eccentricity Shortest Path Problem with Respect to Structural  Parameters",
    "abstract": "Minimum Eccentricity Shortest Path Problem with Respect to Structural  Parameters",
    "descriptor": "",
    "authors": [
      "Martin Ku\u010dera",
      "Ond\u0159ej Such\u00fd"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2008.07898"
  },
  {
    "id": "arXiv:2010.04918",
    "title": "Automatically Deriving Control-Flow Graph Generators from Operational  Semantics",
    "abstract": "Automatically Deriving Control-Flow Graph Generators from Operational  Semantics",
    "descriptor": "",
    "authors": [
      "James Koppel",
      "Jackson Kearl",
      "Armando Solar-Lezama"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2010.04918"
  },
  {
    "id": "arXiv:2011.09290",
    "title": "Practical Privacy Attacks on Vertical Federated Learning",
    "abstract": "Practical Privacy Attacks on Vertical Federated Learning",
    "descriptor": "",
    "authors": [
      "Haiqin Weng",
      "Juntao Zhang",
      "Xingjun Ma",
      "Feng Xue",
      "Tao Wei",
      "Shouling Ji",
      "Zhiyuan Zong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.09290"
  },
  {
    "id": "arXiv:2012.06568",
    "title": "Learning Energy-Based Models With Adversarial Training",
    "abstract": "Comments: ECCV2022, code is available at this https URL",
    "descriptor": "\nComments: ECCV2022, code is available at this https URL\n",
    "authors": [
      "Xuwang Yin",
      "Shiying Li",
      "Gustavo K. Rohde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.06568"
  },
  {
    "id": "arXiv:2012.07369",
    "title": "Learning for MPC with Stability & Safety Guarantees",
    "abstract": "Learning for MPC with Stability & Safety Guarantees",
    "descriptor": "",
    "authors": [
      "S\u00e9bastien Gros",
      "Mario Zanon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.07369"
  },
  {
    "id": "arXiv:2102.09237",
    "title": "Strongly Connected Topology Model and Confirmation-based Propagation  Method for Cross-chain Interaction",
    "abstract": "Strongly Connected Topology Model and Confirmation-based Propagation  Method for Cross-chain Interaction",
    "descriptor": "",
    "authors": [
      "Hong Su"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.09237"
  },
  {
    "id": "arXiv:2103.03567",
    "title": "Thermodynamic topology optimization including plasticity",
    "abstract": "Thermodynamic topology optimization including plasticity",
    "descriptor": "",
    "authors": [
      "Miriam Kick",
      "Philipp Junker"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2103.03567"
  },
  {
    "id": "arXiv:2103.06127",
    "title": "Linearly Qualified Types: Generic inference for capabilities and  uniqueness",
    "abstract": "Linearly Qualified Types: Generic inference for capabilities and  uniqueness",
    "descriptor": "",
    "authors": [
      "Arnaud Spiwack",
      "Csongor Kiss",
      "Jean-Philippe Bernardy",
      "Nicolas Wu",
      "Richard Eisenberg"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2103.06127"
  },
  {
    "id": "arXiv:2103.07011",
    "title": "Towards Socially Intelligent Agents with Mental State Transition and  Human Utility",
    "abstract": "Comments: Long paper accepted by SIGDIAL 2022",
    "descriptor": "\nComments: Long paper accepted by SIGDIAL 2022\n",
    "authors": [
      "Liang Qiu",
      "Yizhou Zhao",
      "Yuan Liang",
      "Pan Lu",
      "Weiyan Shi",
      "Zhou Yu",
      "Song-Chun Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.07011"
  },
  {
    "id": "arXiv:2103.10185",
    "title": "About subordinated generalizations of 3 classical models of option  pricing",
    "abstract": "About subordinated generalizations of 3 classical models of option  pricing",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Balcerek",
      "Grzegorz Krzy\u017canowski",
      "Marcin Magdziarz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.10185"
  },
  {
    "id": "arXiv:2103.14453",
    "title": "Data Augmentation in Natural Language Processing: A Novel Text  Generation Approach for Long and Short Text Classifiers",
    "abstract": "Comments: 17 pages, 3 figure, 5 tables",
    "descriptor": "\nComments: 17 pages, 3 figure, 5 tables\n",
    "authors": [
      "Markus Bayer",
      "Marc-Andr\u00e9 Kaufhold",
      "Bj\u00f6rn Buchhold",
      "Marcel Keller",
      "J\u00f6rg Dallmeyer",
      "Christian Reuter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.14453"
  },
  {
    "id": "arXiv:2103.16365",
    "title": "FoV-NeRF: Foveated Neural Radiance Fields for Virtual Reality",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Nianchen Deng",
      "Zhenyi He",
      "Jiannan Ye",
      "Budmonde Duinkharjav",
      "Praneeth Chakravarthula",
      "Xubo Yang",
      "Qi Sun"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.16365"
  },
  {
    "id": "arXiv:2104.08166",
    "title": "Automatic Termination for Hyperparameter Optimization",
    "abstract": "Comments: Accepted at AutoML Conference 2022",
    "descriptor": "\nComments: Accepted at AutoML Conference 2022\n",
    "authors": [
      "Anastasia Makarova",
      "Huibin Shen",
      "Valerio Perrone",
      "Aaron Klein",
      "Jean Baptiste Faddoul",
      "Andreas Krause",
      "Matthias Seeger",
      "Cedric Archambeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.08166"
  },
  {
    "id": "arXiv:2104.09340",
    "title": "Code Structure Guided Transformer for Source Code Summarization",
    "abstract": "Code Structure Guided Transformer for Source Code Summarization",
    "descriptor": "",
    "authors": [
      "Shuzheng Gao",
      "Cuiyun Gao",
      "Yulan He",
      "Jichuan Zeng",
      "Lun Yiu Nie",
      "Xin Xia",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.09340"
  },
  {
    "id": "arXiv:2104.10997",
    "title": "Economic MPC of Markov Decision Processes: Dissipativity in Undiscounted  Infinite-Horizon Optimal Control",
    "abstract": "Economic MPC of Markov Decision Processes: Dissipativity in Undiscounted  Infinite-Horizon Optimal Control",
    "descriptor": "",
    "authors": [
      "S\u00e9bastien Gros",
      "Mario Zanon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.10997"
  },
  {
    "id": "arXiv:2105.14944",
    "title": "The effectiveness of feature attribution methods and its correlation  with automatic evaluation scores",
    "abstract": "Comments: NeurIPS 2021; 10 pages of Main text; 28 pages of Appendix",
    "descriptor": "\nComments: NeurIPS 2021; 10 pages of Main text; 28 pages of Appendix\n",
    "authors": [
      "Giang Nguyen",
      "Daeyoung Kim",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.14944"
  },
  {
    "id": "arXiv:2106.00365",
    "title": "Scientific Computing in the Cavendish Laboratory and the pioneering  women Computors",
    "abstract": "Comments: 11 pages, 8 figures, accepted by Annals of Science",
    "descriptor": "\nComments: 11 pages, 8 figures, accepted by Annals of Science\n",
    "authors": [
      "Verity Allan",
      "Caitriona Leedham"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2106.00365"
  },
  {
    "id": "arXiv:2107.01809",
    "title": "Boosting Transferability of Targeted Adversarial Examples via  Hierarchical Generative Networks",
    "abstract": "Boosting Transferability of Targeted Adversarial Examples via  Hierarchical Generative Networks",
    "descriptor": "",
    "authors": [
      "Xiao Yang",
      "Yinpeng Dong",
      "Tianyu Pang",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01809"
  },
  {
    "id": "arXiv:2107.03021",
    "title": "Bi-level Feature Alignment for Versatile Image Translation and  Manipulation",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Fangneng Zhan",
      "Yingchen Yu",
      "Rongliang Wu",
      "Jiahui Zhang",
      "Kaiwen Cui",
      "Aoran Xiao",
      "Shijian Lu",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.03021"
  },
  {
    "id": "arXiv:2107.03158",
    "title": "A Survey on Data Augmentation for Text Classification",
    "abstract": "Comments: 43 pages, 5 figures, 9 tables",
    "descriptor": "\nComments: 43 pages, 5 figures, 9 tables\n",
    "authors": [
      "Markus Bayer",
      "Marc-Andr\u00e9 Kaufhold",
      "Christian Reuter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.03158"
  },
  {
    "id": "arXiv:2108.00513",
    "title": "Attention-based Aspect Reasoning for Knowledge Base Question Answering  on Clinical Notes",
    "abstract": "Comments: Accepted to ACM BCB 2022",
    "descriptor": "\nComments: Accepted to ACM BCB 2022\n",
    "authors": [
      "Ping Wang",
      "Tian Shi",
      "Khushbu Agarwal",
      "Sutanay Choudhury",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.00513"
  },
  {
    "id": "arXiv:2108.12821",
    "title": "Analyzing and Mitigating Interference in Neural Architecture Search",
    "abstract": "Comments: ICML 2022, Spotlight",
    "descriptor": "\nComments: ICML 2022, Spotlight\n",
    "authors": [
      "Jin Xu",
      "Xu Tan",
      "Kaitao Song",
      "Renqian Luo",
      "Yichong Leng",
      "Tao Qin",
      "Tie-Yan Liu",
      "Jian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.12821"
  },
  {
    "id": "arXiv:2109.00161",
    "title": "Simultaneous Neural Network Approximation for Smooth Functions",
    "abstract": "Simultaneous Neural Network Approximation for Smooth Functions",
    "descriptor": "",
    "authors": [
      "Sean Hon",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.00161"
  },
  {
    "id": "arXiv:2109.05776",
    "title": "Learning to Predict Diverse Human Motions from a Single Image via  Mixture Density Networks",
    "abstract": "Learning to Predict Diverse Human Motions from a Single Image via  Mixture Density Networks",
    "descriptor": "",
    "authors": [
      "Chunzhi Gu",
      "Yan Zhao",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05776"
  },
  {
    "id": "arXiv:2109.07033",
    "title": "A local energy-based discontinuous Galerkin method for fourth order  semilinear wave equations",
    "abstract": "A local energy-based discontinuous Galerkin method for fourth order  semilinear wave equations",
    "descriptor": "",
    "authors": [
      "Lu Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.07033"
  },
  {
    "id": "arXiv:2109.07647",
    "title": "Sublinear Time Eigenvalue Approximation via Random Sampling",
    "abstract": "Comments: 58 pages, 4 figures",
    "descriptor": "\nComments: 58 pages, 4 figures\n",
    "authors": [
      "Rajarshi Bhattacharjee",
      "Gregory Dexter",
      "Petros Drineas",
      "Cameron Musco",
      "Archan Ray"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.07647"
  },
  {
    "id": "arXiv:2109.10077",
    "title": "Scale-aware direct monocular odometry",
    "abstract": "Comments: This paper has been accepted for publication in the IROS2022 conference",
    "descriptor": "\nComments: This paper has been accepted for publication in the IROS2022 conference\n",
    "authors": [
      "Carlos Campos",
      "Juan D. Tard\u00f3s"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.10077"
  },
  {
    "id": "arXiv:2109.13226",
    "title": "BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning  for Automatic Speech Recognition",
    "abstract": "Comments: 14 pages, 7 figures, 13 tables; v2: minor corrections, reference baselines and bibliography updated; v3: corrections based on reviewer feedback, bibliography updated",
    "descriptor": "\nComments: 14 pages, 7 figures, 13 tables; v2: minor corrections, reference baselines and bibliography updated; v3: corrections based on reviewer feedback, bibliography updated\n",
    "authors": [
      "Yu Zhang",
      "Daniel S. Park",
      "Wei Han",
      "James Qin",
      "Anmol Gulati",
      "Joel Shor",
      "Aren Jansen",
      "Yuanzhong Xu",
      "Yanping Huang",
      "Shibo Wang",
      "Zongwei Zhou",
      "Bo Li",
      "Min Ma",
      "William Chan",
      "Jiahui Yu",
      "Yongqiang Wang",
      "Liangliang Cao",
      "Khe Chai Sim",
      "Bhuvana Ramabhadran",
      "Tara N. Sainath",
      "Fran\u00e7oise Beaufays",
      "Zhifeng Chen",
      "Quoc V. Le",
      "Chung-Cheng Chiu",
      "Ruoming Pang",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.13226"
  },
  {
    "id": "arXiv:2110.00072",
    "title": "Inequality and Inequity in Network-based Ranking and Recommendation  Algorithms",
    "abstract": "Comments: 23 pages, 7 figures and 3 tables in main manuscript. Includes supplementary material",
    "descriptor": "\nComments: 23 pages, 7 figures and 3 tables in main manuscript. Includes supplementary material\n",
    "authors": [
      "Lisette Esp\u00edn-Noboa",
      "Claudia Wagner",
      "Markus Strohmaier",
      "Fariba Karimi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.00072"
  },
  {
    "id": "arXiv:2110.03892",
    "title": "Bounding-box deep calibration for high performance face detection",
    "abstract": "Comments: 12 pages, 7 figures, 5 tables, 1 algorithm, 9 equation, 2 definition",
    "descriptor": "\nComments: 12 pages, 7 figures, 5 tables, 1 algorithm, 9 equation, 2 definition\n",
    "authors": [
      "Shi Luo",
      "Xiongfei Li",
      "Xiaoli Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03892"
  },
  {
    "id": "arXiv:2110.07291",
    "title": "Only Time Will Tell: Modelling Information Diffusion in Code Review with  Time-Varying Hypergraphs",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Michael Dorner",
      "Darja \u0160mite",
      "Daniel Mendez",
      "Krzysztof Wnuk",
      "Jacek Czerwonka"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.07291"
  },
  {
    "id": "arXiv:2110.07292",
    "title": "Sign and Relevance learning",
    "abstract": "Comments: 26 pages, 12 figures",
    "descriptor": "\nComments: 26 pages, 12 figures\n",
    "authors": [
      "Sama Daryanavard",
      "Bernd Porr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2110.07292"
  },
  {
    "id": "arXiv:2110.07618",
    "title": "Function-space Inference with Sparse Implicit Processes",
    "abstract": "Comments: Published at ICML 2022 (long oral presentation). Code available at this https URL",
    "descriptor": "\nComments: Published at ICML 2022 (long oral presentation). Code available at this https URL\n",
    "authors": [
      "Sim\u00f3n Rodr\u00edguez Santana",
      "Bryan Zaldivar",
      "Daniel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07618"
  },
  {
    "id": "arXiv:2110.07682",
    "title": "Sound and Complete Neural Network Repair with Minimality and Locality  Guarantees",
    "abstract": "Comments: 17 pages, 3 figures",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Feisi Fu",
      "Wenchao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07682"
  },
  {
    "id": "arXiv:2111.00232",
    "title": "MFNet: Multi-class Few-shot Segmentation Network with Pixel-wise Metric  Learning",
    "abstract": "Comments: Accepted on IEEE Transactions on Circuits and Systems for Video Technology",
    "descriptor": "\nComments: Accepted on IEEE Transactions on Circuits and Systems for Video Technology\n",
    "authors": [
      "Miao Zhang",
      "Miaojing Shi",
      "Li Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00232"
  },
  {
    "id": "arXiv:2111.04130",
    "title": "NLP From Scratch Without Large-Scale Pretraining: A Simple and Efficient  Framework",
    "abstract": "Comments: 14 pages, 5 figures",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Xingcheng Yao",
      "Yanan Zheng",
      "Xiaocong Yang",
      "Zhilin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.04130"
  },
  {
    "id": "arXiv:2111.07059",
    "title": "Classical and Quantum Algorithms for Variants of Subset-Sum via Dynamic  Programming",
    "abstract": "Comments: 28 pages, 1 figure; v2: title changed, referee's comments incorporated",
    "descriptor": "\nComments: 28 pages, 1 figure; v2: title changed, referee's comments incorporated\n",
    "authors": [
      "Jonathan Allcock",
      "Yassine Hamoudi",
      "Antoine Joux",
      "Felix Klingelh\u00f6fer",
      "Miklos Santha"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.07059"
  },
  {
    "id": "arXiv:2111.08761",
    "title": "Stronger Generalization Guarantees for Robot Learning by Combining  Generative Models and Real-World Data",
    "abstract": "Stronger Generalization Guarantees for Robot Learning by Combining  Generative Models and Real-World Data",
    "descriptor": "",
    "authors": [
      "Abhinav Agarwal",
      "Sushant Veer",
      "Allen Z. Ren",
      "Anirudha Majumdar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08761"
  },
  {
    "id": "arXiv:2111.12485",
    "title": "Understanding the Dynamics of DNNs Using Graph Modularity",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Yao Lu",
      "Wen Yang",
      "Yunzhe Zhang",
      "Zuohui Chen",
      "Jinyin Chen",
      "Qi Xuan",
      "Zhen Wang",
      "Xiaoniu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12485"
  },
  {
    "id": "arXiv:2112.00584",
    "title": "The Shape Part Slot Machine: Contact-based Reasoning for Generating 3D  Shapes from Parts",
    "abstract": "Comments: European Conference on Computer Vision (ECCV) 2022",
    "descriptor": "\nComments: European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Kai Wang",
      "Paul Guerrero",
      "Vladimir Kim",
      "Siddhartha Chaudhuri",
      "Minhyuk Sung",
      "Daniel Ritchie"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00584"
  },
  {
    "id": "arXiv:2112.01551",
    "title": "D3Net: A Unified Speaker-Listener Architecture for 3D Dense Captioning  and Visual Grounding",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Dave Zhenyu Chen",
      "Qirui Wu",
      "Matthias Nie\u00dfner",
      "Angel X. Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01551"
  },
  {
    "id": "arXiv:2112.02308",
    "title": "MoFaNeRF: Morphable Facial Neural Radiance Field",
    "abstract": "Comments: accepted to ECCV2022; code available at this http URL",
    "descriptor": "\nComments: accepted to ECCV2022; code available at this http URL\n",
    "authors": [
      "Yiyu Zhuang",
      "Hao Zhu",
      "Xusen Sun",
      "Xun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.02308"
  },
  {
    "id": "arXiv:2112.02537",
    "title": "Designing Enhanced Multi-dimensional Constellations for Code-Domain NOMA",
    "abstract": "Designing Enhanced Multi-dimensional Constellations for Code-Domain NOMA",
    "descriptor": "",
    "authors": [
      "Haifeng Wen",
      "Zilong Liu",
      "Qu Luo",
      "Chuang Shi",
      "Pei Xiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.02537"
  },
  {
    "id": "arXiv:2112.02990",
    "title": "4DContrast: Contrastive Learning with Dynamic Correspondences for 3D  Scene Understanding",
    "abstract": "Comments: Accepted by ECCV 2022, Video: this https URL",
    "descriptor": "\nComments: Accepted by ECCV 2022, Video: this https URL\n",
    "authors": [
      "Yujin Chen",
      "Matthias Nie\u00dfner",
      "Angela Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02990"
  },
  {
    "id": "arXiv:2112.06102",
    "title": "NeuroHSMD: Neuromorphic Hybrid Spiking Motion Detector",
    "abstract": "NeuroHSMD: Neuromorphic Hybrid Spiking Motion Detector",
    "descriptor": "",
    "authors": [
      "Pedro Machado",
      "Joao Filipe Ferreira",
      "Andreas Oikonomou",
      "T.M. McGinnity"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.06102"
  },
  {
    "id": "arXiv:2112.06242",
    "title": "Formulating Event-based Image Reconstruction as a Linear Inverse Problem  using Optical Flow",
    "abstract": "Comments: 19 pages, 22 figures, 5 tables",
    "descriptor": "\nComments: 19 pages, 22 figures, 5 tables\n",
    "authors": [
      "Zelin Zhang",
      "Anthony Yezzi",
      "Guillermo Gallego"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.06242"
  },
  {
    "id": "arXiv:2112.06623",
    "title": "ROMEO: Exploring Juliet through the Lens of Assembly Language",
    "abstract": "Comments: 6 pages, code available at this https URL",
    "descriptor": "\nComments: 6 pages, code available at this https URL\n",
    "authors": [
      "Clemens-Alexander Brust",
      "Bernd Gruner",
      "Tim Sonnekalb"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.06623"
  },
  {
    "id": "arXiv:2112.08106",
    "title": "Enhance Connectivity of Promising Regions for Sampling-based Path  Planning",
    "abstract": "Comments: Accepted in Transactions on Automation Science and Engineering, 2022",
    "descriptor": "\nComments: Accepted in Transactions on Automation Science and Engineering, 2022\n",
    "authors": [
      "Han Ma",
      "Chenming Li",
      "Jianbang Liu",
      "Jiankun Wang",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08106"
  },
  {
    "id": "arXiv:2112.08718",
    "title": "Prompt Tuning GPT-2 language model for parameter-efficient domain  adaptation of ASR systems",
    "abstract": "Comments: Accepted at InterSpeech 2022",
    "descriptor": "\nComments: Accepted at InterSpeech 2022\n",
    "authors": [
      "Saket Dingliwal",
      "Ashish Shenoy",
      "Sravan Bodapati",
      "Ankur Gandhe",
      "Ravi Teja Gadde",
      "Katrin Kirchhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08718"
  },
  {
    "id": "arXiv:2112.10103",
    "title": "SAGA: Stochastic Whole-Body Grasping with Contact",
    "abstract": "Comments: Accepted by ECCV 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted by ECCV 2022. Project page: this https URL\n",
    "authors": [
      "Yan Wu",
      "Jiahao Wang",
      "Yan Zhang",
      "Siwei Zhang",
      "Otmar Hilliges",
      "Fisher Yu",
      "Siyu Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.10103"
  },
  {
    "id": "arXiv:2112.10644",
    "title": "Self-attention Presents Low-dimensional Knowledge Graph Embeddings for  Link Prediction",
    "abstract": "Comments: 13 pages, 2 figure, 5 tables",
    "descriptor": "\nComments: 13 pages, 2 figure, 5 tables\n",
    "authors": [
      "Peyman Baghershahi",
      "Reshad Hosseini",
      "Hadi Moradi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.10644"
  },
  {
    "id": "arXiv:2112.11449",
    "title": "Doubly-Valid/Doubly-Sharp Sensitivity Analysis for Causal Inference with  Unmeasured Confounding",
    "abstract": "Doubly-Valid/Doubly-Sharp Sensitivity Analysis for Causal Inference with  Unmeasured Confounding",
    "descriptor": "",
    "authors": [
      "Jacob Dorn",
      "Kevin Guo",
      "Nathan Kallus"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.11449"
  },
  {
    "id": "arXiv:2112.12961",
    "title": "Optimal Model Averaging of Support Vector Machines in Diverging Model  Spaces",
    "abstract": "Comments: need to be improved further",
    "descriptor": "\nComments: need to be improved further\n",
    "authors": [
      "Chaoxia Yuan",
      "Chao Ying",
      "Zhou Yu",
      "Fang Fang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12961"
  },
  {
    "id": "arXiv:2112.13951",
    "title": "Improving Nonparametric Classification via Local Radial Regression with  an Application to Stock Prediction",
    "abstract": "Comments: 23pages, 10 figures, first two authors (R. Cao and A. Okuno) contributed equally to this work",
    "descriptor": "\nComments: 23pages, 10 figures, first two authors (R. Cao and A. Okuno) contributed equally to this work\n",
    "authors": [
      "Ruixing Cao",
      "Akifumi Okuno",
      "Kei Nakagawa",
      "Hidetoshi Shimodaira"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.13951"
  },
  {
    "id": "arXiv:2201.00844",
    "title": "Deriving discriminative classifiers from generative models",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Elie Azeraf",
      "Emmanuel Monfrini",
      "Wojciech Pieczynski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00844"
  },
  {
    "id": "arXiv:2201.05596",
    "title": "DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to  Power Next-Generation AI Scale",
    "abstract": "Comments: This paper is published at ICML 2022: this https URL",
    "descriptor": "\nComments: This paper is published at ICML 2022: this https URL\n",
    "authors": [
      "Samyam Rajbhandari",
      "Conglong Li",
      "Zhewei Yao",
      "Minjia Zhang",
      "Reza Yazdani Aminabadi",
      "Ammar Ahmad Awan",
      "Jeff Rasley",
      "Yuxiong He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.05596"
  },
  {
    "id": "arXiv:2201.09263",
    "title": "Differential Geometry for Neural Implicit Models",
    "abstract": "Differential Geometry for Neural Implicit Models",
    "descriptor": "",
    "authors": [
      "Tiago Novello",
      "Guilherme Schardong",
      "Luiz Schirmer",
      "Vinicius da Silva",
      "Helio Lopes",
      "Luiz Velho"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09263"
  },
  {
    "id": "arXiv:2201.09857",
    "title": "STOPS: Short-Term-based Volatility-controlled Policy Search and its  Global Convergence",
    "abstract": "STOPS: Short-Term-based Volatility-controlled Policy Search and its  Global Convergence",
    "descriptor": "",
    "authors": [
      "Liangliang Xu",
      "Daoming Lyu",
      "Yangchen Pan",
      "Aiwen Jiang",
      "Bo Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09857"
  },
  {
    "id": "arXiv:2201.10374",
    "title": "Multiscale modeling of linear elastic heterogeneous structures via  localized model order reduction",
    "abstract": "Multiscale modeling of linear elastic heterogeneous structures via  localized model order reduction",
    "descriptor": "",
    "authors": [
      "Philipp Diercks",
      "Karen Veroy",
      "Annika Robens-Radermacher",
      "J\u00f6rg F. Unger"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.10374"
  },
  {
    "id": "arXiv:2201.11113",
    "title": "Post-training Quantization for Neural Networks with Provable Guarantees",
    "abstract": "Post-training Quantization for Neural Networks with Provable Guarantees",
    "descriptor": "",
    "authors": [
      "Jinjie Zhang",
      "Yixuan Zhou",
      "Rayan Saab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11113"
  },
  {
    "id": "arXiv:2201.11729",
    "title": "Implicit Regularization in Hierarchical Tensor Factorization and Deep  Convolutional Neural Networks",
    "abstract": "Comments: Accepted to ICML 2022",
    "descriptor": "\nComments: Accepted to ICML 2022\n",
    "authors": [
      "Noam Razin",
      "Asaf Maman",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11729"
  },
  {
    "id": "arXiv:2201.12041",
    "title": "Rapid protein assignments and structures from raw NMR spectra with the  deep learning technique ARTINA",
    "abstract": "Rapid protein assignments and structures from raw NMR spectra with the  deep learning technique ARTINA",
    "descriptor": "",
    "authors": [
      "Piotr Klukowski",
      "Roland Riek",
      "Peter G\u00fcntert"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12041"
  },
  {
    "id": "arXiv:2201.12362",
    "title": "Physics-informed neural networks to learn cardiac fiber orientation from  multiple electroanatomical maps",
    "abstract": "Comments: 29 pages, 11 figures",
    "descriptor": "\nComments: 29 pages, 11 figures\n",
    "authors": [
      "Carlos Ruiz Herrera",
      "Thomas Grandits",
      "Gernot Plank",
      "Paris Perdikaris",
      "Francisco Sahli Costabal",
      "Simone Pezzuto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2201.12362"
  },
  {
    "id": "arXiv:2201.12532",
    "title": "Modeling Complex Dependencies for Session-based Recommendations via  Graph Neural Networks",
    "abstract": "Comments: 12 pages, 4 figures, conference",
    "descriptor": "\nComments: 12 pages, 4 figures, conference\n",
    "authors": [
      "Qian Zhang",
      "Wenpeng Lu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12532"
  },
  {
    "id": "arXiv:2201.13311",
    "title": "Neighbour Interaction based Click-Through Rate Prediction via  Graph-masked Transformer",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Erxue Min",
      "Yu Rong",
      "Tingyang Xu",
      "Yatao Bian",
      "Peilin Zhao",
      "Junzhou Huang",
      "Da Luo",
      "Kangyi Lin",
      "Sophia Ananiadou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13311"
  },
  {
    "id": "arXiv:2202.00520",
    "title": "Exact Matrix Factorization Updates for Nonlinear Programming",
    "abstract": "Comments: 39 pages, 1 figure, 2 tables",
    "descriptor": "\nComments: 39 pages, 1 figure, 2 tables\n",
    "authors": [
      "Adolfo R. Escobedo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.00520"
  },
  {
    "id": "arXiv:2202.02545",
    "title": "Optimization of a Real-Time Wavelet-Based Algorithm for Improving Speech  Intelligibility",
    "abstract": "Comments: 16 pages, 7 figures, 4 tables",
    "descriptor": "\nComments: 16 pages, 7 figures, 4 tables\n",
    "authors": [
      "Tianqu Kang",
      "Anh-Dung Dinh",
      "Binghong Wang",
      "Tianyuan Du",
      "Yijia Chen",
      "Kevin Chau"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.02545"
  },
  {
    "id": "arXiv:2202.09387",
    "title": "A mixed-integer programming model for identifying intuitive ambulance  dispatching policies",
    "abstract": "A mixed-integer programming model for identifying intuitive ambulance  dispatching policies",
    "descriptor": "",
    "authors": [
      "Laura A. Albert"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.09387"
  },
  {
    "id": "arXiv:2202.11781",
    "title": "RadioTransformer: A Cascaded Global-Focal Transformer for Visual  Attention-guided Disease Classification",
    "abstract": "RadioTransformer: A Cascaded Global-Focal Transformer for Visual  Attention-guided Disease Classification",
    "descriptor": "",
    "authors": [
      "Moinak Bhattacharya",
      "Shubham Jain",
      "Prateek Prasanna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11781"
  },
  {
    "id": "arXiv:2202.12243",
    "title": "Flat Latent Manifolds for Human-machine Co-creation of Music",
    "abstract": "Comments: 3rd Conference on AI Music Creativity (AIMC 2022)",
    "descriptor": "\nComments: 3rd Conference on AI Music Creativity (AIMC 2022)\n",
    "authors": [
      "Nutan Chen",
      "Djalel Benbouzid",
      "Francesco Ferroni",
      "Mathis Nitschke",
      "Luciano Pinna",
      "Patrick van der Smagt"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.12243"
  },
  {
    "id": "arXiv:2202.13784",
    "title": "A Signature-based Algorithm for Computing the Nondegenerate Locus of a  Polynomial System",
    "abstract": "Comments: 22 pages, 2 figures. Substantial rewrite of content of the parts of the paper involving signature-based Gr\\\"obner basis algorithms, both the exposition and the description of the core algorithm of the paper changed",
    "descriptor": "\nComments: 22 pages, 2 figures. Substantial rewrite of content of the parts of the paper involving signature-based Gr\\\"obner basis algorithms, both the exposition and the description of the core algorithm of the paper changed\n",
    "authors": [
      "Christian Eder",
      "Pierre Lairez",
      "Rafael Mohr",
      "Mohab Safey El Din"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.13784"
  },
  {
    "id": "arXiv:2203.00474",
    "title": "On the sample complexity of stabilizing linear dynamical systems from  data",
    "abstract": "Comments: 29 pages, 4 figures",
    "descriptor": "\nComments: 29 pages, 4 figures\n",
    "authors": [
      "Steffen W. R. Werner",
      "Benjamin Peherstorfer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.00474"
  },
  {
    "id": "arXiv:2203.00795",
    "title": "Amplitude Control for Parallel Lattices of Docked Modboats",
    "abstract": "Comments: 7 pages. Accepted to the 2022 International Conference on Robotics and Automation (ICRA)",
    "descriptor": "\nComments: 7 pages. Accepted to the 2022 International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Gedaliah Knizhnik",
      "Mark Yim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.00795"
  },
  {
    "id": "arXiv:2203.00796",
    "title": "Flow-Based Control of Marine Robots in Gyre-Like Environments",
    "abstract": "Comments: 7 pages. Published at 2022 International Conference on Robotics and Automation (ICRA)",
    "descriptor": "\nComments: 7 pages. Published at 2022 International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Gedaliah Knizhnik",
      "Peihan Li",
      "Xi Yu",
      "M. Ani Hsieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.00796"
  },
  {
    "id": "arXiv:2203.06660",
    "title": "Incomplete List Setting of the Hospitals/Residents Problem with  Maximally Satisfying Lower Quotas",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2105.03093",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.03093\n",
    "authors": [
      "Kazuhisa Makino",
      "Shuichi Miyazaki",
      "Yu Yokoi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.06660"
  },
  {
    "id": "arXiv:2203.08472",
    "title": "Fusing Local Similarities for Retrieval-based 3D Orientation Estimation  of Unseen Objects",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Chen Zhao",
      "Yinlin Hu",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.08472"
  },
  {
    "id": "arXiv:2203.09674",
    "title": "A workflow for segmenting soil and plant X-ray CT images with deep  learning in Googles Colaboratory",
    "abstract": "Comments: 58 pages, 9 figures, 2 Tables",
    "descriptor": "\nComments: 58 pages, 9 figures, 2 Tables\n",
    "authors": [
      "Devin A. Rippner",
      "Pranav Raja",
      "J. Mason Earles",
      "Alexander Buchko",
      "Mina Momayyezi",
      "Fiona Duong",
      "Dilworth Parkinson",
      "Elizabeth Forrestel",
      "Ken Shackel",
      "Jeffrey Neyhart",
      "Andrew J. McElrone"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2203.09674"
  },
  {
    "id": "arXiv:2203.09675",
    "title": "Fast Bayesian Coresets via Subsampling and Quasi-Newton Refinement",
    "abstract": "Fast Bayesian Coresets via Subsampling and Quasi-Newton Refinement",
    "descriptor": "",
    "authors": [
      "Cian Naik",
      "Judith Rousseau",
      "Trevor Campbell"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.09675"
  },
  {
    "id": "arXiv:2203.10789",
    "title": "Domain Generalization by Mutual-Information Regularization with  Pre-trained Models",
    "abstract": "Comments: ECCV 2022 camera-ready",
    "descriptor": "\nComments: ECCV 2022 camera-ready\n",
    "authors": [
      "Junbum Cha",
      "Kyungjae Lee",
      "Sungrae Park",
      "Sanghyuk Chun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10789"
  },
  {
    "id": "arXiv:2203.12088",
    "title": "Deep Portrait Delighting",
    "abstract": "Comments: Accepted in ECCV2022",
    "descriptor": "\nComments: Accepted in ECCV2022\n",
    "authors": [
      "Joshua Weir",
      "Junhong Zhao",
      "Andrew Chalmers",
      "Taehyun Rhee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12088"
  },
  {
    "id": "arXiv:2203.12719",
    "title": "What to Hide from Your Students: Attention-Guided Masked Image Modeling",
    "abstract": "Comments: ECCV 2022. Codes and models are available at this https URL",
    "descriptor": "\nComments: ECCV 2022. Codes and models are available at this https URL\n",
    "authors": [
      "Ioannis Kakogeorgiou",
      "Spyros Gidaris",
      "Bill Psomas",
      "Yannis Avrithis",
      "Andrei Bursuc",
      "Konstantinos Karantzalos",
      "Nikos Komodakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12719"
  },
  {
    "id": "arXiv:2203.13166",
    "title": "Self-supervised Video-centralised Transformer for Video Face Clustering",
    "abstract": "Self-supervised Video-centralised Transformer for Video Face Clustering",
    "descriptor": "",
    "authors": [
      "Yujiang Wang",
      "Mingzhi Dong",
      "Jie Shen",
      "Yiming Luo",
      "Yiming Lin",
      "Pingchuan Ma",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13166"
  },
  {
    "id": "arXiv:2203.15150",
    "title": "Tight bounds on the hardness of learning simple nonparametric mixtures",
    "abstract": "Tight bounds on the hardness of learning simple nonparametric mixtures",
    "descriptor": "",
    "authors": [
      "Bryon Aragam",
      "Wai Ming Tai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15150"
  },
  {
    "id": "arXiv:2203.15371",
    "title": "mc-BEiT: Multi-choice Discretization for Image BERT Pre-training",
    "abstract": "Comments: Accepted by ECCC 2022",
    "descriptor": "\nComments: Accepted by ECCC 2022\n",
    "authors": [
      "Xiaotong Li",
      "Yixiao Ge",
      "Kun Yi",
      "Zixuan Hu",
      "Ying Shan",
      "Ling-Yu Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15371"
  },
  {
    "id": "arXiv:2203.17218",
    "title": "Improved Relation Networks for End-to-End Speaker Verification and  Identification",
    "abstract": "Comments: Accepted to Interspeech 2022",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Ashutosh Chaubey",
      "Sparsh Sinha",
      "Susmita Ghose"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.17218"
  },
  {
    "id": "arXiv:2204.00492",
    "title": "Provable concept learning for interpretable predictions using  variational autoencoders",
    "abstract": "Provable concept learning for interpretable predictions using  variational autoencoders",
    "descriptor": "",
    "authors": [
      "Armeen Taeb",
      "Nicolo Ruggeri",
      "Carina Schnuck",
      "Fanny Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.00492"
  },
  {
    "id": "arXiv:2204.01341",
    "title": "An application of Pixel Interval Down-sampling (PID) for dense tiny  microorganism counting on environmental microorganism images",
    "abstract": "An application of Pixel Interval Down-sampling (PID) for dense tiny  microorganism counting on environmental microorganism images",
    "descriptor": "",
    "authors": [
      "Jiawei Zhang",
      "Xin Zhao",
      "Tao Jiang",
      "Md Mamunur Rahaman",
      "Yudong Yao",
      "Yu-Hao Lin",
      "Jinghua Zhang",
      "Ao Pan",
      "Marcin Grzegorzek",
      "Chen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.01341"
  },
  {
    "id": "arXiv:2204.02011",
    "title": "ELECRec: Training Sequential Recommenders as Discriminators",
    "abstract": "Comments: Accepted to SIGIR 2022",
    "descriptor": "\nComments: Accepted to SIGIR 2022\n",
    "authors": [
      "Yongjun Chen",
      "Jia Li",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02011"
  },
  {
    "id": "arXiv:2204.02445",
    "title": "CHORE: Contact, Human and Object REconstruction from a single RGB image",
    "abstract": "Comments: Accepted at ECCV 2022, Camera ready version",
    "descriptor": "\nComments: Accepted at ECCV 2022, Camera ready version\n",
    "authors": [
      "Xianghui Xie",
      "Bharat Lal Bhatnagar",
      "Gerard Pons-Moll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02445"
  },
  {
    "id": "arXiv:2204.04627",
    "title": "Stripformer: Strip Transformer for Fast Image Deblurring",
    "abstract": "Comments: ECCV 2022 Oral Presentation",
    "descriptor": "\nComments: ECCV 2022 Oral Presentation\n",
    "authors": [
      "Fu-Jen Tsai",
      "Yan-Tsung Peng",
      "Yen-Yu Lin",
      "Chung-Chi Tsai",
      "Chia-Wen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04627"
  },
  {
    "id": "arXiv:2204.04666",
    "title": "Energy-Sensitive Trajectory Design and Restoration Areas Allocation for  UAV-Enabled Grassland Restoration",
    "abstract": "Energy-Sensitive Trajectory Design and Restoration Areas Allocation for  UAV-Enabled Grassland Restoration",
    "descriptor": "",
    "authors": [
      "Dongbin Jiao",
      "Lingyu Wang",
      "Peng Yang",
      "Weibo Yang",
      "Yu Peng",
      "Zhanhuan Shang",
      "Fengyuan Ren"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.04666"
  },
  {
    "id": "arXiv:2204.06236",
    "title": "An improved numerical method for hyperbolic Lagrangian Coherent  Structures using Differential Algebra",
    "abstract": "Comments: Updates preprint to incorporate reviewer feedback. Main argument and results unchanged. Submitted to Journal of Computational Sciences. LaTeX, 45 pages",
    "descriptor": "\nComments: Updates preprint to incorporate reviewer feedback. Main argument and results unchanged. Submitted to Journal of Computational Sciences. LaTeX, 45 pages\n",
    "authors": [
      "Jack Tyler",
      "Alexander Wittig"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.06236"
  },
  {
    "id": "arXiv:2204.06909",
    "title": "On the Modeling and Analysis of Fast Conditional Handover for  5G-Advanced",
    "abstract": "Comments: 7 pages, 7 figures. Accepted for presentation at the 2022 Annual IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (IEEE PIMRC 2022)",
    "descriptor": "\nComments: 7 pages, 7 figures. Accepted for presentation at the 2022 Annual IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (IEEE PIMRC 2022)\n",
    "authors": [
      "Subhyal Bin Iqbal",
      "Ahmad Awada",
      "Umur Karabulut",
      "Ingo Viering",
      "Philipp Schulz",
      "Gerhard P. Fettweis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.06909"
  },
  {
    "id": "arXiv:2204.11424",
    "title": "It Takes Two Flints to Make a Fire: Multitask Learning of Neural  Relation and Explanation Classifiers",
    "abstract": "It Takes Two Flints to Make a Fire: Multitask Learning of Neural  Relation and Explanation Classifiers",
    "descriptor": "",
    "authors": [
      "Zheng Tang",
      "Mihai Surdeanu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.11424"
  },
  {
    "id": "arXiv:2204.13841",
    "title": "An Extensive Data Processing Pipeline for MIMIC-IV",
    "abstract": "An Extensive Data Processing Pipeline for MIMIC-IV",
    "descriptor": "",
    "authors": [
      "Mehak Gupta",
      "Brennan Gallamoza",
      "Nicolas Cutrona",
      "Pranjal Dhakal",
      "Raphael Poulain",
      "Rahmatollah Beheshti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.13841"
  },
  {
    "id": "arXiv:2204.14068",
    "title": "Controlled Generation of Unseen Faults for Partial and Open-Partial  Domain Adaptation",
    "abstract": "Controlled Generation of Unseen Faults for Partial and Open-Partial  Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Katharina Rombach",
      "Dr. Gabriel Michau",
      "Prof. Dr. Olga Fink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.14068"
  },
  {
    "id": "arXiv:2204.14109",
    "title": "TEMOS: Generating diverse human motions from textual descriptions",
    "abstract": "Comments: ECCV 2022 Camera ready",
    "descriptor": "\nComments: ECCV 2022 Camera ready\n",
    "authors": [
      "Mathis Petrovich",
      "Michael J. Black",
      "G\u00fcl Varol"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.14109"
  },
  {
    "id": "arXiv:2205.01414",
    "title": "Multimodal Detection of Unknown Objects on Roads for Autonomous Driving",
    "abstract": "Comments: Daniel Bogdoll, Enrico Eisen, Maximilian Nitsche, and Christin Scheib contributed equally. Accepted for publication at SMC 2022",
    "descriptor": "\nComments: Daniel Bogdoll, Enrico Eisen, Maximilian Nitsche, and Christin Scheib contributed equally. Accepted for publication at SMC 2022\n",
    "authors": [
      "Daniel Bogdoll",
      "Enrico Eisen",
      "Maximilian Nitsche",
      "Christin Scheib",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.01414"
  },
  {
    "id": "arXiv:2205.03436",
    "title": "EdgeViTs: Competing Light-weight CNNs on Mobile Devices with Vision  Transformers",
    "abstract": "Comments: Accepted in ECCV 2022",
    "descriptor": "\nComments: Accepted in ECCV 2022\n",
    "authors": [
      "Junting Pan",
      "Adrian Bulat",
      "Fuwen Tan",
      "Xiatian Zhu",
      "Lukasz Dudziak",
      "Hongsheng Li",
      "Georgios Tzimiropoulos",
      "Brais Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.03436"
  },
  {
    "id": "arXiv:2205.05511",
    "title": "Efficient Automated Deep Learning for Time Series Forecasting",
    "abstract": "Efficient Automated Deep Learning for Time Series Forecasting",
    "descriptor": "",
    "authors": [
      "Difan Deng",
      "Florian Karl",
      "Frank Hutter",
      "Bernd Bischl",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05511"
  },
  {
    "id": "arXiv:2205.13568",
    "title": "Learning Dialogue Representations from Consecutive Utterances",
    "abstract": "Comments: NAACL 2022 main conference",
    "descriptor": "\nComments: NAACL 2022 main conference\n",
    "authors": [
      "Zhihan Zhou",
      "Dejiao Zhang",
      "Wei Xiao",
      "Nicholas Dingwall",
      "Xiaofei Ma",
      "Andrew O. Arnold",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13568"
  },
  {
    "id": "arXiv:2205.15225",
    "title": "Few-shot Class-incremental Learning for 3D Point Cloud Objects",
    "abstract": "Few-shot Class-incremental Learning for 3D Point Cloud Objects",
    "descriptor": "",
    "authors": [
      "Townim Chowdhury",
      "Ali Cheraghian",
      "Sameera Ramasinghe",
      "Sahar Ahmadi",
      "Morteza Saberi",
      "Shafin Rahman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15225"
  },
  {
    "id": "arXiv:2206.01191",
    "title": "EfficientFormer: Vision Transformers at MobileNet Speed",
    "abstract": "EfficientFormer: Vision Transformers at MobileNet Speed",
    "descriptor": "",
    "authors": [
      "Yanyu Li",
      "Geng Yuan",
      "Yang Wen",
      "Eric Hu",
      "Georgios Evangelidis",
      "Sergey Tulyakov",
      "Yanzhi Wang",
      "Jian Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01191"
  },
  {
    "id": "arXiv:2206.01612",
    "title": "OmniXAI: A Library for Explainable AI",
    "abstract": "Comments: Wait for the Github release. The name of the library may need to be changed due to legal concerns",
    "descriptor": "\nComments: Wait for the Github release. The name of the library may need to be changed due to legal concerns\n",
    "authors": [
      "Wenzhuo Yang",
      "Hung Le",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01612"
  },
  {
    "id": "arXiv:2206.03256",
    "title": "Flexible Group Fairness Metrics for Survival Analysis",
    "abstract": "Comments: Accepted in DSHealth 2022 (Workshop on Applied Data Science for Healthcare)",
    "descriptor": "\nComments: Accepted in DSHealth 2022 (Workshop on Applied Data Science for Healthcare)\n",
    "authors": [
      "Raphael Sonabend",
      "Florian Pfisterer",
      "Alan Mishler",
      "Moritz Schauer",
      "Lukas Burk",
      "Sumantrak Mukherjee",
      "Sebastian Vollmer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.03256"
  },
  {
    "id": "arXiv:2206.06155",
    "title": "Concept Identification for Complex Engineering Datasets",
    "abstract": "Comments: 19 pages, 14 figures, accepted at Advanced Engineering Informatics",
    "descriptor": "\nComments: 19 pages, 14 figures, accepted at Advanced Engineering Informatics\n",
    "authors": [
      "Felix Lanfermann",
      "Sebastian Schmitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06155"
  },
  {
    "id": "arXiv:2206.07765",
    "title": "US News and Social Media Framing around Vaping",
    "abstract": "US News and Social Media Framing around Vaping",
    "descriptor": "",
    "authors": [
      "Keyu Chen",
      "Marzieh Babaeianjelodar",
      "Yiwen Shi",
      "Rohan Aanegola",
      "Lam Yin Cheung",
      "Preslav Ivanov Nakov",
      "Shweta Yadav",
      "Angus Bancroft",
      "Ashiqur R. KhudaBukhsh",
      "Munmun De Choudhury",
      "Frederick L. Altice",
      "Navin Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.07765"
  },
  {
    "id": "arXiv:2206.10594",
    "title": "How is Vaping Framed on Online Knowledge Dissemination Platforms?",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2206.07765, arXiv:2206.09024",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.07765, arXiv:2206.09024\n",
    "authors": [
      "Keyu Chen",
      "Yiwen Shi",
      "Jun Luo",
      "Joyce Jiang",
      "Shweta Yadav",
      "Munmun De Choudhury",
      "Ashiqur R. KhudaBukhsh",
      "Marzieh Babaeianjelodar",
      "Frederick Altice",
      "Navin Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.10594"
  },
  {
    "id": "arXiv:2206.10878",
    "title": "Feature Re-calibration based Multiple Instance Learning for Whole Slide  Image Classification",
    "abstract": "Comments: MICCAI 2022",
    "descriptor": "\nComments: MICCAI 2022\n",
    "authors": [
      "Philip Chikontwe",
      "Soo Jeong Nam",
      "Heounjeong Go",
      "Meejeong Kim",
      "Hyun Jung Sung",
      "Sang Hyun Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10878"
  },
  {
    "id": "arXiv:2206.10883",
    "title": "Multi-LexSum: Real-World Summaries of Civil Rights Lawsuits at Multiple  Granularities",
    "abstract": "Comments: 37 pages, 2 figures, 9 tables",
    "descriptor": "\nComments: 37 pages, 2 figures, 9 tables\n",
    "authors": [
      "Zejiang Shen",
      "Kyle Lo",
      "Lauren Yu",
      "Nathan Dahlberg",
      "Margo Schlanger",
      "Doug Downey"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.10883"
  },
  {
    "id": "arXiv:2206.12528",
    "title": "Predicting Stock Price Movement after Disclosure of Corporate Annual  Reports: A Case Study of 2021 China CSI 300 Stocks",
    "abstract": "Comments: My experimental conditions were not set correctly, and almost all the data in the table were filled in incorrectly. I had to repeat all the experiments and make updated descriptions, but the wrong data and descriptions caused confusion to others. I may need several months to redo the experiment, so I hope to withdraw my manuscript first",
    "descriptor": "\nComments: My experimental conditions were not set correctly, and almost all the data in the table were filled in incorrectly. I had to repeat all the experiments and make updated descriptions, but the wrong data and descriptions caused confusion to others. I may need several months to redo the experiment, so I hope to withdraw my manuscript first\n",
    "authors": [
      "Fengyu Han",
      "Yue Wang"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.12528"
  },
  {
    "id": "arXiv:2207.00885",
    "title": "Reinforcement Learning Approaches for the Orienteering Problem with  Stochastic and Dynamic Release Dates",
    "abstract": "Reinforcement Learning Approaches for the Orienteering Problem with  Stochastic and Dynamic Release Dates",
    "descriptor": "",
    "authors": [
      "Yuanyuan Li",
      "Claudia Archetti",
      "Ivana Ljubic"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.00885"
  },
  {
    "id": "arXiv:2207.01151",
    "title": "Modeling Randomly Walking Volatility with Chained Gamma Distributions",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Di Zhang",
      "Qiang Niu",
      "Youzhou Zhou"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Artificial Intelligence (cs.AI)",
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.01151"
  },
  {
    "id": "arXiv:2207.02721",
    "title": "Deep Learning approach for Classifying Trusses and Runners of  Strawberries",
    "abstract": "Deep Learning approach for Classifying Trusses and Runners of  Strawberries",
    "descriptor": "",
    "authors": [
      "Jakub Pomykala",
      "Francisco de Lemos",
      "Isibor Kennedy Ihianle",
      "David Ada Adama",
      "Pedro Machado"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.02721"
  },
  {
    "id": "arXiv:2207.03402",
    "title": "Scoped Capabilities for Polymorphic Effects",
    "abstract": "Comments: 39 pages",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Martin Odersky",
      "Aleksander Boruch-Gruszecki",
      "Edward Lee",
      "Jonathan Brachth\u00e4user",
      "Ond\u0159ej Lhot\u00e1k"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.03402"
  },
  {
    "id": "arXiv:2207.04589",
    "title": "Learned Video Compression via Heterogeneous Deformable Compensation  Network",
    "abstract": "Learned Video Compression via Heterogeneous Deformable Compensation  Network",
    "descriptor": "",
    "authors": [
      "Huairui Wang",
      "Zhenzhong Chen",
      "Chang Wen Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.04589"
  },
  {
    "id": "arXiv:2207.04789",
    "title": "bloomRF: On Performing Range-Queries in Bloom-Filters with  Piecewise-Monotone Hash Functions and Prefix Hashing",
    "abstract": "Comments: Extended version. Original accepted at EDBT 2023",
    "descriptor": "\nComments: Extended version. Original accepted at EDBT 2023\n",
    "authors": [
      "Bernhard M\u00f6\u00dfner",
      "Christian Riegger",
      "Arthur Bernhardt",
      "Ilia Petrov"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.04789"
  },
  {
    "id": "arXiv:2207.04873",
    "title": "Hierarchical Average Precision Training for Pertinent Image Retrieval",
    "abstract": "Hierarchical Average Precision Training for Pertinent Image Retrieval",
    "descriptor": "",
    "authors": [
      "Elias Ramzi",
      "Nicolas Audebert",
      "Nicolas Thome",
      "Cl\u00e9ment Rambour",
      "Xavier Bitot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.04873"
  },
  {
    "id": "arXiv:2207.06067",
    "title": "Pyramid Transformer for Traffic Sign Detection",
    "abstract": "Pyramid Transformer for Traffic Sign Detection",
    "descriptor": "",
    "authors": [
      "Omid Nejati Manzari",
      "Amin Boudesh",
      "Shahriar B. Shokouhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06067"
  },
  {
    "id": "arXiv:2207.06202",
    "title": "Adversarially-Aware Robust Object Detector",
    "abstract": "Comments: ECCV2022 oral paper",
    "descriptor": "\nComments: ECCV2022 oral paper\n",
    "authors": [
      "Ziyi Dong",
      "Pengxu Wei",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06202"
  },
  {
    "id": "arXiv:2207.06211",
    "title": "Sample-dependent Adaptive Temperature Scaling for Improved Calibration",
    "abstract": "Sample-dependent Adaptive Temperature Scaling for Improved Calibration",
    "descriptor": "",
    "authors": [
      "Tom Joy",
      "Francesco Pinto",
      "Ser-Nam Lim",
      "Philip H. S. Torr",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06211"
  },
  {
    "id": "arXiv:2207.06706",
    "title": "SHREC 2022 Track on Online Detection of Heterogeneous Gestures",
    "abstract": "Comments: Accepted on Computer & Graphics journal",
    "descriptor": "\nComments: Accepted on Computer & Graphics journal\n",
    "authors": [
      "Ariel Caputo",
      "Marco Emporio",
      "Andrea Giachetti",
      "Marco Cristani",
      "Guido Borghi",
      "Andrea D'Eusanio",
      "Minh-Quan Le",
      "Hai-Dang Nguyen",
      "Minh-Triet Tran",
      "F. Ambellan",
      "M. Hanik",
      "E. Nava-Yazdani",
      "C. von Tycowicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06706"
  },
  {
    "id": "arXiv:2207.08046",
    "title": "MDM:Visual Explanations for Neural Networks via Multiple Dynamic Mask",
    "abstract": "MDM:Visual Explanations for Neural Networks via Multiple Dynamic Mask",
    "descriptor": "",
    "authors": [
      "Yitao Peng",
      "Longzhen Yang",
      "Yihang Liu",
      "Lianghua He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08046"
  },
  {
    "id": "arXiv:2207.08531",
    "title": "DID-M3D: Decoupling Instance Depth for Monocular 3D Object Detection",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Liang Peng",
      "Xiaopei Wu",
      "Zheng Yang",
      "Haifeng Liu",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08531"
  },
  {
    "id": "arXiv:2207.08560",
    "title": "Latency-Aware Collaborative Perception",
    "abstract": "Comments: 14 pages, 11 figures, Accepted by European conference on computer vision, 2022",
    "descriptor": "\nComments: 14 pages, 11 figures, Accepted by European conference on computer vision, 2022\n",
    "authors": [
      "Zixing Lei",
      "Shunli Ren",
      "Yue Hu",
      "Wenjun Zhang",
      "Siheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.08560"
  },
  {
    "id": "arXiv:2207.09298",
    "title": "Magpie: Automatically Tuning Static Parameters for Distributed File  Systems using Deep Reinforcement Learning",
    "abstract": "Comments: Accepted at The IEEE International Conference on Cloud Engineering (IC2E) conference 2022",
    "descriptor": "\nComments: Accepted at The IEEE International Conference on Cloud Engineering (IC2E) conference 2022\n",
    "authors": [
      "Houkun Zhu",
      "Dominik Scheinert",
      "Lauritz Thamsen",
      "Kordian Gontarska",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09298"
  },
  {
    "id": "arXiv:2207.09603",
    "title": "AiATrack: Attention in Attention for Transformer Visual Tracking",
    "abstract": "Comments: Accepted by ECCV 2022. Code and models are publicly available at this https URL",
    "descriptor": "\nComments: Accepted by ECCV 2022. Code and models are publicly available at this https URL\n",
    "authors": [
      "Shenyuan Gao",
      "Chunluan Zhou",
      "Chao Ma",
      "Xinggang Wang",
      "Junsong Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09603"
  },
  {
    "id": "arXiv:2207.09675",
    "title": "ERA: Expert Retrieval and Assembly for Early Action Prediction",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Lin Geng Foo",
      "Tianjiao Li",
      "Hossein Rahmani",
      "Qiuhong Ke",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09675"
  },
  {
    "id": "arXiv:2207.09777",
    "title": "AU-Supervised Convolutional Vision Transformers for Synthetic Facial  Expression Recognition",
    "abstract": "AU-Supervised Convolutional Vision Transformers for Synthetic Facial  Expression Recognition",
    "descriptor": "",
    "authors": [
      "Shuyi Mao",
      "Xinpeng Li",
      "Junyao Chen",
      "Xiaojiang Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09777"
  },
  {
    "id": "arXiv:2207.09933",
    "title": "Robust Landmark-based Stent Tracking in X-ray Fluoroscopy",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Luojie Huang",
      "Yikang Liu",
      "Li Chen",
      "Eric Z. Chen",
      "Xiao Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09933"
  },
  {
    "id": "arXiv:2207.10106",
    "title": "World Robot Challenge 2020 -- Partner Robot: A Data-Driven Approach for  Room Tidying with Mobile Manipulator",
    "abstract": "World Robot Challenge 2020 -- Partner Robot: A Data-Driven Approach for  Room Tidying with Mobile Manipulator",
    "descriptor": "",
    "authors": [
      "Tatsuya Matsushima",
      "Yuki Noguchi",
      "Jumpei Arima",
      "Toshiki Aoki",
      "Yuki Okita",
      "Yuya Ikeda",
      "Koki Ishimoto",
      "Shohei Taniguchi",
      "Yuki Yamashita",
      "Shoichi Seto",
      "Shixiang Shane Gu",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10106"
  },
  {
    "id": "arXiv:2207.10120",
    "title": "BRACE: The Breakdancing Competition Dataset for Dance Motion Synthesis",
    "abstract": "Comments: ECCV 2022. Dataset available at this https URL",
    "descriptor": "\nComments: ECCV 2022. Dataset available at this https URL\n",
    "authors": [
      "Davide Moltisanti",
      "Jinyi Wu",
      "Bo Dai",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10120"
  },
  {
    "id": "arXiv:2207.10157",
    "title": "Visual Knowledge Tracing",
    "abstract": "Comments: 14 pages, 4 figures, 14 supplemental pages, 11 supplemental figures, accepted to European Conference on Computer Vision (ECCV) 2022",
    "descriptor": "\nComments: 14 pages, 4 figures, 14 supplemental pages, 11 supplemental figures, accepted to European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Neehar Kondapaneni",
      "Pietro Perona",
      "Oisin Mac Aodha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.10157"
  },
  {
    "id": "arXiv:2207.10172",
    "title": "Video Anomaly Detection by Solving Decoupled Spatio-Temporal Jigsaw  Puzzles",
    "abstract": "Comments: Accepted by ECCV'2022; Code is available at this https URL",
    "descriptor": "\nComments: Accepted by ECCV'2022; Code is available at this https URL\n",
    "authors": [
      "Guodong Wang",
      "Yunhong Wang",
      "Jie Qin",
      "Dongming Zhang",
      "Xiuguo Bao",
      "Di Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10172"
  },
  {
    "id": "arXiv:2207.10226",
    "title": "Improving Privacy-Preserving Vertical Federated Learning by Efficient  Communication with ADMM",
    "abstract": "Improving Privacy-Preserving Vertical Federated Learning by Efficient  Communication with ADMM",
    "descriptor": "",
    "authors": [
      "Chulin Xie",
      "Pin-Yu Chen",
      "Ce Zhang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10226"
  },
  {
    "id": "arXiv:2207.10241",
    "title": "Unsupervised Legendre-Galerkin Neural Network for Stiff Partial  Differential Equations",
    "abstract": "Comments: 29 pages, 8 figures",
    "descriptor": "\nComments: 29 pages, 8 figures\n",
    "authors": [
      "Junho Choi",
      "Namjung Kim",
      "Youngjoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10241"
  },
  {
    "id": "arXiv:2207.10276",
    "title": "ProMix: Combating Label Noise via Maximizing Clean Sample Utility",
    "abstract": "Comments: Winner of the 1st Learning and Mining with Noisy Labels Challenge in IJCAI-ECAI 2022 (an informal technical report)",
    "descriptor": "\nComments: Winner of the 1st Learning and Mining with Noisy Labels Challenge in IJCAI-ECAI 2022 (an informal technical report)\n",
    "authors": [
      "Haobo Wang",
      "Ruixuan Xiao",
      "Yiwen Dong",
      "Lei Feng",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10276"
  },
  {
    "id": "arXiv:2207.10456",
    "title": "Semantic-Aware Fine-Grained Correspondence",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Yingdong Hu",
      "Renhao Wang",
      "Kaifeng Zhang",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10456"
  },
  {
    "id": "arXiv:2207.10457",
    "title": "A Survey of Robotic Harvesting Systems and Enabling Technologies",
    "abstract": "Comments: 40 pages, 3 figures. This paper is a pre-print version under review. Added comment \"This paper is a pre-print version under review\" at the top of the title page",
    "descriptor": "\nComments: 40 pages, 3 figures. This paper is a pre-print version under review. Added comment \"This paper is a pre-print version under review\" at the top of the title page\n",
    "authors": [
      "Leonidas Droukas",
      "Zoe Doulgeri",
      "Nikolaos L. Tsakiridis",
      "Dimitra Triantafyllou",
      "Ioannis Kleitsiotis",
      "Ioannis Mariolis",
      "Dimitrios Giakoumis",
      "Dimitrios Tzovaras",
      "Dimitrios Kateris",
      "Dionysis Bochtis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10457"
  },
  {
    "id": "arXiv:2207.10478",
    "title": "Room geometry blind inference based on the localization of real sound  source and first order reflections",
    "abstract": "Room geometry blind inference based on the localization of real sound  source and first order reflections",
    "descriptor": "",
    "authors": [
      "Shan Gao",
      "Xihong Wu",
      "Tianshu Qu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10478"
  },
  {
    "id": "arXiv:2207.10576",
    "title": "Democratizing Ethical Assessment of Natural Language Generation Models",
    "abstract": "Comments: 28th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2022), August 14-18, 2022, Washington, DC",
    "descriptor": "\nComments: 28th SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2022), August 14-18, 2022, Washington, DC\n",
    "authors": [
      "Amin Rasekh",
      "Ian Eisenberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10576"
  },
  {
    "id": "arXiv:2207.10643",
    "title": "STOP: A dataset for Spoken Task Oriented Semantic Parsing",
    "abstract": "STOP: A dataset for Spoken Task Oriented Semantic Parsing",
    "descriptor": "",
    "authors": [
      "Paden Tomasello",
      "Akshat Shrivastava",
      "Daniel Lazar",
      "Po-Chun Hsu",
      "Duc Le",
      "Adithya Sagar",
      "Ali Elkahky",
      "Jade Copet",
      "Wei-Ning Hsu",
      "Yossef Mordechay",
      "Robin Algayres",
      "Tu Ahn Nguyen",
      "Emmanuel Dupoux",
      "Luke Zettlemoyer",
      "Abdelrahman Mohamed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10643"
  }
]
[
  {
    "id": "arXiv:2207.09453",
    "title": "e3nn: Euclidean Neural Networks",
    "abstract": "We present e3nn, a generalized framework for creating E(3) equivariant\ntrainable functions, also known as Euclidean neural networks. e3nn naturally\noperates on geometry and geometric tensors that describe systems in 3D and\ntransform predictably under a change of coordinate system. The core of e3nn are\nequivariant operations such as the TensorProduct class or the spherical\nharmonics functions that can be composed to create more complex modules such as\nconvolutions and attention mechanisms. These core operations of e3nn can be\nused to efficiently articulate Tensor Field Networks, 3D Steerable CNNs,\nClebsch-Gordan Networks, SE(3) Transformers and other E(3) equivariant\nnetworks.",
    "descriptor": "\nComments: draft\n",
    "authors": [
      "Mario Geiger",
      "Tess Smidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.09453"
  },
  {
    "id": "arXiv:2207.09455",
    "title": "To update or not to update? Neurons at equilibrium in deep models",
    "abstract": "Recent advances in deep learning optimization showed that, with some\na-posteriori information on fully-trained models, it is possible to match the\nsame performance by simply training a subset of their parameters. Such a\ndiscovery has a broad impact from theory to applications, driving the research\ntowards methods to identify the minimum subset of parameters to train without\nlook-ahead information exploitation. However, the methods proposed do not match\nthe state-of-the-art performance, and rely on unstructured sparsely connected\nmodels. In this work we shift our focus from the single parameters to the\nbehavior of the whole neuron, exploiting the concept of neuronal equilibrium\n(NEq). When a neuron is in a configuration at equilibrium (meaning that it has\nlearned a specific input-output relationship), we can halt its update; on the\ncontrary, when a neuron is at non-equilibrium, we let its state evolve towards\nan equilibrium state, updating its parameters. The proposed approach has been\ntested on different state-of-the-art learning strategies and tasks, validating\nNEq and observing that the neuronal equilibrium depends on the specific\nlearning setup.",
    "descriptor": "",
    "authors": [
      "Andrea Bragagnolo",
      "Enzo Tartaglione",
      "Marco Grangetto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09455"
  },
  {
    "id": "arXiv:2207.09457",
    "title": "A Deep Learning Framework for Wind Turbine Repair Action Prediction  Using Alarm Sequences and Long Short Term Memory Algorithms",
    "abstract": "With an increasing emphasis on driving down the costs of Operations and\nMaintenance (O$\\&$M) in the Offshore Wind (OSW) sector, comes the requirement\nto explore new methodology and applications of Deep Learning (DL) to the\ndomain. Condition-based monitoring (CBM) has been at the forefront of recent\nresearch developing alarm-based systems and data-driven decision making. This\npaper provides a brief insight into the research being conducted in this area,\nwith a specific focus on alarm sequence modelling and the associated challenges\nfaced in its implementation. The paper proposes a novel idea to predict a set\nof relevant repair actions from an input sequence of alarm sequences, comparing\nLong Short-term Memory (LSTM) and Bidirectional LSTM (biLSTM) models. Achieving\ntraining accuracy results of up to 80.23$\\%$, and test accuracy results of up\nto 76.01$\\%$ with biLSTM gives a strong indication to the potential benefits of\nthe proposed approach that can be furthered in future research. The paper\nintroduces a framework that integrates the proposed approach into O$\\&$M\nprocedures and discusses the potential benefits which include the reduction of\na confusing plethora of alarms, as well as unnecessary vessel transfers to the\nturbines for fault diagnosis and correction.",
    "descriptor": "",
    "authors": [
      "Connor Walker",
      "Callum Rothon",
      "Koorosh Aslansefat",
      "Yiannis Papadopoulos",
      "Nina Dethlefs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09457"
  },
  {
    "id": "arXiv:2207.09459",
    "title": "Contaminant source identification in groundwater by means of artificial  neural network",
    "abstract": "In a desired environmental protection system, groundwater may not be\nexcluded. In addition to the problem of over-exploitation, in total\ndisagreement with the concept of sustainable development, another not\nnegligible issue concerns the groundwater contamination. Mainly, this aspect is\ndue to intensive agricultural activities or industrialized areas. In\nliterature, several papers have dealt with transport problem, especially for\ninverse problems in which the release history or the source location are\nidentified. The innovative aim of the paper is to develop a data-driven model\nthat is able to analyze multiple scenarios, even strongly non-linear, in order\nto solve forward and inverse transport problems, preserving the reliability of\nthe results and reducing the uncertainty. Furthermore, this tool has the\ncharacteristic of providing extremely fast responses, essential to identify\nremediation strategies immediately. The advantages produced by the model were\ncompared with literature studies. In this regard, a feedforward artificial\nneural network, which has been trained to handle different cases, represents\nthe data-driven model. Firstly, to identify the concentration of the pollutant\nat specific observation points in the study area (forward problem); secondly,\nto deal with inverse problems identifying the release history at known source\nlocation; then, in case of one contaminant source, identifying the release\nhistory and, at the same time, the location of the source in a specific\nsub-domain of the investigated area. At last, the observation error is\ninvestigated and estimated. The results are satisfactorily achieved,\nhighlighting the capability of the ANN to deal with multiple scenarios by\napproximating nonlinear functions without the physical point of view that\ndescribes the phenomenon, providing reliable results, with very low\ncomputational burden and uncertainty.",
    "descriptor": "\nComments: Published on Journal of Hydrology\n",
    "authors": [
      "Daniele Secci",
      "Laura Molino",
      "Andrea Zanini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.09459"
  },
  {
    "id": "arXiv:2207.09460",
    "title": "Money and Trust in Metaverses, Bitcoin and Stablecoins in global social  XR",
    "abstract": "We present a state of the art and positioning book, about Web3, Bitcoin, and\n`Metaverse'; describing the intersections and synergies. A high level overview\nof Web3 technologies leads to a description of blockchain, and the Bitcoin\nnetwork is specifically selected for detailed examination. Suitable components\nof the extended Bitcoin ecosystem are described in more depth. Other mechanisms\nfor native digital value transfer are described, with a focus on `money'.\nMetaverse technology is over-viewed, primarily from the perspective of Bitcoin\nand extended reality.\\par Bitcoin is selected as the best contender for value\ntransfer in metaverses because of it's free and open source nature, and network\neffect. Challenges and risks of this approach are identified. A cloud\ndeployable virtual machine based technology stack deployment guide with a focus\non cybersecurity best practice can be downloaded from GitHub to experiment with\nthe technologies. This deployable lab is designed to inform development of\nsecure value transaction, for small and medium sized companies.",
    "descriptor": "",
    "authors": [
      "John Joseph O'Hare",
      "Allen Fairchild",
      "Umran Ali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.09460"
  },
  {
    "id": "arXiv:2207.09486",
    "title": "Formalising the Krull Topology in Lean",
    "abstract": "The Galois group of an infinite Galois extension has a natural topology,\ncalled the Krull topology, which has the important property of being profinite.\nIt is impossible to talk about Galois representations, and hence the Langlands\nProgram, without first defining the Krull topology. We explain our\nformalisation of this topology, and our proof that it is profinite, in the Lean\n3 theorem prover.",
    "descriptor": "",
    "authors": [
      "Sebastian Monnet"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2207.09486"
  },
  {
    "id": "arXiv:2207.09497",
    "title": "Economics and Optimal Investment Policies of Attackers and Defenders in  Cybersecurity",
    "abstract": "In our time cybersecurity has grown to be a topic of massive proportion at\nthe national and enterprise levels. Our thesis is that the economic perspective\nand investment decision-making are vital factors in determining the outcome of\nthe struggle. To build our economic framework, we borrow from the pioneering\nwork of Gordon and Loeb in which the Defender optimally trades-off investments\nfor lower likelihood of its system breach. Our two-sided model additionally has\nan Attacker, assumed to be rational and also guided by economic considerations\nin its decision-making, to which the Defender responds. Our model is a\nsimplified adaptation of a model proposed during the Cold War for weapons\ndeployment in the US. Our model may also be viewed as a Stackelberg game and,\nfrom an analytic perspective, as a Max-Min problem, the analysis of which is\nknown to have to contend with discontinuous behavior. The complexity of our\nsimple model is rooted in its inherent nonlinearity and, more consequentially,\nnon-convexity of the objective function in the optimization. The possibilities\nof the Attacker's actions add substantially to the risk to the Defender, and\nthe Defender's rational, risk-neutral optimal investments in general\nsubstantially exceed the optimal investments predicted by the one-sided\nGordon-Loeb model. We obtain a succinct set of three decision types that\ncategorize all of the Defender's optimal investment decisions. Also, the\nDefender's optimal decisions exhibit discontinuous behavior as the initial\nvulnerability of its system is varied. The analysis is supplemented by\nextensive numerical illustrations. The results from our model open several\nmajor avenues for future work.",
    "descriptor": "\nComments: 27 pages, 13 figures\n",
    "authors": [
      "Austin Ebel",
      "Debasis Mitra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2207.09497"
  },
  {
    "id": "arXiv:2207.09499",
    "title": "Deep Analysis of Visual Product Reviews",
    "abstract": "With the proliferation of the e-commerce industry, analyzing customer\nfeedback is becoming indispensable to a service provider. In recent days, it\ncan be noticed that customers upload the purchased product images with their\nreview scores. In this paper, we undertake the task of analyzing such visual\nreviews, which is very new of its kind. In the past, the researchers worked on\nanalyzing language feedback, but here we do not take any assistance from\nlinguistic reviews that may be absent, since a recent trend can be observed\nwhere customers prefer to quickly upload the visual feedback instead of typing\nlanguage feedback. We propose a hierarchical architecture, where the\nhigher-level model engages in product categorization, and the lower-level model\npays attention to predicting the review score from a customer-provided product\nimage. We generated a database by procuring real visual product reviews, which\nwas quite challenging. Our architecture obtained some promising results by\nperforming extensive experiments on the employed database. The proposed\nhierarchical architecture attained a 57.48% performance improvement over the\nsingle-level best comparable architecture.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Chandranath Adak",
      "Soumi Chattopadhyay",
      "Muhammad Saqib"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09499"
  },
  {
    "id": "arXiv:2207.09503",
    "title": "A Comparison of HDF5, Zarr, and netCDF4 in Performing Common I/O  Operations",
    "abstract": "Scientific data is often stored in files because of the simplicity they\nprovide in managing, transferring, and sharing data. These files are typically\nstructured in a specific arrangement and contain metadata to understand the\nstructure the data is stored in. There are numerous file formats in use in\nvarious scientific domains that provide abstractions for storing and retrieving\ndata. With the abundance of file formats aiming to store large amounts of\nscientific data quickly and easily, a question that arises is, \"Which\nscientific file format is best suited for a general use case?\" In this study,\nwe compiled a set of benchmarks for common file operations, i.e., create, open,\nread, write, and close, and used the results of these benchmarks to compare\nthree popular formats: HDF5, netCDF4, and Zarr.",
    "descriptor": "\nComments: 5 pages, 12 figures\n",
    "authors": [
      "Sriniket Ambatipudi",
      "Suren Byna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.09503"
  },
  {
    "id": "arXiv:2207.09504",
    "title": "Invariant Feature Learning for Generalized Long-Tailed Classification",
    "abstract": "Existing long-tailed classification (LT) methods only focus on tackling the\nclass-wise imbalance that head classes have more samples than tail classes, but\noverlook the attribute-wise imbalance. In fact, even if the class is balanced,\nsamples within each class may still be long-tailed due to the varying\nattributes. Note that the latter is fundamentally more ubiquitous and\nchallenging than the former because attributes are not just implicit for most\ndatasets, but also combinatorially complex, thus prohibitively expensive to be\nbalanced. Therefore, we introduce a novel research problem: Generalized\nLong-Tailed classification (GLT), to jointly consider both kinds of imbalances.\nBy \"generalized\", we mean that a GLT method should naturally solve the\ntraditional LT, but not vice versa. Not surprisingly, we find that most\nclass-wise LT methods degenerate in our proposed two benchmarks: ImageNet-GLT\nand MSCOCO-GLT. We argue that it is because they over-emphasize the adjustment\nof class distribution while neglecting to learn attribute-invariant features.\nTo this end, we propose an Invariant Feature Learning (IFL) method as the first\nstrong baseline for GLT. IFL first discovers environments with divergent\nintra-class distributions from the imperfect predictions and then learns\ninvariant features across them. Promisingly, as an improved feature backbone,\nIFL boosts all the LT line-up: one/two-stage re-balance, augmentation, and\nensemble. Codes and benchmarks are available on Github:\nhttps://github.com/KaihuaTang/Generalized-Long-Tailed-Benchmarks.pytorch",
    "descriptor": "\nComments: Accepted to ECCV 2022. Codes and benchmarks are available on Github: this https URL\n",
    "authors": [
      "Kaihua Tang",
      "Mingyuan Tao",
      "Jiaxin Qi",
      "Zhenguang Liu",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09504"
  },
  {
    "id": "arXiv:2207.09505",
    "title": "An Efficient Method for Face Quality Assessment on the Edge",
    "abstract": "Face recognition applications in practice are composed of two main steps:\nface detection and feature extraction. In a sole vision-based solution, the\nfirst step generates multiple detection for a single identity by ingesting a\ncamera stream. A practical approach on edge devices should prioritize these\ndetection of identities according to their conformity to recognition. In this\nperspective, we propose a face quality score regression by just appending a\nsingle layer to a face landmark detection network. With almost no additional\ncost, face quality scores are obtained by training this single layer to regress\nrecognition scores with surveillance like augmentations. We implemented the\nproposed approach on edge GPUs with all face detection pipeline steps,\nincluding detection, tracking, and alignment. Comprehensive experiments show\nthe proposed approach's efficiency through comparison with SOTA face quality\nregression models on different data sets and real-life scenarios.",
    "descriptor": "\nComments: Accepted to ECCV2020-Embedded Vision Workshop\n",
    "authors": [
      "Sefa Burak Okcu",
      "Burak O\u011fuz \u00d6zkalayc\u0131",
      "Cevahir \u00c7\u0131\u011fla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09505"
  },
  {
    "id": "arXiv:2207.09506",
    "title": "Thoughts on child safety on commodity platforms",
    "abstract": "The explosion of global social media and online communication platforms has\nchanged how we interact with each other and as a society, bringing with it new\nsecurity and privacy challenges. Like all technologies, these platforms can be\nabused and they are routinely used to attempt to cause harm at scale. One of\nthe most significant offence types that is enabled by these platforms is child\nsexual abuse - both scaling existing abuse and enabling entirely new types of\nonline-only abuse where the impacts on the victim are equally catastrophic.\nMany platforms invest significantly in combating this crime, referring\nconfirmed evidence of illegality to law enforcement. The introduction of\nend-to-end encryption and similar technologies breaks many of the mitigations\nin place today and this has led to a debate around the apparent dichotomy of\ngood child safety and good general user privacy and security. This debate has\nconcentrated on the problem of detecting offenders sharing known abuse imagery\nusing a technique known as client side scanning. We will show that the real\nproblem of online child sexual abuse is much more complex than offender image\nsharing, providing a new set of 'harm archetypes' to better group harms into\ncategories that have similar technical characteristics and, as far as we are\nable, bring more clarity to the processes currently used by platforms and law\nenforcement in relation to child sexual abuse content and the real world\nimpacts. We explore, at a high level, a variety of techniques that could be\nused as part of any potential solution and examine the benefits and disbenefits\nthat may accrue in various use cases, and use a hypothetical service as an\nexample of how various techniques could be brought together to provide both\nuser privacy and security, while protecting child safety and enabling law\nenforcement action.",
    "descriptor": "",
    "authors": [
      "Ian Levy",
      "Crispin Robinson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.09506"
  },
  {
    "id": "arXiv:2207.09507",
    "title": "SeasoNet: A Seasonal Scene Classification, segmentation and Retrieval  dataset for satellite Imagery over Germany",
    "abstract": "This work presents SeasoNet, a new large-scale multi-label land cover and\nland use scene understanding dataset. It includes $1\\,759\\,830$ images from\nSentinel-2 tiles, with 12 spectral bands and patch sizes of up to $ 120 \\\n\\mathrm{px} \\times 120 \\ \\mathrm{px}$. Each image is annotated with large scale\npixel level labels from the German land cover model LBM-DE2018 with land cover\nclasses based on the CORINE Land Cover database (CLC) 2018 and a five times\nsmaller minimum mapping unit (MMU) than the original CLC maps. We provide pixel\nsynchronous examples from all four seasons, plus an additional snowy set. These\nproperties make SeasoNet the currently most versatile and biggest remote\nsensing scene understanding dataset with possible applications ranging from\nscene classification over land cover mapping to content-based cross season\nimage retrieval and self-supervised feature learning. We provide baseline\nresults by evaluating state-of-the-art deep networks on the new dataset in\nscene classification and semantic segmentation scenarios.",
    "descriptor": "\nComments: Accepted at IEEE International Geoscience and Remote Sensing Symposium (IGARSS) 2022\n",
    "authors": [
      "Dominik Ko\u00dfmann",
      "Viktor Brack",
      "Thorsten Wilhelm"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09507"
  },
  {
    "id": "arXiv:2207.09508",
    "title": "HSE-NN Team at the 4th ABAW Competition: Multi-task Emotion Recognition  and Learning from Synthetic Images",
    "abstract": "In this paper, we present the results of the HSE-NN team in the 4th\ncompetition on Affective Behavior Analysis in-the-wild (ABAW). The novel\nmulti-task EfficientNet model is trained for simultaneous recognition of facial\nexpressions and prediction of valence and arousal on static photos. The\nresulting MT-EmotiEffNet extracts visual features that are fed into simple\nfeed-forward neural networks in the multi-task learning challenge. We obtain\nperformance measure 1.3 on the validation set, which is significantly greater\nwhen compared to either performance of baseline (0.3) or existing models that\nare trained only on the s-Aff-Wild2 database. In the learning from synthetic\ndata challenge, the quality of the original synthetic training set is increased\nby using the super-resolution techniques, such as Real-ESRGAN. Next, the\nMT-EmotiEffNet is fine-tuned on the new training set. The final prediction is a\nsimple blending ensemble of pre-trained and fine-tuned MT-EmotiEffNets. Our\naverage validation F1 score is 18% greater than the baseline convolutional\nneural network.",
    "descriptor": "\nComments: 13 pages, 3 figures, 8 tables\n",
    "authors": [
      "Andrey V. Savchenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09508"
  },
  {
    "id": "arXiv:2207.09509",
    "title": "TestSelector: Automatic Test Suite Selection for Student Projects --  Extended Version",
    "abstract": "Computer Science course instructors routinely have to create comprehensive\ntest suites to assess programming assignments. The creation of such test suites\nis typically not trivial as it involves selecting a limited number of tests\nfrom a set of (semi-)randomly generated ones. Manual strategies for test\nselection do not scale when considering large testing inputs needed, for\ninstance, for the assessment of algorithms exercises. To facilitate this\nprocess, we present TestSelector, a new framework for automatic selection of\noptimal test suites for student projects. The key advantage of TestSelector\nover existing approaches is that it is easily extensible with arbitrarily\ncomplex code coverage measures, not requiring these measures to be encoded into\nthe logic of an exact constraint solver. We demonstrate the flexibility of\nTestSelector by extending it with support for a range of classical code\ncoverage measures and using it to select test suites for a number of real-world\nalgorithms projects, further showing that the selected test suites outperform\nrandomly selected ones in finding bugs in students' code.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Filipe Marques",
      "Ant\u00f3nio Morgado",
      "Jos\u00e9 Fragoso Santos",
      "Mikol\u00e1\u0161 Janota"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.09509"
  },
  {
    "id": "arXiv:2207.09510",
    "title": "Contributions of Shape, Texture, and Color in Visual Recognition",
    "abstract": "We investigate the contributions of three important features of the human\nvisual system (HVS)~ -- ~shape, texture, and color ~ -- ~to object\nclassification. We build a humanoid vision engine (HVE) that explicitly and\nseparately computes shape, texture, and color features from images. The\nresulting feature vectors are then concatenated to support the final\nclassification. We show that HVE can summarize and rank-order the contributions\nof the three features to object recognition. We use human experiments to\nconfirm that both HVE and humans predominantly use some specific features to\nsupport the classification of specific classes (e.g., texture is the dominant\nfeature to distinguish a zebra from other quadrupeds, both for humans and HVE).\nWith the help of HVE, given any environment (dataset), we can summarize the\nmost important features for the whole task (task-specific; e.g., color is the\nmost important feature overall for classification with the CUB dataset), and\nfor each class (class-specific; e.g., shape is the most important feature to\nrecognize boats in the iLab-20M dataset). To demonstrate more usefulness of\nHVE, we use it to simulate the open-world zero-shot learning ability of humans\nwith no attribute labeling. Finally, we show that HVE can also simulate human\nimagination ability with the combination of different features. We will\nopen-source the HVE engine and corresponding datasets.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Yunhao Ge",
      "Yao Xiao",
      "Zhi Xu",
      "Xingrui Wang",
      "Laurent Itti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09510"
  },
  {
    "id": "arXiv:2207.09511",
    "title": "Approximation Power of Deep Neural Networks: an explanatory mathematical  survey",
    "abstract": "The goal of this survey is to present an explanatory review of the\napproximation properties of deep neural networks. Specifically, we aim at\nunderstanding how and why deep neural networks outperform other classical\nlinear and nonlinear approximation methods. This survey consists of three\nchapters. In Chapter 1 we review the key ideas and concepts underlying deep\nnetworks and their compositional nonlinear structure. We formalize the neural\nnetwork problem by formulating it as an optimization problem when solving\nregression and classification problems. We briefly discuss the stochastic\ngradient descent algorithm and the back-propagation formulas used in solving\nthe optimization problem and address a few issues related to the performance of\nneural networks, including the choice of activation functions, cost functions,\noverfitting issues, and regularization. In Chapter 2 we shift our focus to the\napproximation theory of neural networks. We start with an introduction to the\nconcept of density in polynomial approximation and in particular study the\nStone-Weierstrass theorem for real-valued continuous functions. Then, within\nthe framework of linear approximation, we review a few classical results on the\ndensity and convergence rate of feedforward networks, followed by more recent\ndevelopments on the complexity of deep networks in approximating Sobolev\nfunctions. In Chapter 3, utilizing nonlinear approximation theory, we further\nelaborate on the power of depth and approximation superiority of deep ReLU\nnetworks over other classical methods of nonlinear approximation.",
    "descriptor": "\nComments: 82 pages, 31 figures\n",
    "authors": [
      "Mohammad Motamed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.09511"
  },
  {
    "id": "arXiv:2207.09519",
    "title": "Tip-Adapter: Training-free Adaption of CLIP for Few-shot Classification",
    "abstract": "Contrastive Vision-Language Pre-training, known as CLIP, has provided a new\nparadigm for learning visual representations using large-scale image-text\npairs. It shows impressive performance on downstream tasks by zero-shot\nknowledge transfer. To further enhance CLIP's adaption capability, existing\nmethods proposed to fine-tune additional learnable modules, which significantly\nimproves the few-shot performance but introduces extra training time and\ncomputational resources. In this paper, we propose a training-free adaption\nmethod for CLIP to conduct few-shot classification, termed as Tip-Adapter,\nwhich not only inherits the training-free advantage of zero-shot CLIP but also\nperforms comparably to those training-required approaches. Tip-Adapter\nconstructs the adapter via a key-value cache model from the few-shot training\nset, and updates the prior knowledge encoded in CLIP by feature retrieval. On\ntop of that, the performance of Tip-Adapter can be further boosted to be\nstate-of-the-art on ImageNet by fine-tuning the cache model for 10$\\times$\nfewer epochs than existing methods, which is both effective and efficient. We\nconduct extensive experiments of few-shot classification on 11 datasets to\ndemonstrate the superiority of our proposed methods. Code is released at\nhttps://github.com/gaopengcuhk/Tip-Adapter.",
    "descriptor": "\nComments: Accepted by ECCV 2022. arXiv admin note: substantial text overlap with arXiv:2111.03930\n",
    "authors": [
      "Renrui Zhang",
      "Zhang Wei",
      "Rongyao Fang",
      "Peng Gao",
      "Kunchang Li",
      "Jifeng Dai",
      "Yu Qiao",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.09519"
  },
  {
    "id": "arXiv:2207.09520",
    "title": "Chance-Constrained AC Optimal Power Flow for Unbalanced Distribution  Grids",
    "abstract": "The growing penetration of distributed energy resources (DERs) is leading to\ncontinually changing operating conditions, which need to be managed efficiently\nby distribution grid operators. The intermittent nature of DERs such as solar\nphotovoltaic (PV) systems as well as load forecasting errors not only increase\nuncertainty in the grid, but also pose significant power quality challenges\nsuch as voltage unbalance and voltage magnitude violations. This paper\nleverages a chance-constrained optimization approach to reduce the impact of\nuncertainty on distribution grid operation. We first present the\nchance-constrained optimal power flow (CC-OPF) problem for distribution grids\nand discuss a reformulation based on constraint tightening that does not\nrequire any approximations or relaxations of the three-phase AC power flow\nequations. We then propose two iterative solution algorithms capable of\nefficiently solving the reformulation. In the case studies, the performance of\nboth algorithms is analyzed by running simulations on the IEEE 13-bus test\nfeeder using real PV and load measurement data. The simulation results indicate\nthat both methods are able to enforce the chance constraints in in- and\nout-of-sample evaluations.",
    "descriptor": "\nComments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Kshitij Girigoudar",
      "Ashley M. Hou",
      "Line A. Roald"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09520"
  },
  {
    "id": "arXiv:2207.09521",
    "title": "The Dice loss in the context of missing or empty labels: Introducing  $\u03a6$ and $\u03b5$",
    "abstract": "Albeit the Dice loss is one of the dominant loss functions in medical image\nsegmentation, most research omits a closer look at its derivative, i.e. the\nreal motor of the optimization when using gradient descent. In this paper, we\nhighlight the peculiar action of the Dice loss in the presence of missing or\nempty labels. First, we formulate a theoretical basis that gives a general\ndescription of the Dice loss and its derivative. It turns out that the choice\nof the reduction dimensions $\\Phi$ and the smoothing term $\\epsilon$ is\nnon-trivial and greatly influences its behavior. We find and propose heuristic\ncombinations of $\\Phi$ and $\\epsilon$ that work in a segmentation setting with\neither missing or empty labels. Second, we empirically validate these findings\nin a binary and multiclass segmentation setting using two publicly available\ndatasets. We confirm that the choice of $\\Phi$ and $\\epsilon$ is indeed\npivotal. With $\\Phi$ chosen such that the reductions happen over a single batch\n(and class) element and with a negligible $\\epsilon$, the Dice loss deals with\nmissing labels naturally and performs similarly compared to recent adaptations\nspecific for missing labels. With $\\Phi$ chosen such that the reductions happen\nover multiple batch elements or with a heuristic value for $\\epsilon$, the Dice\nloss handles empty labels correctly. We believe that this work highlights some\nessential perspectives and hope that it encourages researchers to better\ndescribe their exact implementation of the Dice loss in future work.",
    "descriptor": "\nComments: 8 pages, 3 figures, 1 table, International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022\n",
    "authors": [
      "Sofie Tilborghs",
      "Jeroen Bertels",
      "David Robben",
      "Dirk Vandermeulen",
      "Frederik Maes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09521"
  },
  {
    "id": "arXiv:2207.09524",
    "title": "Identification and characterization of misinformation superspreaders on  social media",
    "abstract": "The world's digital information ecosystem continues to struggle with the\nspread of misinformation. Prior work has suggested that users who consistently\ndisseminate a disproportionate amount of low-credibility content -- so-called\nsuperspreaders -- are at the center of this problem. We quantitatively confirm\nthis hypothesis and introduce simple metrics to predict the top misinformation\nsuperspreaders several months into the future. We then conduct a qualitative\nreview to characterize the most prolific superspreaders and analyze their\nsharing behaviors. Superspreaders include pundits with large followings,\nlow-credibility media outlets, personal accounts affiliated with those media\noutlets, and a range of influencers. They are primarily political in nature and\nuse more toxic language than the typical user sharing misinformation. We also\nfind concerning evidence suggesting that Twitter may be overlooking prominent\nsuperspreaders. We hope this work will further public understanding of bad\nactors and promote steps to mitigate their negative impacts on healthy digital\ndiscourse.",
    "descriptor": "",
    "authors": [
      "Matthew R. DeVerna",
      "Rachith Aiyappa",
      "Diogo Pacheco",
      "John Bryden",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.09524"
  },
  {
    "id": "arXiv:2207.09525",
    "title": "Crowdsourcing Impacts: Exploring the Utility of Crowds for Anticipating  Societal Impacts of Algorithmic Decision Making",
    "abstract": "With the increasing pervasiveness of algorithms across industry and\ngovernment, a growing body of work has grappled with how to understand their\nsocietal impact and ethical implications. Various methods have been used at\ndifferent stages of algorithm development to encourage researchers and\ndesigners to consider the potential societal impact of their research. An\nunderstudied yet promising area in this realm is using participatory foresight\nto anticipate these different societal impacts. We employ crowdsourcing as a\nmeans of participatory foresight to uncover four different types of impact\nareas based on a set of governmental algorithmic decision making tools: (1)\nperceived valence, (2) societal domains, (3) specific abstract impact types,\nand (4) ethical algorithm concerns. Our findings suggest that this method is\neffective at leveraging the cognitive diversity of the crowd to uncover a range\nof issues. We further analyze the complexities within the interaction of the\nimpact areas identified to demonstrate how crowdsourcing can illuminate\npatterns around the connections between impacts. Ultimately this work\nestablishes crowdsourcing as an effective means of anticipating algorithmic\nimpact which complements other approaches towards assessing algorithms in\nsociety by leveraging participatory foresight and cognitive diversity.",
    "descriptor": "\nComments: 10 pages, 2 figures. Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society (August 2022)\n",
    "authors": [
      "Julia Barnett",
      "Nicholas Diakopoulos"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.09525"
  },
  {
    "id": "arXiv:2207.09529",
    "title": "COVID-19 Detection from Respiratory Sounds with Hierarchical Spectrogram  Transformers",
    "abstract": "Monitoring of prevalent airborne diseases such as COVID-19 characteristically\ninvolve respiratory assessments. While auscultation is a mainstream method for\nsymptomatic monitoring, its diagnostic utility is hampered by the need for\ndedicated hospital visits. Continual remote monitoring based on recordings of\nrespiratory sounds on portable devices is a promising alternative, which can\nassist in screening of COVID-19. In this study, we introduce a novel deep\nlearning approach to distinguish patients with COVID-19 from healthy controls\ngiven audio recordings of cough or breathing sounds. The proposed approach\nleverages a novel hierarchical spectrogram transformer (HST) on spectrogram\nrepresentations of respiratory sounds. HST embodies self-attention mechanisms\nover local windows in spectrograms, and window size is progressively grown over\nmodel stages to capture local to global context. HST is compared against\nstate-of-the-art conventional and deep-learning baselines. Comprehensive\ndemonstrations on a multi-national dataset indicate that HST outperforms\ncompeting methods, achieving over 97% area under the receiver operating\ncharacteristic curve (AUC) in detecting COVID-19 cases.",
    "descriptor": "",
    "authors": [
      "Idil Aytekin",
      "Onat Dalmaz",
      "Kaan Gonc",
      "Haydar Ankishan",
      "Emine U Saritas",
      "Ulas Bagci",
      "Haydar Celik",
      "Tolga Cukur"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.09529"
  },
  {
    "id": "arXiv:2207.09530",
    "title": "Knowledge distillation with a class-aware loss for endoscopic disease  detection",
    "abstract": "Prevalence of gastrointestinal (GI) cancer is growing alarmingly every year\nleading to a substantial increase in the mortality rate. Endoscopic detection\nis providing crucial diagnostic support, however, subtle lesions in upper and\nlower GI are quite hard to detect and cause considerable missed detection. In\nthis work, we leverage deep learning to develop a framework to improve the\nlocalization of difficult to detect lesions and minimize the missed detection\nrate. We propose an end to end student-teacher learning setup where class\nprobabilities of a trained teacher model on one class with larger dataset are\nused to penalize multi-class student network. Our model achieves higher\nperformance in terms of mean average precision (mAP) on both endoscopic disease\ndetection (EDD2020) challenge and Kvasir-SEG datasets. Additionally, we show\nthat using such learning paradigm, our model is generalizable to unseen test\nset giving higher APs for clinically crucial neoplastic and polyp categories",
    "descriptor": "\nComments: Paper accepted at the CaPTion workshop at MICCAI2022\n",
    "authors": [
      "Pedro E. Chavarrias-Solanon",
      "Mansoor Ali-Teevno",
      "Gilberto Ochoa-Ruiz",
      "Sharib Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09530"
  },
  {
    "id": "arXiv:2207.09531",
    "title": "A Block-based Convolutional Neural Network for Low-Resolution Image  Classification",
    "abstract": "The success of CNN-based architecture on image classification in learning and\nextracting features made them so popular these days, but the task of image\nclassification becomes more challenging when we use state of art models to\nclassify noisy and low-quality images. To solve this problem, we proposed a\nnovel image classification architecture that learns subtle details in\nlow-resolution images that are blurred and noisy. In order to build our new\nblocks, we used the idea of Res Connections and the Inception module ideas.\nUsing the MNIST datasets, we have conducted extensive experiments that show\nthat the introduced architecture is more accurate and faster than other\nstate-of-the-art Convolutional neural networks. As a result of the special\ncharacteristics of our model, it can achieve a better result with fewer\nparameters.",
    "descriptor": "\nComments: 6 pages, 5 figures and 2 tables\n",
    "authors": [
      "Ashkan Ganj",
      "Mohsen Ebadpour",
      "Mahdi Darvish",
      "Hamid Bahador"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09531"
  },
  {
    "id": "arXiv:2207.09534",
    "title": "VisQuiz: Exploring Feedback Mechanisms to Improve Graphical Perception",
    "abstract": "Graphical perception studies are a key element of visualization research,\nforming the basis of design recommendations and contributing to our\nunderstanding of how people make sense of visualizations. However, graphical\nperception studies typically include only brief training sessions, and the\nimpact of longer and more in-depth feedback remains unclear. In this paper, we\nexplore the design and evaluation of feedback for graphical perception tasks,\ncalled VisQuiz. Using a quiz-like metaphor, we design feedback for a typical\nvisualization comparison experiment, showing participants their answer\nalongside the correct answer in an animated sequence in each trial. We extend\nthis quiz metaphor to include summary feedback after each stage of the\nexperiment, providing additional moments for participants to reflect on their\nperformance. To evaluate VisQuiz, we conduct a between-subjects experiment,\nincluding three stages of 40 trials each with a control condition that included\nonly summary feedback. Results from n = 80 participants show that once\nparticipants started receiving trial feedback (Stage 2) they performed\nsignificantly better with bubble charts than those in the control condition.\nThis effect carried over when feedback was removed (Stage 3). Results also\nsuggest an overall trend of improved performance due to feedback. We discuss\nthese findings in the context of other visualization literacy efforts, and\npossible future work at the intersection of visualization, feedback, and\nlearning. Experiment data and analysis scripts are available at the following\nrepository https://osf.io/jys5d/",
    "descriptor": "\nComments: 5 pages, 5 figures, short paper\n",
    "authors": [
      "Ryan Birchfield",
      "Maddison Caten",
      "Errica Cheng",
      "Madyson Kelly",
      "Truman Larson",
      "Hoan Phan Pham",
      "Yiren Ding",
      "No\u00eblle Rakotondravony",
      "Lane Harrison"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.09534"
  },
  {
    "id": "arXiv:2207.09535",
    "title": "Forget-me-not! Contrastive Critics for Mitigating Posterior Collapse",
    "abstract": "Variational autoencoders (VAEs) suffer from posterior collapse, where the\npowerful neural networks used for modeling and inference optimize the objective\nwithout meaningfully using the latent representation. We introduce inference\ncritics that detect and incentivize against posterior collapse by requiring\ncorrespondence between latent variables and the observations. By connecting the\ncritic's objective to the literature in self-supervised contrastive\nrepresentation learning, we show both theoretically and empirically that\noptimizing inference critics increases the mutual information between\nobservations and latents, mitigating posterior collapse. This approach is\nstraightforward to implement and requires significantly less training time than\nprior methods, yet obtains competitive results on three established datasets.\nOverall, the approach lays the foundation to bridge the previously disconnected\nframeworks of contrastive learning and probabilistic modeling with variational\nautoencoders, underscoring the benefits both communities may find at their\nintersection.",
    "descriptor": "\nComments: Conference on Uncertainty in Artificial Intelligence (UAI) 2022\n",
    "authors": [
      "Sachit Menon",
      "David Blei",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.09535"
  },
  {
    "id": "arXiv:2207.09536",
    "title": "Unified Grid-Forming Control of PMSG Wind Turbines for Fast Frequency  Response and MPPT",
    "abstract": "In this work we present a novel dual-port grid-forming control strategy, for\npermanent magnet synchronous generator wind turbines with back-to-back voltage\nsource converters, that unifies the entire range of functions from maximum\npower point tracking (MPPT) to providing inertia and fast frequency response\nwithout explicit mode switching between grid-following and grid-forming\ncontrol. The controls impose a well-defined AC voltage at the grid-side\nconverter (GSC) and the machine-side converter (MSC) AC terminals and\nexplicitly stabilize the DC-link capacitor voltage through both GSC and MSC.\nThe wind turbine's kinetic energy storage and curtailment are adjusted through\na combination of implicit rotor speed control and pitch angle control and\ndirectly determine the operating mode and level of grid support. Moreover, we\nprovide analytical small-signal stability conditions for a simplified system\nand explicitly characterize the relationship between control gains,\ncurtailment, and the wind turbines steady-state response. Finally, a detailed\nsimulation study is used to validate the results and compared the proposed\ncontrol with state-of-the-art MPPT control.",
    "descriptor": "\nComments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Xue Lyu",
      "Irina Suboti\u0107",
      "Dominic Gro\u00df"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09536"
  },
  {
    "id": "arXiv:2207.09539",
    "title": "Revealing Secrets From Pre-trained Models",
    "abstract": "With the growing burden of training deep learning models with large data\nsets, transfer-learning has been widely adopted in many emerging deep learning\nalgorithms. Transformer models such as BERT are the main player in natural\nlanguage processing and use transfer-learning as a de facto standard training\nmethod. A few big data companies release pre-trained models that are trained\nwith a few popular datasets with which end users and researchers fine-tune the\nmodel with their own datasets. Transfer-learning significantly reduces the time\nand effort of training models. However, it comes at the cost of security\nconcerns. In this paper, we show a new observation that pre-trained models and\nfine-tuned models have significantly high similarities in weight values. Also,\nwe demonstrate that there exist vendor-specific computing patterns even for the\nsame models. With these new findings, we propose a new model extraction attack\nthat reveals the model architecture and the pre-trained model used by the\nblack-box victim model with vendor-specific computing patterns and then\nestimates the entire model weights based on the weight value similarities\nbetween the fine-tuned model and pre-trained model. We also show that the\nweight similarity can be leveraged for increasing the model extraction\nfeasibility through a novel weight extraction pruning.",
    "descriptor": "",
    "authors": [
      "Mujahid Al Rafi",
      "Yuan Feng",
      "Hyeran Jeon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09539"
  },
  {
    "id": "arXiv:2207.09542",
    "title": "Controllable Data Generation by Deep Learning: A Review",
    "abstract": "Designing and generating new data under targeted properties has been\nattracting various critical applications such as molecule design, image editing\nand speech synthesis. Traditional hand-crafted approaches heavily rely on\nexpertise experience and intensive human efforts, yet still suffer from the\ninsufficiency of scientific knowledge and low throughput to support effective\nand efficient data generation. Recently, the advancement of deep learning\ninduces expressive methods that can learn the underlying representation and\nproperties of data. Such capability provides new opportunities in figuring out\nthe mutual relationship between the structural patterns and functional\nproperties of the data and leveraging such relationship to generate structural\ndata given the desired properties. This article provides a systematic review of\nthis promising research area, commonly known as controllable deep data\ngeneration. Firstly, the potential challenges are raised and preliminaries are\nprovided. Then the controllable deep data generation is formally defined, a\ntaxonomy on various techniques is proposed and the evaluation metrics in this\nspecific domain are summarized. After that, exciting applications of\ncontrollable deep data generation are introduced and existing works are\nexperimentally analyzed and compared. Finally, the promising future directions\nof controllable deep data generation are highlighted and five potential\nchallenges are identified.",
    "descriptor": "",
    "authors": [
      "Shiyu Wang",
      "Yuanqi Du",
      "Xiaojie Guo",
      "Bo Pan",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09542"
  },
  {
    "id": "arXiv:2207.09543",
    "title": "Industry Led Use-Case Development for Human-Swarm Operations",
    "abstract": "In the domain of unmanned vehicles, autonomous robotic swarms promise to\ndeliver increased efficiency and collective autonomy. How these swarms will\noperate in the future, and what communication requirements and operational\nboundaries will arise are yet to be sufficiently defined. A workshop was\nconducted with 11 professional unmanned-vehicle operators and designers with\nthe objective of identifying use-cases for developing and testing robotic\nswarms. Three scenarios were defined by experts and were then compiled to\nproduce a single use case outlining the scenario, objectives, agents,\ncommunication requirements and stages of operation when collaborating with\nhighly autonomous swarms. Our compiled use case is intended for researchers,\ndesigners, and manufacturers alike to test and tailor their design pipeline to\naccommodate for some of the key issues in human-swarm ininteraction. Examples\nof application include informing simulation development, forming the basis of\nfurther design workshops, and identifying trust issues that may arise between\nhuman operators and the swarm.",
    "descriptor": "\nComments: Accepted at AAAI 2022 Spring Symposium Series (Putting AI in the Critical Loop: Assured Trust and Autonomy in Human-Machine Teams)\n",
    "authors": [
      "Jediah R. Clark",
      "Mohammad Naiseh",
      "Joel Fischer",
      "Marise Galvez Trigo",
      "Katie Parnell",
      "Mario Brito",
      "Adrian Bodenmann",
      "Sarvapali D. Ramchurn",
      "Mohammad Divband Soorati"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2207.09543"
  },
  {
    "id": "arXiv:2207.09545",
    "title": "Pandora Box Problem with Nonobligatory Inspection: Hardness and Improved  Approximation Algorithms",
    "abstract": "Weitzman (1979) introduced the Pandora's Box problem as a model for\nsequential search with inspection costs, and gave an elegant index-based policy\nthat attains provably optimal expected payoff. In various scenarios, the\nsearching agent may select an option without making a costly inspection. Doval\n(2018) studied a version of Pandora's problem that allows this, and showed that\nthe index-based policy and various other simple policies are no longer optimal.\nBeyhaghi and Kleinberg (2019) gave the first non-trivial approximation\nalgorithm for the problem, showing a simple policy with expected payoff at\nleast a $(1 - \\frac 1 e)$-fraction that of the optimal policy. No hardness\nresult for the problem was known.\nIn this work, we show that it is NP-hard to compute an optimal policy for\nPandora's problem with nonobligatory inspection. We also give a polynomial-time\nscheme that computes policies with an expected payoff at least $(0.8 -\n\\epsilon)$-fraction of the optimal, for arbitrarily small $\\epsilon > 0$.",
    "descriptor": "",
    "authors": [
      "Hu Fu",
      "Jiawei Li",
      "Daogao Liu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.09545"
  },
  {
    "id": "arXiv:2207.09554",
    "title": "HoloLens 2 Technical Evaluation as Mixed Reality Guide",
    "abstract": "Mixed Reality (MR) is an evolving technology lying in the continuum spanned\nby related technologies such as Virtual Reality (VR) and Augmented Reality\n(AR), and creates an exciting way of interacting with people and the\nenvironment. This technology is fast becoming a tool used by many people,\npotentially improving living environments and work efficiency. Microsoft\nHoloLens has played an important role in the progress of MR, from the first\ngeneration to the second generation. In this paper, we systematically evaluate\nthe functions of applicable functions in HoloLens 2. These evaluations can\nserve as a performance benchmark that can help people who need to use this\ninstrument for research or applications in the future. The detailed tests and\nthe performance evaluation of the different functionalities show the usability\nand possible limitations of each function. We mainly divide the experiment into\nthe existing functions of the HoloLens 1, the new functions of the HoloLens 2,\nand the use of research mode. This research results will be useful for MR\nresearchers who want to use HoloLens 2 as a research tool to design their own\nMR applications.",
    "descriptor": "",
    "authors": [
      "Hung-Jui Guo",
      "Balakrishnan Prabhakaran"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.09554"
  },
  {
    "id": "arXiv:2207.09555",
    "title": "Xronos: Predictable Coordination for Safety-Critical Distributed  Embedded Systems",
    "abstract": "Asynchronous frameworks for distributed embedded systems, like ROS and MQTT,\nare increasingly used in safety-critical applications such as autonomous\ndriving, where the cost of unintended behavior is high. The coordination\nmechanism between the components in these frameworks, however, gives rise to\nnondeterminism, where factors such as communication timing can lead to\narbitrary ordering in the handling of messages. In this paper, we demonstrate\nthe significance of this problem in an open-source full-stack autonomous\ndriving software, Autoware.Auto 1.0, which relies on ROS 2. We give an\nalternative: Xronos, an open-source framework for distributed embedded systems\nthat has a novel coordination strategy with predictable properties under\nclearly stated assumptions. If these assumptions are violated, Xronos provides\nfor application-specific fault handlers to be invoked. We port Autoware.Auto to\nXronos and show that it avoids the identified problems with manageable cost in\nend-to-end latency. Furthermore, we compare the maximum throughput of Xronos to\nROS 2 and MQTT using microbenchmarks under different settings, including on\nthree different hardware configurations, and find that it can match or exceed\nthose frameworks in terms of throughput.",
    "descriptor": "",
    "authors": [
      "Soroush Bateni",
      "Marten Lohstroh",
      "Hou Seng Wong",
      "Rohan Tabish",
      "Hokeun Kim",
      "Shaokai Lin",
      "Christian Menard",
      "Cong Liu",
      "Edward A. Lee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.09555"
  },
  {
    "id": "arXiv:2207.09562",
    "title": "QuoteKG: A Multilingual Knowledge Graph of Quotes",
    "abstract": "Quotes of public figures can mark turning points in history. A quote can\nexplain its originator's actions, foreshadowing political or personal decisions\nand revealing character traits. Impactful quotes cross language barriers and\ninfluence the general population's reaction to specific stances, always facing\nthe risk of being misattributed or taken out of context. The provision of a\ncross-lingual knowledge graph of quotes that establishes the authenticity of\nquotes and their contexts is of great importance to allow the exploration of\nthe lives of important people as well as topics from the perspective of what\nwas actually said. In this paper, we present QuoteKG, the first multilingual\nknowledge graph of quotes. We propose the QuoteKG creation pipeline that\nextracts quotes from Wikiquote, a free and collaboratively created collection\nof quotes in many languages, and aligns different mentions of the same quote.\nQuoteKG includes nearly one million quotes in $55$ languages, said by more than\n$69,000$ people of public interest across a wide range of topics. QuoteKG is\npublicly available and can be accessed via a SPARQL endpoint.",
    "descriptor": "",
    "authors": [
      "Tin Kuculo",
      "Simon Gottschalk",
      "Elena Demidova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.09562"
  },
  {
    "id": "arXiv:2207.09564",
    "title": "Collective Decision Making in Communication-Constrained Environments",
    "abstract": "One of the main tasks for autonomous robot swarms is to collectively decide\non the best available option. Achieving that requires a high quality\ncommunication between the agents that may not be always available in a real\nworld environment. In this paper we introduce the communication-constrained\ncollective decision-making problem where some areas of the environment limit\nthe agents' ability to communicate, either by reducing success rate or blocking\nthe communication channels. We propose a decentralised algorithm for mapping\nenvironmental features for robot swarms as well as improving collective\ndecision making in communication-limited environments without prior knowledge\nof the communication landscape. Our results show that making a collective aware\nof the communication environment can improve the speed of convergence in the\npresence of communication limitations, at least 3 times faster, without\nsacrificing accuracy.",
    "descriptor": "\nComments: 6 pages, 7 figures, accepted to the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Thomas G. Kelly",
      "Mohammad Divband Soorati",
      "Klaus-Peter Zauner",
      "Sarvapali D. Ramchurn",
      "Danesh Tarapore"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2207.09564"
  },
  {
    "id": "arXiv:2207.09566",
    "title": "Human-guided Collaborative Problem Solving: A Natural Language based  Framework",
    "abstract": "We consider the problem of human-machine collaborative problem solving as a\nplanning task coupled with natural language communication. Our framework\nconsists of three components -- a natural language engine that parses the\nlanguage utterances to a formal representation and vice-versa, a concept\nlearner that induces generalized concepts for plans based on limited\ninteractions with the user, and an HTN planner that solves the task based on\nhuman interaction. We illustrate the ability of this framework to address the\nkey challenges of collaborative problem solving by demonstrating it on a\ncollaborative building task in a Minecraft-based blocksworld domain. The\naccompanied demo video is available at https://youtu.be/q1pWe4aahF0.",
    "descriptor": "\nComments: ICAPS 2021 (demo track)\n",
    "authors": [
      "Harsha Kokel",
      "Mayukh Das",
      "Rakibul Islam",
      "Julia Bonn",
      "Jon Cai",
      "Soham Dan",
      "Anjali Narayan-Chen",
      "Prashant Jayannavar",
      "Janardhan Rao Doppa",
      "Julia Hockenmaier",
      "Sriraam Natarajan",
      "Martha Palmer",
      "Dan Roth"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.09566"
  },
  {
    "id": "arXiv:2207.09568",
    "title": "FedNet2Net: Saving Communication and Computations in Federated Learning  with Model Growing",
    "abstract": "Federated learning (FL) is a recently developed area of machine learning, in\nwhich the private data of a large number of distributed clients is used to\ndevelop a global model under the coordination of a central server without\nexplicitly exposing the data. The standard FL strategy has a number of\nsignificant bottlenecks including large communication requirements and high\nimpact on the clients' resources. Several strategies have been described in the\nliterature trying to address these issues. In this paper, a novel scheme based\non the notion of \"model growing\" is proposed. Initially, the server deploys a\nsmall model of low complexity, which is trained to capture the data complexity\nduring the initial set of rounds. When the performance of such a model\nsaturates, the server switches to a larger model with the help of\nfunction-preserving transformations. The model complexity increases as more\ndata is processed by the clients, and the overall process continues until the\ndesired performance is achieved. Therefore, the most complex model is broadcast\nonly at the final stage in our approach resulting in substantial reduction in\ncommunication cost and client computational requirements. The proposed approach\nis tested extensively on three standard benchmarks and is shown to achieve\nsubstantial reduction in communication and client computation while achieving\ncomparable accuracy when compared to the current most effective strategies.",
    "descriptor": "\nComments: This version of the contribution has been accepted for publication in the proceedings of 31st International Conference on Artificial Neural Networks\n",
    "authors": [
      "Amit Kumar Kundu",
      "Joseph Jaja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.09568"
  },
  {
    "id": "arXiv:2207.09572",
    "title": "Towards Robust Multivariate Time-Series Forecasting: Adversarial Attacks  and Defense Mechanisms",
    "abstract": "As deep learning models have gradually become the main workhorse of time\nseries forecasting, the potential vulnerability under adversarial attacks to\nforecasting and decision system accordingly has emerged as a main issue in\nrecent years. Albeit such behaviors and defense mechanisms started to be\ninvestigated for the univariate time series forecasting, there are still few\nstudies regarding the multivariate forecasting which is often preferred due to\nits capacity to encode correlations between different time series. In this\nwork, we study and design adversarial attack on multivariate probabilistic\nforecasting models, taking into consideration attack budget constraints and the\ncorrelation architecture between multiple time series. Specifically, we\ninvestigate a sparse indirect attack that hurts the prediction of an item (time\nseries) by only attacking the history of a small number of other items to save\nattacking cost. In order to combat these attacks, we also develop two defense\nstrategies. First, we adopt randomized smoothing to multivariate time series\nscenario and verify its effectiveness via empirical experiments. Second, we\nleverage a sparse attacker to enable end-to-end adversarial training that\ndelivers robust probabilistic forecasters. Extensive experiments on real\ndataset confirm that our attack schemes are powerful and our defend algorithms\nare more effective compared with other baseline defense mechanisms.",
    "descriptor": "",
    "authors": [
      "Linbo Liu",
      "Youngsuk Park",
      "Trong Nghia Hoang",
      "Hilaf Hasson",
      "Jun Huan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.09572"
  },
  {
    "id": "arXiv:2207.09580",
    "title": "A Frequency-Velocity CNN for Developing Near-Surface 2D Vs Images from  Linear-Array, Active-Source Wavefield Measurements",
    "abstract": "This paper presents a frequency-velocity convolutional neural network (CNN)\nfor rapid, non-invasive 2D shear wave velocity (Vs) imaging of near-surface\ngeo-materials. Operating in the frequency-velocity domain allows for\nsignificant flexibility in the linear-array, active-source experimental testing\nconfigurations used for generating the CNN input, which are normalized\ndispersion images. Unlike wavefield images, normalized dispersion images are\nrelatively insensitive to the experimental testing configuration, accommodating\nvarious source types, source offsets, numbers of receivers, and receiver\nspacings. We demonstrate the effectiveness of the frequency-velocity CNN by\napplying it to a classic near-surface geophysics problem, namely, imaging a\ntwo-layer, undulating, soil-over-bedrock interface. This problem was recently\ninvestigated in our group by developing a time-distance CNN, which showed great\npromise but lacked flexibility in utilizing different field-testing\nconfigurations. Herein, the new frequency-velocity CNN is shown to have\ncomparable accuracy to the time-distance CNN while providing greater\nflexibility to handle varied field applications. The frequency-velocity CNN was\ntrained, validated, and tested using 100,000 synthetic near-surface models. The\nability of the proposed frequency-velocity CNN to generalize across various\nacquisition configurations is first tested using synthetic near-surface models\nwith different acquisition configurations from that of the training set, and\nthen applied to experimental field data collected at the Hornsby Bend site in\nAustin, Texas, USA. When fully developed for a wider range of geological\nconditions, the proposed CNN may ultimately be used as a rapid, end-to-end\nalternative for current pseudo-2D surface wave imaging techniques or to develop\nstarting models for full waveform inversion.",
    "descriptor": "\nComments: 34 pages, 13 figures, 2 tables\n",
    "authors": [
      "Aser Abbas",
      "Joseph P. Vantassel",
      "Brady R. Cox",
      "Krishna Kumar",
      "Jodie Crocker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.09580"
  },
  {
    "id": "arXiv:2207.09584",
    "title": "Sample Efficient Learning of Predictors that Complement Humans",
    "abstract": "One of the goals of learning algorithms is to complement and reduce the\nburden on human decision makers. The expert deferral setting wherein an\nalgorithm can either predict on its own or defer the decision to a downstream\nexpert helps accomplish this goal. A fundamental aspect of this setting is the\nneed to learn complementary predictors that improve on the human's weaknesses\nrather than learning predictors optimized for average error. In this work, we\nprovide the first theoretical analysis of the benefit of learning complementary\npredictors in expert deferral. To enable efficiently learning such predictors,\nwe consider a family of consistent surrogate loss functions for expert deferral\nand analyze their theoretical properties. Finally, we design active learning\nschemes that require minimal amount of data of human expert predictions in\norder to learn accurate deferral systems.",
    "descriptor": "\nComments: ICML 2022\n",
    "authors": [
      "Mohammad-Amin Charusaie",
      "Hussein Mozannar",
      "David Sontag",
      "Samira Samadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.09584"
  },
  {
    "id": "arXiv:2207.09592",
    "title": "Inclusive Privacy Design for Older Adults Living in Ambient Assisted  Living",
    "abstract": "Ambient assisted living (AAL) environments support independence and quality\nof life of older adults However, in an AAL environment, privacy-related issues\n(e.g., unawareness, information disclosure, and lack of support) directly\nimpact older adults and bystanders (e.g., caregivers, service providers, etc.).\nWe explore the privacy challenges that both older adults and bystanders face in\nAAL. We call for inclusive privacy design and recommend following areas of\nimprovement: consent, notification, and consideration for cultural differences.",
    "descriptor": "\nComments: 5 pages, 1 figure, accepted to Workshop on Inclusive Privacy and Security (WIPS 2022)\n",
    "authors": [
      "Nyteisha Bookert",
      "May Almousa",
      "Mohd Anwar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.09592"
  },
  {
    "id": "arXiv:2207.09593",
    "title": "Privacy Threats on the Internet of Medical Things",
    "abstract": "The Internet of Medical Things (IoMT) is a frequent target of attacks --\ncompromising both patient data and healthcare infra-structure. While\nprivacy-enhanced technologies and services (PETS) are developed to mitigate\ntraditional privacy concerns, they cannot be applied without identifying\nspecific threat models. Therefore, our position is that the new threat\nland-scape created by the relatively new and underexplored IoMT domain must be\nstudied. We briefly discuss specific privacy threats and threat actors in IoMT.\nFurthermore, we argue that the privacy policy gap needs to be identified for\nthe IoMT threat landscape.",
    "descriptor": "\nComments: 4 pages, accepted to The Workshop on Privacy Threat Modeling (PTM) at the Eighteenth Symposium on Usable Privacy and Security (SOUPS 2022)\n",
    "authors": [
      "Nyteisha Bookert",
      "Mohd Anwar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.09593"
  },
  {
    "id": "arXiv:2207.09594",
    "title": "ICRICS: Iterative Compensation Recovery for Image Compressive Sensing",
    "abstract": "Closed-loop architecture is widely utilized in automatic control systems and\nattain distinguished performance. However, classical compressive sensing\nsystems employ open-loop architecture with separated sampling and\nreconstruction units. Therefore, a method of iterative compensation recovery\nfor image compressive sensing (ICRICS) is proposed by introducing closed-loop\nframework into traditional compresses sensing systems. The proposed method\ndepends on any existing approaches and upgrades their reconstruction\nperformance by adding negative feedback structure. Theory analysis on negative\nfeedback of compressive sensing systems is performed. An approximate\nmathematical proof of the effectiveness of the proposed method is also\nprovided. Simulation experiments on more than 3 image datasets show that the\nproposed method is superior to 10 competition approaches in reconstruction\nperformance. The maximum increment of average peak signal-to-noise ratio is\n4.36 dB and the maximum increment of average structural similarity is 0.034 on\none dataset. The proposed method based on negative feedback mechanism can\nefficiently correct the recovery error in the existing systems of image\ncompressive sensing.",
    "descriptor": "",
    "authors": [
      "Honggui Li",
      "Maria Trocan",
      "Dimitri Galayko",
      "Mohamad Sawan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.09594"
  },
  {
    "id": "arXiv:2207.09597",
    "title": "Feasible Adversarial Robust Reinforcement Learning for Underspecified  Environments",
    "abstract": "Robust reinforcement learning (RL) considers the problem of learning policies\nthat perform well in the worst case among a set of possible environment\nparameter values. In real-world environments, choosing the set of possible\nvalues for robust RL can be a difficult task. When that set is specified too\nnarrowly, the agent will be left vulnerable to reasonable parameter values\nunaccounted for. When specified too broadly, the agent will be too cautious. In\nthis paper, we propose Feasible Adversarial Robust RL (FARR), a method for\nautomatically determining the set of environment parameter values over which to\nbe robust. FARR implicitly defines the set of feasible parameter values as\nthose on which an agent could achieve a benchmark reward given enough training\nresources. By formulating this problem as a two-player zero-sum game, FARR\njointly learns an adversarial distribution over parameter values with feasible\nsupport and a policy robust over this feasible parameter set. Using the PSRO\nalgorithm to find an approximate Nash equilibrium in this FARR game, we show\nthat an agent trained with FARR is more robust to feasible adversarial\nparameter selection than with existing minimax, domain-randomization, and\nregret objectives in a parameterized gridworld and three MuJoCo control\nenvironments.",
    "descriptor": "",
    "authors": [
      "JB Lanier",
      "Stephen McAleer",
      "Pierre Baldi",
      "Roy Fox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.09597"
  },
  {
    "id": "arXiv:2207.09603",
    "title": "AiATrack: Attention in Attention for Transformer Visual Tracking",
    "abstract": "Transformer trackers have achieved impressive advancements recently, where\nthe attention mechanism plays an important role. However, the independent\ncorrelation computation in the attention mechanism could result in noisy and\nambiguous attention weights, which inhibits further performance improvement. To\naddress this issue, we propose an attention in attention (AiA) module, which\nenhances appropriate correlations and suppresses erroneous ones by seeking\nconsensus among all correlation vectors. Our AiA module can be readily applied\nto both self-attention blocks and cross-attention blocks to facilitate feature\naggregation and information propagation for visual tracking. Moreover, we\npropose a streamlined Transformer tracking framework, dubbed AiATrack, by\nintroducing efficient feature reuse and target-background embeddings to make\nfull use of temporal references. Experiments show that our tracker achieves\nstate-of-the-art performance on six tracking benchmarks while running at a\nreal-time speed.",
    "descriptor": "\nComments: Accepted to ECCV 2022. Code and models are publicly available at this https URL\n",
    "authors": [
      "Shenyuan Gao",
      "Chunluan Zhou",
      "Chao Ma",
      "Xinggang Wang",
      "Junsong Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09603"
  },
  {
    "id": "arXiv:2207.09608",
    "title": "Probablement, Wahrscheinlich, Likely ? A Cross-Language Study of How  People Verbalize Probabilities in Icon Array Visualizations",
    "abstract": "Visualizations today are used across a wide range of languages and cultures.\nYet the extent to which language impacts how we reason about data and\nvisualizations remains unclear. In this paper, we explore the intersection of\nvisualization and language through a cross-language study on estimative\nprobability tasks with icon-array visualizations. Across Arabic, English,\nFrench, German, and Mandarin, n = 50 participants per language both chose\nprobability expressions - e.g. likely, probable - to describe icon-array\nvisualizations (Vis-to-Expression), and drew icon-array visualizations to match\na given expression (Expression-to-Vis). Results suggest that there is no clear\none-to-one mapping of probability expressions and associated visual ranges\nbetween languages. Several translated expressions fell significantly above or\nbelow the range of the corresponding English expressions. Compared to other\nlanguages, French and German respondents appear to exhibit high levels of\nconsistency between the visualizations they drew and the words they chose.\nParticipants across languages used similar words when describing scenarios\nabove 80% chance, with more variance in expressions targeting mid-range and\nlower values. We discuss how these results suggest potential differences in the\nexpressiveness of language as it relates to visualization interpretation and\ndesign goals, as well as practical implications for translation efforts and\nfuture studies at the intersection of languages, culture, and visualization.\nExperiment data, source code, and analysis scripts are available at the\nfollowing repository: https://osf.io/g5d4r/.",
    "descriptor": "\nComments: 11 pages, 10 figures, conference paper\n",
    "authors": [
      "No\u00eblle Rakotondravony",
      "Yiren Ding",
      "Lane Harrison"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.09608"
  },
  {
    "id": "arXiv:2207.09609",
    "title": "Towards Accurate and Robust Classification in Continuously Transitioning  Industrial Sprays with Mixup",
    "abstract": "Image classification with deep neural networks has seen a surge of\ntechnological breakthroughs with promising applications in areas such as face\nrecognition, medical imaging, and autonomous driving. In engineering problems,\nhowever, such as high-speed imaging of engine fuel injector sprays or body\npaint sprays, deep neural networks face a fundamental challenge related to the\navailability of adequate and diverse data. Typically, only thousands or\nsometimes even hundreds of samples are available for training. In addition, the\ntransition between different spray classes is a continuum and requires a high\nlevel of domain expertise to label the images accurately. In this work, we used\nMixup as an approach to systematically deal with the data scarcity and\nambiguous class boundaries found in industrial spray applications. We show that\ndata augmentation can mitigate the over-fitting problem of large neural\nnetworks on small data sets, to a certain level, but cannot fundamentally\nresolve the issue. We discuss how a convex linear interpolation of different\nclasses naturally aligns with the continuous transition between different\nclasses in our application. Our experiments demonstrate Mixup as a simple yet\neffective method to train an accurate and robust deep neural network classifier\nwith only a few hundred samples.",
    "descriptor": "\nComments: 9 pages, 5 figures, 5 tables\n",
    "authors": [
      "Hongjiang Li",
      "Huanyi Shui",
      "Alemayehu Admasu",
      "Praveen Narayanan",
      "Devesh Upadhyay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09609"
  },
  {
    "id": "arXiv:2207.09610",
    "title": "Unsupervised Deep Multi-Shape Matching",
    "abstract": "3D shape matching is a long-standing problem in computer vision and computer\ngraphics. While deep neural networks were shown to lead to state-of-the-art\nresults in shape matching, existing learning-based approaches are limited in\nthe context of multi-shape matching: (i) either they focus on matching pairs of\nshapes only and thus suffer from cycle-inconsistent multi-matchings, or (ii)\nthey require an explicit template shape to address the matching of a collection\nof shapes. In this paper, we present a novel approach for deep multi-shape\nmatching that ensures cycle-consistent multi-matchings while not depending on\nan explicit template shape. To this end, we utilise a shape-to-universe\nmulti-matching representation that we combine with powerful functional map\nregularisation, so that our multi-shape matching neural network can be trained\nin a fully unsupervised manner. While the functional map regularisation is only\nconsidered during training time, functional maps are not computed for\npredicting correspondences, thereby allowing for fast inference. We demonstrate\nthat our method achieves state-of-the-art results on several challenging\nbenchmark datasets, and, most remarkably, that our unsupervised method even\noutperforms recent supervised methods.",
    "descriptor": "\nComments: to be published in ECCV2022\n",
    "authors": [
      "Dongliang Cao",
      "Florian Bernard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2207.09610"
  },
  {
    "id": "arXiv:2207.09611",
    "title": "Combined Federated and Split Learning in Edge Computing for Ubiquitous  Intelligence in Internet of Things: State of the Art and Future Directions",
    "abstract": "Federated learning (FL) and split learning (SL) are two emerging\ncollaborative learning methods that may greatly facilitate ubiquitous\nintelligence in Internet of Things (IoT). Federated learning enables machine\nlearning (ML) models locally trained using private data to be aggregated into a\nglobal model. Split learning allows different portions of an ML model to be\ncollaboratively trained on different workers in a learning framework. Federated\nlearning and split learning, each has unique advantages and respective\nlimitations, may complement each other toward ubiquitous intelligence in IoT.\nTherefore, combination of federated learning and split learning recently became\nan active research area attracting extensive interest. In this article, we\nreview the latest developments in federated learning and split learning and\npresent a survey on the state-of-the-art technologies for combining these two\nlearning methods in an edge computing-based IoT environment. We also identify\nsome open problems and discuss possible directions for future research in this\narea with a hope to further arouse the research community's interest in this\nemerging field.",
    "descriptor": "",
    "authors": [
      "Qiang Duan",
      "Shijing Hu",
      "Ruijun Deng",
      "Zhihui Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.09611"
  },
  {
    "id": "arXiv:2207.09613",
    "title": "Exploiting Domain Transferability for Collaborative Inter-level Domain  Adaptive Object Detection",
    "abstract": "Domain adaptation for object detection (DAOD) has recently drawn much\nattention owing to its capability of detecting target objects without any\nannotations. To tackle the problem, previous works focus on aligning features\nextracted from partial levels (e.g., image-level, instance-level, RPN-level) in\na two-stage detector via adversarial training. However, individual levels in\nthe object detection pipeline are closely related to each other and this\ninter-level relation is unconsidered yet. To this end, we introduce a novel\nframework for DAOD with three proposed components: Multi-scale-aware\nUncertainty Attention (MUA), Transferable Region Proposal Network (TRPN), and\nDynamic Instance Sampling (DIS). With these modules, we seek to reduce the\nnegative transfer effect during training while maximizing transferability as\nwell as discriminability in both domains. Finally, our framework implicitly\nlearns domain invariant regions for object detection via exploiting the\ntransferable information and enhances the complementarity between different\ndetection levels by collaboratively utilizing their domain information. Through\nablation studies and experiments, we show that the proposed modules contribute\nto the performance improvement in a synergic way, demonstrating the\neffectiveness of our method. Moreover, our model achieves a new\nstate-of-the-art performance on various benchmarks.",
    "descriptor": "\nComments: Accepted to Expert Systems with Applications. The first three authors contributed equally\n",
    "authors": [
      "Mirae Do",
      "Seogkyu Jeon",
      "Pilhyeon Lee",
      "Kibeom Hong",
      "Yu-seung Ma",
      "Hyeran Byun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09613"
  },
  {
    "id": "arXiv:2207.09614",
    "title": "Adaptive Partition of Unity Interpolation Method with Moving Patches",
    "abstract": "The adaptive partition of unity interpolation method, introduced by Aiton and\nDriscoll, using Chebyshev local interpolants, is explored for interpolating\nfunctions with sharp gradients representing two-medium problems. For functions\nthat evolve under vector fields, the partition of unity patches (covers) can be\nshifted and resized to follow the changing dynamics of local profiles. The\nmethod is tested for selected 1D and 2D two-medium problems with linear\ndivergence-free vector fields. In those cases, the volume fraction in each\npatch contributing to volume conservation throughout the domain can be kept in\nhigh accuracy down to machine precisions. Applications that could benefit from\nthe method include volume tracking and multiphase flow modeling.",
    "descriptor": "",
    "authors": [
      "Alfa Heryudono",
      "Mehdi Raessi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.09614"
  },
  {
    "id": "arXiv:2207.09615",
    "title": "Overlooked factors in concept-based explanations: Dataset choice,  concept salience, and human capability",
    "abstract": "Concept-based interpretability methods aim to explain deep neural network\nmodel predictions using a predefined set of semantic concepts. These methods\nevaluate a trained model on a new, \"probe\" dataset and correlate model\npredictions with the visual concepts labeled in that dataset. Despite their\npopularity, they suffer from limitations that are not well-understood and\narticulated by the literature. In this work, we analyze three commonly\noverlooked factors in concept-based explanations. First, the choice of the\nprobe dataset has a profound impact on the generated explanations. Our analysis\nreveals that different probe datasets may lead to very different explanations,\nand suggests that the explanations are not generalizable outside the probe\ndataset. Second, we find that concepts in the probe dataset are often less\nsalient and harder to learn than the classes they claim to explain, calling\ninto question the correctness of the explanations. We argue that only visually\nsalient concepts should be used in concept-based explanations. Finally, while\nexisting methods use hundreds or even thousands of concepts, our human studies\nreveal a much stricter upper bound of 32 concepts or less, beyond which the\nexplanations are much less practically useful. We make suggestions for future\ndevelopment and analysis of concept-based interpretability methods. Code for\nour analysis and user interface can be found at\n\\url{https://github.com/princetonvisualai/OverlookedFactors}",
    "descriptor": "",
    "authors": [
      "Vikram V. Ramaswamy",
      "Sunnie S. Y. Kim",
      "Ruth Fong",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09615"
  },
  {
    "id": "arXiv:2207.09616",
    "title": "Towards Transmission-Friendly and Robust CNN Models over Cloud and  Device",
    "abstract": "Deploying deep convolutional neural network (CNN) models on ubiquitous\nInternet of Things (IoT) devices has attracted much attention from industry and\nacademia since it greatly facilitates our lives by providing various\nrapid-response services. Due to the limited resources of IoT devices,\ncloud-assisted training of CNN models has become the mainstream. However, most\nexisting related works suffer from a large amount of model parameter\ntransmission and weak model robustness. To this end, this paper proposes a\ncloud-assisted CNN training framework with low model parameter transmission and\nstrong model robustness. In the proposed framework, we first introduce MonoCNN,\nwhich contains only a few learnable filters, and other filters are\nnonlearnable. These nonlearnable filter parameters are generated according to\ncertain rules, i.e., the filter generation function (FGF), and can be saved and\nreproduced by a few random seeds. Thus, the cloud server only needs to send\nthese learnable filters and a few seeds to the IoT device. Compared to\ntransmitting all model parameters, sending several learnable filter parameters\nand seeds can significantly reduce parameter transmission. Then, we investigate\nmultiple FGFs and enable the IoT device to use the FGF to generate multiple\nfilters and combine them into MonoCNN. Thus, MonoCNN is affected not only by\nthe training data but also by the FGF. The rules of the FGF play a role in\nregularizing the MonoCNN, thereby improving its robustness. Experimental\nresults show that compared to state-of-the-art methods, our proposed framework\ncan reduce a large amount of model parameter transfer between the cloud server\nand the IoT device while improving the performance by approximately 2.2% when\ndealing with corrupted data. The code is available at\nhttps://github.com/evoxlos/mono-cnn-pytorch.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Chuntao Ding",
      "Zhichao Lu",
      "Felix Juefei Xu",
      "Vishnu Naresh Boddeti",
      "Yidong Li",
      "Jiannong Cao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.09616"
  },
  {
    "id": "arXiv:2207.09619",
    "title": "Learning Latent Traits for Simulated Cooperative Driving Tasks",
    "abstract": "To construct effective teaming strategies between humans and AI systems in\ncomplex, risky situations requires an understanding of individual preferences\nand behaviors of humans. Previously this problem has been treated in\ncase-specific or data-agnostic ways. In this paper, we build a framework\ncapable of capturing a compact latent representation of the human in terms of\ntheir behavior and preferences based on data from a simulated population of\ndrivers. Our framework leverages, to the extent available, knowledge of\nindividual preferences and types from samples within the population to deploy\ninteraction policies appropriate for specific drivers. We then build a\nlightweight simulation environment, HMIway-env, for modelling one form of\ndistracted driving behavior, and use it to generate data for different driver\ntypes and train intervention policies. We finally use this environment to\nquantify both the ability to discriminate drivers and the effectiveness of\nintervention policies.",
    "descriptor": "",
    "authors": [
      "Jonathan A. DeCastro",
      "Deepak Gopinath",
      "Guy Rosman",
      "Emily Sumner",
      "Shabnam Hakimi",
      "Simon Stent"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2207.09619"
  },
  {
    "id": "arXiv:2207.09622",
    "title": "Natural Thresholding Algorithms for Signal Recovery with Sparsity",
    "abstract": "The algorithms based on the technique of optimal $k$-thresholding (OT) were\nrecently proposed for signal recovery, and they are very different from the\ntraditional family of hard thresholding methods. However, the computational\ncost for OT-based algorithms remains high at the current stage of their\ndevelopment. This stimulates the development of the so-called natural\nthresholding (NT) algorithm and its variants in this paper. The family of NT\nalgorithms is developed through the first-order approximation of the so-called\nregularized optimal $k$-thresholding model, and thus the computational cost for\nthis family of algorithms is significantly lower than that of the OT-based\nalgorithms. The guaranteed performance of NT-type algorithms for signal\nrecovery from noisy measurements is shown under the restricted isometry\nproperty and concavity of the objective function of regularized optimal\n$k$-thresholding model. Empirical results indicate that the NT-type algorithms\nare robust and very comparable to several mainstream algorithms for sparse\nsignal recovery.",
    "descriptor": "",
    "authors": [
      "Yun-Bin Zhao",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.09622"
  },
  {
    "id": "arXiv:2207.09624",
    "title": "Learning from few examples: Classifying sex from retinal images via deep  learning",
    "abstract": "Deep learning has seen tremendous interest in medical imaging, particularly\nin the use of convolutional neural networks (CNNs) for developing automated\ndiagnostic tools. The facility of its non-invasive acquisition makes retinal\nfundus imaging amenable to such automated approaches. Recent work in analyzing\nfundus images using CNNs relies on access to massive data for training and\nvalidation - hundreds of thousands of images. However, data residency and data\nprivacy restrictions stymie the applicability of this approach in medical\nsettings where patient confidentiality is a mandate. Here, we showcase results\nfor the performance of DL on small datasets to classify patient sex from fundus\nimages - a trait thought not to be present or quantifiable in fundus images\nuntil recently. We fine-tune a Resnet-152 model whose last layer has been\nmodified for binary classification. In several experiments, we assess\nperformance in the small dataset context using one private (DOVS) and one\npublic (ODIR) data source. Our models, developed using approximately 2500\nfundus images, achieved test AUC scores of up to 0.72 (95% CI: [0.67, 0.77]).\nThis corresponds to a mere 25% decrease in performance despite a nearly\n1000-fold decrease in the dataset size compared to prior work in the\nliterature. Even with a hard task like sex categorization from retinal images,\nwe find that classification is possible with very small datasets. Additionally,\nwe perform domain adaptation experiments between DOVS and ODIR; explore the\neffect of data curation on training and generalizability; and investigate model\nensembling to maximize CNN classifier performance in the context of small\ndevelopment datasets.",
    "descriptor": "",
    "authors": [
      "Aaron Berk",
      "Gulcenur Ozturan",
      "Parsa Delavari",
      "David Maberley",
      "\u00d6zg\u00fcr Y\u0131lmaz",
      "Ipek Oruc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09624"
  },
  {
    "id": "arXiv:2207.09625",
    "title": "Explicit Image Caption Editing",
    "abstract": "Given an image and a reference caption, the image caption editing task aims\nto correct the misalignment errors and generate a refined caption. However, all\nexisting caption editing works are implicit models, ie, they directly produce\nthe refined captions without explicit connections to the reference captions. In\nthis paper, we introduce a new task: Explicit Caption Editing (ECE). ECE models\nexplicitly generate a sequence of edit operations, and this edit operation\nsequence can translate the reference caption into a refined one. Compared to\nthe implicit editing, ECE has multiple advantages: 1) Explainable: it can trace\nthe whole editing path. 2) Editing Efficient: it only needs to modify a few\nwords. 3) Human-like: it resembles the way that humans perform caption editing,\nand tries to keep original sentence structures. To solve this new task, we\npropose the first ECE model: TIger. TIger is a non-autoregressive\ntransformer-based model, consisting of three modules: Tagger_del, Tagger_add,\nand Inserter. Specifically, Tagger_del decides whether each word should be\npreserved or not, Tagger_add decides where to add new words, and Inserter\npredicts the specific word for adding. To further facilitate ECE research, we\npropose two new ECE benchmarks by re-organizing two existing datasets, dubbed\nCOCO-EE and Flickr30K-EE, respectively. Extensive ablations on both two\nbenchmarks have demonstrated the effectiveness of TIger.",
    "descriptor": "\nComments: ECCV 2022, dataset and code are available at this https URL\n",
    "authors": [
      "Zhen Wang",
      "Long Chen",
      "Wenbo Ma",
      "Guangxing Han",
      "Yulei Niu",
      "Jian Shao",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09625"
  },
  {
    "id": "arXiv:2207.09627",
    "title": "EVHA: Explainable Vision System for Hardware Testing and Assurance -- An  Overview",
    "abstract": "Due to the ever-growing demands for electronic chips in different sectors the\nsemiconductor companies have been mandated to offshore their manufacturing\nprocesses. This unwanted matter has made security and trustworthiness of their\nfabricated chips concerning and caused creation of hardware attacks. In this\ncondition, different entities in the semiconductor supply chain can act\nmaliciously and execute an attack on the design computing layers, from devices\nto systems. Our attack is a hardware Trojan that is inserted during mask\ngeneration/fabrication in an untrusted foundry. The Trojan leaves a footprint\nin the fabricated through addition, deletion, or change of design cells. In\norder to tackle this problem, we propose Explainable Vision System for Hardware\nTesting and Assurance (EVHA) in this work that can detect the smallest possible\nchange to a design in a low-cost, accurate, and fast manner. The inputs to this\nsystem are Scanning Electron Microscopy (SEM) images acquired from the\nIntegrated Circuits (ICs) under examination. The system output is determination\nof IC status in terms of having any defect and/or hardware Trojan through\naddition, deletion, or change in the design cells at the cell-level. This\narticle provides an overview on the design, development, implementation, and\nanalysis of our defense system.",
    "descriptor": "\nComments: Please contact Dr. Shayan Taheri for any questions and/or comments regarding the paper arXiv submission at: \"www.shayan-taheri.com\". The Paper Initial Submission: The ACM Journal on Emerging Technologies in Computing Systems (JETC)\n",
    "authors": [
      "Md Mahfuz Al Hasan",
      "Mohammad Tahsin Mostafiz",
      "Thomas An Le",
      "Jake Julia",
      "Nidish Vashistha",
      "Shayan Taheri",
      "Navid Asadizanjani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09627"
  },
  {
    "id": "arXiv:2207.09629",
    "title": "Perspective Phase Angle Model for Polarimetric 3D Reconstruction",
    "abstract": "Current polarimetric 3D reconstruction methods, including those in the\nwell-established shape from polarization literature, are all developed under\nthe orthographic projection assumption. In the case of a large field of view,\nhowever, this assumption does not hold and may result in significant\nreconstruction errors in methods that make this assumption. To address this\nproblem, we present the perspective phase angle (PPA) model that is applicable\nto perspective cameras. Compared with the orthographic model, the proposed PPA\nmodel accurately describes the relationship between polarization phase angle\nand surface normal under perspective projection. In addition, the PPA model\nmakes it possible to estimate surface normals from only one single-view phase\nangle map and does not suffer from the so-called {\\pi}-ambiguity problem.\nExperiments on real data show that the PPA model is more accurate for surface\nnormal estimation with a perspective camera than the orthographic model.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Guangcheng Chen",
      "Li He",
      "Yisheng Guan",
      "Hong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09629"
  },
  {
    "id": "arXiv:2207.09634",
    "title": "HyperNet: Self-Supervised Hyperspectral Spatial-Spectral Feature  Understanding Network for Hyperspectral Change Detection",
    "abstract": "The fast development of self-supervised learning lowers the bar learning\nfeature representation from massive unlabeled data and has triggered a series\nof research on change detection of remote sensing images. Challenges in\nadapting self-supervised learning from natural images classification to remote\nsensing images change detection arise from difference between the two tasks.\nThe learned patch-level feature representations are not satisfying for the\npixel-level precise change detection. In this paper, we proposed a novel\npixel-level self-supervised hyperspectral spatial-spectral understanding\nnetwork (HyperNet) to accomplish pixel-wise feature representation for\neffective hyperspectral change detection. Concretely, not patches but the whole\nimages are fed into the network and the multi-temporal spatial-spectral\nfeatures are compared pixel by pixel. Instead of processing the two-dimensional\nimaging space and spectral response dimension in hybrid style, a powerful\nspatial-spectral attention module is put forward to explore the spatial\ncorrelation and discriminative spectral features of multi-temporal\nhyperspectral images (HSIs), separately. Only the positive samples at the same\nlocation of bi-temporal HSIs are created and forced to be aligned, aiming at\nlearning the spectral difference-invariant features. Moreover, a new similarity\nloss function named focal cosine is proposed to solve the problem of imbalanced\neasy and hard positive samples comparison, where the weights of those hard\nsamples are enlarged and highlighted to promote the network training. Six\nhyperspectral datasets have been adopted to test the validity and\ngeneralization of proposed HyperNet. The extensive experiments demonstrate the\nsuperiority of HyperNet over the state-of-the-art algorithms on downstream\nhyperspectral change detection tasks.",
    "descriptor": "\nComments: 14 pages, 17 figures\n",
    "authors": [
      "Meiqi Hu",
      "Chen Wu",
      "Liangpei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09634"
  },
  {
    "id": "arXiv:2207.09638",
    "title": "Doge Tickets: Uncovering Domain-general Language Models by Playing  Lottery Tickets",
    "abstract": "Over-parameterized models, typically pre-trained language models (LMs), have\nshown an appealing expressive power due to their small learning bias. However,\nthe huge learning capacity of LMs can also lead to large learning variance. In\na pilot study, we find that, when faced with multiple domains, a critical\nportion of parameters behave unexpectedly in a domain-specific manner while\nothers behave in a domain-general one. Motivated by this phenomenon, we for the\nfirst time posit that domain-general parameters can underpin a domain-general\nLM that can be derived from the original LM. To uncover the domain-general LM,\nwe propose to identify domain-general parameters by playing lottery tickets\n(dubbed doge tickets). In order to intervene the lottery, we propose a\ndomain-general score, which depicts how domain-invariant a parameter is by\nassociating it with the variance. Comprehensive experiments are conducted on\nthe Amazon, Mnli and OntoNotes datasets. The results show that the doge tickets\nobtains an improved out-of-domain generalization in comparison with a range of\ncompetitive baselines. Analysis results further hint the existence of\ndomain-general parameters and the performance consistency of doge tickets.",
    "descriptor": "\nComments: Accepted to NLPCC 2022. Code is available at this https URL\n",
    "authors": [
      "Yi Yang",
      "Chen Zhang",
      "Benyou Wang",
      "Dawei Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09638"
  },
  {
    "id": "arXiv:2207.09639",
    "title": "DC-BENCH: Dataset Condensation Benchmark",
    "abstract": "Dataset Condensation is a newly emerging technique aiming at learning a tiny\ndataset that captures the rich information encoded in the original dataset. As\nthe size of datasets contemporary machine learning models rely on becomes\nincreasingly large, condensation methods become a prominent direction for\naccelerating network training and reducing data storage. Despite numerous\nmethods have been proposed in this rapidly growing field, evaluating and\ncomparing different condensation methods is non-trivial and still remains an\nopen issue. The quality of condensed dataset are often shadowed by many\ncritical contributing factors to the end performance, such as data augmentation\nand model architectures. The lack of a systematic way to evaluate and compare\ncondensation methods not only hinders our understanding of existing techniques,\nbut also discourages practical usage of the synthesized datasets. This work\nprovides the first large-scale standardized benchmark on Dataset Condensation.\nIt consists of a suite of evaluations to comprehensively reflect the\ngenerability and effectiveness of condensation methods through the lens of\ntheir generated dataset. Leveraging this benchmark, we conduct a large-scale\nstudy of current condensation methods, and report many insightful findings that\nopen up new possibilities for future development. The benchmark library,\nincluding evaluators, baseline methods, and generated datasets, is open-sourced\nto facilitate future research and application.",
    "descriptor": "",
    "authors": [
      "Justin Cui",
      "Ruochen Wang",
      "Si Si",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09639"
  },
  {
    "id": "arXiv:2207.09640",
    "title": "Test-Time Adaptation via Conjugate Pseudo-labels",
    "abstract": "Test-time adaptation (TTA) refers to adapting neural networks to distribution\nshifts, with access to only the unlabeled test samples from the new domain at\ntest-time. Prior TTA methods optimize over unsupervised objectives such as the\nentropy of model predictions in TENT [Wang et al., 2021], but it is unclear\nwhat exactly makes a good TTA loss. In this paper, we start by presenting a\nsurprising phenomenon: if we attempt to meta-learn the best possible TTA loss\nover a wide class of functions, then we recover a function that is remarkably\nsimilar to (a temperature-scaled version of) the softmax-entropy employed by\nTENT. This only holds, however, if the classifier we are adapting is trained\nvia cross-entropy; if trained via squared loss, a different best TTA loss\nemerges. To explain this phenomenon, we analyze TTA through the lens of the\ntraining losses's convex conjugate. We show that under natural conditions, this\n(unsupervised) conjugate function can be viewed as a good local approximation\nto the original supervised loss and indeed, it recovers the best losses found\nby meta-learning. This leads to a generic recipe that can be used to find a\ngood TTA loss for any given supervised training loss function of a general\nclass. Empirically, our approach consistently dominates other baselines over a\nwide range of benchmarks. Our approach is particularly of interest when applied\nto classifiers trained with novel loss functions, e.g., the recently-proposed\nPolyLoss, where it differs substantially from (and outperforms) an\nentropy-based loss. Further, we show that our approach can also be interpreted\nas a kind of self-training using a very specific soft label, which we refer to\nas the conjugate pseudolabel. Overall, our method provides a broad framework\nfor better understanding and improving test-time adaptation. Code is available\nat https://github.com/locuslab/tta_conjugate.",
    "descriptor": "\nComments: 19 Pages, Under Review\n",
    "authors": [
      "Sachin Goyal",
      "Mingjie Sun",
      "Aditi Raghunathan",
      "Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09640"
  },
  {
    "id": "arXiv:2207.09643",
    "title": "Integrating Linguistic Theory and Neural Language Models",
    "abstract": "Transformer-based language models have recently achieved remarkable results\nin many natural language tasks. However, performance on leaderboards is\ngenerally achieved by leveraging massive amounts of training data, and rarely\nby encoding explicit linguistic knowledge into neural models. This has led many\nto question the relevance of linguistics for modern natural language\nprocessing. In this dissertation, I present several case studies to illustrate\nhow theoretical linguistics and neural language models are still relevant to\neach other. First, language models are useful to linguists by providing an\nobjective tool to measure semantic distance, which is difficult to do using\ntraditional methods. On the other hand, linguistic theory contributes to\nlanguage modelling research by providing frameworks and sources of data to\nprobe our language models for specific aspects of language understanding.\nThis thesis contributes three studies that explore different aspects of the\nsyntax-semantics interface in language models. In the first part of my thesis,\nI apply language models to the problem of word class flexibility. Using mBERT\nas a source of semantic distance measurements, I present evidence in favour of\nanalyzing word class flexibility as a directional process. In the second part\nof my thesis, I propose a method to measure surprisal at intermediate layers of\nlanguage models. My experiments show that sentences containing morphosyntactic\nanomalies trigger surprisals earlier in language models than semantic and\ncommonsense anomalies. Finally, in the third part of my thesis, I adapt several\npsycholinguistic studies to show that language models contain knowledge of\nargument structure constructions. In summary, my thesis develops new\nconnections between natural language processing, linguistic theory, and\npsycholinguistics to provide fresh perspectives for the interpretation of\nlanguage models.",
    "descriptor": "\nComments: PhD dissertation\n",
    "authors": [
      "Bai Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.09643"
  },
  {
    "id": "arXiv:2207.09644",
    "title": "Hierarchically Self-Supervised Transformer for Human Skeleton  Representation Learning",
    "abstract": "Despite the success of fully-supervised human skeleton sequence modeling,\nutilizing self-supervised pre-training for skeleton sequence representation\nlearning has been an active field because acquiring task-specific skeleton\nannotations at large scales is difficult. Recent studies focus on learning\nvideo-level temporal and discriminative information using contrastive learning,\nbut overlook the hierarchical spatial-temporal nature of human skeletons.\nDifferent from such superficial supervision at the video level, we propose a\nself-supervised hierarchical pre-training scheme incorporated into a\nhierarchical Transformer-based skeleton sequence encoder (Hi-TRS), to\nexplicitly capture spatial, short-term, and long-term temporal dependencies at\nframe, clip, and video levels, respectively. To evaluate the proposed\nself-supervised pre-training scheme with Hi-TRS, we conduct extensive\nexperiments covering three skeleton-based downstream tasks including action\nrecognition, action detection, and motion prediction. Under both supervised and\nsemi-supervised evaluation protocols, our method achieves the state-of-the-art\nperformance. Additionally, we demonstrate that the prior knowledge learned by\nour model in the pre-training stage has strong transfer capability for\ndifferent downstream tasks.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Yuxiao Chen",
      "Long Zhao",
      "Jianbo Yuan",
      "Yu Tian",
      "Zhaoyang Xia",
      "Shijie Geng",
      "Ligong Han",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09644"
  },
  {
    "id": "arXiv:2207.09645",
    "title": "Downwash-aware Control Allocation for Over-actuated UAV Platforms",
    "abstract": "Tracking position and orientation independently affords more agile maneuver\nfor over-actuated multirotor Unmanned Aerial Vehicles (UAVs) while introducing\nundesired downwash effects; downwash flows generated by thrust generators may\ncounteract others due to close proximity, which significantly threatens the\nstability of the platform. The complexity of modeling aerodynamic airflow\nchallenges control algorithms from properly compensating for such a side\neffect. Leveraging the input redundancies in over-actuated UAVs, we tackle this\nissue with a novel control allocation framework that considers downwash effects\nand explores the entire allocation space for an optimal solution. This optimal\nsolution avoids downwash effects while providing high thrust efficiency within\nthe hardware constraints. To the best of our knowledge, ours is the first\nformal derivation to investigate the downwash effects on over-actuated UAVs. We\nverify our framework on different hardware configurations in both simulation\nand experiment.",
    "descriptor": "",
    "authors": [
      "Yao Su",
      "Chi Chu",
      "Meng Wang",
      "Jiarui Li",
      "Liu Yang",
      "Yixin Zhu",
      "Hangxin Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.09645"
  },
  {
    "id": "arXiv:2207.09646",
    "title": "Aware of the History: Trajectory Forecasting with the Local Behavior  Data",
    "abstract": "The historical trajectories previously passing through a location may help\ninfer the future trajectory of an agent currently at this location. Despite\ngreat improvements in trajectory forecasting with the guidance of\nhigh-definition maps, only a few works have explored such local historical\ninformation. In this work, we re-introduce this information as a new type of\ninput data for trajectory forecasting systems: the local behavior data, which\nwe conceptualize as a collection of location-specific historical trajectories.\nLocal behavior data helps the systems emphasize the prediction locality and\nbetter understand the impact of static map objects on moving agents. We propose\na novel local-behavior-aware (LBA) prediction framework that improves\nforecasting accuracy by fusing information from observed trajectories, HD maps,\nand local behavior data. Also, where such historical data is insufficient or\nunavailable, we employ a local-behavior-free (LBF) prediction framework, which\nadopts a knowledge-distillation-based architecture to infer the impact of\nmissing data. Extensive experiments demonstrate that upgrading existing methods\nwith these two frameworks significantly improves their performances.\nEspecially, the LBA framework boosts the SOTA methods' performance on the\nnuScenes dataset by at least 14% for the K=1 metrics.",
    "descriptor": "\nComments: This paper has been accepted by ECCV 2022\n",
    "authors": [
      "Yiqi Zhong",
      "Zhenyang Ni",
      "Siheng Chen",
      "Ulrich Neumann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09646"
  },
  {
    "id": "arXiv:2207.09648",
    "title": "Roadmap Towards Responsible AI in Crisis Resilience Management",
    "abstract": "Novel data sensing and AI technologies are finding practical use in the\nanalysis of crisis resilience, revealing the need to consider how responsible\nartificial intelligence (AI) practices can mitigate harmful outcomes and\nprotect vulnerable populations. In this opinion paper, we present a responsible\nAI roadmap that is embedded in the Crisis Information Management Circle. This\nroadmap includes six propositions to highlight and address important challenges\nand considerations specifically related to responsible AI for crisis resilience\nmanagement. We cover a wide spectrum of interwoven challenges and\nconsiderations pertaining to the responsible collection, analysis, sharing and\nuse of information such as equity, fairness, biases, explainability and\ntransparency, accountability, privacy, inter-organizational coordination, and\npublic engagement. Through examining issues around AI systems for crisis\nresilience management, we dissect the inherent complexities of information\nmanagement and decision-making in crises and highlight the urgency of\nresponsible AI research and practice. The ideas laid out in this opinion paper\nare the first attempt in establishing a roadmap for researchers, practitioners,\ndevelopers, emergency managers, humanitarian organizations, and public\nofficials to address important considerations for responsible AI pertaining to\ncrisis resilience management.",
    "descriptor": "",
    "authors": [
      "Cheng-Chun Lee",
      "Tina Comes",
      "Megan Finn",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09648"
  },
  {
    "id": "arXiv:2207.09649",
    "title": "GenText: Unsupervised Artistic Text Generation via Decoupled Font and  Texture Manipulation",
    "abstract": "Automatic artistic text generation is an emerging topic which receives\nincreasing attention due to its wide applications. The artistic text can be\ndivided into three components, content, font, and texture, respectively.\nExisting artistic text generation models usually focus on manipulating one\naspect of the above components, which is a sub-optimal solution for\ncontrollable general artistic text generation. To remedy this issue, we propose\na novel approach, namely GenText, to achieve general artistic text style\ntransfer by separably migrating the font and texture styles from the different\nsource images to the target images in an unsupervised manner. Specifically, our\ncurrent work incorporates three different stages, stylization, destylization,\nand font transfer, respectively, into a unified platform with a single powerful\nencoder network and two separate style generator networks, one for font\ntransfer, the other for stylization and destylization. The destylization stage\nfirst extracts the font style of the font reference image, then the font\ntransfer stage generates the target content with the desired font style.\nFinally, the stylization stage renders the resulted font image with respect to\nthe texture style in the reference image. Moreover, considering the difficult\ndata acquisition of paired artistic text images, our model is designed under\nthe unsupervised setting, where all stages can be effectively optimized from\nunpaired data. Qualitative and quantitative results are performed on artistic\ntext benchmarks, which demonstrate the superior performance of our proposed\nmodel. The code with models will become publicly available in the future.",
    "descriptor": "",
    "authors": [
      "Qirui Huang",
      "Bin Fu",
      "Aozhong zhang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09649"
  },
  {
    "id": "arXiv:2207.09650",
    "title": "Task Allocation using a Team of Robots",
    "abstract": "Task allocation using a team or coalition of robots is one of the most\nimportant problems in robotics, computer science, operational research, and\nartificial intelligence. In recent work, research has focused on handling\ncomplex objectives and feasibility constraints amongst other variations of the\nmulti-robot task allocation problem. There are many examples of important\nresearch progress in these directions. We present a general formulation of the\ntask allocation problem that generalizes several versions that are\nwell-studied. Our formulation includes the states of robots, tasks, and the\nsurrounding environment in which they operate. We describe how the problem can\nvary depending on the feasibility constraints, objective functions, and the\nlevel of dynamically changing information. In addition, we discuss existing\nsolution approaches for the problem including optimization-based approaches,\nand market-based approaches.",
    "descriptor": "\nComments: Accepted for publication in the journal Current Robotics Reports\n",
    "authors": [
      "Haris Aziz",
      "Arindam Pal",
      "Ali Pourmiri",
      "Fahimeh Ramezani",
      "Brendan Sims"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2207.09650"
  },
  {
    "id": "arXiv:2207.09653",
    "title": "FedDM: Iterative Distribution Matching for Communication-Efficient  Federated Learning",
    "abstract": "Federated learning~(FL) has recently attracted increasing attention from\nacademia and industry, with the ultimate goal of achieving collaborative\ntraining under privacy and communication constraints. Existing iterative model\naveraging based FL algorithms require a large number of communication rounds to\nobtain a well-performed model due to extremely unbalanced and non-i.i.d data\npartitioning among different clients. Thus, we propose FedDM to build the\nglobal training objective from multiple local surrogate functions, which\nenables the server to gain a more global view of the loss landscape. In detail,\nwe construct synthetic sets of data on each client to locally match the loss\nlandscape from original data through distribution matching. FedDM reduces\ncommunication rounds and improves model quality by transmitting more\ninformative and smaller synthesized data compared with unwieldy model weights.\nWe conduct extensive experiments on three image classification datasets, and\nresults show that our method can outperform other FL counterparts in terms of\nefficiency and model performance. Moreover, we demonstrate that FedDM can be\nadapted to preserve differential privacy with Gaussian mechanism and train a\nbetter model under the same privacy budget.",
    "descriptor": "",
    "authors": [
      "Yuanhao Xiong",
      "Ruochen Wang",
      "Minhao Cheng",
      "Felix Yu",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.09653"
  },
  {
    "id": "arXiv:2207.09654",
    "title": "Learning Topological Interactions for Multi-Class Medical Image  Segmentation",
    "abstract": "Deep learning methods have achieved impressive performance for multi-class\nmedical image segmentation. However, they are limited in their ability to\nencode topological interactions among different classes (e.g., containment and\nexclusion). These constraints naturally arise in biomedical images and can be\ncrucial in improving segmentation quality. In this paper, we introduce a novel\ntopological interaction module to encode the topological interactions into a\ndeep neural network. The implementation is completely convolution-based and\nthus can be very efficient. This empowers us to incorporate the constraints\ninto end-to-end training and enrich the feature representation of neural\nnetworks. The efficacy of the proposed method is validated on different types\nof interactions. We also demonstrate the generalizability of the method on both\nproprietary and public challenge datasets, in both 2D and 3D settings, as well\nas across different modalities such as CT and Ultrasound. Code is available at:\nhttps://github.com/TopoXLab/TopoInteraction",
    "descriptor": "\nComments: Accepted to ECCV 2022 (Oral); 32 pages, 19 figures\n",
    "authors": [
      "Saumya Gupta",
      "Xiaoling Hu",
      "James Kaan",
      "Michael Jin",
      "Mutshipay Mpoy",
      "Katherine Chung",
      "Gagandeep Singh",
      "Mary Saltz",
      "Tahsin Kurc",
      "Joel Saltz",
      "Apostolos Tassiopoulos",
      "Prateek Prasanna",
      "Chao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09654"
  },
  {
    "id": "arXiv:2207.09655",
    "title": "How can I improve my scientific impact? The most influential factors in  predicting the h-index",
    "abstract": "Evaluation of researchers' output is vital for hiring committees and funding\nbodies, and it is usually measured via their scientific productivity,\ncitations, or a combined metric such as h-index. Assessing young researchers is\nmore critical because it takes a while to get citations and increment of\nh-index. Hence, predicting the h-index can help to discover the researchers'\nscientific impact. In addition, identifying the influential factors to predict\nthe scientific impact is helpful for researchers seeking solutions to improve\nit. This study investigates the effect of author, paper and venue-specific\nfeatures on the future h-index. For this purpose, we used machine learning\nmethods to predict the h-index and feature analysis techniques to advance the\nunderstanding of feature impact. Utilizing the bibliometric data in Scopus, we\ndefined and extracted two main groups of features. The first relates to prior\nscientific impact, and we name it 'prior impact-based features' and includes\nthe number of publications, received citations, and h-index. The second group\nis 'non-impact-based features' and contains the features related to author,\nco-authorship, paper, and venue characteristics. We explored their importance\nin predicting h-index for researchers in three different career phases. Also,\nwe examine the temporal dimension of predicting performance for different\nfeature categories to find out which features are more reliable for long- and\nshort-term prediction. We referred to the gender of the authors to examine the\nrole of this author's characteristics in the prediction task. Our findings\nshowed that gender has a very slight effect in predicting the h-index. We found\nthat non-impact-based features are more robust predictors for younger scholars\nthan seniors in the short term. Also, prior impact-based features lose their\npower to predict more than other features in the long-term.",
    "descriptor": "",
    "authors": [
      "Fakhri Momeni",
      "Philip Mayr",
      "Stefan Dietze"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2207.09655"
  },
  {
    "id": "arXiv:2207.09656",
    "title": "Unsupervised Domain Adaptation for One-stage Object Detector using  Offsets to Bounding Box",
    "abstract": "Most existing domain adaptive object detection methods exploit adversarial\nfeature alignment to adapt the model to a new domain. Recent advances in\nadversarial feature alignment strives to reduce the negative effect of\nalignment, or negative transfer, that occurs because the distribution of\nfeatures varies depending on the category of objects. However, by analyzing the\nfeatures of the anchor-free one-stage detector, in this paper, we find that\nnegative transfer may occur because the feature distribution varies depending\non the regression value for the offset to the bounding box as well as the\ncategory. To obtain domain invariance by addressing this issue, we align the\nfeature conditioned on the offset value, considering the modality of the\nfeature distribution. With a very simple and effective conditioning method, we\npropose OADA (Offset-Aware Domain Adaptive object detector) that achieves\nstate-of-the-art performances in various experimental settings. In addition, by\nanalyzing through singular value decomposition, we find that our model enhances\nboth discriminability and transferability.",
    "descriptor": "\nComments: ECCV 2022, 24 pages\n",
    "authors": [
      "Jayeon Yoo",
      "Inseop Chung",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09656"
  },
  {
    "id": "arXiv:2207.09657",
    "title": "Multigraph Topology Design for Cross-Silo Federated Learning",
    "abstract": "Cross-silo federated learning utilizes a few hundred reliable data silos with\nhigh-speed access links to jointly train a model. While this approach becomes a\npopular setting in federated learning, designing a robust topology to reduce\nthe training time is still an open problem. In this paper, we present a new\nmultigraph topology for cross-silo federated learning. We first construct the\nmultigraph using the overlay graph. We then parse this multigraph into\ndifferent simple graphs with isolated nodes. The existence of isolated nodes\nallows us to perform model aggregation without waiting for other nodes, hence\nreducing the training time. We further propose a new distributed learning\nalgorithm to use with our multigraph topology. The intensive experiments on\npublic datasets show that our proposed method significantly reduces the\ntraining time compared with recent state-of-the-art topologies while ensuring\nconvergence and maintaining the model's accuracy.",
    "descriptor": "",
    "authors": [
      "Binh X. Nguyen",
      "Tuong Do",
      "Hien Nguyen",
      "Vuong Pham",
      "Toan Tran",
      "Erman Tjiputra",
      "Quang Tran",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.09657"
  },
  {
    "id": "arXiv:2207.09658",
    "title": "Learning Depth from Focus in the Wild",
    "abstract": "For better photography, most recent commercial cameras including smartphones\nhave either adopted large-aperture lens to collect more light or used a burst\nmode to take multiple images within short times. These interesting features\nlead us to examine depth from focus/defocus.\nIn this work, we present a convolutional neural network-based depth\nestimation from single focal stacks. Our method differs from relevant\nstate-of-the-art works with three unique features. First, our method allows\ndepth maps to be inferred in an end-to-end manner even with image alignment.\nSecond, we propose a sharp region detection module to reduce blur ambiguities\nin subtle focus changes and weakly texture-less regions. Third, we design an\neffective downsampling module to ease flows of focal information in feature\nextractions. In addition, for the generalization of the proposed network, we\ndevelop a simulator to realistically reproduce the features of commercial\ncameras, such as changes in field of view, focal length and principal points.\nBy effectively incorporating these three unique features, our network\nachieves the top rank in the DDFF 12-Scene benchmark on most metrics. We also\ndemonstrate the effectiveness of the proposed method on various quantitative\nevaluations and real-world images taken from various off-the-shelf cameras\ncompared with state-of-the-art methods. Our source code is publicly available\nat https://github.com/wcy199705/DfFintheWild.",
    "descriptor": "",
    "authors": [
      "Changyeon Won",
      "Hae-Gon Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09658"
  },
  {
    "id": "arXiv:2207.09661",
    "title": "Hand-Assisted Expression Recognition Method from Synthetic Images at the  Fourth ABAW Challenge",
    "abstract": "Learning from synthetic images plays an important role in facial expression\nrecognition task due to the difficulties of labeling the real images, and it is\nchallenging because of the gap between the synthetic images and real images.\nThe fourth Affective Behavior Analysis in-the-wild Competition raises the\nchallenge and provides the synthetic images generated from Aff-Wild2 dataset.\nIn this paper, we propose a hand-assisted expression recognition method to\nreduce the gap between the synthetic data and real data. Our method consists of\ntwo parts: expression recognition module and hand prediction module. Expression\nrecognition module extracts expression information and hand prediction module\npredicts whether the image contains hands. Decision mode is used to combine the\nresults of two modules, and post-pruning is used to improve the result. F1\nscore is used to verify the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Xiangyu Miao",
      "Jiahe Wang",
      "Yanan Chang",
      "Yi Wu",
      "Shangfei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09661"
  },
  {
    "id": "arXiv:2207.09662",
    "title": "HTNet: Anchor-free Temporal Action Localization with Hierarchical  Transformers",
    "abstract": "Temporal action localization (TAL) is a task of identifying a set of actions\nin a video, which involves localizing the start and end frames and classifying\neach action instance. Existing methods have addressed this task by using\npredefined anchor windows or heuristic bottom-up boundary-matching strategies,\nwhich are major bottlenecks in inference time. Additionally, the main challenge\nis the inability to capture long-range actions due to a lack of global\ncontextual information. In this paper, we present a novel anchor-free\nframework, referred to as HTNet, which predicts a set of <start time, end time,\nclass> triplets from a video based on a Transformer architecture. After the\nprediction of coarse boundaries, we refine it through a background feature\nsampling (BFS) module and hierarchical Transformers, which enables our model to\naggregate global contextual information and effectively exploit the inherent\nsemantic relationships in a video. We demonstrate how our method localizes\naccurate action instances and achieves state-of-the-art performance on two TAL\nbenchmark datasets: THUMOS14 and ActivityNet 1.3.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Tae-Kyung Kang",
      "Gun-Hee Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09662"
  },
  {
    "id": "arXiv:2207.09663",
    "title": "Streamable Neural Fields",
    "abstract": "Neural fields have emerged as a new data representation paradigm and have\nshown remarkable success in various signal representations. Since they preserve\nsignals in their network parameters, the data transfer by sending and receiving\nthe entire model parameters prevents this emerging technology from being used\nin many practical scenarios. We propose streamable neural fields, a single\nmodel that consists of executable sub-networks of various widths. The proposed\narchitectural and training techniques enable a single network to be streamable\nover time and reconstruct different qualities and parts of signals. For\nexample, a smaller sub-network produces smooth and low-frequency signals, while\na larger sub-network can represent fine details. Experimental results have\nshown the effectiveness of our method in various domains, such as 2D images,\nvideos, and 3D signed distance functions. Finally, we demonstrate that our\nproposed method improves training stability, by exploiting parameter sharing.",
    "descriptor": "\nComments: To appear in ECCV 2022\n",
    "authors": [
      "Junwoo Cho",
      "Seungtae Nam",
      "Daniel Rho",
      "Jong Hwan Ko",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09663"
  },
  {
    "id": "arXiv:2207.09664",
    "title": "Pseudo-label Guided Cross-video Pixel Contrast for Robotic Surgical  Scene Segmentation with Limited Annotations",
    "abstract": "Surgical scene segmentation is fundamentally crucial for prompting cognitive\nassistance in robotic surgery. However, pixel-wise annotating surgical video in\na frame-by-frame manner is expensive and time consuming. To greatly reduce the\nlabeling burden, in this work, we study semi-supervised scene segmentation from\nrobotic surgical video, which is practically essential yet rarely explored\nbefore. We consider a clinically suitable annotation situation under the\nequidistant sampling. We then propose PGV-CL, a novel pseudo-label guided\ncross-video contrast learning method to boost scene segmentation. It\neffectively leverages unlabeled data for a trusty and global model\nregularization that produces more discriminative feature representation.\nConcretely, for trusty representation learning, we propose to incorporate\npseudo labels to instruct the pair selection, obtaining more reliable\nrepresentation pairs for pixel contrast. Moreover, we expand the representation\nlearning space from previous image-level to cross-video, which can capture the\nglobal semantics to benefit the learning process. We extensively evaluate our\nmethod on a public robotic surgery dataset EndoVis18 and a public cataract\ndataset CaDIS. Experimental results demonstrate the effectiveness of our\nmethod, consistently outperforming the state-of-the-art semi-supervised methods\nunder different labeling ratios, and even surpassing fully supervised training\non EndoVis18 with 10.1% labeling.",
    "descriptor": "\nComments: Accepted by IROS 2022\n",
    "authors": [
      "Yang Yu",
      "Zixu Zhao",
      "Yueming Jin",
      "Guangyong Chen",
      "Qi Dou",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09664"
  },
  {
    "id": "arXiv:2207.09666",
    "title": "GRIT: Faster and Better Image captioning Transformer Using Dual Visual  Features",
    "abstract": "Current state-of-the-art methods for image captioning employ region-based\nfeatures, as they provide object-level information that is essential to\ndescribe the content of images; they are usually extracted by an object\ndetector such as Faster R-CNN. However, they have several issues, such as lack\nof contextual information, the risk of inaccurate detection, and the high\ncomputational cost. The first two could be resolved by additionally using\ngrid-based features. However, how to extract and fuse these two types of\nfeatures is uncharted. This paper proposes a Transformer-only neural\narchitecture, dubbed GRIT (Grid- and Region-based Image captioning\nTransformer), that effectively utilizes the two visual features to generate\nbetter captions. GRIT replaces the CNN-based detector employed in previous\nmethods with a DETR-based one, making it computationally faster. Moreover, its\nmonolithic design consisting only of Transformers enables end-to-end training\nof the model. This innovative design and the integration of the dual visual\nfeatures bring about significant performance improvement. The experimental\nresults on several image captioning benchmarks show that GRIT outperforms\nprevious methods in inference accuracy and speed.",
    "descriptor": "\nComments: Accepted to ECCV 2022; 14 pages with appendix; Code: this https URL\n",
    "authors": [
      "Van-Quang Nguyen",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.09666"
  },
  {
    "id": "arXiv:2207.09667",
    "title": "Generalizable and Robust Deep Learning Algorithm for Atrial Fibrillation  Diagnosis Across Ethnicities, Ages and Sexes",
    "abstract": "To drive health innovation that meets the needs of all and democratize\nhealthcare, there is a need to assess the generalization performance of deep\nlearning (DL) algorithms across various distribution shifts to ensure that\nthese algorithms are robust. This retrospective study is, to the best of our\nknowledge, the first to develop and assess the generalization performance of a\ndeep learning (DL) model for AF events detection from long term beat-to-beat\nintervals across ethnicities, ages and sexes. The new recurrent DL model,\ndenoted ArNet2, was developed on a large retrospective dataset of 2,147\npatients totaling 51,386 hours of continuous electrocardiogram (ECG). The\nmodels generalization was evaluated on manually annotated test sets from four\ncenters (USA, Israel, Japan and China) totaling 402 patients. The model was\nfurther validated on a retrospective dataset of 1,730 consecutives Holter\nrecordings from the Rambam Hospital Holter clinic, Haifa, Israel. The model\noutperformed benchmark state-of-the-art models and generalized well across\nethnicities, ages and sexes. Performance was higher for female than male and\nyoung adults (less than 60 years old) and showed some differences across\nethnicities. The main finding explaining these variations was an impairment in\nperformance in groups with a higher prevalence of atrial flutter (AFL). Our\nfindings on the relative performance of ArNet2 across groups may have clinical\nimplications on the choice of the preferred AF examination method to use\nrelative to the group of interest.",
    "descriptor": "",
    "authors": [
      "Shany Biton",
      "Mohsin Aldhafeeri",
      "Erez Marcusohn",
      "Kenta Tsutsui",
      "Tom Szwagier",
      "Adi Elias",
      "Julien Oster",
      "Jean Marc Sellal",
      "Mahmoud Suleiman",
      "Joachim A. Behar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2207.09667"
  },
  {
    "id": "arXiv:2207.09669",
    "title": "Efficient Dependency Analysis for Rule-Based Ontologies",
    "abstract": "Several types of dependencies have been proposed for the static analysis of\nexistential rule ontologies, promising insights about computational properties\nand possible practical uses of a given set of rules, e.g., in ontology-based\nquery answering. Unfortunately, these dependencies are rarely implemented, so\ntheir potential is hardly realised in practice. We focus on two kinds of rule\ndependencies -- positive reliances and restraints -- and design and implement\noptimised algorithms for their efficient computation. Experiments on real-world\nontologies of up to more than 100,000 rules show the scalability of our\napproach, which lets us realise several previously proposed applications as\npractical case studies. In particular, we can analyse to what extent rule-based\nbottom-up approaches of reasoning can be guaranteed to yield redundancy-free\n\"lean\" knowledge graphs (so-called cores) on practical ontologies.",
    "descriptor": "\nComments: Extended report of our ISWC 2022 paper\n",
    "authors": [
      "Larry Gonz\u00e1lez",
      "Alex Ivliev",
      "Markus Kr\u00f6tzsch",
      "Stephan Mennicke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.09669"
  },
  {
    "id": "arXiv:2207.09670",
    "title": "Optimal Path Planning for Connected and Automated Vehicles in Lane-free  Traffic with Vehicle Nudging",
    "abstract": "The paper presents a movement strategy for Connected and Automated Vehicles\n(CAVs) in a lane-free traffic environment with vehicle nudging by use of an\noptimal control approach. State-dependent constraints on control inputs are\nconsidered to ensure that the vehicle moves within the road boundaries and to\nprevent collisions. An objective function, comprising various sub-objectives,\nis designed, whose minimization leads to vehicle advancement at the desired\nspeed, whenever possible, while avoiding obstacles. A nonlinear optimal control\nproblem (OCP) is formulated for the minimization of the objective function\nsubject to constraints for each vehicle. A computationally efficient Feasible\nDirection Algorithm (FDA) is called, on event-triggered basis, to compute in\nreal time the numerical solution for finite time horizons within a Model\nPredictive Control (MPC) framework. The approach is applied to each vehicle on\nthe road, while running simulations on a lane-free ring-road, for a wide range\nof vehicle densities and different types of vehicles. From the simulations,\nwhich create countless driving episodes for each involved vehicle, it is\nobserved that the proposed approach is highly efficient in delivering safe,\ncomfortable and efficient vehicle trajectories, as well as high traffic flow\noutcomes. The approach is under investigation for further use in various\nlane-free road infrastructures for CAV traffic.",
    "descriptor": "",
    "authors": [
      "Venkata Karteek Yanumula",
      "Panagiotis Typaldos",
      "Dimitrios Troullinos",
      "Milad Malekzadeh",
      "Ioannis Papamichail",
      "Markos Papageorgiou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.09670"
  },
  {
    "id": "arXiv:2207.09672",
    "title": "Duplicate Detection as a Service",
    "abstract": "Completeness of a knowledge graph is an important quality dimension and\nfactor on how well an application that makes use of it performs. Completeness\ncan be improved by performing knowledge enrichment. Duplicate detection aims to\nfind identity links between the instances of knowledge graphs and is a\nfundamental subtask of knowledge enrichment. Current solutions to the problem\nrequire expert knowledge of the tool and the knowledge graph they are applied\nto. Users might not have this expert knowledge. We present our service-based\napproach to the duplicate detection task that provides an easy-to-use no-code\nsolution that is still competitive with the state-of-the-art and has recently\nbeen adopted in an industrial context. The evaluation will be based on several\nfrequently used test scenarios.",
    "descriptor": "",
    "authors": [
      "Juliette Opdenplatz",
      "Umutcan \u015eim\u015fek",
      "Dieter Fensel"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.09672"
  },
  {
    "id": "arXiv:2207.09674",
    "title": "Improving Data Driven Inverse Text Normalization using Data Augmentation",
    "abstract": "Inverse text normalization (ITN) is used to convert the spoken form output of\nan automatic speech recognition (ASR) system to a written form. Traditional\nhandcrafted ITN rules can be complex to transcribe and maintain. Meanwhile\nneural modeling approaches require quality large-scale spoken-written pair\nexamples in the same or similar domain as the ASR system (in-domain data), to\ntrain. Both these approaches require costly and complex annotations. In this\npaper, we present a data augmentation technique that effectively generates rich\nspoken-written numeric pairs from out-of-domain textual data with minimal human\nannotation. We empirically demonstrate that ITN model trained using our data\naugmentation technique consistently outperform ITN model trained using only\nin-domain data across all numeric surfaces like cardinal, currency, and\nfraction, by an overall accuracy of 14.44%.",
    "descriptor": "",
    "authors": [
      "Laxmi Pandey",
      "Debjyoti Paul",
      "Pooja Chitkara",
      "Yutong Pang",
      "Xuedong Zhang",
      "Kjell Schubert",
      "Mark Chou",
      "Shu Liu",
      "Yatharth Saraf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.09674"
  },
  {
    "id": "arXiv:2207.09675",
    "title": "ERA: Expert Retrieval and Assembly for Early Action Prediction",
    "abstract": "Early action prediction aims to successfully predict the class label of an\naction before it is completely performed. This is a challenging task because\nthe beginning stages of different actions can be very similar, with only minor\nsubtle differences for discrimination. In this paper, we propose a novel Expert\nRetrieval and Assembly (ERA) module that retrieves and assembles a set of\nexperts most specialized at using discriminative subtle differences, to\ndistinguish an input sample from other highly similar samples. To encourage our\nmodel to effectively use subtle differences for early action prediction, we\npush experts to discriminate exclusively between samples that are highly\nsimilar, forcing these experts to learn to use subtle differences that exist\nbetween those samples. Additionally, we design an effective Expert Learning\nRate Optimization method that balances the experts' optimization and leads to\nbetter performance. We evaluate our ERA module on four public action datasets\nand achieve state-of-the-art performance.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Lin Geng Foo",
      "Tianjiao Li",
      "Hossein Rahmani",
      "Qiuhong Ke",
      "Jun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09675"
  },
  {
    "id": "arXiv:2207.09677",
    "title": "Mathematical and numerical analysis to shrinking-dimer saddle dynamics  with local Lipschitz conditions",
    "abstract": "We present a mathematical and numerical investigation to the shrinkingdimer\nsaddle dynamics for finding any-index saddle points in the solution landscape.\nDue to the dimer approximation of Hessian in saddle dynamics, the local\nLipschitz assumptions and the strong nonlinearity for the saddle dynamics, it\nremains challenges for delicate analysis, such as the the boundedness of the\nsolutions and the dimer error. We address these issues to bound the solutions\nunder proper relaxation parameters, based on which we prove the error estimates\nfor numerical discretization to the shrinking-dimer saddle dynamics by matching\nthe dimer length and the time step size. Furthermore, the Richardson\nextrapolation is employed to obtain a high-order approximation.\nThe inherent reason of requiring the matching of the dimer length and the\ntime step size lies in that the former serves a different mesh size from the\nlater, and thus the proposed numerical method is close to a fully-discrete\nnumerical scheme of some spacetime PDE model with the Hessian in the saddle\ndynamics and its dimer approximation serving as a \"spatial operator\" and its\ndiscretization, respectively, which in turn indicates the PDE nature of the\nsaddle dynamics.",
    "descriptor": "",
    "authors": [
      "Lei Zhang",
      "Pingwen Zhang",
      "Xiangcheng Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.09677"
  },
  {
    "id": "arXiv:2207.09679",
    "title": "Explaining Deepfake Detection by Analysing Image Matching",
    "abstract": "This paper aims to interpret how deepfake detection models learn artifact\nfeatures of images when just supervised by binary labels. To this end, three\nhypotheses from the perspective of image matching are proposed as follows. 1.\nDeepfake detection models indicate real/fake images based on visual concepts\nthat are neither source-relevant nor target-relevant, that is, considering such\nvisual concepts as artifact-relevant. 2. Besides the supervision of binary\nlabels, deepfake detection models implicitly learn artifact-relevant visual\nconcepts through the FST-Matching (i.e. the matching fake, source, target\nimages) in the training set. 3. Implicitly learned artifact visual concepts\nthrough the FST-Matching in the raw training set are vulnerable to video\ncompression. In experiments, the above hypotheses are verified among various\nDNNs. Furthermore, based on this understanding, we propose the FST-Matching\nDeepfake Detection Model to boost the performance of forgery detection on\ncompressed videos. Experiment results show that our method achieves great\nperformance, especially on highly-compressed (e.g. c40) videos.",
    "descriptor": "\nComments: Accepted at ECCV 2022, Code is available at: this https URL\n",
    "authors": [
      "Shichao Dong",
      "Jin Wang",
      "Jiajun Liang",
      "Haoqiang Fan",
      "Renhe Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09679"
  },
  {
    "id": "arXiv:2207.09682",
    "title": "Quantized Training of Gradient Boosting Decision Trees",
    "abstract": "Recent years have witnessed significant success in Gradient Boosting Decision\nTrees (GBDT) for a wide range of machine learning applications. Generally, a\nconsensus about GBDT's training algorithms is gradients and statistics are\ncomputed based on high-precision floating points. In this paper, we investigate\nan essentially important question which has been largely ignored by the\nprevious literature: how many bits are needed for representing gradients in\ntraining GBDT? To solve this mystery, we propose to quantize all the\nhigh-precision gradients in a very simple yet effective way in the GBDT's\ntraining algorithm. Surprisingly, both our theoretical analysis and empirical\nstudies show that the necessary precisions of gradients without hurting any\nperformance can be quite low, e.g., 2 or 3 bits. With low-precision gradients,\nmost arithmetic operations in GBDT training can be replaced by integer\noperations of 8, 16, or 32 bits. Promisingly, these findings may pave the way\nfor much more efficient training of GBDT from several aspects: (1) speeding up\nthe computation of gradient statistics in histograms; (2) compressing the\ncommunication cost of high-precision statistical information during distributed\ntraining; (3) the inspiration of utilization and development of hardware\narchitectures which well support low-precision computation for GBDT training.\nBenchmarked on CPU, GPU, and distributed clusters, we observe up to 2$\\times$\nspeedup of our simple quantization strategy compared with SOTA GBDT systems on\nextensive datasets, demonstrating the effectiveness and potential of the\nlow-precision training of GBDT. The code will be released to the official\nrepository of LightGBM.",
    "descriptor": "",
    "authors": [
      "Yu Shi",
      "Guolin Ke",
      "Zhuoming Chen",
      "Shuxin Zheng",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09682"
  },
  {
    "id": "arXiv:2207.09684",
    "title": "On the Versatile Uses of Partial Distance Correlation in Deep Learning",
    "abstract": "Comparing the functional behavior of neural network models, whether it is a\nsingle network over time or two (or more networks) during or post-training, is\nan essential step in understanding what they are learning (and what they are\nnot), and for identifying strategies for regularization or efficiency\nimprovements. Despite recent progress, e.g., comparing vision transformers to\nCNNs, systematic comparison of function, especially across different networks,\nremains difficult and is often carried out layer by layer. Approaches such as\ncanonical correlation analysis (CCA) are applicable in principle, but have been\nsparingly used so far. In this paper, we revisit a (less widely known) from\nstatistics, called distance correlation (and its partial variant), designed to\nevaluate correlation between feature spaces of different dimensions. We\ndescribe the steps necessary to carry out its deployment for large scale models\n-- this opens the door to a surprising array of applications ranging from\nconditioning one deep model w.r.t. another, learning disentangled\nrepresentations as well as optimizing diverse models that would directly be\nmore robust to adversarial attacks. Our experiments suggest a versatile\nregularizer (or constraint) with many advantages, which avoids some of the\ncommon difficulties one faces in such analyses. Code is at\nhttps://github.com/zhenxingjian/Partial_Distance_Correlation.",
    "descriptor": "",
    "authors": [
      "Xingjian Zhen",
      "Zihang Meng",
      "Rudrasis Chakraborty",
      "Vikas Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09684"
  },
  {
    "id": "arXiv:2207.09685",
    "title": "BigColor: Colorization using a Generative Color Prior for Natural Images",
    "abstract": "For realistic and vivid colorization, generative priors have recently been\nexploited. However, such generative priors often fail for in-the-wild complex\nimages due to their limited representation space. In this paper, we propose\nBigColor, a novel colorization approach that provides vivid colorization for\ndiverse in-the-wild images with complex structures. While previous generative\npriors are trained to synthesize both image structures and colors, we learn a\ngenerative color prior to focus on color synthesis given the spatial structure\nof an image. In this way, we reduce the burden of synthesizing image structures\nfrom the generative prior and expand its representation space to cover diverse\nimages. To this end, we propose a BigGAN-inspired encoder-generator network\nthat uses a spatial feature map instead of a spatially-flattened BigGAN latent\ncode, resulting in an enlarged representation space. Our method enables robust\ncolorization for diverse inputs in a single forward pass, supports arbitrary\ninput resolutions, and provides multi-modal colorization results. We\ndemonstrate that BigColor significantly outperforms existing methods especially\non in-the-wild images with complex structures.",
    "descriptor": "",
    "authors": [
      "Geonung Kim",
      "Kyoungkook Kang",
      "Seongtae Kim",
      "Hwayoon Lee",
      "Sehoon Kim",
      "Jonghyun Kim",
      "Seung-Hwan Baek",
      "Sunghyun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09685"
  },
  {
    "id": "arXiv:2207.09686",
    "title": "Object-Compositional Neural Implicit Surfaces",
    "abstract": "The neural implicit representation has shown its effectiveness in novel view\nsynthesis and high-quality 3D reconstruction from multi-view images. However,\nmost approaches focus on holistic scene representation yet ignore individual\nobjects inside it, thus limiting potential downstream applications. In order to\nlearn object-compositional representation, a few works incorporate the 2D\nsemantic map as a cue in training to grasp the difference between objects. But\nthey neglect the strong connections between object geometry and instance\nsemantic information, which leads to inaccurate modeling of individual\ninstance. This paper proposes a novel framework, ObjectSDF, to build an\nobject-compositional neural implicit representation with high fidelity in 3D\nreconstruction and object representation. Observing the ambiguity of\nconventional volume rendering pipelines, we model the scene by combining the\nSigned Distance Functions (SDF) of individual object to exert explicit surface\nconstraint. The key in distinguishing different instances is to revisit the\nstrong association between an individual object's SDF and semantic label.\nParticularly, we convert the semantic information to a function of object SDF\nand develop a unified and compact representation for scene and objects.\nExperimental results show the superiority of ObjectSDF framework in\nrepresenting both the holistic object-compositional scene and the individual\ninstances. Code can be found at https://qianyiwu.github.io/objectsdf/",
    "descriptor": "\nComments: ECCV2022, Project Page: this https URL Code: this https URL\n",
    "authors": [
      "Qianyi Wu",
      "Xian Liu",
      "Yuedong Chen",
      "Kejie Li",
      "Chuanxia Zheng",
      "Jianfei Cai",
      "Jianmin Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09686"
  },
  {
    "id": "arXiv:2207.09689",
    "title": "Uncertainty Inspired Underwater Image Enhancement",
    "abstract": "A main challenge faced in the deep learning-based Underwater Image\nEnhancement (UIE) is that the ground truth high-quality image is unavailable.\nMost of the existing methods first generate approximate reference maps and then\ntrain an enhancement network with certainty. This kind of method fails to\nhandle the ambiguity of the reference map. In this paper, we resolve UIE into\ndistribution estimation and consensus process. We present a novel probabilistic\nnetwork to learn the enhancement distribution of degraded underwater images.\nSpecifically, we combine conditional variational autoencoder with adaptive\ninstance normalization to construct the enhancement distribution. After that,\nwe adopt a consensus process to predict a deterministic result based on a set\nof samples from the distribution. By learning the enhancement distribution, our\nmethod can cope with the bias introduced in the reference map labeling to some\nextent. Additionally, the consensus process is useful to capture a robust and\nstable result. We examined the proposed method on two widely used real-world\nunderwater image enhancement datasets. Experimental results demonstrate that\nour approach enables sampling possible enhancement predictions. Meanwhile, the\nconsensus estimate yields competitive performance compared with\nstate-of-the-art UIE methods. Code available at\nhttps://github.com/zhenqifu/PUIE-Net.",
    "descriptor": "",
    "authors": [
      "Zhenqi Fu",
      "Wu Wang",
      "Yue Huang",
      "Xinghao Ding",
      "Kai-Kuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09689"
  },
  {
    "id": "arXiv:2207.09690",
    "title": "Design of Coded Caching Schemes with Linear Subpacketizations Based on  Injective Arc Coloring of Regular Digraphs",
    "abstract": "Coded caching is an effective technique to decongest the amount of traffic in\nthe backhaul link. In such a scheme, each file hosted in the server is divided\ninto a number of packets to pursue a low transmission rate based on the\ndelicate design of contents cached into users and broadcast messages. However,\nthe implementation complexity of this scheme increases with the number of\npackets. It is desirable to design a scheme with a small subpacketization level\nand a relatively low transmission rate. Recently, placement delivery array\n(PDA) was proposed to address the subpacketization bottleneck of coded caching.\nThis paper investigates the design PDA from a new perspective, i.e., the\ninjective arc coloring of regular digraphs. It is shown that the injective arc\ncoloring of a regular digraph can yield a PDA with the same number of rows and\ncolumns. Based on this, a new class of regular digraphs are defined and the\nupper bounds on the injective chromatic index of such digraphs are derived.\nConsequently, some new coded caching schemes with a linear subpacketization\nlevel and a small transmission rate are proposed, one of which generalizes the\nexisting scheme for the scenario with a more flexible number of users.",
    "descriptor": "",
    "authors": [
      "Xianzhang Wu",
      "Minquan Cheng",
      "Li Chen",
      "Congduan Li",
      "Zifan Shi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.09690"
  },
  {
    "id": "arXiv:2207.09691",
    "title": "Efficient Meta-Tuning for Content-aware Neural Video Delivery",
    "abstract": "Recently, Deep Neural Networks (DNNs) are utilized to reduce the bandwidth\nand improve the quality of Internet video delivery. Existing methods train\ncorresponding content-aware super-resolution (SR) model for each video chunk on\nthe server, and stream low-resolution (LR) video chunks along with SR models to\nthe client. Although they achieve promising results, the huge computational\ncost of network training limits their practical applications. In this paper, we\npresent a method named Efficient Meta-Tuning (EMT) to reduce the computational\ncost. Instead of training from scratch, EMT adapts a meta-learned model to the\nfirst chunk of the input video. As for the following chunks, it fine-tunes the\npartial parameters selected by gradient masking of previous adapted model. In\norder to achieve further speedup for EMT, we propose a novel sampling strategy\nto extract the most challenging patches from video frames. The proposed\nstrategy is highly efficient and brings negligible additional cost. Our method\nsignificantly reduces the computational cost and achieves even better\nperformance, paving the way for applying neural video delivery techniques to\npractical applications. We conduct extensive experiments based on various\nefficient SR architectures, including ESPCN, SRCNN, FSRCNN and EDSR-1,\ndemonstrating the generalization ability of our work. The code is released at\n\\url{https://github.com/Neural-video-delivery/EMT-Pytorch-ECCV2022}.",
    "descriptor": "\nComments: Accepted at ECCV2022\n",
    "authors": [
      "Xiaoqi Li",
      "Jiaming Liu",
      "Shizun Wang",
      "Cheng Lyu",
      "Ming Lu",
      "Yurong Chen",
      "Anbang Yao",
      "Yandong Guo",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.09691"
  },
  {
    "id": "arXiv:2207.09693",
    "title": "Correntropy-Based Logistic Regression with Automatic Relevance  Determination for Robust Sparse Brain Activity Decoding",
    "abstract": "Recent studies have utilized sparse classifications to predict categorical\nvariables from high-dimensional brain activity signals to expose human's\nintentions and mental states, selecting the relevant features automatically in\nthe model training process. However, existing sparse classification models will\nlikely be prone to the performance degradation which is caused by noise\ninherent in the brain recordings. To address this issue, we aim to propose a\nnew robust and sparse classification algorithm in this study. To this end, we\nintroduce the correntropy learning framework into the automatic relevance\ndetermination based sparse classification model, proposing a new\ncorrentropy-based robust sparse logistic regression algorithm. To demonstrate\nthe superior brain activity decoding performance of the proposed algorithm, we\nevaluate it on a synthetic dataset, an electroencephalogram (EEG) dataset, and\na functional magnetic resonance imaging (fMRI) dataset. The extensive\nexperimental results confirm that not only the proposed method can achieve\nhigher classification accuracy in a noisy and high-dimensional classification\ntask, but also it would select those more informative features for the decoding\nscenarios. Integrating the correntropy learning approach with the automatic\nrelevance determination technique will significantly improve the robustness\nwith respect to the noise, leading to more adequate robust sparse brain\ndecoding algorithm. It provides a more powerful approach in the real-world\nbrain activity decoding and the brain-computer interfaces.",
    "descriptor": "",
    "authors": [
      "Yuanhao Li",
      "Badong Chen",
      "Yuxi Shi",
      "Natsue Yoshimura",
      "Yasuharu Koike"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2207.09693"
  },
  {
    "id": "arXiv:2207.09695",
    "title": "Convergence of the fully discrete incremental projection scheme for  incompressible flows",
    "abstract": "The present paper addresses the convergence of a first order in time\nincremental projection scheme for the time-dependent incompressible\nNavier-Stokes equations to a weak solution, without any assumption of existence\nor regularity assumptions on the exact solution. We prove the convergence of\nthe approximate solutions obtained by the semi-discrete scheme and a fully\ndiscrete scheme using a staggered finite volume scheme on non uniform\nrectangular meshes. Some first a priori estimates on the approximate solutions\nyield the existence. Compactness arguments, relying on these estimates,\ntogether with some estimates on the translates of the discrete time\nderivatives, are then developed to obtain convergence (up to the extraction of\na subsequence), when the time step tends to zero in the semi-discrete scheme\nand when the space and time steps tend to zero in the fully discrete scheme;\nthe approximate solutions are thus shown to converge to a limit function which\nis then shown to be a weak solution to the continuous problem by passing to the\nlimit in these schemes.",
    "descriptor": "",
    "authors": [
      "Thierry Gallou\u00ebt",
      "Rapha\u00e8le Herbin",
      "Jean-Claude Latch\u00e9",
      "David Maltese"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.09695"
  },
  {
    "id": "arXiv:2207.09697",
    "title": "Robust Object Detection With Inaccurate Bounding Boxes",
    "abstract": "Learning accurate object detectors often requires large-scale training data\nwith precise object bounding boxes. However, labeling such data is expensive\nand time-consuming. As the crowd-sourcing labeling process and the ambiguities\nof the objects may raise noisy bounding box annotations, the object detectors\nwill suffer from the degenerated training data. In this work, we aim to address\nthe challenge of learning robust object detectors with inaccurate bounding\nboxes. Inspired by the fact that localization precision suffers significantly\nfrom inaccurate bounding boxes while classification accuracy is less affected,\nwe propose leveraging classification as a guidance signal for refining\nlocalization results. Specifically, by treating an object as a bag of\ninstances, we introduce an Object-Aware Multiple Instance Learning approach\n(OA-MIL), featured with object-aware instance selection and object-aware\ninstance extension. The former aims to select accurate instances for training,\ninstead of directly using inaccurate box annotations. The latter focuses on\ngenerating high-quality instances for selection. Extensive experiments on\nsynthetic noisy datasets (i.e., noisy PASCAL VOC and MS-COCO) and a real noisy\nwheat head dataset demonstrate the effectiveness of our OA-MIL. Code is\navailable at https://github.com/cxliu0/OA-MIL.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Chengxin Liu",
      "Kewei Wang",
      "Hao Lu",
      "Zhiguo Cao",
      "Ziming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09697"
  },
  {
    "id": "arXiv:2207.09705",
    "title": "Resolving Copycat Problems in Visual Imitation Learning via Residual  Action Prediction",
    "abstract": "Imitation learning is a widely used policy learning method that enables\nintelligent agents to acquire complex skills from expert demonstrations. The\ninput to the imitation learning algorithm is usually composed of both the\ncurrent observation and historical observations since the most recent\nobservation might not contain enough information. This is especially the case\nwith image observations, where a single image only includes one view of the\nscene, and it suffers from a lack of motion information and object occlusions.\nIn theory, providing multiple observations to the imitation learning agent will\nlead to better performance. However, surprisingly people find that sometimes\nimitation from observation histories performs worse than imitation from the\nmost recent observation. In this paper, we explain this phenomenon from the\ninformation flow within the neural network perspective. We also propose a novel\nimitation learning neural network architecture that does not suffer from this\nissue by design. Furthermore, our method scales to high-dimensional image\nobservations. Finally, we benchmark our approach on two widely used simulators,\nCARLA and MuJoCo, and it successfully alleviates the copycat problem and\nsurpasses the existing solutions.",
    "descriptor": "\nComments: 27 pages, 10 figures, ECCV2022\n",
    "authors": [
      "Chia-Chi Chuang",
      "Donglin Yang",
      "Chuan Wen",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09705"
  },
  {
    "id": "arXiv:2207.09706",
    "title": "Modelling the Turtle Python library in CSP",
    "abstract": "Software verification is an important tool in establishing the reliability of\ncritical systems. One potential area of application is in the field of\nrobotics, as robots take on more tasks in both day-to-day areas and highly\nspecialised domains. Robots are usually given a plan to follow, if there are\nerrors in this plan the robot will not perform reliably. The capability to\ncheck plans for errors in advance could prevent this. Python is a popular\nprogramming language in the robotics domain, through the use of the Robot\nOperating System (ROS) and various other libraries. Python's Turtle package\nprovides a mobile agent, which we formally model here using Communicating\nSequential Processes (CSP). Our interactive toolchain CSP2Turtle with CSP model\nand Python components, enables Turtle plans to be verified in CSP before being\nexecuted in Python. This means that certain classes of errors can be avoided,\nand provides a starting point for more detailed verification of Turtle programs\nand more complex robotic systems. We illustrate our approach with examples of\nrobot navigation and obstacle avoidance in a 2D grid-world.",
    "descriptor": "\nComments: In Proceedings AREA 2022, arXiv:2207.09058\n",
    "authors": [
      "Dara MacConville",
      "Marie Farrell",
      "Matt Luckcuck",
      "Rosemary Monahan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.09706"
  },
  {
    "id": "arXiv:2207.09707",
    "title": "Careful Autonomous Agents in Environments With Multiple Common Resources",
    "abstract": "Careful rational synthesis was defined in (Condurache et al. 2021) as a\nquantitative extension of Fisman et al.'s rational synthesis (Fisman et al.\n2010), as a model of multi-agent systems in which agents are interacting in a\ngraph arena in a turn-based fashion. There is one common resource, and each\naction may decrease or increase the resource. Each agent has a temporal\nqualitative objective and wants to maintain the value of the resource positive.\nOne must find a Nash equilibrium. This problem is decidable.\nIn more practical settings, the verification of the critical properties of\nmulti-agent systems calls for models with many resources. Indeed, agents and\nrobots consume and produce more than one type of resource: electric energy,\nfuel, raw material, manufactured goods, etc. We thus explore the problem of\ncareful rational synthesis with several resources. We show that the problem is\nundecidable. We then propose a variant with bounded resources, motivated by the\nobservation that in practical settings, the storage of resources is limited. We\nshow that the problem becomes decidable, and is no harder than controller\nsynthesis with Linear-time Temporal Logic objectives.",
    "descriptor": "\nComments: In Proceedings AREA 2022, arXiv:2207.09058\n",
    "authors": [
      "Rodica Condurache",
      "Catalin Dima",
      "Madalina Jitaru",
      "Youssouf Oualhadj",
      "Nicolas Troquard"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.09707"
  },
  {
    "id": "arXiv:2207.09708",
    "title": "RV4JaCa -- Runtime Verification for Multi-Agent Systems",
    "abstract": "This paper presents a Runtime Verification (RV) approach for Multi-Agent\nSystems (MAS) using the JaCaMo framework. Our objective is to bring a layer of\nsecurity to the MAS. This layer is capable of controlling events during the\nexecution of the system without needing a specific implementation in the\nbehaviour of each agent to recognise the events. MAS have been used in the\ncontext of hybrid intelligence. This use requires communication between\nsoftware agents and human beings. In some cases, communication takes place via\nnatural language dialogues. However, this kind of communication brings us to a\nconcern related to controlling the flow of dialogue so that agents can prevent\nany change in the topic of discussion that could impair their reasoning. We\ndemonstrate the implementation of a monitor that aims to control this dialogue\nflow in a MAS that communicates with the user through natural language to aid\ndecision-making in hospital bed allocation.",
    "descriptor": "\nComments: In Proceedings AREA 2022, arXiv:2207.09058\n",
    "authors": [
      "Debora C. Engelmann",
      "Angelo Ferrando",
      "Alison R. Panisson",
      "Davide Ancona",
      "Rafael H. Bordini",
      "Viviana Mascardi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.09708"
  },
  {
    "id": "arXiv:2207.09709",
    "title": "Temporal Planning with Incomplete Knowledge and Perceptual Information",
    "abstract": "In real-world applications, the ability to reason about incomplete knowledge,\nsensing, temporal notions, and numeric constraints is vital. While several AI\nplanners are capable of dealing with some of these requirements, they are\nmostly limited to problems with specific types of constraints. This paper\npresents a new planning approach that combines contingent plan construction\nwithin a temporal planning framework, offering solutions that consider numeric\nconstraints and incomplete knowledge. We propose a small extension to the\nPlanning Domain Definition Language (PDDL) to model (i) incomplete, (ii)\nknowledge sensing actions that operate over unknown propositions, and (iii)\npossible outcomes from non-deterministic sensing effects. We also introduce a\nnew set of planning domains to evaluate our solver, which has shown good\nperformance on a variety of problems.",
    "descriptor": "\nComments: In Proceedings AREA 2022, arXiv:2207.09058\n",
    "authors": [
      "Yaniel Carreno",
      "Yvan Petillot",
      "Ronald P. A. Petrick"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.09709"
  },
  {
    "id": "arXiv:2207.09710",
    "title": "Learning Sequence Representations by Non-local Recurrent Neural Memory",
    "abstract": "The key challenge of sequence representation learning is to capture the\nlong-range temporal dependencies. Typical methods for supervised sequence\nrepresentation learning are built upon recurrent neural networks to capture\ntemporal dependencies. One potential limitation of these methods is that they\nonly model one-order information interactions explicitly between adjacent time\nsteps in a sequence, hence the high-order interactions between nonadjacent time\nsteps are not fully exploited. It greatly limits the capability of modeling the\nlong-range temporal dependencies since the temporal features learned by\none-order interactions cannot be maintained for a long term due to temporal\ninformation dilution and gradient vanishing. To tackle this limitation, we\npropose the Non-local Recurrent Neural Memory (NRNM) for supervised sequence\nrepresentation learning, which performs non-local operations \\MR{by means of\nself-attention mechanism} to learn full-order interactions within a sliding\ntemporal memory block and models global interactions between memory blocks in a\ngated recurrent manner. Consequently, our model is able to capture long-range\ndependencies. Besides, the latent high-level features contained in high-order\ninteractions can be distilled by our model. We validate the effectiveness and\ngeneralization of our NRNM on three types of sequence applications across\ndifferent modalities, including sequence classification, step-wise sequential\nprediction and sequence similarity learning. Our model compares favorably\nagainst other state-of-the-art methods specifically designed for each of these\nsequence applications.",
    "descriptor": "\nComments: To be appeared in International Journal of Computer Vision (IJCV). arXiv admin note: substantial text overlap with arXiv:1908.09535\n",
    "authors": [
      "Wenjie Pei",
      "Xin Feng",
      "Canmiao Fu",
      "Qiong Cao",
      "Guangming Lu",
      "Yu-Wing Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09710"
  },
  {
    "id": "arXiv:2207.09711",
    "title": "Towards VEsNA, a Framework for Managing Virtual Environments via Natural  Language Agents",
    "abstract": "Automating a factory where robots are involved is neither trivial nor cheap.\nEngineering the factory automation process in such a way that return of\ninterest is maximized and risk for workers and equipment is minimized, is hence\nof paramount importance. Simulation can be a game changer in this scenario but\nrequires advanced programming skills that domain experts and industrial\ndesigners might not have. In this paper we present the preliminary design and\nimplementation of a general-purpose framework for creating and exploiting\nVirtual Environments via Natural language Agents (VEsNA). VEsNA takes advantage\nof agent-based technologies and natural language processing to enhance the\ndesign of virtual environments. The natural language input provided to VEsNA is\nunderstood by a chatbot and passed to a cognitive intelligent agent that\nimplements the logic behind displacing objects in the virtual environment. In\nthe VEsNA vision, the intelligent agent will be able to reason on this\ndisplacement and on its compliance to legal and normative constraints. It will\nalso be able to implement what-if analysis and case-based reasoning. Objects\npopulating the virtual environment will include active objects and will\npopulate a dynamic simulation whose outcomes will be interpreted by the\ncognitive agent; explanations and suggestions will be passed back to the user\nby the chatbot.",
    "descriptor": "\nComments: In Proceedings AREA 2022, arXiv:2207.09058\n",
    "authors": [
      "Andrea Gatti",
      "Viviana Mascardi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2207.09711"
  },
  {
    "id": "arXiv:2207.09712",
    "title": "The Need for a Meta-Architecture for Robot Autonomy",
    "abstract": "Long-term autonomy of robotic systems implicitly requires dependable\nplatforms that are able to naturally handle hardware and software faults,\nproblems in behaviors, or lack of knowledge. Model-based dependable platforms\nadditionally require the application of rigorous methodologies during the\nsystem development, including the use of correct-by-construction techniques to\nimplement robot behaviors. As the level of autonomy in robots increases, so do\nthe cost of offering guarantees about the dependability of the system.\nCertifiable dependability of autonomous robots, we argue, can benefit from\nformal models of the integration of several cognitive functions, knowledge\nprocessing, reasoning, and meta-reasoning. Here we put forward the case for a\ngenerative model of cognitive architectures for autonomous robotic agents that\nsubscribes to the principles of model-based engineering and certifiable\ndependability, autonomic computing, and knowledge-enabled robotics.",
    "descriptor": "\nComments: In Proceedings AREA 2022, arXiv:2207.09058\n",
    "authors": [
      "Stalin Mu\u00f1oz Guti\u00e9rrez",
      "Gerald Steinbauer-Wagner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09712"
  },
  {
    "id": "arXiv:2207.09713",
    "title": "Towards Plug'n Play Task-Level Autonomy for Robotics Using POMDPs and  Generative Models",
    "abstract": "To enable robots to achieve high level objectives, engineers typically write\nscripts that apply existing specialized skills, such as navigation, object\ndetection and manipulation to achieve these goals. Writing good scripts is\nchallenging since they must intelligently balance the inherent stochasticity of\na physical robot's actions and sensors, and the limited information it has. In\nprinciple, AI planning can be used to address this challenge and generate good\nbehavior policies automatically. But this requires passing three hurdles.\nFirst, the AI must understand each skill's impact on the world. Second, we must\nbridge the gap between the more abstract level at which we understand what a\nskill does and the low-level state variables used within its code. Third, much\nintegration effort is required to tie together all components. We describe an\napproach for integrating robot skills into a working autonomous robot\ncontroller that schedules its skills to achieve a specified task and carries\nfour key advantages. 1) Our Generative Skill Documentation Language (GSDL)\nmakes code documentation simpler, compact, and more expressive using ideas from\nprobabilistic programming languages. 2) An expressive abstraction mapping (AM)\nbridges the gap between low-level robot code and the abstract AI planning\nmodel. 3) Any properly documented skill can be used by the controller without\nany additional programming effort, providing a Plug'n Play experience. 4) A\nPOMDP solver schedules skill execution while properly balancing partial\nobservability, stochastic behavior, and noisy sensing.",
    "descriptor": "\nComments: In Proceedings AREA 2022, arXiv:2207.09058\n",
    "authors": [
      "Or Wertheim",
      "Dan R. Suissa",
      "Ronen I. Brafman"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.09713"
  },
  {
    "id": "arXiv:2207.09714",
    "title": "Differentiable Agent-based Epidemiology",
    "abstract": "Mechanistic simulators are an indispensable tool for epidemiology to explore\nthe behavior of complex, dynamic infections under varying conditions and\nnavigate uncertain environments. ODE-based models are the dominant paradigm\nthat enable fast simulations and are tractable to gradient-based optimization,\nbut make simplifying assumptions about population homogeneity. Agent-based\nmodels (ABMs) are an increasingly popular alternative paradigm that can\nrepresent the heterogeneity of contact interactions with granular detail and\nagency of individual behavior. However, conventional ABM frameworks are not\ndifferentiable and present challenges in scalability; due to which it is\nnon-trivial to connect them to auxiliary data sources easily. In this paper we\nintroduce GradABM which is a new scalable, fast and differentiable design for\nABMs. GradABM runs simulations in few seconds on commodity hardware and enables\nfast forward and differentiable inverse simulations. This makes it amenable to\nbe merged with deep neural networks and seamlessly integrate heterogeneous data\nsources to help with calibration, forecasting and policy evaluation. We\ndemonstrate the efficacy of GradABM via extensive experiments with real\nCOVID-19 and influenza datasets. We are optimistic this work will bring ABM and\nAI communities closer together.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Ayush Chopra",
      "Alexander Rodr\u00edguez",
      "Jayakumar Subramanian",
      "Balaji Krishnamurthy",
      "B. Aditya Prakash",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Populations and Evolution (q-bio.PE)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2207.09714"
  },
  {
    "id": "arXiv:2207.09716",
    "title": "Multi-Task Learning for Emotion Descriptors Estimation at the fourth  ABAW Challenge",
    "abstract": "Facial valence/arousal, expression and action unit are related tasks in\nfacial affective analysis. However, the tasks only have limited performance in\nthe wild due to the various collected conditions. The 4th competition on\naffective behavior analysis in the wild (ABAW) provided images with\nvalence/arousal, expression and action unit labels. In this paper, we introduce\nmulti-task learning framework to enhance the performance of three related tasks\nin the wild. Feature sharing and label fusion are used to utilize their\nrelations. We conduct experiments on the provided training and validating data.",
    "descriptor": "",
    "authors": [
      "Yanan Chang",
      "Yi Wu",
      "Xiangyu Miao",
      "Jiahe Wang",
      "Shangfei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09716"
  },
  {
    "id": "arXiv:2207.09721",
    "title": "Feature Representation Learning for Unsupervised Cross-domain Image  Retrieval",
    "abstract": "Current supervised cross-domain image retrieval methods can achieve excellent\nperformance. However, the cost of data collection and labeling imposes an\nintractable barrier to practical deployment in real applications. In this\npaper, we investigate the unsupervised cross-domain image retrieval task, where\nclass labels and pairing annotations are no longer a prerequisite for training.\nThis is an extremely challenging task because there is no supervision for both\nin-domain feature representation learning and cross-domain alignment. We\naddress both challenges by introducing: 1) a new cluster-wise contrastive\nlearning mechanism to help extract class semantic-aware features, and 2) a\nnovel distance-of-distance loss to effectively measure and minimize the domain\ndiscrepancy without any external supervision. Experiments on the Office-Home\nand DomainNet datasets consistently show the superior image retrieval\naccuracies of our framework over state-of-the-art approaches. Our source code\ncan be found at https://github.com/conghuihu/UCDIR.",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Conghui Hu",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09721"
  },
  {
    "id": "arXiv:2207.09725",
    "title": "OTPose: Occlusion-Aware Transformer for Pose Estimation in  Sparsely-Labeled Videos",
    "abstract": "Although many approaches for multi-human pose estimation in videos have shown\nprofound results, they require densely annotated data which entails excessive\nman labor. Furthermore, there exists occlusion and motion blur that inevitably\nlead to poor estimation performance. To address these problems, we propose a\nmethod that leverages an attention mask for occluded joints and encodes\ntemporal dependency between frames using transformers. First, our framework\ncomposes different combinations of sparsely annotated frames that denote the\ntrack of the overall joint movement. We propose an occlusion attention mask\nfrom these combinations that enable encoding occlusion-aware heatmaps as a\nsemi-supervised task. Second, the proposed temporal encoder employs transformer\narchitecture to effectively aggregate the temporal relationship and\nkeypoint-wise attention from each time step and accurately refines the target\nframe's final pose estimation. We achieve state-of-the-art pose estimation\nresults for PoseTrack2017 and PoseTrack2018 datasets and demonstrate the\nrobustness of our approach to occlusion and motion blur in sparsely annotated\nvideo data.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Kyung-Min Jin",
      "Gun-Hee Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09725"
  },
  {
    "id": "arXiv:2207.09728",
    "title": "Revisiting data augmentation for subspace clustering",
    "abstract": "Subspace clustering is the classical problem of clustering a collection of\ndata samples that approximately lie around several low-dimensional subspaces.\nThe current state-of-the-art approaches for this problem are based on the\nself-expressive model which represents the samples as linear combination of\nother samples. However, these approaches require sufficiently well-spread\nsamples for accurate representation which might not be necessarily accessible\nin many applications. In this paper, we shed light on this commonly neglected\nissue and argue that data distribution within each subspace plays a critical\nrole in the success of self-expressive models. Our proposed solution to tackle\nthis issue is motivated by the central role of data augmentation in the\ngeneralization power of deep neural networks. We propose two subspace\nclustering frameworks for both unsupervised and semi-supervised settings that\nuse augmented samples as an enlarged dictionary to improve the quality of the\nself-expressive representation. We present an automatic augmentation strategy\nusing a few labeled samples for the semi-supervised problem relying on the fact\nthat the data samples lie in the union of multiple linear subspaces.\nExperimental results confirm the effectiveness of data augmentation, as it\nsignificantly improves the performance of general self-expressive models.",
    "descriptor": "\nComments: 38 pages (including 10 of supplementary material)\n",
    "authors": [
      "Maryam Abdolali",
      "Nicolas Gillis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.09728"
  },
  {
    "id": "arXiv:2207.09730",
    "title": "Contractible_Spaces, Homotopy Equivalence and Homeomorphism in Digital  Topology",
    "abstract": "This article provides a brief overview of the main results in the field of\ncontractible digital spaces and contractible transformations of digital spaces\nand contains new results. We introduce new types of contractible digital spaces\nsuch as the cone and the double cone. Based on this, we introduce new\ncontractible transformations that covert the digital space into a homotopy\nequivalent to the first one. We group together these transformations and get 6\ntypes of contractible transformations. These transformations can be used to\nconvert a closed digital n-dimensional manifold into another closed\nn-dimensional manifold homeomorphic to the first one.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Alexander Evako"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2207.09730"
  },
  {
    "id": "arXiv:2207.09735",
    "title": "CrossHuman: Learning Cross-Guidance from Multi-Frame Images for Human  Reconstruction",
    "abstract": "We propose CrossHuman, a novel method that learns cross-guidance from\nparametric human model and multi-frame RGB images to achieve high-quality 3D\nhuman reconstruction. To recover geometry details and texture even in invisible\nregions, we design a reconstruction pipeline combined with tracking-based\nmethods and tracking-free methods. Given a monocular RGB sequence, we track the\nparametric human model in the whole sequence, the points (voxels) corresponding\nto the target frame are warped to reference frames by the parametric body\nmotion. Guided by the geometry priors of the parametric body and spatially\naligned features from RGB sequence, the robust implicit surface is fused.\nMoreover, a multi-frame transformer (MFT) and a self-supervised warp refinement\nmodule are integrated to the framework to relax the requirements of parametric\nbody and help to deal with very loose cloth. Compared with previous works, our\nCrossHuman enables high-fidelity geometry details and texture in both visible\nand invisible regions and improves the accuracy of the human reconstruction\neven under estimated inaccurate parametric human models. The experiments\ndemonstrate that our method achieves state-of-the-art (SOTA) performance.",
    "descriptor": "",
    "authors": [
      "Liliang Chen",
      "Jiaqi Li",
      "Han Huang",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09735"
  },
  {
    "id": "arXiv:2207.09744",
    "title": "MLMSA: Multi-Label Multi-Side-Channel-Information enabled Deep Learning  Attacks on APUF Variants",
    "abstract": "To improve the modeling resilience of silicon strong physical unclonable\nfunctions (PUFs), in particular, the APUFs, that yield a very large number of\nchallenge response pairs (CRPs), a number of composited APUF variants such as\nXOR-APUF, interpose-PUF (iPUF), feed-forward APUF (FF-APUF),and OAX-APUF have\nbeen devised. When examining their security in terms of modeling resilience,\nutilizing multiple information sources such as power side channel information\n(SCI) or/and reliability SCI given a challenge is under-explored, which poses a\nchallenge to their supposed modeling resilience in practice. Building upon\nmulti-label/head deep learning model architecture,this work proposes\nMulti-Label Multi-Side-channel-information enabled deep learning Attacks\n(MLMSA) to thoroughly evaluate the modeling resilience of aforementioned APUF\nvariants. Despite its simplicity, MLMSA can successfully break large-scaled\nAPUF variants, which has not previously been achieved. More precisely, the\nMLMSA breaks 128-stage 30-XOR-APUF, (9, 9)- and (2, 18)-iPUFs, and (2, 2,\n30)-OAX-APUF when CRPs, power SCI and reliability SCI are concurrently used. It\nbreaks 128-stage 12-XOR-APUF and (2, 2, 9)-OAX-APUF even when only the\neasy-to-obtain reliability SCI and CRPs are exploited. The 128-stage six-loop\nFF-APUF and one-loop 20-XOR-FF-APUF can be broken by simultaneously using\nreliability SCI and CRPs. All these attacks are normally completed within an\nhour with a standard personalcomputer. Therefore, MLMSA is a useful technique\nfor evaluating other existing or any emerging strong PUF designs.",
    "descriptor": "",
    "authors": [
      "Yansong Gao",
      "Jianrong Yao",
      "Lihui Pang",
      "Wei Yang",
      "Anmin Fu",
      "Said F. Al-Sarawi",
      "Derek Abbott"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.09744"
  },
  {
    "id": "arXiv:2207.09745",
    "title": "Benchmarking tools for a priori identifiability analysis",
    "abstract": "The structural identifiability and the observability of a model determine the\npossibility of inferring its parameters and states by observing its outputs.\nThese properties should be analysed before attempting to calibrate a model.\nUnfortunately, such \\textit{a priori} analysis can be challenging, since it\nrequires symbolic calculations that often have a high computational cost. In\nrecent years a number of software tools have been developed for this task,\nmostly in the systems biology community but also in other disciplines. These\ntools have vastly different features and capabilities, and a critical\nassessment of their performance is still lacking. Here we present a\ncomprehensive study of the computational resources available for analysing\nstructural identifiability. We consider 12 software tools developed in 7\nprogramming languages (Matlab, Maple, Mathematica, Julia, Python, Reduce, and\nMaxima), and evaluate their performance using a set of 25 case studies created\nfrom 21 models. Our results reveal their strengths and weaknesses, provide\nguidelines for choosing the most appropriate tool for a given problem, and\nhighlight opportunities for future developments.",
    "descriptor": "\nComments: 15 pages, 1 figure\n",
    "authors": [
      "Xabier Rey Barreiro",
      "Alejandro F. Villaverde"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2207.09745"
  },
  {
    "id": "arXiv:2207.09746",
    "title": "Can Causal (and Counterfactual) Reasoning improve Privacy Threat  Modelling?",
    "abstract": "Causal questions often permeate in our day-to-day activities. With causal\nreasoning and counterfactual intuition, privacy threats can not only be\nalleviated but also prevented. In this paper, we discuss what is causal and\ncounterfactual reasoning and how this can be applied in the field of privacy\nthreat modelling (PTM). We believe that the future of PTM relies on how we can\ncausally and counterfactually imagine cybersecurity threats and incidents.",
    "descriptor": "\nComments: Accepted at PTM-SOUPS'22\n",
    "authors": [
      "Rakshit Naidu",
      "Navid Kagalwalla"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.09746"
  },
  {
    "id": "arXiv:2207.09748",
    "title": "Facial Affect Analysis: Learning from Synthetic Data & Multi-Task  Learning Challenges",
    "abstract": "Facial affect analysis remains a challenging task with its setting\ntransitioned from lab-controlled to in-the-wild situations. In this paper, we\npresent novel frameworks to handle the two challenges in the 4th Affective\nBehavior Analysis In-The-Wild (ABAW) competition: i) Multi-Task-Learning (MTL)\nChallenge and ii) Learning from Synthetic Data (LSD) Challenge. For MTL\nchallenge, we adopt the SMM-EmotionNet with a better ensemble strategy of\nfeature vectors. For LSD challenge, we propose respective methods to combat the\nproblems of single labels, imbalanced distribution, fine-tuning limitations,\nand choice of model architectures. Experimental results on the official\nvalidation sets from the competition demonstrated that our proposed approaches\noutperformed baselines by a large margin. The code is available at\nhttps://github.com/sylyoung/ABAW4-HUST-ANT.",
    "descriptor": "",
    "authors": [
      "Siyang Li",
      "Yifan Xu",
      "Huanyu Wu",
      "Dongrui Wu",
      "Yingjie Yin",
      "Jiajiong Cao",
      "Jingting Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09748"
  },
  {
    "id": "arXiv:2207.09750",
    "title": "Fair Context-Aware Privacy Threat Modelling",
    "abstract": "Given the progressive nature of the world today, fairness is a very important\nsocial aspect in various areas, and it has long been studied with the advent of\ntechnology. To the best of our knowledge, methods of quantifying fairness\nerrors and fairness in privacy threat models have been absent. To this end, in\nthis short paper, we examine notions of fairness in privacy threat modelling\ndue to different causes of privacy threats within a particular\nsituation/context and that across contexts.",
    "descriptor": "\nComments: Accepted at PTM-SOUPS'22\n",
    "authors": [
      "Saswat Das",
      "Rakshit Naidu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.09750"
  },
  {
    "id": "arXiv:2207.09755",
    "title": "A Temporally and Spatially Local Spike-based Backpropagation Algorithm  to Enable Training in Hardware",
    "abstract": "Spiking Neural Networks (SNNs) have emerged as a hardware efficient\narchitecture for classification tasks. The penalty of spikes-based encoding has\nbeen the lack of a universal training mechanism performed entirely using\nspikes. There have been several attempts to adopt the powerful backpropagation\n(BP) technique used in non-spiking artificial neural networks (ANN): (1) SNNs\ncan be trained by externally computed numerical gradients. (2) A major\nadvancement toward native spike-based learning has been the use of approximate\nBackpropagation using spike-time-dependent plasticity (STDP) with phased\nforward/backward passes. However, the transfer of information between such\nphases necessitates external memory and computational access. This is a\nchallenge for neuromorphic hardware implementations. In this paper, we propose\na stochastic SNN-based Back-Prop (SSNN-BP) algorithm that utilizes a composite\nneuron to simultaneously compute the forward pass activations and backward pass\ngradients explicitly with spikes. Although signed gradient values are a\nchallenge for spike-based representation, we tackle this by splitting the\ngradient signal into positive and negative streams. The composite neuron\nencodes information in the form of stochastic spike-trains and converts\nBackpropagation weight updates into temporally and spatially local discrete\nSTDP-like spike coincidence updates compatible with hardware-friendly Resistive\nProcessing Units (RPUs). Furthermore, our method approaches BP ANN baseline\nwith sufficiently long spike-trains. Finally, we show that softmax\ncross-entropy loss function can be implemented through inhibitory lateral\nconnections enforcing a Winner Take All (WTA) rule. Our SNN shows excellent\ngeneralization through comparable performance to ANNs on the MNIST,\nFashion-MNIST and Extended MNIST datasets. Thus, SSNN-BP enables BP compatible\nwith purely spike-based neuromorphic hardware.",
    "descriptor": "",
    "authors": [
      "Anmol Biswas",
      "Vivek Saraswat",
      "Udayan Ganguly"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09755"
  },
  {
    "id": "arXiv:2207.09759",
    "title": "Task-adaptive Spatial-Temporal Video Sampler for Few-shot Action  Recognition",
    "abstract": "A primary challenge faced in few-shot action recognition is inadequate video\ndata for training. To address this issue, current methods in this field mainly\nfocus on devising algorithms at the feature level while little attention is\npaid to processing input video data. Moreover, existing frame sampling\nstrategies may omit critical action information in temporal and spatial\ndimensions, which further impacts video utilization efficiency. In this paper,\nwe propose a novel video frame sampler for few-shot action recognition to\naddress this issue, where task-specific spatial-temporal frame sampling is\nachieved via a temporal selector (TS) and a spatial amplifier (SA).\nSpecifically, our sampler first scans the whole video at a small computational\ncost to obtain a global perception of video frames. The TS plays its role in\nselecting top-T frames that contribute most significantly and subsequently. The\nSA emphasizes the discriminative information of each frame by amplifying\ncritical regions with the guidance of saliency maps. We further adopt\ntask-adaptive learning to dynamically adjust the sampling strategy according to\nthe episode task at hand. Both the implementations of TS and SA are\ndifferentiable for end-to-end optimization, facilitating seamless integration\nof our proposed sampler with most few-shot action recognition methods.\nExtensive experiments show a significant boost in the performances on various\nbenchmarks including long-term videos.",
    "descriptor": "\nComments: Accepted by ACM MM 2022\n",
    "authors": [
      "Huabin Liu",
      "Weixian Lv",
      "John See",
      "Weiyao Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09759"
  },
  {
    "id": "arXiv:2207.09763",
    "title": "GIPSO: Geometrically Informed Propagation for Online Adaptation in 3D  LiDAR Segmentation",
    "abstract": "3D point cloud semantic segmentation is fundamental for autonomous driving.\nMost approaches in the literature neglect an important aspect, i.e., how to\ndeal with domain shift when handling dynamic scenes. This can significantly\nhinder the navigation capabilities of self-driving vehicles. This paper\nadvances the state of the art in this research field. Our first contribution\nconsists in analysing a new unexplored scenario in point cloud segmentation,\nnamely Source-Free Online Unsupervised Domain Adaptation (SF-OUDA). We\nexperimentally show that state-of-the-art methods have a rather limited ability\nto adapt pre-trained deep network models to unseen domains in an online manner.\nOur second contribution is an approach that relies on adaptive self-training\nand geometric-feature propagation to adapt a pre-trained source model online\nwithout requiring either source data or target labels. Our third contribution\nis to study SF-OUDA in a challenging setup where source data is synthetic and\ntarget data is point clouds captured in the real world. We use the recent\nSynLiDAR dataset as a synthetic source and introduce two new synthetic (source)\ndatasets, which can stimulate future synthetic-to-real autonomous driving\nresearch. Our experiments show the effectiveness of our segmentation approach\non thousands of real-world point clouds. Code and synthetic datasets are\navailable at https://github.com/saltoricristiano/gipso-sfouda.",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Cristiano Saltori",
      "Evgeny Krivosheev",
      "St\u00e9phane Lathuili\u00e8re",
      "Nicu Sebe",
      "Fabio Galasso",
      "Giuseppe Fiameni",
      "Elisa Ricci",
      "Fabio Poiesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09763"
  },
  {
    "id": "arXiv:2207.09765",
    "title": "ApHMM: Accelerating Profile Hidden Markov Models for Fast and  Energy-Efficient Genome Analysis",
    "abstract": "Profile hidden Markov models (pHMMs) are widely used in many bioinformatics\napplications to accurately identify similarities between biological sequences\n(e.g., DNA or protein sequences). PHMMs use a commonly-adopted and\nhighly-accurate method, called the Baum-Welch algorithm, to calculate these\nsimilarities. However, the Baum-Welch algorithm is computationally expensive,\nand existing works provide either software- or hardware-only solutions for a\nfixed pHMM design. When we analyze the state-of-the-art works, we find that\nthere is a pressing need for a flexible, high-performant, and energy-efficient\nhardware-software co-design to efficiently and effectively solve all the major\ninefficiencies in the Baum-Welch algorithm for pHMMs.\nWe propose ApHMM, the first flexible acceleration framework that can\nsignificantly reduce computational and energy overheads of the Baum-Welch\nalgorithm for pHMMs. ApHMM leverages hardware-software co-design to solve the\nmajor inefficiencies in the Baum-Welch algorithm by 1) designing a flexible\nhardware to support different pHMMs designs, 2) exploiting the predictable data\ndependency pattern in an on-chip memory with memoization techniques, 3) quickly\neliminating negligible computations with a hardware-based filter, and 4)\nminimizing the redundant computations. We implement our 1) hardware-software\noptimizations on a specialized hardware and 2) software optimizations for GPUs\nto provide the first flexible Baum-Welch accelerator for pHMMs. ApHMM provides\nsignificant speedups of 15.55x-260.03x, 1.83x-5.34x, and 27.97x compared to\nCPU, GPU, and FPGA implementations of the Baum-Welch algorithm, respectively.\nApHMM outperforms the state-of-the-art CPU implementations of three important\nbioinformatics applications, 1) error correction, 2) protein family search, and\n3) multiple sequence alignment, by 1.29x-59.94x, 1.03x-1.75x, and 1.03x-1.95x,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Can Firtina",
      "Kamlesh Pillai",
      "Gurpreet S. Kalsi",
      "Bharathwaj Suresh",
      "Damla Senol Cali",
      "Jeremie Kim",
      "Taha Shahroodi",
      "Meryem Banu Cavlak",
      "Joel Lindegger",
      "Mohammed Alser",
      "Juan G\u00f3mez Luna",
      "Sreenivas Subramoney",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2207.09765"
  },
  {
    "id": "arXiv:2207.09766",
    "title": "K-Means Based Constellation Optimization for Index Modulated  Reconfigurable Intelligent Surfaces",
    "abstract": "Reconfigurable intelligent surface (RIS) has recently emerged as a promising\ntechnology enabling next-generation wireless networks. In this paper, we\ndevelop an improved index modulation (IM) scheme by utilizing RIS to convey\ninformation. Specifically, we study an RIS-aided multiple-input single-output\n(MISO) system, in which the information bits are conveyed by reflection\npatterns of RIS rather than the conventional amplitude-phase constellation.\nFurthermore, the K-means algorithm is employed to optimize the reflection\nconstellation to improve the error performance. Also, we propose a generalized\nGray coding method for mapping information bits to an appropriate reflection\nconstellation and analytically evaluate the error performance of the proposed\nscheme by deriving a closed-form expression of the average bit error rate\n(BER). Finally, numerical results verify the accuracy of our theoretical\nanalysis as well as the substantially improved BER performance of the proposed\nRIS-based IM scheme.",
    "descriptor": "",
    "authors": [
      "Hao Liu",
      "Jiancheng An",
      "Wangyang Xu",
      "Xing Jia",
      "Lu Gan",
      "Chau Yuen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.09766"
  },
  {
    "id": "arXiv:2207.09767",
    "title": "Collaborating Domain-shared and Target-specific Feature Clustering for  Cross-domain 3D Action Recognition",
    "abstract": "In this work, we consider the problem of cross-domain 3D action recognition\nin the open-set setting, which has been rarely explored before. Specifically,\nthere is a source domain and a target domain that contain the skeleton\nsequences with different styles and categories, and our purpose is to cluster\nthe target data by utilizing the labeled source data and unlabeled target data.\nFor such a challenging task, this paper presents a novel approach dubbed CoDT\nto collaboratively cluster the domain-shared features and target-specific\nfeatures. CoDT consists of two parallel branches. One branch aims to learn\ndomain-shared features with supervised learning in the source domain, while the\nother is to learn target-specific features using contrastive learning in the\ntarget domain. To cluster the features, we propose an online clustering\nalgorithm that enables simultaneous promotion of robust pseudo label generation\nand feature clustering. Furthermore, to leverage the complementarity of\ndomain-shared features and target-specific features, we propose a novel\ncollaborative clustering strategy to enforce pair-wise relationship consistency\nbetween the two branches. We conduct extensive experiments on multiple\ncross-domain 3D action recognition datasets, and the results demonstrate the\neffectiveness of our method.",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Qinying Liu",
      "Zilei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09767"
  },
  {
    "id": "arXiv:2207.09768",
    "title": "Learning Counterfactually Invariant Predictors",
    "abstract": "We propose a method to learn predictors that are invariant under\ncounterfactual changes of certain covariates. This method is useful when the\nprediction target is causally influenced by covariates that should not affect\nthe predictor output. For instance, an object recognition model may be\ninfluenced by position, orientation, or scale of the object itself. We address\nthe problem of training predictors that are explicitly counterfactually\ninvariant to changes of such covariates. We propose a model-agnostic\nregularization term based on conditional kernel mean embeddings, to enforce\ncounterfactual invariance during training. We prove the soundness of our\nmethod, which can handle mixed categorical and continuous multi-variate\nattributes. Empirical results on synthetic and real-world data demonstrate the\nefficacy of our method in a variety of settings.",
    "descriptor": "",
    "authors": [
      "Francesco Quinzan",
      "Cecilia Casolo",
      "Krikamol Muandet",
      "Niki Kilbertus",
      "Yucen Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.09768"
  },
  {
    "id": "arXiv:2207.09769",
    "title": "A Hybrid Convolutional Neural Network with Meta Feature Learning for  Abnormality Detection in Wireless Capsule Endoscopy Images",
    "abstract": "Wireless Capsule Endoscopy is one of the most advanced non-invasive methods\nfor the examination of gastrointestinal tracts. An intelligent computer-aided\ndiagnostic system for detecting gastrointestinal abnormalities like polyp,\nbleeding, inflammation, etc. is highly exigent in wireless capsule endoscopy\nimage analysis. Abnormalities greatly differ in their shape, size, color, and\ntexture, and some appear to be visually similar to normal regions. This poses a\nchallenge in designing a binary classifier due to intra-class variations. In\nthis study, a hybrid convolutional neural network is proposed for abnormality\ndetection that extracts a rich pool of meaningful features from wireless\ncapsule endoscopy images using a variety of convolution operations. It consists\nof three parallel convolutional neural networks, each with a distinctive\nfeature learning capability. The first network utilizes depthwise separable\nconvolution, while the second employs cosine normalized convolution operation.\nA novel meta-feature extraction mechanism is introduced in the third network,\nto extract patterns from the statistical information drawn over the features\ngenerated from the first and second networks and its own previous layer. The\nnetwork trio effectively handles intra-class variance and efficiently detects\ngastrointestinal abnormalities. The proposed hybrid convolutional neural\nnetwork model is trained and tested on two widely used publicly available\ndatasets. The test results demonstrate that the proposed model outperforms six\nstate-of-the-art methods with 97\\% and 98\\% classification accuracy on KID and\nKvasir-Capsule datasets respectively. Cross dataset evaluation results also\ndemonstrate the generalization performance of the proposed model.",
    "descriptor": "",
    "authors": [
      "Samir Jain",
      "Ayan Seal",
      "Aparajita Ojha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09769"
  },
  {
    "id": "arXiv:2207.09771",
    "title": "Localization supervision of chest x-ray classifiers using label-specific  eye-tracking annotation",
    "abstract": "Convolutional neural networks (CNNs) have been successfully applied to chest\nx-ray (CXR) images. Moreover, annotated bounding boxes have been shown to\nimprove the interpretability of a CNN in terms of localizing abnormalities.\nHowever, only a few relatively small CXR datasets containing bounding boxes are\navailable, and collecting them is very costly. Opportunely, eye-tracking (ET)\ndata can be collected in a non-intrusive way during the clinical workflow of a\nradiologist. We use ET data recorded from radiologists while dictating CXR\nreports to train CNNs. We extract snippets from the ET data by associating them\nwith the dictation of keywords and use them to supervise the localization of\nabnormalities. We show that this method improves a model's interpretability\nwithout impacting its image-level classification.",
    "descriptor": "",
    "authors": [
      "Ricardo Bigolin Lanfredi",
      "Joyce D. Schroeder",
      "Tolga Tasdizen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.09771"
  },
  {
    "id": "arXiv:2207.09774",
    "title": "Drivable Volumetric Avatars using Texel-Aligned Features",
    "abstract": "Photorealistic telepresence requires both high-fidelity body modeling and\nfaithful driving to enable dynamically synthesized appearance that is\nindistinguishable from reality. In this work, we propose an end-to-end\nframework that addresses two core challenges in modeling and driving full-body\navatars of real people. One challenge is driving an avatar while staying\nfaithful to details and dynamics that cannot be captured by a global\nlow-dimensional parameterization such as body pose. Our approach supports\ndriving of clothed avatars with wrinkles and motion that a real driving\nperformer exhibits beyond the training corpus. Unlike existing global state\nrepresentations or non-parametric screen-space approaches, we introduce\ntexel-aligned features -- a localised representation which can leverage both\nthe structural prior of a skeleton-based parametric model and observed sparse\nimage signals at the same time. Another challenge is modeling a temporally\ncoherent clothed avatar, which typically requires precise surface tracking. To\ncircumvent this, we propose a novel volumetric avatar representation by\nextending mixtures of volumetric primitives to articulated objects. By\nexplicitly incorporating articulation, our approach naturally generalizes to\nunseen poses. We also introduce a localized viewpoint conditioning, which leads\nto a large improvement in generalization of view-dependent appearance. The\nproposed volumetric representation does not require high-quality mesh tracking\nas a prerequisite and brings significant quality improvements compared to\nmesh-based counterparts. In our experiments, we carefully examine our design\nchoices and demonstrate the efficacy of our approach, outperforming the\nstate-of-the-art methods on challenging driving scenarios.",
    "descriptor": "",
    "authors": [
      "Edoardo Remelli",
      "Timur Bagautdinov",
      "Shunsuke Saito",
      "Tomas Simon",
      "Chenglei Wu",
      "Shih-En Wei",
      "Kaiwen Guo",
      "Zhe Cao",
      "Fabian Prada",
      "Jason Saragih",
      "Yaser Sheikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09774"
  },
  {
    "id": "arXiv:2207.09775",
    "title": "More Practical Scenario of Open-set Object Detection: Open at Category  Level and Closed at Super-category Level",
    "abstract": "Open-set object detection (OSOD) has recently attracted considerable\nattention. It is to detect unknown objects while correctly\ndetecting/classifying known objects. We first point out that the scenario of\nOSOD considered in recent studies, which considers an unlimited variety of\nunknown objects similar to open-set recognition (OSR), has a fundamental issue.\nThat is, we cannot determine what to detect and what not for such unlimited\nunknown objects, which is necessary for detection tasks. This issue leads to\ndifficulty with the evaluation of methods' performance on unknown object\ndetection. We then introduce a novel scenario of OSOD, which deals with only\nunknown objects that share the super-category with known objects. It has many\nreal-world applications, e.g., detecting an increasing number of fine-grained\nobjects. This new setting is free from the above issue and evaluation\ndifficulty. Moreover, it makes detecting unknown objects more realistic owing\nto the visual similarity between known and unknown objects. We show through\nexperimental results that a simple method based on the uncertainty of class\nprediction from standard detectors outperforms the current state-of-the-art\nOSOD methods tested in the previous setting.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Yusuke Hosoya",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09775"
  },
  {
    "id": "arXiv:2207.09776",
    "title": "Numerical solution of kinetic SPDEs via stochastic Magnus expansion",
    "abstract": "In this paper, we show how the It\\^o-stochastic Magnus expansion can be used\nto efficiently solve stochastic partial differential equations (SPDE) with two\nspace variables numerically. To this end, we will first discretize the SPDE in\nspace only by utilizing finite difference methods and vectorize the resulting\nequation exploiting its sparsity. As a benchmark, we will apply it to the case\nof the stochastic Langevin equation with constant coefficients, where an\nexplicit solution is available, and compare the Magnus scheme with the\nEuler-Maruyama scheme. We will see that the Magnus expansion is superior in\nterms of both accuracy and especially computational time by using a single GPU\nand verify it in a variable coefficient case. Notably, we will see speed-ups of\norder ranging form 20 to 200 compared to the Euler-Maruyama scheme, depending\non the accuracy target and the spatial resolution.",
    "descriptor": "",
    "authors": [
      "Kevin Kamm",
      "Stefano Pagliarani",
      "Andrea Pascucci"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2207.09776"
  },
  {
    "id": "arXiv:2207.09777",
    "title": "AU-Supervised Convolutional Vision Transformers for Synthetic Facial  Expression Recognition",
    "abstract": "The paper describes our proposed methodology for the six basic expression\nclassification track of Affective Behavior Analysis in-the-wild (ABAW)\nCompetition 2022. In Learing from Synthetic Data(LSD) task, facial expression\nrecognition (FER) methods aim to learn the representation of expression from\nthe artificially generated data and generalise to real data. Because of the\nambiguous of the synthetic data and the objectivity of the facial Action Unit\n(AU), we resort to the AU information for performance boosting, and make\ncontributions as follows. First, to adapt the model to synthetic scenarios, we\nuse the knowledge from pre-trained large-scale face recognition data. Second,\nwe propose a conceptually-new framework, termed as AU-Supervised Convolutional\nVision Transformers (AU-CVT), which clearly improves the performance of FER by\njointly training auxiliary datasets with AU or pseudo AU labels. Our AU-CVT\nachieved F1 score as $0.6863$, accuracy as $0.7433$ on the validation set. The\nsource code of our work is publicly available online:\nhttps://github.com/msy1412/ABAW4",
    "descriptor": "",
    "authors": [
      "Shuyi Mao",
      "Xinpeng Li",
      "Junyao Chen",
      "Xiaojiang Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09777"
  },
  {
    "id": "arXiv:2207.09778",
    "title": "CoSMix: Compositional Semantic Mix for Domain Adaptation in 3D LiDAR  Segmentation",
    "abstract": "3D LiDAR semantic segmentation is fundamental for autonomous driving. Several\nUnsupervised Domain Adaptation (UDA) methods for point cloud data have been\nrecently proposed to improve model generalization for different sensors and\nenvironments. Researchers working on UDA problems in the image domain have\nshown that sample mixing can mitigate domain shift. We propose a new approach\nof sample mixing for point cloud UDA, namely Compositional Semantic Mix\n(CoSMix), the first UDA approach for point cloud segmentation based on sample\nmixing. CoSMix consists of a two-branch symmetric network that can process\nlabelled synthetic data (source) and real-world unlabelled point clouds\n(target) concurrently. Each branch operates on one domain by mixing selected\npieces of data from the other one, and by using the semantic information\nderived from source labels and target pseudo-labels. We evaluate CoSMix on two\nlarge-scale datasets, showing that it outperforms state-of-the-art methods by a\nlarge margin. Our code is available at\nhttps://github.com/saltoricristiano/cosmix-uda.",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Cristiano Saltori",
      "Fabio Galasso",
      "Giuseppe Fiameni",
      "Nicu Sebe",
      "Elisa Ricci",
      "Fabio Poiesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09778"
  },
  {
    "id": "arXiv:2207.09783",
    "title": "Cancer Subtyping by Improved Transcriptomic Features Using Vector  Quantized Variational Autoencoder",
    "abstract": "Defining and separating cancer subtypes is essential for facilitating\npersonalized therapy modality and prognosis of patients. The definition of\nsubtypes has been constantly recalibrated as a result of our deepened\nunderstanding. During this recalibration, researchers often rely on clustering\nof cancer data to provide an intuitive visual reference that could reveal the\nintrinsic characteristics of subtypes. The data being clustered are often omics\ndata such as transcriptomics that have strong correlations to the underlying\nbiological mechanism. However, while existing studies have shown promising\nresults, they suffer from issues associated with omics data: sample scarcity\nand high dimensionality. As such, existing methods often impose unrealistic\nassumptions to extract useful features from the data while avoiding overfitting\nto spurious correlations. In this paper, we propose to leverage a recent strong\ngenerative model, Vector Quantized Variational AutoEncoder (VQ-VAE), to tackle\nthe data issues and extract informative latent features that are crucial to the\nquality of subsequent clustering by retaining only information relevant to\nreconstructing the input. VQ-VAE does not impose strict assumptions and hence\nits latent features are better representations of the input, capable of\nyielding superior clustering performance with any mainstream clustering method.\nExtensive experiments and medical analysis on multiple datasets comprising 10\ndistinct cancers demonstrate the VQ-VAE clustering results can significantly\nand robustly improve prognosis over prevalent subtyping systems.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Zheng Chen",
      "Ziwei Yang",
      "Lingwei Zhu",
      "Guang Shi",
      "Kun Yue",
      "Takashi Matsubara",
      "Shigehiko Kanaya",
      "MD Altaf-Ul-Amin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09783"
  },
  {
    "id": "arXiv:2207.09784",
    "title": "Anomaly Detection of Smart Metering System for Power Management with  Battery Storage System/Electric Vehicle",
    "abstract": "A novel smart metering technique capable of anomaly detection was proposed\nfor real-time home power management system. Smart meter data generated in\nreal-time was obtained from 900 households of single apartments. To detect\noutliers and missing values in smart meter data, a deep learning model, the\nautoencoder, consisting of a graph convolutional network and bidirectional long\nshort-term memory network, was applied to the smart metering technique. Power\nmanagement based on the smart metering technique was performed by\nmulti-objective optimization in the presence of a battery storage system and an\nelectric vehicle. The results of the power management employing the proposed\nsmart metering technique indicate a reduction in electricity cost and amount of\npower supplied by the grid compared to the results of power management without\nanomaly detection.",
    "descriptor": "\nComments: Accepted at ETRI Journal\n",
    "authors": [
      "Sangkeum Lee",
      "Sarvar Hussain Nengroo",
      "Hojun Jin",
      "Yoonmee Doh",
      "Chungho Lee",
      "Taewook Heo",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09784"
  },
  {
    "id": "arXiv:2207.09786",
    "title": "Non-Uniform Diffusion Models",
    "abstract": "Diffusion models have emerged as one of the most promising frameworks for\ndeep generative modeling. In this work, we explore the potential of non-uniform\ndiffusion models. We show that non-uniform diffusion leads to multi-scale\ndiffusion models which have similar structure to this of multi-scale\nnormalizing flows. We experimentally find that in the same or less training\ntime, the multi-scale diffusion model achieves better FID score than the\nstandard uniform diffusion model. More importantly, it generates samples $4.4$\ntimes faster in $128\\times 128$ resolution. The speed-up is expected to be\nhigher in higher resolutions where more scales are used. Moreover, we show that\nnon-uniform diffusion leads to a novel estimator for the conditional score\nfunction which achieves on par performance with the state-of-the-art\nconditional denoising estimator. Our theoretical and experimental findings are\naccompanied by an open source library MSDiff which can facilitate further\nresearch of non-uniform diffusion models.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.13606\n",
    "authors": [
      "Georgios Batzolis",
      "Jan Stanczuk",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Christian Etmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09786"
  },
  {
    "id": "arXiv:2207.09790",
    "title": "FaceFormer: Scale-aware Blind Face Restoration with Transformers",
    "abstract": "Blind face restoration usually encounters with diverse scale face inputs,\nespecially in the real world. However, most of the current works support\nspecific scale faces, which limits its application ability in real-world\nscenarios. In this work, we propose a novel scale-aware blind face restoration\nframework, named FaceFormer, which formulates facial feature restoration as\nscale-aware transformation. The proposed Facial Feature Up-sampling (FFUP)\nmodule dynamically generates upsampling filters based on the original\nscale-factor priors, which facilitate our network to adapt to arbitrary face\nscales. Moreover, we further propose the facial feature embedding (FFE) module\nwhich leverages transformer to hierarchically extract diversity and robustness\nof facial latent. Thus, our FaceFormer achieves fidelity and robustness\nrestored faces, which possess realistic and symmetrical details of facial\ncomponents. Extensive experiments demonstrate that our proposed method trained\nwith synthetic dataset generalizes better to a natural low quality images than\ncurrent state-of-the-arts.",
    "descriptor": "",
    "authors": [
      "Aijin Li",
      "Gen Li",
      "Lei Sun",
      "Xintao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09790"
  },
  {
    "id": "arXiv:2207.09791",
    "title": "Schwarz methods by domain truncation",
    "abstract": "Schwarz methods use a decomposition of the computational domain into\nsubdomains and need to put boundary conditions on the subdomain boundaries. In\ndomain truncation one restricts the unbounded domain to a bounded computational\ndomain and also needs to put boundary conditions on the computational domain\nboundaries. It turns out to be fruitful to think of the domain decomposition in\nSchwarz methods as truncation of the domain onto subdomains. The first truly\noptimal Schwarz method that converges in a finite number of steps was proposed\nin 1994 and used precisely transparent boundary conditions as transmission\nconditions between subdomains. Approximating these transparent boundary\nconditions for fast convergence of Schwarz methods led to the development of\noptimized Schwarz methods -- a name that has become common for Schwarz methods\nbased on domain truncation. Compared to classical Schwarz methods which use\nsimple Dirichlet transmission conditions and have been successfully used in a\nwide range of applications, optimized Schwarz methods are much less well\nunderstood, mainly due to their more sophisticated transmission conditions.\nThis present situation is the motivation for our survey: to give a\ncomprehensive review and precise exploration of convergence behaviors of\noptimized Schwarz methods based on Fourier analysis taking into account the\noriginal boundary conditions, many subdomain decompositions and layered media.\nThe transmission conditions we study include the lowest order absorbing\nconditions (Robin), and also more advanced perfectly matched layers (PML), both\ndeveloped first for domain truncation.",
    "descriptor": "\nComments: 32MB, 137 pages, a lot of figures\n",
    "authors": [
      "Martin J. Gander",
      "Hui Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.09791"
  },
  {
    "id": "arXiv:2207.09792",
    "title": "Unsupervised Industrial Anomaly Detection via Pattern Generative and  Contrastive Networks",
    "abstract": "It is hard to collect enough flaw images for training deep learning network\nin industrial production. Therefore, existing industrial anomaly detection\nmethods prefer to use CNN-based unsupervised detection and localization network\nto achieve this task. However, these methods always fail when there are\nvarieties happened in new signals since traditional end-to-end networks suffer\nbarriers of fitting nonlinear model in high-dimensional space. Moreover, they\nhave a memory library by clustering the feature of normal images essentially,\nwhich cause it is not robust to texture change. To this end, we propose the\nVision Transformer based (VIT-based) unsupervised anomaly detection network. It\nutilizes a hierarchical task learning and human experience to enhance its\ninterpretability. Our network consists of pattern generation and comparison\nnetworks. Pattern generation network uses two VIT-based encoder modules to\nextract the feature of two consecutive image patches, then uses VIT-based\ndecoder module to learn the human designed style of these features and predict\nthe third image patch. After this, we use the Siamese-based network to compute\nthe similarity of the generation image patch and original image patch. Finally,\nwe refine the anomaly localization by the bi-directional inference strategy.\nComparison experiments on public dataset MVTec dataset show our method achieves\n99.8% AUC, which surpasses previous state-of-the-art methods. In addition, we\ngive a qualitative illustration on our own leather and cloth datasets. The\naccurate segment results strongly prove the accuracy of our method in anomaly\ndetection.",
    "descriptor": "",
    "authors": [
      "Jianfeng Huang",
      "Chenyang Li",
      "Yimin Lin",
      "Shiguo Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09792"
  },
  {
    "id": "arXiv:2207.09796",
    "title": "EASNet: Searching Elastic and Accurate Network Architecture for Stereo  Matching",
    "abstract": "Recent advanced studies have spent considerable human efforts on optimizing\nnetwork architectures for stereo matching but hardly achieved both high\naccuracy and fast inference speed. To ease the workload in network design,\nneural architecture search (NAS) has been applied with great success to various\nsparse prediction tasks, such as image classification and object detection.\nHowever, existing NAS studies on the dense prediction task, especially stereo\nmatching, still cannot be efficiently and effectively deployed on devices of\ndifferent computing capabilities. To this end, we propose to train an elastic\nand accurate network for stereo matching (EASNet) that supports various 3D\narchitectural settings on devices with different computing capabilities. Given\nthe deployment latency constraint on the target device, we can quickly extract\na sub-network from the full EASNet without additional training while the\naccuracy of the sub-network can still be maintained. Extensive experiments show\nthat our EASNet outperforms both state-of-the-art human-designed and NAS-based\narchitectures on Scene Flow and MPI Sintel datasets in terms of model accuracy\nand inference speed. Particularly, deployed on an inference GPU, EASNet\nachieves a new SOTA 0.73 EPE on the Scene Flow dataset with 100 ms, which is\n4.5$\\times$ faster than LEAStereo with a better quality model.",
    "descriptor": "",
    "authors": [
      "Qiang Wang",
      "Shaohuai Shi",
      "Kaiyong Zhao",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09796"
  },
  {
    "id": "arXiv:2207.09797",
    "title": "Exact Matching: Correct Parity and FPT Parameterized by Independence  Number",
    "abstract": "Given an integer $k$ and a graph where every edge is colored either red or\nblue, the goal of the exact matching problem is to find a perfect matching with\nthe property that exactly $k$ of its edges are red. Soon after Papadimitriou\nand Yannakakis introduced the problem in 1982, a randomized polynomial-time\nalgorithm solving the problem was described by Mulmuley et al. Despite a lot of\neffort, it is still not known today whether a deterministic polynomial-time\nalgorithm exists. This makes the exact matching problem an important candidate\nto test the popular conjecture that the complexity classes P and RP are equal.\nIn a recent article, progress was made towards this goal by showing that for\n(bipartite) graphs of bounded (bipartite) independence number, a polynomial\ntime algorithm exists. In terms of parameterized complexity, this algorithm was\nan XP-algorithm parameterized by the independence number. In this article, we\nimprove the techniques to obtain an FPT-algorithm for bipartite graphs. If the\ninput is a general graph we show that one can at least compute a perfect\nmatching $M$ which has the correct number of red edges modulo 2. This is\nmotivated by our last result, in which we prove that an FPT algorithm for\ngeneral graphs reduces to the problem of finding in polynomial time a perfect\nmatching $M$ with the correct number of red edges modulo 2 and additionally at\nmost $k$ red edges.",
    "descriptor": "",
    "authors": [
      "Nicolas El Maalouly",
      "Raphael Steiner",
      "Lasse Wulf"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2207.09797"
  },
  {
    "id": "arXiv:2207.09800",
    "title": "The community structure of collaboration networks in computer science  and its impact on scientific production and consumption",
    "abstract": "Collaboration networks, where nodes represent authors and edges coauthorships\namong them, are key to understanding the consumption, production, and diffusion\nof knowledge. Due to social mechanisms, biases, and constraints at play, these\nnetworks are organized in tight communities with different levels of\nsegregation. Here, we aim to quantify the extent and impact of segregation in\ncollaboration networks. We study the field of Computer Science via the Semantic\nScholar Open Research Corpus. We measure the segregation of communities using\nthe Spectral Segregation Index (SSI) and find three categories: non-segregated,\nmoderately segregated, and highly segregated communities. We focus our\nattention on non-segregated and highly segregated communities, quantifying and\ncomparing their structural topology and core location. When we consider\ncommunities of both categories in the same size range, our results show no\ndifferences in density and clustering, but evident variability in their core\nposition. As community size increases, communities are more likely to occupy a\ncore closer to the network nucleus. However, controlling for size, highly\nsegregated communities tend to be located closer to the network periphery than\nnon-segregated communities. Finally, we analyse differences in citations gained\nby researchers depending on their community segregation level. Interestingly,\nresearchers in highly segregated communities gain more citations per\npublication when located in the periphery. They have a higher chance of\nreceiving citations from members of their same community in all cores.\nResearchers in non-segregated communities accrue more citations per publication\nin intermediary and central cores. To our knowledge, our work is the first to\ncharacterise segregated communities in scientific collaboration networks and to\ninvestigate their relationship with the impact measured in terms of citations.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Ana Maria Jaramillo",
      "Hywel T.P. Williams",
      "Nicola Perra",
      "Ronaldo Menezes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.09800"
  },
  {
    "id": "arXiv:2207.09803",
    "title": "Computing Densest $k$-Subgraph with Structural Parameters",
    "abstract": "\\textsc{Densest $k$-Subgraph} is the problem to find a vertex subset $S$ of\nsize $k$ such that the number of edges in the subgraph induced by $S$ is\nmaximized. In this paper, we show that \\textsc{Densest $k$-Subgraph} is fixed\nparameter tractable when parameterized by neighborhood diversity, block\ndeletion number, distance-hereditary deletion number, and cograph deletion\nnumber, respectively. Furthermore, we give a $2$-approximation\n$2^{\\tc(G)/2}n^{O(1)}$-time algorithm where $\\tc(G)$ is the twin cover number\nof an input graph $G$.",
    "descriptor": "",
    "authors": [
      "Tesshu Hanaka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.09803"
  },
  {
    "id": "arXiv:2207.09805",
    "title": "Multimodal Transformer for Automatic 3D Annotation and Object Detection",
    "abstract": "Despite a growing number of datasets being collected for training 3D object\ndetection models, significant human effort is still required to annotate 3D\nboxes on LiDAR scans. To automate the annotation and facilitate the production\nof various customized datasets, we propose an end-to-end multimodal transformer\n(MTrans) autolabeler, which leverages both LiDAR scans and images to generate\nprecise 3D box annotations from weak 2D bounding boxes. To alleviate the\npervasive sparsity problem that hinders existing autolabelers, MTrans densifies\nthe sparse point clouds by generating new 3D points based on 2D image\ninformation. With a multi-task design, MTrans segments the\nforeground/background, densifies LiDAR point clouds, and regresses 3D boxes\nsimultaneously. Experimental results verify the effectiveness of the MTrans for\nimproving the quality of the generated labels. By enriching the sparse point\nclouds, our method achieves 4.48\\% and 4.03\\% better 3D AP on KITTI moderate\nand hard samples, respectively, versus the state-of-the-art autolabeler. MTrans\ncan also be extended to improve the accuracy for 3D object detection, resulting\nin a remarkable 89.45\\% AP on KITTI hard samples. Codes are at\n\\url{https://github.com/Cliu2/MTrans}.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Chang Liu",
      "Xiaoyan Qian",
      "Binxiao Huang",
      "Xiaojuan Qi",
      "Edmund Lam",
      "Siew-Chong Tan",
      "Ngai Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09805"
  },
  {
    "id": "arXiv:2207.09812",
    "title": "The Anatomy of Video Editing: A Dataset and Benchmark Suite for  AI-Assisted Video Editing",
    "abstract": "Machine learning is transforming the video editing industry. Recent advances\nin computer vision have leveled-up video editing tasks such as intelligent\nreframing, rotoscoping, color grading, or applying digital makeups. However,\nmost of the solutions have focused on video manipulation and VFX. This work\nintroduces the Anatomy of Video Editing, a dataset, and benchmark, to foster\nresearch in AI-assisted video editing. Our benchmark suite focuses on video\nediting tasks, beyond visual effects, such as automatic footage organization\nand assisted video assembling. To enable research on these fronts, we annotate\nmore than 1.5M tags, with relevant concepts to cinematography, from 196176\nshots sampled from movie scenes. We establish competitive baseline methods and\ndetailed analyses for each of the tasks. We hope our work sparks innovative\nresearch towards underexplored areas of AI-assisted video editing.",
    "descriptor": "",
    "authors": [
      "Dawit Mureja Argaw",
      "Fabian Caba Heilbron",
      "Joon-Young Lee",
      "Markus Woodson",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09812"
  },
  {
    "id": "arXiv:2207.09813",
    "title": "A Shared Autonomy Reconfigurable Control Framework for Telemanipulation  of Multi-arm Systems",
    "abstract": "Teleoperation is a widely adopted strategy to control robotic manipulators\nexecuting complex tasks that require highly dexterous movements and critical\nhigh-level intelligence. Classical teleoperation schemes are based on either\njoystick control, or on more intuitive interfaces which map directly the user\narm motions into one robot arm's motions. These approaches have limits when the\nexecution of a given task requires reconfigurable multiple robotic arm systems.\nIndeed, the simultaneous teleoperation of two or more robot arms could extend\nthe workspace of the manipulation cell, or increase its total payload, or\nafford other advantages. In different phases of a reconfigurable multi-arm\nsystem, each robot could act as an independent arm, or as one of a pair of\ncooperating arms, or as one of the fingers of a virtual, large robot hand. This\nmanuscript proposes a novel telemanipulation framework that enables both the\nindividual and combined control of any number of robotic arms. Thanks to the\ndesigned control architecture, the human operator can intuitively choose the\nproposed control modalities and the manipulators that make the task convenient\nto execute through the user interface. Moreover, through the tele-impedance\nparadigm, the system can address complex tasks that require physical\ninteraction by letting the robot mimic the arm impedance and position\nreferences of the human operator. The proposed framework is validated with 8\nsubjects controlling 4 Franka Emika Panda robots with 7-DoFs to execute a\ntelemanipulation task. Qualitative results of the experiments show us the\npromising applicability of our framework.",
    "descriptor": "\nComments: 8 pages, 8 figures, accepted to IEEE Robotics and Automation Letters, for associated video, see this https URL\n",
    "authors": [
      "Idil Ozdamar",
      "Marco Laghi",
      "Giorgio Grioli",
      "Arash Ajoudani",
      "Manuel G. Catalano",
      "Antonio Bicchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.09813"
  },
  {
    "id": "arXiv:2207.09814",
    "title": "NUWA-Infinity: Autoregressive over Autoregressive Generation for  Infinite Visual Synthesis",
    "abstract": "In this paper, we present NUWA-Infinity, a generative model for infinite\nvisual synthesis, which is defined as the task of generating arbitrarily-sized\nhigh-resolution images or long-duration videos. An autoregressive over\nautoregressive generation mechanism is proposed to deal with this variable-size\ngeneration task, where a global patch-level autoregressive model considers the\ndependencies between patches, and a local token-level autoregressive model\nconsiders dependencies between visual tokens within each patch. A Nearby\nContext Pool (NCP) is introduced to cache-related patches already generated as\nthe context for the current patch being generated, which can significantly save\ncomputation costs without sacrificing patch-level dependency modeling. An\nArbitrary Direction Controller (ADC) is used to decide suitable generation\norders for different visual synthesis tasks and learn order-aware positional\nembeddings. Compared to DALL-E, Imagen and Parti, NUWA-Infinity can generate\nhigh-resolution images with arbitrary sizes and support long-duration video\ngeneration additionally. Compared to NUWA, which also covers images and videos,\nNUWA-Infinity has superior visual synthesis capabilities in terms of resolution\nand variable-size generation. The GitHub link is\nhttps://github.com/microsoft/NUWA. The homepage link is\nhttps://nuwa-infinity.microsoft.com.",
    "descriptor": "\nComments: 24 pages, 19 figures\n",
    "authors": [
      "Chenfei Wu",
      "Jian Liang",
      "Xiaowei Hu",
      "Zhe Gan",
      "Jianfeng Wang",
      "Lijuan Wang",
      "Zicheng Liu",
      "Yuejian Fang",
      "Nan Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09814"
  },
  {
    "id": "arXiv:2207.09818",
    "title": "Operating Envelopes under Probabilistic Electricity Demand and Solar  Generation Forecasts",
    "abstract": "The increasing penetration of distributed energy resources in low-voltage\nnetworks is turning end-users from consumers to prosumers. However, the\nincomplete smart meter rollout and paucity of smart meter data due to the\nregulatory separation between retail and network service provision make active\ndistribution network management difficult. Furthermore, distribution network\noperators oftentimes do not have access to real-time smart meter data, which\ncreates an additional challenge. For the lack of better solutions, they use\nblanket rooftop solar export limits, leading to suboptimal outcomes. To address\nthis, we designed a conditional generative adversarial network (CGAN)-based\nmodel to forecast household solar generation and electricity demand, which\nserves as an input to chance-constrained optimal power flow used to compute\nfair operating envelopes under uncertainty.",
    "descriptor": "\nComments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Yu Yi",
      "Gregor Verbic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09818"
  },
  {
    "id": "arXiv:2207.09821",
    "title": "Journal Impact Factor and Peer Review Thoroughness and Helpfulness: A  Supervised Machine Learning Study",
    "abstract": "The journal impact factor (JIF) is often equated with journal quality and the\nquality of the peer review of the papers submitted to the journal. We examined\nthe association between the content of peer review and JIF by analysing 10,000\npeer review reports submitted to 1,644 medical and life sciences journals. Two\nresearchers hand-coded a random sample of 2,000 sentences. We then trained\nmachine learning models to classify all 187,240 sentences as contributing or\nnot contributing to content categories. We examined the association between ten\ngroups of journals defined by JIF deciles and the content of peer reviews using\nlinear mixed-effects models, adjusting for the length of the review. The JIF\nranged from 0.21 to 74.70. The length of peer reviews increased from the lowest\n(median number of words 185) to the JIF group (387 words). The proportion of\nsentences allocated to different content categories varied widely, even within\nJIF groups. For thoroughness, sentences on 'Materials and Methods' were more\ncommon in the highest JIF journals than in the lowest JIF group (difference of\n7.8 percentage points; 95% CI 4.9 to 10.7%). The trend for 'Presentation and\nReporting' went in the opposite direction, with the highest JIF journals giving\nless emphasis to such content (difference -8.9%; 95% CI -11.3 to -6.5%). For\nhelpfulness, reviews for higher JIF journals devoted less attention to\n'Suggestion and Solution' and provided fewer Examples than lower impact factor\njournals. No, or only small differences were evident for other content\ncategories. In conclusion, peer review in journals with higher JIF tends to be\nmore thorough in discussing the methods used but less helpful in terms of\nsuggesting solutions and providing examples. Differences were modest and\nvariability high, indicating that the JIF is a bad predictor for the quality of\npeer review of an individual manuscript.",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Anna Severin",
      "Michaela Strinzel",
      "Matthias Egger",
      "Tiago Barros",
      "Alexander Sokolov",
      "Julia Vilstrup Mouatt",
      "Stefan M\u00fcller"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.09821"
  },
  {
    "id": "arXiv:2207.09823",
    "title": "Joint Precoding and Artificial Noise Design for MU-MIMO Wiretap Channels",
    "abstract": "Secure precoding superimposed with artificial noise (AN) is a promising\ntransmission technique to improve security by harnessing the superposition\nnature of the wireless medium. However, finding a jointly optimal precoding and\nAN structure is very challenging in downlink multi-user multiple-input\nmultiple-output (MU-MIMO) wiretap channels with multiple eavesdroppers. The\nmajor challenge in maximizing the secrecy rate arises from the non-convexity\nand non-smoothness of the rate function. Traditionally, an alternating\noptimization framework that identifies beamforming vectors and AN covariance\nmatrix has been adopted; yet this alternating approach has limitations in\nmaximizing the secrecy rate. In this paper, we put forth a novel secure\nprecoding algorithm that jointly and simultaneously optimizes the beams and AN\ncovariance matrix for maximizing the secrecy rate when a transmitter has either\nperfect or partial channel knowledge of eavesdroppers. To this end, we first\nestablish an approximate secrecy rate in a smooth function. Then, we derive the\nfirst-order optimality condition in the form of the nonlinear eigenvalue\nproblem (NEP). We present a computationally efficient algorithm to identify the\nprincipal eigenvector of the NEP as a suboptimal solution for secure precoding.\nSimulations demonstrate that the proposed methods improve secrecy rate\nsignificantly compared to the existing secure precoding methods.",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Eunsung Choi",
      "Mintaek Oh",
      "Jinseok Choi",
      "Jeonghun Park",
      "Namyoon Lee",
      "Naofal Al-Dhahir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.09823"
  },
  {
    "id": "arXiv:2207.09827",
    "title": "Comparing directed networks via denoising graphlet distributions",
    "abstract": "Network comparison is a widely-used tool for analyzing complex systems, with\napplications in varied domains including comparison of protein interactions or\nhighlighting changes in structure of trade networks. In recent years, a number\nof network comparison methodologies based on the distribution of graphlets\n(small connected network subgraphs) have been introduced. In particular, NetEmd\nhas recently achieved state of the art performance in undirected networks. In\nthis work, we propose an extension of NetEmd to directed networks and deal with\nthe significant increase in complexity of graphlet structure in the directed\ncase by denoising through linear projections. Simulation results show that our\nframework is able to improve on the performance of a simple translation of the\nundirected NetEmd algorithm to the directed case, especially when networks\ndiffer in size and density.",
    "descriptor": "",
    "authors": [
      "Miguel E. P. Silva",
      "Robert E. Gaunt",
      "Luis Ospina-Forero",
      "Caroline Jay",
      "Thomas House"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2207.09827"
  },
  {
    "id": "arXiv:2207.09828",
    "title": "${\\mathcal K}$-monotonicity and feedback synthesis for incrementally  stable networks",
    "abstract": "We discuss the role of monotonicity in enabling numerically tractable modular\ncontrol design for networked nonlinear systems. We first show that the\nvariational systems of monotone systems can be embedded into positive systems.\nUtilizing this embedding, we show how to solve a network stabilization problem\nby enforcing monotonicity and exponential dissipativity of the network\nsub-components. Such modular approach leads to a design algorithm based on a\nsequence of linear programming problems.",
    "descriptor": "",
    "authors": [
      "Yu Kawano",
      "Fulvio Forni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.09828"
  },
  {
    "id": "arXiv:2207.09830",
    "title": "The Atlas Benchmark: an Automated Evaluation Framework for Human Motion  Prediction",
    "abstract": "Human motion trajectory prediction, an essential task for autonomous systems\nin many domains, has been on the rise in recent years. With a multitude of new\nmethods proposed by different communities, the lack of standardized benchmarks\nand objective comparisons is increasingly becoming a major limitation to assess\nprogress and guide further research. Existing benchmarks are limited in their\nscope and flexibility to conduct relevant experiments and to account for\ncontextual cues of agents and environments. In this paper we present Atlas, a\nbenchmark to systematically evaluate human motion trajectory prediction\nalgorithms in a unified framework. Atlas offers data preprocessing functions,\nhyperparameter optimization, comes with popular datasets and has the\nflexibility to setup and conduct underexplored yet relevant experiments to\nanalyze a method's accuracy and robustness. In an example application of Atlas,\nwe compare five popular model- and learning-based predictors and find that,\nwhen properly applied, early physics-based approaches are still remarkably\ncompetitive. Such results confirm the necessity of benchmarks like Atlas.",
    "descriptor": "\nComments: Accepted to and will be presented at the IEEE RO-MAN 2022 conference\n",
    "authors": [
      "Andrey Rudenko",
      "Luigi Palmieri",
      "Wanting Huang",
      "Achim J. Lilienthal",
      "Kai O. Arras"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.09830"
  },
  {
    "id": "arXiv:2207.09833",
    "title": "AI Fairness: from Principles to Practice",
    "abstract": "This paper summarizes and evaluates various approaches, methods, and\ntechniques for pursuing fairness in artificial intelligence (AI) systems. It\nexamines the merits and shortcomings of these measures and proposes practical\nguidelines for defining, measuring, and preventing bias in AI. In particular,\nit cautions against some of the simplistic, yet common, methods for evaluating\nbias in AI systems, and offers more sophisticated and effective alternatives.\nThe paper also addresses widespread controversies and confusions in the field\nby providing a common language among different stakeholders of high-impact AI\nsystems. It describes various trade-offs involving AI fairness, and provides\npractical recommendations for balancing them. It offers techniques for\nevaluating the costs and benefits of fairness targets, and defines the role of\nhuman judgment in setting these targets. This paper provides discussions and\nguidelines for AI practitioners, organization leaders, and policymakers, as\nwell as various links to additional materials for a more technical audience.\nNumerous real-world examples are provided to clarify the concepts, challenges,\nand recommendations from a practical perspective.",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Arash Bateni",
      "Matthew C. Chan",
      "Ray Eitel-Porter"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09833"
  },
  {
    "id": "arXiv:2207.09835",
    "title": "UNIF: United Neural Implicit Functions for Clothed Human Reconstruction  and Animation",
    "abstract": "We propose united implicit functions (UNIF), a part-based method for clothed\nhuman reconstruction and animation with raw scans and skeletons as the input.\nPrevious part-based methods for human reconstruction rely on ground-truth part\nlabels from SMPL and thus are limited to minimal-clothed humans. In contrast,\nour method learns to separate parts from body motions instead of part\nsupervision, thus can be extended to clothed humans and other articulated\nobjects. Our Partition-from-Motion is achieved by a bone-centered\ninitialization, a bone limit loss, and a section normal loss that ensure stable\npart division even when the training poses are limited. We also present a\nminimal perimeter loss for SDF to suppress extra surfaces and part overlapping.\nAnother core of our method is an adjacent part seaming algorithm that produces\nnon-rigid deformations to maintain the connection between parts which\nsignificantly relieves the part-based artifacts. Under this algorithm, we\nfurther propose \"Competing Parts\", a method that defines blending weights by\nthe relative position of a point to bones instead of the absolute position,\navoiding the generalization problem of neural implicit functions with inverse\nLBS (linear blend skinning). We demonstrate the effectiveness of our method by\nclothed human body reconstruction and animation on the CAPE and the ClothSeq\ndatasets.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Shenhan Qian",
      "Jiale Xu",
      "Ziwei Liu",
      "Liqian Ma",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09835"
  },
  {
    "id": "arXiv:2207.09840",
    "title": "EleGANt: Exquisite and Locally Editable GAN for Makeup Transfer",
    "abstract": "Most existing methods view makeup transfer as transferring color\ndistributions of different facial regions and ignore details such as eye\nshadows and blushes. Besides, they only achieve controllable transfer within\npredefined fixed regions. This paper emphasizes the transfer of makeup details\nand steps towards more flexible controls. To this end, we propose Exquisite and\nlocally editable GAN for makeup transfer (EleGANt). It encodes facial\nattributes into pyramidal feature maps to preserves high-frequency information.\nIt uses attention to extract makeup features from the reference and adapt them\nto the source face, and we introduce a novel Sow-Attention Module that applies\nattention within shifted overlapped windows to reduce the computational cost.\nMoreover, EleGANt is the first to achieve customized local editing within\narbitrary areas by corresponding editing on the feature maps. Extensive\nexperiments demonstrate that EleGANt generates realistic makeup faces with\nexquisite details and achieves state-of-the-art performance. The code is\navailable at https://github.com/Chenyu-Yang-2000/EleGANt.",
    "descriptor": "",
    "authors": [
      "Chenyu Yang",
      "Wanrong He",
      "Yingqing Xu",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09840"
  },
  {
    "id": "arXiv:2207.09844",
    "title": "Stability and interpolation properties for Stokes-like virtual element  spaces",
    "abstract": "We prove stability bounds for Stokes-like virtual element spaces in two and\nthree dimensions. Such bounds are also instrumental in deriving optimal\ninterpolation estimates. Furthermore, we develop some numerical tests in order\nto investigate the behaviour of the stability constants also from the practical\nside.",
    "descriptor": "",
    "authors": [
      "L. Beir\u00e3o da Veiga",
      "L. Mascotto",
      "J. Meng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.09844"
  },
  {
    "id": "arXiv:2207.09845",
    "title": "Quantifying the Effect of Feedback Frequency in Interactive  Reinforcement Learning for Robotic Tasks",
    "abstract": "Reinforcement learning (RL) has become widely adopted in robot control.\nDespite many successes, one major persisting problem can be very low data\nefficiency. One solution is interactive feedback, which has been shown to speed\nup RL considerably. As a result, there is an abundance of different strategies,\nwhich are, however, primarily tested on discrete grid-world and small scale\noptimal control scenarios. In the literature, there is no consensus about which\nfeedback frequency is optimal or at which time the feedback is most beneficial.\nTo resolve these discrepancies we isolate and quantify the effect of feedback\nfrequency in robotic tasks with continuous state and action spaces. The\nexperiments encompass inverse kinematics learning for robotic manipulator arms\nof different complexity. We show that seemingly contradictory reported\nphenomena occur at different complexity levels. Furthermore, our results\nsuggest that no single ideal feedback frequency exists. Rather that feedback\nfrequency should be changed as the agent's proficiency in the task increases.",
    "descriptor": "\nComments: Neural Computing and Applications. Special Issue on Human-aligned Reinforcement Learning for Autonomous Agents and Robots\n",
    "authors": [
      "Daniel Harnack",
      "Julie Pivin-Bachler",
      "Nicol\u00e1s Navarro-Guerrero"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09845"
  },
  {
    "id": "arXiv:2207.09847",
    "title": "Predicting Word Learning in Children from the Performance of Computer  Vision Systems",
    "abstract": "For human children as well as machine learning systems, a key challenge in\nlearning a word is linking the word to the visual phenomena it describes. We\nexplore this aspect of word learning by using the performance of computer\nvision systems as a proxy for the difficulty of learning a word from visual\ncues. We show that the age at which children acquire different categories of\nwords is predicted by the performance of visual classification and captioning\nsystems, over and above the expected effects of word frequency. The performance\nof the computer vision systems is related to human judgments of the\nconcreteness of words, supporting the idea that we are capturing the\nrelationship between words and visual phenomena.",
    "descriptor": "",
    "authors": [
      "Sunayana Rane",
      "Mira L. Nencheva",
      "Zeyu Wang",
      "Casey Lew-Williams",
      "Olga Russakovsky",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09847"
  },
  {
    "id": "arXiv:2207.09849",
    "title": "Automated machine learning for borehole resistivity measurements",
    "abstract": "Deep neural networks (DNNs) offer a real-time solution for the inversion of\nborehole resistivity measurements to approximate forward and inverse operators.\nIt is possible to use extremely large DNNs to approximate the operators, but it\ndemands a considerable training time. Moreover, evaluating the network after\ntraining also requires a significant amount of memory and processing power. In\naddition, we may overfit the model. In this work, we propose a scoring function\nthat accounts for the accuracy and size of the DNNs compared to a reference DNN\nthat provides a good approximation for the operators. Using this scoring\nfunction, we use DNN architecture search algorithms to obtain a quasi-optimal\nDNN smaller than the reference network; hence, it requires less computational\neffort during training and evaluation. The quasi-optimal DNN delivers\ncomparable accuracy to the original large DNN.",
    "descriptor": "",
    "authors": [
      "M. Shahriari",
      "D. Pardo",
      "S. Kargaran",
      "T. Teijeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09849"
  },
  {
    "id": "arXiv:2207.09851",
    "title": "An Embedded Monocular Vision Approach for Ground-Aware Objects Detection  and Position Estimation",
    "abstract": "In the RoboCup Small Size League (SSL), teams are encouraged to propose\nsolutions for executing basic soccer tasks inside the SSL field using only\nembedded sensing information. Thus, this work proposes an embedded monocular\nvision approach for detecting objects and estimating relative positions inside\nthe soccer field. Prior knowledge from the environment is exploited by assuming\nobjects lay on the ground, and the onboard camera has its position fixed on the\nrobot. We implemented the proposed method on an NVIDIA Jetson Nano and employed\nSSD MobileNet v2 for 2D Object Detection with TensorRT optimization, detecting\nballs, robots, and goals with distances up to 3.5 meters. Ball localization\nevaluation shows that the proposed solution overcomes the currently used SSL\nvision system for positions closer than 1 meter to the onboard camera with a\nRoot Mean Square Error of 14.37 millimeters. In addition, the proposed method\nachieves real-time performance with an average processing speed of 30 frames\nper second.",
    "descriptor": "\nComments: 12 pages, 5 figures, submitted to RoboCup Symposium 2022\n",
    "authors": [
      "Jo\u00e3o G. Melo",
      "Edna Barros"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09851"
  },
  {
    "id": "arXiv:2207.09853",
    "title": "Simplicity in Auctions Revisited: The Primitive Complexity",
    "abstract": "In this paper we revisit the notion of simplicity in mechanisms. We consider\na seller of $m$ items, facing a single buyer with valuation $v$. We observe\nthat previous attempts to define complexity measures often fail to classify\nmechanisms that are intuitively considered simple (e.g., the \"selling\nseparately\" mechanism) as such. We suggest to view a menu as simple if a bundle\nthat maximizes the buyer's profit can be found by conducting a few primitive\noperations that are considered simple. The \\emph{primitive complexity of a\nmenu} is the number of primitive operations needed to (adaptively) find a\nprofit-maximizing entry in the menu. In this paper, the primitive operation\nthat we study is essentially computing the outcome of the \"selling separately\"\nmechanism.\nDoes the primitive complexity capture the simplicity of other auctions that\nare intuitively simple? We consider \\emph{bundle-size pricing}, a common\npricing method in which the price of a bundle depends only on its size. Our\nmain technical contribution is determining the primitive complexity of\nbundle-size pricing menus in various settings. We show that for any\ndistribution $\\cal D$ over weighted matroid rank valuations, even distributions\nwith arbitrary correlation among their values, there is always a bundle-size\npricing menu with low primitive complexity that achieves almost the same\nrevenue as the optimal bundle-size pricing menu. As part of this proof we\nprovide a randomized algorithm that for any weighted matroid rank valuation $v$\nand integer $k$, finds the most valuable set of size $k$ with only a\npoly-logarithmic number of demand and value queries. We show that this result\nis essentially tight in several aspects. For example, if the valuation $v$ is\nsubmodular, then finding the most valuable set of size $k$ requires\nexponentially many queries (this solves an open question of Badanidiyuru et al.\n[EC'12]).",
    "descriptor": "",
    "authors": [
      "Moshe Babaioff",
      "Shahar Dobzinski",
      "Ron Kupfer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.09853"
  },
  {
    "id": "arXiv:2207.09854",
    "title": "Auto-active Verification of Graph Algorithms, Written in OCaml",
    "abstract": "Functional programming offers the perfect ground for building\ncorrect-by-construction software. Languages of such paradigm normally feature\nstate-of-the-art type systems, good abstraction mechanisms, and well-defined\nexecution models. We claim that all of these make software written in a\nfunctional language excellent targets for formal certification. Yet, somehow\nsurprising, techniques such as deductive verification have been seldom applied\nto large-scale programs, written in mainstream functional languages. In this\npaper, we wish to address this situation and present the auto-active proof of\nrealistic OCaml implementations. We choose implementations issued from the\nOCamlgraph library as our target, since this is both a large-scale and\nwidely-used piece of OCaml code. We use Cameleer, a recently proposed tool for\nthe deductive verification of OCaml programs, to conduct the proofs of the\nselected case studies. The vast majority of such proofs are completed\nfully-automatically, using SMT solvers, and when needed we can apply\nlightweight interactive proof inside the Why3 IDE (Cameleer translates an input\nprogram into an equivalent WhyML one, the language of the Why3 verification\nframework). To the best of our knowledge, these are the first mechanized,\nmostly-automated proofs of graph algorithms written in OCaml.",
    "descriptor": "",
    "authors": [
      "Daniel Castanho",
      "M\u00e1rio Pereira"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.09854"
  },
  {
    "id": "arXiv:2207.09855",
    "title": "Everything is There in Latent Space: Attribute Editing and Attribute  Style Manipulation by StyleGAN Latent Space Exploration",
    "abstract": "Unconstrained Image generation with high realism is now possible using recent\nGenerative Adversarial Networks (GANs). However, it is quite challenging to\ngenerate images with a given set of attributes. Recent methods use style-based\nGAN models to perform image editing by leveraging the semantic hierarchy\npresent in the layers of the generator. We present Few-shot Latent-based\nAttribute Manipulation and Editing (FLAME), a simple yet effective framework to\nperform highly controlled image editing by latent space manipulation.\nSpecifically, we estimate linear directions in the latent space (of a\npre-trained StyleGAN) that controls semantic attributes in the generated image.\nIn contrast to previous methods that either rely on large-scale attribute\nlabeled datasets or attribute classifiers, FLAME uses minimal supervision of a\nfew curated image pairs to estimate disentangled edit directions. FLAME can\nperform both individual and sequential edits with high precision on a diverse\nset of images while preserving identity. Further, we propose a novel task of\nAttribute Style Manipulation to generate diverse styles for attributes such as\neyeglass and hair. We first encode a set of synthetic images of the same\nidentity but having different attribute styles in the latent space to estimate\nan attribute style manifold. Sampling a new latent from this manifold will\nresult in a new attribute style in the generated image. We propose a novel\nsampling method to sample latent from the manifold, enabling us to generate a\ndiverse set of attribute styles beyond the styles present in the training set.\nFLAME can generate diverse attribute styles in a disentangled manner. We\nillustrate the superior performance of FLAME against previous image editing\nmethods by extensive qualitative and quantitative comparisons. FLAME also\ngeneralizes well on multiple datasets such as cars and churches.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Rishubh Parihar",
      "Ankit Dhiman",
      "Tejan Karmali",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09855"
  },
  {
    "id": "arXiv:2207.09856",
    "title": "Evaluating the Stability of Deep Image Quality Assessment With Respect  to Image Scaling",
    "abstract": "Image quality assessment (IQA) is a fundamental metric for image processing\ntasks (e.g., compression). With full-reference IQAs, traditional IQAs, such as\nPSNR and SSIM, have been used. Recently, IQAs based on deep neural networks\n(deep IQAs), such as LPIPS and DISTS, have also been used. It is known that\nimage scaling is inconsistent among deep IQAs, as some perform down-scaling as\npre-processing, whereas others instead use the original image size. In this\npaper, we show that the image scale is an influential factor that affects deep\nIQA performance. We comprehensively evaluate four deep IQAs on the same five\ndatasets, and the experimental results show that image scale significantly\ninfluences IQA performance. We found that the most appropriate image scale is\noften neither the default nor the original size, and the choice differs\ndepending on the methods and datasets used. We visualized the stability and\nfound that PieAPP is the most stable among the four deep IQAs.",
    "descriptor": "\nComments: IEICE Transactions on Information and Systems (Letter)\n",
    "authors": [
      "Koki Tsubota",
      "Hiroaki Akutsu",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.09856"
  },
  {
    "id": "arXiv:2207.09858",
    "title": "UniHPF : Universal Healthcare Predictive Framework with Zero Domain  Knowledge",
    "abstract": "Despite the abundance of Electronic Healthcare Records (EHR), its\nheterogeneity restricts the utilization of medical data in building predictive\nmodels. To address this challenge, we propose Universal Healthcare Predictive\nFramework (UniHPF), which requires no medical domain knowledge and minimal\npre-processing for multiple prediction tasks. Experimental results demonstrate\nthat UniHPF is capable of building large-scale EHR models that can process any\nform of medical data from distinct EHR systems. Our framework significantly\noutperforms baseline models in multi-source learning tasks, including transfer\nand pooled learning, while also showing comparable results when trained on a\nsingle medical dataset. To empirically demonstrate the efficacy of our work, we\nconducted extensive experiments using various datasets, model structures, and\ntasks. We believe that our findings can provide helpful insights for further\nresearch on the multi-source learning of EHRs.",
    "descriptor": "\nComments: Main paper (11pages)\n",
    "authors": [
      "Kyunghoon Hur",
      "Jungwoo Oh",
      "Junu Kim",
      "Min Jae Lee",
      "Eunbyeol Choi",
      "Jiyoun Kim",
      "Seong-Eun Moon",
      "Young-Hak Kim",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09858"
  },
  {
    "id": "arXiv:2207.09860",
    "title": "Learning to Solve Soft-Constrained Vehicle Routing Problems with  Lagrangian Relaxation",
    "abstract": "Vehicle Routing Problems (VRPs) in real-world applications often come with\nvarious constraints, therefore bring additional computational challenges to\nexact solution methods or heuristic search approaches. The recent idea to learn\nheuristic move patterns from sample data has become increasingly promising to\nreduce solution developing costs. However, using learning-based approaches to\naddress more types of constrained VRP remains a challenge. The difficulty lies\nin controlling for constraint violations while searching for optimal solutions.\nTo overcome this challenge, we propose a Reinforcement Learning based method to\nsolve soft-constrained VRPs by incorporating the Lagrangian relaxation\ntechnique and using constrained policy optimization. We apply the method on\nthree common types of VRPs, the Travelling Salesman Problem with Time Windows\n(TSPTW), the Capacitated VRP (CVRP) and the Capacitated VRP with Time Windows\n(CVRPTW), to show the generalizability of the proposed method. After comparing\nto existing RL-based methods and open-source heuristic solvers, we demonstrate\nits competitive performance in finding solutions with a good balance in travel\ndistance, constraint violations and inference speed.",
    "descriptor": "",
    "authors": [
      "Qiaoyue Tang",
      "Yangzhe Kong",
      "Lemeng Pan",
      "Choonmeng Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09860"
  },
  {
    "id": "arXiv:2207.09865",
    "title": "Discrete-Constrained Regression for Local Counting Models",
    "abstract": "Local counts, or the number of objects in a local area, is a continuous value\nby nature. Yet recent state-of-the-art methods show that formulating counting\nas a classification task performs better than regression. Through a series of\nexperiments on carefully controlled synthetic data, we show that this\ncounter-intuitive result is caused by imprecise ground truth local counts.\nFactors such as biased dot annotations and incorrectly matched Gaussian kernels\nused to generate ground truth counts introduce deviations from the true local\ncounts. Standard continuous regression is highly sensitive to these errors,\nexplaining the performance gap between classification and regression. To\nmitigate the sensitivity, we loosen the regression formulation from a\ncontinuous scale to a discrete ordering and propose a novel\ndiscrete-constrained (DC) regression. Applied to crowd counting, DC-regression\nis more accurate than both classification and standard regression on three\npublic benchmarks. A similar advantage also holds for the age estimation task,\nverifying the overall effectiveness of DC-regression.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Haipeng Xiong",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09865"
  },
  {
    "id": "arXiv:2207.09868",
    "title": "Adaptive Mixture of Experts Learning for Generalizable Face  Anti-Spoofing",
    "abstract": "With various face presentation attacks emerging continually, face\nanti-spoofing (FAS) approaches based on domain generalization (DG) have drawn\ngrowing attention. Existing DG-based FAS approaches always capture the\ndomain-invariant features for generalizing on the various unseen domains.\nHowever, they neglect individual source domains' discriminative characteristics\nand diverse domain-specific information of the unseen domains, and the trained\nmodel is not sufficient to be adapted to various unseen domains. To address\nthis issue, we propose an Adaptive Mixture of Experts Learning (AMEL)\nframework, which exploits the domain-specific information to adaptively\nestablish the link among the seen source domains and unseen target domains to\nfurther improve the generalization. Concretely, Domain-Specific Experts (DSE)\nare designed to investigate discriminative and unique domain-specific features\nas a complement to common domain-invariant features. Moreover, Dynamic Expert\nAggregation (DEA) is proposed to adaptively aggregate the complementary\ninformation of each source expert based on the domain relevance to the unseen\ntarget domain. And combined with meta-learning, these modules work\ncollaboratively to adaptively aggregate meaningful domain-specific information\nfor the various unseen target domains. Extensive experiments and visualizations\ndemonstrate the effectiveness of our method against the state-of-the-art\ncompetitors.",
    "descriptor": "\nComments: Accepted to ACM MM 2022\n",
    "authors": [
      "Qianyu Zhou",
      "Ke-Yue Zhang",
      "Taiping Yao",
      "Ran Yi",
      "Shouhong Ding",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09868"
  },
  {
    "id": "arXiv:2207.09869",
    "title": "A Novel Neural Network Training Method for Autonomous Driving Using  Semi-Pseudo-Labels and 3D Data Augmentations",
    "abstract": "Training neural networks to perform 3D object detection for autonomous\ndriving requires a large amount of diverse annotated data. However, obtaining\ntraining data with sufficient quality and quantity is expensive and sometimes\nimpossible due to human and sensor constraints. Therefore, a novel solution is\nneeded for extending current training methods to overcome this limitation and\nenable accurate 3D object detection. Our solution for the above-mentioned\nproblem combines semi-pseudo-labeling and novel 3D augmentations. For\ndemonstrating the applicability of the proposed method, we have designed a\nconvolutional neural network for 3D object detection which can significantly\nincrease the detection range in comparison with the training data distribution.",
    "descriptor": "",
    "authors": [
      "Tamas Matuszka",
      "Daniel Kozma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09869"
  },
  {
    "id": "arXiv:2207.09872",
    "title": "A Lattice-Theoretical View of Strategy Iteration",
    "abstract": "Strategy iteration is a technique frequently used for two-player games in\norder to determine the winner or compute payoffs, but to the best of our\nknowledge no general framework for strategy iteration has been considered.\nInspired by previous work on simple stochastic games, we propose a general\nformalisation of strategy iteration for solving least fixpoint equations over a\nsuitable class of complete lattices, based on MV-chains. We devise algorithms\nthat can be used for non-expansive fixpoint functions represented as so-called\nmin-, respectively, max-decompositions. Correspondingly, we develop two\ndifferent techniques: strategy iteration from above, which has to solve the\nproblem that iteration might reach a fixpoint that is not the least, and from\nbelow, which is algorithmically simpler, but requires a more involved\ncorrectness argument. We apply our method to solve energy games and compute\nbehavioural metrics for probabilistic automata.",
    "descriptor": "",
    "authors": [
      "Paolo Baldan",
      "Richard Eggert",
      "Barbara K\u00f6nig",
      "Tommaso Padoan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.09872"
  },
  {
    "id": "arXiv:2207.09879",
    "title": "Beam Alignment for the Cell-Free mmWave Massive MU-MIMO Uplink",
    "abstract": "Millimeter-wave (mmWave) cell-free massive multi-user (MU) multiple-input\nmultiple-output (MIMO) systems combine the large bandwidths available at mmWave\nfrequencies with the improved coverage of cell-free systems. However, to combat\nthe high path loss at mmWave frequencies, user equipments (UEs) must form beams\nin meaningful directions, i.e., to a nearby access point (AP). At the same\ntime, multiple UEs should avoid transmitting to the same AP to reduce MU\ninterference. We propose an interference-aware method for beam alignment (BA)\nin the cell-free mmWave massive MU-MIMO uplink. In the considered scenario, the\nAPs perform full digital receive beamforming while the UEs perform analog\ntransmit beamforming. We evaluate our method using realistic mmWave channels\nfrom a commercial ray-tracer, showing the superiority of the proposed method\nover omnidirectional transmission as well as over methods that do not take MU\ninterference into account.",
    "descriptor": "\nComments: To appear at the IEEE International Workshop on Signal Processing Systems (SiPS) 2022\n",
    "authors": [
      "Jannik Brun",
      "Victoria Palhares",
      "Gian Marti",
      "Christoph Studer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.09879"
  },
  {
    "id": "arXiv:2207.09884",
    "title": "Negative Samples are at Large: Leveraging Hard-distance Elastic Loss for  Re-identification",
    "abstract": "We present a Momentum Re-identification (MoReID) framework that can leverage\na very large number of negative samples in training for general\nre-identification task. The design of this framework is inspired by Momentum\nContrast (MoCo), which uses a dictionary to store current and past batches to\nbuild a large set of encoded samples. As we find it less effective to use past\npositive samples which may be highly inconsistent to the encoded feature\nproperty formed with the current positive samples, MoReID is designed to use\nonly a large number of negative samples stored in the dictionary. However, if\nwe train the model using the widely used Triplet loss that uses only one sample\nto represent a set of positive/negative samples, it is hard to effectively\nleverage the enlarged set of negative samples acquired by the MoReID framework.\nTo maximize the advantage of using the scaled-up negative sample set, we newly\nintroduce Hard-distance Elastic loss (HE loss), which is capable of using more\nthan one hard sample to represent a large number of samples. Our experiments\ndemonstrate that a large number of negative samples provided by MoReID\nframework can be utilized at full capacity only with the HE loss, achieving the\nstate-of-the-art accuracy on three re-ID benchmarks, VeRi-776, Market-1501, and\nVeRi-Wild.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Hyungtae Lee",
      "Sungmin Eum",
      "Heesung Kwon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09884"
  },
  {
    "id": "arXiv:2207.09889",
    "title": "When Is TTS Augmentation Through a Pivot Language Useful?",
    "abstract": "Developing Automatic Speech Recognition (ASR) for low-resource languages is a\nchallenge due to the small amount of transcribed audio data. For many such\nlanguages, audio and text are available separately, but not audio with\ntranscriptions. Using text, speech can be synthetically produced via\ntext-to-speech (TTS) systems. However, many low-resource languages do not have\nquality TTS systems either. We propose an alternative: produce synthetic audio\nby running text from the target language through a trained TTS system for a\nhigher-resource pivot language. We investigate when and how this technique is\nmost effective in low-resource settings. In our experiments, using several\nthousand synthetic TTS text-speech pairs and duplicating authentic data to\nbalance yields optimal results. Our findings suggest that searching over a set\nof candidate pivot languages can lead to marginal improvements and that,\nsurprisingly, ASR performance can by harmed by increases in measured TTS\nquality. Application of these findings improves ASR by 64.5\\% and 45.0\\%\ncharacter error reduction rate (CERR) respectively for two low-resource\nlanguages: Guaran\\'i and Suba.",
    "descriptor": "",
    "authors": [
      "Nathaniel Robinson",
      "Perez Ogayo",
      "Swetha Gangu",
      "David R. Mortensen",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.09889"
  },
  {
    "id": "arXiv:2207.09895",
    "title": "PFMC: a parallel symbolic model checker for security protocol  verification",
    "abstract": "We present an investigation into the design and implementation of a parallel\nmodel checker for security protocol verification that is based on a symbolic\nmodel of the adversary, where instantiations of concrete terms and messages are\navoided until needed to resolve a particular assertion. We propose to build on\nthis naturally lazy approach to parallelise this symbolic state exploration and\nevaluation. We utilise the concept of strategies in Haskell, which abstracts\naway from the low-level details of thread management and modularly adds\nparallel evaluation strategies (encapsulated as a monad in Haskell). We build\non an existing symbolic model checker, OFMC, which is already implemented in\nHaskell. We show that there is a very significant speed up of around 3-5 times\nimprovement when moving from the original single-threaded implementation of\nOFMC to our multi-threaded version, for both the Dolev-Yao attacker model and\nmore general algebraic attacker models. We identify several issues in\nparallelising the model checker: among others, controlling growth of memory\nconsumption, balancing lazy vs strict evaluation, and achieving an optimal\ngranularity of parallelism.",
    "descriptor": "",
    "authors": [
      "Alex James",
      "Alwen Tiu",
      "Nisansala Yatapanage"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.09895"
  },
  {
    "id": "arXiv:2207.09897",
    "title": "Successor Representation Active Inference",
    "abstract": "Recent work has uncovered close links between between classical reinforcement\nlearning algorithms, Bayesian filtering, and Active Inference which lets us\nunderstand value functions in terms of Bayesian posteriors. An alternative, but\nless explored, model-free RL algorithm is the successor representation, which\nexpresses the value function in terms of a successor matrix of expected future\nstate occupancies. In this paper, we derive the probabilistic interpretation of\nthe successor representation in terms of Bayesian filtering and thus design a\nnovel active inference agent architecture utilizing successor representations\ninstead of model-based planning. We demonstrate that active inference successor\nrepresentations have significant advantages over current active inference\nagents in terms of planning horizon and computational cost. Moreover, we\ndemonstrate how the successor representation agent can generalize to changing\nreward functions such as variants of the expected free energy.",
    "descriptor": "\nComments: 20/07/22 initial upload\n",
    "authors": [
      "Beren Millidge",
      "Christopher L Buckley"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09897"
  },
  {
    "id": "arXiv:2207.09899",
    "title": "Labeling instructions matter in biomedical image analysis",
    "abstract": "Biomedical image analysis algorithm validation depends on high-quality\nannotation of reference datasets, for which labeling instructions are key.\nDespite their importance, their optimization remains largely unexplored. Here,\nwe present the first systematic study of labeling instructions and their impact\non annotation quality in the field. Through comprehensive examination of\nprofessional practice and international competitions registered at the MICCAI\nSociety, we uncovered a discrepancy between annotators' needs for labeling\ninstructions and their current quality and availability. Based on an analysis\nof 14,040 images annotated by 156 annotators from four professional companies\nand 708 Amazon Mechanical Turk (MTurk) crowdworkers using instructions with\ndifferent information density levels, we further found that including exemplary\nimages significantly boosts annotation performance compared to text-only\ndescriptions, while solely extending text descriptions does not. Finally,\nprofessional annotators constantly outperform MTurk crowdworkers. Our study\nraises awareness for the need of quality standards in biomedical image analysis\nlabeling instructions.",
    "descriptor": "",
    "authors": [
      "Tim R\u00e4dsch",
      "Annika Reinke",
      "Vivienn Weru",
      "Minu D. Tizabi",
      "Nicholas Schreck",
      "A. Emre Kavur",
      "B\u00fcnyamin Pekdemir",
      "Tobias Ro\u00df",
      "Annette Kopp-Schneider",
      "Lena Maier-Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09899"
  },
  {
    "id": "arXiv:2207.09902",
    "title": "Bayesian Hyperparameter Optimization for Deep Neural Network-Based  Network Intrusion Detection",
    "abstract": "Traditional network intrusion detection approaches encounter feasibility and\nsustainability issues to combat modern, sophisticated, and unpredictable\nsecurity attacks. Deep neural networks (DNN) have been successfully applied for\nintrusion detection problems. The optimal use of DNN-based classifiers requires\ncareful tuning of the hyper-parameters. Manually tuning the hyperparameters is\ntedious, time-consuming, and computationally expensive. Hence, there is a need\nfor an automatic technique to find optimal hyperparameters for the best use of\nDNN in intrusion detection. This paper proposes a novel Bayesian\noptimization-based framework for the automatic optimization of hyperparameters,\nensuring the best DNN architecture. We evaluated the performance of the\nproposed framework on NSL-KDD, a benchmark dataset for network intrusion\ndetection. The experimental results show the framework's effectiveness as the\nresultant DNN architecture demonstrates significantly higher intrusion\ndetection performance than the random search optimization-based approach in\nterms of accuracy, precision, recall, and f1-score.",
    "descriptor": "",
    "authors": [
      "Mohammad Masum",
      "Hossain Shahriar",
      "Hisham Haddad",
      "Md Jobair Hossain Faruk",
      "Maria Valero",
      "Md Abdullah Khan",
      "Mohammad A. Rahman",
      "Muhaiminul I. Adnan",
      "Alfredo Cuzzocrea"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09902"
  },
  {
    "id": "arXiv:2207.09908",
    "title": "Integrated Finite Element Neural Network (I-FENN) for non-local  continuum damage mechanics",
    "abstract": "We present a new Integrated Finite Element Neural Network framework (I-FENN),\nwith the objective to accelerate the numerical solution of nonlinear\ncomputational mechanics problems. We leverage the swift predictive capability\nof neural networks (NNs) and we embed them inside the finite element stiffness\nfunction, to compute element-level state variables and their derivatives within\na nonlinear, iterative numerical solution. This process is conducted jointly\nwith conventional finite element methods that involve shape functions: the NN\nreceives input data that resembles the material point deformation and its\noutput is used to construct element-level field variables such as the element\nJacobian matrix and residual vector. Here we introduce I-FENN to the continuum\ndamage analysis of quasi-brittle materials, and we establish a new non-local\ngradient-based damage framework which operates at the cost of a local damage\napproach. First, we develop a physics informed neural network (PINN) to\nresemble the non-local gradient model and then we train the neural network\noffline. The network learns to predict the non-local equivalent strain at each\nmaterial point, as well as its derivative with respect to the local strain.\nThen, the PINN is integrated in the element stiffness definition and conducts\nthe local to non-local strain transformation, whereas the two PINN outputs are\nused to construct the element Jacobian matrix and residual vector. This process\nis carried out within the nonlinear solver, until numerical convergence is\nachieved. The resulting method bears the computational cost of the conventional\nlocal damage approach, but ensures mesh-independent results and a diffused\nnon-local strain and damage profile. As a result, the proposed method tackles\nthe vital drawbacks of both the local and non-local gradient method,\nrespectively being the mesh-dependence and additional computational cost.",
    "descriptor": "",
    "authors": [
      "Panos Pantidis",
      "Mostafa E. Mobasher"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.09908"
  },
  {
    "id": "arXiv:2207.09909",
    "title": "SLAMER: Simultaneous Localization and Map-Assisted Environment  Recognition",
    "abstract": "This paper presents a simultaneous localization and map-assisted environment\nrecognition (SLAMER) method. Mobile robots usually have an environment map and\nenvironment information can be assigned to the map. Important information for\nmobile robots such as no entry zone can be predicted if localization has\nsucceeded since relative pose of them can be known. However, this prediction is\nfailed when localization does not work. Uncertainty of pose estimate must be\nconsidered for robustly using the map information. In addition, robots have\nexternal sensors and environment information can be recognized using the\nsensors. This on-line recognition of course contains uncertainty; however, it\nhas to be fused with the map information for robust environment recognition\nsince the map also contains uncertainty owing to over time. SLAMER can\nsimultaneously cope with these uncertainties and achieves accurate localization\nand environment recognition. In this paper, we demonstrate LiDAR-based\nimplementation of SLAMER in two cases. In the first case, we use the\nSemanticKITTI dataset and show that SLAMER achieves accurate estimate more than\ntraditional methods. In the second case, we use an indoor mobile robot and show\nthat unmeasurable environmental objects such as open doors and no entry lines\ncan be recognized.",
    "descriptor": "",
    "authors": [
      "Naoki Akai"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.09909"
  },
  {
    "id": "arXiv:2207.09912",
    "title": "Online Evasion Attacks on Recurrent Models:The Power of Hallucinating  the Future",
    "abstract": "Recurrent models are frequently being used in online tasks such as autonomous\ndriving, and a comprehensive study of their vulnerability is called for.\nExisting research is limited in generality only addressing application-specific\nvulnerability or making implausible assumptions such as the knowledge of future\ninput. In this paper, we present a general attack framework for online tasks\nincorporating the unique constraints of the online setting different from\noffline tasks. Our framework is versatile in that it covers time-varying\nadversarial objectives and various optimization constraints, allowing for a\ncomprehensive study of robustness. Using the framework, we also present a novel\nwhite-box attack called Predictive Attack that `hallucinates' the future. The\nattack achieves 98 percent of the performance of the ideal but infeasible\nclairvoyant attack on average. We validate the effectiveness of the proposed\nframework and attacks through various experiments.",
    "descriptor": "\nComments: 7 pages, 10 figures, IJCAI'22\n",
    "authors": [
      "Byunggill Joe",
      "Insik Shin",
      "Jihun Hamm"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09912"
  },
  {
    "id": "arXiv:2207.09914",
    "title": "Constraint-based type inference for FreezeML",
    "abstract": "FreezeML is a new approach to first-class polymorphic type inference that\nemploys term annotations to control when and how polymorphic types are\ninstantiated and generalised. It conservatively extends Hindley-Milner type\ninference and was first presented as an extension to Algorithm W. More modern\ntype inference techniques such as HM(X) and OutsideIn($X$) employ constraints\nto support features such as type classes, type families, rows, and other\nextensions. We take the first step towards modernising FreezeML by presenting a\nconstraint-based type inference algorithm. We introduce a new constraint\nlanguage, inspired by the Pottier/R\\'emy presentation of HM(X), in order to\nallow FreezeML type inference problems to be expressed as constraints. We\npresent a deterministic stack machine for solving FreezeML constraints and\nprove its termination and correctness.",
    "descriptor": "",
    "authors": [
      "Frank Emrich",
      "Jan Stolarek",
      "James Cheney",
      "Sam Lindley"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.09914"
  },
  {
    "id": "arXiv:2207.09915",
    "title": "A note on the variation of geometric functionals",
    "abstract": "Calculus of Variation combined with Differential Geometry as tools of\nmodelling and solving problems in image processing and computer vision were\nintroduced in the late 80's and the 90s of the 20th century. The beginning of\nan extensive work in these directions was marked by works such as Geodesic\nActive Contours (GAC), the Beltrami framework, level set method of Osher and\nSethian the works of Charpiat et al. and the works by Chan and Vese to name\njust a few. In many cases the optimization of these functional are done by the\ngradient descent method via the calculation of the Euler-Lagrange equations.\nStraightforward use of the resulted EL equations in the gradient descent scheme\nleads to non-geometric and in some cases non sensical equations. It is\ncostumary to modify these EL equations or even the functional itself in order\nto obtain geometric and/or sensical equations. The aim of this note is to point\nto the correct way to derive the EL and the gradient descent equations such\nthat the resulted gradient descent equation is geometric and makes sense.",
    "descriptor": "",
    "authors": [
      "Nir Sochen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09915"
  },
  {
    "id": "arXiv:2207.09916",
    "title": "The Poisson binomial mechanism for secure and private federated learning",
    "abstract": "We introduce the Poisson Binomial mechanism (PBM), a discrete differential\nprivacy mechanism for distributed mean estimation (DME) with applications to\nfederated learning and analytics. We provide a tight analysis of its privacy\nguarantees, showing that it achieves the same privacy-accuracy trade-offs as\nthe continuous Gaussian mechanism. Our analysis is based on a novel bound on\nthe R\\'enyi divergence of two Poisson binomial distributions that may be of\nindependent interest.\nUnlike previous discrete DP schemes based on additive noise, our mechanism\nencodes local information into a parameter of the binomial distribution, and\nhence the output distribution is discrete with bounded support. Moreover, the\nsupport does not increase as the privacy budget $\\varepsilon \\rightarrow 0$ as\nin the case of additive schemes which require the addition of more noise to\nachieve higher privacy; on the contrary, the support becomes smaller as\n$\\varepsilon \\rightarrow 0$. The bounded support enables us to combine our\nmechanism with secure aggregation (SecAgg), a multi-party cryptographic\nprotocol, without the need of performing modular clipping which results in an\nunbiased estimator of the sum of the local vectors. This in turn allows us to\napply it in the private FL setting and provide an upper bound on the\nconvergence rate of the SGD algorithm. Moreover, since the support of the\noutput distribution becomes smaller as $\\varepsilon \\rightarrow 0$, the\ncommunication cost of our scheme decreases with the privacy constraint\n$\\varepsilon$, outperforming all previous distributed DP schemes based on\nadditive noise in the high privacy or low communication regimes.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Wei-Ning Chen",
      "Ayfer \u00d6zg\u00fcr",
      "Peter Kairouz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.09916"
  },
  {
    "id": "arXiv:2207.09918",
    "title": "Large Scale Radio Frequency Signal Classification",
    "abstract": "Existing datasets used to train deep learning models for narrowband radio\nfrequency (RF) signal classification lack enough diversity in signal types and\nchannel impairments to sufficiently assess model performance in the real world.\nWe introduce the Sig53 dataset consisting of 5 million synthetically-generated\nsamples from 53 different signal classes and expertly chosen impairments. We\nalso introduce TorchSig, a signals processing machine learning toolkit that can\nbe used to generate this dataset. TorchSig incorporates data handling\nprinciples that are common to the vision domain, and it is meant to serve as an\nopen-source foundation for future signals machine learning research. Initial\nexperiments using the Sig53 dataset are conducted using state of the art (SoTA)\nconvolutional neural networks (ConvNets) and Transformers. These experiments\nreveal Transformers outperform ConvNets without the need for additional\nregularization or a ConvNet teacher, which is contrary to results from the\nvision domain. Additional experiments demonstrate that TorchSig's\ndomain-specific data augmentations facilitate model training, which ultimately\nbenefits model performance. Finally, TorchSig supports on-the-fly synthetic\ndata creation at training time, thus enabling massive scale training sessions\nwith virtually unlimited datasets.",
    "descriptor": "",
    "authors": [
      "Luke Boegner",
      "Manbir Gulati",
      "Garrett Vanhoy",
      "Phillip Vallance",
      "Bradley Comar",
      "Silvija Kokalj-Filipovic",
      "Craig Lennon",
      "Robert D. Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.09918"
  },
  {
    "id": "arXiv:2207.09919",
    "title": "Design and implementation of a DApp to store health data",
    "abstract": "This work presents the design and implementation of a decentralized\napplication (DApp) that aims to guarantee the privacy of data related to the\nhealth area, which are stored and shared within a blockchain network. For this,\nencryption with RSA, ECC and AES algorithms is used. The platforms,\ntechnologies, tools and libraries required for development are presented, as\nwell as implementation details.",
    "descriptor": "\nComments: in Portuguese language\n",
    "authors": [
      "Christofer L. Sega",
      "Anubis G. de M. Rossetto",
      "Valderi R. Q. Leithardt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.09919"
  },
  {
    "id": "arXiv:2207.09920",
    "title": "DESCN: Deep Entire Space Cross Networks for Individual Treatment Effect  Estimation",
    "abstract": "Causal Inference has wide applications in various areas such as E-commerce\nand precision medicine, and its performance heavily relies on the accurate\nestimation of the Individual Treatment Effect (ITE). Conventionally, ITE is\npredicted by modeling the treated and control response functions separately in\ntheir individual sample spaces. However, such an approach usually encounters\ntwo issues in practice, i.e. divergent distribution between treated and control\ngroups due to treatment bias, and significant sample imbalance of their\npopulation sizes. This paper proposes Deep Entire Space Cross Networks (DESCN)\nto model treatment effects from an end-to-end perspective. DESCN captures the\nintegrated information of the treatment propensity, the response, and the\nhidden treatment effect through a cross network in a multi-task learning\nmanner. Our method jointly learns the treatment and response functions in the\nentire sample space to avoid treatment bias and employs an intermediate pseudo\ntreatment effect prediction network to relieve sample imbalance. Extensive\nexperiments are conducted on a synthetic dataset and a large-scaled production\ndataset from the E-commerce voucher distribution business. The results indicate\nthat DESCN can successfully enhance the accuracy of ITE estimation and improve\nthe uplift ranking performance. A sample of the production dataset and the\nsource code are released to facilitate future research in the community, which\nis, to the best of our knowledge, the first large-scale public biased treatment\ndataset for causal inference.",
    "descriptor": "\nComments: KDD 2022\n",
    "authors": [
      "Kailiang Zhong",
      "Fengtong Xiao",
      "Yan Ren",
      "Yaorong Liang",
      "Wenqing Yao",
      "Xiaofeng Yang",
      "Ling Cen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09920"
  },
  {
    "id": "arXiv:2207.09925",
    "title": "An Efficient Framework for Few-shot Skeleton-based Temporal Action  Segmentation",
    "abstract": "Temporal action segmentation (TAS) aims to classify and locate actions in the\nlong untrimmed action sequence. With the success of deep learning, many deep\nmodels for action segmentation have emerged. However, few-shot TAS is still a\nchallenging problem. This study proposes an efficient framework for the\nfew-shot skeleton-based TAS, including a data augmentation method and an\nimproved model. The data augmentation approach based on motion interpolation is\npresented here to solve the problem of insufficient data, and can increase the\nnumber of samples significantly by synthesizing action sequences. Besides, we\nconcatenate a Connectionist Temporal Classification (CTC) layer with a network\ndesigned for skeleton-based TAS to obtain an optimized model. Leveraging CTC\ncan enhance the temporal alignment between prediction and ground truth and\nfurther improve the segment-wise metrics of segmentation results. Extensive\nexperiments on both public and self-constructed datasets, including two\nsmall-scale datasets and one large-scale dataset, show the effectiveness of two\nproposed methods in improving the performance of the few-shot skeleton-based\nTAS task.",
    "descriptor": "",
    "authors": [
      "Leiyang Xu",
      "Qiang Wang",
      "Xiaotian Lin",
      "Lin Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09925"
  },
  {
    "id": "arXiv:2207.09927",
    "title": "ViGAT: Bottom-up event recognition and explanation in video using  factorized graph attention network",
    "abstract": "In this paper a pure-attention bottom-up approach, called ViGAT, that\nutilizes an object detector together with a Vision Transformer (ViT) backbone\nnetwork to derive object and frame features, and a head network to process\nthese features for the task of event recognition and explanation in video, is\nproposed. The ViGAT head consists of graph attention network (GAT) blocks\nfactorized along the spatial and temporal dimensions in order to capture\neffectively both local and long-term dependencies between objects or frames.\nMoreover, using the weighted in-degrees (WiDs) derived from the adjacency\nmatrices at the various GAT blocks, we show that the proposed architecture can\nidentify the most salient objects and frames that explain the decision of the\nnetwork. A comprehensive evaluation study is performed, demonstrating that the\nproposed approach provides state-of-the-art results on three large, publicly\navailable video datasets (FCVID, Mini-Kinetics, ActivityNet).",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Nikolaos Gkalelis",
      "Dimitrios Daskalakis",
      "Vasileios Mezaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2207.09927"
  },
  {
    "id": "arXiv:2207.09928",
    "title": "Upgrading the protection of children from manipulative and addictive  strategies in online games: Legal and technical solutions beyond privacy  regulation",
    "abstract": "Despite the increasing awareness from academia, civil society and media to\nthe issue of child manipulation online, the current EU regulatory system fails\nat providing sufficient levels of protection. Given the universality of the\nissue, there is a need to combine and further these scattered efforts into a\nunitary, multidisciplinary theory of digital manipulation that identifies\ncauses and effects, systematizes the technical and legal knowledge on\nmanipulative and addictive tactics, and to find effective regulatory mechanisms\nto fill the legislative gaps. In this paper we discuss manipulative and\nexploitative strategies in the context of online games for children, suggest a\nnumber of possible reasons for the failure of the applicable regulatory system,\npropose an \"upgrade\" for the regulatory approach to address these risks from\nthe perspective of freedom of thought, and present and discuss technological\napproaches that allow for the development of games that verifiably protect the\nprivacy and freedoms of players.",
    "descriptor": "",
    "authors": [
      "Tommaso Crepax",
      "Jan Tobias Muehlberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.09928"
  },
  {
    "id": "arXiv:2207.09933",
    "title": "Robust Landmark-based Stent Tracking in X-ray Fluoroscopy",
    "abstract": "In clinical procedures of angioplasty (i.e., open clogged coronary arteries),\ndevices such as balloons and stents need to be placed and expanded in arteries\nunder the guidance of X-ray fluoroscopy. Due to the limitation of X-ray dose,\nthe resulting images are often noisy. To check the correct placement of these\ndevices, typically multiple motion-compensated frames are averaged to enhance\nthe view. Therefore, device tracking is a necessary procedure for this purpose.\nEven though angioplasty devices are designed to have radiopaque markers for the\nease of tracking, current methods struggle to deliver satisfactory results due\nto the small marker size and complex scenes in angioplasty. In this paper, we\npropose an end-to-end deep learning framework for single stent tracking, which\nconsists of three hierarchical modules: U-Net based landmark detection, ResNet\nbased stent proposal and feature extraction, and graph convolutional neural\nnetwork (GCN) based stent tracking that temporally aggregates both spatial\ninformation and appearance features. The experiments show that our method\nperforms significantly better in detection compared with the state-of-the-art\npoint-based tracking models. In addition, its fast inference speed satisfies\nclinical requirements.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Luojie Huang",
      "Yikang Liu",
      "Li Chen",
      "Eric Z Chen",
      "Xiao Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09933"
  },
  {
    "id": "arXiv:2207.09934",
    "title": "DeepIPC: Deeply Integrated Perception and Control for Mobile Robot in  Real Environments",
    "abstract": "We propose DeepIPC, an end-to-end multi-task model that handles both\nperception and control tasks in driving a mobile robot autonomously. The model\nconsists of two main parts, perception and controller modules. The perception\nmodule takes RGB image and depth map to perform semantic segmentation and\nbird's eye view (BEV) semantic mapping along with providing their encoded\nfeatures. Meanwhile, the controller module processes these features with the\nmeasurement of GNSS locations and angular speed to estimate waypoints that come\nwith latent features. Then, two different agents are used to translate\nwaypoints and latent features into a set of navigational controls to drive the\nrobot. The model is evaluated by predicting driving records and performing\nautomated driving under various conditions in the real environment. Based on\nthe experimental results, DeepIPC achieves the best drivability and multi-task\nperformance even with fewer parameters compared to the other models.",
    "descriptor": "\nComments: To be submitted to a journal or conference proceedings\n",
    "authors": [
      "Oskar Natan",
      "Jun Miura"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09934"
  },
  {
    "id": "arXiv:2207.09935",
    "title": "Towards Efficient and Scale-Robust Ultra-High-Definition Image  Demoireing",
    "abstract": "With the rapid development of mobile devices, modern widely-used mobile\nphones typically allow users to capture 4K resolution (i.e.,\nultra-high-definition) images. However, for image demoireing, a challenging\ntask in low-level vision, existing works are generally carried out on\nlow-resolution or synthetic images. Hence, the effectiveness of these methods\non 4K resolution images is still unknown. In this paper, we explore moire\npattern removal for ultra-high-definition images. To this end, we propose the\nfirst ultra-high-definition demoireing dataset (UHDM), which contains 5,000\nreal-world 4K resolution image pairs, and conduct a benchmark study on current\nstate-of-the-art methods. Further, we present an efficient baseline model\nESDNet for tackling 4K moire images, wherein we build a semantic-aligned\nscale-aware module to address the scale variation of moire patterns. Extensive\nexperiments manifest the effectiveness of our approach, which outperforms\nstate-of-the-art methods by a large margin while being much more lightweight.\nCode and dataset are available at https://xinyu-andy.github.io/uhdm-page.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Xin Yu",
      "Peng Dai",
      "Wenbo Li",
      "Lan Ma",
      "Jiajun Shen",
      "Jia Li",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09935"
  },
  {
    "id": "arXiv:2207.09936",
    "title": "A Secure Clustering Protocol with Fuzzy Trust Evaluation and Outlier  Detection for Industrial Wireless Sensor Networks",
    "abstract": "Security is one of the major concerns in Industrial Wireless Sensor Networks\n(IWSNs). To assure the security in clustered IWSNs, this paper presents a\nsecure clustering protocol with fuzzy trust evaluation and outlier detection\n(SCFTO). Firstly, to deal with the transmission uncertainty in an open wireless\nmedium, an interval type-2 fuzzy logic controller is adopted to estimate the\ntrusts. And then a density based outlier detection mechanism is introduced to\nacquire an adaptive trust threshold used to isolate the malicious nodes from\nbeing cluster heads. Finally, a fuzzy based cluster heads election method is\nproposed to achieve a balance between energy saving and security assurance, so\nthat a normal sensor node with more residual energy or less confidence on other\nnodes has higher probability to be the cluster head. Extensive experiments\nverify that our secure clustering protocol can effectively defend the network\nagainst attacks from internal malicious or compromised nodes.",
    "descriptor": "",
    "authors": [
      "Liu Yang",
      "Yinzhi Lu",
      "Simon X. Yang",
      "Tan Guo",
      "Zhifang Liang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09936"
  },
  {
    "id": "arXiv:2207.09937",
    "title": "Abelian Combinatorics on Words: a Survey",
    "abstract": "We survey known results and open problems in abelian combinatorics on words.\nAbelian combinatorics on words is the extension to the commutative setting of\nthe classical theory of combinatorics on words, i.e., the extension based on\nthe equivalence relation defined in the set of words by having the same Parikh\nvector, that is, the same number of occurrences of each letter of the alphabet\n-- called \\emph{abelian equivalence}. In the past few years, there was a lot of\nresearch on abelian analogues of classical definitions and properties in\ncombinatorics on words. This survey aims to gather these results.",
    "descriptor": "",
    "authors": [
      "Gabriele Fici",
      "Svetlana Puzynina"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.09937"
  },
  {
    "id": "arXiv:2207.09940",
    "title": "Fault-Tolerant Distributed Directories",
    "abstract": "A distributed directory is an overlay data structure on a graph $G$ that\nhelps to access a shared token $t$. The directory supports three operations:\npublish, to announce the token, lookup, to read the contents of the token, and\nmove, to get exclusive update access to the token. The directory is built upon\na hierarchical partition of the graph using either weak or strong clusters. The\nmain mechanism is the maintenance of a directory path that starts at the root\nnode in the hierarchy and points to the current owner of the token. In the\nliterature, there are known directory algorithms based on hierarchical graph\nstructures, but none of them have considered failures. Given a hierarchical\npartition, we consider the impact of $f$ edge failures on the functionality and\nperformance of the distributed directory. The edge failures may result in the\nsplitting of clusters into up to $f+1$ connected components. To recover the\nhierarchical partition after failures, we maintain spanning trees in the\nclusters and their connected components. If $G$ remains connected, we show that\nthe directory path length is dilated by only a factor $f$. We also show that\nthe performance of the directory operations is affected in the worst case by a\nfactor $f$ with respect to the message complexity.",
    "descriptor": "",
    "authors": [
      "Judith Beesterm\u00f6ller",
      "Costas Busch",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.09940"
  },
  {
    "id": "arXiv:2207.09949",
    "title": "VirtualPose: Learning Generalizable 3D Human Pose Models from Virtual  Data",
    "abstract": "While monocular 3D pose estimation seems to have achieved very accurate\nresults on the public datasets, their generalization ability is largely\noverlooked. In this work, we perform a systematic evaluation of the existing\nmethods and find that they get notably larger errors when tested on different\ncameras, human poses and appearance. To address the problem, we introduce\nVirtualPose, a two-stage learning framework to exploit the hidden \"free lunch\"\nspecific to this task, i.e. generating infinite number of poses and cameras for\ntraining models at no cost. To that end, the first stage transforms images to\nabstract geometry representations (AGR), and then the second maps them to 3D\nposes. It addresses the generalization issue from two aspects: (1) the first\nstage can be trained on diverse 2D datasets to reduce the risk of over-fitting\nto limited appearance; (2) the second stage can be trained on diverse AGR\nsynthesized from a large number of virtual cameras and poses. It outperforms\nthe SOTA methods without using any paired images and 3D poses from the\nbenchmarks, which paves the way for practical applications. Code is available\nat https://github.com/wkom/VirtualPose.",
    "descriptor": "",
    "authors": [
      "Jiajun Su",
      "Chunyu Wang",
      "Xiaoxuan Ma",
      "Wenjun Zeng",
      "Yizhou Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09949"
  },
  {
    "id": "arXiv:2207.09950",
    "title": "MeritRank: Sybil Tolerant Reputation for Merit-based Tokenomics",
    "abstract": "Decentralized reputation schemes present a promising area of experimentation\nin blockchain applications. These solutions aim to overcome the shortcomings of\nsimple monetary incentive mechanisms of naive tokenomics. However, there is a\nsignificant research gap regarding the limitations and benefits of such\nsolutions. We formulate these trade-offs as a conjecture on the\nirreconcilability of three desirable properties of the reputation system in\nthis context. Such a system can not be simultaneously generalizable, trustless,\nand Sybil resistant. To handle the limitations of this trilemma, we propose\nMeritRank: Sybil tolerant feedback aggregation mechanism for reputation.\nInstead of preventing Sybil attacks, our approach successfully bounds the\nbenefits of these attacks. Using a dataset of participants' interactions in\nMakerDAO, we run experiments to demonstrate Sybil tolerance of MeritRank. Decay\nparameters of reputation in MeritRank: transitivity decay and connectivity\ndecay, allow for a fine-tuning of desirable levels of reputation utility and\nSybil tolerance in different use contexts.",
    "descriptor": "",
    "authors": [
      "Bulat Nasrulin",
      "Georgy Ishmaev",
      "Johan Pouwelse"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2207.09950"
  },
  {
    "id": "arXiv:2207.09953",
    "title": "Learning Pedestrian Group Representations for Multi-modal Trajectory  Prediction",
    "abstract": "Modeling the dynamics of people walking is a problem of long-standing\ninterest in computer vision. Many previous works involving pedestrian\ntrajectory prediction define a particular set of individual actions to\nimplicitly model group actions. In this paper, we present a novel architecture\nnamed GP-Graph which has collective group representations for effective\npedestrian trajectory prediction in crowded environments, and is compatible\nwith all types of existing approaches. A key idea of GP-Graph is to model both\nindividual-wise and group-wise relations as graph representations. To do this,\nGP-Graph first learns to assign each pedestrian into the most likely behavior\ngroup. Using this assignment information, GP-Graph then forms both intra- and\ninter-group interactions as graphs, accounting for human-human relations within\na group and group-group relations, respectively. To be specific, for the\nintra-group interaction, we mask pedestrian graph edges out of an associated\ngroup. We also propose group pooling&unpooling operations to represent a group\nwith multiple pedestrians as one graph node. Lastly, GP-Graph infers a\nprobability map for socially-acceptable future trajectories from the integrated\nfeatures of both group interactions. Moreover, we introduce a group-level\nlatent vector sampling to ensure collective inferences over a set of possible\nfuture trajectories. Extensive experiments are conducted to validate the\neffectiveness of our architecture, which demonstrates consistent performance\nimprovements with publicly available benchmarks. Code is publicly available at\nhttps://github.com/inhwanbae/GPGraph.",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Inhwan Bae",
      "Jin-Hwi Park",
      "Hae-Gon Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.09953"
  },
  {
    "id": "arXiv:2207.09955",
    "title": "Operation-Level Performance Benchmarking of Graph Neural Networks for  Scientific Applications",
    "abstract": "As Graph Neural Networks (GNNs) increase in popularity for scientific machine\nlearning, their training and inference efficiency is becoming increasingly\ncritical. Additionally, the deep learning field as a whole is trending towards\nwider and deeper networks, and ever increasing data sizes, to the point where\nhard hardware bottlenecks are often encountered. Emerging specialty hardware\nplatforms provide an exciting solution to this problem. In this paper, we\nsystematically profile and select low-level operations pertinent to GNNs for\nscientific computing implemented in the Pytorch Geometric software framework.\nThese are then rigorously benchmarked on NVIDIA A100 GPUs for several various\ncombinations of input values, including tensor sparsity. We then analyze these\nresults for each operation. At a high level, we conclude that on NVIDIA\nsystems: (1) confounding bottlenecks such as memory inefficiency often dominate\nruntime costs moreso than data sparsity alone, (2) native Pytorch operations\nare often as or more competitive than their Pytorch Geometric equivalents,\nespecially at low to moderate levels of input data sparsity, and (3) many\noperations central to state-of-the-art GNN architectures have little to no\noptimization for sparsity. We hope that these results serve as a baseline for\nthose developing these operations on specialized hardware and that our\nsubsequent analysis helps to facilitate future software and hardware based\noptimizations of these operations and thus scalable GNN performance as a whole.",
    "descriptor": "\nComments: Published as workshop paper at MLSys 2022 (MLBench)\n",
    "authors": [
      "Ryien Hosseini",
      "Filippo Simini",
      "Venkatram Vishwanath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2207.09955"
  },
  {
    "id": "arXiv:2207.09956",
    "title": "Telepresence Video Quality Assessment",
    "abstract": "Video conferencing, which includes both video and audio content, has\ncontributed to dramatic increases in Internet traffic, as the COVID-19 pandemic\nforced millions of people to work and learn from home. Global Internet traffic\nof video conferencing has dramatically increased Because of this, efficient and\naccurate video quality tools are needed to monitor and perceptually optimize\ntelepresence traffic streamed via Zoom, Webex, Meet, etc. However, existing\nmodels are limited in their prediction capabilities on multi-modal, live\nstreaming telepresence content. Here we address the significant challenges of\nTelepresence Video Quality Assessment (TVQA) in several ways. First, we\nmitigated the dearth of subjectively labeled data by collecting ~2k\ntelepresence videos from different countries, on which we crowdsourced ~80k\nsubjective quality labels. Using this new resource, we created a\nfirst-of-a-kind online video quality prediction framework for live streaming,\nusing a multi-modal learning framework with separate pathways to compute visual\nand audio quality predictions. Our all-in-one model is able to provide accurate\nquality predictions at the patch, frame, clip, and audiovisual levels. Our\nmodel achieves state-of-the-art performance on both existing quality databases\nand our new TVQA database, at a considerably lower computational expense,\nmaking it an attractive solution for mobile and embedded systems.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Zhenqiang Ying",
      "Deepti Ghadiyaram",
      "Alan Bovik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.09956"
  },
  {
    "id": "arXiv:2207.09957",
    "title": "Estimating Model Performance under Domain Shifts with Class-Specific  Confidence Scores",
    "abstract": "Machine learning models are typically deployed in a test setting that differs\nfrom the training setting, potentially leading to decreased model performance\nbecause of domain shift. If we could estimate the performance that a\npre-trained model would achieve on data from a specific deployment setting, for\nexample a certain clinic, we could judge whether the model could safely be\ndeployed or if its performance degrades unacceptably on the specific data.\nExisting approaches estimate this based on the confidence of predictions made\non unlabeled test data from the deployment's domain. We find existing methods\nstruggle with data that present class imbalance, because the methods used to\ncalibrate confidence do not account for bias induced by class imbalance,\nconsequently failing to estimate class-wise accuracy. Here, we introduce\nclass-wise calibration within the framework of performance estimation for\nimbalanced datasets. Specifically, we derive class-specific modifications of\nstate-of-the-art confidence-based model evaluation methods including\ntemperature scaling (TS), difference of confidences (DoC), and average\nthresholded confidence (ATC). We also extend the methods to estimate Dice\nsimilarity coefficient (DSC) in image segmentation. We conduct experiments on\nfour tasks and find the proposed modifications consistently improve the\nestimation accuracy for imbalanced datasets. Our methods improve accuracy\nestimation by 18\\% in classification under natural domain shifts, and double\nthe estimation accuracy on segmentation tasks, when compared with prior\nmethods.",
    "descriptor": "\nComments: Accepted at MICCAI 2022\n",
    "authors": [
      "Zeju Li",
      "Konstantinos Kamnitsas",
      "Mobarakol Islam",
      "Chen Chen",
      "Ben Glocker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09957"
  },
  {
    "id": "arXiv:2207.09962",
    "title": "PPAD-Complete Pure Approximate Nash Equilibria in Lipschitz Games",
    "abstract": "Lipschitz games, in which there is a limit $\\lambda$ (the Lipschitz value of\nthe game) on how much a player's payoffs may change when some other player\ndeviates, were introduced about 10 years ago by Azrieli and Shmaya. They showed\nvia the probabilistic method that $n$-player Lipschitz games with $m$\nstrategies per player have pure $\\epsilon$-approximate Nash equilibria, for\n$\\epsilon\\geq\\lambda\\sqrt{8n\\log(2mn)}$. Here we provide the first hardness\nresult for the corresponding computational problem, showing that even for a\nsimple class of Lipschitz games (Lipschitz polymatrix games), finding pure\n$\\epsilon$-approximate equilibria is PPAD-complete, for suitable pairs of\nvalues $(\\epsilon(n), \\lambda(n))$. Novel features of this result include both\nthe proof of PPAD hardness (in which we apply a population game reduction from\nunrestricted polymatrix games) and the proof of containment in PPAD (by\nderandomizing the selection of a pure equilibrium from a mixed one). In fact,\nour approach implies containment in PPAD for any class of Lipschitz games where\npayoffs from mixed-strategy profiles can be deterministically computed.",
    "descriptor": "\nComments: 16 pages, accepted for publication in the 15th International Symposium on Algorithmic Game Theory\n",
    "authors": [
      "Paul W. Goldberg",
      "Matthew J. Katzman"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.09962"
  },
  {
    "id": "arXiv:2207.09963",
    "title": "Rethinking Few-Shot Class-Incremental Learning with Open-Set Hypothesis  in Hyperbolic Geometry",
    "abstract": "Few-Shot Class-Incremental Learning (FSCIL) aims at incrementally learning\nnovel classes from a few labeled samples by avoiding the overfitting and\ncatastrophic forgetting simultaneously. The current protocol of FSCIL is built\nby mimicking the general class-incremental learning setting, while it is not\ntotally appropriate due to the different data configuration, i.e., novel\nclasses are all in the limited data regime. In this paper, we rethink the\nconfiguration of FSCIL with the open-set hypothesis by reserving the\npossibility in the first session for incoming categories. To assign better\nperformances on both close-set and open-set recognition to the model,\nHyperbolic Reciprocal Point Learning module (Hyper-RPL) is built on Reciprocal\nPoint Learning (RPL) with hyperbolic neural networks. Besides, for learning\nnovel categories from limited labeled data, we incorporate a hyperbolic metric\nlearning (Hyper-Metric) module into the distillation-based framework to\nalleviate the overfitting issue and better handle the trade-off issue between\nthe preservation of old knowledge and the acquisition of new knowledge. The\ncomprehensive assessments of the proposed configuration and modules on three\nbenchmark datasets are executed to validate the effectiveness concerning three\nevaluation indicators.",
    "descriptor": "\nComments: submitted to IEEE Transactions on Cybernetics\n",
    "authors": [
      "Yawen Cui",
      "Zitong Yu",
      "Wei Peng",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09963"
  },
  {
    "id": "arXiv:2207.09964",
    "title": "On a Generalized Framework for Time-Aware Knowledge Graphs",
    "abstract": "Knowledge graphs have emerged as an effective tool for managing and\nstandardizing semistructured domain knowledge in a human- and\nmachine-interpretable way. In terms of graph-based domain applications, such as\nembeddings and graph neural networks, current research is increasingly taking\ninto account the time-related evolution of the information encoded within a\ngraph. Algorithms and models for stationary and static knowledge graphs are\nextended to make them accessible for time-aware domains, where time-awareness\ncan be interpreted in different ways. In particular, a distinction needs to be\nmade between the validity period and the traceability of facts as objectives of\ntime-related knowledge graph extensions. In this context, terms and definitions\nsuch as dynamic and temporal are often used inconsistently or interchangeably\nin the literature. Therefore, with this paper we aim to provide a short but\nwell-defined overview of time-aware knowledge graph extensions and thus\nfaciliate future research in this field as well.",
    "descriptor": "\nComments: Accepted for publication at Semantics 2022\n",
    "authors": [
      "Franz Krause",
      "Tobias Weller",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09964"
  },
  {
    "id": "arXiv:2207.09965",
    "title": "M2-Net: Multi-stages Specular Highlight Detection and Removal in  Multi-scenes",
    "abstract": "In this paper, we propose a novel uniformity framework for highlight\ndetection and removal in multi-scenes, including synthetic images, face images,\nnatural images, and text images. The framework consists of three main\ncomponents, highlight feature extractor module, highlight coarse removal\nmodule, and highlight refine removal module. Firstly, the highlight feature\nextractor module can directly separate the highlight feature and non-highlight\nfeature from the original highlight image. Then highlight removal image is\nobtained using a coarse highlight removal network. To further improve the\nhighlight removal effect, the refined highlight removal image is finally\nobtained using refine highlight removal module based on contextual highlight\nattention mechanisms. Extensive experimental results in multiple scenes\nindicate that the proposed framework can obtain excellent visual effects of\nhighlight removal and achieve state-of-the-art results in several quantitative\nevaluation metrics. Our algorithm is applied for the first time in video\nhighlight removal with promising results.",
    "descriptor": "",
    "authors": [
      "Zhaoyangfan Huang",
      "Kun Hu",
      "Xingjun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09965"
  },
  {
    "id": "arXiv:2207.09966",
    "title": "Temporal and cross-modal attention for audio-visual zero-shot learning",
    "abstract": "Audio-visual generalised zero-shot learning for video classification requires\nunderstanding the relations between the audio and visual information in order\nto be able to recognise samples from novel, previously unseen classes at test\ntime. The natural semantic and temporal alignment between audio and visual data\nin video data can be exploited to learn powerful representations that\ngeneralise to unseen classes at test time. We propose a multi-modal and\nTemporal Cross-attention Framework (\\modelName) for audio-visual generalised\nzero-shot learning. Its inputs are temporally aligned audio and visual features\nthat are obtained from pre-trained networks. Encouraging the framework to focus\non cross-modal correspondence across time instead of self-attention within the\nmodalities boosts the performance significantly. We show that our proposed\nframework that ingests temporal features yields state-of-the-art performance on\nthe \\ucf, \\vgg, and \\activity benchmarks for (generalised) zero-shot learning.\nCode for reproducing all results is available at\n\\url{https://github.com/ExplainableML/TCAF-GZSL}.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Otniel-Bogdan Mercea",
      "Thomas Hummel",
      "A. Sophia Koepke",
      "Zeynep Akata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09966"
  },
  {
    "id": "arXiv:2207.09975",
    "title": "Implementacion de un sistema IoT de bajo costo para el monitoreo de la  calidad del aire en El Salvador",
    "abstract": "Environmental pollution is a factor that represents a significant health\nrisk. In El Salvador, The entity in charge of monitoring air quality is the\nministry of Environment and Natural Resources, currently said ministry only has\n3 stations for monitoring air quality throughout the territory of the country.\nThe main objective of this work was the application of internet of things\ntechniques in the design and implementation of a station of remote particulate\npollution monitoring in the surrounding air. As well as setting up an Internet\nof Things (IoT) platform for the deployment of the data collected by the remote\nstation. The development methodology of this research was based on the Model of\nReference Architecture for IoT systems, which has as based on the development\nof system prototypes based on the correct choice of components available and\nsuitable for the specific environment or application. For this case, they were\nused as inputs for the electronic hardware and Esp32 controller together with a\nWemos-Lolin development board together with a sensor of particulate matter\ncontamination PMS5003; by the side of software for the IoT platform was\nimplemented a storage system, graphics and website based on low-cost tools The\nmain result obtained in this work was an IoT prototype of an electronic station\nthat allows monitoring the levels of contamination by the material of particles\nin the environment, whose data are accessible from any device with internet\naccess through a site web, another result of this work is the configuring an\nIoT platform or cloud to connect wireless with the electronic station, the\nstorage of the data produced by it and a web visualization stage.",
    "descriptor": "\nComments: In Spanish language. In conference proceedings XXX Reunion Internacional de Otono en Comunicaciones, Computacion, Electronica, Automatizacion y Exposicion Industrial Tema Central: Internet para Todos, hacia la Conectividad Universal\n",
    "authors": [
      "Omar Otoniel Flores-Cortez",
      "Ronny Adalberto Cortez",
      "Veronica Rosa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09975"
  },
  {
    "id": "arXiv:2207.09978",
    "title": "NeuralBF: Neural Bilateral Filtering for Top-down Instance Segmentation  on Point Clouds",
    "abstract": "We introduce a method for instance proposal generation for 3D point clouds.\nExisting techniques typically directly regress proposals in a single\nfeed-forward step, leading to inaccurate estimation. We show that this serves\nas a critical bottleneck, and propose a method based on iterative bilateral\nfiltering with learned kernels. Following the spirit of bilateral filtering, we\nconsider both the deep feature embeddings of each point, as well as their\nlocations in the 3D space. We show via synthetic experiments that our method\nbrings drastic improvements when generating instance proposals for a given\npoint of interest. We further validate our method on the challenging ScanNet\nbenchmark, achieving the best instance segmentation performance amongst the\nsub-category of top-down methods.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Weiwei Sun",
      "Daniel Rebain",
      "Renjie Liao",
      "Vladimir Tankovich",
      "Soroosh Yazdani",
      "Kwang Moo Yi",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2207.09978"
  },
  {
    "id": "arXiv:2207.09980",
    "title": "REFACTOR GNNS: Revisiting Factorisation-based Models from a  Message-Passing Perspective",
    "abstract": "Factorisation-based Models (FMs), such as DistMult, have enjoyed enduring\nsuccess for Knowledge Graph Completion (KGC) tasks, often outperforming Graph\nNeural Networks (GNNs). However, unlike GNNs, FMs struggle to incorporate node\nfeatures and to generalise to unseen nodes in inductive settings. Our work\nbridges the gap between FMs and GNNs by proposing REFACTOR GNNS. This new\narchitecture draws upon both modelling paradigms, which previously were largely\nthought of as disjoint. Concretely, using a message-passing formalism, we show\nhow FMs can be cast as GNNs by reformulating the gradient descent procedure as\nmessage-passing operations, which forms the basis of our REFACTOR GNNS. Across\na multitude of well-established KGC benchmarks, our REFACTOR GNNS achieve\ncomparable transductive performance to FMs, and state-of-the-art inductive\nperformance while using an order of magnitude fewer parameters.",
    "descriptor": "",
    "authors": [
      "Yihong Chen",
      "Pushkar Mishra",
      "Luca Franceschi",
      "Pasquale Minervini",
      "Pontus Stenetorp",
      "Sebastian Riedel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.09980"
  },
  {
    "id": "arXiv:2207.09983",
    "title": "Diffsound: Discrete Diffusion Model for Text-to-sound Generation",
    "abstract": "Generating sound effects that humans want is an important topic. However,\nthere are few studies in this area for sound generation. In this study, we\ninvestigate generating sound conditioned on a text prompt and propose a novel\ntext-to-sound generation framework that consists of a text encoder, a Vector\nQuantized Variational Autoencoder (VQ-VAE), a decoder, and a vocoder. The\nframework first uses the decoder to transfer the text features extracted from\nthe text encoder to a mel-spectrogram with the help of VQ-VAE, and then the\nvocoder is used to transform the generated mel-spectrogram into a waveform. We\nfound that the decoder significantly influences the generation performance.\nThus, we focus on designing a good decoder in this study. We begin with the\ntraditional autoregressive decoder, which has been proved as a state-of-the-art\nmethod in previous sound generation works. However, the AR decoder always\npredicts the mel-spectrogram tokens one by one in order, which introduces the\nunidirectional bias and accumulation of errors problems. Moreover, with the AR\ndecoder, the sound generation time increases linearly with the sound duration.\nTo overcome the shortcomings introduced by AR decoders, we propose a\nnon-autoregressive decoder based on the discrete diffusion model, named\nDiffsound. Specifically, the Diffsound predicts all of the mel-spectrogram\ntokens in one step and then refines the predicted tokens in the next step, so\nthe best-predicted results can be obtained after several steps. Our experiments\nshow that our proposed Diffsound not only produces better text-to-sound\ngeneration results when compared with the AR decoder but also has a faster\ngeneration speed, e.g., MOS: 3.56 \\textit{v.s} 2.786, and the generation speed\nis five times faster than the AR decoder.",
    "descriptor": "\nComments: Submitted to TASLP2022\n",
    "authors": [
      "Dongchao Yang",
      "Jianwei Yu",
      "Helin Wang",
      "Wen Wang",
      "Chao Weng",
      "Yuexian Zou",
      "Dong Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.09983"
  },
  {
    "id": "arXiv:2207.09988",
    "title": "DecoupleNet: Decoupled Network for Domain Adaptive Semantic Segmentation",
    "abstract": "Unsupervised domain adaptation in semantic segmentation has been raised to\nalleviate the reliance on expensive pixel-wise annotations. It leverages a\nlabeled source domain dataset as well as unlabeled target domain images to\nlearn a segmentation network. In this paper, we observe two main issues of the\nexisting domain-invariant learning framework. (1) Being distracted by the\nfeature distribution alignment, the network cannot focus on the segmentation\ntask. (2) Fitting source domain data well would compromise the target domain\nperformance. To address these issues, we propose DecoupleNet that alleviates\nsource domain overfitting and enables the final model to focus more on the\nsegmentation task. Furthermore, we put forward Self-Discrimination (SD) and\nintroduce an auxiliary classifier to learn more discriminative target domain\nfeatures with pseudo labels. Finally, we propose Online Enhanced Self-Training\n(OEST) to contextually enhance the quality of pseudo labels in an online\nmanner. Experiments show our method outperforms existing state-of-the-art\nmethods, and extensive ablation studies verify the effectiveness of each\ncomponent. Code is available at https://github.com/dvlab-research/DecoupleNet.",
    "descriptor": "\nComments: Accepted to ECCV 2022. Code is available at this https URL\n",
    "authors": [
      "Xin Lai",
      "Zhuotao Tian",
      "Xiaogang Xu",
      "Yingcong Chen",
      "Shu Liu",
      "Hengshuang Zhao",
      "Liwei Wang",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09988"
  },
  {
    "id": "arXiv:2207.09989",
    "title": "The Regularised Inertial Dean-Kawasaki equation: discontinuous Galerkin  approximation and modelling for low-density regime",
    "abstract": "The Regularised Inertial Dean-Kawasaki model (RIDK) is a nonlinear stochastic\nPDE which captures fluctuations around the mean-field limit for large-scale\nparticle systems in both density and momentum. We focus on the following two\naspects. Firstly, we set up a discontinuous Galerkin (DG) discretisation scheme\nfor the RIDK model: we provide suitable definitions of numerical fluxes at the\ninterface of the mesh elements which are consistent with the wave-type nature\nof the RIDK model and grant stability of the simulations, and we quantify the\nrate of convergence in mean square to the continuous RIDK model. Secondly, we\nintroduce modifications of the RIDK model in order to preserve positivity of\nthe density (such a feature does not hold for the original RIDK model). By\nmeans of numerical simulations, we show that the modifications lead to\nphysically realistic and positive density profiles. In one case, subject to\nadditional regularity constraints, we also prove positivity. Finally, we\npresent an application of our methodology to a system of diffusing and reacting\nparticles. Our Python code is available in open-source format.",
    "descriptor": "\nComments: 33 pages, 13 figures\n",
    "authors": [
      "Federico Cornalba",
      "Tony Shardlow"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2207.09989"
  },
  {
    "id": "arXiv:2207.09993",
    "title": "Computing Tree Decompositions with Small Independence Number",
    "abstract": "The independence number of a tree decomposition is the maximum of the\nindependence numbers of the subgraphs induced by its bags. The\ntree-independence number of a graph is the minimum independence number of a\ntree decomposition of it. Several NP-hard graph problems, like maximum weight\nindependent set, can be solved in time $n^{O(k)}$ if the input graph is given\nwith a tree decomposition of independence number at most $k$. However, it was\nan open problem if tree-independence number could be computed or approximated\nin $n^{f(k)}$ time, for some function $f$, and in particular it was not known\nif maximum weight independent set could be solved in polynomial time on graphs\nof bounded tree-independence number.\nIn this paper, we resolve the main open problems about the computation of\ntree-independence number. First, we give an algorithm that given an $n$-vertex\ngraph $G$ and an integer $k$, in time $2^{O(k^2)} n^{O(k)}$ either outputs a\ntree decomposition of $G$ with independence number at most $8k$, or determines\nthat the tree-independence number of $G$ is larger than $k$. This implies\n$2^{O(k^2)} n^{O(k)}$ time algorithms for various problems, like maximum weight\nindependent set, parameterized by tree-independence number $k$ without needing\nthe decomposition as an input. Then, we show that the exact computing of\ntree-independence number is para-NP-hard, in particular, that for every\nconstant $k \\ge 4$ it is NP-hard to decide if a given graph has\ntree-independence number at most $k$.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Tuukka Korhonen",
      "Martin Milani\u010d"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.09993"
  },
  {
    "id": "arXiv:2207.09996",
    "title": "Phenomenon-Signal Model: Formalisation, Graph and Application",
    "abstract": "Considering information as the basis of action, it may be of interest to\nexamine the flow and acquisition of information between the actors in traffic.\nThe central question is: Which signals does an automated driving system (which\nwill be referred to as an automaton in the remainder of this paper) in traffic\nhave to receive, decode or send in road traffic in order to act safely and in a\nmanner that is compliant with valid standards. The phenomenon-signal model\n(PSM) is a method for structuring the problem area and for analysing and\ndescribing this very signal flow. The aim of this paper is to explain the\nbasics, the structure and the application of this method.",
    "descriptor": "\nComments: 21 pages, 6 figures\n",
    "authors": [
      "Hans Nikolaus Beck",
      "Nayel Fabian Salem",
      "Veronica Haber",
      "Matthias Rauschenbach",
      "Jan Reich"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09996"
  },
  {
    "id": "arXiv:2207.09999",
    "title": "Digital Twin-based Intrusion Detection for Industrial Control Systems",
    "abstract": "Digital twins have recently gained significant interest in simulation,\noptimization, and predictive maintenance of Industrial Control Systems (ICS).\nRecent studies discuss the possibility of using digital twins for intrusion\ndetection in industrial systems. Accordingly, this study contributes to a\ndigital twin-based security framework for industrial control systems, extending\nits capabilities for simulation of attacks and defense mechanisms. Four types\nof process-aware attack scenarios are implemented on a standalone open-source\ndigital twin of an industrial filling plant: command injection, network Denial\nof Service (DoS), calculated measurement modification, and naive measurement\nmodification. A stacked ensemble classifier is proposed as the real-time\nintrusion detection, based on the offline evaluation of eight supervised\nmachine learning algorithms. The designed stacked model outperforms previous\nmethods in terms of F1-Score and accuracy, by combining the predictions of\nvarious algorithms, while it can detect and classify intrusions in near\nreal-time (0.1 seconds). This study also discusses the practicality and\nbenefits of the proposed digital twin-based security framework.",
    "descriptor": "\nComments: 7 pages, 7 figures, 3 tables, workshop paper\n",
    "authors": [
      "Seba Anna Varghese",
      "Alireza Dehlaghi Ghadim",
      "Ali Balador",
      "Zahra Alimadadi",
      "Panos Papadimitratos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09999"
  },
  {
    "id": "arXiv:2207.10002",
    "title": "Overcoming Shortcut Learning in a Target Domain by Generalizing Basic  Visual Factors from a Source Domain",
    "abstract": "Shortcut learning occurs when a deep neural network overly relies on spurious\ncorrelations in the training dataset in order to solve downstream tasks. Prior\nworks have shown how this impairs the compositional generalization capability\nof deep learning models. To address this problem, we propose a novel approach\nto mitigate shortcut learning in uncontrolled target domains. Our approach\nextends the training set with an additional dataset (the source domain), which\nis specifically designed to facilitate learning independent representations of\nbasic visual factors. We benchmark our idea on synthetic target domains where\nwe explicitly control shortcut opportunities as well as real-world target\ndomains. Furthermore, we analyze the effect of different specifications of the\nsource domain and the network architecture on compositional generalization. Our\nmain finding is that leveraging data from a source domain is an effective way\nto mitigate shortcut learning. By promoting independence across different\nfactors of variation in the learned representations, networks can learn to\nconsider only predictive factors and ignore potential shortcut factors during\ninference.",
    "descriptor": "\nComments: Accepted for publication at European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Piyapat Saranrittichai",
      "Chaithanya Kumar Mummadi",
      "Claudia Blaiotta",
      "Mauricio Munoz",
      "Volker Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10002"
  },
  {
    "id": "arXiv:2207.10003",
    "title": "BYEL : Bootstrap on Your Emotion Latent",
    "abstract": "According to the problem of dataset construction cost for training in deep\nlearning and the development of generative models, more and more researches are\nbeing conducted to train with synthetic data and to inference using real data.\nWe propose emotion aware Self-Supervised Learning using ABAW's Learning\nSynthetic Data (LSD) dataset. We pre-train our method to LSD dataset as a\nself-supervised learning and then use the same LSD dataset to do downstream\ntraining on the emotion classification task as a supervised learning. As a\nresult, a higher result(0.63) than baseline(0.5) was obtained.",
    "descriptor": "\nComments: ABAW4th competition\n",
    "authors": [
      "Hyungjun Lee",
      "Hwangyu Lim",
      "Sejoon Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10003"
  },
  {
    "id": "arXiv:2207.10006",
    "title": "Fine-grained Early Frequency Attention for Deep Speaker Recognition",
    "abstract": "Attention mechanisms have emerged as important tools that boost the\nperformance of deep models by allowing them to focus on key parts of learned\nembeddings. However, current attention mechanisms used in speaker recognition\ntasks fail to consider fine-grained information items such as frequency bins in\ninput spectral representations used by the deep networks. To address this\nissue, we propose the novel Fine-grained Early Frequency Attention (FEFA) for\nspeaker recognition in-the-wild. Once integrated into a deep neural network,\nour proposed mechanism works by obtaining queries from early layers of the\nnetwork and generating learnable weights to attend to information items as\nsmall as the frequency bins in the input spectral representations. To evaluate\nthe performance of FEFA, we use several well-known deep models as backbone\nnetworks and integrate our attention module in their pipelines. The overall\nperformance of these networks (with and without FEFA) are evaluated on the\nVoxCeleb1 dataset, where we observe considerable improvements when FEFA is\nused.",
    "descriptor": "\nComments: Accepted In IJCNN 2022\n",
    "authors": [
      "Amirhossein Hajavi",
      "Ali Etemad"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.10006"
  },
  {
    "id": "arXiv:2207.10008",
    "title": "E-Graph: Minimal Solution for Rigid Rotation with Extensibility Graphs",
    "abstract": "Minimal solutions for relative rotation and translation estimation tasks have\nbeen explored in different scenarios, typically relying on the so-called\nco-visibility graph. However, how to build direct rotation relationships\nbetween two frames without overlap is still an open topic, which, if solved,\ncould greatly improve the accuracy of visual odometry.\nIn this paper, a new minimal solution is proposed to solve relative rotation\nestimation between two images without overlapping areas by exploiting a new\ngraph structure, which we call Extensibility Graph (E-Graph). Differently from\na co-visibility graph, high-level landmarks, including vanishing directions and\nplane normals, are stored in our E-Graph, which are geometrically extensible.\nBased on E-Graph, the rotation estimation problem becomes simpler and more\nelegant, as it can deal with pure rotational motion and requires fewer\nassumptions, e.g. Manhattan/Atlanta World, planar/vertical motion. Finally, we\nembed our rotation estimation strategy into a complete camera tracking and\nmapping system which obtains 6-DoF camera poses and a dense 3D mesh model.\nExtensive experiments on public benchmarks demonstrate that the proposed\nmethod achieves state-of-the-art tracking performance.",
    "descriptor": "",
    "authors": [
      "Yanyan Li",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10008"
  },
  {
    "id": "arXiv:2207.10010",
    "title": "A Totally Predictable Outcome: An Investigation of Traversals of  Infinite Structures",
    "abstract": "Functors with an instance of the Traversable type class can be thought of as\ndata structures which permit a traversal of their elements. This has been made\nprecise by the correspondence between traversable functors and finitary\ncontainers (also known as polynomial functors) -- established in the context of\ntotal, necessarily terminating, functions. However, the Haskell language is\nnon-strict and permits functions that do not terminate. It has long been\nobserved that traversals can at times in fact operate over infinite lists, for\nexample in distributing the Reader applicative. The result of such a traversal\nremains an infinite structure, however it nonetheless is productive -- i.e.\nsuccessive amounts of finite computation yield either termination or successive\nresults. To investigate this phenomenon, we draw on tools from guarded\nrecursion, making use of equational reasoning directly in Haskell.",
    "descriptor": "",
    "authors": [
      "Gershom Bazerman"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.10010"
  },
  {
    "id": "arXiv:2207.10011",
    "title": "Sampling type method combined with deep learning for inverse scattering  with one incident wave",
    "abstract": "We consider the inverse problem of determining the geometry of penetrable\nobjects from scattering data generated by one incident wave at a fixed\nfrequency. We first study an orthogonality sampling type method which is fast,\nsimple to implement, and robust against noise in the data. This sampling method\nhas a new imaging functional that is applicable to data measured in near field\nor far field regions. The resolution analysis of the imaging functional is\nanalyzed where the explicit decay rate of the functional is established. A\nconnection with the orthogonality sampling method by Potthast is also studied.\nThe sampling method is then combined with a deep neural network to solve the\ninverse scattering problem. This combined method can be understood as a network\nusing the image computed by the sampling method for the first layer and\nfollowed by the U-net architecture for the rest of the layers. The fast\ncomputation and the knowledge from the results of the sampling method help\nspeed up the training of the network. The combination leads to a significant\nimprovement in the reconstruction results initially obtained by the sampling\nmethod. The combined method is also able to invert some limited aperture\nexperimental data without any additional transfer training.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Thu Le",
      "Dinh-Liem Nguyen",
      "Vu Nguyen",
      "Trung Truong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.10011"
  },
  {
    "id": "arXiv:2207.10015",
    "title": "Generative Domain Adaptation for Face Anti-Spoofing",
    "abstract": "Face anti-spoofing (FAS) approaches based on unsupervised domain adaption\n(UDA) have drawn growing attention due to promising performances for target\nscenarios. Most existing UDA FAS methods typically fit the trained models to\nthe target domain via aligning the distribution of semantic high-level\nfeatures. However, insufficient supervision of unlabeled target domains and\nneglect of low-level feature alignment degrade the performances of existing\nmethods. To address these issues, we propose a novel perspective of UDA FAS\nthat directly fits the target data to the models, i.e., stylizes the target\ndata to the source-domain style via image translation, and further feeds the\nstylized data into the well-trained source model for classification. The\nproposed Generative Domain Adaptation (GDA) framework combines two carefully\ndesigned consistency constraints: 1) Inter-domain neural statistic consistency\nguides the generator in narrowing the inter-domain gap. 2) Dual-level semantic\nconsistency ensures the semantic quality of stylized images. Besides, we\npropose intra-domain spectrum mixup to further expand target data distributions\nto ensure generalization and reduce the intra-domain gap. Extensive experiments\nand visualizations demonstrate the effectiveness of our method against the\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Qianyu Zhou",
      "Ke-Yue Zhang",
      "Taiping Yao",
      "Ran Yi",
      "Kekai Sheng",
      "Shouhong Ding",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10015"
  },
  {
    "id": "arXiv:2207.10016",
    "title": "Two-Dimensional Typewriter Automata",
    "abstract": "A typewriter automaton is a special variant of a two-dimensional automaton\nthat receives two-dimensional words as input and is only capable of moving its\ninput head through its input word in three directions: downward, leftward, and\nrightward. In addition, downward and leftward moves may only be made via a\nspecial \"reset\" move that simulates the action of a typewriter's carriage\nreturn.\nIn this paper, we initiate the study of the typewriter automaton model and\nrelate it to similar models, including three-way two-dimensional automata,\nboustrophedon automata, and returning automata. We study the recognition powers\nof the typewriter automaton model, establish closure properties of the class of\nlanguages recognized by the model, and consider operational state complexity\nbounds for the specific operation of row concatenation. We also provide a\nvariety of potential future research directions pertaining to the model.",
    "descriptor": "",
    "authors": [
      "Taylor J. Smith"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2207.10016"
  },
  {
    "id": "arXiv:2207.10017",
    "title": "Predictive Object-Centric Process Monitoring",
    "abstract": "The automation and digitalization of business processes has resulted in large\namounts of data captured in information systems, which can aid businesses in\nunderstanding their processes better, improve workflows, or provide operational\nsupport. By making predictions about ongoing processes, bottlenecks can be\nidentified and resources reallocated, as well as insights gained into the state\nof a process instance (case). Traditionally, data is extracted from systems in\nthe form of an event log with a single identifying case notion, such as an\norder id for an Order to Cash (O2C) process. However, real processes often have\nmultiple object types, for example, order, item, and package, so a format that\nforces the use of a single case notion does not reflect the underlying\nrelations in the data. The Object-Centric Event Log (OCEL) format was\nintroduced to correctly capture this information. The state-of-the-art\npredictive methods have been tailored to only traditional event logs. This\nthesis shows that a prediction method utilizing Generative Adversarial Networks\n(GAN), Long Short-Term Memory (LSTM) architectures, and Sequence to Sequence\nmodels (Seq2seq), can be augmented with the rich data contained in OCEL.\nObjects in OCEL can have attributes that are useful in predicting the next\nevent and timestamp, such as a priority class attribute for an object type\npackage indicating slower or faster processing. In the metrics of sequence\nsimilarity of predicted remaining events and mean absolute error (MAE) of the\ntimestamp, the approach in this thesis matches or exceeds previous research,\ndepending on whether selected object attributes are useful features for the\nmodel. Additionally, this thesis provides a web interface to predict the next\nsequence of activities from user input.",
    "descriptor": "",
    "authors": [
      "Timo Rohrer",
      "Anahita Farhang Ghahfarokhi",
      "Mohamed Behery",
      "Gerhard Lakemeyer",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10017"
  },
  {
    "id": "arXiv:2207.10018",
    "title": "Mitigating Algorithmic Bias with Limited Annotations",
    "abstract": "Existing work on fairness modeling commonly assumes that sensitive attributes\nfor all instances are fully available, which may not be true in many real-world\napplications due to the high cost of acquiring sensitive information. When\nsensitive attributes are not disclosed or available, it is needed to manually\nannotate a small part of the training data to mitigate bias. However, the\nskewed distribution across different sensitive groups preserves the skewness of\nthe original dataset in the annotated subset, which leads to non-optimal bias\nmitigation. To tackle this challenge, we propose Active Penalization Of\nDiscrimination (APOD), an interactive framework to guide the limited\nannotations towards maximally eliminating the effect of algorithmic bias. The\nproposed APOD integrates discrimination penalization with active instance\nselection to efficiently utilize the limited annotation budget, and it is\ntheoretically proved to be capable of bounding the algorithmic bias. According\nto the evaluation on five benchmark datasets, APOD outperforms the\nstate-of-the-arts baseline methods under the limited annotation budget, and\nshows comparable performance to fully annotated bias mitigation, which\ndemonstrates that APOD could benefit real-world applications when sensitive\ninformation is limited.",
    "descriptor": "",
    "authors": [
      "Guanchu Wang",
      "Mengnan Du",
      "Ninghao Liu",
      "Na Zou",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.10018"
  },
  {
    "id": "arXiv:2207.10020",
    "title": "MANI-Rank: Multiple Attribute and Intersectional Group Fairness for  Consensus Ranking",
    "abstract": "Combining the preferences of many rankers into one single consensus ranking\nis critical for consequential applications from hiring and admissions to\nlending. While group fairness has been extensively studied for classification,\ngroup fairness in rankings and in particular rank aggregation remains in its\ninfancy. Recent work introduced the concept of fair rank aggregation for\ncombining rankings but restricted to the case when candidates have a single\nbinary protected attribute, i.e., they fall into two groups only. Yet it\nremains an open problem how to create a consensus ranking that represents the\npreferences of all rankers while ensuring fair treatment for candidates with\nmultiple protected attributes such as gender, race, and nationality. In this\nwork, we are the first to define and solve this open Multi-attribute Fair\nConsensus Ranking (MFCR) problem. As a foundation, we design novel group\nfairness criteria for rankings, called MANI-RANK, ensuring fair treatment of\ngroups defined by individual protected attributes and their intersection.\nLeveraging the MANI-RANK criteria, we develop a series of algorithms that for\nthe first time tackle the MFCR problem. Our experimental study with a rich\nvariety of consensus scenarios demonstrates our MFCR methodology is the only\napproach to achieve both intersectional and protected attribute fairness while\nalso representing the preferences expressed through many base rankings. Our\nreal-world case study on merit scholarships illustrates the effectiveness of\nour MFCR methods to mitigate bias across multiple protected attributes and\ntheir intersections. This is an extended version of \"MANI-Rank: Multiple\nAttribute and Intersectional Group Fairness for Consensus Ranking\", to appear\nin ICDE 2022.",
    "descriptor": "\nComments: This paper has been accepted by IEEE ICDE 2022. 15 pages, and 7 figures\n",
    "authors": [
      "Kathleen Cachel",
      "Elke Rundensteiner",
      "Lane Harrison"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10020"
  },
  {
    "id": "arXiv:2207.10022",
    "title": "Secrets of Event-Based Optical Flow",
    "abstract": "Event cameras respond to scene dynamics and offer advantages to estimate\nmotion. Following recent image-based deep-learning achievements, optical flow\nestimation methods for event cameras have rushed to combine those image-based\nmethods with event data. However, it requires several adaptations (data\nconversion, loss function, etc.) as they have very different properties. We\ndevelop a principled method to extend the Contrast Maximization framework to\nestimate optical flow from events alone. We investigate key elements: how to\ndesign the objective function to prevent overfitting, how to warp events to\ndeal better with occlusions, and how to improve convergence with multi-scale\nraw events. With these key elements, our method ranks first among unsupervised\nmethods on the MVSEC benchmark, and is competitive on the DSEC benchmark.\nMoreover, our method allows us to expose the issues of the ground truth flow in\nthose benchmarks, and produces remarkable results when it is transferred to\nunsupervised learning settings. Our code is available at\nhttps://github.com/tub-rip/event_based_optical_flow",
    "descriptor": "\nComments: 23 pages, 11 figures, 7 tables, this https URL\n",
    "authors": [
      "Shintaro Shiba",
      "Yoshimitsu Aoki",
      "Guillermo Gallego"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10022"
  },
  {
    "id": "arXiv:2207.10023",
    "title": "Tailoring Self-Supervision for Supervised Learning",
    "abstract": "Recently, it is shown that deploying a proper self-supervision is a\nprospective way to enhance the performance of supervised learning. Yet, the\nbenefits of self-supervision are not fully exploited as previous pretext tasks\nare specialized for unsupervised representation learning. To this end, we begin\nby presenting three desirable properties for such auxiliary tasks to assist the\nsupervised objective. First, the tasks need to guide the model to learn rich\nfeatures. Second, the transformations involved in the self-supervision should\nnot significantly alter the training distribution. Third, the tasks are\npreferred to be light and generic for high applicability to prior arts.\nSubsequently, to show how existing pretext tasks can fulfill these and be\ntailored for supervised learning, we propose a simple auxiliary\nself-supervision task, predicting localizable rotation (LoRot). Our exhaustive\nexperiments validate the merits of LoRot as a pretext task tailored for\nsupervised learning in terms of robustness and generalization capability. Our\ncode is available at https://github.com/wjun0830/Localizable-Rotation.",
    "descriptor": "\nComments: Accepted to ECCV 2022. Code is available at github.com/wjun0830/Localizable-Rotation\n",
    "authors": [
      "WonJun Moon",
      "Ji-Hwan Kim",
      "Jae-Pil Heo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10023"
  },
  {
    "id": "arXiv:2207.10024",
    "title": "Difficulty-Aware Simulator for Open Set Recognition",
    "abstract": "Open set recognition (OSR) assumes unknown instances appear out of the blue\nat the inference time. The main challenge of OSR is that the response of models\nfor unknowns is totally unpredictable. Furthermore, the diversity of open set\nmakes it harder since instances have different difficulty levels. Therefore, we\npresent a novel framework, DIfficulty-Aware Simulator (DIAS), that generates\nfakes with diverse difficulty levels to simulate the real world. We first\ninvestigate fakes from generative adversarial network (GAN) in the classifier's\nviewpoint and observe that these are not severely challenging. This leads us to\ndefine the criteria for difficulty by regarding samples generated with GANs\nhaving moderate-difficulty. To produce hard-difficulty examples, we introduce\nCopycat, imitating the behavior of the classifier. Furthermore, moderate- and\neasy-difficulty samples are also yielded by our modified GAN and Copycat,\nrespectively. As a result, DIAS outperforms state-of-the-art methods with both\nmetrics of AUROC and F-score. Our code is available at\nhttps://github.com/wjun0830/Difficulty-Aware-Simulator.",
    "descriptor": "\nComments: Accepted to ECCV 2022. Code is available at github.com/wjun0830/Difficulty-Aware-Simulator\n",
    "authors": [
      "WonJun Moon",
      "Junho Park",
      "Hyun Seok Seong",
      "Cheol-Ho Cho",
      "Jae-Pil Heo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10024"
  },
  {
    "id": "arXiv:2207.10025",
    "title": "Learning from Synthetic Data: Facial Expression Classification based on  Ensemble of Multi-task Networks",
    "abstract": "Facial expression in-the-wild is essential for various interactive computing\ndomains. Especially, \"Learning from Synthetic Data\" (LSD) is an important topic\nin the facial expression recognition task. In this paper, we propose a\nmulti-task learning-based facial expression recognition approach which consists\nof emotion and appearance learning branches that can share all face\ninformation, and present preliminary results for the LSD challenge introduced\nin the 4th affective behavior analysis in-the-wild (ABAW) competition. Our\nmethod achieved the mean F1 score of 0.71.",
    "descriptor": "",
    "authors": [
      "Jae-Yeop Jeong",
      "Yeong-Gi Hong",
      "JiYeon Oh",
      "Sumin Hong",
      "Jin-Woo Jeong",
      "Yuchul Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10025"
  },
  {
    "id": "arXiv:2207.10026",
    "title": "Locality Guidance for Improving Vision Transformers on Tiny Datasets",
    "abstract": "While the Vision Transformer (VT) architecture is becoming trendy in computer\nvision, pure VT models perform poorly on tiny datasets. To address this issue,\nthis paper proposes the locality guidance for improving the performance of VTs\non tiny datasets. We first analyze that the local information, which is of\ngreat importance for understanding images, is hard to be learned with limited\ndata due to the high flexibility and intrinsic globality of the self-attention\nmechanism in VTs. To facilitate local information, we realize the locality\nguidance for VTs by imitating the features of an already trained convolutional\nneural network (CNN), inspired by the built-in local-to-global hierarchy of\nCNN. Under our dual-task learning paradigm, the locality guidance provided by a\nlightweight CNN trained on low-resolution images is adequate to accelerate the\nconvergence and improve the performance of VTs to a large extent. Therefore,\nour locality guidance approach is very simple and efficient, and can serve as a\nbasic performance enhancement method for VTs on tiny datasets. Extensive\nexperiments demonstrate that our method can significantly improve VTs when\ntraining from scratch on tiny datasets and is compatible with different kinds\nof VTs and datasets. For example, our proposed method can boost the performance\nof various VTs on tiny datasets (e.g., 13.07% for DeiT, 8.98% for T2T and 7.85%\nfor PVT), and enhance even stronger baseline PVTv2 by 1.86% to 79.30%, showing\nthe potential of VTs on tiny datasets. The code is available at\nhttps://github.com/lkhl/tiny-transformers.",
    "descriptor": "",
    "authors": [
      "Kehan Li",
      "Runyi Yu",
      "Zhennan Wang",
      "Li Yuan",
      "Guoli Song",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10026"
  },
  {
    "id": "arXiv:2207.10031",
    "title": "MOTCOM: The Multi-Object Tracking Dataset Complexity Metric",
    "abstract": "There exists no comprehensive metric for describing the complexity of\nMulti-Object Tracking (MOT) sequences. This lack of metrics decreases\nexplainability, complicates comparison of datasets, and reduces the\nconversation on tracker performance to a matter of leader board position. As a\nremedy, we present the novel MOT dataset complexity metric (MOTCOM), which is a\ncombination of three sub-metrics inspired by key problems in MOT: occlusion,\nerratic motion, and visual similarity. The insights of MOTCOM can open nuanced\ndiscussions on tracker performance and may lead to a wider acknowledgement of\nnovel contributions developed for either less known datasets or those aimed at\nsolving sub-problems. We evaluate MOTCOM on the comprehensive MOT17, MOT20, and\nMOTSynth datasets and show that MOTCOM is far better at describing the\ncomplexity of MOT sequences compared to the conventional density and number of\ntracks. Project page at https://vap.aau.dk/motcom",
    "descriptor": "\nComments: ECCV 2022. Project webpage this https URL\n",
    "authors": [
      "Malte Pedersen",
      "Joakim Bruslund Haurum",
      "Patrick Dendorfer",
      "Thomas B. Moeslund"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10031"
  },
  {
    "id": "arXiv:2207.10032",
    "title": "Detecting Harmful Online Conversational Content towards LGBTQIA+  Individuals",
    "abstract": "Online discussions, panels, talk page edits, etc., often contain harmful\nconversational content i.e., hate speech, death threats and offensive language,\nespecially towards certain demographic groups. For example, individuals who\nidentify as members of the LGBTQIA+ community and/or BIPOC (Black, Indigenous,\nPeople of Color) are at higher risk for abuse and harassment online. In this\nwork, we first introduce a real-world dataset that will enable us to study and\nunderstand harmful online conversational content. Then, we conduct several\nexploratory data analysis experiments to gain deeper insights from the dataset.\nWe later describe our approach for detecting harmful online Anti-LGBTQIA+\nconversational content, and finally, we implement two baseline machine learning\nmodels (i.e., Support Vector Machine and Logistic Regression), and fine-tune 3\npre-trained large language models (BERT, RoBERTa, and HateBERT). Our findings\nverify that large language models can achieve very promising performance on\ndetecting online Anti-LGBTQIA+ conversational content detection tasks.",
    "descriptor": "\nComments: Accepted to NAACL 2022 Queer in AI Workshop\n",
    "authors": [
      "Jamell Dacon",
      "Harry Shomer",
      "Shaylynn Crum-Dacon",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.10032"
  },
  {
    "id": "arXiv:2207.10035",
    "title": "Fully Sparse 3D Object Detection",
    "abstract": "As the perception range of LiDAR increases, LiDAR-based 3D object detection\nbecomes a dominant task in the long-range perception task of autonomous\ndriving. The mainstream 3D object detectors usually build dense feature maps in\nthe network backbone and prediction head. However, the computational and\nspatial costs on the dense feature map are quadratic to the perception range,\nwhich makes them hardly scale up to the long-range setting. To enable efficient\nlong-range LiDAR-based object detection, we build a fully sparse 3D object\ndetector (FSD). The computational and spatial cost of FSD is roughly linear to\nthe number of points and independent of the perception range. FSD is built upon\nthe general sparse voxel encoder and a novel sparse instance recognition (SIR)\nmodule. SIR first groups the points into instances and then applies\ninstance-wise feature extraction and prediction. In this way, SIR resolves the\nissue of center feature missing, which hinders the design of the fully sparse\narchitecture for all center-based or anchor-based detectors. Moreover, SIR\navoids the time-consuming neighbor queries in previous point-based methods by\ngrouping points into instances. We conduct extensive experiments on the\nlarge-scale Waymo Open Dataset to reveal the working mechanism of FSD, and\nstate-of-the-art performance is reported. To demonstrate the superiority of FSD\nin long-range detection, we also conduct experiments on Argoverse 2 Dataset,\nwhich has a much larger perception range ($200m$) than Waymo Open Dataset\n($75m$). On such a large perception range, FSD achieves state-of-the-art\nperformance and is 2.4$\\times$ faster than the dense counterpart.Codes will be\nreleased at https://github.com/TuSimple/SST.",
    "descriptor": "",
    "authors": [
      "Lue Fan",
      "Feng Wang",
      "Naiyan Wang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10035"
  },
  {
    "id": "arXiv:2207.10047",
    "title": "Densely Constrained Depth Estimator for Monocular 3D Object Detection",
    "abstract": "Estimating accurate 3D locations of objects from monocular images is a\nchallenging problem because of lacking depth. Previous work shows that\nutilizing the object's keypoint projection constraints to estimate multiple\ndepth candidates boosts the detection performance. However, the existing\nmethods can only utilize vertical edges as projection constraints for depth\nestimation. So these methods only use a small number of projection constraints\nand produce insufficient depth candidates, leading to inaccurate depth\nestimation. In this paper, we propose a method that utilizes dense projection\nconstraints from edges of any direction. In this way, we employ much more\nprojection constraints and produce considerable depth candidates. Besides, we\npresent a graph matching weighting module to merge the depth candidates. The\nproposed method DCD (Densely Constrained Detector) achieves state-of-the-art\nperformance on the KITTI and WOD benchmarks. Code is released at\nhttps://github.com/BraveGroup/DCD.",
    "descriptor": "\nComments: Accept by ECCV22\n",
    "authors": [
      "Yingyan Li",
      "Yunchao Chen",
      "Jiawei He",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10047"
  },
  {
    "id": "arXiv:2207.10049",
    "title": "Pretraining a Neural Network before Knowing Its Architecture",
    "abstract": "Training large neural networks is possible by training a smaller hypernetwork\nthat predicts parameters for the large ones. A recently released Graph\nHyperNetwork (GHN) trained this way on one million smaller ImageNet\narchitectures is able to predict parameters for large unseen networks such as\nResNet-50. While networks with predicted parameters lose performance on the\nsource task, the predicted parameters have been found useful for fine-tuning on\nother tasks. We study if fine-tuning based on the same GHN is still useful on\nnovel strong architectures that were published after the GHN had been trained.\nWe found that for recent architectures such as ConvNeXt, GHN initialization\nbecomes less useful than for ResNet-50. One potential reason is the increased\ndistribution shift of novel architectures from those used to train the GHN. We\nalso found that the predicted parameters lack the diversity necessary to\nsuccessfully fine-tune parameters with gradient descent. We alleviate this\nlimitation by applying simple post-processing techniques to predicted\nparameters before fine-tuning them on a target task and improve fine-tuning of\nResNet-50 and ConvNeXt.",
    "descriptor": "\nComments: Accepted at ICML 2022 Workshop on Pre-training: Perspectives, Pitfalls, and Paths Forward, source code is available at this https URL\n",
    "authors": [
      "Boris Knyazev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10049"
  },
  {
    "id": "arXiv:2207.10050",
    "title": "Discriminator-Weighted Offline Imitation Learning from Suboptimal  Demonstrations",
    "abstract": "We study the problem of offline Imitation Learning (IL) where an agent aims\nto learn an optimal expert behavior policy without additional online\nenvironment interactions. Instead, the agent is provided with a supplementary\noffline dataset from suboptimal behaviors. Prior works that address this\nproblem either require that expert data occupies the majority proportion of the\noffline dataset, or need to learn a reward function and perform offline\nreinforcement learning (RL) afterwards. In this paper, we aim to address the\nproblem without additional steps of reward learning and offline RL training for\nthe case when demonstrations contain a large proportion of suboptimal data.\nBuilt upon behavioral cloning (BC), we introduce an additional discriminator to\ndistinguish expert and non-expert data. We propose a cooperation framework to\nboost the learning of both tasks, Based on this framework, we design a new IL\nalgorithm, where the outputs of discriminator serve as the weights of the BC\nloss. Experimental results show that our proposed algorithm achieves higher\nreturns and faster training speed compared to baseline algorithms.",
    "descriptor": "\nComments: ICML 2022, code at this https URL\n",
    "authors": [
      "Haoran Xu",
      "Xianyuan Zhan",
      "Honglei Yin",
      "Huiling Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.10050"
  },
  {
    "id": "arXiv:2207.10053",
    "title": "3D Clothed Human Reconstruction in the Wild",
    "abstract": "Although much progress has been made in 3D clothed human reconstruction, most\nof the existing methods fail to produce robust results from in-the-wild images,\nwhich contain diverse human poses and appearances. This is mainly due to the\nlarge domain gap between training datasets and in-the-wild datasets. The\ntraining datasets are usually synthetic ones, which contain rendered images\nfrom GT 3D scans. However, such datasets contain simple human poses and less\nnatural image appearances compared to those of real in-the-wild datasets, which\nmakes generalization of it to in-the-wild images extremely challenging. To\nresolve this issue, in this work, we propose ClothWild, a 3D clothed human\nreconstruction framework that firstly addresses the robustness on in-thewild\nimages. First, for the robustness to the domain gap, we propose a weakly\nsupervised pipeline that is trainable with 2D supervision targets of\nin-the-wild datasets. Second, we design a DensePose-based loss function to\nreduce ambiguities of the weak supervision. Extensive empirical tests on\nseveral public in-the-wild datasets demonstrate that our proposed ClothWild\nproduces much more accurate and robust results than the state-of-the-art\nmethods. The codes are available in here:\nhttps://github.com/hygenie1228/ClothWild_RELEASE.",
    "descriptor": "\nComments: Accepted to ECCV 2022, 25 pages including the supplementary material\n",
    "authors": [
      "Gyeongsik Moon",
      "Hyeongjin Nam",
      "Takaaki Shiratori",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10053"
  },
  {
    "id": "arXiv:2207.10060",
    "title": "Efficient numerical valuation of European options under the two-asset  Kou jump-diffusion model",
    "abstract": "This paper concerns the numerical solution of the two-dimensional\ntime-dependent partial integro-differential equation (PIDE) that holds for the\nvalues of European-style options under the two-asset Kou jump-diffusion model.\nA main feature of this equation is the presence of a nonlocal double integral\nterm. For its numerical evaluation, we extend a highly efficient algorithm\nderived by Toivanen (2008) in the case of the one-dimensional Kou integral. The\nacquired algorithm for the two-dimensional Kou integral has optimal\ncomputational cost: the number of basic arithmetic operations is directly\nproportional to the number of spatial grid points in the semidiscretization.\nFor the effective discretization in time, we study seven contemporary operator\nsplitting schemes of the implicit-explicit (IMEX) and the alternating direction\nimplicit (ADI) kind. All these schemes allow for a convenient, explicit\ntreatment of the integral term. By ample numerical experiments for\nput-on-the-average option values, the stability and convergence behaviour as\nwell as the mutual performance of the seven operator splitting schemes are\ninvestigated. Moreover, the Greeks Delta and Gamma are considered.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1901.03839\n",
    "authors": [
      "Karel in 't Hout",
      "Pieter Lamotte"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2207.10060"
  },
  {
    "id": "arXiv:2207.10061",
    "title": "Monocular 3D Object Reconstruction with GAN Inversion",
    "abstract": "Recovering a textured 3D mesh from a monocular image is highly challenging,\nparticularly for in-the-wild objects that lack 3D ground truths. In this work,\nwe present MeshInversion, a novel framework to improve the reconstruction by\nexploiting the generative prior of a 3D GAN pre-trained for 3D textured mesh\nsynthesis. Reconstruction is achieved by searching for a latent space in the 3D\nGAN that best resembles the target mesh in accordance with the single view\nobservation. Since the pre-trained GAN encapsulates rich 3D semantics in terms\nof mesh geometry and texture, searching within the GAN manifold thus naturally\nregularizes the realness and fidelity of the reconstruction. Importantly, such\nregularization is directly applied in the 3D space, providing crucial guidance\nof mesh parts that are unobserved in the 2D space. Experiments on standard\nbenchmarks show that our framework obtains faithful 3D reconstructions with\nconsistent geometry and texture across both observed and unobserved parts.\nMoreover, it generalizes well to meshes that are less commonly seen, such as\nthe extended articulation of deformable objects. Code is released at\nhttps://github.com/junzhezhang/mesh-inversion",
    "descriptor": "\nComments: ECCV 2022. Project page: this https URL\n",
    "authors": [
      "Junzhe Zhang",
      "Daxuan Ren",
      "Zhongang Cai",
      "Chai Kiat Yeo",
      "Bo Dai",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10061"
  },
  {
    "id": "arXiv:2207.10062",
    "title": "DataPerf: Benchmarks for Data-Centric AI Development",
    "abstract": "Machine learning (ML) research has generally focused on models, while the\nmost prominent datasets have been employed for everyday ML tasks without regard\nfor the breadth, difficulty, and faithfulness of these datasets to the\nunderlying problem. Neglecting the fundamental importance of datasets has\ncaused major problems involving data cascades in real-world applications and\nsaturation of dataset-driven criteria for model quality, hindering research\ngrowth. To solve this problem, we present DataPerf, a benchmark package for\nevaluating ML datasets and dataset-working algorithms. We intend it to enable\nthe \"data ratchet,\" in which training sets will aid in evaluating test sets on\nthe same problems, and vice versa. Such a feedback-driven strategy will\ngenerate a virtuous loop that will accelerate development of data-centric AI.\nThe MLCommons Association will maintain DataPerf.",
    "descriptor": "",
    "authors": [
      "Mark Mazumder",
      "Colby Banbury",
      "Xiaozhe Yao",
      "Bojan Karla\u0161",
      "William Gaviria Rojas",
      "Sudnya Diamos",
      "Greg Diamos",
      "Lynn He",
      "Douwe Kiela",
      "David Jurado",
      "David Kanter",
      "Rafael Mosquera",
      "Juan Ciro",
      "Lora Aroyo",
      "Bilge Acun",
      "Sabri Eyuboglu",
      "Amirata Ghorbani",
      "Emmett Goodman",
      "Tariq Kane",
      "Christine R. Kirkpatrick",
      "Tzu-Sheng Kuo",
      "Jonas Mueller",
      "Tristan Thrush",
      "Joaquin Vanschoren",
      "Margaret Warren",
      "Adina Williams",
      "Serena Yeung",
      "Newsha Ardalani",
      "Praveen Paritosh",
      "Ce Zhang",
      "James Zou",
      "Carole-Jean Wu",
      "Cody Coleman",
      "Andrew Ng",
      "Peter Mattson",
      "Vijay Janapa Reddi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10062"
  },
  {
    "id": "arXiv:2207.10063",
    "title": "Softening online extremes organically and at scale",
    "abstract": "Calls are escalating for social media platforms to do more to mitigate\nextreme online communities whose views can lead to real-world harms, e.g.,\nmis/disinformation and distrust that increased Covid-19 fatalities, and now\nextend to monkeypox, unsafe baby formula alternatives, cancer, abortions, and\nclimate change; white replacement that inspired the 2022 Buffalo shooter and\nwill likely inspire others; anger that threatens elections, e.g., 2021 U.S.\nCapitol attack; notions of male supremacy that encourage abuse of women;\nanti-Semitism, anti-LGBQT hate and QAnon conspiracies. But should 'doing more'\nmean doing more of the same, or something different? If so, what? Here we start\nby showing why platforms doing more of the same will not solve the problem.\nSpecifically, our analysis of nearly 100 million Facebook users entangled over\nvaccines and now Covid and beyond, shows that the extreme communities' ecology\nhas a hidden resilience to Facebook's removal interventions; that Facebook's\nmessaging interventions are missing key audience sectors and getting ridiculed;\nthat a key piece of these online extremes' narratives is being mislabeled as\nincorrect science; and that the threat of censorship is inciting the creation\nof parallel presences on other platforms with potentially broader audiences. We\nthen demonstrate empirically a new solution that can soften online extremes\norganically without having to censor or remove communities or their content, or\ncheck or correct facts, or promote any preventative messaging, or seek a\nconsensus. This solution can be automated at scale across social media\nplatforms quickly and with minimal cost.",
    "descriptor": "\nComments: Comments welcome to neiljohnson@gwu.edu\n",
    "authors": [
      "Elvira Maria Restrepo",
      "Martin Moreno",
      "Lucia Illari",
      "Neil F. Johnson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10063"
  },
  {
    "id": "arXiv:2207.10074",
    "title": "Semantic uncertainty intervals for disentangled latent spaces",
    "abstract": "Meaningful uncertainty quantification in computer vision requires reasoning\nabout semantic information -- say, the hair color of the person in a photo or\nthe location of a car on the street. To this end, recent breakthroughs in\ngenerative modeling allow us to represent semantic information in disentangled\nlatent spaces, but providing uncertainties on the semantic latent variables has\nremained challenging. In this work, we provide principled uncertainty intervals\nthat are guaranteed to contain the true semantic factors for any underlying\ngenerative model. The method does the following: (1) it uses quantile\nregression to output a heuristic uncertainty interval for each element in the\nlatent space (2) calibrates these uncertainties such that they contain the true\nvalue of the latent for a new, unseen input. The endpoints of these calibrated\nintervals can then be propagated through the generator to produce interpretable\nuncertainty visualizations for each semantic factor. This technique reliably\ncommunicates semantically meaningful, principled, and instance-adaptive\nuncertainty in inverse problems like image super-resolution and image\ncompletion.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Swami Sankaranarayanan",
      "Anastasios N. Angelopoulos",
      "Stephen Bates",
      "Yaniv Romano",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.10074"
  },
  {
    "id": "arXiv:2207.10075",
    "title": "Is an Object-Centric Video Representation Beneficial for Transfer?",
    "abstract": "The objective of this work is to learn an object-centric video\nrepresentation, with the aim of improving transferability to novel tasks, i.e.,\ntasks different from the pre-training task of action classification. To this\nend, we introduce a new object-centric video recognition model based on a\ntransformer architecture. The model learns a set of object-centric summary\nvectors for the video, and uses these vectors to fuse the visual and\nspatio-temporal trajectory `modalities' of the video clip. We also introduce a\nnovel trajectory contrast loss to further enhance objectness in these summary\nvectors. With experiments on four datasets -- SomethingSomething-V2,\nSomethingElse, Action Genome and EpicKitchens -- we show that the\nobject-centric model outperforms prior video representations (both\nobject-agnostic and object-aware), when: (1) classifying actions on unseen\nobjects and unseen environments; (2) low-shot learning to novel classes; (3)\nlinear probe to other downstream tasks; as well as (4) for standard action\nclassification.",
    "descriptor": "",
    "authors": [
      "Chuhan Zhang",
      "Ankush Gupta",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10075"
  },
  {
    "id": "arXiv:2207.10077",
    "title": "Discover and Mitigate Unknown Biases with Debiasing Alternate Networks",
    "abstract": "Deep image classifiers have been found to learn biases from datasets. To\nmitigate the biases, most previous methods require labels of protected\nattributes (e.g., age, skin tone) as full-supervision, which has two\nlimitations: 1) it is infeasible when the labels are unavailable; 2) they are\nincapable of mitigating unknown biases -- biases that humans do not\npreconceive. To resolve those problems, we propose Debiasing Alternate Networks\n(DebiAN), which comprises two networks -- a Discoverer and a Classifier. By\ntraining in an alternate manner, the discoverer tries to find multiple unknown\nbiases of the classifier without any annotations of biases, and the classifier\naims at unlearning the biases identified by the discoverer. While previous\nworks evaluate debiasing results in terms of a single bias, we create\nMulti-Color MNIST dataset to better benchmark mitigation of multiple biases in\na multi-bias setting, which not only reveals the problems in previous methods\nbut also demonstrates the advantage of DebiAN in identifying and mitigating\nmultiple biases simultaneously. We further conduct extensive experiments on\nreal-world datasets, showing that the discoverer in DebiAN can identify unknown\nbiases that may be hard to be found by humans. Regarding debiasing, DebiAN\nachieves strong bias mitigation performance.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Zhiheng Li",
      "Anthony Hoogs",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10077"
  },
  {
    "id": "arXiv:1610.07204",
    "title": "Output-sensitive Complexity of Multiobjective Combinatorial Optimization",
    "abstract": "We study output-sensitive algorithms and complexity for multiobjective\ncombinatorial optimization problems. In this computational complexity\nframework, an algorithm for a general enumeration problem is regarded efficient\nif it is output-sensitive, i.e., its running time is bounded by a polynomial in\nthe input and the output size. We provide both practical examples of MOCO\nproblems for which such an efficient algorithm exists as well as problems for\nwhich no efficient algorithm exists under mild complexity theoretic\nassumptions.",
    "descriptor": "",
    "authors": [
      "Fritz B\u00f6kler",
      "Matthias Ehrgott",
      "Christopher Morris",
      "Petra Mutzel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1610.07204"
  },
  {
    "id": "arXiv:2207.09451",
    "title": "Balancing polynomials, Fibonacci numbers and some new series for $\u03c0$",
    "abstract": "We evaluate some types of infinite series with balancing and Lucas-balancing\npolynomials in closed form. These evaluations will lead to some new curious\nseries for $\\pi$ involving Fibonacci and Lucas numbers. Our findings complement\nthose of Castellanos from 1986 and 1989.",
    "descriptor": "\nComments: 16 pages, 5 tables\n",
    "authors": [
      "Robert Frontczak",
      "Kalika Prasad"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.09451"
  },
  {
    "id": "arXiv:2207.09483",
    "title": "Comparison of automatic prostate zones segmentation models in MRI images  using U-net-like architectures",
    "abstract": "Prostate cancer is the second-most frequently diagnosed cancer and the sixth\nleading cause of cancer death in males worldwide. The main problem that\nspecialists face during the diagnosis of prostate cancer is the localization of\nRegions of Interest (ROI) containing a tumor tissue. Currently, the\nsegmentation of this ROI in most cases is carried out manually by expert\ndoctors, but the procedure is plagued with low detection rates (of about\n27-44%) or overdiagnosis in some patients. Therefore, several research works\nhave tackled the challenge of automatically segmenting and extracting features\nof the ROI from magnetic resonance images, as this process can greatly\nfacilitate many diagnostic and therapeutic applications. However, the lack of\nclear prostate boundaries, the heterogeneity inherent to the prostate tissue,\nand the variety of prostate shapes makes this process very difficult to\nautomate.In this work, six deep learning models were trained and analyzed with\na dataset of MRI images obtained from the Centre Hospitalaire de Dijon and\nUniversitat Politecnica de Catalunya. We carried out a comparison of multiple\ndeep learning models (i.e. U-Net, Attention U-Net, Dense-UNet, Attention\nDense-UNet, R2U-Net, and Attention R2U-Net) using categorical cross-entropy\nloss function. The analysis was performed using three metrics commonly used for\nimage segmentation: Dice score, Jaccard index, and mean squared error. The\nmodel that give us the best result segmenting all the zones was R2U-Net, which\nachieved 0.869, 0.782, and 0.00013 for Dice, Jaccard and mean squared error,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Pablo Cesar Quihui-Rubio",
      "Gilberto Ochoa-Ruiz",
      "Miguel Gonzalez-Mendoza",
      "Gerardo Rodriguez-Hernandez",
      "Christian Mata"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09483"
  },
  {
    "id": "arXiv:2207.09514",
    "title": "ESPnet-SE++: Speech Enhancement for Robust Speech Recognition,  Translation, and Understanding",
    "abstract": "This paper presents recent progress on integrating speech separation and\nenhancement (SSE) into the ESPnet toolkit. Compared with the previous ESPnet-SE\nwork, numerous features have been added, including recent state-of-the-art\nspeech enhancement models with their respective training and evaluation\nrecipes. Importantly, a new interface has been designed to flexibly combine\nspeech enhancement front-ends with other tasks, including automatic speech\nrecognition (ASR), speech translation (ST), and spoken language understanding\n(SLU). To showcase such integration, we performed experiments on carefully\ndesigned synthetic datasets for noisy-reverberant multi-channel ST and SLU\ntasks, which can be used as benchmark corpora for future research. In addition\nto these new tasks, we also use CHiME-4 and WSJ0-2Mix to benchmark multi- and\nsingle-channel SE approaches. Results show that the integration of SE\nfront-ends with back-end tasks is a promising research direction even for tasks\nbesides ASR, especially in the multi-channel scenario. The code is available\nonline at https://github.com/ESPnet/ESPnet. The multi-channel ST and SLU\ndatasets, which are another contribution of this work, are released on\nHuggingFace.",
    "descriptor": "\nComments: To appear in Interspeech 2022\n",
    "authors": [
      "Yen-Ju Lu",
      "Xuankai Chang",
      "Chenda Li",
      "Wangyou Zhang",
      "Samuele Cornell",
      "Zhaoheng Ni",
      "Yoshiki Masuyama",
      "Brian Yan",
      "Robin Scheibler",
      "Zhong-Qiu Wang",
      "Yu Tsao",
      "Yanmin Qian",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.09514"
  },
  {
    "id": "arXiv:2207.09517",
    "title": "LightSolver -- A New Quantum-inspired Solver Cracks the 3-Regular  3-XORSAT Challenge",
    "abstract": "The increasing complexity of required computational tasks alongside the\ninherent limitations in conventional computing calls for disruptive innovation.\nLightSolver devised a new quantum-inspired computing paradigm, which utilizes\nan all-optical platform for solving hard optimization problems. In this work,\nLightSolver introduces its digital simulator and joins the 3-Regular 3-XORSAT\n(3R3X) challenge, which aims to map the best available state-of-the-art\nclassical and quantum solvers. So far, the challenge has resulted in a clear\nexponential barrier in terms of time-to-solution (TTS), preventing the\ninspected platforms from solving problems larger than a few hundred variables.\nLightSolver's simulator is the first to break the exponential barrier,\noutperforming both classical and quantum platforms by several\norders-of-magnitude and extending the maximal problem size to more than 16,000\nvariables.",
    "descriptor": "",
    "authors": [
      "Idan Meirzada",
      "Assaf Kalinski",
      "Dov Furman",
      "Tsafrir Armon",
      "Talya Vaknin",
      "Harel Primack",
      "Chene Tradonsky",
      "Ruti Ben-Shlomi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2207.09517"
  },
  {
    "id": "arXiv:2207.09557",
    "title": "A review on recent advances in scenario aggregation methods for power  system analysis",
    "abstract": "Worldwide commitments to net zero greenhouse emissions have accelerated\ninvestments in renewable energy resources. The requirements for operating and\nplanning power systems are becoming stringent because of the need to take into\naccount the uncertainty associated with renewable generation. Several modeling\nframeworks that consider the inherent uncertainty in the operation and planning\nof the power system have been extensively studied. Stochastic optimization has\nbeen the most popular approach among these frameworks due to its intuitive\nrepresentation, especially when formulated using discrete probabilistic\nscenarios to represent the random variables. Although many scenarios\nrepresenting all possible uncertain operating conditions would be needed to\naccurate evaluate stochastic operation and planning models, the size of the\nscenario set impacts computational complexity, posing a significant tradeoff\nbetween uncertainty detail representation and computational tractability.\nDuring the last decade, a large body of research has focused on developing\nnew scenario aggregation methods to derive reduced scenario sets that show\nproperties similar to the original scenario set while decreasing computational\nburden. This review provides an up-to-date, comprehensive classification and\nanalysis of the literature related to scenario aggregation methods for\naddressing power system optimization problems. First, we present a general\nframework and the aggregation methodologies. Then, the main studies related to\ntemporal and spatial scenario aggregation are described, followed by a\nbibliometric analysis of the main publication sources, authors, and application\nproblems. Finally, we provide a numerical analysis and discuss 16 aggregation\nmethods for the transmission expansion planning problem. Finally,\nrecommendations, opportunities, and conclusions are discussed.",
    "descriptor": "",
    "authors": [
      "Aiusha Sangadiev",
      "Alvaro Gonzalez-Castellanos",
      "David Pozo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09557"
  },
  {
    "id": "arXiv:2207.09560",
    "title": "Holistic Robust Data-Driven Decisions",
    "abstract": "The design of data-driven formulations for machine learning and\ndecision-making with good out-of-sample performance is a key challenge. The\nobservation that good in-sample performance does not guarantee good\nout-of-sample performance is generally known as overfitting. Practical\noverfitting can typically not be attributed to a single cause but instead is\ncaused by several factors all at once. We consider here three overfitting\nsources: (i) statistical error as a result of working with finite sample data,\n(ii) data noise which occurs when the data points are measured only with finite\nprecision, and finally (iii) data misspecification in which a small fraction of\nall data may be wholly corrupted. We argue that although existing data-driven\nformulations may be robust against one of these three sources in isolation they\ndo not provide holistic protection against all overfitting sources\nsimultaneously. We design a novel data-driven formulation which does guarantee\nsuch holistic protection and is furthermore computationally viable. Our\ndistributionally robust optimization formulation can be interpreted as a novel\ncombination of a Kullback-Leibler and Levy-Prokhorov robust optimization\nformulation. Finally, we show how in the context of classification and\nregression problems several popular regularized and robust formulations reduce\nto a particular case of our proposed more general formulation.",
    "descriptor": "",
    "authors": [
      "Amine Bennouna",
      "Bart Van Parys"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09560"
  },
  {
    "id": "arXiv:2207.09582",
    "title": "Segmentation of 3D Dental Images Using Deep Learning",
    "abstract": "3D image segmentation is a recent and crucial step in many medical analysis\nand recognition schemes. In fact, it represents a relevant research subject and\na fundamental challenge due to its importance and influence. This paper\nprovides a multi-phase Deep Learning-based system that hybridizes various\nefficient methods in order to get the best 3D segmentation output. First, to\nreduce the amount of data and accelerate the processing time, the application\nof Decimate compression technique is suggested and justified. We then use a CNN\nmodel to segment dental images into fifteen separated classes. In the end, a\nspecial KNN-based transformation is applied for the purpose of removing\nisolated meshes and of correcting dental forms. Experimentations demonstrate\nthe precision and the robustness of the selected framework applied to 3D dental\nimages within a private clinical benchmark.",
    "descriptor": "",
    "authors": [
      "Omar Boudraa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09582"
  },
  {
    "id": "arXiv:2207.09588",
    "title": "New Auction Algorithms for Path Planning, Network Transport, and  Reinforcement Learning",
    "abstract": "We consider some classical optimization problems in path planning and network\ntransport, and we introduce new auction-based algorithms for their optimal and\nsuboptimal solution. The algorithms are based on mathematical ideas that are\nrelated to competitive bidding by persons for objects and the attendant market\nequilibrium, which underlie auction processes. However, the starting point of\nour algorithms is different, namely weighted and unweighted path construction\nin directed graphs, rather than assignment of persons to objects. The new\nalgorithms have several potential advantages over existing methods: they are\nempirically faster in some important contexts, such as max-flow, they are\nwell-suited for on-line replanning, and they can be adapted to distributed\nasynchronous operation. Moreover, they allow arbitrary initial prices, without\ncomplementary slackness restrictions, and thus are better-suited to take\nadvantage of reinforcement learning methods that use off-line training with\ndata, as well as on-line training during real-time operation. The new\nalgorithms may also find use in reinforcement learning contexts involving\napproximation, such as multistep lookahead and tree search schemes, and/or\nrollout algorithms.",
    "descriptor": "",
    "authors": [
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.09588"
  },
  {
    "id": "arXiv:2207.09665",
    "title": "ExoSGAN and ExoACGAN: Exoplanet Detection using Adversarial Training  Algorithms",
    "abstract": "Exoplanet detection opens the door to the discovery of new habitable worlds\nand helps us understand how planets were formed. With the objective of finding\nearth-like habitable planets, NASA launched Kepler space telescope and its\nfollow up mission K2. The advancement of observation capabilities has increased\nthe range of fresh data available for research, and manually handling them is\nboth time-consuming and difficult. Machine learning and deep learning\ntechniques can greatly assist in lowering human efforts to process the vast\narray of data produced by the modern instruments of these exoplanet programs in\nan economical and unbiased manner. However, care should be taken to detect all\nthe exoplanets precisely while simultaneously minimizing the misclassification\nof non-exoplanet stars. In this paper, we utilize two variations of generative\nadversarial networks, namely semi-supervised generative adversarial networks\nand auxiliary classifier generative adversarial networks, to detect transiting\nexoplanets in K2 data. We find that the usage of these models can be helpful\nfor the classification of stars with exoplanets. Both of our techniques are\nable to categorize the light curves with a recall and precision of 1.00 on the\ntest data. Our semi-supervised technique is beneficial to solve the cumbersome\ntask of creating a labeled dataset.",
    "descriptor": "\nComments: 26 pages total\n",
    "authors": [
      "Cicy K Agnes",
      "Akthar Naveed V",
      "Anitha Mary M O Chacko"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09665"
  },
  {
    "id": "arXiv:2207.09688",
    "title": "Intrinsic dimension estimation for discrete metrics",
    "abstract": "Real world-datasets characterized by discrete features are ubiquitous: from\ncategorical surveys to clinical questionnaires, from unweighted networks to DNA\nsequences. Nevertheless, the most common unsupervised dimensional reduction\nmethods are designed for continuous spaces, and their use for discrete spaces\ncan lead to errors and biases. In this letter we introduce an algorithm to\ninfer the intrinsic dimension (ID) of datasets embedded in discrete spaces. We\ndemonstrate its accuracy on benchmark datasets, and we apply it to analyze a\nmetagenomic dataset for species fingerprinting, finding a surprisingly small\nID, of order 2. This suggests that evolutive pressure acts on a low-dimensional\nmanifold despite the high-dimensionality of sequences' space.",
    "descriptor": "\nComments: RevTeX4.2, 12 pages, 9 figures\n",
    "authors": [
      "Iuri Macocco",
      "Aldo Glielmo",
      "Jacopo Grilli",
      "Alessandro Laio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.09688"
  },
  {
    "id": "arXiv:2207.09732",
    "title": "Introducing Auxiliary Text Query-modifier to Content-based Audio  Retrieval",
    "abstract": "The amount of audio data available on public websites is growing rapidly, and\nan efficient mechanism for accessing the desired data is necessary. We propose\na content-based audio retrieval method that can retrieve a target audio that is\nsimilar to but slightly different from the query audio by introducing auxiliary\ntextual information which describes the difference between the query and target\naudio. While the range of conventional content-based audio retrieval is limited\nto audio that is similar to the query audio, the proposed method can adjust the\nretrieval range by adding an embedding of the auxiliary text query-modifier to\nthe embedding of the query sample audio in a shared latent space. To evaluate\nour method, we built a dataset comprising two different audio clips and the\ntext that describes the difference. The experimental results show that the\nproposed method retrieves the paired audio more accurately than the baseline.\nWe also confirmed based on visualization that the proposed method obtains the\nshared latent space in which the audio difference and the corresponding text\nare represented as similar embedding vectors.",
    "descriptor": "\nComments: Accepted to Interspeech 2022\n",
    "authors": [
      "Daiki Takeuchi",
      "Yasunori Ohishi",
      "Daisuke Niizumi",
      "Noboru Harada",
      "Kunio Kashino"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.09732"
  },
  {
    "id": "arXiv:2207.09733",
    "title": "Direct and Residual Subspace Decomposition of Spatial Room Impulse  Responses",
    "abstract": "Psychoacoustic experiments have shown that directional properties of, in\nparticular, the direct sound, salient reflections, and the late reverberation\nof an acoustic room response can have a distinct influence on the auditory\nperception of a given room. Spatial room impulse responses (SRIRs) capture\nthose properties and thus are used for direction-dependent room acoustic\nanalysis and virtual acoustic rendering. This work proposes a subspace method\nthat decomposes SRIRs into a direct part, which comprises the direct sound and\nthe salient reflections, and a residual, to facilitate enhanced analysis and\nrendering methods by providing individual access to these components. The\nproposed method is based on the generalized singular value decomposition and\ninterprets the residual as noise that is to be separated from the other\ncomponents of the reverberation. It utilizes a noise estimate to identify large\ngeneralized singular values, which are then attributed to the direct part. By\nadvancing from the end of the SRIR toward the beginning while iteratively\nupdating the noise estimate, the method is able to work with anisotropic and\nslowly time-varying reverberant sound fields. The proposed method does not\nrequire direction-of-arrival estimation of reflections and shows an improved\nseparation of the direct part from the residual compared to an existing\napproach. A case study with measured SRIRs suggests a high robustness of the\nmethod under different acoustic conditions. A reference implementation is\nprovided.",
    "descriptor": "\nComments: Submitted to IEEE/ACM Transactions on Audio, Speech, and Language Processing\n",
    "authors": [
      "Thomas Deppisch",
      "Sebasti\u00e0 V. Amengual Gar\u00ed",
      "Paul Calamia",
      "Jens Ahrens"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.09733"
  },
  {
    "id": "arXiv:2207.09734",
    "title": "The Free Energy Principle drives neuromorphic development",
    "abstract": "We show how any system with morphological degrees of freedom and locally\nlimited free energy will, under the constraints of the free energy principle,\nevolve toward a neuromorphic morphology that supports hierarchical computations\nin which each level of the hierarchy enacts a coarse-graining of its inputs,\nand dually a fine-graining of its outputs. Such hierarchies occur throughout\nbiology, from the architectures of intracellular signal transduction pathways\nto the large-scale organization of perception and action cycles in the\nmammalian brain. Formally, the close formal connections between cone-cocone\ndiagrams (CCCD) as models of quantum reference frames on the one hand, and\nbetween CCCDs and topological quantum field theories on the other, allow the\nrepresentation of such computations in the fully-general quantum-computational\nframework of topological quantum neural networks.",
    "descriptor": "",
    "authors": [
      "Chris Fields",
      "Karl Friston",
      "James F. Glazebrook",
      "Michael Levin",
      "Antonino Marcian\u00f2"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2207.09734"
  },
  {
    "id": "arXiv:2207.09740",
    "title": "Interpreting Latent Spaces of Generative Models for Medical Images using  Unsupervised Methods",
    "abstract": "Generative models such as Generative Adversarial Networks (GANs) and\nVariational Autoencoders (VAEs) play an increasingly important role in medical\nimage analysis. The latent spaces of these models often show semantically\nmeaningful directions corresponding to human-interpretable image\ntransformations. However, until now, their exploration for medical images has\nbeen limited due to the requirement of supervised data. Several methods for\nunsupervised discovery of interpretable directions in GAN latent spaces have\nshown interesting results on natural images. This work explores the potential\nof applying these techniques on medical images by training a GAN and a VAE on\nthoracic CT scans and using an unsupervised method to discover interpretable\ndirections in the resulting latent space. We find several directions\ncorresponding to non-trivial image transformations, such as rotation or breast\nsize. Furthermore, the directions show that the generative models capture 3D\nstructure despite being presented only with 2D data. The results show that\nunsupervised methods to discover interpretable directions in GANs generalize to\nVAEs and can be applied to medical images. This opens a wide array of future\nwork using these methods in medical image analysis.",
    "descriptor": "\nComments: Accepted for presentation at DGM4MICCAI 2022\n",
    "authors": [
      "Julian Sch\u00f6n",
      "Raghavendra Selvan",
      "Jens Petersen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09740"
  },
  {
    "id": "arXiv:2207.09747",
    "title": "Towards Transfer Learning of wav2vec 2.0 for Automatic Lyric  Transcription",
    "abstract": "Automatic speech recognition (ASR) has progressed significantly in recent\nyears due to large-scale datasets and the paradigm of self-supervised learning\n(SSL) methods. However, as its counterpart problem in the singing domain,\nautomatic lyric transcription (ALT) suffers from limited data and degraded\nintelligibility of sung lyrics, which has caused it to develop at a slower\npace. To fill in the performance gap between ALT and ASR, we attempt to exploit\nthe similarities between speech and singing. In this work, we propose a\ntransfer-learning-based ALT solution that takes advantage of these similarities\nby adapting wav2vec 2.0, an SSL ASR model, to the singing domain. We maximize\nthe effectiveness of transfer learning by exploring the influence of different\ntransfer starting points. We further enhance the performance by extending the\noriginal CTC model to a hybrid CTC/attention model. Our method surpasses\nprevious approaches by a large margin on various ALT benchmark datasets.\nFurther experiment shows that, with even a tiny proportion of training data,\nour method still achieves competitive performance.",
    "descriptor": "\nComments: Draft accepted by ISMIR 2022\n",
    "authors": [
      "Longshen Ou",
      "Xiangming Gu",
      "Ye Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.09747"
  },
  {
    "id": "arXiv:2207.09751",
    "title": "Contraction Bidimensionality of Geometric Intersection Graphs",
    "abstract": "Given a graph $G$, we define ${\\bf bcg}(G)$ as the minimum $k$ for which $G$\ncan be contracted to the uniformly triangulated grid $\\Gamma_{k}$. A graph\nclass ${\\cal G}$ has the SQG${\\bf C}$ property if every graph $G\\in{\\cal G}$\nhas treewidth $\\mathcal{O}({\\bf bcg}(G)^{c})$ for some $1\\leq c<2$. The\nSQG${\\bf C}$ property is important for algorithm design as it defines the\napplicability horizon of a series of meta-algorithmic results, in the framework\nof bidimensionality theory, related to fast parameterized algorithms,\nkernelization, and approximation schemes. These results apply to a wide family\nof problems, namely problems that are contraction-bidimensional. Our main\ncombinatorial result reveals a wide family of graph classes that satisfy the\nSQG${\\bf C}$ property. This family includes, in particular, bounded-degree\nstring graphs. This considerably extends the applicability of bidimensionality\ntheory for contraction bidimensional problems.",
    "descriptor": "",
    "authors": [
      "Julien Baste",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2207.09751"
  },
  {
    "id": "arXiv:2207.09785",
    "title": "Unsupervised energy disaggregation via convolutional sparse coding",
    "abstract": "In this work, a method for unsupervised energy disaggregation in private\nhouseholds equipped with smart meters is proposed. This method aims to classify\npower consumption as active or passive, granting the ability to report on the\nresidents' activity and presence without direct interaction. This lays the\nfoundation for applications like non-intrusive health monitoring of private\nhomes.\nThe proposed method is based on minimizing a suitable energy functional, for\nwhich the iPALM (inertial proximal alternating linearized minimization)\nalgorithm is employed, demonstrating that various conditions guaranteeing\nconvergence are satisfied.\nIn order to confirm feasibility of the proposed method, experiments on\nsemi-synthetic test data sets and a comparison to existing, supervised methods\nare provided.",
    "descriptor": "\nComments: 9 pages, 2 figures, 3 tables\n",
    "authors": [
      "Christian Aarset",
      "Andreas Habring",
      "Martin Holler",
      "Mario Mitter"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.09785"
  },
  {
    "id": "arXiv:2207.09842",
    "title": "aflow.org: A Web Ecosystem of Databases, Software and Tools",
    "abstract": "To enable materials databases supporting computational and experimental\nresearch, it is critical to develop platforms that both facilitate access to\nthe data and provide the tools used to generate/analyze it - all while\nconsidering the diversity of users' experience levels and usage needs. The\nrecently formulated FAIR principles (Findable, Accessible, Interoperable, and\nReusable) establish a common framework to aid these efforts. This article\ndescribes aflow.org, a web ecosystem developed to provide FAIR - compliant\naccess to the AFLOW databases. Graphical and programmatic retrieval methods are\noffered, ensuring accessibility for all experience levels and data needs.\naflow.org goes beyond data-access by providing applications to important\nfeatures of the AFLOW software, assisting users in their own calculations\nwithout the need to install the entire high-throughput framework. Outreach\ncommitments to provide AFLOW tutorials and materials science education to a\nglobal and diverse audiences will also be presented.",
    "descriptor": "\nComments: 32 pages, 8 figures\n",
    "authors": [
      "Marco Esters",
      "Corey Oses",
      "Simon Divilov",
      "Hagen Eckert",
      "Rico Friedrich",
      "David Hicks",
      "Michael J. Mehl",
      "Frisco Rose",
      "Andriy Smolyanyuk",
      "Arrigo Calzolari",
      "Xiomara Campilongo",
      "Cormac Toher",
      "Stefano Curtarolo"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.09842"
  },
  {
    "id": "arXiv:2207.09874",
    "title": "Stream-based active learning with linear models",
    "abstract": "The proliferation of automated data collection schemes and the advances in\nsensorics are increasing the amount of data we are able to monitor in\nreal-time. However, given the high annotation costs and the time required by\nquality inspections, data is often available in an unlabeled form. This is\nfostering the use of active learning for the development of soft sensors and\npredictive models. In production, instead of performing random inspections to\nobtain product information, labels are collected by evaluating the information\ncontent of the unlabeled data. Several query strategy frameworks for regression\nhave been proposed in the literature but most of the focus has been dedicated\nto the static pool-based scenario. In this work, we propose a new strategy for\nthe stream-based scenario, where instances are sequentially offered to the\nlearner, which must instantaneously decide whether to perform the quality check\nto obtain the label or discard the instance. The approach is inspired by the\noptimal experimental design theory and the iterative aspect of the\ndecision-making process is tackled by setting a threshold on the\ninformativeness of the unlabeled data points. The proposed approach is\nevaluated using numerical simulations and the Tennessee Eastman Process\nsimulator. The results confirm that selecting the examples suggested by the\nproposed algorithm allows for a faster reduction in the prediction error.",
    "descriptor": "",
    "authors": [
      "Davide Cacciarelli",
      "Murat Kulahci",
      "John S\u00f8lve Tyssedal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09874"
  },
  {
    "id": "arXiv:2207.09938",
    "title": "Deep Preconditioners and their application to seismic wavefield  processing",
    "abstract": "Seismic data processing heavily relies on the solution of physics-driven\ninverse problems. In the presence of unfavourable data acquisition conditions\n(e.g., regular or irregular coarse sampling of sources and/or receivers), the\nunderlying inverse problem becomes very ill-posed and prior information is\nrequired to obtain a satisfactory solution. Sparsity-promoting inversion,\ncoupled with fixed-basis sparsifying transforms, represent the go-to approach\nfor many processing tasks due to its simplicity of implementation and proven\nsuccessful application in a variety of acquisition scenarios. Leveraging the\nability of deep neural networks to find compact representations of complex,\nmulti-dimensional vector spaces, we propose to train an AutoEncoder network to\nlearn a direct mapping between the input seismic data and a representative\nlatent manifold. The trained decoder is subsequently used as a nonlinear\npreconditioner for the physics-driven inverse problem at hand. Synthetic and\nfield data are presented for a variety of seismic processing tasks and the\nproposed nonlinear, learned transformations are shown to outperform fixed-basis\ntransforms and convergence faster to the sought solution.",
    "descriptor": "",
    "authors": [
      "Matteo Ravasi"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.09938"
  },
  {
    "id": "arXiv:2207.09944",
    "title": "Probable Domain Generalization via Quantile Risk Minimization",
    "abstract": "Domain generalization (DG) seeks predictors which perform well on unseen test\ndistributions by leveraging labeled training data from multiple related\ndistributions or domains. To achieve this, the standard formulation optimizes\nfor worst-case performance over the set of all possible domains. However, with\nworst-case shifts very unlikely in practice, this generally leads to\noverly-conservative solutions. In fact, a recent study found that no DG\nalgorithm outperformed empirical risk minimization in terms of average\nperformance. In this work, we argue that DG is neither a worst-case problem nor\nan average-case problem, but rather a probabilistic one. To this end, we\npropose a probabilistic framework for DG, which we call Probable Domain\nGeneralization, wherein our key idea is that distribution shifts seen during\ntraining should inform us of probable shifts at test time. To realize this, we\nexplicitly relate training and test domains as draws from the same underlying\nmeta-distribution, and propose a new optimization problem -- Quantile Risk\nMinimization (QRM) -- which requires that predictors generalize with high\nprobability. We then prove that QRM: (i) produces predictors that generalize to\nnew domains with a desired probability, given sufficiently many domains and\nsamples; and (ii) recovers the causal predictor as the desired probability of\ngeneralization approaches one. In our experiments, we introduce a more holistic\nquantile-focused evaluation protocol for DG, and show that our algorithms\noutperform state-of-the-art baselines on real and synthetic data.",
    "descriptor": "",
    "authors": [
      "Cian Eastwood",
      "Alexander Robey",
      "Shashank Singh",
      "Julius von K\u00fcgelgen",
      "Hamed Hassani",
      "George J. Pappas",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09944"
  },
  {
    "id": "arXiv:2207.09947",
    "title": "Fixed Points of Cone Mapping with the Application to Neural Networks",
    "abstract": "We derive conditions for the existence of fixed points of cone mappings\nwithout assuming scalability of functions. Monotonicity and scalability are\noften inseparable in the literature in the context of searching for fixed\npoints of interference mappings. In applications, such mappings are\napproximated by non-negative neural networks. It turns out, however, that the\nprocess of training non-negative networks requires imposing an artificial\nconstraint on the weights of the model. However, in the case of specific\nnon-negative data, it cannot be said that if the mapping is non-negative, it\nhas only non-negative weights. Therefore, we considered the problem of the\nexistence of fixed points for general neural networks, assuming the conditions\nof tangency conditions with respect to specific cones. This does not relax the\nphysical assumptions, because even assuming that the input and output are to be\nnon-negative, the weights can have (small, but) less than zero values. Such\nproperties (often found in papers on the interpretability of weights of neural\nnetworks) lead to the weakening of the assumptions about the monotonicity or\nscalability of the mapping associated with the neural network. To the best of\nour knowledge, this paper is the first to study this phenomenon.",
    "descriptor": "",
    "authors": [
      "Grzegorz Gabor",
      "Krzysztof Rykaczewski"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "General Topology (math.GN)"
    ],
    "url": "https://arxiv.org/abs/2207.09947"
  },
  {
    "id": "arXiv:2207.09951",
    "title": "Deep Reinforcement Learning for Market Making Under a Hawkes  Process-Based Limit Order Book Model",
    "abstract": "The stochastic control problem of optimal market making is among the central\nproblems in quantitative finance. In this paper, a deep reinforcement\nlearning-based controller is trained on a weakly consistent, multivariate\nHawkes process-based limit order book simulator to obtain market making\ncontrols. The proposed approach leverages the advantages of Monte Carlo\nbacktesting and contributes to the line of research on market making under\nweakly consistent limit order book models. The ensuing deep reinforcement\nlearning controller is compared to multiple market making benchmarks, with the\nresults indicating its superior performance with respect to various risk-reward\nmetrics, even under significant transaction costs.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Bruno Ga\u0161perov",
      "Zvonko Kostanj\u010dar"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2207.09951"
  },
  {
    "id": "arXiv:2207.09959",
    "title": "Exploration of Parameter Spaces Assisted by Machine Learning",
    "abstract": "We showcase a variety of functions and classes that implement sampling\nprocedures with improved exploration of the parameter space assisted by machine\nlearning. Special attention is paid to setting sane defaults with the objective\nthat adjustments required by different problems remain minimal. This collection\nof routines can be employed for different types of analysis, from finding\nbounds on the parameter space to accumulating samples in areas of interest. In\nparticular, we discuss two methods assisted by incorporating different machine\nlearning models: regression and classification. We show that a machine learning\nclassifier can provide higher efficiency for exploring the parameter space.\nAlso, we introduce a boosting technique to improve the slow convergence at the\nstart of the process. The use of these routines is better explained with the\nhelp of a few examples that illustrate the type of results one can obtain. We\nalso include examples of the code used to obtain the examples as well as\ndescriptions of the adjustments that can be made to adapt the calculation to\nother problems. We finalize by showing the impact of these techniques when\nexploring the parameter space of the two Higgs doublet model that matches the\nmeasured Higgs Boson signal strength. The code used for this paper and\ninstructions on how to use it are available on the web.",
    "descriptor": "\nComments: 15 pages, 5 figures. Code and instructions are available on this https URL\n",
    "authors": [
      "A. Hammad",
      "Myeonghun Park",
      "Raymundo Ramos",
      "Pankaj Saha"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09959"
  },
  {
    "id": "arXiv:2207.09960",
    "title": "Measuring and signing fairness as performance under multiple stakeholder  distributions",
    "abstract": "As learning machines increase their influence on decisions concerning human\nlives, analyzing their fairness properties becomes a subject of central\nimportance. Yet, our best tools for measuring the fairness of learning systems\nare rigid fairness metrics encapsulated as mathematical one-liners, offer\nlimited power to the stakeholders involved in the prediction task, and are easy\nto manipulate when we exhort excessive pressure to optimize them. To advance\nthese issues, we propose to shift focus from shaping fairness metrics to\ncurating the distributions of examples under which these are computed. In\nparticular, we posit that every claim about fairness should be immediately\nfollowed by the tagline \"Fair under what examples, and collected by whom?\". By\nhighlighting connections to the literature in domain generalization, we propose\nto measure fairness as the ability of the system to generalize under multiple\nstress tests -- distributions of examples with social relevance. We encourage\neach stakeholder to curate one or multiple stress tests containing examples\nreflecting their (possibly conflicting) interests. The machine passes or fails\neach stress test by falling short of or exceeding a pre-defined metric value.\nThe test results involve all stakeholders in a discussion about how to improve\nthe learning system, and provide flexible assessments of fairness dependent on\ncontext and based on interpretable data. We provide full implementation\nguidelines for stress testing, illustrate both the benefits and shortcomings of\nthis framework, and introduce a cryptographic scheme to enable a degree of\nprediction accountability from system providers.",
    "descriptor": "",
    "authors": [
      "David Lopez-Paz",
      "Diane Bouchacourt",
      "Levent Sagun",
      "Nicolas Usunier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09960"
  },
  {
    "id": "arXiv:2207.09971",
    "title": "NeuralNEB -- Neural Networks can find Reaction Paths Fast",
    "abstract": "Machine Learning (ML) models have, in contrast to their usefulness in\nmolecular dynamics studies, had limited success as surrogate potentials for\nreaction barrier search. It is due to the scarcity of training data in relevant\ntransition state regions of chemical space. Currently, available datasets for\ntraining ML models on small molecular systems almost exclusively contain\nconfigurations at or near equilibrium. In this work, we present the dataset\nTransition1x containing 9.6 million Density Functional Theory (DFT)\ncalculations of forces and energies of molecular configurations on and around\nreaction pathways at the wB97x/6-31G(d) level of theory. The data was generated\nby running Nudged Elastic Band (NEB) calculations with DFT on 10k reactions\nwhile saving intermediate calculations. We train state-of-the-art equivariant\ngraph message-passing neural network models on Transition1x and cross-validate\non the popular ANI1x and QM9 datasets. We show that ML models cannot learn\nfeatures in transition-state regions solely by training on hitherto popular\nbenchmark datasets. Transition1x is a new challenging benchmark that will\nprovide an important step towards developing next-generation ML force fields\nthat also work far away from equilibrium configurations and reactive systems.",
    "descriptor": "",
    "authors": [
      "Mathias Schreiner",
      "Arghya Bhowmik",
      "Tejs Vegge",
      "Ole Winther"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.09971"
  },
  {
    "id": "arXiv:2207.09972",
    "title": "Improved mixing for the convex polygon triangulation flip walk",
    "abstract": "We prove that the well-studied triangulation flip walk on a convex point set\nmixes in time $O(n^{4.75}),$ the first progress since McShine and Tetali's\n$O(n^5 \\log n)$ bound in 1997. In the process we determine the expansion of the\nassociahedron graph $K_n$ up to a factor of $O(n^{3/4})$. To obtain these\nresults, we extend a framework we developed in a previous preprint--extending\nthe projection-restriction technique of Jerrum, Son, Tetali, and Vigoda--for\nestablishing conditions under which the Glauber dynamics on independent sets\nand other combinatorial structures mix rapidly.",
    "descriptor": "\nComments: 47 pages, 8 figures\n",
    "authors": [
      "David Eppstein",
      "Daniel Frishberg"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2207.09972"
  },
  {
    "id": "arXiv:2207.09998",
    "title": "Short-Depth Circuits for Dicke State Preparation",
    "abstract": "We present short-depth circuits to deterministically prepare any Dicke state\n|Dn,k>, which is the equal-amplitude superposition of all n-qubit computational\nbasis states with Hamming Weight k. Dicke states are an important class of\nentangled quantum states with a large variety of applications, and a long\nhistory of experimental creation in physical systems. On the other hand, not\nmuch is known regarding efficient scalable quantum circuits for Dicke state\npreparation on realistic quantum computing hardware connectivities.\nHere we present preparation circuits for Dicke states |Dn,k> with (i) a depth\nof O(k log(n/k)) for All-to-All connectivity (such as on current ion trap\ndevices); (ii) a depth of O(k sqrt(n/k)) = O(sqrt(nk) for Grid connectivity on\ngrids of size Omega(sqrt(n/s)) x O(sqrt(ns)) with s<=k (such as on current\nsuperconducting qubit devices).\nBoth approaches have a total gate count of O(kn), need no ancilla qubits, and\ngeneralize to both the preparation and compression of symmetric pure states in\nwhich all non-zero amplitudes correspond to states with Hamming weight at most\nk. Thus our work significantly improves and expands previous state-of-the art\ncircuits which had depth O(n) on a Linear Nearest Neighbor connectivity for\narbitrary k (Fundamentals of Computation Theory 2019) and depth O(log n) on\nAll-to-All connectivity for k=1 (Advanced Quantum Technologies 2019).",
    "descriptor": "\nComments: IEEE International Conference on Quantum Computing and Engineering, QCE'22, to appear, 2022\n",
    "authors": [
      "Andreas B\u00e4rtschi",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.09998"
  },
  {
    "id": "arXiv:2207.10040",
    "title": "Single Frame Atmospheric Turbulence Mitigation: A Benchmark Study and A  New Physics-Inspired Transformer Model",
    "abstract": "Image restoration algorithms for atmospheric turbulence are known to be much\nmore challenging to design than traditional ones such as blur or noise because\nthe distortion caused by the turbulence is an entanglement of spatially varying\nblur, geometric distortion, and sensor noise. Existing CNN-based restoration\nmethods built upon convolutional kernels with static weights are insufficient\nto handle the spatially dynamical atmospheric turbulence effect. To address\nthis problem, in this paper, we propose a physics-inspired transformer model\nfor imaging through atmospheric turbulence. The proposed network utilizes the\npower of transformer blocks to jointly extract a dynamical turbulence\ndistortion map and restore a turbulence-free image. In addition, recognizing\nthe lack of a comprehensive dataset, we collect and present two new real-world\nturbulence datasets that allow for evaluation with both classical objective\nmetrics (e.g., PSNR and SSIM) and a new task-driven metric using text\nrecognition accuracy. Both real testing sets and all related code will be made\npublicly available.",
    "descriptor": "\nComments: This paper is accepted as a poster at ECCV 2022\n",
    "authors": [
      "Zhiyuan Mao",
      "Ajay Jaiswal",
      "Zhangyang Wang",
      "Stanley H. Chan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10040"
  },
  {
    "id": "arXiv:2207.10046",
    "title": "Adaptive Step-Size Methods for Compressed SGD",
    "abstract": "Compressed Stochastic Gradient Descent (SGD) algorithms have been recently\nproposed to address the communication bottleneck in distributed and\ndecentralized optimization problems, such as those that arise in federated\nmachine learning. Existing compressed SGD algorithms assume the use of\nnon-adaptive step-sizes(constant or diminishing) to provide theoretical\nconvergence guarantees. Typically, the step-sizes are fine-tuned in practice to\nthe dataset and the learning algorithm to provide good empirical performance.\nSuch fine-tuning might be impractical in many learning scenarios, and it is\ntherefore of interest to study compressed SGD using adaptive step-sizes.\nMotivated by prior work on adaptive step-size methods for SGD to train neural\nnetworks efficiently in the uncompressed setting, we develop an adaptive\nstep-size method for compressed SGD. In particular, we introduce a scaling\ntechnique for the descent step in compressed SGD, which we use to establish\norder-optimal convergence rates for convex-smooth and strong convex-smooth\nobjectives under an interpolation condition and for non-convex objectives under\na strong growth condition. We also show through simulation examples that\nwithout this scaling, the algorithm can fail to converge. We present\nexperimental results on deep neural networks for real-world datasets, and\ncompare the performance of our proposed algorithm with previously proposed\ncompressed SGD methods in literature, and demonstrate improved performance on\nResNet-18, ResNet-34 and DenseNet architectures for CIFAR-100 and CIFAR-10\ndatasets at various levels of compression.",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "Adarsh M. Subramaniam",
      "Akshayaa Magesh",
      "Venugopal V. Veeravalli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10046"
  },
  {
    "id": "arXiv:2207.10071",
    "title": "DDPG based on multi-scale strokes for financial time series trading  strategy",
    "abstract": "With the development of artificial intelligence,more and more financial\npractitioners apply deep reinforcement learning to financial trading\nstrategies.However,It is difficult to extract accurate features due to the\ncharacteristics of considerable noise,highly non-stationary,and non-linearity\nof single-scale time series,which makes it hard to obtain high returns.In this\npaper,we extract a multi-scale feature matrix on multiple time scales of\nfinancial time series,according to the classic financial theory-Chan Theory,and\nput forward to an approach of multi-scale stroke deep deterministic policy\ngradient reinforcement learning model(MSSDDPG)to search for the optimal trading\nstrategy.We carried out experiments on the datasets of the Dow Jones,S&P 500 of\nU.S. stocks, and China's CSI 300,SSE Composite,evaluate the performance of our\napproach compared with turtle trading strategy, Deep\nQ-learning(DQN)reinforcement learning strategy,and deep deterministic policy\ngradient (DDPG) reinforcement learning strategy.The result shows that our\napproach gets the best performance in China CSI 300,SSE Composite,and get an\noutstanding result in Dow Jones,S&P 500 of U.S.",
    "descriptor": "\nComments: 10 pages,5 figures,to be published in 2022 8th International Conference on Computer Technology Applications conference\n",
    "authors": [
      "Jun-Cheng Chen",
      "Cong-Xiao Chen",
      "Li-Juan Duan",
      "Zhi Cai"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10071"
  },
  {
    "id": "arXiv:1712.07223",
    "title": "Assessing the Performance of Leja and Clenshaw-Curtis Collocation for  Computational Electromagnetics with Random Input Data",
    "abstract": "Comments: 29 pages, 13 figures, 2 tables",
    "descriptor": "\nComments: 29 pages, 13 figures, 2 tables\n",
    "authors": [
      "Dimitrios Loukrezis",
      "Ulrich R\u00f6mer",
      "Herbert De Gersem"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/1712.07223"
  },
  {
    "id": "arXiv:1805.03765",
    "title": "Near Optimal Linear Algebra in the Online and Sliding Window Models",
    "abstract": "Near Optimal Linear Algebra in the Online and Sliding Window Models",
    "descriptor": "",
    "authors": [
      "Vladimir Braverman",
      "Petros Drineas",
      "Cameron Musco",
      "Christopher Musco",
      "Jalaj Upadhyay",
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1805.03765"
  },
  {
    "id": "arXiv:1912.08805",
    "title": "Pseudospectral Shattering, the Sign Function, and Diagonalization in  Nearly Matrix Multiplication Time",
    "abstract": "Comments: 84 pages, 3 figures, comments welcome. Slightly edited intro from first version + explicit statement of forward error Theorem (Corolary 1.7). Minor corrections, new references and clarifications. Appendix with some new proofs added",
    "descriptor": "\nComments: 84 pages, 3 figures, comments welcome. Slightly edited intro from first version + explicit statement of forward error Theorem (Corolary 1.7). Minor corrections, new references and clarifications. Appendix with some new proofs added\n",
    "authors": [
      "Jess Banks",
      "Jorge Garza-Vargas",
      "Archit Kulkarni",
      "Nikhil Srivastava"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Functional Analysis (math.FA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1912.08805"
  },
  {
    "id": "arXiv:1912.10867",
    "title": "Analysis of the hands in egocentric vision: A survey",
    "abstract": "Analysis of the hands in egocentric vision: A survey",
    "descriptor": "",
    "authors": [
      "Andrea Bandini",
      "Jos\u00e9 Zariffa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1912.10867"
  },
  {
    "id": "arXiv:2002.00792",
    "title": "Generative and discriminative training of Boltzmann machine through  Quantum annealing",
    "abstract": "Generative and discriminative training of Boltzmann machine through  Quantum annealing",
    "descriptor": "",
    "authors": [
      "Siddhartha Srivastava",
      "Veera Sundararaghavan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.00792"
  },
  {
    "id": "arXiv:2006.05630",
    "title": "Distributionally Robust Batch Contextual Bandits",
    "abstract": "Comments: The short version has been accepted in ICML 2020",
    "descriptor": "\nComments: The short version has been accepted in ICML 2020\n",
    "authors": [
      "Nian Si",
      "Fan Zhang",
      "Zhengyuan Zhou",
      "Jose Blanchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05630"
  },
  {
    "id": "arXiv:2007.08069",
    "title": "Maximizing coverage while ensuring fairness: a tale of conflicting  objective",
    "abstract": "Comments: Revised version, under submission to journal",
    "descriptor": "\nComments: Revised version, under submission to journal\n",
    "authors": [
      "Abolfazl Asudeh",
      "Tanya Berger-Wolf",
      "Bhaskar DasGupta",
      "Anastasios Sidiropoulos"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2007.08069"
  },
  {
    "id": "arXiv:2008.08628",
    "title": "On Connections Between Association Schemes and Analyses of Polyhedral  and Positive Semidefinite Lift-and-Project Relaxations",
    "abstract": "On Connections Between Association Schemes and Analyses of Polyhedral  and Positive Semidefinite Lift-and-Project Relaxations",
    "descriptor": "",
    "authors": [
      "Yu Hin Au",
      "Nathan Lindzey",
      "Levent Tun\u00e7el"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2008.08628"
  },
  {
    "id": "arXiv:2010.13062",
    "title": "Transgender Community Sentiment Analysis from Social Media Data: A  Natural Language Processing Approach",
    "abstract": "Comments: 5 pages, 1 figures",
    "descriptor": "\nComments: 5 pages, 1 figures\n",
    "authors": [
      "Yuqiao Liu",
      "Yudan Wang",
      "Ying Zhao",
      "Zhixiang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.13062"
  },
  {
    "id": "arXiv:2011.07442",
    "title": "Speech Enhancement Guided by Contextual Articulatory Information",
    "abstract": "Comments: submitted to TASLP",
    "descriptor": "\nComments: submitted to TASLP\n",
    "authors": [
      "Yen-Ju Lu",
      "Chia-Yu Chang",
      "Cheng Yu",
      "Ching-Feng Liu",
      "Jeih-weih Hung",
      "Shinji Watanabe",
      "Yu Tsao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2011.07442"
  },
  {
    "id": "arXiv:2011.10698",
    "title": "Backdoor Attacks on the DNN Interpretation System",
    "abstract": "Comments: Published at the 2022 AAAI Conference on Artificial Intelligence (AAAI), 2022",
    "descriptor": "\nComments: Published at the 2022 AAAI Conference on Artificial Intelligence (AAAI), 2022\n",
    "authors": [
      "Shihong Fang",
      "Anna Choromanska"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.10698"
  },
  {
    "id": "arXiv:2012.04087",
    "title": "Invertibility Conditions for the Admittance Matrices of Balanced Power  Systems",
    "abstract": "Comments: 12 pages, 4 figures, 1 table, submitted to IEEE Transactions on Power Systems",
    "descriptor": "\nComments: 12 pages, 4 figures, 1 table, submitted to IEEE Transactions on Power Systems\n",
    "authors": [
      "Daniel Turizo",
      "Daniel K. Molzahn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.04087"
  },
  {
    "id": "arXiv:2012.04263",
    "title": "Towards Accurate Active Camera Localization",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Qihang Fang",
      "Yingda Yin",
      "Qingnan Fan",
      "Fei Xia",
      "Siyan Dong",
      "Sheng Wang",
      "Jue Wang",
      "Leonidas Guibas",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.04263"
  },
  {
    "id": "arXiv:2012.07065",
    "title": "LSCALE: Latent Space Clustering-Based Active Learning for Node  Classification",
    "abstract": "Comments: ECML-PKDD 2022",
    "descriptor": "\nComments: ECML-PKDD 2022\n",
    "authors": [
      "Juncheng Liu",
      "Yiwei Wang",
      "Bryan Hooi",
      "Renchi Yang",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2012.07065"
  },
  {
    "id": "arXiv:2102.00311",
    "title": "Fairness through Social Welfare Optimization",
    "abstract": "Comments: 23 pages, 3 figures",
    "descriptor": "\nComments: 23 pages, 3 figures\n",
    "authors": [
      "Violet Xinying Chen",
      "J.N. Hooker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.00311"
  },
  {
    "id": "arXiv:2102.12369",
    "title": "Neural content-aware collaborative filtering for cold-start music  recommendation",
    "abstract": "Neural content-aware collaborative filtering for cold-start music  recommendation",
    "descriptor": "",
    "authors": [
      "Paul Magron",
      "C\u00e9dric F\u00e9votte"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2102.12369"
  },
  {
    "id": "arXiv:2103.14373",
    "title": "D2C-SR: A Divergence to Convergence Approach for Real-World Image  Super-Resolution",
    "abstract": "Comments: 14 pages, 12 figures",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Youwei Li",
      "Haibin Huang",
      "Lanpeng Jia",
      "Haoqiang Fan",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14373"
  },
  {
    "id": "arXiv:2103.16554",
    "title": "Pre-training strategies and datasets for facial representation learning",
    "abstract": "Comments: Accepted at ECCV 2022",
    "descriptor": "\nComments: Accepted at ECCV 2022\n",
    "authors": [
      "Adrian Bulat",
      "Shiyang Cheng",
      "Jing Yang",
      "Andrew Garbett",
      "Enrique Sanchez",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.16554"
  },
  {
    "id": "arXiv:2104.02618",
    "title": "Subjective Assessment Experiments That Recruit Few Observers With  Repetitions (FOWR)",
    "abstract": "Comments: IEEE Transactions on Multimedia",
    "descriptor": "\nComments: IEEE Transactions on Multimedia\n",
    "authors": [
      "Pablo Perez",
      "Lucjan Janowski",
      "Narciso Garcia",
      "Margaret Pinson"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2104.02618"
  },
  {
    "id": "arXiv:2104.14767",
    "title": "TREND: Truncated Generalized Normal Density Estimation of Inception  Embeddings for GAN Evaluation",
    "abstract": "Comments: Accepted in ECCV 2022",
    "descriptor": "\nComments: Accepted in ECCV 2022\n",
    "authors": [
      "Junghyuk Lee",
      "Jong-Seok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14767"
  },
  {
    "id": "arXiv:2105.07743",
    "title": "Universal Regular Conditional Distributions",
    "abstract": "Comments: Regular Conditional Distributions, Geometric Deep Learning, Computational Optimal Transport, Measure-Valued Neural Networks, Universal Approximation, Transformers",
    "descriptor": "\nComments: Regular Conditional Distributions, Geometric Deep Learning, Computational Optimal Transport, Measure-Valued Neural Networks, Universal Approximation, Transformers\n",
    "authors": [
      "Anastasis Kratsios"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Metric Geometry (math.MG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.07743"
  },
  {
    "id": "arXiv:2105.13940",
    "title": "Differentiable Artificial Reverberation",
    "abstract": "Comments: Accepted to TASLP",
    "descriptor": "\nComments: Accepted to TASLP\n",
    "authors": [
      "Sungho Lee",
      "Hyeong-Seok Choi",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.13940"
  },
  {
    "id": "arXiv:2106.04703",
    "title": "Categorical Data Structures for Technical Computing",
    "abstract": "Comments: 27 pages, 7 figures",
    "descriptor": "\nComments: 27 pages, 7 figures\n",
    "authors": [
      "Evan Patterson",
      "Owen Lynch",
      "James Fairbanks"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.04703"
  },
  {
    "id": "arXiv:2106.05587",
    "title": "A Discontinuity Capturing Shallow Neural Network for Elliptic Interface  Problems",
    "abstract": "A Discontinuity Capturing Shallow Neural Network for Elliptic Interface  Problems",
    "descriptor": "",
    "authors": [
      "Wei-Fan Hu",
      "Te-Sheng Lin",
      "Ming-Chih Lai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05587"
  },
  {
    "id": "arXiv:2106.06380",
    "title": "Finite volume schemes and Lax-Wendroff consistency",
    "abstract": "Finite volume schemes and Lax-Wendroff consistency",
    "descriptor": "",
    "authors": [
      "R Eymard",
      "T Gallou\u00ebt",
      "R Herbin",
      "J.-C Latch\u00e9"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.06380"
  },
  {
    "id": "arXiv:2106.09703",
    "title": "MaCLR: Motion-aware Contrastive Learning of Representations for Videos",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Fanyi Xiao",
      "Joseph Tighe",
      "Davide Modolo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09703"
  },
  {
    "id": "arXiv:2106.10558",
    "title": "Rayleigh-Gauss-Newton optimization with enhanced sampling for  variational Monte Carlo",
    "abstract": "Comments: 12 pages, 8 figures",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Robert J. Webber",
      "Michael Lindsey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.10558"
  },
  {
    "id": "arXiv:2107.03234",
    "title": "Quadratic and Higher-Order Unconstrained Binary Optimization of Railway  Rescheduling for Quantum Computing",
    "abstract": "Quadratic and Higher-Order Unconstrained Binary Optimization of Railway  Rescheduling for Quantum Computing",
    "descriptor": "",
    "authors": [
      "Krzysztof Domino",
      "Akash Kundu",
      "\u00d6zlem Salehi",
      "Krzysztof Krawiec"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.03234"
  },
  {
    "id": "arXiv:2107.05515",
    "title": "Mathematical Analysis of Redistricting in Utah",
    "abstract": "Comments: 27 pages, 6. figures, submitted to \"Statistics and Public Policy\"",
    "descriptor": "\nComments: 27 pages, 6. figures, submitted to \"Statistics and Public Policy\"\n",
    "authors": [
      "Annika King",
      "Jacob Murri",
      "Jake Callahan",
      "Adrienne Russell",
      "Tyler J. Jarvis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.05515"
  },
  {
    "id": "arXiv:2107.12096",
    "title": "Towards Unbiased Visual Emotion Recognition via Causal Intervention",
    "abstract": "Comments: Accepted to ACM Multimedia 2022, code is available at this https URL",
    "descriptor": "\nComments: Accepted to ACM Multimedia 2022, code is available at this https URL\n",
    "authors": [
      "Yuedong Chen",
      "Xu Yang",
      "Tat-Jen Cham",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.12096"
  },
  {
    "id": "arXiv:2108.08908",
    "title": "Entropy-Preserving and Entropy-Stable Relaxation IMEX and Multirate  Time-Stepping Methods",
    "abstract": "Comments: 37 pages, 16 figures, 4 tables",
    "descriptor": "\nComments: 37 pages, 16 figures, 4 tables\n",
    "authors": [
      "Shinhoo Kang",
      "Emil M. Constantinescu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2108.08908"
  },
  {
    "id": "arXiv:2109.02353",
    "title": "Reconfigurable Intelligent Surface Empowered Over-the-Air Federated Edge  Learning",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Hang Liu",
      "Zehong Lin",
      "Xiaojun Yuan",
      "Ying-Jun Angela Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.02353"
  },
  {
    "id": "arXiv:2109.05698",
    "title": "Detecting Textual Adversarial Examples through Randomized Substitution  and Vote",
    "abstract": "Comments: Accepted by UAI 2022, code is avaliable at this https URL",
    "descriptor": "\nComments: Accepted by UAI 2022, code is avaliable at this https URL\n",
    "authors": [
      "Xiaosen Wang",
      "Yifeng Xiong",
      "Kun He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05698"
  },
  {
    "id": "arXiv:2109.07764",
    "title": "Meeting-Merging-Mission: A Multi-robot Coordinate Framework for  Large-Scale Communication-Limited Exploration",
    "abstract": "Meeting-Merging-Mission: A Multi-robot Coordinate Framework for  Large-Scale Communication-Limited Exploration",
    "descriptor": "",
    "authors": [
      "Yuman Gao",
      "Yingjian Wang",
      "Xingguang Zhong",
      "Tiankai Yang",
      "Mingyang Wang",
      "Zhixiong Xu",
      "Yongchao Wang",
      "Chao Xu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07764"
  },
  {
    "id": "arXiv:2109.08685",
    "title": "Self-supervised learning methods and applications in medical imaging  analysis: A survey",
    "abstract": "Self-supervised learning methods and applications in medical imaging  analysis: A survey",
    "descriptor": "",
    "authors": [
      "Saeed Shurrab",
      "Rehab Duwairi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08685"
  },
  {
    "id": "arXiv:2109.09367",
    "title": "Network Clustering by Embedding of Attribute-augmented Graphs",
    "abstract": "Comments: 31 pages, 12 figures, preprint",
    "descriptor": "\nComments: 31 pages, 12 figures, preprint\n",
    "authors": [
      "Pasqua D'Ambra",
      "Panayot S. Vassilevski",
      "Luisa Cutillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2109.09367"
  },
  {
    "id": "arXiv:2109.10447",
    "title": "Adding Negation to Lambda Mu",
    "abstract": "Comments: 37 pages",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Steffen van Bakel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.10447"
  },
  {
    "id": "arXiv:2110.00201",
    "title": "Error-free approximation of explicit linear MPC through lattice  piecewise affine expression",
    "abstract": "Error-free approximation of explicit linear MPC through lattice  piecewise affine expression",
    "descriptor": "",
    "authors": [
      "Jun Xu",
      "Yunjiang Lou",
      "Bart De Schutter",
      "Zhenhua Xiong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.00201"
  },
  {
    "id": "arXiv:2110.01216",
    "title": "Passivity-Based Decentralized Criteria for Small-Signal Stability of  Power Systems with Converter-Interfaced Generation",
    "abstract": "Passivity-Based Decentralized Criteria for Small-Signal Stability of  Power Systems with Converter-Interfaced Generation",
    "descriptor": "",
    "authors": [
      "Kaustav Dey",
      "Anil Kulkarni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.01216"
  },
  {
    "id": "arXiv:2110.01593",
    "title": "Generalized Kernel Thinning",
    "abstract": "Comments: Published in ICLR 2022",
    "descriptor": "\nComments: Published in ICLR 2022\n",
    "authors": [
      "Raaz Dwivedi",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.01593"
  },
  {
    "id": "arXiv:2110.04079",
    "title": "A Hybrid Spatial-temporal Deep Learning Architecture for Lane Detection",
    "abstract": "Comments: 18 pages, 5 figures. Published by Computer-Aided Civil and Infrastructure Engineering (CACIE). Open access from this https URL",
    "descriptor": "\nComments: 18 pages, 5 figures. Published by Computer-Aided Civil and Infrastructure Engineering (CACIE). Open access from this https URL\n",
    "authors": [
      "Yongqi Dong",
      "Sandeep Patil",
      "Bart van Arem",
      "Haneen Farah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.04079"
  },
  {
    "id": "arXiv:2110.06160",
    "title": "Method to Build Equivalent Models of Microgrids for RMS Dynamic  Simulation of Power Systems",
    "abstract": "Comments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada",
    "descriptor": "\nComments: In proceedings of the 11th Bulk Power Systems Dynamics and Control Symposium (IREP 2022), July 25-30, 2022, Banff, Canada\n",
    "authors": [
      "Rodrigo A. Ramos",
      "Ahda P. Grilo-Pavani",
      "Artur B. Piardi",
      "Tatiane C. C. Fernandes"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.06160"
  },
  {
    "id": "arXiv:2110.06206",
    "title": "StARformer: Transformer with State-Action-Reward Representations for  Visual Reinforcement Learning",
    "abstract": "Comments: Accepted to ECCV 2022. Our code is available at this https URL",
    "descriptor": "\nComments: Accepted to ECCV 2022. Our code is available at this https URL\n",
    "authors": [
      "Jinghuan Shang",
      "Kumara Kahatapitiya",
      "Xiang Li",
      "Michael S. Ryoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06206"
  },
  {
    "id": "arXiv:2110.06890",
    "title": "Extending Environments To Measure Self-Reflection In Reinforcement  Learning",
    "abstract": "Comments: 24 pages, 2 figures, 1 table, 2 listings",
    "descriptor": "\nComments: 24 pages, 2 figures, 1 table, 2 listings\n",
    "authors": [
      "Samuel Allen Alexander",
      "Michael Castaneda",
      "Kevin Compher",
      "Oscar Martinez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06890"
  },
  {
    "id": "arXiv:2110.08352",
    "title": "Omni-sparsity DNN: Fast Sparsity Optimization for On-Device Streaming  E2E ASR via Supernet",
    "abstract": "Omni-sparsity DNN: Fast Sparsity Optimization for On-Device Streaming  E2E ASR via Supernet",
    "descriptor": "",
    "authors": [
      "Haichuan Yang",
      "Yuan Shangguan",
      "Dilin Wang",
      "Meng Li",
      "Pierce Chuang",
      "Xiaohui Zhang",
      "Ganesh Venkatesh",
      "Ozlem Kalinli",
      "Vikas Chandra"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.08352"
  },
  {
    "id": "arXiv:2110.10077",
    "title": "Deep Learning to Estimate Permeability using Geophysical Data",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "M. K. Mudunuru",
      "E. L. D. Cromwell",
      "H. Wang",
      "X. Chen"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10077"
  },
  {
    "id": "arXiv:2111.01374",
    "title": "A Game of Primes",
    "abstract": "A Game of Primes",
    "descriptor": "",
    "authors": [
      "Raghavendra Bhat"
    ],
    "subjectives": [
      "General Mathematics (math.GM)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.01374"
  },
  {
    "id": "arXiv:2111.04476",
    "title": "Twitter Big Data as a Resource for Exoskeleton Research: A Large-Scale  Dataset of about 140,000 Tweets and 100 Research Questions",
    "abstract": "Twitter Big Data as a Resource for Exoskeleton Research: A Large-Scale  Dataset of about 140,000 Tweets and 100 Research Questions",
    "descriptor": "",
    "authors": [
      "Nirmalya Thakur"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.04476"
  },
  {
    "id": "arXiv:2111.11187",
    "title": "PointMixer: MLP-Mixer for Point Cloud Understanding",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Jaesung Choe",
      "Chunghyun Park",
      "Francois Rameau",
      "Jaesik Park",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11187"
  },
  {
    "id": "arXiv:2111.12385",
    "title": "Space-Partitioning RANSAC",
    "abstract": "Space-Partitioning RANSAC",
    "descriptor": "",
    "authors": [
      "Daniel Barath",
      "Gabor Valasek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12385"
  },
  {
    "id": "arXiv:2111.12506",
    "title": "Generalized Normalizing Flows via Markov Chains",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2109.11375",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.11375\n",
    "authors": [
      "Paul Hagemann",
      "Johannes Hertrich",
      "Gabriele Steidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.12506"
  },
  {
    "id": "arXiv:2111.12990",
    "title": "Learning Algebraic Representation for Systematic Generalization in  Abstract Reasoning",
    "abstract": "Comments: ECCV 2022 paper. Supplementary: this http URL Project: this http URL",
    "descriptor": "\nComments: ECCV 2022 paper. Supplementary: this http URL Project: this http URL\n",
    "authors": [
      "Chi Zhang",
      "Sirui Xie",
      "Baoxiong Jia",
      "Ying Nian Wu",
      "Song-Chun Zhu",
      "Yixin Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12990"
  },
  {
    "id": "arXiv:2111.13681",
    "title": "ManiFest: Manifold Deformation for Few-shot Image Translation",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Fabio Pizzati",
      "Jean-Fran\u00e7ois Lalonde",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.13681"
  },
  {
    "id": "arXiv:2111.13844",
    "title": "Adaptive Image Transformations for Transfer-based Adversarial Attack",
    "abstract": "Comments: 34 pages, 7 figures, 11 tables. Accepted by ECCV2022",
    "descriptor": "\nComments: 34 pages, 7 figures, 11 tables. Accepted by ECCV2022\n",
    "authors": [
      "Zheng Yuan",
      "Jie Zhang",
      "Shiguang Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13844"
  },
  {
    "id": "arXiv:2111.13876",
    "title": "Learning Discriminative Shrinkage Deep Networks for Image Deconvolution",
    "abstract": "Learning Discriminative Shrinkage Deep Networks for Image Deconvolution",
    "descriptor": "",
    "authors": [
      "Pin-Hung Kuo",
      "Jinshan Pan",
      "Shao-Yi Chien",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13876"
  },
  {
    "id": "arXiv:2111.14188",
    "title": "An Empirical Study of Topic Transition in Dialogue",
    "abstract": "Comments: 5 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: 5 pages, 4 figures, 3 tables\n",
    "authors": [
      "Mayank Soni",
      "Brendan Spillane",
      "Emer Gilmartin",
      "Christian Saam",
      "Benjamin R. Cowan",
      "Vincent Wade"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.14188"
  },
  {
    "id": "arXiv:2112.03108",
    "title": "Flood Inflow Forecast Using L2-norm Ensemble Weighting Sea Surface  Feature",
    "abstract": "Comments: 23 pages, 13 figures, 5 tables",
    "descriptor": "\nComments: 23 pages, 13 figures, 5 tables\n",
    "authors": [
      "Takato Yasuno",
      "Masazumi Amakata",
      "Junichiro Fujii",
      "Masahiro Okano",
      "Riku Ogata"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.03108"
  },
  {
    "id": "arXiv:2112.03799",
    "title": "A pragmatic account of the weak evidence effect",
    "abstract": "Comments: in press at Open Mind",
    "descriptor": "\nComments: in press at Open Mind\n",
    "authors": [
      "Samuel A. Barnett",
      "Thomas L. Griffiths",
      "Robert D. Hawkins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.03799"
  },
  {
    "id": "arXiv:2112.07187",
    "title": "Formal Estimation of Collision Risks for Autonomous Vehicles: A  Compositional Data-Driven Approach",
    "abstract": "Comments: This work has been accepted at IEEE Transactions on Control of Network Systems",
    "descriptor": "\nComments: This work has been accepted at IEEE Transactions on Control of Network Systems\n",
    "authors": [
      "Abolfazl Lavaei",
      "Luigi Di Lillo",
      "Andrea Censi",
      "Emilio Frazzoli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.07187"
  },
  {
    "id": "arXiv:2112.08684",
    "title": "META: Mimicking Embedding via oThers' Aggregation for Generalizable  Person Re-identification",
    "abstract": "META: Mimicking Embedding via oThers' Aggregation for Generalizable  Person Re-identification",
    "descriptor": "",
    "authors": [
      "Boqiang Xu",
      "Jian Liang",
      "Lingxiao He",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08684"
  },
  {
    "id": "arXiv:2112.08906",
    "title": "On the Uncertain Single-View Depths in Colonoscopies",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Javier Rodr\u00edguez-Puigvert",
      "David Recasens",
      "Javier Civera",
      "Rub\u00e9n Mart\u00ednez-Cant\u00edn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08906"
  },
  {
    "id": "arXiv:2112.08932",
    "title": "Learning from Guided Play: A Scheduled Hierarchical Approach for  Improving Exploration in Adversarial Imitation Learning",
    "abstract": "Comments: In Proceedings of the Neural Information Processing Systems (NeurIPS'21) Deep Reinforcement Learning Workshop, Sydney, Australia, Dec. 13, 2021",
    "descriptor": "\nComments: In Proceedings of the Neural Information Processing Systems (NeurIPS'21) Deep Reinforcement Learning Workshop, Sydney, Australia, Dec. 13, 2021\n",
    "authors": [
      "Trevor Ablett",
      "Bryan Chan",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08932"
  },
  {
    "id": "arXiv:2112.13548",
    "title": "Responsive Listening Head Generation: A Benchmark Dataset and Baseline",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Mohan Zhou",
      "Yalong Bai",
      "Wei Zhang",
      "Ting Yao",
      "Tiejun Zhao",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.13548"
  },
  {
    "id": "arXiv:2112.13697",
    "title": "Weakly Supervised Visual-Auditory Human-eye Fixation Prediction with  Multigranularity Perception",
    "abstract": "Weakly Supervised Visual-Auditory Human-eye Fixation Prediction with  Multigranularity Perception",
    "descriptor": "",
    "authors": [
      "Guotao Wang",
      "Chenglizhao Chen",
      "Deng-Ping Fan",
      "Aimin Hao",
      "Hong Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.13697"
  },
  {
    "id": "arXiv:2112.15232",
    "title": "Triads of Conics Associated with a Triangle",
    "abstract": "Comments: 24 pages, 24 figures, 17 references",
    "descriptor": "\nComments: 24 pages, 24 figures, 17 references\n",
    "authors": [
      "Ronaldo Garcia",
      "Liliana Gheorghe",
      "Peter Moses",
      "Dan Reznik"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.15232"
  },
  {
    "id": "arXiv:2201.00207",
    "title": "AutoDES: AutoML Pipeline Generation of Classification with Dynamic  Ensemble Strategy Selection",
    "abstract": "AutoDES: AutoML Pipeline Generation of Classification with Dynamic  Ensemble Strategy Selection",
    "descriptor": "",
    "authors": [
      "Yunpu Zhao",
      "Rui Zhang",
      "Xiaqing Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00207"
  },
  {
    "id": "arXiv:2201.05889",
    "title": "StolenEncoder: Stealing Pre-trained Encoders in Self-supervised Learning",
    "abstract": "Comments: To appear in ACM Conference on Computer and Communications Security (CCS), 2022",
    "descriptor": "\nComments: To appear in ACM Conference on Computer and Communications Security (CCS), 2022\n",
    "authors": [
      "Yupei Liu",
      "Jinyuan Jia",
      "Hongbin Liu",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05889"
  },
  {
    "id": "arXiv:2201.07412",
    "title": "Poseur: Direct Human Pose Regression with Transformers",
    "abstract": "Comments: Accepted to Proc. Eur. Conf. Comp. Vision (ECCV) 2022",
    "descriptor": "\nComments: Accepted to Proc. Eur. Conf. Comp. Vision (ECCV) 2022\n",
    "authors": [
      "Weian Mao",
      "Yongtao Ge",
      "Chunhua Shen",
      "Zhi Tian",
      "Xinlong Wang",
      "Zhibin Wang",
      "Anton van den Hengel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.07412"
  },
  {
    "id": "arXiv:2201.08620",
    "title": "Extended Randomized Kaczmarz Method for Sparse Least Squares and  Impulsive Noise Problems",
    "abstract": "Extended Randomized Kaczmarz Method for Sparse Least Squares and  Impulsive Noise Problems",
    "descriptor": "",
    "authors": [
      "Frank Sch\u00f6pfer",
      "Dirk A Lorenz",
      "Lionel Tondji",
      "Maximilian Winkler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.08620"
  },
  {
    "id": "arXiv:2201.08931",
    "title": "Frequency and Phase Synchronization in Distributed Antenna Arrays Based  on Consensus Averaging and Kalman Filtering",
    "abstract": "Frequency and Phase Synchronization in Distributed Antenna Arrays Based  on Consensus Averaging and Kalman Filtering",
    "descriptor": "",
    "authors": [
      "Mohammed Rashid",
      "Jeffrey A. Nanzer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08931"
  },
  {
    "id": "arXiv:2201.09243",
    "title": "Increasing the Cost of Model Extraction with Calibrated Proof of Work",
    "abstract": "Comments: Published as a conference paper at ICLR 2022 (Spotlight - 5% of submitted papers)",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022 (Spotlight - 5% of submitted papers)\n",
    "authors": [
      "Adam Dziedzic",
      "Muhammad Ahmad Kaleem",
      "Yu Shen Lu",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09243"
  },
  {
    "id": "arXiv:2201.10828",
    "title": "Reflexivity of Partitions Induced by Weighted Poset Metric and  Combinatorial Metric",
    "abstract": "Reflexivity of Partitions Induced by Weighted Poset Metric and  Combinatorial Metric",
    "descriptor": "",
    "authors": [
      "Yang Xu",
      "Haibin Kan",
      "Guangyue Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.10828"
  },
  {
    "id": "arXiv:2201.11840",
    "title": "GC3: An Optimizing Compiler for GPU Collective Communication",
    "abstract": "GC3: An Optimizing Compiler for GPU Collective Communication",
    "descriptor": "",
    "authors": [
      "Meghan Cowan",
      "Saeed Maleki",
      "Madanlal Musuvathi",
      "Olli Saarikivi",
      "Yifan Xiong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11840"
  },
  {
    "id": "arXiv:2201.13019",
    "title": "On the Robustness of Quality Measures for GANs",
    "abstract": "Comments: Accepted at the European Conference in Computer Vision (ECCV 2022)",
    "descriptor": "\nComments: Accepted at the European Conference in Computer Vision (ECCV 2022)\n",
    "authors": [
      "Motasem Alfarra",
      "Juan C. P\u00e9rez",
      "Anna Fr\u00fchst\u00fcck",
      "Philip H. S. Torr",
      "Peter Wonka",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13019"
  },
  {
    "id": "arXiv:2202.01551",
    "title": "Isometries and MacWilliams Extension Property for Weighted Poset Metric",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2201.10828",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2201.10828\n",
    "authors": [
      "Yang Xu",
      "Haibin Kan",
      "Guangyue Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01551"
  },
  {
    "id": "arXiv:2202.01719",
    "title": "FORML: Learning to Reweight Data for Fairness",
    "abstract": "Comments: 9 pages, 2 figures, Presented at ICML 2022 DataPerf Workshop",
    "descriptor": "\nComments: 9 pages, 2 figures, Presented at ICML 2022 DataPerf Workshop\n",
    "authors": [
      "Bobby Yan",
      "Skyler Seto",
      "Nicholas Apostoloff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01719"
  },
  {
    "id": "arXiv:2202.02650",
    "title": "Efficient Privacy Preserving Logistic Regression for Horizontally  Distributed Data",
    "abstract": "Efficient Privacy Preserving Logistic Regression for Horizontally  Distributed Data",
    "descriptor": "",
    "authors": [
      "Guanhong Miao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2202.02650"
  },
  {
    "id": "arXiv:2202.03791",
    "title": "A Kleene Theorem for Higher-Dimensional Automata",
    "abstract": "A Kleene Theorem for Higher-Dimensional Automata",
    "descriptor": "",
    "authors": [
      "Uli Fahrenberg",
      "Christian Johansen",
      "Georg Struth",
      "Krzysztof Ziemia\u0144ski"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2202.03791"
  },
  {
    "id": "arXiv:2202.04208",
    "title": "Validating Causal Inference Methods",
    "abstract": "Comments: 5 figures, 13 pages",
    "descriptor": "\nComments: 5 figures, 13 pages\n",
    "authors": [
      "Harsh Parikh",
      "Carlos Varjao",
      "Louise Xu",
      "Eric Tchetgen Tchetgen"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2202.04208"
  },
  {
    "id": "arXiv:2202.07261",
    "title": "Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks",
    "abstract": "Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks",
    "descriptor": "",
    "authors": [
      "Qianjiang Hu",
      "Daizong Liu",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.07261"
  },
  {
    "id": "arXiv:2202.08361",
    "title": "Vectorization of a thread-parallel Jacobi singular value decomposition  method",
    "abstract": "Comments: A separate \"supplementary materials\" document has been appended to the main paper as Appendix for technical reasons",
    "descriptor": "\nComments: A separate \"supplementary materials\" document has been appended to the main paper as Appendix for technical reasons\n",
    "authors": [
      "Vedran Novakovi\u0107"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2202.08361"
  },
  {
    "id": "arXiv:2202.08761",
    "title": "QuerTCI: A Tool Integrating GitHub Issue Querying with Comment  Classification",
    "abstract": "QuerTCI: A Tool Integrating GitHub Issue Querying with Comment  Classification",
    "descriptor": "",
    "authors": [
      "Ye Paing",
      "Tatiana Castro V\u00e9lez",
      "Raffi Khatchadourian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.08761"
  },
  {
    "id": "arXiv:2202.11225",
    "title": "Deterministic and Stochastic Fixed-time Stability of Discrete-time  Autonomous Systems",
    "abstract": "Deterministic and Stochastic Fixed-time Stability of Discrete-time  Autonomous Systems",
    "descriptor": "",
    "authors": [
      "Farzaneh Tatari",
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.11225"
  },
  {
    "id": "arXiv:2202.12387",
    "title": "Provable Stochastic Optimization for Global Contrastive Learning: Small  Batch Does Not Harm Performance",
    "abstract": "Comments: Accepted by ICML2022",
    "descriptor": "\nComments: Accepted by ICML2022\n",
    "authors": [
      "Zhuoning Yuan",
      "Yuexin Wu",
      "Zi-Hao Qiu",
      "Xianzhi Du",
      "Lijun Zhang",
      "Denny Zhou",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12387"
  },
  {
    "id": "arXiv:2203.00973",
    "title": "A density peaks clustering algorithm with sparse search and K-d tree",
    "abstract": "Comments: IEEE ACCESS",
    "descriptor": "\nComments: IEEE ACCESS\n",
    "authors": [
      "Yunxiao Shan",
      "Shu Li",
      "Fuxiang Li",
      "Yuxin Cui",
      "Shuai Li",
      "Ming Zhou",
      "Xiang Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.00973"
  },
  {
    "id": "arXiv:2203.01325",
    "title": "Self-Supervised Learning for Real-World Super-Resolution from Dual  Zoomed Observations",
    "abstract": "Comments: ECCV 2022 camera ready",
    "descriptor": "\nComments: ECCV 2022 camera ready\n",
    "authors": [
      "Zhilu Zhang",
      "Ruohao Wang",
      "Hongzhi Zhang",
      "Yunjin Chen",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01325"
  },
  {
    "id": "arXiv:2203.01909",
    "title": "An Adaptive Human Driver Model for Realistic Race Car Simulations",
    "abstract": "Comments: 12 pages, 12 figures",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Stefan L\u00f6ckel",
      "Siwei Ju",
      "Maximilian Schaller",
      "Peter van Vliet",
      "Jan Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.01909"
  },
  {
    "id": "arXiv:2203.02102",
    "title": "BEATS: An Open-Source, High-Precision, Multi-Channel EEG Acquisition  Tool System",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Bing Zou",
      "Yubo Zheng",
      "Mu Shen",
      "Yingying Luo",
      "Lei Li",
      "Lin Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.02102"
  },
  {
    "id": "arXiv:2203.02452",
    "title": "Contextformer: A Transformer with Spatio-Channel Attention for Context  Modeling in Learned Image Compression",
    "abstract": "Comments: Accepted at ECCV 2022; 31 pages (14 main paper + References + 13 Appendix)",
    "descriptor": "\nComments: Accepted at ECCV 2022; 31 pages (14 main paper + References + 13 Appendix)\n",
    "authors": [
      "A. Burakhan Koyuncu",
      "Han Gao",
      "Atanas Boev",
      "Georgii Gaikov",
      "Elena Alshina",
      "Eckehard Steinbach"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.02452"
  },
  {
    "id": "arXiv:2203.02793",
    "title": "Hundreds of new satellites of figure-eight orbit computed with high  precision",
    "abstract": "Comments: 12 pages, 9 figures, 1 table",
    "descriptor": "\nComments: 12 pages, 9 figures, 1 table\n",
    "authors": [
      "I. Hristov",
      "R. Hristova",
      "I. Puzynin",
      "T. Puzynina",
      "Z. Sharipov",
      "Z. Tukhliev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.02793"
  },
  {
    "id": "arXiv:2203.03220",
    "title": "On the error rate of importance sampling with randomized quasi-Monte  Carlo",
    "abstract": "On the error rate of importance sampling with randomized quasi-Monte  Carlo",
    "descriptor": "",
    "authors": [
      "Zhijian He",
      "Zhan Zheng",
      "Xiaoqun Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.03220"
  },
  {
    "id": "arXiv:2203.03931",
    "title": "PASS: Part-Aware Self-Supervised Pre-Training for Person  Re-Identification",
    "abstract": "Comments: Accepted by ECCV2022. Codes are available at this https URL",
    "descriptor": "\nComments: Accepted by ECCV2022. Codes are available at this https URL\n",
    "authors": [
      "Kuan Zhu",
      "Haiyun Guo",
      "Tianyi Yan",
      "Yousong Zhu",
      "Jinqiao Wang",
      "Ming Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03931"
  },
  {
    "id": "arXiv:2203.04187",
    "title": "RankSeg: Adaptive Pixel Classification with Image Category Ranking for  Segmentation",
    "abstract": "Comments: Accepted at ECCV 2022, Code will be available at: this https URL",
    "descriptor": "\nComments: Accepted at ECCV 2022, Code will be available at: this https URL\n",
    "authors": [
      "Haodi He",
      "Yuhui Yuan",
      "Xiangyu Yue",
      "Han Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04187"
  },
  {
    "id": "arXiv:2203.04203",
    "title": "AssistQ: Affordance-centric Question-driven Task Completion for  Egocentric Assistant",
    "abstract": "Comments: Accepted by ECCV 2022. Equal contribution: Benita Wong, Joya Chen, You Wu; Corresponding author: Mike Zheng Shou",
    "descriptor": "\nComments: Accepted by ECCV 2022. Equal contribution: Benita Wong, Joya Chen, You Wu; Corresponding author: Mike Zheng Shou\n",
    "authors": [
      "Benita Wong",
      "Joya Chen",
      "You Wu",
      "Stan Weixian Lei",
      "Dongxing Mao",
      "Difei Gao",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04203"
  },
  {
    "id": "arXiv:2203.04694",
    "title": "Align-Deform-Subtract: An Interventional Framework for Explaining Object  Differences",
    "abstract": "Comments: ICLR 2022 Workshop on Objects, Structure and Causality",
    "descriptor": "\nComments: ICLR 2022 Workshop on Objects, Structure and Causality\n",
    "authors": [
      "Cian Eastwood",
      "Li Nanbo",
      "Christopher K. I. Williams"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.04694"
  },
  {
    "id": "arXiv:2203.04920",
    "title": "Effects of Epileptiform Activity on Discharge Outcome in Critically Ill  Patients",
    "abstract": "Effects of Epileptiform Activity on Discharge Outcome in Critically Ill  Patients",
    "descriptor": "",
    "authors": [
      "Harsh Parikh",
      "Kentaro Hoffman",
      "Haoqi Sun",
      "Wendong Ge",
      "Jin Jing",
      "Rajesh Amerineni",
      "Lin Liu",
      "Jimeng Sun",
      "Sahar Zafar",
      "Aaron Struck",
      "Alexander Volfovsky",
      "Cynthia Rudin",
      "M. Brandon Westover"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04920"
  },
  {
    "id": "arXiv:2203.04955",
    "title": "Temporal Difference Learning for Model Predictive Control",
    "abstract": "Comments: Code and videos: this https URL",
    "descriptor": "\nComments: Code and videos: this https URL\n",
    "authors": [
      "Nicklas Hansen",
      "Xiaolong Wang",
      "Hao Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.04955"
  },
  {
    "id": "arXiv:2203.05203",
    "title": "MORE: Multi-Order RElation Mining for Dense Captioning in 3D Scenes",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Yang Jiao",
      "Shaoxiang Chen",
      "Zequn Jie",
      "Jingjing Chen",
      "Lin Ma",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05203"
  },
  {
    "id": "arXiv:2203.06145",
    "title": "Neuromorphic Data Augmentation for Training Spiking Neural Networks",
    "abstract": "Comments: Accepted to the 17th European Conference on Computer Vision (ECCV 2022)",
    "descriptor": "\nComments: Accepted to the 17th European Conference on Computer Vision (ECCV 2022)\n",
    "authors": [
      "Yuhang Li",
      "Youngeun Kim",
      "Hyoungseob Park",
      "Tamar Geller",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06145"
  },
  {
    "id": "arXiv:2203.06451",
    "title": "Bringing Rolling Shutter Images Alive with Dual Reversed Distortion",
    "abstract": "Comments: ECCV2022 Oral",
    "descriptor": "\nComments: ECCV2022 Oral\n",
    "authors": [
      "Zhihang Zhong",
      "Mingdeng Cao",
      "Xiao Sun",
      "Zhirong Wu",
      "Zhongyi Zhou",
      "Yinqiang Zheng",
      "Stephen Lin",
      "Imari Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06451"
  },
  {
    "id": "arXiv:2203.07574",
    "title": "Time-series image denoising of pressure-sensitive paint data by  projected multivariate singular spectrum analysis",
    "abstract": "Comments: 16 pages, 12 figures",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Yuya Ohmichi",
      "Kohmi Takahashi",
      "Kazuyuki Nakakita"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2203.07574"
  },
  {
    "id": "arXiv:2203.08606",
    "title": "A Reachability Index for Recursive Label-Concatenated Graph Queries",
    "abstract": "A Reachability Index for Recursive Label-Concatenated Graph Queries",
    "descriptor": "",
    "authors": [
      "Chao Zhang",
      "Angela Bonifati",
      "Hugo Kapp",
      "Vlad Ioan Haprian",
      "Jean-Pierre Lozi"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.08606"
  },
  {
    "id": "arXiv:2203.09440",
    "title": "TO-Scene: A Large-scale Dataset for Understanding 3D Tabletop Scenes",
    "abstract": "Comments: ECCV 2022 (Oral Presentation)",
    "descriptor": "\nComments: ECCV 2022 (Oral Presentation)\n",
    "authors": [
      "Mutian Xu",
      "Pei Chen",
      "Haolin Liu",
      "Xiaoguang Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09440"
  },
  {
    "id": "arXiv:2203.09554",
    "title": "CoGS: Controllable Generation and Search from Sketch and Style",
    "abstract": "CoGS: Controllable Generation and Search from Sketch and Style",
    "descriptor": "",
    "authors": [
      "Cusuh Ham",
      "Gemma Canet Tarres",
      "Tu Bui",
      "James Hays",
      "Zhe Lin",
      "John Collomosse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09554"
  },
  {
    "id": "arXiv:2203.11191",
    "title": "Robust Visual Tracking by Segmentation",
    "abstract": "Comments: Accepted at ECCV 2022. Code and trained models are available at: this https URL",
    "descriptor": "\nComments: Accepted at ECCV 2022. Code and trained models are available at: this https URL\n",
    "authors": [
      "Matthieu Paul",
      "Martin Danelljan",
      "Christoph Mayer",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.11191"
  },
  {
    "id": "arXiv:2203.11654",
    "title": "Fine-Grained Scene Graph Generation with Data Transfer",
    "abstract": "Comments: ECCV 2022 (Oral)",
    "descriptor": "\nComments: ECCV 2022 (Oral)\n",
    "authors": [
      "Ao Zhang",
      "Yuan Yao",
      "Qianyu Chen",
      "Wei Ji",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11654"
  },
  {
    "id": "arXiv:2203.12119",
    "title": "Visual Prompt Tuning",
    "abstract": "Comments: ECCV2022",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Menglin Jia",
      "Luming Tang",
      "Bor-Chun Chen",
      "Claire Cardie",
      "Serge Belongie",
      "Bharath Hariharan",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12119"
  },
  {
    "id": "arXiv:2203.12961",
    "title": "Multilevel Bayesian Deep Neural Networks",
    "abstract": "Multilevel Bayesian Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Neil K. Chada",
      "Ajay Jasra",
      "Kody J. H. Law",
      "Sumeetpal S. Singh"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.12961"
  },
  {
    "id": "arXiv:2203.13231",
    "title": "A Broad Comparative Evaluation of x86-64 Binary Rewriters",
    "abstract": "Comments: 16 pages, 14 tables, 5 figures",
    "descriptor": "\nComments: 16 pages, 14 tables, 5 figures\n",
    "authors": [
      "Eric Schulte",
      "Michael D. Brown",
      "Vlad Folts"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.13231"
  },
  {
    "id": "arXiv:2203.13409",
    "title": "Multi-scale and Cross-scale Contrastive Learning for Semantic  Segmentation",
    "abstract": "Comments: to appear at ECCV 2022",
    "descriptor": "\nComments: to appear at ECCV 2022\n",
    "authors": [
      "Theodoros Pissas",
      "Claudio S. Ravasio",
      "Lyndon Da Cruz",
      "Christos Bergeles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13409"
  },
  {
    "id": "arXiv:2203.13621",
    "title": "Post-Disaster Communications: Enabling Technologies, Architectures, and  Open Challenges",
    "abstract": "Post-Disaster Communications: Enabling Technologies, Architectures, and  Open Challenges",
    "descriptor": "",
    "authors": [
      "Maurilio Matracia",
      "Nasir Saeed",
      "Mustafa A. Kishk",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.13621"
  },
  {
    "id": "arXiv:2203.14099",
    "title": "Competition-Based Resilience in Distributed Quadratic Optimization",
    "abstract": "Comments: 7 pages, 8 figures; revised version; accepted for CDC 2022",
    "descriptor": "\nComments: 7 pages, 8 figures; revised version; accepted for CDC 2022\n",
    "authors": [
      "Luca Ballotta",
      "Giacomo Como",
      "Jeff S. Shamma",
      "Luca Schenato"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.14099"
  },
  {
    "id": "arXiv:2203.14798",
    "title": "Sublinear Algorithms and Lower Bounds for Estimating MST and TSP Cost in  General Metrics",
    "abstract": "Sublinear Algorithms and Lower Bounds for Estimating MST and TSP Cost in  General Metrics",
    "descriptor": "",
    "authors": [
      "Yu Chen",
      "Sanjeev Khanna",
      "Zihan Tan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.14798"
  },
  {
    "id": "arXiv:2203.15946",
    "title": "Towards Learning Neural Representations from Shadows",
    "abstract": "Towards Learning Neural Representations from Shadows",
    "descriptor": "",
    "authors": [
      "Kushagra Tiwary",
      "Tzofi Klinghoffer",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15946"
  },
  {
    "id": "arXiv:2203.16317",
    "title": "PseCo: Pseudo Labeling and Consistency Training for Semi-Supervised  Object Detection",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Gang Li",
      "Xiang Li",
      "Yujie Wang",
      "Yichao Wu",
      "Ding Liang",
      "Shanshan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16317"
  },
  {
    "id": "arXiv:2203.16482",
    "title": "RFNet-4D: Joint Object Reconstruction and Flow Estimation from 4D Point  Clouds",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Tuan-Anh Vu",
      "Duc Thanh Nguyen",
      "Binh-Son Hua",
      "Quang-Hieu Pham",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16482"
  },
  {
    "id": "arXiv:2203.16996",
    "title": "Measuring hand use in the home after cervical spinal cord injury using  egocentric video",
    "abstract": "Measuring hand use in the home after cervical spinal cord injury using  egocentric video",
    "descriptor": "",
    "authors": [
      "Andrea Bandini",
      "Mehdy Dousty",
      "Sander L. Hitzig",
      "B. Catharine Craven",
      "Sukhvinder Kalsi-Ryan",
      "Jos\u00e9 Zariffa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16996"
  },
  {
    "id": "arXiv:2203.17190",
    "title": "Mixed-Phoneme BERT: Improving BERT with Mixed Phoneme and Sup-Phoneme  Representations for Text to Speech",
    "abstract": "Comments: Accepted by interspeech 2022",
    "descriptor": "\nComments: Accepted by interspeech 2022\n",
    "authors": [
      "Guangyan Zhang",
      "Kaitao Song",
      "Xu Tan",
      "Daxin Tan",
      "Yuzi Yan",
      "Yanqing Liu",
      "Gang Wang",
      "Wei Zhou",
      "Tao Qin",
      "Tan Lee",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17190"
  },
  {
    "id": "arXiv:2204.00298",
    "title": "Unitail: Detecting, Reading, and Matching in Retail Scene",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Fangyi Chen",
      "Han Zhang",
      "Zaiwang Li",
      "Jiachen Dou",
      "Shentong Mo",
      "Hao Chen",
      "Yongxin Zhang",
      "Uzair Ahmed",
      "Chenchen Zhu",
      "Marios Savvides"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00298"
  },
  {
    "id": "arXiv:2204.00486",
    "title": "GEB+: A Benchmark for Generic Event Boundary Captioning, Grounding and  Retrieval",
    "abstract": "Comments: In Proceedings of the European Conference on Computer Vision 2022",
    "descriptor": "\nComments: In Proceedings of the European Conference on Computer Vision 2022\n",
    "authors": [
      "Yuxuan Wang",
      "Difei Gao",
      "Licheng Yu",
      "Stan Weixian Lei",
      "Matt Feiszli",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00486"
  },
  {
    "id": "arXiv:2204.00559",
    "title": "DFNet: Enhance Absolute Pose Regression with Direct Feature Matching",
    "abstract": "Comments: ECCV 2022. Code released at this https URL",
    "descriptor": "\nComments: ECCV 2022. Code released at this https URL\n",
    "authors": [
      "Shuai Chen",
      "Xinghui Li",
      "Zirui Wang",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00559"
  },
  {
    "id": "arXiv:2204.00570",
    "title": "Connect, Not Collapse: Explaining Contrastive Learning for Unsupervised  Domain Adaptation",
    "abstract": "Comments: Accepted to ICML 2022 (Long Talk)",
    "descriptor": "\nComments: Accepted to ICML 2022 (Long Talk)\n",
    "authors": [
      "Kendrick Shen",
      "Robbie Jones",
      "Ananya Kumar",
      "Sang Michael Xie",
      "Jeff Z. HaoChen",
      "Tengyu Ma",
      "Percy Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00570"
  },
  {
    "id": "arXiv:2204.01341",
    "title": "An application of Pixel Interval Down-sampling (PID) for dense tiny  microorganism counting on environmental microorganism images",
    "abstract": "An application of Pixel Interval Down-sampling (PID) for dense tiny  microorganism counting on environmental microorganism images",
    "descriptor": "",
    "authors": [
      "Jiawei Zhang",
      "Ning Xu",
      "Chen Li",
      "Md Mamunur Rahaman",
      "Yu-Dong Yao",
      "Yu-Hao Lin",
      "Jinghua Zhang",
      "Tao Jiang",
      "Wenjun Qin",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.01341"
  },
  {
    "id": "arXiv:2204.01802",
    "title": "An Algebraic System for Constructing Cryptographic Permutations over  Finite Fields",
    "abstract": "An Algebraic System for Constructing Cryptographic Permutations over  Finite Fields",
    "descriptor": "",
    "authors": [
      "Arnab Roy",
      "Matthias Steiner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.01802"
  },
  {
    "id": "arXiv:2204.02804",
    "title": "Federated Self-supervised Speech Representations: Are We There Yet?",
    "abstract": "Federated Self-supervised Speech Representations: Are We There Yet?",
    "descriptor": "",
    "authors": [
      "Yan Gao",
      "Javier Fernandez-Marques",
      "Titouan Parcollet",
      "Abhinav Mehrotra",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02804"
  },
  {
    "id": "arXiv:2204.04662",
    "title": "FOSTER: Feature Boosting and Compression for Class-Incremental Learning",
    "abstract": "Comments: Accepted to ECCV 2022. Code is available at: this https URL",
    "descriptor": "\nComments: Accepted to ECCV 2022. Code is available at: this https URL\n",
    "authors": [
      "Fu-Yun Wang",
      "Da-Wei Zhou",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04662"
  },
  {
    "id": "arXiv:2204.04676",
    "title": "Simple Baselines for Image Restoration",
    "abstract": "Comments: Accepted to ECCV 2022; Code: this https URL",
    "descriptor": "\nComments: Accepted to ECCV 2022; Code: this https URL\n",
    "authors": [
      "Liangyu Chen",
      "Xiaojie Chu",
      "Xiangyu Zhang",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04676"
  },
  {
    "id": "arXiv:2204.04906",
    "title": "Application of QUBO solver using black-box optimization to structural  design for resonance avoidance",
    "abstract": "Comments: This is a preprint of an article published in Scientific Reports. The final authenticated version is available online at: 10.1038/s41598-022-16149-8",
    "descriptor": "\nComments: This is a preprint of an article published in Scientific Reports. The final authenticated version is available online at: 10.1038/s41598-022-16149-8\n",
    "authors": [
      "Tadayoshi Matsumori",
      "Masato Taki",
      "Tadashi Kadowaki"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.04906"
  },
  {
    "id": "arXiv:2204.05141",
    "title": "Learning Object-Centered Autotelic Behaviors with Graph Neural Networks",
    "abstract": "Comments: 15 pages, 10 figures, published at the Conference on Lifelong Learning Agents COLLAS 2022",
    "descriptor": "\nComments: 15 pages, 10 figures, published at the Conference on Lifelong Learning Agents COLLAS 2022\n",
    "authors": [
      "Ahmed Akakzia",
      "Olivier Sigaud"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.05141"
  },
  {
    "id": "arXiv:2204.08269",
    "title": "Differentiable Time-Frequency Scattering on GPU",
    "abstract": "Comments: 8 pages, 6 figures. Submitted to the International Conference on Digital Audio Effects (DAFX) 2022",
    "descriptor": "\nComments: 8 pages, 6 figures. Submitted to the International Conference on Digital Audio Effects (DAFX) 2022\n",
    "authors": [
      "John Muradeli",
      "Cyrus Vahidi",
      "Changhong Wang",
      "Han Han",
      "Vincent Lostanlen",
      "Mathieu Lagrange",
      "George Fazekas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.08269"
  },
  {
    "id": "arXiv:2204.08682",
    "title": "Investigation of a Data Split Strategy Involving the Time Axis in  Adverse Event Prediction Using Machine Learning",
    "abstract": "Comments: 20 pages, 4 figures",
    "descriptor": "\nComments: 20 pages, 4 figures\n",
    "authors": [
      "Katsuhisa Morita",
      "Tadahaya Mizuno",
      "Hiroyuki Kusuhara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.08682"
  },
  {
    "id": "arXiv:2204.10909",
    "title": "Error-in-variables modelling for operator learning",
    "abstract": "Comments: 23 pages, 10 figures",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Ravi G. Patel",
      "Indu Manickam",
      "Myoungkyu Lee",
      "Mamikon Gulian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.10909"
  },
  {
    "id": "arXiv:2204.12384",
    "title": "Qunity: A Unified Language for Quantum and Classical Computing (Extended  Version)",
    "abstract": "Comments: 60 pages, presented at QPL 2022",
    "descriptor": "\nComments: 60 pages, presented at QPL 2022\n",
    "authors": [
      "Finn Voichick",
      "Liyi Li",
      "Robert Rand",
      "Michael Hicks"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.12384"
  },
  {
    "id": "arXiv:2204.13170",
    "title": "AdaBest: Minimizing Client Drift in Federated Learning via Adaptive Bias  Estimation",
    "abstract": "Comments: AdaBest",
    "descriptor": "\nComments: AdaBest\n",
    "authors": [
      "Farshid Varno",
      "Marzie Saghayi",
      "Laya Rafiee Sevyeri",
      "Sharut Gupta",
      "Stan Matwin",
      "Mohammad Havaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2204.13170"
  },
  {
    "id": "arXiv:2204.13547",
    "title": "Generic Dijkstra: correctness and tractability",
    "abstract": "Generic Dijkstra: correctness and tractability",
    "descriptor": "",
    "authors": [
      "Ireneusz Szcze\u015bniak",
      "Bo\u017cena Wo\u017ana-Szcze\u015bniak"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.13547"
  },
  {
    "id": "arXiv:2205.02886",
    "title": "Data Augmentation for Manipulation",
    "abstract": "Comments: Robotics Science and Systems (RSS) 2022 Project Website: this https URL",
    "descriptor": "\nComments: Robotics Science and Systems (RSS) 2022 Project Website: this https URL\n",
    "authors": [
      "Peter Mitrano",
      "Dmitry Berenson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.02886"
  },
  {
    "id": "arXiv:2205.04002",
    "title": "Towards a High-performance and Secure Memory System and Architecture for  Emerging Applications",
    "abstract": "Towards a High-performance and Secure Memory System and Architecture for  Emerging Applications",
    "descriptor": "",
    "authors": [
      "Zhendong Wang",
      "Yang Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.04002"
  },
  {
    "id": "arXiv:2205.05183",
    "title": "All-to-All Encode in Synchronous Systems",
    "abstract": "All-to-All Encode in Synchronous Systems",
    "descriptor": "",
    "authors": [
      "Canran Wang",
      "Netanel Raviv"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.05183"
  },
  {
    "id": "arXiv:2205.06212",
    "title": "Contingency-constrained economic dispatch with safe reinforcement  learning",
    "abstract": "Contingency-constrained economic dispatch with safe reinforcement  learning",
    "descriptor": "",
    "authors": [
      "Michael Eichelbeck",
      "Hannah Markgraf",
      "Matthias Althoff"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.06212"
  },
  {
    "id": "arXiv:2205.06230",
    "title": "Simple Open-Vocabulary Object Detection with Vision Transformers",
    "abstract": "Comments: ECCV 2022 camera-ready version",
    "descriptor": "\nComments: ECCV 2022 camera-ready version\n",
    "authors": [
      "Matthias Minderer",
      "Alexey Gritsenko",
      "Austin Stone",
      "Maxim Neumann",
      "Dirk Weissenborn",
      "Alexey Dosovitskiy",
      "Aravindh Mahendran",
      "Anurag Arnab",
      "Mostafa Dehghani",
      "Zhuoran Shen",
      "Xiao Wang",
      "Xiaohua Zhai",
      "Thomas Kipf",
      "Neil Houlsby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.06230"
  },
  {
    "id": "arXiv:2205.06254",
    "title": "Learned Vertex Descent: A New Direction for 3D Human Model Fitting",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Enric Corona",
      "Gerard Pons-Moll",
      "Guillem Aleny\u00e0",
      "Francesc Moreno-Noguer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.06254"
  },
  {
    "id": "arXiv:2205.07803",
    "title": "Average-Case Hardness of Proving Tautologies and Theorems",
    "abstract": "Average-Case Hardness of Proving Tautologies and Theorems",
    "descriptor": "",
    "authors": [
      "Hunter Monroe"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.07803"
  },
  {
    "id": "arXiv:2205.08022",
    "title": "A faster algorithm for Vertex Cover parameterized by solution size",
    "abstract": "A faster algorithm for Vertex Cover parameterized by solution size",
    "descriptor": "",
    "authors": [
      "David G. Harris",
      "N. S. Narayanaswamy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2205.08022"
  },
  {
    "id": "arXiv:2205.08834",
    "title": "Finding Qs: Profiling QAnon Supporters on Parler",
    "abstract": "Comments: Accepted at the International AAAI Conference on Web and Social Media (ICWSM, 2023)",
    "descriptor": "\nComments: Accepted at the International AAAI Conference on Web and Social Media (ICWSM, 2023)\n",
    "authors": [
      "Dominik B\u00e4r",
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.08834"
  },
  {
    "id": "arXiv:2205.09224",
    "title": "Entailment Tree Explanations via Iterative Retrieval-Generation Reasoner",
    "abstract": "Comments: published in NAACL 2022",
    "descriptor": "\nComments: published in NAACL 2022\n",
    "authors": [
      "Danilo Ribeiro",
      "Shen Wang",
      "Xiaofei Ma",
      "Rui Dong",
      "Xiaokai Wei",
      "Henry Zhu",
      "Xinchi Chen",
      "Zhiheng Huang",
      "Peng Xu",
      "Andrew Arnold",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09224"
  },
  {
    "id": "arXiv:2205.09944",
    "title": "6G Network AI Architecture for Everyone-Centric Customized Services",
    "abstract": "6G Network AI Architecture for Everyone-Centric Customized Services",
    "descriptor": "",
    "authors": [
      "Yang Yang",
      "Mulei Ma",
      "Hequan Wu",
      "Quan Yu",
      "Ping Zhang",
      "Xiaohu You",
      "Jianjun Wu",
      "Chenghui Peng",
      "Tak-Shing Peter Yum",
      "Sherman Shen",
      "Hamid Aghvami",
      "Geoffrey Y Li",
      "Jiangzhou Wang",
      "Guangyi Liu",
      "Peng Gao",
      "Xiongyan Tang",
      "Chang Cao",
      "John Thompson",
      "Kat-Kit Wong",
      "Shanzhi Chen",
      "Merouane Debbah",
      "Schahram Dustdar",
      "Frank Eliassen",
      "Tao Chen",
      "Xiangyang Duan",
      "Shaohui Sun",
      "Xiaofeng Tao",
      "Qinyu Zhang",
      "Jianwei Huang",
      "Shuguang Cui",
      "Wenjun Zhang",
      "Jie Li",
      "Yue Gao",
      "Honggang Zhang",
      "Xu Chen",
      "Xiaohu Ge",
      "Yong Xiao",
      "Cheng-Xiang Wang",
      "Zaichen Zhang",
      "Song Ci",
      "Guoqiang Mao",
      "Changle Li",
      "Ziyu Shao",
      "Yong Zhou",
      "Junrui Liang",
      "Kai Li",
      "Liantao Wu",
      "Fanglei Sun",
      "Kunlun Wang",
      "Zening Liu",
      "Kun Yang",
      "Jun Wang",
      "Teng Gao",
      "Hongfeng Shu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.09944"
  },
  {
    "id": "arXiv:2205.11335",
    "title": "Leakage Subspace Precoding and Scheduling for Physical Layer Security in  Multi-User XL-MIMO Systems",
    "abstract": "Comments: 5 pages and 4 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 5 pages and 4 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Gonzalo J. Anaya-Lopez",
      "Jose P. Gonzalez-Coma",
      "F. Javier Lopez-Martinez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11335"
  },
  {
    "id": "arXiv:2205.12796",
    "title": "Non-rigid Point Cloud Registration with Neural Deformation Pyramid",
    "abstract": "Comments: Code: this https URL",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Yang Li",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12796"
  },
  {
    "id": "arXiv:2205.15781",
    "title": "Co-Training for Unsupervised Domain Adaptation of Semantic Segmentation  Models",
    "abstract": "Co-Training for Unsupervised Domain Adaptation of Semantic Segmentation  Models",
    "descriptor": "",
    "authors": [
      "Jose L. G\u00f3mez",
      "Gabriel Villalonga",
      "Antonio M. L\u00f3pez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.15781"
  },
  {
    "id": "arXiv:2206.00288",
    "title": "Sustaining Security and Safety in ICT: A Quest for Terminology,  Objectives, and Limits",
    "abstract": "Sustaining Security and Safety in ICT: A Quest for Terminology,  Objectives, and Limits",
    "descriptor": "",
    "authors": [
      "Jan Tobias Muehlberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00288"
  },
  {
    "id": "arXiv:2206.02640",
    "title": "Policy Optimization for Markov Games: Unified Framework and Faster  Convergence",
    "abstract": "Policy Optimization for Markov Games: Unified Framework and Faster  Convergence",
    "descriptor": "",
    "authors": [
      "Runyu Zhang",
      "Qinghua Liu",
      "Huan Wang",
      "Caiming Xiong",
      "Na Li",
      "Yu Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.02640"
  },
  {
    "id": "arXiv:2206.03463",
    "title": "HM-LDM: A Hybrid-Membership Latent Distance Model",
    "abstract": "Comments: Camera-ready version. Accepted for oral presentation at the 11th International Conference on Complex Networks and their Applications, CNA 22",
    "descriptor": "\nComments: Camera-ready version. Accepted for oral presentation at the 11th International Conference on Complex Networks and their Applications, CNA 22\n",
    "authors": [
      "Nikolaos Nakis",
      "Abdulkadir \u00c7elikkanat",
      "Morten M\u00f8rup"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.03463"
  },
  {
    "id": "arXiv:2206.04397",
    "title": "ESBMC-Jimple: Verifying Kotlin Programs via Jimple Intermediate  Representation",
    "abstract": "Comments: ACM SIGSOFT International Symposium on Software Testing and Analysis 2022",
    "descriptor": "\nComments: ACM SIGSOFT International Symposium on Software Testing and Analysis 2022\n",
    "authors": [
      "Rafael Menezes",
      "Daniel Moura",
      "Helena Cavalcante",
      "Rosiane de Freitas",
      "Lucas C. Cordeiro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.04397"
  },
  {
    "id": "arXiv:2206.06182",
    "title": "AI-based Data Preparation and Data Analytics in Healthcare: The Case of  Diabetes",
    "abstract": "Comments: The work has been presented at the conference Ital-IA 2022 (this https URL)",
    "descriptor": "\nComments: The work has been presented at the conference Ital-IA 2022 (this https URL)\n",
    "authors": [
      "Marianna Maranghi",
      "Aris Anagnostopoulos",
      "Irene Cannistraci",
      "Ioannis Chatzigiannakis",
      "Federico Croce",
      "Giulia Di Teodoro",
      "Michele Gentile",
      "Giorgio Grani",
      "Maurizio Lenzerini",
      "Stefano Leonardi",
      "Andrea Mastropietro",
      "Laura Palagi",
      "Massimiliano Pappa",
      "Riccardo Rosati",
      "Riccardo Valentini",
      "Paola Velardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2206.06182"
  },
  {
    "id": "arXiv:2206.07025",
    "title": "A deterministic view on explicit data-driven (M)PC",
    "abstract": "Comments: 7 pages, 2 figure, submitted to 61st IEE Conference on Decision and Control 2022",
    "descriptor": "\nComments: 7 pages, 2 figure, submitted to 61st IEE Conference on Decision and Control 2022\n",
    "authors": [
      "Manuel Kl\u00e4dtke",
      "Dieter Teichrib",
      "Nils Schl\u00fcter",
      "Moritz Schulze Darup"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.07025"
  },
  {
    "id": "arXiv:2206.07458",
    "title": "VisageSynTalk: Unseen Speaker Video-to-Speech Synthesis via  Speech-Visage Feature Selection",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Joanna Hong",
      "Minsu Kim",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.07458"
  },
  {
    "id": "arXiv:2206.09465",
    "title": "Cybersecurity Law: Legal Jurisdiction and Authority",
    "abstract": "Comments: This report is developed for partial fulfillment of the requirements for the degree of Juris Masters of Law at GMU's Antonin Scalia Law School",
    "descriptor": "\nComments: This report is developed for partial fulfillment of the requirements for the degree of Juris Masters of Law at GMU's Antonin Scalia Law School\n",
    "authors": [
      "Feras A. Batarseh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09465"
  },
  {
    "id": "arXiv:2206.09571",
    "title": "Deep Random Vortex Method for Simulation and Inference of Navier-Stokes  Equations",
    "abstract": "Deep Random Vortex Method for Simulation and Inference of Navier-Stokes  Equations",
    "descriptor": "",
    "authors": [
      "Rui Zhang",
      "Peiyan Hu",
      "Qi Meng",
      "Yue Wang",
      "Rongchan Zhu",
      "Bingguang Chen",
      "Zhi-Ming Ma",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.09571"
  },
  {
    "id": "arXiv:2206.09628",
    "title": "Diversified Adversarial Attacks based on Conjugate Gradient Method",
    "abstract": "Comments: Proceedings of the 39th International Conference on Machine Learning (ICML 2022)",
    "descriptor": "\nComments: Proceedings of the 39th International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Keiichiro Yamamura",
      "Haruki Sato",
      "Nariaki Tateiwa",
      "Nozomi Hata",
      "Toru Mitsutake",
      "Issa Oe",
      "Hiroki Ishikura",
      "Katsuki Fujisawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09628"
  },
  {
    "id": "arXiv:2206.13228",
    "title": "NLTS Hamiltonians from good quantum codes",
    "abstract": "Comments: 12 pages, 1 figure, added funding information and discussions",
    "descriptor": "\nComments: 12 pages, 1 figure, added funding information and discussions\n",
    "authors": [
      "Anurag Anshu",
      "Nikolas P. Breuckmann",
      "Chinmay Nirkhe"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.13228"
  },
  {
    "id": "arXiv:2206.14180",
    "title": "High-Resolution Virtual Try-On with Misalignment and Occlusion-Handled  Conditions",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Sangyun Lee",
      "Gyojung Gu",
      "Sunghyun Park",
      "Seunghwan Choi",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14180"
  },
  {
    "id": "arXiv:2207.00974",
    "title": "NARRATE: A Normal Assisted Free-View Portrait Stylizer",
    "abstract": "Comments: 14 pages,13 figures this https URL",
    "descriptor": "\nComments: 14 pages,13 figures this https URL\n",
    "authors": [
      "Youjia Wang",
      "Teng Xu",
      "Yiwen Wu",
      "Minzhang Li",
      "Wenzheng Chen",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.00974"
  },
  {
    "id": "arXiv:2207.01322",
    "title": "Harmonizer: Learning to Perform White-Box Image and Video Harmonization",
    "abstract": "Harmonizer: Learning to Perform White-Box Image and Video Harmonization",
    "descriptor": "",
    "authors": [
      "Zhanghan Ke",
      "Chunyi Sun",
      "Lei Zhu",
      "Ke Xu",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.01322"
  },
  {
    "id": "arXiv:2207.01375",
    "title": "GraphVid: It Only Takes a Few Nodes to Understand a Video",
    "abstract": "Comments: Accepted to ECCV2022 (Oral)",
    "descriptor": "\nComments: Accepted to ECCV2022 (Oral)\n",
    "authors": [
      "Eitan Kosman",
      "Dotan Di Castro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.01375"
  },
  {
    "id": "arXiv:2207.01975",
    "title": "Federated Self-supervised Learning for Video Understanding",
    "abstract": "Federated Self-supervised Learning for Video Understanding",
    "descriptor": "",
    "authors": [
      "Yasar Abbas Ur Rehman",
      "Yan Gao",
      "Jiajun Shen",
      "Pedro Porto Buarque de Gusmao",
      "Nicholas Lane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.01975"
  },
  {
    "id": "arXiv:2207.02192",
    "title": "CEN : Cooperatively Evolving Networks",
    "abstract": "CEN : Cooperatively Evolving Networks",
    "descriptor": "",
    "authors": [
      "Ch. Sobhan Babu",
      "Ravindra Guravannavar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02192"
  },
  {
    "id": "arXiv:2207.02375",
    "title": "3DG-STFM: 3D Geometric Guided Student-Teacher Feature Matching",
    "abstract": "3DG-STFM: 3D Geometric Guided Student-Teacher Feature Matching",
    "descriptor": "",
    "authors": [
      "Runyu Mao",
      "Chen Bai",
      "Yatong An",
      "Fengqing Zhu",
      "Cheng Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.02375"
  },
  {
    "id": "arXiv:2207.02466",
    "title": "GLENet: Boosting 3D Object Detectors with Generative Label Uncertainty  Estimation",
    "abstract": "GLENet: Boosting 3D Object Detectors with Generative Label Uncertainty  Estimation",
    "descriptor": "",
    "authors": [
      "Yifan Zhang",
      "Qijian Zhang",
      "Zhiyu Zhu",
      "Junhui Hou",
      "Yixuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.02466"
  },
  {
    "id": "arXiv:2207.03401",
    "title": "Minimum $2$-edge strongly biconnected spanning directed subgraph problem",
    "abstract": "Minimum $2$-edge strongly biconnected spanning directed subgraph problem",
    "descriptor": "",
    "authors": [
      "Raed Jaberi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.03401"
  },
  {
    "id": "arXiv:2207.04680",
    "title": "Towards Scale-Aware, Robust, and Generalizable Unsupervised Monocular  Depth Estimation by Integrating IMU Motion Dynamics",
    "abstract": "Comments: Accepted to ECCV 2022. Code is released at this https URL",
    "descriptor": "\nComments: Accepted to ECCV 2022. Code is released at this https URL\n",
    "authors": [
      "Sen Zhang",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04680"
  },
  {
    "id": "arXiv:2207.04788",
    "title": "DCCF: Deep Comprehensible Color Filter Learning Framework for  High-Resolution Image Harmonization",
    "abstract": "Comments: ECCV 2022 (Oral)",
    "descriptor": "\nComments: ECCV 2022 (Oral)\n",
    "authors": [
      "Ben Xue",
      "Shenghui Ran",
      "Quan Chen",
      "Rongfei Jia",
      "Binqiang Zhao",
      "Xing Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.04788"
  },
  {
    "id": "arXiv:2207.05407",
    "title": "Hennessy-Milner Theorems via Galois Connections",
    "abstract": "Hennessy-Milner Theorems via Galois Connections",
    "descriptor": "",
    "authors": [
      "Harsh Beohar",
      "Sebastian Gurke",
      "Barbara K\u00f6nig",
      "Karla Messing"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.05407"
  },
  {
    "id": "arXiv:2207.05444",
    "title": "Category-Level 6D Object Pose and Size Estimation using Self-Supervised  Deep Prior Deformation Networks",
    "abstract": "Comments: Accepted by ECCV2022",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Jiehong Lin",
      "Zewei Wei",
      "Changxing Ding",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.05444"
  },
  {
    "id": "arXiv:2207.05509",
    "title": "Hybrid Physical-Neural ODEs for Fast N-body Simulations",
    "abstract": "Comments: Accepted at the ICML 2022 Workshop on Machine Learning for Astrophysics. Updated version with link to the source code",
    "descriptor": "\nComments: Accepted at the ICML 2022 Workshop on Machine Learning for Astrophysics. Updated version with link to the source code\n",
    "authors": [
      "Denise Lanzieri",
      "Fran\u00e7ois Lanusse",
      "Jean-Luc Starck"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05509"
  },
  {
    "id": "arXiv:2207.06087",
    "title": "Storage and Retrieval Codes in Star Product PIR Schemes with Colluding  Servers",
    "abstract": "Comments: 24 pages,PIR schemes with the storage code and the retrieval code in the same family of algebraic codes seem not always efficient. arXiv admin note: text overlap with arXiv:2207.03163",
    "descriptor": "\nComments: 24 pages,PIR schemes with the storage code and the retrieval code in the same family of algebraic codes seem not always efficient. arXiv admin note: text overlap with arXiv:2207.03163\n",
    "authors": [
      "Hao Chen",
      "Liqing Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.06087"
  },
  {
    "id": "arXiv:2207.06095",
    "title": "Eliminating Gradient Conflict in Reference-based Line-Art Colorization",
    "abstract": "Comments: Accepted by ECCV2022",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Zekun Li",
      "Zhengyang Geng",
      "Zhao Kang",
      "Wenyu Chen",
      "Yibo Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06095"
  },
  {
    "id": "arXiv:2207.06503",
    "title": "Randomly pivoted Cholesky: Practical approximation of a kernel matrix  with few entry evaluations",
    "abstract": "Comments: 28 pages, 4 figures",
    "descriptor": "\nComments: 28 pages, 4 figures\n",
    "authors": [
      "Yifan Chen",
      "Ethan N. Epperly",
      "Joel A. Tropp",
      "Robert J. Webber"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.06503"
  },
  {
    "id": "arXiv:2207.06819",
    "title": "Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks",
    "abstract": "Anomal-E: A Self-Supervised Network Intrusion Detection System based on  Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Evan Caville",
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.06819"
  },
  {
    "id": "arXiv:2207.06926",
    "title": "Double Loop Monte Carlo Estimator with Importance Sampling for  McKean-Vlasov Stochastic Differential Equation",
    "abstract": "Double Loop Monte Carlo Estimator with Importance Sampling for  McKean-Vlasov Stochastic Differential Equation",
    "descriptor": "",
    "authors": [
      "Nadhir Ben Rached",
      "Abdul-Lateef Haji-Ali",
      "Shyam Mohan",
      "Ra\u00fal Tempone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.06926"
  },
  {
    "id": "arXiv:2207.07755",
    "title": "Carleman Linearization of Nonlinear Systems and Its Finite-Section  Approximations",
    "abstract": "Comments: 25 Pages, 10 figures",
    "descriptor": "\nComments: 25 Pages, 10 figures\n",
    "authors": [
      "Arash Amini",
      "Cong Zheng",
      "Qiyu Sun",
      "Nader Motee"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.07755"
  },
  {
    "id": "arXiv:2207.07823",
    "title": "DB-LSH: Locality-Sensitive Hashing with Query-based Dynamic Bucketing",
    "abstract": "Comments: Accepted by ICDE 2022",
    "descriptor": "\nComments: Accepted by ICDE 2022\n",
    "authors": [
      "Yao Tian",
      "Xi Zhao",
      "Xiaofang Zhou"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.07823"
  },
  {
    "id": "arXiv:2207.07861",
    "title": "TransGrasp: Grasp Pose Estimation of a Category of Objects by  Transferring Grasps from Only One Labeled Instance",
    "abstract": "Comments: Accepted to European Conference on Computer Vision (ECCV) 2022",
    "descriptor": "\nComments: Accepted to European Conference on Computer Vision (ECCV) 2022\n",
    "authors": [
      "Hongtao Wen",
      "Jianhang Yan",
      "Wanli Peng",
      "Yi Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.07861"
  },
  {
    "id": "arXiv:2207.08000",
    "title": "DiffuStereo: High Quality Human Reconstruction via Diffusion-based  Stereo Using Sparse Cameras",
    "abstract": "Comments: Accepted by ECCV2022",
    "descriptor": "\nComments: Accepted by ECCV2022\n",
    "authors": [
      "Ruizhi Shao",
      "Zerong Zheng",
      "Hongwen Zhang",
      "Jingxiang Sun",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08000"
  },
  {
    "id": "arXiv:2207.08017",
    "title": "Is Soccer a lie or simply a complex system?",
    "abstract": "Comments: 15 pages, in Spanish language, 6 Figures",
    "descriptor": "\nComments: 15 pages, in Spanish language, 6 Figures\n",
    "authors": [
      "Nelson Fernandez",
      "Ricardo Bernal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.08017"
  },
  {
    "id": "arXiv:2207.08040",
    "title": "Reinforcement Learning For Survival, A Clinically Motivated Method For  Critically Ill Patients",
    "abstract": "Reinforcement Learning For Survival, A Clinically Motivated Method For  Critically Ill Patients",
    "descriptor": "",
    "authors": [
      "Thesath Nanayakkara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.08040"
  },
  {
    "id": "arXiv:2207.08141",
    "title": "ELECTRA is a Zero-Shot Learner, Too",
    "abstract": "Comments: The source code is available at: this https URL",
    "descriptor": "\nComments: The source code is available at: this https URL\n",
    "authors": [
      "Shiwen Ni",
      "Hung-Yu Kao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.08141"
  },
  {
    "id": "arXiv:2207.08435",
    "title": "Robust Simulation-Based Inference in Cosmology with Bayesian Neural  Networks",
    "abstract": "Comments: 5 pages, 3 figures. Accepted at the ML4Astro Machine Learning for Astrophysics Workshop at the Thirty-ninth International Conference on Machine Learning (ICML 2022)",
    "descriptor": "\nComments: 5 pages, 3 figures. Accepted at the ML4Astro Machine Learning for Astrophysics Workshop at the Thirty-ninth International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Pablo Lemos",
      "Miles Cranmer",
      "Muntazir Abidi",
      "ChangHoon Hahn",
      "Michael Eickenberg",
      "Elena Massara",
      "David Yallup",
      "Shirley Ho"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08435"
  },
  {
    "id": "arXiv:2207.08609",
    "title": "ExAgt: Expert-guided Augmentation for Representation Learning of Traffic  Scenarios",
    "abstract": "Comments: Accepted as a conference paper in ITSC 2022, Macau, China",
    "descriptor": "\nComments: Accepted as a conference paper in ITSC 2022, Macau, China\n",
    "authors": [
      "Lakshman Balasubramanian",
      "Jonas Wurst",
      "Robin Egolf",
      "Michael Botsch",
      "Wolfgang Utschick",
      "Ke Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08609"
  },
  {
    "id": "arXiv:2207.08782",
    "title": "Instance-Aware Observer Network for Out-of-Distribution Object  Segmentation",
    "abstract": "Instance-Aware Observer Network for Out-of-Distribution Object  Segmentation",
    "descriptor": "",
    "authors": [
      "Victor Besnier",
      "Andrei Bursuc",
      "David Picard",
      "Alexandre Briot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08782"
  },
  {
    "id": "arXiv:2207.08824",
    "title": "3D Equivariant Molecular Graph Pretraining",
    "abstract": "3D Equivariant Molecular Graph Pretraining",
    "descriptor": "",
    "authors": [
      "Rui Jiao",
      "Jiaqi Han",
      "Wenbing Huang",
      "Yu Rong",
      "Yang Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08824"
  },
  {
    "id": "arXiv:2207.08978",
    "title": "A Security & Privacy Analysis of US-based Contact Tracing Apps",
    "abstract": "A Security & Privacy Analysis of US-based Contact Tracing Apps",
    "descriptor": "",
    "authors": [
      "Joydeep Mitra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.08978"
  },
  {
    "id": "arXiv:2207.09021",
    "title": "Actionable and Interpretable Fault Localization for Recurring Failures  in Online Service Systems",
    "abstract": "Comments: Accepted by ESEC/FSE 2022. This is the peer-review version and further changes will be made",
    "descriptor": "\nComments: Accepted by ESEC/FSE 2022. This is the peer-review version and further changes will be made\n",
    "authors": [
      "Zeyan Li",
      "Nengwen Zhao",
      "Mingjie Li",
      "Xianglin Lu",
      "Lixin Wang",
      "Dongdong Chang",
      "Xiaohui Nie",
      "Li Cao",
      "Wenzhi Zhang",
      "Kaixin Sui",
      "Yanhua Wang",
      "Xu Du",
      "Guoqiang Duan",
      "Dan Pei"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.09021"
  },
  {
    "id": "arXiv:2207.09050",
    "title": "Don't Forget to Buy Milk: Contextually Aware Grocery Reminder Household  Robot",
    "abstract": "Comments: Accepted at IEEE ICDL 2022",
    "descriptor": "\nComments: Accepted at IEEE ICDL 2022\n",
    "authors": [
      "Ali Ayub",
      "Chrystopher L. Nehaniv",
      "Kerstin Dautenhahn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09050"
  },
  {
    "id": "arXiv:2207.09068",
    "title": "PiC: A Phrase-in-Context Dataset for Phrase Understanding and Semantic  Search",
    "abstract": "Comments: 25 pages, 12 figures",
    "descriptor": "\nComments: 25 pages, 12 figures\n",
    "authors": [
      "Thang M. Pham",
      "Seunghyun Yoon",
      "Trung Bui",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09068"
  },
  {
    "id": "arXiv:2207.09071",
    "title": "Learning Action Translator for Meta Reinforcement Learning on  Sparse-Reward Tasks",
    "abstract": "Comments: Published in AAAI 2022",
    "descriptor": "\nComments: Published in AAAI 2022\n",
    "authors": [
      "Yijie Guo",
      "Qiucheng Wu",
      "Honglak Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09071"
  },
  {
    "id": "arXiv:2207.09108",
    "title": "eCDT: Event Clustering for Simultaneous Feature Detection and Tracking-",
    "abstract": "Comments: IROS2022 accepted paper",
    "descriptor": "\nComments: IROS2022 accepted paper\n",
    "authors": [
      "Sumin Hu",
      "Yeeun Kim",
      "Hyungtae Lim",
      "Alex Junho Lee",
      "Hyun Myung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09108"
  },
  {
    "id": "arXiv:2207.09120",
    "title": "Expert-LaSTS: Expert-Knowledge Guided Latent Space for Traffic Scenarios",
    "abstract": "Comments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Jonas Wurst",
      "Lakshman Balasubramanian",
      "Michael Botsch",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09120"
  },
  {
    "id": "arXiv:2207.09209",
    "title": "FLDetector: Defending Federated Learning Against Model Poisoning Attacks  via Detecting Malicious Clients",
    "abstract": "Comments: Accepted by KDD 2022 (Research Track)",
    "descriptor": "\nComments: Accepted by KDD 2022 (Research Track)\n",
    "authors": [
      "Zaixi Zhang",
      "Xiaoyu Cao",
      "Jinayuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09209"
  },
  {
    "id": "arXiv:2207.09248",
    "title": "Don't Stop Learning: Towards Continual Learning for the CLIP Model",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Yuxuan Ding",
      "Lingqiao Liu",
      "Chunna Tian",
      "Jingyuan Yang",
      "Haoxuan Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09248"
  },
  {
    "id": "arXiv:2207.09332",
    "title": "Rethinking IoU-based Optimization for Single-stage 3D Object Detection",
    "abstract": "Comments: Accepted by ECCV2022. The code is available at this https URL",
    "descriptor": "\nComments: Accepted by ECCV2022. The code is available at this https URL\n",
    "authors": [
      "Hualian Sheng",
      "Sijia Cai",
      "Na Zhao",
      "Bing Deng",
      "Jianqiang Huang",
      "Xian-Sheng Hua",
      "Min-Jian Zhao",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09332"
  },
  {
    "id": "arXiv:2207.09370",
    "title": "Data-Centric Epidemic Forecasting: A Survey",
    "abstract": "Comments: 67 pages, 12 figures",
    "descriptor": "\nComments: 67 pages, 12 figures\n",
    "authors": [
      "Alexander Rodr\u00edguez",
      "Harshavardhan Kamarthi",
      "Pulak Agarwal",
      "Javen Ho",
      "Mira Patel",
      "Suchet Sapre",
      "B. Aditya Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2207.09370"
  }
]
[
  {
    "id": "arXiv:2109.04470",
    "title": "Truth Discovery in Sequence Labels from Crowds",
    "abstract": "Annotations quality and quantity positively affect the performance of\nsequence labeling, a vital task in Natural Language Processing. Hiring domain\nexperts to annotate a corpus set is very costly in terms of money and time.\nCrowdsourcing platforms, such as Amazon Mechanical Turk (AMT), have been\ndeployed to assist in this purpose. However, these platforms are prone to human\nerrors due to the lack of expertise; hence, one worker's annotations cannot be\ndirectly used to train the model. Existing literature in annotation aggregation\nmore focuses on binary or multi-choice problems. In recent years, handling the\nsequential label aggregation tasks on imbalanced datasets with complex\ndependencies between tokens has been challenging. To conquer the challenge, we\npropose an optimization-based method that infers the best set of aggregated\nannotations using labels provided by workers. The proposed Aggregation method\nfor Sequential Labels from Crowds ($AggSLC$) jointly considers the\ncharacteristics of sequential labeling tasks, workers' reliabilities, and\nadvanced machine learning techniques. We evaluate $AggSLC$ on different\ncrowdsourced data for Named Entity Recognition (NER), Information Extraction\ntasks in biomedical (PICO), and the simulated dataset. Our results show that\nthe proposed method outperforms the state-of-the-art aggregation methods. To\nachieve insights into the framework, we study $AggSLC$ components'\neffectiveness through ablation studies by evaluating our model in the absence\nof the prediction module and inconsistency loss function. Theoretical analysis\nof our algorithm's convergence points that the proposed $AggSLC$ halts after a\nfinite number of iterations.",
    "descriptor": "",
    "authors": [
      "Nasim Sabetpour",
      "Adithya Kulkarni",
      "Sihong Xie",
      "Qi Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04470"
  },
  {
    "id": "arXiv:2109.04500",
    "title": "Semantic Parsing in Task-Oriented Dialog with Recursive Insertion-based  Encoder",
    "abstract": "We introduce a Recursive INsertion-based Encoder (RINE), a novel approach for\nsemantic parsing in task-oriented dialog. Our model consists of an encoder\nnetwork that incrementally builds the semantic parse tree by predicting the\nnon-terminal label and its positions in the linearized tree. At the generation\ntime, the model constructs the semantic parse tree by recursively inserting the\npredicted non-terminal labels at the predicted positions until termination.\nRINE achieves state-of-the-art exact match accuracy on low- and high-resource\nversions of the conversational semantic parsing benchmark TOP (Gupta et al.,\n2018; Chen et al., 2020), outperforming strong sequence-to-sequence models and\ntransition-based parsers. We also show that our model design is applicable to\nnested named entity recognition task, where it performs on par with\nstate-of-the-art approach designed for that task. Finally, we demonstrate that\nour approach is 2-3.5 times faster than the sequence-to-sequence model at\ninference time.",
    "descriptor": "",
    "authors": [
      "Elman Mansimov",
      "Yi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04500"
  },
  {
    "id": "arXiv:2109.04502",
    "title": "BDPGO: Balanced Distributed Pose Graph Optimization Framework for Swarm  Robotics",
    "abstract": "Distributed pose graph optimization (DPGO) is one of the fundamental\ntechniques of swarm robotics. Currently, the sub-problems of DPGO are built on\nthe native poses. Our validation proves that this approach may introduce an\nimbalance in the sizes of the sub-problems in real-world scenarios, which\naffects the speed of DPGO optimization, and potentially increases communication\nrequirements. In addition, the coherence of the estimated poses is not\nguaranteed when the robots in the swarm fail, or partial robots are\ndisconnected. In this paper, we propose BDPGO, a balanced distributed pose\ngraph optimization framework using the idea of decoupling the robot poses and\nDPGO. BDPGO re-distributes the poses in the pose graph to the robot swarm in a\nbalanced way by introducing a two-stage graph partitioning method to build\nbalanced subproblems. Our validation demonstrates that BDPGO significantly\nimproves the optimization speed without changing the specific algorithm of DPGO\nin realistic datasets. What's more, we also validate that BDPGO is robust to\nrobot failure, changes in the wireless network. BDPGO has capable of keeps the\ncoherence of the estimated poses in these situations. The framework also has\nthe potential to be applied to other collaborative simultaneous localization\nand mapping (CSLAM) problems involved in distributedly solving the factor\ngraph.",
    "descriptor": "\nComments: Submitted to IEEE Robotics and Automation Letters (RA-L) with ICRA 2022\n",
    "authors": [
      "Hao Xu",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04502"
  },
  {
    "id": "arXiv:2109.04504",
    "title": "Bootstrapped Meta-Learning",
    "abstract": "Meta-learning empowers artificial intelligence to increase its efficiency by\nlearning how to learn. Unlocking this potential involves overcoming a\nchallenging meta-optimisation problem that often exhibits ill-conditioning, and\nmyopic meta-objectives. We propose an algorithm that tackles these issues by\nletting the meta-learner teach itself. The algorithm first bootstraps a target\nfrom the meta-learner, then optimises the meta-learner by minimising the\ndistance to that target under a chosen (pseudo-)metric. Focusing on\nmeta-learning with gradients, we establish conditions that guarantee\nperformance improvements and show that the improvement is related to the target\ndistance. Thus, by controlling curvature, the distance measure can be used to\nease meta-optimization, for instance by reducing ill-conditioning. Further, the\nbootstrapping mechanism can extend the effective meta-learning horizon without\nrequiring backpropagation through all updates. The algorithm is versatile and\neasy to implement. We achieve a new state-of-the art for model-free agents on\nthe Atari ALE benchmark, improve upon MAML in few-shot learning, and\ndemonstrate how our approach opens up new possibilities by meta-learning\nefficient exploration in a Q-learning agent.",
    "descriptor": "\nComments: 31 pages, 19 figures, 7 tables\n",
    "authors": [
      "Sebastian Flennerhag",
      "Yannick Schroecker",
      "Tom Zahavy",
      "Hado van Hasselt",
      "David Silver",
      "Satinder Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04504"
  },
  {
    "id": "arXiv:2109.04507",
    "title": "Scrutinizing uncitedness of selective Indian physics and astronomy  journals through the prism of some h-type indicators",
    "abstract": "There exist huge chunk of academic items receiving no citation years after\nyears and remaining beyond the veil of ignorance of the academic audience.\nThese are known as uncited items. Now, the question is, why a paper fails to\nget citation? The attribute of incapability of receiving citation may be termed\nas Uncitedness. This paper traces brief history of the concept of uncitedness\nsprouted first in 1964 in an article entitled Cybernetics, homeostasis and a\nmodel of disease by Gerson Jacobs. The concept of uncitedness was\nscientometrically first explained by Garfield in 1970. The uncitedness of\ntwelve esteemed Indian physics and astronomy journals over a twelve years'\n(2009-2020) time span is analysed here. Besides Uncitedness Factor (UF), three\nother indicators are introduced here, viz. Citation per paper per Year (CY),\nh-core Density (HD) and Time-normalised h-index (TH). The journal-wise\nvariational patterns of these four indicators, i.e. UF, CY, HD and TH and the\nrelationships of UF with other three indicators are analysed. The calculated\nnumerical values of these indicators are observed to formulate seven\nhypotheses, which are tested by F-Test method. The average annual rate of\nchange of uncited paper is found 67% of total number of papers. The indicator\nCY is found temporally constant. The indicator HD is found nearly constant\njournal-wise over the entire time span, while the indicator TH is found nearly\nconstant for all journals. The UF inversely varies with CY and TH for the\njournals and directly varies with TH over the years. Except few highly reputed\nIndian journals in physics and astronomy, majority other journals face the\nsituation of uncitedness. The uncitedness of Indian journals in this field\noutshines the same for global journals by 12%, which indicates lack of\ncirculation and timely reach of research communication to the relevant\naudience.",
    "descriptor": "\nComments: 22 pages, 3 Figures\n",
    "authors": [
      "Amit Kumar Das",
      "Bidyarthi Dutta"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2109.04507"
  },
  {
    "id": "arXiv:2109.04513",
    "title": "Filling the Gaps in Ancient Akkadian Texts: A Masked Language Modelling  Approach",
    "abstract": "We present models which complete missing text given transliterations of\nancient Mesopotamian documents, originally written on cuneiform clay tablets\n(2500 BCE - 100 CE). Due to the tablets' deterioration, scholars often rely on\ncontextual cues to manually fill in missing parts in the text in a subjective\nand time-consuming process. We identify that this challenge can be formulated\nas a masked language modelling task, used mostly as a pretraining objective for\ncontextualized language models. Following, we develop several architectures\nfocusing on the Akkadian language, the lingua franca of the time. We find that\ndespite data scarcity (1M tokens) we can achieve state of the art performance\non missing tokens prediction (89% hit@5) using a greedy decoding scheme and\npretraining on data from other languages and different time periods. Finally,\nwe conduct human evaluations showing the applicability of our models in\nassisting experts to transcribe texts in extinct languages.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 (Main Conference)\n",
    "authors": [
      "Koren Lazar",
      "Benny Saret",
      "Asaf Yehudai",
      "Wayne Horowitz",
      "Nathan Wasserman",
      "Gabriel Stanovsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04513"
  },
  {
    "id": "arXiv:2109.04516",
    "title": "Robust Impedance Control for Dexterous Interaction Using Fractal  Impedance Controller with IK-Optimisation",
    "abstract": "Robust dynamic interactions are required to move robots in daily environments\nalongside humans. Optimisation and learning methods have been used to mimic and\nreproduce human movements. However, they are often not robust and their\ngeneralisation is limited. This work proposed a hierarchical control\narchitecture for robot manipulators and provided capabilities of reproducing\nhuman-like motions during unknown interaction dynamics. Our results show that\nthe reproduced end-effector trajectories can preserve the main characteristics\nof the initial human motion recorded via a motion capture system, and are\nrobust against external perturbations. The data indicate that some detailed\nmovements are hard to reproduce due to the physical limits of the hardware that\ncannot reach the same velocity recorded in human movements. Nevertheless, these\ntechnical problems can be addressed by using better hardware and our proposed\nalgorithms can still be applied to produce imitated motions.",
    "descriptor": "",
    "authors": [
      "Carlo Tiseo",
      "Quentin Rouxel",
      "Zhibin Li",
      "Michael Mistry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04516"
  },
  {
    "id": "arXiv:2109.04517",
    "title": "Prediction and Prevention of Pandemics via Graphical Model Inference and  Convex Programming",
    "abstract": "Hard-to-predict bursts of COVID-19 pandemic revealed significance of\nstatistical modeling which would resolve spatio-temporal correlations over\ngeographical areas, for example spread of the infection over a city with census\ntract granularity. In this manuscript, we provide algorithmic answers to the\nfollowing two inter-related public health challenges. (1) Inference Challenge:\nassuming that there are $N$ census blocks (nodes) in the city, and given an\ninitial infection at any set of nodes, what is the probability for a subset of\ncensus blocks to become infected by the time the spread of the infection burst\nis stabilized? (2) Prevention Challenge: What is the minimal control action one\ncan take to minimize the infected part of the stabilized state footprint? To\nanswer the challenges, we build a Graphical Model of pandemic of the attractive\nIsing (pair-wise, binary) type, where each node represents a census track and\neach edge factor represents the strength of the pairwise interaction between a\npair of nodes. We show that almost all attractive Ising Models on dense graphs\nresult in either of the two modes for the most probable state: either all nodes\nwhich were not infected initially became infected, or all the initially\nuninfected nodes remain uninfected. This bi-modal solution of the Inference\nChallenge allows us to re-state the Prevention Challenge as the following\ntractable convex programming: for the bare Ising Model with pair-wise and bias\nfactors representing the system without prevention measures, such that the MAP\nstate is fully infected for at least one of the initial infection patterns,\nfind the closest, in $l_1$ norm, set of factors resulting in all the MAP states\nof the Ising model, with the optimal prevention measures applied, to become\nsafe.",
    "descriptor": "",
    "authors": [
      "Mikhail Krechetov",
      "Amir Mohammad Esmaieeli Sikaroudi",
      "Alon Efrat",
      "Valentin Polishchuk",
      "Michael Chertkov"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.04517"
  },
  {
    "id": "arXiv:2109.04518",
    "title": "Unsupervised Causal Binary Concepts Discovery with VAE for Black-box  Model Explanation",
    "abstract": "We aim to explain a black-box classifier with the form: `data X is classified\nas class Y because X \\textit{has} A, B and \\textit{does not have} C' in which\nA, B, and C are high-level concepts. The challenge is that we have to discover\nin an unsupervised manner a set of concepts, i.e., A, B and C, that is useful\nfor the explaining the classifier. We first introduce a structural generative\nmodel that is suitable to express and discover such concepts. We then propose a\nlearning process that simultaneously learns the data distribution and\nencourages certain concepts to have a large causal influence on the classifier\noutput. Our method also allows easy integration of user's prior knowledge to\ninduce high interpretability of concepts. Using multiple datasets, we\ndemonstrate that our method can discover useful binary concepts for\nexplanation.",
    "descriptor": "",
    "authors": [
      "Thien Q. Tran",
      "Kazuto Fukuchi",
      "Youhei Akimoto",
      "Jun Sakuma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04518"
  },
  {
    "id": "arXiv:2109.04524",
    "title": "Fine Manipulation and Dynamic Interaction in Haptic Teleoperation",
    "abstract": "Teleoperation of robots enables remote intervention in distant and dangerous\ntasks without putting the operator in harm's way. However, remote operation\nfaces fundamental challenges due to limits in communication delay and\nbandwidth. The proposed work improves the performances of teleoperation\narchitecture based on Fractal Impedance Controller (FIC), by integrating the\nmost recent manipulation architecture in the haptic teleoperation pipeline. The\nupdated controller takes advantage of the inverse kinematics optimisation in\nthe manipulation, and hence improves dynamic interactions during fine\nmanipulation without renouncing the robustness of the FIC controller.\nAdditionally, the proposed method allows an online trade-off between the\nmanipulation controller and the teleoperated behaviour, allowing a safe\nsuperimposition of these two behaviours. The validated experimental results\nshow that the proposed method is robust to reduced communication bandwidth and\ndelays. Moreover, we demonstrated that the remote teleoperated robot remains\nstable and safe to interact with, even when the communication with the master\nside is abruptly interrupted.",
    "descriptor": "",
    "authors": [
      "Carlo Tiseo",
      "Quentin Rouxel",
      "Zhibin Li",
      "Michael Mistry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04524"
  },
  {
    "id": "arXiv:2109.04525",
    "title": "Sharper bounds on the Fourier concentration of DNFs",
    "abstract": "In 1992 Mansour proved that every size-$s$ DNF formula is\nFourier-concentrated on $s^{O(\\log\\log s)}$ coefficients. We improve this to\n$s^{O(\\log\\log k)}$ where $k$ is the read number of the DNF. Since $k$ is\nalways at most $s$, our bound matches Mansour's for all DNFs and strengthens it\nfor small-read ones. The previous best bound for read-$k$ DNFs was\n$s^{O(k^{3/2})}$. For $k$ up to $\\tilde{\\Theta}(\\log\\log s)$, we further\nimprove our bound to the optimal $\\mathrm{poly}(s)$; previously no such bound\nwas known for any $k = \\omega_s(1)$.\nOur techniques involve new connections between the term structure of a DNF,\nviewed as a set system, and its Fourier spectrum.",
    "descriptor": "\nComments: 19 pages; to appear at FOCS 2021\n",
    "authors": [
      "Victor Lecomte",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.04525"
  },
  {
    "id": "arXiv:2109.04527",
    "title": "CrowdDriven: A New Challenging Dataset for Outdoor Visual Localization",
    "abstract": "Visual localization is the problem of estimating the position and orientation\nfrom which a given image (or a sequence of images) is taken in a known scene.\nIt is an important part of a wide range of computer vision and robotics\napplications, from self-driving cars to augmented/virtual reality systems.\nVisual localization techniques should work reliably and robustly under a wide\nrange of conditions, including seasonal, weather, illumination and man-made\nchanges. Recent benchmarking efforts model this by providing images under\ndifferent conditions, and the community has made rapid progress on these\ndatasets since their inception. However, they are limited to a few geographical\nregions and often recorded with a single device. We propose a new benchmark for\nvisual localization in outdoor scenes, using crowd-sourced data to cover a wide\nrange of geographical regions and camera devices with a focus on the failure\ncases of current algorithms. Experiments with state-of-the-art localization\napproaches show that our dataset is very challenging, with all evaluated\nmethods failing on its hardest parts. As part of the dataset release, we\nprovide the tooling used to generate it, enabling efficient and effective 2D\ncorrespondence annotation to obtain reference poses.",
    "descriptor": "",
    "authors": [
      "Ara Jafarzadeh",
      "Manuel Lopez Antequera",
      "Pau Gargallo",
      "Yubin Kuang",
      "Carl Toft",
      "Fredrik Kahl",
      "Torsten Sattler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04527"
  },
  {
    "id": "arXiv:2109.04529",
    "title": "Parameterized inapproximability of Morse matching",
    "abstract": "We study the problem of minimizing the number of critical simplices from the\npoint of view of inapproximability and parameterized complexity. We first show\ninapproximability of Min-Morse Matching within a factor of\n$2^{\\log^{(1-\\epsilon)}n}$. Our second result shows that Min-Morse Matching is\n${\\bf W{[P]}}$-hard with respect to the standard parameter. Next, we show that\nMin-Morse Matching with standard parameterization has no FPT approximation\nalgorithm for any approximation factor $\\rho$. The above hardness results are\napplicable to complexes of dimension $\\ge 2$.\nOn the positive side, we provide a factor $O(\\frac{n}{\\log n})$ approximation\nalgorithm for Min-Morse Matching on $2$-complexes, noting that no such\nalgorithm is known for higher dimensional complexes. Finally, we devise\ndiscrete gradients with very few critical simplices for typical instances drawn\nfrom a fairly wide range of parameter values of the Costa-Farber model of\nrandom complexes.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Ulrich Bauer",
      "Abhishek Rathod"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.04529"
  },
  {
    "id": "arXiv:2109.04530",
    "title": "Notes on Generalizing the Maximum Entropy Principle to Uncertain Data",
    "abstract": "The principle of maximum entropy is a broadly applicable technique for\ncomputing a distribution with the least amount of information possible while\ncommonly constrained to match empirically estimated feature expectations. We\nseek to generalize this principle to scenarios where the empirical feature\nexpectations cannot be computed because the model variables are only partially\nobserved, which introduces a dependency on the learned model. Extending and\ngeneralizing the principle of latent maximum entropy, we introduce uncertain\nmaximum entropy and describe an expectation-maximization based solution to\napproximately solve these problems. We show that our technique generalizes the\nprinciple of maximum entropy and latent maximum entropy and discuss a generally\napplicable regularization technique for adding error terms to feature\nexpectation constraints in the event of limited data.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Kenneth Bogert"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04530"
  },
  {
    "id": "arXiv:2109.04532",
    "title": "3D Real-Time Supercomputer Monitoring",
    "abstract": "Supercomputers are complex systems producing vast quantities of performance\ndata from multiple sources and of varying types. Performance data from each of\nthe thousands of nodes in a supercomputer tracks multiple forms of storage,\nmemory, networks, processors, and accelerators. Optimization of application\nperformance is critical for cost effective usage of a supercomputer and\nrequires efficient methods for effectively viewing performance data. The\ncombination of supercomputing analytics and 3D gaming visualization enables\nreal-time processing and visual data display of massive amounts of information\nthat humans can process quickly with little training. Our system fully utilizes\nthe capabilities of modern 3D gaming environments to create novel\nrepresentations of computing hardware which intuitively represent the physical\nattributes of the supercomputer while displaying real-time alerts and component\nutilization. This system allows operators to quickly assess how the\nsupercomputer is being used, gives users visibility into the resources they are\nconsuming, and provides instructors new ways to interactively teach the\ncomputing architecture concepts necessary for efficient computing",
    "descriptor": "",
    "authors": [
      "Bill Bergeron",
      "Matthew Hubbell",
      "Dylan Sequeira",
      "Winter Williams",
      "William Arcand",
      "David Bestor",
      "Chansup",
      "Byun",
      "Vijay Gadepally",
      "Michael Houle",
      "Michael Jones",
      "Anna Klien",
      "Peter Michaleas",
      "Lauren Milechin",
      "Julie Mullen Andrew Prout",
      "Albert Reuther",
      "Antonio Rosa",
      "Siddharth Samsi",
      "Charles Yee",
      "Jeremy Kepner"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.04532"
  },
  {
    "id": "arXiv:2109.04533",
    "title": "FedCon: A Contrastive Framework for Federated Semi-Supervised Learning",
    "abstract": "Federated Semi-Supervised Learning (FedSSL) has gained rising attention from\nboth academic and industrial researchers, due to its unique characteristics of\nco-training machine learning models with isolated yet unlabeled data. Most\nexisting FedSSL methods focus on the classical scenario, i.e, the labeled and\nunlabeled data are stored at the client side. However, in real world\napplications, client users may not provide labels without any incentive. Thus,\nthe scenario of labels at the server side is more practical. Since unlabeled\ndata and labeled data are decoupled, most existing FedSSL approaches may fail\nto deal with such a scenario. To overcome this problem, in this paper, we\npropose FedCon, which introduces a new learning paradigm, i.e., contractive\nlearning, to FedSSL. Experimental results on three datasets show that FedCon\nachieves the best performance with the contractive framework compared with\nstate-of-the-art baselines under both IID and Non-IID settings. Besides,\nablation studies demonstrate the characteristics of the proposed FedCon\nframework.",
    "descriptor": "",
    "authors": [
      "Zewei Long",
      "Jiaqi Wang",
      "Yaqing Wang",
      "Houping Xiao",
      "Fenglong Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04533"
  },
  {
    "id": "arXiv:2109.04535",
    "title": "Identifying Morality Frames in Political Tweets using Relational  Learning",
    "abstract": "Extracting moral sentiment from text is a vital component in understanding\npublic opinion, social movements, and policy decisions. The Moral Foundation\nTheory identifies five moral foundations, each associated with a positive and\nnegative polarity. However, moral sentiment is often motivated by its targets,\nwhich can correspond to individuals or collective entities. In this paper, we\nintroduce morality frames, a representation framework for organizing moral\nattitudes directed at different entities, and come up with a novel and\nhigh-quality annotated dataset of tweets written by US politicians. Then, we\npropose a relational learning model to predict moral attitudes towards entities\nand moral foundations jointly. We do qualitative and quantitative evaluations,\nshowing that moral sentiment towards entities differs highly across political\nideologies.",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Shamik Roy",
      "Maria Leonor Pacheco",
      "Dan Goldwasser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04535"
  },
  {
    "id": "arXiv:2109.04536",
    "title": "Performance Analysis of CP2K Code for Ab Initio Molecular Dynamics",
    "abstract": "Using a realistic molecular catalyst system, we conduct scaling studies of ab\ninitio molecular dynamics simulations using the CP2K code on both Intel Xeon\nCPU and NVIDIA V100 GPU architectures. We explore using process placement and\naffinity to gain additional performance improvements. We also use statistical\nmethods to understand performance changes in spite of the variability in\nruntime for each molecular dynamics timestep. We found ideal conditions for CPU\nruns included at least four MPI ranks per node, bound evenly across each\nsocket, and fully utilizing processing cores with one OpenMP thread per core,\nno benefit was shown from reserving cores for the system. The CPU-only\nsimulations scaled at 70% or more of the ideal scaling up to 10 compute nodes,\nafter which the returns began to diminish more quickly. Simulations on a single\n40-core node with two NVIDIA V100 GPUs for acceleration achieved over 3.7x\nspeedup compared to the fastest single 36-core node CPU-only version, and\nshowed 13% speedup over the fastest time we achieved across five CPU-only\nnodes.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Dewi Yokelson",
      "Nikolay V. Tkachenko",
      "Robert Robey",
      "Ying Wai Li",
      "Pavel A. Dub"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.04536"
  },
  {
    "id": "arXiv:2109.04543",
    "title": "Generic resources are what you need: Style transfer tasks without  task-specific parallel training data",
    "abstract": "Style transfer aims to rewrite a source text in a different target style\nwhile preserving its content. We propose a novel approach to this task that\nleverages generic resources, and without using any task-specific parallel\n(source-target) data outperforms existing unsupervised approaches on the two\nmost popular style transfer tasks: formality transfer and polarity swap. In\npractice, we adopt a multi-step procedure which builds on a generic pre-trained\nsequence-to-sequence model (BART). First, we strengthen the model's ability to\nrewrite by further pre-training BART on both an existing collection of generic\nparaphrases, as well as on synthetic pairs created using a general-purpose\nlexical resource. Second, through an iterative back-translation approach, we\ntrain two models, each in a transfer direction, so that they can provide each\nother with synthetically generated pairs, dynamically in the training process.\nLastly, we let our best reresulting model generate static synthetic pairs to be\nused in a supervised training regime. Besides methodology and state-of-the-art\nresults, a core contribution of this work is a reflection on the nature of the\ntwo tasks we address, and how their differences are highlighted by their\nresponse to our approach.",
    "descriptor": "\nComments: Accepted to EMNLP2021 (main conference)\n",
    "authors": [
      "Huiyuan Lai",
      "Antonio Toral",
      "Malvina Nissim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04543"
  },
  {
    "id": "arXiv:2109.04546",
    "title": "Math Word Problem Generation with Mathematical Consistency and Problem  Context Constraints",
    "abstract": "We study the problem of generating arithmetic math word problems (MWPs) given\na math equation that specifies the mathematical computation and a context that\nspecifies the problem scenario. Existing approaches are prone to generating\nMWPs that are either mathematically invalid or have unsatisfactory language\nquality. They also either ignore the context or require manual specification of\na problem template, which compromises the diversity of the generated MWPs. In\nthis paper, we develop a novel MWP generation approach that leverages i)\npre-trained language models and a context keyword selection model to improve\nthe language quality of the generated MWPs and ii) an equation consistency\nconstraint for math equations to improve the mathematical validity of the\ngenerated MWPs. Extensive quantitative and qualitative experiments on three\nreal-world MWP datasets demonstrate the superior performance of our approach\ncompared to various baselines.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Zichao Wang",
      "Andrew S. Lan",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04546"
  },
  {
    "id": "arXiv:2109.04548",
    "title": "All-Purpose Hashing",
    "abstract": "Despite being one of the oldest data structures in computer science, hash\ntables continue to be the focus of a great deal of both theoretical and\nempirical research. A central reason for this is that many of the fundamental\nproperties that one desires from a hash table are difficult to achieve\nsimultaneously; thus many variants offering different trade-offs have been\nproposed.\nThis paper introduces Iceberg hashing, a hash table that simultaneously\noffers the strongest known guarantees on a large number of core properties.\nIceberg hashing supports constant-time operations while improving on the state\nof the art for space efficiency, cache efficiency, and low failure probability.\nIceberg hashing is also the first hash table to support a load factor of up to\n$1 - o(1)$ while being stable, meaning that the position where an element is\nstored only ever changes when resizes occur. In fact, in the setting where keys\nare $\\Theta(\\log n)$ bits, the space guarantees that Iceberg hashing offers,\nnamely that is uses at most $\\log \\binom{|U|}{n} + O(n \\log \\log n)$ bits to\nstore $n$ items from a universe $U$, matches a lower bound by Demaine et al.\nthat applies to any stable hash table.\nIceberg hashing introduces new general-purpose techniques for some of the\nmost basic aspects of hash-table design. Notably, our indirection-free\ntechnique for dynamic resizing, which we call waterfall addressing, and our\ntechniques for achieving stability and very-high probability guarantees, can be\napplied to any hash table that makes use of the front-yard/backyard paradigm\nfor hash table design.",
    "descriptor": "",
    "authors": [
      "Michael A. Bender",
      "Alex Conway",
      "Mart\u00edn Farach-Colton",
      "William Kuszmaul",
      "Guido Tagliavini"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.04548"
  },
  {
    "id": "arXiv:2109.04550",
    "title": "SeDyT: A General Framework for Multi-Step Event Forecasting via Sequence  Modeling on Dynamic Entity Embeddings",
    "abstract": "Temporal Knowledge Graphs store events in the form of subjects, relations,\nobjects, and timestamps which are often represented by dynamic heterogeneous\ngraphs. Event forecasting is a critical and challenging task in Temporal\nKnowledge Graph reasoning that predicts the subject or object of an event in\nthe future. To obtain temporal embeddings multi-step away in the future,\nexisting methods learn generative models that capture the joint distribution of\nthe observed events. To reduce the high computation costs, these methods rely\non unrealistic assumptions of independence and approximations in training and\ninference. In this work, we propose SeDyT, a discriminative framework that\nperforms sequence modeling on the dynamic entity embeddings to solve the\nmulti-step event forecasting problem. SeDyT consists of two components: a\nTemporal Graph Neural Network that generates dynamic entity embeddings in the\npast and a sequence model that predicts the entity embeddings in the future.\nCompared with the generative models, SeDyT does not rely on any heuristic-based\nprobability model and has low computation complexity in both training and\ninference. SeDyT is compatible with most Temporal Graph Neural Networks and\nsequence models. We also design an efficient training method that trains the\ntwo components in one gradient descent propagation. We evaluate the performance\nof SeDyT on five popular datasets. By combining temporal Graph Neural Network\nmodels and sequence models, SeDyT achieves an average of 2.4% MRR improvement\nwhen not using the validation set and more than 10% MRR improvement when using\nthe validation set.",
    "descriptor": "",
    "authors": [
      "Hongkuan Zhou",
      "James Orme-Rogers",
      "Rajgopal Kannan",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04550"
  },
  {
    "id": "arXiv:2109.04552",
    "title": "SPECTRA: Sparse Structured Text Rationalization",
    "abstract": "Selective rationalization aims to produce decisions along with rationales\n(e.g., text highlights or word alignments between two sentences). Commonly,\nrationales are modeled as stochastic binary masks, requiring sampling-based\ngradient estimators, which complicates training and requires careful\nhyperparameter tuning. Sparse attention mechanisms are a deterministic\nalternative, but they lack a way to regularize the rationale extraction (e.g.,\nto control the sparsity of a text highlight or the number of alignments). In\nthis paper, we present a unified framework for deterministic extraction of\nstructured explanations via constrained inference on a factor graph, forming a\ndifferentiable layer. Our approach greatly eases training and rationale\nregularization, generally outperforming previous work on what comes to\nperformance and plausibility of the extracted rationales. We further provide a\ncomparative study of stochastic and deterministic methods for rationale\nextraction for classification and natural language inference tasks, jointly\nassessing their predictive power, quality of the explanations, and model\nvariability.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 (main conference)\n",
    "authors": [
      "Nuno Miguel Guerreiro",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04552"
  },
  {
    "id": "arXiv:2109.04553",
    "title": "Is Attention Better Than Matrix Decomposition?",
    "abstract": "As an essential ingredient of modern deep learning, attention mechanism,\nespecially self-attention, plays a vital role in the global correlation\ndiscovery. However, is hand-crafted attention irreplaceable when modeling the\nglobal context? Our intriguing finding is that self-attention is not better\nthan the matrix decomposition (MD) model developed 20 years ago regarding the\nperformance and computational cost for encoding the long-distance dependencies.\nWe model the global context issue as a low-rank recovery problem and show that\nits optimization algorithms can help design global information blocks. This\npaper then proposes a series of Hamburgers, in which we employ the optimization\nalgorithms for solving MDs to factorize the input representations into\nsub-matrices and reconstruct a low-rank embedding. Hamburgers with different\nMDs can perform favorably against the popular global context module\nself-attention when carefully coping with gradients back-propagated through\nMDs. Comprehensive experiments are conducted in the vision tasks where it is\ncrucial to learn the global context, including semantic segmentation and image\ngeneration, demonstrating significant improvements over self-attention and its\nvariants.",
    "descriptor": "\nComments: ICLR 2021\n",
    "authors": [
      "Zhengyang Geng",
      "Meng-Hao Guo",
      "Hongxu Chen",
      "Xia Li",
      "Ke Wei",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04553"
  },
  {
    "id": "arXiv:2109.04554",
    "title": "Feature-based Individual Fairness in k-Clustering",
    "abstract": "Ensuring fairness in machine learning algorithms is a challenging and\nimportant task. We consider the problem of clustering a set of points while\nensuring fairness constraints. While there have been several attempts to\ncapture group fairness in the k-clustering problem, fairness at an individual\nlevel is not well-studied. We introduce a new notion of individual fairness in\nk-clustering based on features that are not necessarily used for clustering. We\nshow that this problem is NP-hard and does not admit a constant factor\napproximation. We then design a randomized algorithm that guarantees\napproximation both in terms of minimizing the clustering distance objective as\nwell as individual fairness under natural restrictions on the distance metric\nand fairness constraints. Finally, our experimental results validate that our\nalgorithm produces lower clustering costs compared to existing algorithms while\nbeing competitive in individual fairness.",
    "descriptor": "",
    "authors": [
      "Debajyoti Kar",
      "Sourav Medya",
      "Debmalya Mandal",
      "Arlei Silva",
      "Palash Dey",
      "Swagato Sanyal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.04554"
  },
  {
    "id": "arXiv:2109.04556",
    "title": "Subword Mapping and Anchoring across Languages",
    "abstract": "State-of-the-art multilingual systems rely on shared vocabularies that\nsufficiently cover all considered languages. To this end, a simple and\nfrequently used approach makes use of subword vocabularies constructed jointly\nover several languages. We hypothesize that such vocabularies are suboptimal\ndue to false positives (identical subwords with different meanings across\nlanguages) and false negatives (different subwords with similar meanings). To\naddress these issues, we propose Subword Mapping and Anchoring across Languages\n(SMALA), a method to construct bilingual subword vocabularies. SMALA extracts\nsubword alignments using an unsupervised state-of-the-art mapping technique and\nuses them to create cross-lingual anchors based on subword similarities. We\ndemonstrate the benefits of SMALA for cross-lingual natural language inference\n(XNLI), where it improves zero-shot transfer to an unseen language without\ntask-specific data, but only by sharing subword embeddings. Moreover, in neural\nmachine translation, we show that joint subword vocabularies obtained with\nSMALA lead to higher BLEU scores on sentences that contain many false positives\nand false negatives.",
    "descriptor": "\nComments: EMNLP 2021, Findings of EMNLP2021\n",
    "authors": [
      "Giorgos Vernikos",
      "Andrei Popescu-Belis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04556"
  },
  {
    "id": "arXiv:2109.04559",
    "title": "Fighting Fake News in Encrypted Messaging with the Fuzzy Anonymous  Complaint Tally System (FACTS)",
    "abstract": "Recent years have seen a strong uptick in both the prevalence and real-world\nconsequences of false information spread through online platforms. At the same\ntime, encrypted messaging systems such as WhatsApp, Signal, and Telegram, are\nrapidly gaining popularity as users seek increased privacy in their digital\nlives.\nThe challenge we address is how to combat the viral spread of misinformation\nwithout compromising privacy. Our FACTS system tracks user complaints on\nmessages obliviously, only revealing the message's contents and originator once\nsufficiently many complaints have been lodged.\nOur system is private, meaning it does not reveal anything about the senders\nor contents of messages which have received few or no complaints; secure,\nmeaning there is no way for a malicious user to evade the system or gain an\noutsized impact over the complaint system; and scalable, as we demonstrate\nexcellent practical efficiency for up to millions of complaints per day.\nOur main technical contribution is a new collaborative counting Bloom filter,\na simple construction with difficult probabilistic analysis, which may have\nindependent interest as a privacy-preserving randomized count sketch data\nstructure.\nCompared to prior work on message flagging and tracing in end-to-end\nencrypted messaging, our novel contribution is the addition of a high threshold\nof multiple complaints that are needed before a message is audited or flagged.\nWe present and carefully analyze the probabilistic performance of our data\nstructure, provide a precise security definition and proof, and then measure\nthe accuracy and scalability of our scheme via experimentation.",
    "descriptor": "\nComments: 16 pages, to appear in NDSS 2022\n",
    "authors": [
      "Linsheng Liu",
      "Daniel S. Roche",
      "Austin Theriault",
      "Arkady Yerukhimovich"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.04559"
  },
  {
    "id": "arXiv:2109.04562",
    "title": "TIAGE: A Benchmark for Topic-Shift Aware Dialog Modeling",
    "abstract": "Human conversations naturally evolve around different topics and fluently\nmove between them. In research on dialog systems, the ability to actively and\nsmoothly transition to new topics is often ignored. In this paper we introduce\nTIAGE, a new topic-shift aware dialog benchmark constructed utilizing human\nannotations on topic shifts. Based on TIAGE, we introduce three tasks to\ninvestigate different scenarios of topic-shift modeling in dialog settings:\ntopic-shift detection, topic-shift triggered response generation and\ntopic-aware dialog generation. Experiments on these tasks show that the\ntopic-shift signals in TIAGE are useful for topic-shift response generation. On\nthe other hand, dialog systems still struggle to decide when to change topic.\nThis indicates further research is needed in topic-shift aware dialog modeling.",
    "descriptor": "\nComments: Accepted to appear in Findings of EMNLP 2021\n",
    "authors": [
      "Huiyuan Xie",
      "Zhenghao Liu",
      "Chenyan Xiong",
      "Zhiyuan Liu",
      "Ann Copestake"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04562"
  },
  {
    "id": "arXiv:2109.04564",
    "title": "Characterization of Constrained Continuous Multiobjective Optimization  Problems: A Feature Space Perspective",
    "abstract": "Despite the increasing interest in constrained multiobjective optimization in\nrecent years, constrained multiobjective optimization problems (CMOPs) are\nstill unsatisfactory understood and characterized. For this reason, the\nselection of appropriate CMOPs for benchmarking is difficult and lacks a formal\nbackground. We address this issue by extending landscape analysis to\nconstrained multiobjective optimization. By employing four exploratory\nlandscape analysis techniques, we propose 29 landscape features (of which 19\nare novel) to characterize CMOPs. These landscape features are then used to\ncompare eight frequently used artificial test suites against a recently\nproposed suite consisting of real-world problems based on physical models. The\nexperimental results reveal that the artificial test problems fail to\nadequately represent some realistic characteristics, such as strong negative\ncorrelation between the objectives and constraints. Moreover, our findings show\nthat all the studied artificial test suites have advantages and limitations,\nand that no \"perfect\" suite exists. Benchmark designers can use the obtained\nresults to select or generate appropriate CMOP instances based on the\ncharacteristics they want to explore.",
    "descriptor": "\nComments: Submitted for consideration for publication in the IEEE Transactions on Evolutionary Computation\n",
    "authors": [
      "Aljo\u0161a Vodopija",
      "Tea Tu\u0161ar",
      "Bogdan Filipi\u010d"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.04564"
  },
  {
    "id": "arXiv:2109.04565",
    "title": "TENET: Temporal CNN with Attention for Anomaly Detection in Automotive  Cyber-Physical Systems",
    "abstract": "Modern vehicles have multiple electronic control units (ECUs) that are\nconnected together as part of a complex distributed cyber-physical system\n(CPS). The ever-increasing communication between ECUs and external electronic\nsystems has made these vehicles particularly susceptible to a variety of\ncyber-attacks. In this work, we present a novel anomaly detection framework\ncalled TENET to detect anomalies induced by cyber-attacks on vehicles. TENET\nuses temporal convolutional neural networks with an integrated attention\nmechanism to detect anomalous attack patterns. TENET is able to achieve an\nimprovement of 32.70% in False Negative Rate, 19.14% in the Mathews Correlation\nCoefficient, and 17.25% in the ROC-AUC metric, with 94.62% fewer model\nparameters, 86.95% decrease in memory footprint, and 48.14% lower inference\ntime when compared to the best performing prior work on automotive anomaly\ndetection.",
    "descriptor": "",
    "authors": [
      "S. V. Thiruloga",
      "V. K. Kukkala",
      "S. Pasricha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.04565"
  },
  {
    "id": "arXiv:2109.04566",
    "title": "SanitAIs: Unsupervised Data Augmentation to Sanitize Trojaned Neural  Networks",
    "abstract": "The application of self-supervised methods has resulted in broad improvements\nto neural network performance by leveraging large, untapped collections of\nunlabeled data to learn generalized underlying structure. In this work, we\nharness unsupervised data augmentation (UDA) to mitigate backdoor or Trojan\nattacks on deep neural networks. We show that UDA is more effective at removing\nthe effects of a trigger than current state-of-the-art methods for both feature\nspace and point triggers. These results demonstrate that UDA is both an\neffective and practical approach to mitigating the effects of backdoors on\nneural networks.",
    "descriptor": "\nComments: 7 pages, 10 figures\n",
    "authors": [
      "Kiran Karra",
      "Chace Ashcraft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04566"
  },
  {
    "id": "arXiv:2109.04567",
    "title": "Fast Algorithms for Minimum Cycle Basis and Minimum Homology Basis",
    "abstract": "We study the problem of finding a minimum homology basis, that is, a shortest\nset of cycles that generates the $1$-dimensional homology classes with\n$\\mathbb{Z}_2$ coefficients in a given simplicial complex $K$. This problem has\nbeen extensively studied in the last few years.\nFor general complexes, the current best deterministic algorithm, by Dey et\nal., runs in $O(N^\\omega + N^2 g)$ time, where $N$ denotes the number of\nsimplices in $K$, $g$ denotes the rank of the $1$-homology group of $K$, and\n$\\omega$ denotes the exponent of matrix multiplication. In this paper, we\npresent two conceptually simple randomized algorithms that compute a minimum\nhomology basis of a general simplicial complex $K$. The first algorithm runs in\n$\\tilde{O}(m^\\omega)$ time, where $m$ denotes the number of edges in $K$,\nwhereas the second algorithm runs in $O(m^\\omega + N m^{\\omega-1})$ time.\nWe also study the problem of finding a minimum cycle basis in an undirected\ngraph $G$ with $n$ vertices and $m$ edges. The best known algorithm for this\nproblem runs in $O(m^\\omega)$ time. Our algorithm, which has a simpler\nhigh-level description, but is slightly more expensive, runs in\n$\\tilde{O}(m^\\omega)$ time.",
    "descriptor": "\nComments: 36th International Symposium on Computational Geometry (SoCG 2020) 64:1--64:11\n",
    "authors": [
      "Abhishek Rathod"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.04567"
  },
  {
    "id": "arXiv:2109.04569",
    "title": "S3G-ARM: Highly Compressive Visual Self-localization from Sequential  Semantic Scene Graph Using Absolute and Relative Measurements",
    "abstract": "In this paper, we address the problem of image sequence-based\nself-localization (ISS) from a new highly compressive scene representation\ncalled sequential semantic scene graph (S3G). Recent developments in deep graph\nconvolutional neural networks (GCNs) have enabled a highly compressive visual\nplace classifier (VPC) that can use a scene graph as the input modality.\nHowever, in such a highly compressive application, the amount of information\nlost in the image-to-graph mapping is significant and can damage the\nclassification performance. To address this issue, we propose a pair of\nsimilarity-preserving mappings, image-to-nodes and image-to-edges, such that\nthe nodes and edges act as absolute and relative features, respectively, that\ncomplement each other. Moreover, the proposed GCN-VPC is applied to a new task\nof viewpoint planning (VP) of the query image sequence, which contributes to\nfurther improvement in the VPC performance. Experiments using the public NCLT\ndataset validated the effectiveness of the proposed method.",
    "descriptor": "\nComments: 6 pages, 7 figures, technical report\n",
    "authors": [
      "Mitsuki Yoshida",
      "Ryogo Yamamoto",
      "Kanji Tanaka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04569"
  },
  {
    "id": "arXiv:2109.04570",
    "title": "Risk-perception-aware control design under dynamic spatial risks",
    "abstract": "This work proposes a novel risk-perception-aware (RPA) control design using\nnon-rational perception of risks associated with uncertain dynamic spatial\ncosts. We use Cumulative Prospect Theory (CPT) to model the risk perception of\na decision maker (DM) and use it to construct perceived risk functions that\ntransform the uncertain dynamic spatial cost to deterministic perceived risks\nof a DM. These risks are then used to build safety sets which can represent\nrisk-averse to risk-insensitive perception. We define a notions of\n\"inclusiveness\" and \"versatility\" based on safety sets and use it to compare\nwith other models such as Conditional value at Risk (CVaR) and Expected risk\n(ER). We theoretically prove that CPT is the most \"inclusive\" and \"versatile\"\nmodel of the lot in the context of risk-perception-aware controls. We further\nuse the perceived risk function along with ideas from control barrier functions\n(CBF) to construct a class of perceived risk CBFs. For a class of\ntruncated-Gaussian costs, we find sufficient geometric conditions for the\nvalidity of this class of CBFs, thus guaranteeing safety. Then, we generate\nperceived-safety-critical controls using a Quadratic program (QP) to guide an\nagent safely according to a given perceived risk model. We present simulations\nin a 2D environment to illustrate the performance of the proposed controller.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Aamodh Suresh",
      "Sonia Martinez"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04570"
  },
  {
    "id": "arXiv:2109.04572",
    "title": "Deciphering Environmental Air Pollution with Large Scale City Data",
    "abstract": "Out of the numerous hazards posing a threat to sustainable environmental\nconditions in the 21st century, only a few have a graver impact than air\npollution. Its importance in determining the health and living standards in\nurban settings is only expected to increase with time. Various factors ranging\nfrom emissions from traffic and power plants, household emissions, natural\ncauses are known to be primary causal agents or influencers behind rising air\npollution levels. However, the lack of large scale data involving the major\nfactors has hindered the research on the causes and relations governing the\nvariability of the different air pollutants. Through this work, we introduce a\nlarge scale city-wise dataset for exploring the relationships among these\nagents over a long period of time. We analyze and explore the dataset to bring\nout inferences which we can derive by modeling the data. Also, we provide a set\nof benchmarks for the problem of estimating or forecasting pollutant levels\nwith a set of diverse models and methodologies. Through our paper, we seek to\nprovide a ground base for further research into this domain that will demand\ncritical attention of ours in the near future.",
    "descriptor": "",
    "authors": [
      "Mayukh Bhattacharyya",
      "Sayan Nag",
      "Udita Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2109.04572"
  },
  {
    "id": "arXiv:2109.04573",
    "title": "Object recognition for robotics from tactile time series data utilising  different neural network architectures",
    "abstract": "Robots need to exploit high-quality information on grasped objects to\ninteract with the physical environment. Haptic data can therefore be used for\nsupplementing the visual modality. This paper investigates the use of\nConvolutional Neural Networks (CNN) and Long-Short Term Memory (LSTM) neural\nnetwork architectures for object classification on Spatio-temporal tactile\ngrasping data. Furthermore, we compared these methods using data from two\ndifferent fingertip sensors (namely the BioTac SP and WTS-FT) in the same\nphysical setup, allowing for a realistic comparison across methods and sensors\nfor the same tactile object classification dataset. Additionally, we propose a\nway to create more training examples from the recorded data. The results show\nthat the proposed method improves the maximum accuracy from 82.4% (BioTac SP\nfingertips) and 90.7% (WTS-FT fingertips) with complete time-series data to\nabout 94% for both sensor types.",
    "descriptor": "",
    "authors": [
      "Wolfgang Bottcher",
      "Pedro Machado",
      "Nikesh Lama",
      "T.M. McGinnity"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04573"
  },
  {
    "id": "arXiv:2109.04574",
    "title": "Speechformer: Reducing Information Loss in Direct Speech Translation",
    "abstract": "Transformer-based models have gained increasing popularity achieving\nstate-of-the-art performance in many research fields including speech\ntranslation. However, Transformer's quadratic complexity with respect to the\ninput sequence length prevents its adoption as is with audio signals, which are\ntypically represented by long sequences. Current solutions resort to an initial\nsub-optimal compression based on a fixed sampling of raw audio features.\nTherefore, potentially useful linguistic information is not accessible to\nhigher-level layers in the architecture. To solve this issue, we propose\nSpeechformer, an architecture that, thanks to reduced memory usage in the\nattention layers, avoids the initial lossy compression and aggregates\ninformation only at a higher level according to more informed linguistic\ncriteria. Experiments on three language pairs (en->de/es/nl) show the efficacy\nof our solution, with gains of up to 0.8 BLEU on the standard MuST-C corpus and\nof up to 4.0 BLEU in a low resource scenario.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 Main Conference\n",
    "authors": [
      "Sara Papi",
      "Marco Gaido",
      "Matteo Negri",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04574"
  },
  {
    "id": "arXiv:2109.04581",
    "title": "A Unified Model with Inertia Shaping for Highly Dynamic Jumps of Legged  Robots",
    "abstract": "To achieve highly dynamic jumps of legged robots, it is essential to control\nthe rotational dynamics of the robot. In this paper, we aim to improve the\njumping performance by proposing a unified model for planning highly dynamic\njumps that can approximately model the centroidal inertia. This model abstracts\nthe robot as a single rigid body for the base and point masses for the legs.\nThe model is called the Lump Leg Single Rigid Body Model (LL-SRBM) and can be\nused to plan motions for both bipedal and quadrupedal robots. By taking the\neffects of leg dynamics into account, LL-SRBM provides a computationally\nefficient way for the motion planner to change the centroidal inertia of the\nrobot with various leg configurations. Concurrently, we propose a novel contact\ndetection method by using the norm of the average spatial velocity. After the\ncontact is detected, the controller is switched to force control to achieve a\nsoft landing. Twisting jump and forward jump experiments on the bipedal robot\nSLIDER and quadrupedal robot ANYmal demonstrate the improved jump performance\nby actively changing the centroidal inertia. These experiments also show the\ngeneralization and the robustness of the integrated planning and control\nframework.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Ke Wang",
      "Guiyang Xin",
      "Songyan Xin",
      "Michael Mistry",
      "Sethu Vijayakumar",
      "Petar Kormushev"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04581"
  },
  {
    "id": "arXiv:2109.04584",
    "title": "Trust your neighbors: A comprehensive survey of neighborhood-based  methods for recommender systems",
    "abstract": "Collaborative recommendation approaches based on nearest-neighbors are still\nhighly popular today due to their simplicity, their efficiency, and their\nability to produce accurate and personalized recommendations. This chapter\noffers a comprehensive survey of neighborhood-based methods for the item\nrecommendation problem. It presents the main characteristics and benefits of\nsuch methods, describes key design choices for implementing a\nneighborhood-based recommender system, and gives practical information on how\nto make these choices. A broad range of methods is covered in the chapter,\nincluding traditional algorithms like k-nearest neighbors as well as advanced\napproaches based on matrix factorization, sparse coding and random walks.",
    "descriptor": "\nComments: 50 pages; Chapter in the Recommender Systems Handbook, 3rd Edition (to appear)\n",
    "authors": [
      "Athanasios N. Nikolakopoulos",
      "Xia Ning",
      "Christian Desrosiers",
      "George Karypis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04584"
  },
  {
    "id": "arXiv:2109.04587",
    "title": "Graph-Based Decoding for Task Oriented Semantic Parsing",
    "abstract": "The dominant paradigm for semantic parsing in recent years is to formulate\nparsing as a sequence-to-sequence task, generating predictions with\nauto-regressive sequence decoders. In this work, we explore an alternative\nparadigm. We formulate semantic parsing as a dependency parsing task, applying\ngraph-based decoding techniques developed for syntactic parsing. We compare\nvarious decoding techniques given the same pre-trained Transformer encoder on\nthe TOP dataset, including settings where training data is limited or contains\nonly partially-annotated examples. We find that our graph-based approach is\ncompetitive with sequence decoders on the standard setting, and offers\nsignificant improvements in data efficiency and settings where\npartially-annotated data is available.",
    "descriptor": "\nComments: To appear in EMNLP 5 pages 4 figures\n",
    "authors": [
      "Jeremy R. Cole",
      "Nanjiang Jiang",
      "Panupong Pasupat",
      "Luheng He",
      "Peter Shaw"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04587"
  },
  {
    "id": "arXiv:2109.04588",
    "title": "BERT, mBERT, or BiBERT? A Study on Contextualized Embeddings for Neural  Machine Translation",
    "abstract": "The success of bidirectional encoders using masked language models, such as\nBERT, on numerous natural language processing tasks has prompted researchers to\nattempt to incorporate these pre-trained models into neural machine translation\n(NMT) systems. However, proposed methods for incorporating pre-trained models\nare non-trivial and mainly focus on BERT, which lacks a comparison of the\nimpact that other pre-trained models may have on translation performance. In\nthis paper, we demonstrate that simply using the output (contextualized\nembeddings) of a tailored and suitable bilingual pre-trained language model\n(dubbed BiBERT) as the input of the NMT encoder achieves state-of-the-art\ntranslation performance. Moreover, we also propose a stochastic layer selection\napproach and a concept of dual-directional translation model to ensure the\nsufficient utilization of contextualized embeddings. In the case of without\nusing back translation, our best models achieve BLEU scores of 30.45 for En->De\nand 38.61 for De->En on the IWSLT'14 dataset, and 31.26 for En->De and 34.94\nfor De->En on the WMT'14 dataset, which exceeds all published numbers.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Haoran Xu",
      "Benjamin Van Durme",
      "Kenton Murray"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04588"
  },
  {
    "id": "arXiv:2109.04593",
    "title": "A Large-Scale Study of Machine Translation in the Turkic Languages",
    "abstract": "Recent advances in neural machine translation (NMT) have pushed the quality\nof machine translation systems to the point where they are becoming widely\nadopted to build competitive systems. However, there is still a large number of\nlanguages that are yet to reap the benefits of NMT. In this paper, we provide\nthe first large-scale case study of the practical application of MT in the\nTurkic language family in order to realize the gains of NMT for Turkic\nlanguages under high-resource to extremely low-resource scenarios. In addition\nto presenting an extensive analysis that identifies the bottlenecks towards\nbuilding competitive systems to ameliorate data scarcity, our study has several\nkey contributions, including, i) a large parallel corpus covering 22 Turkic\nlanguages consisting of common public datasets in combination with new datasets\nof approximately 2 million parallel sentences, ii) bilingual baselines for 26\nlanguage pairs, iii) novel high-quality test sets in three different\ntranslation domains and iv) human evaluation scores. All models, scripts, and\ndata will be released to the public.",
    "descriptor": "\nComments: 9 pages, 1 figure, 8 tables. Main proceedings of EMNLP 2021\n",
    "authors": [
      "Jamshidbek Mirzakhalov",
      "Anoop Babu",
      "Duygu Ataman",
      "Sherzod Kariev",
      "Francis Tyers",
      "Otabek Abduraufov",
      "Mammad Hajili",
      "Sardana Ivanova",
      "Abror Khaytbaev",
      "Antonio Laverghetta Jr.",
      "Behzodbek Moydinboyev",
      "Esra Onal",
      "Shaxnoza Pulatova",
      "Ahsan Wahab",
      "Orhan Firat",
      "Sriram Chellappan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04593"
  },
  {
    "id": "arXiv:2109.04595",
    "title": "C-MinHash: Practically Reducing Two Permutations to Just One",
    "abstract": "Traditional minwise hashing (MinHash) requires applying $K$ independent\npermutations to estimate the Jaccard similarity in massive binary (0/1) data,\nwhere $K$ can be (e.g.,) 1024 or even larger, depending on applications. The\nrecent work on C-MinHash (Li and Li, 2021) has shown, with rigorous proofs,\nthat only two permutations are needed. An initial permutation is applied to\nbreak whatever structures which might exist in the data, and a second\npermutation is re-used $K$ times to produce $K$ hashes, via a circulant\nshifting fashion. (Li and Li, 2021) has proved that, perhaps surprisingly, even\nthough the $K$ hashes are correlated, the estimation variance is strictly\nsmaller than the variance of the traditional MinHash.\nIt has been demonstrated in (Li and Li, 2021) that the initial permutation in\nC-MinHash is indeed necessary. For the ease of theoretical analysis, they have\nused two independent permutations. In this paper, we show that one can actually\nsimply use one permutation. That is, one single permutation is used for both\nthe initial pre-processing step to break the structures in the data and the\ncirculant hashing step to generate $K$ hashes. Although the theoretical\nanalysis becomes very complicated, we are able to explicitly write down the\nexpression for the expectation of the estimator. The new estimator is no longer\nunbiased but the bias is extremely small and has essentially no impact on the\nestimation accuracy (mean square errors). An extensive set of experiments are\nprovided to verify our claim for using just one permutation.",
    "descriptor": "",
    "authors": [
      "Xiaoyun Li",
      "Ping Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04595"
  },
  {
    "id": "arXiv:2109.04598",
    "title": "Automatic Portrait Video Matting via Context Motion Network",
    "abstract": "Our automatic portrait video matting method does not require extra inputs.\nMost state-of-the-art matting methods rely on semantic segmentation methods to\nautomatically generate the trimap. Their performance is compromised due to the\nlack of temporal information. Our method exploits semantic information as well\nas temporal information from optical flow and produces high-quality results.",
    "descriptor": "",
    "authors": [
      "Qiqi Hou",
      "Charlie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04598"
  },
  {
    "id": "arXiv:2109.04600",
    "title": "EVOQUER: Enhancing Temporal Grounding with Video-Pivoted BackQuery  Generation",
    "abstract": "Temporal grounding aims to predict a time interval of a video clip\ncorresponding to a natural language query input. In this work, we present\nEVOQUER, a temporal grounding framework incorporating an existing text-to-video\ngrounding model and a video-assisted query generation network. Given a query\nand an untrimmed video, the temporal grounding model predicts the target\ninterval, and the predicted video clip is fed into a video translation task by\ngenerating a simplified version of the input query. EVOQUER forms closed-loop\nlearning by incorporating loss functions from both temporal grounding and query\ngeneration serving as feedback. Our experiments on two widely used datasets,\nCharades-STA and ActivityNet, show that EVOQUER achieves promising improvements\nby 1.05 and 1.31 at R@0.7. We also discuss how the query generation task could\nfacilitate error analysis by explaining temporal grounding model behavior.",
    "descriptor": "\nComments: Accepted by Visually Grounded Interaction and Language (ViGIL) Workshop at NAACL 2021\n",
    "authors": [
      "Yanjun Gao",
      "Lulu Liu",
      "Jason Wang",
      "Xin Chen",
      "Huayan Wang",
      "Rui Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04600"
  },
  {
    "id": "arXiv:2109.04602",
    "title": "Augmenting BERT-style Models with Predictive Coding to Improve  Discourse-level Representations",
    "abstract": "Current language models are usually trained using a self-supervised scheme,\nwhere the main focus is learning representations at the word or sentence level.\nHowever, there has been limited progress in generating useful discourse-level\nrepresentations. In this work, we propose to use ideas from predictive coding\ntheory to augment BERT-style language models with a mechanism that allows them\nto learn suitable discourse-level representations. As a result, our proposed\napproach is able to predict future sentences using explicit top-down\nconnections that operate at the intermediate layers of the network. By\nexperimenting with benchmarks designed to evaluate discourse-related knowledge\nusing pre-trained sentence representations, we demonstrate that our approach\nimproves performance in 6 out of 11 tasks by excelling in discourse\nrelationship detection.",
    "descriptor": "\nComments: Accepted paper EMNLP2021\n",
    "authors": [
      "Vladimir Araujo",
      "Andr\u00e9s Villa",
      "Marcelo Mendoza",
      "Marie-Francine Moens",
      "Alvaro Soto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04602"
  },
  {
    "id": "arXiv:2109.04604",
    "title": "How May I Help You? Using Neural Text Simplification to Improve  Downstream NLP Tasks",
    "abstract": "The general goal of text simplification (TS) is to reduce text complexity for\nhuman consumption. This paper investigates another potential use of neural TS:\nassisting machines performing natural language processing (NLP) tasks. We\nevaluate the use of neural TS in two ways: simplifying input texts at\nprediction time and augmenting data to provide machines with additional\ninformation during training. We demonstrate that the latter scenario provides\npositive effects on machine performance on two separate datasets. In\nparticular, the latter use of TS improves the performances of LSTM (1.82-1.98%)\nand SpanBERT (0.7-1.3%) extractors on TACRED, a complex, large-scale,\nreal-world relation extraction task. Further, the same setting yields\nimprovements of up to 0.65% matched and 0.62% mismatched accuracies for a BERT\ntext classifier on MNLI, a practical natural language inference dataset.",
    "descriptor": "\nComments: 7 pages, 7 tables, accepted to Empirical Methods for Natural Language Processing 2021, Punta Cana, Dominican Republic\n",
    "authors": [
      "Hoang Van",
      "Zheng Tang",
      "Mihai Surdeanu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04604"
  },
  {
    "id": "arXiv:2109.04605",
    "title": "Analytical Process Scheduling Optimization for Heterogeneous Multi-core  Systems",
    "abstract": "In this paper, we propose the first optimum process scheduling algorithm for\nan increasingly prevalent type of heterogeneous multicore (HEMC) system that\ncombines high-performance big cores and energy-efficient small cores with the\nsame instruction-set architecture (ISA). Existing algorithms are all\nheuristics-based, and the well-known IPC-driven approach essentially tries to\nschedule high scaling factor processes on big cores. Our analysis shows that,\nfor optimum solutions, it is also critical to consider placing long running\nprocesses on big cores. Tests of SPEC 2006 cases on various big-small core\ncombinations show that our proposed optimum approach is up to 34% faster than\nthe IPC-driven heuristic approach in terms of total workload completion time.\nThe complexity of our algorithm is O(NlogN) where N is the number of processes.\nTherefore, the proposed optimum algorithm is practical for use.",
    "descriptor": "",
    "authors": [
      "Chien-Hao Chen",
      "Ren-Song Tsay"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Operating Systems (cs.OS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2109.04605"
  },
  {
    "id": "arXiv:2109.04606",
    "title": "Risk-bounded Path Planning for Urban Air Mobility Operations under  Uncertainty",
    "abstract": "Collision avoidance is an essential concern for the autonomous operations of\naerial vehicles in dynamic and uncertain urban environments. This paper\nintroduces a risk-bounded path planning algorithm for unmanned aerial vehicles\n(UAVs) operating in such environments. This algorithm advances the\nrapidly-exploring random tree (RRT) with chance constraints to generate\nprobabilistically guaranteed collision-free paths that are robust to vehicle\nand environmental obstacle uncertainties. Assuming all uncertainties follow\nGaussian distributions, the chance constraints are established through\nconverting dynamic and probabilistic constraints into equivalent static and\ndeterministic constraints. By incorporating chance constraints into the RRT\nalgorithm, the proposed algorithm not only inherits the computational advantage\nof sampling-based algorithms but also guarantees a probabilistically feasible\nflying zone at every time step. Simulation results show the promising\nperformance of the proposed algorithm.",
    "descriptor": "\nComments: 13pages, IEEE journal article\n",
    "authors": [
      "Pengcheng Wu",
      "Junfei Xie",
      "Yanchao Liu",
      "Jun Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04606"
  },
  {
    "id": "arXiv:2109.04607",
    "title": "IndoBERTweet: A Pretrained Language Model for Indonesian Twitter with  Effective Domain-Specific Vocabulary Initialization",
    "abstract": "We present IndoBERTweet, the first large-scale pretrained model for\nIndonesian Twitter that is trained by extending a monolingually-trained\nIndonesian BERT model with additive domain-specific vocabulary. We focus in\nparticular on efficient model adaptation under vocabulary mismatch, and\nbenchmark different ways of initializing the BERT embedding layer for new word\ntypes. We find that initializing with the average BERT subword embedding makes\npretraining five times faster, and is more effective than proposed methods for\nvocabulary adaptation in terms of extrinsic evaluation over seven Twitter-based\ndatasets.",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Fajri Koto",
      "Jey Han Lau",
      "Timothy Baldwin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04607"
  },
  {
    "id": "arXiv:2109.04608",
    "title": "Spatially Focused Attack against Spatiotemporal Graph Neural Networks",
    "abstract": "Spatiotemporal forecasting plays an essential role in various applications in\nintelligent transportation systems (ITS), such as route planning, navigation,\nand traffic control and management. Deep Spatiotemporal graph neural networks\n(GNNs), which capture both spatial and temporal patterns, have achieved great\nsuccess in traffic forecasting applications. Understanding how GNNs-based\nforecasting work and the vulnerability and robustness of these models becomes\ncritical to real-world applications. For example, if spatiotemporal GNNs are\nvulnerable in real-world traffic prediction applications, a hacker can easily\nmanipulate the results and cause serious traffic congestion and even a\ncity-scale breakdown. However, despite that recent studies have demonstrated\nthat deep neural networks (DNNs) are vulnerable to carefully designed\nperturbations in multiple domains like objection classification and graph\nrepresentation, current adversarial works cannot be directly applied to\nspatiotemporal forecasting due to the causal nature and spatiotemporal\nmechanisms in forecasting models. To fill this gap, in this paper we design\nSpatially Focused Attack (SFA) to break spatiotemporal GNNs by attacking a\nsingle vertex. To achieve this, we first propose the inverse estimation to\naddress the causality issue; then, we apply genetic algorithms with a universal\nattack method as the evaluation function to locate the weakest vertex; finally,\nperturbations are generated by solving an inverse estimation-based optimization\nproblem. We conduct experiments on real-world traffic data and our results show\nthat perturbations in one vertex designed by SA can be diffused into a large\npart of the graph.",
    "descriptor": "",
    "authors": [
      "Fuqiang Liu",
      "Luis Miranda-Moreno",
      "Lijun Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04608"
  },
  {
    "id": "arXiv:2109.04609",
    "title": "An Exploratory Study on Long Dialogue Summarization: What Works and  What's Next",
    "abstract": "Dialogue summarization helps readers capture salient information from long\nconversations in meetings, interviews, and TV series. However, real-world\ndialogues pose a great challenge to current summarization models, as the\ndialogue length typically exceeds the input limits imposed by recent\ntransformer-based pre-trained models, and the interactive nature of dialogues\nmakes relevant information more context-dependent and sparsely distributed than\nnews articles. In this work, we perform a comprehensive study on long dialogue\nsummarization by investigating three strategies to deal with the lengthy input\nproblem and locate relevant information: (1) extended transformer models such\nas Longformer, (2) retrieve-then-summarize pipeline models with several\ndialogue utterance retrieval methods, and (3) hierarchical dialogue encoding\nmodels such as HMNet. Our experimental results on three long dialogue datasets\n(QMSum, MediaSum, SummScreen) show that the retrieve-then-summarize pipeline\nmodels yield the best performance. We also demonstrate that the summary quality\ncan be further improved with a stronger retrieval model and pretraining on\nproper external summarization datasets.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Yusen Zhang",
      "Ansong Ni",
      "Tao Yu",
      "Rui Zhang",
      "Chenguang Zhu",
      "Budhaditya Deb",
      "Asli Celikyilmaz",
      "Ahmed Hassan Awadallah",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04609"
  },
  {
    "id": "arXiv:2109.04611",
    "title": "Query-driven Segment Selection for Ranking Long Documents",
    "abstract": "Transformer-based rankers have shown state-of-the-art performance. However,\ntheir self-attention operation is mostly unable to process long sequences. One\nof the common approaches to train these rankers is to heuristically select some\nsegments of each document, such as the first segment, as training data.\nHowever, these segments may not contain the query-related parts of documents.\nTo address this problem, we propose query-driven segment selection from long\ndocuments to build training data. The segment selector provides relevant\nsamples with more accurate labels and non-relevant samples which are harder to\nbe predicted. The experimental results show that the basic BERT-based ranker\ntrained with the proposed segment selector significantly outperforms that\ntrained by the heuristically selected segments, and performs equally to the\nstate-of-the-art model with localized self-attention that can process longer\ninput sequences. Our findings open up new direction to design efficient\ntransformer-based rankers.",
    "descriptor": "\nComments: 5 pages, 0 figure\n",
    "authors": [
      "Youngwoo Kim",
      "Razieh Rahimi",
      "Hamed Bonab",
      "James Allan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04611"
  },
  {
    "id": "arXiv:2109.04614",
    "title": "A Fast-and-Effective Early-Stage Multi-level Cache Optimization Method  Based on Reuse-Distance Analysis",
    "abstract": "In this paper, we propose a practical and effective approach allowing\ndesigners to optimize multi-level cache size at the early system design phase.\nOur key contribution is to generalize the reuse distance analysis method and\ndevelop an effective and practical cache design optimization approach. We adopt\na simple scanning search method to locate optimal cache solutions in terms of\ncache size, power consumption, or average data access delay. The proposed\napproach is particularly useful for early-phase system designers and is\nverified to be 150 to 250 times faster than the traditional simulation-based\napproach. In addition, we also introduce a simplified analytical model and\nprovide designers insights about how cache design parameters may affect the\nexpected results. As a result, designers can make an adequate decision in the\nearly system design phase.",
    "descriptor": "",
    "authors": [
      "Cheng-Lin Tsai",
      "Ren-Song Tsay"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2109.04614"
  },
  {
    "id": "arXiv:2109.04617",
    "title": "Efficiently Identifying Task Groupings for Multi-Task Learning",
    "abstract": "Multi-task learning can leverage information learned by one task to benefit\nthe training of other tasks. Despite this capacity, naively training all tasks\ntogether in one model often degrades performance, and exhaustively searching\nthrough combinations of task groupings can be prohibitively expensive. As a\nresult, efficiently identifying the tasks that would benefit from co-training\nremains a challenging design question without a clear solution. In this paper,\nwe suggest an approach to select which tasks should train together in\nmulti-task learning models. Our method determines task groupings in a single\ntraining run by co-training all tasks together and quantifying the effect to\nwhich one task's gradient would affect another task's loss. On the large-scale\nTaskonomy computer vision dataset, we find this method can decrease test loss\nby 10.0\\% compared to simply training all tasks together while operating 11.6\ntimes faster than a state-of-the-art task grouping method.",
    "descriptor": "",
    "authors": [
      "Christopher Fifty",
      "Ehsan Amid",
      "Zhe Zhao",
      "Tianhe Yu",
      "Rohan Anil",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04617"
  },
  {
    "id": "arXiv:2109.04620",
    "title": "Rule-based Morphological Inflection Improves Neural Terminology  Translation",
    "abstract": "Current approaches to incorporating terminology constraints in machine\ntranslation (MT) typically assume that the constraint terms are provided in\ntheir correct morphological forms. This limits their application to real-world\nscenarios where constraint terms are provided as lemmas. In this paper, we\nintroduce a modular framework for incorporating lemma constraints in neural MT\n(NMT) in which linguistic knowledge and diverse types of NMT models can be\nflexibly applied. It is based on a novel cross-lingual inflection module that\ninflects the target lemma constraints based on the source context. We explore\nlinguistically motivated rule-based and data-driven neural-based inflection\nmodules and design English-German health and English-Lithuanian news test\nsuites to evaluate them in domain adaptation and low-resource MT settings.\nResults show that our rule-based inflection module helps NMT models incorporate\nlemma constraints more accurately than a neural module and outperforms the\nexisting end-to-end approach with lower training costs.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Weijia Xu",
      "Marine Carpuat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04620"
  },
  {
    "id": "arXiv:2109.04621",
    "title": "An Effective Early Multi-core System Shared Cache Design Method Based on  Reuse-distance Analysis",
    "abstract": "In this paper, we proposed an effective and efficient multi-core shared-cache\ndesign optimization approach based on reuse-distance analysis of the data\ntraces of target applications. Since data traces are independent of system\nhardware architectures, a designer can easily compute the best cache design at\nthe early system design phase using our approach. We devise a very efficient\nand yet accurate method to derive the aggregated reuse-distance histograms of\nconcurrent applications for accurate cache performance analysis and\noptimization. Essentially, the actual shared-cache contention results of\nconcurrent applications are embedded in the aggregated reuse-distance\nhistograms and therefore the approach is very effective. The experimental\nresults show that the average error rate of shared-cache miss-count estimations\nof our approach is less than 2.4%. Using a simple scanning search method, one\ncan easily determine the true optimal cache configurations at the early system\ndesign phase.",
    "descriptor": "",
    "authors": [
      "Hsin-Yu Ho",
      "Ren-Song Tsay"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2109.04621"
  },
  {
    "id": "arXiv:2109.04623",
    "title": "ReLU Regression with Massart Noise",
    "abstract": "We study the fundamental problem of ReLU regression, where the goal is to fit\nRectified Linear Units (ReLUs) to data. This supervised learning task is\nefficiently solvable in the realizable setting, but is known to be\ncomputationally hard with adversarial label noise. In this work, we focus on\nReLU regression in the Massart noise model, a natural and well-studied\nsemi-random noise model. In this model, the label of every point is generated\naccording to a function in the class, but an adversary is allowed to change\nthis value arbitrarily with some probability, which is {\\em at most} $\\eta <\n1/2$. We develop an efficient algorithm that achieves exact parameter recovery\nin this model under mild anti-concentration assumptions on the underlying\ndistribution. Such assumptions are necessary for exact recovery to be\ninformation-theoretically possible. We demonstrate that our algorithm\nsignificantly outperforms naive applications of $\\ell_1$ and $\\ell_2$\nregression on both synthetic and real data.",
    "descriptor": "",
    "authors": [
      "Ilias Diakonikolas",
      "Jongho Park",
      "Christos Tzamos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04623"
  },
  {
    "id": "arXiv:2109.04624",
    "title": "Style Pooling: Automatic Text Style Obfuscation for Improved  Classification Fairness",
    "abstract": "Text style can reveal sensitive attributes of the author (e.g. race or age)\nto the reader, which can, in turn, lead to privacy violations and bias in both\nhuman and algorithmic decisions based on text. For example, the style of\nwriting in job applications might reveal protected attributes of the candidate\nwhich could lead to bias in hiring decisions, regardless of whether hiring\ndecisions are made algorithmically or by humans. We propose a VAE-based\nframework that obfuscates stylistic features of human-generated text through\nstyle transfer by automatically re-writing the text itself. Our framework\noperationalizes the notion of obfuscated style in a flexible way that enables\ntwo distinct notions of obfuscated style: (1) a minimal notion that effectively\nintersects the various styles seen in training, and (2) a maximal notion that\nseeks to obfuscate by adding stylistic features of all sensitive attributes to\ntext, in effect, computing a union of styles. Our style-obfuscation framework\ncan be used for multiple purposes, however, we demonstrate its effectiveness in\nimproving the fairness of downstream classifiers. We also conduct a\ncomprehensive study on style pooling's effect on fluency, semantic consistency,\nand attribute removal from text, in two and three domain style obfuscation.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04624"
  },
  {
    "id": "arXiv:2109.04626",
    "title": "A Fast PC Algorithm with Reversed-order Pruning and A Parallelization  Strategy",
    "abstract": "The PC algorithm is the state-of-the-art algorithm for causal structure\ndiscovery on observational data. It can be computationally expensive in the\nworst case due to the conditional independence tests are performed in an\nexhaustive-searching manner. This makes the algorithm computationally\nintractable when the task contains several hundred or thousand nodes,\nparticularly when the true underlying causal graph is dense. We propose a\ncritical observation that the conditional set rendering two nodes independent\nis non-unique, and including certain redundant nodes do not sacrifice result\naccuracy. Based on this finding, the innovations of our work are two-folds.\nFirst, we innovate on a reserve order linkage pruning PC algorithm which\nsignificantly increases the algorithm's efficiency. Second, we propose a\nparallel computing strategy for statistical independence tests by leveraging\ntensor computation, which brings further speedup. We also prove the proposed\nalgorithm does not induce statistical power loss under mild graph and data\ndimensionality assumptions. Experimental results show that the single-threaded\nversion of the proposed algorithm can achieve a 6-fold speedup compared to the\nPC algorithm on a dense 95-node graph, and the parallel version can make a\n825-fold speed-up. We also provide proof that the proposed algorithm is\nconsistent under the same set of conditions with conventional PC algorithm.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Kai Zhang",
      "Chao Tian",
      "Kun Zhang",
      "Todd Johnson",
      "Xiaoqian Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2109.04626"
  },
  {
    "id": "arXiv:2109.04627",
    "title": "ACFNet: Adaptively-Cooperative Fusion Network for RGB-D Salient Object  Detection",
    "abstract": "The reasonable employment of RGB and depth data show great significance in\npromoting the development of computer vision tasks and robot-environment\ninteraction. However, there are different advantages and disadvantages in the\nearly and late fusion of the two types of data. Besides, due to the diversity\nof object information, using a single type of data in a specific scenario tends\nto result in semantic misleading. Based on the above considerations, we propose\nan adaptively-cooperative fusion network (ACFNet) with ResinRes structure for\nsalient object detection. This structure is designed to flexibly utilize the\nadvantages of feature fusion in early and late stages. Secondly, an\nadaptively-cooperative semantic guidance (ACG) scheme is designed to suppress\ninaccurate features in the guidance phase. Further, we proposed a type-based\nattention module (TAM) to optimize the network and enhance the multi-scale\nperception of different objects. For different objects, the features generated\nby different types of convolution are enhanced or suppressed by the gated\nmechanism for segmentation optimization. ACG and TAM optimize the transfer of\nfeature streams according to their data attributes and convolution attributes,\nrespectively. Sufficient experiments conducted on RGB-D SOD datasets illustrate\nthat the proposed network performs favorably against 18 state-of-the-art\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Jinchao Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04627"
  },
  {
    "id": "arXiv:2109.04629",
    "title": "An Overview of the HFL Model Checking Project",
    "abstract": "In this article, we give an overview of our project on higher-order program\nverification based on HFL (higher-order fixpoint logic) model checking. After a\nbrief introduction to HFL, we explain how it can be applied to program\nverification, and summarize the current status of the project.",
    "descriptor": "\nComments: In Proceedings HCVS 2021, arXiv:2109.03988\n",
    "authors": [
      "Naoki Kobayashi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.04629"
  },
  {
    "id": "arXiv:2109.04630",
    "title": "Termination Analysis of Programs with Multiphase Control-Flow",
    "abstract": "Programs with multiphase control-flow are programs where the execution passes\nthrough several (possibly implicit) phases. Proving termination of such\nprograms (or inferring corresponding runtime bounds) is often challenging since\nit requires reasoning on these phases separately. In this paper we discuss\ntechniques for proving termination of such programs, in particular: (1) using\nmultiphase ranking functions, where we will discuss theoretical aspects of such\nranking functions for several kinds of program representations; and (2) using\ncontrol-flow refinement, in particular partial evaluation of Constrained Horn\nClauses, to simplify the control-flow allowing, among other things, to prove\ntermination with simpler ranking functions.",
    "descriptor": "\nComments: In Proceedings HCVS 2021, arXiv:2109.03988\n",
    "authors": [
      "Jes\u00fas J. Domenech",
      "Samir Genaim"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.04630"
  },
  {
    "id": "arXiv:2109.04631",
    "title": "Regular Path Clauses and Their Application in Solving Loops",
    "abstract": "A well-established approach to reasoning about loops during program analysis\nis to capture the effect of a loop by extracting recurrences from the loop;\nthese express relationships between the values of variables, or program\nproperties such as cost, on successive loop iterations. Recurrence solvers are\ncapable of computing closed forms for some recurrences, thus deriving precise\nrelationships capturing the complete loop execution. However, many recurrences\nextracted from loops cannot be solved, due to their having multiple recursive\ncases or multiple arguments. In the literature, several techniques for\napproximating the solution of unsolvable recurrences have been proposed. The\napproach presented in this paper is to define transformations based on regular\npath expressions and loop counters that (i) transform multi-path loops to\nsingle-path loops, giving rise to recurrences with a single recursive case, and\n(ii) transform multi-argument recurrences to single-argument recurrences, thus\nenabling the use of recurrence solvers on the transformed recurrences. Using\nthis approach, precise solutions can sometimes be obtained that are not\nobtained by approximation methods.",
    "descriptor": "\nComments: In Proceedings HCVS 2021, arXiv:2109.03988\n",
    "authors": [
      "Bishoksan Kafle",
      "John P. Gallagher",
      "Manuel V. Hermenegildo",
      "Maximiliano Klemen",
      "Pedro L\u00f3pez-Garc\u00eda",
      "Jos\u00e9 F. Morales"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.04631"
  },
  {
    "id": "arXiv:2109.04632",
    "title": "Reducing Higher-order Recursion Scheme Equivalence to Coinductive  Higher-order Constrained Horn Clauses",
    "abstract": "Higher-order constrained Horn clauses (HoCHC) are a semantically-invariant\nsystem of higher-order logic modulo theories. With semi-decidable unsolvability\nover a semi-decidable background theory, HoCHC is suitable for safety\nverification. Less is known about its relation to larger classes of\nhigher-order verification problems. Motivated by program equivalence, we\nintroduce a coinductive version of HoCHC that enjoys a greatest model property.\nWe define an encoding of higher-order recursion schemes (HoRS) into HoCHC logic\nprograms. Correctness of this encoding reduces decidability of the open HoRS\nequivalence problem -- and, thus, the LambdaY-calculus B\\\"ohm tree equivalence\nproblem -- to semi-decidability of coinductive HoCHC over a complete and\ndecidable theory of trees.",
    "descriptor": "\nComments: In Proceedings HCVS 2021, arXiv:2109.03988\n",
    "authors": [
      "Jerome Jochems"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.04632"
  },
  {
    "id": "arXiv:2109.04633",
    "title": "A Fixed-point Theorem for Horn Formula Equations",
    "abstract": "We consider constrained Horn clause solving from the more general point of\nview of solving formula equations. Constrained Horn clauses correspond to the\nsubclass of Horn formula equations. We state and prove a fixed-point theorem\nfor Horn formula equations which is based on expressing the fixed-point\ncomputation of a minimal model of a set of Horn clauses on the object level as\na formula in first-order logic with a least fixed point operator. We describe\nseveral corollaries of this fixed-point theorem, in particular concerning the\nlogical foundations of program verification, and sketch how to generalise it to\nincorporate abstract interpretations.",
    "descriptor": "\nComments: In Proceedings HCVS 2021, arXiv:2109.03988\n",
    "authors": [
      "Stefan Hetzl",
      "Johannes Kloibhofer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.04633"
  },
  {
    "id": "arXiv:2109.04634",
    "title": "Knowledge-Assisted Reasoning of Model-Augmented System Requirements with  Event Calculus and Goal-Directed Answer Set Programming",
    "abstract": "We consider requirements for cyber-physical systems represented in\nconstrained natural language. We present novel automated techniques for aiding\nin the development of these requirements so that they are consistent and can\nwithstand perceived failures. We show how cyber-physical systems' requirements\ncan be modeled using the event calculus (EC), a formalism used in AI for\nrepresenting actions and change. We also show how answer set programming (ASP)\nand its query-driven implementation s(CASP) can be used to directly realize the\nevent calculus model of the requirements. This event calculus model can be used\nto automatically validate the requirements. Since ASP is an expressive\nknowledge representation language, it can also be used to represent contextual\nknowledge about cyber-physical systems, which, in turn, can be used to find\ngaps in their requirements specifications. We illustrate our approach through\nan altitude alerting system from the avionics domain.",
    "descriptor": "\nComments: In Proceedings HCVS 2021, arXiv:2109.03988\n",
    "authors": [
      "Brendan Hall",
      "Sarat Chandra Varanasi",
      "Jan Fiedor",
      "Joaqu\u00edn Arias",
      "Kinjal Basu",
      "Fang Li",
      "Devesh Bhatt",
      "Kevin Driscoll",
      "Elmer Salazar",
      "Gopal Gupta"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2109.04634"
  },
  {
    "id": "arXiv:2109.04635",
    "title": "Competition Report: CHC-COMP-21",
    "abstract": "CHC-COMP-21 is the fourth competition of solvers for Constrained Horn\nClauses. In this year, 7 solvers participated at the competition, and were\nevaluated in 7 separate tracks on problems in linear integer arithmetic, linear\nreal arithmetic, arrays, and algebraic data-types. The competition was run in\nMarch 2021 using the StarExec computing cluster. This report gives an overview\nof the competition design, explains the organisation of the competition, and\npresents the competition results.",
    "descriptor": "\nComments: In Proceedings HCVS 2021, arXiv:2109.03988. arXiv admin note: substantial text overlap with arXiv:2008.02939\n",
    "authors": [
      "Grigory Fedyukovich",
      "Philipp R\u00fcmmer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2109.04635"
  },
  {
    "id": "arXiv:2109.04636",
    "title": "STL2vec: Signal Temporal Logic Embeddings for Control Synthesis With  Recurrent Neural Networks",
    "abstract": "In this paper, a method for learning a recurrent neural network (RNN)\ncontroller that maximizes the robustness of signal temporal logic (STL)\nspecifications is presented. In contrast to previous methods, we consider\nsynthesizing the RNN controller for which the user is able to select an STL\nspecification arbitrarily from multiple STL specifications. To obtain such a\ncontroller, we propose a novel notion called STL2vec, which represents a vector\nrepresentation of the STL specifications and exhibits their similarities. The\nconstruction of the STL2vec is useful since it allows us to enhance the\nefficiency and performance of the RNN controller. We validate our proposed\nmethod through the examples of the path planning problem.",
    "descriptor": "\nComments: submitted for publication\n",
    "authors": [
      "Wataru Hashimoto",
      "Kazumune Hashimoto",
      "Shigemasa Takai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04636"
  },
  {
    "id": "arXiv:2109.04639",
    "title": "GenCAT: Generating Attributed Graphs with Controlled Relationships  between Classes, Attributes, and Topology",
    "abstract": "Generating large synthetic attributed graphs with node labels is an important\ntask to support various experimental studies for graph analysis methods.\nExisting graph generators fail to simultaneously simulate the relationships\nbetween labels, attributes, and topology which real-world graphs exhibit.\nMotivated by this limitation, we propose GenCAT, an attributed graph generator\nfor controlling those relationships, which has the following advantages. (i)\nGenCAT generates graphs with user-specified node degrees and flexibly controls\nthe relationship between nodes and labels by incorporating the connection\nproportion for each node to classes. (ii) Generated attribute values follow\nuser-specified distributions, and users can flexibly control the correlation\nbetween the attributes and labels. (iii) Graph generation scales linearly to\nthe number of edges. GenCAT is the first generator to support all three of\nthese practical features. Through extensive experiments, we demonstrate that\nGenCAT can efficiently generate high-quality complex attributed graphs with\nuser-controlled relationships between labels, attributes, and topology.",
    "descriptor": "",
    "authors": [
      "Seiji Maekawa",
      "Yuya Sasaki",
      "George Fletcher",
      "Makoto Onizuka"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.04639"
  },
  {
    "id": "arXiv:2109.04640",
    "title": "Projected State-action Balancing Weights for Offline Reinforcement  Learning",
    "abstract": "Offline policy evaluation (OPE) is considered a fundamental and challenging\nproblem in reinforcement learning (RL). This paper focuses on the value\nestimation of a target policy based on pre-collected data generated from a\npossibly different policy, under the framework of infinite-horizon Markov\ndecision processes. Motivated by the recently developed marginal importance\nsampling method in RL and the covariate balancing idea in causal inference, we\npropose a novel estimator with approximately projected state-action balancing\nweights for the policy value estimation. We obtain the convergence rate of\nthese weights, and show that the proposed value estimator is semi-parametric\nefficient under technical conditions. In terms of asymptotics, our results\nscale with both the number of trajectories and the number of decision points at\neach trajectory. As such, consistency can still be achieved with a limited\nnumber of subjects when the number of decision points diverges. In addition, we\nmake a first attempt towards characterizing the difficulty of OPE problems,\nwhich may be of independent interest. Numerical experiments demonstrate the\npromising performance of our proposed estimator.",
    "descriptor": "",
    "authors": [
      "Jiayi Wang",
      "Zhengling Qi",
      "Raymond K.W. Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.04640"
  },
  {
    "id": "arXiv:2109.04641",
    "title": "Learning to Teach with Student Feedback",
    "abstract": "Knowledge distillation (KD) has gained much attention due to its\neffectiveness in compressing large-scale pre-trained models. In typical KD\nmethods, the small student model is trained to match the soft targets generated\nby the big teacher model. However, the interaction between student and teacher\nis one-way. The teacher is usually fixed once trained, resulting in static soft\ntargets to be distilled. This one-way interaction leads to the teacher's\ninability to perceive the characteristics of the student and its training\nprogress. To address this issue, we propose Interactive Knowledge Distillation\n(IKD), which also allows the teacher to learn to teach from the feedback of the\nstudent. In particular, IKD trains the teacher model to generate specific soft\ntarget at each training step for a certain student. Joint optimization for both\nteacher and student is achieved by two iterative steps: a course step to\noptimize student with the soft target of teacher, and an exam step to optimize\nteacher with the feedback of student. IKD is a general framework that is\northogonal to most existing knowledge distillation methods. Experimental\nresults show that IKD outperforms traditional KD methods on various NLP tasks.",
    "descriptor": "",
    "authors": [
      "Yitao Liu",
      "Tianxiang Sun",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04641"
  },
  {
    "id": "arXiv:2109.04645",
    "title": "CINS: Comprehensive Instruction for Few-shot Learning in  Task-orientedDialog Systems",
    "abstract": "As labeling cost for different modules in task-oriented dialog (ToD) systems\nis high, a major challenge in practice is to learn different tasks with the\nleast amount of labeled data. Recently, prompting methods over pre-trained\nlanguage models (PLMs) have shown promising results for few-shot learning in\nToD. To better utilize the power of PLMs, this paper proposes Comprehensive\nInstruction (CINS) that exploits PLMs with extra task-specific instructions. We\ndesign a schema(definition, constraint, prompt) of instructions and their\ncustomized realizations for three important downstream tasks in ToD, i.e.\nintent classification, dialog state tracking, and natural language generation.\nA sequence-to-sequence model (T5)is adopted to solve these three tasks in a\nunified framework. Extensive experiments are conducted on these ToD tasks in\nrealistic few-shot learning scenarios with small validation data. Empirical\nresults demonstrate that the proposed CINS approach consistently improves\ntechniques that finetune PLMs with raw input or short prompts.",
    "descriptor": "",
    "authors": [
      "Fei Mi",
      "Yitong Li",
      "Yasheng Wang",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04645"
  },
  {
    "id": "arXiv:2109.04646",
    "title": "AI Agents in Emergency Response Applications",
    "abstract": "Emergency personnel respond to various situations ranging from fire, medical,\nhazardous materials, industrial accidents, to natural disasters. Situations\nsuch as natural disasters or terrorist acts require a multifaceted response of\nfirefighters, paramedics, hazmat teams, and other agencies. Engineering AI\nsystems that aid emergency personnel proves to be a difficult system\nengineering problem. Mission-critical \"edge AI\" situations require low-latency,\nreliable analytics. To further add complexity, a high degree of model accuracy\nis required when lives are at stake, creating a need for the deployment of\nhighly accurate, however computationally intensive models to\nresource-constrained devices. To address all these issues, we propose an\nagent-based architecture for deployment of AI agents via 5G service-based\narchitecture.",
    "descriptor": "",
    "authors": [
      "Aryan Naim",
      "Ryan Alimo",
      "Jay Braun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.04646"
  },
  {
    "id": "arXiv:2109.04649",
    "title": "Utilizing Shannon's Entropy to Create Privacy Aware Architectures",
    "abstract": "Privacy is an individual choice to determine which personal details can be\ncollected, used and shared. Individual consent and transparency are the core\ntenets for earning customers trust and this motivates the organizations to\nadopt privacy enhancing practices while creating the systems. The goal of a\nprivacy-aware design is to protect information in a way that does not increase\nan adversary's existing knowledge about an individual beyond what is\npermissible. This becomes critical when these data elements can be linked with\nthe wealth of auxiliary information available outside the system to identify an\nindividual. Privacy regulations around the world provide directives to protect\nindividual privacy but are generally complex and vague, making their\ntranslation into actionable and technical privacy-friendly architectures\nchallenging. In this paper, we utilize Shannon's Entropy to create an objective\nmetric that can help simplify the state-of-the-art Privacy Design Strategies\nproposed in the literature and aid our key technical design decisions to create\nprivacy aware architectures.",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "bhinav Palia",
      "Rajat Tandon",
      "Carl Mathis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.04649"
  },
  {
    "id": "arXiv:2109.04650",
    "title": "What Changes Can Large-scale Language Models Bring? Intensive Study on  HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers",
    "abstract": "GPT-3 shows remarkable in-context learning ability of large-scale language\nmodels (LMs) trained on hundreds of billion scale data. Here we address some\nremaining issues less reported by the GPT-3 paper, such as a non-English LM,\nthe performances of different sized models, and the effect of recently\nintroduced prompt optimization on in-context learning. To achieve this, we\nintroduce HyperCLOVA, a Korean variant of 82B GPT-3 trained on a Korean-centric\ncorpus of 560B tokens. Enhanced by our Korean-specific tokenization, HyperCLOVA\nwith our training configuration shows state-of-the-art in-context zero-shot and\nfew-shot learning performances on various downstream tasks in Korean. Also, we\nshow the performance benefits of prompt-based learning and demonstrate how it\ncan be integrated into the prompt engineering pipeline. Then we discuss the\npossibility of materializing the No Code AI paradigm by providing AI\nprototyping capabilities to non-experts of ML by introducing HyperCLOVA studio,\nan interactive prompt engineering interface. Lastly, we demonstrate the\npotential of our methods with three successful in-house applications.",
    "descriptor": "\nComments: Accepted to EMNLP2021 as a long paper\n",
    "authors": [
      "Boseop Kim",
      "HyoungSeok Kim",
      "Sang-Woo Lee",
      "Gichang Lee",
      "Donghyun Kwak",
      "Dong Hyeon Jeon",
      "Sunghyun Park",
      "Sungju Kim",
      "Seonhoon Kim",
      "Dongpil Seo",
      "Heungsub Lee",
      "Minyoung Jeong",
      "Sungjae Lee",
      "Minsub Kim",
      "Suk Hyun Ko",
      "Seokhun Kim",
      "Taeyong Park",
      "Jinuk Kim",
      "Soyoung Kang",
      "Na-Hyeon Ryu",
      "Kang Min Yoo",
      "Minsuk Chang",
      "Soobin Suh",
      "Sookyo In",
      "Jinseong Park",
      "Kyungduk Kim",
      "Hiun Kim",
      "Jisu Jeong",
      "Yong Goo Yeo",
      "Donghoon Ham",
      "Dongju Park",
      "Min Young Lee",
      "Jaewook Kang",
      "Inho Kang",
      "Jung-Woo Ha",
      "Woomyoung Park",
      "Nako Sung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04650"
  },
  {
    "id": "arXiv:2109.04652",
    "title": "Predicting emergent linguistic compositions through time: Syntactic  frame extension via multimodal chaining",
    "abstract": "Natural language relies on a finite lexicon to express an unbounded set of\nemerging ideas. One result of this tension is the formation of new\ncompositions, such that existing linguistic units can be combined with emerging\nitems into novel expressions. We develop a framework that exploits the\ncognitive mechanisms of chaining and multimodal knowledge to predict emergent\ncompositional expressions through time. We present the syntactic frame\nextension model (SFEM) that draws on the theory of chaining and knowledge from\n\"percept\", \"concept\", and \"language\" to infer how verbs extend their frames to\nform new compositions with existing and novel nouns. We evaluate SFEM\nrigorously on the 1) modalities of knowledge and 2) categorization models of\nchaining, in a syntactically parsed English corpus over the past 150 years. We\nshow that multimodal SFEM predicts newly emerged verb syntax and arguments\nsubstantially better than competing models using purely linguistic or unimodal\nknowledge. We find support for an exemplar view of chaining as opposed to a\nprototype view and reveal how the joint approach of multimodal chaining may be\nfundamental to the creation of literal and figurative language uses including\nmetaphor and metonymy.",
    "descriptor": "",
    "authors": [
      "Lei Yu",
      "Yang Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04652"
  },
  {
    "id": "arXiv:2109.04653",
    "title": "Towards Developing a Multilingual and Code-Mixed Visual Question  Answering System by Knowledge Distillation",
    "abstract": "Pre-trained language-vision models have shown remarkable performance on the\nvisual question answering (VQA) task. However, most pre-trained models are\ntrained by only considering monolingual learning, especially the resource-rich\nlanguage like English. Training such models for multilingual setups demand high\ncomputing resources and multilingual language-vision dataset which hinders\ntheir application in practice. To alleviate these challenges, we propose a\nknowledge distillation approach to extend an English language-vision model\n(teacher) into an equally effective multilingual and code-mixed model\n(student). Unlike the existing knowledge distillation methods, which only use\nthe output from the last layer of the teacher network for distillation, our\nstudent model learns and imitates the teacher from multiple intermediate layers\n(language and vision encoders) with appropriately designed distillation\nobjectives for incremental knowledge extraction. We also create the large-scale\nmultilingual and code-mixed VQA dataset in eleven different language setups\nconsidering the multiple Indian and European languages. Experimental results\nand in-depth analysis show the effectiveness of the proposed VQA model over the\npre-trained language-vision models on eleven diverse language setups.",
    "descriptor": "\nComments: Accepted in EMNLP-Findings (2021)\n",
    "authors": [
      "Humair Raj Khan",
      "Deepak Gupta",
      "Asif Ekbal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04653"
  },
  {
    "id": "arXiv:2109.04654",
    "title": "Per Garment Capture and Synthesis for Real-time Virtual Try-on",
    "abstract": "Virtual try-on is a promising application of computer graphics and human\ncomputer interaction that can have a profound real-world impact especially\nduring this pandemic. Existing image-based works try to synthesize a try-on\nimage from a single image of a target garment, but it inherently limits the\nability to react to possible interactions. It is difficult to reproduce the\nchange of wrinkles caused by pose and body size change, as well as pulling and\nstretching of the garment by hand. In this paper, we propose an alternative per\ngarment capture and synthesis workflow to handle such rich interactions by\ntraining the model with many systematically captured images. Our workflow is\ncomposed of two parts: garment capturing and clothed person image synthesis. We\ndesigned an actuated mannequin and an efficient capturing process that collects\nthe detailed deformations of the target garments under diverse body sizes and\nposes. Furthermore, we proposed to use a custom-designed measurement garment,\nand we captured paired images of the measurement garment and the target\ngarments. We then learn a mapping between the measurement garment and the\ntarget garments using deep image-to-image translation. The customer can then\ntry on the target garments interactively during online shopping.",
    "descriptor": "\nComments: Accepted to UIST2021. Project page: this https URL\n",
    "authors": [
      "Toby Chong",
      "I-Chao Shen",
      "Nobuyuki Umetani",
      "Takeo Igarashi"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04654"
  },
  {
    "id": "arXiv:2109.04655",
    "title": "Zero-Shot Dialogue State Tracking via Cross-Task Transfer",
    "abstract": "Zero-shot transfer learning for dialogue state tracking (DST) enables us to\nhandle a variety of task-oriented dialogue domains without the expense of\ncollecting in-domain data. In this work, we propose to transfer the\n\\textit{cross-task} knowledge from general question answering (QA) corpora for\nthe zero-shot DST task. Specifically, we propose TransferQA, a transferable\ngenerative QA model that seamlessly combines extractive QA and multi-choice QA\nvia a text-to-text transformer framework, and tracks both categorical slots and\nnon-categorical slots in DST. In addition, we introduce two effective ways to\nconstruct unanswerable questions, namely, negative question sampling and\ncontext truncation, which enable our model to handle \"none\" value slots in the\nzero-shot DST setting. The extensive experiments show that our approaches\nsubstantially improve the existing zero-shot and few-shot results on MultiWoz.\nMoreover, compared to the fully trained baseline on the Schema-Guided Dialogue\ndataset, our approach shows better generalization ability in unseen domains.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Zhaojiang Lin",
      "Bing Liu",
      "Andrea Madotto",
      "Seungwhan Moon",
      "Paul Crook",
      "Zhenpeng Zhou",
      "Zhiguang Wang",
      "Zhou Yu",
      "Eunjoon Cho",
      "Rajen Subba",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04655"
  },
  {
    "id": "arXiv:2109.04656",
    "title": "Efficient Black-Box Checking via Model Checking with Strengthened  Specifications",
    "abstract": "Black-box checking (BBC)} is a testing method for cyber-physical systems\n(CPSs) as well as software systems. BBC consists of active automata learning\nand model checking; a Mealy machine is learned from the system under test\n(SUT), and the learned Mealy machine is verified against a specification using\nmodel checking. When the Mealy machine violates the specification, the model\nchecker returns an input witnessing the specification violation of the Mealy\nmachine. We use it to refine the Mealy machine or conclude that the SUT\nviolates the specification. Otherwise, we conduct equivalence testing to find\nan input witnessing the difference between the Mealy machine and the SUT. In\nthe BBC for CPSs, equivalence testing tends to be time-consuming due to the\ntime for the system execution. In this paper, we enhance the BBC utilizing\nmodel checking with strengthened specifications. By model checking with a\nstrengthened specification, we have more chance to obtain an input witnessing\nthe specification violation than model checking with the original\nspecification. The refinement of the Mealy machine with such an input tends to\nreduce the number of equivalence testing, which improves the efficiency. We\nconducted experiments with an automotive benchmark. Our experiment results\ndemonstrate the merit of our method.",
    "descriptor": "\nComments: Accepted to RV'21\n",
    "authors": [
      "Junya Shijubo",
      "Masaki Waga",
      "Kohei Suenaga"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.04656"
  },
  {
    "id": "arXiv:2109.04658",
    "title": "Speech Enhancement by Noise Self-Supervised Rank-Constrained Spatial  Covariance Matrix Estimation via Independent Deeply Learned Matrix Analysis",
    "abstract": "Rank-constrained spatial covariance matrix estimation (RCSCME) is a method\nfor the situation that the directional target speech and the diffuse noise are\nmixed. In conventional RCSCME, independent low-rank matrix analysis (ILRMA) is\nused as the preprocessing method. We propose RCSCME using independent deeply\nlearned matrix analysis (IDLMA), which is a supervised extension of ILRMA. In\nthis method, IDLMA requires deep neural networks (DNNs) to separate the target\nspeech and the noise. We use Denoiser, which is a single-channel speech\nenhancement DNN, in IDLMA to estimate not only the target speech but also the\nnoise. We also propose noise self-supervised RCSCME, in which we estimate the\nnoise-only time intervals using the output of Denoiser and design the prior\ndistribution of the noise spatial covariance matrix for RCSCME. We confirm that\nthe proposed methods outperform the conventional methods under several noise\nconditions.",
    "descriptor": "\nComments: accepted for APSIPA2021\n",
    "authors": [
      "Sota Misawa",
      "Norihiro Takamune",
      "Tomohiko Nakamura",
      "Daichi Kitamura",
      "Hiroshi Saruwatari",
      "Masakazu Une",
      "Shoji Makino"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.04658"
  },
  {
    "id": "arXiv:2109.04660",
    "title": "Dynamic Collective Intelligence Learning: Finding Efficient Sparse Model  via Refined Gradients for Pruned Weights",
    "abstract": "With the growth of deep neural networks (DNN), the number of DNN parameters\nhas drastically increased. This makes DNN models hard to be deployed on\nresource-limited embedded systems. To alleviate this problem, dynamic pruning\nmethods have emerged, which try to find diverse sparsity patterns during\ntraining by utilizing Straight-Through-Estimator (STE) to approximate gradients\nof pruned weights. STE can help the pruned weights revive in the process of\nfinding dynamic sparsity patterns. However, using these coarse gradients causes\ntraining instability and performance degradation owing to the unreliable\ngradient signal of the STE approximation. In this work, to tackle this issue,\nwe introduce refined gradients to update the pruned weights by forming dual\nforwarding paths from two sets (pruned and unpruned) of weights. We propose a\nnovel Dynamic Collective Intelligence Learning (DCIL) which makes use of the\nlearning synergy between the collective intelligence of both weight sets. We\nverify the usefulness of the refined gradients by showing enhancements in the\ntraining stability and the model performance on the CIFAR and ImageNet\ndatasets. DCIL outperforms various previously proposed pruning schemes\nincluding other dynamic pruning methods with enhanced stability during\ntraining.",
    "descriptor": "",
    "authors": [
      "Jangho Kim",
      "Jayeon Yoo",
      "Yeji Song",
      "KiYoon Yoo",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04660"
  },
  {
    "id": "arXiv:2109.04661",
    "title": "Sixteen Years of Phishing User Studies: What Have We Learned?",
    "abstract": "Several previous studies have investigated user susceptibility to phishing\nattacks. A thorough meta-analysis or systematic review is required to gain a\nbetter understanding of these findings and to assess the strength of evidence\nfor phishing susceptibility of a subpopulation, e.g., older users. We aim to\ndetermine whether an effect exists; another aim is to determine whether the\neffect is positive or negative and to obtain a single summary estimate of the\neffect.\nOBJECTIVES: We systematically review the results of previous user studies on\nphishing susceptibility and conduct a meta-analysis.\nMETHOD: We searched four online databases for English studies on phishing. We\nincluded all user studies in phishing detection and prevention, whether they\nproposed new training techniques or analyzed users' vulnerability.\nFINDINGS: A careful analysis reveals some discrepancies between the findings.\nMore than half of the studies that analyzed the effect of age reported no\nstatistically significant relationship between age and users' performance. Some\nstudies reported older people performed better while some reported the\nopposite. A similar finding holds for the gender difference. The meta-analysis\nshows: 1) a significant relationship between participants' age and their\nsusceptibility 2) females are more susceptible than males 3) users training\nsignificantly improves their detection ability",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Shahryar Baki",
      "Rakesh Verma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04661"
  },
  {
    "id": "arXiv:2109.04666",
    "title": "Euphemistic Phrase Detection by Masked Language Model",
    "abstract": "It is a well-known approach for fringe groups and organizations to use\neuphemisms -- ordinary-sounding and innocent-looking words with a secret\nmeaning -- to conceal what they are discussing. For instance, drug dealers\noften use \"pot\" for marijuana and \"avocado\" for heroin. From a social media\ncontent moderation perspective, though recent advances in NLP have enabled the\nautomatic detection of such single-word euphemisms, no existing work is capable\nof automatically detecting multi-word euphemisms, such as \"blue dream\"\n(marijuana) and \"black tar\" (heroin). Our paper tackles the problem of\neuphemistic phrase detection without human effort for the first time, as far as\nwe are aware. We first perform phrase mining on a raw text corpus (e.g., social\nmedia posts) to extract quality phrases. Then, we utilize word embedding\nsimilarities to select a set of euphemistic phrase candidates. Finally, we rank\nthose candidates by a masked language model -- SpanBERT. Compared to strong\nbaselines, we report 20-50% higher detection accuracies using our algorithm for\ndetecting euphemistic phrases.",
    "descriptor": "",
    "authors": [
      "Wanzheng Zhu",
      "Suma Bhat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04666"
  },
  {
    "id": "arXiv:2109.04667",
    "title": "A structure preserving numerical scheme for Fokker-Planck equations of  structured neural networks with learning rules",
    "abstract": "In this work, we are concerned with a Fokker-Planck equation related to the\nnonlinear noisy leaky integrate-and-fire model for biological neural networks\nwhich are structured by the synaptic weights and equipped with the Hebbian\nlearning rule. The equation contains a small parameter $\\varepsilon$ separating\nthe time scales of learning and reacting behavior of the neural system, and an\nasymptotic limit model can be derived by letting $\\varepsilon\\to 0$, where the\nmicroscopic quasi-static states and the macroscopic evolution equation are\ncoupled through the total firing rate. To handle the endowed flux-shift\nstructure and the multi-scale dynamics in a unified framework, we propose a\nnumerical scheme for this equation that is mass conservative, unconditionally\npositivity preserving, and asymptotic preserving. We provide extensive\nnumerical tests to verify the schemes' properties and carry out a set of\nnumerical experiments to investigate the model's learning ability, and explore\nthe solution's behavior when the neural network is excitatory.",
    "descriptor": "\nComments: 24 pages, 8 figures\n",
    "authors": [
      "Qing He",
      "Jingwei Hu",
      "Zhennan Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04667"
  },
  {
    "id": "arXiv:2109.04672",
    "title": "Investigating Numeracy Learning Ability of a Text-to-Text Transfer Model",
    "abstract": "The transformer-based pre-trained language models have been tremendously\nsuccessful in most of the conventional NLP tasks. But they often struggle in\nthose tasks where numerical understanding is required. Some possible reasons\ncan be the tokenizers and pre-training objectives which are not specifically\ndesigned to learn and preserve numeracy. Here we investigate the ability of\ntext-to-text transfer learning model (T5), which has outperformed its\npredecessors in the conventional NLP tasks, to learn numeracy. We consider four\nnumeracy tasks: numeration, magnitude order prediction, finding minimum and\nmaximum in a series, and sorting. We find that, although T5 models perform\nreasonably well in the interpolation setting, they struggle considerably in the\nextrapolation setting across all four tasks.",
    "descriptor": "\nComments: 7 pages, 10 figures, 5 tables, Accepted in the Findings of EMNLP 2021\n",
    "authors": [
      "Kuntal Kumar Pal",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04672"
  },
  {
    "id": "arXiv:2109.04673",
    "title": "DIALKI: Knowledge Identification in Conversational Systems through  Dialogue-Document Contextualization",
    "abstract": "Identifying relevant knowledge to be used in conversational systems that are\ngrounded in long documents is critical to effective response generation. We\nintroduce a knowledge identification model that leverages the document\nstructure to provide dialogue-contextualized passage encodings and better\nlocate knowledge relevant to the conversation. An auxiliary loss captures the\nhistory of dialogue-document connections. We demonstrate the effectiveness of\nour model on two document-grounded conversational datasets and provide analyses\nshowing generalization to unseen documents and long dialogue contexts.",
    "descriptor": "\nComments: EMNLP 2021 camera-ready\n",
    "authors": [
      "Zeqiu Wu",
      "Bo-Ru Lu",
      "Hannaneh Hajishirzi",
      "Mari Ostendorf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04673"
  },
  {
    "id": "arXiv:2109.04674",
    "title": "Follow the Gradient: Crossing the Reality Gap using Differentiable  Physics (RealityGrad)",
    "abstract": "We propose a novel iterative approach for crossing the reality gap that\nutilises live robot rollouts and differentiable physics. Our method,\nRealityGrad, demonstrates for the first time, an efficient sim2real transfer in\ncombination with a real2sim model optimisation for closing the reality gap.\nDifferentiable physics has become an alluring alternative to classical\nrigid-body simulation due to the current culmination of automatic\ndifferentiation libraries, compute and non-linear optimisation libraries. Our\nmethod builds on this progress and employs differentiable physics for efficient\ntrajectory optimisation. We demonstrate RealitGrad on a dynamic control task\nfor a serial link robot manipulator and present results that show its\nefficiency and ability to quickly improve not just the robot's performance in\nreal world tasks but also enhance the simulation model for future tasks. One\niteration of RealityGrad takes less than 22 minutes on a desktop computer while\nreducing the error by 2/3, making it efficient compared to other sim2real\nmethods in both compute and time. Our methodology and application of\ndifferentiable physics establishes a promising approach for crossing the\nreality gap and has great potential for scaling to complex environments.",
    "descriptor": "\nComments: 8 Pages\n",
    "authors": [
      "Jack Collins",
      "Ross Brown",
      "J\u00fcrgen Leitner",
      "David Howard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04674"
  },
  {
    "id": "arXiv:2109.04676",
    "title": "On a Numerical Solution of Structural model for the Probability of  Defaultunder a Regime-Switching Synchronous-Jump Tempered Stable L\u00e9vyModel  with Desingularized Meshfree Collocation method",
    "abstract": "In the paper [Hainaut, D. and Colwell, D.B., A structural model for credit\nrisk with switchingprocesses and synchronous jumps, The European Journal of\nFinance44(33) (4238):3262-3284],the authors exploit a synchronous-jump\nregime-switching model to compute the default probabilityof a publicly traded\ncompany. Here, we first generalize the proposed L\\'evy model to more\ngeneralsetting of tempered stable processes recently introduced into the\nfinance literature. Based on thesingularity of the resulting partial\nintegro-differential operator, we propose a general frameworkbased on strictly\npositive-definite functions to de-singularize the operator. We then analyze\nanefficient meshfree collocation method based on radial basis functions to\napproximate the solution ofthe corresponding system of partial\nintegro-differential equations arising from the structural creditrisk model. We\nshow that under some regularity assumptions, our proposed method\nnaturallyde-sinularizes the problem in the tempered stable case. Numerical\nresults of applying the methodon some standard examples from the literature\nconfirms the accuracy of our theoretical results andnumerical algorithm.",
    "descriptor": "",
    "authors": [
      "Davood Damircheli",
      "Seyed-Mohammad-Mahdi Kazemi",
      "Ali Foroush Bastani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04676"
  },
  {
    "id": "arXiv:2109.04677",
    "title": "Optimizing Space Utilization for More Effective Multi-Robot Path  Planning",
    "abstract": "We perform a systematic exploration of the principle of Space Utilization\nOptimization (SUO) as a heuristic for planning better individual paths in a\ndecoupled multi-robot path planner, with applications to both one-shot and\nlife-long multi-robot path planning problems. We show that the decentralized\nheuristic set, SU-I, preserves single path optimality and significantly reduces\ncongestion that naturally happens when many paths are planned without\ncoordination. Integration of SU-I into complete planners brings dramatic\nreductions in computation time due to the significantly reduced number of\nconflicts and leads to sizable solution optimality gains in diverse evaluation\nscenarios with medium and large maps, for both one-shot and life-long problem\nsettings.",
    "descriptor": "\nComments: Submitting to ICRA 2022\n",
    "authors": [
      "Shuai D. Han",
      "Jingjin Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04677"
  },
  {
    "id": "arXiv:2109.04681",
    "title": "Jammkle: Fibre jamming 3D printed multi-material tendons and their  application in a robotic ankle",
    "abstract": "Fibre jamming is a relatively new and understudied soft robotic mechanism\nthat has previously found success when used in stiffness-tuneable arms and\nfingers. However, to date researchers have not fully taken advantage of the\nfreedom offered by contemporary fabrication techniques including multi-material\n3D printing in the creation of fibre jamming structures. In this research, we\npresent a novel, modular, multi-material, 3D printed, fibre jamming tendon unit\nfor use in a stiffness-tuneable compliant robotic ankle, or Jammkle. We\ndescribe the design and fabrication of the Jammkle and highlight its advantages\ncompared to examples from modern literature. We develop a multiphysics model of\nthe tendon unit, showing good agreement with experimental data. Finally, we\ndemonstrate a practical application by integrating multiple tendon units into a\nrobotic ankle and perform extensive testing and characterisation. We show that\nthe Jammkle outperforms comparative leg structures in terms of compliance,\ndamping, and slip prevention.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "James Brett",
      "Katrina Lo Surdo",
      "Lauren Hanson",
      "Joshua Pinskier",
      "David Howard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04681"
  },
  {
    "id": "arXiv:2109.04683",
    "title": "PIP: Physical Interaction Prediction via Mental Imagery with Span  Selection",
    "abstract": "To align advanced artificial intelligence (AI) with human values and promote\nsafe AI, it is important for AI to predict the outcome of physical\ninteractions. Even with the ongoing debates on how humans predict the outcomes\nof physical interactions among objects in the real world, there are works\nattempting to tackle this task via cognitive-inspired AI approaches. However,\nthere is still a lack of AI approaches that mimic the mental imagery humans use\nto predict physical interactions in the real world. In this work, we propose a\nnovel PIP scheme: Physical Interaction Prediction via Mental Imagery with Span\nSelection. PIP utilizes a deep generative model to output future frames of\nphysical interactions among objects before extracting crucial information for\npredicting physical interactions by focusing on salient frames using span\nselection. To evaluate our model, we propose a large-scale SPACE+ dataset of\nsynthetic video frames, including three physical interaction events in a 3D\nenvironment. Our experiments show that PIP outperforms baselines and human\nperformance in physical interaction prediction for both seen and unseen\nobjects. Furthermore, PIP's span selection scheme can effectively identify the\nframes where physical interactions among objects occur within the generated\nframes, allowing for added interpretability.",
    "descriptor": "",
    "authors": [
      "Jiafei Duan",
      "Samson Yu",
      "Soujanya Poria",
      "Bihan Wen",
      "Cheston Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04683"
  },
  {
    "id": "arXiv:2109.04684",
    "title": "Enhancing Unsupervised Anomaly Detection with Score-Guided Network",
    "abstract": "Anomaly detection plays a crucial role in various real-world applications,\nincluding healthcare and finance systems. Owing to the limited number of\nanomaly labels in these complex systems, unsupervised anomaly detection methods\nhave attracted great attention in recent years. Two major challenges faced by\nthe existing unsupervised methods are: (i) distinguishing between normal and\nabnormal data in the transition field, where normal and abnormal data are\nhighly mixed together; (ii) defining an effective metric to maximize the gap\nbetween normal and abnormal data in a hypothesis space, which is built by a\nrepresentation learner. To that end, this work proposes a novel scoring network\nwith a score-guided regularization to learn and enlarge the anomaly score\ndisparities between normal and abnormal data. With such score-guided strategy,\nthe representation learner can gradually learn more informative representation\nduring the model training stage, especially for the samples in the transition\nfield. We next propose a score-guided autoencoder (SG-AE), incorporating the\nscoring network into an autoencoder framework for anomaly detection, as well as\nother three state-of-the-art models, to further demonstrate the effectiveness\nand transferability of the design. Extensive experiments on both synthetic and\nreal-world datasets demonstrate the state-of-the-art performance of these\nscore-guided models (SGMs).",
    "descriptor": "",
    "authors": [
      "Zongyuan Huang",
      "Baohua Zhang",
      "Guoqiang Hu",
      "Longyuan Li",
      "Yanyan Xu",
      "Yaohui Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04684"
  },
  {
    "id": "arXiv:2109.04685",
    "title": "Residual 3D Scene Flow Learning with Context-Aware Feature Extraction",
    "abstract": "Scene flow estimation is the task to predict the point-wise 3D displacement\nvector between two consecutive frames of point clouds, which has important\napplication in fields such as service robots and autonomous driving. Although\nmany previous works have explored greatly on scene flow estimation based on\npoint clouds, we point out two problems that have not been noticed or well\nsolved before: 1) Points of adjacent frames in repetitive patterns may be\nwrongly associated due to similar spatial structure in their neighbourhoods; 2)\nScene flow between adjacent frames of point clouds with long-distance movement\nmay be inaccurately estimated. To solve the first problem, we propose a novel\ncontext-aware set conv layer to exploit contextual structure information of\nEuclidean space and learn soft aggregation weights for local point features.\nOur design is inspired by human perception of contextual structure information\nduring scene understanding. We incorporate the context-aware set conv layer in\na context-aware point feature pyramid module of 3D point clouds for scene flow\nestimation. For the second problem, we propose an explicit residual flow\nlearning structure in the residual flow refinement layer to cope with\nlong-distance movement. The experiments and ablation study on FlyingThings3D\nand KITTI scene flow datasets demonstrate the effectiveness of each proposed\ncomponent and that we solve problem of ambiguous inter-frame association and\nlong-distance movement estimation. Quantitative results on both FlyingThings3D\nand KITTI scene flow datasets show that our method achieves state-of-the-art\nperformance, surpassing all other previous works to the best of our knowledge\nby at least 25%.",
    "descriptor": "\nComments: 8 pages, 4 figures, under review\n",
    "authors": [
      "Guangming Wang",
      "Yunzhe Hu",
      "Xinrui Wu",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04685"
  },
  {
    "id": "arXiv:2109.04687",
    "title": "CLINS: Continuous-Time Trajectory Estimation for LiDAR-Inertial System",
    "abstract": "In this paper, we propose a highly accurate continuous-time trajectory\nestimation framework dedicated to SLAM (Simultaneous Localization and Mapping)\napplications, which enables fuse high-frequency and asynchronous sensor data\neffectively. We apply the proposed framework in a 3D LiDAR-inertial system for\nevaluations. The proposed method adopts a non-rigid registration method for\ncontinuous-time trajectory estimation and simultaneously removing the motion\ndistortion in LiDAR scans. Additionally, we propose a two-state continuous-time\ntrajectory correction method to efficiently and efficiently tackle the\ncomputationally-intractable global optimization problem when loop closure\nhappens. We examine the accuracy of the proposed approach on several publicly\navailable datasets and the data we collected. The experimental results indicate\nthat the proposed method outperforms the discrete-time methods regarding\naccuracy especially when aggressive motion occurs. Furthermore, we open source\nour code at \\url{https://github.com/APRIL-ZJU/clins} to benefit research\ncommunity.",
    "descriptor": "\nComments: IROS-2021\n",
    "authors": [
      "Jiajun Lv",
      "Kewei Hu",
      "Jinhong Xu",
      "Yong Liu",
      "Xiushui Ma",
      "Xingxing Zuo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04687"
  },
  {
    "id": "arXiv:2109.04689",
    "title": "Generating Self-Contained and Summary-Centric Question Answer Pairs via  Differentiable Reward Imitation Learning",
    "abstract": "Motivated by suggested question generation in conversational news\nrecommendation systems, we propose a model for generating question-answer pairs\n(QA pairs) with self-contained, summary-centric questions and\nlength-constrained, article-summarizing answers. We begin by collecting a new\ndataset of news articles with questions as titles and pairing them with\nsummaries of varying length. This dataset is used to learn a QA pair generation\nmodel producing summaries as answers that balance brevity with sufficiency\njointly with their corresponding questions. We then reinforce the QA pair\ngeneration process with a differentiable reward function to mitigate exposure\nbias, a common problem in natural language generation. Both automatic metrics\nand human evaluation demonstrate these QA pairs successfully capture the\ncentral gists of the articles and achieve high answer accuracy.",
    "descriptor": "\nComments: To appear in Proceedings of EMNLP 2021\n",
    "authors": [
      "Li Zhou",
      "Kevin Small",
      "Yong Zhang",
      "Sandeep Atluri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04689"
  },
  {
    "id": "arXiv:2109.04692",
    "title": "Analysis of Heterogeneous Structures of Non-separated Scales on Curved  Bridge Nodes",
    "abstract": "Numerically predicting the performance of heterogenous structures without\nscale separation represents a significant challenge to meet the critical\nrequirements on computational scalability and efficiency -- adopting a mesh\nfine enough to fully account for the small-scale heterogeneities leads to\nprohibitive computational costs while simply ignoring these fine\nheterogeneities tends to drastically over-stiffen the structure's rigidity.\nThis study proposes an approach to construct new material-aware shape (basis)\nfunctions per element on a coarse discretization of the structure with respect\nto each curved bridge nodes (CBNs) defined along the elements' boundaries.\nInstead of formulating their derivation by solving a nonlinear optimization\nproblem, the shape functions are constructed by building a map from the CBNs to\nthe interior nodes and are ultimately presented in an explicit matrix form as a\nproduct of a B\\'ezier interpolation transformation and a boundary-interior\ntransformation. The CBN shape function accomodates more flexibility in closely\ncapturing the coarse element's heterogeneity, overcomes the important and\nchallenging issues of inter-element stiffness and displacement discontinuity\nacross interface between coarse elements, and improves the analysis accuracy by\norders of magnitude; they also meet the basic geometric properties of shape\nfunctions that avoid aphysical analysis results. Extensive numerical examples,\nincluding a 3D industrial example of billions of degrees of freedom, are also\ntested to demonstrate the approach's performance in comparison with results\nobtained from classical approaches.",
    "descriptor": "\nComments: 29 pages, 23 figures\n",
    "authors": [
      "Ming Li",
      "Jingqiao Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04692"
  },
  {
    "id": "arXiv:2109.04697",
    "title": "Unfolding Projection-free SDP Relaxation of Binary Graph Classifier via  GDPA Linearization",
    "abstract": "Algorithm unfolding creates an interpretable and parsimonious neural network\narchitecture by implementing each iteration of a model-based algorithm as a\nneural layer. However, unfolding a proximal splitting algorithm with a positive\nsemi-definite (PSD) cone projection operator per iteration is expensive, due to\nthe required full matrix eigen-decomposition. In this paper, leveraging a\nrecent linear algebraic theorem called Gershgorin disc perfect alignment\n(GDPA), we unroll a projection-free algorithm for semi-definite programming\nrelaxation (SDR) of a binary graph classifier, where the PSD cone constraint is\nreplaced by a set of \"tightest possible\" linear constraints per iteration. As a\nresult, each iteration only requires computing a linear program (LP) and one\nextreme eigenvector. Inside the unrolled network, we optimize parameters via\nstochastic gradient descent (SGD) that determine graph edge weights in two\nways: i) a metric matrix that computes feature distances, and ii) a sparse\nweight matrix computed via local linear embedding (LLE). Experimental results\nshow that our unrolled network outperformed pure model-based graph classifiers,\nand achieved comparable performance to pure data-driven networks but using far\nfewer parameters.",
    "descriptor": "",
    "authors": [
      "Cheng Yang",
      "Gene Cheung",
      "Wai-tian Tan",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04697"
  },
  {
    "id": "arXiv:2109.04698",
    "title": "Face-NMS: A Core-set Selection Approach for Efficient Face Recognition",
    "abstract": "Recently, face recognition in the wild has achieved remarkable success and\none key engine is the increasing size of training data. For example, the\nlargest face dataset, WebFace42M contains about 2 million identities and 42\nmillion faces. However, a massive number of faces raise the constraints in\ntraining time, computing resources, and memory cost. The current research on\nthis problem mainly focuses on designing an efficient Fully-connected layer\n(FC) to reduce GPU memory consumption caused by a large number of identities.\nIn this work, we relax these constraints by resolving the redundancy problem of\nthe up-to-date face datasets caused by the greedily collecting operation (i.e.\nthe core-set selection perspective). As the first attempt in this perspective\non the face recognition problem, we find that existing methods are limited in\nboth performance and efficiency. For superior cost-efficiency, we contribute a\nnovel filtering strategy dubbed Face-NMS. Face-NMS works on feature space and\nsimultaneously considers the local and global sparsity in generating core sets.\nIn practice, Face-NMS is analogous to Non-Maximum Suppression (NMS) in the\nobject detection community. It ranks the faces by their potential contribution\nto the overall sparsity and filters out the superfluous face in the pairs with\nhigh similarity for local sparsity. With respect to the efficiency aspect,\nFace-NMS accelerates the whole pipeline by applying a smaller but sufficient\nproxy dataset in training the proxy model. As a result, with Face-NMS, we\nsuccessfully scale down the WebFace42M dataset to 60% while retaining its\nperformance on the main benchmarks, offering a 40% resource-saving and 1.64\ntimes acceleration. The code is publicly available for reference at\nhttps://github.com/HuangJunJie2017/Face-NMS.",
    "descriptor": "\nComments: Data efficient face recognition; Core-set selection\n",
    "authors": [
      "Yunze Chen",
      "Junjie Huang",
      "Jiagang Zhu",
      "Zheng Zhu",
      "Tian Yang",
      "Guan Huang",
      "Dalong Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04698"
  },
  {
    "id": "arXiv:2109.04699",
    "title": "EfficientCLIP: Efficient Cross-Modal Pre-training by Ensemble Confident  Learning and Language Modeling",
    "abstract": "While large scale pre-training has achieved great achievements in bridging\nthe gap between vision and language, it still faces several challenges. First,\nthe cost for pre-training is expensive. Second, there is no efficient way to\nhandle the data noise which degrades model performance. Third, previous methods\nonly leverage limited image-text paired data, while ignoring richer\nsingle-modal data, which may result in poor generalization to single-modal\ndownstream tasks. In this work, we propose an EfficientCLIP method via Ensemble\nConfident Learning to obtain a less noisy data subset. Extra rich non-paired\nsingle-modal text data is used for boosting the generalization of text branch.\nWe achieve the state-of-the-art performance on Chinese cross-modal retrieval\ntasks with only 1/10 training resources compared to CLIP and WenLan, while\nshowing excellent generalization to single-modal tasks, including text\nretrieval and text classification.",
    "descriptor": "",
    "authors": [
      "Jue Wang",
      "Haofan Wang",
      "Jincan Deng",
      "Weijia Wu",
      "Debing Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04699"
  },
  {
    "id": "arXiv:2109.04703",
    "title": "Heterogeneous Graph Neural Networks for Keyphrase Generation",
    "abstract": "The encoder-decoder framework achieves state-of-the-art results in keyphrase\ngeneration (KG) tasks by predicting both present keyphrases that appear in the\nsource document and absent keyphrases that do not. However, relying solely on\nthe source document can result in generating uncontrollable and inaccurate\nabsent keyphrases. To address these problems, we propose a novel graph-based\nmethod that can capture explicit knowledge from related references. Our model\nfirst retrieves some document-keyphrases pairs similar to the source document\nfrom a pre-defined index as references. Then a heterogeneous graph is\nconstructed to capture relationships of different granularities between the\nsource document and its references. To guide the decoding process, a\nhierarchical attention and copy mechanism is introduced, which directly copies\nappropriate words from both the source document and its references based on\ntheir relevance and significance. The experimental results on multiple KG\nbenchmarks show that the proposed model achieves significant improvements\nagainst other baseline models, especially with regard to the absent keyphrase\nprediction.",
    "descriptor": "\nComments: Accepted by EMNLP 2021\n",
    "authors": [
      "Jiacheng Ye",
      "Ruijian Cai",
      "Tao Gui",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04703"
  },
  {
    "id": "arXiv:2109.04705",
    "title": "Rethinking Zero-shot Neural Machine Translation: From a Perspective of  Latent Variables",
    "abstract": "Zero-shot translation, directly translating between language pairs unseen in\ntraining, is a promising capability of multilingual neural machine translation\n(NMT). However, it usually suffers from capturing spurious correlations between\nthe output language and language invariant semantics due to the maximum\nlikelihood training objective, leading to poor transfer performance on\nzero-shot translation. In this paper, we introduce a denoising autoencoder\nobjective based on pivot language into traditional training objective to\nimprove the translation accuracy on zero-shot directions. The theoretical\nanalysis from the perspective of latent variables shows that our approach\nactually implicitly maximizes the probability distributions for zero-shot\ndirections. On two benchmark machine translation datasets, we demonstrate that\nthe proposed method is able to effectively eliminate the spurious correlations\nand significantly outperforms state-of-the-art methods with a remarkable\nperformance. Our code is available at https://github.com/Victorwz/zs-nmt-dae.",
    "descriptor": "\nComments: EMNLP Findings 2021\n",
    "authors": [
      "Weizhi Wang",
      "Zhirui Zhang",
      "Yichao Du",
      "Boxing Chen",
      "Jun Xie",
      "Weihua Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04705"
  },
  {
    "id": "arXiv:2109.04706",
    "title": "TIE: An Autonomous and Adaptive Terrestrial-Aerial Quadrotor",
    "abstract": "This letter presents a fully autonomous robot system that possesses both\nterrestrial and aerial mobility. We firstly develop a lightweight\nterrestrial-aerial quadrotor that carries sufficient sensing and computing\nresources. It incorporates both the high mobility of unmanned aerial vehicles\nand the long endurance of unmanned ground vehicles. An adaptive navigation\nframework is then proposed that brings complete autonomy to it. In this\nframework, a hierarchical motion planner is proposed to generate safe and\nlow-power terrestrial-aerial trajectories in unknown environments. Moreover, we\npresent a unified motion controller which dynamically adjusts energy\nconsumption in terrestrial locomotion. Extensive realworld experiments and\nbenchmark comparisons validate the robustness and outstanding performance of\nthe proposed system. During the tests, it safely traverses complex environments\nwith terrestrial aerial integrated mobility, and achieves 7 times energy\nsavings in terrestrial locomotion. Finally, we will release our code and\nhardware configuration as an open-source package.",
    "descriptor": "\nComments: 8pages, 12figures, submitted to RA-L and ICRA2022\n",
    "authors": [
      "Ruibin Zhang",
      "Yuze Wu",
      "Lixian Zhang",
      "Chao Xu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04706"
  },
  {
    "id": "arXiv:2109.04707",
    "title": "Knowledge-Aware Meta-learning for Low-Resource Text Classification",
    "abstract": "Meta-learning has achieved great success in leveraging the historical learned\nknowledge to facilitate the learning process of the new task. However, merely\nlearning the knowledge from the historical tasks, adopted by current\nmeta-learning algorithms, may not generalize well to testing tasks when they\nare not well-supported by training tasks. This paper studies a low-resource\ntext classification problem and bridges the gap between meta-training and\nmeta-testing tasks by leveraging the external knowledge bases. Specifically, we\npropose KGML to introduce additional representation for each sentence learned\nfrom the extracted sentence-specific knowledge graph. The extensive experiments\non three datasets demonstrate the effectiveness of KGML under both supervised\nadaptation and unsupervised adaptation settings.",
    "descriptor": "\nComments: Accepted by EMNLP 2021\n",
    "authors": [
      "Huaxiu Yao",
      "Yingxin Wu",
      "Maruan Al-Shedivat",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04707"
  },
  {
    "id": "arXiv:2109.04708",
    "title": "Dynamic Terminology Integration for COVID-19 and other Emerging Domains",
    "abstract": "The majority of language domains require prudent use of terminology to ensure\nclarity and adequacy of information conveyed. While the correct use of\nterminology for some languages and domains can be achieved by adapting\ngeneral-purpose MT systems on large volumes of in-domain parallel data, such\nquantities of domain-specific data are seldom available for less-resourced\nlanguages and niche domains. Furthermore, as exemplified by COVID-19 recently,\nno domain-specific parallel data is readily available for emerging domains.\nHowever, the gravity of this recent calamity created a high demand for reliable\ntranslation of critical information regarding pandemic and infection\nprevention. This work is part of WMT2021 Shared Task: Machine Translation using\nTerminologies, where we describe Tilde MT systems that are capable of dynamic\nterminology integration at the time of translation. Our systems achieve up to\n94% COVID-19 term use accuracy on the test set of the EN-FR language pair\nwithout having access to any form of in-domain information during system\ntraining. We conclude our work with a broader discussion considering the Shared\nTask itself and terminology translation in MT.",
    "descriptor": "\nComments: To be published in WMT21\n",
    "authors": [
      "Toms Bergmanis",
      "M\u0101rcis Pinnis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.04708"
  },
  {
    "id": "arXiv:2109.04711",
    "title": "Pre-train or Annotate? Domain Adaptation with a Constrained Budget",
    "abstract": "Recent work has demonstrated that pre-training in-domain language models can\nboost performance when adapting to a new domain. However, the costs associated\nwith pre-training raise an important question: given a fixed budget, what steps\nshould an NLP practitioner take to maximize performance? In this paper, we\nstudy domain adaptation under budget constraints, and approach it as a customer\nchoice problem between data annotation and pre-training. Specifically, we\nmeasure the annotation cost of three procedural text datasets and the\npre-training cost of three in-domain language models. Then we evaluate the\nutility of different combinations of pre-training and data annotation under\nvarying budget constraints to assess which combination strategy works best. We\nfind that, for small budgets, spending all funds on annotation leads to the\nbest performance; once the budget becomes large enough, a combination of data\nannotation and in-domain pre-training works more optimally. We therefore\nsuggest that task-specific data annotation should be part of an economical\nstrategy when adapting an NLP model to a new domain.",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Fan Bai",
      "Alan Ritter",
      "Wei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04711"
  },
  {
    "id": "arXiv:2109.04712",
    "title": "Balancing Methods for Multi-label Text Classification with Long-Tailed  Class Distribution",
    "abstract": "Multi-label text classification is a challenging task because it requires\ncapturing label dependencies. It becomes even more challenging when class\ndistribution is long-tailed. Resampling and re-weighting are common approaches\nused for addressing the class imbalance problem, however, they are not\neffective when there is label dependency besides class imbalance because they\nresult in oversampling of common labels. Here, we introduce the application of\nbalancing loss functions for multi-label text classification. We perform\nexperiments on a general domain dataset with 90 labels (Reuters-21578) and a\ndomain-specific dataset from PubMed with 18211 labels. We find that a\ndistribution-balanced loss function, which inherently addresses both the class\nimbalance and label linkage problems, outperforms commonly used loss functions.\nDistribution balancing methods have been successfully used in the image\nrecognition field. Here, we show their effectiveness in natural language\nprocessing. Source code is available at\nhttps://github.com/blessu/BalancedLossNLP.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Yi Huang",
      "Buse Giledereli",
      "Abdullatif K\u00f6ksal",
      "Arzucan \u00d6zg\u00fcr",
      "Elif Ozkirimli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04712"
  },
  {
    "id": "arXiv:2109.04713",
    "title": "Personalized Entity Search by Sparse and Scrutable User Profiles",
    "abstract": "Prior work on personalizing web search results has focused on considering\nquery-and-click logs to capture users individual interests. For product search,\nextensive user histories about purchases and ratings have been exploited.\nHowever, for general entity search, such as for books on specific topics or\ntravel destinations with certain features, personalization is largely\nunderexplored. In this paper, we address personalization of book search, as an\nexemplary case of entity search, by exploiting sparse user profiles obtained\nthrough online questionnaires. We devise and compare a variety of re-ranking\nmethods based on language models or neural learning. Our experiments show that\neven very sparse information about individuals can enhance the effectiveness of\nthe search results.",
    "descriptor": "",
    "authors": [
      "Ghazaleh Haratinezhad Torbati",
      "Andrew Yates",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.04713"
  },
  {
    "id": "arXiv:2109.04715",
    "title": "AfroMT: Pretraining Strategies and Reproducible Benchmarks for  Translation of 8 African Languages",
    "abstract": "Reproducible benchmarks are crucial in driving progress of machine\ntranslation research. However, existing machine translation benchmarks have\nbeen mostly limited to high-resource or well-represented languages. Despite an\nincreasing interest in low-resource machine translation, there are no\nstandardized reproducible benchmarks for many African languages, many of which\nare used by millions of speakers but have less digitized textual data. To\ntackle these challenges, we propose AfroMT, a standardized, clean, and\nreproducible machine translation benchmark for eight widely spoken African\nlanguages. We also develop a suite of analysis tools for system diagnosis\ntaking into account the unique properties of these languages. Furthermore, we\nexplore the newly considered case of low-resource focused pretraining and\ndevelop two novel data augmentation-based strategies, leveraging word-level\nalignment information and pseudo-monolingual data for pretraining multilingual\nsequence-to-sequence models. We demonstrate significant improvements when\npretraining on 11 languages, with gains of up to 2 BLEU points over strong\nbaselines. We also show gains of up to 12 BLEU points over cross-lingual\ntransfer baselines in data-constrained scenarios. All code and pretrained\nmodels will be released as further steps towards larger reproducible benchmarks\nfor African languages.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Machel Reid",
      "Junjie Hu",
      "Graham Neubig",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04715"
  },
  {
    "id": "arXiv:2109.04716",
    "title": "You Get What You Chat: Using Conversations to Personalize Search-based  Recommendations",
    "abstract": "Prior work on personalized recommendations has focused on exploiting explicit\nsignals from user-specific queries, clicks, likes, and ratings. This paper\ninvestigates tapping into a different source of implicit signals of interests\nand tastes: online chats between users. The paper develops an expressive model\nand effective methods for personalizing search-based entity recommendations.\nUser models derived from chats augment different methods for re-ranking entity\nanswers for medium-grained queries. The paper presents specific techniques to\nenhance the user models by capturing domain-specific vocabularies and by\nentity-based expansion. Experiments are based on a collection of online chats\nfrom a controlled user study covering three domains: books, travel, food. We\nevaluate different configurations and compare chat-based user models against\nconcise user profiles from questionnaires. Overall, these two variants perform\non par in terms of NCDG@20, but each has advantages in certain domains.",
    "descriptor": "",
    "authors": [
      "Ghazaleh Haratinezhad Torbati",
      "Andrew Yates",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.04716"
  },
  {
    "id": "arXiv:2109.04717",
    "title": "xBalloon: Animated Objects with Balloon Plastic Actuator",
    "abstract": "Shape-changing interfaces are promising for users to change the physical\nproperties of common objects. However, prevailing approaches of actuation\ndevices require either professional equipment or materials that are not\ncommonly accessible to non-professional users. In this work, we focus on the\ncontrollable soft actuators with inflatable structures because they are soft\nthus safe for human computer interaction. We propose a soft actuator design,\ncalled xBalloon, that is workable, inexpensive and easy-to-fabricate. It\nconsists of daily materials including balloons and plastics and can realize\nbending actuation very effectively. For characterization, we fabricated\nxBalloon samples with different geometrical parameters and tested them\nregarding the bending performance and found the analytical model describing the\nrelationship between the shape and the bending width. We then used xBalloons to\nanimate a series of common objects and all can work satisfactorily. We further\nverified the user experience about the the fabrication and found that even\nthose with no prior robotic knowledge can fabricate xBalloons with ease and\nconfidence. Given all these advantages, we believe that xBalloon is an ideal\nplatform for interaction design and entertainment applications.",
    "descriptor": "\nComments: Proceedings of AH 2021.6 pages, 10 figures\n",
    "authors": [
      "Haoran Xie",
      "Takuma Torii",
      "Aoshi Chiba",
      "Qiukai Qi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04717"
  },
  {
    "id": "arXiv:2109.04719",
    "title": "NaviChoker: Augmenting Pressure Sensation via Pneumatic Actuator",
    "abstract": "Many technologies have been developed in recent years to present audiovisual\ninformation in new ways, but developing an information presentation interface\nto convey tactile information is still a challenge. We propose a tactile device\nusing wearable technology that is an all-around pressure presentation system\nusing pneumatic actuators. Specifically, we develop a system in which a choker\nequipped with a pneumatic actuator is worn around the neck, that applies\npressure in any direction to indicate to the user the direction in which to\nwalk and also when to start and stop walking. In this paper, we describe the\nconstruction of the device, evaluation experiments, our assessment of the\nprototype, and future plans for the device.",
    "descriptor": "\nComments: Proceedings of AH 2021. 4 pages, 7 figures\n",
    "authors": [
      "Shogo Yoshida",
      "Haoran Xie",
      "Kazunori Miyata"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04719"
  },
  {
    "id": "arXiv:2109.04720",
    "title": "6MapNet: Representing soccer players from tracking data by a triplet  network",
    "abstract": "Although the values of individual soccer players have become astronomical,\nsubjective judgments still play a big part in the player analysis. Recently,\nthere have been new attempts to quantitatively grasp players' styles using\nvideo-based event stream data. However, they have some limitations in\nscalability due to high annotation costs and sparsity of event stream data. In\nthis paper, we build a triplet network named 6MapNet that can effectively\ncapture the movement styles of players using in-game GPS data. Without any\nannotation of soccer-specific actions, we use players' locations and velocities\nto generate two types of heatmaps. Our subnetworks then map these heatmap pairs\ninto feature vectors whose similarity corresponds to the actual similarity of\nplaying styles. The experimental results show that players can be accurately\nidentified with only a small number of matches by our method.",
    "descriptor": "\nComments: 12 pages, 4 figures, In 8th Workshop on Machine Learning and Data Mining for Sports Analytics (MLSA21)\n",
    "authors": [
      "Hyunsung Kim",
      "Jihun Kim",
      "Dongwook Chung",
      "Jonghyun Lee",
      "Jinsung Yoon",
      "Sang-Ki Ko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04720"
  },
  {
    "id": "arXiv:2109.04721",
    "title": "Where Should I Look? Optimised Gaze Control for Whole-Body Collision  Avoidance in Dynamic Environments",
    "abstract": "As robots operate in increasingly complex and dynamic environments, fast\nmotion re-planning has become a widely explored area of research. In a\nreal-world deployment, we often lack the ability to fully observe the\nenvironment at all times, giving rise to the challenge of determining how to\nbest perceive the environment given a continuously updated motion plan. We\nprovide the first investigation into a `smart' controller for gaze control with\nthe objective of providing effective perception of the environment for obstacle\navoidance and motion planning in dynamic and unknown environments. We detail\nthe novel problem of determining the best head camera behaviour for mobile\nrobots when constrained by a trajectory. Furthermore, we propose a greedy\noptimisation-based solution that uses a combination of voxelised rewards and\nmotion primitives. We demonstrate that our method outperforms the benchmark\nmethods in 2D and 3D environments, in respect of both the ability to explore\nthe local surroundings, as well as in a superior success rate of finding\ncollision-free trajectories -- our method is shown to provide 7.4x better map\nexploration while consistently achieving a higher success rate for generating\ncollision-free trajectories. We verify our findings on a physical Toyota Human\nSupport Robot (HSR) using a GPU-accelerated perception framework.",
    "descriptor": "\nComments: 8 pages, 11 figures, submitted to IEEE Robotics and Automation Letters (RA-L) (with ICRA option)\n",
    "authors": [
      "Mark Nicholas Finean",
      "Wolfgang Merkt",
      "Ioannis Havoutis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04721"
  },
  {
    "id": "arXiv:2109.04726",
    "title": "AutoTriggER: Named Entity Recognition with Auxiliary Trigger Extraction",
    "abstract": "Deep neural models for low-resource named entity recognition (NER) have shown\nimpressive results by leveraging distant super-vision or other meta-level\ninformation (e.g. explanation). However, the costs of acquiring such additional\ninformation are generally prohibitive, especially in domains where existing\nresources (e.g. databases to be used for distant supervision) may not exist. In\nthis paper, we present a novel two-stage framework (AutoTriggER) to improve NER\nperformance by automatically generating and leveraging \"entity triggers\" which\nare essentially human-readable clues in the text that can help guide the model\nto make better decisions. Thus, the framework is able to both create and\nleverage auxiliary supervision by itself. Through experiments on three\nwell-studied NER datasets, we show that our automatically extracted triggers\nare well-matched to human triggers, and AutoTriggER improves performance over a\nRoBERTa-CRFarchitecture by nearly 0.5 F1 points on average and much more in a\nlow resource setting.",
    "descriptor": "\nComments: 10 pages, 12 figures, Best paper at TrustNLP@NAACL 2021 and presented at WeaSuL@ICLR 2021\n",
    "authors": [
      "Dong-Ho Lee",
      "Ravi Kiran Selvam",
      "Sheikh Muhammad Sarwar",
      "Bill Yuchen Lin",
      "Mahak Agarwal",
      "Fred Morstatter",
      "Jay Pujara",
      "Elizabeth Boschee",
      "James Allan",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.04726"
  },
  {
    "id": "arXiv:2109.04727",
    "title": "A Simple and Effective Method To Eliminate the Self Language Bias in  Multilingual Representations",
    "abstract": "Language agnostic and semantic-language information isolation is an emerging\nresearch direction for multilingual representations models. We explore this\nproblem from a novel angle of geometric algebra and semantic space. A simple\nbut highly effective method \"Language Information Removal (LIR)\" factors out\nlanguage identity information from semantic related components in multilingual\nrepresentations pre-trained on multi-monolingual data. A post-training and\nmodel-agnostic method, LIR only uses simple linear operations, e.g. matrix\nfactorization and orthogonal projection. LIR reveals that for weak-alignment\nmultilingual systems, the principal components of semantic spaces primarily\nencodes language identity information. We first evaluate the LIR on a\ncross-lingual question answer retrieval task (LAReQA), which requires the\nstrong alignment for the multilingual embedding space. Experiment shows that\nLIR is highly effectively on this task, yielding almost 100% relative\nimprovement in MAP for weak-alignment models. We then evaluate the LIR on\nAmazon Reviews and XEVAL dataset, with the observation that removing language\ninformation is able to improve the cross-lingual transfer performance.",
    "descriptor": "\nComments: Accepted to the 2021 Conference on Empirical Methods in Natural Language Processing\n",
    "authors": [
      "Ziyi Yang",
      "Yinfei Yang",
      "Daniel Cer",
      "Eric Darve"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04727"
  },
  {
    "id": "arXiv:2109.04730",
    "title": "Boosting Graph Search with Attention Network for Solving the General  Orienteering Problem",
    "abstract": "Recently, several studies have explored the use of neural network to solve\ndifferent routing problems, which is an auspicious direction. These studies\nusually design an encoder-decoder based framework that uses encoder embeddings\nof nodes and the problem-specific context to produce node sequence(path), and\nfurther optimize the produced result on top by beam search. However, existing\nmodels can only support node coordinates as input, ignore the self-referential\nproperty of the studied routing problems, and lack the consideration about the\nlow reliability in the initial stage of node selection, thus are hard to be\napplied in real-world.\nIn this paper, we take the orienteering problem as an example to tackle these\nlimitations. We propose a novel combination of a variant beam search algorithm\nand a learned heuristic for solving the general orienteering problem. We\nacquire the heuristic with an attention network that takes the distances among\nnodes as input, and learn it via a reinforcement learning framework. The\nempirical studies show that our method can surpass a wide range of baselines\nand achieve results close to the optimal or highly specialized approach. Also,\nour proposed framework can be easily applied to other routing problems. Our\ncode is publicly available.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Zongtao Liu",
      "Jing Xu",
      "Jintao Su",
      "Tao Xiao",
      "Yang Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04730"
  },
  {
    "id": "arXiv:2109.04732",
    "title": "Assessing the Reliability of Word Embedding Gender Bias Measures",
    "abstract": "Various measures have been proposed to quantify human-like social biases in\nword embeddings. However, bias scores based on these measures can suffer from\nmeasurement error. One indication of measurement quality is reliability,\nconcerning the extent to which a measure produces consistent results. In this\npaper, we assess three types of reliability of word embedding gender bias\nmeasures, namely test-retest reliability, inter-rater consistency and internal\nconsistency. Specifically, we investigate the consistency of bias scores across\ndifferent choices of random seeds, scoring rules and words. Furthermore, we\nanalyse the effects of various factors on these measures' reliability scores.\nOur findings inform better design of word embedding gender bias measures.\nMoreover, we urge researchers to be more critical about the application of such\nmeasures.",
    "descriptor": "\nComments: 23 pages, 24 figures, 3 tables. Accepted to EMNLP 2021\n",
    "authors": [
      "Yupei Du",
      "Qixiang Fang",
      "Dong Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04732"
  },
  {
    "id": "arXiv:2109.04733",
    "title": "Genre as Weak Supervision for Cross-lingual Dependency Parsing",
    "abstract": "Recent work has shown that monolingual masked language models learn to\nrepresent data-driven notions of language variation which can be used for\ndomain-targeted training data selection. Dataset genre labels are already\nfrequently available, yet remain largely unexplored in cross-lingual setups. We\nharness this genre metadata as a weak supervision signal for targeted data\nselection in zero-shot dependency parsing. Specifically, we project\ntreebank-level genre information to the finer-grained sentence level, with the\ngoal to amplify information implicitly stored in unsupervised contextualized\nrepresentations. We demonstrate that genre is recoverable from multilingual\ncontextual embeddings and that it provides an effective signal for training\ndata selection in cross-lingual, zero-shot scenarios. For 12 low-resource\nlanguage treebanks, six of which are test-only, our genre-specific methods\nsignificantly outperform competitive baselines as well as recent\nembedding-based methods for data selection. Moreover, genre-based data\nselection provides new state-of-the-art results for three of these target\nlanguages.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 (Main Conference)\n",
    "authors": [
      "Max M\u00fcller-Eberstein",
      "Rob van der Goot",
      "Barbara Plank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04733"
  },
  {
    "id": "arXiv:2109.04735",
    "title": "Temporal Pyramid Transformer with Multimodal Interaction for Video  Question Answering",
    "abstract": "Video question answering (VideoQA) is challenging given its multimodal\ncombination of visual understanding and natural language understanding. While\nexisting approaches seldom leverage the appearance-motion information in the\nvideo at multiple temporal scales, the interaction between the question and the\nvisual information for textual semantics extraction is frequently ignored.\nTargeting these issues, this paper proposes a novel Temporal Pyramid\nTransformer (TPT) model with multimodal interaction for VideoQA. The TPT model\ncomprises two modules, namely Question-specific Transformer (QT) and Visual\nInference (VI). Given the temporal pyramid constructed from a video, QT builds\nthe question semantics from the coarse-to-fine multimodal co-occurrence between\neach word and the visual content. Under the guidance of such question-specific\nsemantics, VI infers the visual clues from the local-to-global multi-level\ninteractions between the question and the video. Within each module, we\nintroduce a multimodal attention mechanism to aid the extraction of\nquestion-video interactions, with residual connections adopted for the\ninformation passing across different levels. Through extensive experiments on\nthree VideoQA datasets, we demonstrate better performances of the proposed\nmethod in comparison with the state-of-the-arts.",
    "descriptor": "\nComments: Submitted to AAAI'22\n",
    "authors": [
      "Min Peng",
      "Chongyang Wang",
      "Yuan Gao",
      "Yu Shi",
      "Xiang-Dong Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04735"
  },
  {
    "id": "arXiv:2109.04738",
    "title": "On the validity of pre-trained transformers for natural language  processing in the software engineering domain",
    "abstract": "Transformers are the current state-of-the-art of natural language processing\nin many domains and are using traction within software engineering research as\nwell. Such models are pre-trained on large amounts of data, usually from the\ngeneral domain. However, we only have a limited understanding regarding the\nvalidity of transformers within the software engineering domain, i.e., how good\nsuch models are at understanding words and sentences within a software\nengineering context and how this improves the state-of-the-art. Within this\narticle, we shed light on this complex, but crucial issue. We compare BERT\ntransformer models trained with software engineering data with transformers\nbased on general domain data in multiple dimensions: their vocabulary, their\nability to understand which words are missing, and their performance in\nclassification tasks. Our results show that for tasks that require\nunderstanding of the software engineering context, pre-training with software\nengineering data is valuable, while general domain models are sufficient for\ngeneral language understanding, also within the software engineering domain.",
    "descriptor": "\nComments: Review status: submitted\n",
    "authors": [
      "Julian von der Mosel",
      "Alexander Trautsch",
      "Steffen Herbold"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04738"
  },
  {
    "id": "arXiv:2109.04740",
    "title": "How Does Fine-tuning Affect the Geometry of Embedding Space: A Case  Study on Isotropy",
    "abstract": "It is widely accepted that fine-tuning pre-trained language models usually\nbrings about performance improvements in downstream tasks. However, there are\nlimited studies on the reasons behind this effectiveness, particularly from the\nviewpoint of structural changes in the embedding space. Trying to fill this\ngap, in this paper, we analyze the extent to which the isotropy of the\nembedding space changes after fine-tuning. We demonstrate that, even though\nisotropy is a desirable geometrical property, fine-tuning does not necessarily\nresult in isotropy enhancements. Moreover, local structures in pre-trained\ncontextual word representations (CWRs), such as those encoding token types or\nfrequency, undergo a massive change during fine-tuning. Our experiments show\ndramatic growth in the number of elongated directions in the embedding space,\nwhich, in contrast to pre-trained CWRs, carry the essential linguistic\nknowledge in the fine-tuned embedding space, making existing isotropy\nenhancement methods ineffective.",
    "descriptor": "\nComments: To appear in Findings of EMNLP 2021\n",
    "authors": [
      "Sara Rajaee",
      "Mohammad Taher Pilehvar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04740"
  },
  {
    "id": "arXiv:2109.04741",
    "title": "Range, Endurance, and Optimal Speed Estimates for Multicopters",
    "abstract": "Multicopters are among the most versatile mobile robots. Their applications\nrange from inspection and mapping tasks to providing vital reconnaissance in\ndisaster zones and to package delivery. The range, endurance, and speed a\nmultirotor vehicle can achieve while performing its task is a decisive factor\nnot only for vehicle design and mission planning, but also for policy makers\ndeciding on the rules and regulations for aerial robots. To the best of the\nauthors' knowledge, this work proposes the first approach to estimate the\nrange, endurance, and optimal flight speed for a wide variety of multicopters.\nThis advance is made possible by combining a state-of-the-art first-principles\naerodynamic multicopter model based on blade-element-momentum theory with an\nelectric-motor model and a graybox battery model. This model predicts the cell\nvoltage with only 1.3% relative error (43.1 mV), even if the battery is\nsubjected to non-constant discharge rates. Our approach is validated with\nreal-world experiments on a test bench as well as with flights at speeds up to\n65 km/h in one of the world's largest motion-capture systems. We also present\nan accurate pen-and-paper algorithm to estimate the range, endurance and\noptimal speed of multicopters to help future researchers build drones with\nmaximal range and endurance, ensuring that future multirotor vehicles are even\nmore versatile.",
    "descriptor": "\nComments: 7 pages + 1 page references\n",
    "authors": [
      "Leonard Bauersfeld",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04741"
  },
  {
    "id": "arXiv:2109.04742",
    "title": "Design of input for data-driven simulation with Hankel and Page matrices",
    "abstract": "The paper deals with the problem of designing informative input trajectories\nfor data-driven simulation. First, the excitation requirements in the case of\nnoise-free data are discussed and new weaker conditions, which assume the\nsimulated input to be known in advance, are provided. Then, the case of noisy\ndata trajectories is considered and an input design problem based on a recently\nproposed maximum likelihood estimator is formulated. A Bayesian interpretation\nis provided, and the implications of using Hankel and Page matrix\nrepresentations are demonstrated. Numerical examples show the impact of the\ndesigned input on the predictive accuracy.",
    "descriptor": "\nComments: Accepted at the 2021 IEEE Conference on Decision and Control\n",
    "authors": [
      "Andrea Iannelli",
      "Mingzhou Yin",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04742"
  },
  {
    "id": "arXiv:2109.04743",
    "title": "A Suitable Hierarchical Framework with Arbitrary Task Dimensions under  Unilateral Constraints for physical Human Robot Interaction",
    "abstract": "In the last years, several hierarchical frameworks have been proposed to deal\nwith highly-redundant robotic systems. Some of that systems are expected to\nperform multiple tasks and physically to interact with the environment.\nHowever, none of the proposed frameworks is able to manage multiple tasks with\narbitrary task dimensions, while respecting unilateral constraints at position,\nvelocity, acceleration and force level, and at the same time, to react\nintuitively to external forces. This work proposes a framework that addresses\nthis problem. The framework is tested in simulation and on a real robot. The\nexperiments on the redundant collaborative industrial robot (KUKA LBR iiwa)\ndemonstrate the advantage of the framework compared to state-of-the-art\napproaches. The framework reacts intuitively to external forces and is able to\nlimit joint positions, velocities, accelerations and forces.",
    "descriptor": "",
    "authors": [
      "Juan David Munoz-Osorio",
      "Felix Allmendinger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04743"
  },
  {
    "id": "arXiv:2109.04744",
    "title": "Automated Machine Learning, Bounded Rationality, and Rational  Metareasoning",
    "abstract": "The notion of bounded rationality originated from the insight that perfectly\nrational behavior cannot be realized by agents with limited cognitive or\ncomputational resources. Research on bounded rationality, mainly initiated by\nHerbert Simon, has a longstanding tradition in economics and the social\nsciences, but also plays a major role in modern AI and intelligent agent\ndesign. Taking actions under bounded resources requires an agent to reflect on\nhow to use these resources in an optimal way - hence, to reason and make\ndecisions on a meta-level. In this paper, we will look at automated machine\nlearning (AutoML) and related problems from the perspective of bounded\nrationality, essentially viewing an AutoML tool as an agent that has to train a\nmodel on a given set of data, and the search for a good way of doing so (a\nsuitable \"ML pipeline\") as deliberation on a meta-level.",
    "descriptor": "\nComments: Accepted at ECMLPKDD WORKSHOP ON AUTOMATING DATA SCIENCE (ADS2021) - this https URL\n",
    "authors": [
      "Eyke H\u00fcllermeier",
      "Felix Mohr",
      "Alexander Tornede",
      "Marcel Wever"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04744"
  },
  {
    "id": "arXiv:2109.04746",
    "title": "Counterfactual Adversarial Learning with Representation Interpolation",
    "abstract": "Deep learning models exhibit a preference for statistical fitting over\nlogical reasoning. Spurious correlations might be memorized when there exists\nstatistical bias in training data, which severely limits the model performance\nespecially in small data scenarios. In this work, we introduce Counterfactual\nAdversarial Training framework (CAT) to tackle the problem from a causality\nperspective. Particularly, for a specific sample, CAT first generates a\ncounterfactual representation through latent space interpolation in an\nadversarial manner, and then performs Counterfactual Risk Minimization (CRM) on\neach original-counterfactual pair to adjust sample-wise loss weight\ndynamically, which encourages the model to explore the true causal effect.\nExtensive experiments demonstrate that CAT achieves substantial performance\nimprovement over SOTA across different downstream tasks, including sentence\nclassification, natural language inference and question answering.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Wei Wang",
      "Boxin Wang",
      "Ning Shi",
      "Jinfeng Li",
      "Bingyu Zhu",
      "Xiangyu Liu",
      "Rong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04746"
  },
  {
    "id": "arXiv:2109.04749",
    "title": "A Holistic Approach to Reactive Mobile Manipulation",
    "abstract": "We present the design and implementation of a taskable reactive mobile\nmanipulation system. Contrary to related work, we treat the arm and base\ndegrees of freedom as a holistic structure which greatly improves the speed and\nfluidity of the resulting motion. At the core of this approach is a robust and\nreactive motion controller which can achieve a desired end-effector pose while\navoiding joint position and velocity limits, and ensuring the mobile\nmanipulator is manoeuvrable throughout the trajectory. This can support\nsensor-based behaviours such as closed-loop visual grasping. As no planning is\ninvolved in our approach, the robot is never stationary thinking about what to\ndo next. We show the versatility of our holistic motion controller by\nimplementing a pick and place system using behaviour trees and demonstrate this\ntask on a 9-degree-of-freedom mobile manipulator. Additionally, we provide an\nopen-source implementation of our motion controller for both non-holonomic and\nomnidirectional mobile manipulators.",
    "descriptor": "\nComments: See project website this https URL\n",
    "authors": [
      "Jesse Haviland",
      "Niko S\u00fcnderhauf",
      "Peter Corke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04749"
  },
  {
    "id": "arXiv:2109.04753",
    "title": "Line as a Visual Sentence: Context-aware Line Descriptor for Visual  Localization",
    "abstract": "Along with feature points for image matching, line features provide\nadditional constraints to solve visual geometric problems in robotics and\ncomputer vision (CV). Although recent convolutional neural network (CNN)-based\nline descriptors are promising for viewpoint changes or dynamic environments,\nwe claim that the CNN architecture has innate disadvantages to abstract\nvariable line length into the fixed-dimensional descriptor. In this paper, we\neffectively introduce Line-Transformers dealing with variable lines. Inspired\nby natural language processing (NLP) tasks where sentences can be understood\nand abstracted well in neural nets, we view a line segment as a sentence that\ncontains points (words). By attending to well-describable points on aline\ndynamically, our descriptor performs excellently on variable line length. We\nalso propose line signature networks sharing the line's geometric attributes to\nneighborhoods. Performing as group descriptors, the networks enhance line\ndescriptors by understanding lines' relative geometries. Finally, we present\nthe proposed line descriptor and matching in a Point and Line Localization\n(PL-Loc). We show that the visual localization with feature points can be\nimproved using our line features. We validate the proposed method for\nhomography estimation and visual localization.",
    "descriptor": "",
    "authors": [
      "Sungho Yoon",
      "Ayoung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04753"
  },
  {
    "id": "arXiv:2109.04756",
    "title": "On Inverse Inertia Matrix and Contact-Force Model for Robotic  Manipulators at Normal Impacts",
    "abstract": "We revisit the impact with zero tangential contact velocities caused by an\narticulated robot arm contacting its rigid environment. The impact behavior\ndepends on the fixed base and multiple rigid links connected by motorized\njoints. Our thorough analysis focuses on deriving the suitable inverse inertia\nmatrix and a realistic contact-force model. We conducted real-robot experiments\nwith the 7 DOF Panda manipulator, collecting data of 150 impacts with varying\njoint configurations and different end-effector speeds. Our findings suggest\ncomputing the inverse inertia matrix assuming the joints are locked, i.e.,\ntransform the composite-rigid-body inertia at the contact point, and the\nmeasurement-consistent contact-force model is viscoelastic.",
    "descriptor": "",
    "authors": [
      "Yuquan Wang",
      "Niels Dehio",
      "Abderrahmane Kheddar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04756"
  },
  {
    "id": "arXiv:2109.04762",
    "title": "Dual-State Capsule Networks for Text Classification",
    "abstract": "Text classification systems based on contextual embeddings are not viable\noptions for many of the low resource languages. On the other hand, recently\nintroduced capsule networks have shown performance in par with these text\nclassification models. Thus, they could be considered as a viable alternative\nfor text classification for languages that do not have pre-trained contextual\nembedding models. However, current capsule networks depend upon spatial\npatterns without considering the sequential features of the text. They are also\nsub-optimal in capturing the context-level information in longer sequences.\nThis paper presents a novel Dual-State Capsule (DS-Caps) network-based\ntechnique for text classification, which is optimized to mitigate these issues.\nTwo varieties of states, namely sentence-level and word-level, are integrated\nwith capsule layers to capture deeper context-level information for language\nmodeling. The dynamic routing process among capsules was also optimized using\nthe context-level information obtained through sentence-level states. The\nDS-Caps networks outperform the existing capsule network architectures for\nmultiple datasets, particularly for tasks with longer sequences of text. We\nalso demonstrate the superiority of DS-Caps in text classification for a low\nresource language.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Piyumal Demotte",
      "Surangika Ranathunga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04762"
  },
  {
    "id": "arXiv:2109.04766",
    "title": "An Execution Fingerprint Dictionary for HPC Application Recognition",
    "abstract": "Applications running on HPC systems waste time and energy if they: (a) use\nresources inefficiently, (b) deviate from allocation purpose (e.g.\ncryptocurrency mining), or (c) encounter errors and failures. It is important\nto know which applications are running on the system, how they use the system,\nand whether they have been executed before. To recognize known applications\nduring execution on a noisy system, we draw inspiration from the way Shazam\nrecognizes known songs playing in a crowded bar. Our contribution is an\nExecution Fingerprint Dictionary (EFD) that stores execution fingerprints of\nsystem metrics (keys) linked to application and input size information (values)\nas key-value pairs for application recognition. Related work often relies on\nextensive system monitoring (many system metrics collected over large time\nwindows) and employs machine learning methods to identify applications. Our\nsolution only uses the first 2 minutes and a single system metric to achieve\nF-scores above 95 percent, providing comparable results to related work but\nwith a fraction of the necessary data and a straightforward mechanism of\nrecognition.",
    "descriptor": "",
    "authors": [
      "Thomas Jakobsche",
      "Nicolas Lachiche",
      "Aur\u00e9lien Cavelan",
      "Florina M. Ciorba"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.04766"
  },
  {
    "id": "arXiv:2109.04767",
    "title": "Multi-label Classification of Aircraft Heading Changes Using Neural  Network to Resolve Conflicts",
    "abstract": "An aircraft conflict occurs when two or more aircraft cross at a certain\ndistance at the same time. Specific air traffic controllers are assigned to\nsolve such conflicts. A controller needs to consider various types of\ninformation in order to solve a conflict. The most common and preliminary\ninformation is the coordinate position of the involved aircraft. Additionally,\na controller has to take into account more information such as flight planning,\nweather, restricted territory, etc. The most important challenges a controller\nhas to face are: to think about the issues involved and make a decision in a\nvery short time. Due to the increased number of aircraft, it is crucial to\nreduce the workload of the controllers and help them make quick decisions. A\nconflict can be solved in many ways, therefore, we consider this problem as a\nmulti-label classification problem. In doing so, we are proposing a multi-label\nclassification model which provides multiple heading advisories for a given\nconflict. This model we named CRMLnet is based on a novel application of a\nmulti-layer neural network and helps the controllers in their decisions. When\ncompared to other machine learning models, our CRMLnet has achieved the best\nresults with an accuracy of 98.72% and ROC of 0.999. The simulated data set\nthat we have developed and used in our experiments will be delivered to the\nresearch community.",
    "descriptor": "\nComments: 27 pages, 24 figures\n",
    "authors": [
      "Md Siddiqur Rahman",
      "Laurent Lapasset",
      "Josiane Mothe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04767"
  },
  {
    "id": "arXiv:2109.04771",
    "title": "Closing the Sim2Real Gap in Dynamic Cloth Manipulation",
    "abstract": "Cloth manipulation is a challenging task due to the many degrees of freedom\nand properties of the material affecting the dynamics of the cloth. The\nnonlinear dynamics of the cloth have particularly strong significance in\ndynamic cloth manipulation, where some parts of the cloth are not directly\ncontrollable. In this paper, we present a novel approach for solving dynamic\ncloth manipulation by training policies using reinforcement learning (RL) in\nsimulation and transferring the learned policies to the real world in a\nzero-shot manner. The proposed method uses visual feedback and material\nproperty randomization in a physics simulator to achieve generalization in the\nreal world. Experimental results show that using only visual feedback is enough\nfor the policies to learn the dynamic manipulation task in a way that transfers\nfrom simulation to the real world. In addition, the randomization of the\ndynamics in simulation enables capturing the behavior of a variety of cloths in\nthe real world.",
    "descriptor": "\nComments: 8 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Julius Hietala",
      "David Blanco-Mulero",
      "Gokhan Alcan",
      "Ville Kyrki"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04771"
  },
  {
    "id": "arXiv:2109.04775",
    "title": "A Strong Baseline for Query Efficient Attacks in a Black Box Setting",
    "abstract": "Existing black box search methods have achieved high success rate in\ngenerating adversarial attacks against NLP models. However, such search methods\nare inefficient as they do not consider the amount of queries required to\ngenerate adversarial attacks. Also, prior attacks do not maintain a consistent\nsearch space while comparing different search methods. In this paper, we\npropose a query efficient attack strategy to generate plausible adversarial\nexamples on text classification and entailment tasks. Our attack jointly\nleverages attention mechanism and locality sensitive hashing (LSH) to reduce\nthe query count. We demonstrate the efficacy of our approach by comparing our\nattack with four baselines across three different search spaces. Further, we\nbenchmark our results across the same search space used in prior attacks. In\ncomparison to attacks proposed, on an average, we are able to reduce the query\ncount by 75% across all datasets and target models. We also demonstrate that\nour attack achieves a higher success rate when compared to prior attacks in a\nlimited query setting.",
    "descriptor": "\nComments: EMNLP 2021 - Main Conference\n",
    "authors": [
      "Rishabh Maheshwary",
      "Saket Maheshwary",
      "Vikram Pudi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04775"
  },
  {
    "id": "arXiv:2109.04778",
    "title": "Improving Multilingual Translation by Representation and Gradient  Regularization",
    "abstract": "Multilingual Neural Machine Translation (NMT) enables one model to serve all\ntranslation directions, including ones that are unseen during training, i.e.\nzero-shot translation. Despite being theoretically attractive, current models\noften produce low quality translations -- commonly failing to even produce\noutputs in the right target language. In this work, we observe that off-target\ntranslation is dominant even in strong multilingual systems, trained on massive\nmultilingual corpora. To address this issue, we propose a joint approach to\nregularize NMT models at both representation-level and gradient-level. At the\nrepresentation level, we leverage an auxiliary target language prediction task\nto regularize decoder outputs to retain information about the target language.\nAt the gradient level, we leverage a small amount of direct data (in thousands\nof sentence pairs) to regularize model gradients. Our results demonstrate that\nour approach is highly effective in both reducing off-target translation\noccurrences and improving zero-shot translation performance by +5.59 and +10.38\nBLEU on WMT and OPUS datasets respectively. Moreover, experiments show that our\nmethod also works well when the small amount of direct data is not available.",
    "descriptor": "\nComments: EMNLP 2021 (Long)\n",
    "authors": [
      "Yilin Yang",
      "Akiko Eriguchi",
      "Alexandre Muzio",
      "Prasad Tadepalli",
      "Stefan Lee",
      "Hany Hassan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04778"
  },
  {
    "id": "arXiv:2109.04780",
    "title": "RoR: Read-over-Read for Long Document Machine Reading Comprehension",
    "abstract": "Transformer-based pre-trained models, such as BERT, have achieved remarkable\nresults on machine reading comprehension. However, due to the constraint of\nencoding length (e.g., 512 WordPiece tokens), a long document is usually split\ninto multiple chunks that are independently read. It results in the reading\nfield being limited to individual chunks without information collaboration for\nlong document machine reading comprehension. To address this problem, we\npropose RoR, a read-over-read method, which expands the reading field from\nchunk to document. Specifically, RoR includes a chunk reader and a document\nreader. The former first predicts a set of regional answers for each chunk,\nwhich are then compacted into a highly-condensed version of the original\ndocument, guaranteeing to be encoded once. The latter further predicts the\nglobal answers from this condensed document. Eventually, a voting strategy is\nutilized to aggregate and rerank the regional and global answers for final\nprediction. Extensive experiments on two benchmarks QuAC and TriviaQA\ndemonstrate the effectiveness of RoR for long document reading. Notably, RoR\nranks 1st place on the QuAC leaderboard (https://quac.ai/) at the time of\nsubmission (May 17th, 2021).",
    "descriptor": "\nComments: Accepted as findings of EMNLP2021\n",
    "authors": [
      "Jing Zhao",
      "Junwei Bao",
      "Yifan Wang",
      "Yongwei Zhou",
      "Youzheng Wu",
      "Xiaodong He",
      "Bowen Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04780"
  },
  {
    "id": "arXiv:2109.04783",
    "title": "Self-Attention Channel Combinator Frontend for End-to-End Multichannel  Far-field Speech Recognition",
    "abstract": "When a sufficiently large far-field training data is presented, jointly\noptimizing a multichannel frontend and an end-to-end (E2E) Automatic Speech\nRecognition (ASR) backend shows promising results. Recent literature has shown\ntraditional beamformer designs, such as MVDR (Minimum Variance Distortionless\nResponse) or fixed beamformers can be successfully integrated as the frontend\ninto an E2E ASR system with learnable parameters. In this work, we propose the\nself-attention channel combinator (SACC) ASR frontend, which leverages the\nself-attention mechanism to combine multichannel audio signals in the magnitude\nspectral domain. Experiments conducted on a multichannel playback test data\nshows that the SACC achieved a 9.3% WERR compared to a state-of-the-art fixed\nbeamformer-based frontend, both jointly optimized with a ContextNet-based ASR\nbackend. We also demonstrate the connection between the SACC and the\ntraditional beamformers, and analyze the intermediate outputs of the SACC.",
    "descriptor": "\nComments: In Proceedings of Interspeech 2021\n",
    "authors": [
      "Rong Gong",
      "Carl Quillen",
      "Dushyant Sharma",
      "Andrew Goderre",
      "Jos\u00e9 La\u00ednez",
      "Ljubomir Milanovi\u0107"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.04783"
  },
  {
    "id": "arXiv:2109.04784",
    "title": "A Dynamic Scheduling Policy for a Network with Heterogeneous  Time-Sensitive Traffic",
    "abstract": "In 5G and beyond systems, the notion of latency gets a great momentum in\nwireless connectivity as a metric for serving real-time communications\nrequirements. However, in many applications, research has pointed out that\nlatency could be inefficient to handle applications with data freshness\nrequirements. Recently, the notion of Age of Information (AoI) that can capture\nthe freshness of the data has attracted a lot of attention. In this work, we\nconsider mixed traffic with time-sensitive users; a deadline-constrained user,\nand an AoI-oriented user. To develop an efficient scheduling policy, we cast a\nnovel optimization problem formulation for minimizing the average AoI while\nsatisfying the timely throughput constraints. The formulated problem is cast as\na Constrained Markov Decision Process (CMDP). We relax the constrained problem\nto an unconstrained Markov Decision Process (MDP) problem by utilizing Lyapunov\noptimization theory and it can be proved that it is solved per frame by\napplying backward dynamic programming algorithms with optimality guarantees.\nSimulation results show that the timely throughput constraints are satisfied\nwhile minimizing the average AoI. Also, simulation results show the convergence\nof the algorithm for different values of the weighted factor and the trade-off\nbetween the AoI and the timely throughput.",
    "descriptor": "\nComments: Submitted in a journal\n",
    "authors": [
      "Emmanouil Fountoulakis",
      "Themistoklis Charalambous",
      "Anthony Ephremides",
      "Nikolaos Pappas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.04784"
  },
  {
    "id": "arXiv:2109.04786",
    "title": "WiFi Meets ML: A Survey on Improving IEEE 802.11 Performance with  Machine Learning",
    "abstract": "Wireless local area networks (WLANs) empowered by IEEE 802.11 (WiFi) hold a\ndominant position in providing Internet access thanks to their freedom of\ndeployment and configuration as well as affordable and highly interoperable\ndevices. The WiFi community is currently deploying WiFi 6 and developing WiFi\n7, which will bring higher data rates, better multi-user and multi-AP support,\nand, most importantly, improved configuration flexibility. These technical\ninnovations, including the plethora of configuration parameters, are making\nnext-generation WLANs exceedingly complex as the dependencies between\nparameters and their joint optimization usually have a non-linear impact on\nnetwork performance. The complexity is further increased in the case of dense\ndeployments and coexistence in shared bands. While classic optimization\napproaches fail in such conditions, machine learning (ML) is well known for\nbeing able to handle complexity. Much research has been published on using ML\nto improve WiFi performance and solutions are slowly being adopted in existing\ndeployments. In this survey, we adopt a structured approach to describing the\nvarious areas where WiFi can be enhanced using ML. To this end, we analyze over\n200 papers in the field providing readers with an overview of the main trends.\nBased on this review, we identify both open challenges in each WiFi performance\narea as well as general future research directions.",
    "descriptor": "\nComments: 45 pages, 17 figures, 325 references\n",
    "authors": [
      "Szymon Szott",
      "Katarzyna Kosek-Szott",
      "Piotr Gaw\u0142owicz",
      "Jorge Torres G\u00f3mez",
      "Boris Bellalta",
      "Anatolij Zubow",
      "Falko Dressler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.04786"
  },
  {
    "id": "arXiv:2109.04787",
    "title": "Exophoric Pronoun Resolution in Dialogues with Topic Regularization",
    "abstract": "Resolving pronouns to their referents has long been studied as a fundamental\nnatural language understanding problem. Previous works on pronoun coreference\nresolution (PCR) mostly focus on resolving pronouns to mentions in text while\nignoring the exophoric scenario. Exophoric pronouns are common in daily\ncommunications, where speakers may directly use pronouns to refer to some\nobjects present in the environment without introducing the objects first.\nAlthough such objects are not mentioned in the dialogue text, they can often be\ndisambiguated by the general topics of the dialogue. Motivated by this, we\npropose to jointly leverage the local context and global topics of dialogues to\nsolve the out-of-text PCR problem. Extensive experiments demonstrate the\neffectiveness of adding topic regularization for resolving exophoric pronouns.",
    "descriptor": "\nComments: EMNLP 2021 main conference\n",
    "authors": [
      "Xintong Yu",
      "Hongming Zhang",
      "Yangqiu Song",
      "Changshui Zhang",
      "Kun Xu",
      "Dong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04787"
  },
  {
    "id": "arXiv:2109.04791",
    "title": "ANTASID: A Novel Temporal Adjustment to Shannon's Index of Difficulty",
    "abstract": "Shannon's Index of Difficulty ($SID$), a logarithmic relation between\nmovement-amplitude and target-width, is reputable for modelling movement-time\nin pointing tasks. However, it cannot resolve the inherent speed-accuracy\ntrade-off, where emphasizing accuracy compromises speed and vice versa.\nEffective target-width is considered as spatial adjustment, compensating for\naccuracy. However, for compensating speed, no significant adjustment exists in\nthe literature. Real-life pointing tasks are both spatially and temporally\nunconstrained. Spatial adjustment alone is insufficient for modelling these\ntasks due to several human factors. To resolve this, we propose $ANTASID$ (A\nNovel Temporal Adjustment to $SID$) formulation with detailed performance\nanalysis. We hypothesized temporal efficiency of interaction as a potential\ntemporal adjustment factor ($t$), compensating for speed. Considering spatial\nand/or temporal adjustments to $SID$, we conducted regression analyses using\nour own and benchmark datasets in both controlled and uncontrolled scenarios.\nThe $ANTASID$ formulation showed significantly superior fitness values and\nthroughput in all the scenarios.",
    "descriptor": "\nComments: 14 pages, 8 figures, 8 tables\n",
    "authors": [
      "Mohammad Ridwan Kabir",
      "Mohammad Ishrak Abedin",
      "Rizvi Ahmed",
      "Hasan Mahmud",
      "Md. Kamrul Hasan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04791"
  },
  {
    "id": "arXiv:2109.04797",
    "title": "Mesh convolutional neural networks for wall shear stress estimation in  3D artery models",
    "abstract": "Computational fluid dynamics (CFD) is a valuable tool for personalised,\nnon-invasive evaluation of hemodynamics in arteries, but its complexity and\ntime-consuming nature prohibit large-scale use in practice. Recently, the use\nof deep learning for rapid estimation of CFD parameters like wall shear stress\n(WSS) on surface meshes has been investigated. However, existing approaches\ntypically depend on a hand-crafted re-parametrisation of the surface mesh to\nmatch convolutional neural network architectures. In this work, we propose to\ninstead use mesh convolutional neural networks that directly operate on the\nsame finite-element surface mesh as used in CFD. We train and evaluate our\nmethod on two datasets of synthetic coronary artery models with and without\nbifurcation, using a ground truth obtained from CFD simulation. We show that\nour flexible deep learning model can accurately predict 3D WSS vectors on this\nsurface mesh. Our method processes new meshes in less than 5 [s], consistently\nachieves a normalised mean absolute error of $\\leq$ 1.6 [%], and peaks at 90.5\n[%] median approximation accuracy over the held-out test set, comparing\nfavorably to previously published work. This shows the feasibility of CFD\nsurrogate modelling using mesh convolutional neural networks for hemodynamic\nparameter estimation in artery models.",
    "descriptor": "\nComments: (MICCAI 2021) Workshop on Statistical Atlases and Computational Modelling of the Heart (STACOM)\n",
    "authors": [
      "Julian Suk",
      "Pim de Haan",
      "Phillip Lippe",
      "Christoph Brune",
      "Jelmer M. Wolterink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2109.04797"
  },
  {
    "id": "arXiv:2109.04800",
    "title": "Quantifying Effective Noise Sources in Coupled Resonating MEMS sensors",
    "abstract": "This paper presents realistic system-level modelling and simulation of\neffective noise sources in a coupled resonating MEMS sensors. A governing set\nof differential equations are used to build a numerical model of a mechanical\nnoise source in a coupled-resonator sensor. An effective thermomechanical noise\nis then quantified through the system-level simulation obtained via Simulink.\nOn a similar note, various noise sources in electronic readout are identified\nand the contribution of each is quantified to determine an effective noise that\nstems from the electronic readout. A comparison between an effective mechanical\nand electronic noise aids in identifying the dominant noise source in a sensor\nsystem. A method to optimize the system noise floor for an amplitude-based the\nreadout is presented. The proposed models present a variety of operating\nconditions, such as finite quality factor, varying coupled electric spring\nstrength, and operation with in-phase and out-of-phase mode. The proposed\nmodels aim to determine the impact of fundamental noise processes and thus\nquantify the ultimate detection limit into a coupled resonating system used for\nvarious sensing applications.",
    "descriptor": "",
    "authors": [
      "Vinayak Pachkawade"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04800"
  },
  {
    "id": "arXiv:2109.04802",
    "title": "Secondary control activation analysed and predicted with explainable AI",
    "abstract": "The transition to a renewable energy system poses challenges for power grid\noperation and stability. Secondary control is key in restoring the power system\nto its reference following a disturbance. Underestimating the necessary control\ncapacity may require emergency measures, such as load shedding. Hence, a solid\nunderstanding of the emerging risks and the driving factors of control is\nneeded. In this contribution, we establish an explainable machine learning\nmodel for the activation of secondary control power in Germany. Training\ngradient boosted trees, we obtain an accurate description of control\nactivation. Using SHapely Additive exPlanation (SHAP) values, we investigate\nthe dependency between control activation and external features such as the\ngeneration mix, forecasting errors, and electricity market data. Thereby, our\nanalysis reveals drivers that lead to high reserve requirements in the German\npower system. Our transparent approach, utilizing open data and making machine\nlearning models interpretable, opens new scientific discovery avenues.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Johannes Kruse",
      "Benjamin Sch\u00e4fer",
      "Dirk Witthaut"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2109.04802"
  },
  {
    "id": "arXiv:2109.04803",
    "title": "Combining Event Calculus and Description Logic Reasoning via Logic  Programming",
    "abstract": "The paper introduces a knowledge representation language that combines the\nevent calculus with description logic in a logic programming framework. The\npurpose is to provide the user with an expressive language for modelling and\nanalysing systems that evolve over time. The approach is exemplified with the\nlogic programming language as implemented in the Fusemate system. The paper\nextends Fusemate's rule language with a weakly DL-safe interface to the\ndescription logic $\\cal ALCIF$ and adapts the event calculus to this extended\nlanguage. This way, time-stamped ABoxes can be manipulated as fluents in the\nevent calculus. All that is done in the frame of Fusemate's concept of\nstratification by time. The paper provides conditions for soundness and\ncompleteness where appropriate. Using an elaborated example it demonstrates the\ninterplay of the event calculus, description logic and logic programming rules\nfor computing possible models as plausible explanations of the current state of\nthe modelled system.",
    "descriptor": "\nComments: This is a corrected version of the paper published in FroCoS 2021. It adds a missing case in the definition of the semantics of body literals , and it fixes a flaw in the definition of possible models\n",
    "authors": [
      "Peter Baumgartner"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.04803"
  },
  {
    "id": "arXiv:2109.04804",
    "title": "Two-derivative deferred correction time discretization for the  discontinuous Galerkin method",
    "abstract": "In this paper, we use an implicit two-derivative deferred correction time\ndiscretization approach and combine it with a spatial discretization of the\ndiscontinuous Galerkin spectral element method to solve (non-)linear PDEs. The\nresulting numerical method is high order accurate in space and time. As the\nnovel scheme handles two time derivatives, the spatial operator for both\nderivatives has to be defined. This results in an extended system matrix of the\nscheme. We analyze this matrix regarding possible simplifications and an\nefficient way to solve the arising (non-)linear system of equations. It is\nshown how a carefully designed preconditioner and a matrix-free approach allow\nfor an efficient implementation and application of the novel scheme. For both,\nlinear advection and the compressible Euler equations, up to eighth order of\naccuracy in time is shown. Finally, it is illustrated how the method can be\nused to approximate solutions to the compressible Navier-Stokes equations.",
    "descriptor": "",
    "authors": [
      "Jonas Zeifang",
      "Jochen Schuetz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04804"
  },
  {
    "id": "arXiv:2109.04807",
    "title": "Unselfish Coded Caching can Yield Unbounded Gains over Symmetrically  Selfish Caching",
    "abstract": "The original coded caching scenario assumes a content library that is of\ninterest to all receiving users. In a realistic scenario though, the users may\nhave diverging interests which may intersect to various degrees. What happens\nfor example if each file is of potential interest to, say, $40\\,\\%$ of the\nusers and each user has potential interest in $40\\,\\%$ of the library? In this\nwork, we investigate the so-called symmetrically selfish coded caching\nscenario, where each user only makes requests from a subset of the library that\ndefines its own File Demand Set (FDS), each user caches selfishly only contents\nfrom its own FDS, and where the different FDSs symmetrically overlap to some\nextent. In the context of various traditional prefetching scenarios (prior to\nthe emergence of coded caching), selfish approaches were known to be\npotentially very effective. On the other hand, with the exception of some\nnotable works, little is known about selfish coded caching. We here present a\nnew information-theoretic converse that proves, in a general setting of\nsymmetric FDS structures, that selfish coded caching, despite enjoying a much\nlarger local caching gain and a much smaller set of possible demands,\nintroduces an unbounded load increase compared to the unselfish case. In\nparticular, in the $K$-user broadcast channel where each user stores a fraction\n$\\gamma$ of the library, where each file (class) is of interest to $\\alpha$\nusers, and where any one specific file is of interest to a fraction $\\delta$ of\nusers, the optimal coding gain of symmetrically selfish caching is at least $(K\n- \\alpha)\\gamma + 1$ times smaller than in the unselfish scenario. This allows\nus to draw the powerful conclusion that the optimal selfish coding gain is\nupper bounded by $1/(1 - \\delta)$, and thus does not scale with $K$. These\nderived limits are shown to be exact for different types of demands.",
    "descriptor": "\nComments: 48 pages, 8 figures. Submitted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Federico Brunero",
      "Petros Elia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.04807"
  },
  {
    "id": "arXiv:2109.04809",
    "title": "Efficient Locally Optimal Number Set Partitioning for Scheduling,  Allocation and Fair Selection",
    "abstract": "We study the optimization version of the set partition problem (where the\ndifference between the partition sums are minimized), which has numerous\napplications in decision theory literature. While the set partitioning problem\nis NP-hard and requires exponential complexity to solve (i.e., intractable); we\nformulate a weaker version of this NP-hard problem, where the goal is to find a\nlocally optimal solution. We show that our proposed algorithms can find a\nlocally optimal solution in near linear time. Our algorithms require neither\npositive nor integer elements in the input set, hence, they are more widely\napplicable.",
    "descriptor": "",
    "authors": [
      "Kaan Gokcesu",
      "Hakan Gokcesu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.04809"
  },
  {
    "id": "arXiv:2109.04810",
    "title": "Mixture-of-Partitions: Infusing Large Biomedical Knowledge Graphs into  BERT",
    "abstract": "Infusing factual knowledge into pre-trained models is fundamental for many\nknowledge-intensive tasks. In this paper, we proposed Mixture-of-Partitions\n(MoP), an infusion approach that can handle a very large knowledge graph (KG)\nby partitioning it into smaller sub-graphs and infusing their specific\nknowledge into various BERT models using lightweight adapters. To leverage the\noverall factual knowledge for a target task, these sub-graph adapters are\nfurther fine-tuned along with the underlying BERT through a mixture layer. We\nevaluate our MoP with three biomedical BERTs (SciBERT, BioBERT, PubmedBERT) on\nsix downstream tasks (inc. NLI, QA, Classification), and the results show that\nour MoP consistently enhances the underlying BERTs in task performance, and\nachieves new SOTA performances on five evaluated datasets.",
    "descriptor": "\nComments: EMNLP 2021 camera-ready version\n",
    "authors": [
      "Zaiqiao Meng",
      "Fangyu Liu",
      "Thomas Hikaru Clark",
      "Ehsan Shareghi",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04810"
  },
  {
    "id": "arXiv:2109.04813",
    "title": "TADA: Taxonomy Adaptive Domain Adaptation",
    "abstract": "Traditional domain adaptation addresses the task of adapting a model to a\nnovel target domain under limited or no additional supervision. While tackling\nthe input domain gap, the standard domain adaptation settings assume no domain\nchange in the output space. In semantic prediction tasks, different datasets\nare often labeled according to different semantic taxonomies. In many\nreal-world settings, the target domain task requires a different taxonomy than\nthe one imposed by the source domain. We therefore introduce the more general\ntaxonomy adaptive domain adaptation (TADA) problem, allowing for inconsistent\ntaxonomies between the two domains. We further propose an approach that jointly\naddresses the image-level and label-level domain adaptation. On the\nlabel-level, we employ a bilateral mixed sampling strategy to augment the\ntarget domain, and a relabelling method to unify and align the label spaces. We\naddress the image-level domain gap by proposing an uncertainty-rectified\ncontrastive learning method, leading to more domain-invariant and class\ndiscriminative features. We extensively evaluate the effectiveness of our\nframework under different TADA settings: open taxonomy, coarse-to-fine\ntaxonomy, and partially-overlapping taxonomy. Our framework outperforms\nprevious state-of-the-art by a large margin, while capable of adapting to new\ntarget domain taxonomies.",
    "descriptor": "\nComments: 15 pages, 5 figures, 6 tables\n",
    "authors": [
      "Rui Gong",
      "Martin Danelljan",
      "Dengxin Dai",
      "Wenguan Wang",
      "Danda Pani Paudel",
      "Ajad Chhatkuli",
      "Fisher Yu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04813"
  },
  {
    "id": "arXiv:2109.04817",
    "title": "Does It Capture STEL? A Modular, Similarity-based Linguistic Style  Evaluation Framework",
    "abstract": "Style is an integral part of natural language. However, evaluation methods\nfor style measures are rare, often task-specific and usually do not control for\ncontent. We propose the modular, fine-grained and content-controlled\nsimilarity-based STyle EvaLuation framework (STEL) to test the performance of\nany model that can compare two sentences on style. We illustrate STEL with two\ngeneral dimensions of style (formal/informal and simple/complex) as well as two\nspecific characteristics of style (contrac'tion and numb3r substitution). We\nfind that BERT-based methods outperform simple versions of commonly used style\nmeasures like 3-grams, punctuation frequency and LIWC-based approaches. We\ninvite the addition of further tasks and task instances to STEL and hope to\nfacilitate the improvement of style-sensitive measures.",
    "descriptor": "\nComments: Accepted at EMNLP2021\n",
    "authors": [
      "Anna Wegmann",
      "Dong Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04817"
  },
  {
    "id": "arXiv:2109.04821",
    "title": "KNODE-MPC: A Knowledge-based Data-driven Predictive Control Framework  for Aerial Robots",
    "abstract": "In this work, we consider the problem of deriving and incorporating accurate\ndynamic models for model predictive control (MPC) with an application to\nquadrotor control. MPC relies on precise dynamic models to achieve the desired\nclosed-loop performance. However, the presence of uncertainties in complex\nsystems and the environments they operate in poses a challenge in obtaining\nsufficiently accurate representations of the system dynamics. In this work, we\nmake use of a deep learning tool, knowledge-based neural ordinary differential\nequations (KNODE), to augment a model obtained from first principles. The\nresulting hybrid model encompasses both a nominal first-principle model and a\nneural network learnt from simulated or real-world experimental data. Using a\nquadrotor, we benchmark our hybrid model against a state-of-the-art Gaussian\nProcess (GP) model and show that the hybrid model provides more accurate\npredictions of the quadrotor dynamics and is able to generalize beyond the\ntraining data. To improve closed-loop performance, the hybrid model is\nintegrated into a novel MPC framework, known as KNODE-MPC. Results show that\nthe integrated framework achieves 73% improvement in simulations and more than\n14% in physical experiments, in terms of trajectory tracking performance.",
    "descriptor": "\nComments: 7 pages, 8 figures. *Equal Contribution. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kong Yao Chee",
      "Tom Z. Jiahao",
      "M. Ani Hsieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04821"
  },
  {
    "id": "arXiv:2109.04822",
    "title": "1st-Order Dynamics on Nonlinear Agents for Resource Allocation over  Uniformly-Connected Networks",
    "abstract": "In this paper, a general nonlinear 1st-order consensus-based solution for\ndistributed constrained convex optimization is considered for applications in\nnetwork resource allocation. The proposed continuous-time solution is used to\noptimize continuously-differentiable strictly convex cost functions over\nweakly-connected undirected multi-agent networks. The solution is anytime\nfeasible and models various nonlinearities to account for imperfections and\nconstraints on the (physical model of) agents in terms of their limited\nactuation capabilities, e.g., quantization and saturation constraints among\nothers. Moreover, different applications impose specific nonlinearities to the\nmodel, e.g., convergence in fixed/finite-time, robustness to uncertainties, and\nnoise-tolerant dynamics. Our proposed distributed resource allocation protocol\ngeneralizes such nonlinear models. Putting convex set analysis together with\nthe Lyapunov theorem, we provide a general technique to prove convergence (i)\nregardless of the particular type of nonlinearity (ii) with weak\nnetwork-connectivity requirement (i.e., uniform-connectivity). We simulate the\nperformance of the protocol in continuous-time coordination of generators,\nknown as the economic dispatch problem (EDP).",
    "descriptor": "",
    "authors": [
      "Mohammadreza Doostmohammadian",
      "Alireza Aghasi",
      "Themistoklis Charalambous"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.04822"
  },
  {
    "id": "arXiv:2109.04824",
    "title": "Inverse design of 3d molecular structures with conditional generative  neural networks",
    "abstract": "The rational design of molecules with desired properties is a long-standing\nchallenge in chemistry. Generative neural networks have emerged as a powerful\napproach to sample novel molecules from a learned distribution. Here, we\npropose a conditional generative neural network for 3d molecular structures\nwith specified structural and chemical properties. This approach is agnostic to\nchemical bonding and enables targeted sampling of novel molecules from\nconditional distributions, even in domains where reference calculations are\nsparse. We demonstrate the utility of our method for inverse design by\ngenerating molecules with specified composition or motifs, discovering\nparticularly stable molecules, and jointly targeting multiple electronic\nproperties beyond the training regime.",
    "descriptor": "",
    "authors": [
      "Niklas W. A. Gebauer",
      "Michael Gastegger",
      "Stefaan S. P. Hessmann",
      "Klaus-Robert M\u00fcller",
      "Kristof T. Sch\u00fctt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04824"
  },
  {
    "id": "arXiv:2109.04825",
    "title": "Artificial Text Detection via Examining the Topology of Attention Maps",
    "abstract": "The impressive capabilities of recent generative models to create texts that\nare challenging to distinguish from the human-written ones can be misused for\ngenerating fake news, product reviews, and even abusive content. Despite the\nprominent performance of existing methods for artificial text detection, they\nstill lack interpretability and robustness towards unseen models. To this end,\nwe propose three novel types of interpretable topological features for this\ntask based on Topological Data Analysis (TDA) which is currently understudied\nin the field of NLP. We empirically show that the features derived from the\nBERT model outperform count- and neural-based baselines up to 10\\% on three\ncommon datasets, and tend to be the most robust towards unseen GPT-style\ngeneration models as opposed to existing methods. The probing analysis of the\nfeatures reveals their sensitivity to the surface and syntactic properties. The\nresults demonstrate that TDA is a promising line with respect to NLP tasks,\nspecifically the ones that incorporate surface and structural information.",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Laida Kushnareva",
      "Daniil Cherniavskii",
      "Vladislav Mikhailov",
      "Ekaterina Artemova",
      "Serguei Barannikov",
      "Alexander Bernstein",
      "Irina Piontkovskaya",
      "Dmitri Piontkovski",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04825"
  },
  {
    "id": "arXiv:2109.04830",
    "title": "Solving the Extended Job Shop Scheduling Problem with AGVs -- Classical  and Quantum Approaches",
    "abstract": "The subject of Job Scheduling Optimisation (JSO) deals with the scheduling of\njobs in an organization, so that the single working steps are optimally\norganized regarding the postulated targets. In this paper a use case is\nprovided which deals with a sub-aspect of JSO, the Job Shop Scheduling Problem\n(JSSP or JSP). As many optimization problems JSSP is NP-complete, which means\nthe complexity increases with every node in the system exponentially. The goal\nof the use case is to show how to create an optimized duty rooster for certain\nworkpieces in a flexible organized machinery, combined with an Autonomous\nGround Vehicle (AGV), using Constraint Programming (CP) and Quantum Computing\n(QC) alternatively. The results of a classical solution based on CP and on a\nQuantum Annealing model are presented and discussed. All presented results have\nbeen elaborated in the research project PlanQK.",
    "descriptor": "",
    "authors": [
      "Marc Geitz",
      "Cristian Grozea",
      "Wolfgang Steigerwald",
      "Robin St\u00f6hr",
      "Armin Wolf"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04830"
  },
  {
    "id": "arXiv:2109.04831",
    "title": "Simulating the Effects of Eco-Friendly Transportation Selections for Air  Pollution Reduction",
    "abstract": "Reducing air pollution, such as CO2 and PM2.5 emissions, is one of the most\nimportant issues for many countries worldwide. Selecting an environmentally\nfriendly transport mode can be an effective approach of individuals to reduce\nair pollution in daily life. In this study, we propose a method to simulate the\neffectiveness of an eco-friendly transport mode selection for reducing air\npollution by using map search logs. We formulate the transport mode selection\nas a combinatorial optimization problem with the constraints regarding the\ntotal amount of CO2 emissions as an example of air pollution and the average\ntravel time. The optimization results show that the total amount of CO2\nemissions can be reduced by 9.23%, whereas the average travel time can in fact\nbe reduced by 9.96%. Our research proposal won first prize in Regular Machine\nLearning Competition Track Task 2 at KDD Cup 2019.",
    "descriptor": "\nComments: KDD Cup 2019 Regular ML Track Task 2, 1st Prize this https URL\n",
    "authors": [
      "Keiichi Ochiai",
      "Tsukasa Demizu",
      "Shin Ishiguro",
      "Shohei Maruyama",
      "Akihiro Kawana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04831"
  },
  {
    "id": "arXiv:2109.04832",
    "title": "Asking It All: Generating Contextualized Questions for any Semantic Role",
    "abstract": "Asking questions about a situation is an inherent step towards understanding\nit. To this end, we introduce the task of role question generation, which,\ngiven a predicate mention and a passage, requires producing a set of questions\nasking about all possible semantic roles of the predicate. We develop a\ntwo-stage model for this task, which first produces a context-independent\nquestion prototype for each role and then revises it to be contextually\nappropriate for the passage. Unlike most existing approaches to question\ngeneration, our approach does not require conditioning on existing answers in\nthe text. Instead, we condition on the type of information to inquire about,\nregardless of whether the answer appears explicitly in the text, could be\ninferred from it, or should be sought elsewhere. Our evaluation demonstrates\nthat we generate diverse and well-formed questions for a large, broad-coverage\nontology of predicates and roles.",
    "descriptor": "\nComments: Accepted as a long paper to EMNLP 2021, Main Conference\n",
    "authors": [
      "Valentina Pyatkin",
      "Paul Roit",
      "Julian Michael",
      "Reut Tsarfaty",
      "Yoav Goldberg",
      "Ido Dagan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04832"
  },
  {
    "id": "arXiv:2109.04833",
    "title": "Multimodal Federated Learning",
    "abstract": "Federated learning is proposed as an alternative to centralized machine\nlearning since its client-server structure provides better privacy protection\nand scalability in real-world applications. In many applications, such as smart\nhomes with IoT devices, local data on clients are generated from different\nmodalities such as sensory, visual, and audio data. Existing federated learning\nsystems only work on local data from a single modality, which limits the\nscalability of the systems.\nIn this paper, we propose a multimodal and semi-supervised federated learning\nframework that trains autoencoders to extract shared or correlated\nrepresentations from different local data modalities on clients. In addition,\nwe propose a multimodal FedAvg algorithm to aggregate local autoencoders\ntrained on different data modalities. We use the learned global autoencoder for\na downstream classification task with the help of auxiliary labelled data on\nthe server. We empirically evaluate our framework on different modalities\nincluding sensory data, depth camera videos, and RGB camera videos. Our\nexperimental results demonstrate that introducing data from multiple modalities\ninto federated learning can improve its accuracy. In addition, we can use\nlabelled data from only one modality for supervised learning on the server and\napply the learned model to testing data from other modalities to achieve decent\naccuracy (e.g., approximately 70% as the best performance), especially when\ncombining contributions from both unimodal clients and multimodal clients.",
    "descriptor": "",
    "authors": [
      "Yuchen Zhao",
      "Payam Barnaghi",
      "Hamed Haddadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04833"
  },
  {
    "id": "arXiv:2109.04834",
    "title": "An Evaluation Dataset and Strategy for Building Robust Multi-turn  Response Selection Model",
    "abstract": "Multi-turn response selection models have recently shown comparable\nperformance to humans in several benchmark datasets. However, in the real\nenvironment, these models often have weaknesses, such as making incorrect\npredictions based heavily on superficial patterns without a comprehensive\nunderstanding of the context. For example, these models often give a high score\nto the wrong response candidate containing several keywords related to the\ncontext but using the inconsistent tense. In this study, we analyze the\nweaknesses of the open-domain Korean Multi-turn response selection models and\npublish an adversarial dataset to evaluate these weaknesses. We also suggest a\nstrategy to build a robust model in this adversarial environment.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Kijong Han",
      "Seojin Lee",
      "Wooin Lee",
      "Joosung Lee",
      "Dong-hun Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04834"
  },
  {
    "id": "arXiv:2109.04835",
    "title": "FR-Detect: A Multi-Modal Framework for Early Fake News Detection on  Social Media Using Publishers Features",
    "abstract": "In recent years, with the expansion of the Internet and attractive social\nmedia infrastructures, people prefer to follow the news through these media.\nDespite the many advantages of these media in the news field, the lack of any\ncontrol and verification mechanism has led to the spread of fake news, as one\nof the most important threats to democracy, economy, journalism and freedom of\nexpression. Designing and using automatic methods to detect fake news on social\nmedia has become a significant challenge. In this paper, we examine the\npublishers' role in detecting fake news on social media. We also suggest a high\naccurate multi-modal framework, namely FR-Detect, using user-related and\ncontent-related features with early detection capability. For this purpose, two\nnew user-related features, namely Activity Credibility and Influence, have been\nintroduced for publishers. Furthermore, a sentence-level convolutional neural\nnetwork is provided to combine these features with latent textual content\nfeatures properly. Experimental results have shown that the publishers'\nfeatures can improve the performance of content-based models by up to 13% and\n29% in accuracy and F1-score, respectively.",
    "descriptor": "",
    "authors": [
      "Ali Jarrahi",
      "Leila Safari"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04835"
  },
  {
    "id": "arXiv:2109.04837",
    "title": "Human-Robot Interaction via a Joint-Initiative Supervised Autonomy  (JISA) Framework",
    "abstract": "In this paper, we propose and validate a Joint-Initiative Supervised Autonomy\n(JISA) framework for Human-Robot Interaction (HRI), in which a robot maintains\na measure of its self-confidence (SC) while performing a task, and only prompts\nthe human supervisor for help when its SC drops. At the same time, during task\nexecution, a human supervisor can intervene in the task being performed, based\non his/her Situation Awareness (SA). To evaluate the applicability and utility\nof JISA, it is implemented on two different HRI tasks: grid-based collaborative\nsimultaneous localization and mapping (SLAM) and automated jigsaw puzzle\nreconstruction. Augmented Reality (AR) (for SLAM) and two-dimensional graphical\nuser interfaces (GUI) (for puzzle reconstruction) are custom-designed to\nenhance human SA and allow intuitive interaction between the human and the\nagent. The superiority of the JISA framework is demonstrated in experiments. In\nSLAM, the superior maps produced by JISA preclude the need for post processing\nof any SLAM stock maps; furthermore, JISA reduces the required mapping time by\napproximately 50 percent versus traditional approaches. In automated puzzle\nreconstruction, the JISA framework outperforms both fully autonomous solutions,\nas well as those resulting from on-demand human intervention prompted by the\nagent.",
    "descriptor": "",
    "authors": [
      "Abbas Sidaoui",
      "Naseem Daher",
      "Daniel Asmar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04837"
  },
  {
    "id": "arXiv:2109.04838",
    "title": "Block Pruning For Faster Transformers",
    "abstract": "Pre-training has improved model accuracy for both classification and\ngeneration tasks at the cost of introducing much larger and slower models.\nPruning methods have proven to be an effective way of reducing model size,\nwhereas distillation methods are proven for speeding up inference. We introduce\na block pruning approach targeting both small and fast models. Our approach\nextends structured methods by considering blocks of any size and integrates\nthis structure into the movement pruning paradigm for fine-tuning. We find that\nthis approach learns to prune out full components of the underlying model, such\nas attention heads. Experiments consider classification and generation tasks,\nyielding among other results a pruned model that is a 2.4x faster, 74% smaller\nBERT on SQuAD v1, with a 1% drop on F1, competitive both with distilled models\nin speed and pruned models in size.",
    "descriptor": "\nComments: EMNLP 2021. Code, hyper-parameters, evaluation results and checkpoints available at this https URL\n",
    "authors": [
      "Fran\u00e7ois Lagunas",
      "Ella Charlaix",
      "Victor Sanh",
      "Alexander M. Rush"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04838"
  },
  {
    "id": "arXiv:2109.04843",
    "title": "Temporally Coherent Person Matting Trained on Fake-Motion Dataset",
    "abstract": "We propose a novel neural-network-based method to perform matting of videos\ndepicting people that does not require additional user input such as trimaps.\nOur architecture achieves temporal stability of the resulting alpha mattes by\nusing motion-estimation-based smoothing of image-segmentation algorithm\noutputs, combined with convolutional-LSTM modules on U-Net skip connections.\nWe also propose a fake-motion algorithm that generates training clips for the\nvideo-matting network given photos with ground-truth alpha mattes and\nbackground videos. We apply random motion to photos and their mattes to\nsimulate movement one would find in real videos and composite the result with\nthe background clips. It lets us train a deep neural network operating on\nvideos in an absence of a large annotated video dataset and provides\nground-truth training-clip foreground optical flow for use in loss functions.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Ivan Molodetskikh",
      "Mikhail Erofeev",
      "Andrey Moskalenko",
      "Dmitry Vatolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04843"
  },
  {
    "id": "arXiv:2109.04846",
    "title": "Model Predictive Control with Infeasible Reference Trajectories",
    "abstract": "Model Predictive Control (MPC) formulations are typically built on the\nrequirement that a feasible reference trajectory is available. In practical\nsettings, however, references that are infeasible with respect to the system\ndynamics are used for convenience. In this paper, we prove under which\nconditions an MPC formulation is Input-to-State Stable~(ISS) in closed-loop\nwhen an infeasible reference is used, and that with proper terminal conditions,\nasymptotic stability towards an optimal reference may be achieved. We\nillustrate the theoretical results with a four-dimensional robotic joint\nexample.",
    "descriptor": "\nComments: 8 pages, 1 figure, submitted to IEEE Transactions on Automatic Control. arXiv admin note: text overlap with arXiv:2001.11602\n",
    "authors": [
      "Ivo Batkovic",
      "Mohammad Ali",
      "Paolo Falcone",
      "Mario Zanon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04846"
  },
  {
    "id": "arXiv:2109.04847",
    "title": "Active learning for reducing labeling effort in text classification  tasks",
    "abstract": "Labeling data can be an expensive task as it is usually performed manually by\ndomain experts. This is cumbersome for deep learning, as it is dependent on\nlarge labeled datasets. Active learning (AL) is a paradigm that aims to reduce\nlabeling effort by only using the data which the used model deems most\ninformative. Little research has been done on AL in a text classification\nsetting and next to none has involved the more recent, state-of-the-art NLP\nmodels. Here, we present an empirical study that compares different\nuncertainty-based algorithms with BERT$_{base}$ as the used classifier. We\nevaluate the algorithms on two NLP classification datasets: Stanford Sentiment\nTreebank and KvK-Frontpages. Additionally, we explore heuristics that aim to\nsolve presupposed problems of uncertainty-based AL; namely, that it is\nunscalable and that it is prone to selecting outliers. Furthermore, we explore\nthe influence of the query-pool size on the performance of AL. Whereas it was\nfound that the proposed heuristics for AL did not improve performance of AL;\nour results show that using uncertainty-based AL with BERT$_{base}$ outperforms\nrandom sampling of data. This difference in performance can decrease as the\nquery-pool size gets larger.",
    "descriptor": "",
    "authors": [
      "Pieter Floris Jacobs",
      "Gideon Maillette de Buy Wenniger",
      "Marco Wiering",
      "Lambert Schomaker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04847"
  },
  {
    "id": "arXiv:2109.04848",
    "title": "How Does Blockchain Security Dictate Blockchain Implementation?",
    "abstract": "Blockchain protocols come with a variety of security guarantees. For example,\nBFT-inspired protocols such as Algorand tend to be secure in the partially\nsynchronous setting, while longest chain protocols like Bitcoin will normally\nrequire stronger synchronicity to be secure. Another fundamental distinction,\ndirectly relevant to scalability solutions such as sharding, is whether or not\na single untrusted user is able to point to *certificates*, which provide\nincontrovertible proof of block confirmation. Algorand produces such\ncertificates, while Bitcoin does not. Are these properties accidental? Or are\nthey inherent consequences of the paradigm of protocol design? Our aim in this\npaper is to understand what, fundamentally, governs the nature of security for\npermissionless blockchain protocols. Using the framework developed in\n(Lewis-Pye and Roughgarden, 2021), we prove general results showing that these\nquestions relate directly to properties of the user selection process, i.e.,\nthe method (such as proof-of-work or proof-of-stake) which is used to select\nusers with the task of updating state. Our results suffice to establish, for\nexample, that the production of certificates is impossible for proof-of-work\nprotocols, but is automatic for standard forms of proof-of-stake protocols. As\na byproduct of our work, we also define a number of security notions and\nidentify the equivalences and inequivalences among them.",
    "descriptor": "\nComments: To appear in the 28th Annual ACM Conference on Computer and Communications Security (CCS). arXiv admin note: substantial text overlap with arXiv:2009.09480\n",
    "authors": [
      "Andrew Lewis-Pye",
      "Tim Roughgarden"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.04848"
  },
  {
    "id": "arXiv:2109.04853",
    "title": "CoPHE: A Count-Preserving Hierarchical Evaluation Metric in Large-Scale  Multi-Label Text Classification",
    "abstract": "Large-Scale Multi-Label Text Classification (LMTC) includes tasks with\nhierarchical label spaces, such as automatic assignment of ICD-9 codes to\ndischarge summaries. Performance of models in prior art is evaluated with\nstandard precision, recall, and F1 measures without regard for the rich\nhierarchical structure. In this work we argue for hierarchical evaluation of\nthe predictions of neural LMTC models. With the example of the ICD-9 ontology\nwe describe a structural issue in the representation of the structured label\nspace in prior art, and propose an alternative representation based on the\ndepth of the ontology. We propose a set of metrics for hierarchical evaluation\nusing the depth-based representation. We compare the evaluation scores from the\nproposed metrics with previously used metrics on prior art LMTC models for\nICD-9 coding in MIMIC-III. We also propose further avenues of research\ninvolving the proposed ontological representation.",
    "descriptor": "\nComments: 5 pages, 2 figures, EMNLP 2021\n",
    "authors": [
      "Mat\u00fa\u0161 Falis",
      "Hang Dong",
      "Alexandra Birch",
      "Beatrice Alex"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04853"
  },
  {
    "id": "arXiv:2109.04858",
    "title": "Compositional Cyber-Physical Systems Theory",
    "abstract": "This dissertation builds a compositional cyber-physical systems theory to\ndevelop concrete semantics relating the above diverse views necessary for\nsafety and security assurance. In this sense, composition can take two forms.\nThe first is composing larger models from smaller ones within each individual\nformalism of requirements, behaviors, and architectures which can be thought of\nas horizontal composition -- a problem which is largely solved. The second and\nmain contribution of this theory is vertical composition, meaning relating or\notherwise providing verified composition across requirement, behavioral, and\narchitecture models and their associated algebras. In this dissertation, we\nshow that one possible solution to vertical composition is to use tools from\ncategory theory. Category theory is a natural candidate for making both\nhorizontal and vertical composition formally explicit because it can relate,\ncompare, and/or unify different algebras.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Georgios Bakirtzis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2109.04858"
  },
  {
    "id": "arXiv:2109.04862",
    "title": "Understanding the Relative Strength of QBF CDCL Solvers and QBF  Resolution",
    "abstract": "QBF solvers implementing the QCDCL paradigm are powerful algorithms that\nsuccessfully tackle many computationally complex applications. However, our\ntheoretical understanding of the strength and limitations of these QCDCL\nsolvers is very limited.\nIn this paper we suggest to formally model QCDCL solvers as proof systems. We\ndefine different policies that can be used for decision heuristics and unit\npropagation and give rise to a number of sound and complete QBF proof systems\n(and hence new QCDCL algorithms). With respect to the standard policies used in\npractical QCDCL solving, we show that the corresponding QCDCL proof system is\nincomparable (via exponential separations) to Q-resolution, the classical QBF\nresolution system used in the literature. This is in stark contrast to the\npropositional setting where CDCL and resolution are known to be p-equivalent.\nThis raises the question what formulas are hard for standard QCDCL, since\nQ-resolution lower bounds do not necessarily apply to QCDCL as we show here. In\nanswer to this question we prove several lower bounds for QCDCL, including\nexponential lower bounds for a large class of random QBFs.\nWe also introduce a strengthening of the decision heuristic used in classical\nQCDCL, which does not necessarily decide variables in order of the prefix, but\nstill allows to learn asserting clauses. We show that with this decision\npolicy, QCDCL can be exponentially faster on some formulas.\nWe further exhibit a QCDCL proof system that is p-equivalent to Q-resolution.\nIn comparison to classical QCDCL, this new QCDCL version adapts both decision\nand unit propagation policies.",
    "descriptor": "",
    "authors": [
      "Olaf Beyersdorff",
      "Benjamin B\u00f6hm"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.04862"
  },
  {
    "id": "arXiv:2109.04863",
    "title": "Proceedings of the 29th International Symposium on Graph Drawing and  Network Visualization (GD 2021)",
    "abstract": "This is the arXiv index for the electronic proceedings of GD 2021, which\ncontains the peer-reviewed and revised accepted papers with an optional\nappendix. Proceedings (without appendices) are also to be published by Springer\nin the Lecture Notes in Computer Science series.",
    "descriptor": "",
    "authors": [
      "Helen Purchase",
      "Ignaz Rutter"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Human-Computer Interaction (cs.HC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.04863"
  },
  {
    "id": "arXiv:2109.04865",
    "title": "Emerging AI Security Threats for Autonomous Cars -- Case Studies",
    "abstract": "Artificial Intelligence has made a significant contribution to autonomous\nvehicles, from object detection to path planning. However, AI models require a\nlarge amount of sensitive training data and are usually computationally\nintensive to build. The commercial value of such models motivates attackers to\nmount various attacks. Adversaries can launch model extraction attacks for\nmonetization purposes or step-ping-stone towards other attacks like model\nevasion. In specific cases, it even results in destroying brand reputation,\ndifferentiation, and value proposition. In addition, IP laws and AI-related\nlegalities are still evolving and are not uniform across countries. We discuss\nmodel extraction attacks in detail with two use-cases and a generic kill-chain\nthat can compromise autonomous cars. It is essential to investigate strategies\nto manage and mitigate the risk of model theft.",
    "descriptor": "\nComments: 6 pages, 4 figures; Manuscript is accepted at ESCAR Europe 2021 conference\n",
    "authors": [
      "Shanthi Lekkala",
      "Tanya Motwani",
      "Manojkumar Parmar",
      "Amit Phadke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04865"
  },
  {
    "id": "arXiv:2109.04867",
    "title": "Studying word order through iterative shuffling",
    "abstract": "As neural language models approach human performance on NLP benchmark tasks,\ntheir advances are widely seen as evidence of an increasingly complex\nunderstanding of syntax. This view rests upon a hypothesis that has not yet\nbeen empirically tested: that word order encodes meaning essential to\nperforming these tasks. We refute this hypothesis in many cases: in the GLUE\nsuite and in various genres of English text, the words in a sentence or phrase\ncan rarely be permuted to form a phrase carrying substantially different\ninformation. Our surprising result relies on inference by iterative shuffling\n(IBIS), a novel, efficient procedure that finds the ordering of a bag of words\nhaving the highest likelihood under a fixed language model. IBIS can use any\nblack-box model without additional training and is superior to existing word\nordering algorithms. Coalescing our findings, we discuss how shuffling\ninference procedures such as IBIS can benefit language modeling and constrained\ngeneration.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Nikolay Malkin",
      "Sameera Lanka",
      "Pranav Goel",
      "Nebojsa Jojic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04867"
  },
  {
    "id": "arXiv:2109.04868",
    "title": "Heading Estimation Using Ultra-Wideband Received Signal Strength and  Gaussian Processes",
    "abstract": "It is essential that a robot has the ability to determine its position and\norientation to execute tasks autonomously. Heading estimation is especially\nchallenging in indoor environments where magnetic distortions make\nmagnetometer-based heading estimation difficult. Ultra-wideband (UWB)\ntransceivers are common in indoor localization problems. This letter\nexperimentally demonstrates how to use UWB range and received signal strength\n(RSS) measurements to estimate robot heading. The RSS of a UWB antenna varies\nwith its orientation. As such, a Gaussian process (GP) is used to learn a\ndata-driven relationship from UWB range and RSS inputs to orientation outputs.\nCombined with a gyroscope in an invariant extended Kalman filter, this realizes\na heading estimation method that uses only UWB and gyroscope measurements.",
    "descriptor": "\nComments: 6 pages, 9 figures, accepted to Robotics and Automation Letters, presented at IROS 2021\n",
    "authors": [
      "Daniil Lisus",
      "Charles Champagne Cossette",
      "Mohammed Shalaby",
      "James Richard Forbes"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04868"
  },
  {
    "id": "arXiv:2109.04869",
    "title": "PlaTe: Visually-Grounded Planning with Transformers in Procedural Tasks",
    "abstract": "In this work, we study the problem of how to leverage instructional videos to\nfacilitate the understanding of human decision-making processes, focusing on\ntraining a model with the ability to plan a goal-directed procedure from\nreal-world videos. Learning structured and plannable state and action spaces\ndirectly from unstructured videos is the key technical challenge of our task.\nThere are two problems: first, the appearance gap between the training and\nvalidation datasets could be large for unstructured videos; second, these gaps\nlead to decision errors that compound over the steps. We address these\nlimitations with Planning Transformer (PlaTe), which has the advantage of\ncircumventing the compounding prediction errors that occur with single-step\nmodels during long model-based rollouts. Our method simultaneously learns the\nlatent state and action information of assigned tasks and the representations\nof the decision-making process from human demonstrations. Experiments conducted\non real-world instructional videos and an interactive environment show that our\nmethod can achieve a better performance in reaching the indicated goal than\nprevious algorithms. We also validated the possibility of applying procedural\ntasks on a UR-5 platform.",
    "descriptor": "",
    "authors": [
      "Jiankai Sun",
      "De-An Huang",
      "Bo Lu",
      "Yun-Hui Liu",
      "Bolei Zhou",
      "Animesh Garg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04869"
  },
  {
    "id": "arXiv:2109.04870",
    "title": "MultiAzterTest: a Multilingual Analyzer on Multiple Levels of Language  for Readability Assessment",
    "abstract": "Readability assessment is the task of determining how difficult or easy a\ntext is or which level/grade it has. Traditionally, language dependent\nreadability formula have been used, but these formulae take few text\ncharacteristics into account. However, Natural Language Processing (NLP) tools\nthat assess the complexity of texts are able to measure more different features\nand can be adapted to different languages. In this paper, we present the\nMultiAzterTest tool: (i) an open source NLP tool which analyzes texts on over\n125 measures of cohesion,language, and readability for English, Spanish and\nBasque, but whose architecture is designed to easily adapt other languages;\n(ii) readability assessment classifiers that improve the performance of\nCoh-Metrix in English, Coh-Metrix-Esp in Spanish and ErreXail in Basque; iii) a\nweb tool. MultiAzterTest obtains 90.09 % in accuracy when classifying into\nthree reading levels (elementary, intermediate, and advanced) in English and\n95.50 % in Basque and 90 % in Spanish when classifying into two reading levels\n(simple and complex) using a SMO classifier. Using cross-lingual features,\nMultiAzterTest also obtains competitive results above all in a complex vs\nsimple distinction.",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Kepa Bengoetxea",
      "Itziar Gonzalez-Dios"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04870"
  },
  {
    "id": "arXiv:2109.04871",
    "title": "Spatio-Temporal Recurrent Networks for Event-Based Optical Flow  Estimation",
    "abstract": "Event camera has offered promising alternative for visual perception,\nespecially in high speed and high dynamic range scenes. Recently, many deep\nlearning methods have shown great success in providing model-free solutions to\nmany event-based problems, such as optical flow estimation. However, existing\ndeep learning methods did not address the importance of temporal information\nwell from the perspective of architecture design and cannot effectively extract\nspatio-temporal features. Another line of research that utilizes Spiking Neural\nNetwork suffers from training issues for deeper architecture. To address these\npoints, a novel input representation is proposed that captures the events\ntemporal distribution for signal enhancement. Moreover, we introduce a\nspatio-temporal recurrent encoding-decoding neural network architecture for\nevent-based optical flow estimation, which utilizes Convolutional Gated\nRecurrent Units to extract feature maps from a series of event images. Besides,\nour architecture allows some traditional frame-based core modules, such as\ncorrelation layer and iterative residual refine scheme, to be incorporated. The\nnetwork is end-to-end trained with self-supervised learning on the\nMulti-Vehicle Stereo Event Camera dataset. We have shown that it outperforms\nall the existing state-of-the-art methods by a large margin.",
    "descriptor": "",
    "authors": [
      "Ziluo Ding",
      "Rui Zhao",
      "Jiyuan Zhang",
      "Tianxiao Gao",
      "Ruiqin Xiong",
      "Zhaofei Yu",
      "Tiejun Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04871"
  },
  {
    "id": "arXiv:2109.04872",
    "title": "Negative Sample Matters: A Renaissance of Metric Learning for Temporal  Grounding",
    "abstract": "Temporal grounding aims to temporally localize a video moment in the video\nwhose semantics are related to a given natural language query. Existing methods\ntypically apply a detection or regression pipeline on the fused representation\nwith a focus on designing complicated heads and fusion strategies. Instead,\nfrom a perspective on temporal grounding as a metric-learning problem, we\npresent a Dual Matching Network (DMN), to directly model the relations between\nlanguage queries and video moments in a joint embedding space. This new\nmetric-learning framework enables fully exploiting negative samples from two\nnew aspects: constructing negative cross-modal pairs from a dual matching\nscheme and mining negative pairs across different videos. These new negative\nsamples could enhance the joint representation learning of two modalities via\ncross-modal pair discrimination to maximize their mutual information.\nExperiments show that DMN achieves highly competitive performance compared with\nstate-of-the-art methods on four video grounding benchmarks. Based on DMN, we\npresent a winner solution for STVG challenge of the 3rd PIC workshop. This\nsuggests that metric-learning is still a promising method for temporal\ngrounding via capturing the essential cross-modal correlation in a joint\nembedding space.",
    "descriptor": "\nComments: 18 pages, 18 figures. 1st place solution to HC-STVG challenge of the 3rd PIC workshop (this http URL)\n",
    "authors": [
      "Zhenzhi Wang",
      "Limin Wang",
      "Tao Wu",
      "Tianhao Li",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.04872"
  },
  {
    "id": "arXiv:2109.04874",
    "title": "Discretizing Dynamics for Maximum Likelihood Constraint Inference",
    "abstract": "Maximum likelihood constraint inference is a powerful technique for\nidentifying unmodeled constraints that affect the behavior of a demonstrator\nacting under a known objective function. However, it was originally formulated\nonly for discrete state-action spaces. Continuous dynamics are more useful for\nmodeling many real-world systems of interest, including the movements of humans\nand robots. We present a method to generate a tabular state-action space that\napproximates continuous dynamics and can be used for constraint inference on\ndemonstrations that obey the true system dynamics. We then demonstrate accurate\nconstraint inference on nonlinear pendulum systems with 2- and 4-dimensional\nstate spaces, and show that performance is robust to a range of\nhyperparameters. The demonstrations are not required to be fully optimal with\nrespect to the objective, and the most likely constraints can be identified\neven when demonstrations cover only a small portion of the state space. For\nthese reasons, the proposed approach may be especially useful for inferring\nconstraints on human demonstrators, which has important applications in\nhuman-robot interaction and biomechanical medicine.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Kaylene C. Stocking",
      "David L. McPherson",
      "Robert P. Matthew",
      "Claire J. Tomlin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04874"
  },
  {
    "id": "arXiv:2109.04876",
    "title": "Integrating Approaches to Word Representation",
    "abstract": "The problem of representing the atomic elements of language in modern neural\nlearning systems is one of the central challenges of the field of natural\nlanguage processing. I present a survey of the distributional, compositional,\nand relational approaches to addressing this task, and discuss various means of\nintegrating them into systems, with special emphasis on the word level and the\nout-of-vocabulary phenomenon.",
    "descriptor": "\nComments: Adapted dissertation introduction\n",
    "authors": [
      "Yuval Pinter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04876"
  },
  {
    "id": "arXiv:2109.04877",
    "title": "Efficient Test Time Adapter Ensembling for Low-resource Language  Varieties",
    "abstract": "Adapters are light-weight modules that allow parameter-efficient fine-tuning\nof pretrained models. Specialized language and task adapters have recently been\nproposed to facilitate cross-lingual transfer of multilingual pretrained models\n(Pfeiffer et al., 2020b). However, this approach requires training a separate\nlanguage adapter for every language one wishes to support, which can be\nimpractical for languages with limited data. An intuitive solution is to use a\nrelated language adapter for the new language variety, but we observe that this\nsolution can lead to sub-optimal performance. In this paper, we aim to improve\nthe robustness of language adapters to uncovered languages without training new\nadapters. We find that ensembling multiple existing language adapters makes the\nfine-tuned model significantly more robust to other language varieties not\nincluded in these adapters. Building upon this observation, we propose Entropy\nMinimized Ensemble of Adapters (EMEA), a method that optimizes the ensemble\nweights of the pretrained language adapters for each test sentence by\nminimizing the entropy of its predictions. Experiments on three diverse groups\nof language varieties show that our method leads to significant improvements on\nboth named entity recognition and part-of-speech tagging across all languages.",
    "descriptor": "\nComments: EMNLP 2021 Findings\n",
    "authors": [
      "Xinyi Wang",
      "Yulia Tsvetkov",
      "Sebastian Ruder",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04877"
  },
  {
    "id": "arXiv:2109.04880",
    "title": "Hybrid modeling of the human cardiovascular system using NeuralFMUs",
    "abstract": "Hybrid modeling, the combination of first principle and machine learning\nmodels, is an emerging research field that gathers more and more attention.\nEven if hybrid models produce formidable results for academic examples, there\nare still different technical challenges that hinder the use of hybrid modeling\nin real-world applications. By presenting NeuralFMUs, the fusion of a FMU, a\nnumerical ODE solver and an ANN, we are paving the way for the use of a variety\nof first principle models from different modeling tools as parts of hybrid\nmodels. This contribution handles the hybrid modeling of a complex, real-world\nexample: Starting with a simplified 1D-fluid model of the human cardiovascular\nsystem (arterial side), the aim is to learn neglected physical effects like\narterial elasticity from data. We will show that the hybrid modeling process is\nmore comfortable, needs less system knowledge and is therefore less error-prone\ncompared to modeling solely based on first principle. Further, the resulting\nhybrid model has improved in computation performance, compared to a pure first\nprinciple white-box model, while still fulfilling the requirements regarding\naccuracy of the considered hemodynamic quantities. The use of the presented\ntechniques is explained in a general manner and the considered use-case can\nserve as example for other modeling and simulation applications in and beyond\nthe medical domain.",
    "descriptor": "",
    "authors": [
      "Tobias Thummerer",
      "Johannes Tintenherr",
      "Lars Mikelsons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2109.04880"
  },
  {
    "id": "arXiv:2109.04881",
    "title": "ProcK: Machine Learning for Knowledge-Intensive Processes",
    "abstract": "Process mining deals with extraction of knowledge from business process\nexecution logs. Traditional process mining tasks, like process model generation\nor conformance checking, rely on a minimalistic feature set where each event is\ncharacterized only by its case identifier, activity type, and timestamp. In\ncontrast, the success of modern machine learning is based on models that take\nany available data as direct input and build layers of features automatically\nduring training. In this work, we introduce ProcK (Process & Knowledge), a\nnovel pipeline to build business process prediction models that take into\naccount both sequential data in the form of event logs and rich semantic\ninformation represented in a graph-structured knowledge base. The hybrid\napproach enables ProcK to flexibly make use of all information residing in the\ndatabases of organizations. Components to extract inter-linked event logs and\nknowledge bases from relational databases are part of the pipeline. We\ndemonstrate the power of ProcK by training it for prediction tasks on the OULAD\ne-learning dataset, where we achieve state-of-the-art performance on the tasks\nof predicting student dropout from courses and predicting their success. We\nalso apply our method on a number of additional machine learning tasks,\nincluding exam score prediction and early predictions that only take into\naccount data recorded during the first weeks of the courses.",
    "descriptor": "",
    "authors": [
      "Tobias Jacobs",
      "Jingyi Yu",
      "Julia Gastinger",
      "Timo Sztyler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.04881"
  },
  {
    "id": "arXiv:2109.04884",
    "title": "SO-SLAM: Semantic Object SLAM with Scale Proportional and Symmetrical  Texture Constraints",
    "abstract": "Object SLAM introduces the concept of objects into Simultaneous Localization\nand Mapping (SLAM) and helps understand indoor scenes for mobile robots and\nobject-level interactive applications. The state-of-art object SLAM systems\nface challenges such as partial observations, occlusions, unobservable\nproblems, limiting the mapping accuracy and robustness. This paper proposes a\nnovel monocular Semantic Object SLAM (SO-SLAM) system that addresses the\nintroduction of object spatial constraints. We explore three representative\nspatial constraints, including scale proportional constraint, symmetrical\ntexture constraint and plane supporting constraint. Based on these semantic\nconstraints, we propose two new methods - a more robust object initialization\nmethod and an orientation fine optimization method. We have verified the\nperformance of the algorithm on the public datasets and an author-recorded\nmobile robot dataset and achieved a significant improvement on mapping effects.\nWe will release the code here: https://github.com/XunshanMan/SoSLAM.",
    "descriptor": "\nComments: Submitted to RAL&ICRA 2022\n",
    "authors": [
      "Ziwei Liao",
      "Yutong Hu",
      "Jiadong Zhang",
      "Xianyu Qi",
      "Xiaoyu Zhang",
      "Wei Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04884"
  },
  {
    "id": "arXiv:2109.04888",
    "title": "Auctioning with Strategically Reticent Bidders",
    "abstract": "Classic mechanism design often assumes that a bidder's action is restricted\nto report a type or a signal, possibly untruthfully. In today's digital\neconomy, bidders are holding increasing amount of private information about the\nauctioned items. And due to legal or ethical concerns, they would demand to\nreveal partial but truthful information, as opposed to report untrue signal or\nmisinformation. To accommodate such bidder behaviors in auction design, we\npropose and study a novel mechanism design setup where each bidder holds two\nkinds of information: (1) private \\emph{value type}, which can be misreported;\n(2) private \\emph{information variable}, which the bidder may want to conceal\nor partially reveal, but importantly, \\emph{not} to misreport.\nWe show that in this new setup, it is still possible to design mechanisms\nthat are both \\emph{Incentive and Information Compatible} (IIC). We develop two\ndifferent black-box transformations, which convert any mechanism $\\mathcal{M}$\nfor classic bidders to a mechanism $\\mathcal{M}'$ for strategically reticent\nbidders, based on either outcome of expectation or expectation of outcome,\nrespectively. We identify properties of the original mechanism $\\mathcal{M}$\nunder which the transformation leads to IIC mechanisms $\\mathcal{M}'$.\nInterestingly, as corollaries of these results, we show that running VCG with\nexpected bidder values maximizes welfare whereas the mechanism using expected\noutcome of Myerson's auction maximizes revenue. Finally, we study how\nregulation on the auctioneer's usage of information may lead to more robust\nmechanisms.",
    "descriptor": "",
    "authors": [
      "Jibang Wu",
      "Ashwinkumar Badanidiyuru",
      "Haifeng Xu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2109.04888"
  },
  {
    "id": "arXiv:2109.04893",
    "title": "AID: Efficient Prediction of Aggregated Intensity of Dependency in  Large-scale Cloud Systems",
    "abstract": "Service reliability is one of the key challenges that cloud providers have to\ndeal with. In cloud systems, unplanned service failures may cause severe\ncascading impacts on their dependent services, deteriorating customer\nsatisfaction. Predicting the cascading impacts accurately and efficiently is\ncritical to the operation and maintenance of cloud systems. Existing approaches\nidentify whether one service depends on another via distributed tracing but no\nprior work focused on discriminating to what extent the dependency between\ncloud services is. In this paper, we survey the outages and the procedure for\nfailure diagnosis in two cloud providers to motivate the definition of the\nintensity of dependency. We define the intensity of dependency between two\nservices as how much the status of the callee service influences the caller\nservice. Then we propose AID, the first approach to predict the intensity of\ndependencies between cloud services. AID first generates a set of candidate\ndependency pairs from the spans. AID then represents the status of each cloud\nservice with a multivariate time series aggregated from the spans. With the\nrepresentation of services, AID calculates the similarities between the\nstatuses of the caller and the callee of each candidate pair. Finally, AID\naggregates the similarities to produce a unified value as the intensity of the\ndependency. We evaluate AID on the data collected from an open-source\nmicroservice benchmark and a cloud system in production. The experimental\nresults show that AID can efficiently and accurately predict the intensity of\ndependencies. We further demonstrate the usefulness of our method in a\nlarge-scale commercial cloud system.",
    "descriptor": "",
    "authors": [
      "Tianyi Yang",
      "Jiacheng Shen",
      "Yuxin Su",
      "Xiao Ling",
      "Yongqiang Yang",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.04893"
  },
  {
    "id": "arXiv:2109.04898",
    "title": "LibFewShot: A Comprehensive Library for Few-shot Learning",
    "abstract": "Few-shot learning, especially few-shot image classification, has received\nincreasing attention and witnessed significant advances in recent years. Some\nrecent studies implicitly show that many generic techniques or ``tricks'', such\nas data augmentation, pre-training, knowledge distillation, and\nself-supervision, may greatly boost the performance of a few-shot learning\nmethod. Moreover, different works may employ different software platforms,\ndifferent training schedules, different backbone architectures and even\ndifferent input image sizes, making fair comparisons difficult and\npractitioners struggle with reproducibility. To address these situations, we\npropose a comprehensive library for few-shot learning (LibFewShot) by\nre-implementing seventeen state-of-the-art few-shot learning methods in a\nunified framework with the same single codebase in PyTorch. Furthermore, based\non LibFewShot, we provide comprehensive evaluations on multiple benchmark\ndatasets with multiple backbone architectures to evaluate common pitfalls and\neffects of different training tricks. In addition, given the recent doubts on\nthe necessity of meta- or episodic-training mechanism, our evaluation results\nshow that such kind of mechanism is still necessary especially when combined\nwith pre-training. We hope our work can not only lower the barriers for\nbeginners to work on few-shot learning but also remove the effects of the\nnontrivial tricks to facilitate intrinsic research on few-shot learning. The\nsource code is available from https://github.com/RL-VIG/LibFewShot.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Wenbin Li",
      "Chuanqi Dong",
      "Pinzhuo Tian",
      "Tiexin Qin",
      "Xuesong Yang",
      "Ziyi Wang",
      "Jing Huo",
      "Yinghuan Shi",
      "Lei Wang",
      "Yang Gao",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04898"
  },
  {
    "id": "arXiv:2109.04901",
    "title": "Document-level Entity-based Extraction as Template Generation",
    "abstract": "Document-level entity-based extraction (EE), aiming at extracting\nentity-centric information such as entity roles and entity relations, is key to\nautomatic knowledge acquisition from text corpora for various domains. Most\ndocument-level EE systems build extractive models, which struggle to model\nlong-term dependencies among entities at the document level. To address this\nissue, we propose a generative framework for two document-level EE tasks:\nrole-filler entity extraction (REE) and relation extraction (RE). We first\nformulate them as a template generation problem, allowing models to efficiently\ncapture cross-entity dependencies, exploit label semantics, and avoid the\nexponential computation complexity of identifying N-ary relations. A novel\ncross-attention guided copy mechanism, TopK Copy, is incorporated into a\npre-trained sequence-to-sequence model to enhance the capabilities of\nidentifying key information in the input document. Experiments done on the\nMUC-4 and SciREX dataset show new state-of-the-art results on REE (+3.26%),\nbinary RE (+4.8%), and 4-ary RE (+2.7%) in F1 score.",
    "descriptor": "\nComments: 13 pages. EMNLP 2021\n",
    "authors": [
      "Kung-Hsiang Huang",
      "Sam Tang",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04901"
  },
  {
    "id": "arXiv:2109.04907",
    "title": "GPA-Teleoperation: Gaze Enhanced Perception-aware Safe Assistive Aerial  Teleoperation",
    "abstract": "Gaze is an intuitive and direct way to represent the intentions of an\nindividual. However, when it comes to assistive aerial teleoperation which aims\nto perform operators' intention, rare attention has been paid to gaze. Existing\nmethods obtain intention directly from the remote controller (RC) input, which\nis inaccurate, unstable, and unfriendly to non-professional operators. Further,\nmost teleoperation works do not consider environment perception which is vital\nto guarantee safety. In this paper, we present GPA-Teleoperation, a gaze\nenhanced perception-aware assistive teleoperation framework, which addresses\nthe above issues systematically. We capture the intention utilizing gaze\ninformation, and generate a topological path matching it. Then we refine the\npath into a safe and feasible trajectory which simultaneously enhances the\nperception awareness to the environment operators are interested in.\nAdditionally, the proposed method is integrated into a customized quadrotor\nsystem. Extensive challenging indoor and outdoor real-world experiments and\nbenchmark comparisons verify that the proposed system is reliable, robust and\napplicable to even unskilled users. We will release the source code of our\nsystem to benefit related researches.",
    "descriptor": "\nComments: 8 pages, 13 figures, submitted to RA-L with ICRA presentation option\n",
    "authors": [
      "Qianhao Wang",
      "Botao He",
      "Zhiren Xun",
      "Chao Xu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04907"
  },
  {
    "id": "arXiv:2109.04908",
    "title": "Error State Extended Kalman Filter Multi-Sensor Fusion for Unmanned  Aerial Vehicle Localization in GPS and Magnetometer Denied Indoor  Environments",
    "abstract": "This paper addresses the issues of unmanned aerial vehicle (UAV) indoor\nnavigation, specifically in areas where GPS and magnetometer sensor\nmeasurements are unavailable or unreliable. The proposed solution is to use an\nerror state extended Kalman filter (ES -EKF) in the context of multi-sensor\nfusion. Its implementation is adapted to fuse measurements from multiple sensor\nsources and the state model is extended to account for sensor drift and\npossible calibration inaccuracies. Experimental validation is performed by\nfusing IMU data obtained from the PixHawk 2.1 flight controller with pose\nmeasurements from LiDAR Cartographer SLAM, visual odometry provided by the\nIntel T265 camera and position measurements from the Pozyx UWB indoor\npositioning system. The estimated odometry from ES-EKF is validated against\nground truth data from the Optitrack motion capture system and its use in a\nposition control loop to stabilize the UAV is demonstrated.",
    "descriptor": "",
    "authors": [
      "Lovro Markovic",
      "Marin Kovac",
      "Robert Milijas",
      "Marko Car",
      "Stjepan Bogdan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04908"
  },
  {
    "id": "arXiv:2109.04909",
    "title": "How Can Subgroup Discovery Help AIOps?",
    "abstract": "The genuine supervision of modern IT systems brings new challenges as it\nrequires higher standards of scalability, reliability and efficiency when\nanalysing and monitoring big data streams. Rule-based inference engines are a\nkey component of maintenance systems in detecting anomalies and automating\ntheir resolution. However, they remain confined to simple and general rules and\ncannot handle the huge amount of data, nor the large number of alerts raised by\nIT systems, a lesson learned from expert systems era. Artificial Intelligence\nfor Operation Systems (AIOps) proposes to take advantage of advanced analytics\nand machine learning on big data to improve and automate every step of\nsupervision systems and aid incident management in detecting outages,\nidentifying root causes and applying appropriate healing actions. Nevertheless,\nthe best AIOps techniques rely on opaque models, strongly limiting their\nadoption. As a part of this PhD thesis, we study how Subgroup Discovery can\nhelp AIOps. This promising data mining technique offers possibilities to\nextract interesting hypothesis from data and understand the underlying process\nbehind predictive models. To ensure relevancy of our propositions, this project\ninvolves both data mining researchers and practitioners from Infologic, a\nFrench software editor.",
    "descriptor": "",
    "authors": [
      "Youcef Remil"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04909"
  },
  {
    "id": "arXiv:2109.04911",
    "title": "RandSolomon: optimally resilient multi-party random number generation  protocol",
    "abstract": "Multi-party random number generation is a key building-block in many\npractical protocols. While straightforward to solve when all parties are\ntrusted to behave correctly, the problem becomes much more difficult in the\npresence of faults. In this context, this paper presents RandSolomon, a\nprotocol that allows a network of N processes to produce an unpredictable\ncommon random number among the non-faulty of them. We provide optimal\nresilience for partially-synchronous systems where less than a third of the\nparticipants might behave arbitrarily and, contrary to many solutions, we do\nnot require at any point faulty-processes to be responsive.",
    "descriptor": "",
    "authors": [
      "Luciano Freitas de Souza",
      "Sara Tucci-Piergiovanni",
      "Renaud Sirdey",
      "Oana Stan",
      "Nicolas Quero",
      "Petr Kuznetsov"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.04911"
  },
  {
    "id": "arXiv:2109.04912",
    "title": "ReasonBERT: Pre-trained to Reason with Distant Supervision",
    "abstract": "We present ReasonBert, a pre-training method that augments language models\nwith the ability to reason over long-range relations and multiple, possibly\nhybrid contexts. Unlike existing pre-training methods that only harvest\nlearning signals from local contexts of naturally occurring texts, we propose a\ngeneralized notion of distant supervision to automatically connect multiple\npieces of text and tables to create pre-training examples that require\nlong-range reasoning. Different types of reasoning are simulated, including\nintersecting multiple pieces of evidence, bridging from one piece of evidence\nto another, and detecting unanswerable cases. We conduct a comprehensive\nevaluation on a variety of extractive question answering datasets ranging from\nsingle-hop to multi-hop and from text-only to table-only to hybrid that require\nvarious reasoning capabilities and show that ReasonBert achieves remarkable\nimprovement over an array of strong baselines. Few-shot experiments further\ndemonstrate that our pre-training method substantially improves sample\nefficiency.",
    "descriptor": "\nComments: Accepted to EMNLP'2021. Our code and pre-trained models are available at this https URL\n",
    "authors": [
      "Xiang Deng",
      "Yu Su",
      "Alyssa Lees",
      "You Wu",
      "Cong Yu",
      "Huan Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04912"
  },
  {
    "id": "arXiv:2109.04918",
    "title": "Estimation and Adaption of Indoor Ego Airflow Disturbance with  Application to Quadrotor Trajectory Planning",
    "abstract": "It is ubiquitously accepted that during the autonomous navigation of the\nquadrotors, one of the most widely adopted unmanned aerial vehicles (UAVs),\nsafety always has the highest priority. However, it is observed that the ego\nairflow disturbance can be a significant adverse factor during flights, causing\npotential safety issues, especially in narrow and confined indoor environments.\nTherefore, we propose a novel method to estimate and adapt indoor ego airflow\ndisturbance of quadrotors, meanwhile applying it to trajectory planning.\nFirstly, the hover experiments for different quadrotors are conducted against\nthe proximity effects. Then with the collected acceleration variance, the\ndisturbances are modeled for the quadrotors according to the proposed\nformulation. The disturbance model is also verified under hover conditions in\ndifferent reconstructed complex environments. Furthermore, the approximation of\nHamilton-Jacobi reachability analysis is performed according to the estimated\ndisturbances to facilitate the safe trajectory planning, which consists of\nkinodynamic path search as well as B-spline trajectory optimization. The whole\nplanning framework is validated on multiple quadrotor platforms in different\nindoor environments.",
    "descriptor": "\nComments: 7 pages, 10 figures, accepted by ICRA2021\n",
    "authors": [
      "Luqi Wang",
      "Boyu Zhou",
      "Chuhao Liu",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04918"
  },
  {
    "id": "arXiv:2109.04919",
    "title": "EmoWOZ: A Large-Scale Corpus and Labelling Scheme for Emotion in  Task-Oriented Dialogue Systems",
    "abstract": "The ability to recognise emotions lends a conversational artificial\nintelligence a human touch. While emotions in chit-chat dialogues have received\nsubstantial attention, emotions in task-oriented dialogues have been largely\noverlooked despite having an equally important role, such as to signal failure\nor success. Existing emotion-annotated task-oriented corpora are limited in\nsize, label richness, and public availability, creating a bottleneck for\ndownstream tasks. To lay a foundation for studies on emotions in task-oriented\ndialogues, we introduce EmoWOZ, a large-scale manually emotion-annotated corpus\nof task-oriented dialogues. EmoWOZ is based on MultiWOZ, a multi-domain\ntask-oriented dialogue dataset. It contains more than 11K dialogues with more\nthan 83K emotion annotations of user utterances. In addition to Wizzard-of-Oz\ndialogues from MultiWOZ, we collect human-machine dialogues within the same set\nof domains to sufficiently cover the space of various emotions that can happen\nduring the lifetime of a data-driven dialogue system. To the best of our\nknowledge, this is the first large-scale open-source corpus of its kind. We\npropose a novel emotion labelling scheme, which is tailored to task-oriented\ndialogues. We report a set of experimental results to show the usability of\nthis corpus for emotion recognition and state tracking in task-oriented\ndialogues.",
    "descriptor": "",
    "authors": [
      "Shutong Feng",
      "Nurul Lubis",
      "Christian Geishauser",
      "Hsien-chin Lin",
      "Michael Heck",
      "Carel van Niekerk",
      "Milica Ga\u0161i\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04919"
  },
  {
    "id": "arXiv:2109.04921",
    "title": "Examining Cross-lingual Contextual Embeddings with Orthogonal Structural  Probes",
    "abstract": "State-of-the-art contextual embeddings are obtained from large language\nmodels available only for a few languages. For others, we need to learn\nrepresentations using a multilingual model. There is an ongoing debate on\nwhether multilingual embeddings can be aligned in a space shared across many\nlanguages. The novel Orthogonal Structural Probe (Limisiewicz and Mare\\v{c}ek,\n2021) allows us to answer this question for specific linguistic features and\nlearn a projection based only on mono-lingual annotated datasets. We evaluate\nsyntactic (UD) and lexical (WordNet) structural information encoded inmBERT's\ncontextual representations for nine diverse languages. We observe that for\nlanguages closely related to English, no transformation is needed. The\nevaluated information is encoded in a shared cross-lingual embedding space. For\nother languages, it is beneficial to apply orthogonal transformation learned\nseparately for each language. We successfully apply our findings to zero-shot\nand few-shot cross-lingual parsing.",
    "descriptor": "\nComments: EMNLP 2021 Main Conference\n",
    "authors": [
      "Tomasz Limisiewicz",
      "David Mare\u010dek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04921"
  },
  {
    "id": "arXiv:2109.04922",
    "title": "Beyond the Tip of the Iceberg: Assessing Coherence of Text Classifiers",
    "abstract": "As large-scale, pre-trained language models achieve human-level and\nsuperhuman accuracy on existing language understanding tasks, statistical bias\nin benchmark data and probing studies have recently called into question their\ntrue capabilities. For a more informative evaluation than accuracy on text\nclassification tasks can offer, we propose evaluating systems through a novel\nmeasure of prediction coherence. We apply our framework to two existing\nlanguage understanding benchmarks with different properties to demonstrate its\nversatility. Our experimental results show that this evaluation framework,\nalthough simple in ideas and implementation, is a quick, effective, and\nversatile measure to provide insight into the coherence of machines'\npredictions.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Shane Storks",
      "Joyce Chai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04922"
  },
  {
    "id": "arXiv:2109.04925",
    "title": "Rapid Model Architecture Adaption for Meta-Learning",
    "abstract": "Network Architecture Search (NAS) methods have recently gathered much\nattention. They design networks with better performance and use a much shorter\nsearch time compared to traditional manual tuning. Despite their efficiency in\nmodel deployments, most NAS algorithms target a single task on a fixed hardware\nsystem. However, real-life few-shot learning environments often cover a great\nnumber of tasks (T ) and deployments on a wide variety of hardware platforms (H\n).\nThe combinatorial search complexity T times H creates a fundamental search\nefficiency challenge if one naively applies existing NAS methods to these\nscenarios. To overcome this issue, we show, for the first time, how to rapidly\nadapt model architectures to new tasks in a many-task many-hardware few-shot\nlearning setup by integrating Model Agnostic Meta Learning (MAML) into the NAS\nflow. The proposed NAS method (H-Meta-NAS) is hardware-aware and performs\noptimisation in the MAML framework. H-Meta-NAS shows a Pareto dominance\ncompared to a variety of NAS and manual baselines in popular few-shot learning\nbenchmarks with various hardware platforms and constraints. In particular, on\nthe 5-way 1-shot Mini-ImageNet classification task, the proposed method\noutperforms the best manual baseline by a large margin (5.21% in accuracy)\nusing 60% less computation.",
    "descriptor": "",
    "authors": [
      "Yiren Zhao",
      "Xitong Gao",
      "Ilia Shumailov",
      "Nicolo Fusi",
      "Robert Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04925"
  },
  {
    "id": "arXiv:2109.04927",
    "title": "Learning to Swarm with Knowledge-Based Neural Ordinary Differential  Equations",
    "abstract": "Understanding single-agent dynamics from collective behaviors in natural\nswarms is crucial for informing robot controller designs in artificial swarms\nand multiagent robotic systems. However, the complexity in agent-to-agent\ninteractions and the decentralized nature of most swarms pose a significant\nchallenge to the extraction of single-robot control laws from global behavior.\nIn this work, we consider the important task of learning decentralized\nsingle-robot controllers based solely on the state observations of a swarm's\ntrajectory. We present a general framework by adopting knowledge-based neural\nordinary differential equations (KNODE) -- a hybrid machine learning method\ncapable of combining artificial neural networks with known agent dynamics. Our\napproach distinguishes itself from most prior works in that we do not require\naction data for learning. We apply our framework to two different flocking\nswarms in 2D and 3D respectively, and demonstrate efficient training by\nleveraging the graphical structure of the swarms' information network. We\nfurther show that the learnt single-robot controllers can not only reproduce\nflocking behavior in the original swarm but also scale to swarms with more\nrobots.",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Tom Z. Jiahao",
      "Lishuo Pan",
      "M. Ani Hsieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.04927"
  },
  {
    "id": "arXiv:2109.04928",
    "title": "Trajectory Optimization with Optimization-Based Dynamics",
    "abstract": "We present a framework for bi-level trajectory optimization in which a\nsystem's dynamics are encoded as the solution to a constrained optimization\nproblem and smooth gradients of this lower-level problem are passed to an\nupper-level trajectory optimizer. This optimization-based dynamics\nrepresentation enables constraint handling, additional variables, and\nnon-smooth forces to be abstracted away from the upper-level optimizer, and\nallows classical unconstrained optimizers to synthesize trajectories for more\ncomplex systems. We provide a path-following method for efficient evaluation of\nconstrained dynamics and utilize the implicit-function theorem to compute\nsmooth gradients of this representation. We demonstrate the framework by\nmodeling systems from locomotion, aerospace, and manipulation domains\nincluding: acrobot with joint limits, cart-pole subject to Coulomb friction,\nRaibert hopper, rocket landing with thrust limits, and planar-push task with\noptimization-based dynamics and then optimize trajectories using iterative LQR.",
    "descriptor": "",
    "authors": [
      "Taylor A. Howell",
      "Simon Le Cleac'h",
      "Sumeet Singh",
      "Pete Florence",
      "Zachary Manchester",
      "Vikas Sindhwani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04928"
  },
  {
    "id": "arXiv:2109.04930",
    "title": "Bodies Uncovered: Learning to Manipulate Real Blankets Around People via  Physics Simulations",
    "abstract": "While robots present an opportunity to provide physical assistance to older\nadults and people with mobility impairments in bed, people frequently rest in\nbed with blankets that cover the majority of their body. To provide assistance\nfor many daily self-care tasks, such as bathing, dressing, or ambulating, a\ncaregiver must first uncover blankets from part of a person's body. In this\nwork, we introduce a formulation for robotic bedding manipulation around people\nin which a robot uncovers a blanket from a target body part while ensuring the\nrest of the human body remains covered. We compare both reinforcement and\nsupervised learning approaches for optimizing policies which provide a robot\nwith grasp and release points that uncover a target part of the body. We\ntrained and conducted evaluations of these policies in physics simulation\nenvironments that consist of a deformable cloth mesh covering a simulated human\nlying supine on a bed. In addition, we transfer simulation-trained policies to\na real mobile manipulator and demonstrate that it can uncover a blanket from\ntarget body parts of a manikin lying in bed. Source code is available online.",
    "descriptor": "\nComments: 8 pages, 8 figures, 3 tables\n",
    "authors": [
      "Kavya Puthuveetil",
      "Charles C. Kemp",
      "Zackory Erickson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04930"
  },
  {
    "id": "arXiv:2109.04934",
    "title": "Constructions of Binary Cross Z-Complementary Pairs With Large CZC Ratio",
    "abstract": "Cross Z-complementary pairs (CZCPs) are a special kind of Z-complementary\npairs (ZCPs) having zero autocorrelation sums around the in-phase position and\nend-shift position, also having zero cross-correlation sums around the\nend-shift position. It can be utilized as a key component in designing optimal\ntraining sequences for broadband spatial modulation (SM) systems over frequency\nselective channels. In this paper, we focus on designing new CZCPs with large\ncross Z-complementary ratio $(\\mathrm{CZC}_{\\mathrm{ratio}})$ by exploring two\npromising approaches. The first one of CZCPs via properly cascading sequences\nfrom a Golay complementary pair (GCP). The proposed construction leads to\n$(28L,13L)-\\mathrm{CZCPs}$, $(28L,13L+\\frac{L}{2})-\\mathrm{CZCPs}$ and\n$(30L,13L-1)-\\mathrm{CZCPs}$, where $L$ is the length of a binary GCP. Besides,\nwe emphasize that, our proposed CZCPs have the largest\n$\\mathrm{CZC}_{\\mathrm{ratio}}=\\frac{27}{28}$, compared with known CZCPs but\nno-perfect CZCPs in the literature. Specially, we proposed optimal binary CZCPs\nwith $(28,13)-\\mathrm{CZCP}$ and $(56,27)-\\mathrm{CZCP}$. The second one of\nCZCPs based on Boolean functions (BFs), and the construction of CZCPs have the\nlargest $\\mathrm{CZC}_{\\mathrm{ratio}}=\\frac{13}{14}$, compared with known\nCZCPs but no-perfect CZCPs in the literature.",
    "descriptor": "",
    "authors": [
      "Hui Zhang",
      "Cuiling Fan",
      "Sihem Mesnager"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.04934"
  },
  {
    "id": "arXiv:2109.04939",
    "title": "Modeling Human Sentence Processing with Left-Corner Recurrent Neural  Network Grammars",
    "abstract": "In computational linguistics, it has been shown that hierarchical structures\nmake language models (LMs) more human-like. However, the previous literature\nhas been agnostic about a parsing strategy of the hierarchical models. In this\npaper, we investigated whether hierarchical structures make LMs more\nhuman-like, and if so, which parsing strategy is most cognitively plausible. In\norder to address this question, we evaluated three LMs against human reading\ntimes in Japanese with head-final left-branching structures: Long Short-Term\nMemory (LSTM) as a sequential model and Recurrent Neural Network Grammars\n(RNNGs) with top-down and left-corner parsing strategies as hierarchical\nmodels. Our computational modeling demonstrated that left-corner RNNGs\noutperformed top-down RNNGs and LSTM, suggesting that hierarchical and\nleft-corner architectures are more cognitively plausible than top-down or\nsequential architectures. In addition, the relationships between the cognitive\nplausibility and (i) perplexity, (ii) parsing, and (iii) beam size will also be\ndiscussed.",
    "descriptor": "\nComments: Accepted by EMNLP 2021\n",
    "authors": [
      "Ryo Yoshida",
      "Hiroshi Noji",
      "Yohei Oseki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04939"
  },
  {
    "id": "arXiv:2109.04945",
    "title": "WikiCSSH: Extracting and Evaluating Computer Science Subject Headings  from Wikipedia",
    "abstract": "Hierarchical domain-specific classification schemas (or subject heading\nvocabularies) are often used to identify, classify, and disambiguate concepts\nthat occur in scholarly articles. In this work, we develop, apply, and evaluate\na human-in-the-loop workflow that first extracts an initial category tree from\ncrowd-sourced Wikipedia data, and then combines community detection, machine\nlearning, and hand-crafted heuristics or rules to prune the initial tree. This\nwork resulted in WikiCSSH; a large-scale, hierarchically organized vocabulary\nfor the domain of computer science (CS). Our evaluation suggests that WikiCSSH\noutperforms alternative CS vocabularies in terms of vocabulary size as well as\nthe performance of lexicon-based key-phrase extraction from scholarly data.\nWikiCSSH can further distinguish between coarse-grained versus fine-grained CS\nconcepts. The outlined workflow can serve as a template for building\nhierarchically-organized subject heading vocabularies for other domains that\nare covered in Wikipedia.",
    "descriptor": "",
    "authors": [
      "Kanyao Han",
      "Pingjing Yang",
      "Shubhanshu Mishra",
      "Jana Diesner"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2109.04945"
  },
  {
    "id": "arXiv:2109.04947",
    "title": "Tiered Reasoning for Intuitive Physics: Toward Verifiable Commonsense  Language Understanding",
    "abstract": "Large-scale, pre-trained language models (LMs) have achieved human-level\nperformance on a breadth of language understanding tasks. However, evaluations\nonly based on end task performance shed little light on machines' true ability\nin language understanding and reasoning. In this paper, we highlight the\nimportance of evaluating the underlying reasoning process in addition to end\nperformance. Toward this goal, we introduce Tiered Reasoning for Intuitive\nPhysics (TRIP), a novel commonsense reasoning dataset with dense annotations\nthat enable multi-tiered evaluation of machines' reasoning process. Our\nempirical results show that while large LMs can achieve high end performance,\nthey struggle to support their predictions with valid supporting evidence. The\nTRIP dataset and our baseline results will motivate verifiable evaluation of\ncommonsense reasoning and facilitate future research toward developing better\nlanguage understanding and reasoning models.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Shane Storks",
      "Qiaozi Gao",
      "Yichi Zhang",
      "Joyce Chai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04947"
  },
  {
    "id": "arXiv:2109.04949",
    "title": "We went to look for meaning and all we got were these lousy  representations: aspects of meaning representation for computational  semantics",
    "abstract": "In this paper we examine different meaning representations that are commonly\nused in different natural language applications today and discuss their limits,\nboth in terms of the aspects of the natural language meaning they are modelling\nand in terms of the aspects of the application for which they are used.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Simon Dobnik",
      "Robin Cooper",
      "Adam Ek",
      "Bill Noble",
      "Staffan Larsson",
      "Nikolai Ilinykh",
      "Vladislav Maraev",
      "Vidya Somashekarappa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04949"
  },
  {
    "id": "arXiv:2109.04951",
    "title": "Development and Validation of a Scalable Fast Load Shedding Technique  for Industrial Power Systems",
    "abstract": "The work aims to improve the existing fast load shedding algorithm for\nindustrial power system to increase performance, reliability, and scalability\nfor future expansions. The paper illustrates the development of a scalable\nalgorithm to compute the shedding matrix, and the test performed on a model of\nthe electric grid of an offshore platform. From this model it is possible to\nstudy the impact on the transients of various parameters, such as spinning\nreserve and delay time. Subsequently, the code is converted into Structured\nText and implemented on an ABB PLC. The scalability of the load shedding\nalgorithm is thus verified, confirming its performance with respect to the\ncomputation of the shedding matrix and the usefulness of the dynamic\nsimulations during the design phase of the plant.",
    "descriptor": "",
    "authors": [
      "Andrea Petriccioli",
      "Samuele Grillo",
      "David Comunello",
      "Andrea Cacace"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04951"
  },
  {
    "id": "arXiv:2109.04953",
    "title": "Does Pretraining for Summarization Require Knowledge Transfer?",
    "abstract": "Pretraining techniques leveraging enormous datasets have driven recent\nadvances in text summarization. While folk explanations suggest that knowledge\ntransfer accounts for pretraining's benefits, little is known about why it\nworks or what makes a pretraining task or dataset suitable. In this paper, we\nchallenge the knowledge transfer story, showing that pretraining on documents\nconsisting of character n-grams selected at random, we can nearly match the\nperformance of models pretrained on real corpora. This work holds the promise\nof eliminating upstream corpora, which may alleviate some concerns over\noffensive language, bias, and copyright issues. To see whether the small\nresidual benefit of using real data could be accounted for by the structure of\nthe pretraining task, we design several tasks motivated by a qualitative study\nof summarization corpora. However, these tasks confer no appreciable benefit,\nleaving open the possibility of a small role for knowledge transfer.",
    "descriptor": "\nComments: Camera-ready for Findings of EMNLP 2021\n",
    "authors": [
      "Kundan Krishna",
      "Jeffrey Bigham",
      "Zachary C. Lipton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04953"
  },
  {
    "id": "arXiv:2109.04954",
    "title": "Saliency Guided Experience Packing for Replay in Continual Learning",
    "abstract": "Artificial learning systems aspire to mimic human intelligence by continually\nlearning from a stream of tasks without forgetting past knowledge. One way to\nenable such learning is to store past experiences in the form of input examples\nin episodic memory and replay them when learning new tasks. However,\nperformance of such method suffers as the size of the memory becomes smaller.\nIn this paper, we propose a new approach for experience replay, where we select\nthe past experiences by looking at the saliency maps which provide visual\nexplanations for the model's decision. Guided by these saliency maps, we pack\nthe memory with only the parts or patches of the input images important for the\nmodel's prediction. While learning a new task, we replay these memory patches\nwith appropriate zero-padding to remind the model about its past decisions. We\nevaluate our algorithm on diverse image classification datasets and report\nbetter performance than the state-of-the-art approaches. With qualitative and\nquantitative analyses we show that our method captures richer summary of past\nexperiences without any memory increase, and hence performs well with small\nepisodic memory.",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Gobinda Saha",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04954"
  },
  {
    "id": "arXiv:2109.04957",
    "title": "Controlled Neural Sentence-Level Reframing of News Articles",
    "abstract": "Framing a news article means to portray the reported event from a specific\nperspective, e.g., from an economic or a health perspective. Reframing means to\nchange this perspective. Depending on the audience or the submessage, reframing\ncan become necessary to achieve the desired effect on the readers. Reframing is\nrelated to adapting style and sentiment, which can be tackled with neural text\ngeneration techniques. However, it is more challenging since changing a frame\nrequires rewriting entire sentences rather than single phrases. In this paper,\nwe study how to computationally reframe sentences in news articles while\nmaintaining their coherence to the context. We treat reframing as a\nsentence-level fill-in-the-blank task for which we train neural models on an\nexisting media frame corpus. To guide the training, we propose three\nstrategies: framed-language pretraining, named-entity preservation, and\nadversarial learning. We evaluate respective models automatically and manually\nfor topic consistency, coherence, and successful reframing. Our results\nindicate that generating properly-framed text works well but with tradeoffs.",
    "descriptor": "",
    "authors": [
      "Wei-Fan Chen",
      "Khalid Al-Khatib",
      "Benno Stein",
      "Henning Wachsmuth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04957"
  },
  {
    "id": "arXiv:2109.04966",
    "title": "Binarized P-Network: Deep Reinforcement Learning of Robot Control from  Raw Images on FPGA",
    "abstract": "This paper explores a Deep Reinforcement Learning (DRL) approach for\ndesigning image-based control for edge robots to be implemented on Field\nProgrammable Gate Arrays (FPGAs). Although FPGAs are more power-efficient than\nCPUs and GPUs, a typical (DRL) method cannot be applied since they are composed\nof many Logic Blocks (LBs) for high-speed logical operations but low-speed\nreal-number operations. To cope with this problem, we propose a novel DRL\nalgorithm called Binarized P-Network (BPN), which learns image-input control\npolicies using Binarized Convolutional Neural Networks (BCNNs). To alleviate\nthe instability of reinforcement learning caused by a BCNN with low function\napproximation accuracy, our BPN adopts a robust value update scheme called\nConservative Value Iteration, which is tolerant of function approximation\nerrors. We confirmed the BPN's effectiveness through applications to a visual\ntracking task in simulation and real-robot experiments with FPGA.",
    "descriptor": "\nComments: 8 pages, Accepted by Robotics and Automation Letters\n",
    "authors": [
      "Yuki Kadokawa",
      "Yoshihisa Tsurumine",
      "Takamitsu Matsubara"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04966"
  },
  {
    "id": "arXiv:2109.04968",
    "title": "Uncertainty-Aware Capacity Allocation in Flow-Based Market Coupling",
    "abstract": "The effective allocation of cross-border trading capacities is one of the\ncentral challenges in implementation of a pan-European internal energy market.\nFlow-based market coupling has shown promising results for to achieve better\nprice convergence between market areas, while, at the same time, improving\ncongestion management effectiveness by explicitly internalizing power flows on\ncritical network elements in the capacity allocation routine. % While academic\npublications that synthesize FBMC in model frameworks agree on a general\nprocess that aligns with the real market coupling process, they differ greatly\nin some core assumptions. However, the question of FBMC effectiveness for a\nfuture power system with a very high share of intermittent renewable generation\nis often overlooked in the current literature. This paper provides a\ncomprehensive summary on FBMC modeling assumptions, discusses implications of\nexternal policy considerations and explicitly discusses the impact of\nhigh-shares of intermittent generation on the effectiveness of FBMC as a method\nof capacity allocation and congestion management in zonal electricity markets.\nWe propose to use an RES uncertainty model and probabilistic security margins\non the FBMC parameterization to effectively assess the impact of forecast\nerrors in renewable dominant power systems. Numerical experiments on the\nwell-studied IEEE 118 bus test system demonstrate the mechanics of the studied\nFBMC simulation. Our data and implementation are published through the\nopen-source power market tool POMATO.",
    "descriptor": "",
    "authors": [
      "Ricahrd Weinhold",
      "Robert Mieth"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04968"
  },
  {
    "id": "arXiv:2109.04975",
    "title": "Citizen centric optimal electric vehicle charging stations locations in  a full city: case of Malaga",
    "abstract": "This article presents the problem of locating electric vehicle (EV) charging\nstations in a city by defining the Electric Vehicle Charging Stations Locations\n(EV-CSL) problem. The idea is to minimize the distance the citizens have to\ntravel to charge their vehicles. EV-CSL takes into account the maximum number\nof charging stations to install and the electric power requirements. Two\nmetaheuristics are applied to address the relying optimization problem: a\ngenetic algorithm (GA) and a variable neighborhood search (VNS). The\nexperimental analysis over a realistic scenario of Malaga city, Spain, shows\nthat the metaheuristics are able to find competitive solutions which\ndramatically improve the actual installation of the stations in Malaga. GA\nprovided statistically the best results.",
    "descriptor": "",
    "authors": [
      "Christian Cintrano",
      "Jamal Toutouh",
      "Enrique Alba"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04975"
  },
  {
    "id": "arXiv:2109.04979",
    "title": "A Study of Joint Graph Inference and Forecasting",
    "abstract": "We study a recent class of models which uses graph neural networks (GNNs) to\nimprove forecasting in multivariate time series.\nThe core assumption behind these models is that there is a latent graph\nbetween the time series (nodes) that governs the evolution of the multivariate\ntime series.\nBy parameterizing a graph in a differentiable way, the models aim to improve\nforecasting quality.\nWe compare four recent models of this class on the forecasting task. Further,\nwe perform ablations to study their behavior under changing conditions, e.g.,\nwhen disabling the graph-learning modules and providing the ground-truth\nrelations instead. Based on our findings, we propose novel ways of combining\nthe existing architectures.",
    "descriptor": "\nComments: Published at the ICML 2021 Time Series Workshop\n",
    "authors": [
      "Daniel Z\u00fcgner",
      "Fran\u00e7ois-Xavier Aubet",
      "Victor Garcia Satorras",
      "Tim Januschowski",
      "Stephan G\u00fcnnemann",
      "Jan Gasthaus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04979"
  },
  {
    "id": "arXiv:2109.04983",
    "title": "A Neural Tangent Kernel Perspective of Infinite Tree Ensembles",
    "abstract": "In practical situations, the ensemble tree model is one of the most popular\nmodels along with neural networks. A soft tree is one of the variants of a\ndecision tree. Instead of using a greedy method for searching splitting rules,\nthe soft tree is trained using a gradient method in which the whole splitting\noperation is formulated in a differentiable form. Although ensembles of such\nsoft trees have been increasingly used in recent years, little theoretical work\nhas been done for understanding their behavior. In this paper, by considering\nan ensemble of infinite soft trees, we introduce and study the Tree Neural\nTangent Kernel (TNTK), which provides new insights into the behavior of the\ninfinite ensemble of soft trees. Using the TNTK, we succeed in theoretically\nfinding several non-trivial properties, such as the effect of the oblivious\ntree structure and the degeneracy of the TNTK induced by the deepening of the\ntrees. Moreover, we empirically examine the performance of an ensemble of\ninfinite soft trees using the TNTK.",
    "descriptor": "",
    "authors": [
      "Ryuichi Kanoh",
      "Mahito Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04983"
  },
  {
    "id": "arXiv:2109.04986",
    "title": "Multi-agent deep reinforcement learning (MADRL) meets multi-user MIMO  systems",
    "abstract": "A multi-agent deep reinforcement learning (MADRL) is a promising approach to\nchallenging problems in wireless environments involving multiple\ndecision-makers (or actors) with high-dimensional continuous action space. In\nthis paper, we present a MADRL-based approach that can jointly optimize\nprecoders to achieve the outer-boundary, called pareto-boundary, of the\nachievable rate region for a multiple-input single-output (MISO) interference\nchannel (IFC). In order to address two main challenges, namely, multiple actors\n(or agents) with partial observability and multi-dimensional continuous action\nspace in MISO IFC setup, we adopt a multi-agent deep deterministic policy\ngradient (MA-DDPG) framework in which decentralized actors with partial\nobservability can learn a multi-dimensional continuous policy in a centralized\nmanner with the aid of shared critic with global information. Meanwhile, we\nwill also address a phase ambiguity issue with the conventional complex\nbaseband representation of signals widely used in radio communications. In\norder to mitigate the impact of phase ambiguity on training performance, we\npropose a training method, called phase ambiguity elimination (PAE), that leads\nto faster learning and better performance of MA-DDPG in wireless communication\nsystems. The simulation results exhibit that MA-DDPG is capable of learning a\nnear-optimal precoding strategy in a MISO IFC environment. To the best of our\nknowledge, this is the first work to demonstrate that the MA-DDPG framework can\njointly optimize precoders to achieve the pareto-boundary of achievable rate\nregion in a multi-cell multi-user multi-antenna system.",
    "descriptor": "\nComments: Accepted for presentation at the IEEE GLOBECOM 2021, SAC, Machine Learning for Communications, December 7 - 11, in Madrid, Spain. @2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media\n",
    "authors": [
      "Heunchul Lee",
      "Jaeseong Jeong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04986"
  },
  {
    "id": "arXiv:2109.04988",
    "title": "Panoptic Narrative Grounding",
    "abstract": "This paper proposes Panoptic Narrative Grounding, a spatially fine and\ngeneral formulation of the natural language visual grounding problem. We\nestablish an experimental framework for the study of this new task, including\nnew ground truth and metrics, and we propose a strong baseline method to serve\nas stepping stone for future work. We exploit the intrinsic semantic richness\nin an image by including panoptic categories, and we approach visual grounding\nat a fine-grained level by using segmentations. In terms of ground truth, we\npropose an algorithm to automatically transfer Localized Narratives annotations\nto specific regions in the panoptic segmentations of the MS COCO dataset. To\nguarantee the quality of our annotations, we take advantage of the semantic\nstructure contained in WordNet to exclusively incorporate noun phrases that are\ngrounded to a meaningfully related panoptic segmentation region. The proposed\nbaseline achieves a performance of 55.4 absolute Average Recall points. This\nresult is a suitable foundation to push the envelope further in the development\nof methods for Panoptic Narrative Grounding.",
    "descriptor": "\nComments: 10 pages, 6 figures, to appear at ICCV 2021 (Oral presentation)\n",
    "authors": [
      "C. Gonz\u00e1lez",
      "N. Ayobi",
      "I. Hern\u00e1ndez",
      "J. Hern\u00e1ndez",
      "J. Pont-Tuset",
      "P. Arbel\u00e1ez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04988"
  },
  {
    "id": "arXiv:2109.04990",
    "title": "Unsupervised Change Detection in Hyperspectral Images using Feature  Fusion Deep Convolutional Autoencoders",
    "abstract": "Binary change detection in bi-temporal co-registered hyperspectral images is\na challenging task due to a large number of spectral bands present in the data.\nResearchers, therefore, try to handle it by reducing dimensions. The proposed\nwork aims to build a novel feature extraction system using a feature fusion\ndeep convolutional autoencoder for detecting changes between a pair of such\nbi-temporal co-registered hyperspectral images. The feature fusion considers\nfeatures across successive levels and multiple receptive fields and therefore\nadds a competitive edge over the existing feature extraction methods. The\nchange detection technique described is completely unsupervised and is much\nmore elegant than other supervised or semi-supervised methods which require\nsome amount of label information. Different methods have been applied to the\nextracted features to find the changes in the two images and it is found that\nthe proposed method clearly outperformed the state of the art methods in\nunsupervised change detection for all the datasets.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Debasrita Chakraborty",
      "Ashish Ghosh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04990"
  },
  {
    "id": "arXiv:2109.04991",
    "title": "Detection of GAN-synthesized street videos",
    "abstract": "Research on the detection of AI-generated videos has focused almost\nexclusively on face videos, usually referred to as deepfakes. Manipulations\nlike face swapping, face reenactment and expression manipulation have been the\nsubject of an intense research with the development of a number of efficient\ntools to distinguish artificial videos from genuine ones. Much less attention\nhas been paid to the detection of artificial non-facial videos. Yet, new tools\nfor the generation of such kind of videos are being developed at a fast pace\nand will soon reach the quality level of deepfake videos. The goal of this\npaper is to investigate the detectability of a new kind of AI-generated videos\nframing driving street sequences (here referred to as DeepStreets videos),\nwhich, by their nature, can not be analysed with the same tools used for facial\ndeepfakes. Specifically, we present a simple frame-based detector, achieving\nvery good performance on state-of-the-art DeepStreets videos generated by the\nVid2vid architecture. Noticeably, the detector retains very good performance on\ncompressed videos, even when the compression level used during training does\nnot match that used for the test videos.",
    "descriptor": "\nComments: 2021 29th European Association for Signal Processing (EURASIP)\n",
    "authors": [
      "Omran Alamayreh",
      "Mauro Barni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04991"
  },
  {
    "id": "arXiv:2109.04993",
    "title": "LAViTeR: Learning Aligned Visual and Textual Representations Assisted by  Image and Caption Generation",
    "abstract": "Pre-training visual and textual representations from large-scale image-text\npairs is becoming a standard approach for many downstream vision-language\ntasks. The transformer-based models learn inter and intra-modal attention\nthrough a list of self-supervised learning tasks. This paper proposes LAViTeR,\na novel architecture for visual and textual representation learning. The main\nmodule, Visual Textual Alignment (VTA) will be assisted by two auxiliary tasks,\nGAN-based image synthesis and Image Captioning. We also propose a new\nevaluation metric measuring the similarity between the learnt visual and\ntextual embedding. The experimental results on two public datasets, CUB and\nMS-COCO, demonstrate superior visual and textual representation alignment in\nthe joint feature embedding space",
    "descriptor": "\nComments: 14 pages, 10 Figures, 5 Tables\n",
    "authors": [
      "Mohammad Abuzar Shaikh",
      "Zhanghexuan Ji",
      "Dana Moukheiber",
      "Sargur Srihari",
      "Mingchen Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04993"
  },
  {
    "id": "arXiv:2109.04994",
    "title": "Topic-Aware Contrastive Learning for Abstractive Dialogue Summarization",
    "abstract": "Unlike well-structured text, such as news reports and encyclopedia articles,\ndialogue content often comes from two or more interlocutors, exchanging\ninformation with each other. In such a scenario, the topic of a conversation\ncan vary upon progression and the key information for a certain topic is often\nscattered across multiple utterances of different speakers, which poses\nchallenges to abstractly summarize dialogues. To capture the various topic\ninformation of a conversation and outline salient facts for the captured\ntopics, this work proposes two topic-aware contrastive learning objectives,\nnamely coherence detection and sub-summary generation objectives, which are\nexpected to implicitly model the topic change and handle information scattering\nchallenges for the dialogue summarization task. The proposed contrastive\nobjectives are framed as auxiliary tasks for the primary dialogue summarization\ntask, united via an alternative parameter updating strategy. Extensive\nexperiments on benchmark datasets demonstrate that the proposed simple method\nsignificantly outperforms strong baselines and achieves new state-of-the-art\nperformance. The code and trained models are publicly available via\n\\href{https://github.com/Junpliu/ConDigSum}{https://github.com/Junpliu/ConDigSum}.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Junpeng Liu",
      "Yanyan Zou",
      "Hainan Zhang",
      "Hongshen Chen",
      "Zhuoye Ding",
      "Caixia Yuan",
      "Xiaojie Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04994"
  },
  {
    "id": "arXiv:2109.04995",
    "title": "Furthering Visual Accessibility with Extended Reality (XR): A Systematic  Review",
    "abstract": "Over the past decade, extended reality (XR) applications have increasingly\nbeen used as assistive technology for people with low vision (LV). Here we\npresent a systematic literature review of 216 publications from 109 different\nvenues assessing the potential of XR technology to serve as not just a visual\naccessibility aid but also as a tool to study perception and behavior in people\nwith low vision and blind people whose vision was restored with a visual\nneuroprosthesis. These technologies may be used to visually enhance a person's\nenvironment for completing daily activities, train LV participants with\nresidual vision, or simulate either a specific visual impairment or the\nartificial vision generated by a prosthetic implant. We also highlight the need\nfor adequate empirical evaluation, the broadening of end-user participation,\nand a more nuanced understanding of the suitability and usability of different\nXR-based accessibility aids.",
    "descriptor": "",
    "authors": [
      "Justin Kasowski",
      "Byron A. Johnson",
      "Ryan Neydavood",
      "Anvitha Akkaraju",
      "Michael Beyeler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04995"
  },
  {
    "id": "arXiv:2109.04996",
    "title": "Efficient Exascale Discretizations: High-Order Finite Element Methods",
    "abstract": "Efficient exploitation of exascale architectures requires rethinking of the\nnumerical algorithms used in many large-scale applications. These architectures\nfavor algorithms that expose ultra fine-grain parallelism and maximize the\nratio of floating point operations to energy intensive data movement. One of\nthe few viable approaches to achieve high efficiency in the area of PDE\ndiscretizations on unstructured grids is to use matrix-free/partially-assembled\nhigh-order finite element methods, since these methods can increase the\naccuracy and/or lower the computational time due to reduced data motion. In\nthis paper we provide an overview of the research and development activities in\nthe Center for Efficient Exascale Discretizations (CEED), a co-design center in\nthe Exascale Computing Project that is focused on the development of\nnext-generation discretization software and algorithms to enable a wide range\nof finite element applications to run efficiently on future hardware. CEED is a\nresearch partnership involving more than 30 computational scientists from two\nUS national labs and five universities, including members of the Nek5000, MFEM,\nMAGMA and PETSc projects. We discuss the CEED co-design activities based on\ntargeted benchmarks, miniapps and discretization libraries and our work on\nperformance optimizations for large-scale GPU architectures. We also provide a\nbroad overview of research and development activities in areas such as\nunstructured adaptive mesh refinement algorithms, matrix-free linear solvers,\nhigh-order data visualization, and list examples of collaborations with several\nECP and external applications.",
    "descriptor": "\nComments: 22 pages, 18 figures\n",
    "authors": [
      "Tzanio Kolev",
      "Paul Fischer",
      "Misun Min",
      "Jack Dongarra",
      "Jed Brown",
      "Veselin Dobrev",
      "Tim Warburton",
      "Stanimire Tomov",
      "Mark S. Shephard",
      "Ahmad Abdelfattah",
      "Valeria Barra",
      "Natalie Beams",
      "Jean-Sylvain Camier",
      "Noel Chalmers",
      "Yohann Dudouit",
      "Ali Karakus",
      "Ian Karlin",
      "Stefan Kerkemeier",
      "Yu-Hsiang Lan",
      "David Medina",
      "Elia Merzari",
      "Aleksandr Obabko",
      "Will Pazner",
      "Thilina Rathnayake",
      "Cameron W. Smith",
      "Lukas Spies",
      "Kasia Swirydowicz",
      "Jeremy Thompson",
      "Ananias Tomboulides",
      "Vladimir Tomov"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04996"
  },
  {
    "id": "arXiv:2109.04997",
    "title": "Box Embeddings: An open-source library for representation learning using  geometric structures",
    "abstract": "A major factor contributing to the success of modern representation learning\nis the ease of performing various vector operations. Recently, objects with\ngeometric structures (eg. distributions, complex or hyperbolic vectors, or\nregions such as cones, disks, or boxes) have been explored for their\nalternative inductive biases and additional representational capacities. In\nthis work, we introduce Box Embeddings, a Python library that enables\nresearchers to easily apply and extend probabilistic box embeddings.",
    "descriptor": "\nComments: The source code and the usage and API documentation for the library is available at this https URL and this https URL\n",
    "authors": [
      "Tejas Chheda",
      "Purujit Goyal",
      "Trang Tran",
      "Dhruvesh Patel",
      "Michael Boratko",
      "Shib Sankar Dasgupta",
      "Andrew McCallum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04997"
  },
  {
    "id": "arXiv:2109.04999",
    "title": "Fairness without the sensitive attribute via Causal Variational  Autoencoder",
    "abstract": "In recent years, most fairness strategies in machine learning models focus on\nmitigating unwanted biases by assuming that the sensitive information is\nobserved. However this is not always possible in practice. Due to privacy\npurposes and var-ious regulations such as RGPD in EU, many personal sensitive\nattributes are frequently not collected. We notice a lack of approaches for\nmitigating bias in such difficult settings, in particular for achieving\nclassical fairness objectives such as Demographic Parity and Equalized Odds. By\nleveraging recent developments for approximate inference, we propose an\napproach to fill this gap. Based on a causal graph, we rely on a new\nvariational auto-encoding based framework named SRCVAE to infer a sensitive\ninformation proxy, that serve for bias mitigation in an adversarial fairness\napproach. We empirically demonstrate significant improvements over existing\nworks in the field. We observe that the generated proxy's latent space recovers\nsensitive information and that our approach achieves a higher accuracy while\nobtaining the same level of fairness on two real datasets, as measured using\ncom-mon fairness definitions.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Vincent Grari",
      "Sylvain Lamprier",
      "Marcin Detyniecki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04999"
  },
  {
    "id": "arXiv:2109.05000",
    "title": "Assessing the Quality of the Datasets by Identifying Mislabeled Samples",
    "abstract": "Due to the over-emphasize of the quantity of data, the data quality has often\nbeen overlooked. However, not all training data points contribute equally to\nlearning. In particular, if mislabeled, it might actively damage the\nperformance of the model and the ability to generalize out of distribution, as\nthe model might end up learning spurious artifacts present in the dataset. This\nproblem gets compounded by the prevalence of heavily parameterized and complex\ndeep neural networks, which can, with their high capacity, end up memorizing\nthe noise present in the dataset. This paper proposes a novel statistic --\nnoise score, as a measure for the quality of each data point to identify such\nmislabeled samples based on the variations in the latent space representation.\nIn our work, we use the representations derived by the inference network of\ndata quality supervised variational autoencoder (AQUAVS). Our method leverages\nthe fact that samples belonging to the same class will have similar latent\nrepresentations. Therefore, by identifying the outliers in the latent space, we\ncan find the mislabeled samples. We validate our proposed statistic through\nexperimentation by corrupting MNIST, FashionMNIST, and CIFAR10/100 datasets in\ndifferent noise settings for the task of identifying mislabelled samples. We\nfurther show significant improvements in accuracy for the classification task\nfor each dataset.",
    "descriptor": "\nComments: Short paper accepted at ASONAM 2021\n",
    "authors": [
      "Vaibhav Pulastya",
      "Gaurav Nuti",
      "Yash Kumar Atri",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.05000"
  },
  {
    "id": "arXiv:2109.05003",
    "title": "Distantly-Supervised Named Entity Recognition with Noise-Robust Learning  and Language Model Augmented Self-Training",
    "abstract": "We study the problem of training named entity recognition (NER) models using\nonly distantly-labeled data, which can be automatically obtained by matching\nentity mentions in the raw text with entity types in a knowledge base. The\nbiggest challenge of distantly-supervised NER is that the distant supervision\nmay induce incomplete and noisy labels, rendering the straightforward\napplication of supervised learning ineffective. In this paper, we propose (1) a\nnoise-robust learning scheme comprised of a new loss function and a noisy label\nremoval step, for training NER models on distantly-labeled data, and (2) a\nself-training method that uses contextualized augmentations created by\npre-trained language models to improve the generalization ability of the NER\nmodel. On three benchmark datasets, our method achieves superior performance,\noutperforming existing distantly-supervised NER models by significant margins.",
    "descriptor": "\nComments: EMNLP 2021. (Code: this https URL)\n",
    "authors": [
      "Yu Meng",
      "Yunyi Zhang",
      "Jiaxin Huang",
      "Xuan Wang",
      "Yu Zhang",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05003"
  },
  {
    "id": "arXiv:2109.05006",
    "title": "BiSECT: Learning to Split and Rephrase Sentences with Bitexts",
    "abstract": "An important task in NLP applications such as sentence simplification is the\nability to take a long, complex sentence and split it into shorter sentences,\nrephrasing as necessary. We introduce a novel dataset and a new model for this\n`split and rephrase' task. Our BiSECT training data consists of 1 million long\nEnglish sentences paired with shorter, meaning-equivalent English sentences. We\nobtain these by extracting 1-2 sentence alignments in bilingual parallel\ncorpora and then using machine translation to convert both sides of the corpus\ninto the same language. BiSECT contains higher quality training examples than\nprevious Split and Rephrase corpora, with sentence splits that require more\nsignificant modifications. We categorize examples in our corpus, and use these\ncategories in a novel model that allows us to target specific regions of the\ninput sentence to be split and edited. Moreover, we show that models trained on\nBiSECT can perform a wider variety of split operations and improve upon\nprevious state-of-the-art approaches in automatic and human evaluations.",
    "descriptor": "\nComments: 9 pages, 9 figures. Long paper to appear in Empirical Methods in Natural Language Processing 2021 (EMNLP 2021)\n",
    "authors": [
      "Joongwon Kim",
      "Mounica Maddela",
      "Reno Kriz",
      "Wei Xu",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05006"
  },
  {
    "id": "arXiv:2109.05013",
    "title": "PWPAE: An Ensemble Framework for Concept Drift Adaptation in IoT Data  Streams",
    "abstract": "As the number of Internet of Things (IoT) devices and systems have surged,\nIoT data analytics techniques have been developed to detect malicious\ncyber-attacks and secure IoT systems; however, concept drift issues often occur\nin IoT data analytics, as IoT data is often dynamic data streams that change\nover time, causing model degradation and attack detection failure. This is\nbecause traditional data analytics models are static models that cannot adapt\nto data distribution changes. In this paper, we propose a Performance Weighted\nProbability Averaging Ensemble (PWPAE) framework for drift adaptive IoT anomaly\ndetection through IoT data stream analytics. Experiments on two public datasets\nshow the effectiveness of our proposed PWPAE method compared against\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted and to appear in IEEE GlobeCom 2021; Code is available at Github link: this https URL\n",
    "authors": [
      "Li Yang",
      "Dimitrios Michael Manias",
      "Abdallah Shami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.05013"
  },
  {
    "id": "arXiv:2109.05014",
    "title": "An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA",
    "abstract": "Knowledge-based visual question answering (VQA) involves answering questions\nthat require external knowledge not present in the image. Existing methods\nfirst retrieve knowledge from external resources, then reason over the selected\nknowledge, the input image, and question for answer prediction. However, this\ntwo-step approach could lead to mismatches that potentially limit the VQA\nperformance. For example, the retrieved knowledge might be noisy and irrelevant\nto the question, and the re-embedded knowledge features during reasoning might\ndeviate from their original meanings in the knowledge base (KB). To address\nthis challenge, we propose PICa, a simple yet effective method that Prompts\nGPT3 via the use of Image Captions, for knowledge-based VQA. Inspired by\nGPT-3's power in knowledge retrieval and question answering, instead of using\nstructured KBs as in previous work, we treat GPT-3 as an implicit and\nunstructured KB that can jointly acquire and process relevant knowledge.\nSpecifically, we first convert the image into captions (or tags) that GPT-3 can\nunderstand, then adapt GPT-3 to solve the VQA task in a few-shot manner by just\nproviding a few in-context VQA examples. We further boost performance by\ncarefully investigating: (i) what text formats best describe the image content,\nand (ii) how in-context examples can be better selected and used. PICa unlocks\nthe first use of GPT-3 for multimodal tasks. By using only 16 examples, PICa\nsurpasses the supervised state of the art by an absolute +8.6 points on the\nOK-VQA dataset. We also benchmark PICa on VQAv2, where PICa also shows a decent\nfew-shot performance.",
    "descriptor": "",
    "authors": [
      "Zhengyuan Yang",
      "Zhe Gan",
      "Jianfeng Wang",
      "Xiaowei Hu",
      "Yumao Lu",
      "Zicheng Liu",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05014"
  },
  {
    "id": "arXiv:2109.05016",
    "title": "Neural Machine Translation Quality and Post-Editing Performance",
    "abstract": "We test the natural expectation that using MT in professional translation\nsaves human processing time. The last such study was carried out by\nSanchez-Torron and Koehn (2016) with phrase-based MT, artificially reducing the\ntranslation quality. In contrast, we focus on neural MT (NMT) of high quality,\nwhich has become the state-of-the-art approach since then and also got adopted\nby most translation companies.\nThrough an experimental study involving over 30 professional translators for\nEnglish -> Czech translation, we examine the relationship between NMT\nperformance and post-editing time and quality. Across all models, we found that\nbetter MT systems indeed lead to fewer changes in the sentences in this\nindustry setting. The relation between system quality and post-editing time is\nhowever not straightforward and, contrary to the results on phrase-based MT,\nBLEU is definitely not a stable predictor of the time or final output quality.",
    "descriptor": "\nComments: 9 pages, 1 page appendix. To be presented at EMNLP2021\n",
    "authors": [
      "Vil\u00e9m Zouhar",
      "Ale\u0161 Tamchyna",
      "Martin Popel",
      "Ond\u0159ej Bojar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.05016"
  },
  {
    "id": "arXiv:2012.15135",
    "title": "Alphabets, rewriting trails and periodic representations in algebraic  bases",
    "abstract": "For $\\beta > 1$ a real algebraic integer ({\\it the base}), the finite\nalphabets $\\mathcal{A} \\subset \\mathbb{Z}$ which realize the identity\n$\\mathbb{Q}(\\beta) = {\\rm Per}_{\\mathcal{A}}(\\beta)$, where ${\\rm\nPer}_{\\mathcal{A}}(\\beta)$ is the set of complex numbers which are $(\\beta,\n\\mathcal{A})$-eventually periodic representations, are investigated. Comparing\nwith the greedy algorithm, minimal and natural alphabets are defined. The\nnatural alphabets are shown to be correlated to the asymptotics of the Pierce\nnumbers of the base $\\beta$ and Lehmer's problem. The notion of rewriting trail\nis introduced to construct intermediate alphabets associated with small\npolynomial values of the base. Consequences on the representations of\nneighbourhoods of the origin in $\\mathbb{Q}(\\beta)$, generalizing Schmidt's\ntheorem related to Pisot numbers, are investigated. Applications to Galois\nconjugation are given for convergent sequences of bases $\\gamma_s := \\gamma_{n,\nm_1 , \\ldots , m_s}$ such that $\\gamma_{s}^{-1}$ is the unique root in $(0,1)$\nof an almost Newman polynomial of the type $-1+x+x^n +x^{m_1}+\\ldots+ x^{m_s}$,\n$n \\geq 3$, $s \\geq 1$, $m_1 - n \\geq n-1$, $m_{q+1}-m_q \\geq n-1$ for all $q\n\\geq 1$. For $\\beta > 1$ a reciprocal algebraic integer close to one, the poles\nof modulus $< 1$ of the dynamical zeta function of the $\\beta$-shift\n$\\zeta_{\\beta}(z)$ are shown, under some assumptions, to be zeroes of the\nminimal polynomial of $\\beta$.",
    "descriptor": "\nComments: 17 pages, 7 figures, 29 references\n",
    "authors": [
      "Denys Dutykh",
      "Jean-Louis Verger-Gaugry"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2012.15135"
  },
  {
    "id": "arXiv:2109.04522",
    "title": "Asynchronous Iterations in Optimization: New Sequence Results and  Sharper Algorithmic Guarantees",
    "abstract": "We introduce novel convergence results for asynchronous iterations which\nappear in the analysis of parallel and distributed optimization algorithms. The\nresults are simple to apply and give explicit estimates for how the degree of\nasynchrony impacts the convergence rates of the iterates. Our results shorten,\nstreamline and strengthen existing convergence proofs for several asynchronous\noptimization methods, and allow us to establish convergence guarantees for\npopular algorithms that were thus far lacking a complete theoretical\nunderstanding. Specifically, we use our results to derive better iteration\ncomplexity bounds for proximal incremental aggregated gradient methods, to\nprovide less conservative analyses of the speedup conditions for asynchronous\nblock-coordinate implementations of Krasnoselskii-Mann iterations, and to\nquantify the convergence rates for totally asynchronous iterations under\nvarious assumptions on communication delays and update rates.",
    "descriptor": "\nComments: 44 pages, 1 Figure\n",
    "authors": [
      "Hamid Reza Feyzmahdavian",
      "Mikael Johansson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04522"
  },
  {
    "id": "arXiv:2109.04526",
    "title": "Ergodic Limits, Relaxations, and Geometric Properties of Random Walk  Node Embeddings",
    "abstract": "Random walk based node embedding algorithms learn vector representations of\nnodes by optimizing an objective function of node embedding vectors and\nskip-bigram statistics computed from random walks on the network. They have\nbeen applied to many supervised learning problems such as link prediction and\nnode classification and have demonstrated state-of-the-art performance. Yet,\ntheir properties remain poorly understood. This paper studies properties of\nrandom walk based node embeddings in the unsupervised setting of discovering\nhidden block structure in the network, i.e., learning node representations\nwhose cluster structure in Euclidean space reflects their adjacency structure\nwithin the network. We characterize the ergodic limits of the embedding\nobjective, its generalization, and related convex relaxations to derive\ncorresponding non-randomized versions of the node embedding objectives. We also\ncharacterize the optimal node embedding Grammians of the non-randomized\nobjectives for the expected graph of a two-community Stochastic Block Model\n(SBM). We prove that the solution Grammian has rank $1$ for a suitable nuclear\nnorm relaxation of the non-randomized objective. Comprehensive experimental\nresults on SBM random networks reveal that our non-randomized ergodic\nobjectives yield node embeddings whose distribution is Gaussian-like, centered\nat the node embeddings of the expected network within each community, and\nconcentrate in the linear degree-scaling regime as the number of nodes\nincreases.",
    "descriptor": "",
    "authors": [
      "Christy Lin",
      "Daniel Sussman",
      "Prakash Ishwar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04526"
  },
  {
    "id": "arXiv:2109.04544",
    "title": "Directional MCLP Analysis and Reconstruction for Spatial Speech  Communication",
    "abstract": "Spatial speech communication, i.e., the reconstruction of spoken signal along\nwith the relative speaker position in the enclosure (reverberation information)\nis considered in this paper. Directional, diffuse components and the source\nposition information are estimated at the transmitter, and perceptually\neffective reproduction is considered at the receiver. We consider spatially\ndistributed microphone arrays for signal acquisition, and node specific signal\nestimation, along with its direction of arrival (DoA) estimation. Short-time\nFourier transform (STFT) domain multi-channel linear prediction (MCLP) approach\nis used to model the diffuse component and relative acoustic transfer function\nis used to model the direct signal component. Distortion-less array response\nconstraint and the time-varying complex Gaussian source model are used in the\njoint estimation of source DoA and the constituent signal components,\nseparately at each node. The intersection between DoA directions at each node\nis used to compute the source position. Signal components computed at the node\nnearest to the estimated source position are taken as the signals for\ntransmission.\nAt the receiver, a four channel loud speaker (LS) setup is used for spatial\nreproduction, in which the source spatial image is reproduced relative to a\nchosen virtual listener position in the transmitter enclosure. Vector base\namplitude panning (VBAP) method is used for direct component reproduction using\nthe LS setup and the diffuse component is reproduced equally from all the loud\nspeakers after decorrelation. This scheme of spatial speech communication is\nshown to be effective and more natural for hands-free telecommunication,\nthrough either loudspeaker listening or binaural headphone listening with head\nrelated transfer function (HRTF) based presentation.",
    "descriptor": "\nComments: The manuscript is submitted as a full paper to IEEE/ACM Transactions on Audio, Speech and Language Processing\n",
    "authors": [
      "Srikanth Raj Chetupalli",
      "Thippur V. Sreenivas"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.04544"
  },
  {
    "id": "arXiv:2109.04561",
    "title": "Supervising the Decoder of Variational Autoencoders to Improve  Scientific Utility",
    "abstract": "Probabilistic generative models are attractive for scientific modeling\nbecause their inferred parameters can be used to generate hypotheses and design\nexperiments. This requires that the learned model provide an accurate\nrepresentation of the input data and yield a latent space that effectively\npredicts outcomes relevant to the scientific question. Supervised Variational\nAutoencoders (SVAEs) have previously been used for this purpose, where a\ncarefully designed decoder can be used as an interpretable generative model\nwhile the supervised objective ensures a predictive latent representation.\nUnfortunately, the supervised objective forces the encoder to learn a biased\napproximation to the generative posterior distribution, which renders the\ngenerative parameters unreliable when used in scientific models. This issue has\nremained undetected as reconstruction losses commonly used to evaluate model\nperformance do not detect bias in the encoder. We address this\npreviously-unreported issue by developing a second order supervision framework\n(SOS-VAE) that influences the decoder to induce a predictive latent\nrepresentation. This ensures that the associated encoder maintains a reliable\ngenerative interpretation. We extend this technique to allow the user to\ntrade-off some bias in the generative parameters for improved predictive\nperformance, acting as an intermediate option between SVAEs and our new\nSOS-VAE. We also use this methodology to address missing data issues that often\narise when combining recordings from multiple scientific experiments. We\ndemonstrate the effectiveness of these developments using synthetic data and\nelectrophysiological recordings with an emphasis on how our learned\nrepresentations can be used to design scientific experiments.",
    "descriptor": "",
    "authors": [
      "Liyun Tu",
      "Austin Talbot",
      "Neil Gallagher",
      "David Carlson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.04561"
  },
  {
    "id": "arXiv:2109.04615",
    "title": "Differential Privacy in Personalized Pricing with Nonparametric Demand  Models",
    "abstract": "In the recent decades, the advance of information technology and abundant\npersonal data facilitate the application of algorithmic personalized pricing.\nHowever, this leads to the growing concern of potential violation of privacy\ndue to adversarial attack. To address the privacy issue, this paper studies a\ndynamic personalized pricing problem with \\textit{unknown} nonparametric demand\nmodels under data privacy protection. Two concepts of data privacy, which have\nbeen widely applied in practices, are introduced: \\textit{central differential\nprivacy (CDP)} and \\textit{local differential privacy (LDP)}, which is proved\nto be stronger than CDP in many cases. We develop two algorithms which make\npricing decisions and learn the unknown demand on the fly, while satisfying the\nCDP and LDP gurantees respectively. In particular, for the algorithm with CDP\nguarantee, the regret is proved to be at most $\\tilde\nO(T^{(d+2)/(d+4)}+\\varepsilon^{-1}T^{d/(d+4)})$. Here, the parameter $T$\ndenotes the length of the time horizon, $d$ is the dimension of the\npersonalized information vector, and the key parameter $\\varepsilon>0$ measures\nthe strength of privacy (smaller $\\varepsilon$ indicates a stronger privacy\nprotection). On the other hand, for the algorithm with LDP guarantee, its\nregret is proved to be at most $\\tilde\nO(\\varepsilon^{-2/(d+2)}T^{(d+1)/(d+2)})$, which is near-optimal as we prove a\nlower bound of $\\Omega(\\varepsilon^{-2/(d+2)}T^{(d+1)/(d+2)})$ for any\nalgorithm with LDP guarantee.",
    "descriptor": "",
    "authors": [
      "Xi Chen",
      "Sentao Miao",
      "Yining Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04615"
  },
  {
    "id": "arXiv:2109.04686",
    "title": "DIRECT: A Differential Dynamic Programming Based Framework for  Trajectory Generation",
    "abstract": "This paper introduces a differential dynamic programming (DDP) based\nframework for polynomial trajectory generation for differentially flat systems.\nIn particular, instead of using a linear equation with increasing size to\nrepresent multiple polynomial segments as in literature, we take a new\nperspective from state-space representation such that the linear equation\nreduces to a finite horizon control system with a fixed state dimension and the\nrequired continuity conditions for consecutive polynomials are automatically\nsatisfied. Consequently, the constrained trajectory generation problem (both\nwith and without time optimization) can be converted to a discrete-time\nfinite-horizon optimal control problem with inequality constraints, which can\nbe approached by a recently developed interior-point DDP (IPDDP) algorithm.\nFurthermore, for unconstrained trajectory generation with preallocated time, we\nshow that this problem is indeed a linear-quadratic tracking (LQT) problem (DDP\nalgorithm with exact one iteration). All these algorithms enjoy linear\ncomplexity with respect to the number of segments. Both numerical comparisons\nwith state-of-the-art methods and physical experiments are presented to verify\nand validate the effectiveness of our theoretical findings. The implementation\ncode will be open-sourced,",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Kun Cao",
      "Muqing Cao",
      "Shenghai Yuan",
      "Lihua Xie"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04686"
  },
  {
    "id": "arXiv:2109.04757",
    "title": "Low-rank statistical finite elements for scalable model-data synthesis",
    "abstract": "Statistical learning additions to physically derived mathematical models are\ngaining traction in the literature. A recent approach has been to augment the\nunderlying physics of the governing equations with data driven Bayesian\nstatistical methodology. Coined statFEM, the method acknowledges a priori model\nmisspecification, by embedding stochastic forcing within the governing\nequations. Upon receipt of additional data, the posterior distribution of the\ndiscretised finite element solution is updated using classical Bayesian\nfiltering techniques. The resultant posterior jointly quantifies uncertainty\nassociated with the ubiquitous problem of model misspecification and the data\nintended to represent the true process of interest. Despite this appeal,\ncomputational scalability is a challenge to statFEM's application to\nhigh-dimensional problems typically experienced in physical and industrial\ncontexts. This article overcomes this hurdle by embedding a low-rank\napproximation of the underlying dense covariance matrix, obtained from the\nleading order modes of the full-rank alternative. Demonstrated on a series of\nreaction-diffusion problems of increasing dimension, using experimental and\nsimulated data, the method reconstructs the sparsely observed data-generating\nprocesses with minimal loss of information, in both posterior mean and the\nvariance, paving the way for further integration of physical and probabilistic\napproaches to complex systems.",
    "descriptor": "\nComments: 32 pages, 12 figures, submitted version\n",
    "authors": [
      "Connor Duffin",
      "Edward Cripps",
      "Thomas Stemler",
      "Mark Girolami"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04757"
  },
  {
    "id": "arXiv:2109.04758",
    "title": "Security analysis method for practical quantum key distribution with  arbitrary encoding schemes",
    "abstract": "Quantum key distribution (QKD) gradually has become a crucial element of\npractical secure communication. In different scenarios, the security analysis\nof genuine QKD systems is complicated. A universal secret key rate calculation\nmethod, used for realistic factors such as multiple degrees of freedom\nencoding, asymmetric protocol structures, equipment flaws, environmental noise,\nand so on, is still lacking. Based on the correlations of statistical data, we\npropose a security analysis method without restriction on encoding schemes.\nThis method makes a trade-off between applicability and accuracy, which can\neffectively analyze various existing QKD systems. We illustrate its ability by\nanalyzing source flaws and a high-dimensional asymmetric protocol. Results\nimply that our method can give tighter bounds than the\nGottesman-Lo-L\\\"utkenhaus-Preskill (GLLP) analysis and is beneficial to analyze\nprotocols with complex encoding structures. Our work has the potential to\nbecome a reference standard for the security analysis of practical QKD.",
    "descriptor": "",
    "authors": [
      "Zehong Chang",
      "Fumin Wang",
      "Xiaoli Wang",
      "Xiaofei Liu",
      "Rongqian Wu",
      "Yi lv",
      "Pei Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2109.04758"
  },
  {
    "id": "arXiv:2109.04760",
    "title": "ReconfigISP: Reconfigurable Camera Image Processing Pipeline",
    "abstract": "Image Signal Processor (ISP) is a crucial component in digital cameras that\ntransforms sensor signals into images for us to perceive and understand.\nExisting ISP designs always adopt a fixed architecture, e.g., several\nsequential modules connected in a rigid order. Such a fixed ISP architecture\nmay be suboptimal for real-world applications, where camera sensors, scenes and\ntasks are diverse. In this study, we propose a novel Reconfigurable ISP\n(ReconfigISP) whose architecture and parameters can be automatically tailored\nto specific data and tasks. In particular, we implement several ISP modules,\nand enable backpropagation for each module by training a differentiable proxy,\nhence allowing us to leverage the popular differentiable neural architecture\nsearch and effectively search for the optimal ISP architecture. A proxy tuning\nmechanism is adopted to maintain the accuracy of proxy networks in all cases.\nExtensive experiments conducted on image restoration and object detection, with\ndifferent sensors, light conditions and efficiency constraints, validate the\neffectiveness of ReconfigISP. Only hundreds of parameters need tuning for every\ntask.",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Ke Yu",
      "Zexian Li",
      "Yue Peng",
      "Chen Change Loy",
      "Jinwei Gu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04760"
  },
  {
    "id": "arXiv:2109.04792",
    "title": "Timing constraints imposed by classical digital control systems on  photonic implementations of measurement-based quantum computing",
    "abstract": "Most of the architectural research on photonic implementations of\nmeasurement-based quantum computing (MBQC) has focused on the quantum resources\ninvolved in the problem with the implicit assumption that these will provide\nthe main constraints on system scaling. However, the `flying-qubit'\narchitecture of photonic MBQC requires specific timing constraints that need to\nbe met by the classical control system. This classical control includes, for\nexample: the amplification of the signals from single-photon detectors to\nvoltage levels compatible with digital systems; the implementation of a control\nsystem which converts measurement outcomes into basis settings for measuring\nsubsequent cluster qubits, in accordance with the quantum algorithm being\nimplemented; and the digital-to-analog converter (DAC) and amplifier systems\nrequired to set these measurement bases using a fast phase modulator. In this\npaper, we analyze the digital system needed to implement arbitrary one-qubit\nrotations and controlled-NOT (CNOT) gates in discrete-variable photonic MBQC,\nin the presence of an ideal cluster state generator, with the main aim of\nunderstanding the timing constraints imposed by the digital logic on the analog\nsystem and quantum hardware. We use static timing analysis of a Xilinx FPGA (7\nseries) to provide a practical upper bound on the speed at which the adaptive\nmeasurement processing can be performed, in turn constraining the photonic\nclock rate of the system. Our work points to the importance of co-designing the\nclassical control system in tandem with the quantum system in order to meet the\nchallenging specifications of a photonic quantum computer.",
    "descriptor": "\nComments: 21 pages, 11 figures. Comments welcome! This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "John R. Scott",
      "Krishna C. Balram"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2109.04792"
  },
  {
    "id": "arXiv:2109.04839",
    "title": "Kahler toric manifolds from dually flat spaces",
    "abstract": "We present a correspondence between real analytic K\\\"{a}hler toric manifolds\nand dually flat spaces, similar to Delzant correspondence in symplectic\ngeometry. This correspondence gives rise to a lifting procedure: if $f:M\\to M'$\nis an affine isometric map between dually flat spaces and if $N$ and $N'$ are\nK\\\"{a}hler toric manifolds associated to $M$ and $M'$, respectively, then there\nis an equivariant K\\\"{a}hler immersion $N\\to N'$. For example, we show that the\nVeronese and Segre embeddings are lifts of inclusion maps between appropriate\nstatistical manifolds. We also discuss applications to Quantum Mechanics.",
    "descriptor": "",
    "authors": [
      "Mathieu Molitor"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)",
      "Symplectic Geometry (math.SG)"
    ],
    "url": "https://arxiv.org/abs/2109.04839"
  },
  {
    "id": "arXiv:2109.04850",
    "title": "Correlation measures of binary sequences derived from Euler quotients",
    "abstract": "Fermat-Euler quotients arose from the study of the first case of Fermat's\nLast Theorem, and have numerous applications in number theory. Recently they\nwere studied from the cryptographic aspects by constructing many pseudorandom\nbinary sequences, whose linear complexities and trace representations were\ncalculated. In this work, we further study their correlation measures by using\nthe approach based on Dirichlet characters, Ramanujan sums and Gauss sums. Our\nresults show that the $4$-order correlation measures of these sequences are\nvery large. Therefore they may not be suggested for cryptography.",
    "descriptor": "",
    "authors": [
      "Huaning Liu",
      "Zhixiong Chen",
      "Chenhuang Wu"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.04850"
  },
  {
    "id": "arXiv:2109.04861",
    "title": "GPS-Denied Navigation Using Low-Cost Inertial Sensors and Recurrent  Neural Networks",
    "abstract": "Autonomous missions of drones require continuous and reliable estimates for\nthe drone's attitude, velocity, and position. Traditionally, these states are\nestimated by applying Extended Kalman Filter (EKF) to Accelerometer, Gyroscope,\nBarometer, Magnetometer, and GPS measurements. When the GPS signal is lost,\nposition and velocity estimates deteriorate quickly, especially when using\nlow-cost inertial sensors. This paper proposes an estimation method that uses a\nRecurrent Neural Network (RNN) to allow reliable estimation of a drone's\nposition and velocity in the absence of GPS signal. The RNN is trained on a\npublic dataset collected using Pixhawk. This low-cost commercial autopilot logs\nthe raw sensor measurements (network inputs) and corresponding EKF estimates\n(ground truth outputs). The dataset is comprised of 548 different flight logs\nwith flight durations ranging from 4 to 32 minutes. For training, 465 flights\nare used, totaling 45 hours. The remaining 83 flights totaling 8 hours are held\nout for validation. Error in a single flight is taken to be the maximum\nabsolute difference in 3D position (MPE) between the RNN predictions (without\nGPS) and the ground truth (EKF with GPS). On the validation set, the median MPE\nis 35 meters. MPE values as low as 2.7 meters in a 5-minutes flight could be\nachieved using the proposed method. The MPE in 90% of the validation flights is\nbounded below 166 meters. The network was experimentally tested and worked in\nreal-time.",
    "descriptor": "\nComments: 17 pages, 39 figures\n",
    "authors": [
      "Ahmed AbdulMajuid",
      "Osama Mohamady",
      "Mohannad Draz",
      "Gamal El-bayoumi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04861"
  },
  {
    "id": "arXiv:2109.04875",
    "title": "Neural Networks for Latent Budget Analysis of Compositional Data",
    "abstract": "Compositional data are non-negative data collected in a rectangular matrix\nwith a constant row sum. Due to the non-negativity the focus is on conditional\nproportions that add up to 1 for each row. A row of conditional proportions is\ncalled an observed budget. Latent budget analysis (LBA) assumes a mixture of\nlatent budgets that explains the observed budgets. LBA is usually fitted to a\ncontingency table, where the rows are levels of one or more explanatory\nvariables and the columns the levels of a response variable. In prospective\nstudies, there is only knowledge about the explanatory variables of individuals\nand interest goes out to predicting the response variable. Thus, a form of LBA\nis needed that has the functionality of prediction. Previous studies proposed a\nconstrained neural network (NN) extension of LBA that was hampered by an\nunsatisfying prediction ability. Here we propose LBA-NN, a feed forward NN\nmodel that yields a similar interpretation to LBA but equips LBA with a better\nability of prediction. A stable and plausible interpretation of LBA-NN is\nobtained through the use of importance plots and table, that show the relative\nimportance of all explanatory variables on the response variable. An LBA-NN-K-\nmeans approach that applies K-means clustering on the importance table is used\nto produce K clusters that are comparable to K latent budgets in LBA. Here we\nprovide different experiments where LBA-NN is implemented and compared with\nLBA. In our analysis, LBA-NN outperforms LBA in prediction in terms of\naccuracy, specificity, recall and mean square error. We provide open-source\nsoftware at GitHub.",
    "descriptor": "",
    "authors": [
      "Zhenwei Yang",
      "Ayoub Bagheri",
      "P.G.M van der Heijden"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.04875"
  },
  {
    "id": "arXiv:2109.04883",
    "title": "Resolving gas bubbles ascending in liquid metal from low-SNR neutron  radiography images",
    "abstract": "We demonstrate a new image processing methodology for resolving gas bubbles\ntravelling through liquid metal from dynamic neutron radiography images with\nintrinsically low signal-to-noise ratio. Image pre-processing, denoising and\nbubble segmentation are described in detail, with practical recommendations.\nExperimental validation is presented - stationary and moving reference bodies\nwith neutron-transparent cavities are radiographed with imaging conditions\nsimilar to the cases with bubbles in liquid metal. The new methods are applied\nto our experimental data from previous and recent imaging campaigns, and the\nperformance of the methods proposed in this paper is compared against our\npreviously developed methods. Significant improvements are observed as well as\nthe capacity to reliably extract physically meaningful information from\nmeasurements performed under highly adverse imaging conditions. The showcased\nimage processing solution and separate elements thereof are readily extendable\nbeyond the present application, and have been made open-source.",
    "descriptor": "",
    "authors": [
      "Mihails Birjukovs",
      "Pavel Trtik",
      "Anders Kaestner",
      "Jan Hovind",
      "Martins Klevs",
      "Knud Thomsen",
      "Andris Jakovics"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04883"
  },
  {
    "id": "arXiv:2109.04886",
    "title": "Proceedings 18th International Conference on Quantum Physics and Logic",
    "abstract": "This volume contains the proceedings of the 18th International Conference on\nQuantum Physics and Logic (QPL 2021), which was held June 7-11, 2021 at the\nUniversity of Gdansk and online. QPL is an annual conference that brings\ntogether researchers working on mathematical foundations of quantum physics,\nquantum computing, and related areas, with a focus on structural perspectives\nand the use of logical tools, ordered algebraic and category-theoretic\nstructures, formal languages, semantical methods, and other computer science\ntechniques applied to the study of physical behaviour in general.",
    "descriptor": "",
    "authors": [
      "Chris Heunen",
      "Miriam Backens"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.04886"
  },
  {
    "id": "arXiv:2109.04894",
    "title": "Large-vocabulary Audio-visual Speech Recognition in Noisy Environments",
    "abstract": "Audio-visual speech recognition (AVSR) can effectively and significantly\nimprove the recognition rates of small-vocabulary systems, compared to their\naudio-only counterparts. For large-vocabulary systems, however, there are still\nmany difficulties, such as unsatisfactory video recognition accuracies, that\nmake it hard to improve over audio-only baselines. In this paper, we\nspecifically consider such scenarios, focusing on the large-vocabulary task of\nthe LRS2 database, where audio-only performance is far superior to video-only\naccuracies, making this an interesting and challenging setup for multi-modal\nintegration.\nTo address the inherent difficulties, we propose a new fusion strategy: a\nrecurrent integration network is trained to fuse the state posteriors of\nmultiple single-modality models, guided by a set of model-based and\nsignal-based stream reliability measures. During decoding, this network is used\nfor stream integration within a hybrid recognizer, where it can thus cope with\nthe time-variant reliability and information content of its multiple feature\ninputs.\nWe compare the results with end-to-end AVSR systems as well as with\ncompetitive hybrid baseline models, finding that the new fusion strategy shows\nsuperior results, on average even outperforming oracle dynamic stream\nweighting, which has so far marked the -- realistically unachievable -- upper\nbound for standard stream weighting. Even though the pure lipreading\nperformance is low, audio-visual integration is helpful under all -- clean,\nnoisy, and reverberant -- conditions. On average, the new system achieves a\nrelative word error rate reduction of 42.18\\% compared to the audio-only model,\npointing at a high effectiveness of the proposed integration approach.",
    "descriptor": "",
    "authors": [
      "Wentao Yu",
      "Steffen Zeiler",
      "Dorothea Kolossa"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.04894"
  },
  {
    "id": "arXiv:2109.04913",
    "title": "Adjoint Differentiation for generic matrix functions",
    "abstract": "We derive a formula for the adjoint $\\overline{A}$ of a square-matrix\noperation of the form $C=f(A)$, where $f$ is holomorphic in the neighborhood of\neach eigenvalue. We then apply the formula to derive closed-form expressions in\nparticular cases of interest such as the case when we have a spectral\ndecomposition $A=UDU^{-1}$, the spectrum cut-off $C=A_+$ and the Nearest\nCorrelation Matrix routine. Finally, we explain how to simplify the computation\nof adjoints for regularized linear regression coefficients.",
    "descriptor": "",
    "authors": [
      "Andrei Goloubentsev",
      "Dmitri Goloubentsev",
      "Evgeny Lakshtanov"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Symbolic Computation (cs.SC)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2109.04913"
  },
  {
    "id": "arXiv:2109.04916",
    "title": "Unsupervised classification of simulated magnetospheric regions",
    "abstract": "In magnetospheric missions, burst mode data sampling should be triggered in\nthe presence of processes of scientific or operational interest. We present an\nunsupervised classification method for magnetospheric regions, that could\nconstitute the first-step of a multi-step method for the automatic\nidentification of magnetospheric processes of interest. Our method is based on\nSelf Organizing Maps (SOMs), and we test it preliminarily on data points from\nglobal magnetospheric simulations obtained with the OpenGGCM-CTIM-RCM code. The\ndimensionality of the data is reduced with Principal Component Analysis before\nclassification. The classification relies exclusively on local plasma\nproperties at the selected data points, without information on their\nneighborhood or on their temporal evolution. We classify the SOM nodes into an\nautomatically selected number of classes, and we obtain clusters that map to\nwell defined magnetospheric regions. We validate our classification results by\nplotting the classified data in the simulated space and by comparing with\nK-means classification. For the sake of result interpretability, we examine the\nSOM feature maps (magnetospheric variables are called features in the context\nof classification), and we use them to unlock information on the clusters. We\nrepeat the classification experiments using different sets of features, we\nquantitatively compare different classification results, and we obtain insights\non which magnetospheric variables make more effective features for unsupervised\nclassification.",
    "descriptor": "",
    "authors": [
      "Maria Elena Innocenti",
      "Jorge Amaya",
      "Joachim Raeder",
      "Romain Dupuis",
      "Banafsheh Ferdousi",
      "Giovanni Lapenta"
    ],
    "subjectives": [
      "Space Physics (physics.space-ph)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.04916"
  },
  {
    "id": "arXiv:2109.04940",
    "title": "Evaluating Policy Implications on the Restrictiveness of Flow-based  Market Coupling with High Shares of Intermittent Generation: A Case Study for  Central Western Europe",
    "abstract": "The current stage in the evolution of the European internal energy market for\nelectricity is defined by the transformation towards a renewable energy system.\nThe Clean Energy Package aims to ensure that methods for capacity allocation\nand congestion management, that are at the center of the European internal\nmarket for electricity, align with this transformation.\nFlow-based market coupling, the preferred method for capacity allocation, is\nfirst and foremost a formal process to allocate exchange capacities to the\nmarkets. However, the process also allows for many considerations of the\ninvolved parties that impact the resulting capacities. As part of the Clear\nEnergy Package, the regulatory body enacted their ambition to increase exchange\ncapacities by enforcing transmission system operators to allocate a minimum\nmargin of physical line capacity with the goal of providing a higher level of\ncompetition and better integration of renewable energy sources. This study\ninvestigates this and other policy relevant consideration of flow-based market\ncoupling.\nThe model results quantify the trade-off between permissive capacity\nallocation and increased congestion management. For high shares of intermittent\nrenewable generation, less constrained exchange capacities are favorable,\nhowever also highlight the importance of the markets ability to integrate high\nshares of intermittent generation. apacities are favourable, however also\nhighlight the importance of the markets ability to integrate high shares of\nintermittent generation.",
    "descriptor": "",
    "authors": [
      "Richard Weinhold"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04940"
  },
  {
    "id": "arXiv:2109.04941",
    "title": "Best-Arm Identification in Correlated Multi-Armed Bandits",
    "abstract": "In this paper we consider the problem of best-arm identification in\nmulti-armed bandits in the fixed confidence setting, where the goal is to\nidentify, with probability $1-\\delta$ for some $\\delta>0$, the arm with the\nhighest mean reward in minimum possible samples from the set of arms\n$\\mathcal{K}$. Most existing best-arm identification algorithms and analyses\noperate under the assumption that the rewards corresponding to different arms\nare independent of each other. We propose a novel correlated bandit framework\nthat captures domain knowledge about correlation between arms in the form of\nupper bounds on expected conditional reward of an arm, given a reward\nrealization from another arm. Our proposed algorithm C-LUCB, which generalizes\nthe LUCB algorithm utilizes this partial knowledge of correlations to sharply\nreduce the sample complexity of best-arm identification. More interestingly, we\nshow that the total samples obtained by C-LUCB are of the form\n$\\mathcal{O}\\left(\\sum_{k \\in \\mathcal{C}}\n\\log\\left(\\frac{1}{\\delta}\\right)\\right)$ as opposed to the typical\n$\\mathcal{O}\\left(\\sum_{k \\in \\mathcal{K}}\n\\log\\left(\\frac{1}{\\delta}\\right)\\right)$ samples required in the independent\nreward setting. The improvement comes, as the $\\mathcal{O}(\\log(1/\\delta))$\nterm is summed only for the set of competitive arms $\\mathcal{C}$, which is a\nsubset of the original set of arms $\\mathcal{K}$. The size of the set\n$\\mathcal{C}$, depending on the problem setting, can be as small as $2$, and\nhence using C-LUCB in the correlated bandits setting can lead to significant\nperformance improvements. Our theoretical findings are supported by experiments\non the Movielens and Goodreads recommendation datasets.",
    "descriptor": "",
    "authors": [
      "Samarth Gupta",
      "Gauri Joshi",
      "Osman Ya\u011fan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04941"
  },
  {
    "id": "arXiv:2109.04960",
    "title": "Automatic Displacement and Vibration Measurement in Laboratory  Experiments with A Deep Learning Method",
    "abstract": "This paper proposes a pipeline to automatically track and measure\ndisplacement and vibration of structural specimens during laboratory\nexperiments. The latest Mask Regional Convolutional Neural Network (Mask R-CNN)\ncan locate the targets and monitor their movement from videos recorded by a\nstationary camera. To improve precision and remove the noise, techniques such\nas Scale-invariant Feature Transform (SIFT) and various filters for signal\nprocessing are included. Experiments on three small-scale reinforced concrete\nbeams and a shaking table test are utilized to verify the proposed method.\nResults show that the proposed deep learning method can achieve the goal to\nautomatically and precisely measure the motion of tested structural members\nduring laboratory experiments.",
    "descriptor": "",
    "authors": [
      "Yongsheng Bai",
      "Ramzi M. Abduallah",
      "Halil Sezen",
      "Alper Yilmaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04960"
  },
  {
    "id": "arXiv:2109.04970",
    "title": "View Blind-spot as Inpainting: Self-Supervised Denoising with Mask  Guided Residual Convolution",
    "abstract": "In recent years, self-supervised denoising methods have shown impressive\nperformance, which circumvent painstaking collection procedure of noisy-clean\nimage pairs in supervised denoising methods and boost denoising applicability\nin real world. One of well-known self-supervised denoising strategies is the\nblind-spot training scheme. However, a few works attempt to improve blind-spot\nbased self-denoiser in the aspect of network architecture. In this paper, we\ntake an intuitive view of blind-spot strategy and consider its process of using\nneighbor pixels to predict manipulated pixels as an inpainting process.\nTherefore, we propose a novel Mask Guided Residual Convolution (MGRConv) into\ncommon convolutional neural networks, e.g. U-Net, to promote blind-spot based\ndenoising. Our MGRConv can be regarded as soft partial convolution and find a\ntrade-off among partial convolution, learnable attention maps, and gated\nconvolution. It enables dynamic mask learning with appropriate mask constrain.\nDifferent from partial convolution and gated convolution, it provides moderate\nfreedom for network learning. It also avoids leveraging external learnable\nparameters for mask activation, unlike learnable attention maps. The\nexperiments show that our proposed plug-and-play MGRConv can assist blind-spot\nbased denoising network to reach promising results on both existing\nsingle-image based and dataset-based methods.",
    "descriptor": "",
    "authors": [
      "Yuhongze Zhou",
      "Liguang Zhou",
      "Tin Lun Lam",
      "Yangsheng Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04970"
  },
  {
    "id": "arXiv:2109.04976",
    "title": "Optimal bounds for bit-sizes of stationary distributions in finite  Markov chains",
    "abstract": "An irreducible stochastic matrix with rational entries has a stationary\ndistribution given by a vector of rational numbers. We give an upper bound on\nthe lowest common denominator of the entries of this vector. Bounds of this\nkind are used to study the complexity of algorithms for solving stochastic mean\npayoff games. They are usually derived using the Hadamard inequality, but this\nleads to suboptimal results. We replace the Hadamard inequality with the Markov\nchain tree formula in order to obtain optimal bounds. We also adapt our\napproach to obtain bounds on the absorption probabilities of finite Markov\nchains and on the gains and bias vectors of Markov chains with rewards.",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Mateusz Skomra"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computer Science and Game Theory (cs.GT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.04976"
  },
  {
    "id": "arXiv:2109.04985",
    "title": "Consensus dynamics on temporal hypergraphs",
    "abstract": "We investigate consensus dynamics on temporal hypergraphs that encode network\nsystems with time-dependent, multi-way interactions. We compare this dynamics\nwith that on appropriate projections of this higher-order network\nrepresentation that flatten the temporal, the multi-way component, or both. For\nlinear average consensus dynamics, we find that the convergence of a randomly\nswitching time-varying system with multi-way interactions is slower than the\nconvergence of the corresponding system with pairwise interactions, which in\nturn exhibits a slower convergence rate than a consensus dynamics on the\ncorresponding static network. We then consider a nonlinear consensus dynamics\nmodel in the temporal setting. Here we find that in addition to an effect on\nthe convergence speed, the final consensus value of the temporal system can\ndiffer strongly from the consensus on the aggregated, static hypergraph. In\nparticular we observe a first-mover advantage in the consensus formation\nprocess: If there is a local majority opinion in the hyperedges that are active\nearly on, the majority in these first-mover groups has a higher influence on\nthe final consensus value - a behaviour that is not observable in this form in\nprojections of the temporal hypergraph.",
    "descriptor": "",
    "authors": [
      "Leonie Neuh\u00e4user",
      "Renaud Lambiotte",
      "Michael T. Schaub"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.04985"
  },
  {
    "id": "arXiv:2109.05019",
    "title": "Spike2Vec: An Efficient and Scalable Embedding Approach for COVID-19  Spike Sequences",
    "abstract": "With the rapid global spread of COVID-19, more and more data related to this\nvirus is becoming available, including genomic sequence data. The total number\nof genomic sequences that are publicly available on platforms such as GISAID is\ncurrently several million, and is increasing with every day. The availability\nof such \\textit{Big Data} creates a new opportunity for researchers to study\nthis virus in detail. This is particularly important with all of the dynamics\nof the COVID-19 variants which emerge and circulate. This rich data source will\ngive us insights on the best ways to perform genomic surveillance for this and\nfuture pandemic threats, with the ultimate goal of mitigating or eliminating\nsuch threats. Analyzing and processing the several million genomic sequences is\na challenging task. Although traditional methods for sequence classification\nare proven to be effective, they are not designed to deal with these specific\ntypes of genomic sequences. Moreover, most of the existing methods also face\nthe issue of scalability. Previous studies which were tailored to coronavirus\ngenomic data proposed to use spike sequences (corresponding to a subsequence of\nthe genome), rather than using the complete genomic sequence, to perform\ndifferent machine learning (ML) tasks such as classification and clustering.\nHowever, those methods suffer from scalability issues. In this paper, we\npropose an approach called Spike2Vec, an efficient and scalable feature vector\nrepresentation for each spike sequence that can be used for downstream ML\ntasks. Through experiments, we show that Spike2Vec is not only scalable on\nseveral million spike sequences, but also outperforms the baseline models in\nterms of prediction accuracy, F1-score, etc.",
    "descriptor": "",
    "authors": [
      "Sarwan Ali; Murray Patterson"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05019"
  },
  {
    "id": "arXiv:1809.02254",
    "title": "Quantum algorithms and approximating polynomials for composed functions  with shared inputs",
    "abstract": "Comments: v2: 31 pages; 1 figure. This update includes an additional result on lower bounds for AC$^0 \\circ \\oplus$ computing the Inner Product function on average. v3: Minor changes. Accepted to Quantum",
    "descriptor": "\nComments: v2: 31 pages; 1 figure. This update includes an additional result on lower bounds for AC$^0 \\circ \\oplus$ computing the Inner Product function on average. v3: Minor changes. Accepted to Quantum\n",
    "authors": [
      "Mark Bun",
      "Robin Kothari",
      "Justin Thaler"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1809.02254"
  },
  {
    "id": "arXiv:1902.04561",
    "title": "Mitigating Traffic Remapping Attacks in Autonomous Multi-hop Wireless  Networks",
    "abstract": "Comments: 16 pages, 11 figures, 3 tables, journal version of conference paper arXiv:1704.04053",
    "descriptor": "\nComments: 16 pages, 11 figures, 3 tables, journal version of conference paper arXiv:1704.04053\n",
    "authors": [
      "Jerzy Konorski",
      "Szymon Szott"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/1902.04561"
  },
  {
    "id": "arXiv:1909.03950",
    "title": "On the Non-Adaptive Zero-Error Capacity of the Discrete Memoryless  Two-Way Channel",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Yujie Gu",
      "Ofer Shayevitz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1909.03950"
  },
  {
    "id": "arXiv:1910.06002",
    "title": "Optimal Clustering from Noisy Binary Feedback",
    "abstract": "Optimal Clustering from Noisy Binary Feedback",
    "descriptor": "",
    "authors": [
      "Kaito Ariu",
      "Jungseul Ok",
      "Alexandre Proutiere",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.06002"
  },
  {
    "id": "arXiv:1910.08607",
    "title": "Exorcising Spectres with Secure Compilers",
    "abstract": "Exorcising Spectres with Secure Compilers",
    "descriptor": "",
    "authors": [
      "Marco Patrignani",
      "Marco Guarnieri"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1910.08607"
  },
  {
    "id": "arXiv:1911.00804",
    "title": "Generalizing to unseen domains via distribution matching",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Isabela Albuquerque",
      "Jo\u00e3o Monteiro",
      "Mohammad Darvishi",
      "Tiago H. Falk",
      "Ioannis Mitliagkas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.00804"
  },
  {
    "id": "arXiv:1911.02499",
    "title": "Dimensional Emotion Detection from Categorical Emotion",
    "abstract": "Comments: 9 pages, 2 figure",
    "descriptor": "\nComments: 9 pages, 2 figure\n",
    "authors": [
      "Sungjoon Park",
      "Jiseon Kim",
      "Seonghyeon Ye",
      "Jaeyeol Jeon",
      "Hee Young Park",
      "Alice Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/1911.02499"
  },
  {
    "id": "arXiv:1911.03959",
    "title": "Multi-Armed Bandits with Correlated Arms",
    "abstract": "Comments: A special case of the model studied in this paper is presented in arXiv:1808.05904",
    "descriptor": "\nComments: A special case of the model studied in this paper is presented in arXiv:1808.05904\n",
    "authors": [
      "Samarth Gupta",
      "Shreyas Chaudhari",
      "Gauri Joshi",
      "Osman Ya\u011fan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.03959"
  },
  {
    "id": "arXiv:1912.04265",
    "title": "In Defense of Uniform Convergence: Generalization via derandomization  with an application to interpolating predictors",
    "abstract": "Comments: 14 pages before references and appendices. 23 pages total. Includes a correction to Lemma 5.3 and Theorem 5.4, and their proofs",
    "descriptor": "\nComments: 14 pages before references and appendices. 23 pages total. Includes a correction to Lemma 5.3 and Theorem 5.4, and their proofs\n",
    "authors": [
      "Jeffrey Negrea",
      "Gintare Karolina Dziugaite",
      "Daniel M. Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.04265"
  },
  {
    "id": "arXiv:2001.03174",
    "title": "Towards Secure Over-The-Air Computation",
    "abstract": "Towards Secure Over-The-Air Computation",
    "descriptor": "",
    "authors": [
      "Matthias Frey",
      "Igor Bjelakovi\u0107",
      "S\u0142awomir Sta\u0144czak"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2001.03174"
  },
  {
    "id": "arXiv:2001.09532",
    "title": "Learning the Hypotheses Space from data: Learning Space and U-curve  Property",
    "abstract": "Comments: This paper has been withdrawn by the authors. This paper has been superseded by arXiv:2109.03866 (merged from arXiv:2001.09532 and arXiv:2001.11578)",
    "descriptor": "\nComments: This paper has been withdrawn by the authors. This paper has been superseded by arXiv:2109.03866 (merged from arXiv:2001.09532 and arXiv:2001.11578)\n",
    "authors": [
      "Diego Marcondes",
      "Adilson Simonis",
      "Junior Barrera"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.09532"
  },
  {
    "id": "arXiv:2001.11107",
    "title": "Hamiltonian neural networks for solving equations of motion",
    "abstract": "Hamiltonian neural networks for solving equations of motion",
    "descriptor": "",
    "authors": [
      "Marios Mattheakis",
      "David Sondak",
      "Pavlos Protopapas"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.11107"
  },
  {
    "id": "arXiv:2001.11578",
    "title": "Learning the Hypotheses Space from data Part II: Convergence and  Feasibility",
    "abstract": "Comments: This paper has been withdrawn by the authors. This paper has been superseded by arXiv:2109.03866 (merged from arXiv:2001.09532 and arXiv:2001.11578)",
    "descriptor": "\nComments: This paper has been withdrawn by the authors. This paper has been superseded by arXiv:2109.03866 (merged from arXiv:2001.09532 and arXiv:2001.11578)\n",
    "authors": [
      "Diego Marcondes",
      "Adilson Simonis",
      "Junior Barrera"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.11578"
  },
  {
    "id": "arXiv:2002.05809",
    "title": "Variational Conditional Dependence Hidden Markov Models for  Skeleton-Based Action Recognition",
    "abstract": "Comments: International Symposium on Visual Computing (ISVC) 2021",
    "descriptor": "\nComments: International Symposium on Visual Computing (ISVC) 2021\n",
    "authors": [
      "Konstantinos P. Panousis",
      "Sotirios Chatzis",
      "Sergios Theodoridis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.05809"
  },
  {
    "id": "arXiv:2003.13641",
    "title": "Feedback Edge Sets in Temporal Graphs",
    "abstract": "Feedback Edge Sets in Temporal Graphs",
    "descriptor": "",
    "authors": [
      "Roman Haag",
      "Hendrik Molter",
      "Rolf Niedermeier",
      "Malte Renken"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2003.13641"
  },
  {
    "id": "arXiv:2004.14379",
    "title": "On a nonlocal Cahn-Hilliard model permitting sharp interfaces",
    "abstract": "On a nonlocal Cahn-Hilliard model permitting sharp interfaces",
    "descriptor": "",
    "authors": [
      "Olena Burkovska",
      "Max Gunzburger"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2004.14379"
  },
  {
    "id": "arXiv:2004.14876",
    "title": "Analyzing the Surprising Variability in Word Embedding Stability Across  Languages",
    "abstract": "Comments: Accepted to EMNLP 2021",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Laura Burdick",
      "Jonathan K. Kummerfeld",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2004.14876"
  },
  {
    "id": "arXiv:2005.00218",
    "title": "Differentially Private Federated Learning with Laplacian Smoothing",
    "abstract": "Differentially Private Federated Learning with Laplacian Smoothing",
    "descriptor": "",
    "authors": [
      "Zhicong Liang",
      "Bao Wang",
      "Quanquan Gu",
      "Stanley Osher",
      "Yuan Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.00218"
  },
  {
    "id": "arXiv:2005.00782",
    "title": "RICA: Evaluating Robust Inference Capabilities Based on Commonsense  Axioms",
    "abstract": "Comments: Accepted in EMNLP 2021 main conference. 20 pages, 8 figures",
    "descriptor": "\nComments: Accepted in EMNLP 2021 main conference. 20 pages, 8 figures\n",
    "authors": [
      "Pei Zhou",
      "Rahul Khanna",
      "Seyeon Lee",
      "Bill Yuchen Lin",
      "Daniel Ho",
      "Jay Pujara",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2005.00782"
  },
  {
    "id": "arXiv:2006.00469",
    "title": "Contextuality in entanglement-assisted one-shot classical communication",
    "abstract": "Comments: 23 pages, 4 figures, improved presentation, moved some proofs to appendices, some discussion added, comments still welcome!",
    "descriptor": "\nComments: 23 pages, 4 figures, improved presentation, moved some proofs to appendices, some discussion added, comments still welcome!\n",
    "authors": [
      "Shiv Akshar Yadavalli",
      "Ravi Kunjwal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2006.00469"
  },
  {
    "id": "arXiv:2006.03495",
    "title": "A conditional one-output likelihood formulation for multitask Gaussian  processes",
    "abstract": "Comments: We have discovered major errors in the paper",
    "descriptor": "\nComments: We have discovered major errors in the paper\n",
    "authors": [
      "\u00d3scar Garc\u00eda-Hinde",
      "Vanessa G\u00f3mez-Verdejo",
      "Manel Mart\u00ednez-Ram\u00f3n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.03495"
  },
  {
    "id": "arXiv:2006.05500",
    "title": "Foreseeing the Benefits of Incidental Supervision",
    "abstract": "Foreseeing the Benefits of Incidental Supervision",
    "descriptor": "",
    "authors": [
      "Hangfeng He",
      "Mingyuan Zhang",
      "Qiang Ning",
      "Dan Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05500"
  },
  {
    "id": "arXiv:2006.07265",
    "title": "Towards control of opinion diversity by introducing zealots into a  polarised social group",
    "abstract": "Comments: 12 pages, 4 figures",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Antoine Vendeville",
      "Benjamin Guedj",
      "Shi Zhou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.07265"
  },
  {
    "id": "arXiv:2006.08152",
    "title": "ForMIC: Foraging via Multiagent RL with Implicit Communication",
    "abstract": "Comments: Submitted to IEEE Robotics and Automation Letters (RA-L) on September 10, 2021",
    "descriptor": "\nComments: Submitted to IEEE Robotics and Automation Letters (RA-L) on September 10, 2021\n",
    "authors": [
      "Samuel Shaw",
      "Emerson Wenzel",
      "Alexis Walker",
      "Guillaume Sartoretti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2006.08152"
  },
  {
    "id": "arXiv:2006.16144",
    "title": "Estimates on the generalization error of Physics Informed Neural  Networks (PINNs) for approximating PDEs",
    "abstract": "Estimates on the generalization error of Physics Informed Neural  Networks (PINNs) for approximating PDEs",
    "descriptor": "",
    "authors": [
      "Siddhartha Mishra",
      "Roberto Molinaro"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2006.16144"
  },
  {
    "id": "arXiv:2007.01002",
    "title": "DeepOPF: A Feasibility-Optimized Deep Neural Network Approach for AC  Optimal Power Flow Problems",
    "abstract": "Comments: 12 pages, 2 figures",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Xiang Pan",
      "Minghua Chen",
      "Tianyu Zhao",
      "Steven H. Low"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.01002"
  },
  {
    "id": "arXiv:2007.14556",
    "title": "Accurate Lung Nodules Segmentation with Detailed Representation Transfer  and Soft Mask Supervision",
    "abstract": "Accurate Lung Nodules Segmentation with Detailed Representation Transfer  and Soft Mask Supervision",
    "descriptor": "",
    "authors": [
      "Changwei Wang",
      "Rongtao Xu",
      "Shibiao Xu",
      "Weiliang Meng",
      "Jun Xiao",
      "Qimin Peng",
      "Xiaopeng Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.14556"
  },
  {
    "id": "arXiv:2008.02123",
    "title": "Extensional equality preservation and verified generic programming",
    "abstract": "Comments: Accepted for publication in the \"Journal of Functional Programming\" in August 2021",
    "descriptor": "\nComments: Accepted for publication in the \"Journal of Functional Programming\" in August 2021\n",
    "authors": [
      "Nicola Botta",
      "Nuria Brede",
      "Patrik Jansson",
      "Tim Richter"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2008.02123"
  },
  {
    "id": "arXiv:2008.02143",
    "title": "On the correctness of monadic backward induction",
    "abstract": "Comments: Accepted for publication in the \"Journal of Functional Programming\" in Sept. 2021",
    "descriptor": "\nComments: Accepted for publication in the \"Journal of Functional Programming\" in Sept. 2021\n",
    "authors": [
      "Nuria Brede",
      "Nicola Botta"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2008.02143"
  },
  {
    "id": "arXiv:2008.07595",
    "title": "Nonlinear Attitude Filter on SO(3): Fast Adaptation and Robustness",
    "abstract": "Comments: 2020 IEEE 16th International Conference on Automation Science and Engineering (CASE)",
    "descriptor": "\nComments: 2020 IEEE 16th International Conference on Automation Science and Engineering (CASE)\n",
    "authors": [
      "Ajay Singh",
      "Trenton S. Sieb",
      "James H. Howe",
      "Hashim A. Hashim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.07595"
  },
  {
    "id": "arXiv:2009.11374",
    "title": "Fast Adaptation Nonlinear Observer for SLAM",
    "abstract": "Comments: 2020 IEEE 24th International Conference on System Theory, Control and Computing (ICSTCC)",
    "descriptor": "\nComments: 2020 IEEE 24th International Conference on System Theory, Control and Computing (ICSTCC)\n",
    "authors": [
      "Trevor P. Drayton",
      "Abdul A. Jaiyeola",
      "Nazmul Hoque",
      "Mikhayla Maurer",
      "Hashim A. Hashim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.11374"
  },
  {
    "id": "arXiv:2009.14658",
    "title": "Learning Hard Retrieval Decoder Attention for Transformers",
    "abstract": "Learning Hard Retrieval Decoder Attention for Transformers",
    "descriptor": "",
    "authors": [
      "Hongfei Xu",
      "Qiuhui Liu",
      "Josef van Genabith",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.14658"
  },
  {
    "id": "arXiv:2010.02501",
    "title": "A Unifying View on Implicit Bias in Training Linear Neural Networks",
    "abstract": "Comments: 38 pages, 7 figures. Revision after ICLR 2021 camera-ready version. Figure 2 newly added, theorem statements revised, including correction of Theorem 2",
    "descriptor": "\nComments: 38 pages, 7 figures. Revision after ICLR 2021 camera-ready version. Figure 2 newly added, theorem statements revised, including correction of Theorem 2\n",
    "authors": [
      "Chulhee Yun",
      "Shankar Krishnan",
      "Hossein Mobahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02501"
  },
  {
    "id": "arXiv:2010.03258",
    "title": "Global Optimization of Objective Functions Represented by ReLU Networks",
    "abstract": "Comments: 27 pages, 7 figures",
    "descriptor": "\nComments: 27 pages, 7 figures\n",
    "authors": [
      "Christopher A. Strong",
      "Haoze Wu",
      "Aleksandar Zelji\u0107",
      "Kyle D. Julian",
      "Guy Katz",
      "Clark Barrett",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2010.03258"
  },
  {
    "id": "arXiv:2010.04809",
    "title": "Lattice (List) Decoding Near Minkowski's Inequality",
    "abstract": "Comments: 14 pages, 2 figures",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Ethan Mook",
      "Chris Peikert"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.04809"
  },
  {
    "id": "arXiv:2010.06127",
    "title": "Model Selection for Cross-Lingual Transfer",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Yang Chen",
      "Alan Ritter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.06127"
  },
  {
    "id": "arXiv:2010.08054",
    "title": "Pose Estimation for Robot Manipulators via Keypoint Optimization and  Sim-to-Real Transfer",
    "abstract": "Comments: 8 pages, 8 figures",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Jingpei Lu",
      "Florian Richter",
      "Michael Yip"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.08054"
  },
  {
    "id": "arXiv:2010.09697",
    "title": "Effects of Parameter Norm Growth During Transformer Training: Inductive  Bias from Gradient Descent",
    "abstract": "Comments: To appear at EMNLP 2021",
    "descriptor": "\nComments: To appear at EMNLP 2021\n",
    "authors": [
      "William Merrill",
      "Vivek Ramanujan",
      "Yoav Goldberg",
      "Roy Schwartz",
      "Noah Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.09697"
  },
  {
    "id": "arXiv:2010.11796",
    "title": "CryptoGRU: Low Latency Privacy-Preserving Text Analysis With GRU",
    "abstract": "CryptoGRU: Low Latency Privacy-Preserving Text Analysis With GRU",
    "descriptor": "",
    "authors": [
      "Bo Feng",
      "Qian Lou",
      "Lei Jiang",
      "Geoffrey C. Fox"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.11796"
  },
  {
    "id": "arXiv:2010.12251",
    "title": "A scalable framework for learning from implicit user feedback to improve  natural language understanding in large-scale conversational AI systems",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Sunghyun Park",
      "Han Li",
      "Ameen Patel",
      "Sidharth Mudgal",
      "Sungjin Lee",
      "Young-Bum Kim",
      "Spyros Matsoukas",
      "Ruhi Sarikaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12251"
  },
  {
    "id": "arXiv:2010.12762",
    "title": "Measuring Association Between Labels and Free-Text Rationales",
    "abstract": "Comments: EMNLP 2021 Camera-Ready. 9 pages main, 6 pages appendix",
    "descriptor": "\nComments: EMNLP 2021 Camera-Ready. 9 pages main, 6 pages appendix\n",
    "authors": [
      "Sarah Wiegreffe",
      "Ana Marasovi\u0107",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12762"
  },
  {
    "id": "arXiv:2010.12800",
    "title": "COUGH: A Challenge Dataset and Models for COVID-19 FAQ Retrieval",
    "abstract": "Comments: EMNLP'21 Main Conference",
    "descriptor": "\nComments: EMNLP'21 Main Conference\n",
    "authors": [
      "Xinliang Frederick Zhang",
      "Heming Sun",
      "Xiang Yue",
      "Simon Lin",
      "Huan Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2010.12800"
  },
  {
    "id": "arXiv:2010.13321",
    "title": "View-Invariant, Occlusion-Robust Probabilistic Embedding for Human Pose",
    "abstract": "Comments: Accepted to International Journal of Computer Vision (IJCV). Code is available at this https URL . Video synchronization results are available at this https URL arXiv admin note: text overlap with arXiv:1912.01001",
    "descriptor": "\nComments: Accepted to International Journal of Computer Vision (IJCV). Code is available at this https URL . Video synchronization results are available at this https URL arXiv admin note: text overlap with arXiv:1912.01001\n",
    "authors": [
      "Ting Liu",
      "Jennifer J. Sun",
      "Long Zhao",
      "Jiaping Zhao",
      "Liangzhe Yuan",
      "Yuxiao Wang",
      "Liang-Chieh Chen",
      "Florian Schroff",
      "Hartwig Adam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.13321"
  },
  {
    "id": "arXiv:2010.15413",
    "title": "Measuring and Harnessing Transference in Multi-Task Learning",
    "abstract": "Measuring and Harnessing Transference in Multi-Task Learning",
    "descriptor": "",
    "authors": [
      "Christopher Fifty",
      "Ehsan Amid",
      "Zhe Zhao",
      "Tianhe Yu",
      "Rohan Anil",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.15413"
  },
  {
    "id": "arXiv:2010.16410",
    "title": "Semi-supervised Relation Extraction via Incremental Meta Self-Training",
    "abstract": "Comments: In Findings of EMNLP 2021 as a long paper. Code and data available at this https URL",
    "descriptor": "\nComments: In Findings of EMNLP 2021 as a long paper. Code and data available at this https URL\n",
    "authors": [
      "Xuming Hu",
      "Chenwei Zhang",
      "Fukun Ma",
      "Chenyao Liu",
      "Lijie Wen",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.16410"
  },
  {
    "id": "arXiv:2011.03738",
    "title": "Sharp Thresholds in Random Simple Temporal Graphs",
    "abstract": "Sharp Thresholds in Random Simple Temporal Graphs",
    "descriptor": "",
    "authors": [
      "Arnaud Casteigts",
      "Michael Raskin",
      "Malte Renken",
      "Viktor Zamaraev"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2011.03738"
  },
  {
    "id": "arXiv:2011.05081",
    "title": "A weighted-sum method for solving the bi-objective traveling thief  problem",
    "abstract": "A weighted-sum method for solving the bi-objective traveling thief  problem",
    "descriptor": "",
    "authors": [
      "Jonatas B. C. Chagas",
      "Markus Wagner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2011.05081"
  },
  {
    "id": "arXiv:2011.07497",
    "title": "NegatER: Unsupervised Discovery of Negatives in Commonsense Knowledge  Bases",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Tara Safavi",
      "Jing Zhu",
      "Danai Koutra"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.07497"
  },
  {
    "id": "arXiv:2011.08723",
    "title": "Robust Stability of Suboptimal Moving Horizon Estimation using an  Observer-Based Candidate Solution",
    "abstract": "Robust Stability of Suboptimal Moving Horizon Estimation using an  Observer-Based Candidate Solution",
    "descriptor": "",
    "authors": [
      "Julian D. Schiller",
      "Sven Kn\u00fcfer",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.08723"
  },
  {
    "id": "arXiv:2011.12079",
    "title": "Multi-Features Guidance Network for partial-to-partial point cloud  registration",
    "abstract": "Comments: preprint version, the final version is accepted by Neural Computing and Applications and is available online at this https URL",
    "descriptor": "\nComments: preprint version, the final version is accepted by Neural Computing and Applications and is available online at this https URL\n",
    "authors": [
      "Hongyuan Wang",
      "Xiang Liu",
      "Wen Kang",
      "Zhiqiang Yan",
      "Bingwen Wang",
      "Qianhao Ning"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.12079"
  },
  {
    "id": "arXiv:2011.12237",
    "title": "The Cost of Simple Bidding in Combinatorial Auctions",
    "abstract": "The Cost of Simple Bidding in Combinatorial Auctions",
    "descriptor": "",
    "authors": [
      "Vitor Bosshard",
      "Sven Seuken"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2011.12237"
  },
  {
    "id": "arXiv:2011.12948",
    "title": "Nerfies: Deformable Neural Radiance Fields",
    "abstract": "Comments: ICCV 2021, Project page with videos: this https URL",
    "descriptor": "\nComments: ICCV 2021, Project page with videos: this https URL\n",
    "authors": [
      "Keunhong Park",
      "Utkarsh Sinha",
      "Jonathan T. Barron",
      "Sofien Bouaziz",
      "Dan B Goldman",
      "Steven M. Seitz",
      "Ricardo Martin-Brualla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2011.12948"
  },
  {
    "id": "arXiv:2011.14469",
    "title": "Cyberphysical Security Through Resiliency: A Systems-centric Approach",
    "abstract": "Cyberphysical Security Through Resiliency: A Systems-centric Approach",
    "descriptor": "",
    "authors": [
      "Cody Fleming",
      "Carl Elks",
      "Georgios Bakirtzis",
      "Stephen C. Adams",
      "Bryan Carter",
      "Peter A. Beling",
      "Barry Horowitz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2011.14469"
  },
  {
    "id": "arXiv:2012.01410",
    "title": "Ontological Smart Contracts in OASIS: Ontology for Agents, Systems, and  Integration of Services",
    "abstract": "Comments: This work has been accepted for publication at The 14th International Symposium on Intelligent Distributed Computing, 16--18 September 2021 - Online. Paper accepted on 8 September 2020",
    "descriptor": "\nComments: This work has been accepted for publication at The 14th International Symposium on Intelligent Distributed Computing, 16--18 September 2021 - Online. Paper accepted on 8 September 2020\n",
    "authors": [
      "Domenico Cantone",
      "Carmelo Fabio Longo",
      "Marianna Nicolosi-Asmundo",
      "Daniele Francesco Santamaria",
      "Corrado Santoro"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.01410"
  },
  {
    "id": "arXiv:2012.03679",
    "title": "Learning normal appearance for fetal anomaly screening: Application to  the unsupervised detection of Hypoplastic Left Heart Syndrome",
    "abstract": "Learning normal appearance for fetal anomaly screening: Application to  the unsupervised detection of Hypoplastic Left Heart Syndrome",
    "descriptor": "",
    "authors": [
      "Elisa Chotzoglou",
      "Thomas Day",
      "Jeremy Tan",
      "Jacqueline Matthew",
      "David Lloyd",
      "Reza Razavi",
      "John Simpson",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.03679"
  },
  {
    "id": "arXiv:2012.05362",
    "title": "Kineverse: A Symbolic Articulation Model Framework for Model-Agnostic  Mobile Manipulation",
    "abstract": "Comments: 8 pages, 7 figures, Submitted to IEEE Robotics and Automation Letters 2021 (RA-L 2021)",
    "descriptor": "\nComments: 8 pages, 7 figures, Submitted to IEEE Robotics and Automation Letters 2021 (RA-L 2021)\n",
    "authors": [
      "Adrian R\u00f6fer",
      "Georg Bartels",
      "Abhinav Valada",
      "Michael Beetz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.05362"
  },
  {
    "id": "arXiv:2012.05649",
    "title": "Concept Generalization in Visual Representation Learning",
    "abstract": "Comments: Accepted to ICCV 2021. See our project website: this https URL for code and ImageNet-CoG level files",
    "descriptor": "\nComments: Accepted to ICCV 2021. See our project website: this https URL for code and ImageNet-CoG level files\n",
    "authors": [
      "Mert Bulent Sariyildiz",
      "Yannis Kalantidis",
      "Diane Larlus",
      "Karteek Alahari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.05649"
  },
  {
    "id": "arXiv:2012.09259",
    "title": "ISD: Self-Supervised Learning by Iterative Similarity Distillation",
    "abstract": "ISD: Self-Supervised Learning by Iterative Similarity Distillation",
    "descriptor": "",
    "authors": [
      "Ajinkya Tejankar",
      "Soroush Abbasi Koohpayegani",
      "Vipin Pillai",
      "Paolo Favaro",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09259"
  },
  {
    "id": "arXiv:2012.14388",
    "title": "Universal Sentence Representation Learning with Conditional Masked  Language Model",
    "abstract": "Comments: Accepted to the 2021 Conference on Empirical Methods in Natural Language Processing",
    "descriptor": "\nComments: Accepted to the 2021 Conference on Empirical Methods in Natural Language Processing\n",
    "authors": [
      "Ziyi Yang",
      "Yinfei Yang",
      "Daniel Cer",
      "Jax Law",
      "Eric Darve"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.14388"
  },
  {
    "id": "arXiv:2012.15562",
    "title": "UNKs Everywhere: Adapting Multilingual Language Models to New Scripts",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Jonas Pfeiffer",
      "Ivan Vuli\u0107",
      "Iryna Gurevych",
      "Sebastian Ruder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15562"
  },
  {
    "id": "arXiv:2012.15710",
    "title": "Revisiting Robust Neural Machine Translation: A Transformer Case Study",
    "abstract": "Comments: EMNLP (findings). The first two authors contributed equally",
    "descriptor": "\nComments: EMNLP (findings). The first two authors contributed equally\n",
    "authors": [
      "Peyman Passban",
      "Puneeth S.M. Saladi",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15710"
  },
  {
    "id": "arXiv:2012.15781",
    "title": "FastIF: Scalable Influence Functions for Efficient Model Interpretation  and Debugging",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Han Guo",
      "Nazneen Fatema Rajani",
      "Peter Hase",
      "Mohit Bansal",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15781"
  },
  {
    "id": "arXiv:2101.00297",
    "title": "Analyzing Commonsense Emergence in Few-shot Knowledge Models",
    "abstract": "Comments: AKBC 2021",
    "descriptor": "\nComments: AKBC 2021\n",
    "authors": [
      "Jeff Da",
      "Ronan Le Bras",
      "Ximing Lu",
      "Yejin Choi",
      "Antoine Bosselut"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00297"
  },
  {
    "id": "arXiv:2101.00433",
    "title": "Modeling Disclosive Transparency in NLP Application Descriptions",
    "abstract": "Comments: To appear at EMNLP 2021. 15 pages, 10 figures, 7 tables",
    "descriptor": "\nComments: To appear at EMNLP 2021. 15 pages, 10 figures, 7 tables\n",
    "authors": [
      "Michael Saxon",
      "Sharon Levy",
      "Xinyi Wang",
      "Alon Albalak",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2101.00433"
  },
  {
    "id": "arXiv:2102.01192",
    "title": "Generative Spoken Language Modeling from Raw Audio",
    "abstract": "Generative Spoken Language Modeling from Raw Audio",
    "descriptor": "",
    "authors": [
      "Kushal Lakhotia",
      "Evgeny Kharitonov",
      "Wei-Ning Hsu",
      "Yossi Adi",
      "Adam Polyak",
      "Benjamin Bolte",
      "Tu-Anh Nguyen",
      "Jade Copet",
      "Alexei Baevski",
      "Adelrahman Mohamed",
      "Emmanuel Dupoux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.01192"
  },
  {
    "id": "arXiv:2102.02618",
    "title": "Optimised one-class classification performance",
    "abstract": "Optimised one-class classification performance",
    "descriptor": "",
    "authors": [
      "Oliver Urs Lenz",
      "Daniel Peralta",
      "Chris Cornelis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.02618"
  },
  {
    "id": "arXiv:2102.02988",
    "title": "AutoPilot: Automating SoC Design Space Exploration for SWaP Constrained  Autonomous UAVs",
    "abstract": "AutoPilot: Automating SoC Design Space Exploration for SWaP Constrained  Autonomous UAVs",
    "descriptor": "",
    "authors": [
      "Srivatsan Krishnan",
      "Zishen Wan",
      "Kshitij Bhardwaj",
      "Paul Whatmough",
      "Aleksandra Faust",
      "Sabrina Neuman",
      "Gu-Yeon Wei",
      "David Brooks",
      "Vijay Janapa Reddi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02988"
  },
  {
    "id": "arXiv:2102.03173",
    "title": "Reconstructing Arbitrary Trees from Traces in the Tree Edit Distance  Model",
    "abstract": "Comments: The proof of the paper's main result, Theorem 13, is incorrect, and therefore the consequence to tree reconstruction in Corollary 14 cannot be claimed. This negates the entirety of Section 5 in the paper. (This does not affect the remaining sections.)",
    "descriptor": "\nComments: The proof of the paper's main result, Theorem 13, is incorrect, and therefore the consequence to tree reconstruction in Corollary 14 cannot be claimed. This negates the entirety of Section 5 in the paper. (This does not affect the remaining sections.)\n",
    "authors": [
      "Thomas Maranzatto",
      "Lev Reyzin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2102.03173"
  },
  {
    "id": "arXiv:2102.03973",
    "title": "Solid Texture Synthesis using Generative Adversarial Networks",
    "abstract": "Solid Texture Synthesis using Generative Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Xin Zhao",
      "Jifeng Guo",
      "Lin Wang",
      "Fanqi Li",
      "Junteng Zheng",
      "Bo Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2102.03973"
  },
  {
    "id": "arXiv:2102.05791",
    "title": "Differentiable Implicit Soft-Body Physics",
    "abstract": "Differentiable Implicit Soft-Body Physics",
    "descriptor": "",
    "authors": [
      "Junior Rojas",
      "Eftychios Sifakis",
      "Ladislav Kavan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2102.05791"
  },
  {
    "id": "arXiv:2102.07632",
    "title": "Impact of EV Charging Stations in Power Grids in Italy and its  Mitigation Mechanisms",
    "abstract": "Impact of EV Charging Stations in Power Grids in Italy and its  Mitigation Mechanisms",
    "descriptor": "",
    "authors": [
      "A. Samson Mogos",
      "Samuele Grillo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.07632"
  },
  {
    "id": "arXiv:2102.08203",
    "title": "On the shape of air-liquid interfaces with surface tension that bound  rigidly-rotating liquids in partially filled containers",
    "abstract": "Comments: 24 pages, 14 figures",
    "descriptor": "\nComments: 24 pages, 14 figures\n",
    "authors": [
      "Enrique Ram\u00e9",
      "Steven J. Weinstein",
      "Nathaniel S. Barlow"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2102.08203"
  },
  {
    "id": "arXiv:2102.09206",
    "title": "Less is More: Pre-training a Strong Siamese Encoder Using a Weak Decoder",
    "abstract": "Less is More: Pre-training a Strong Siamese Encoder Using a Weak Decoder",
    "descriptor": "",
    "authors": [
      "Shuqi Lu",
      "Chenyan Xiong",
      "Di He",
      "Guolin Ke",
      "Waleed Malik",
      "Zhicheng Dou",
      "Paul Bennett",
      "Tieyan Liu",
      "Arnold Overwijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09206"
  },
  {
    "id": "arXiv:2102.09761",
    "title": "Scaling Creative Inspiration with Fine-Grained Functional Facets of  Ideas",
    "abstract": "Scaling Creative Inspiration with Fine-Grained Functional Facets of  Ideas",
    "descriptor": "",
    "authors": [
      "Tom Hope",
      "Ronen Tamari",
      "Hyeonsu Kang",
      "Daniel Hershcovich",
      "Joel Chan",
      "Aniket Kittur",
      "Dafna Shahaf"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.09761"
  },
  {
    "id": "arXiv:2102.11861",
    "title": "Generative Modelling of BRDF Textures from Flash Images",
    "abstract": "Generative Modelling of BRDF Textures from Flash Images",
    "descriptor": "",
    "authors": [
      "Philipp Henzler",
      "Valentin Deschaintre",
      "Niloy J. Mitra",
      "Tobias Ritschel"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11861"
  },
  {
    "id": "arXiv:2102.13605",
    "title": "ECO: Enabling Energy-Neutral IoT Devices through Runtime Allocation of  Harvested Energy",
    "abstract": "ECO: Enabling Energy-Neutral IoT Devices through Runtime Allocation of  Harvested Energy",
    "descriptor": "",
    "authors": [
      "Yigit Tuncel",
      "Ganapati Bhat",
      "Jaehyun Park",
      "Umit Ogras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.13605"
  },
  {
    "id": "arXiv:2103.01378",
    "title": "Contrastive Explanations for Model Interpretability",
    "abstract": "Contrastive Explanations for Model Interpretability",
    "descriptor": "",
    "authors": [
      "Alon Jacovi",
      "Swabha Swayamdipta",
      "Shauli Ravfogel",
      "Yanai Elazar",
      "Yejin Choi",
      "Yoav Goldberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01378"
  },
  {
    "id": "arXiv:2103.04055",
    "title": "Visualizing Robot Intent for Object Handovers with Augmented Reality",
    "abstract": "Comments: 7 pages, 5 Figures, 5 Tables",
    "descriptor": "\nComments: 7 pages, 5 Figures, 5 Tables\n",
    "authors": [
      "Rhys Newbury",
      "Akansel Cosgun",
      "Tysha Crowley-Davis",
      "Wesley P. Chan",
      "Tom Drummond",
      "Elizabeth Croft"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.04055"
  },
  {
    "id": "arXiv:2103.05789",
    "title": "Cybersecurity in Robotics: Challenges, Quantitative Modeling, and  Practice",
    "abstract": "Cybersecurity in Robotics: Challenges, Quantitative Modeling, and  Practice",
    "descriptor": "",
    "authors": [
      "Quanyan Zhu",
      "Stefan Rass",
      "Bernhard Dieber",
      "Victor Mayoral Vilches"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.05789"
  },
  {
    "id": "arXiv:2103.06819",
    "title": "TAG: Transformer Attack from Gradient",
    "abstract": "Comments: Accepted to Findings of EMNLP 2021",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Jieren Deng",
      "Yijue Wang",
      "Ji Li",
      "Chao Shang",
      "Hang Liu",
      "Sanguthevar Rajasekaran",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.06819"
  },
  {
    "id": "arXiv:2103.07352",
    "title": "Visual Cues and Error Correction for Translation Robustness",
    "abstract": "Comments: Accepted at Findings of EMNLP 2021",
    "descriptor": "\nComments: Accepted at Findings of EMNLP 2021\n",
    "authors": [
      "Zhenhao Li",
      "Marek Rei",
      "Lucia Specia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.07352"
  },
  {
    "id": "arXiv:2103.07654",
    "title": "Understanding User Topic Preferences across Multiple Social Networks",
    "abstract": "Understanding User Topic Preferences across Multiple Social Networks",
    "descriptor": "",
    "authors": [
      "Ziqing Zhu",
      "Jiuxin Cao",
      "Tao Zhou",
      "Huiyu Min",
      "Bo Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.07654"
  },
  {
    "id": "arXiv:2103.08713",
    "title": "Multi-task learning for virtual flow metering",
    "abstract": "Comments: 23 pages, 11 figures",
    "descriptor": "\nComments: 23 pages, 11 figures\n",
    "authors": [
      "Anders T. Sandnes",
      "Bjarne Grimstad",
      "Odd Kolbj\u00f8rnsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.08713"
  },
  {
    "id": "arXiv:2103.08740",
    "title": "Observability-Blocking Control using Sparser and Regional Feedback for  Network Synchronization Processes",
    "abstract": "Observability-Blocking Control using Sparser and Regional Feedback for  Network Synchronization Processes",
    "descriptor": "",
    "authors": [
      "Abdullah Al Maruf",
      "Sandip Roy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.08740"
  },
  {
    "id": "arXiv:2103.08922",
    "title": "Combining Morphological and Histogram based Text Line Segmentation in  the OCR Context",
    "abstract": "Comments: Journal of Data Mining and Digital Humanities",
    "descriptor": "\nComments: Journal of Data Mining and Digital Humanities\n",
    "authors": [
      "Pit Schneider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.08922"
  },
  {
    "id": "arXiv:2103.11320",
    "title": "Lawyers are Dishonest? Quantifying Representational Harms in Commonsense  Knowledge Resources",
    "abstract": "Lawyers are Dishonest? Quantifying Representational Harms in Commonsense  Knowledge Resources",
    "descriptor": "",
    "authors": [
      "Ninareh Mehrabi",
      "Pei Zhou",
      "Fred Morstatter",
      "Jay Pujara",
      "Xiang Ren",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.11320"
  },
  {
    "id": "arXiv:2103.16424",
    "title": "Two-stage Robust Energy Storage Planning with Probabilistic Guarantees:  A Data-driven Approach",
    "abstract": "Two-stage Robust Energy Storage Planning with Probabilistic Guarantees:  A Data-driven Approach",
    "descriptor": "",
    "authors": [
      "Chao Yan",
      "Xinbo Geng",
      "Zhaohong Bie",
      "Le Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.16424"
  },
  {
    "id": "arXiv:2103.16590",
    "title": "Evaluating the Morphosyntactic Well-formedness of Generated Texts",
    "abstract": "Comments: EMNLP 2021 camera-ready",
    "descriptor": "\nComments: EMNLP 2021 camera-ready\n",
    "authors": [
      "Adithya Pratapa",
      "Antonios Anastasopoulos",
      "Shruti Rijhwani",
      "Aditi Chaudhary",
      "David R. Mortensen",
      "Graham Neubig",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.16590"
  },
  {
    "id": "arXiv:2103.16874",
    "title": "VITON-HD: High-Resolution Virtual Try-On via Misalignment-Aware  Normalization",
    "abstract": "Comments: 21 pages; project page: this https URL; accepted to CVPR 2021; code URL added, references formatted",
    "descriptor": "\nComments: 21 pages; project page: this https URL; accepted to CVPR 2021; code URL added, references formatted\n",
    "authors": [
      "Seunghwan Choi",
      "Sunghyun Park",
      "Minsoo Lee",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.16874"
  },
  {
    "id": "arXiv:2104.00921",
    "title": "AAformer: Auto-Aligned Transformer for Person Re-Identification",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Kuan Zhu",
      "Haiyun Guo",
      "Shiliang Zhang",
      "Yaowei Wang",
      "Gaopan Huang",
      "Honglin Qiao",
      "Jing Liu",
      "Jinqiao Wang",
      "Ming Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.00921"
  },
  {
    "id": "arXiv:2104.01454",
    "title": "Few-Shot Keyword Spotting in Any Language",
    "abstract": "Few-Shot Keyword Spotting in Any Language",
    "descriptor": "",
    "authors": [
      "Mark Mazumder",
      "Colby Banbury",
      "Josh Meyer",
      "Pete Warden",
      "Vijay Janapa Reddi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.01454"
  },
  {
    "id": "arXiv:2104.04767",
    "title": "MobileStyleGAN: A Lightweight Convolutional Neural Network for  High-Fidelity Image Synthesis",
    "abstract": "MobileStyleGAN: A Lightweight Convolutional Neural Network for  High-Fidelity Image Synthesis",
    "descriptor": "",
    "authors": [
      "Sergei Belousov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2104.04767"
  },
  {
    "id": "arXiv:2104.05094",
    "title": "Constructing Contrastive samples via Summarization for Text  Classification with limited annotations",
    "abstract": "Constructing Contrastive samples via Summarization for Text  Classification with limited annotations",
    "descriptor": "",
    "authors": [
      "Yangkai Du",
      "Tengfei Ma",
      "Lingfei Wu",
      "Fangli Xu",
      "Xuhong Zhang",
      "Shouling Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05094"
  },
  {
    "id": "arXiv:2104.05547",
    "title": "WHOSe Heritage: Classification of UNESCO World Heritage \"Outstanding  Universal Value\" Documents with Soft Labels",
    "abstract": "Comments: 19 pages, 5 figures, accepted by Findings of EMNLP 2021. The data and models presented in this paper can be found in the following GitHub link: this https URL or this http URL",
    "descriptor": "\nComments: 19 pages, 5 figures, accepted by Findings of EMNLP 2021. The data and models presented in this paper can be found in the following GitHub link: this https URL or this http URL\n",
    "authors": [
      "Nan Bai",
      "Renqian Luo",
      "Pirouz Nourian",
      "Ana Pereira Roders"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2104.05547"
  },
  {
    "id": "arXiv:2104.05837",
    "title": "Relational World Knowledge Representation in Contextual Language Models:  A Review",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Tara Safavi",
      "Danai Koutra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05837"
  },
  {
    "id": "arXiv:2104.05845",
    "title": "Visual Goal-Step Inference using wikiHow",
    "abstract": "Visual Goal-Step Inference using wikiHow",
    "descriptor": "",
    "authors": [
      "Yue Yang",
      "Artemis Panagopoulou",
      "Qing Lyu",
      "Li Zhang",
      "Mark Yatskar",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2104.05845"
  },
  {
    "id": "arXiv:2104.06022",
    "title": "Lessons on Parameter Sharing across Layers in Transformers",
    "abstract": "Lessons on Parameter Sharing across Layers in Transformers",
    "descriptor": "",
    "authors": [
      "Sho Takase",
      "Shun Kiyono"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06022"
  },
  {
    "id": "arXiv:2104.06644",
    "title": "Masked Language Modeling and the Distributional Hypothesis: Order Word  Matters Pre-training for Little",
    "abstract": "Comments: To appear at EMNLP 2021; 26 pages total (9 main, 6 reference and 11 Appendix)",
    "descriptor": "\nComments: To appear at EMNLP 2021; 26 pages total (9 main, 6 reference and 11 Appendix)\n",
    "authors": [
      "Koustuv Sinha",
      "Robin Jia",
      "Dieuwke Hupkes",
      "Joelle Pineau",
      "Adina Williams",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06644"
  },
  {
    "id": "arXiv:2104.06979",
    "title": "TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for  Unsupervised Sentence Embedding Learning",
    "abstract": "Comments: Accepted at EMNLP 2021 Findings",
    "descriptor": "\nComments: Accepted at EMNLP 2021 Findings\n",
    "authors": [
      "Kexin Wang",
      "Nils Reimers",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.06979"
  },
  {
    "id": "arXiv:2104.07425",
    "title": "Pseudo Zero Pronoun Resolution Improves Zero Anaphora Resolution",
    "abstract": "Comments: Long paper accepted by EMNLP2021 main conference",
    "descriptor": "\nComments: Long paper accepted by EMNLP2021 main conference\n",
    "authors": [
      "Ryuto Konno",
      "Shun Kiyono",
      "Yuichiroh Matsubayashi",
      "Hiroki Ouchi",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07425"
  },
  {
    "id": "arXiv:2104.07566",
    "title": "BAM: A Balanced Attention Mechanism for Single Image Super Resolution",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Fanyi Wang",
      "Haotian Hu",
      "Cheng Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07566"
  },
  {
    "id": "arXiv:2104.07637",
    "title": "The Effect of Efficient Messaging and Input Variability on Neural-Agent  Iterated Language Learning",
    "abstract": "Comments: To appear at EMNLP 2021",
    "descriptor": "\nComments: To appear at EMNLP 2021\n",
    "authors": [
      "Yuchen Lian",
      "Arianna Bisazza",
      "Tessa Verhoef"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07637"
  },
  {
    "id": "arXiv:2104.07789",
    "title": "Detect and Classify -- Joint Span Detection and Classification for  Health Outcomes",
    "abstract": "Detect and Classify -- Joint Span Detection and Classification for  Health Outcomes",
    "descriptor": "",
    "authors": [
      "Michael Abaho",
      "Danushka Bollegala",
      "Paula Williamson",
      "Susanna Dodd"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07789"
  },
  {
    "id": "arXiv:2104.08247",
    "title": "What to Pre-Train on? Efficient Intermediate Task Selection",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Clifton Poth",
      "Jonas Pfeiffer",
      "Andreas R\u00fcckl\u00e9",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08247"
  },
  {
    "id": "arXiv:2104.08384",
    "title": "\"Wikily\" Supervised Neural Translation Tailored to Cross-Lingual Tasks",
    "abstract": "Comments: To appear in EMNLP 2021 main conference",
    "descriptor": "\nComments: To appear in EMNLP 2021 main conference\n",
    "authors": [
      "Mohammad Sadegh Rasooli",
      "Chris Callison-Burch",
      "Derry Tanti Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08384"
  },
  {
    "id": "arXiv:2104.08597",
    "title": "XLEnt: Mining a Large Cross-lingual Entity Dataset with  Lexical-Semantic-Phonetic Word Alignment",
    "abstract": "XLEnt: Mining a Large Cross-lingual Entity Dataset with  Lexical-Semantic-Phonetic Word Alignment",
    "descriptor": "",
    "authors": [
      "Ahmed El-Kishky",
      "Adithya Renduchintala",
      "James Cross",
      "Francisco Guzm\u00e1n",
      "Philipp Koehn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08597"
  },
  {
    "id": "arXiv:2104.08645",
    "title": "Improving Zero-Shot Cross-Lingual Transfer Learning via Robust Training",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Kuan-Hao Huang",
      "Wasi Uddin Ahmad",
      "Nanyun Peng",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08645"
  },
  {
    "id": "arXiv:2104.08685",
    "title": "Linguistic Dependencies and Statistical Dependence",
    "abstract": "Comments: EMNLP2021 camera-ready version. 9 pages, plus references and appendices",
    "descriptor": "\nComments: EMNLP2021 camera-ready version. 9 pages, plus references and appendices\n",
    "authors": [
      "Jacob Louis Hoover",
      "Alessandro Sordoni",
      "Wenyu Du",
      "Timothy J. O'Donnell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.08685"
  },
  {
    "id": "arXiv:2104.08799",
    "title": "Keyphrase Generation with Fine-Grained Evaluation-Guided Reinforcement  Learning",
    "abstract": "Comments: 11 pages, Findings of EMNLP 2021",
    "descriptor": "\nComments: 11 pages, Findings of EMNLP 2021\n",
    "authors": [
      "Yichao Luo",
      "Yige Xu",
      "Jiacheng Ye",
      "Xipeng Qiu",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08799"
  },
  {
    "id": "arXiv:2104.08821",
    "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings",
    "abstract": "Comments: Accepted to EMNLP 2021. The code and pre-trained models are available at this https URL",
    "descriptor": "\nComments: Accepted to EMNLP 2021. The code and pre-trained models are available at this https URL\n",
    "authors": [
      "Tianyu Gao",
      "Xingcheng Yao",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08821"
  },
  {
    "id": "arXiv:2104.09574",
    "title": "Probing Commonsense Explanation in Dialogue Response Generation",
    "abstract": "Comments: Accepted in EMNLP 2021-Findings. 15 pages, 12 figures, 3 tables",
    "descriptor": "\nComments: Accepted in EMNLP 2021-Findings. 15 pages, 12 figures, 3 tables\n",
    "authors": [
      "Pei Zhou",
      "Pegah Jandaghi",
      "Bill Yuchen Lin",
      "Justin Cho",
      "Jay Pujara",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09574"
  },
  {
    "id": "arXiv:2104.13813",
    "title": "MOVO: a dApp for DLT-based Smart Mobility",
    "abstract": "MOVO: a dApp for DLT-based Smart Mobility",
    "descriptor": "",
    "authors": [
      "Mirko Zichichi",
      "Stefano Ferretti",
      "Gabriele D'Angelo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.13813"
  },
  {
    "id": "arXiv:2104.13819",
    "title": "Towards Decentralized Complex Queries over Distributed Ledgers: a Data  Marketplace Use-case",
    "abstract": "Towards Decentralized Complex Queries over Distributed Ledgers: a Data  Marketplace Use-case",
    "descriptor": "",
    "authors": [
      "Mirko Zichichi",
      "Luca Serena",
      "Stefano Ferretti",
      "Gabriele D'Angelo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2104.13819"
  },
  {
    "id": "arXiv:2105.00110",
    "title": "Triangle Centrality",
    "abstract": "Triangle Centrality",
    "descriptor": "",
    "authors": [
      "Paul Burkhardt"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.00110"
  },
  {
    "id": "arXiv:2105.00327",
    "title": "AirCode: A Robust Object Encoding Method",
    "abstract": "AirCode: A Robust Object Encoding Method",
    "descriptor": "",
    "authors": [
      "Kuan Xu",
      "Chen Wang",
      "Chao Chen",
      "Wei Wu",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.00327"
  },
  {
    "id": "arXiv:2105.00884",
    "title": "RL-IoT: Reinforcement Learning to Interact with IoT Devices",
    "abstract": "Comments: 9 pages, 11 figures, 2021 IEEE International Conference on Omni-Layer Intelligent Systems (COINS)",
    "descriptor": "\nComments: 9 pages, 11 figures, 2021 IEEE International Conference on Omni-Layer Intelligent Systems (COINS)\n",
    "authors": [
      "Giulia Milan",
      "Luca Vassio",
      "Idilio Drago",
      "Marco Mellia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.00884"
  },
  {
    "id": "arXiv:2105.01961",
    "title": "Stitch Fix for Mapper and Topological Gains",
    "abstract": "Stitch Fix for Mapper and Topological Gains",
    "descriptor": "",
    "authors": [
      "Youjia Zhou",
      "Nathaniel Saul",
      "Ilkin Safarli",
      "Bala Krishnamoorthy",
      "Bei Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.01961"
  },
  {
    "id": "arXiv:2105.03432",
    "title": "Generalising Multilingual Concept-to-Text NLG with Language Agnostic  Delexicalisation",
    "abstract": "Comments: ACL-IJCNLP 2021 camera ready version",
    "descriptor": "\nComments: ACL-IJCNLP 2021 camera ready version\n",
    "authors": [
      "Giulio Zhou",
      "Gerasimos Lampouras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03432"
  },
  {
    "id": "arXiv:2105.03824",
    "title": "FNet: Mixing Tokens with Fourier Transforms",
    "abstract": "Comments: NB update: We were measuring speeds incorrectly. FNet trains 80%/70% faster than BERT on GPU/TPU (not 7x/2x as initially reported). Other speed metrics (LRA & small models) are also updated, but relative differences are roughly the same. Context: While the Fourier layer itself is significantly faster than self-attention (see Appendix A.4), overall training speed is slowed by feed-forward layers",
    "descriptor": "\nComments: NB update: We were measuring speeds incorrectly. FNet trains 80%/70% faster than BERT on GPU/TPU (not 7x/2x as initially reported). Other speed metrics (LRA & small models) are also updated, but relative differences are roughly the same. Context: While the Fourier layer itself is significantly faster than self-attention (see Appendix A.4), overall training speed is slowed by feed-forward layers\n",
    "authors": [
      "James Lee-Thorp",
      "Joshua Ainslie",
      "Ilya Eckstein",
      "Santiago Ontanon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03824"
  },
  {
    "id": "arXiv:2105.06018",
    "title": "Robust Dynamic Multi-Modal Data Fusion: A Model Uncertainty Perspective",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Bin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.06018"
  },
  {
    "id": "arXiv:2105.07269",
    "title": "Mean Shift for Self-Supervised Learning",
    "abstract": "Mean Shift for Self-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Soroush Abbasi Koohpayegani",
      "Ajinkya Tejankar",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07269"
  },
  {
    "id": "arXiv:2105.11061",
    "title": "An Automated and Comprehensive Framework for IoT Botnet Detection and  Analysis (IoT-BDA)",
    "abstract": "Comments: This article has been accepted for publication in IEEE Access Journal",
    "descriptor": "\nComments: This article has been accepted for publication in IEEE Access Journal\n",
    "authors": [
      "Tolijan Trajanovski",
      "Ning Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.11061"
  },
  {
    "id": "arXiv:2105.11107",
    "title": "FineAction: A Fine-Grained Video Dataset for Temporal Action  Localization",
    "abstract": "Comments: One track of DeeperAction Workshop@ICCV2021. HomePage: this https URL",
    "descriptor": "\nComments: One track of DeeperAction Workshop@ICCV2021. HomePage: this https URL\n",
    "authors": [
      "Yi Liu",
      "Limin Wang",
      "Xiao Ma",
      "Yali Wang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11107"
  },
  {
    "id": "arXiv:2105.11702",
    "title": "Transfer Learning and Curriculum Learning in Sokoban",
    "abstract": "Transfer Learning and Curriculum Learning in Sokoban",
    "descriptor": "",
    "authors": [
      "Zhao Yang",
      "Mike Preuss",
      "Aske Plaat"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11702"
  },
  {
    "id": "arXiv:2106.07806",
    "title": "Highdicom: A Python library for standardized encoding of image  annotations and machine learning model outputs in pathology and radiology",
    "abstract": "Highdicom: A Python library for standardized encoding of image  annotations and machine learning model outputs in pathology and radiology",
    "descriptor": "",
    "authors": [
      "Christopher P. Bridge",
      "Chris Gorman",
      "Steven Pieper",
      "Sean W. Doyle",
      "Jochen K. Lennerz",
      "Jayashree Kalpathy-Cramer",
      "David A. Clunie",
      "Andriy Y. Fedorov",
      "Markus D. Herrmann"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07806"
  },
  {
    "id": "arXiv:2106.08826",
    "title": "A discrete optimisation approach for target path planning whilst evading  sensors",
    "abstract": "A discrete optimisation approach for target path planning whilst evading  sensors",
    "descriptor": "",
    "authors": [
      "J.E. Beasley"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08826"
  },
  {
    "id": "arXiv:2106.09485",
    "title": "Secure Multi-Function Computation with Private Remote Sources",
    "abstract": "Comments: Shorter version to appear in the IEEE International Symposium on Information Theory 2021",
    "descriptor": "\nComments: Shorter version to appear in the IEEE International Symposium on Information Theory 2021\n",
    "authors": [
      "Onur G\u00fcnl\u00fc",
      "Matthieu Bloch",
      "Rafael F. Schaefer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.09485"
  },
  {
    "id": "arXiv:2106.10963",
    "title": "Wireless Communication Aided by Intelligent Reflecting Surface: Active  or Passive?",
    "abstract": "Comments: We studied the comparison between active and passive IRS with optimized IRS deployment",
    "descriptor": "\nComments: We studied the comparison between active and passive IRS with optimized IRS deployment\n",
    "authors": [
      "Changsheng You",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.10963"
  },
  {
    "id": "arXiv:2106.11858",
    "title": "MEAL: Manifold Embedding-based Active Learning",
    "abstract": "MEAL: Manifold Embedding-based Active Learning",
    "descriptor": "",
    "authors": [
      "Deepthi Sreenivasaiah",
      "Johannes Otterbach",
      "Thomas Wollmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11858"
  },
  {
    "id": "arXiv:2106.13228",
    "title": "HyperNeRF: A Higher-Dimensional Representation for Topologically Varying  Neural Radiance Fields",
    "abstract": "Comments: SIGGRAPH Asia 2021, Project page: this https URL",
    "descriptor": "\nComments: SIGGRAPH Asia 2021, Project page: this https URL\n",
    "authors": [
      "Keunhong Park",
      "Utkarsh Sinha",
      "Peter Hedman",
      "Jonathan T. Barron",
      "Sofien Bouaziz",
      "Dan B Goldman",
      "Ricardo Martin-Brualla",
      "Steven M. Seitz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2106.13228"
  },
  {
    "id": "arXiv:2106.15942",
    "title": "On the Role of Hypocrisy in Escaping the Tragedy of the Commons",
    "abstract": "On the Role of Hypocrisy in Escaping the Tragedy of the Commons",
    "descriptor": "",
    "authors": [
      "Amos Korman",
      "Robin Vacus"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.15942"
  },
  {
    "id": "arXiv:2107.01198",
    "title": "DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature",
    "abstract": "Comments: Accepted at EMNLP-2021 (System Demonstration Track)",
    "descriptor": "\nComments: Accepted at EMNLP-2021 (System Demonstration Track)\n",
    "authors": [
      "Abheesht Sharma",
      "Gunjan Chhablani",
      "Harshit Pandey",
      "Rajaswa Patil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01198"
  },
  {
    "id": "arXiv:2107.02174",
    "title": "What Makes for Hierarchical Vision Transformer?",
    "abstract": "What Makes for Hierarchical Vision Transformer?",
    "descriptor": "",
    "authors": [
      "Yuxin Fang",
      "Xinggang Wang",
      "Rui Wu",
      "Wenyu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02174"
  },
  {
    "id": "arXiv:2107.02375",
    "title": "SplitAVG: A heterogeneity-aware federated deep learning method for  medical imaging",
    "abstract": "SplitAVG: A heterogeneity-aware federated deep learning method for  medical imaging",
    "descriptor": "",
    "authors": [
      "Miao Zhang",
      "Liangqiong Qu",
      "Praveer Singh",
      "Jayashree Kalpathy-Cramer",
      "Daniel L. Rubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.02375"
  },
  {
    "id": "arXiv:2107.06790",
    "title": "Governing Decentralized Complex Queries Through a DAO",
    "abstract": "Governing Decentralized Complex Queries Through a DAO",
    "descriptor": "",
    "authors": [
      "Mirko Zichichi",
      "Luca Serena",
      "Stefano Ferretti",
      "Gabriele D'Angelo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.06790"
  },
  {
    "id": "arXiv:2107.08351",
    "title": "A Novel Approach to Analyze Fashion Digital Archive from Humanities",
    "abstract": "Comments: In Proceedings of 'The 23rd International Conference on Asia-Pacific Digital Libraries' 17 pages, 8 figures. arXiv admin note: text overlap with arXiv:2009.13395",
    "descriptor": "\nComments: In Proceedings of 'The 23rd International Conference on Asia-Pacific Digital Libraries' 17 pages, 8 figures. arXiv admin note: text overlap with arXiv:2009.13395\n",
    "authors": [
      "Satoshi Takahashi",
      "Keiko Yamaguchi",
      "Asuka Watanabe"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2107.08351"
  },
  {
    "id": "arXiv:2107.09581",
    "title": "Entropy as a Topological Operad Derivation",
    "abstract": "Comments: 13 pages; v2. version appearing in Entropy (minor changes, typos fixed)",
    "descriptor": "\nComments: 13 pages; v2. version appearing in Entropy (minor changes, typos fixed)\n",
    "authors": [
      "Tai-Danae Bradley"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Information Theory (cs.IT)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2107.09581"
  },
  {
    "id": "arXiv:2107.13519",
    "title": "On the state of reporting in crowdsourcing experiments and a checklist  to aid current practices",
    "abstract": "Comments: Accepted to CSCW 2021",
    "descriptor": "\nComments: Accepted to CSCW 2021\n",
    "authors": [
      "Jorge Ram\u00edrez",
      "Burcu Sayin",
      "Marcos Baez",
      "Fabio Casati",
      "Luca Cernuzzi",
      "Boualem Benatallah",
      "Gianluca Demartini"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.13519"
  },
  {
    "id": "arXiv:2108.00270",
    "title": "Opinion Prediction with User Fingerprinting",
    "abstract": "Comments: 10 pages, 6 figures, RANLP conference 2021",
    "descriptor": "\nComments: 10 pages, 6 figures, RANLP conference 2021\n",
    "authors": [
      "Kishore Tumarada",
      "Yifan Zhang",
      "Fan Yang",
      "Eduard Dragut",
      "Omprakash Gnawali",
      "Arjun Mukherjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.00270"
  },
  {
    "id": "arXiv:2108.01390",
    "title": "Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer",
    "abstract": "Comments: We propose a novel and effective design for dynamic vision transformer to achieve better computational efficiency. The code is available at this https URL",
    "descriptor": "\nComments: We propose a novel and effective design for dynamic vision transformer to achieve better computational efficiency. The code is available at this https URL\n",
    "authors": [
      "Yifan Xu",
      "Zhijie Zhang",
      "Mengdan Zhang",
      "Kekai Sheng",
      "Ke Li",
      "Weiming Dong",
      "Liqing Zhang",
      "Changsheng Xu",
      "Xing Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01390"
  },
  {
    "id": "arXiv:2108.04539",
    "title": "BROS: A Pre-trained Language Model Focusing on Text and Layout for  Better Key Information Extraction from Documents",
    "abstract": "Comments: 13 pages, 9 figures",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Teakgyu Hong",
      "Donghyun Kim",
      "Mingi Ji",
      "Wonseok Hwang",
      "Daehyun Nam",
      "Sungrae Park"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.04539"
  },
  {
    "id": "arXiv:2108.05060",
    "title": "MultiTask-CenterNet (MCN): Efficient and Diverse Multitask Learning  using an Anchor Free Approach",
    "abstract": "Comments: Accepted by IEEE International Conference on Computer Vision (ICCV) 2021",
    "descriptor": "\nComments: Accepted by IEEE International Conference on Computer Vision (ICCV) 2021\n",
    "authors": [
      "Falk Heuer",
      "Sven Mantowsky",
      "Syed Saqib Bukhari",
      "Georg Schneider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.05060"
  },
  {
    "id": "arXiv:2108.05669",
    "title": "Bursting Scientific Filter Bubbles: Boosting Innovation via Novel Author  Discovery",
    "abstract": "Bursting Scientific Filter Bubbles: Boosting Innovation via Novel Author  Discovery",
    "descriptor": "",
    "authors": [
      "Jason Portenoy",
      "Marissa Radensky",
      "Jevin West",
      "Eric Horvitz",
      "Daniel Weld",
      "Tom Hope"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.05669"
  },
  {
    "id": "arXiv:2108.06009",
    "title": "Non-imaging real-time detection and tracking of fast-moving objects  using a single-pixel detector",
    "abstract": "Non-imaging real-time detection and tracking of fast-moving objects  using a single-pixel detector",
    "descriptor": "",
    "authors": [
      "Fengming Zhou",
      "Xuelei Shi",
      "Jie Chen",
      "Tianhang Tang",
      "Yiguang Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06009"
  },
  {
    "id": "arXiv:2108.07739",
    "title": "A New Backbone for Hyperspectral Image Reconstruction",
    "abstract": "Comments: add references",
    "descriptor": "\nComments: add references\n",
    "authors": [
      "Jiamian Wang",
      "Yulun Zhang",
      "Xin Yuan",
      "Yun Fu",
      "Zhiqiang Tao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.07739"
  },
  {
    "id": "arXiv:2108.07910",
    "title": "An Empirical Testing of Autonomous Vehicle Simulator System for Urban  Driving",
    "abstract": "Comments: 8 pages, 8 figures, 4 tables",
    "descriptor": "\nComments: 8 pages, 8 figures, 4 tables\n",
    "authors": [
      "John Seymour",
      "Dac-Thanh-Chuong Ho",
      "Quang-Hung Luu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.07910"
  },
  {
    "id": "arXiv:2108.07971",
    "title": "De-identification of Unstructured Clinical Texts from Sequence to  Sequence Perspective",
    "abstract": "Comments: Accepted in Poster Track for ACM CCS 2021",
    "descriptor": "\nComments: Accepted in Poster Track for ACM CCS 2021\n",
    "authors": [
      "Md Monowar Anjum",
      "Noman Mohammed",
      "Xiaoqian Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.07971"
  },
  {
    "id": "arXiv:2108.08143",
    "title": "Effective and scalable clustering of SARS-CoV-2 sequences",
    "abstract": "Comments: To Appear at: International Conference on Big Data Research (ICBDR)",
    "descriptor": "\nComments: To Appear at: International Conference on Big Data Research (ICBDR)\n",
    "authors": [
      "Sarwan Ali",
      "Tamkanat-E-Ali",
      "Muhammad Asad Khan",
      "Imdadullah Khan",
      "Murray Patterson"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08143"
  },
  {
    "id": "arXiv:2108.10461",
    "title": "Deterministic Dynamic Matching In Worst-Case Update Time",
    "abstract": "Deterministic Dynamic Matching In Worst-Case Update Time",
    "descriptor": "",
    "authors": [
      "Peter Kiss"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.10461"
  },
  {
    "id": "arXiv:2108.10814",
    "title": "On the intersections of finitely generated subgroups of free groups:  reduced rank to full rank",
    "abstract": "Comments: 30 pages, 5 figures",
    "descriptor": "\nComments: 30 pages, 5 figures\n",
    "authors": [
      "Marco Linton"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2108.10814"
  },
  {
    "id": "arXiv:2108.11601",
    "title": "Retrieval Augmented Code Generation and Summarization",
    "abstract": "Comments: accepted in EMNLP-Findings 2021",
    "descriptor": "\nComments: accepted in EMNLP-Findings 2021\n",
    "authors": [
      "Md Rizwan Parvez",
      "Wasi Uddin Ahmad",
      "Saikat Chakraborty",
      "Baishakhi Ray",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.11601"
  },
  {
    "id": "arXiv:2108.12229",
    "title": "ProtoInfoMax: Prototypical Networks with Mutual Information Maximization  for Out-of-Domain Detection",
    "abstract": "Comments: This manuscript will be available in ACL Anthology section EMNLP2021-Findings papers",
    "descriptor": "\nComments: This manuscript will be available in ACL Anthology section EMNLP2021-Findings papers\n",
    "authors": [
      "Iftitahu Ni'mah",
      "Meng Fang",
      "Vlado Menkovski",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.12229"
  },
  {
    "id": "arXiv:2108.12596",
    "title": "Representation Memorization for Fast Learning New Knowledge without  Forgetting",
    "abstract": "Representation Memorization for Fast Learning New Knowledge without  Forgetting",
    "descriptor": "",
    "authors": [
      "Fei Mi",
      "Tao Lin",
      "Boi Faltings"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2108.12596"
  },
  {
    "id": "arXiv:2108.12738",
    "title": "SummerTime: Text Summarization Toolkit for Non-experts",
    "abstract": "Comments: EMNLP 2021 Demo Track",
    "descriptor": "\nComments: EMNLP 2021 Demo Track\n",
    "authors": [
      "Ansong Ni",
      "Zhangir Azerbayev",
      "Mutethia Mutuma",
      "Troy Feng",
      "Yusen Zhang",
      "Tao Yu",
      "Ahmed Hassan Awadallah",
      "Dragomir Radev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.12738"
  },
  {
    "id": "arXiv:2108.12971",
    "title": "HELMHOLTZ: A Verifier for Tezos Smart Contracts Based on Refinement  Types",
    "abstract": "HELMHOLTZ: A Verifier for Tezos Smart Contracts Based on Refinement  Types",
    "descriptor": "",
    "authors": [
      "Yuki Nishida",
      "Hiromasa Saito",
      "Ran Chen",
      "Akira Kawata",
      "Jun Furuse",
      "Kohei Suenaga",
      "Atsushi Igarashi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.12971"
  },
  {
    "id": "arXiv:2108.13104",
    "title": "A Coinductive Version of Milner's Proof System for Regular Expressions  Modulo Bisimilarity",
    "abstract": "Comments: 31 pages (16 pages article and 15 pages appendix); v2: improved motivation coinductive proofs",
    "descriptor": "\nComments: 31 pages (16 pages article and 15 pages appendix); v2: improved motivation coinductive proofs\n",
    "authors": [
      "Clemens Grabmayer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2108.13104"
  },
  {
    "id": "arXiv:2108.13450",
    "title": "Modularity and Heavy-Tailed Degree Distributions",
    "abstract": "Comments: 11 pages, 5 figures",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Larry Wilson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.13450"
  },
  {
    "id": "arXiv:2108.13562",
    "title": "Adversarial Example Devastation and Detection on Speech Recognition  System by Adding Random Noise",
    "abstract": "Comments: 20 pages, 5 figures, Submitted to Multimedia Systems",
    "descriptor": "\nComments: 20 pages, 5 figures, Submitted to Multimedia Systems\n",
    "authors": [
      "Mingyu Dong",
      "Diqun Yan",
      "Yongkang Gong",
      "Rangding Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2108.13562"
  },
  {
    "id": "arXiv:2108.13751",
    "title": "A Search Engine for Discovery of Scientific Challenges and Directions",
    "abstract": "A Search Engine for Discovery of Scientific Challenges and Directions",
    "descriptor": "",
    "authors": [
      "Dan Lahav",
      "Jon Saad Falcon",
      "Bailey Kuehl",
      "Sophie Johnson",
      "Sravanthi Parasa",
      "Noam Shomron",
      "Duen Horng Chau",
      "Diyi Yang",
      "Eric Horvitz",
      "Daniel S. Weld",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.13751"
  },
  {
    "id": "arXiv:2109.00778",
    "title": "Better Self-training for Image Classification through Self-supervision",
    "abstract": "Comments: added link to code repository",
    "descriptor": "\nComments: added link to code repository\n",
    "authors": [
      "Attaullah Sahito",
      "Eibe Frank",
      "Bernhard Pfahringer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.00778"
  },
  {
    "id": "arXiv:2109.00788",
    "title": "Transfer of Pretrained Model Weights Substantially Improves  Semi-Supervised Image Classification",
    "abstract": "Comments: added link to code and data repo",
    "descriptor": "\nComments: added link to code and data repo\n",
    "authors": [
      "Attaullah Sahito",
      "Eibe Frank",
      "Bernhard Pfahringer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.00788"
  },
  {
    "id": "arXiv:2109.00794",
    "title": "Semi-Supervised Learning using Siamese Networks",
    "abstract": "Comments: added link of GitHub repository",
    "descriptor": "\nComments: added link of GitHub repository\n",
    "authors": [
      "Attaullah Sahito",
      "Eibe Frank",
      "Bernhard Pfahringer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.00794"
  },
  {
    "id": "arXiv:2109.01383",
    "title": "A Multi-Sensor Interface to Improve the Teaching and Learning Experience  in Arc Welding Training Tasks",
    "abstract": "A Multi-Sensor Interface to Improve the Teaching and Learning Experience  in Arc Welding Training Tasks",
    "descriptor": "",
    "authors": [
      "Hoi-Yin Lee",
      "Peng Zhou",
      "Jiangliu Wang",
      "Victor Wu",
      "David Navarro-Alarcon"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.01383"
  },
  {
    "id": "arXiv:2109.01850",
    "title": "Supervised Contrastive Learning for Multimodal Unreliable News Detection  in COVID-19 Pandemic",
    "abstract": "Comments: Accepted by the CIKM 2021",
    "descriptor": "\nComments: Accepted by the CIKM 2021\n",
    "authors": [
      "Wenjia Zhang",
      "Lin Gui",
      "Yulan He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.01850"
  },
  {
    "id": "arXiv:2109.01854",
    "title": "Predicting isocitrate dehydrogenase mutation status in glioma using  structural brain networks and graph neural networks",
    "abstract": "Comments: Accepted by Brain Lesion Workshop",
    "descriptor": "\nComments: Accepted by Brain Lesion Workshop\n",
    "authors": [
      "Yiran Wei",
      "Yonghao Li",
      "Xi Chen",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Chao Li",
      "Stephen J. Price"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.01854"
  },
  {
    "id": "arXiv:2109.02832",
    "title": "Besov Function Approximation and Binary Classification on  Low-Dimensional Manifolds Using Convolutional Residual Networks",
    "abstract": "Besov Function Approximation and Binary Classification on  Low-Dimensional Manifolds Using Convolutional Residual Networks",
    "descriptor": "",
    "authors": [
      "Hao Liu",
      "Minshuo Chen",
      "Tuo Zhao",
      "Wenjing Liao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02832"
  },
  {
    "id": "arXiv:2109.02860",
    "title": "GCsT: Graph Convolutional Skeleton Transformer for Action Recognition",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Ruwen Bai",
      "Min Li",
      "Bo Meng",
      "Fengfa Li",
      "Junxing Ren",
      "Miao Jiang",
      "Degang Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.02860"
  },
  {
    "id": "arXiv:2109.02862",
    "title": "ICCAD Special Session Paper: Quantum-Classical Hybrid Machine Learning  for Image Classification",
    "abstract": "ICCAD Special Session Paper: Quantum-Classical Hybrid Machine Learning  for Image Classification",
    "descriptor": "",
    "authors": [
      "Mahabubul Alam",
      "Satwik Kundu",
      "Rasit Onur Topaloglu",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02862"
  },
  {
    "id": "arXiv:2109.02899",
    "title": "Blockchains through ontologies: the case study of the Ethereum ERC721  standard in OASIS (Extended Version)",
    "abstract": "Comments: Extended version of Blockchains through ontologies: the case study of the Ethereum ERC721 standard in OASIS, Proceedings of IDC 2021",
    "descriptor": "\nComments: Extended version of Blockchains through ontologies: the case study of the Ethereum ERC721 standard in OASIS, Proceedings of IDC 2021\n",
    "authors": [
      "Giampaolo Bella",
      "Domenico Cantone",
      "Cristiano Longo",
      "Marianna Nicolosi-Asmundo",
      "Daniele Francesco Santamaria"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.02899"
  },
  {
    "id": "arXiv:2109.02952",
    "title": "QEnclave -- A practical solution for secure quantum cloud computing",
    "abstract": "Comments: 25 pages, 5 figures",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Yao Ma",
      "Elham Kashefi",
      "Myrto Arapinis",
      "Kaushik Chakraborty",
      "Marc Kaplan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.02952"
  },
  {
    "id": "arXiv:2109.02956",
    "title": "Smart Automotive Technology Adherence to the Law: (De)Constructing Road  Rules for Autonomous System Development, Verification and Safety",
    "abstract": "Smart Automotive Technology Adherence to the Law: (De)Constructing Road  Rules for Autonomous System Development, Verification and Safety",
    "descriptor": "",
    "authors": [
      "Scott McLachlan",
      "Martin Neil",
      "Kudakwashe Dube",
      "Ronny Bogani",
      "Norman Fenton",
      "Burkhard Schaffer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.02956"
  },
  {
    "id": "arXiv:2109.02972",
    "title": "Don't Go Far Off: An Empirical Study on Neural Poetry Translation",
    "abstract": "Comments: EMNLP 2021 Camera ready",
    "descriptor": "\nComments: EMNLP 2021 Camera ready\n",
    "authors": [
      "Tuhin Chakrabarty",
      "Arkadiy Saakyan",
      "Smaranda Muresan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.02972"
  },
  {
    "id": "arXiv:2109.03138",
    "title": "Interests, Difficulties, Sentiments, and Tool Usages of Concurrency  Developers: A Large-Scale Study on Stack Overflow",
    "abstract": "Interests, Difficulties, Sentiments, and Tool Usages of Concurrency  Developers: A Large-Scale Study on Stack Overflow",
    "descriptor": "",
    "authors": [
      "Mehdi Bagherzadeh",
      "Syed Ahmed",
      "Srilakshmi Sripathi",
      "Raffi Khatchadourian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.03138"
  },
  {
    "id": "arXiv:2109.03158",
    "title": "Idiosyncratic but not Arbitrary: Learning Idiolects in Online Registers  Reveals Distinctive yet Consistent Individual Styles",
    "abstract": "Comments: EMNLP 2021 main conference",
    "descriptor": "\nComments: EMNLP 2021 main conference\n",
    "authors": [
      "Jian Zhu",
      "David Jurgens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03158"
  },
  {
    "id": "arXiv:2109.03592",
    "title": "Strong Scaling of OpenACC enabled Nek5000 on several GPU based HPC  systems",
    "abstract": "Comments: 14 pages, 8 figures. Submitted to HPC-Asia 2022 conference",
    "descriptor": "\nComments: 14 pages, 8 figures. Submitted to HPC-Asia 2022 conference\n",
    "authors": [
      "Jonathan Vincent",
      "Jing Gong",
      "Martin Karp",
      "Adam Peplinski",
      "Niclas Jansson",
      "Artur Podobas",
      "Andreas Jocksch",
      "Jie Yao",
      "Fazle Hussain",
      "Stefano Markidis",
      "Matts Karlsson",
      "Dirk Pleiter",
      "Erwin Laure",
      "Philipp Schlatter"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.03592"
  },
  {
    "id": "arXiv:2109.03667",
    "title": "Energy Footprint of Blockchain Consensus Mechanisms Beyond Proof-of-Work",
    "abstract": "Energy Footprint of Blockchain Consensus Mechanisms Beyond Proof-of-Work",
    "descriptor": "",
    "authors": [
      "Moritz Platt",
      "Johannes Sedlmeir",
      "Daniel Platt",
      "Ulrich Gallersd\u00f6rfer",
      "Paolo Tasca",
      "Jiahua Xu",
      "Nikhil Vadgama",
      "Juan Ignacio Iba\u00f1ez"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.03667"
  },
  {
    "id": "arXiv:2109.03805",
    "title": "Panoptic nuScenes: A Large-Scale Benchmark for LiDAR Panoptic  Segmentation and Tracking",
    "abstract": "Comments: The benchmark is available at this https URL",
    "descriptor": "\nComments: The benchmark is available at this https URL\n",
    "authors": [
      "Whye Kit Fong",
      "Rohit Mohan",
      "Juana Valeria Hurtado",
      "Lubing Zhou",
      "Holger Caesar",
      "Oscar Beijbom",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03805"
  },
  {
    "id": "arXiv:2109.03813",
    "title": "Video2Skill: Adapting Events in Demonstration Videos to Skills in an  Environment using Cyclic MDP Homomorphisms",
    "abstract": "Video2Skill: Adapting Events in Demonstration Videos to Skills in an  Environment using Cyclic MDP Homomorphisms",
    "descriptor": "",
    "authors": [
      "Sumedh A Sontakke",
      "Sumegh Roychowdhury",
      "Mausoom Sarkar",
      "Nikaash Puri",
      "Balaji Krishnamurthy",
      "Laurent Itti"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03813"
  },
  {
    "id": "arXiv:2109.03848",
    "title": "Knowledge mining of unstructured information: application to  cyber-domain",
    "abstract": "Knowledge mining of unstructured information: application to  cyber-domain",
    "descriptor": "",
    "authors": [
      "Tuomas Takko",
      "Kunal Bhattacharya",
      "Martti Lehto",
      "Pertti Jalasvirta",
      "Aapo Cederberg",
      "Kimmo Kaski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03848"
  },
  {
    "id": "arXiv:2109.03858",
    "title": "Collecting a Large-Scale Gender Bias Dataset for Coreference Resolution  and Machine Translation",
    "abstract": "Comments: Accepted to Findings of EMNLP 2021",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Shahar Levy",
      "Koren Lazar",
      "Gabriel Stanovsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03858"
  },
  {
    "id": "arXiv:2109.03943",
    "title": "Sharp regret bounds for empirical Bayes and compound decision problems",
    "abstract": "Sharp regret bounds for empirical Bayes and compound decision problems",
    "descriptor": "",
    "authors": [
      "Yury Polyanskiy",
      "Yihong Wu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.03943"
  },
  {
    "id": "arXiv:2109.03945",
    "title": "Vulnerabilities and Attacks Against Industrial Control Systems and  Critical Infrastructures",
    "abstract": "Vulnerabilities and Attacks Against Industrial Control Systems and  Critical Infrastructures",
    "descriptor": "",
    "authors": [
      "Georgios Michail Makrakis",
      "Constantinos Kolias",
      "Georgios Kambourakis",
      "Craig Rieger",
      "Jacob Benjamin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.03945"
  },
  {
    "id": "arXiv:2109.03969",
    "title": "Multilingual Speech Recognition for Low-Resource Indian Languages using  Multi-Task conformer",
    "abstract": "Comments: 5 pages. Rejected from Interspeech 2021. arXiv admin note: substantial text overlap with arXiv:2109.03277",
    "descriptor": "\nComments: 5 pages. Rejected from Interspeech 2021. arXiv admin note: substantial text overlap with arXiv:2109.03277\n",
    "authors": [
      "Krishna D N"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.03969"
  },
  {
    "id": "arXiv:2109.03974",
    "title": "Constants of Motion: The Antidote to Chaos in Optimization and Game  Dynamics",
    "abstract": "Constants of Motion: The Antidote to Chaos in Optimization and Game  Dynamics",
    "descriptor": "",
    "authors": [
      "Georgios Piliouras",
      "Xiao Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03974"
  },
  {
    "id": "arXiv:2109.04173",
    "title": "Relating Graph Neural Networks to Structural Causal Models",
    "abstract": "Comments: Main paper: 7 pages, References: 2 pages, Appendix: 10 pages; Main paper: 5 figures, Appendix: 3 figures",
    "descriptor": "\nComments: Main paper: 7 pages, References: 2 pages, Appendix: 10 pages; Main paper: 5 figures, Appendix: 3 figures\n",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Petar Veli\u010dkovi\u0107",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04173"
  },
  {
    "id": "arXiv:2109.04204",
    "title": "A decision support framework for optimal vaccine distribution across a  multi-tier cold chain network",
    "abstract": "A decision support framework for optimal vaccine distribution across a  multi-tier cold chain network",
    "descriptor": "",
    "authors": [
      "Shanmukhi Sripada",
      "Ayush Jain",
      "Prasanna Ramamoorthy",
      "Varun Ramamohan"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04204"
  },
  {
    "id": "arXiv:2109.04258",
    "title": "A Derivative-based Parser Generator for Visibly Pushdown Grammars",
    "abstract": "A Derivative-based Parser Generator for Visibly Pushdown Grammars",
    "descriptor": "",
    "authors": [
      "Xiaodong Jia",
      "Ashish Kumar",
      "Gang Tan"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2109.04258"
  },
  {
    "id": "arXiv:2109.04313",
    "title": "Continuous Event-Line Constraint for Closed-Form Velocity Initialization",
    "abstract": "Continuous Event-Line Constraint for Closed-Form Velocity Initialization",
    "descriptor": "",
    "authors": [
      "Peng Xin",
      "Xu Wanting",
      "Yang Jiaqi",
      "Kneip Laurent"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04313"
  },
  {
    "id": "arXiv:2109.04360",
    "title": "Measuring Uncertainty in Signal Fingerprinting with Gaussian Processes  Going Deep",
    "abstract": "Comments: 8 pages, 10 figures; To be appear on the 2021 International Conference on Indoor Positioning and Indoor Navigation (IPIN)",
    "descriptor": "\nComments: 8 pages, 10 figures; To be appear on the 2021 International Conference on Indoor Positioning and Indoor Navigation (IPIN)\n",
    "authors": [
      "Ran Guan",
      "Andi Zhang",
      "Mengchao Li",
      "Yongliang Wang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04360"
  },
  {
    "id": "arXiv:2109.04374",
    "title": "IFBiD: Inference-Free Bias Detection",
    "abstract": "IFBiD: Inference-Free Bias Detection",
    "descriptor": "",
    "authors": [
      "Ignacio Serna",
      "Aythami Morales",
      "Julian Fierrez",
      "Javier Ortega-Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04374"
  },
  {
    "id": "arXiv:2109.04400",
    "title": "Cross-lingual Transfer for Text Classification with Dictionary-based  Heterogeneous Graph",
    "abstract": "Comments: Published in Findings of EMNLP 2021",
    "descriptor": "\nComments: Published in Findings of EMNLP 2021\n",
    "authors": [
      "Nuttapong Chairatanakul",
      "Noppayut Sriwatanasakdi",
      "Nontawat Charoenphakdee",
      "Xin Liu",
      "Tsuyoshi Murata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04400"
  },
  {
    "id": "arXiv:2109.04409",
    "title": "Reconstructing and grounding narrated instructional videos in 3D",
    "abstract": "Reconstructing and grounding narrated instructional videos in 3D",
    "descriptor": "",
    "authors": [
      "Dimitri Zhukov",
      "Ignacio Rocco",
      "Ivan Laptev",
      "Josef Sivic",
      "Johannes L. Sch\u00f6nberger",
      "Bugra Tekin",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04409"
  },
  {
    "id": "arXiv:2109.04463",
    "title": "Neural Latents Benchmark '21: Evaluating latent variable models of  neural population activity",
    "abstract": "Comments: Corrected missing line in Figure 3",
    "descriptor": "\nComments: Corrected missing line in Figure 3\n",
    "authors": [
      "Felix Pei",
      "Joel Ye",
      "David Zoltowski",
      "Anqi Wu",
      "Raeed H. Chowdhury",
      "Hansem Sohn",
      "Joseph E. O'Doherty",
      "Krishna V. Shenoy",
      "Matthew T. Kaufman",
      "Mark Churchland",
      "Mehrdad Jazayeri",
      "Lee E. Miller",
      "Jonathan Pillow",
      "Il Memming Park",
      "Eva L. Dyer",
      "Chethan Pandarinath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.04463"
  }
]
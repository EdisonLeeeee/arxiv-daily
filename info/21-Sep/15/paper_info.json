[
  {
    "id": "arXiv:2109.06168",
    "title": "Generatively Augmented Neural Network Watchdog for Image Classification  Networks",
    "abstract": "The identification of out-of-distribution data is vital to the deployment of\nclassification networks. For example, a generic neural network that has been\ntrained to differentiate between images of dogs and cats can only classify an\ninput as either a dog or a cat. If a picture of a car or a kumquat were to be\nsupplied to this classifier, the result would still be either a dog or a cat.\nIn order to mitigate this, techniques such as the neural network watchdog have\nbeen developed. The compression of the image input into the latent layer of the\nautoencoder defines the region of in-distribution in the image space. This\nin-distribution set of input data has a corresponding boundary in the image\nspace. The watchdog assesses whether inputs are in inside or outside this\nboundary. This paper demonstrates how to sharpen this boundary using generative\nnetwork training data augmentation thereby bettering the discrimination and\noverall performance of the watchdog.",
    "descriptor": "\nComments: 9 Pages, 22 Figures\n",
    "authors": [
      "Justin M. Bui",
      "Glauco A. Amigo",
      "Robert J. Marks II"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06168"
  },
  {
    "id": "arXiv:2109.06174",
    "title": "A Decentralized Electronic Prescription Management System",
    "abstract": "The ongoing digital transformation of the medical sector requires solutions\nthat are convenient and efficient for all stakeholders while protecting\npatients' sensitive data. One example involving both patients and health\nprofessionals that has already attracted design-oriented research are medical\nprescriptions. However, current implementations of electronic prescriptions\ntypically create centralized data silos, leaving user data vulnerable to\ncybersecurity incidents and impeding interoperability. Research has also\nproposed decentralized solutions based on blockchain technology as an\nalternative, but privacy-related challenges have either been ignored or shifted\nto complex or yet non-standardized solutions so far. This paper presents a\ndesign and implementation of a system for the exchange of electronic\nprescriptions based on the combination of two blockchains and a digital wallet\napp. Our solution combines the bilateral, verifiable, and privacy-focused\nexchange of information between doctors, patients, and pharmacies based on a\nverifiable credential with a token-based, anonymized double-spending check. Our\nqualitative and quantitative evaluations suggest that this architecture can\nimprove existing approaches to electronic prescription management by offering\npatients control over their data by design, a sufficient level of performance\nand scalability, and interoperability with emerging digital identity management\nsolutions for users, businesses, and institutions.",
    "descriptor": "",
    "authors": [
      "Vincent Schlatt",
      "Johannes Sedlmeir",
      "Janina Traue",
      "Fabiane V\u00f6lter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06174"
  },
  {
    "id": "arXiv:2109.06176",
    "title": "TREATED:Towards Universal Defense against Textual Adversarial Attacks",
    "abstract": "Recent work shows that deep neural networks are vulnerable to adversarial\nexamples. Much work studies adversarial example generation, while very little\nwork focuses on more critical adversarial defense. Existing adversarial\ndetection methods usually make assumptions about the adversarial example and\nattack method (e.g., the word frequency of the adversarial example, the\nperturbation level of the attack method). However, this limits the\napplicability of the detection method. To this end, we propose TREATED, a\nuniversal adversarial detection method that can defend against attacks of\nvarious perturbation levels without making any assumptions. TREATED identifies\nadversarial examples through a set of well-designed reference models. Extensive\nexperiments on three competitive neural networks and two widely used datasets\nshow that our method achieves better detection performance than baselines. We\nfinally conduct ablation studies to verify the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Bin Zhu",
      "Zhaoquan Gu",
      "Le Wang",
      "Zhihong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06176"
  },
  {
    "id": "arXiv:2109.06180",
    "title": "Deep Generative Models to Extend Active Directory Graphs with Honeypot  Users",
    "abstract": "Active Directory (AD) is a crucial element of large organizations, given its\ncentral role in managing access to resources. Since AD is used by all users in\nthe organization, it is hard to detect attackers. We propose to generate and\nplace fake users (honeyusers) in AD structures to help detect attacks. However,\nnot any honeyuser will attract attackers. Our method generates honeyusers with\na Variational Autoencoder that enriches the AD structure with well-positioned\nhoneyusers. It first learns the embeddings of the original nodes and edges in\nthe AD, then it uses a modified Bidirectional DAG-RNN to encode the parameters\nof the probability distribution of the latent space of node representations.\nFinally, it samples nodes from this distribution and uses an MLP to decide\nwhere the nodes are connected. The model was evaluated by the similarity of the\ngenerated AD with the original, by the positions of the new nodes, by the\nsimilarity with GraphRNN and finally by making real intruders attack the\ngenerated AD structure to see if they select the honeyusers. Results show that\nour machine learning model is good enough to generate well-placed honeyusers\nfor existing AD structures so that intruders are lured into them.",
    "descriptor": "\nComments: 2nd International Conference on Deep Learning Theory and Applications - DeLTA2021\n",
    "authors": [
      "Ondrej Lukas",
      "Sebastian Garcia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06180"
  },
  {
    "id": "arXiv:2109.06181",
    "title": "Towards Better Model Understanding with Path-Sufficient Explanations",
    "abstract": "Feature based local attribution methods are amongst the most prevalent in\nexplainable artificial intelligence (XAI) literature. Going beyond standard\ncorrelation, recently, methods have been proposed that highlight what should be\nminimally sufficient to justify the classification of an input (viz. pertinent\npositives). While minimal sufficiency is an attractive property, the resulting\nexplanations are often too sparse for a human to understand and evaluate the\nlocal behavior of the model, thus making it difficult to judge its overall\nquality. To overcome these limitations, we propose a novel method called\nPath-Sufficient Explanations Method (PSEM) that outputs a sequence of\nsufficient explanations for a given input of strictly decreasing size (or\nvalue) -- from original input to a minimally sufficient explanation -- which\ncan be thought to trace the local boundary of the model in a smooth manner,\nthus providing better intuition about the local model behavior for the specific\ninput. We validate these claims, both qualitatively and quantitatively, with\nexperiments that show the benefit of PSEM across all three modalities (image,\ntabular and text). A user study depicts the strength of the method in\ncommunicating the local behavior, where (many) users are able to correctly\ndetermine the prediction made by a model.",
    "descriptor": "",
    "authors": [
      "Ronny Luss",
      "Amit Dhurandhar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06181"
  },
  {
    "id": "arXiv:2109.06232",
    "title": "The Emergence of the Shape Bias Results from Communicative Efficiency",
    "abstract": "By the age of two, children tend to assume that new word categories are based\non objects' shape, rather than their color or texture; this assumption is\ncalled the shape bias. They are thought to learn this bias by observing that\ntheir caregiver's language is biased towards shape based categories. This\npresents a chicken and egg problem: if the shape bias must be present in the\nlanguage in order for children to learn it, how did it arise in language in the\nfirst place? In this paper, we propose that communicative efficiency explains\nboth how the shape bias emerged and why it persists across generations. We\nmodel this process with neural emergent language agents that learn to\ncommunicate about raw pixelated images. First, we show that the shape bias\nemerges as a result of efficient communication strategies employed by agents.\nSecond, we show that pressure brought on by communicative need is also\nnecessary for it to persist across generations; simply having a shape bias in\nan agent's input language is insufficient. These results suggest that, over and\nabove the operation of other learning strategies, the shape bias in human\nlearners may emerge and be sustained by communicative pressures.",
    "descriptor": "\nComments: Accepted at CoNLL 2021\n",
    "authors": [
      "Eva Portelance",
      "Michael C. Frank",
      "Dan Jurafsky",
      "Alessandro Sordoni",
      "Romain Laroche"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.06232"
  },
  {
    "id": "arXiv:2109.06234",
    "title": "Machine Learning for Online Algorithm Selection under Censored Feedback",
    "abstract": "In online algorithm selection (OAS), instances of an algorithmic problem\nclass are presented to an agent one after another, and the agent has to quickly\nselect a presumably best algorithm from a fixed set of candidate algorithms.\nFor decision problems such as satisfiability (SAT), quality typically refers to\nthe algorithm's runtime. As the latter is known to exhibit a heavy-tail\ndistribution, an algorithm is normally stopped when exceeding a predefined\nupper time limit. As a consequence, machine learning methods used to optimize\nan algorithm selection strategy in a data-driven manner need to deal with\nright-censored samples, a problem that has received little attention in the\nliterature so far. In this work, we revisit multi-armed bandit algorithms for\nOAS and discuss their capability of dealing with the problem. Moreover, we\nadapt them towards runtime-oriented losses, allowing for partially censored\ndata while keeping a space- and time-complexity independent of the time\nhorizon. In an extensive experimental evaluation on an adapted version of the\nASlib benchmark, we demonstrate that theoretically well-founded methods based\non Thompson sampling perform specifically strong and improve in comparison to\nexisting methods.",
    "descriptor": "",
    "authors": [
      "Alexander Tornede",
      "Viktor Bengs",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06234"
  },
  {
    "id": "arXiv:2109.06238",
    "title": "Extended Version of GTGraffiti: Spray Painting Graffiti Art from Human  Painting Motions with a Cable Driven Parallel Robot",
    "abstract": "We present a system that paints graffiti art with applications in art\npreservation, human-robot collaboration, and other tasks which require\nlarge-scale dynamic motion. The problem of painting graffiti in a human style\nis particularly challenging and requires a systems approach because the art and\nrobotics must be designed around each other. Our approach consists of three\nstages: artwork capture, robot hardware, and robot planning and control. We use\nmotion capture to capture collaborator painting motions which are then composed\nand processed into a time-varying linear feedback controller for a cable-driven\nparallel robot (CDPR) to execute. In this work, we will describe the capturing\nprocess, the design and construction of a purpose-built CDPR, and the software\nfor turning an artist's vision into control commands. While we acknowledge that\nfurther work is needed for a system which can perfectly recreate human artwork,\nour results represent a contribution by demonstrating that we can reproduce\nartist motions up to 2m/s and 10m/s$^2$ within 2cm to paint artworks.",
    "descriptor": "\nComments: Accompanying ICRA 2022 Submission\n",
    "authors": [
      "Gerry Chen",
      "Sereym Baek",
      "Juan-Diego Florez",
      "Wanli Qian",
      "Sang-won Leigh",
      "Seth Hutchinson",
      "Frank Dellaert"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06238"
  },
  {
    "id": "arXiv:2109.06241",
    "title": "Incremental Abstraction in Distributed Probabilistic SLAM Graphs",
    "abstract": "Scene graphs represent the key components of a scene in a compact and\nsemantically rich way, but are difficult to build during incremental SLAM\noperation because of the challenges of robustly identifying abstract scene\nelements and optimising continually changing, complex graphs. We present a\ndistributed, graph-based SLAM framework for incrementally building scene graphs\nbased on two novel components. First, we propose an incremental abstraction\nframework in which a neural network proposes abstract scene elements that are\nincorporated into the factor graph of a feature-based monocular SLAM system.\nScene elements are confirmed or rejected through optimisation and incrementally\nreplace the points yielding a more dense, semantic and compact representation.\nSecond, enabled by our novel routing procedure, we use Gaussian Belief\nPropagation (GBP) for distributed inference on a graph processor. The time per\niteration of GBP is structure-agnostic and we demonstrate the speed advantages\nover direct methods for inference of heterogeneous factor graphs. We run our\nsystem on real indoor datasets using planar abstractions and recover the major\nplanes with significant compression.",
    "descriptor": "\nComments: 8 pages. Project page: this https URL\n",
    "authors": [
      "Joseph Ortiz",
      "Talfan Evans",
      "Edgar Sucar",
      "Andrew J. Davison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06241"
  },
  {
    "id": "arXiv:2109.06243",
    "title": "KroneckerBERT: Learning Kronecker Decomposition for Pre-trained Language  Models via Knowledge Distillation",
    "abstract": "The development of over-parameterized pre-trained language models has made a\nsignificant contribution toward the success of natural language processing.\nWhile over-parameterization of these models is the key to their generalization\npower, it makes them unsuitable for deployment on low-capacity devices. We push\nthe limits of state-of-the-art Transformer-based pre-trained language model\ncompression using Kronecker decomposition. We use this decomposition for\ncompression of the embedding layer, all linear mappings in the multi-head\nattention, and the feed-forward network modules in the Transformer layer. We\nperform intermediate-layer knowledge distillation using the uncompressed model\nas the teacher to improve the performance of the compressed model. We present\nour KroneckerBERT, a compressed version of the BERT_BASE model obtained using\nthis framework. We evaluate the performance of KroneckerBERT on well-known NLP\nbenchmarks and show that for a high compression factor of 19 (5% of the size of\nthe BERT_BASE model), our KroneckerBERT outperforms state-of-the-art\ncompression methods on the GLUE. Our experiments indicate that the proposed\nmodel has promising out-of-distribution robustness and is superior to the\nstate-of-the-art compression methods on SQuAD.",
    "descriptor": "",
    "authors": [
      "Marzieh S. Tahaei",
      "Ella Charlaix",
      "Vahid Partovi Nia",
      "Ali Ghodsi",
      "Mehdi Rezagholizadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06243"
  },
  {
    "id": "arXiv:2109.06250",
    "title": "TTM: Terrain Traversability Mapping for Autonomous Excavator Navigation  in Unstructured Environments",
    "abstract": "We present Terrain Traversability Mapping (TTM), a real-time mapping approach\nfor terrain traversability estimation and path planning for autonomous\nexcavators in an unstructured environment. We propose an efficient\nlearning-based geometric method to extract terrain features from RGB images and\n3D pointclouds and incorporate them into a global map for planning and\nnavigation for autonomous excavation. Our method used the physical\ncharacteristics of the excavator, including maximum climbing degree and other\nmachine specifications, to determine the traversable area. Our method can adapt\nto changing environments and update the terrain information in real-time.\nMoreover, we prepare a novel dataset, Autonomous Excavator Terrain (AET)\ndataset, consisting of RGB images from construction sites with seven categories\naccording to navigability. We integrate our mapping approach with planning and\ncontrol modules in an autonomous excavator navigation system, which outperforms\nprevious method by 49.3% in terms of success rate based on existing planning\nschemes. With our mapping the excavator can navigate through unstructured\nenvironments consisting of deep pits, steep hills, rock piles, and other\ncomplex terrain features.",
    "descriptor": "",
    "authors": [
      "Tianrui Guan",
      "Zhenpeng He",
      "Dinesh Manocha",
      "Liangjun Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06250"
  },
  {
    "id": "arXiv:2109.06253",
    "title": "Multi-Sentence Resampling: A Simple Approach to Alleviate Dataset Length  Bias and Beam-Search Degradation",
    "abstract": "Neural Machine Translation (NMT) is known to suffer from a beam-search\nproblem: after a certain point, increasing beam size causes an overall drop in\ntranslation quality. This effect is especially pronounced for long sentences.\nWhile much work was done analyzing this phenomenon, primarily for\nautoregressive NMT models, there is still no consensus on its underlying cause.\nIn this work, we analyze errors that cause major quality degradation with large\nbeams in NMT and Automatic Speech Recognition (ASR). We show that a factor that\nstrongly contributes to the quality degradation with large beams is\n\\textit{dataset length-bias} - \\textit{NMT datasets are strongly biased towards\nshort sentences}. To mitigate this issue, we propose a new data augmentation\ntechnique -- \\textit{Multi-Sentence Resampling (MSR)}. This technique extends\nthe training examples by concatenating several sentences from the original\ndataset to make a long training example. We demonstrate that MSR significantly\nreduces degradation with growing beam size and improves final translation\nquality on the IWSTL$15$ En-Vi, IWSTL$17$ En-Fr, and WMT$14$ En-De datasets.",
    "descriptor": "",
    "authors": [
      "Ivan Provilkov",
      "Andrey Malinin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06253"
  },
  {
    "id": "arXiv:2109.06255",
    "title": "Implicit Regularization Effects of the Sobolev Norms in Image Processing",
    "abstract": "In this paper, we propose to use the general $L^2$-based Sobolev norms (i.e.,\n$H^s$ norms, $s\\in \\mathbb{R}$) to measure the data discrepancy due to noise in\nimage processing tasks that are formulated as optimization problems. As opposed\nto a popular trend of developing regularization methods, we emphasize that an\n\\textit{implicit} regularization effect can be achieved through the class of\nSobolev norms as the data-fitting term. Specifically, we analyze that the\nimplicit regularization comes from the weights that the $H^s$ norm imposes on\ndifferent frequency contents of an underlying image. We also build the\nconnections of such norms with the optimal transport-based metrics and the\nSobolev gradient-based methods, leading to a better understanding of functional\nspaces/metrics and the optimization process involved in image processing. We\nuse the fast Fourier transform to compute the $H^s$ norm efficiently and\ncombine it with the total variation regularization in the framework of the\nalternating direction method of multipliers (ADMM). Numerical results in both\ndenoising and deblurring support our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Yunan Yang",
      "Jingwei Hu",
      "Yifei Lou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.06255"
  },
  {
    "id": "arXiv:2109.06262",
    "title": "Evaluating Multiway Multilingual NMT in the Turkic Languages",
    "abstract": "Despite the increasing number of large and comprehensive machine translation\n(MT) systems, evaluation of these methods in various languages has been\nrestrained by the lack of high-quality parallel corpora as well as engagement\nwith the people that speak these languages. In this study, we present an\nevaluation of state-of-the-art approaches to training and evaluating MT systems\nin 22 languages from the Turkic language family, most of which being extremely\nunder-explored. First, we adopt the TIL Corpus with a few key improvements to\nthe training and the evaluation sets. Then, we train 26 bilingual baselines as\nwell as a multi-way neural MT (MNMT) model using the corpus and perform an\nextensive analysis using automatic metrics as well as human evaluations. We\nfind that the MNMT model outperforms almost all bilingual baselines in the\nout-of-domain test sets and finetuning the model on a downstream task of a\nsingle pair also results in a huge performance boost in both low- and\nhigh-resource scenarios. Our attentive analysis of evaluation criteria for MT\nmodels in Turkic languages also points to the necessity for further research in\nthis direction. We release the corpus splits, test sets as well as models to\nthe public.",
    "descriptor": "\nComments: 9 pages, 3 figures, 7 tables. To be presented at WMT 2021\n",
    "authors": [
      "Jamshidbek Mirzakhalov",
      "Anoop Babu",
      "Aigiz Kunafin",
      "Ahsan Wahab",
      "Behzod Moydinboyev",
      "Sardana Ivanova",
      "Mokhiyakhon Uzokova",
      "Shaxnoza Pulatova",
      "Duygu Ataman",
      "Julia Kreutzer",
      "Francis Tyers",
      "Orhan Firat",
      "John Licato",
      "Sriram Chellappan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06262"
  },
  {
    "id": "arXiv:2109.06264",
    "title": "Post-OCR Document Correction with large Ensembles of Character Sequence  Models",
    "abstract": "In this paper, we propose a novel method based on character\nsequence-to-sequence models to correct documents already processed with Optical\nCharacter Recognition (OCR) systems. The main contribution of this paper is a\nset of strategies to accurately process strings much longer than the ones used\nto train the sequence model while being sample- and resource-efficient,\nsupported by thorough experimentation. The strategy with the best performance\ninvolves splitting the input document in character n-grams and combining their\nindividual corrections into the final output using a voting scheme that is\nequivalent to an ensemble of a large number of sequence models. We further\ninvestigate how to weigh the contributions from each one of the members of this\nensemble. We test our method on nine languages of the ICDAR 2019 competition on\npost-OCR text correction and achieve a new state-of-the-art performance in five\nof them. Our code for post-OCR correction is shared at\nhttps://github.com/jarobyte91/post_ocr_correction.",
    "descriptor": "",
    "authors": [
      "Juan Ramirez-Orta",
      "Eduardo Xamena",
      "Ana Maguitman",
      "Evangelos Milios",
      "Axel J. Soto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06264"
  },
  {
    "id": "arXiv:2109.06265",
    "title": "Program-to-Circuit: Exploiting GNNs for Program Representation and  Circuit Translation",
    "abstract": "Circuit design is complicated and requires extensive domain-specific\nexpertise. One major obstacle stuck on the way to hardware agile development is\nthe considerably time-consuming process of accurate circuit quality evaluation.\nTo significantly expedite the circuit evaluation during the translation from\nbehavioral languages to circuit designs, we formulate it as a\nProgram-to-Circuit problem, aiming to exploit the representation power of graph\nneural networks (GNNs) by representing C/C++ programs as graphs. The goal of\nthis work is four-fold. First, we build a standard benchmark containing 40k\nC/C++ programs, each of which is translated to a circuit design with actual\nhardware quality metrics, aiming to facilitate the development of effective\nGNNs targeting this high-demand circuit design area. Second, 14\nstate-of-the-art GNN models are analyzed on the Program-to-Circuit problem. We\nidentify key design challenges of this problem, which should be carefully\nhandled but not yet solved by existing GNNs. The goal is to provide\ndomain-specific knowledge for designing GNNs with suitable inductive biases.\nThird, we discuss three sets of real-world benchmarks for GNN generalization\nevaluation, and analyze the performance gap between standard programs and the\nreal-case ones. The goal is to enable transfer learning from limited training\ndata to real-world large-scale circuit design problems. Fourth, the\nProgram-to-Circuit problem is a representative within the Program-to-X\nframework, a set of program-based analysis problems with various downstream\ntasks. The in-depth understanding of strength and weaknesses in applying GNNs\non Program-to-Circuit could largely benefit the entire family of Program-to-X.\nPioneering in this direction, we expect more GNN endeavors to revolutionize\nthis high-demand Program-to-Circuit problem and to enrich the expressiveness of\nGNNs on programs.",
    "descriptor": "",
    "authors": [
      "Nan Wu",
      "Huake He",
      "Yuan Xie",
      "Pan Li",
      "Cong Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06265"
  },
  {
    "id": "arXiv:2109.06266",
    "title": "Automatic Tuning of Tensorflow's CPU Backend using Gradient-Free  Optimization Algorithms",
    "abstract": "Modern deep learning (DL) applications are built using DL libraries and\nframeworks such as TensorFlow and PyTorch. These frameworks have complex\nparameters and tuning them to obtain good training and inference performance is\nchallenging for typical users, such as DL developers and data scientists.\nManual tuning requires deep knowledge of the user-controllable parameters of DL\nframeworks as well as the underlying hardware. It is a slow and tedious\nprocess, and it typically delivers sub-optimal solutions.\nIn this paper, we treat the problem of tuning parameters of DL frameworks to\nimprove training and inference performance as a black-box optimization problem.\nWe then investigate applicability and effectiveness of Bayesian optimization\n(BO), genetic algorithm (GA), and Nelder-Mead simplex (NMS) to tune the\nparameters of TensorFlow's CPU backend. While prior work has already\ninvestigated the use of Nelder-Mead simplex for a similar problem, it does not\nprovide insights into the applicability of other more popular algorithms.\nTowards that end, we provide a systematic comparative analysis of all three\nalgorithms in tuning TensorFlow's CPU backend on a variety of DL models. Our\nfindings reveal that Bayesian optimization performs the best on the majority of\nmodels. There are, however, cases where it does not deliver the best results.",
    "descriptor": "\nComments: To appear in the Proceedings of the Machine Learning on HPC Systems (MLHPCS) workshop held in conjunction with International Supercomputing Conference (ISC), July 2, 2021\n",
    "authors": [
      "Derssie Mebratu",
      "Niranjan Hasabnis",
      "Pietro Mercati",
      "Gaurit Sharma",
      "Shamima Najnin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.06266"
  },
  {
    "id": "arXiv:2109.06267",
    "title": "Are Group Acknowledgements Worth Anything in IEEE 802.15.4 DSME: A  Comparative Analysis",
    "abstract": "For data collection scenarios in the Industrial Internet of Things, wireless\ncommunication provides a cost-effective and easy-to-deploy alternative to wired\nnetworks. The main focus lies on energy efficiency and reliability, as many\ndevices are battery operated. IEEE 802.15.4 DSME enhances reliability by\nacknowledging each packet individually, imposing an overhead for each\ntransmitted packet, and increasing energy consumption. In networks with little\ninterference, it may be beneficial to aggregate the acknowledgments for\nmultiple nodes and broadcast them in a compressed format to all nodes in the\nneighborhood. The IEEE 802.15.4 2012 standard describes such a group\nacknowledgment scheme which, however, disappears in later iterations of the\nstandard. This paper compares different group acknowledgment schemes and\nproposes a novel group acknowledgment scheme with the goal to examine whether\ngroup acknowledgments constitute a viable alternative to regular\nacknowledgments in reliable data-collection scenarios. Our analysis suggests\nthat apart from a few cases, GACKs do not constitute a valid alternative to the\ndirect acknowledgement of data packets.",
    "descriptor": "",
    "authors": [
      "Florian Meyer",
      "Phil Malessa",
      "Jan Niklas Diercks",
      "Volker Turau"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.06267"
  },
  {
    "id": "arXiv:2109.06270",
    "title": "STraTA: Self-Training with Task Augmentation for Better Few-shot  Learning",
    "abstract": "Despite their recent successes in tackling many NLP tasks, large-scale\npre-trained language models do not perform as well in few-shot settings where\nonly a handful of training examples are available. To address this shortcoming,\nwe propose STraTA, which stands for Self-Training with Task Augmentation, an\napproach that builds on two key ideas for effective leverage of unlabeled data.\nFirst, STraTA uses task augmentation, a novel technique that synthesizes a\nlarge amount of data for auxiliary-task fine-tuning from target-task unlabeled\ntexts. Second, STraTA performs self-training by further fine-tuning the strong\nbase model created by task augmentation on a broad distribution of\npseudo-labeled data. Our experiments demonstrate that STraTA can substantially\nimprove sample efficiency across 12 few-shot benchmarks. Remarkably, on the\nSST-2 sentiment dataset, STraTA, with only 8 training examples per class,\nachieves comparable results to standard fine-tuning with 67K training examples.\nOur analyses reveal that task augmentation and self-training are both\ncomplementary and independently effective.",
    "descriptor": "\nComments: Accepted as a conference paper at EMNLP 2021, 17 pages, 3 figures, 11 tables\n",
    "authors": [
      "Tu Vu",
      "Minh-Thang Luong",
      "Quoc V. Le",
      "Grady Simon",
      "Mohit Iyyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06270"
  },
  {
    "id": "arXiv:2109.06275",
    "title": "MindCraft: Theory of Mind Modeling for Situated Dialogue in  Collaborative Tasks",
    "abstract": "An ideal integration of autonomous agents in a human world implies that they\nare able to collaborate on human terms. In particular, theory of mind plays an\nimportant role in maintaining common ground during human collaboration and\ncommunication. To enable theory of mind modeling in situated interactions, we\nintroduce a fine-grained dataset of collaborative tasks performed by pairs of\nhuman subjects in the 3D virtual blocks world of Minecraft. It provides\ninformation that captures partners' beliefs of the world and of each other as\nan interaction unfolds, bringing abundant opportunities to study human\ncollaborative behaviors in situated language communication. As a first step\ntowards our goal of developing embodied AI agents able to infer belief states\nof collaborative partners in situ, we build and present results on\ncomputational models for several theory of mind tasks.",
    "descriptor": "",
    "authors": [
      "Cristian-Paul Bara",
      "Sky CH-Wang",
      "Joyce Chai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06275"
  },
  {
    "id": "arXiv:2109.06279",
    "title": "Interactive All-Hex Meshing via Cuboid Decomposition",
    "abstract": "Standard PolyCube-based hexahedral (hex) meshing methods aim to deform the\ninput domain into an axis-aligned PolyCube volume with integer corners; if this\ndeformation is bijective, then applying the inverse map to the voxelized\nPolyCube yields a valid hex mesh. A key challenge in these methods is to\nmaintain the bijectivity of the PolyCube deformation, thus reducing the\nrobustness of these algorithms. In this work, we present an interactive\npipeline for hex meshing that sidesteps this challenge by using a new\nrepresentation of PolyCubes as unions of cuboids. We begin by deforming the\ninput tetrahedral mesh into a near-PolyCube domain whose faces are close but\nnot perfectly aligned to the major axis directions. We then build a PolyCube by\noptimizing the layout of a set of cuboids with user guidance to closely fit the\ndeformed domain. Finally, we construct an inversion-free pullback map from the\nvoxelized PolyCube to the input domain while optimizing for mesh quality\nmetrics. We allow extensive user control over each stage, such as editing the\nvoxelized PolyCube, positioning surface vertices, and exploring the trade-off\namong competing quality metrics, while also providing automatic alternatives.\nWe validate our method on over one hundred shapes, including models that are\nchallenging for past PolyCube-based and frame-field-based methods. Our pipeline\nreliably produces hex meshes with quality on par with or better than\nstate-of-the-art. We additionally conduct a user study with 20 participants in\nwhich the majority prefer hex meshes they make using our tool to the ones from\nautomatic state-of-the-art methods. This demonstrates the need for intuitive\ninteractive hex meshing tools where the user can dictate the priorities of\ntheir mesh.",
    "descriptor": "",
    "authors": [
      "Lingxiao Li",
      "Paul Zhang",
      "Dmitriy Smirnov",
      "S. Mazdak Abulnaga",
      "Justin Solomon"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.06279"
  },
  {
    "id": "arXiv:2109.06283",
    "title": "Graph Algorithms for Multiparallel Word Alignment",
    "abstract": "With the advent of end-to-end deep learning approaches in machine\ntranslation, interest in word alignments initially decreased; however, they\nhave again become a focus of research more recently. Alignments are useful for\ntypological research, transferring formatting like markup to translated texts,\nand can be used in the decoding of machine translation systems. At the same\ntime, massively multilingual processing is becoming an important NLP scenario,\nand pretrained language and machine translation models that are truly\nmultilingual are proposed. However, most alignment algorithms rely on bitexts\nonly and do not leverage the fact that many parallel corpora are multiparallel.\nIn this work, we exploit the multiparallelity of corpora by representing an\ninitial set of bilingual alignments as a graph and then predicting additional\nedges in the graph. We present two graph algorithms for edge prediction: one\ninspired by recommender systems and one based on network link prediction. Our\nexperimental results show absolute improvements in $F_1$ of up to 28% over the\nbaseline bilingual word aligner in different datasets.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Ayyoob Imani",
      "Masoud Jalili Sabet",
      "L\u00fctfi Kerem \u015eenel",
      "Philipp Dufter",
      "Fran\u00e7ois Yvon",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06283"
  },
  {
    "id": "arXiv:2109.06287",
    "title": "Project 412Connect: Bridging Students and Communities",
    "abstract": "In this work, we describe some of the challenges Black-owned businesses face\nin the United States, and specifically in the city of Pittsburgh. Taking into\naccount local dynamics and the communicated desires of Black-owned businesses\nin the Pittsburgh region, we determine that university students represent an\nunder-utilized market for these businesses. We investigate the root causes for\nthis inefficiency and design and implement a platform, 412Connect\n(https://www.412connect.org/), to increase online support for Pittsburgh\nBlack-owned businesses from students in the Pittsburgh university community.\nThe site operates by coordinating interactions between student users and\nparticipating businesses via targeted recommendations. For platform designers,\nwe describe the project from its conception, paying special attention to our\nmotivation and design choices. Our design choices are aided by two simple,\nnovel models for badge design and recommendation systems that may be of\ntheoretical interest. Along the way we highlight challenges and lessons from\ncoordinating a grassroots volunteer project working in conjunction with\ncommunity partners, and the opportunities and pitfalls of engaged scholarship.",
    "descriptor": "\nComments: To be published in EAAMO 2021\n",
    "authors": [
      "Alex DiChristofano",
      "Michael L. Hamilton",
      "Sera Linardi",
      "Mara F. McCloud"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.06287"
  },
  {
    "id": "arXiv:2109.06288",
    "title": "Striking a new balance in accuracy and simplicity with the Probabilistic  Inductive Miner",
    "abstract": "Numerous process discovery techniques exist for generating process models\nthat describe recorded executions of business processes. The models are meant\nto generalize executions into human-understandable modeling patterns, notably\nparallelism, and enable rigorous analysis of process deviations. However,\nwell-defined models with parallelism returned by existing techniques are often\ntoo complex or generalize the recorded behavior too strongly to be trusted in a\npractical business context. We bridge this gap by introducing the Probabilistic\nInductive Miner (PIM) based on the Inductive Miner framework. PIM compares in\neach step the most probable operators and structures based on frequency\ninformation in the data, which results in block-structured models with\nsignificantly higher accuracy. All design choices in PIM are based on business\ncontext requirements obtained through a user study with industrial process\nmining experts. PIM is evaluated quantitatively and in an novel kind of\nempirical study comparing users' trust in discovered model structures. The\nevaluations show that PIM strikes a unique trade-off between model accuracy and\nmodel complexity, that is conclusively preferred by users over all\nstate-of-the-art process discovery methods.",
    "descriptor": "\nComments: accepted at IEEE International Conference on Process Mining (ICPM) 2021, submitted version\n",
    "authors": [
      "Dennis Brons",
      "Roeland Scheepens",
      "Dirk Fahland"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.06288"
  },
  {
    "id": "arXiv:2109.06296",
    "title": "Monocular Camera Localization for Automated Vehicles Using Image  Retrieval",
    "abstract": "We address the problem of finding the current position and heading angle of\nan autonomous vehicle in real-time using a single camera. Compared to methods\nwhich require LiDARs and high definition (HD) 3D maps in real-time, the\nproposed approach is easily scalable and computationally efficient, at the\nprice of lower precision.\nThe new method combines and adapts existing algorithms in three different\nfields: image retrieval, mapping database, and particle filtering. The result\nis a simple, real-time localization method using an image retrieval method\nwhose performance is comparable to other monocular camera localization methods\nwhich use a map built with LiDARs.\nWe evaluate the proposed method using the KITTI odometry dataset and via\nclosed-loop experiments with an indoor 1:10 autonomous vehicle. The tests\ndemonstrate real-time capability and a 10cm level accuracy. Also, experimental\nresults of the closed-loop indoor tests show the presence of a positive\nfeedback loop between the localization error and the control error. Such\nphenomena is analysed in details at the end of the article.",
    "descriptor": "",
    "authors": [
      "Eunhyek Joa",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06296"
  },
  {
    "id": "arXiv:2109.06302",
    "title": "Developers Who Vlog: Dismantling Stereotypes through Community and  Identity",
    "abstract": "Developers are more than \"nerds behind computers all day\", they lead a normal\nlife, and not all take the traditional path to learn programming. However, the\npublic still sees software development as a profession for \"math wizards\". To\nlearn more about this special type of knowledge worker from their first-person\nperspective, we conducted three studies to learn how developers describe a day\nin their life through vlogs on YouTube and how these vlogs were received by the\nbroader community. We first interviewed 16 developers who vlogged to identify\ntheir motivations for creating this content and their intention behind what\nthey chose to portray. Second, we analyzed 130 vlogs (video blogs) to\nunderstand the range of the content conveyed through videos. Third, we analyzed\n1176 comments from the 130 vlogs to understand the impact the vlogs have on the\naudience. We found that developers were motivated to promote and build a\ndiverse community, by sharing different aspects of life that define their\nidentity, and by creating awareness about learning and career opportunities in\ncomputing. They used vlogs to share a variety of how software developers work\nand live -- showcasing often unseen experiences, including intimate moments\nfrom their personal life. From our comment analysis, we found that the vlogs\nwere valuable to the audience to find information and seek advice. Commenters\nsought opportunities to connect with others over shared triumphs and trials\nthey faced that were also shown in the vlogs. As a central theme, we found that\ndevelopers use vlogs to challenge the misconceptions and stereotypes around\ntheir identity, work-life, and well-being. These social stigmas are obstacles\nto an inclusive and accepting community and can deter people from choosing\nsoftware development as a career. We also discuss the implications of using\nvlogs to support developers, researchers, and beyond.",
    "descriptor": "\nComments: 33 pages, 2 tables, 3 figures\n",
    "authors": [
      "Souti Chattopadhyay",
      "Denae Ford",
      "Thomas Zimmermann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.06302"
  },
  {
    "id": "arXiv:2109.06304",
    "title": "Phrase-BERT: Improved Phrase Embeddings from BERT with an Application to  Corpus Exploration",
    "abstract": "Phrase representations derived from BERT often do not exhibit complex phrasal\ncompositionality, as the model relies instead on lexical similarity to\ndetermine semantic relatedness. In this paper, we propose a contrastive\nfine-tuning objective that enables BERT to produce more powerful phrase\nembeddings. Our approach (Phrase-BERT) relies on a dataset of diverse phrasal\nparaphrases, which is automatically generated using a paraphrase generation\nmodel, as well as a large-scale dataset of phrases in context mined from the\nBooks3 corpus. Phrase-BERT outperforms baselines across a variety of\nphrase-level similarity tasks, while also demonstrating increased lexical\ndiversity between nearest neighbors in the vector space. Finally, as a case\nstudy, we show that Phrase-BERT embeddings can be easily integrated with a\nsimple autoencoder to build a phrase-based neural topic model that interprets\ntopics as mixtures of words and phrases by performing a nearest neighbor search\nin the embedding space. Crowdsourced evaluations demonstrate that this\nphrase-based topic model produces more coherent and meaningful topics than\nbaseline word and phrase-level topic models, further validating the utility of\nPhrase-BERT.",
    "descriptor": "\nComments: EMNLP 2021 Conference Camera Ready\n",
    "authors": [
      "Shufan Wang",
      "Laure Thompson",
      "Mohit Iyyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06304"
  },
  {
    "id": "arXiv:2109.06306",
    "title": "BERT for Target Apps Selection: Analyzing the Diversity and Performance  of BERT in Unified Mobile Search",
    "abstract": "A unified mobile search framework aims to identify the mobile apps that can\nsatisfy a user's information need and route the user's query to them. Previous\nwork has shown that resource descriptions for mobile apps are sparse as they\nrely on the app's previous queries. This problem puts certain apps in dominance\nand leaves out the resource-scarce apps from the top ranks. In this case, we\nneed a ranker that goes beyond simple lexical matching. Therefore, our goal is\nto study the extent of a BERT-based ranker's ability to improve the quality and\ndiversity of app selection. To this end, we compare the results of the\nBERT-based ranker with other information retrieval models, focusing on the\nanalysis of selected apps diversification. Our analysis shows that the\nBERT-based ranker selects more diverse apps while improving the quality of\nbaseline results by selecting the relevant apps such as Facebook and Contacts\nfor more personal queries and decreasing the bias towards the dominant\nresources such as the Google Search app.",
    "descriptor": "",
    "authors": [
      "Negin Ghasemi",
      "Mohammad Aliannejadi",
      "Djoerd Hiemstra"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.06306"
  },
  {
    "id": "arXiv:2109.06308",
    "title": "Mitigating Catastrophic Forgetting in Scheduled Sampling with Elastic  Weight Consolidation in Neural Machine Translation",
    "abstract": "Despite strong performance in many sequence-to-sequence tasks, autoregressive\nmodels trained with maximum likelihood estimation suffer from exposure bias,\ni.e. a discrepancy between the ground-truth prefixes used during training and\nthe model-generated prefixes used at inference time. Scheduled sampling is a\nsimple and often empirically successful approach which addresses this issue by\nincorporating model-generated prefixes into the training process. However, it\nhas been argued that it is an inconsistent training objective leading to models\nignoring the prefixes altogether. In this paper, we conduct systematic\nexperiments and find that it ameliorates exposure bias by increasing model\nreliance on the input sequence. We also observe that as a side-effect, it\nworsens performance when the model-generated prefix is correct, a form of\ncatastrophic forgetting. We propose using Elastic Weight Consolidation as\ntrade-off between mitigating exposure bias and retaining output quality.\nExperiments on two IWSLT'14 translation tasks demonstrate that our approach\nalleviates catastrophic forgetting and significantly improves BLEU compared to\nstandard scheduled sampling.",
    "descriptor": "",
    "authors": [
      "Michalis Korakakis",
      "Andreas Vlachos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06308"
  },
  {
    "id": "arXiv:2109.06309",
    "title": "Fairness and Data Protection Impact Assessments",
    "abstract": "In this paper, we critically examine the effectiveness of the requirement to\nconduct a Data Protection Impact Assessment (DPIA) in Article 35 of the General\nData Protection Regulation (GDPR) in light of fairness metrics. Through this\nanalysis, we explore the role of the fairness principle as introduced in\nArticle 5(1)(a) and its multifaceted interpretation in the obligation to\nconduct a DPIA. Our paper argues that although there is a significant\ntheoretical role for the considerations of fairness in the DPIA process, an\nanalysis of the various guidance documents issued by data protection\nauthorities on the obligation to conduct a DPIA reveals that they rarely\nmention the fairness principle in practice.",
    "descriptor": "",
    "authors": [
      "Atoosa Kasirzadeh",
      "Damian Clifford"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.06309"
  },
  {
    "id": "arXiv:2109.06310",
    "title": "State Relevance for Off-Policy Evaluation",
    "abstract": "Importance sampling-based estimators for off-policy evaluation (OPE) are\nvalued for their simplicity, unbiasedness, and reliance on relatively few\nassumptions. However, the variance of these estimators is often high,\nespecially when trajectories are of different lengths. In this work, we\nintroduce Omitting-States-Irrelevant-to-Return Importance Sampling (OSIRIS), an\nestimator which reduces variance by strategically omitting likelihood ratios\nassociated with certain states. We formalize the conditions under which OSIRIS\nis unbiased and has lower variance than ordinary importance sampling, and we\ndemonstrate these properties empirically.",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Simon P. Shen",
      "Yecheng Jason Ma",
      "Omer Gottesman",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06310"
  },
  {
    "id": "arXiv:2109.06312",
    "title": "Pre-emptive learning-to-defer for sequential medical decision-making  under uncertainty",
    "abstract": "We propose SLTD (`Sequential Learning-to-Defer') a framework for\nlearning-to-defer pre-emptively to an expert in sequential decision-making\nsettings. SLTD measures the likelihood of improving value of deferring now\nversus later based on the underlying uncertainty in dynamics. In particular, we\nfocus on the non-stationarity in the dynamics to accurately learn the deferral\npolicy. We demonstrate our pre-emptive deferral can identify regions where the\ncurrent policy has a low probability of improving outcomes. SLTD outperforms\nexisting non-sequential learning-to-defer baselines, whilst reducing overall\nuncertainty on multiple synthetic and real-world simulators with non-stationary\ndynamics. We further derive and decompose the propagated (long-term)\nuncertainty for interpretation by the domain expert to provide an indication of\nwhen the model's performance is reliable.",
    "descriptor": "",
    "authors": [
      "Shalmali Joshi",
      "Sonali Parbhoo",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06312"
  },
  {
    "id": "arXiv:2109.06316",
    "title": "Learning Constraints and Descriptive Segmentation for Subevent Detection",
    "abstract": "Event mentions in text correspond to real-world events of varying degrees of\ngranularity. The task of subevent detection aims to resolve this granularity\nissue, recognizing the membership of multi-granular events in event complexes.\nSince knowing the span of descriptive contexts of event complexes helps infer\nthe membership of events, we propose the task of event-based text segmentation\n(EventSeg) as an auxiliary task to improve the learning for subevent detection.\nTo bridge the two tasks together, we propose an approach to learning and\nenforcing constraints that capture dependencies between subevent detection and\nEventSeg prediction, as well as guiding the model to make globally consistent\ninference. Specifically, we adopt Rectifier Networks for constraint learning\nand then convert the learned constraints to a regularization term in the loss\nfunction of the neural model. Experimental results show that the proposed\nmethod outperforms baseline methods by 2.3% and 2.5% on benchmark datasets for\nsubevent detection, HiEve and IC, respectively, while achieving a decent\nperformance on EventSeg prediction.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Haoyu Wang",
      "Hongming Zhang",
      "Muhao Chen",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06316"
  },
  {
    "id": "arXiv:2109.06317",
    "title": "Project Pipeline: Preservation, Persistence, and Performance",
    "abstract": "Preservation pipelines demonstrate extended value when digitized content is\nalso computation ready. Expanding this to historical controlled vocabularies\npublished in analog format requires additional steps if they are to be fully\nleveraged for research. This paper reports on work addressing this challenge.\nWe report on a pipeline and project progress addressing three key goals: 1)\ntransforming the 1910 Library of Congress Subject Headings (LCSH) to the Simple\nKnowledge Organization System (SKOS) linked data standard, 2) implementing\npersistent identifiers (PIDs) and launching our prototype ARK resolver, and 3)\nimporting the 1910 LCSH into the Helping Interdisciplinary Vocabulary\nEngineering (HIVE) System to support automatic metadata generation and\nscholarly analysis of the historical record. The discussion considers the\nimplications of our work in the broader context of preservation, and the\nconclusion summarizes our work and identifies next steps.",
    "descriptor": "\nComments: 5 pages, 2 figures. 17th International Conference on Digital Preservation (iPRES) 2021, Beijing, China\n",
    "authors": [
      "Jane Greenberg",
      "Christopher B. Rauch",
      "Mat Kelly"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2109.06317"
  },
  {
    "id": "arXiv:2109.06321",
    "title": "Mitigating Sampling Bias and Improving Robustness in Active Learning",
    "abstract": "This paper presents simple and efficient methods to mitigate sampling bias in\nactive learning while achieving state-of-the-art accuracy and model robustness.\nWe introduce supervised contrastive active learning by leveraging the\ncontrastive loss for active learning under a supervised setting. We propose an\nunbiased query strategy that selects informative data samples of diverse\nfeature representations with our methods: supervised contrastive active\nlearning (SCAL) and deep feature modeling (DFM). We empirically demonstrate our\nproposed methods reduce sampling bias, achieve state-of-the-art accuracy and\nmodel calibration in an active learning setup with the query computation 26x\nfaster than Bayesian active learning by disagreement and 11x faster than\nCoreSet. The proposed SCAL method outperforms by a big margin in robustness to\ndataset shift and out-of-distribution.",
    "descriptor": "\nComments: Human in the Loop Learning workshop at International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Ranganath Krishnan",
      "Alok Sinha",
      "Nilesh Ahuja",
      "Mahesh Subedar",
      "Omesh Tickoo",
      "Ravi Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06321"
  },
  {
    "id": "arXiv:2109.06323",
    "title": "Stochastic Observer for SLAM on the Lie Group",
    "abstract": "A robust nonlinear stochastic observer for simultaneous localization and\nmapping (SLAM) is proposed using the available uncertain measurements of\nangular velocity, translational velocity, and features. The proposed observer\nis posed on the Lie Group of $\\mathbb{SLAM}_{n}\\left(3\\right)$ to mimic the\ntrue stochastic SLAM dynamics. The proposed approach considers the velocity\nmeasurements to be attached with an unknown bias and an unknown Gaussian noise.\nThe proposed SLAM observer ensures that the closed loop error signals are\nsemi-globally uniformly ultimately bounded. Simulation results demonstrates the\nefficiency and robustness of the proposed approach, revealing its ability to\nlocalize the unknown vehicle, as well as mapping the unknown environment given\nmeasurements obtained from low-cost units.",
    "descriptor": "",
    "authors": [
      "Marium Tawhid",
      "Ajay Singh Ludher",
      "Hashim A. Hashim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06323"
  },
  {
    "id": "arXiv:2109.06324",
    "title": "A Massively Multilingual Analysis of Cross-linguality in Shared  Embedding Space",
    "abstract": "In cross-lingual language models, representations for many different\nlanguages live in the same space. Here, we investigate the linguistic and\nnon-linguistic factors affecting sentence-level alignment in cross-lingual\npretrained language models for 101 languages and 5,050 language pairs. Using\nBERT-based LaBSE and BiLSTM-based LASER as our models, and the Bible as our\ncorpus, we compute a task-based measure of cross-lingual alignment in the form\nof bitext retrieval performance, as well as four intrinsic measures of vector\nspace alignment and isomorphism. We then examine a range of linguistic,\nquasi-linguistic, and training-related features as potential predictors of\nthese alignment metrics. The results of our analyses show that word order\nagreement and agreement in morphological complexity are two of the strongest\nlinguistic predictors of cross-linguality. We also note in-family training data\nas a stronger predictor than language-specific training data across the board.\nWe verify some of our linguistic findings by looking at the effect of\nmorphological segmentation on English-Inuktitut alignment, in addition to\nexamining the effect of word order agreement on isomorphism for 66 zero-shot\nlanguage pairs from a different corpus. We make the data and code for our\nexperiments publicly available.",
    "descriptor": "\nComments: 15 pages, 8 figures, EMNLP 2021\n",
    "authors": [
      "Alex Jones",
      "William Yang Wang",
      "Kyle Mahowald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06324"
  },
  {
    "id": "arXiv:2109.06325",
    "title": "safe-control-gym: a Unified Benchmark Suite for Safe Learning-based  Control and Reinforcement Learning",
    "abstract": "In recent years, reinforcement learning and learning-based control -- as well\nas the study of their safety, crucial for deployment in real-world robots --\nhave gained significant traction. However, to adequately gauge the progress and\napplicability of new results, we need the tools to equitably compare the\napproaches proposed by the controls and reinforcement learning communities.\nHere, we propose a new open-source benchmark suite, called safe-control-gym.\nOur starting point is OpenAI's Gym API, which is one of the de facto standard\nin reinforcement learning research. Yet, we highlight the reasons for its\nlimited appeal to control theory researchers -- and safe control, in\nparticular. E.g., the lack of analytical models and constraint specifications.\nThus, we propose to extend this API with (i) the ability to specify (and query)\nsymbolic models and constraints and (ii) introduce simulated disturbances in\nthe control inputs, measurements, and inertial properties. We provide\nimplementations for three dynamic systems -- the cart-pole, 1D, and 2D\nquadrotor -- and two control tasks -- stabilization and trajectory tracking. To\ndemonstrate our proposal -- and in an attempt to bring research communities\ncloser together -- we show how to use safe-control-gym to quantitatively\ncompare the control performance, data efficiency, and safety of multiple\napproaches from the areas of traditional control, learning-based control, and\nreinforcement learning.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Zhaocong Yuan",
      "Adam W. Hall",
      "Siqi Zhou",
      "Lukas Brunke",
      "Melissa Greeff",
      "Jacopo Panerati",
      "Angela P. Schoellig"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06325"
  },
  {
    "id": "arXiv:2109.06327",
    "title": "Evaluating Transferability of BERT Models on Uralic Languages",
    "abstract": "Transformer-based language models such as BERT have outperformed previous\nmodels on a large number of English benchmarks, but their evaluation is often\nlimited to English or a small number of well-resourced languages. In this work,\nwe evaluate monolingual, multilingual, and randomly initialized language models\nfrom the BERT family on a variety of Uralic languages including Estonian,\nFinnish, Hungarian, Erzya, Moksha, Karelian, Livvi, Komi Permyak, Komi Zyrian,\nNorthern S\\'ami, and Skolt S\\'ami. When monolingual models are available\n(currently only et, fi, hu), these perform better on their native language, but\nin general they transfer worse than multilingual models or models of\ngenetically unrelated languages that share the same character set. Remarkably,\nstraightforward transfer of high-resource models, even without special efforts\ntoward hyperparameter optimization, yields what appear to be state of the art\nPOS and NER tools for the minority Uralic languages where there is sufficient\ndata for finetuning.",
    "descriptor": "\nComments: Seventh International Workshop for Computational Linguistics of Uralic Languages (IWCLUL 2021)\n",
    "authors": [
      "Judit \u00c1cs",
      "D\u00e1niel L\u00e9vai",
      "Andr\u00e1s Kornai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06327"
  },
  {
    "id": "arXiv:2109.06329",
    "title": "The correlation coefficient between citation metrics and winning a Nobel  or Abel Prize",
    "abstract": "Computing such correlation coefficient would be straightforward had we had\navailable the rankings given by the prize committee to all scientists in the\npool. In reality we only have citation rankings for all scientists. This means,\nhowever, that we have the ordinal rankings of the prize winners with regard to\ncitation metrics. I use maximum likelihood method to infer the most probable\ncorrelation coefficient to produce the observed pattern of ordinal ranks of the\nprize winners. I get the correlation coefficients of 0.47 and 0.59 between the\ncomposite citation indicator and getting Abel Prize and Fields Medal,\nrespectively. The correlation coefficient between getting a Nobel Prize and the\nQ-factor is 0.65. These coefficients are of the same magnitude as the\ncorrelation coefficient between Elo ratings of the chess players and their\npopularity measured as numbers of webpages mentioning the players.",
    "descriptor": "",
    "authors": [
      "M.V. Simkin"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.06329"
  },
  {
    "id": "arXiv:2109.06332",
    "title": "Achieving Zero Constraint Violation for Constrained Reinforcement  Learning via Primal-Dual Approach",
    "abstract": "Reinforcement learning is widely used in applications where one needs to\nperform sequential decisions while interacting with the environment. The\nproblem becomes more challenging when the decision requirement includes\nsatisfying some safety constraints. The problem is mathematically formulated as\nconstrained Markov decision process (CMDP). In the literature, various\nalgorithms are available to solve CMDP problems in a model-free manner to\nachieve $\\epsilon$-optimal cumulative reward with $\\epsilon$ feasible policies.\nAn $\\epsilon$-feasible policy implies that it suffers from constraint\nviolation. An important question here is whether we can achieve\n$\\epsilon$-optimal cumulative reward with zero constraint violations or not. To\nachieve that, we advocate the use of a randomized primal-dual approach to\nsolving the CMDP problems and propose a conservative stochastic primal-dual\nalgorithm (CSPDA) which is shown to exhibit $\\tilde{\\mathcal{O}}(1/\\epsilon^2)$\nsample complexity to achieve $\\epsilon$-optimal cumulative reward with zero\nconstraint violations. In the prior works, the best available sample complexity\nfor the $\\epsilon$-optimal policy with zero constraint violation is\n$\\tilde{\\mathcal{O}}(1/\\epsilon^5)$. Hence, the proposed algorithm provides a\nsignificant improvement as compared to the state of the art.",
    "descriptor": "",
    "authors": [
      "Qinbo Bai",
      "Amrit Singh Bedi",
      "Mridul Agarwal",
      "Alec Koppel",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06332"
  },
  {
    "id": "arXiv:2109.06333",
    "title": "Old BERT, New Tricks: Artificial Language Learning for Pre-Trained  Language Models",
    "abstract": "We extend the artificial language learning experimental paradigm from\npsycholinguistics and apply it to pre-trained language models -- specifically,\nBERT (Devlin et al., 2019). We treat the model as a subject in an artificial\nlanguage learning experimental setting: in order to learn the relation between\ntwo linguistic properties A and B, we introduce a set of new, non-existent,\nlinguistic items, give the model information about their variation along\nproperty A, then measure to what extent the model learns property B for these\nitems as a result of training. We show this method at work for degree modifiers\n(expressions like \"slightly\", \"very\", \"rather\", \"extremely\") and test the\nhypothesis that the degree expressed by modifiers (low, medium or high degree)\nis related to their sensitivity to sentence polarity (whether they show\npreference for affirmative or negative sentences or neither). Our experimental\nresults are compatible with existing linguistic observations that relate degree\nsemantics to polarity-sensitivity, including the main one: low degree semantics\nleads to positive polarity sensitivity (that is, to preference towards\naffirmative contexts). The method can be used in linguistics to elaborate on\nhypotheses and interpret experimental results, as well as for more insightful\nevaluation of linguistic representations in language models.",
    "descriptor": "",
    "authors": [
      "Lisa Bylinina",
      "Alexey Tikhonov",
      "Ekaterina Garmash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06333"
  },
  {
    "id": "arXiv:2109.06339",
    "title": "ML Based Lineage in Databases",
    "abstract": "In this work, we track the lineage of tuples throughout their database\nlifetime. That is, we consider a scenario in which tuples (records) that are\nproduced by a query may affect other tuple insertions into the DB, as part of a\nnormal workflow. As time goes on, exact provenance explanations for such tuples\nbecome deeply nested, increasingly consuming space, and resulting in decreased\nclarity and readability. We present a novel approach for approximating lineage\ntracking, using a Machine Learning (ML) and Natural Language Processing (NLP)\ntechnique; namely, word embedding. The basic idea is summarizing (and\napproximating) the lineage of each tuple via a small set of constant-size\nvectors (the number of vectors per-tuple is a hyperparameter). Therefore, our\nsolution does not suffer from space complexity blow-up over time, and it\n\"naturally ranks\" explanations to the existence of a tuple. We devise an\nalternative and improved lineage tracking mechanism, that of keeping track of\nand querying lineage at the column level; thereby, we manage to better\ndistinguish between the provenance features and the textual characteristics of\na tuple. We integrate our lineage computations into the PostgreSQL system via\nan extension (ProvSQL) and experimentally exhibit useful results in terms of\naccuracy against exact, semiring-based, justifications. In the experiments, we\nfocus on tuples with multiple generations of tuples in their lifelong lineage\nand analyze them in terms of direct and distant lineage. The experiments\nsuggest a high usefulness potential for the proposed approximate lineage\nmethods and the further suggested enhancements. This especially holds for the\ncolumn-based vectors method which exhibits high precision and high per-level\nrecall.",
    "descriptor": "",
    "authors": [
      "Michael Leybovich",
      "Oded Shmueli"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06339"
  },
  {
    "id": "arXiv:2109.06349",
    "title": "Few-Shot Intent Detection via Contrastive Pre-Training and Fine-Tuning",
    "abstract": "In this work, we focus on a more challenging few-shot intent detection\nscenario where many intents are fine-grained and semantically similar. We\npresent a simple yet effective few-shot intent detection schema via contrastive\npre-training and fine-tuning. Specifically, we first conduct self-supervised\ncontrastive pre-training on collected intent datasets, which implicitly learns\nto discriminate semantically similar utterances without using any labels. We\nthen perform few-shot intent detection together with supervised contrastive\nlearning, which explicitly pulls utterances from the same intent closer and\npushes utterances across different intents farther. Experimental results show\nthat our proposed method achieves state-of-the-art performance on three\nchallenging intent detection datasets under 5-shot and 10-shot settings.",
    "descriptor": "\nComments: Accepted by EMNLP 2021 main conference\n",
    "authors": [
      "Jianguo Zhang",
      "Trung Bui",
      "Seunghyun Yoon",
      "Xiang Chen",
      "Zhiwei Liu",
      "Congying Xia",
      "Quan Hung Tran",
      "Walter Chang",
      "Philip Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06349"
  },
  {
    "id": "arXiv:2109.06352",
    "title": "Uncertainty-Aware Machine Translation Evaluation",
    "abstract": "Several neural-based metrics have been recently proposed to evaluate machine\ntranslation quality. However, all of them resort to point estimates, which\nprovide limited information at segment level. This is made worse as they are\ntrained on noisy, biased and scarce human judgements, often resulting in\nunreliable quality predictions. In this paper, we introduce uncertainty-aware\nMT evaluation and analyze the trustworthiness of the predicted quality. We\ncombine the COMET framework with two uncertainty estimation methods, Monte\nCarlo dropout and deep ensembles, to obtain quality scores along with\nconfidence intervals. We compare the performance of our uncertainty-aware MT\nevaluation methods across multiple language pairs from the QT21 dataset and the\nWMT20 metrics task, augmented with MQM annotations. We experiment with varying\nnumbers of references and further discuss the usefulness of uncertainty-aware\nquality estimation (without references) to flag possibly critical translation\nmistakes.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Taisiya Glushkova",
      "Chrysoula Zerva",
      "Ricardo Rei",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06352"
  },
  {
    "id": "arXiv:2109.06355",
    "title": "Optimizing FPGA-based Accelerator Design for Large-Scale Molecular  Similarity Search",
    "abstract": "Molecular similarity search has been widely used in drug discovery to\nidentify structurally similar compounds from large molecular databases rapidly.\nWith the increasing size of chemical libraries, there is growing interest in\nthe efficient acceleration of large-scale similarity search. Existing works\nmainly focus on CPU and GPU to accelerate the computation of the Tanimoto\ncoefficient in measuring the pairwise similarity between different molecular\nfingerprints. In this paper, we propose and optimize an FPGA-based accelerator\ndesign on exhaustive and approximate search algorithms. On exhaustive search\nusing BitBound & folding, we analyze the similarity cutoff and folding level\nrelationship with search speedup and accuracy, and propose a scalable\non-the-fly query engine on FPGAs to reduce the resource utilization and\npipeline interval. We achieve a 450 million compounds-per-second processing\nthroughput for a single query engine. On approximate search using hierarchical\nnavigable small world (HNSW), a popular algorithm with high recall and query\nspeed. We propose an FPGA-based graph traversal engine to utilize a high\nthroughput register array based priority queue and fine-grained distance\ncalculation engine to increase the processing capability. Experimental results\nshow that the proposed FPGA-based HNSW implementation has a 103385 query per\nsecond (QPS) on the Chembl database with 0.92 recall and achieves a 35x speedup\nthan the existing CPU implementation on average. To the best of our knowledge,\nour FPGA-based implementation is the first attempt to accelerate molecular\nsimilarity search algorithms on FPGA and has the highest performance among\nexisting approaches.",
    "descriptor": "\nComments: ICCAD 2021\n",
    "authors": [
      "Hongwu Peng",
      "Shiyang Chen",
      "Zhepeng Wang",
      "Junhuan Yang",
      "Scott A. Weitze",
      "Tong Geng",
      "Ang Li",
      "Jinbo Bi",
      "Minghu Song",
      "Weiwen Jiang",
      "Hang Liu",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2109.06355"
  },
  {
    "id": "arXiv:2109.06356",
    "title": "An Iterative Approach to Improving Solution Quality for AC Optimal Power  Flow Problems",
    "abstract": "The existence of multiple solutions to AC optimal power flow (ACOPF) problems\nhas been noted for decades. Existing solvers are generally successful in\nfinding local solutions, which satisfy first and second order optimality\nconditions, but may not be globally optimal. In this paper, we propose a simple\niterative approach to improve the quality of solutions to ACOPF problems.\nFirst, we call an existing solver for the ACOPF problem. From the solution and\nthe associated dual variables, we form a partial Lagrangian. Then we optimize\nthis partial Lagrangian and use its solution as a warm start to call the solver\nagain for the ACOPF problem. By repeating this process, we can iteratively\nimprove the solution quality, moving from local solutions to global ones. We\nshow the effectiveness of our algorithm on standard IEEE networks. The\nsimulation results show that our algorithm can escape from local solutions to\nachieve global optimums within a few iterations.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.12075\n",
    "authors": [
      "Ling Zhang",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06356"
  },
  {
    "id": "arXiv:2109.06358",
    "title": "A Practical Adversarial Attack on Contingency Detection of Smart Energy  Systems",
    "abstract": "Due to the advances in computing and sensing, deep learning (DL) has widely\nbeen applied in smart energy systems (SESs). These DL-based solutions have\nproved their potentials in improving the effectiveness and adaptiveness of the\ncontrol systems. However, in recent years, increasing evidence shows that DL\ntechniques can be manipulated by adversarial attacks with carefully-crafted\nperturbations. Adversarial attacks have been studied in computer vision and\nnatural language processing. However, there is very limited work focusing on\nthe adversarial attack deployment and mitigation in energy systems. In this\nregard, to better prepare the SESs against potential adversarial attacks, we\npropose an innovative adversarial attack model that can practically compromise\ndynamical controls of energy system. We also optimize the deployment of the\nproposed adversarial attack model by employing deep reinforcement learning (RL)\ntechniques. In this paper, we present our first-stage work in this direction.\nIn simulation section, we evaluate the performance of our proposed adversarial\nattack model using standard IEEE 9-bus system.",
    "descriptor": "\nComments: 5 Pages, 6 figures\n",
    "authors": [
      "Moein Sabounchi",
      "Jin Wei-Kocsis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06358"
  },
  {
    "id": "arXiv:2109.06361",
    "title": "POPCORN: Progressive Pseudo-labeling with Consistency Regularization and  Neighboring",
    "abstract": "Semi-supervised learning (SSL) uses unlabeled data to compensate for the\nscarcity of annotated images and the lack of method generalization to unseen\ndomains, two usual problems in medical segmentation tasks. In this work, we\npropose POPCORN, a novel method combining consistency regularization and\npseudo-labeling designed for image segmentation. The proposed framework uses\nhigh-level regularization to constrain our segmentation model to use similar\nlatent features for images with similar segmentations. POPCORN estimates a\nproximity graph to select data from easiest ones to more difficult ones, in\norder to ensure accurate pseudo-labeling and to limit confirmation bias.\nApplied to multiple sclerosis lesion segmentation, our method demonstrates\ncompetitive results compared to other state-of-the-art SSL strategies.",
    "descriptor": "",
    "authors": [
      "Reda Abdellah Kamraoui",
      "Vinh-Thong Ta",
      "Nicolas Papadakis",
      "Fanny Compaire",
      "Jos\u00e9 V Manjon",
      "Pierrick Coup\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06361"
  },
  {
    "id": "arXiv:2109.06362",
    "title": "Theoretical Guarantees of Fictitious Discount Algorithms for Episodic  Reinforcement Learning and Global Convergence of Policy Gradient Methods",
    "abstract": "When designing algorithms for finite-time-horizon episodic reinforcement\nlearning problems, a common approach is to introduce a fictitious discount\nfactor and use stationary policies for approximations. Empirically, it has been\nshown that the fictitious discount factor helps reduce variance, and stationary\npolicies serve to save the per-iteration computational cost. Theoretically,\nhowever, there is no existing work on convergence analysis for algorithms with\nthis fictitious discount recipe. This paper takes the first step towards\nanalyzing these algorithms. It focuses on two vanilla policy gradient (VPG)\nvariants: the first being a widely used variant with discounted advantage\nestimations (DAE), the second with an additional fictitious discount factor in\nthe score functions of the policy gradient estimators. Non-asymptotic\nconvergence guarantees are established for both algorithms, and the additional\ndiscount factor is shown to reduce the bias introduced in DAE and thus improve\nthe algorithm convergence asymptotically. A key ingredient of our analysis is\nto connect three settings of Markov decision processes (MDPs): the\nfinite-time-horizon, the average reward and the discounted settings. To our\nbest knowledge, this is the first theoretical guarantee on fictitious discount\nalgorithms for the episodic reinforcement learning of finite-time-horizon MDPs,\nwhich also leads to the (first) global convergence of policy gradient methods\nfor finite-time-horizon episodic reinforcement learning.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Xin Guo",
      "Anran Hu",
      "Junzi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.06362"
  },
  {
    "id": "arXiv:2109.06363",
    "title": "Sensor Adversarial Traits: Analyzing Robustness of 3D Object Detection  Sensor Fusion Models",
    "abstract": "A critical aspect of autonomous vehicles (AVs) is the object detection stage,\nwhich is increasingly being performed with sensor fusion models: multimodal 3D\nobject detection models which utilize both 2D RGB image data and 3D data from a\nLIDAR sensor as inputs. In this work, we perform the first study to analyze the\nrobustness of a high-performance, open source sensor fusion model architecture\ntowards adversarial attacks and challenge the popular belief that the use of\nadditional sensors automatically mitigate the risk of adversarial attacks. We\nfind that despite the use of a LIDAR sensor, the model is vulnerable to our\npurposefully crafted image-based adversarial attacks including disappearance,\nuniversal patch, and spoofing. After identifying the underlying reason, we\nexplore some potential defenses and provide some recommendations for improved\nsensor fusion models.",
    "descriptor": "",
    "authors": [
      "Won Park",
      "Nan Li",
      "Qi Alfred Chen",
      "Z. Morley Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06363"
  },
  {
    "id": "arXiv:2109.06365",
    "title": "From Heatmaps to Structural Explanations of Image Classifiers",
    "abstract": "This paper summarizes our endeavors in the past few years in terms of\nexplaining image classifiers, with the aim of including negative results and\ninsights we have gained. The paper starts with describing the explainable\nneural network (XNN), which attempts to extract and visualize several\nhigh-level concepts purely from the deep network, without relying on human\nlinguistic concepts. This helps users understand network classifications that\nare less intuitive and substantially improves user performance on a difficult\nfine-grained classification task of discriminating among different species of\nseagulls.\nRealizing that an important missing piece is a reliable heatmap visualization\ntool, we have developed I-GOS and iGOS++ utilizing integrated gradients to\navoid local optima in heatmap generation, which improved the performance across\nall resolutions. During the development of those visualizations, we realized\nthat for a significant number of images, the classifier has multiple different\npaths to reach a confident prediction. This has lead to our recent development\nof structured attention graphs (SAGs), an approach that utilizes beam search to\nlocate multiple coarse heatmaps for a single image, and compactly visualizes a\nset of heatmaps by capturing how different combinations of image regions impact\nthe confidence of a classifier.\nThrough the research process, we have learned much about insights in building\ndeep network explanations, the existence and frequency of multiple\nexplanations, and various tricks of the trade that make explanations work. In\nthis paper, we attempt to share those insights and opinions with the readers\nwith the hope that some of them will be informative for future researchers on\nexplainable deep learning.",
    "descriptor": "\nComments: Submitted to Applied AI Letters\n",
    "authors": [
      "Li Fuxin",
      "Zhongang Qi",
      "Saeed Khorram",
      "Vivswan Shitole",
      "Prasad Tadepalli",
      "Minsuk Kahng",
      "Alan Fern"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06365"
  },
  {
    "id": "arXiv:2109.06366",
    "title": "A Dyadic Simulation Approach to Efficient Range-Summability",
    "abstract": "Efficient range-summability (ERS) of a long list of random variables is a\nfundamental algorithmic problem that has applications to three important\ndatabase applications, namely, data stream processing, space-efficient\nhistogram maintenance (SEHM), and approximate nearest neighbor searches (ANNS).\nIn this work, we propose a novel dyadic simulation framework and develop three\nnovel ERS solutions, namely Gaussian-dyadic simulation tree (DST), Cauchy-DST\nand Random Walk-DST, using it. We also propose novel rejection sampling\ntechniques to make these solutions computationally efficient. Furthermore, we\ndevelop a novel k-wise independence theory that allows our ERS solutions to\nhave both high computational efficiencies and strong provable independence\nguarantees.",
    "descriptor": "",
    "authors": [
      "Jingfan Meng",
      "Huayi Wang",
      "Jun Xu",
      "Mitsunori Ogihara"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06366"
  },
  {
    "id": "arXiv:2109.06368",
    "title": "Policy Optimization Using Semiparametric Models for Dynamic Pricing",
    "abstract": "In this paper, we study the contextual dynamic pricing problem where the\nmarket value of a product is linear in its observed features plus some market\nnoise. Products are sold one at a time, and only a binary response indicating\nsuccess or failure of a sale is observed. Our model setting is similar to\nJavanmard and Nazerzadeh [2019] except that we expand the demand curve to a\nsemiparametric model and need to learn dynamically both parametric and\nnonparametric components. We propose a dynamic statistical learning and\ndecision-making policy that combines semiparametric estimation from a\ngeneralized linear model with an unknown link and online decision-making to\nminimize regret (maximize revenue). Under mild conditions, we show that for a\nmarket noise c.d.f. $F(\\cdot)$ with $m$-th order derivative ($m\\geq 2$), our\npolicy achieves a regret upper bound of $\\tilde{O}_{d}(T^{\\frac{2m+1}{4m-1}})$,\nwhere $T$ is time horizon and $\\tilde{O}_{d}$ is the order that hides\nlogarithmic terms and the dimensionality of feature $d$. The upper bound is\nfurther reduced to $\\tilde{O}_{d}(\\sqrt{T})$ if $F$ is super smooth whose\nFourier transform decays exponentially. In terms of dependence on the horizon\n$T$, these upper bounds are close to $\\Omega(\\sqrt{T})$, the lower bound where\n$F$ belongs to a parametric class. We further generalize these results to the\ncase with dynamically dependent product features under the strong mixing\ncondition.",
    "descriptor": "\nComments: 60 pages, 18 figures\n",
    "authors": [
      "Jianqing Fan",
      "Yongyi Guo",
      "Mengxin Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06368"
  },
  {
    "id": "arXiv:2109.06372",
    "title": "Tracking Control foe Multi-Agent Systems Using Broadcast Signals Based  on Positive Realness",
    "abstract": "Broadcast control is one of decentralized control methods for networked\nmulti-agent systems. In this method, each agent does not communicate with the\nothers, and autonomously determines its own action using only the same signal\nsent from a central controller. Therefore, it is effective for systems with\nnumerous agents or no-communication between agents. However, it is difficult to\nmanage the stochastic action process of agents considering engineering\napplications. This paper proposes a decentralized control such that agents\nautonomously select the deterministic actions. Firstly, a non-linear controller\nwith a binary output of each agent including 0 is introduced in order to\nexpress stop actions autonomously when the target is achieved. The asymptotic\nstability to the target is proved. Secondly, the controller can adjust the\ntendency of actions in order to make it easier to manage the actions. Thirdly,\nthe controller is extended to that with a continuous output in order to reduce\nthe tracking error to the target and the output vibration. Finally, the\neffectiveness of the proposed control is verified by numerical experiments.",
    "descriptor": "\nComments: 12 pages with 11 figures\n",
    "authors": [
      "Yasushi Amano",
      "Tomohiko Jimbo",
      "Kenji Fujimoto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.06372"
  },
  {
    "id": "arXiv:2109.06374",
    "title": "Hunspell for Sorani Kurdish Spell Checking and Morphological Analysis",
    "abstract": "Spell checking and morphological analysis are two fundamental tasks in text\nand natural language processing and are addressed in the early stages of the\ndevelopment of language technology. Despite the previous efforts, there is no\nprogress in open-source to create such tools for Sorani Kurdish, also known as\nCentral Kurdish, as a less-resourced language. In this paper, we present our\nefforts in annotating a lexicon with morphosyntactic tags and also, extracting\nmorphological rules of Sorani Kurdish to build a morphological analyzer, a\nstemmer and a spell-checking system using Hunspell. This implementation can be\nused for further developments in the field by researchers and also, be\nintegrated into text editors under a publicly available license.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Sina Ahmadi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2109.06374"
  },
  {
    "id": "arXiv:2109.06375",
    "title": "Adaptive Constrained Kinematic Control using Partial or Complete  Task-Space Measurements",
    "abstract": "Recent advancements in constrained kinematic control make it an attractive\nstrategy for controlling robots with arbitrary geometry in challenging tasks.\nMost current works assume that the robot kinematic model is precise enough for\nthe task at hand. However, with increasing demands and safety requirements in\nrobotic applications, there is a need for a controller that compensates online\nfor kinematic inaccuracies. We propose an adaptive constrained kinematic\ncontrol strategy based on quadratic programming, which uses partial or complete\ntask-space measurements to compensate online for calibration errors. Our method\nis validated in experiments and simulations that show increased accuracy and\nsafety compared to a state-of-the-art kinematic control strategy.",
    "descriptor": "\nComments: 12 pages, 9 figures, Under Review for the IEEE Transactions on Robotics (T-RO)\n",
    "authors": [
      "Murilo Marques Marinho",
      "Bruno Vilhena Adorno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06375"
  },
  {
    "id": "arXiv:2109.06379",
    "title": "Compression, Transduction, and Creation: A Unified Framework for  Evaluating Natural Language Generation",
    "abstract": "Natural language generation (NLG) spans a broad range of tasks, each of which\nserves for specific objectives and desires different properties of generated\ntext. The complexity makes automatic evaluation of NLG particularly\nchallenging. Previous work has typically focused on a single task and developed\nindividual evaluation metrics based on specific intuitions. In this paper, we\npropose a unifying perspective based on the nature of information change in NLG\ntasks, including compression (e.g., summarization), transduction (e.g., text\nrewriting), and creation (e.g., dialog). Information alignment between input,\ncontext, and output text plays a common central role in characterizing the\ngeneration. With automatic alignment prediction models, we develop a family of\ninterpretable metrics that are suitable for evaluating key aspects of different\nNLG tasks, often without need of gold reference data. Experiments show the\nuniformly designed metrics achieve stronger or comparable correlations with\nhuman judgement compared to state-of-the-art metrics in each of diverse tasks,\nincluding text summarization, style transfer, and knowledge-grounded dialog.",
    "descriptor": "\nComments: EMNLP 2021, Code available at this https URL\n",
    "authors": [
      "Mingkai Deng",
      "Bowen Tan",
      "Zhengzhong Liu",
      "Eric P. Xing",
      "Zhiting Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06379"
  },
  {
    "id": "arXiv:2109.06382",
    "title": "Cohmeleon: Learning-Based Orchestration of Accelerator Coherence in  Heterogeneous SoCs",
    "abstract": "One of the most critical aspects of integrating loosely-coupled accelerators\nin heterogeneous SoC architectures is orchestrating their interactions with the\nmemory hierarchy, especially in terms of navigating the various cache-coherence\noptions: from accelerators accessing off-chip memory directly, bypassing the\ncache hierarchy, to accelerators having their own private cache. By running\nreal-size applications on FPGA-based prototypes of many-accelerator multi-core\nSoCs, we show that the best cache-coherence mode for a given accelerator varies\nat runtime, depending on the accelerator's characteristics, the workload size,\nand the overall SoC status.\nCohmeleon applies reinforcement learning to select the best coherence mode\nfor each accelerator dynamically at runtime, as opposed to statically at design\ntime. It makes these selections adaptively, by continuously observing the\nsystem and measuring its performance. Cohmeleon is accelerator-agnostic,\narchitecture-independent, and it requires minimal hardware support. Cohmeleon\nis also transparent to application programmers and has a negligible software\noverhead. FPGA-based experiments show that our runtime approach offers, on\naverage, a 38% speedup with a 66% reduction of off-chip memory accesses\ncompared to state-of-the-art design-time approaches. Moreover, it can match\nruntime solutions that are manually tuned for the target architecture.",
    "descriptor": "\nComments: To appear in the 54th IEEE/ACM Symposium on Microarchitecture (MICRO 2021)\n",
    "authors": [
      "Joseph Zuckerman",
      "Davide Giri",
      "Jihye Kwon",
      "Paolo Mantovani",
      "Luca P. Carloni"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2109.06382"
  },
  {
    "id": "arXiv:2109.06387",
    "title": "Rationales for Sequential Predictions",
    "abstract": "Sequence models are a critical component of modern NLP systems, but their\npredictions are difficult to explain. We consider model explanations though\nrationales, subsets of context that can explain individual model predictions.\nWe find sequential rationales by solving a combinatorial optimization: the best\nrationale is the smallest subset of input tokens that would predict the same\noutput as the full sequence. Enumerating all subsets is intractable, so we\npropose an efficient greedy algorithm to approximate this objective. The\nalgorithm, which is called greedy rationalization, applies to any model. For\nthis approach to be effective, the model should form compatible conditional\ndistributions when making predictions on incomplete subsets of the context.\nThis condition can be enforced with a short fine-tuning step. We study greedy\nrationalization on language modeling and machine translation. Compared to\nexisting baselines, greedy rationalization is best at optimizing the\ncombinatorial objective and provides the most faithful rationales. On a new\ndataset of annotated sequential rationales, greedy rationales are most similar\nto human rationales.",
    "descriptor": "\nComments: To appear in the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP 2021)\n",
    "authors": [
      "Keyon Vafa",
      "Yuntian Deng",
      "David M. Blei",
      "Alexander M. Rush"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06387"
  },
  {
    "id": "arXiv:2109.06388",
    "title": "On Distributed Learning with Constant Communication Bits",
    "abstract": "In this paper, we study a distributed learning problem constrained by\nconstant communication bits. Specifically, we consider the distributed\nhypothesis testing (DHT) problem where two distributed nodes are constrained to\ntransmit a constant number of bits to a central decoder. In such cases, we show\nthat in order to achieve the optimal error exponents, it suffices to consider\nthe empirical distributions of observed data sequences and encode them to the\ntransmission bits. With such a coding strategy, we develop a geometric approach\nin the distribution spaces and characterize the optimal schemes. In particular,\nwe show the optimal achievable error exponents and coding schemes for the\nfollowing cases: (i) both nodes can transmit $\\log_23$ bits; (ii) one of the\nnodes can transmit $1$ bit, and the other node is not constrained; (iii) the\njoint distribution of the nodes are conditionally independent given one\nhypothesis. Furthermore, we provide several numerical examples for illustrating\nthe theoretical results. Our results provide theoretical guidance for designing\npractical distributed learning rules, and the developed approach also reveals\nnew potentials for establishing error exponents for DHT with more general\ncommunication constraints.",
    "descriptor": "\nComments: Submitted to JSAIT\n",
    "authors": [
      "Xiangxiang Xu",
      "Shao-Lun Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06388"
  },
  {
    "id": "arXiv:2109.06395",
    "title": "An Inverse Procedural Modeling Pipeline for SVBRDF Maps",
    "abstract": "Procedural modeling is now the de facto standard of material modeling in\nindustry. Procedural models can be edited and are easily extended, unlike\npixel-based representations of captured materials. In this paper, we present a\nsemi-automatic pipeline for general material proceduralization. Given\nSpatially-Varying Bidirectional Reflectance Distribution Functions (SVBRDFs)\nrepresented as sets of pixel maps, our pipeline decomposes them into a tree of\nsub-materials whose spatial distributions are encoded by their associated mask\nmaps. This semi-automatic decomposition of material maps progresses\nhierarchically, driven by our new spectrum-aware material matting and\ninstance-based decomposition methods. Each decomposed sub-material is\nproceduralized by a novel multi-layer noise model to capture local variations\nat different scales. Spatial distributions of these sub-materials are modeled\neither by a by-example inverse synthesis method recovering Point Process\nTexture Basis Functions (PPTBF) or via random sampling. To reconstruct\nprocedural material maps, we propose a differentiable rendering-based\noptimization that recomposes all generated procedures together to maximize the\nsimilarity between our procedural models and the input material pixel maps. We\nevaluate our pipeline on a variety of synthetic and real materials. We\ndemonstrate our method's capacity to process a wide range of material types,\neliminating the need for artist designed material graphs required in previous\nwork. As fully procedural models, our results expand to arbitrary resolution\nand enable high level user control of appearance.",
    "descriptor": "",
    "authors": [
      "Yiwei Hu",
      "Chengan He",
      "Valentin Deschaintre",
      "Julie Dorsey",
      "Holly Rushmeier"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.06395"
  },
  {
    "id": "arXiv:2109.06397",
    "title": "AdaPruner: Adaptive Channel Pruning and Effective Weights Inheritance",
    "abstract": "Channel pruning is one of the major compression approaches for deep neural\nnetworks. While previous pruning methods have mostly focused on identifying\nunimportant channels, channel pruning is considered as a special case of neural\narchitecture search in recent years. However, existing methods are either\ncomplicated or prone to sub-optimal pruning. In this paper, we propose a\npruning framework that adaptively determines the number of each layer's\nchannels as well as the wights inheritance criteria for sub-network. Firstly,\nevaluate the importance of each block in the network based on the mean of the\nscaling parameters of the BN layers. Secondly, use the bisection method to\nquickly find the compact sub-network satisfying the budget. Finally, adaptively\nand efficiently choose the weight inheritance criterion that fits the current\narchitecture and fine-tune the pruned network to recover performance. AdaPruner\nallows to obtain pruned network quickly, accurately and efficiently, taking\ninto account both the structure and initialization weights. We prune the\ncurrently popular CNN models (VGG, ResNet, MobileNetV2) on different image\nclassification datasets, and the experimental results demonstrate the\neffectiveness of our proposed method. On ImageNet, we reduce 32.8% FLOPs of\nMobileNetV2 with only 0.62% decrease for top-1 accuracy, which exceeds all\nprevious state-of-the-art channel pruning methods. The code will be released.",
    "descriptor": "",
    "authors": [
      "Xiangcheng Liu",
      "Jian Cao",
      "Hongyi Yao",
      "Wenyu Sun",
      "Yuan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06397"
  },
  {
    "id": "arXiv:2109.06398",
    "title": "Adaptive Proposal Generation Network for Temporal Sentence Localization  in Videos",
    "abstract": "We address the problem of temporal sentence localization in videos (TSLV).\nTraditional methods follow a top-down framework which localizes the target\nsegment with pre-defined segment proposals. Although they have achieved decent\nperformance, the proposals are handcrafted and redundant. Recently, bottom-up\nframework attracts increasing attention due to its superior efficiency. It\ndirectly predicts the probabilities for each frame as a boundary. However, the\nperformance of bottom-up model is inferior to the top-down counterpart as it\nfails to exploit the segment-level interaction. In this paper, we propose an\nAdaptive Proposal Generation Network (APGN) to maintain the segment-level\ninteraction while speeding up the efficiency. Specifically, we first perform a\nforeground-background classification upon the video and regress on the\nforeground frames to adaptively generate proposals. In this way, the\nhandcrafted proposal design is discarded and the redundant proposals are\ndecreased. Then, a proposal consolidation module is further developed to\nenhance the semantic of the generated proposals. Finally, we locate the target\nmoments with these generated proposals following the top-down framework.\nExtensive experiments on three challenging benchmarks show that our proposed\nAPGN significantly outperforms previous state-of-the-art methods.",
    "descriptor": "\nComments: Accepted as a long paper in the main conference of EMNLP 2021\n",
    "authors": [
      "Daizong Liu",
      "Xiaoye Qu",
      "Jianfeng Dong",
      "Pan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06398"
  },
  {
    "id": "arXiv:2109.06400",
    "title": "Progressively Guide to Attend: An Iterative Alignment Framework for  Temporal Sentence Grounding",
    "abstract": "A key solution to temporal sentence grounding (TSG) exists in how to learn\neffective alignment between vision and language features extracted from an\nuntrimmed video and a sentence description. Existing methods mainly leverage\nvanilla soft attention to perform the alignment in a single-step process.\nHowever, such single-step attention is insufficient in practice, since\ncomplicated relations between inter- and intra-modality are usually obtained\nthrough multi-step reasoning. In this paper, we propose an Iterative Alignment\nNetwork (IA-Net) for TSG task, which iteratively interacts inter- and\nintra-modal features within multiple steps for more accurate grounding.\nSpecifically, during the iterative reasoning process, we pad multi-modal\nfeatures with learnable parameters to alleviate the nowhere-to-attend problem\nof non-matched frame-word pairs, and enhance the basic co-attention mechanism\nin a parallel manner. To further calibrate the misaligned attention caused by\neach reasoning step, we also devise a calibration module following each\nattention module to refine the alignment knowledge. With such iterative\nalignment scheme, our IA-Net can robustly capture the fine-grained relations\nbetween vision and language domains step-by-step for progressively reasoning\nthe temporal boundaries. Extensive experiments conducted on three challenging\nbenchmarks demonstrate that our proposed model performs better than the\nstate-of-the-arts.",
    "descriptor": "\nComments: Accepted as a long paper in the main conference of EMNLP 2021\n",
    "authors": [
      "Daizong Liu",
      "Xiaoye Qu",
      "Pan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06400"
  },
  {
    "id": "arXiv:2109.06401",
    "title": "Camera-Tracklet-Aware Contrastive Learning for Unsupervised Vehicle  Re-Identification",
    "abstract": "Recently, vehicle re-identification methods based on deep learning constitute\nremarkable achievement. However, this achievement requires large-scale and\nwell-annotated datasets. In constructing the dataset, assigning globally\navailable identities (Ids) to vehicles captured from a great number of cameras\nis labour-intensive, because it needs to consider their subtle appearance\ndifferences or viewpoint variations. In this paper, we propose\ncamera-tracklet-aware contrastive learning (CTACL) using the multi-camera\ntracklet information without vehicle identity labels. The proposed CTACL\ndivides an unlabelled domain, i.e., entire vehicle images, into multiple\ncamera-level subdomains and conducts contrastive learning within and beyond the\nsubdomains. The positive and negative samples for contrastive learning are\ndefined using tracklet Ids of each camera. Additionally, the domain adaptation\nacross camera networks is introduced to improve the generalisation performance\nof learnt representations and alleviate the performance degradation resulted\nfrom the domain gap between the subdomains. We demonstrate the effectiveness of\nour approach on video-based and image-based vehicle Re-ID datasets.\nExperimental results show that the proposed method outperforms the recent\nstate-of-the-art unsupervised vehicle Re-ID methods. The source code for this\npaper is publicly available on\n`https://github.com/andreYoo/CTAM-CTACL-VVReID.git'.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Jongmin Yu",
      "Junsik Kim",
      "Minkyung Kim",
      "Hyeontaek Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06401"
  },
  {
    "id": "arXiv:2109.06402",
    "title": "Exploring Personality and Online Social Engagement: An Investigation of  MBTI Users on Twitter",
    "abstract": "Text-based personality prediction by computational models is an emerging\nfield with the potential to significantly improve on key weaknesses of\nsurvey-based personality assessment. We investigate 3848 profiles from Twitter\nwith self-labeled Myers-Briggs personality traits (MBTI) - a framework closely\nrelated to the Five Factor Model of personality - to better understand how\ntext-based digital traces from social engagement online can be used to predict\nuser personality traits. We leverage BERT, a state-of-the-art NLP architecture\nbased on deep learning, to analyze various sources of text that hold most\npredictive power for our task. We find that biographies, statuses, and liked\ntweets contain significant predictive power for all dimensions of the MBTI\nsystem. We discuss our findings and their implications for the validity of the\nMBTI and the lexical hypothesis, a foundational theory underlying the Five\nFactor Model that links language use and behavior. Our results hold optimistic\nimplications for personality psychologists, computational linguists, and other\nsocial scientists aiming to predict personality from observational text data\nand explore the links between language and core behavioral traits.",
    "descriptor": "",
    "authors": [
      "Partha Kadambi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06402"
  },
  {
    "id": "arXiv:2109.06403",
    "title": "Symbolic determinant identity testing and non-commutative ranks of  matrix Lie algebras",
    "abstract": "One approach to make progress on the symbolic determinant identity testing\n(SDIT) problem is to study the structure of singular matrix spaces. After\nsettling the non-commutative rank problem (Garg-Gurvits-Oliveira-Wigderson,\nFound. Comput. Math. 2020; Ivanyos-Qiao-Subrahmanyam, Comput. Complex. 2018), a\nnatural next step is to understand singular matrix spaces whose non-commutative\nrank is full. At present, examples of such matrix spaces are mostly sporadic,\nso it is desirable to discover them in a more systematic way.\nIn this paper, we make a step towards this direction, by studying the family\nof matrix spaces that are closed under the commutator operation, that is matrix\nLie algebras. On the one hand, we demonstrate that matrix Lie algebras over the\ncomplex number field give rise to singular matrix spaces with full\nnon-commutative ranks. On the other hand, we show that SDIT of such spaces can\nbe decided in deterministic polynomial time. Moreover, we give a\ncharacterization for the matrix Lie algebras to yield a matrix space possessing\nsingularity certificates as studied by Lov'asz (B. Braz. Math. Soc., 1989) and\nRaz and Wigderson (Building Bridges II, 2019).",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "G\u00e1bor Ivanyos",
      "Tushant Mittal",
      "Youming Qiao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2109.06403"
  },
  {
    "id": "arXiv:2109.06404",
    "title": "Detecting Safety Problems of Multi-Sensor Fusion in Autonomous Driving",
    "abstract": "Autonomous driving (AD) systems have been thriving in recent years. In\ngeneral, they receive sensor data, compute driving decisions, and output\ncontrol signals to the vehicles. To smooth out the uncertainties brought by\nsensor inputs, AD systems usually leverage multi-sensor fusion (MSF) to fuse\nthe sensor inputs and produce a more reliable understanding of the\nsurroundings. However, MSF cannot completely eliminate the uncertainties since\nit lacks the knowledge about which sensor provides the most accurate data. As a\nresult, critical consequences might happen unexpectedly. In this work, we\nobserved that the popular MSF methods in an industry-grade Advanced\nDriver-Assistance System (ADAS) can mislead the car control and result in\nserious safety hazards. Misbehavior can happen regardless of the used fusion\nmethods and the accurate data from at least one sensor. To attribute the safety\nhazards to a MSF method, we formally define the fusion errors and propose a way\nto distinguish safety violations causally induced by such errors. Further, we\ndevelop a novel evolutionary-based domain-specific search framework,\nFusionFuzz, for the efficient detection of fusion errors. We evaluate our\nframework on two widely used MSF methods. %in two driving environments.\nExperimental results show that FusionFuzz identifies more than 150 fusion\nerrors. Finally, we provide several suggestions to improve the MSF methods\nunder study.",
    "descriptor": "",
    "authors": [
      "Ziyuan Zhong",
      "Zhisheng Hu",
      "Shengjian Guo",
      "Xinyang Zhang",
      "Zhenyu Zhong",
      "Baishakhi Ray"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.06404"
  },
  {
    "id": "arXiv:2109.06407",
    "title": "Neural Networks with Physics-Informed Architectures and Constraints for  Dynamical Systems Modeling",
    "abstract": "Effective inclusion of physics-based knowledge into deep neural network\nmodels of dynamical systems can greatly improve data efficiency and\ngeneralization. Such a-priori knowledge might arise from physical principles\n(e.g., conservation laws) or from the system's design (e.g., the Jacobian\nmatrix of a robot), even if large portions of the system dynamics remain\nunknown. We develop a framework to learn dynamics models from trajectory data\nwhile incorporating a-priori system knowledge as inductive bias. More\nspecifically, the proposed framework uses physics-based side information to\ninform the structure of the neural network itself, and to place constraints on\nthe values of the outputs and the internal states of the model. It represents\nthe system's vector field as a composition of known and unknown functions, the\nlatter of which are parametrized by neural networks. The physics-informed\nconstraints are enforced via the augmented Lagrangian method during the model's\ntraining. We experimentally demonstrate the benefits of the proposed approach\non a variety of dynamical systems -- including a benchmark suite of robotics\nenvironments featuring large state spaces, non-linear dynamics, external\nforces, contact forces, and control inputs. By exploiting a-priori system\nknowledge during training, the proposed approach learns to predict the system\ndynamics two orders of magnitude more accurately than a baseline approach that\ndoes not include prior knowledge, given the same training dataset.",
    "descriptor": "",
    "authors": [
      "Franck Djeumou",
      "Cyrus Neary",
      "Eric Goubault",
      "Sylvie Putot",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06407"
  },
  {
    "id": "arXiv:2109.06409",
    "title": "Reinforcement Learning with Evolutionary Trajectory Generator: A General  Approach for Quadrupedal Locomotion",
    "abstract": "Recently reinforcement learning (RL) has emerged as a promising approach for\nquadrupedal locomotion, which can save the manual effort in conventional\napproaches such as designing skill-specific controllers. However, due to the\ncomplex nonlinear dynamics in quadrupedal robots and reward sparsity, it is\nstill difficult for RL to learn effective gaits from scratch, especially in\nchallenging tasks such as walking over the balance beam. To alleviate such\ndifficulty, we propose a novel RL-based approach that contains an evolutionary\nfoot trajectory generator. Unlike prior methods that use a fixed trajectory\ngenerator, the generator continually optimizes the shape of the output\ntrajectory for the given task, providing diversified motion priors to guide the\npolicy learning. The policy is trained with reinforcement learning to output\nresidual control signals that fit different gaits. We then optimize the\ntrajectory generator and policy network alternatively to stabilize the training\nand share the exploratory data to improve sample efficiency. As a result, our\napproach can solve a range of challenging tasks in simulation by learning from\nscratch, including walking on a balance beam and crawling through the cave. To\nfurther verify the effectiveness of our approach, we deploy the controller\nlearned in the simulation on a 12-DoF quadrupedal robot, and it can\nsuccessfully traverse challenging scenarios with efficient gaits.",
    "descriptor": "",
    "authors": [
      "Haojie Shi",
      "Bo Zhou",
      "Hongsheng Zeng",
      "Fan Wang",
      "Yueqiang Dong",
      "Jiangyong Li",
      "Kang Wang",
      "Hao Tian",
      "Max Q.-H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06409"
  },
  {
    "id": "arXiv:2109.06415",
    "title": "Gradient Imitation Reinforcement Learning for Low Resource Relation  Extraction",
    "abstract": "Low-resource Relation Extraction (LRE) aims to extract relation facts from\nlimited labeled corpora when human annotation is scarce. Existing works either\nutilize self-training scheme to generate pseudo labels that will cause the\ngradual drift problem, or leverage meta-learning scheme which does not solicit\nfeedback explicitly. To alleviate selection bias due to the lack of feedback\nloops in existing LRE learning paradigms, we developed a Gradient Imitation\nReinforcement Learning method to encourage pseudo label data to imitate the\ngradient descent direction on labeled data and bootstrap its optimization\ncapability through trial and error. We also propose a framework called GradLRE,\nwhich handles two major scenarios in low-resource relation extraction. Besides\nthe scenario where unlabeled data is sufficient, GradLRE handles the situation\nwhere no unlabeled data is available, by exploiting a contextualized\naugmentation method to generate data. Experimental results on two public\ndatasets demonstrate the effectiveness of GradLRE on low resource relation\nextraction when comparing with baselines.",
    "descriptor": "\nComments: In EMNLP 2021 as a long paper. Code and data available at this https URL\n",
    "authors": [
      "Xuming Hu",
      "Chenwei Zhang",
      "Yawen Yang",
      "Xiaohe Li",
      "Li Lin",
      "Lijie Wen",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06415"
  },
  {
    "id": "arXiv:2109.06416",
    "title": "MMCoVaR: Multimodal COVID-19 Vaccine Focused Data Repository for Fake  News Detection and a Baseline Architecture for Classification",
    "abstract": "The outbreak of COVID-19 has resulted in an \"infodemic\" that has encouraged\nthe propagation of misinformation about COVID-19 and cure methods which, in\nturn, could negatively affect the adoption of recommended public health\nmeasures in the larger population. In this paper, we provide a new multimodal\n(consisting of images, text and temporal information) labeled dataset\ncontaining news articles and tweets on the COVID-19 vaccine. We collected 2,593\nnews articles from 80 publishers for one year between Feb 16th 2020 to May 8th\n2021 and 24184 Twitter posts (collected between April 17th 2021 to May 8th\n2021). We combine ratings from three news media ranking sites: Medias Bias\nChart, News Guard and Media Bias/Fact Check (MBFC) to classify the news dataset\ninto two levels of credibility: reliable and unreliable. The combination of\nthree filters allows for higher precision of labeling. We also propose a stance\ndetection mechanism to annotate tweets into three levels of credibility:\nreliable, unreliable and inconclusive. We provide several statistics as well as\nother analytics like, publisher distribution, publication date distribution,\ntopic analysis, etc. We also provide a novel architecture that classifies the\nnews data into misinformation or truth to provide a baseline performance for\nthis dataset. We find that the proposed architecture has an F-Score of 0.919\nand accuracy of 0.882 for fake news detection. Furthermore, we provide\nbenchmark performance for misinformation detection on tweet dataset. This new\nmultimodal dataset can be used in research on COVID-19 vaccine, including\nmisinformation detection, influence of fake COVID-19 vaccine information, etc.",
    "descriptor": "\nComments: 12 pages, 8 figures. This paper has been accepted for publication in ASONAM 2021\n",
    "authors": [
      "Mingxuan Chen",
      "Xinqiao Chu",
      "K.P. Subbalakshmi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06416"
  },
  {
    "id": "arXiv:2109.06417",
    "title": "Cross-document Event Identity via Dense Annotation",
    "abstract": "In this paper, we study the identity of textual events from different\ndocuments. While the complex nature of event identity is previously studied\n(Hovy et al., 2013), the case of events across documents is unclear. Prior work\non cross-document event coreference has two main drawbacks. First, they\nrestrict the annotations to a limited set of event types. Second, they\ninsufficiently tackle the concept of event identity. Such annotation setup\nreduces the pool of event mentions and prevents one from considering the\npossibility of quasi-identity relations. We propose a dense annotation approach\nfor cross-document event coreference, comprising a rich source of event\nmentions and a dense annotation effort between related document pairs. To this\nend, we design a new annotation workflow with careful quality control and an\neasy-to-use annotation interface. In addition to the links, we further collect\noverlapping event contexts, including time, location, and participants, to shed\nsome light on the relation between identity decisions and context. We present\nan open-access dataset for cross-document event coreference, CDEC-WN, collected\nfrom English Wikinews and open-source our annotation toolkit to encourage\nfurther research on cross-document tasks.",
    "descriptor": "\nComments: CoNLL 2021 camera-ready\n",
    "authors": [
      "Adithya Pratapa",
      "Zhengzhong Liu",
      "Kimihiro Hasegawa",
      "Linwei Li",
      "Yukari Yamakawa",
      "Shikun Zhang",
      "Teruko Mitamura"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06417"
  },
  {
    "id": "arXiv:2109.06422",
    "title": "Cross-Region Domain Adaptation for Class-level Alignment",
    "abstract": "Semantic segmentation requires a lot of training data, which necessitates\ncostly annotation. There have been many studies on unsupervised domain\nadaptation (UDA) from one domain to another, e.g., from computer graphics to\nreal images. However, there is still a gap in accuracy between UDA and\nsupervised training on native domain data. It is arguably attributable to\nclass-level misalignment between the source and target domain data. To cope\nwith this, we propose a method that applies adversarial training to align two\nfeature distributions in the target domain. It uses a self-training framework\nto split the image into two regions (i.e., trusted and untrusted), which form\ntwo distributions to align in the feature space. We term this approach\ncross-region adaptation (CRA) to distinguish from the previous methods of\naligning different domain distributions, which we call cross-domain adaptation\n(CDA). CRA can be applied after any CDA method. Experimental results show that\nthis always improves the accuracy of the combined CDA method, having updated\nthe state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Zhijie Wang",
      "Xing Liu",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06422"
  },
  {
    "id": "arXiv:2109.06424",
    "title": "Statistical Inference: The Missing Piece of RecSys Experiment  Reliability Discourse",
    "abstract": "This paper calls attention to the missing component of the recommender system\nevaluation process: Statistical Inference. There is active research in several\ncomponents of the recommender system evaluation process: selecting baselines,\nstandardizing benchmarks, and target item sampling. However, there has not yet\nbeen significant work on the role and use of statistical inference for\nanalyzing recommender system evaluation results. In this paper, we argue that\nthe use of statistical inference is a key component of the evaluation process\nthat has not been given sufficient attention. We support this argument with\nsystematic review of recent RecSys papers to understand how statistical\ninference is currently being used, along with a brief survey of studies that\nhave been done on the use of statistical inference in the information retrieval\ncommunity. We present several challenges that exist for inference in\nrecommendation experiment which buttresses the need for empirical studies to\naid with appropriately selecting and applying statistical inference techniques.",
    "descriptor": "",
    "authors": [
      "Ngozi Ihemelandu",
      "Michael D. Ekstrand"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.06424"
  },
  {
    "id": "arXiv:2109.06427",
    "title": "Commonsense-Focused Dialogues for Response Generation: An Empirical  Study",
    "abstract": "Smooth and effective communication requires the ability to perform latent or\nexplicit commonsense inference. Prior commonsense reasoning benchmarks (such as\nSocialIQA and CommonsenseQA) mainly focus on the discriminative task of\nchoosing the right answer from a set of candidates, and do not involve\ninteractive language generation as in dialogue. Moreover, existing dialogue\ndatasets do not explicitly focus on exhibiting commonsense as a facet. In this\npaper, we present an empirical study of commonsense in dialogue response\ngeneration. We first auto-extract commonsensical dialogues from existing\ndialogue datasets by leveraging ConceptNet, a commonsense knowledge graph.\nFurthermore, building on social contexts/situations in SocialIQA, we collect a\nnew dialogue dataset with 25K dialogues aimed at exhibiting social commonsense\nin an interactive setting. We evaluate response generation models trained using\nthese datasets and find that models trained on both extracted and our collected\ndata produce responses that consistently exhibit more commonsense than\nbaselines. Finally we propose an approach for automatic evaluation of\ncommonsense that relies on features derived from ConceptNet and pre-trained\nlanguage and dialog models, and show reasonable correlation with human\nevaluation of responses' commonsense quality. We are releasing a subset of our\ncollected data, Commonsense-Dialogues, containing about 11K dialogs.",
    "descriptor": "\nComments: Accepted at SIGDIAL 2021. 12 pages, 5 tables\n",
    "authors": [
      "Pei Zhou",
      "Karthik Gopalakrishnan",
      "Behnam Hedayatnia",
      "Seokhwan Kim",
      "Jay Pujara",
      "Xiang Ren",
      "Yang Liu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06427"
  },
  {
    "id": "arXiv:2109.06429",
    "title": "Knowledge-guided Self-supervised Learning for estimating River-Basin  Characteristics",
    "abstract": "Machine Learning is being extensively used in hydrology, especially\nstreamflow prediction of basins/watersheds. Basin characteristics are essential\nfor modeling the rainfall-runoff response of these watersheds and therefore\ndata-driven methods must take into account this ancillary characteristics data.\nHowever there are several limitations, namely uncertainty in the measured\ncharacteristics, partially missing characteristics for some of the basins or\nunknown characteristics that may not be present in the known measured set. In\nthis paper we present an inverse model that uses a knowledge-guided\nself-supervised learning algorithm to infer basin characteristics using the\nmeteorological drivers and streamflow response data. We evaluate our model on\nthe the CAMELS dataset and the results validate its ability to reduce\nmeasurement uncertainty, impute missing characteristics, and identify unknown\ncharacteristics.",
    "descriptor": "\nComments: Submitted to Science-Guided AI, SGAI-AAAI-21\n",
    "authors": [
      "Rahul Ghosh",
      "Arvind Renganathan",
      "Ankush Khandelwal",
      "Xiaowei Jia",
      "Xiang Li",
      "John Neiber",
      "Chris Duffy",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06429"
  },
  {
    "id": "arXiv:2109.06431",
    "title": "Exploring the Long Short-Term Dependencies to Infer Shot Influence in  Badminton Matches",
    "abstract": "Identifying significant shots in a rally is important for evaluating players'\nperformance in badminton matches. While there are several studies that have\nquantified player performance in other sports, analyzing badminton data is\nremained untouched. In this paper, we introduce a badminton language to fully\ndescribe the process of the shot and propose a deep learning model composed of\na novel short-term extractor and a long-term encoder for capturing a\nshot-by-shot sequence in a badminton rally by framing the problem as predicting\na rally result. Our model incorporates an attention mechanism to enable the\ntransparency of the action sequence to the rally result, which is essential for\nbadminton experts to gain interpretable predictions. Experimental evaluation\nbased on a real-world dataset demonstrates that our proposed model outperforms\nthe strong baselines. The source code is publicly available at\nhttps://github.com/yao0510/Shot-Influence.",
    "descriptor": "\nComments: 6 pages, accepted by ICDM 2021\n",
    "authors": [
      "Wei-Yao Wang",
      "Teng-Fong Chan",
      "Hui-Kuo Yang",
      "Chih-Chuan Wang",
      "Yao-Chung Fan",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06431"
  },
  {
    "id": "arXiv:2109.06432",
    "title": "Improved Few-shot Segmentation by Redifinition of the Roles of  Multi-level CNN Features",
    "abstract": "This study is concerned with few-shot segmentation, i.e., segmenting the\nregion of an unseen object class in a query image, given support image(s) of\nits instances. The current methods rely on the pretrained CNN features of the\nsupport and query images. The key to good performance depends on the proper\nfusion of their mid-level and high-level features; the former contains\nshape-oriented information, while the latter has class-oriented information.\nCurrent state-of-the-art methods follow the approach of Tian et al., which\ngives the mid-level features the primary role and the high-level features the\nsecondary role. In this paper, we reinterpret this widely employed approach by\nredifining the roles of the multi-level features; we swap the primary and\nsecondary roles. Specifically, we regard that the current methods improve the\ninitial estimate generated from the high-level features using the mid-level\nfeatures. This reinterpretation suggests a new application of the current\nmethods: to apply the same network multiple times to iteratively update the\nestimate of the object's region, starting from its initial estimate. Our\nexperiments show that this method is effective and has updated the previous\nstate-of-the-art on COCO-20$^i$ in the 1-shot and 5-shot settings and on\nPASCAL-5$^i$ in the 1-shot setting.",
    "descriptor": "",
    "authors": [
      "Zhijie Wang",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06432"
  },
  {
    "id": "arXiv:2109.06436",
    "title": "YES SIR!Optimizing Semantic Space of Negatives with Self-Involvement  Ranker",
    "abstract": "Pre-trained model such as BERT has been proved to be an effective tool for\ndealing with Information Retrieval (IR) problems. Due to its inspiring\nperformance, it has been widely used to tackle with real-world IR problems such\nas document ranking. Recently, researchers have found that selecting \"hard\"\nrather than \"random\" negative samples would be beneficial for fine-tuning\npre-trained models on ranking tasks. However, it remains elusive how to\nleverage hard negative samples in a principled way. To address the\naforementioned issues, we propose a fine-tuning strategy for document ranking,\nnamely Self-Involvement Ranker (SIR), to dynamically select hard negative\nsamples to construct high-quality semantic space for training a high-quality\nranking model. Specifically, SIR consists of sequential compressors implemented\nwith pre-trained models. Front compressor selects hard negative samples for\nrear compressor. Moreover, SIR leverages supervisory signal to adaptively\nadjust semantic space of negative samples. Finally, supervisory signal in rear\ncompressor is computed based on condition probability and thus can control\nsample dynamic and further enhance the model performance. SIR is a lightweight\nand general framework for pre-trained models, which simplifies the ranking\nprocess in industry practice. We test our proposed solution on MS MARCO with\ndocument ranking setting, and the results show that SIR can significantly\nimprove the ranking performance of various pre-trained models. Moreover, our\nmethod became the new SOTA model anonymously on MS MARCO Document ranking\nleaderboard in May 2021.",
    "descriptor": "",
    "authors": [
      "Ruizhi Pu",
      "Xinyu Zhang",
      "Ruofei Lai",
      "Zikai Guo",
      "Yinxia Zhang",
      "Hao Jiang",
      "Yongkang Wu",
      "Yantao Jia",
      "Zhicheng Dou",
      "Zhao Cao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06436"
  },
  {
    "id": "arXiv:2109.06437",
    "title": "Uncovering Implicit Gender Bias in Narratives through Commonsense  Inference",
    "abstract": "Pre-trained language models learn socially harmful biases from their training\ncorpora, and may repeat these biases when used for generation. We study gender\nbiases associated with the protagonist in model-generated stories. Such biases\nmay be expressed either explicitly (\"women can't park\") or implicitly (e.g. an\nunsolicited male character guides her into a parking space). We focus on\nimplicit biases, and use a commonsense reasoning engine to uncover them.\nSpecifically, we infer and analyze the protagonist's motivations, attributes,\nmental states, and implications on others. Our findings regarding implicit\nbiases are in line with prior work that studied explicit biases, for example\nshowing that female characters' portrayal is centered around appearance, while\nmale figures' focus on intellect.",
    "descriptor": "\nComments: Accepted at Findings of EMNLP 2021\n",
    "authors": [
      "Tenghao Huang",
      "Faeze Brahman",
      "Vered Shwartz",
      "Snigdha Chaturvedi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06437"
  },
  {
    "id": "arXiv:2109.06438",
    "title": "Learning to Drive on the Wrong Side of the Road: How American Computing  Came to Rely on Conferences for Primary Publication",
    "abstract": "In contrast to other fields where conferences are typically for less polished\nor in-progress research, computing has long relied on referred conference\npapers as a venue for the final publication of completed research. While\nfrequently a topic of informal discussion, debates about its efficacy, or\nlibrary science research, the development of this phenomena has not been\nhistorically analyzed. This paper presents the first systematic investigation\nof the development of modern computing publications. It relies on\nsemi-structured interviews with eight computing professors from diverse\nbackgrounds to understand how researchers experienced changes in publication\nculture over time. Ultimately, the article concludes that the early presence of\nnon-academic practitioners in research and a degree of \"path dependence\"or a\ntendency to continue on the established path rather than the most economically\noptimal one\" allowed conferences to gain and hold prominence as the field\nexploded in popularity during the 1980s.",
    "descriptor": "\nComments: Undergraduate thesis accepted to the History department at North Carolina State for Completion of an honors bachelor's of arts\n",
    "authors": [
      "Elijah Bouma-Sims"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.06438"
  },
  {
    "id": "arXiv:2109.06440",
    "title": "Complexity-aware Adaptive Training and Inference for Edge-Cloud  Distributed AI Systems",
    "abstract": "The ubiquitous use of IoT and machine learning applications is creating large\namounts of data that require accurate and real-time processing. Although\nedge-based smart data processing can be enabled by deploying pretrained models,\nthe energy and memory constraints of edge devices necessitate distributed deep\nlearning between the edge and the cloud for complex data. In this paper, we\npropose a distributed AI system to exploit both the edge and the cloud for\ntraining and inference. We propose a new architecture, MEANet, with a main\nblock, an extension block, and an adaptive block for the edge. The inference\nprocess can terminate at either the main block, the extension block, or the\ncloud. The MEANet is trained to categorize inputs into easy/hard/complex\nclasses. The main block identifies instances of easy/hard classes and\nclassifies easy classes with high confidence. Only data with high probabilities\nof belonging to hard classes would be sent to the extension block for\nprediction. Further, only if the neural network at the edge shows low\nconfidence in the prediction, the instance is considered complex and sent to\nthe cloud for further processing. The training technique lends to the majority\nof inference on edge devices while going to the cloud only for a small set of\ncomplex jobs, as determined by the edge. The performance of the proposed system\nis evaluated via extensive experiments using modified models of ResNets and\nMobileNetV2 on CIFAR-100 and ImageNet datasets. The results show that the\nproposed distributed model has improved accuracy and energy consumption,\nindicating its capacity to adapt.",
    "descriptor": "\nComments: 41st IEEE International Conference on Distributed Computing Systems, 2021\n",
    "authors": [
      "Yinghan Long",
      "Indranil Chakraborty",
      "Gopalakrishnan Srinivasan",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06440"
  },
  {
    "id": "arXiv:2109.06441",
    "title": "Structure-Enhanced Pop Music Generation via Harmony-Aware Learning",
    "abstract": "Automatically composing pop music with a satisfactory structure is an\nattractive but challenging topic. Although the musical structure is easy to be\nperceived by human, it is difficult to be described clearly and defined\naccurately. And it is still far from being solved that how we should model the\nstructure in pop music generation. In this paper, we propose to leverage\nharmony-aware learning for structure-enhanced pop music generation. On the one\nhand, one of the participants of harmony, chord, represents the harmonic set of\nmultiple notes, which is integrated closely with the spatial structure of\nmusic, texture. On the other hand, the other participant of harmony, chord\nprogression, usually accompanies with the development of the music, which\npromotes the temporal structure of music, form. Besides, when chords evolve\ninto chord progression, the texture and the form can be bridged by the harmony\nnaturally, which contributes to the joint learning of the two structures.\nFurthermore, we propose the Harmony-Aware Hierarchical Music Transformer (HAT),\nwhich can exploit the structure adaptively from the music, and interact on the\nmusic tokens at multiple levels to enhance the signals of the structure in\nvarious musical elements. Results of subjective and objective evaluations\ndemonstrate that HAT significantly improves the quality of generated music,\nespecially in the structureness.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Xueyao Zhang",
      "Jinchao Zhang",
      "Yao Qiu",
      "Li Wang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.06441"
  },
  {
    "id": "arXiv:2109.06442",
    "title": "Domain Sparsification of Discrete Distributions using Entropic  Independence",
    "abstract": "We present a framework for speeding up the time it takes to sample from\ndiscrete distributions $\\mu$ defined over subsets of size $k$ of a ground set\nof $n$ elements, in the regime $k\\ll n$. We show that having estimates of\nmarginals $\\mathbb{P}_{S\\sim \\mu}[i\\in S]$, the task of sampling from $\\mu$ can\nbe reduced to sampling from distributions $\\nu$ supported on size $k$ subsets\nof a ground set of only $n^{1-\\alpha}\\cdot \\operatorname{poly}(k)$ elements.\nHere, $1/\\alpha\\in [1, k]$ is the parameter of entropic independence for $\\mu$.\nFurther, the sparsified distributions $\\nu$ are obtained by applying a sparse\n(mostly $0$) external field to $\\mu$, an operation that often retains\nalgorithmic tractability of sampling from $\\nu$. This phenomenon, which we dub\ndomain sparsification, allows us to pay a one-time cost of estimating the\nmarginals of $\\mu$, and in return reduce the amortized cost needed to produce\nmany samples from the distribution $\\mu$, as is often needed in upstream tasks\nsuch as counting and inference.\nFor a wide range of distributions where $\\alpha=\\Omega(1)$, our result\nreduces the domain size, and as a corollary, the cost-per-sample, by a\n$\\operatorname{poly}(n)$ factor. Examples include monomers in a monomer-dimer\nsystem, non-symmetric determinantal point processes, and partition-constrained\nStrongly Rayleigh measures. Our work significantly extends the reach of prior\nwork of Anari and Derezi\\'nski who obtained domain sparsification for\ndistributions with a log-concave generating polynomial (corresponding to\n$\\alpha=1$). As a corollary of our new analysis techniques, we also obtain a\nless stringent requirement on the accuracy of marginal estimates even for the\ncase of log-concave polynomials; roughly speaking, we show that constant-factor\napproximation is enough for domain sparsification, improving over $O(1/k)$\nrelative error established in prior work.",
    "descriptor": "",
    "authors": [
      "Nima Anari",
      "Micha\u0142 Derezi\u0144ski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.06442"
  },
  {
    "id": "arXiv:2109.06443",
    "title": "Designing a Combinatorial Financial Options Market",
    "abstract": "Financial options are contracts that specify the right to buy or sell an\nunderlying asset at a strike price by an expiration date. Standard exchanges\noffer options of predetermined strike values and trade options of different\nstrikes independently, even for those written on the same underlying asset.\nSuch independent market design can introduce arbitrage opportunities and lead\nto the thin market problem. The paper first proposes a mechanism that\nconsolidates and matches orders on standard options related to the same\nunderlying asset, while providing agents the flexibility to specify any custom\nstrike value. The mechanism generalizes the classic double auction, runs in\ntime polynomial to the number of orders, and poses no risk to the exchange,\nregardless of the value of the underlying asset at expiration. Empirical\nanalysis on real-market options data shows that the mechanism can find new\nmatches for options of different strike prices and reduce bid-ask spreads.\nExtending standard options written on a single asset, we propose and define a\nnew derivative instrument -- combinatorial financial options that offer\ncontract holders the right to buy or sell any linear combination of multiple\nunderlying assets. We generalize our single-asset mechanism to match options\nwritten on different combinations of assets, and prove that optimal clearing of\ncombinatorial financial options is coNP-hard. To facilitate market operations,\nwe propose an algorithm that finds the exact optimal match through iterative\nconstraint generation, and evaluate its performance on synthetically generated\ncombinatorial options markets of different scales. As option prices reveal the\nmarket's collective belief of an underlying asset's future value, a\ncombinatorial options market enables the expression of aggregate belief about\nfuture correlations among assets.",
    "descriptor": "\nComments: To appear in EC21\n",
    "authors": [
      "Xintong Wang",
      "David M. Pennock",
      "Nikhil R. Devanur",
      "David M. Rothschild",
      "Biaoshuai Tao",
      "Michael P. Wellman"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.06443"
  },
  {
    "id": "arXiv:2109.06445",
    "title": "Optimal Qubit Mapping with Simultaneous Gate Absorption",
    "abstract": "Before quantum error correction (QEC) is achieved, quantum computers focus on\nnoisy intermediate-scale quantum (NISQ) applications. Compared to the\nwell-known quantum algorithms requiring QEC, like Shor's or Grover's algorithm,\nNISQ applications have different structures and properties to exploit in\ncompilation. A key step in compilation is mapping the qubits in the program to\nphysical qubits on a given quantum computer, which has been shown to be an\nNP-hard problem. In this paper, we present OLSQ-GA, an optimal qubit mapper\nwith a key feature of simultaneous SWAP gate absorption during qubit mapping,\nwhich we show to be a very effective optimization technique for NISQ\napplications. For the class of quantum approximate optimization algorithm\n(QAOA), an important NISQ application, OLSQ-GA reduces depth by up to 50.0% and\nSWAP count by 100% compared to other state-of-the-art methods, which translates\nto 55.9% fidelity improvement. The solution optimality of OLSQ-GA is achieved\nby the exact SMT formulation. For better scalability, we augment our approach\nwith additional constraints in the form of initial mapping or alternating\nmatching, which speeds up OLSQ-GA by up to 272X with no or little loss of\noptimality.",
    "descriptor": "\nComments: 8 pages, 8 figures, to appear in ICCAD'21\n",
    "authors": [
      "Bochen Tan",
      "Jason Cong"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.06445"
  },
  {
    "id": "arXiv:2109.06446",
    "title": "Multi-modal Motion Prediction with Transformer-based Neural Network for  Autonomous Driving",
    "abstract": "Predicting the behaviors of other agents on the road is critical for\nautonomous driving to ensure safety and efficiency. However, the challenging\npart is how to represent the social interactions between agents and output\ndifferent possible trajectories with interpretability. In this paper, we\nintroduce a neural prediction framework based on the Transformer structure to\nmodel the relationship among the interacting agents and extract the attention\nof the target agent on the map waypoints. Specifically, we organize the\ninteracting agents into a graph and utilize the multi-head attention\nTransformer encoder to extract the relations between them. To address the\nmulti-modality of motion prediction, we propose a multi-modal attention\nTransformer encoder, which modifies the multi-head attention mechanism to\nmulti-modal attention, and each predicted trajectory is conditioned on an\nindependent attention mode. The proposed model is validated on the Argoverse\nmotion forecasting dataset and shows state-of-the-art prediction accuracy while\nmaintaining a small model size and a simple training process. We also\ndemonstrate that the multi-modal attention module can automatically identify\ndifferent modes of the target agent's attention on the map, which improves the\ninterpretability of the model.",
    "descriptor": "",
    "authors": [
      "Zhiyu Huang",
      "Xiaoyu Mo",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06446"
  },
  {
    "id": "arXiv:2109.06448",
    "title": "Tesla-Rapture: A Lightweight Gesture Recognition System from mmWave  Radar Point Clouds",
    "abstract": "We present Tesla-Rapture, a gesture recognition interface for point clouds\ngenerated by mmWave Radars. State of the art gesture recognition models are\neither too resource consuming or not sufficiently accurate for integration into\nreal-life scenarios using wearable or constrained equipment such as IoT devices\n(e.g. Raspberry PI), XR hardware (e.g. HoloLens), or smart-phones. To tackle\nthis issue, we developed Tesla, a Message Passing Neural Network (MPNN) graph\nconvolution approach for mmWave radar point clouds. The model outperforms the\nstate of the art on two datasets in terms of accuracy while reducing the\ncomputational complexity and, hence, the execution time. In particular, the\napproach, is able to predict a gesture almost 8 times faster than the most\naccurate competitor. Our performance evaluation in different scenarios\n(environments, angles, distances) shows that Tesla generalizes well and\nimproves the accuracy up to 20% in challenging scenarios like a through-wall\nsetting and sensing at extreme angles. Utilizing Tesla, we develop\nTesla-Rapture, a real-time implementation using a mmWave Radar on a Raspberry\nPI 4 and evaluate its accuracy and time-complexity. We also publish the source\ncode, the trained models, and the implementation of the model for embedded\ndevices.",
    "descriptor": "\nComments: The paper is submitted to the journal of Transactions on Mobile Computing. And it is still under review\n",
    "authors": [
      "Dariush Salami",
      "Ramin Hasibi",
      "Sameera Palipana",
      "Petar Popovski",
      "Tom Michoel",
      "Stephan Sigg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06448"
  },
  {
    "id": "arXiv:2109.06449",
    "title": "Deep hierarchical reinforcement agents for automated penetration testing",
    "abstract": "Penetration testing the organised attack of a computer system in order to\ntest existing defences has been used extensively to evaluate network security.\nThis is a time consuming process and requires in-depth knowledge for the\nestablishment of a strategy that resembles a real cyber-attack. This paper\npresents a novel deep reinforcement learning architecture with hierarchically\nstructured agents called HA-DRL, which employs an algebraic action\ndecomposition strategy to address the large discrete action space of an\nautonomous penetration testing simulator where the number of actions is\nexponentially increased with the complexity of the designed cybersecurity\nnetwork. The proposed architecture is shown to find the optimal attacking\npolicy faster and more stably than a conventional deep Q-learning agent which\nis commonly used as a method to apply artificial intelligence in automatic\npenetration testing.",
    "descriptor": "\nComments: Presented at 1st International Workshop on Adaptive Cyber Defense, 2021 (arXiv:2108.08476)\n",
    "authors": [
      "Khuong Tran",
      "Ashlesha Akella",
      "Maxwell Standen",
      "Junae Kim",
      "David Bowman",
      "Toby Richer",
      "Chin-Teng Lin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06449"
  },
  {
    "id": "arXiv:2109.06450",
    "title": "A machine-learning framework for daylight and visual comfort assessment  in early design stages",
    "abstract": "This research is mainly focused on the assessment of machine learning\nalgorithms in the prediction of daylight and visual comfort metrics in the\nearly design stages. A dataset was primarily developed from 2880 simulations\nderived from Honeybee for Grasshopper. The simulations were done for a shoebox\nspace with a one side window. The alternatives emerged from different physical\nfeatures, including room dimensions, interior surfaces reflectance, window\ndimensions and orientations, number of windows, and shading states. 5 metrics\nwere used for daylight evaluations, including UDI, sDA, mDA, ASE, and sVD.\nQuality Views were analyzed for the same shoebox spaces via a grasshopper-based\nalgorithm, developed from the LEED v4 evaluation framework for Quality Views.\nThe dataset was further analyzed with an Artificial Neural Network algorithm\nwritten in Python. The accuracy of the predictions was estimated at 97% on\naverage. The developed model could be used in early design stages analyses\nwithout the need for time-consuming simulations in previously used platforms\nand programs.",
    "descriptor": "\nComments: This paper was presented at the 2021 IBPSA (International Building Performance Simulation Association) Conference in Bruges, Belgium\n",
    "authors": [
      "Hanieh Nourkojouri",
      "Zahra Sadat Zomorodian",
      "Mohammad Tahsildoost",
      "Zohreh Shaghaghian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06450"
  },
  {
    "id": "arXiv:2109.06452",
    "title": "Spiking Neural Networks for Visual Place Recognition via Weighted  Neuronal Assignments",
    "abstract": "Spiking neural networks (SNNs) offer both compelling potential advantages,\nincluding energy efficiency and low latencies, and challenges including the\nnon-differentiable nature of event spikes. Much of the initial research in this\narea has converted deep neural networks to equivalent SNNs, but this conversion\napproach potentially negates some of the potential advantages of SNN-based\napproaches developed from scratch. One promising area for high performance SNNs\nis template matching and image recognition. This research introduces the first\nhigh performance SNN for the Visual Place Recognition (VPR) task: given a query\nimage, the SNN has to find the closest match out of a list of reference images.\nAt the core of this new system is a novel assignment scheme that implements a\nform of ambiguity-informed salience, by up-weighting single-place-encoding\nneurons and down-weighting \"ambiguous\" neurons that respond to multiple\ndifferent reference places. In a range of experiments on the challenging Oxford\nRobotCar and Nordland datasets, we show that our SNN achieves comparable VPR\nperformance to state-of-the-art and classical techniques, and degrades\ngracefully in performance with an increasing number of reference places. Our\nresults provide a significant milestone towards SNNs that can provide robust,\nenergy-efficient and low latency robot localization.",
    "descriptor": "\nComments: 8 pages, 6 figures, under review\n",
    "authors": [
      "Somayeh Hussaini",
      "Michael Milford",
      "Tobias Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06452"
  },
  {
    "id": "arXiv:2109.06458",
    "title": "Exploring the Connection between Knowledge Distillation and Logits  Matching",
    "abstract": "Knowledge distillation is a generalized logits matching technique for model\ncompression. Their equivalence is previously established on the condition of\n$\\textit{infinity temperature}$ and $\\textit{zero-mean normalization}$. In this\npaper, we prove that with only $\\textit{infinity temperature}$, the effect of\nknowledge distillation equals to logits matching with an extra regularization.\nFurthermore, we reveal that an additional weaker condition --\n$\\textit{equal-mean initialization}$ rather than the original\n$\\textit{zero-mean normalization}$ already suffices to set up the equivalence.\nThe key to our proof is we realize that in modern neural networks with the\ncross-entropy loss and softmax activation, the mean of back-propagated gradient\non logits always keeps zero.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Defang Chen",
      "Can Wang",
      "Yan Feng",
      "Chun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06458"
  },
  {
    "id": "arXiv:2109.06459",
    "title": "A Machine-learning Framework for Acoustic Design Assessment in Early  Design Stages",
    "abstract": "In time-cost scale model studies, predicting acoustic performance by using\nsimulation methods is a commonly used method that is preferred. In this field,\nbuilding acoustic simulation tools are complicated by several challenges,\nincluding the high cost of acoustic tools, the need for acoustic expertise, and\nthe time-consuming process of acoustic simulation. The goal of this project is\nto introduce a simple model with a short calculation time to estimate the room\nacoustic condition in the early design stages of the building. This paper\npresents a working prototype for a new method of machine learning (ML) to\napproximate a series of typical room acoustic parameters using only geometric\ndata as input characteristics. A novel dataset consisting of acoustical\nsimulations of a single room with 2916 different configurations are used to\ntrain and test the proposed model. In the stimulation process, features that\ninclude room dimensions, window size, material absorption coefficient,\nfurniture, and shading type have been analysed by using Pachyderm acoustic\nsoftware. The mentioned dataset is used as the input of seven machine-learning\nmodels based on fully connected Deep Neural Networks (DNN). The average error\nof ML models is between 1% to 3%, and the average error of the new predicted\nsamples after the validation process is between 2% to 12%.",
    "descriptor": "",
    "authors": [
      "Reyhane Abarghooie",
      "Zahra Sadat Zomorodian",
      "Mohammad Tahsildoost",
      "Zohreh Shaghaghian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.06459"
  },
  {
    "id": "arXiv:2109.06466",
    "title": "Task-adaptive Pre-training and Self-training are Complementary for  Natural Language Understanding",
    "abstract": "Task-adaptive pre-training (TAPT) and Self-training (ST) have emerged as the\nmajor semi-supervised approaches to improve natural language understanding\n(NLU) tasks with massive amount of unlabeled data. However, it's unclear\nwhether they learn similar representations or they can be effectively combined.\nIn this paper, we show that TAPT and ST can be complementary with simple TFS\nprotocol by following TAPT -> Finetuning -> Self-training (TFS) process.\nExperimental results show that TFS protocol can effectively utilize unlabeled\ndata to achieve strong combined gains consistently across six datasets covering\nsentiment classification, paraphrase identification, natural language\ninference, named entity recognition and dialogue slot classification. We\ninvestigate various semi-supervised settings and consistently show that gains\nfrom TAPT and ST can be strongly additive by following TFS procedure. We hope\nthat TFS could serve as an important semi-supervised baseline for future NLP\nstudies.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Shiyang Li",
      "Semih Yavuz",
      "Wenhu Chen",
      "Xifeng Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06466"
  },
  {
    "id": "arXiv:2109.06467",
    "title": "Dodging Attack Using Carefully Crafted Natural Makeup",
    "abstract": "Deep learning face recognition models are used by state-of-the-art\nsurveillance systems to identify individuals passing through public areas\n(e.g., airports). Previous studies have demonstrated the use of adversarial\nmachine learning (AML) attacks to successfully evade identification by such\nsystems, both in the digital and physical domains. Attacks in the physical\ndomain, however, require significant manipulation to the human participant's\nface, which can raise suspicion by human observers (e.g. airport security\nofficers). In this study, we present a novel black-box AML attack which\ncarefully crafts natural makeup, which, when applied on a human participant,\nprevents the participant from being identified by facial recognition models. We\nevaluated our proposed attack against the ArcFace face recognition model, with\n20 participants in a real-world setup that includes two cameras, different\nshooting angles, and different lighting conditions. The evaluation results show\nthat in the digital domain, the face recognition system was unable to identify\nall of the participants, while in the physical domain, the face recognition\nsystem was able to identify the participants in only 1.22% of the frames\n(compared to 47.57% without makeup and 33.73% with random natural makeup),\nwhich is below a reasonable threshold of a realistic operational environment.",
    "descriptor": "",
    "authors": [
      "Nitzan Guetta",
      "Asaf Shabtai",
      "Inderjeet Singh",
      "Satoru Momiyama",
      "Yuval Elovici"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06467"
  },
  {
    "id": "arXiv:2109.06469",
    "title": "Deep Denerative Models for Drug Design and Response",
    "abstract": "Designing new chemical compounds with desired pharmaceutical properties is a\nchallenging task and takes years of development and testing. Still, a majority\nof new drugs fail to prove efficient. Recent success of deep generative\nmodeling holds promises of generation and optimization of new molecules. In\nthis review paper, we provide an overview of the current generative models, and\ndescribe necessary biological and chemical terminology, including molecular\nrepresentations needed to understand the field of drug design and drug\nresponse. We present commonly used chemical and biological databases, and tools\nfor generative modeling. Finally, we summarize the current state of generative\nmodeling for drug design and drug response prediction, highlighting the\nstate-of-art approaches and limitations the field is currently facing.",
    "descriptor": "",
    "authors": [
      "Karina Zadorozhny",
      "Lada Nuzhna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06469"
  },
  {
    "id": "arXiv:2109.06471",
    "title": "Identifying Untrustworthy Samples: Data Filtering for Open-domain  Dialogues with Bayesian Optimization",
    "abstract": "Being able to reply with a related, fluent, and informative response is an\nindispensable requirement for building high-quality conversational agents. In\norder to generate better responses, some approaches have been proposed, such as\nfeeding extra information by collecting large-scale datasets with human\nannotations, designing neural conversational models (NCMs) with complex\narchitecture and loss functions, or filtering out untrustworthy samples based\non a dialogue attribute, e.g., Relatedness or Genericness. In this paper, we\nfollow the third research branch and present a data filtering method for\nopen-domain dialogues, which identifies untrustworthy samples from training\ndata with a quality measure that linearly combines seven dialogue attributes.\nThe attribute weights are obtained via Bayesian Optimization (BayesOpt) that\naims to optimize an objective function for dialogue generation iteratively on\nthe validation set. Then we score training samples with the quality measure,\nsort them in descending order, and filter out those at the bottom. Furthermore,\nto accelerate the \"filter-train-evaluate\" iterations involved in BayesOpt on\nlarge-scale datasets, we propose a training framework that integrates maximum\nlikelihood estimation (MLE) and negative training method (NEG). The training\nmethod updates parameters of a trained NCMs on two small sets with newly\nmaintained and removed samples, respectively. Specifically, MLE is applied to\nmaximize the log-likelihood of newly maintained samples, while NEG is used to\nminimize the log-likelihood of newly removed ones. Experimental results on two\ndatasets show that our method can effectively identify untrustworthy samples,\nand NCMs trained on the filtered datasets achieve better performance.",
    "descriptor": "\nComments: Accepted by CIKM 2021\n",
    "authors": [
      "Lei Shen",
      "Haolan Zhan",
      "Xin Shen",
      "Hongshen Chen",
      "Xiaofang Zhao",
      "Xiaodan Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06471"
  },
  {
    "id": "arXiv:2109.06473",
    "title": "Position Paper on Simulating Privacy Dynamics in Recommender Systems",
    "abstract": "In this position paper, we discuss the merits of simulating privacy dynamics\nin recommender systems. We study this issue at hand from two perspectives:\nFirstly, we present a conceptual approach to integrate privacy into recommender\nsystem simulations, whose key elements are privacy agents. These agents can\nenhance users' profiles with different privacy preferences, e.g., their\ninclination to disclose data to the recommender system. Plus, they can protect\nusers' privacy by guarding all actions that could be a threat to privacy. For\nexample, agents can prohibit a user's privacy-threatening actions or apply\nprivacy-enhancing techniques, e.g., Differential Privacy, to make actions less\nthreatening. Secondly, we identify three critical topics for future research in\nprivacy-aware recommender system simulations: (i) How could we model users'\nprivacy preferences and protect users from performing any privacy-threatening\nactions? (ii) To what extent do privacy agents modify the users' document\npreferences? (iii) How do privacy preferences and privacy protections impact\nrecommendations and privacy of others? Our conceptual privacy-aware simulation\napproach makes it possible to investigate the impact of privacy preferences and\nprivacy protection on the micro-level, i.e., a single user, but also on the\nmacro-level, i.e., all recommender system users. With this work, we hope to\npresent perspectives on how privacy-aware simulations could be realized, such\nthat they enable researchers to study the dynamics of privacy within a\nrecommender system.",
    "descriptor": "\nComments: Accepted to the Workshop on Simulation Methods for Recommender Systems at ACM RecSys 2021\n",
    "authors": [
      "Peter M\u00fcllner",
      "Elisabeth Lex",
      "Dominik Kowald"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.06473"
  },
  {
    "id": "arXiv:2109.06474",
    "title": "Space Time Recurrent Memory Network",
    "abstract": "We propose a novel visual memory network architecture for the learning and\ninference problem in the spatial-temporal domain. Different from the popular\ntransformers, we maintain a fixed set of memory slots in our memory network and\nexplore designs to input new information into the memory, combine the\ninformation in different memory slots and decide when to discard old memory\nslots. Finally, this architecture is benchmarked on the video object\nsegmentation and video prediction problems. Through the experiments, we show\nthat our memory architecture can achieve competitive results with\nstate-of-the-art while maintaining constant memory capacity.",
    "descriptor": "",
    "authors": [
      "Hung Nguyen",
      "Fuxin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06474"
  },
  {
    "id": "arXiv:2109.06478",
    "title": "Specification and Validation of Autonomous Driving Systems: A Multilevel  Semantic Framework",
    "abstract": "Autonomous Driving Systems (ADS) are critical dynamic reconfigurable agent\nsystems whose specification and validation raises extremely challenging\nproblems. The paper presents a multilevel semantic framework for the\nspecification of ADS and discusses associated validation problems. The\nframework relies on a formal definition of maps modeling the physical\nenvironment in which vehicles evolve. Maps are directed metric graphs whose\nnodes represent positions and edges represent segments of roads. We study basic\nproperties of maps including their geometric consistency. Furthermore, we study\nposition refinement and segment abstraction relations allowing multilevel\nrepresentation from purely topological to detailed geometric. We progressively\ndefine first order logics for modeling families of maps and distributions of\nvehicles over maps. These are Configuration Logics, which in addition to the\nusual logical connectives are equipped with a coalescing operator to build\nconfigurations of models. We study their semantics and basic properties. We\nillustrate their use for the specification of traffic rules and scenarios\ncharacterizing sequences of scenes. We study various aspects of the validation\nproblem including run-time verification and satisfiability of specifications.\nFinally, we show links of our framework with practical validation needs for ADS\nand advocate its adequacy for addressing the many facets of this challenge.",
    "descriptor": "\nComments: 35 pages, 11 figures, 7 tables\n",
    "authors": [
      "Marius Bozga",
      "Joseph Sifakis"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.06478"
  },
  {
    "id": "arXiv:2109.06479",
    "title": "Large-scale Autonomous Flight with Real-time Semantic SLAM under Dense  Forest Canopy",
    "abstract": "In this letter, we propose an integrated autonomous flight and semantic SLAM\nsystem that can perform long-range missions and real-time semantic mapping in\nhighly cluttered, unstructured, and GPS-denied under-canopy environments.\nFirst, tree trunks and ground planes are detected from LIDAR scans. We use a\nneural network and an instance extraction algorithm to enable semantic\nsegmentation in real time onboard the UAV. Second, detected tree trunk\ninstances are modeled as cylinders and associated across the whole LIDAR\nsequence. This semantic data association constraints both robot poses as well\nas trunk landmark models. The output of semantic SLAM is used in state\nestimation, planning, and control algorithms in real time. The global planner\nrelies on a sparse map to plan the shortest path to the global goal, and the\nlocal trajectory planner uses a small but finely discretized robot-centric map\nto plan a dynamically feasible and collision-free trajectory to the local goal.\nBoth the global path and local trajectory lead to drift-corrected goals, thus\nhelping the UAV execute its mission accurately and safely.",
    "descriptor": "\nComments: Xu Liu and Guilherme V. Nardari contributed equally to this work\n",
    "authors": [
      "Xu Liu",
      "Guilherme V. Nardari",
      "Fernando Cladera Ojeda",
      "Yuezhan Tao",
      "Alex Zhou",
      "Thomas Donnelly",
      "Chao Qu",
      "Steven W. Chen",
      "Roseli A. F. Romero",
      "Camillo J. Taylor",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06479"
  },
  {
    "id": "arXiv:2109.06480",
    "title": "Logic-level Evidence Retrieval and Graph-based Verification Network for  Table-based Fact Verification",
    "abstract": "Table-based fact verification task aims to verify whether the given statement\nis supported by the given semi-structured table. Symbolic reasoning with\nlogical operations plays a crucial role in this task. Existing methods leverage\nprograms that contain rich logical information to enhance the verification\nprocess. However, due to the lack of fully supervised signals in the program\ngeneration process, spurious programs can be derived and employed, which leads\nto the inability of the model to catch helpful logical operations. To address\nthe aforementioned problems, in this work, we formulate the table-based fact\nverification task as an evidence retrieval and reasoning framework, proposing\nthe Logic-level Evidence Retrieval and Graph-based Verification network\n(LERGV). Specifically, we first retrieve logic-level program-like evidence from\nthe given table and statement as supplementary evidence for the table. After\nthat, we construct a logic-level graph to capture the logical relations between\nentities and functions in the retrieved evidence, and design a graph-based\nverification network to perform logic-level graph-based reasoning based on the\nconstructed graph to classify the final entailment relation. Experimental\nresults on the large-scale benchmark TABFACT show the effectiveness of the\nproposed approach.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Qi Shi",
      "Yu Zhang",
      "Qingyu Yin",
      "Ting Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06480"
  },
  {
    "id": "arXiv:2109.06481",
    "title": "AligNART: Non-autoregressive Neural Machine Translation by Jointly  Learning to Estimate Alignment and Translate",
    "abstract": "Non-autoregressive neural machine translation (NART) models suffer from the\nmulti-modality problem which causes translation inconsistency such as token\nrepetition. Most recent approaches have attempted to solve this problem by\nimplicitly modeling dependencies between outputs. In this paper, we introduce\nAligNART, which leverages full alignment information to explicitly reduce the\nmodality of the target distribution. AligNART divides the machine translation\ntask into $(i)$ alignment estimation and $(ii)$ translation with aligned\ndecoder inputs, guiding the decoder to focus on simplified one-to-one\ntranslation. To alleviate the alignment estimation problem, we further propose\na novel alignment decomposition method. Our experiments show that AligNART\noutperforms previous non-iterative NART models that focus on explicit modality\nreduction on WMT14 En$\\leftrightarrow$De and WMT16 Ro$\\rightarrow$En.\nFurthermore, AligNART achieves BLEU scores comparable to those of the\nstate-of-the-art connectionist temporal classification based models on WMT14\nEn$\\leftrightarrow$De. We also observe that AligNART effectively addresses the\ntoken repetition problem even without sequence-level knowledge distillation.",
    "descriptor": "\nComments: Accepted by EMNLP 2021\n",
    "authors": [
      "Jongyoon Song",
      "Sungwon Kim",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06481"
  },
  {
    "id": "arXiv:2109.06485",
    "title": "A Ring Model for Data Anomalies",
    "abstract": "A distributed system keeps consistency by disallowing data anomalies.\nHowever, especially in the database, the definitions of data anomalies in the\ncurrent ANSI standard are controversial. The standard does not include all\nanomalies and does not introduce characters of anomalies. First, the\ndefinitions lack a mathematical formalization and cause ambiguous\ninterpretations. Second, the definitions of anomalies are case-by-case, which\ncould not have a comprehensive understanding of data anomalies. In this paper,\nwe propose a ring anomalies detection method (the bingo model) in the\ndistribution system and applying it to databases. The bingo model introduces\nanomalies construction and gives the base anomalies formalization method. Based\non anomalies we propose consistency levels. We prove the simplified anomaly\nrings in the model to classified anomalies to give the independent consistency\nlevels. We specify the bingo model to databases and find 22 anomalies in\naddition to existing anomalies.",
    "descriptor": "",
    "authors": [
      "Haixiang Li",
      "Xiaoyan Li",
      "Chang Liu",
      "Xiaoyong Du",
      "Wei Lu",
      "Anqun Pan"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2109.06485"
  },
  {
    "id": "arXiv:2109.06486",
    "title": "Conditional Synthetic Data Generation for Robust Machine Learning  Applications with Limited Pandemic Data",
    "abstract": "$\\textbf{Background:}$ At the onset of a pandemic, such as COVID-19, data\nwith proper labeling/attributes corresponding to the new disease might be\nunavailable or sparse. Machine Learning (ML) models trained with the available\ndata, which is limited in quantity and poor in diversity, will often be biased\nand inaccurate. At the same time, ML algorithms designed to fight pandemics\nmust have good performance and be developed in a time-sensitive manner. To\ntackle the challenges of limited data, and label scarcity in the available\ndata, we propose generating conditional synthetic data, to be used alongside\nreal data for developing robust ML models. $\\textbf{Methods:}$ We present a\nhybrid model consisting of a conditional generative flow and a classifier for\nconditional synthetic data generation. The classifier decouples the feature\nrepresentation for the condition, which is fed to the flow to extract the local\nnoise. We generate synthetic data by manipulating the local noise with fixed\nconditional feature representation. We also propose a semi-supervised approach\nto generate synthetic samples in the absence of labels for a majority of the\navailable data. $\\textbf{Results:}$ We performed conditional synthetic\ngeneration for chest computed tomography (CT) scans corresponding to normal,\nCOVID-19, and pneumonia afflicted patients. We show that our method\nsignificantly outperforms existing models both on qualitative and quantitative\nperformance, and our semi-supervised approach can efficiently synthesize\nconditional samples under label scarcity. As an example of downstream use of\nsynthetic data, we show improvement in COVID-19 detection from CT scans with\nconditional synthetic data augmentation.",
    "descriptor": "",
    "authors": [
      "Hari Prasanna Das",
      "Ryan Tran",
      "Japjot Singh",
      "Xiangyu Yue",
      "Geoff Tison",
      "Alberto Sangiovanni-Vincentelli",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06486"
  },
  {
    "id": "arXiv:2109.06488",
    "title": "Multilevel profiling of situation and dialogue-based deep networks for  movie genre classification using movie trailers",
    "abstract": "Automated movie genre classification has emerged as an active and essential\narea of research and exploration. Short duration movie trailers provide useful\ninsights about the movie as video content consists of the cognitive and the\naffective level features. Previous approaches were focused upon either\ncognitive or affective content analysis. In this paper, we propose a novel\nmulti-modality: situation, dialogue, and metadata-based movie genre\nclassification framework that takes both cognition and affect-based features\ninto consideration. A pre-features fusion-based framework that takes into\naccount: situation-based features from a regular snapshot of a trailer that\nincludes nouns and verbs providing the useful affect-based mapping with the\ncorresponding genres, dialogue (speech) based feature from audio, metadata\nwhich together provides the relevant information for cognitive and affect based\nvideo analysis. We also develop the English movie trailer dataset (EMTD), which\ncontains 2000 Hollywood movie trailers belonging to five popular genres:\nAction, Romance, Comedy, Horror, and Science Fiction, and perform\ncross-validation on the standard LMTD-9 dataset for validating the proposed\nframework. The results demonstrate that the proposed methodology for movie\ngenre classification has performed excellently as depicted by the F1 scores,\nprecision, recall, and area under the precision-recall curves.",
    "descriptor": "\nComments: 21 pages, 7 figures\n",
    "authors": [
      "Dinesh Kumar Vishwakarma",
      "Mayank Jindal",
      "Ayush Mittal",
      "Aditya Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06488"
  },
  {
    "id": "arXiv:2109.06489",
    "title": "Instance-wise Graph-based Framework for Multivariate Time Series  Forecasting",
    "abstract": "The multivariate time series forecasting has attracted more and more\nattention because of its vital role in different fields in the real world, such\nas finance, traffic, and weather. In recent years, many research efforts have\nbeen proposed for forecasting multivariate time series. Although some previous\nwork considers the interdependencies among different variables in the same\ntimestamp, existing work overlooks the inter-connections between different\nvariables at different time stamps. In this paper, we propose a simple yet\nefficient instance-wise graph-based framework to utilize the inter-dependencies\nof different variables at different time stamps for multivariate time series\nforecasting. The key idea of our framework is aggregating information from the\nhistorical time series of different variables to the current time series that\nwe need to forecast. We conduct experiments on the Traffic, Electricity, and\nExchange-Rate multivariate time series datasets. The results show that our\nproposed model outperforms the state-of-the-art baseline methods.",
    "descriptor": "",
    "authors": [
      "Wentao Xu",
      "Weiqing Liu",
      "Jiang Bian",
      "Jian Yin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06489"
  },
  {
    "id": "arXiv:2109.06493",
    "title": "Formal Methods for Quantum Programs: A Survey",
    "abstract": "While recent progress in quantum hardware open the door for significant\nspeedup in certain key areas (cryptography, biology, chemistry, optimization,\nmachine learning, etc), quantum algorithms are still hard to implement right,\nand the validation of such quantum programs is achallenge. Moreover, importing\nthe testing and debugging practices at use in classical programming is\nextremely difficult in the quantum case, due to the destructive aspect of\nquantum measurement. As an alternative strategy, formal methods are prone to\nplay a decisive role in the emerging field of quantum software. Recent works\ninitiate solutions for problems occurring at every stage of the development\nprocess: high-level program design, implementation, compilation, etc. We review\nthe induced challenges for an efficient use of formal methods in quantum\ncomputing and the current most promising research directions.",
    "descriptor": "",
    "authors": [
      "Christophe Chareton",
      "S\u00e9bastien Bardin",
      "Dongho Lee",
      "Beno\u00eet Valiron",
      "Renaud Vilmart",
      "Zhaowei Xu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.06493"
  },
  {
    "id": "arXiv:2109.06495",
    "title": "Error analysis for 2D stochastic Navier--Stokes equations in bounded  domains",
    "abstract": "We study a finite-element based space-time discretisation for the 2D\nstochastic Navier-Stokes equations in a bounded domain supplemented with\nno-slip boundary conditions. We prove optimal convergence rates in the energy\nnorm with respect to convergence in probability, that is convergence of order\n(almost) 1/2 in time and 1 in space. This was previously only known in the\nspace-periodic case, where higher order energy estimates for any given\n(deterministic) time are available. In contrast to this, in the Dirichlet-case\nestimates are only known for a (possibly large) stopping time. We overcome this\nproblem by introducing an approach based on discrete stopping times. This\nreplaces the localised estimates (with respect to the sample space) from\nearlier contributions.",
    "descriptor": "",
    "authors": [
      "Dominic Breit",
      "Andreas Prohl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.06495"
  },
  {
    "id": "arXiv:2109.06501",
    "title": "conSultantBERT: Fine-tuned Siamese Sentence-BERT for Matching Jobs and  Job Seekers",
    "abstract": "In this paper we focus on constructing useful embeddings of textual\ninformation in vacancies and resumes, which we aim to incorporate as features\ninto job to job seeker matching models alongside other features. We explain our\ntask where noisy data from parsed resumes, heterogeneous nature of the\ndifferent sources of data, and crosslinguality and multilinguality present\ndomain-specific challenges.\nWe address these challenges by fine-tuning a Siamese Sentence-BERT (SBERT)\nmodel, which we call conSultantBERT, using a large-scale, real-world, and high\nquality dataset of over 270,000 resume-vacancy pairs labeled by our staffing\nconsultants. We show how our fine-tuned model significantly outperforms\nunsupervised and supervised baselines that rely on TF-IDF-weighted feature\nvectors and BERT embeddings. In addition, we find our model successfully\nmatches cross-lingual and multilingual textual content.",
    "descriptor": "\nComments: Accepted at The Workshop on Recommender Systems for Human Resources (RecSys in HR 2021), 8 pages, 1 table, 4 figures\n",
    "authors": [
      "Dor Lavi",
      "Volodymyr Medentsiy",
      "David Graus"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.06501"
  },
  {
    "id": "arXiv:2109.06504",
    "title": "Nonlinear Robust Periodic Output Regulation of Minimum Phase Systems",
    "abstract": "In linear systems theory it's a well known fact that a regulator given by the\ncascade of an oscillatory dynamics, driven by some regulated variables, and of\na stabiliser stabilising the cascade of the plant and of the oscillators has\nthe ability of blocking on the steady state of the regulated variables any\nharmonics matched with the ones of the oscillators. This is the well-celebrated\ninternal model principle. In this paper we are interested to follow the same\ndesign route for a controlled plant that is a nonlinear and periodic system\nwith period T : we add a bunch of linear oscillators, embedding n o harmonics\nthat are multiple of 2$\\pi$/T , driven by a \"regulated variable\" of the\nnonlinear system, we look for a stabiliser for the nonlinear cascade of the\nplant and the oscillators, and we study the asymptotic properties of the\nresulting closedloop regulated variable. In this framework the contributions of\nthe paper are multiple: for specific class of minimum-phase systems we present\na systematic way of designing a stabiliser, which is uniform with respect to n\no , by using a mix of high-gain and forwarding techniques; we prove that the\nresulting closed-loop system has a periodic steady state with period T with a\ndomain of attraction not shrinking with n o ; similarly to the linear case, we\nalso show that the spectrum of the steady state closed-loop regulated variable\ndoes not contain the n harmonics embedded in the bunch of oscillators and that\nthe L 2 norm of the regulated variable is a monotonically decreasing function\nof n o. The results are robust, namely the asymptotic properties on the\nregulated variable hold also in presence of any uncertainties in the controlled\nplant not destroying closed-loop stability.",
    "descriptor": "\nComments: Mathematics of Control, Signals, and Systems, Springer Verlag, In press\n",
    "authors": [
      "Daniele Astolfi",
      "Laurent Praly",
      "Lorenzo Marconi",
      "Mines Paristech"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06504"
  },
  {
    "id": "arXiv:2109.06505",
    "title": "Optimal To-Do List Gamification for Long Term Planning",
    "abstract": "Most people struggle with prioritizing work. While inexact heuristics have\nbeen developed over time, there is still no tractable principled algorithm for\ndeciding which of the many possible tasks one should tackle in any given day,\nmonth, week, or year. Additionally, some people suffer from cognitive biases\nsuch as the present bias, leading to prioritization of their immediate\nexperience over long-term consequences which manifests itself as\nprocrastination and inefficient task prioritization. Our method utilizes\noptimal gamification to help people overcome these problems by incentivizing\neach task by a number of points that convey how valuable it is in the long-run.\nWe extend the previous version of our optimal gamification method with added\nservices for helping people decide which tasks should and should not be done\nwhen there is not enough time to do everything. To improve the efficiency and\nscalability of the to-do list solver, we designed a hierarchical procedure that\ntackles the problem from the top-level goals to fine-grained tasks. We test the\naccuracy of the incentivised to-do list by comparing the performance of the\nstrategy with the points computed exactly using Value Iteration for a variety\nof case studies. These case studies were specifically designed to cover the\ncorner cases to get an accurate judge of performance. Our method yielded the\nsame performance as the exact method for all case studies. To demonstrate its\nfunctionality, we released an API that makes it easy to deploy our method in\nWeb and app services. We assessed the scalability of our method by applying it\nto to-do lists with increasingly larger numbers of goals, sub-goals per goal,\nhierarchically nested levels of subgoals. We found that the method provided\nthrough our API is able to tackle fairly large to-do lists having a 576 tasks.\nThis indicates that our method is suitable for real-world applications.",
    "descriptor": "",
    "authors": [
      "Saksham Consul",
      "Jugoslav Stojcheski",
      "Valkyrie Felso",
      "Falk Lieder"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06505"
  },
  {
    "id": "arXiv:2109.06508",
    "title": "Tribrid: Stance Classification with Neural Inconsistency Detection",
    "abstract": "We study the problem of performing automatic stance classification on social\nmedia with neural architectures such as BERT. Although these architectures\ndeliver impressive results, their level is not yet comparable to the one of\nhumans and they might produce errors that have a significant impact on the\ndownstream task (e.g., fact-checking). To improve the performance, we present a\nnew neural architecture where the input also includes automatically generated\nnegated perspectives over a given claim. The model is jointly learned to make\nsimultaneously multiple predictions, which can be used either to improve the\nclassification of the original perspective or to filter out doubtful\npredictions. In the first case, we propose a weakly supervised method for\ncombining the predictions into a final one. In the second case, we show that\nusing the confidence scores to remove doubtful predictions allows our method to\nachieve human-like performance over the retained information, which is still a\nsizable part of the original input.",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Song Yang",
      "Jacopo Urbani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06508"
  },
  {
    "id": "arXiv:2109.06510",
    "title": "On the bilateral preconditioning for a L2-type all-at-once system  arising from time-space fractional Bloch-Torrey equations",
    "abstract": "Time-space fractional Bloch-Torrey equations are developed by some\nresearchers to investigate the relationship between diffusion and\nfractional-order dynamics. In this paper, we first propose a second-order\nscheme for this equation by employing the recently proposed L2-type formula\n[A.~A.~Alikhanov, C.~Huang, Appl.~Math.~Comput.~(2021) 126545]. Then, we prove\nthe stability and the convergence of this scheme. Based on such the numerical\nscheme, a L2-type all-at-once system is derived. In order to solve this system\nin a parallel-in-time pattern, a bilateral preconditioning technique is\ndesigned according to the special structure of the system. We theoretically\nshow that the condition number of the preconditioned matrix is uniformly\nbounded by a constant for the time fractional order $\\alpha \\in (0,0.3624)$.\nNumerical results are reported to show the efficiency of our method.",
    "descriptor": "\nComments: 24 pages, 6 tables, 4 figures\n",
    "authors": [
      "Yong-Liang Zhao",
      "Jing Wu",
      "Xian-Ming Gu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.06510"
  },
  {
    "id": "arXiv:2109.06511",
    "title": "Geometric analysis of gaits and optimal control for three-link kinematic  swimmers",
    "abstract": "Many robotic systems locomote using gaits - periodic changes of internal\nshape, whose mechanical interaction with the robot`s environment generate\ncharacteristic net displacements. Prominent examples with two shape variables\nare the low Reynolds number 3-link \"Purcell swimmer\" with inputs of 2 joint\nangles and the \"ideal fluid\" swimmer. Gait analysis of these systems allows for\nintelligent decisions to be made about the swimmer`s locomotive properties,\nincreasing the potential for robotic autonomy. In this work, we present\ncomparative analysis of gait optimization using two different methods. The\nfirst method is variational approach of \"Pontryagin`s maximum principle\" (PMP)\nfrom optimal control theory. We apply PMP for several variants of 3-link\nswimmers, with and without incorporation of bounds on joint angles. The second\nmethod is differential-geometric analysis of the gaits based on curvature\n(total Lie bracket) of the local connection for 3-link swimmers. Using\noptimized body-motion coordinates, contour plots of the curvature in shape\nspace gives visualization that enables identifying distance-optimal gaits as\nzero level sets. Combining and comparing results of the two methods enables\nbetter understanding of changes in existence, shape and topology of\ndistance-optimal gait trajectories, depending on the swimmers' parameters.",
    "descriptor": "",
    "authors": [
      "Oren Wiezel",
      "Suresh Ramasamy",
      "Nathan Justus",
      "Yizhar Or",
      "Ross Hatton"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06511"
  },
  {
    "id": "arXiv:2109.06513",
    "title": "Exploring Prompt-based Few-shot Learning for Grounded Dialog Generation",
    "abstract": "Dialog grounding enables conversational models to make full use of external\ninformation to establish multiple desired qualities, such as knowledgeable,\nengaging and empathetic. However, naturally grounded dialog corpora are usually\nnot directly available, which puts forward requirements for the few-shot\nlearning ability of conversational models. Motivated by recent advances in\npre-trained language models and prompt-based learning, in this paper we explore\nprompt-based few-shot learning for grounded dialog generation (GDG). We first\nformulate the prompt construction for GDG tasks, based on which we then conduct\ncomprehensive empirical analysis on two common types of prompting methods:\ntemplate-based prompting and soft-prompting. We demonstrate the potential of\nprompt-based methods in few-shot learning for GDG and provide directions of\nimprovement for future work.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Chujie Zheng",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06513"
  },
  {
    "id": "arXiv:2109.06514",
    "title": "Vision Transformer for Learning Driving Policies in Complex Multi-Agent  Environments",
    "abstract": "Driving in a complex urban environment is a difficult task that requires a\ncomplex decision policy. In order to make informed decisions, one needs to gain\nan understanding of the long-range context and the importance of other\nvehicles. In this work, we propose to use Vision Transformer (ViT) to learn a\ndriving policy in urban settings with birds-eye-view (BEV) input images. The\nViT network learns the global context of the scene more effectively than with\nearlier proposed Convolutional Neural Networks (ConvNets). Furthermore, ViT's\nattention mechanism helps to learn an attention map for the scene which allows\nthe ego car to determine which surrounding cars are important to its next\ndecision. We demonstrate that a DQN agent with a ViT backbone outperforms\nbaseline algorithms with ConvNet backbones pre-trained in various ways. In\nparticular, the proposed method helps reinforcement learning algorithms to\nlearn faster, with increased performance and less data than baselines.",
    "descriptor": "",
    "authors": [
      "Eshagh Kargar",
      "Ville Kyrki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06514"
  },
  {
    "id": "arXiv:2109.06515",
    "title": "Netmarble AI Center's WMT21 Automatic Post-Editing Shared Task  Submission",
    "abstract": "This paper describes Netmarble's submission to WMT21 Automatic Post-Editing\n(APE) Shared Task for the English-German language pair. First, we propose a\nCurriculum Training Strategy in training stages. Facebook Fair's WMT19 news\ntranslation model was chosen to engage the large and powerful pre-trained\nneural networks. Then, we post-train the translation model with different\nlevels of data at each training stages. As the training stages go on, we make\nthe system learn to solve multiple tasks by adding extra information at\ndifferent training stages gradually. We also show a way to utilize the\nadditional data in large volume for APE tasks. For further improvement, we\napply Multi-Task Learning Strategy with the Dynamic Weight Average during the\nfine-tuning stage. To fine-tune the APE corpus with limited data, we add some\nrelated subtasks to learn a unified representation. Finally, for better\nperformance, we leverage external translations as augmented machine translation\n(MT) during the post-training and fine-tuning. As experimental results show,\nour APE system significantly improves the translations of provided MT results\nby -2.848 and +3.74 on the development dataset in terms of TER and BLEU,\nrespectively. It also demonstrates its effectiveness on the test dataset with\nhigher quality than the development dataset.",
    "descriptor": "\nComments: WMT21 Automatic Post-Editing Shared Task System Paper (at EMNLP2021 Workshop)\n",
    "authors": [
      "Shinhyeok Oh",
      "Sion Jang",
      "Hu Xu",
      "Shounan An",
      "Insoo Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06515"
  },
  {
    "id": "arXiv:2109.06516",
    "title": "Designing Multi-Stage Coupled Convex Programming with Data-Driven  McCormick Envelope Relaxations for Motion Planning",
    "abstract": "For multi-limbed robots, motion planning with posture and force constraints\ntends to be a difficult optimization problem due to nonlinearities, which also\npresent extended solve times. We propose a multi-stage optimization framework\nwith data-driven inter-stage coupling constraints to address the nonlinearity.\nBoth clustering and evolutionary approaches to find the McCormick envelope\nrelaxations are used to find the problem-specific parameters. The learned\nconstraints are then used in the prior stages, which provides advanced\nknowledge of the following stages. This leads to improved solve times and\ninterpretability of the results. The planner is validated through multiple\nwalking and climbing tasks on a 10 kg hexapod robot.",
    "descriptor": "",
    "authors": [
      "Xuan Lin",
      "Min Sung Ahn",
      "Dennis Hong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06516"
  },
  {
    "id": "arXiv:2109.06520",
    "title": "A Double-Linked Blockchain Approach Based on Proof-of-Refundable-Tax  Consensus Algorithm",
    "abstract": "In this paper we propose a double-linked blockchain data structure that\ngreatly improves blockchain performance and guarantees single chain with no\nforks. Additionally, with the proposed proof-of-refundable-tax (PoRT) consensus\nalgorithm, our approach can construct highly reliable, efficient, fair and\nstable blockchain operations. The PoRT algorithm adopts a verifiable random\nfunction instead of mining to select future block maintainers with the\nprobability proportional to each participant's personal refundable tax. The\nindividual refundable tax serves as an index of the activeness of participation\nand hence PoRT can effectively prevent Sybil attacks. Also, with the\nblock-completion reward deducted from each maintainer's refundable tax, our\nblockchain system maintains a stable wealth distribution and avoids the \"rich\nbecome richer\" problem. We have implemented the approach and tested with very\npromising results.",
    "descriptor": "",
    "authors": [
      "Jiang Zheng-Xun",
      "Tsay Ren-Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06520"
  },
  {
    "id": "arXiv:2109.06521",
    "title": "Efficient Sampling of Dependency Structures",
    "abstract": "Probabilistic distributions over spanning trees in directed graphs are a\nfundamental model of dependency structure in natural language processing,\nsyntactic dependency trees. In NLP, dependency trees often have an additional\nroot constraint: only one edge may emanate from the root. However, no sampling\nalgorithm has been presented in the literature to account for this additional\nconstraint. In this paper, we adapt two spanning tree sampling algorithms to\nfaithfully sample dependency trees from a graph subject to the root constraint.\nWilson (1996)'s sampling algorithm has a running time of $\\mathcal{O}(H)$ where\n$H$ is the mean hitting time of the graph. Colbourn (1996)'s sampling algorithm\nhas a running time of $\\mathcal{O}(N^3)$, which is often greater than the mean\nhitting time of a directed graph. Additionally, we build upon Colbourn's\nalgorithm and present a novel extension that can sample $K$ trees without\nreplacement in $\\mathcal{O}(K N^3 + K^2 N)$ time. To the best of our knowledge,\nno algorithm has been given for sampling spanning trees without replacement\nfrom a directed graph.",
    "descriptor": "",
    "authors": [
      "Ran Zmigrod",
      "Tim Vieira",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06521"
  },
  {
    "id": "arXiv:2109.06522",
    "title": "New Extremal Binary Self-Dual Codes of Length 72 from  $M_6(\\mathbb{F}_2)G$ - Group Matrix Rings by a Hybrid Search Technique Based  on a Neighbourhood-Virus Optimisation Algorithm",
    "abstract": "In this paper, a new search technique based on the virus optimisation\nalgorithm is proposed for calculating the neighbours of binary self-dual codes.\nThe aim of this new technique is to calculate neighbours of self-dual codes\nwithout reducing the search field in the search process (this is a known in the\nliterature approach due to the computational time constraint) but still\nobtaining results in a reasonable time (significantly faster when compared to\nthe standard linear computational search). We employ this new search algorithm\nto the well-known neighbour method and its extension, the $k^{th}$-range\nneighbours and search for binary $[72,36,12]$ self-dual codes. In particular,\nwe present six generator matrices of the form $[I_{36} \\ | \\ \\tau_6(v)],$ where\n$I_{36}$ is the $36 \\times 36$ identity matrix, $v$ is an element in the group\nmatrix ring $M_6(\\mathbb{F}_2)G$ and $G$ is a finite group of order 6, which we\nthen employ to the proposed algorithm and search for binary $[72,36,12]$\nself-dual codes directly over the finite field $\\mathbb{F}_2$. We construct\n1471 new Type I binary $[72, 36, 12]$ self-dual codes with the rare parameters\n$\\gamma=11, 13, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32$ in\ntheir weight enumerators.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.07739, arXiv:2102.12863\n",
    "authors": [
      "Adrian Korban",
      "Serap Sahinkaya",
      "Deniz Ustun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06522"
  },
  {
    "id": "arXiv:2109.06523",
    "title": "Dependability Analysis of Deep Reinforcement Learning based Robotics and  Autonomous Systems",
    "abstract": "While Deep Reinforcement Learning (DRL) provides transformational\ncapabilities to the control of Robotics and Autonomous Systems (RAS), the\nblack-box nature of DRL and uncertain deployment-environments of RAS pose new\nchallenges on its dependability. Although there are many existing works\nimposing constraints on the DRL policy to ensure a successful completion of the\nmission, it is far from adequate in terms of assessing the DRL-driven RAS in a\nholistic way considering all dependability properties. In this paper, we\nformally define a set of dependability properties in temporal logic and\nconstruct a Discrete-Time Markov Chain (DTMC) to model the dynamics of\nrisk/failures of a DRL-driven RAS interacting with the stochastic environment.\nWe then do Probabilistic Model Checking based on the designed DTMC to verify\nthose properties. Our experimental results show that the proposed method is\neffective as a holistic assessment framework, while uncovers conflicts between\nthe properties that may need trade-offs in the training. Moreover, we find the\nstandard DRL training cannot improve dependability properties, thus requiring\nbespoke optimisation objectives concerning them. Finally, our method offers a\nnovel dependability analysis to the Sim-to-Real challenge of DRL.",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Yi Dong",
      "Xingyu Zhao",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.06523"
  },
  {
    "id": "arXiv:2109.06524",
    "title": "Different Strokes for Different Folks: Investigating Appropriate Further  Pre-training Approaches for Diverse Dialogue Tasks",
    "abstract": "Loading models pre-trained on the large-scale corpus in the general domain\nand fine-tuning them on specific downstream tasks is gradually becoming a\nparadigm in Natural Language Processing. Previous investigations prove that\nintroducing a further pre-training phase between pre-training and fine-tuning\nphases to adapt the model on the domain-specific unlabeled data can bring\npositive effects. However, most of these further pre-training works just keep\nrunning the conventional pre-training task, e.g., masked language model, which\ncan be regarded as the domain adaptation to bridge the data distribution gap.\nAfter observing diverse downstream tasks, we suggest that different tasks may\nalso need a further pre-training phase with appropriate training tasks to\nbridge the task formulation gap. To investigate this, we carry out a study for\nimproving multiple task-oriented dialogue downstream tasks through designing\nvarious tasks at the further pre-training phase. The experiment shows that\ndifferent downstream tasks prefer different further pre-training tasks, which\nhave intrinsic correlation and most further pre-training tasks significantly\nimprove certain target tasks rather than all. Our investigation indicates that\nit is of great importance and effectiveness to design appropriate further\npre-training tasks modeling specific information that benefit downstream tasks.\nBesides, we present multiple constructive empirical conclusions for enhancing\ntask-oriented dialogues.",
    "descriptor": "\nComments: Accepted as a long paper at EMNLP 2021 (Main Conference)\n",
    "authors": [
      "Yao Qiu",
      "Jinchao Zhang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06524"
  },
  {
    "id": "arXiv:2109.06526",
    "title": "Image-Based Alignment of 3D Scans",
    "abstract": "Full 3D scanning can efficiently be obtained using structured light scanning\ncombined with a rotation stage. In this setting it is, however, necessary to\nreposition the object and scan it in different poses in order to cover the\nentire object. In this case, correspondence between the scans is lost, since\nthe object was moved. In this paper, we propose a fully automatic method for\naligning the scans of an object in two different poses. This is done by\nmatching 2D features between images from two poses and utilizing correspondence\nbetween the images and the scanned point clouds. To demonstrate the approach,\nwe present the results of scanning three dissimilar objects.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Dolores Messer",
      "Jakob Wilm",
      "Eythor R. Eiriksson",
      "Vedrana A. Dahl",
      "Anders B. Dahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06526"
  },
  {
    "id": "arXiv:2109.06527",
    "title": "Learning Bill Similarity with Annotated and Augmented Corpora of Bills",
    "abstract": "Bill writing is a critical element of representative democracy. However, it\nis often overlooked that most legislative bills are derived, or even directly\ncopied, from other bills. Despite the significance of bill-to-bill linkages for\nunderstanding the legislative process, existing approaches fail to address\nsemantic similarities across bills, let alone reordering or paraphrasing which\nare prevalent in legal document writing. In this paper, we overcome these\nlimitations by proposing a 5-class classification task that closely reflects\nthe nature of the bill generation process. In doing so, we construct a\nhuman-labeled dataset of 4,721 bill-to-bill relationships at the\nsubsection-level and release this annotated dataset to the research community.\nTo augment the dataset, we generate synthetic data with varying degrees of\nsimilarity, mimicking the complex bill writing process. We use BERT variants\nand apply multi-stage training, sequentially fine-tuning our models with\nsynthetic and human-labeled datasets. We find that the predictive performance\nsignificantly improves when training with both human-labeled and synthetic\ndata. Finally, we apply our trained model to infer section- and bill-level\nsimilarities. Our analysis shows that the proposed methodology successfully\ncaptures the similarities across legal documents at various levels of\naggregation.",
    "descriptor": "\nComments: Accepted at EMNLP 2021(Long paper)\n",
    "authors": [
      "Jiseon Kim",
      "Elden Griggs",
      "In Song Kim",
      "Alice Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06527"
  },
  {
    "id": "arXiv:2109.06530",
    "title": "Comparison of power sector models by analyzing the impact of modeling  features on optimal capacity expansion",
    "abstract": "The transition towards decarbonized energy systems requires the expansion of\nrenewable and flexibility technologies in power sectors. In a model comparison,\nwe examine the optimal expansion of such technologies with six capacity\nexpansion power system models. The technologies under investigation include\nbase- and peak-load power plants, electricity storage, and transmission. We\ndefine four highly simplified and harmonized use cases that focus on the\nexpansion of only one or two specific technologies to isolate their effects on\nmodel results. We find that deviating assumptions on limited availability\nfactors of technologies cause technology-specific deviations between optimal\ncapacity expansion in models in almost all use cases. Fixed\nenergy-to-power-ratios of storage can entirely change model optimal expansion\noutcomes, especially shifting the ratio between short- and long-duration\nstorage. Fixed initial and end storage levels can impact the seasonal use of\nlong-duration storage. Models with a pre-ordered dispatch structure\nsignificantly deviate from linear optimization models, as limited foresight and\nflexibility can lead to higher capacity investments. A simplified net transfer\ncapacity approach underestimates the need for grid infrastructure compared to a\nmore detailed direct current load flow approach. We further find deviations in\nmodel results of optimal storage and transmission capacity expansion between\nregions and link them to variable renewable energy generation and demand\ncharacteristics. We expect that the general effects identified in our stylized\nsetting also hold in more detailed model applications, although they may be\nless visible there.",
    "descriptor": "",
    "authors": [
      "Jonas van Ouwerkerk",
      "Hans Christian Gils",
      "Hedda Gardian",
      "Martin Kittel",
      "Wolf-Peter Schill",
      "Alexander Zerrahn",
      "Alexander Murmann",
      "Jann Launer",
      "Laura Torralba-D\u00edaz",
      "Christian Bu\u00dfar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06530"
  },
  {
    "id": "arXiv:2109.06533",
    "title": "Los fact-checkers iberoamericanos frente a la COVID-19. An\u00e1lisis de  actividad en Facebook / The Ibero-American fact-checkers facing the COVID-19.  Analysis of activity on Facebook",
    "abstract": "Introduction: The COVID-19 pandemic revealed infodemics as an aggravating\nfactor in health emergencies, a situation that enhanced the role of data\nverification journalism in crisis situations. This article aims to know the\ndynamics of publication and interaction on Facebook of the international\nfact-checking group LatamChequea Coronavirus during the first two months after\nthe declaration of the COVID-19 pandemic by the WHO (March 11, 2020 - May 11,\n2020). Methodology: The contents, metadata and reactions generated in a total\nof 5736 posts published by 31 different fact-checkers were collected with\nCrowdtangle and analyzed. Results: Among the most shared publications, those\nrelated to the COVID-19 generated more reactions and comments than those\nreferring to other topics; the volume of shares is high in relation to other\ngenerally more frequent interactions and publications that include links\nachieved more interactions of all kinds than those based on videos or images.\nThere are positive correlations between the number of likes and the number of\nshares, and between the angry reaction and the number of comments. Discussion\nand conclusions: The relevance of sharing in the set of interactions would\nindicate a high interest of the users to share the denials about fake news,\nsomething that distances from previous referenced investigations. The results\nalso point to the influence of the emotional reaction expressed in the\ninteraction with the content in the form of sharing or commenting.",
    "descriptor": "\nComments: Preprint aceptado en Observatorio (OBS*) Journal, 22 p\\'aginas, in Spanish, 7 tablas, 1 gr\\'afico\n",
    "authors": [
      "Alberto Dafonte-G\u00f3mez",
      "Mar\u00eda-Isabel M\u00edguez-Gonz\u00e1lez",
      "Xabier Mart\u00ednez-Rol\u00e1n"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.06533"
  },
  {
    "id": "arXiv:2109.06536",
    "title": "Improving Gradient-based Adversarial Training for Text Classification by  Contrastive Learning and Auto-Encoder",
    "abstract": "Recent work has proposed several efficient approaches for generating\ngradient-based adversarial perturbations on embeddings and proved that the\nmodel's performance and robustness can be improved when they are trained with\nthese contaminated embeddings. While they paid little attention to how to help\nthe model to learn these adversarial samples more efficiently. In this work, we\nfocus on enhancing the model's ability to defend gradient-based adversarial\nattack during the model's training process and propose two novel adversarial\ntraining approaches: (1) CARL narrows the original sample and its adversarial\nsample in the representation space while enlarging their distance from\ndifferent labeled samples. (2) RAR forces the model to reconstruct the original\nsample from its adversarial representation. Experiments show that the proposed\ntwo approaches outperform strong baselines on various text classification\ndatasets. Analysis experiments find that when using our approaches, the\nsemantic representation of the input sentence won't be significantly affected\nby adversarial perturbations, and the model's performance drops less under\nadversarial attack. That is to say, our approaches can effectively improve the\nrobustness of the model. Besides, RAR can also be used to generate text-form\nadversarial samples.",
    "descriptor": "\nComments: Accepted as a long paper at ACL 2021 (Findings)\n",
    "authors": [
      "Yao Qiu",
      "Jinchao Zhang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06536"
  },
  {
    "id": "arXiv:2109.06538",
    "title": "Challenging Instances are Worth Learning: Generating Valuable Negative  Samples for Response Selection Training",
    "abstract": "Retrieval-based chatbot selects the appropriate response from candidates\naccording to the context, which heavily depends on a response selection module.\nA response selection module is generally a scoring model to evaluate candidates\nand is usually trained on the annotated positive response and sampled negative\nresponses. Sampling negative responses lead to two risks: a). The sampled\nnegative instances, especially that from random sampling methods, are mostly\nirrelevant to the dialogue context and too easy to be fitted at the training\nstage while causing a weak model in the real scenario. b). The so-called\nnegative instances may be positive, which is known as the fake negative\nproblem. To address the above issue, we employ pre-trained language models,\nsuch as the DialoGPT to construct more challenging negative instances to\nenhance the model robustness. Specifically, we provide garbled context to the\npre-trained model to generate responses and filter the fake negative ones. In\nthis way, our negative instances are fluent, context-related, and more\nchallenging for the model to learn, while can not be positive. Extensive\nexperiments show that our method brings significant and stable improvements on\nthe dialogue response selection capacity.",
    "descriptor": "",
    "authors": [
      "Yao Qiu",
      "Jinchao Zhang",
      "Huiying Ren",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06538"
  },
  {
    "id": "arXiv:2109.06543",
    "title": "Multi-Level Features Contrastive Networks for Unsupervised Domain  Adaptation",
    "abstract": "Unsupervised domain adaptation aims to train a model from the labeled source\ndomain to make predictions on the unlabeled target domain when the data\ndistribution of the two domains is different. As a result, it needs to reduce\nthe data distribution difference between the two domains to improve the model's\ngeneralization ability. Existing methods tend to align the two domains directly\nat the domain-level, or perform class-level domain alignment based on deep\nfeature. The former ignores the relationship between the various classes in the\ntwo domains, which may cause serious negative transfer, the latter alleviates\nit by introducing pseudo-labels of the target domain, but it does not consider\nthe importance of performing class-level alignment on shallow feature\nrepresentations. In this paper, we develop this work on the method of\nclass-level alignment. The proposed method reduces the difference between two\ndomains dramaticlly by aligning multi-level features. In the case that the two\ndomains share the label space, the class-level alignment is implemented by\nintroducing Multi-Level Feature Contrastive Networks (MLFCNet). In practice,\nsince the categories of samples in target domain are unavailable, we\niteratively use clustering algorithm to obtain the pseudo-labels, and then\nminimize Multi-Level Contrastive Discrepancy (MLCD) loss to achieve more\naccurate class-level alignment. Experiments on three real-world benchmarks\nImageCLEF-DA, Office-31 and Office-Home demonstrate that MLFCNet compares\nfavorably against the existing state-of-the-art domain adaptation methods.",
    "descriptor": "\nComments: 9 pages,5 figures\n",
    "authors": [
      "Le Liu",
      "Jieren Cheng",
      "Boyi Liu",
      "Yue Yang",
      "Ke Zhou",
      "Qiaobo Da"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06543"
  },
  {
    "id": "arXiv:2109.06550",
    "title": "Fast and Accurate Extrinsic Calibration for Multiple LiDARs and Cameras",
    "abstract": "In this letter, we propose a fast, accurate, and targetless extrinsic\ncalibration method for multiple LiDARs and cameras based on adaptive\nvoxelization. On the theory level, we incorporate the LiDAR extrinsic\ncalibration with the bundle adjustment method. We derive the second-order\nderivatives of the cost function w.r.t. the extrinsic parameter to accelerate\nthe optimization. On the implementation level, we apply the adaptive\nvoxelization to dynamically segment the LiDAR point cloud into voxels with\nnon-identical sizes, and reduce the computation time in the process of feature\ncorrespondence matching. The robustness and accuracy of our proposed method\nhave been verified with experiments in outdoor test scenes under multiple\nLiDAR-camera configurations.",
    "descriptor": "\nComments: 8 pages, 13 figures\n",
    "authors": [
      "Xiyuan Liu",
      "Chongjian Yuan",
      "Fu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06550"
  },
  {
    "id": "arXiv:2109.06554",
    "title": "Talking Space: inference from spatial linguistic meanings",
    "abstract": "This paper concerns the intersection of natural language and the physical\nspace around us in which we live, that we observe and/or imagine things within.\nMany important features of language have spatial connotations, for example,\nmany prepositions (like in, next to, after, on, etc.) are fundamentally\nspatial. Space is also a key factor of the meanings of many\nwords/phrases/sentences/text, and space is a, if not the key, context for\nreferencing (e.g. pointing) and embodiment.\nWe propose a mechanism for how space and linguistic structure can be made to\ninteract in a matching compositional fashion. Examples include Cartesian space,\nsubway stations, chesspieces on a chess-board, and Penrose's staircase. The\nstarting point for our construction is the DisCoCat model of compositional\nnatural language meaning, which we relax to accommodate physical space. We\naddress the issue of having multiple agents/objects in a space, including the\ncase that each agent has different capabilities with respect to that space,\ne.g., the specific moves each chesspiece can make, or the different velocities\none may be able to reach.\nOnce our model is in place, we show how inferences drawing from the structure\nof physical space can be made. We also how how linguistic model of space can\ninteract with other such models related to our senses and/or embodiment, such\nas the conceptual spaces of colour, taste and smell, resulting in a rich\ncompositional model of meaning that is close to human experience and embodiment\nin the world.",
    "descriptor": "\nComments: 33 pages, many pictures\n",
    "authors": [
      "Vincent Wang-Mascianica",
      "Bob Coecke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.06554"
  },
  {
    "id": "arXiv:2109.06557",
    "title": "The concept of class invariant in object-oriented programming",
    "abstract": "Class invariants -- consistency constraints preserved by every operation on\nobjects of a given type -- are fundamental to building and understanding\nobject-oriented programs. They should also be a key help in verifying them, but\nturn out instead to raise major verification challenges which have prompted a\nsignificant literature with, until now, no widely accepted solution. The\npresent work introduces a general proof rule meant to address invariant-related\nissues and allow verification tools benefit from invariants. It first clarifies\nthe notion of invariant and identify the three problems: callbacks, furtive\naccess and reference leak. As an example, the 2016 Ethereum DAO bug, in which\n\\$50 million were stolen, resulted from a callback invalidating an invariant.\nThe discussion starts with a \"Simple Model\" and an associated proof rule,\ndemonstrating its soundness. It then removes one by one the three assumptions\nof the Simple Model, each removal bringing up one of the three issues, and\nintroduces the corresponding adaptation to the proof rule. The final version of\nthe rule can tackle tricky examples, including \"challenge problems\" listed in\nthe literature.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.02388\n",
    "authors": [
      "Bertrand Meyer",
      "Alisa Arkadova",
      "Alexander Kogtenkov",
      "Alexandr Naumchev"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.06557"
  },
  {
    "id": "arXiv:2109.06561",
    "title": "Beyond Distributed Subgraph Detection: Induced Subgraphs, Multicolored  Problems and Graph Parameters",
    "abstract": "Subgraph detection has recently been one of the most studied problems in the\nCONGEST model of distributed computing. In this work, we study the distributed\ncomplexity of problems closely related to subgraph detection, mainly focusing\non induced subgraph detection. The main line of this work presents lower bounds\nand parameterized algorithms w.r.t structural parameters of the input graph:\n-- On general graphs, we give unconditional lower bounds for induced\ndetection of cycles and patterns of treewidth 2 in CONGEST. Moreover, by\nadapting reductions from centralized parameterized complexity, we prove lower\nbounds in CONGEST for detecting patterns with a 4-clique, and for induced path\ndetection conditional on the hardness of triangle detection in the congested\nclique.\n-- On graphs of bounded degeneracy, we show that induced paths can be\ndetected fast in CONGEST using techniques from parameterized algorithms, while\ndetecting cycles and patterns of treewidth 2 is hard.\n-- On graphs of bounded vertex cover number, we show that induced subgraph\ndetection is easy in CONGEST for any pattern graph. More specifically, we adapt\na centralized parameterized algorithm for a more general maximum common induced\nsubgraph detection problem to the distributed setting.\nIn addition to these induced subgraph detection results, we study various\nrelated problems in the CONGEST and congested clique models, including for\nmulticolored versions of subgraph-detection-like problems.",
    "descriptor": "",
    "authors": [
      "Janne H. Korhonen",
      "Amir Nikabadi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06561"
  },
  {
    "id": "arXiv:2109.06562",
    "title": "Anomaly Attribution of Multivariate Time Series using Counterfactual  Reasoning",
    "abstract": "There are numerous methods for detecting anomalies in time series, but that\nis only the first step to understanding them. We strive to exceed this by\nexplaining those anomalies. Thus we develop a novel attribution scheme for\nmultivariate time series relying on counterfactual reasoning. We aim to answer\nthe counterfactual question of would the anomalous event have occurred if the\nsubset of the involved variables had been more similarly distributed to the\ndata outside of the anomalous interval. Specifically, we detect anomalous\nintervals using the Maximally Divergent Interval (MDI) algorithm, replace a\nsubset of variables with their in-distribution values within the detected\ninterval and observe if the interval has become less anomalous, by re-scoring\nit with MDI. We evaluate our method on multivariate temporal and\nspatio-temporal data and confirm the accuracy of our anomaly attribution of\nmultiple well-understood extreme climate events such as heatwaves and\nhurricanes.",
    "descriptor": "\nComments: ICMLA 2021\n",
    "authors": [
      "Violeta Teodora Trifunov",
      "Maha Shadaydeh",
      "Bj\u00f6rn Barz",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06562"
  },
  {
    "id": "arXiv:2109.06565",
    "title": "Variation-Incentive Loss Re-weighting for Regression Analysis on Biased  Data",
    "abstract": "Both classification and regression tasks are susceptible to the biased\ndistribution of training data. However, existing approaches are focused on the\nclass-imbalanced learning and cannot be applied to the problems of numerical\nregression where the learning targets are continuous values rather than\ndiscrete labels. In this paper, we aim to improve the accuracy of the\nregression analysis by addressing the data skewness/bias during model training.\nWe first introduce two metrics, uniqueness and abnormality, to reflect the\nlocalized data distribution from the perspectives of their feature (i.e.,\ninput) space and target (i.e., output) space. Combining these two metrics we\npropose a Variation-Incentive Loss re-weighting method (VILoss) to optimize the\ngradient descent-based model training for regression analysis. We have\nconducted comprehensive experiments on both synthetic and real-world data sets.\nThe results show significant improvement in the model quality (reduction in\nerror by up to 11.9%) when using VILoss as the loss criterion in training.",
    "descriptor": "\nComments: 9 pages with appendix\n",
    "authors": [
      "Wentai Wu",
      "Ligang He",
      "Weiwei Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06565"
  },
  {
    "id": "arXiv:2109.06569",
    "title": "The Complexity of Vector Partition",
    "abstract": "We consider the {\\em vector partition problem}, where $n$ agents, each with a\n$d$-dimensional attribute vector, are to be partitioned into $p$ parts so as to\nminimize cost which is a given function on the sums of attribute vectors in\neach part. The problem has applications in a variety of areas including\nclustering, logistics and health care. We consider the complexity and\nparameterized complexity of the problem under various assumptions on the\nnatural parameters $p,d,a,t$ of the problem where $a$ is the maximum absolute\nvalue of any attribute and $t$ is the number of agent types, and raise some of\nthe many remaining open problems.",
    "descriptor": "",
    "authors": [
      "Shmuel Onn"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.06569"
  },
  {
    "id": "arXiv:2109.06573",
    "title": "The Impact of User Demographics and Task Types on Cross-App Mobile  Search",
    "abstract": "Recent developments in the mobile app industry have resulted in various types\nof mobile apps, each targeting a different need and a specific audience.\nConsequently, users access distinct apps to complete their information need\ntasks. This leads to the use of various apps not only separately, but also\ncollaboratively in the same session to achieve a single goal. Recent work has\nargued the need for a unified mobile search system that would act as metasearch\non users' mobile devices. The system would identify the target apps for the\nuser's query, submit the query to the apps, and present the results to the user\nin a unified way. In this work, we aim to deepen our understanding of user\nbehavior while accessing information on their mobile phones by conducting an\nextensive analysis of various aspects related to the search process. In\nparticular, we study the effect of task type and user demographics on their\nbehavior in interacting with mobile apps. Our findings reveal trends and\npatterns that can inform the design of a more effective mobile information\naccess environment.",
    "descriptor": "\nComments: FQAS Invited Paper\n",
    "authors": [
      "Mohammad Aliannejadi",
      "Fabio Crestani",
      "Theo Huibers",
      "Monica Landoni",
      "Emiliana Murgia",
      "Maria Soledad Pera"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.06573"
  },
  {
    "id": "arXiv:2109.06576",
    "title": "The Effect of False Positives: Why Fuzzy Message Detection Leads to  Fuzzy Privacy Guarantees?",
    "abstract": "Fuzzy Message Detection (FMD) is a recent cryptographic primitive invented by\nBeck et al. (CCS'21) where an untrusted server performs coarse message\nfiltering for its clients in a recipient-anonymous way. In FMD - besides the\ntrue positive messages - the clients download from the server their cover\nmessages determined by their false-positive detection rates. What is more,\nwithin FMD, the server cannot distinguish between genuine and cover traffic. In\nthis paper, we formally analyze the privacy guarantees of FMD from four\ndifferent angles. First, we evaluate what privacy provisions are offered by\nFMD. We found that FMD does not provide relationship anonymity without\nadditional cryptographic techniques protecting the senders' identities.\nMoreover, FMD only provides a reasonable degree of recipient unlinkability when\nusers apply considerable false-positive rates, and concurrently there is\nsignificant traffic. Second, we perform a differential privacy (DP) analysis\nand coin a relaxed DP definition to capture the privacy guarantees FMD yields.\nThird, we study FMD through a game-theoretic lens and argue why FMD is not\nsustainable without altruistic users. Finally, we simulate FMD on real-world\ncommunication data. Our theoretical and empirical results assist FMD users to\nadequately select their false-positive detection rates for various applications\nwith given privacy requirements.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Istv\u00e1n Andr\u00e1s Seres",
      "Bal\u00e1zs Pej\u00f3",
      "P\u00e9ter Burcsi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.06576"
  },
  {
    "id": "arXiv:2109.06578",
    "title": "Joining Forces: Applying Design Thinking Techniques in Scrum Meetings",
    "abstract": "The most prominent Agile framework Scrum, is often criticized for its amount\nof meetings. These regular events are essential to the empirical\ninspect-and-adapt cycle proposed by Agile methods. Scrum meetings face several\nchallenges, such as being perceived as boring, repetitive, or irrelevant,\nleading to decreased cooperation in teams and less successful projects. In an\nattempt to address these challenges, Agile practitioners have adopted teamwork,\ninnovation, and design techniques geared towards improving collaboration.\nAdditionally, they have developed their own activities to be used in Scrum\nmeetings, most notably for conducting retrospective and planning events. Design\nthinking incorporates non-designers and designers in design and\nconceptualization activities, including user research, ideation, or testing.\nAccordingly, the design thinking approach provides a process with different\nphases and accompanying techniques for each step. These design thinking\ntechniques can support shared understanding in teams and can improve\ncollaboration, creativity, and product understanding. For these reasons, design\nthinking techniques represent a worthwhile addition to the Scrum meeting\ntoolkit and can support Agile meetings in preventing or countering common\nmeeting challenges and achieving meeting goals. This chapter explores how\ntechniques from the design thinking toolkit can support Scrum meetings from a\ntheoretical and practical viewpoint. We analyze Scrum meetings' requirements,\ngoals, and challenges and link them to groups of techniques from the design\nthinking toolkit. In addition, we review interview and observational data from\ntwo previous studies with software development practitioners and derive\nconcrete examples. As a result, we present initial guidelines on integrating\ndesign thinking techniques into Scrum meetings to make them more engaging,\ncollaborative, and interactive.",
    "descriptor": "",
    "authors": [
      "Franziska Dobrigkeit",
      "Christoph Matthies",
      "Ralf Teusner",
      "Michael Perscheid"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.06578"
  },
  {
    "id": "arXiv:2109.06580",
    "title": "Continuous Homeostatic Reinforcement Learning for Self-Regulated  Autonomous Agents",
    "abstract": "Homeostasis is a prevalent process by which living beings maintain their\ninternal milieu around optimal levels. Multiple lines of evidence suggest that\nliving beings learn to act to predicatively ensure homeostasis (allostasis). A\nclassical theory for such regulation is drive reduction, where a function of\nthe difference between the current and the optimal internal state. The recently\nintroduced homeostatic regulated reinforcement learning theory (HRRL), by\ndefining within the framework of reinforcement learning a reward function based\non the internal state of the agent, makes the link between the theories of\ndrive reduction and reinforcement learning. The HRRL makes it possible to\nexplain multiple eating disorders. However, the lack of continuous change in\nthe internal state of the agent with the discrete-time modeling has been so far\na key shortcoming of the HRRL theory. Here, we propose an extension of the\nhomeostatic reinforcement learning theory to a continuous environment in space\nand time, while maintaining the validity of the theoretical results and the\nbehaviors explained by the model in discrete time. Inspired by the\nself-regulating mechanisms abundantly present in biology, we also introduce a\nmodel for the dynamics of the agent internal state, requiring the agent to\ncontinuously take actions to maintain homeostasis. Based on the\nHamilton-Jacobi-Bellman equation and function approximation with neural\nnetworks, we derive a numerical scheme allowing the agent to learn directly how\nits internal mechanism works, and to choose appropriate action policies via\nreinforcement learning and an appropriate exploration of the environment. Our\nnumerical experiments show that the agent does indeed learn to behave in a way\nthat is beneficial to its survival in the environment, making our framework\npromising for modeling animal dynamics and decision-making.",
    "descriptor": "",
    "authors": [
      "Hugo Lauren\u00e7on",
      "Charbel-Rapha\u00ebl S\u00e9gerie",
      "Johann Lussange",
      "Boris S. Gutkin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06580"
  },
  {
    "id": "arXiv:2109.06583",
    "title": "A Semantic Indexing Structure for Image Retrieval",
    "abstract": "In large-scale image retrieval, many indexing methods have been proposed to\nnarrow down the searching scope of retrieval. The features extracted from\nimages usually are of high dimensions or unfixed sizes due to the existence of\nkey points. Most of existing index structures suffer from the dimension curse,\nthe unfixed feature size and/or the loss of semantic similarity. In this paper\na new classification-based indexing structure, called Semantic Indexing\nStructure (SIS), is proposed, in which we utilize the semantic categories\nrather than clustering centers to create database partitions, such that the\nproposed index SIS can be combined with feature extractors without the\nrestriction of dimensions. Besides, it is observed that the size of each\nsemantic partition is positively correlated with the semantic distribution of\ndatabase. Along this way, we found that when the partition number is normalized\nto five, the proposed algorithm performed very well in all the tests. Compared\nwith state-of-the-art models, SIS achieves outstanding performance.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Ying Wang",
      "Tingzhen Liu",
      "Zepeng Bu",
      "Yuhui Huang",
      "Lizhong Gao",
      "Qiao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.06583"
  },
  {
    "id": "arXiv:2109.06584",
    "title": "Choosing the Right Algorithm With Hints From Complexity Theory",
    "abstract": "Choosing a suitable algorithm from the myriads of different search heuristics\nis difficult when faced with a novel optimization problem. In this work, we\nargue that the purely academic question of what could be the best possible\nalgorithm in a certain broad class of black-box optimizers can give fruitful\nindications in which direction to search for good established optimization\nheuristics. We demonstrate this approach on the recently proposed DLB\nbenchmark, for which the only known results are $O(n^3)$ runtimes for several\nclassic evolutionary algorithms and an $O(n^2 \\log n)$ runtime for an\nestimation-of-distribution algorithm. Our finding that the unary unbiased\nblack-box complexity is only $O(n^2)$ suggests the Metropolis algorithm as an\ninteresting candidate and we prove that it solves the DLB problem in quadratic\ntime. Since we also prove that better runtimes cannot be obtained in the class\nof unary unbiased algorithms, we shift our attention to algorithms that use the\ninformation of more parents to generate new solutions. An artificial algorithm\nof this type having an $O(n \\log n)$ runtime leads to the result that the\nsignificance-based compact genetic algorithm (sig-cGA) can solve the DLB\nproblem also in time $O(n \\log n)$. Our experiments show a remarkably good\nperformance of the Metropolis algorithm, clearly the best of all algorithms\nregarded for reasonable problem sizes.",
    "descriptor": "\nComments: 1 Figure. Full version of a paper appearing at IJCAI 2021\n",
    "authors": [
      "Shouda Wang",
      "Weijie Zheng",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06584"
  },
  {
    "id": "arXiv:2109.06587",
    "title": "Sum-Product-Attention Networks: Leveraging Self-Attention in  Probabilistic Circuits",
    "abstract": "Probabilistic circuits (PCs) have become the de-facto standard for learning\nand inference in probabilistic modeling. We introduce Sum-Product-Attention\nNetworks (SPAN), a new generative model that integrates probabilistic circuits\nwith Transformers. SPAN uses self-attention to select the most relevant parts\nof a probabilistic circuit, here sum-product networks, to improve the modeling\ncapability of the underlying sum-product network. We show that while modeling,\nSPAN focuses on a specific set of independent assumptions in every product\nlayer of the sum-product network. Our empirical evaluations show that SPAN\noutperforms state-of-the-art probabilistic generative models on various\nbenchmark data sets as well is an efficient generative image model.",
    "descriptor": "",
    "authors": [
      "Zhongjie Yu",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06587"
  },
  {
    "id": "arXiv:2109.06590",
    "title": "High-Fidelity GAN Inversion for Image Attribute Editing",
    "abstract": "We present a novel high-fidelity generative adversarial network (GAN)\ninversion framework that enables attribute editing with image-specific details\nwell-preserved (e.g., background, appearance and illumination). We first\nformulate GAN inversion as a lossy data compression problem and carefully\ndiscuss the Rate-Distortion-Edit trade-off. Due to this trade-off, previous\nworks fail to achieve high-fidelity reconstruction while keeping compelling\nediting ability with a low bit-rate latent code only. In this work, we propose\na distortion consultation approach that employs the distortion map as a\nreference for reconstruction. In the distortion consultation inversion (DCI),\nthe distortion map is first projected to a high-rate latent map, which then\ncomplements the basic low-rate latent code with (lost) details via consultation\nfusion. To achieve high-fidelity editing, we propose an adaptive distortion\nalignment (ADA) module with a self-supervised training scheme. Extensive\nexperiments in the face and car domains show a clear improvement in terms of\nboth inversion and editing quality.",
    "descriptor": "\nComments: Project Page is at this https URL\n",
    "authors": [
      "Tengfei Wang",
      "Yong Zhang",
      "Yanbo Fan",
      "Jue Wang",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06590"
  },
  {
    "id": "arXiv:2109.06591",
    "title": "The impact of the COVID-19 pandemic on academic productivity",
    "abstract": "'Publish or perish' is an expression describing the pressure on academics to\nconsistently publish research to ensure a successful career in academia. With a\nglobal pandemic that has changed the world, how has it changed academic\nproductivity? Here we show that academics are posting just as many publications\non the arXiv pre-print server as if there were no pandemic: 168,630 were posted\nin 2020, a +12.6% change from 2019 and $+1.4\\sigma$ deviation above the\npredicted 162,577 $\\pm$ 4,393. However, some immediate impacts are visible in\nindividual research fields. Conference cancellations have led to sharp drops in\npre-prints, but laboratory closures have had mixed effects. Only some\nexperimental fields show mild declines in outputs, with most being consistent\non previous years or even increasing above model expectations. The most\nsignificant change is a 50% increase ($+8\\sigma$) in quantitative biology\nresearch, all related to the COVID-19 pandemic. Some of these publications are\nby biologists using arXiv for the first time, and some are written by\nresearchers from other fields (e.g., physicists, mathematicians). While\nquantitative biology pre-prints have returned to pre-pandemic levels, 20% of\nthe research in this field is now focussed on the COVID-19 pandemic,\ndemonstrating a strong shift in research focus.",
    "descriptor": "\nComments: Submitted to RSOS\n",
    "authors": [
      "Andrew R. Casey",
      "Ilya Mandel",
      "Prasun K. Ray"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "General Economics (econ.GN)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.06591"
  },
  {
    "id": "arXiv:2109.06593",
    "title": "Online Algorithms with Lookaround",
    "abstract": "We introduce a new model of computation: the online LOCAL model (OLOCAL). In\nthis model, the adversary reveals the nodes of the input graph one by one, in\nthe same way as in classical online algorithms, but for each new node the\nalgorithm can also inspect its radius-$T$ neighborhood before choosing the\noutput; instead of looking ahead in time, we have the power of looking around\nin space. It is natural to compare OLOCAL with the LOCAL model of distributed\ncomputing, in which all nodes make decisions simultaneously in parallel based\non their radius-$T$ neighborhoods.",
    "descriptor": "",
    "authors": [
      "Amirreza Akbari",
      "Henrik Lievonen",
      "Darya Melnyk",
      "Joona Sarkijarvi",
      "Jukka Suomela"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.06593"
  },
  {
    "id": "arXiv:2109.06595",
    "title": "GPT-2C: A GPT-2 parser for Cowrie honeypot logs",
    "abstract": "Deception technologies like honeypots produce comprehensive log reports, but\noften lack interoperability with EDR and SIEM technologies. A key bottleneck is\nthat existing information transformation plugins perform well on static logs\n(e.g. geolocation), but face limitations when it comes to parsing dynamic log\ntopics (e.g. user-generated content). In this paper, we present a run-time\nsystem (GPT-2C) that leverages large pre-trained models (GPT-2) to parse\ndynamic logs generate by a Cowrie SSH honeypot. Our fine-tuned model achieves\n89\\% inference accuracy in the new domain and demonstrates acceptable execution\nlatency.",
    "descriptor": "",
    "authors": [
      "Febrian Setianto",
      "Erion Tsani",
      "Fatima Sadiq",
      "Georgios Domalis",
      "Dimitris Tsakalidis",
      "Panos Kostakos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06595"
  },
  {
    "id": "arXiv:2109.06596",
    "title": "GPGM-SLAM: a Robust SLAM System for Unstructured Planetary Environments  with Gaussian Process Gradient Maps",
    "abstract": "Simultaneous Localization and Mapping (SLAM) techniques play a key role\ntowards long-term autonomy of mobile robots due to the ability to correct\nlocalization errors and produce consistent maps of an environment over time.\nContrarily to urban or man-made environments, where the presence of unique\nobjects and structures offer unique cues for localization, the appearance of\nunstructured natural environments is often ambiguous and self-similar,\nhindering the performances of loop closure detection. In this paper, we present\nan approach to improve the robustness of place recognition in the context of a\nsubmap-based stereo SLAM based on Gaussian Process Gradient Maps (GPGMaps).\nGPGMaps embed a continuous representation of the gradients of the local terrain\nelevation by means of Gaussian Process regression and Structured Kernel\nInterpolation, given solely noisy elevation measurements. We leverage the\nimage-like structure of GPGMaps to detect loop closures using traditional\nvisual features and Bag of Words. GPGMap matching is performed as an SE(2)\nalignment to establish loop closure constraints within a pose graph. We\nevaluate the proposed pipeline on a variety of datasets recorded on Mt. Etna,\nSicily and in the Morocco desert, respectively Moon- and Mars-like\nenvironments, and we compare the localization performances with\nstate-of-the-art approaches for visual SLAM and visual loop closure detection.",
    "descriptor": "\nComments: Submission to Field Robotics (www.journalfieldrobotics.org), under review\n",
    "authors": [
      "Riccardo Giubilato",
      "Cedric Le Gentil",
      "Mallikarjuna Vayugundla",
      "Martin J. Schuster",
      "Teresa Vidal-Calleja",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06596"
  },
  {
    "id": "arXiv:2109.06598",
    "title": "Just What do You Think You're Doing, Dave?' A Checklist for Responsible  Data Use in NLP",
    "abstract": "A key part of the NLP ethics movement is responsible use of data, but exactly\nwhat that means or how it can be best achieved remain unclear. This position\npaper discusses the core legal and ethical principles for collection and\nsharing of textual data, and the tensions between them. We propose a potential\nchecklist for responsible data (re-)use that could both standardise the peer\nreview of conference submissions, as well as enable a more in-depth view of\npublished research across the community. Our proposal aims to contribute to the\ndevelopment of a consistent standard for data (re-)use, embraced across NLP\nconferences.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Anna Rogers",
      "Tim Baldwin",
      "Kobi Leins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06598"
  },
  {
    "id": "arXiv:2109.06601",
    "title": "Distributed Vertex Cover Reconfiguration",
    "abstract": "Reconfiguration schedules, i.e., sequences that gradually transform one\nsolution of a problem to another while always maintaining feasibility, have\nbeen extensively studied. Most research has dealt with the decision problem of\nwhether a reconfiguration schedule exists, and the complexity of finding one. A\nprime example is the reconfiguration of vertex covers. We initiate the study of\nbatched vertex cover reconfiguration, which allows to reconfigure multiple\nvertices concurrently while requiring that any adversarial reconfiguration\norder within a batch maintains feasibility. The latter provides robustness,\ne.g., if the simultaneous reconfiguration of a batch cannot be guaranteed. The\nquality of a schedule is measured by the number of batches until all nodes are\nreconfigured, and its cost, i.e., the maximum size of an intermediate vertex\ncover.\nTo set a baseline for batch reconfiguration, we show that for graphs\nbelonging to one of the classes $\\{\\mathsf{cycles, trees, forests, chordal,\ncactus, even\\text{-}hole\\text{-}free, claw\\text{-}free}\\}$, there are schedules\nthat use $O(\\varepsilon^{-1})$ batches and incur only a $1+\\varepsilon$\nmultiplicative increase in cost over the best sequential schedules. Our main\ncontribution is to compute such batch schedules in $O(\\varepsilon^{-1}\\log^*\nn)$ distributed time, which we also show to be tight. Further, we show that\nonce we step out of these graph classes we face a very different situation.\nThere are graph classes on which no efficient distributed algorithm can obtain\nthe best (or almost best) existing schedule. Moreover, there are classes of\nbounded degree graphs which do not admit any reconfiguration schedules without\nincurring a large multiplicative increase in the cost at all.",
    "descriptor": "",
    "authors": [
      "Keren Censor-Hillel",
      "Yannic Maus",
      "Shahar Romem-Peled",
      "Tigran Tonoyan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.06601"
  },
  {
    "id": "arXiv:2109.06604",
    "title": "Non-Parametric Unsupervised Domain Adaptation for Neural Machine  Translation",
    "abstract": "Recently, $k$NN-MT has shown the promising capability of directly\nincorporating the pre-trained neural machine translation (NMT) model with\ndomain-specific token-level $k$-nearest-neighbor ($k$NN) retrieval to achieve\ndomain adaptation without retraining. Despite being conceptually attractive, it\nheavily relies on high-quality in-domain parallel corpora, limiting its\ncapability on unsupervised domain adaptation, where in-domain parallel corpora\nare scarce or nonexistent. In this paper, we propose a novel framework that\ndirectly uses in-domain monolingual sentences in the target language to\nconstruct an effective datastore for $k$-nearest-neighbor retrieval. To this\nend, we first introduce an autoencoder task based on the target language, and\nthen insert lightweight adapters into the original NMT model to map the\ntoken-level representation of this task to the ideal representation of\ntranslation task. Experiments on multi-domain datasets demonstrate that our\nproposed approach significantly improves the translation accuracy with\ntarget-side monolingual data, while achieving comparable performance with\nback-translation.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Xin Zheng",
      "Zhirui Zhang",
      "Shujian Huang",
      "Boxing Chen",
      "Jun Xie",
      "Weihua Luo",
      "Jiajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06604"
  },
  {
    "id": "arXiv:2109.06605",
    "title": "MDAPT: Multilingual Domain Adaptive Pretraining in a Single Model",
    "abstract": "Domain adaptive pretraining, i.e. the continued unsupervised pretraining of a\nlanguage model on domain-specific text, improves the modelling of text for\ndownstream tasks within the domain. Numerous real-world applications are based\non domain-specific text, e.g. working with financial or biomedical documents,\nand these applications often need to support multiple languages. However,\nlarge-scale domain-specific multilingual pretraining data for such scenarios\ncan be difficult to obtain, due to regulations, legislation, or simply a lack\nof language- and domain-specific text. One solution is to train a single\nmultilingual model, taking advantage of the data available in as many languages\nas possible. In this work, we explore the benefits of domain adaptive\npretraining with a focus on adapting to multiple languages within a specific\ndomain. We propose different techniques to compose pretraining corpora that\nenable a language model to both become domain-specific and multilingual.\nEvaluation on nine domain-specific datasets-for biomedical named entity\nrecognition and financial sentence classification-covering seven different\nlanguages show that a single multilingual domain-specific model can outperform\nthe general multilingual model, and performs close to its monolingual\ncounterpart. This finding holds across two different pretraining methods,\nadapter-based pretraining and full model pretraining.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Rasmus K\u00e6r J\u00f8rgensen",
      "Mareike Hartmann",
      "Xiang Dai",
      "Desmond Elliott"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06605"
  },
  {
    "id": "arXiv:2109.06608",
    "title": "Strong Approximations and Irrationality in Financial Networks with  Financial Derivatives",
    "abstract": "Financial networks model a set of financial institutions (firms)\ninterconnected by obligations. Recent work has introduced to this model a class\nof obligations called credit default swaps, a certain kind of financial\nderivatives. The main computational challenge for such systems is known as the\nclearing problem, which is to determine which firms are in default and to\ncompute their exposure to systemic risk, technically known as their recovery\nrates. It is known that the recovery rates form the set of fixed points of a\nsimple function, and that these fixed points can be irrational. Furthermore,\nSchuldenzucker et al. (2016) have shown that finding a weakly (or \"almost\")\napproximate (rational) fixed point is PPAD-complete.\nIn light of the above, we further study the clearing problem from the point\nof view of irrationality and approximation strength. Firstly, as weakly\napproximate solutions are hard to justify for financial institutions, we study\nthe complexity of finding a strongly (or \"near\") approximate solution, and show\nFIXP-completeness. Secondly, we study the structural properties required for\nirrationality, and we give necessary conditions for irrational solutions to\nemerge: The presence of certain types of cycles in a financial network forces\nthe recovery rates to take the form of roots of second- or higher-degree\npolynomials. In the absence of a large subclass of such cycles, we study the\ncomplexity of finding an exact fixed point, which we show to be a problem close\nto, albeit outside of, PPAD.",
    "descriptor": "",
    "authors": [
      "Stavros D. Ioannidis",
      "Bart de Keijzer",
      "Carmine Ventre"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.06608"
  },
  {
    "id": "arXiv:2109.06609",
    "title": "DSDF: An approach to handle stochastic agents in collaborative  multi-agent reinforcement learning",
    "abstract": "Multi-Agent reinforcement learning has received lot of attention in recent\nyears and have applications in many different areas. Existing methods involving\nCentralized Training and Decentralized execution, attempts to train the agents\ntowards learning a pattern of coordinated actions to arrive at optimal joint\npolicy. However if some agents are stochastic to varying degrees of\nstochasticity, the above methods often fail to converge and provides poor\ncoordination among agents. In this paper we show how this stochasticity of\nagents, which could be a result of malfunction or aging of robots, can add to\nthe uncertainty in coordination and there contribute to unsatisfactory global\ncoordination. In this case, the deterministic agents have to understand the\nbehavior and limitations of the stochastic agents while arriving at optimal\njoint policy. Our solution, DSDF which tunes the discounted factor for the\nagents according to uncertainty and use the values to update the utility\nnetworks of individual agents. DSDF also helps in imparting an extent of\nreliability in coordination thereby granting stochastic agents tasks which are\nimmediate and of shorter trajectory with deterministic ones taking the tasks\nwhich involve longer planning. Such an method enables joint co-ordinations of\nagents some of which may be partially performing and thereby can reduce or\ndelay the investment of agent/robot replacement in many circumstances. Results\non benchmark environment for different scenarios shows the efficacy of the\nproposed approach when compared with existing approaches.",
    "descriptor": "",
    "authors": [
      "Satheesh K. Perepu",
      "Kaushik Dey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06609"
  },
  {
    "id": "arXiv:2109.06610",
    "title": "Statistical limits of dictionary learning: random matrix theory and the  spectral replica method",
    "abstract": "We consider increasingly complex models of matrix denoising and dictionary\nlearning in the Bayes-optimal setting, in the challenging regime where the\nmatrices to infer have a rank growing linearly with the system size. This is in\ncontrast with most existing literature concerned with the low-rank (i.e.,\nconstant-rank) regime. We first consider a class of rotationally invariant\nmatrix denoising problems whose mutual information and minimum mean-square\nerror are computable using standard techniques from random matrix theory. Next,\nwe analyze the more challenging models of dictionary learning. To do so we\nintroduce a novel combination of the replica method from statistical mechanics\ntogether with random matrix theory, coined spectral replica method. It allows\nus to conjecture variational formulas for the mutual information between hidden\nrepresentations and the noisy data as well as for the overlaps quantifying the\noptimal reconstruction error. The proposed methods reduce the number of degrees\nof freedom from $\\Theta(N^2)$ (matrix entries) to $\\Theta(N)$ (eigenvalues or\nsingular values), and yield Coulomb gas representations of the mutual\ninformation which are reminiscent of matrix models in physics. The main\ningredients are the use of HarishChandra-Itzykson-Zuber spherical integrals\ncombined with a new replica symmetric decoupling ansatz at the level of the\nprobability distributions of eigenvalues (or singular values) of certain\noverlap matrices.",
    "descriptor": "",
    "authors": [
      "Jean Barbier",
      "Nicolas Macris"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.06610"
  },
  {
    "id": "arXiv:2109.06612",
    "title": "Histogram binning revisited with a focus on human perception",
    "abstract": "This paper presents a quantitative user study to evaluate how well users can\nvisually perceive the underlying data distribution from a histogram\nrepresentation. We used different sample and bin sizes and four different\ndistributions (uniform, normal, bimodal, and gamma). The study results confirm\nthat, in general, more bins correlate with fewer errors by the viewers.\nHowever, upon a certain number of bins, the error rate cannot be improved by\nadding more bins. By comparing our study results with the outcomes of existing\nmathematical models for histogram binning (e.g., Sturges' formula, Scott's\nnormal reference rule, the Rice Rule, or Freedman-Diaconis' choice), we can see\nthat most of them overestimate the number of bins necessary to make the\ndistribution visible to a human viewer.",
    "descriptor": "\nComments: Accepted as short paper at VIS 2021. Supplemental material can be found at this https URL\n",
    "authors": [
      "Raphael Sahann",
      "Torsten M\u00f6ller",
      "Johanna Schmidt"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.06612"
  },
  {
    "id": "arXiv:2109.06613",
    "title": "Exploring the Use of Static and Dynamic Analysis to Improve the  Performance of the Mining Sandbox Approach for Android Malware Identification",
    "abstract": "The Android mining sandbox approach consists in running dynamic analysis\ntools on a benign version of an Android app and recording every call to\nsensitive APIs. Later, one can use this information to (a) prevent calls to\nother sensitive APIs (those not previously recorded) or (b) run the dynamic\nanalysis tools again in a different version of the app -- in order to identify\npossible malicious behavior. Although the use of dynamic analysis for mining\nAndroid sandboxes has been empirically investigated before, little is known\nabout the potential benefits of combining static analysis with the mining\nsandbox approach for identifying malicious behavior. As such, in this paper we\npresent the results of two empirical studies: The first is a non-exact\nreplication of a previous research work from Bao et al., which compares the\nperformance of test case generation tools for mining Android sandboxes. The\nsecond is a new experiment to investigate the implications of using taint\nanalysis algorithms to complement the mining sandbox approach in the task to\nidentify malicious behavior. Our study brings several findings. For instance,\nthe first study reveals that a static analysis component of DroidFax (a tool\nused for instrumenting Android apps in the Bao et al. study) contributes\nsubstantially to the performance of the dynamic analysis tools explored in the\nprevious work. The results of the second study show that taint analysis is also\npractical to complement the mining sandboxes approach, improve the performance\nof the later strategy in at most 28.57%.",
    "descriptor": "\nComments: 31 pages, 6 figures. Paper accepted for publication in The Journal of Systems & Software\n",
    "authors": [
      "Francisco Handrick da Costa",
      "Ismael Medeiros",
      "Thales Menezes",
      "Jo\u00e3o Victor da Silva",
      "Ingrid Lorraine da Silva",
      "Rodrigo Bonif\u00e1cio",
      "Krishna Narasimhan",
      "M\u00e1rcio Ribeiro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.06613"
  },
  {
    "id": "arXiv:2109.06619",
    "title": "Sampling Network Guided Cross-Entropy Method for Unsupervised Point  Cloud Registration",
    "abstract": "In this paper, by modeling the point cloud registration task as a Markov\ndecision process, we propose an end-to-end deep model embedded with the\ncross-entropy method (CEM) for unsupervised 3D registration. Our model consists\nof a sampling network module and a differentiable CEM module. In our sampling\nnetwork module, given a pair of point clouds, the sampling network learns a\nprior sampling distribution over the transformation space. The learned sampling\ndistribution can be used as a \"good\" initialization of the differentiable CEM\nmodule. In our differentiable CEM module, we first propose a maximum consensus\ncriterion based alignment metric as the reward function for the point cloud\nregistration task. Based on the reward function, for each state, we then\nconstruct a fused score function to evaluate the sampled transformations, where\nwe weight the current and future rewards of the transformations. Particularly,\nthe future rewards of the sampled transforms are obtained by performing the\niterative closest point (ICP) algorithm on the transformed state. By selecting\nthe top-k transformations with the highest scores, we iteratively update the\nsampling distribution. Furthermore, in order to make the CEM differentiable, we\nuse the sparsemax function to replace the hard top-$k$ selection. Finally, we\nformulate a Geman-McClure estimator based loss to train our end-to-end\nregistration model. Extensive experimental results demonstrate the good\nregistration performance of our method on benchmark datasets.",
    "descriptor": "\nComments: Accepted by ICCV-2021\n",
    "authors": [
      "Haobo Jiang",
      "Yaqi Shen",
      "Jin Xie",
      "Jun Li",
      "Jianjun Qian",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06619"
  },
  {
    "id": "arXiv:2109.06620",
    "title": "Dynamic Attentive Graph Learning for Image Restoration",
    "abstract": "Non-local self-similarity in natural images has been verified to be an\neffective prior for image restoration. However, most existing deep non-local\nmethods assign a fixed number of neighbors for each query item, neglecting the\ndynamics of non-local correlations. Moreover, the non-local correlations are\nusually based on pixels, prone to be biased due to image degradation. To\nrectify these weaknesses, in this paper, we propose a dynamic attentive graph\nlearning model (DAGL) to explore the dynamic non-local property on patch level\nfor image restoration. Specifically, we propose an improved graph model to\nperform patch-wise graph convolution with a dynamic and adaptive number of\nneighbors for each node. In this way, image content can adaptively balance\nover-smooth and over-sharp artifacts through the number of its connected\nneighbors, and the patch-wise non-local correlations can enhance the message\npassing process. Experimental results on various image restoration tasks:\nsynthetic image denoising, real image denoising, image demosaicing, and\ncompression artifact reduction show that our DAGL can produce state-of-the-art\nresults with superior accuracy and visual quality. The source code is available\nat https://github.com/jianzhangcs/DAGL.",
    "descriptor": "\nComments: Accepted by ICCV 2021\n",
    "authors": [
      "Chong Mou",
      "Jian Zhang",
      "Zhuoyuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06620"
  },
  {
    "id": "arXiv:2109.06622",
    "title": "Optimizing the ecological connectivity of landscapes with generalized  flow models and preprocessing",
    "abstract": "In this paper we consider the problem of optimizing the ecological\nconnectivity of a landscape under a budget constraint by improving habitat\nareas and ecological corridors between them. We consider a formulation of this\nproblem in terms of graphs in which vertices represent the habitat areas and\narcs represent a probability of connection between two areas that depend on the\nquality of the respective corridor. We propose a new generalized flow model\nthat improves existing models for this problem and an efficient preprocessing\nalgorithm that reduces the size of the graphs on which generalized flows is\ncomputed. Reported numerical experiments highlight the benefice of these two\ncontributions on computation times and show that larger problems can be solved\nusing them. Our experiments also show that several variants of greedy\nalgorithms perform relatively well on practical instances while they return\narbitrary bad solutions in the worst case.",
    "descriptor": "\nComments: 26 pages, 5 figures , preprint submitted to Networks\n",
    "authors": [
      "Fran\u00e7ois Hamonic",
      "C\u00e9cile Albert",
      "Basile Cou\u00ebtoux",
      "Yann Vax\u00e8s"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06622"
  },
  {
    "id": "arXiv:2109.06625",
    "title": "Towards optimized actions in critical situations of soccer games with  deep reinforcement learning",
    "abstract": "Soccer is a sparse rewarding game: any smart or careless action in critical\nsituations can change the result of the match. Therefore players, coaches, and\nscouts are all curious about the best action to be performed in critical\nsituations, such as the times with a high probability of losing ball possession\nor scoring a goal. This work proposes a new state representation for the soccer\ngame and a batch reinforcement learning to train a smart policy network. This\nnetwork gets the contextual information of the situation and proposes the\noptimal action to maximize the expected goal for the team. We performed\nextensive numerical experiments on the soccer logs made by InStat for 104\nEuropean soccer matches. The results show that in all 104 games, the optimized\npolicy obtains higher rewards than its counterpart in the behavior policy.\nBesides, our framework learns policies that are close to the expected behavior\nin the real world. For instance, in the optimized policy, we observe that some\nactions such as foul, or ball out can be sometimes more rewarding than a shot\nin specific situations.",
    "descriptor": "",
    "authors": [
      "Pegah Rahimian",
      "Afshin Oroojlooy",
      "Laszlo Toka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06625"
  },
  {
    "id": "arXiv:2109.06627",
    "title": "Scalable Font Reconstruction with Dual Latent Manifolds",
    "abstract": "We propose a deep generative model that performs typography analysis and font\nreconstruction by learning disentangled manifolds of both font style and\ncharacter shape. Our approach enables us to massively scale up the number of\ncharacter types we can effectively model compared to previous methods.\nSpecifically, we infer separate latent variables representing character and\nfont via a pair of inference networks which take as input sets of glyphs that\neither all share a character type, or belong to the same font. This design\nallows our model to generalize to characters that were not observed during\ntraining time, an important task in light of the relative sparsity of most\nfonts. We also put forward a new loss, adapted from prior work that measures\nlikelihood using an adaptive distribution in a projected space, resulting in\nmore natural images without requiring a discriminator. We evaluate on the task\nof font reconstruction over various datasets representing character types of\nmany languages, and compare favorably to modern style transfer systems\naccording to both automatic and manually-evaluated metrics.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Nikita Srivatsan",
      "Si Wu",
      "Jonathan T. Barron",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06627"
  },
  {
    "id": "arXiv:2109.06628",
    "title": "Open-World Active Learning with Stacking Ensemble for Self-Driving Cars",
    "abstract": "The environments, in which autonomous cars act, are high-risky, dynamic, and\nfull of uncertainty, demanding a continuous update of their sensory information\nand knowledge bases. The frequency of facing an unknown object is too high\nmaking hard the usage of Artificial Intelligence (AI) classical classification\nmodels that usually rely on the close-world assumption. This problem of\nclassifying objects in this domain is better faced with and open-world AI\napproach. We propose an algorithm to identify not only all the known entities\nthat may appear in front of the car, but also to detect and learn the classes\nof those unknown objects that may be rare to stand on an highway (e.g., a lost\nbox from a truck). Our approach relies on the DOC algorithm from Lei Shu et.\nal. as well as on the Query-by-Committee algorithm.",
    "descriptor": "",
    "authors": [
      "Paulo R. Vieira",
      "Pedro D. F\u00e9lix",
      "Luis Macedo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06628"
  },
  {
    "id": "arXiv:2109.06629",
    "title": "Investigation of condominium building collapse in Surfside, Florida: a  video feature tracking approach",
    "abstract": "On June 24, 2021, a 12-story condominium building (Champlain Towers South) in\nSurfside, Florida partially collapsed, resulting in one of the deadliest\nbuilding collapses in United States history with 98 people are confirmed dead.\nWe analyze this collapse event using a video clip that is publicly available\nfrom social media. We apply computer vision algorithms to corroborate new\ninformation from the video clip that may not be readily interpreted by human\neyes. By comparing the differential features against different video frames,\nour method can quantify the falling structural components by intuitively\nshowing the directions and magnitudes of their movements. We demonstrate the\npotential of this video processing methodology in investigations of\ncatastrophic structural failures and hope our results would serve as the basis\nfor further investigations of this and other structure collapse events.",
    "descriptor": "",
    "authors": [
      "Xiangxiong Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06629"
  },
  {
    "id": "arXiv:2109.06630",
    "title": "Detecting Layout Templates in Complex Multiregion Files",
    "abstract": "Spreadsheets are among the most commonly used file formats for data\nmanagement, distribution, and analysis. Their widespread employment makes it\neasy to gather large collections of data, but their flexible canvas-based\nstructure makes automated analysis difficult without heavy preparation. One of\nthe common problems that practitioners face is the presence of multiple,\nindependent regions in a single spreadsheet, possibly separated by repeated\nempty cells. We define such files as \"multiregion\" files. In collections of\nvarious spreadsheets, we can observe that some share the same layout. We\npresent the Mondrian approach to automatically identify layout templates across\nmultiple files and systematically extract the corresponding regions. Our\napproach is composed of three phases: first, each file is rendered as an image\nand inspected for elements that could form regions; then, using a clustering\nalgorithm, the identified elements are grouped to form regions; finally, every\nfile layout is represented as a graph and compared with others to find layout\ntemplates. We compare our method to state-of-the-art table recognition\nalgorithms on two corpora of real-world enterprise spreadsheets. Our approach\nshows the best performances in detecting reliable region boundaries within each\nfile and can correctly identify recurring layouts across files.",
    "descriptor": "",
    "authors": [
      "Gerardo Vitagliano",
      "Lan Jiang",
      "Felix Naumann"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.06630"
  },
  {
    "id": "arXiv:2109.06634",
    "title": "A Novel Data Encryption Method Inspired by Adversarial Attacks",
    "abstract": "Due to the advances of sensing and storage technologies, a tremendous amount\nof data becomes available and, it supports the phenomenal growth of artificial\nintelligence (AI) techniques especially, deep learning (DL), in various\napplication domains. While the data sources become valuable assets for enabling\nthe success of autonomous decision-making, they also lead to critical\nvulnerabilities in privacy and security. For example, data leakage can be\nexploited via querying and eavesdropping in the exploratory phase for black-box\nattacks against DL-based autonomous decision-making systems. To address this\nissue, in this work, we propose a novel data encryption method, called\nAdvEncryption, by exploiting the principle of adversarial attacks. Different\nfrom existing encryption technologies, the AdvEncryption method is not\ndeveloped to prevent attackers from exploiting the dataset. Instead, our\nproposed method aims to trap the attackers in a misleading feature distillation\nof the data. To achieve this goal, our AdvEncryption method consists of two\nessential components: 1) an adversarial attack-inspired encryption mechanism to\nencrypt the data with stealthy adversarial perturbation, and 2) a decryption\nmechanism that minimizes the impact of the perturbations on the effectiveness\nof autonomous decision making. In the performance evaluation section, we\nevaluate the performance of our proposed AdvEncryption method through case\nstudies considering different scenarios.",
    "descriptor": "",
    "authors": [
      "Praveen Fernando",
      "Jin Wei-Kocsis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06634"
  },
  {
    "id": "arXiv:2109.06637",
    "title": "Multi-modal Representation Learning for Video Advertisement Content  Structuring",
    "abstract": "Video advertisement content structuring aims to segment a given video\nadvertisement and label each segment on various dimensions, such as\npresentation form, scene, and style. Different from real-life videos, video\nadvertisements contain sufficient and useful multi-modal content like caption\nand speech, which provides crucial video semantics and would enhance the\nstructuring process. In this paper, we propose a multi-modal encoder to learn\nmulti-modal representation from video advertisements by interacting between\nvideo-audio and text. Based on multi-modal representation, we then apply\nBoundary-Matching Network to generate temporal proposals. To make the proposals\nmore accurate, we refine generated proposals by scene-guided alignment and\nre-ranking. Finally, we incorporate proposal located embeddings into the\nintroduced multi-modal encoder to capture temporal relationships between local\nfeatures of each proposal and global features of the whole video for\nclassification. Experimental results show that our method achieves\nsignificantly improvement compared with several baselines and Rank 1 on the\ntask of Multi-modal Ads Video Understanding in ACM Multimedia 2021 Grand\nChallenge. Ablation study further shows that leveraging multi-modal content\nlike caption and speech in video advertisements significantly improve the\nperformance.",
    "descriptor": "",
    "authors": [
      "Daya Guo",
      "Zhaoyang Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.06637"
  },
  {
    "id": "arXiv:2109.06638",
    "title": "Learnable Discrete Wavelet Pooling (LDW-Pooling) For Convolutional  Networks",
    "abstract": "Pooling is a simple but essential layer in modern deep CNN architectures for\nfeature aggregation and extraction. Typical CNN design focuses on the conv\nlayers and activation functions, while leaving the pooling layers with fewer\noptions. We introduce the Learning Discrete Wavelet Pooling (LDW-Pooling) that\ncan be applied universally to replace standard pooling operations to better\nextract features with improved accuracy and efficiency. Motivated from the\nwavelet theory, we adopt the low-pass (L) and high-pass (H) filters\nhorizontally and vertically for pooling on a 2D feature map. Feature signals\nare decomposed into four (LL, LH, HL, HH) subbands to retain features better\nand avoid information dropping. The wavelet transform ensures features after\npooling can be fully preserved and recovered. We next adopt an energy-based\nattention learning to fine-select crucial and representative features.\nLDW-Pooling is effective and efficient when compared with other\nstate-of-the-art pooling techniques such as WaveletPooling and LiftPooling.\nExtensive experimental validation shows that LDW-Pooling can be applied to a\nwide range of standard CNN architectures and consistently outperform standard\n(max, mean, mixed, and stochastic) pooling operations.",
    "descriptor": "",
    "authors": [
      "Jun-Wei Hsieh",
      "Ming-Ching Chang",
      "Ping-Yang Chen",
      "Bor-Shiun Wang",
      "Lipeng Ke",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06638"
  },
  {
    "id": "arXiv:2109.06640",
    "title": "Online k-Way Matching with Delays and the H-Metric",
    "abstract": "In this paper, we study $k$-Way Min-cost Perfect Matching with Delays - the\n$k$-MPMD problem. This problem considers a metric space with $n$ nodes.\nRequests arrive at these nodes in an online fashion. The task is to match these\nrequests into sets of exactly $k$, such that the space and time cost of all\nmatched requests are minimized. The notion of the space cost requires a\ndefinition of an underlying metric space that gives distances of subsets of $k$\nelements. For $k>2$, the task of finding a suitable metric space is at the core\nof our problem: We show that for some known generalizations to $k=3$ points,\nsuch as the $2$-metric and the $D$-metric, there exists no competitive\nrandomized algorithm for the $3$-MPMD problem. The $G$-metrics are defined for\n3 points and allows for a competitive algorithm for the $3$-MPMD problem. For\n$k>3$ points, there exist two generalizations of the $G$-metrics known as $n$-\nand $K$-metrics. We show that neither the $n$-metrics nor the $K$-metrics can\nbe used for the $k$-MPMD problem. On the positive side, we introduce the\n$H$-metrics, the first metrics to allow for a solution of the $k$-MPMD problem\nfor all $k$. In order to devise an online algorithm for the $k$-MPMD problem on\nthe $H$-metrics, we embed the $H$-metric into trees with an $O(\\log n)$\ndistortion. Based on this embedding result, we extend the algorithm proposed by\nAzar et al. (2017) and achieve a competitive ratio of $O(\\log n)$ for the\n$k$-MPMD problem.",
    "descriptor": "",
    "authors": [
      "Darya Melnyk",
      "Yuyi Wang",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06640"
  },
  {
    "id": "arXiv:2109.06647",
    "title": "A space-time multiscale method for parabolic problems",
    "abstract": "We present a space-time multiscale method for a parabolic model problem with\nan underlying coefficient that may be highly oscillatory with respect to both\nthe spatial and the temporal variables. The method is based on the framework of\nthe Variational Multiscale Method in the context of a space-time formulation\nand computes a coarse-scale representation of the differential operator that is\nenriched by auxiliary space-time corrector functions. Once computed, the\ncoarse-scale representation allows us to efficiently obtain well-approximating\ndiscrete solutions for multiple right-hand sides. We prove first-order\nconvergence independently of the oscillation scales in the coefficient and\nillustrate how the space-time correctors decay exponentially in both space and\ntime, making it possible to localize the corresponding computations. This\nlocalization allows us to define a practical and computationally efficient\nmethod in terms of complexity and memory, for which we provide a posteriori\nerror estimates and present numerical examples.",
    "descriptor": "",
    "authors": [
      "Per Ljung",
      "Roland Maier",
      "Axel M\u00e5lqvist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.06647"
  },
  {
    "id": "arXiv:2109.06651",
    "title": "CropDefender: deep watermark which is more convenient to train and more  robust against cropping",
    "abstract": "Digital image watermarking, which is a technique for invisibly embedding\ninformation into an image, is used in fields such as property rights\nprotection. In recent years, some research has proposed the use of neural\nnetworks to add watermarks to natural images. We take StegaStamp as an example\nfor our research. Whether facing traditional image editing methods, such as\nbrightness, contrast, saturation adjustment, or style change like 1-bit\nconversion, GAN, StegaStamp has robustness far beyond traditional watermarking\ntechniques, but it still has two drawbacks: it is vulnerable to cropping and is\nhard to train. We found that the causes of vulnerability to cropping is not the\nloss of information on the edge, but the movement of watermark position. By\nexplicitly introducing the perturbation of cropping into the training, the\ncropping resistance is significantly improved. For the problem of difficult\ntraining, we introduce instance normalization to solve the vanishing gradient,\nset losses' weights as learnable parameters to reduce the number of\nhyperparameters, and use sigmoid to restrict pixel values of the generated\nimage.",
    "descriptor": "",
    "authors": [
      "Jiayu Ding",
      "Yuchen Cao",
      "Changhao Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06651"
  },
  {
    "id": "arXiv:2109.06652",
    "title": "Domain Adaptation by Maximizing Population Correlation with Neural  Architecture Search",
    "abstract": "In Domain Adaptation (DA), where the feature distributions of the source and\ntarget domains are different, various distance-based methods have been proposed\nto minimize the discrepancy between the source and target domains to handle the\ndomain shift. In this paper, we propose a new similarity function, which is\ncalled Population Correlation (PC), to measure the domain discrepancy for DA.\nBase on the PC function, we propose a new method called Domain Adaptation by\nMaximizing Population Correlation (DAMPC) to learn a domain-invariant feature\nrepresentation for DA. Moreover, most existing DA methods use hand-crafted\nbottleneck networks, which may limit the capacity and flexibility of the\ncorresponding model. Therefore, we further propose a method called DAMPC with\nNeural Architecture Search (DAMPC-NAS) to search the optimal network\narchitecture for DAMPC. Experiments on several benchmark datasets, including\nOffice-31, Office-Home, and VisDA-2017, show that the proposed DAMPC-NAS method\nachieves better results than state-of-the-art DA methods.",
    "descriptor": "",
    "authors": [
      "Zhixiong Yue",
      "Pengxin Guo",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06652"
  },
  {
    "id": "arXiv:2109.06653",
    "title": "An entropy stable spectral vanishing viscosity for discontinuous  Galerkin schemes: application to shock capturing and LES models",
    "abstract": "We present a stable spectral vanishing viscosity for discontinuous Galerkin\nschemes, with applications to turbulent and supersonic flows. The idea behind\nthe SVV is to spatially filter the dissipative fluxes, such that it\nconcentrates in higher wavenumbers, where the flow is typically under-resolved,\nleaving low wavenumbers dissipation-free. Moreover, we derive a stable\napproximation of the Guermond-Popov fluxes with the Bassi-Rebay 1 scheme, used\nto introduce density regularization in shock capturing simulations. This\nfiltering uses a Cholesky decomposition of the fluxes that ensures the entropy\nstability of the scheme, which also includes a stable approximation of boundary\nconditions for adiabatic walls. For turbulent flows, we test the method with\nthe three-dimensional Taylor-Green vortex and show that energy is correctly\ndissipated, and the scheme is stable when a kinetic energy preserving\nsplit-form is used in combination with a low dissipation Riemann solver.\nFinally, we test the shock capturing capabilities of our method with the\nShu-Osher and the supersonic forward facing step cases, obtaining good results\nwithout spurious oscillations even with coarse meshes.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s Mateo-Gab\u00edn",
      "Juan Manzanero",
      "Eusebio Valero"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2109.06653"
  },
  {
    "id": "arXiv:2109.06655",
    "title": "Improving Test Case Generation for REST APIs Through Hierarchical  Clustering",
    "abstract": "With the ever-increasing use of web APIs in modern-day applications, it is\nbecoming more important to test the system as a whole. In the last decade,\ntools and approaches have been proposed to automate the creation of\nsystem-level test cases for these APIs using evolutionary algorithms (EAs). One\nof the limiting factors of EAs is that the genetic operators (crossover and\nmutation) are fully randomized, potentially breaking promising patterns in the\nsequences of API requests discovered during the search. Breaking these patterns\nhas a negative impact on the effectiveness of the test case generation process.\nTo address this limitation, this paper proposes a new approach that uses\nagglomerative hierarchical clustering (AHC) to infer a linkage tree model,\nwhich captures, replicates, and preserves these patterns in new test cases. We\nevaluate our approach, called LT-MOSA, by performing an empirical study on 7\nreal-world benchmark applications w.r.t. branch coverage and real-fault\ndetection capability. We also compare LT-MOSA with the two existing\nstate-of-the-art white-box techniques (MIO, MOSA) for REST API testing. Our\nresults show that LT-MOSA achieves a statistically significant increase in test\ntarget coverage (i.e., lines and branches) compared to MIO and MOSA in 4 and 5\nout of 7 applications, respectively. Furthermore, LT-MOSA discovers 27 and 18\nunique real-faults that are left undetected by MIO and MOSA, respectively.",
    "descriptor": "",
    "authors": [
      "Dimitri Stallenberg",
      "Mitchell Olsthoorn",
      "Annibale Panichella"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06655"
  },
  {
    "id": "arXiv:2109.06657",
    "title": "Dynamic self-triggered control for nonlinear systems based on hybrid  Lyapunov functions",
    "abstract": "Self-triggered control (STC) is a well-established technique to reduce the\namount of samples for sampled-data systems, and is hence particularly useful\nfor Networked Control Systems. At each sampling instant, an STC mechanism\ndetermines not only an updated control input but also when the next sample\nshould be taken. In this paper, a dynamic STC mechanism for nonlinear systems\nis proposed. The mechanism incorporates a dynamic variable for determining the\nnext sampling instant. Such a dynamic variable for the trigger decision has\nbeen proven to be a powerful tool for increasing sampling intervals in the\nclosely related concept of event-triggered control, but was so far not\nexploited for STC. This gap is closed in this paper. For the proposed\nmechanism, the dynamic variable is chosen to be the filtered values of the\nLyapunov function at past sampling instants. The next sampling instant is,\nbased on the dynamic variable and on hybrid Lyapunov function techniques,\nchosen such that an average decrease of the Lyapunov function is ensured. The\nproposed mechanism is illustrated with a numerical example from the literature.\nFor this example, the obtained sampling intervals are significantly larger than\nfor existing static STC mechanisms. This paper is the accepted version of [1],\ncontaining also proofs of the main results.",
    "descriptor": "\nComments: Accepted for 60th IEEE Conference on Decision and Control\n",
    "authors": [
      "Michael Hertneck",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06657"
  },
  {
    "id": "arXiv:2109.06660",
    "title": "An MRC Framework for Semantic Role Labeling",
    "abstract": "Semantic Role Labeling (SRL) aims at recognizing the predicate-argument\nstructure of a sentence and can be decomposed into two subtasks: predicate\ndisambiguation and argument labeling. Prior work deals with these two tasks\nindependently, which ignores the semantic connection between the two tasks. In\nthis paper, we propose to use the machine reading comprehension (MRC) framework\nto bridge this gap. We formalize predicate disambiguation as multiple-choice\nmachine reading comprehension, where the descriptions of candidate senses of a\ngiven predicate are used as options to select the correct sense. The chosen\npredicate sense is then used to determine the semantic roles for that\npredicate, and these semantic roles are used to construct the query for another\nMRC model for argument labeling. In this way, we are able to leverage both the\npredicate semantics and the semantic role semantics for argument labeling. We\nalso propose to select a subset of all the possible semantic roles for\ncomputational efficiency. Experiments show that the proposed framework achieves\nstate-of-the-art results on both span and dependency benchmarks.",
    "descriptor": "",
    "authors": [
      "Nan Wang",
      "Jiwei Li",
      "Yuxian Meng",
      "Xiaofei Sun",
      "Jun He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06660"
  },
  {
    "id": "arXiv:2109.06661",
    "title": "Expert Knowledge-Guided Length-Variant Hierarchical Label Generation for  Proposal Classification",
    "abstract": "To advance the development of science and technology, research proposals are\nsubmitted to open-court competitive programs developed by government agencies\n(e.g., NSF). Proposal classification is one of the most important tasks to\nachieve effective and fair review assignments. Proposal classification aims to\nclassify a proposal into a length-variant sequence of labels. In this paper, we\nformulate the proposal classification problem into a hierarchical multi-label\nclassification task. Although there are certain prior studies, proposal\nclassification exhibit unique features: 1) the classification result of a\nproposal is in a hierarchical discipline structure with different levels of\ngranularity; 2) proposals contain multiple types of documents; 3) domain\nexperts can empirically provide partial labels that can be leveraged to improve\ntask performances. In this paper, we focus on developing a new deep proposal\nclassification framework to jointly model the three features. In particular, to\nsequentially generate labels, we leverage previously-generated labels to\npredict the label of next level; to integrate partial labels from experts, we\nuse the embedding of these empirical partial labels to initialize the state of\nneural networks. Our model can automatically identify the best length of label\nsequence to stop next label prediction. Finally, we present extensive results\nto demonstrate that our method can jointly model partial labels, textual\ninformation, and semantic dependencies in label sequences, and, thus, achieve\nadvanced performances.",
    "descriptor": "",
    "authors": [
      "Meng Xiao",
      "Ziyue Qiao",
      "Yanjie Fu",
      "Yi Du",
      "Pengyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06661"
  },
  {
    "id": "arXiv:2109.06662",
    "title": "Identifying partial mouse brain microscopy images from Allen reference  atlas using a contrastively learned semantic space",
    "abstract": "Precise identification of mouse brain microscopy images is a crucial first\nstep when anatomical structures in the mouse brain are to be registered to a\nreference atlas. Practitioners usually rely on manual comparison of images or\ntools that assume the presence of complete images. This work explores Siamese\nNetworks as the method for finding corresponding 2D reference atlas plates for\ngiven partial 2D mouse brain images. Siamese networks are a class of\nconvolutional neural networks (CNNs) that use weight-shared paths to obtain low\ndimensional embeddings of pairs of input images. The correspondence between the\npartial mouse brain image and reference atlas plate is determined based on the\ndistance between low dimensional embeddings of brain slices and atlas plates\nthat are obtained from Siamese networks using contrastive learning. Experiments\nshowed that Siamese CNNs can precisely identify brain slices using the Allen\nmouse brain atlas when training and testing images come from the same source.\nThey achieved TOP-1 and TOP-5 accuracy of 25% and 100%, respectively, taking\nonly 7.2 seconds to identify 29 images.",
    "descriptor": "\nComments: Source code available at this https URL 7 pages, 5 figures\n",
    "authors": [
      "Justinas Antanavicius",
      "Roberto Leiras Gonzalez",
      "Raghavendra Selvan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06662"
  },
  {
    "id": "arXiv:2109.06663",
    "title": "An Insect-Inspired Randomly, Weighted Neural Network with Random Fourier  Features For Neuro-Symbolic Relational Learning",
    "abstract": "Insects, such as fruit flies and honey bees, can solve simple associative\nlearning tasks and learn abstract concepts such as \"sameness\" and \"difference\",\nwhich is viewed as a higher-order cognitive function and typically thought to\ndepend on top-down neocortical processing. Empirical research with fruit flies\nstrongly supports that a randomized representational architecture is used in\nolfactory processing in insect brains. Based on these results, we propose a\nRandomly Weighted Feature Network (RWFN) that incorporates randomly drawn,\nuntrained weights in an encoder that uses an adapted linear model as a decoder.\nThe randomized projections between input neurons and higher-order processing\ncenters in the input brain is mimicked in RWFN by a single-hidden-layer neural\nnetwork that specially structures latent representations in the hidden layer\nusing random Fourier features that better represent complex relationships\nbetween inputs using kernel approximation. Because of this special\nrepresentation, RWFNs can effectively learn the degree of relationship among\ninputs by training only a linear decoder model. We compare the performance of\nRWFNs to LTNs for Semantic Image Interpretation (SII) tasks that have been used\nas a representative example of how LTNs utilize reasoning over first-order\nlogic to surpass the performance of solely data-driven methods. We demonstrate\nthat compared to LTNs, RWFNs can achieve better or similar performance for both\nobject classification and detection of the part-of relations between objects in\nSII tasks while using much far fewer learnable parameters (1:62 ratio) and a\nfaster learning process (1:2 ratio of running speed). Furthermore, we show that\nbecause the randomized weights do not depend on the data, several decoders can\nshare a single randomized encoder, giving RWFNs a unique economy of spatial\nscale for simultaneous classification tasks.",
    "descriptor": "\nComments: 17 pages, 5 figures, 2 tables, submitted to NeSy20/21 @ IJCLR. arXiv admin note: text overlap with arXiv:2006.12392\n",
    "authors": [
      "Jinyung Hong",
      "Theodore P. Pavlic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06663"
  },
  {
    "id": "arXiv:2109.06667",
    "title": "A Blockchain based Federated Learning for Message Dissemination in  Vehicular Networks",
    "abstract": "Message exchange among vehicles plays an important role in ensuring road\nsafety. Emergency message dissemination is usually carried out by broadcasting.\nHowever, high vehicle density and mobility usually lead to challenges in\nmessage dissemination such as broadcasting storm and low probability of packet\nreception. This paper proposes a federated learning based blockchain-assisted\nmessage dissemination solution. Similar to the incentive-based Proof-of-Work\nconsensus in blockchain, vehicles compete to become a relay node (miner) by\nprocessing the proposed Proof-of-Federated-Learning (PoFL) consensus which is\nembedded in the smart contract of blockchain. Both theoretical and practical\nanalysis of the proposed solution are provided. Specifically, the proposed\nblockchain based federated learning results in more number of vehicles\nuploading their models in a given time, which can potentially lead to a more\naccurate model in less time as compared to the same solution without using\nblockchain. It also outperforms the other blockchain approaches for message\ndissemination by reducing 65.2% of time delay in consensus, improving at least\n8.2% message delivery rate and preserving privacy of neighbor vehicle more\nefficiently. The economic model to incentivize vehicles participating in\nfederated learning and message dissemination is further analyzed using\nStackelberg game model.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Ferheen Ayaz",
      "Zhengguo Sheng",
      "Daxin Tian",
      "Yong Liang Guan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06667"
  },
  {
    "id": "arXiv:2109.06668",
    "title": "Exploration in Deep Reinforcement Learning: A Comprehensive Survey",
    "abstract": "Deep Reinforcement Learning (DRL) and Deep Multi-agent Reinforcement Learning\n(MARL) have achieved significant success across a wide range of domains, such\nas game AI, autonomous vehicles, robotics and finance. However, DRL and deep\nMARL agents are widely known to be sample-inefficient and millions of\ninteractions are usually needed even for relatively simple game settings, thus\npreventing the wide application in real-industry scenarios. One bottleneck\nchallenge behind is the well-known exploration problem, i.e., how to\nefficiently explore the unknown environments and collect informative\nexperiences that could benefit the policy learning most.\nIn this paper, we conduct a comprehensive survey on existing exploration\nmethods in DRL and deep MARL for the purpose of providing understandings and\ninsights on the critical problems and solutions. We first identify several key\nchallenges to achieve efficient exploration, which most of the exploration\nmethods aim at addressing. Then we provide a systematic survey of existing\napproaches by classifying them into two major categories: uncertainty-oriented\nexploration and intrinsic motivation-oriented exploration. The essence of\nuncertainty-oriented exploration is to leverage the quantification of the\nepistemic and aleatoric uncertainty to derive efficient exploration. By\ncontrast, intrinsic motivation-oriented exploration methods usually incorporate\ndifferent reward agnostic information for intrinsic exploration guidance.\nBeyond the above two main branches, we also conclude other exploration methods\nwhich adopt sophisticated techniques but are difficult to be classified into\nthe above two categories. In addition, we provide a comprehensive empirical\ncomparison of exploration methods for DRL on a set of commonly used benchmarks.\nFinally, we summarize the open problems of exploration in DRL and deep MARL and\npoint out a few future directions.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1908.06976 by other authors\n",
    "authors": [
      "Tianpei Yang",
      "Hongyao Tang",
      "Chenjia Bai",
      "Jinyi Liu",
      "Jianye Hao",
      "Zhaopeng Meng",
      "Peng Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.06668"
  },
  {
    "id": "arXiv:2109.06671",
    "title": "High-Resolution Image Harmonization via Collaborative Dual  Transformations",
    "abstract": "Given a composite image, image harmonization aims to adjust the foreground to\nmake it compatible with the background. High-resolution image harmonization is\nin high demand, but still remains unexplored. Conventional image harmonization\nmethods learn global RGB-to-RGB transformation which could effortlessly scale\nto high resolution, but ignore diverse local context. Recent deep learning\nmethods learn the dense pixel-to-pixel transformation which could generate\nharmonious outputs, but are highly constrained in low resolution. In this work,\nwe propose a high-resolution image harmonization network with Collaborative\nDual Transformation (CDTNet) to combine pixel-to-pixel transformation and\nRGB-to-RGB transformation coherently in an end-to-end framework. Our CDTNet\nconsists of a low-resolution generator for pixel-to-pixel transformation, a\ncolor mapping module for RGB-to-RGB transformation, and a refinement module to\ntake advantage of both. Extensive experiments on high-resolution image\nharmonization dataset demonstrate that our CDTNet strikes a good balance\nbetween efficiency and effectiveness.",
    "descriptor": "",
    "authors": [
      "Wenyan Cong",
      "Xinhao Tao",
      "Li Niu",
      "Jing Liang",
      "Xuesong Gao",
      "Qihao Sun",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06671"
  },
  {
    "id": "arXiv:2109.06675",
    "title": "Topics Emerged in the Biomedical Field and Their Characteristics",
    "abstract": "This study aims to reveal what kind of topics emerged in the biomedical\ndomain by retrospectively analyzing newly added MeSH (Medical Subject Headings)\nterms from 2001 to 2010 and how they have been used for indexing since their\ninclusion in the thesaurus. The goal is to investigate if the future trend of a\nnew topic depends on what kind of topic it is without relying on external\nindicators such as growth, citation patterns, or word co-occurrences. This\ntopic perspective complements the traditional publication perspective in\nstudying emerging topics. Results show that topic characteristics, including\ntopic category, clinical significance, and if a topic has any narrower terms at\nthe time of inclusion, influence future popularity of a new MeSH. Four\nemergence trend patterns are identified, including emerged and sustained,\nemerged not sustained, emerged and fluctuated, and not yet emerged. Predictive\nmodels using topic characteristics for emerging topic prediction show promise.\nThis suggests that the characteristics of topics and domain should be\nconsidered when predicting future emergence of research topics. This study\nbridges a gap in emerging topic prediction by offering a topic perspective and\nadvocates for considering topic and domain characteristics as well as economic,\nmedical, and environmental impact when studying emerging topics in the\nbiomedical domain.",
    "descriptor": "",
    "authors": [
      "Kun Lu",
      "Guancan Yang",
      "Xue Wang"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2109.06675"
  },
  {
    "id": "arXiv:2109.06679",
    "title": "Efficient Inference for Multilingual Neural Machine Translation",
    "abstract": "Multilingual NMT has become an attractive solution for MT deployment in\nproduction. But to match bilingual quality, it comes at the cost of larger and\nslower models. In this work, we consider several ways to make multilingual NMT\nfaster at inference without degrading its quality. We experiment with several\n\"light decoder\" architectures in two 20-language multi-parallel settings:\nsmall-scale on TED Talks and large-scale on ParaCrawl. Our experiments\ndemonstrate that combining a shallow decoder with vocabulary filtering leads to\nmore than twice faster inference with no loss in translation quality. We\nvalidate our findings with BLEU and chrF (on 380 language pairs), robustness\nevaluation and human evaluation.",
    "descriptor": "\nComments: Accepted as a long paper to EMNLP 2021\n",
    "authors": [
      "Alexandre Berard",
      "Dain Lee",
      "St\u00e9phane Clinchant",
      "Kweonwoo Jung",
      "Vassilina Nikoulina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06679"
  },
  {
    "id": "arXiv:2109.06684",
    "title": "Non-autoregressive Transformer with Unified Bidirectional Decoder for  Automatic Speech Recognition",
    "abstract": "Non-autoregressive (NAR) transformer models have been studied intensively in\nautomatic speech recognition (ASR), and a substantial part of NAR transformer\nmodels is to use the casual mask to limit token dependencies. However, the\ncasual mask is designed for the left-to-right decoding process of the\nnon-parallel autoregressive (AR) transformer, which is inappropriate for the\nparallel NAR transformer since it ignores the right-to-left contexts. Some\nmodels are proposed to utilize right-to-left contexts with an extra decoder,\nbut these methods increase the model complexity. To tackle the above problems,\nwe propose a new non-autoregressive transformer with a unified bidirectional\ndecoder (NAT-UBD), which can simultaneously utilize left-to-right and\nright-to-left contexts. However, direct use of bidirectional contexts will\ncause information leakage, which means the decoder output can be affected by\nthe character information from the input of the same position. To avoid\ninformation leakage, we propose a novel attention mask and modify vanilla\nqueries, keys, and values matrices for NAT-UBD. Experimental results verify\nthat NAT-UBD can achieve character error rates (CERs) of 5.0%/5.5% on the\nAishell1 dev/test sets, outperforming all previous NAR transformer models.\nMoreover, NAT-UBD can run 49.8x faster than the AR transformer baseline when\ndecoding in a single step.",
    "descriptor": "\nComments: 5 pages, 3 figures. Paper submitted to ICASSP 2022\n",
    "authors": [
      "Chuan-Fei Zhang",
      "Yan Liu",
      "Tian-Hao Zhang",
      "Song-Lu Chen",
      "Feng Chen",
      "Xu-Cheng Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.06684"
  },
  {
    "id": "arXiv:2109.06686",
    "title": "Diffeomorphic Image Registration with An Optimal Control Relaxation and  Its Implementation",
    "abstract": "Image registration has played an important role in image processing problems,\nespecially in medical imaging applications. It is well known that when the\ndeformation is large, many variational models cannot ensure diffeomorphism. In\nthis paper, we propose a new registration model based on an optimal control\nrelaxation constraint for large deformation images, which can theoretically\nguarantee that the registration mapping is diffeomorphic. We present an\nanalysis of optimal control relaxation for indirectly seeking the diffeomorphic\ntransformation of Jacobian determinant equation and its registration\napplications, including the construction of diffeomorphic transformation as a\nspecial space. We also provide an existence result for the control increment\noptimization problem in the proposed diffeomorphic image registration model\nwith an optimal control relaxation. Furthermore, a fast iterative scheme based\non the augmented Lagrangian multipliers method (ALMM) is analyzed to solve the\ncontrol increment optimization problem, and a convergence analysis is followed.\nFinally, a grid unfolding indicator is given, and a robust solving algorithm\nfor using the deformation correction and backtrack strategy is proposed to\nguarantee that the solution is diffeomorphic. Numerical experiments show that\nthe registration model we proposed can not only get a diffeomorphic mapping\nwhen the deformation is large, but also achieves the state-of-the-art\nperformance in quantitative evaluations in comparing with other classical\nmodels.",
    "descriptor": "\nComments: This is a preprint manuscript, which is submitted to SIIMS Journal\n",
    "authors": [
      "Jianping Zhang",
      "Yanyan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.06686"
  },
  {
    "id": "arXiv:2109.06688",
    "title": "Luminance Attentive Networks for HDR Image and Panorama Reconstruction",
    "abstract": "It is very challenging to reconstruct a high dynamic range (HDR) from a low\ndynamic range (LDR) image as an ill-posed problem. This paper proposes a\nluminance attentive network named LANet for HDR reconstruction from a single\nLDR image. Our method is based on two fundamental observations: (1) HDR images\nstored in relative luminance are scale-invariant, which means the HDR images\nwill hold the same information when multiplied by any positive real number.\nBased on this observation, we propose a novel normalization method called \" HDR\ncalibration \" for HDR images stored in relative luminance, calibrating HDR\nimages into a similar luminance scale according to the LDR images. (2) The main\ndifference between HDR images and LDR images is in under-/over-exposed areas,\nespecially those highlighted. Following this observation, we propose a\nluminance attention module with a two-stream structure for LANet to pay more\nattention to the under-/over-exposed areas. In addition, we propose an extended\nnetwork called panoLANet for HDR panorama reconstruction from an LDR panorama\nand build a dualnet structure for panoLANet to solve the distortion problem\ncaused by the equirectangular panorama. Extensive experiments show that our\nproposed approach LANet can reconstruct visually convincing HDR images and\ndemonstrate its superiority over state-of-the-art approaches in terms of all\nmetrics in inverse tone mapping. The image-based lighting application with our\nproposed panoLANet also demonstrates that our method can simulate natural scene\nlighting using only LDR panorama. Our source code is available at\nhttps://github.com/LWT3437/LANet.",
    "descriptor": "",
    "authors": [
      "Hanning Yu",
      "Wentao Liu",
      "Chengjiang Long",
      "Bo Dong",
      "Qin Zou",
      "Chunxia Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06688"
  },
  {
    "id": "arXiv:2109.06689",
    "title": "Reactive and Safe Road User Simulations using Neural Barrier  Certificates",
    "abstract": "Reactive and safe agent modelings are important for nowadays traffic\nsimulator designs and safe planning applications. In this work, we proposed a\nreactive agent model which can ensure safety without comprising the original\npurposes, by learning only high-level decisions from expert data and a\nlow-level decentralized controller guided by the jointly learned decentralized\nbarrier certificates. Empirical results show that our learned road user\nsimulation models can achieve a significant improvement in safety comparing to\nstate-of-the-art imitation learning and pure control-based methods, while being\nsimilar to human agents by having smaller errors to the expert data. Moreover,\nour learned reactive agents are shown to generalize better to unseen traffic\nconditions, and react better to other road users and therefore can help\nunderstand challenging planning problems pragmatically.",
    "descriptor": "\nComments: Accepted at IROS 2021\n",
    "authors": [
      "Yue Meng",
      "Zengyi Qin",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06689"
  },
  {
    "id": "arXiv:2109.06692",
    "title": "LRWR: Large-Scale Benchmark for Lip Reading in Russian language",
    "abstract": "Lipreading, also known as visual speech recognition, aims to identify the\nspeech content from videos by analyzing the visual deformations of lips and\nnearby areas. One of the significant obstacles for research in this field is\nthe lack of proper datasets for a wide variety of languages: so far, these\nmethods have been focused only on English or Chinese. In this paper, we\nintroduce a naturally distributed large-scale benchmark for lipreading in\nRussian language, named LRWR, which contains 235 classes and 135 speakers. We\nprovide a detailed description of the dataset collection pipeline and dataset\nstatistics. We also present a comprehensive comparison of the current popular\nlipreading methods on LRWR and conduct a detailed analysis of their\nperformance. The results demonstrate the differences between the benchmarked\nlanguages and provide several promising directions for lipreading models\nfinetuning. Thanks to our findings, we also achieved new state-of-the-art\nresults on the LRW benchmark.",
    "descriptor": "",
    "authors": [
      "Evgeniy Egorov",
      "Vasily Kostyumov",
      "Mikhail Konyk",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06692"
  },
  {
    "id": "arXiv:2109.06697",
    "title": "Safe Nonlinear Control Using Robust Neural Lyapunov-Barrier Functions",
    "abstract": "Safety and stability are common requirements for robotic control systems;\nhowever, designing safe, stable controllers remains difficult for nonlinear and\nuncertain models. We develop a model-based learning approach to synthesize\nrobust feedback controllers with safety and stability guarantees. We take\ninspiration from robust convex optimization and Lyapunov theory to define\nrobust control Lyapunov barrier functions that generalize despite model\nuncertainty. We demonstrate our approach in simulation on problems including\ncar trajectory tracking, nonlinear control with obstacle avoidance, satellite\nrendezvous with safety constraints, and flight control with a learned ground\neffect model. Simulation results show that our approach yields controllers that\nmatch or exceed the capabilities of robust MPC while reducing computational\ncosts by an order of magnitude.",
    "descriptor": "\nComments: Accepted to the 5th Annual Conference on Robot Learning (CoRL 21)\n",
    "authors": [
      "Charles Dawson",
      "Zengyi Qin",
      "Sicun Gao",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06697"
  },
  {
    "id": "arXiv:2109.06702",
    "title": "Learning Based Adaptive Force Control of Robotic Manipulation Based on  Real-Time Object Stiffness Detection",
    "abstract": "Force control is essential for medical robots when touching and contacting\nthe patient's body. To increase the stability and efficiency in force control,\nan Adaption Module could be used to adjust the parameters for different contact\nsituations. We propose an adaptive controller with an Adaption Module which can\nproduce control parameters based on force feedback and real-time stiffness\ndetection. We develop methods for learning the optimal policies by value\niteration and using the data generated from those policies to train the\nAdaptive Module. We test this controller on different zones of a person's arm.\nAll the parameters used in practice are learned from data. The experiments show\nthat the proposed adaptive controller can exert various target forces on\ndifferent zones of the arm with fast convergence and good stability.",
    "descriptor": "",
    "authors": [
      "Zhaoxing Deng",
      "Xutian Deng",
      "Miao Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06702"
  },
  {
    "id": "arXiv:2109.06703",
    "title": "A system for information extraction from scientific texts in Russian",
    "abstract": "In this paper, we present a system for information extraction from scientific\ntexts in the Russian language. The system performs several tasks in an\nend-to-end manner: term recognition, extraction of relations between terms, and\nterm linking with entities from the knowledge base. These tasks are extremely\nimportant for information retrieval, recommendation systems, and\nclassification. The advantage of the implemented methods is that the system\ndoes not require a large amount of labeled data, which saves time and effort\nfor data labeling and therefore can be applied in low- and mid-resource\nsettings. The source code is publicly available and can be used for different\nresearch purposes.",
    "descriptor": "",
    "authors": [
      "Elena Bruches",
      "Anastasia Mezentseva",
      "Tatiana Batura"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06703"
  },
  {
    "id": "arXiv:2109.06704",
    "title": "KFCNet: Knowledge Filtering and Contrastive Learning Network for  Generative Commonsense Reasoning",
    "abstract": "Pre-trained language models have led to substantial gains over a broad range\nof natural language processing (NLP) tasks, but have been shown to have\nlimitations for natural language generation tasks with high-quality\nrequirements on the output, such as commonsense generation and ad keyword\ngeneration. In this work, we present a novel Knowledge Filtering and\nContrastive learning Network (KFCNet) which references external knowledge and\nachieves better generation performance. Specifically, we propose a BERT-based\nfilter model to remove low-quality candidates, and apply contrastive learning\nseparately to each of the encoder and decoder, within a general\nencoder--decoder architecture. The encoder contrastive module helps to capture\nglobal target semantics during encoding, and the decoder contrastive module\nenhances the utility of retrieved prototypes while learning general features.\nExtensive experiments on the CommonGen benchmark show that our model\noutperforms the previous state of the art by a large margin: +6.6 points (42.5\nvs. 35.9) for BLEU-4, +3.7 points (33.3 vs. 29.6) for SPICE, and +1.3 points\n(18.3 vs. 17.0) for CIDEr. We further verify the effectiveness of the proposed\ncontrastive module on ad keyword generation, and show that our model has\npotential commercial value.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 Findings\n",
    "authors": [
      "Haonan Li",
      "Yeyun Gong",
      "Jian Jiao",
      "Ruofei Zhang",
      "Timothy Baldwin",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06704"
  },
  {
    "id": "arXiv:2109.06705",
    "title": "A Novel Global Feature-Oriented Relational Triple Extraction Model based  on Table Filling",
    "abstract": "Table filling based relational triple extraction methods are attracting\ngrowing research interests due to their promising performance and their\nabilities on extracting triples from complex sentences. However, this kind of\nmethods are far from their full potential because most of them only focus on\nusing local features but ignore the global associations of relations and of\ntoken pairs, which increases the possibility of overlooking some important\ninformation during triple extraction. To overcome this deficiency, we propose a\nglobal feature-oriented triple extraction model that makes full use of the\nmentioned two kinds of global associations. Specifically, we first generate a\ntable feature for each relation. Then two kinds of global associations are\nmined from the generated table features. Next, the mined global associations\nare integrated into the table feature of each relation. This\n\"generate-mine-integrate\" process is performed multiple times so that the table\nfeature of each relation is refined step by step. Finally, each relation's\ntable is filled based on its refined table feature, and all triples linked to\nthis relation are extracted based on its filled table. We evaluate the proposed\nmodel on three benchmark datasets. Experimental results show our model is\neffective and it achieves state-of-the-art results on all of these datasets.\nThe source code of our work is available at: https://github.com/neukg/GRTE.",
    "descriptor": "\nComments: EMNLP2021\n",
    "authors": [
      "Feiliang Ren",
      "Longhui Zhang",
      "Shujuan Yin",
      "Xiaofeng Zhao",
      "Shilei Liu",
      "Bochao Li",
      "Yaduo Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06705"
  },
  {
    "id": "arXiv:2109.06706",
    "title": "A graph complexity measure based on the spectral analysis of the Laplace  operator",
    "abstract": "In this work we introduce a concept of complexity for undirected graphs in\nterms of the spectral analysis of the Laplacian operator defined by the\nincidence matrix of the graph. Precisely, we compute the norm of the vector of\neigenvalues of both the graph and its complement and take their product. Doing\nso, we obtain a quantity that satisfies two basic properties that are the\nexpected for a measure of complexity. First,complexity of fully connected and\nfully disconnected graphs vanish. Second, complexity of complementary graphs\ncoincide. This notion of complexity allows us to distinguish different kinds of\ngraphs by placing them in a \"croissant-shaped\" region of the plane link density\n- complexity, highlighting some features like connectivity,concentration,\nuniformity or regularity and existence of clique-like clusters. Indeed,\nconsidering graphs with a fixed number of nodes, by plotting the link density\nversus the complexity we find that graphs generated by different methods take\nplace at different regions of the plane. We consider some generated graphs, in\nparticular the Erd\\\"os-R\\'enyi, the Watts-Strogatz and the Barab\\'asi-Albert\nmodels. Also, we place some particular, let us say deterministic, to wit,\nlattices, stars, hyper-concentrated and cliques-containing graphs. It is worthy\nnoticing that these deterministic classical models of graphs depict the\nboundary of the croissant-shaped region. Finally, as an application to graphs\ngenerated by real measurements, we consider the brain connectivity graphs from\ntwo epileptic patients obtained from magnetoencephalography (MEG) recording,\nboth in a baseline period and in ictal periods .In this case, our definition of\ncomplexity could be used as a tool for discerning between states, by the\nanalysis of differences at distinct frequencies of the MEG recording.",
    "descriptor": "\nComments: 11 pages , 7 figures\n",
    "authors": [
      "Diego M. Mateos",
      "Federico Morana",
      "Hugo Aimar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06706"
  },
  {
    "id": "arXiv:2109.06707",
    "title": "A pragmatic approach to estimating average treatment effects from EHR  data: the effect of prone positioning on mechanically ventilated COVID-19  patients",
    "abstract": "Despite the recent progress in the field of causal inference, to date there\nis no agreed upon methodology to glean treatment effect estimation from\nobservational data. The consequence on clinical practice is that, when lacking\nresults from a randomized trial, medical personnel is left without guidance on\nwhat seems to be effective in a real-world scenario. This article showcases a\npragmatic methodology to obtain preliminary estimation of treatment effect from\nobservational studies. Our approach was tested on the estimation of treatment\neffect of the proning maneuver on oxygenation levels, on a cohort of COVID-19\nIntensive Care patients. We modeled our study design on a recent RCT for\nproning (the PROSEVA trial). Linear regression, propensity score models such as\nblocking and DR-IPW, BART and two versions of Counterfactual Regression were\nemployed to provide estimates on observational data comprising first wave\nCOVID-19 ICU patient data from 25 Dutch hospitals. 6371 data points, from 745\nmechanically ventilated patients, were included in the study. Estimates for the\nearly effect of proning -- P/F ratio from 2 to 8 hours after proning -- ranged\nbetween 14.54 and 20.11 mm Hg depending on the model. Estimates for the late\neffect of proning -- oxygenation from 12 to 24 hours after proning -- ranged\nbetween 13.53 and 15.26 mm Hg. All confidence interval being strictly above\nzero indicated that the effect of proning on oxygenation for COVID-19 patient\nwas positive and comparable in magnitude to the effect on non COVID-19\npatients. These results provide further evidence on the effectiveness of\nproning on the treatment of COVID-19 patients. This study, along with the\naccompanying open-source code, provides a blueprint for treatment effect\nestimation in scenarios where RCT data is lacking. Funding: SIDN fund,\nCovidPredict consortium, Pacmed.",
    "descriptor": "",
    "authors": [
      "Adam Izdebski",
      "Patrick J Thoral",
      "Robbert C A Lalisang",
      "Dean M McHugh",
      "Robert Entjes",
      "Nardo J M van der Meer",
      "Dave A Dongelmans",
      "Age D Boelens",
      "Sander Rigter",
      "Stefaan H A Hendriks",
      "Remko de Jong",
      "Marlijn J A Kamps",
      "Marco Peters",
      "A Karakus",
      "Diederik Gommers",
      "Dharmanand Ramnarain",
      "Evert-Jan Wils",
      "Sefanja Achterberg",
      "Ralph Nowitzky",
      "Walter van den Tempel",
      "Cornelis P C de Jager",
      "Fleur G C A Nooteboom",
      "Evelien Oostdijk",
      "Peter Koetsier",
      "Alexander D Cornet",
      "Auke C Reidinga",
      "Wouter de Ruijter",
      "Rob J Bosman",
      "Tim Frenzel",
      "Louise C Urlings-Strop",
      "Paul de Jong",
      "Ellen G M Smit",
      "Olaf L Cremer",
      "Frits H M van Osch",
      "Harald J Faber",
      "Judith Lens",
      "Gert B Brunnekreef",
      "Barbara Festen-Spanjer",
      "Tom Dormans",
      "Bram Simons",
      "A A Rijkeboer",
      "Annemieke Dijkstra",
      "Sesmu Arbous",
      "Marcel Aries",
      "Menno Beukema",
      "Rutger van Raalte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06707"
  },
  {
    "id": "arXiv:2109.06710",
    "title": "Fast Federated Edge Learning with Overlapped Communication and  Computation and Channel-Aware Fair Client Scheduling",
    "abstract": "We consider federated edge learning (FEEL) over wireless fading channels\ntaking into account the downlink and uplink channel latencies, and the random\ncomputation delays at the clients. We speed up the training process by\noverlapping the communication with computation. With fountain coded\ntransmission of the global model update, clients receive the global model\nasynchronously, and start performing local computations right away. Then, we\npropose a dynamic client scheduling policy, called MRTP, for uploading local\nmodel updates to the parameter server (PS), which, at any time, schedules the\nclient with the minimum remaining upload time. However, MRTP can lead to biased\nparticipation of clients in the update process, resulting in performance\ndegradation in non-iid data scenarios. To overcome this, we propose two\nalternative schemes with fairness considerations, termed as age-aware MRTP\n(A-MRTP), and opportunistically fair MRTP (OF-MRTP). In A-MRTP, the remaining\nclients are scheduled according to the ratio between their remaining\ntransmission time and the update age, while in OF-MRTP, the selection mechanism\nutilizes the long term average channel rate of the clients to further reduce\nthe latency while ensuring fair participation of the clients. It is shown\nthrough numerical simulations that OF-MRTP provides significant reduction in\nlatency without sacrificing test accuracy.",
    "descriptor": "\nComments: Accepted in IEEE SPAWC 2021\n",
    "authors": [
      "Mehmet Emre Ozfatura",
      "Junlin Zhao",
      "Deniz G\u00fcnd\u00fcz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06710"
  },
  {
    "id": "arXiv:2109.06711",
    "title": "COVID-Net Clinical ICU: Enhanced Prediction of ICU Admission for  COVID-19 Patients via Explainability and Trust Quantification",
    "abstract": "The COVID-19 pandemic continues to have a devastating global impact, and has\nplaced a tremendous burden on struggling healthcare systems around the world.\nGiven the limited resources, accurate patient triaging and care planning is\ncritical in the fight against COVID-19, and one crucial task within care\nplanning is determining if a patient should be admitted to a hospital's\nintensive care unit (ICU). Motivated by the need for transparent and\ntrustworthy ICU admission clinical decision support, we introduce COVID-Net\nClinical ICU, a neural network for ICU admission prediction based on patient\nclinical data. Driven by a transparent, trust-centric methodology, the proposed\nCOVID-Net Clinical ICU was built using a clinical dataset from Hospital\nSirio-Libanes comprising of 1,925 COVID-19 patients, and is able to predict\nwhen a COVID-19 positive patient would require ICU admission with an accuracy\nof 96.9% to facilitate better care planning for hospitals amidst the on-going\npandemic. We conducted system-level insight discovery using a quantitative\nexplainability strategy to study the decision-making impact of different\nclinical features and gain actionable insights for enhancing predictive\nperformance. We further leveraged a suite of trust quantification metrics to\ngain deeper insights into the trustworthiness of COVID-Net Clinical ICU. By\ndigging deeper into when and why clinical predictive models makes certain\ndecisions, we can uncover key factors in decision making for critical clinical\ndecision support tasks such as ICU admission prediction and identify the\nsituations under which clinical predictive models can be trusted for greater\naccountability.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Audrey Chung",
      "Mahmoud Famouri",
      "Andrew Hryniowski",
      "Alexander Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06711"
  },
  {
    "id": "arXiv:2109.06713",
    "title": "Machine-Learned Prediction Equilibrium for Dynamic Traffic Assignment",
    "abstract": "We study a dynamic traffic assignment model, where agents base their\ninstantaneous routing decisions on real-time delay predictions. We formulate a\nmathematically concise model and derive properties of the predictors that\nensure a dynamic prediction equilibrium exists. We demonstrate the versatility\nof our framework by showing that it subsumes the well-known full information\nand instantaneous information models, in addition to admitting further\nrealistic predictors as special cases. We complement our theoretical analysis\nby an experimental study, in which we systematically compare the induced\naverage travel times of different predictors, including a machine-learning\nmodel trained on data gained from previously computed equilibrium flows, both\non a synthetic and a real road network.",
    "descriptor": "\nComments: 26 pages including Appendix and Figures\n",
    "authors": [
      "Lukas Graf",
      "Tobias Harks",
      "Kostas Kollias",
      "Michael Markl"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.06713"
  },
  {
    "id": "arXiv:2109.06714",
    "title": "Semantic Answer Type Prediction using BERT: IAI at the ISWC SMART Task  2020",
    "abstract": "This paper summarizes our participation in the SMART Task of the ISWC 2020\nChallenge. A particular question we are interested in answering is how well\nneural methods, and specifically transformer models, such as BERT, perform on\nthe answer type prediction task compared to traditional approaches. Our main\nfinding is that coarse-grained answer types can be identified effectively with\nstandard text classification methods, with over 95% accuracy, and BERT can\nbring only marginal improvements. For fine-grained type detection, on the other\nhand, BERT clearly outperforms previous retrieval-based approaches.",
    "descriptor": "\nComments: Published in Proceedings of the SeMantic AnsweR Type prediction task (SMART) at ISWC 2020 Semantic Web Challenge co-located with the 19th International Semantic Web Conference (ISWC 2020). this http URL\n",
    "authors": [
      "Vinay Setty",
      "Krisztian Balog"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.06714"
  },
  {
    "id": "arXiv:2109.06715",
    "title": "IGNNITION: Bridging the Gap Between Graph Neural Networks and Networking  Systems",
    "abstract": "Recent years have seen the vast potential of Graph Neural Networks (GNN) in\nmany fields where data is structured as graphs (e.g., chemistry, recommender\nsystems). In particular, GNNs are becoming increasingly popular in the field of\nnetworking, as graphs are intrinsically present at many levels (e.g., topology,\nrouting). The main novelty of GNNs is their ability to generalize to other\nnetworks unseen during training, which is an essential feature for developing\npractical Machine Learning (ML) solutions for networking. However, implementing\na functional GNN prototype is currently a cumbersome task that requires strong\nskills in neural network programming. This poses an important barrier to\nnetwork engineers that often do not have the necessary ML expertise. In this\narticle, we present IGNNITION, a novel open-source framework that enables fast\nprototyping of GNNs for networking systems. IGNNITION is based on an intuitive\nhigh-level abstraction that hides the complexity behind GNNs, while still\noffering great flexibility to build custom GNN architectures. To showcase the\nversatility and performance of this framework, we implement two\nstate-of-the-art GNN models applied to different networking use cases. Our\nresults show that the GNN models produced by IGNNITION are equivalent in terms\nof accuracy and performance to their native implementations in TensorFlow.",
    "descriptor": "\nComments: Accepted for publication at IEEE Network Magazine\n",
    "authors": [
      "David Pujol-Perich",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Miquel Ferriol",
      "Shihan Xiao",
      "Bo Wu",
      "Albert Cabellos-Aparicio",
      "Pere Barlet-Ros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.06715"
  },
  {
    "id": "arXiv:2109.06716",
    "title": "HPOBench: A Collection of Reproducible Multi-Fidelity Benchmark Problems  for HPO",
    "abstract": "To achieve peak predictive performance, hyperparameter optimization (HPO) is\na crucial component of machine learning and its applications. Over the last\nyears,the number of efficient algorithms and tools for HPO grew substantially.\nAt the same time, the community is still lacking realistic, diverse,\ncomputationally cheap,and standardized benchmarks. This is especially the case\nfor multi-fidelity HPO methods. To close this gap, we propose HPOBench, which\nincludes 7 existing and 5 new benchmark families, with in total more than 100\nmulti-fidelity benchmark problems. HPOBench allows to run this extendable set\nof multi-fidelity HPO benchmarks in a reproducible way by isolating and\npackaging the individual benchmarks in containers. It also provides surrogate\nand tabular benchmarks for computationally affordable yet statistically sound\nevaluations. To demonstrate the broad compatibility of HPOBench and its\nusefulness, we conduct an exemplary large-scale study evaluating 6 well known\nmulti-fidelity HPO tools.",
    "descriptor": "",
    "authors": [
      "Katharina Eggensperger",
      "Philipp M\u00fcller",
      "Neeratyoy Mallik",
      "Matthias Feurer",
      "Ren\u00e9 Sass",
      "Aaron Klein",
      "Noor Awad",
      "Marius Lindauer",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06716"
  },
  {
    "id": "arXiv:2109.06717",
    "title": "Controllable Dialogue Generation with Disentangled Multi-grained Style  Specification and Attribute Consistency Reward",
    "abstract": "Controllable text generation is an appealing but challenging task, which\nallows users to specify particular attributes of the generated outputs. In this\npaper, we propose a controllable dialogue generation model to steer response\ngeneration under multi-attribute constraints. Specifically, we define and\ncategorize the commonly used control attributes into global and local ones,\nwhich possess different granularities of effects on response generation. Then,\nwe significantly extend the conventional seq2seq framework by introducing a\nnovel two-stage decoder, which first uses a multi-grained style specification\nlayer to impose the stylistic constraints and determine word-level control\nstates of responses based on the attributes, and then employs a response\ngeneration layer to generate final responses maintaining both semantic\nrelevancy to the contexts and fidelity to the attributes. Furthermore, we train\nour model with an attribute consistency reward to promote response control with\nexplicit supervision signals. Extensive experiments and in-depth analyses on\ntwo datasets indicate that our model can significantly outperform competitive\nbaselines in terms of response quality, content diversity and controllability.",
    "descriptor": "",
    "authors": [
      "Zhe Hu",
      "Zhiwei Cao",
      "Hou Pong Chan",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Jinsong Su",
      "Hua Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06717"
  },
  {
    "id": "arXiv:2109.06719",
    "title": "Sparse Fuzzy Attention for Structural Sentiment Analysis",
    "abstract": "Attention scorers have achieved success in parsing tasks like semantic and\nsyntactic dependency parsing. However, in tasks modeled into parsing, like\nstructural sentiment analysis, \"dependency edges\" are very sparse which hinders\nparser performance. Thus we propose a sparse and fuzzy attention scorer with\npooling layers which improves parser performance and sets the new\nstate-of-the-art on structural sentiment analysis. We further explore the\nparsing modeling on structural sentiment analysis with second-order parsing and\nintroduce a novel sparse second-order edge building procedure that leads to\nsignificant improvement in parsing performance.",
    "descriptor": "",
    "authors": [
      "Letain Peng",
      "Zuchao Li",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06719"
  },
  {
    "id": "arXiv:2109.06721",
    "title": "Linear block and convolutional MDS codes to required rate, distance and  type",
    "abstract": "Algebraic methods for the design of series of maximum distance separable\n(MDS) linear block and convolutional codes to required specifications and types\nare presented. Algorithms are given to design codes to required rate\nandrequired error-correcting capability and required types. Infinite series of\nblock codes with rate approaching a given rational $R$ with $0<R<1$ and\nrelative distance over length approaching $(1-R)$ are designed. These can be\ndesigned over fields of given characteristic $p$ or over fields of prime order\nand can of of specified typessuch as (i) dual-containing under Euclidean inner\nproduct, (ii) dual-containing under Hermitian inner product, (iii) quantum\nerror-correcting, (iv) linear complementary dual (LCD). Convolutional codes to\nrequired rate and distance are designed and infinite series of convolutional\ncodes with rate approaching a given rational $R$ and distance over length\napproaching $2(1-R)$. Properties, including distances, are shown algebraically\nand algebraic explicit efficient decoding methods are known.",
    "descriptor": "",
    "authors": [
      "Ted Hurley"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06721"
  },
  {
    "id": "arXiv:2109.06723",
    "title": "Simulations in Recommender Systems: An industry perspective",
    "abstract": "The construction of effective Recommender Systems (RS) is a complex process,\nmainly due to the nature of RSs which involves large scale software-systems and\nhuman interactions. Iterative development processes require deep understanding\nof a current baseline as well as the ability to estimate the impact of changes\nin multiple variables of interest. Simulations are well suited to address both\nchallenges and potentially leading to a high velocity construction process, a\nfundamental requirement in commercial contexts. Recently, there has been\nsignificant interest in RS Simulation Platforms, which allow RS developers to\neasily craft simulated environments where their systems can be analysed. In\nthis work we discuss how simulations help to increase velocity, we look at the\nliterature around RS Simulation Platforms, analyse strengths and gaps and\ndistill a set of guiding principles for the design of RS Simulation Platforms\nthat we believe will maximize the velocity of iterative RS construction\nprocesses.",
    "descriptor": "\nComments: G pages\n",
    "authors": [
      "Lucas Bernardi",
      "Sakshi Batra",
      "Cintia Alicia Bruscantini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06723"
  },
  {
    "id": "arXiv:2109.06726",
    "title": "Approximation of Curve-based Sleeve Functions in High Dimensions",
    "abstract": "Sleeve functions are generalizations of the well-established ridge functions\nthat play a major role in the theory of partial differential equation, medical\nimaging, statistics, and neural networks. Where ridge functions are non-linear,\nunivariate functions of the distance to hyperplanes, sleeve functions are based\non the squared distance to lower-dimensional manifolds. The present work is a\nfirst step to study general sleeve functions by starting with sleeve functions\nbased on finite-length curves. To capture these curve-based sleeve functions,\nwe propose and study a two-step method, where first the outer univariate\nfunction - the profile - is recovered, and second the underlying curve is\nrepresented by a polygonal chain. Introducing a concept of well-separation, we\nensure that the proposed method always terminates and approximate the true\nsleeve function with a certain quality. Investigating the local geometry, we\nstudy an inexact version of our method and show its success under certain\nconditions.",
    "descriptor": "",
    "authors": [
      "Robert Beinert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2109.06726"
  },
  {
    "id": "arXiv:2109.06728",
    "title": "Learning Density Distribution of Reachable States for Autonomous Systems",
    "abstract": "State density distribution, in contrast to worst-case reachability, can be\nleveraged for safety-related problems to better quantify the likelihood of the\nrisk for potentially hazardous situations. In this work, we propose a\ndata-driven method to compute the density distribution of reachable states for\nnonlinear and even black-box systems. Our semi-supervised approach learns\nsystem dynamics and the state density jointly from trajectory data, guided by\nthe fact that the state density evolution follows the Liouville partial\ndifferential equation. With the help of neural network reachability tools, our\napproach can estimate the set of all possible future states as well as their\ndensity. Moreover, we could perform online safety verification with probability\nranges for unsafe behaviors to occur. We use an extensive set of experiments to\nshow that our learned solution can produce a much more accurate estimate on\ndensity distribution, and can quantify risks less conservatively and flexibly\ncomparing with worst-case analysis.",
    "descriptor": "\nComments: Accepted at CoRL 2021\n",
    "authors": [
      "Yue Meng",
      "Dawei Sun",
      "Zeng Qiu",
      "Md Tawhid Bin Waez",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06728"
  },
  {
    "id": "arXiv:2109.06730",
    "title": "A Hierarchical Control Framework for Drift Maneuvering of Autonomous  Vehicles",
    "abstract": "Drift control is significant to the safety of autonomous vehicles when there\nis a sudden loss of traction due to external conditions such as rain or snow.\nIt is a challenging control problem due to the presence of significant sideslip\nand nearly full saturation of the tires. In this paper, we focus on the control\nof drift maneuvers following circular paths with either fixed or moving\ncenters, subject to change in the tire-ground interaction, which are common\ntraining tasks for drift enthusiasts and can therefore be used as benchmarks of\nthe performance of drift control. In order to achieve the above tasks, we\npropose a novel hierarchical control architecture which decouples the curvature\nand center control of the trajectory. In particular, an outer loop stabilizes\nthe center by tuning the target curvature, and an inner loop tracks the\ncurvature using a feedforward/feedback controller enhanced by an\n$\\mathcal{L}_1$ adaptive component. The hierarchical architecture is flexible\nbecause the inner loop is task-agnostic and adaptive to changes in tire-road\ninteraction, which allows the outer loop to be designed independent of\nlow-level dynamics, opening up the possibility of incorporating sophisticated\nplanning algorithms. We implement our control strategy on a simulation platform\nas well as on a 1/10 scale Radio-Control~(RC) car, and both the simulation and\nexperiment results illustrate the effectiveness of our strategy in achieving\nthe above described set of drift maneuvering tasks.",
    "descriptor": "",
    "authors": [
      "Bo Yang",
      "Yiwen Lu",
      "Xu Yang",
      "Yilin Mo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06730"
  },
  {
    "id": "arXiv:2109.06733",
    "title": "Controllable cross-speaker emotion transfer for end-to-end speech  synthesis",
    "abstract": "The cross-speaker emotion transfer task in TTS particularly aims to\nsynthesize speech for a target speaker with the emotion transferred from\nreference speech recorded by another (source) speaker. During the emotion\ntransfer process, the identity information of the source speaker could also\naffect the synthesized results, resulting in the issue of speaker leakage. This\npaper proposes a new method with the aim to synthesize controllable emotional\nexpressive speech and meanwhile maintain the target speaker's identity in the\ncross-speaker emotion TTS task. The proposed method is a Tacotron2-based\nframework with the emotion embedding as the conditioning variable to provide\nemotion information. Two emotion disentangling modules are contained in our\nmethod to 1) get speaker-independent and emotion-discriminative embedding, and\n2) explicitly constrain the emotion and speaker identity of synthetic speech to\nbe that as expected. Moreover, we present an intuitive method to control the\nemotional strength in the synthetic speech for the target speaker.\nSpecifically, the learned emotion embedding is adjusted with a flexible scalar\nvalue, which allows controlling the emotion strength conveyed by the embedding.\nExtensive experiments have been conducted on a Mandarin disjoint corpus, and\nthe results demonstrate that the proposed method is able to synthesize\nreasonable emotional speech for the target speaker. Compared to the\nstate-of-the-art reference embedding learned methods, our method gets the best\nperformance on the cross-speaker emotion transfer task, indicating that our\nmethod achieves the new state-of-the-art performance on learning the\nspeaker-independent emotion embedding. Furthermore, the strength ranking test\nand pitch trajectories plots demonstrate that the proposed method can\neffectively control the emotion strength, leading to prosody-diverse synthetic\nspeech.",
    "descriptor": "",
    "authors": [
      "Tao Li",
      "Xinsheng Wang",
      "Qicong Xie",
      "Zhichao Wang",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.06733"
  },
  {
    "id": "arXiv:2109.06736",
    "title": "Sequential Modelling with Applications to Music Recommendation,  Fact-Checking, and Speed Reading",
    "abstract": "Sequential modelling entails making sense of sequential data, which naturally\noccurs in a wide array of domains. One example is systems that interact with\nusers, log user actions and behaviour, and make recommendations of items of\npotential interest to users on the basis of their previous interactions. In\nsuch cases, the sequential order of user interactions is often indicative of\nwhat the user is interested in next. Similarly, for systems that automatically\ninfer the semantics of text, capturing the sequential order of words in a\nsentence is essential, as even a slight re-ordering could significantly alter\nits original meaning. This thesis makes methodological contributions and new\ninvestigations of sequential modelling for the specific application areas of\nsystems that recommend music tracks to listeners and systems that process text\nsemantics in order to automatically fact-check claims, or \"speed read\" text for\nefficient further classification. (Rest of abstract omitted due to arXiv\nabstract limit)",
    "descriptor": "\nComments: PhD Thesis, University of Copenhagen, Faculty of Science\n",
    "authors": [
      "Christian Hansen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06736"
  },
  {
    "id": "arXiv:2109.06737",
    "title": "Comparing Reconstruction- and Contrastive-based Models for Visual Task  Planning",
    "abstract": "Learning state representations enables robotic planning directly from raw\nobservations such as images. Most methods learn state representations by\nutilizing losses based on the reconstruction of the raw observations from a\nlower-dimensional latent space. The similarity between observations in the\nspace of images is often assumed and used as a proxy for estimating similarity\nbetween the underlying states of the system. However, observations commonly\ncontain task-irrelevant factors of variation which are nonetheless important\nfor reconstruction, such as varying lighting and different camera viewpoints.\nIn this work, we define relevant evaluation metrics and perform a thorough\nstudy of different loss functions for state representation learning. We show\nthat models exploiting task priors, such as Siamese networks with a simple\ncontrastive loss, outperform reconstruction-based representations in visual\ntask planning.",
    "descriptor": "\nComments: for the associated project web page, see this https URL\n",
    "authors": [
      "Constantinos Chamzas",
      "Martina Lippi",
      "Michael C. Welle",
      "Anastasia Varava",
      "Lydia E. Kavraki",
      "Danica Kragic"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06737"
  },
  {
    "id": "arXiv:2109.06740",
    "title": "Deceptive Decision-Making Under Uncertainty",
    "abstract": "We study the design of autonomous agents that are capable of deceiving\noutside observers about their intentions while carrying out tasks in\nstochastic, complex environments. By modeling the agent's behavior as a Markov\ndecision process, we consider a setting where the agent aims to reach one of\nmultiple potential goals while deceiving outside observers about its true goal.\nWe propose a novel approach to model observer predictions based on the\nprinciple of maximum entropy and to efficiently generate deceptive strategies\nvia linear programming. The proposed approach enables the agent to exhibit a\nvariety of tunable deceptive behaviors while ensuring the satisfaction of\nprobabilistic constraints on the behavior. We evaluate the performance of the\nproposed approach via comparative user studies and present a case study on the\nstreets of Manhattan, New York, using real travel time distributions.",
    "descriptor": "",
    "authors": [
      "Yagiz Savas",
      "Christos K. Verginis",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06740"
  },
  {
    "id": "arXiv:2109.06746",
    "title": "Why Existing Machine Learning Methods Fails At Extracting the  Information of Future Returns Out of Historical Sctock Prices : the  Curve-Shape-Feature and Non-Curve-Shape-Feature Modes",
    "abstract": "The financial time series analysis is important access to touch the complex\nlaws of financial markets. Among many goals of the financial time series\nanalysis, one is to construct a model that can extract the information of the\nfuture return out of the known historical stock data, such as stock price,\nfinancial news, and e.t.c. To design such a model, prior knowledge on how the\nfuture return is correlated with the historical stock prices is needed. In this\nwork, we focus on the issue: in what mode the future return is correlated with\nthe historical stock prices. We manually design several financial time series\nwhere the future return is correlated with the historical stock prices in\npre-designed modes, namely the curve-shape-feature (CSF) and the\nnon-curve-shape-feature (NCSF) modes. In the CSF mode, the future return can be\nextracted from the curve shapes of the historical stock prices. By applying\nvarious kinds of existing algorithms on those pre-designed time series and real\nfinancial time series, we show that: (1) the major information of the future\nreturn is not contained in the curve-shape features of historical stock prices.\nThat is, the future return is not mainly correlated with the historical stock\nprices in the CSF mode. (2) Various kinds of existing machine learning\nalgorithms are good at extracting the curveshape features in the historical\nstock prices and thus are inappropriate for financial time series analysis\nalthough they are successful in the image recognition and natural language\nprocessing. That is, new models handling the NCSF series are needed in the\nfinancial time series analysis.",
    "descriptor": "",
    "authors": [
      "Jia-Yao Yang",
      "Hao Zhu",
      "Yue-Jie Hou",
      "Ping Zhang",
      "Chi-Chun Zhou"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2109.06746"
  },
  {
    "id": "arXiv:2109.06747",
    "title": "Adaptive Information Seeking for Open-Domain Question Answering",
    "abstract": "Information seeking is an essential step for open-domain question answering\nto efficiently gather evidence from a large corpus. Recently, iterative\napproaches have been proven to be effective for complex questions, by\nrecursively retrieving new evidence at each step. However, almost all existing\niterative approaches use predefined strategies, either applying the same\nretrieval function multiple times or fixing the order of different retrieval\nfunctions, which cannot fulfill the diverse requirements of various questions.\nIn this paper, we propose a novel adaptive information-seeking strategy for\nopen-domain question answering, namely AISO. Specifically, the whole retrieval\nand answer process is modeled as a partially observed Markov decision process,\nwhere three types of retrieval operations (e.g., BM25, DPR, and hyperlink) and\none answer operation are defined as actions. According to the learned policy,\nAISO could adaptively select a proper retrieval action to seek the missing\nevidence at each step, based on the collected evidence and the reformulated\nquery, or directly output the answer when the evidence set is sufficient for\nthe question. Experiments on SQuAD Open and HotpotQA fullwiki, which serve as\nsingle-hop and multi-hop open-domain QA benchmarks, show that AISO outperforms\nall baseline methods with predefined strategies in terms of both retrieval and\nanswer evaluations.",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Yunchang Zhu",
      "Liang Pang",
      "Yanyan Lan",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06747"
  },
  {
    "id": "arXiv:2109.06748",
    "title": "Incentivizing Mobile Edge Caching and Sharing: An Evolutionary Game  Approach",
    "abstract": "Mobile Edge Caching is a promising technique to enhance the content delivery\nquality and reduce the backhaul link congestion, by storing popular content at\nthe network edge or mobile devices (e.g. base stations and smartphones) that\nare proximate to content requesters. In this work, we study a novel mobile edge\ncaching framework, which enables mobile devices to cache and share popular\ncontents with each other via device-to-device (D2D) links. We are interested in\nthe following incentive problem of mobile device users: whether and which users\nare willing to cache and share what contents, taking the user mobility and\ncost/reward into consideration. The problem is challenging in a large-scale\nnetwork with a large number of users. We introduce the evolutionary game\ntheory, an effective tool for analyzing large-scale dynamic systems, to analyze\nthe mobile users' content caching and sharing strategies. Specifically, we\nfirst derive the users' best caching and sharing strategies, and then analyze\nhow these best strategies change dynamically over time, based on which we\nfurther characterize the system equilibrium systematically. Simulation results\nshow that the proposed caching scheme outperforms the existing schemes in terms\nof the total transmission cost and the cellular load. In particular, in our\nsimulation, the total transmission cost can be reduced by 42.5%-55.2% and the\ncellular load can be reduced by 21.5%-56.4%.",
    "descriptor": "\nComments: This manuscript serves as the technical report for the paper published in the conference of IEEE Globecom 2021\n",
    "authors": [
      "Mingyu Li",
      "Changkun Jiang",
      "Lin Gao",
      "Tong Wang",
      "Yufei Jiang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.06748"
  },
  {
    "id": "arXiv:2109.06752",
    "title": "The complexity of sharing a pizza",
    "abstract": "Assume you have a 2-dimensional pizza with $2n$ ingredients that you want to\nshare with your friend. For this you are allowed to cut the pizza using several\nstraight cuts, and then give every second piece to your friend. You want to do\nthis fairly, that is, your friend and you should each get exactly half of each\ningredient. How many cuts do you need?\nIt was recently shown using topological methods that $n$ cuts always suffice.\nIn this work, we study the computational complexity of finding such $n$ cuts.\nOur main result is that this problem is PPA-complete when the ingredients are\nrepresented as point sets. For this, we give a new proof that for point sets\n$n$ cuts suffice, which does not use any topological methods.\nWe further prove several hardness results as well as a higher-dimensional\nvariant for the case where the ingredients are well-separated.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Patrick Schnider"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2109.06752"
  },
  {
    "id": "arXiv:2109.06762",
    "title": "Greenformer: Factorization Toolkit for Efficient Deep Neural Networks",
    "abstract": "While the recent advances in deep neural networks (DNN) bring remarkable\nsuccess, the computational cost also increases considerably. In this paper, we\nintroduce Greenformer, a toolkit to accelerate the computation of neural\nnetworks through matrix factorization while maintaining performance.\nGreenformer can be easily applied with a single line of code to any DNN model.\nOur experimental results show that Greenformer is effective for a wide range of\nscenarios. We provide the showcase of Greenformer at\nhttps://samuelcahyawijaya.github.io/greenformer-demo/.",
    "descriptor": "",
    "authors": [
      "Samuel Cahyawijaya",
      "Genta Indra Winata",
      "Holy Lovenia",
      "Bryan Wilie",
      "Wenliang Dai",
      "Etsuko Ishii",
      "Pascale Fung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06762"
  },
  {
    "id": "arXiv:2109.06765",
    "title": "Identification of linear time-invariant systems with Dynamic Mode  Decomposition",
    "abstract": "Dynamic mode decomposition (DMD) is a popular data-driven framework to\nextract linear dynamics from complex high-dimensional systems. In this work, we\nstudy the system identification properties of DMD. We first show that DMD is\ninvariant under linear transformations in the image of the data matrix. If, in\naddition, the data is constructed from a linear time-invariant system, then we\nprove that DMD can recover the original dynamics under mild conditions. If the\nlinear dynamics are discretized with a Runge-Kutta method, then we further\nclassify the error of the DMD approximation and detail that for one-stage\nRunge-Kutta methods even the continuous dynamics can be recovered with DMD. A\nnumerical example illustrates the theoretical findings.",
    "descriptor": "",
    "authors": [
      "Jan Heiland",
      "Benjamin Unger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06765"
  },
  {
    "id": "arXiv:2109.06768",
    "title": "MotionHint: Self-Supervised Monocular Visual Odometrywith Motion  Constraints",
    "abstract": "We present a novel self-supervised algorithmnamedMotionHintfor monocular\nvisual odometry (VO) that takes motion constraints into account. A key aspect\nof ourapproach is to use an appropriate motion model that can help existing\nself-supervised monocular VO (SSM-VO) algorithms to overcome issues related to\nthe local minima within their self-supervised loss functions. The motion model\nis expressed with a neural network named PPnet. It is trained to coarsely\npredict the next pose of the camera and the uncertainty of this prediction. Our\nself-supervised approach combines the original loss and the motion loss, which\nis the weighted difference between the prediction and the generated ego-motion.\nTaking two existing SSM-VO systems as our baseline, we evaluate our MotionHint\nalgorithm on the standard KITTI and EuRoC benchmark. Experimental results show\nthat our MotionHint algorithm can be easily applied to existing open-source\nstate-of-the-art SSM-VO systems to greatly improve the performance on KITTI\ndataset by reducing the resulting ATE by up to 28.73%. For EuRoc dataset, our\nmethod can extract the motion model.But due to the poor performance of the\nbaseline methods, MotionHint cannot significantly improve their results.",
    "descriptor": "",
    "authors": [
      "Cong Wang",
      "Yu-Ping Wang",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06768"
  },
  {
    "id": "arXiv:2109.06772",
    "title": "Improving Zero-shot Cross-lingual Transfer between Closely Related  Languages by injecting Character-level Noise",
    "abstract": "Cross-lingual transfer between a high-resource language and its dialects or\nclosely related language varieties should be facilitated by their similarity,\nbut current approaches that operate in the embedding space do not take surface\nsimilarity into account. In this work, we present a simple yet effective\nstrategy to improve cross-lingual transfer between closely related varieties by\naugmenting the data of the high-resource parent language with character-level\nnoise to make the model more robust towards spelling variations. Our strategy\nshows consistent improvements over several languages and tasks: Zero-shot\ntransfer of POS tagging and topic identification between language varieties\nfrom the Germanic, Uralic, and Romance language genera. Our work provides\nevidence for the usefulness of simple surface-level noise in improving transfer\nbetween language varieties.",
    "descriptor": "\nComments: dialects, language varieties\n",
    "authors": [
      "No\u00ebmi Aepli",
      "Rico Sennrich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06772"
  },
  {
    "id": "arXiv:2109.06773",
    "title": "Obstacle Avoidance for Autonomous Mobile Robots Based on Mapping Method",
    "abstract": "In recent years, the mobile robot has been considerable attention to\nresearchers for its application in various environments. For a mobile robot\nnavigating its way from starting point to a goal point while traversing through\ndeterrents, needs to recognize the obstacles and generate new trajectories to\nreach the destination. This paper presents an obstacle avoidance method for\nmobile robots using an open-source in robot operation system (ROS) combining\nwith the dynamic window approach (DWA) algorithm. The experiment is carried out\nusing a mobile robot in which the navigation data is based on data collecting\nby a laser scanner. The experimental results show that the robot could work\nwell in environments containing static and dynamic obstacles.",
    "descriptor": "",
    "authors": [
      "Anh-Tu Nguyen",
      "Cong-Thanh Vu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06773"
  },
  {
    "id": "arXiv:2109.06776",
    "title": "Automatic Reuse, Adaption, and Execution of Simulation Experiments via  Provenance Patterns",
    "abstract": "Simulation experiments are typically conducted repeatedly during the model\ndevelopment process, for example, to re-validate if a behavioral property still\nholds after several model changes. Approaches for automatically reusing and\ngenerating simulation experiments can support modelers in conducting simulation\nstudies in a more systematic and effective manner. They rely on explicit\nexperiment specifications and, so far, on user interaction for initiating the\nreuse. Thereby, they are constrained to support the reuse of simulation\nexperiments in a specific setting. Our approach now goes one step further by\nautomatically identifying and adapting the experiments to be reused for a\nvariety of scenarios. To achieve this, we exploit provenance graphs of\nsimulation studies, which provide valuable information about the previous\nmodeling and experimenting activities, and contain meta-information about the\ndifferent entities that were used or produced during the simulation study. We\ndefine provenance patterns and associate them with a semantics, which allows us\nto interpret the different activities, and construct transformation rules for\nprovenance graphs. Our approach is implemented in a Reuse and Adapt framework\nfor Simulation Experiments (RASE) which can interface with various modeling and\nsimulation tools. In the case studies, we demonstrate the utility of our\nframework for a) the repeated sensitivity analysis of an agent-based model of\nmigration routes, and b) the cross-validation of two models of a cell signaling\npathway.",
    "descriptor": "",
    "authors": [
      "Pia Wilsdorf",
      "Anja Wolpers",
      "Jason Hilton",
      "Fiete Haack",
      "Adelinde M. Uhrmacher"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2109.06776"
  },
  {
    "id": "arXiv:2109.06777",
    "title": "PETGEN: Personalized Text Generation Attack on Deep Sequence  Embedding-based Classification Models",
    "abstract": "\\textit{What should a malicious user write next to fool a detection model?}\nIdentifying malicious users is critical to ensure the safety and integrity of\ninternet platforms. Several deep learning based detection models have been\ncreated. However, malicious users can evade deep detection models by\nmanipulating their behavior, rendering these models of little use. The\nvulnerability of such deep detection models against adversarial attacks is\nunknown. Here we create a novel adversarial attack model against deep user\nsequence embedding-based classification models, which use the sequence of user\nposts to generate user embeddings and detect malicious users. In the attack,\nthe adversary generates a new post to fool the classifier. We propose a novel\nend-to-end Personalized Text Generation Attack model, called \\texttt{PETGEN},\nthat simultaneously reduces the efficacy of the detection model and generates\nposts that have several key desirable properties. Specifically, \\texttt{PETGEN}\ngenerates posts that are personalized to the user's writing style, have\nknowledge about a given target context, are aware of the user's historical\nposts on the target context, and encapsulate the user's recent topical\ninterests. We conduct extensive experiments on two real-world datasets (Yelp\nand Wikipedia, both with ground-truth of malicious users) to show that\n\\texttt{PETGEN} significantly reduces the performance of popular deep user\nsequence embedding-based classification models. \\texttt{PETGEN} outperforms\nfive attack baselines in terms of text quality and attack efficacy in both\nwhite-box and black-box classifier settings. Overall, this work paves the path\ntowards the next generation of adversary-aware sequence classification models.",
    "descriptor": "\nComments: Accepted for publication at: 2021 ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD'2021). Code and data at: this https URL\n",
    "authors": [
      "Bing He",
      "Mustaque Ahamad",
      "Srijan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.06777"
  },
  {
    "id": "arXiv:2109.06780",
    "title": "Benchmarking the Spectrum of Agent Capabilities",
    "abstract": "Evaluating the general abilities of intelligent agents requires complex\nsimulation environments. Existing benchmarks typically evaluate only one narrow\ntask per environment, requiring researchers to perform expensive training runs\non many different environments. We introduce Crafter, an open world survival\ngame with visual inputs that evaluates a wide range of general abilities within\na single environment. Agents either learn from the provided reward signal or\nthrough intrinsic objectives and are evaluated by semantically meaningful\nachievements that can be unlocked during each episode, such as discovering\nresources and crafting tools. Consistently unlocking all achievements requires\nstrong generalization, deep exploration, and long-term reasoning. We\nexperimentally verify that Crafter is of appropriate difficulty to drive future\nresearch and provide baselines scores of reward agents and unsupervised agents.\nFurthermore, we observe sophisticated behaviors emerging from maximizing the\nreward signal, such as building tunnel systems, bridges, houses, and\nplantations. We hope that Crafter will accelerate research progress by quickly\nevaluating a wide spectrum of abilities.",
    "descriptor": "\nComments: Website: this https URL\n",
    "authors": [
      "Danijar Hafner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06780"
  },
  {
    "id": "arXiv:2109.06783",
    "title": "Learning to Navigate Intersections with Unsupervised Driver Trait  Inference",
    "abstract": "Navigation through uncontrolled intersections is one of the key challenges\nfor autonomous vehicles. Identifying the subtle differences in hidden traits of\nother drivers can bring significant benefits when navigating in such\nenvironments. We propose an unsupervised method for inferring driver traits\nsuch as driving styles from observed vehicle trajectories. We use a variational\nautoencoder with recurrent neural networks to learn a latent representation of\ntraits without any ground truth trait labels. Then, we use this trait\nrepresentation to learn a policy for an autonomous vehicle to navigate through\na T-intersection with deep reinforcement learning. Our pipeline enables the\nautonomous vehicle to adjust its actions when dealing with drivers of different\ntraits to ensure safety and efficiency. Our method demonstrates promising\nperformance and outperforms state-of-the-art baselines in the T-intersection\nscenario.",
    "descriptor": "",
    "authors": [
      "Shuijing Liu",
      "Peixin Chang",
      "Haonan Chen",
      "Neeloy Chakraborty",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06783"
  },
  {
    "id": "arXiv:2109.06786",
    "title": "Multiple shooting with neural differential equations",
    "abstract": "Neural differential equations have recently emerged as a flexible\ndata-driven/hybrid approach to model time-series data. This work experimentally\ndemonstrates that if the data contains oscillations, then standard fitting of a\nneural differential equation may give flattened out trajectory that fails to\ndescribe the data. We then introduce the multiple shooting method and present\nsuccessful demonstrations of this method for the fitting of a neural\ndifferential equation to two datasets (synthetic and experimental) that the\nstandard approach fails to fit. Constraints introduced by multiple shooting can\nbe satisfied using a penalty or augmented Lagrangian method.",
    "descriptor": "",
    "authors": [
      "Evren Mert Turan",
      "Johannes J\u00e4schke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06786"
  },
  {
    "id": "arXiv:2109.06788",
    "title": "Computing Balanced Solutions for Large International Kidney Exchange  Schemes",
    "abstract": "To overcome incompatibility issues, kidney patients may swap their donors. In\ninternational kidney exchange programmes (IKEPs), countries merge their\nnational patient-donor pools. We consider a recent credit system where in each\nround, countries are given an initial kidney transplant allocation which is\nadjusted by a credit function yielding a target allocation. The goal is to find\na solution in the patient-donor compatibility graph that approaches the target\nallocation as closely as possible, to ensure long-term stability of the\ninternational pool. As solutions, we use maximum matchings that\nlexicographically minimize the country deviations from the target allocation.\nWe first give a polynomial-time algorithm for computing such matchings. We then\nperform, for the first time, a computational study for a large number of\ncountries. For the initial allocations we use, besides two easy-to-compute\nsolution concepts, two classical concepts: the Shapley value and nucleolus.\nThese are hard to compute, but by using state-of-the-art software we show that\nthey are now within reach for IKEPs of up to fifteen countries. Our experiments\nshow that using lexicographically minimal maximum matchings instead of ones\nthat only minimize the largest deviation from the target allocation (as\npreviously done) may make an IKEP up to 52% more balanced.",
    "descriptor": "",
    "authors": [
      "M\u00e1rton Benedek",
      "P\u00e9ter Bir\u00f3",
      "Walter Kern",
      "Dani\u00ebl Paulusma"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06788"
  },
  {
    "id": "arXiv:2109.06789",
    "title": "Recovery of a Space-Time Dependent Diffusion Coefficient in  Subdiffusion: Stability, Approximation and Error Analysis",
    "abstract": "In this work, we study an inverse problem of recovering a space-time\ndependent diffusion coefficient in the subdiffusion model from the distributed\nobservation, where the mathematical model involves a Djrbashian-Caputo\nfractional derivative of order $\\alpha\\in(0,1)$ in time. The main technical\nchallenges of both theoretical and numerical analysis lie in the limited\nsmoothing properties due to the fractional differential operator and the high\ndegree of nonlinearity of the forward map from the unknown diffusion\ncoefficient to the distributed observation. Theoretically, we establish two\nconditional stability results using a novel test function, which leads to a\nstability bound in $L^2(0,T;L^2(\\Omega))$ under a suitable positivity\ncondition. The positivity condition is verified for a large class of problem\ndata. Numerically, we develop a rigorous procedure for the recovery of the\ndiffusion coefficient based on a regularized least-squares formulation, which\nis then discretized by the standard Galerkin method with continuous piecewise\nlinear elements in space and backward Euler convolution quadrature in time. We\nprovide a complete error analysis of the fully discrete formulation, by\ncombining several new error estimates for the direct problem (optimal in terms\nof data regularity), a discrete version of fractional maximal $L^p$ regularity,\nand a nonstandard energy argument. Under the positivity condition, we obtain a\nstandard $L^2(0,T; L^2(\\Omega))$ error estimate consistent with the conditional\nstability. Further, we illustrate the analysis with some numerical examples.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Bangti Jin",
      "Zhi Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.06789"
  },
  {
    "id": "arXiv:2109.06790",
    "title": "A Deep Learning Approach for Masking Fetal Gender in Ultrasound Images",
    "abstract": "Ultrasound (US) imaging is highly effective with regards to both cost and\nversatility in real-time diagnosis; however, determination of fetal gender by\nUS scan in the early stages of pregnancy is also a cause of sex-selective\nabortion. This work proposes a deep learning object detection approach to\naccurately mask fetal gender in US images in order to increase the\naccessibility of the technology. We demonstrate how the YOLOv5L architecture\nexhibits superior performance relative to other object detection models on this\ntask. Our model achieves 45.8% AP[0.5:0.95], 92% F1-score and 0.006 False\nPositive Per Image rate on our test set. Furthermore, we introduce a bounding\nbox delay rule based on frame-to-frame structural similarity to reduce the\nfalse negative rate by 85%, further improving masking reliability.",
    "descriptor": "",
    "authors": [
      "Amit Borundiya",
      "Arshak Navruzyan",
      "Dennis Igoschev",
      "Feras C. Oughali",
      "Hemanth Pasupuleti",
      "Mike Fuller",
      "Vinay Kanigicherla",
      "T S Aniruddha Kashyap",
      "Rishabh Chaurasia",
      "Sonali Vinod Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06790"
  },
  {
    "id": "arXiv:2109.06795",
    "title": "ROMAX: Certifiably Robust Deep Multiagent Reinforcement Learning via  Convex Relaxation",
    "abstract": "In a multirobot system, a number of cyber-physical attacks (e.g.,\ncommunication hijack, observation perturbations) can challenge the robustness\nof agents. This robustness issue worsens in multiagent reinforcement learning\nbecause there exists the non-stationarity of the environment caused by\nsimultaneously learning agents whose changing policies affect the transition\nand reward functions. In this paper, we propose a minimax MARL approach to\ninfer the worst-case policy update of other agents. As the minimax formulation\nis computationally intractable to solve, we apply the convex relaxation of\nneural networks to solve the inner minimization problem. Such convex relaxation\nenables robustness in interacting with peer agents that may have significantly\ndifferent behaviors and also achieves a certified bound of the original\noptimization problem. We evaluate our approach on multiple mixed\ncooperative-competitive tasks and show that our method outperforms the previous\nstate of the art approaches on this topic.",
    "descriptor": "",
    "authors": [
      "Chuangchuang Sun",
      "Dong-Ki Kim",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06795"
  },
  {
    "id": "arXiv:2109.06796",
    "title": "A comprehensive secure protocol for all D2D scenarios",
    "abstract": "To fulfill two integral aims of abating cellular traffic and enhancing\nefficiency of cellular network, D2D is considered as a novel channel of\ncommunication. This form of communication has introduced for 4th cellular\ncommunication and enacts a significant role in the 5th generation. Four D2D\ncommunication scenarios defined in the references, includes direct D2D and\nrelaying D2D communication both with and without cellular infrastructure. One\nof the major challenges addressing D2D protocols contributes to the fact that\nthey have one single secure protocol that can adapt to the four scenarios. In\nthe current study, we propose a secure D2D protocol based on ARIADNE. To\nauthenticate and key agreement between Source and Destination, we employ LTE-A\nAKA protocol, further for broadcast authentication between relaying nodes TESLA\nwas applied. In Contrary to the recent protocols, our proposed protocol has\ninconsiderable computation overhead and trivial communication overhead than\nSODE and preserve many security properties such as Authentication,\nAuthorization, Confidentiality, Integrity, Secure Key Agreement, and Secure\nRouting Transmission. We check Authentication, Confidentiality, Reachability,\nand Secure Key Agreement of the proposed protocol with ProVerif verification\ntools.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Hoda Nematy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06796"
  },
  {
    "id": "arXiv:2109.06798",
    "title": "Everything Is All It Takes: A Multipronged Strategy for Zero-Shot  Cross-Lingual Information Extraction",
    "abstract": "Zero-shot cross-lingual information extraction (IE) describes the\nconstruction of an IE model for some target language, given existing\nannotations exclusively in some other language, typically English. While the\nadvance of pretrained multilingual encoders suggests an easy optimism of \"train\non English, run on any language\", we find through a thorough exploration and\nextension of techniques that a combination of approaches, both new and old,\nleads to better performance than any one cross-lingual strategy in particular.\nWe explore techniques including data projection and self-training, and how\ndifferent pretrained encoders impact them. We use English-to-Arabic IE as our\ninitial example, demonstrating strong performance in this setting for event\nextraction, named entity recognition, part-of-speech tagging, and dependency\nparsing. We then apply data projection and self-training to three tasks across\neight target languages. Because no single set of techniques performs the best\nacross all tasks, we encourage practitioners to explore various configurations\nof the techniques described in this work when seeking to improve on zero-shot\ntraining.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Mahsa Yarmohammadi",
      "Shijie Wu",
      "Marc Marone",
      "Haoran Xu",
      "Seth Ebner",
      "Guanghui Qin",
      "Yunmo Chen",
      "Jialiang Guo",
      "Craig Harman",
      "Kenton Murray",
      "Aaron Steven White",
      "Mark Dredze",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06798"
  },
  {
    "id": "arXiv:2109.06800",
    "title": "Rethinking Trust in Social Robotics",
    "abstract": "In 2018 the European Commission highlighted the demand of a human-centered\napproach to AI. Such a claim is gaining even more relevance considering\ntechnologies specifically designed to directly interact and physically\ncollaborate with human users in the real world. This is notably the case of\nsocial robots. The domain of Human-Robot Interaction (HRI) emerged to\ninvestigate these issues. \"Human-robot trust\" has been highlighted as one of\nthe most challenging and intriguing factors influencing HRI. On the one hand,\nuser studies and technical experts underline how trust is a key element to\nfacilitate users' acceptance, consequently increasing the chances to pursue the\ngiven task. On the other hand, such a phenomenon raises also ethical and\nphilosophical concerns leading scholars in these domains to argue that humans\nshould not trust robots. However, trust in HRI is not an index of fragility, it\nis rooted in anthropomorphism, and it is a natural characteristic of every\nhuman being. Thus, instead of focusing solely on how to inspire user trust in\nsocial robots, this paper argues that what should be investigated is to what\nextent and for which purpose it is suitable to trust robots. Such an endeavour\nrequires an interdisciplinary approach taking into account (i) technical needs\nand (ii) psychological implications.",
    "descriptor": "\nComments: In proceedings of SCRITA 2021 (arXiv:2108.08092), a workshop at IEEE RO-MAN 2021: this https URL\n",
    "authors": [
      "Rachele Carli",
      "Amro Najjar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06800"
  },
  {
    "id": "arXiv:2109.06804",
    "title": "Coverability, Termination, and Finiteness in Recursive Petri Nets",
    "abstract": "In the early two-thousands, Recursive Petri nets have been introduced in\norder to model distributed planning of multi-agent systems for which counters\nand recursivity were necessary. Although Recursive Petri nets strictly extend\nPetri nets and context-free grammars, most of the usual problems (reachability,\ncoverability, finiteness, boundedness and termination) were known to be\nsolvable by using non-primitive recursive algorithms. For almost all other\nextended Petri nets models containing a stack, the complexity of coverability\nand termination are unknown or strictly larger than EXPSPACE. In contrast, we\nestablish here that for Recursive Petri nets, the coverability, termination,\nboundedness and finiteness problems are EXPSPACE-complete as for Petri nets.\nFrom an expressiveness point of view, we show that coverability languages of\nRecursive Petri nets strictly include the union of coverability languages of\nPetri nets and context-free languages. Thus we get a more powerful model than\nPetri net for free.",
    "descriptor": "",
    "authors": [
      "Alain Finkel",
      "Serge Haddad",
      "Igor Khmelnitsky"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2109.06804"
  },
  {
    "id": "arXiv:2109.06807",
    "title": "A Temporal Variational Model for Story Generation",
    "abstract": "Recent language models can generate interesting and grammatically correct\ntext in story generation but often lack plot development and long-term\ncoherence. This paper experiments with a latent vector planning approach based\non a TD-VAE (Temporal Difference Variational Autoencoder), using the model for\nconditioning and reranking for text generation. The results demonstrate strong\nperformance in automatic cloze and swapping evaluations. The human judgments\nshow stories generated with TD-VAE reranking improve on a GPT-2 medium baseline\nand show comparable performance to a hierarchical LSTM reranking model.\nConditioning on the latent vectors proves disappointing and deteriorates\nperformance in human evaluation because it reduces the diversity of generation,\nand the models don't learn to progress the narrative. This highlights an\nimportant difference between technical task performance (e.g. cloze) and\ngenerating interesting stories.",
    "descriptor": "\nComments: 9 pages, 19 with references and appendices, 6 figures, and 4 tables\n",
    "authors": [
      "David Wilmot",
      "Frank Keller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06807"
  },
  {
    "id": "arXiv:2109.06808",
    "title": "What are the attackers doing now? Automating cyber threat intelligence  extraction from text on pace with the changing threat landscape: A survey",
    "abstract": "Cybersecurity researchers have contributed to the automated extraction of CTI\nfrom textual sources, such as threat reports and online articles, where\ncyberattack strategies, procedures, and tools are described. The goal of this\narticle is to aid cybersecurity researchers understand the current techniques\nused for cyberthreat intelligence extraction from text through a survey of\nrelevant studies in the literature. We systematically collect \"CTI extraction\nfrom text\"-related studies from the literature and categorize the CTI\nextraction purposes. We propose a CTI extraction pipeline abstracted from these\nstudies. We identify the data sources, techniques, and CTI sharing formats\nutilized in the context of the proposed pipeline. Our work finds ten types of\nextraction purposes, such as extraction indicators of compromise extraction,\nTTPs (tactics, techniques, procedures of attack), and cybersecurity keywords.\nWe also identify seven types of textual sources for CTI extraction, and textual\ndata obtained from hacker forums, threat reports, social media posts, and\nonline news articles have been used by almost 90% of the studies. Natural\nlanguage processing along with both supervised and unsupervised machine\nlearning techniques such as named entity recognition, topic modelling,\ndependency parsing, supervised classification, and clustering are used for CTI\nextraction. We observe the technical challenges associated with these studies\nrelated to obtaining available clean, labelled data which could assure\nreplication, validation, and further extension of the studies. As we find the\nstudies focusing on CTI information extraction from text, we advocate for\nbuilding upon the current CTI extraction work to help cybersecurity\npractitioners with proactive decision making such as threat prioritization,\nautomated threat modelling to utilize knowledge from past cybersecurity\nincidents.",
    "descriptor": "",
    "authors": [
      "Md Rayhanur Rahman",
      "Rezvan Mahdavi-Hezaveh",
      "Laurie Williams"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06808"
  },
  {
    "id": "arXiv:2109.06810",
    "title": "Design and Model Predictive Control of Mars Coaxial Quadrotor",
    "abstract": "Mars has been a prime candidate for planetary exploration of the solar system\nbecause of the science discoveries that support chances of future habitation on\nthis planet. Martian caves and lava tubes like terrains, which consists of\nuneven ground, poor visibility and confined space, makes it impossible for\nwheel based rovers to navigate through these areas. In order to address these\nlimitations and advance the exploration capability in a Martian terrain, this\narticle presents the design and control of a novel coaxial quadrotor Micro\nAerial Vehicle (MAV). As it will be presented, the key contributions on the\ndesign and control architecture of the proposed Mars coaxial quadrotor, are\nintroducing an alternative and more enhanced, from a control point of view\nconcept, when compared in terms of autonomy to Ingenuity. Based on the\npresented design, the article will introduce the mathematical modelling and\nautomatic control framework of the vehicle that will consist of a linearised\nmodel of a co-axial quadrotor and a corresponding Model Predictive Controller\n(MPC) for the trajectory tracking. Among the many models, proposed for the\naerial flight on Mars, a reliable control architecture lacks in the related\nstate of the art. The MPC based closed loop responses of the proposed MAV will\nbe verified in different conditions during the flight with additional\ndisturbances, induced to replicate a real flight scenario. In order to further\nvalidate the proposed control architecture and prove the efficacy of the\nsuggested design, the introduced Mars coaxial quadrotor and the MPC scheme will\nbe compared to a PID-type controller, similar to the Ingenuity helicopter's\ncontrol architecture for the position and the heading.",
    "descriptor": "",
    "authors": [
      "Akash Patel",
      "Avijit Banerjee",
      "Bjorn Lindqvist",
      "Christoforos Kanellakis",
      "George Nikolakopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06810"
  },
  {
    "id": "arXiv:2109.06811",
    "title": "Egalitarian Byzantine Fault Tolerance",
    "abstract": "Minimizing end-to-end latency in geo-replicated systems usually makes it\nnecessary to compromise on resilience, resource efficiency, or throughput\nperformance, because existing approaches either tolerate only crashes, require\nadditional replicas, or rely on a global leader for consensus. In this paper,\nwe eliminate the need for such tradeoffs by presenting Isos, a leaderless\nreplication protocol that tolerates up to $f$ Byzantine faults with a minimum\nof $3f+1$ replicas. To reduce latency in wide-area environments, Isos relies on\nan efficient consensus algorithm that allows all participating replicas to\npropose new requests and thereby enables clients to avoid delays by submitting\nrequests to their nearest replica. In addition, Isos minimizes overhead by\nlimiting message ordering to requests that conflict with each other (e.g., due\nto accessing the same state parts) and by already committing them after three\ncommunication steps if at least $f+1$ replicas report each conflict. Our\nexperimental evaluation with a geo-replicated key-value store shows that these\nproperties allow Isos to provide lower end-to-end latency than existing\nprotocols, especially for use-case scenarios in which the clients of a system\nare distributed across multiple locations.",
    "descriptor": "\nComments: 22 pages, extended version of PRDC 2021 paper\n",
    "authors": [
      "Michael Eischer",
      "Tobias Distler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.06811"
  },
  {
    "id": "arXiv:2109.06815",
    "title": "Predicting Loss Risks for B2B Tendering Processes",
    "abstract": "Sellers and executives who maintain a bidding pipeline of sales engagements\nwith multiple clients for many opportunities significantly benefit from\ndata-driven insight into the health of each of their bids. There are many\npredictive models that offer likelihood insights and win prediction modeling\nfor these opportunities. Currently, these win prediction models are in the form\nof binary classification and only make a prediction for the likelihood of a win\nor loss. The binary formulation is unable to offer any insight as to why a\nparticular deal might be predicted as a loss. This paper offers a multi-class\nclassification model to predict win probability, with the three loss classes\noffering specific reasons as to why a loss is predicted, including no bid,\ncustomer did not pursue, and lost to competition. These classes offer an\nindicator of how that opportunity might be handled given the nature of the\nprediction. Besides offering baseline results on the multi-class\nclassification, this paper also offers results on the model after class\nimbalance handling, with the results achieving a high accuracy of 85% and an\naverage AUC score of 0.94.",
    "descriptor": "",
    "authors": [
      "Eelaaf Zahid",
      "Yuya Jeremy Ong",
      "Aly Megahed",
      "Taiga Nakamura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06815"
  },
  {
    "id": "arXiv:2109.06817",
    "title": "Automatic hippocampal surface generation via 3D U-net and active shape  modeling with hybrid particle swarm optimization",
    "abstract": "In this paper, we proposed and validated a fully automatic pipeline for\nhippocampal surface generation via 3D U-net coupled with active shape modeling\n(ASM). Principally, the proposed pipeline consisted of three steps. In the\nbeginning, for each magnetic resonance image, a 3D U-net was employed to obtain\nthe automatic hippocampus segmentation at each hemisphere. Secondly, ASM was\nperformed on a group of pre-obtained template surfaces to generate mean shape\nand shape variation parameters through principal component analysis.\nUltimately, hybrid particle swarm optimization was utilized to search for the\noptimal shape variation parameters that best match the segmentation. The\nhippocampal surface was then generated from the mean shape and the shape\nvariation parameters. The proposed pipeline was observed to provide hippocampal\nsurfaces at both hemispheres with high accuracy, correct anatomical topology,\nand sufficient smoothness.",
    "descriptor": "",
    "authors": [
      "Pinyuan Zhong",
      "Yue Zhang",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06817"
  },
  {
    "id": "arXiv:2109.06822",
    "title": "LM-Critic: Language Models for Unsupervised Grammatical Error Correction",
    "abstract": "Training a model for grammatical error correction (GEC) requires a set of\nlabeled ungrammatical / grammatical sentence pairs, but manually annotating\nsuch pairs can be expensive. Recently, the Break-It-Fix-It (BIFI) framework has\ndemonstrated strong results on learning to repair a broken program without any\nlabeled examples, but this relies on a perfect critic (e.g., a compiler) that\nreturns whether an example is valid or not, which does not exist for the GEC\ntask. In this work, we show how to leverage a pretrained language model (LM) in\ndefining an LM-Critic, which judges a sentence to be grammatical if the LM\nassigns it a higher probability than its local perturbations. We apply this\nLM-Critic and BIFI along with a large set of unlabeled sentences to bootstrap\nrealistic ungrammatical / grammatical pairs for training a corrector. We\nevaluate our approach on GEC datasets across multiple domains (CoNLL-2014,\nBEA-2019, GMEG-wiki and GMEG-yahoo) and show that it outperforms existing\nmethods in both the unsupervised setting (+7.7 F0.5) and the supervised setting\n(+0.5 F0.5).",
    "descriptor": "\nComments: EMNLP 2021. Code & data available at this https URL\n",
    "authors": [
      "Michihiro Yasunaga",
      "Jure Leskovec",
      "Percy Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06822"
  },
  {
    "id": "arXiv:2109.06826",
    "title": "Few-shot Quality-Diversity Optimisation",
    "abstract": "In the past few years, a considerable amount of research has been dedicated\nto the exploitation of previous learning experiences and the design of Few-shot\nand Meta Learning approaches, in problem domains ranging from Computer Vision\nto Reinforcement Learning based control. A notable exception, where to the best\nof our knowledge, little to no effort has been made in this direction is\nQuality-Diversity (QD) optimisation. QD methods have been shown to be effective\ntools in dealing with deceptive minima and sparse rewards in Reinforcement\nLearning. However, they remain costly due to their reliance on inherently\nsample inefficient evolutionary processes. We show that, given examples from a\ntask distribution, information about the paths taken by optimisation in\nparameter space can be leveraged to build a prior population, which when used\nto initialise QD methods in unseen environments, allows for few-shot\nadaptation. Our proposed method does not require backpropagation. It is simple\nto implement and scale, and furthermore, it is agnostic to the underlying\nmodels that are being trained. Experiments carried in both sparse and dense\nreward settings using robotic manipulation and navigation benchmarks show that\nit considerably reduces the number of generations that are required for QD\noptimisation in these environments.",
    "descriptor": "\nComments: 8 pages, 3 figures, 2 tables\n",
    "authors": [
      "Achkan Salehi",
      "Alexandre Coninx",
      "Stephane Doncieux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.06826"
  },
  {
    "id": "arXiv:2109.06827",
    "title": "Types of Out-of-Distribution Texts and How to Detect Them",
    "abstract": "Despite agreement on the importance of detecting out-of-distribution (OOD)\nexamples, there is little consensus on the formal definition of OOD examples\nand how to best detect them. We categorize these examples by whether they\nexhibit a background shift or a semantic shift, and find that the two major\napproaches to OOD detection, model calibration and density estimation (language\nmodeling for text), have distinct behavior on these types of OOD data. Across\n14 pairs of in-distribution and OOD English natural language understanding\ndatasets, we find that density estimation methods consistently beat calibration\nmethods in background shift settings, while performing worse in semantic shift\nsettings. In addition, we find that both methods generally fail to detect\nexamples from challenge data, highlighting a weak spot for current methods.\nSince no single method works well across all settings, our results call for an\nexplicit definition of OOD examples when evaluating different detection\nmethods.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Udit Arora",
      "William Huang",
      "He He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06827"
  },
  {
    "id": "arXiv:2109.06828",
    "title": "A Multi-scale Visual Analytics Approach for Exploring Biomedical  Knowledge",
    "abstract": "This paper describes an ongoing multi-scale visual analytics approach for\nexploring and analyzing biomedical knowledge at scale.We utilize global and\nlocal views, hierarchical and flow-based graph layouts, multi-faceted search,\nneighborhood recommendations, and document visualizations to help researchers\ninteractively explore, query, and analyze biological graphs against the\nbackdrop of biomedical knowledge. The generality of our approach - insofar as\nit re-quires only knowledge graphs linked to documents - means it can support a\nrange of therapeutic use cases across different domains, from disease\npropagation to drug discovery. Early interactions with domain experts support\nour approach for use cases with graphs with over 40,000 nodes and 350,000\nedges.",
    "descriptor": "",
    "authors": [
      "Fahd Husain",
      "Rosa Romero-Gomez",
      "Emily Kuang",
      "Dario Segura",
      "Adamo Carolli",
      "Lai Chung Liu",
      "Manfred Cheung",
      "Yohann Paris"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.06828"
  },
  {
    "id": "arXiv:2109.06831",
    "title": "GALOPP: Multi-Agent Deep Reinforcement Learning For Persistent  Monitoring With Localization Constraints",
    "abstract": "Persistently monitoring a region under localization and communication\nconstraints is a challenging problem. In this paper, we consider a heterogenous\nrobotic system consisting of two types of agents -- anchor agents that have\naccurate localization capability, and auxiliary agents that have low\nlocalization accuracy. The auxiliary agents must be within the communication\nrange of an {anchor}, directly or indirectly to localize itself. The objective\nof the robotic team is to minimize the uncertainty in the environment through\npersistent monitoring. We propose a multi-agent deep reinforcement learning\n(MADRL) based architecture with graph attention called Graph Localized Proximal\nPolicy Optimization (GALLOP), which incorporates the localization and\ncommunication constraints of the agents along with persistent monitoring\nobjective to determine motion policies for each agent. We evaluate the\nperformance of GALLOP on three different custom-built environments. The results\nshow the agents are able to learn a stable policy and outperform greedy and\nrandom search baseline approaches.",
    "descriptor": "",
    "authors": [
      "Manav Mishra",
      "Prithvi Poddar",
      "Jingxi Chen",
      "Pratap Tokekar",
      "P.B. Sujit"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06831"
  },
  {
    "id": "arXiv:2109.06835",
    "title": "The Perils of Using Mechanical Turk to Evaluate Open-Ended Text  Generation",
    "abstract": "Recent text generation research has increasingly focused on open-ended\ndomains such as story and poetry generation. Because models built for such\ntasks are difficult to evaluate automatically, most researchers in the space\njustify their modeling choices by collecting crowdsourced human judgments of\ntext quality (e.g., Likert scores of coherence or grammaticality) from Amazon\nMechanical Turk (AMT). In this paper, we first conduct a survey of 45\nopen-ended text generation papers and find that the vast majority of them fail\nto report crucial details about their AMT tasks, hindering reproducibility. We\nthen run a series of story evaluation experiments with both AMT workers and\nEnglish teachers and discover that even with strict qualification filters, AMT\nworkers (unlike teachers) fail to distinguish between model-generated text and\nhuman-generated references. We show that AMT worker judgments improve when they\nare shown model-generated output alongside human-generated references, which\nenables the workers to better calibrate their ratings. Finally, interviews with\nthe English teachers provide deeper insights into the challenges of the\nevaluation process, particularly when rating model-generated text.",
    "descriptor": "\nComments: EMNLP 2021 (20 pages)\n",
    "authors": [
      "Marzena Karpinska",
      "Nader Akoury",
      "Mohit Iyyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06835"
  },
  {
    "id": "arXiv:2109.06836",
    "title": "What's in Your Wallet? Privacy and Security Issues in Web 3.0",
    "abstract": "Much of the recent excitement around decentralized finance (DeFi) comes from\nhopes that DeFi can be a secure, private, less centralized alternative to\ntraditional finance systems but the accuracy of these hopes has to date been\nunderstudied; people moving to DeFi sites to improve their privacy and security\nmay actually end up with less of both.\nIn this work, we improve the state of DeFi by conducting the first\nmeasurement of the privacy and security properties of popular DeFi\napplications. We find that DeFi applications suffer from the same kinds of\nprivacy and security risks that frequent other parts of the Web. For example,\nwe find that one common tracker has the ability to record Ethereum addresses on\nover 56% of websites analyzed. Further, we find that many trackers on DeFi\nsites can trivially link a user's Ethereum address with PII (e.g., name or\ndemographic information) or phish users.\nThis work also proposes remedies to the vulnerabilities we identify, in the\nform of improvements to the most common cryptocurrency wallet. Our wallet\nmodification replaces the user's real Ethereum address with site-specific\naddresses, making it harder for DeFi sites and third parties to (i) learn the\nuser's real address and (ii) track them across sites.",
    "descriptor": "",
    "authors": [
      "Philipp Winter",
      "Anna Harbluk Lorimer",
      "Peter Snyder",
      "Benjamin Livshits"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06836"
  },
  {
    "id": "arXiv:2109.06837",
    "title": "Object Shell Reconstruction: Camera-centric Object Representation for  Robotic Grasping",
    "abstract": "Robots can effectively grasp and manipulate objects using their 3D models. In\nthis paper, we propose a simple shape representation and a reconstruction\nmethod that outperforms state-of-the-art methods in terms of geometric metrics\nand enables grasp generation with high precision and success. Our\nreconstruction method models the object geometry as a pair of depth images,\ncomposing the \"shell\" of the object. This representation allows using\nimage-to-image residual ConvNet architectures for 3D reconstruction, generates\nobject reconstruction directly in the camera frame, and generalizes well to\nnovel object types. Moreover, an object shell can be converted into an object\nmesh in a fraction of a second, providing time and memory efficient alternative\nto voxel or implicit representations. We explore the application of shell\nrepresentation for grasp planning. With rigorous experimental validation, both\nin simulation and on a real setup, we show that shell reconstruction\nencapsulates sufficient geometric information to generate precise grasps and\nthe associated grasp quality with over 90% accuracy. Diverse grasps computed on\nshell reconstructions allow the robot to select and execute grasps in cluttered\nscenes with more than 93% success rate.",
    "descriptor": "\nComments: 18 pages, 12 figures, 7 tables\n",
    "authors": [
      "Nikhil Chavan-Dafle",
      "Sergiy Popovych",
      "Shubham Agrawal",
      "Daniel D. Lee",
      "Volkan Isler"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06837"
  },
  {
    "id": "arXiv:2109.06838",
    "title": "ePiC: Employing Proverbs in Context as a Benchmark for Abstract Language  Understanding",
    "abstract": "While large language models have shown exciting progress on several NLP\nbenchmarks, evaluating their ability for complex analogical reasoning remains\nunder-explored. Here, we introduce a high-quality crowdsourced dataset of\nnarratives for employing proverbs in context as a benchmark for abstract\nlanguage understanding. The dataset provides fine-grained annotation of aligned\nspans between proverbs and narratives, and contains minimal lexical overlaps\nbetween narratives and proverbs, ensuring that models need to go beyond\nsurface-level reasoning to succeed. We explore three tasks: (1) proverb\nrecommendation and alignment prediction, (2) narrative generation for a given\nproverb and topic, and (3) identifying narratives with similar motifs. Our\nexperiments show that neural language models struggle in our tasks compared to\nhumans, and the tasks pose multiple learning challenges.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Sayan Ghosh",
      "Shashank Srivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06838"
  },
  {
    "id": "arXiv:2109.06850",
    "title": "BenchIE: Open Information Extraction Evaluation Based on Facts, Not  Tokens",
    "abstract": "Intrinsic evaluations of OIE systems are carried out either manually -- with\nhuman evaluators judging the correctness of extractions -- or automatically, on\nstandardized benchmarks. The latter, while much more cost-effective, is less\nreliable, primarily because of the incompleteness of the existing OIE\nbenchmarks: the ground truth extractions do not include all acceptable variants\nof the same fact, leading to unreliable assessment of models' performance.\nMoreover, the existing OIE benchmarks are available for English only. In this\nwork, we introduce BenchIE: a benchmark and evaluation framework for\ncomprehensive evaluation of OIE systems for English, Chinese and German. In\ncontrast to existing OIE benchmarks, BenchIE takes into account informational\nequivalence of extractions: our gold standard consists of fact synsets,\nclusters in which we exhaustively list all surface forms of the same fact. We\nbenchmark several state-of-the-art OIE systems using BenchIE and demonstrate\nthat these systems are significantly less effective than indicated by existing\nOIE benchmarks. We make BenchIE (data and evaluation code) publicly available.",
    "descriptor": "",
    "authors": [
      "Kiril Gashteovski",
      "Mingying Yu",
      "Bhushan Kotnis",
      "Carolin Lawrence",
      "Goran Glavas",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06850"
  },
  {
    "id": "arXiv:2109.06853",
    "title": "Summarize-then-Answer: Generating Concise Explanations for Multi-hop  Reading Comprehension",
    "abstract": "How can we generate concise explanations for multi-hop Reading Comprehension\n(RC)? The current strategies of identifying supporting sentences can be seen as\nan extractive question-focused summarization of the input text. However, these\nextractive explanations are not necessarily concise i.e. not minimally\nsufficient for answering a question. Instead, we advocate for an abstractive\napproach, where we propose to generate a question-focused, abstractive summary\nof input paragraphs and then feed it to an RC system. Given a limited amount of\nhuman-annotated abstractive explanations, we train the abstractive explainer in\na semi-supervised manner, where we start from the supervised model and then\ntrain it further through trial and error maximizing a conciseness-promoted\nreward function. Our experiments demonstrate that the proposed abstractive\nexplainer can generate more compact explanations than an extractive explainer\nwith limited supervision (only 2k instances) while maintaining sufficiency.",
    "descriptor": "\nComments: Accepted to EMNLP2021 Long Paper (Main Track)\n",
    "authors": [
      "Naoya Inoue",
      "Harsh Trivedi",
      "Steven Sinha",
      "Niranjan Balasubramanian",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06853"
  },
  {
    "id": "arXiv:2109.06855",
    "title": "Timely Status Updating Over Erasure Channels Using an Energy Harvesting  Sensor: Single and Multiple Sources",
    "abstract": "A status updating system is considered in which data from multiple sources\nare sampled by an energy harvesting sensor and transmitted to a remote\ndestination through an erasure channel. The goal is to deliver status updates\nof all sources in a timely manner, such that the cumulative long-term average\nage-of-information (AoI) is minimized. The AoI for each source is defined as\nthe time elapsed since the generation time of the latest successful status\nupdate received at the destination from that source. Transmissions are subject\nto energy availability, which arrives in units according to a Poisson process,\nwith each energy unit capable of carrying out one transmission from only one\nsource. The sensor is equipped with a unit-sized battery to save the incoming\nenergy. A scheduling policy is designed in order to determine which source is\nsampled using the available energy. The problem is studied in two main\nsettings: no erasure status feedback, and perfect instantaneous feedback.",
    "descriptor": "\nComments: Accepted for publication in the IEEE Transactions on Green Communications and Networking (TGCN). arXiv admin note: substantial text overlap with arXiv:1811.04912\n",
    "authors": [
      "Ahmed Arafa",
      "Jing Yang",
      "Sennur Ulukus",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.06855"
  },
  {
    "id": "arXiv:2109.06858",
    "title": "CyberBunker 2.0 -- A Domain and Traffic Perspective on a Bulletproof  Hoster",
    "abstract": "In September 2019, 600 armed German cops seized the physical premise of a\nBulletproof Hoster (BPH) referred to as CyberBunker 2.0. The hoster resided in\na decommissioned NATO bunker and advertised to host everything but child porn\nand anything related to terrorism while keeping servers online no matter what.\nWhile the anatomy, economics and interconnection-level characteristics of BPHs\nare studied, their traffic characteristics are unknown. In this poster, we\npresent the first analysis of domains, web pages, and traffic captured at a\nmajor tier-1 ISP and a large IXP at the time when the CyberBunker was in\noperation. Our study sheds light on traffic characteristics of a BPH in\noperation. We show that a traditional BGP-based BPH identification approach\ncannot detect the CyberBunker, but find characteristics from a domain and\ntraffic perspective that can add to future identification approaches.",
    "descriptor": "\nComments: ACM CCS 2021 Poster\n",
    "authors": [
      "Daniel Kopp",
      "Eric Strehle",
      "Oliver Hohlfeld"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.06858"
  },
  {
    "id": "arXiv:2109.06859",
    "title": "One-Class Meta-Learning: Towards Generalizable Few-Shot Open-Set  Classification",
    "abstract": "Real-world classification tasks are frequently required to work in an\nopen-set setting. This is especially challenging for few-shot learning problems\ndue to the small sample size for each known category, which prevents existing\nopen-set methods from working effectively; however, most multiclass few-shot\nmethods are limited to closed-set scenarios. In this work, we address the\nproblem of few-shot open-set classification by first proposing methods for\nfew-shot one-class classification and then extending them to few-shot\nmulticlass open-set classification. We introduce two independent few-shot\none-class classification methods: Meta Binary Cross-Entropy (Meta-BCE), which\nlearns a separate feature representation for one-class classification, and\nOne-Class Meta-Learning (OCML), which learns to generate one-class classifiers\ngiven standard multiclass feature representation. Both methods can augment any\nexisting few-shot learning method without requiring retraining to work in a\nfew-shot multiclass open-set setting without degrading its closed-set\nperformance. We demonstrate the benefits and drawbacks of both methods in\ndifferent problem settings and evaluate them on three standard benchmark\ndatasets, miniImageNet, tieredImageNet, and Caltech-UCSD-Birds-200-2011, where\nthey surpass the state-of-the-art methods in the few-shot multiclass open-set\nand few-shot one-class tasks.",
    "descriptor": "\nComments: 21 pages, submitted to BMVC 2021\n",
    "authors": [
      "Jedrzej Kozerawski",
      "Matthew Turk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06859"
  },
  {
    "id": "arXiv:2109.06860",
    "title": "Broaden the Vision: Geo-Diverse Visual Commonsense Reasoning",
    "abstract": "Commonsense is defined as the knowledge that is shared by everyone. However,\ncertain types of commonsense knowledge are correlated with culture and\ngeographic locations and they are only shared locally. For example, the\nscenarios of wedding ceremonies vary across regions due to different customs\ninfluenced by historical and religious factors. Such regional characteristics,\nhowever, are generally omitted in prior work. In this paper, we construct a\nGeo-Diverse Visual Commonsense Reasoning dataset (GD-VCR) to test\nvision-and-language models' ability to understand cultural and\ngeo-location-specific commonsense. In particular, we study two state-of-the-art\nVision-and-Language models, VisualBERT and ViLBERT trained on VCR, a standard\nmultimodal commonsense benchmark with images primarily from Western regions. We\nthen evaluate how well the trained models can generalize to answering the\nquestions in GD-VCR. We find that the performance of both models for\nnon-Western regions including East Asia, South Asia, and Africa is\nsignificantly lower than that for Western region. We analyze the reasons behind\nthe performance disparity and find that the performance gap is larger on QA\npairs that: 1) are concerned with culture-related scenarios, e.g., weddings,\nreligious activities, and festivals; 2) require high-level geo-diverse\ncommonsense reasoning rather than low-order perception and recognition. Dataset\nand code are released at https://github.com/WadeYin9712/GD-VCR.",
    "descriptor": "\nComments: EMNLP 2021. Code and data are available at this https URL\n",
    "authors": [
      "Da Yin",
      "Liunian Harold Li",
      "Ziniu Hu",
      "Nanyun Peng",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06860"
  },
  {
    "id": "arXiv:2109.06861",
    "title": "Nonlinearities in Steerable SO(2)-Equivariant CNNs",
    "abstract": "Invariance under symmetry is an important problem in machine learning. Our\npaper looks specifically at equivariant neural networks where transformations\nof inputs yield homomorphic transformations of outputs. Here, steerable CNNs\nhave emerged as the standard solution. An inherent problem of steerable\nrepresentations is that general nonlinear layers break equivariance, thus\nrestricting architectural choices. Our paper applies harmonic distortion\nanalysis to illuminate the effect of nonlinearities on Fourier representations\nof SO(2). We develop a novel FFT-based algorithm for computing representations\nof non-linearly transformed activations while maintaining band-limitation. It\nyields exact equivariance for polynomial (approximations of) nonlinearities, as\nwell as approximate solutions with tunable accuracy for general functions. We\napply the approach to build a fully E(3)-equivariant network for sampled 3D\nsurface data. In experiments with 2D and 3D data, we obtain results that\ncompare favorably to the state-of-the-art in terms of accuracy while permitting\ncontinuous symmetry and exact equivariance.",
    "descriptor": "",
    "authors": [
      "Daniel Franzen",
      "Michael Wand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06861"
  },
  {
    "id": "arXiv:2109.06862",
    "title": "Legal Transformer Models May Not Always Help",
    "abstract": "Deep learning-based Natural Language Processing methods, especially\ntransformers, have achieved impressive performance in the last few years.\nApplying those state-of-the-art NLP methods to legal activities to automate or\nsimplify some simple work is of great value. This work investigates the value\nof domain adaptive pre-training and language adapters in legal NLP tasks. By\ncomparing the performance of language models with domain adaptive pre-training\non different tasks and different dataset splits, we show that domain adaptive\npre-training is only helpful with low-resource downstream tasks, thus far from\nbeing a panacea. We also benchmark the performance of adapters in a typical\nlegal NLP task and show that they can yield similar performance to full model\ntuning with much smaller training costs. As an additional result, we release\nLegalRoBERTa, a RoBERTa model further pre-trained on legal corpora.",
    "descriptor": "",
    "authors": [
      "Sakbo Geng",
      "R\u00e9mi Lebret",
      "Karl Aberer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06862"
  },
  {
    "id": "arXiv:2109.06867",
    "title": "On Decentralized Multi-Transmitter Coded Caching",
    "abstract": "This paper investigates a setup consisting of multiple transmitters serving\nmultiple cache-enabled clients through a linear network, which covers both\nwired and wireless transmission situations. We investigate decentralized coded\ncaching scenarios in which there is either no cooperation or limited\ncooperation between the clients at the cache content placement phase. For the\nfully decentralized caching case (i.e., no cooperation) we analyze the\nperformance of the system in terms of the Coding Delay metric. Furthermore, we\ninvestigate a hybrid cache content placement scenario in which there are two\ngroups of users with different cache content placement situations (i.e.,\nlimited cooperation). Also, we examine the effect of finite file size in above\nscenarios.",
    "descriptor": "",
    "authors": [
      "Mohammad Mahmoudi",
      "Mohammad Javad Sojdeh",
      "Seyed Pooya Shariatpanahi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.06867"
  },
  {
    "id": "arXiv:2109.06870",
    "title": "Performance-Efficiency Trade-offs in Unsupervised Pre-training for  Speech Recognition",
    "abstract": "This paper is a study of performance-efficiency trade-offs in pre-trained\nmodels for automatic speech recognition (ASR). We focus on wav2vec 2.0, and\nformalize several architecture designs that influence both the model\nperformance and its efficiency. Putting together all our observations, we\nintroduce SEW (Squeezed and Efficient Wav2vec), a pre-trained model\narchitecture with significant improvements along both performance and\nefficiency dimensions across a variety of training setups. For example, under\nthe 100h-960h semi-supervised setup on LibriSpeech, SEW achieves a 1.9x\ninference speedup compared to wav2vec 2.0, with a 13.5% relative reduction in\nword error rate. With a similar inference time, SEW reduces word error rate by\n25-50% across different model sizes.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Felix Wu",
      "Kwangyoun Kim",
      "Jing Pan",
      "Kyu Han",
      "Kilian Q. Weinberger",
      "Yoav Artzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.06870"
  },
  {
    "id": "arXiv:2109.05895",
    "title": "Inferring the prior in routing games using public signalling",
    "abstract": "This paper considers Bayesian persuasion for routing games where information\nabout the uncertain state of the network is provided by a traffic information\nsystem (TIS) using public signals. In this setup, the TIS commits to a\nsignalling scheme and participants form a posterior belief about the state of\nthe network based on prior beliefs and received signal. They subsequently\nselect routes minimizing their individual expected travel time under their\nposterior beliefs, giving rise to a Wardrop equilibrium. We investigate how the\nTIS can infer the prior beliefs held by the participants by designing suitable\nsignalling schemes, and observing the equilibrium flows under different\nsignals. We show that under mild conditions a signalling scheme that allows for\nexact inference of the prior exists. We then provide an iterative algorithm\nthat finds such a scheme in a finite number of steps. Finally, we show how in\nthe simplified 2-road, 2-state case such a scheme can be constructed without\nthe need for a sequential procedure. Several examples illustrate our results.",
    "descriptor": "",
    "authors": [
      "Jasper Verbree",
      "Ashish Cherukuri"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.05895"
  },
  {
    "id": "arXiv:2109.06171",
    "title": "In-filter Computing For Designing Ultra-light Acoustic Pattern  Recognizers",
    "abstract": "We present a novel in-filter computing framework that can be used for\ndesigning ultra-light acoustic classifiers for use in smart internet-of-things\n(IoTs). Unlike a conventional acoustic pattern recognizer, where the feature\nextraction and classification are designed independently, the proposed\narchitecture integrates the convolution and nonlinear filtering operations\ndirectly into the kernels of a Support Vector Machine (SVM). The result of this\nintegration is a template-based SVM whose memory and computational footprint\n(training and inference) is light enough to be implemented on an FPGA-based IoT\nplatform. While the proposed in-filter computing framework is general enough,\nin this paper, we demonstrate this concept using a Cascade of Asymmetric\nResonator with Inner Hair Cells (CAR-IHC) based acoustic feature extraction\nalgorithm. The complete system has been optimized using time-multiplexing and\nparallel-pipeline techniques for a Xilinx Spartan 7 series Field Programmable\nGate Array (FPGA). We show that the system can achieve robust classification\nperformance on benchmark sound recognition tasks using only ~ 1.5k Look-Up\nTables (LUTs) and ~ 2.8k Flip-Flops (FFs), a significant improvement over other\napproaches.",
    "descriptor": "\nComments: in IEEE Internet of Things Journal\n",
    "authors": [
      "Abhishek Ramdas Nair",
      "Shantanu Chakrabartty",
      "Chetan Singh Thakur"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06171"
  },
  {
    "id": "arXiv:2109.06177",
    "title": "Towards a Computational Framework for Automated Discovery and Modeling  of Biological Rhythms from Wearable Data Streams",
    "abstract": "Modeling biological rhythms helps understand the complex principles behind\nthe physical and psychological abnormalities of human bodies, to plan life\nschedules, and avoid persisting fatigue and mood and sleep alterations due to\nthe desynchronization of those rhythms. The first step in modeling biological\nrhythms is to identify their characteristics, such as cyclic periods, phase,\nand amplitude. However, human rhythms are susceptible to external events, which\ncause irregular fluctuations in waveforms and affect the characterization of\neach rhythm. In this paper, we present our exploratory work towards developing\na computational framework for automated discovery and modeling of human\nrhythms. We first identify cyclic periods in time series data using three\ndifferent methods and test their performance on both synthetic data and real\nfine-grained biological data. We observe consistent periods are detected by all\nthree methods. We then model inner cycles within each period through\nidentifying change points to observe fluctuations in biological data that may\ninform the impact of external events on human rhythms. The results provide\ninitial insights into the design of a computational framework for discovering\nand modeling human rhythms.",
    "descriptor": "\nComments: 18 pages, 12 figures, 4 tables\n",
    "authors": [
      "Runze Yan",
      "Afsaneh Doryab"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.06177"
  },
  {
    "id": "arXiv:2109.06235",
    "title": "Hierarchical Robust Adaptive Control for Wind Turbines with Actuator  Fault",
    "abstract": "This paper solves the problem of regulating the rotor speed tracking error\nfor wind turbines in the full-load region by an effective robust-adaptive\ncontrol strategy. The developed controller compensates for the uncertainty in\nthe control input effectiveness caused by a pitch actuator fault, unmeasurable\nwind disturbance, and nonlinearity in the model. Wind turbines have multi-layer\nstructures such that the high-level structure is nonlinearly coupled through an\naggregation of the low-level control authorities. Hence, the control design is\ndivided into two stages. First, an $\\mathcal{L}_2$ controller is designed to\nattenuate the influence of wind disturbance fluctuations on the rotor speed.\nThen, in the low-level layer, a controller is designed using a proposed\nadaptation mechanism to compensate for actuator faults. The theoretical results\nshow that the closed-loop equilibrium point of the regulated rotor speed\ntracking error dynamics in the high level is finite-gain $\\mathcal{L}_2$\nstable, and the closed-loop error dynamics in the low level is globally\nasymptotically stable. Simulation results show that the developed controller\nsignificantly reduces the root mean square of the rotor speed error compared to\nsome well-known works, despite the largely fluctuating wind disturbance, and\nthe time-varying uncertainty in the control input effectiveness.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Sina Ameli",
      "Olugbenga Moses Anubi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06235"
  },
  {
    "id": "arXiv:2109.06248",
    "title": "Distilling GHZ States using Stabilizer Codes",
    "abstract": "Entanglement distillation is a well-studied problem in quantum information,\nwhere one typically starts with $n$ noisy Bell pairs and distills $k$ Bell\npairs of higher fidelity. While distilling Bell pairs is the canonical setting,\nit is important to study the distillation of multipartite entangled states\nbecause these can be useful for realizing distributed algorithms on quantum\nnetworks. In this paper, we study the distillation of GHZ states using quantum\nerror correcting codes (QECCs). Using the stabilizer formalism, we begin by\nexplaining the QECC-based Bell pair distillation protocol in arXiv:0708.3699,\nwhich relies particularly on the transpose symmetry between Alice's and Bob's\nqubits in Bell states. Extending this idea, we show that, given $n$ GHZ states,\nperforming a matrix on Alice's qubits is equivalent to performing a \"stretched\"\nversion of the transpose of the matrix on the qubits of Bob and Charlie. We\ncall this mapping to the stretched version of the matrix the GHZ-map, and show\nthat it is an algebra homomorphism. Using this property, we show that Alice\nprojecting her qubits onto an $[[n,k]]$ stabilizer code implies the\nsimultaneous projection of Bob's and Charlie's qubits onto an induced\n$[[2n,k]]$ stabilizer code. Guided by this insight, we develop a GHZ\ndistillation protocol based on local operations and classical communication\nthat uses any stabilizer code. Inspired by stabilizer measurements on GHZ\nstates, we also develop a new algorithm to generate logical Pauli operators of\nany stabilizer code and use it in the protocol. Since quantum codes with finite\nrate and almost linear minimum distance have recently been discovered, this\npaper paves the way for high-rate high-output-fidelity GHZ distillation. We\nprovide simulation results on the $5$-qubit perfect code to emphasize the\nimportance of the placement of a certain local Clifford operation in the\nprotocol.",
    "descriptor": "\nComments: Main paper: 19 pages, single column, IEEEtran class, 3 figures, 2 tables (protocol examples), 3 pseudo-codes. Implementation online: this https URL Comments welcome!\n",
    "authors": [
      "Narayanan Rengaswamy",
      "Ankur Raina",
      "Nithin Raveendran",
      "Bane Vasi\u0107"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06248"
  },
  {
    "id": "arXiv:2109.06274",
    "title": "Cross-Modality Domain Adaptation for Vestibular Schwannoma and Cochlea  Segmentation",
    "abstract": "Automatic methods to segment the vestibular schwannoma (VS) tumors and the\ncochlea from magnetic resonance imaging (MRI) are critical to VS treatment\nplanning. Although supervised methods have achieved satisfactory performance in\nVS segmentation, they require full annotations by experts, which is laborious\nand time-consuming. In this work, we aim to tackle the VS and cochlea\nsegmentation problem in an unsupervised domain adaptation setting. Our proposed\nmethod leverages both the image-level domain alignment to minimize the domain\ndivergence and semi-supervised training to further boost the performance.\nFurthermore, we propose to fuse the labels predicted from multiple models via\nnoisy label correction. Our results on the challenge validation leaderboard\nshowed that our unsupervised method has achieved promising VS and cochlea\nsegmentation performance with mean dice score of 0.8261 $\\pm$ 0.0416; The mean\ndice value for the tumor is 0.8302 $\\pm$ 0.0772. This is comparable to the\nweakly-supervised based method.",
    "descriptor": "",
    "authors": [
      "Han Liu",
      "Yubo Fan",
      "Can Cui",
      "Dingjie Su",
      "Andrew McNeil",
      "Benoit M.Dawant"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06274"
  },
  {
    "id": "arXiv:2109.06294",
    "title": "On the regularized risk of distributionally robust learning over deep  neural networks",
    "abstract": "In this paper we explore the relation between distributionally robust\nlearning and different forms of regularization to enforce robustness of deep\nneural networks. In particular, starting from a concrete min-max\ndistributionally robust problem, and using tools from optimal transport theory,\nwe derive first order and second order approximations to the distributionally\nrobust problem in terms of appropriate regularized risk minimization problems.\nIn the context of deep ResNet models, we identify the structure of the\nresulting regularization problems as mean-field optimal control problems where\nthe number and dimension of state variables is within a dimension-free factor\nof the dimension of the original unrobust problem. Using the Pontryagin maximum\nprinciples associated to these problems we motivate a family of scalable\nalgorithms for the training of robust neural networks. Our analysis recovers\nsome results and algorithms known in the literature (in settings explained\nthroughout the paper) and provides many other theoretical and algorithmic\ninsights that to our knowledge are novel. In our analysis we employ tools that\nwe deem useful for a future analysis of more general adversarial learning\nproblems.",
    "descriptor": "",
    "authors": [
      "Camilo Garcia Trillos",
      "Nicolas Garcia Trillos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.06294"
  },
  {
    "id": "arXiv:2109.06343",
    "title": "Data-based Online Optimization of Networked Systems with Infrequent  Feedback",
    "abstract": "We consider optimization problems for (networked) systems, where we minimize\na cost that includes a known time-varying function associated with the system's\noutputs and an unknown function of the inputs. We focus on a data-based online\nprojected gradient algorithm where: i) the input-output map of the system is\nreplaced by measurements of the output whenever available (thus leading to a\n\"closed-loop\" setup); and ii) the unknown function is learned based on\nfunctional evaluations that may occur infrequently. Accordingly, the\nfeedback-based online algorithm operates in a regime with inexact gradient\nknowledge and with random updates. We show that the online algorithm generates\npoints that are within a bounded error from the optimal solution of the\nproblem; in particular, we provide error bounds in expectation and in\nhigh-probability, where the latter is given when the gradient error follows a\nsub-Weibull distribution and when missing measurements are modeled as Bernoulli\nrandom variables. We also provide results in terms of input-to-state stability\nin expectation and in probability. Numerical results are presented in the\ncontext of a demand response task in power systems.",
    "descriptor": "\nComments: Submitted to IEEE L-CSS and ACC 2022\n",
    "authors": [
      "Ana M. Ospina",
      "Nicola Bastianello",
      "Emiliano Dall'Anese"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06343"
  },
  {
    "id": "arXiv:2109.06344",
    "title": "On the Correlation between the Noise and a Priori Error Vectors in  Affine Projection Algorithms",
    "abstract": "This paper analyzes the correlation matrix between the a priori error and\nmeasurement noise vectors for affine projection algorithms (APA). This\ncorrelation stems from the dependence between the filter tap estimates and the\nnoise samples, and has a strong influence on the mean square behavior of the\nalgorithm. We show that the correlation matrix is upper triangular, and compute\nthe diagonal elements in closed form, showing that they are independent of the\ninput process statistics. Also, for white inputs we show that the matrix is\nfully diagonal. These results are valid in the transient and steady states of\nthe algorithm considering a possibly variable step-size. Our only assumption is\nthat the filter order is large compared to the projection order of APA and we\nmake no assumptions on the input signal except for stationarity. Using these\nresults, we perform a steady-state analysis of the algorithm for small step\nsize and provide a new simple closed-form expression for mean-square error,\nwhich has comparable or better accuracy to many preexisting expressions, and is\nmuch simpler to compute. Finally, we also obtain expressions for the\nsteady-state energy of the other components of the error vector.",
    "descriptor": "\nComments: 23 pages, 7 figures. Submitted for possible publication\n",
    "authors": [
      "Andres Altieri"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06344"
  },
  {
    "id": "arXiv:2109.06346",
    "title": "Physics Driven Domain Specific Transporter Framework with Attention  Mechanism for Ultrasound Imaging",
    "abstract": "Most applications of deep learning techniques in medical imaging are\nsupervised and require a large number of labeled data which is expensive and\nrequires many hours of careful annotation by experts. In this paper, we propose\nan unsupervised, physics driven domain specific transporter framework with an\nattention mechanism to identify relevant key points with applications in\nultrasound imaging. The proposed framework identifies key points that provide a\nconcise geometric representation highlighting regions with high structural\nvariation in ultrasound videos. We incorporate physics driven domain specific\ninformation as a feature probability map and use the radon transform to\nhighlight features in specific orientations. The proposed framework has been\ntrained on130 Lung ultrasound (LUS) videos and 113 Wrist ultrasound (WUS)\nvideos and validated on 100 Lung ultrasound (LUS) videos and 58 Wrist\nultrasound (WUS) videos acquired from multiple centers across the globe. Images\nfrom both datasets were independently assessed by experts to identify\nclinically relevant features such as A-lines, B-lines and pleura from LUS and\nradial metaphysis, radial epiphysis and carpal bones from WUS videos. The key\npoints detected from both datasets showed high sensitivity (LUS = 99\\% , WUS =\n74\\%) in detecting the image landmarks identified by experts. Also, on\nemploying for classification of the given lung image into normal and abnormal\nclasses, the proposed approach, even with no prior training, achieved an\naverage accuracy of 97\\% and an average F1-score of 95\\% respectively on the\ntask of co-classification with 3 fold cross-validation. With the purely\nunsupervised nature of the proposed approach, we expect the key point detection\napproach to increase the applicability of ultrasound in various examination\nperformed in emergency and point of care.",
    "descriptor": "\nComments: 11 pages,18 figures(including supplementary material)\n",
    "authors": [
      "Arpan Tripathi",
      "Abhilash Rakkunedeth",
      "Mahesh Raveendranatha Panicker",
      "Jack Zhang",
      "Naveenjyote Boora",
      "Jessica Knight",
      "Jacob Jaremko",
      "Yale Tung Chen",
      "Kiran Vishnu Narayan",
      "Kesavadas C"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06346"
  },
  {
    "id": "arXiv:2109.06421",
    "title": "COVID-Net MLSys: Designing COVID-Net for the Clinical Workflow",
    "abstract": "As the COVID-19 pandemic continues to devastate globally, one promising field\nof research is machine learning-driven computer vision to streamline various\nparts of the COVID-19 clinical workflow. These machine learning methods are\ntypically stand-alone models designed without consideration for the integration\nnecessary for real-world application workflows. In this study, we take a\nmachine learning and systems (MLSys) perspective to design a system for\nCOVID-19 patient screening with the clinical workflow in mind. The COVID-Net\nsystem is comprised of the continuously evolving COVIDx dataset, COVID-Net deep\nneural network for COVID-19 patient detection, and COVID-Net S deep neural\nnetworks for disease severity scoring for COVID-19 positive patient cases. The\ndeep neural networks within the COVID-Net system possess state-of-the-art\nperformance, and are designed to be integrated within a user interface (UI) for\nclinical decision support with automatic report generation to assist clinicians\nin their treatment decisions.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Audrey G. Chung",
      "Maya Pavlova",
      "Hayden Gunraj",
      "Naomi Terhljan",
      "Alexander MacLean",
      "Hossein Aboutalebi",
      "Siddharth Surana",
      "Andy Zhao",
      "Saad Abbasi",
      "Alexander Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06421"
  },
  {
    "id": "arXiv:2109.06483",
    "title": "Overlap-aware low-latency online speaker diarization based on end-to-end  local segmentation",
    "abstract": "We propose to address online speaker diarization as a combination of\nincremental clustering and local diarization applied to a rolling buffer\nupdated every 500ms. Every single step of the proposed pipeline is designed to\ntake full advantage of the strong ability of a recently proposed end-to-end\noverlap-aware segmentation to detect and separate overlapping speakers. In\nparticular, we propose a modified version of the statistics pooling layer\n(initially introduced in the x-vector architecture) to give less weight to\nframes where the segmentation model predicts simultaneous speakers.\nFurthermore, we derive cannot-link constraints from the initial segmentation\nstep to prevent two local speakers from being wrongfully merged during the\nincremental clustering step. Finally, we show how the latency of the proposed\napproach can be adjusted between 500ms and 5s to match the requirements of a\nparticular use case, and we provide a systematic analysis of the influence of\nlatency on the overall performance (on AMI, DIHARD and VoxConverse).",
    "descriptor": "\nComments: To appear in ASRU 2021. Code available at this https URL\n",
    "authors": [
      "Juan M. Coria",
      "Herv\u00e9 Bredin",
      "Sahar Ghannay",
      "Sophie Rosset"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.06483"
  },
  {
    "id": "arXiv:2109.06500",
    "title": "The Dean-Kawasaki equation and the structure of density fluctuations in  systems of diffusing particles",
    "abstract": "The Dean-Kawasaki equation - a strongly singular SPDE - is a basic equation\nof fluctuating hydrodynamics; it has been proposed in the physics literature to\ndescribe the fluctuations of the density of $N$ independent diffusing particles\nin the regime of large particle numbers $N\\gg 1$. The singular nature of the\nDean-Kawasaki equation presents a substantial challenge for both its analysis\nand its rigorous mathematical justification. Besides being non-renormalisable\nby the theory of regularity structures by Hairer et al., it has recently been\nshown to not even admit nontrivial martingale solutions.\nIn the present work, we give a rigorous and fully quantitative justification\nof the Dean-Kawasaki equation by considering the natural regularisation\nprovided by standard numerical discretisations: We show that\nstructure-preserving discretisations of the Dean-Kawasaki equation may\napproximate the density fluctuations of $N$ non-interacting diffusing particles\nto arbitrary order in $N^{-1}$ (in suitable weak metrics). In other words, the\nDean-Kawasaki equation may be interpreted as a \"recipe\" for accurate and\nefficient numerical simulations of the density fluctuations of independent\ndiffusing particles.",
    "descriptor": "\nComments: 65 pages, 6 figures\n",
    "authors": [
      "Federico Cornalba",
      "Julian Fischer"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.06500"
  },
  {
    "id": "arXiv:2109.06519",
    "title": "PRETUS: A plug-in based platform for real-time ultrasound imaging  research",
    "abstract": "We present PRETUS -a Plugin-based Real Time UltraSound software platform for\nlive ultrasound image analysis and operator support. The software is\nlightweight; functionality is brought in via independent plug-ins that can be\narranged in sequence. The software allows to capture the real-time stream of\nultrasound images from virtually any ultrasound machine, applies computational\nmethods and visualises the results on-the-fly.\nPlug-ins can run concurrently without blocking each other. They can be\nimplemented in C ++ and Python. A graphical user interface can be implemented\nfor each plug-in, and presented to the user in a compact way. The software is\nfree and open source, and allows for rapid prototyping and testing of real-time\nultrasound imaging methods in a manufacturer-agnostic fashion. The software is\nprovided with input, output and processing plug-ins, as well as with tutorials\nto illustrate how to develop new plug-ins for PRETUS.",
    "descriptor": "",
    "authors": [
      "Alberto Gomez",
      "Veronika A. Zimmer",
      "Gavin Wheeler",
      "Nicolas Toussaint",
      "Shujie Deng",
      "Robert Wright",
      "Emily Skelton",
      "Jackie Matthew",
      "Bernhard Kainz",
      "Jo Hajnal",
      "Julia Schnabel"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.06519"
  },
  {
    "id": "arXiv:2109.06540",
    "title": "3-Dimensional Deep Learning with Spatial Erasing for Unsupervised  Anomaly Segmentation in Brain MRI",
    "abstract": "Purpose. Brain Magnetic Resonance Images (MRIs) are essential for the\ndiagnosis of neurological diseases. Recently, deep learning methods for\nunsupervised anomaly detection (UAD) have been proposed for the analysis of\nbrain MRI. These methods rely on healthy brain MRIs and eliminate the\nrequirement of pixel-wise annotated data compared to supervised deep learning.\nWhile a wide range of methods for UAD have been proposed, these methods are\nmostly 2D and only learn from MRI slices, disregarding that brain lesions are\ninherently 3D and the spatial context of MRI volumes remains unexploited.\nMethods. We investigate whether using increased spatial context by using MRI\nvolumes combined with spatial erasing leads to improved unsupervised anomaly\nsegmentation performance compared to learning from slices. We evaluate and\ncompare 2D variational autoencoder (VAE) to their 3D counterpart, propose 3D\ninput erasing, and systemically study the impact of the data set size on the\nperformance.\nResults. Using two publicly available segmentation data sets for evaluation,\n3D VAE outperform their 2D counterpart, highlighting the advantage of\nvolumetric context. Also, our 3D erasing methods allow for further performance\nimprovements. Our best performing 3D VAE with input erasing leads to an average\nDICE score of 31.40% compared to 25.76% for the 2D VAE.\nConclusions. We propose 3D deep learning methods for UAD in brain MRI\ncombined with 3D erasing and demonstrate that 3D methods clearly outperform\ntheir 2D counterpart for anomaly segmentation. Also, our spatial erasing method\nallows for further performance improvements and reduces the requirement for\nlarge data sets.",
    "descriptor": "\nComments: Accepted for publication in the International Journal of Computer Assisted Radiology and Surgery (IJCARS)\n",
    "authors": [
      "Marcel Bengs",
      "Finn Behrendt",
      "Julia Kr\u00fcger",
      "Roland Opfer",
      "Alexander Schlaefer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06540"
  },
  {
    "id": "arXiv:2109.06547",
    "title": "Multi-Scale Input Strategies for Medulloblastoma Tumor Classification  using Deep Transfer Learning",
    "abstract": "Medulloblastoma (MB) is a primary central nervous system tumor and the most\ncommon malignant brain cancer among children. Neuropathologists perform\nmicroscopic inspection of histopathological tissue slides under a microscope to\nassess the severity of the tumor. This is a time-consuming task and often\ninfused with observer variability. Recently, pre-trained convolutional neural\nnetworks (CNN) have shown promising results for MB subtype classification.\nTypically, high-resolution images are divided into smaller tiles for\nclassification, while the size of the tiles has not been systematically\nevaluated. We study the impact of tile size and input strategy and classify the\ntwo major histopathological subtypes-Classic and Demoplastic/Nodular. To this\nend, we use recently proposed EfficientNets and evaluate tiles with increasing\nsize combined with various downsampling scales. Our results demonstrate using\nlarge input tiles pixels followed by intermediate downsampling and patch\ncropping significantly improves MB classification performance. Our\ntop-performing method achieves the AUC-ROC value of 90.90\\% compared to 84.53\\%\nusing the previous approach with smaller input tiles.",
    "descriptor": "\nComments: Accepted at CURAC 2021\n",
    "authors": [
      "Marcel Bengs",
      "Satish Pant",
      "Michael Bockmayr",
      "Ulrich Sch\u00fcller",
      "Alexander Schlaefer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06547"
  },
  {
    "id": "arXiv:2109.06548",
    "title": "Dense Deep Unfolding Network with 3D-CNN Prior for Snapshot Compressive  Imaging",
    "abstract": "Snapshot compressive imaging (SCI) aims to record three-dimensional signals\nvia a two-dimensional camera. For the sake of building a fast and accurate SCI\nrecovery algorithm, we incorporate the interpretability of model-based methods\nand the speed of learning-based ones and present a novel dense deep unfolding\nnetwork (DUN) with 3D-CNN prior for SCI, where each phase is unrolled from an\niteration of Half-Quadratic Splitting (HQS). To better exploit the\nspatial-temporal correlation among frames and address the problem of\ninformation loss between adjacent phases in existing DUNs, we propose to adopt\nthe 3D-CNN prior in our proximal mapping module and develop a novel dense\nfeature map (DFM) strategy, respectively. Besides, in order to promote network\nrobustness, we further propose a dense feature map adaption (DFMA) module to\nallow inter-phase information to fuse adaptively. All the parameters are\nlearned in an end-to-end fashion. Extensive experiments on simulation data and\nreal data verify the superiority of our method. The source code is available at\nhttps://github.com/jianzhangcs/SCI3D.",
    "descriptor": "\nComments: Accepted by ICCV 2021\n",
    "authors": [
      "Zhuoyuan Wu",
      "Jian Zhang",
      "Chong Mou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06548"
  },
  {
    "id": "arXiv:2109.06579",
    "title": "Bayesian AirComp with Sign-Alignment Precoding for Wireless Federated  Learning",
    "abstract": "In this paper, we consider the problem of wireless federated learning based\non sign stochastic gradient descent (signSGD) algorithm via a multiple access\nchannel. When sending locally computed gradient's sign information, each mobile\ndevice requires to apply precoding to circumvent wireless fading effects. In\npractice, however, acquiring perfect knowledge of channel state information\n(CSI) at all mobile devices is infeasible. In this paper, we present a simple\nyet effective precoding method with limited channel knowledge, called\nsign-alignment precoding. The idea of sign-alignment precoding is to protect\nsign-flipping errors from wireless fadings. Under the Gaussian prior assumption\non the local gradients, we also derive the mean squared error (MSE)-optimal\naggregation function called Bayesian over-the-air computation (BayAirComp). Our\nkey finding is that one-bit precoding with BayAirComp aggregation can provide a\nbetter learning performance than the existing precoding method even using\nperfect CSI with AirComp aggregation.",
    "descriptor": "\nComments: This paper is 8 pages long, and has 4 figures. This paper is the extended version of the conference paper which is accepted in 2021 IEEE GlobeCom\n",
    "authors": [
      "Chanho Park",
      "Seunghoon Lee",
      "Namyoon Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06579"
  },
  {
    "id": "arXiv:2109.06589",
    "title": "Information Cocoons in Online Navigation",
    "abstract": "Social media and online navigation bring us enjoyable experience in accessing\ninformation, and simultaneously create information cocoons (ICs) in which we\nare unconsciously trapped with limited and biased information. We provide a\nformal definition of IC in the scenario of online navigation. Subsequently, by\nanalyzing real recommendation networks extracted from Science, PNAS and Amazon\nwebsites, and testing mainstream algorithms in disparate recommender systems,\nwe demonstrate that similarity-based recommendation techniques result in ICs,\nwhich suppress the system navigability by hundreds of times. We further propose\na flexible recommendation strategy that solves the IC-induced problem and\nimproves retrieval accuracy in navigation, demonstrated by simulations on real\ndata and online experiments on the largest video website in China.",
    "descriptor": "\nComments: 14 pages, 3 figures, 1 table, 30 references\n",
    "authors": [
      "Lei Hou",
      "Xue Pan",
      "Kecheng Liu",
      "Zimo Yang",
      "Jianguo Liu",
      "Tao Zhou"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.06589"
  },
  {
    "id": "arXiv:2109.06602",
    "title": "$\\varepsilon$-isometric dimension reduction for incompressible subsets  of $\\ell_p$",
    "abstract": "Fix $p\\in[1,\\infty)$, $K\\in(0,\\infty)$ and a probability measure $\\mu$. We\nprove that for every $n\\in\\mathbb{N}$, $\\varepsilon\\in(0,1)$ and\n$x_1,\\ldots,x_n\\in L_p(\\mu)$ with $\\big\\| \\max_{i\\in\\{1,\\ldots,n\\}} |x_i|\n\\big\\|_{L_p(\\mu)} \\leq K$, there exists $d\\leq \\frac{32e^2 (2K)^{2p}\\log\nn}{\\varepsilon^2}$ and vectors $y_1,\\ldots, y_n \\in \\ell_p^d$ such that\n$$\\forall \\ i,j\\in\\{1,\\ldots,n\\}, \\qquad \\|x_i-x_j\\|^p_{L_p(\\mu)}- \\varepsilon\n\\leq \\|y_i-y_j\\|_{\\ell_p^d}^p \\leq \\|x_i-x_j\\|^p_{L_p(\\mu)}+\\varepsilon.$$\nMoreover, the argument implies the existence of a greedy algorithm which\noutputs $\\{y_i\\}_{i=1}^n$ after receiving $\\{x_i\\}_{i=1}^n$ as input. The proof\nrelies on a derandomized version of Maurey's empirical method (1981) combined\nwith a combinatorial idea of Ball (1990) and classical factorization theory of\n$L_p(\\mu)$ spaces. Motivated by the above embedding, we introduce the notion of\n$\\varepsilon$-isometric dimension reduction of the unit ball ${\\bf B}_E$ of a\nnormed space $(E,\\|\\cdot\\|_E)$ and we prove that ${\\bf B}_{\\ell_p}$ does not\nadmit $\\varepsilon$-isometric dimension reduction by linear operators for any\nvalue of $p\\neq2$.",
    "descriptor": "",
    "authors": [
      "Alexandros Eskenazis"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Data Structures and Algorithms (cs.DS)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2109.06602"
  },
  {
    "id": "arXiv:2109.06635",
    "title": "Deep Convolutional Generative Modeling for Artificial Microstructure  Development of Aluminum-Silicon Alloy",
    "abstract": "Machine learning which is a sub-domain of an Artificial Intelligence which is\nfinding various applications in manufacturing and material science sectors. In\nthe present study, Deep Generative Modeling which a type of unsupervised\nmachine learning technique has been adapted for the constructing the artificial\nmicrostructure of Aluminium-Silicon alloy. Deep Generative Adversarial Networks\nhas been used for developing the artificial microstructure of the given\nmicrostructure image dataset. The results obtained showed that the developed\nmodels had learnt to replicate the lining near the certain images of the\nmicrostructures.",
    "descriptor": "",
    "authors": [
      "Akshansh Mishra",
      "Tarushi Pathak"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06635"
  },
  {
    "id": "arXiv:2109.06670",
    "title": "Non-accessible localizations",
    "abstract": "In a 2005 paper, Casacuberta, Scevenels and Smith construct a homotopy\nidempotent functor $E$ on the category of simplicial sets with the property\nthat whether it can be expressed as localization with respect to a map $f$ is\nindependent of the ZFC axioms. We show that this construction can be carried\nout in homotopy type theory. More precisely, we give a general method of\nassociating to a suitable (possibly large) family of maps, a reflective\nsubuniverse of any universe $\\mathcal{U}$. When specialized to an appropriate\nfamily, this produces a localization which when interpreted in the\n$\\infty$-topos of spaces agrees with the localization corresponding to $E$. Our\napproach generalizes the approach of [CSS] in two ways. First, by working in\nhomotopy type theory, our construction can be interpreted in any\n$\\infty$-topos. Second, while the local objects produced by [CSS] are always\n1-types, our construction can produce $n$-types, for any $n$. This is new, even\nin the $\\infty$-topos of spaces. In addition, by making use of universes, our\nproof is very direct.\nAlong the way, we prove many results about \"small\" types that are of\nindependent interest. As an application, we give a new proof that separated\nlocalizations exist. We also give results that say when a localization with\nrespect to a family of maps can be presented as localization with respect to a\nsingle map, and show that the simplicial model satisfies a strong form of the\naxiom of choice which implies that sets cover and that the law of excluded\nmiddle holds.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "J. Daniel Christensen"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2109.06670"
  },
  {
    "id": "arXiv:2109.06677",
    "title": "Specified Certainty Classification, with Application to Read  Classification for Reference-Guided Metagenomic Assembly",
    "abstract": "Specified Certainty Classification (SCC) is a new paradigm for employing\nclassifiers whose outputs carry uncertainties, typically in the form of\nBayesian posterior probabilities. By allowing the classifier output to be less\nprecise than one of a set of atomic decisions, SCC allows all decisions to\nachieve a specified level of certainty, as well as provides insights into\nclassifier behavior by examining all decisions that are possible. Our primary\nillustration is read classification for reference-guided genome assembly, but\nwe demonstrate the breadth of SCC by also analyzing COVID-19 vaccination data.",
    "descriptor": "",
    "authors": [
      "Alan F. Karr",
      "Jason Hauzel",
      "Prahlad Menon",
      "Adam A. Porter",
      "Marcel Schaefer"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06677"
  },
  {
    "id": "arXiv:2109.06699",
    "title": "An Apparatus for the Simulation of Breathing Disorders: Physically  Meaningful Generation of Surrogate Data",
    "abstract": "Whilst debilitating breathing disorders, such as chronic obstructive\npulmonary disease (COPD), are rapidly increasing in prevalence, we witness a\ncontinued integration of artificial intelligence into healthcare. While this\npromises improved detection and monitoring of breathing disorders, AI\ntechniques are \"data hungry\" which highlights the importance of generating\nphysically meaningful surrogate data. Such domain knowledge aware surrogates\nwould enable both an improved understanding of respiratory waveform changes\nwith different breathing disorders and different severities, and enhance the\ntraining of machine learning algorithms. To this end, we introduce an apparatus\ncomprising of PVC tubes and 3D printed parts as a simple yet effective method\nof simulating both obstructive and restrictive respiratory waveforms in healthy\nsubjects. Independent control over both inspiratory and expiratory resistances\nallows for the simulation of obstructive breathing disorders through the whole\nspectrum of FEV1/FVC spirometry ratios (used to classify COPD), ranging from\nhealthy values to values seen in severe chronic obstructive pulmonary disease.\nMoreover, waveform characteristics of breathing disorders, such as a change in\ninspiratory duty cycle or peak flow are also observed in the waveforms\nresulting from use of the artificial breathing disorder simulation apparatus.\nOverall, the proposed apparatus provides us with a simple, effective and\nphysically meaningful way to generate surrogate breathing disorder waveforms, a\nprerequisite for the use of artificial intelligence in respiratory health.",
    "descriptor": "",
    "authors": [
      "Harry J. Davies",
      "Ghena Hammour",
      "Danilo P. Mandic"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.06699"
  },
  {
    "id": "arXiv:2109.06700",
    "title": "Neural Upscaling from Residue-level Protein Structure Networks to  Atomistic Structure",
    "abstract": "Coarse-graining is a powerful tool for extending the reach of dynamic models\nof proteins and other biological macromolecules. Topological coarse-graining,\nin which biomolecules or sets thereof are represented via graph structures, is\na particularly useful way of obtaining highly compressed representations of\nmolecular structure, and simulations operating via such representations can\nachieve substantial computational savings. A drawback of coarse-graining,\nhowever, is the loss of atomistic detail - an effect that is especially acute\nfor topological representations such as protein structure networks (PSNs).\nHere, we introduce an approach based on a combination of machine learning and\nphysically-guided refinement for inferring atomic coordinates from PSNs. This\n\"neural upscaling\" procedure exploits the constraints implied by PSNs on\npossible configurations, as well as differences in the likelihood of observing\ndifferent configurations with the same PSN. Using a 1 $\\mu$s atomistic\nmolecular dynamics trajectory of A$\\beta_{1-40}$, we show that neural upscaling\nis able to effectively recapitulate detailed structural information for\nintrinsically disordered proteins, being particularly successful in recovering\nfeatures such as transient secondary structure. These results suggest that\nscalable network-based models for protein structure and dynamics may be used in\nsettings where atomistic detail is desired, with upscaling employed to impute\natomic coordinates from PSNs.",
    "descriptor": "",
    "authors": [
      "Vy Duong",
      "Elizabeth Diessner",
      "Gianmarc Grazioli",
      "Rachel W. Martin",
      "Carter T. Butts"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2109.06700"
  },
  {
    "id": "arXiv:2109.06709",
    "title": "QKD parameter estimation by two-universal hashing leads to faster  convergence to the asymptotic rate",
    "abstract": "This paper proposes and proves security of a QKD protocol which uses\ntwo-universal hashing instead of random sampling to estimate the number of bit\nflip and phase flip errors. For this protocol, the difference between\nasymptotic and finite key rate decreases with the number $n$ of qubits as\n$cn^{-1}$, where $c$ depends on the security parameter. For comparison, the\nsame difference decreases no faster than $c'n^{-1/3}$ for an optimized protocol\nthat uses random sampling and has the same asymptotic rate, where $c'$ depends\non the security parameter and the error rate.",
    "descriptor": "",
    "authors": [
      "Dimiter Ostrev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06709"
  },
  {
    "id": "arXiv:2109.06724",
    "title": "Orbital stabilization of underactuated mechanical systems without  Euler-Lagrange structure after of a collocated pre-feedback",
    "abstract": "In this note we study the generation of attractive oscillations of a class of\nmechanical systems with underactuation one. The proposed design consists of two\nterms, i.e., a partial linearizing state feedback, and an immersion and\ninvariance orbital stabilization controller. The first step is adopted to\nsimplify analysis and design, however, bringing an additional difficulty that\nthe model losses Euler-Lagrange structures after the collocated pre-feedback.\nTo address this, we propose a constructive solution to the orbital\nstabilization problem via a smooth controller in an analytic form, and the\nmodel class identified in the paper is characterized via some easily apriori\nverifiable assumptions on the inertia matrix and potential energy.",
    "descriptor": "",
    "authors": [
      "Jose Guadalupe Romero",
      "Bowen Yi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06724"
  },
  {
    "id": "arXiv:2109.06732",
    "title": "Tuna-AI: tuna biomass estimation with Machine Learning models trained on  oceanography and echosounder FAD data",
    "abstract": "Echo-sounder data registered by buoys attached to drifting FADs provide a\nvery valuablesource of information on populations of tuna and their behaviour.\nThis value increases whenthese data are supplemented with oceanographic data\ncoming from CMEMS. We use thesesources to develop Tuna-AI, a Machine Learning\nmodel aimed at predicting tuna biomassunder a given buoy, which uses a 3-day\nwindow of echo-sounder data to capture the dailyspatio-temporal patterns\ncharacteristic of tuna schools. As the supervised signal for training,we employ\nmore than5000set events with their corresponding tuna catch reported by theAGAC\ntuna purse seine fleet.",
    "descriptor": "",
    "authors": [
      "Daniel Precioso",
      "Manuel Navarro-Garc\u00eda",
      "Kathryn Gavira-O'Neill",
      "Alberto Torres-Barr\u00e1n",
      "David Gordo",
      "Victor Gallego-Alcal\u00e1",
      "David G\u00f3mez-Ullate"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06732"
  },
  {
    "id": "arXiv:2109.06755",
    "title": "Construction of $k$-matchings and $k$-regular subgraphs in graph  products",
    "abstract": "A $k$-matching $M$ of a graph $G=(V,E)$ is a subset $M\\subseteq E$ such that\neach connected component in the subgraph $F = (V,M)$ of $G$ is either a\nsingle-vertex graph or $k$-regular, i.e., each vertex has degree $k$. In this\ncontribution, we are interested in $k$-matchings within the four standard graph\nproducts: the Cartesian, strong, direct and lexicographic product.\nAs we shall see, the problem of finding non-empty $k$-matchings ($k\\geq 3$)\nin graph products is NP-complete. Due to the general intractability of this\nproblem, we focus on distinct polynomial-time constructions of $k$-matchings in\na graph product $G\\star H$ that are based on $k_G$-matchings $M_G$ and\n$k_H$-matchings $M_H$ of its factors $G$ and $H$, respectively. In particular,\nwe are interested in properties of the factors that have to be satisfied such\nthat these constructions yield a maximum $k$-matching in the respective\nproducts. Such constructions are also called \"well-behaved\" and we provide\nseveral characterizations for this type of $k$-matchings.\nOur specific constructions of $k$-matchings in graph products satisfy the\nproperty of being weak-homomorphism preserving, i.e., constructed matched edges\nin the product are never \"projected\" to unmatched edges in the factors. This\nleads to the concept of weak-homomorphism preserving $k$-matchings. Although\nthe specific $k$-matchings constructed here are not always maximum\n$k$-matchings of the products, they have always maximum size among all\nweak-homomorphism preserving $k$-matchings. Not all weak-homomorphism\npreserving $k$-matchings, however, can be constructed in our manner. We will,\ntherefore, determine the size of maximum-sized elements among all\nweak-homomorphims preserving $k$-matching within the respective graph products,\nprovided that the matchings in the factors satisfy some general assumptions.",
    "descriptor": "",
    "authors": [
      "Anna Lindeberg",
      "Marc Hellmuth"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06755"
  },
  {
    "id": "arXiv:2109.06756",
    "title": "ImUnity: a generalizable VAE-GAN solution for multicenter MR image  harmonization",
    "abstract": "ImUnity is an original deep-learning model designed for efficient and\nflexible MR image harmonization. A VAE-GAN network, coupled with a confusion\nmodule and an optional biological preservation module, uses multiple 2D-slices\ntaken from different anatomical locations in each subject of the training\ndatabase, as well as image contrast transformations for its self-supervised\ntraining. It eventually generates 'corrected' MR images that can be used for\nvarious multi-center population studies. Using 3 open source databases (ABIDE,\nOASIS and SRPBS), which contain MR images from multiple acquisition scanner\ntypes or vendors and a large range of subjects ages, we show that ImUnity: (1)\noutperforms state-of-the-art methods in terms of quality of images generated\nusing traveling subjects; (2) removes sites or scanner biases while improving\npatients classification; (3) harmonizes data coming from new sites or scanners\nwithout the need for an additional fine-tuning and (4) allows the selection of\nmultiple MR reconstructed images according to the desired applications. Tested\nhere on T1-weighted images, ImUnity could be used to harmonize other types of\nmedical images.",
    "descriptor": "\nComments: 15 pages, 7 Figures\n",
    "authors": [
      "Stenzel Cackowski",
      "Emmanuel L. Barbier",
      "Michel Dojat",
      "Thomas Christen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06756"
  },
  {
    "id": "arXiv:2109.06792",
    "title": "The Logic of Quantum Programs",
    "abstract": "We present a logical calculus for reasoning about information flow in quantum\nprograms. In particular we introduce a dynamic logic that is capable of dealing\nwith quantum measurements, unitary evolutions and entanglements in compound\nquantum systems. We give a syntax and a relational semantics in which we\nabstract away from phases and probabilities. We present a sound proof system\nfor this logic, and we show how to characterize by logical means various forms\nof entanglement (e.g. the Bell states) and various linear operators. As an\nexample we sketch an analysis of the teleportation protocol.",
    "descriptor": "\nComments: 18 pages, date 2004, presented at the 2nd International Workshop on Quantum Programming Languages, affiliated to LICS 2004\n",
    "authors": [
      "Alexandru Baltag",
      "Sonja Smets"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.06792"
  },
  {
    "id": "arXiv:2109.06824",
    "title": "Self-Supervised Metric Learning With Graph Clustering For Speaker  Diarization",
    "abstract": "In this paper, we propose a novel algorithm for speaker diarization using\nmetric learning for graph based clustering. The graph clustering algorithms use\nan adjacency matrix consisting of similarity scores. These scores are computed\nbetween speaker embeddings extracted from pairs of audio segments within the\ngiven recording. In this paper, we propose an approach that jointly learns the\nspeaker embeddings and the similarity metric using principles of\nself-supervised learning. The metric learning network implements a neural model\nof the probabilistic linear discriminant analysis (PLDA). The self-supervision\nis derived from the pseudo labels obtained from a previous iteration of\nclustering. The entire model of representation learning and metric learning is\ntrained with a binary cross entropy loss. By combining the self-supervision\nbased metric learning along with the graph-based clustering algorithm, we\nachieve significant relative improvements of 60% and 7% over the x-vector PLDA\nagglomerative hierarchical clustering (AHC) approach on AMI and the DIHARD\ndatasets respectively in terms of diarization error rates (DER).",
    "descriptor": "\nComments: 8 pages, Accepted in ASRU 2021\n",
    "authors": [
      "Prachi Singh",
      "Sriram Ganapathy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.06824"
  },
  {
    "id": "arXiv:2109.06847",
    "title": "Wrapping trust for interoperability. A study of wrapped tokens",
    "abstract": "As known, blockchains are traditionally blind to the real world. This implies\nthe reliance on third parties called oracles when extrinsic data is needed for\nsmart contracts. However, reintroducing trust and single point of failure,\noracles implementation is still controversial and debated. The blindness to the\nreal world makes blockchains also unable to communicate with each other\npreventing any form of interoperability. An early approach to the\ninteroperability issue is constituted by wrapped tokens, representing\nblockchain native tokens issued on a non-native blockchain. Similar to how\noracles reintroduce trust, and single point of failure, the issuance of wrapped\ntokens involves third parties whose characteristics need to be considered when\nevaluating the advantages of crossing-chains. This paper provides an overview\nof the wrapped tokens and the main technologies implemented in their issuance.\nAdvantages, as well as limitations, are also listed and discussed.",
    "descriptor": "\nComments: 14 pages, 4 figures and 1 table. Oriented to a conference\n",
    "authors": [
      "Giulio Caldarelli"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2109.06847"
  },
  {
    "id": "arXiv:2109.06849",
    "title": "A geometric perspective on functional outlier detection",
    "abstract": "We consider functional outlier detection from a geometric perspective,\nspecifically: for functional data sets drawn from a functional manifold which\nis defined by the data's modes of variation in amplitude and phase. Based on\nthis manifold, we develop a conceptualization of functional outlier detection\nthat is more widely applicable and realistic than previously proposed. Our\ntheoretical and experimental analyses demonstrate several important advantages\nof this perspective: It considerably improves theoretical understanding and\nallows to describe and analyse complex functional outlier scenarios\nconsistently and in full generality, by differentiating between structurally\nanomalous outlier data that are off-manifold and distributionally outlying data\nthat are on-manifold but at its margins. This improves practical feasibility of\nfunctional outlier detection: We show that simple manifold learning methods can\nbe used to reliably infer and visualize the geometric structure of functional\ndata sets. We also show that standard outlier detection methods requiring\ntabular data inputs can be applied to functional data very successfully by\nsimply using their vector-valued representations learned from manifold learning\nmethods as input features. Our experiments on synthetic and real data sets\ndemonstrate that this approach leads to outlier detection performances at least\non par with existing functional data-specific methods in a large variety of\nsettings, without the highly specialized, complex methodology and narrow domain\nof application these methods often entail.",
    "descriptor": "\nComments: 40 pages, 20 figures\n",
    "authors": [
      "Moritz Herrmann",
      "Fabian Scheipl"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.06849"
  },
  {
    "id": "arXiv:2109.06856",
    "title": "Performance of a Markovian neural network versus dynamic programming on  a fishing control problem",
    "abstract": "Fishing quotas are unpleasant but efficient to control the productivity of a\nfishing site. A popular model has a stochastic differential equation for the\nbiomass on which a stochastic dynamic programming or a Hamilton-Jacobi-Bellman\nalgorithm can be used to find the stochastic control -- the fishing quota. We\ncompare the solutions obtained by dynamic programming against those obtained\nwith a neural network which preserves the Markov property of the solution. The\nmethod is extended to a similar multi species model to check its robustness in\nhigh dimension.",
    "descriptor": "",
    "authors": [
      "Mathieu Lauri\u00e8re",
      "Gilles Pag\u00e8s",
      "Olivier Pironneau"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06856"
  },
  {
    "id": "arXiv:1612.02547",
    "title": "Self-composable Programming",
    "abstract": "Comments: limitations of evaluation",
    "descriptor": "\nComments: limitations of evaluation\n",
    "authors": [
      "Hiun Kim"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/1612.02547"
  },
  {
    "id": "arXiv:1612.07844",
    "title": "Linear Time Logics -- A Coalgebraic Perspective",
    "abstract": "Comments: Major revision: Section 4 is new. Section 5 and 6 are revised to make use of Section 4. Section 7 contains new results compared to the previous version",
    "descriptor": "\nComments: Major revision: Section 4 is new. Section 5 and 6 are revised to make use of Section 4. Section 7 contains new results compared to the previous version\n",
    "authors": [
      "Corina Cirstea"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1612.07844"
  },
  {
    "id": "arXiv:1707.02590",
    "title": "Refinable Function : An Object-oriented Approach to Procedure Modularity",
    "abstract": "Comments: limitations of evaluation",
    "descriptor": "\nComments: limitations of evaluation\n",
    "authors": [
      "Hiun Kim"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/1707.02590"
  },
  {
    "id": "arXiv:1805.02094",
    "title": "Exploring Hyper-Parameter Optimization for Neural Machine Translation on  GPU Architectures",
    "abstract": "Comments: 2018 2nd Naval Applications for Machine Learning",
    "descriptor": "\nComments: 2018 2nd Naval Applications for Machine Learning\n",
    "authors": [
      "Robert Lim",
      "Kenneth Heafield",
      "Hieu Hoang",
      "Mark Briers",
      "Allen Malony"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1805.02094"
  },
  {
    "id": "arXiv:1808.06979",
    "title": "Thresholding at the monopoly price: an agnostic way to improve bidding  strategies in revenue-maximizing auctions",
    "abstract": "Thresholding at the monopoly price: an agnostic way to improve bidding  strategies in revenue-maximizing auctions",
    "descriptor": "",
    "authors": [
      "Thomas Nedelec",
      "Marc Abeille",
      "Cl\u00e9ment Calauz\u00e8nes",
      "Benjamin Heymann",
      "Vianney Perchet",
      "Noureddine El Karoui"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1808.06979"
  },
  {
    "id": "arXiv:1809.08169",
    "title": "On sets of terms with a given intersection type",
    "abstract": "On sets of terms with a given intersection type",
    "descriptor": "",
    "authors": [
      "Andrew Polonsky",
      "Richard Statman"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1809.08169"
  },
  {
    "id": "arXiv:1901.10333",
    "title": "Stochastic fractional integro-differential equations with weakly  singular kernels: Well-posedness and Euler--Maruyama approximation",
    "abstract": "Stochastic fractional integro-differential equations with weakly  singular kernels: Well-posedness and Euler--Maruyama approximation",
    "descriptor": "",
    "authors": [
      "Xinjie Dai",
      "Aiguo Xiao",
      "Weiping Bu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1901.10333"
  },
  {
    "id": "arXiv:1906.04376",
    "title": "Recognizing License Plates in Real-Time",
    "abstract": "Comments: License Plate Detection and Recognition, Computer Vision, Supervised Learning",
    "descriptor": "\nComments: License Plate Detection and Recognition, Computer Vision, Supervised Learning\n",
    "authors": [
      "Xuewen Yang",
      "Xin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1906.04376"
  },
  {
    "id": "arXiv:1906.11632",
    "title": "A Survey on GANs for Anomaly Detection",
    "abstract": "A Survey on GANs for Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Federico Di Mattia",
      "Paolo Galeone",
      "Michele De Simoni",
      "Emanuele Ghelfi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.11632"
  },
  {
    "id": "arXiv:1909.10330",
    "title": "Formations and generalized Davenport-Schinzel sequences",
    "abstract": "Formations and generalized Davenport-Schinzel sequences",
    "descriptor": "",
    "authors": [
      "Jesse Geneson",
      "Peter Tian",
      "Katherine Tung"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1909.10330"
  },
  {
    "id": "arXiv:1909.12205",
    "title": "Adaptive Binary-Ternary Quantization",
    "abstract": "Adaptive Binary-Ternary Quantization",
    "descriptor": "",
    "authors": [
      "Ryan Razani",
      "Gr\u00e9goire Morin",
      "Vahid Partovi Nia",
      "Eyy\u00fcb Sari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.12205"
  },
  {
    "id": "arXiv:1910.12747",
    "title": "Introduction to local certification",
    "abstract": "Comments: Final version for DMTCS",
    "descriptor": "\nComments: Final version for DMTCS\n",
    "authors": [
      "Laurent Feuilloley"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1910.12747"
  },
  {
    "id": "arXiv:2002.00797",
    "title": "Stochastic geometry to generalize the Mondrian Process",
    "abstract": "Stochastic geometry to generalize the Mondrian Process",
    "descriptor": "",
    "authors": [
      "Eliza O'Reilly",
      "Ngoc Tran"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2002.00797"
  },
  {
    "id": "arXiv:2004.09926",
    "title": "Regular matching problems for infinite trees",
    "abstract": "Comments: 35 pages, including an appendix. We corrected several typos and misprints. We added more detailed explanations in various proofs and we gave more examples. The appendix on infinite words was rewritten",
    "descriptor": "\nComments: 35 pages, including an appendix. We corrected several typos and misprints. We added more detailed explanations in various proofs and we gave more examples. The appendix on infinite words was rewritten\n",
    "authors": [
      "Carlos Camino",
      "Volker Diekert",
      "Besik Dundua",
      "Mircea Marin",
      "G\u00e9raud S\u00e9nizergues"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2004.09926"
  },
  {
    "id": "arXiv:2005.00033",
    "title": "Fighting the COVID-19 Infodemic: Modeling the Perspective of  Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the  Society",
    "abstract": "Comments: disinformation, misinformation, factuality, fact-checking, fact-checkers, check-worthiness, Social Media Platforms, COVID-19, social media",
    "descriptor": "\nComments: disinformation, misinformation, factuality, fact-checking, fact-checkers, check-worthiness, Social Media Platforms, COVID-19, social media\n",
    "authors": [
      "Firoj Alam",
      "Shaden Shaar",
      "Fahim Dalvi",
      "Hassan Sajjad",
      "Alex Nikolov",
      "Hamdy Mubarak",
      "Giovanni Da San Martino",
      "Ahmed Abdelali",
      "Nadir Durrani",
      "Kareem Darwish",
      "Abdulaziz Al-Homaid",
      "Wajdi Zaghouani",
      "Tommaso Caselli",
      "Gijs Danoe",
      "Friso Stolk",
      "Britt Bruntink",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2005.00033"
  },
  {
    "id": "arXiv:2005.02205",
    "title": "When Machine Unlearning Jeopardizes Privacy",
    "abstract": "When Machine Unlearning Jeopardizes Privacy",
    "descriptor": "",
    "authors": [
      "Min Chen",
      "Zhikun Zhang",
      "Tianhao Wang",
      "Michael Backes",
      "Mathias Humbert",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.02205"
  },
  {
    "id": "arXiv:2005.11223",
    "title": "L2R2: Leveraging Ranking for Abductive Reasoning",
    "abstract": "Comments: SIGIR 2020",
    "descriptor": "\nComments: SIGIR 2020\n",
    "authors": [
      "Yunchang Zhu",
      "Liang Pang",
      "Yanyan Lan",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2005.11223"
  },
  {
    "id": "arXiv:2005.12772",
    "title": "How to see the eight Thurston geometries",
    "abstract": "How to see the eight Thurston geometries",
    "descriptor": "",
    "authors": [
      "Tiago Novello",
      "Vin\u00edcius da Silva",
      "Luiz Velho",
      "Mikhail Belolipetsky"
    ],
    "subjectives": [
      "Geometric Topology (math.GT)",
      "Graphics (cs.GR)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2005.12772"
  },
  {
    "id": "arXiv:2006.02420",
    "title": "Learning to Scan: A Deep Reinforcement Learning Approach for  Personalized Scanning in CT Imaging",
    "abstract": "Learning to Scan: A Deep Reinforcement Learning Approach for  Personalized Scanning in CT Imaging",
    "descriptor": "",
    "authors": [
      "Ziju Shen",
      "Yufei Wang",
      "Dufan Wu",
      "Xu Yang",
      "Bin Dong"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2006.02420"
  },
  {
    "id": "arXiv:2006.03151",
    "title": "Hidden Markov models as recurrent neural networks: an application to  Alzheimer's disease",
    "abstract": "Hidden Markov models as recurrent neural networks: an application to  Alzheimer's disease",
    "descriptor": "",
    "authors": [
      "Matt Baucum",
      "Anahita Khojandi",
      "Theodore Papamarkou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2006.03151"
  },
  {
    "id": "arXiv:2006.05021",
    "title": "CLAIMED: A CLAssification-Incorporated Minimum Energy Design to explore  a multivariate response surface with feasibility constraints",
    "abstract": "CLAIMED: A CLAssification-Incorporated Minimum Energy Design to explore  a multivariate response surface with feasibility constraints",
    "descriptor": "",
    "authors": [
      "Mert Y. Sengul",
      "Yao Song",
      "Linglin He",
      "Adri C. T. van Duin",
      "Ying Hung",
      "Tirthankar Dasgupta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.05021"
  },
  {
    "id": "arXiv:2006.10604",
    "title": "Compositional theories for host-core languages",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Davide Trotta",
      "Margherita Zorzi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2006.10604"
  },
  {
    "id": "arXiv:2006.10641",
    "title": "Information Extraction from a Strategic Sender: The Zero Error Case",
    "abstract": "Comments: Submitted to the IEEE Transactions on Information Theory",
    "descriptor": "\nComments: Submitted to the IEEE Transactions on Information Theory\n",
    "authors": [
      "Anuj S. Vora",
      "Ankur A. Kulkarni"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.10641"
  },
  {
    "id": "arXiv:2006.15032",
    "title": "Numerical analysis of a structure-preserving space-discretization for an  anisotropic and heterogeneous boundary controlled N-dimensional wave equation  as port-Hamiltonian system",
    "abstract": "Comments: 35 pages, 1 figure, submitted",
    "descriptor": "\nComments: 35 pages, 1 figure, submitted\n",
    "authors": [
      "Ghislain Haine",
      "Denis Matignon",
      "Anass Serhani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2006.15032"
  },
  {
    "id": "arXiv:2006.16978",
    "title": "Randomized Kaczmarz converges along small singular vectors",
    "abstract": "Randomized Kaczmarz converges along small singular vectors",
    "descriptor": "",
    "authors": [
      "Stefan Steinerberger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2006.16978"
  },
  {
    "id": "arXiv:2007.02910",
    "title": "A Weighted Randomized Kaczmarz Method for Solving Linear Systems",
    "abstract": "A Weighted Randomized Kaczmarz Method for Solving Linear Systems",
    "descriptor": "",
    "authors": [
      "Stefan Steinerberger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2007.02910"
  },
  {
    "id": "arXiv:2008.05801",
    "title": "An explicit construction of graphs of bounded degree that are far from  being Hamiltonian",
    "abstract": "Comments: 16 pages, 4 figures",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Isolde Adler",
      "Noleen K\u00f6hler"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2008.05801"
  },
  {
    "id": "arXiv:2008.07682",
    "title": "Residual Learning from Demonstration: Adapting DMPs for Contact-rich  Manipulation",
    "abstract": "Residual Learning from Demonstration: Adapting DMPs for Contact-rich  Manipulation",
    "descriptor": "",
    "authors": [
      "Todor Davchev",
      "Kevin Sebastian Luck",
      "Michael Burke",
      "Franziska Meier",
      "Stefan Schaal",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2008.07682"
  },
  {
    "id": "arXiv:2008.08170",
    "title": "Accelerated Zeroth-Order and First-Order Momentum Methods from Mini to  Minimax Optimization",
    "abstract": "Comments: 66 pages, 2 tables, 4 figures. We fix some minor errors in our paper",
    "descriptor": "\nComments: 66 pages, 2 tables, 4 figures. We fix some minor errors in our paper\n",
    "authors": [
      "Feihu Huang",
      "Shangqian Gao",
      "Jian Pei",
      "Heng Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.08170"
  },
  {
    "id": "arXiv:2009.01567",
    "title": "MAX CUT in Weighted Random Intersection Graphs and Discrepancy of Sparse  Random Set Systems",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Sotiris Nikoletseas",
      "Christoforos Raptopoulos",
      "Paul Spirakis"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2009.01567"
  },
  {
    "id": "arXiv:2009.04550",
    "title": "Biclustering with Alternating K-Means",
    "abstract": "Biclustering with Alternating K-Means",
    "descriptor": "",
    "authors": [
      "Nicolas Fraiman",
      "Zichao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04550"
  },
  {
    "id": "arXiv:2009.06689",
    "title": "Online learning-based trajectory tracking for underactuated vehicles  with uncertain dynamics",
    "abstract": "Online learning-based trajectory tracking for underactuated vehicles  with uncertain dynamics",
    "descriptor": "",
    "authors": [
      "Thomas Beckers",
      "Leonardo Colombo",
      "Sandra Hirche",
      "George J. Pappas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.06689"
  },
  {
    "id": "arXiv:2010.00952",
    "title": "Distributed Proximal Splitting Algorithms with Rates and Acceleration",
    "abstract": "Distributed Proximal Splitting Algorithms with Rates and Acceleration",
    "descriptor": "",
    "authors": [
      "Laurent Condat",
      "Grigory Malinovsky",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.00952"
  },
  {
    "id": "arXiv:2010.03743",
    "title": "Visual News: Benchmark and Challenges in News Image Captioning",
    "abstract": "Comments: 9 pages, 5 figures, accepted to EMNLP2021",
    "descriptor": "\nComments: 9 pages, 5 figures, accepted to EMNLP2021\n",
    "authors": [
      "Fuxiao Liu",
      "Yinghan Wang",
      "Tianlu Wang",
      "Vicente Ordonez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.03743"
  },
  {
    "id": "arXiv:2010.07226",
    "title": "Discriminating Equivalent Algorithms via Relative Performance",
    "abstract": "Discriminating Equivalent Algorithms via Relative Performance",
    "descriptor": "",
    "authors": [
      "Aravind Sankaran",
      "Paolo Bientinesi"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.07226"
  },
  {
    "id": "arXiv:2010.08238",
    "title": "Toward Evaluating Re-identification Risks in the Local Privacy Model",
    "abstract": "Comments: Accepted at Transactions on Data Privacy",
    "descriptor": "\nComments: Accepted at Transactions on Data Privacy\n",
    "authors": [
      "Takao Murakami",
      "Kenta Takahashi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2010.08238"
  },
  {
    "id": "arXiv:2010.11536",
    "title": "Joint Use of Node Attributes and Proximity for Semi-Supervised  Classification on Graphs",
    "abstract": "Comments: 17 pages, 5 figures",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Arpit Merchant",
      "Michael Mathioudakis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.11536"
  },
  {
    "id": "arXiv:2010.14666",
    "title": "Equivariant Filter (EqF)",
    "abstract": "Comments: 19 pages, 3 figures, submitted to IEEE TAC",
    "descriptor": "\nComments: 19 pages, 3 figures, submitted to IEEE TAC\n",
    "authors": [
      "Pieter van Goor",
      "Tarek Hamel",
      "Robert Mahony"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.14666"
  },
  {
    "id": "arXiv:2011.03106",
    "title": "IMU-Assisted Learning of Single-View Rolling Shutter Correction",
    "abstract": "IMU-Assisted Learning of Single-View Rolling Shutter Correction",
    "descriptor": "",
    "authors": [
      "Jiawei Mo",
      "Md Jahidul Islam",
      "Junaed Sattar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.03106"
  },
  {
    "id": "arXiv:2011.03424",
    "title": "Session-aware Recommendation: A Surprising Quest for the  State-of-the-art",
    "abstract": "Session-aware Recommendation: A Surprising Quest for the  State-of-the-art",
    "descriptor": "",
    "authors": [
      "Sara Latifi",
      "Noemi Mauro",
      "Dietmar Jannach"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2011.03424"
  },
  {
    "id": "arXiv:2011.03748",
    "title": "B-GAP: Behavior-Guided Action Prediction and Navigation for Autonomous  Driving",
    "abstract": "Comments: Submitted to RA-L and ICRA 2022",
    "descriptor": "\nComments: Submitted to RA-L and ICRA 2022\n",
    "authors": [
      "Angelos Mavrogiannis",
      "Rohan Chandra",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.03748"
  },
  {
    "id": "arXiv:2011.08225",
    "title": "Automatic selection of clustering algorithms using supervised graph  embedding",
    "abstract": "Automatic selection of clustering algorithms using supervised graph  embedding",
    "descriptor": "",
    "authors": [
      "Noy Cohen-Shapira",
      "Lior Rokach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.08225"
  },
  {
    "id": "arXiv:2011.13127",
    "title": "Copy-and-Patch Binary Code Generation",
    "abstract": "Copy-and-Patch Binary Code Generation",
    "descriptor": "",
    "authors": [
      "Haoran Xu",
      "Fredrik Kjolstad"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2011.13127"
  },
  {
    "id": "arXiv:2012.03477",
    "title": "Document Graph for Neural Machine Translation",
    "abstract": "Comments: Accepted by EMNLP2021",
    "descriptor": "\nComments: Accepted by EMNLP2021\n",
    "authors": [
      "Mingzhou Xu",
      "Liangyou Li",
      "Derek. F. Wong",
      "Qun Liu",
      "Lidia S. Chao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.03477"
  },
  {
    "id": "arXiv:2012.09855",
    "title": "Infinite Nature: Perpetual View Generation of Natural Scenes from a  Single Image",
    "abstract": "Comments: ICCV 2021 (oral); Project page: this https URL; Video: this https URL",
    "descriptor": "\nComments: ICCV 2021 (oral); Project page: this https URL; Video: this https URL\n",
    "authors": [
      "Andrew Liu",
      "Richard Tucker",
      "Varun Jampani",
      "Ameesh Makadia",
      "Noah Snavely",
      "Angjoo Kanazawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2012.09855"
  },
  {
    "id": "arXiv:2101.00373",
    "title": "Non-line-of-Sight Imaging via Neural Transient Fields",
    "abstract": "Non-line-of-Sight Imaging via Neural Transient Fields",
    "descriptor": "",
    "authors": [
      "Siyuan Shen",
      "Zi Wang",
      "Ping Liu",
      "Zhengqing Pan",
      "Ruiqian Li",
      "Tian Gao",
      "Shiying Li",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.00373"
  },
  {
    "id": "arXiv:2101.04255",
    "title": "Quantum Mathematics in Artificial Intelligence",
    "abstract": "Comments: Manuscript updated with research from the past few months and an appendix on quantum category theory",
    "descriptor": "\nComments: Manuscript updated with research from the past few months and an appendix on quantum category theory\n",
    "authors": [
      "Dominic Widdows",
      "Kirsty Kitto",
      "Trevor Cohen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2101.04255"
  },
  {
    "id": "arXiv:2101.07779",
    "title": "Agile Scrum Development in an ad hoc Software Collaboration",
    "abstract": "Comments: Revisions: expanded introduction, discussion, and conclusion; reorganized section content; revised abstract, references, and descriptions of the collaboration; added Related Works section. Results unchanged",
    "descriptor": "\nComments: Revisions: expanded introduction, discussion, and conclusion; reorganized section content; revised abstract, references, and descriptions of the collaboration; added Related Works section. Results unchanged\n",
    "authors": [
      "A. L. Baxter",
      "S. Y. BenZvi",
      "W. Bonivento",
      "A. Brazier",
      "M. Clark",
      "A. Coleiro",
      "D. Collom",
      "M. Colomer-Molla",
      "B. Cousins",
      "A. Delgado Orellana",
      "D. Dornic",
      "V. Ekimtcov",
      "S. ElSayed",
      "A. Gallo Rosso",
      "P. Godwin",
      "S. Griswold",
      "A. Habig",
      "S. Horiuchi",
      "D. A. Howell",
      "M. W. G. Johnson",
      "M. Juric",
      "J. P. Kneller",
      "A. Kopec",
      "C. Kopper",
      "V. Kulikovskiy",
      "M. Lamoureux",
      "R. F. Lang",
      "S. Li",
      "M. Lincetto",
      "W. Lindstrom",
      "M. W. Linvill",
      "C. McCully",
      "J. Migenda",
      "D. Milisavljevic",
      "S. Nelson",
      "R. Novoseltseva",
      "E. O'Sullivan",
      "D. Petravick",
      "B. W. Pointon",
      "N. Raj",
      "A. Renshaw",
      "J. Rumleskie",
      "R. Tapia",
      "J. C. L. Tseng",
      "C. D. Tunnell",
      "C. F. Vigorito",
      "C. J. Virtue",
      "C. Weaver",
      "L. Winslow",
      "R. Wolski",
      "X. J. Xu",
      "Y. Xu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2101.07779"
  },
  {
    "id": "arXiv:2101.08237",
    "title": "An Empirical Study and Analysis on Open-Set Semi-Supervised Learning",
    "abstract": "An Empirical Study and Analysis on Open-Set Semi-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Huixiang Luo",
      "Hao Cheng",
      "Fanxu Meng",
      "Yuting Gao",
      "Ke Li",
      "Mengdan Zhang",
      "Xing Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.08237"
  },
  {
    "id": "arXiv:2101.11148",
    "title": "Functional Observers with Linear Error Dynamics for Nonlinear Systems",
    "abstract": "Functional Observers with Linear Error Dynamics for Nonlinear Systems",
    "descriptor": "",
    "authors": [
      "Costas Kravaris",
      "Sunjeev Venkateswaran"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.11148"
  },
  {
    "id": "arXiv:2101.11597",
    "title": "Dexterous Manipulation Primitives for the Real Robot Challenge",
    "abstract": "Comments: For a video of our method, see this https URL&list=PLt9QxrtaftrHGXcp4Oh8-s_OnQnBnLtei&index=1 . For our code, visit this https URL",
    "descriptor": "\nComments: For a video of our method, see this https URL&list=PLt9QxrtaftrHGXcp4Oh8-s_OnQnBnLtei&index=1 . For our code, visit this https URL\n",
    "authors": [
      "Claire Chen",
      "Krishnan Srinivasan",
      "Jeffrey Zhang",
      "Junwu Zhang",
      "Lin Shao",
      "Shenli Yuan",
      "Preston Culbertson",
      "Hongkai Dai",
      "Mac Schwager",
      "Jeannette Bohg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.11597"
  },
  {
    "id": "arXiv:2102.01621",
    "title": "Depth separation beyond radial functions",
    "abstract": "Depth separation beyond radial functions",
    "descriptor": "",
    "authors": [
      "Luca Venturi",
      "Samy Jelassi",
      "Tristan Ozuch",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.01621"
  },
  {
    "id": "arXiv:2102.03266",
    "title": "Transductive Zero-Shot Learning by Decoupled Feature Generation",
    "abstract": "Comments: Published at the IEEE/CVF Winter Conference on Computer Vision (WACV) 2021",
    "descriptor": "\nComments: Published at the IEEE/CVF Winter Conference on Computer Vision (WACV) 2021\n",
    "authors": [
      "Federico Marmoreo",
      "Jacopo Cavazza",
      "Vittorio Murino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.03266"
  },
  {
    "id": "arXiv:2102.03603",
    "title": "On frequency- and time-limited H2-optimal model order reduction",
    "abstract": "On frequency- and time-limited H2-optimal model order reduction",
    "descriptor": "",
    "authors": [
      "Umair Zulfiqar",
      "Victor Sreeram",
      "Xin Du"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.03603"
  },
  {
    "id": "arXiv:2102.04014",
    "title": "Point-set Distances for Learning Representations of 3D Point Clouds",
    "abstract": "Comments: ICCV 2021 camera-ready paper (8 pages) with supplementary (3.5 pages)",
    "descriptor": "\nComments: ICCV 2021 camera-ready paper (8 pages) with supplementary (3.5 pages)\n",
    "authors": [
      "Trung Nguyen",
      "Quang-Hieu Pham",
      "Tam Le",
      "Tung Pham",
      "Nhat Ho",
      "Binh-Son Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.04014"
  },
  {
    "id": "arXiv:2102.05766",
    "title": "Fused Acoustic and Text Encoding for Multimodal Bilingual Pretraining  and Speech Translation",
    "abstract": "Fused Acoustic and Text Encoding for Multimodal Bilingual Pretraining  and Speech Translation",
    "descriptor": "",
    "authors": [
      "Renjie Zheng",
      "Junkun Chen",
      "Mingbo Ma",
      "Liang Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.05766"
  },
  {
    "id": "arXiv:2102.06570",
    "title": "User manual for bch, a program for the fast computation of the  Baker-Campbell-Hausdorff and similar series",
    "abstract": "User manual for bch, a program for the fast computation of the  Baker-Campbell-Hausdorff and similar series",
    "descriptor": "",
    "authors": [
      "Harald Hofst\u00e4tter"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2102.06570"
  },
  {
    "id": "arXiv:2102.07899",
    "title": "A Deep-Learning Approach For Direct Whole-Heart Mesh Reconstruction",
    "abstract": "A Deep-Learning Approach For Direct Whole-Heart Mesh Reconstruction",
    "descriptor": "",
    "authors": [
      "Fanwei Kong",
      "Nathan Wilson",
      "Shawn C. Shadden"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07899"
  },
  {
    "id": "arXiv:2102.08109",
    "title": "Arboreal Categories: An Axiomatic Theory of Resources",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Samson Abramsky",
      "Luca Reggio"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.08109"
  },
  {
    "id": "arXiv:2102.08703",
    "title": "Local Mending",
    "abstract": "Local Mending",
    "descriptor": "",
    "authors": [
      "Alkida Balliu",
      "Juho Hirvonen",
      "Darya Melnyk",
      "Dennis Olivetti",
      "Joel Rybicki",
      "Jukka Suomela"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.08703"
  },
  {
    "id": "arXiv:2102.12564",
    "title": "Triplet loss based embeddings for forensic speaker identification in  Spanish",
    "abstract": "Comments: Long Paper: Neural Computing and Applications, Special Issue on LatinX in AI Research (2021). 11 pages, 5 figures",
    "descriptor": "\nComments: Long Paper: Neural Computing and Applications, Special Issue on LatinX in AI Research (2021). 11 pages, 5 figures\n",
    "authors": [
      "Emmanuel Maqueda",
      "Javier Alvarez-Jimenez",
      "Carlos Mena",
      "Ivan Meza"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2102.12564"
  },
  {
    "id": "arXiv:2103.01306",
    "title": "Scalable Scene Flow from Point Clouds in the Real World",
    "abstract": "Scalable Scene Flow from Point Clouds in the Real World",
    "descriptor": "",
    "authors": [
      "Philipp Jund",
      "Chris Sweeney",
      "Nichola Abdo",
      "Zhifeng Chen",
      "Jonathon Shlens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01306"
  },
  {
    "id": "arXiv:2103.01378",
    "title": "Contrastive Explanations for Model Interpretability",
    "abstract": "Comments: Accepted to EMNLP 2021 as a long paper",
    "descriptor": "\nComments: Accepted to EMNLP 2021 as a long paper\n",
    "authors": [
      "Alon Jacovi",
      "Swabha Swayamdipta",
      "Shauli Ravfogel",
      "Yanai Elazar",
      "Yejin Choi",
      "Yoav Goldberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01378"
  },
  {
    "id": "arXiv:2103.03809",
    "title": "PalmTree: Learning an Assembly Language Model for Instruction Embedding",
    "abstract": "PalmTree: Learning an Assembly Language Model for Instruction Embedding",
    "descriptor": "",
    "authors": [
      "Xuezixiang Li",
      "Qu Yu",
      "Heng Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2103.03809"
  },
  {
    "id": "arXiv:2103.03854",
    "title": "A Pilot Study on Visually Stimulated Cognitive Tasks for EEG-Based  Dementia Recognition",
    "abstract": "A Pilot Study on Visually Stimulated Cognitive Tasks for EEG-Based  Dementia Recognition",
    "descriptor": "",
    "authors": [
      "Supavit Kongwudhikunakorn",
      "Suktipol Kiatthaveephong",
      "Kamonwan Thanontip",
      "Pitshaporn Leelaarporn",
      "Maytus Piriyajitakonkij",
      "Thananya Charoenpattarawut",
      "Phairot Autthasan",
      "Rattanaphon Chaisaen",
      "Pathitta Dujada",
      "Thapanun Sudhawiyangkul",
      "Vorapun Senanarong",
      "Theerawit Wilaiprasitporn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2103.03854"
  },
  {
    "id": "arXiv:2103.03923",
    "title": "Surface Warping Incorporating Machine Learning Assisted Domain  Likelihood Estimation: A New Paradigm in Mine Geology Modelling and  Automation",
    "abstract": "Comments: Keywords: Bayesian computation, machine learning, ensemble classifiers, neural network, mesh geometry, surface warping, geochemistry, domain likelihood, geological boundaries. 23 pages, 15 figures, 11 tables",
    "descriptor": "\nComments: Keywords: Bayesian computation, machine learning, ensemble classifiers, neural network, mesh geometry, surface warping, geochemistry, domain likelihood, geological boundaries. 23 pages, 15 figures, 11 tables\n",
    "authors": [
      "Raymond Leung",
      "Mehala Balamurali",
      "Alexander Lowe"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.03923"
  },
  {
    "id": "arXiv:2103.09154",
    "title": "Leveraging Recent Advances in Deep Learning for Audio-Visual Emotion  Recognition",
    "abstract": "Comments: 8 pages, 3 figures, Pattern Recognition Letters",
    "descriptor": "\nComments: 8 pages, 3 figures, Pattern Recognition Letters\n",
    "authors": [
      "Liam Schoneveld",
      "Alice Othmani",
      "Hazem Abdelkawy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.09154"
  },
  {
    "id": "arXiv:2103.11109",
    "title": "DataLens: Scalable Privacy Preserving Training via Gradient Compression  and Aggregation",
    "abstract": "Comments: Accepted to ACM CCS 2021. 23 pages, 4 figures, 12 tables",
    "descriptor": "\nComments: Accepted to ACM CCS 2021. 23 pages, 4 figures, 12 tables\n",
    "authors": [
      "Boxin Wang",
      "Fan Wu",
      "Yunhui Long",
      "Luka Rimanic",
      "Ce Zhang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.11109"
  },
  {
    "id": "arXiv:2103.11949",
    "title": "Reinforcement Learning based on Scenario-tree MPC for ASVs",
    "abstract": "Comments: This paper has been accepted to 2021 American Control Conference (ACC). 6 pages, 9 figures",
    "descriptor": "\nComments: This paper has been accepted to 2021 American Control Conference (ACC). 6 pages, 9 figures\n",
    "authors": [
      "Arash Bahari Kordabad",
      "Hossein Nejatbakhsh Esfahani",
      "Anastasios M. Lekkas",
      "S\u00e9bastien Gros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.11949"
  },
  {
    "id": "arXiv:2103.11955",
    "title": "Improving and Simplifying Pattern Exploiting Training",
    "abstract": "Comments: EMNLP 2021 (12 pages, 2 figures)",
    "descriptor": "\nComments: EMNLP 2021 (12 pages, 2 figures)\n",
    "authors": [
      "Derek Tam",
      "Rakesh R Menon",
      "Mohit Bansal",
      "Shashank Srivastava",
      "Colin Raffel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.11955"
  },
  {
    "id": "arXiv:2103.12437",
    "title": "Learning without Seeing nor Knowing: Towards Open Zero-Shot Learning",
    "abstract": "Learning without Seeing nor Knowing: Towards Open Zero-Shot Learning",
    "descriptor": "",
    "authors": [
      "Federico Marmoreo",
      "Julio Ivan Davila Carrazco",
      "Vittorio Murino",
      "Jacopo Cavazza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12437"
  },
  {
    "id": "arXiv:2103.14373",
    "title": "D2C-SR: A Divergence to Convergence Approach for Real-World Image  Super-Resolution",
    "abstract": "Comments: 14 pages, 12 figures",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Youwei Li",
      "Haibin Huang",
      "Lanpeng Jia",
      "Haoqiang Fan",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14373"
  },
  {
    "id": "arXiv:2103.14583",
    "title": "Leveraging pre-trained representations to improve access to  untranscribed speech from endangered languages",
    "abstract": "Comments: Accepted at ASRU 2021",
    "descriptor": "\nComments: Accepted at ASRU 2021\n",
    "authors": [
      "Nay San",
      "Martijn Bartelds",
      "Mitchell Browne",
      "Lily Clifford",
      "Fiona Gibson",
      "John Mansfield",
      "David Nash",
      "Jane Simpson",
      "Myfany Turpin",
      "Maria Vollmer",
      "Sasha Wilmoth",
      "Dan Jurafsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.14583"
  },
  {
    "id": "arXiv:2103.15341",
    "title": "Stiff Neural Ordinary Differential Equations",
    "abstract": "Stiff Neural Ordinary Differential Equations",
    "descriptor": "",
    "authors": [
      "Suyong Kim",
      "Weiqi Ji",
      "Sili Deng",
      "Yingbo Ma",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.15341"
  },
  {
    "id": "arXiv:2104.00785",
    "title": "Unitarization Through Approximate Basis",
    "abstract": "Comments: Review Significantly improves presentation of results, adds more details",
    "descriptor": "\nComments: Review Significantly improves presentation of results, adds more details\n",
    "authors": [
      "Joshua Cook"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2104.00785"
  },
  {
    "id": "arXiv:2104.04103",
    "title": "Causal Decision Making and Causal Effect Estimation Are Not the Same...  and Why It Matters",
    "abstract": "Causal Decision Making and Causal Effect Estimation Are Not the Same...  and Why It Matters",
    "descriptor": "",
    "authors": [
      "Carlos Fern\u00e1ndez-Lor\u00eda",
      "Foster Provost"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04103"
  },
  {
    "id": "arXiv:2104.04515",
    "title": "Connecting Attributions and QA Model Behavior on Realistic  Counterfactuals",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Xi Ye",
      "Rohan Nair",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.04515"
  },
  {
    "id": "arXiv:2104.05178",
    "title": "Polar-Precoding: A Unitary Finite-Feedback Transmit Precoder for  Polar-Coded MIMO Systems",
    "abstract": "Comments: Polar-coded MIMO system, polarization criterion, precoding, unitary matrix",
    "descriptor": "\nComments: Polar-coded MIMO system, polarization criterion, precoding, unitary matrix\n",
    "authors": [
      "Jinnan Piao",
      "Kai Niu",
      "Jincheng Dai",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.05178"
  },
  {
    "id": "arXiv:2104.07500",
    "title": "Learning Zero-Shot Multifaceted Visually Grounded Word Embeddings via  Multi-Task Training",
    "abstract": "Comments: To be published in the 25th Conference on Computational Natural Language Learning (CoNLL 2021)",
    "descriptor": "\nComments: To be published in the 25th Conference on Computational Natural Language Learning (CoNLL 2021)\n",
    "authors": [
      "Hassan Shahmohammadi",
      "Hendrik P. A. Lensch",
      "R. Harald Baayen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07500"
  },
  {
    "id": "arXiv:2104.08427",
    "title": "Models and Predictive Control for Nonplanar Vehicle Navigation",
    "abstract": "Comments: Minor changes to Appendix",
    "descriptor": "\nComments: Minor changes to Appendix\n",
    "authors": [
      "Thomas Fork",
      "H. Eric Tseng",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.08427"
  },
  {
    "id": "arXiv:2104.08455",
    "title": "Neural Path Hunter: Reducing Hallucination in Dialogue Systems via Path  Grounding",
    "abstract": "Comments: EMNLP 2021 18 pages",
    "descriptor": "\nComments: EMNLP 2021 18 pages\n",
    "authors": [
      "Nouha Dziri",
      "Andrea Madotto",
      "Osmar Zaiane",
      "Avishek Joey Bose"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08455"
  },
  {
    "id": "arXiv:2104.08771",
    "title": "Cross-Attention is All You Need: Adapting Pretrained Transformers for  Machine Translation",
    "abstract": "Comments: Accepted to EMNLP 2021 Main Conference",
    "descriptor": "\nComments: Accepted to EMNLP 2021 Main Conference\n",
    "authors": [
      "Mozhdeh Gheini",
      "Xiang Ren",
      "Jonathan May"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08771"
  },
  {
    "id": "arXiv:2104.12379",
    "title": "Towards Visual Semantics",
    "abstract": "Towards Visual Semantics",
    "descriptor": "",
    "authors": [
      "Fausto Giunchiglia",
      "Luca Erculiani",
      "Andrea Passerini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.12379"
  },
  {
    "id": "arXiv:2104.14202",
    "title": "Bayesian Deep Neural Networks for Supervised Learning Single-View Depth",
    "abstract": "Bayesian Deep Neural Networks for Supervised Learning Single-View Depth",
    "descriptor": "",
    "authors": [
      "Javier Rodr\u00edguez-Puigvert",
      "Rub\u00e9n Mart\u00ednez-Cant\u00edn",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.14202"
  },
  {
    "id": "arXiv:2104.14547",
    "title": "NURBS-Diff: A differentiable programming module for NURBS",
    "abstract": "NURBS-Diff: A differentiable programming module for NURBS",
    "descriptor": "",
    "authors": [
      "Anjana Deva Prasad",
      "Aditya Balu",
      "Harshil Shah",
      "Soumik Sarkar",
      "Chinmay Hegde",
      "Adarsh Krishnamurthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14547"
  },
  {
    "id": "arXiv:2105.02020",
    "title": "Multi-Modal Loop Closing in Unstructured Planetary Environments with  Visually Enriched Submaps",
    "abstract": "Comments: Accepted at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021)",
    "descriptor": "\nComments: Accepted at the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2021)\n",
    "authors": [
      "Riccardo Giubilato",
      "Mallikarjuna Vayugundla",
      "Wolfgang St\u00fcrzl",
      "Martin J. Schuster",
      "Armin Wedler",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.02020"
  },
  {
    "id": "arXiv:2105.02963",
    "title": "Attention-augmented Spatio-Temporal Segmentation for Land Cover Mapping",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Rahul Ghosh",
      "Praveen Ravirathinam",
      "Xiaowei Jia",
      "Chenxi Lin",
      "Zhenong Jin",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.02963"
  },
  {
    "id": "arXiv:2105.03643",
    "title": "Latency-Controlled Neural Architecture Search for Streaming Speech  Recognition",
    "abstract": "Comments: Accepted to ASRU 2021",
    "descriptor": "\nComments: Accepted to ASRU 2021\n",
    "authors": [
      "Liqiang He",
      "Shulin Feng",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.03643"
  },
  {
    "id": "arXiv:2105.04033",
    "title": "Key Assistance, Key Agreement, and Layered Secrecy for Bosonic Broadcast  Channels",
    "abstract": "Key Assistance, Key Agreement, and Layered Secrecy for Bosonic Broadcast  Channels",
    "descriptor": "",
    "authors": [
      "Uzi Pereg",
      "Roberto Ferrara",
      "Matthieu R. Bloch"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.04033"
  },
  {
    "id": "arXiv:2105.04107",
    "title": "MmWave MIMO Communication with Semi-Passive RIS: A Low-Complexity  Channel Estimation Scheme",
    "abstract": "Comments: To appear in Proc. IEEE Global Communications Conference (GLOBECOM), Madrid, Spain, Dec.2021",
    "descriptor": "\nComments: To appear in Proc. IEEE Global Communications Conference (GLOBECOM), Madrid, Spain, Dec.2021\n",
    "authors": [
      "Jiangfeng Hu",
      "Haifan Yin",
      "Emil Bj\u00f6rnson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.04107"
  },
  {
    "id": "arXiv:2105.04213",
    "title": "Temporal-Spatial Feature Pyramid for Video Saliency Detection",
    "abstract": "Temporal-Spatial Feature Pyramid for Video Saliency Detection",
    "descriptor": "",
    "authors": [
      "Qinyao Chang",
      "Shiping Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.04213"
  },
  {
    "id": "arXiv:2105.07109",
    "title": "The Low-Dimensional Linear Geometry of Contextualized Word  Representations",
    "abstract": "Comments: To be published in the 25th Conference on Computational Natural Language Learning (CoNLL)",
    "descriptor": "\nComments: To be published in the 25th Conference on Computational Natural Language Learning (CoNLL)\n",
    "authors": [
      "Evan Hernandez",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.07109"
  },
  {
    "id": "arXiv:2105.09978",
    "title": "Transducer Synthesis from Universal Register Automata in (N,>)",
    "abstract": "Transducer Synthesis from Universal Register Automata in (N,>)",
    "descriptor": "",
    "authors": [
      "Ayrat Khalimov",
      "Emmanuel Filiot",
      "L\u00e9o Exibard"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.09978"
  },
  {
    "id": "arXiv:2105.12049",
    "title": "Honest-but-Curious Nets: Sensitive Attributes of Private Inputs Can Be  Secretly Coded into the Classifiers' Outputs",
    "abstract": "Comments: In Proceedings of the 2021 ACMSIGSAC Conference on Computer and Communications Security (CCS '21)",
    "descriptor": "\nComments: In Proceedings of the 2021 ACMSIGSAC Conference on Computer and Communications Security (CCS '21)\n",
    "authors": [
      "Mohammad Malekzadeh",
      "Anastasia Borovykh",
      "Deniz G\u00fcnd\u00fcz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.12049"
  },
  {
    "id": "arXiv:2105.12697",
    "title": "Intriguing Parameters of Structural Causal Models",
    "abstract": "Comments: Main paper: 7 pages, References: 1 page, Supplement: 3 pages. Main paper: 5 figures, Supplement: 1 figure",
    "descriptor": "\nComments: Main paper: 7 pages, References: 1 page, Supplement: 3 pages. Main paper: 5 figures, Supplement: 1 figure\n",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.12697"
  },
  {
    "id": "arXiv:2105.14579",
    "title": "Intensional Kleene and Rice Theorems for Abstract Program Semantics",
    "abstract": "Comments: 42 pages. Journal paper submitted to Information and Computation",
    "descriptor": "\nComments: 42 pages. Journal paper submitted to Information and Computation\n",
    "authors": [
      "Paolo Baldan",
      "Francesco Ranzato",
      "Linpeng Zhang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.14579"
  },
  {
    "id": "arXiv:2105.15096",
    "title": "Small-Scale Spatial-Temporal Correlation and Degrees of Freedom for  Reconfigurable Intelligent Surfaces",
    "abstract": "Comments: 5 pages, 7 figures, IEEE Wireless Communications Letters, DOI:10.1109/LWC.2021.3112781",
    "descriptor": "\nComments: 5 pages, 7 figures, IEEE Wireless Communications Letters, DOI:10.1109/LWC.2021.3112781\n",
    "authors": [
      "Shu Sun",
      "Hangsong Yan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.15096"
  },
  {
    "id": "arXiv:2106.00232",
    "title": "Multimodal Transportation with Ridesharing of Personal Vehicles",
    "abstract": "Comments: 32 pages, 11 figures, 7 tables",
    "descriptor": "\nComments: 32 pages, 11 figures, 7 tables\n",
    "authors": [
      "Qian-Ping Gu",
      "Jiajian Leo Liang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00232"
  },
  {
    "id": "arXiv:2106.01870",
    "title": "Maximizing Extractable Value from Automated Market Makers",
    "abstract": "Comments: 15 pages. Under submission",
    "descriptor": "\nComments: 15 pages. Under submission\n",
    "authors": [
      "Massimo Bartoletti",
      "James Hsin-yu Chiang",
      "Alberto Lluch-Lafuente"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01870"
  },
  {
    "id": "arXiv:2106.03699",
    "title": "Formalizing Distribution Inference Risks",
    "abstract": "Comments: ICML 2021 Workshop on Theory and Practice of Differential Privacy. Longer version of work available at arXiv:2109.06024",
    "descriptor": "\nComments: ICML 2021 Workshop on Theory and Practice of Differential Privacy. Longer version of work available at arXiv:2109.06024\n",
    "authors": [
      "Anshuman Suri",
      "David Evans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.03699"
  },
  {
    "id": "arXiv:2106.03776",
    "title": "CDN-MEDAL: Two-stage Density and Difference Approximation Framework for  Motion Analysis",
    "abstract": "Comments: 14 pages, 5 figures, to be submitted",
    "descriptor": "\nComments: 14 pages, 5 figures, to be submitted\n",
    "authors": [
      "Nguyen-Tien Cuong",
      "Hung Ngoc Phan",
      "Nhat Minh Chung",
      "Phuong Hoai Ha",
      "Synh Viet-Uyen Ha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03776"
  },
  {
    "id": "arXiv:2106.04312",
    "title": "Speech BERT Embedding For Improving Prosody in Neural TTS",
    "abstract": "Speech BERT Embedding For Improving Prosody in Neural TTS",
    "descriptor": "",
    "authors": [
      "Liping Chen",
      "Yan Deng",
      "Xi Wang",
      "Frank K. Soong",
      "Lei He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2106.04312"
  },
  {
    "id": "arXiv:2106.05041",
    "title": "Fuzzy propositional configuration logics",
    "abstract": "Fuzzy propositional configuration logics",
    "descriptor": "",
    "authors": [
      "Paulina Paraponiari"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.05041"
  },
  {
    "id": "arXiv:2106.06882",
    "title": "Sparse PointPillars: Maintaining and Exploiting Input Sparsity to  Improve Runtime on Embedded Systems",
    "abstract": "Sparse PointPillars: Maintaining and Exploiting Input Sparsity to  Improve Runtime on Embedded Systems",
    "descriptor": "",
    "authors": [
      "Kyle Vedder",
      "Eric Eaton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06882"
  },
  {
    "id": "arXiv:2106.06896",
    "title": "SAR Image Change Detection Based on Multiscale Capsule Network",
    "abstract": "SAR Image Change Detection Based on Multiscale Capsule Network",
    "descriptor": "",
    "authors": [
      "Yunhao Gao",
      "Feng Gao",
      "Junyu Dong",
      "Heng-Chao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.06896"
  },
  {
    "id": "arXiv:2106.08556",
    "title": "Coreference-Aware Dialogue Summarization",
    "abstract": "Comments: Accepted for presentation at SIGDIAL-2021. Version2: add BART-Large results/fix typos",
    "descriptor": "\nComments: Accepted for presentation at SIGDIAL-2021. Version2: add BART-Large results/fix typos\n",
    "authors": [
      "Zhengyuan Liu",
      "Ke Shi",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08556"
  },
  {
    "id": "arXiv:2106.09159",
    "title": "Automatic Curricula via Expert Demonstrations",
    "abstract": "Comments: Preprint, work in progress",
    "descriptor": "\nComments: Preprint, work in progress\n",
    "authors": [
      "Siyu Dai",
      "Andreas Hofmann",
      "Brian Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09159"
  },
  {
    "id": "arXiv:2106.11731",
    "title": "MIMIR: Deep Regression for Automated Analysis of UK Biobank Body MRI",
    "abstract": "MIMIR: Deep Regression for Automated Analysis of UK Biobank Body MRI",
    "descriptor": "",
    "authors": [
      "Taro Langner",
      "Andr\u00e9s Mart\u00ednez Mora",
      "Robin Strand",
      "H\u00e5kan Ahlstr\u00f6m",
      "Joel Kullberg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11731"
  },
  {
    "id": "arXiv:2106.12240",
    "title": "Querying RDF Databases with Sub-CONSTRUCTs",
    "abstract": "Comments: In Proceedings SCSS 2021, arXiv:2109.02501",
    "descriptor": "\nComments: In Proceedings SCSS 2021, arXiv:2109.02501\n",
    "authors": [
      "Dominique Duval",
      "Rachid Echahed",
      "Fr\u00e9d\u00e9ric Prost"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2106.12240"
  },
  {
    "id": "arXiv:2106.12496",
    "title": "Threaded Code Generation with a Meta-tracing JIT Compiler",
    "abstract": "Comments: In Proceedings of ICOOOLPS '21: Workshop on Implementation, Compilation, Optimization of OO Languages, Programs and Systems (ICOOOLPS '21)",
    "descriptor": "\nComments: In Proceedings of ICOOOLPS '21: Workshop on Implementation, Compilation, Optimization of OO Languages, Programs and Systems (ICOOOLPS '21)\n",
    "authors": [
      "Yusuke Izawa",
      "Hidehiko Masuhara",
      "Carl Friedrich Bolz-Tereick",
      "Youyou Cong"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.12496"
  },
  {
    "id": "arXiv:2106.14086",
    "title": "Planar and Toroidal Morphs Made Easier",
    "abstract": "Comments: 19 pages, 5 figures. Previous version appeared in Proc. Graph Drawing 2021",
    "descriptor": "\nComments: 19 pages, 5 figures. Previous version appeared in Proc. Graph Drawing 2021\n",
    "authors": [
      "Jeff Erickson",
      "Patrick Lin"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.14086"
  },
  {
    "id": "arXiv:2106.14431",
    "title": "Modelling Monotonic and Non-Monotonic Attribute Dependencies with  Embeddings: A Theoretical Analysis",
    "abstract": "Comments: Accepted for AKBC 2021",
    "descriptor": "\nComments: Accepted for AKBC 2021\n",
    "authors": [
      "Steven Schockaert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.14431"
  },
  {
    "id": "arXiv:2106.15510",
    "title": "Fast and Accurate Road Crack Detection Based on Adaptive Cost-Sensitive  Loss Function",
    "abstract": "Comments: 14 pages,12 figures, 8 tables",
    "descriptor": "\nComments: 14 pages,12 figures, 8 tables\n",
    "authors": [
      "Kai Li",
      "Bo Wang",
      "Yingjie Tian",
      "Zhiquan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.15510"
  },
  {
    "id": "arXiv:2106.16101",
    "title": "AdaGDA: Faster Adaptive Gradient Descent Ascent Methods for Minimax  Optimization",
    "abstract": "Comments: 29 pages, 3 tables, 2 figures. arXiv admin note: text overlap with arXiv:2008.08170, arXiv:2010.06097, arXiv:2106.11396",
    "descriptor": "\nComments: 29 pages, 3 tables, 2 figures. arXiv admin note: text overlap with arXiv:2008.08170, arXiv:2010.06097, arXiv:2106.11396\n",
    "authors": [
      "Feihu Huang",
      "Heng Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16101"
  },
  {
    "id": "arXiv:2107.01347",
    "title": "Traffic Signal Control with Communicative Deep Reinforcement Learning  Agents: a Case Study",
    "abstract": "Traffic Signal Control with Communicative Deep Reinforcement Learning  Agents: a Case Study",
    "descriptor": "",
    "authors": [
      "Paolo Fazzini",
      "Isaac Wheeler",
      "Francesco Petracchini"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01347"
  },
  {
    "id": "arXiv:2107.01531",
    "title": "TENET: A Time-reversal Enhancement Network for Noise-robust ASR",
    "abstract": "Comments: Accepted to ASRU 2021",
    "descriptor": "\nComments: Accepted to ASRU 2021\n",
    "authors": [
      "Fu-An Chao",
      "Shao-Wei Fan Jiang",
      "Bi-Cheng Yan",
      "Jeih-weih Hung",
      "Berlin Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.01531"
  },
  {
    "id": "arXiv:2107.02882",
    "title": "Twin-width and polynomial kernels",
    "abstract": "Comments: 32 pages, 11 figures",
    "descriptor": "\nComments: 32 pages, 11 figures\n",
    "authors": [
      "\u00c9douard Bonnet",
      "Eun Jung Kim",
      "Amadeus Reinald",
      "St\u00e9phan Thomass\u00e9",
      "R\u00e9mi Watrigant"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.02882"
  },
  {
    "id": "arXiv:2107.03186",
    "title": "Learning Time-Invariant Reward Functions through Model-Based Inverse  Reinforcement Learning",
    "abstract": "Learning Time-Invariant Reward Functions through Model-Based Inverse  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Todor Davchev",
      "Sarah Bechtle",
      "Subramanian Ramamoorthy",
      "Franziska Meier"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.03186"
  },
  {
    "id": "arXiv:2107.03649",
    "title": "Heavily Augmented Sound Event Detection utilizing Weak Predictions",
    "abstract": "Comments: Won 3rd place on IEEE DCASE 2021 Task 4",
    "descriptor": "\nComments: Won 3rd place on IEEE DCASE 2021 Task 4\n",
    "authors": [
      "Hyeonuk Nam",
      "Byeong-Yun Ko",
      "Gyeong-Tae Lee",
      "Seong-Hu Kim",
      "Won-Ho Jung",
      "Sang-Min Choi",
      "Yong-Hwa Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.03649"
  },
  {
    "id": "arXiv:2107.04770",
    "title": "Computer Vision-assisted Single-antenna and Single-anchor RSSI  Localization Harnessing Dynamic Blockage Events",
    "abstract": "Comments: Submitted to IEEE Access",
    "descriptor": "\nComments: Submitted to IEEE Access\n",
    "authors": [
      "Tomoya Sunami",
      "Sohei Itahara",
      "Yusuke Koda",
      "Takayuki Nishio",
      "Koji Yamamoto"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.04770"
  },
  {
    "id": "arXiv:2107.05541",
    "title": "End-to-End Natural Language Understanding Pipeline for Bangla  Conversational Agents",
    "abstract": "Comments: Accepted in IEEE International Conference on Machine Learning and Applications 2021",
    "descriptor": "\nComments: Accepted in IEEE International Conference on Machine Learning and Applications 2021\n",
    "authors": [
      "Fahim Shahriar Khan",
      "Mueeze Al Mushabbir",
      "Mohammad Sabik Irbaz",
      "MD Abdullah Al Nasim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05541"
  },
  {
    "id": "arXiv:2107.07087",
    "title": "Entropic Inequality Constraints from $e$-separation Relations in  Directed Acyclic Graphs with Hidden Variables",
    "abstract": "Comments: 16 pages. Minor changes, mostly a revision to definition of minimal mediary entropy. (The revised definition of MME in arVix v2 takes the finite cardinality property of the mediary as a premise; in arXiv v1 we mistakenly claimed that mediary could be assumed to have finite cardinality without loss of generality.) With appreciation to Murat Kocaoglu for prompting these revisions",
    "descriptor": "\nComments: 16 pages. Minor changes, mostly a revision to definition of minimal mediary entropy. (The revised definition of MME in arVix v2 takes the finite cardinality property of the mediary as a premise; in arXiv v1 we mistakenly claimed that mediary could be assumed to have finite cardinality without loss of generality.) With appreciation to Murat Kocaoglu for prompting these revisions\n",
    "authors": [
      "Noam Finkelstein",
      "Beata Zjawin",
      "Elie Wolfe",
      "Ilya Shpitser",
      "Robert W. Spekkens"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07087"
  },
  {
    "id": "arXiv:2107.07141",
    "title": "An Efficient Semi-Streaming PTAS for Tournament Feedback ArcSet with Few  Passes",
    "abstract": "Comments: 30 pages, 4 figures, 1 table, 8 algorithms",
    "descriptor": "\nComments: 30 pages, 4 figures, 1 table, 8 algorithms\n",
    "authors": [
      "Anubhav Baweja",
      "Justin Jia",
      "David P. Woodruff"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.07141"
  },
  {
    "id": "arXiv:2107.07361",
    "title": "From Reddit to Wall Street: The role of committed minorities in  financial collective action",
    "abstract": "Comments: Main: 9 pages, 3 figures, 3 tables. Supplementary: 7 pages, 7 figures",
    "descriptor": "\nComments: Main: 9 pages, 3 figures, 3 tables. Supplementary: 7 pages, 7 figures\n",
    "authors": [
      "Lorenzo Lucchini",
      "Luca Maria Aiello",
      "Laura Alessandretti",
      "Gianmarco De Francisci Morales",
      "Michele Starnini",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.07361"
  },
  {
    "id": "arXiv:2107.07946",
    "title": "Lack of evidence for correlation between COVID-19 infodemic and vaccine  acceptance",
    "abstract": "Lack of evidence for correlation between COVID-19 infodemic and vaccine  acceptance",
    "descriptor": "",
    "authors": [
      "Carlo M. Valensise",
      "Matteo Cinelli",
      "Matthieu Nadini",
      "Alessandro Galeazzi",
      "Antonio Peruzzi",
      "Gabriele Etta",
      "Fabiana Zollo",
      "Andrea Baronchelli",
      "Walter Quattrociocchi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.07946"
  },
  {
    "id": "arXiv:2107.09091",
    "title": "Support Recovery in Universal One-bit Compressed Sensing",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Arya Mazumdar",
      "Soumyabrata Pal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.09091"
  },
  {
    "id": "arXiv:2107.10821",
    "title": "To Ship or Not to Ship: An Extensive Evaluation of Automatic Metrics for  Machine Translation",
    "abstract": "Comments: Accepted to WMT 2021 research papers",
    "descriptor": "\nComments: Accepted to WMT 2021 research papers\n",
    "authors": [
      "Tom Kocmi",
      "Christian Federmann",
      "Roman Grundkiewicz",
      "Marcin Junczys-Dowmunt",
      "Hitokazu Matsushita",
      "Arul Menezes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.10821"
  },
  {
    "id": "arXiv:2107.12765",
    "title": "Resource Optimization with Interference Coupling in Multi-IRS-assisted  Multi-cell Systems",
    "abstract": "Resource Optimization with Interference Coupling in Multi-IRS-assisted  Multi-cell Systems",
    "descriptor": "",
    "authors": [
      "Zhanwei Yu",
      "Di Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.12765"
  },
  {
    "id": "arXiv:2107.13143",
    "title": "CycleGAN-based Non-parallel Speech Enhancement with an Adaptive  Attention-in-attention Mechanism",
    "abstract": "Comments: Accepted by APSIPA-ASC 2021 (7 pages)",
    "descriptor": "\nComments: Accepted by APSIPA-ASC 2021 (7 pages)\n",
    "authors": [
      "Guochen Yu",
      "Yutian Wang",
      "Chengshi Zheng",
      "Hui Wang",
      "Qin Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.13143"
  },
  {
    "id": "arXiv:2108.00452",
    "title": "Amalgamation is PSPACE-hard",
    "abstract": "Comments: 15 pages, 1 figure",
    "descriptor": "\nComments: 15 pages, 1 figure\n",
    "authors": [
      "Manuel Bodirsky",
      "Simon Kn\u00e4uer",
      "Jakub Rydval"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2108.00452"
  },
  {
    "id": "arXiv:2108.01012",
    "title": "Rapidly-Exploring Random Graph Next-Best View Exploration for Ground  Vehicles",
    "abstract": "Comments: 7 pages, 6 figures, accepted for the 10th European Conference on Mobile Robots (ECMR 2021), see open-sourced code here: this https URL",
    "descriptor": "\nComments: 7 pages, 6 figures, accepted for the 10th European Conference on Mobile Robots (ECMR 2021), see open-sourced code here: this https URL\n",
    "authors": [
      "Marco Steinbrink",
      "Philipp Koch",
      "Bernhard Jung",
      "Stefan May"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.01012"
  },
  {
    "id": "arXiv:2108.03171",
    "title": "Quantum Meets the Minimum Circuit Size Problem",
    "abstract": "Quantum Meets the Minimum Circuit Size Problem",
    "descriptor": "",
    "authors": [
      "Nai-Hui Chia",
      "Chi-Ning Chou",
      "Jiayu Zhang",
      "Ruizhe Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.03171"
  },
  {
    "id": "arXiv:2108.03458",
    "title": "Scientific X-ray",
    "abstract": "Scientific X-ray",
    "descriptor": "",
    "authors": [
      "Qi Li",
      "Luoyi Fu",
      "Xinbing Wang",
      "Chenghu Zhou"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.03458"
  },
  {
    "id": "arXiv:2108.03815",
    "title": "P-WAE: Generalized Patch-Wasserstein Autoencoder for Anomaly Screening",
    "abstract": "P-WAE: Generalized Patch-Wasserstein Autoencoder for Anomaly Screening",
    "descriptor": "",
    "authors": [
      "Yurong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.03815"
  },
  {
    "id": "arXiv:2108.04800",
    "title": "Meta-repository of screening mammography classifiers",
    "abstract": "Comments: 16 pages, 2 figures. Meta-repository available at this https URL; added results on the OPTIMAM dataset",
    "descriptor": "\nComments: 16 pages, 2 figures. Meta-repository available at this https URL; added results on the OPTIMAM dataset\n",
    "authors": [
      "Benjamin Stadnick",
      "Jan Witowski",
      "Vishwaesh Rajiv",
      "Jakub Ch\u0142\u0119dowski",
      "Farah E. Shamout",
      "Kyunghyun Cho",
      "Krzysztof J. Geras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.04800"
  },
  {
    "id": "arXiv:2108.06209",
    "title": "W2v-BERT: Combining Contrastive Learning and Masked Language Modeling  for Self-Supervised Speech Pre-Training",
    "abstract": "W2v-BERT: Combining Contrastive Learning and Masked Language Modeling  for Self-Supervised Speech Pre-Training",
    "descriptor": "",
    "authors": [
      "Yu-An Chung",
      "Yu Zhang",
      "Wei Han",
      "Chung-Cheng Chiu",
      "James Qin",
      "Ruoming Pang",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2108.06209"
  },
  {
    "id": "arXiv:2108.06480",
    "title": "Evaluating the sum of convergent positive series",
    "abstract": "Comments: 11 pages, 5 tables, 11 references. We added one more example. The title of the paper is changed",
    "descriptor": "\nComments: 11 pages, 5 tables, 11 references. We added one more example. The title of the paper is changed\n",
    "authors": [
      "Vyacheslav M. Abramov"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.06480"
  },
  {
    "id": "arXiv:2108.07406",
    "title": "From the Greene--Wu Convolution to Gradient Estimation over Riemannian  Manifolds",
    "abstract": "From the Greene--Wu Convolution to Gradient Estimation over Riemannian  Manifolds",
    "descriptor": "",
    "authors": [
      "Tianyu Wang",
      "Yifeng Huang",
      "Didong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.07406"
  },
  {
    "id": "arXiv:2108.07472",
    "title": "PAC Learnability of Approximate Nash Equilibrium in Bimatrix Games",
    "abstract": "PAC Learnability of Approximate Nash Equilibrium in Bimatrix Games",
    "descriptor": "",
    "authors": [
      "Zhijian Duan",
      "Dinghuai Zhang",
      "Wenhan Huang",
      "Yali Du",
      "Yaodong Yang",
      "Jun Wang",
      "Xiaotie Deng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2108.07472"
  },
  {
    "id": "arXiv:2108.07942",
    "title": "Algorithmic techniques for finding resistance distances on structured  graphs",
    "abstract": "Algorithmic techniques for finding resistance distances on structured  graphs",
    "descriptor": "",
    "authors": [
      "E. J. Evans",
      "A. E. Francis"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.07942"
  },
  {
    "id": "arXiv:2108.08003",
    "title": "Stochastic Cluster Embedding",
    "abstract": "Stochastic Cluster Embedding",
    "descriptor": "",
    "authors": [
      "Zhirong Yang",
      "Yuwei Chen",
      "Denis Sedov",
      "Samuel Kaski",
      "Jukka Corander"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08003"
  },
  {
    "id": "arXiv:2108.08298",
    "title": "A Machine Learning Modelling Benchmark for Temperature Field  Reconstruction of Heat-Source Systems",
    "abstract": "A Machine Learning Modelling Benchmark for Temperature Field  Reconstruction of Heat-Source Systems",
    "descriptor": "",
    "authors": [
      "Xiaoqian Chen",
      "Zhiqiang Gong",
      "Xiaoyu Zhao",
      "Weien Zhou",
      "Wen Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.08298"
  },
  {
    "id": "arXiv:2108.08536",
    "title": "A Unified Objective for Novel Class Discovery",
    "abstract": "Comments: ICCV 2021 (Oral)",
    "descriptor": "\nComments: ICCV 2021 (Oral)\n",
    "authors": [
      "Enrico Fini",
      "Enver Sangineto",
      "St\u00e9phane Lathuili\u00e8re",
      "Zhun Zhong",
      "Moin Nabi",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08536"
  },
  {
    "id": "arXiv:2108.08614",
    "title": "UNIQORN: Unified Question Answering over RDF Knowledge Graphs and  Natural Language Text",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Soumajit Pramanik",
      "Jesujoba Alabi",
      "Rishiraj Saha Roy",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.08614"
  },
  {
    "id": "arXiv:2108.08957",
    "title": "Unified Representation of Geometric Primitives for Graph-SLAM  Optimization Using Decomposed Quadrics",
    "abstract": "Comments: This paper has been submitted to ICRA 2022",
    "descriptor": "\nComments: This paper has been submitted to ICRA 2022\n",
    "authors": [
      "Weikun Zhen",
      "Huai Yu",
      "Yaoyu Hu",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.08957"
  },
  {
    "id": "arXiv:2108.09093",
    "title": "Towards Understanding the Generative Capability of Adversarially Robust  Classifiers",
    "abstract": "Comments: Accepted by ICCV 2021, Oral",
    "descriptor": "\nComments: Accepted by ICCV 2021, Oral\n",
    "authors": [
      "Yao Zhu",
      "Jiacheng Ma",
      "Jiacheng Sun",
      "Zewei Chen",
      "Rongxin Jiang",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.09093"
  },
  {
    "id": "arXiv:2108.09674",
    "title": "Detection and Localization of Multiple Image Splicing Using MobileNet V1",
    "abstract": "Detection and Localization of Multiple Image Splicing Using MobileNet V1",
    "descriptor": "",
    "authors": [
      "Kalyani Kadam",
      "Dr. Swati Ahirrao",
      "Dr. Ketan Kotecha",
      "Sayan Sahu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.09674"
  },
  {
    "id": "arXiv:2108.11211",
    "title": "Clustering acoustic emission data streams with sequentially appearing  clusters using mixture models",
    "abstract": "Clustering acoustic emission data streams with sequentially appearing  clusters using mixture models",
    "descriptor": "",
    "authors": [
      "Emmanuel Ramasso",
      "Thierry Denoeux",
      "Gael Chevallier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2108.11211"
  },
  {
    "id": "arXiv:2108.11514",
    "title": "Bilateral Denoising Diffusion Models",
    "abstract": "Bilateral Denoising Diffusion Models",
    "descriptor": "",
    "authors": [
      "Max W. Y. Lam",
      "Jun Wang",
      "Rongjie Huang",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.11514"
  },
  {
    "id": "arXiv:2108.11781",
    "title": "On the use of test smells for prediction of flaky tests",
    "abstract": "On the use of test smells for prediction of flaky tests",
    "descriptor": "",
    "authors": [
      "B. H. P. Camara",
      "M. A. G. Silva",
      "A. T. Endo",
      "S. R. Vergilio"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.11781"
  },
  {
    "id": "arXiv:2108.12724",
    "title": "DEGREE: A Data-Efficient Generative Event Extraction Model",
    "abstract": "Comments: The first two authors contribute equally",
    "descriptor": "\nComments: The first two authors contribute equally\n",
    "authors": [
      "I-Hung Hsu",
      "Kuan-Hao Huang",
      "Elizabeth Boschee",
      "Scott Miller",
      "Prem Natarajan",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.12724"
  },
  {
    "id": "arXiv:2108.12748",
    "title": "Joint LED Selection and Precoding Optimization for Multiple-User  Multiple-Cell VLC Systems",
    "abstract": "Joint LED Selection and Precoding Optimization for Multiple-User  Multiple-Cell VLC Systems",
    "descriptor": "",
    "authors": [
      "Yang Yang",
      "Yujie Yang",
      "Mingzhe Chen",
      "Chunyan Feng",
      "Hailun Xia",
      "Shuguang Cui",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.12748"
  },
  {
    "id": "arXiv:2108.13934",
    "title": "Robust Retrieval Augmented Generation for Zero-shot Slot Filling",
    "abstract": "Comments: Accepted at EMNLP 2021. arXiv admin note: substantial text overlap with arXiv:2104.08610",
    "descriptor": "\nComments: Accepted at EMNLP 2021. arXiv admin note: substantial text overlap with arXiv:2104.08610\n",
    "authors": [
      "Michael Glass",
      "Gaetano Rossiello",
      "Md Faisal Mahbub Chowdhury",
      "Alfio Gliozzo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.13934"
  },
  {
    "id": "arXiv:2109.00542",
    "title": "Shared Certificates for Neural Network Verification",
    "abstract": "Shared Certificates for Neural Network Verification",
    "descriptor": "",
    "authors": [
      "Christian Sprecher",
      "Marc Fischer",
      "Dimitar I. Dimitrov",
      "Gagandeep Singh",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.00542"
  },
  {
    "id": "arXiv:2109.00676",
    "title": "Self-supervised Recommendation with Cross-channel Matching  Representation and Hierarchical Contrastive Learning",
    "abstract": "Comments: The full-text language was polished and part of the experiment content was revised",
    "descriptor": "\nComments: The full-text language was polished and part of the experiment content was revised\n",
    "authors": [
      "Dongjie Zhu",
      "Yundong Sun",
      "Haiwen Du",
      "Zhaoshuo Tian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.00676"
  },
  {
    "id": "arXiv:2109.00685",
    "title": "Excess Capacity and Backdoor Poisoning",
    "abstract": "Excess Capacity and Backdoor Poisoning",
    "descriptor": "",
    "authors": [
      "Naren Sarayu Manoj",
      "Avrim Blum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.00685"
  },
  {
    "id": "arXiv:2109.02811",
    "title": "A Digital Smart City for Emerging Mobility Systems",
    "abstract": "Comments: 6 pages, 8 figures",
    "descriptor": "\nComments: 6 pages, 8 figures\n",
    "authors": [
      "Raymond M. Zayas",
      "Logan E. Beaver",
      "Behdad Chalaki",
      "Heeseung Bang",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.02811"
  },
  {
    "id": "arXiv:2109.03146",
    "title": "Toward Generating Sufficiently Valid Test Case Results: A Method for  Systematically Assigning Test Cases to Test Bench Configurations in a  Scenario-Based Test Approach for Automated Vehicles",
    "abstract": "Comments: Prepublication. To be submitted to IEEE Access",
    "descriptor": "\nComments: Prepublication. To be submitted to IEEE Access\n",
    "authors": [
      "Markus Steimle",
      "Nico Weber"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.03146"
  },
  {
    "id": "arXiv:2109.03154",
    "title": "PEEK: A Large Dataset of Learner Engagement with Educational Videos",
    "abstract": "Comments: To be published at ORSUM '21: 4th Workshop on Online Recommender Systems and User Modeling at ACM RecSys 2021",
    "descriptor": "\nComments: To be published at ORSUM '21: 4th Workshop on Online Recommender Systems and User Modeling at ACM RecSys 2021\n",
    "authors": [
      "Sahan Bulathwela",
      "Maria Perez-Ortiz",
      "Erik Novak",
      "Emine Yilmaz",
      "John Shawe-Taylor"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03154"
  },
  {
    "id": "arXiv:2109.03402",
    "title": "Mixup Decoding for Diverse Machine Translation",
    "abstract": "Comments: Findings of EMNLP 2021",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Jicheng Li",
      "Pengzhi Gao",
      "Xuanfu Wu",
      "Yang Feng",
      "Zhongjun He",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03402"
  },
  {
    "id": "arXiv:2109.03585",
    "title": "Matching in the Dark: A Dataset for Matching Image Pairs of Low-light  Scenes",
    "abstract": "Comments: 15 pages, 14 figures, ICCV2021",
    "descriptor": "\nComments: 15 pages, 14 figures, ICCV2021\n",
    "authors": [
      "Wenzheng Song",
      "Masanori Suganuma",
      "Xing Liu",
      "Noriyuki Shimobayashi",
      "Daisuke Maruta",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03585"
  },
  {
    "id": "arXiv:2109.03675",
    "title": "EMA: Auditing Data Removal from Trained Models",
    "abstract": "Comments: MICCAI 2021",
    "descriptor": "\nComments: MICCAI 2021\n",
    "authors": [
      "Yangsibo Huang",
      "Xiaoxiao Li",
      "Kai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03675"
  },
  {
    "id": "arXiv:2109.03702",
    "title": "Unsupervised clothing change adaptive person ReID",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Ziyue Zhang",
      "Shuai Jiang",
      "Congzhentao Huang",
      "Richard YiDa Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03702"
  },
  {
    "id": "arXiv:2109.03754",
    "title": "Memory and Knowledge Augmented Language Models for Inferring Salience in  Long-Form Stories",
    "abstract": "Comments: Accepted to the EMNLP 2021 Conference as a long-paper, 9 pages, 15 pages with appendices and references, 2 figures, 4 tables",
    "descriptor": "\nComments: Accepted to the EMNLP 2021 Conference as a long-paper, 9 pages, 15 pages with appendices and references, 2 figures, 4 tables\n",
    "authors": [
      "David Wilmot",
      "Frank Keller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03754"
  },
  {
    "id": "arXiv:2109.03812",
    "title": "fastMRI+: Clinical Pathology Annotations for Knee and Brain Fully  Sampled Multi-Coil MRI Data",
    "abstract": "fastMRI+: Clinical Pathology Annotations for Knee and Brain Fully  Sampled Multi-Coil MRI Data",
    "descriptor": "",
    "authors": [
      "Ruiyang Zhao",
      "Burhaneddin Yaman",
      "Yuxin Zhang",
      "Russell Stewart",
      "Austin Dixon",
      "Florian Knoll",
      "Zhengnan Huang",
      "Yvonne W. Lui",
      "Michael S. Hansen",
      "Matthew P. Lungren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.03812"
  },
  {
    "id": "arXiv:2109.04332",
    "title": "PPT: Pre-trained Prompt Tuning for Few-shot Learning",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Yuxian Gu",
      "Xu Han",
      "Zhiyuan Liu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04332"
  },
  {
    "id": "arXiv:2109.04604",
    "title": "How May I Help You? Using Neural Text Simplification to Improve  Downstream NLP Tasks",
    "abstract": "Comments: 7 pages, 7 tables, accepted to Empirical Methods for Natural Language Processing 2021, Punta Cana, Dominican Republic",
    "descriptor": "\nComments: 7 pages, 7 tables, accepted to Empirical Methods for Natural Language Processing 2021, Punta Cana, Dominican Republic\n",
    "authors": [
      "Hoang Van",
      "Zheng Tang",
      "Mihai Surdeanu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04604"
  },
  {
    "id": "arXiv:2109.04645",
    "title": "CINS: Comprehensive Instruction for Few-shot Learning in Task-oriented  Dialog Systems",
    "abstract": "CINS: Comprehensive Instruction for Few-shot Learning in Task-oriented  Dialog Systems",
    "descriptor": "",
    "authors": [
      "Fei Mi",
      "Yitong Li",
      "Yasheng Wang",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04645"
  },
  {
    "id": "arXiv:2109.04681",
    "title": "Jammkle: Fibre jamming 3D printed multi-material tendons and their  application in a robotic ankle",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "James Brett",
      "Katrina Lo Surdo",
      "Lauren Hanson",
      "Joshua Pinskier",
      "David Howard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04681"
  },
  {
    "id": "arXiv:2109.04780",
    "title": "RoR: Read-over-Read for Long Document Machine Reading Comprehension",
    "abstract": "Comments: Accepted as findings of EMNLP2021",
    "descriptor": "\nComments: Accepted as findings of EMNLP2021\n",
    "authors": [
      "Jing Zhao",
      "Junwei Bao",
      "Yifan Wang",
      "Yongwei Zhou",
      "Youzheng Wu",
      "Xiaodong He",
      "Bowen Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04780"
  },
  {
    "id": "arXiv:2109.04831",
    "title": "Simulating the Effects of Eco-Friendly Transportation Selections for Air  Pollution Reduction",
    "abstract": "Comments: KDD Cup 2019 Regular ML Track Task 2, 1st Prize this https URL",
    "descriptor": "\nComments: KDD Cup 2019 Regular ML Track Task 2, 1st Prize this https URL\n",
    "authors": [
      "Keiichi Ochiai",
      "Tsukasa Demizu",
      "Shin Ishiguro",
      "Shohei Maruyama",
      "Akihiro Kawana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04831"
  },
  {
    "id": "arXiv:2109.04883",
    "title": "Resolving gas bubbles ascending in liquid metal from low-SNR neutron  radiography images",
    "abstract": "Resolving gas bubbles ascending in liquid metal from low-SNR neutron  radiography images",
    "descriptor": "",
    "authors": [
      "Mihails Birjukovs",
      "Pavel Trtik",
      "Anders Kaestner",
      "Jan Hovind",
      "Martins Klevs",
      "Dariusz Jakub Gawryluk",
      "Knud Thomsen",
      "Andris Jakovics"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04883"
  },
  {
    "id": "arXiv:2109.05078",
    "title": "A semi-supervised self-training method to develop assistive intelligence  for segmenting multiclass bridge elements from inspection videos",
    "abstract": "Comments: Published in Structural Health Monitoring",
    "descriptor": "\nComments: Published in Structural Health Monitoring\n",
    "authors": [
      "Muhammad Monjurul Karim",
      "Ruwen Qin",
      "Zhaozheng Yin",
      "Genda Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05078"
  },
  {
    "id": "arXiv:2109.05143",
    "title": "Bundled Gradients through Contact via Randomized Smoothing",
    "abstract": "Comments: The first two authors contributed equally",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "H.J. Terry Suh",
      "Tao Pang",
      "Russ Tedrake"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.05143"
  },
  {
    "id": "arXiv:2109.05238",
    "title": "Universal Simultaneous Machine Translation with Mixture-of-Experts  Wait-k Policy",
    "abstract": "Comments: Accepted at EMNLP 2021 (main conference). 12 pages, 7 figures, 4 tables",
    "descriptor": "\nComments: Accepted at EMNLP 2021 (main conference). 12 pages, 7 figures, 4 tables\n",
    "authors": [
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05238"
  },
  {
    "id": "arXiv:2109.05244",
    "title": "Modeling Concentrated Cross-Attention for Neural Machine Translation  with Gaussian Mixture Model",
    "abstract": "Comments: Accepted at Findings of EMNLP 2021. 11 pages, 7 figures, 7 tables",
    "descriptor": "\nComments: Accepted at Findings of EMNLP 2021. 11 pages, 7 figures, 7 tables\n",
    "authors": [
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05244"
  },
  {
    "id": "arXiv:2109.05373",
    "title": "An efficient and robust monolithic approach to phase-field quasi-static  brittle fracture using a modified Newton method",
    "abstract": "Comments: Accepted manuscript: Added references, added Armijo algorithm, more details on modified Newton algorithm, added mesh sensitivity analysis, comparison with original extrapolated scheme in Annex",
    "descriptor": "\nComments: Accepted manuscript: Added references, added Armijo algorithm, more details on modified Newton algorithm, added mesh sensitivity analysis, comparison with original extrapolated scheme in Annex\n",
    "authors": [
      "O. Lampron",
      "D. Therriault",
      "M. L\u00e9vesque"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2109.05373"
  },
  {
    "id": "arXiv:2109.05402",
    "title": "Differentially Private Variable Selection via the Knockoff Filter",
    "abstract": "Comments: Accepted to the 2021 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)",
    "descriptor": "\nComments: Accepted to the 2021 IEEE International Workshop on Machine Learning for Signal Processing (MLSP)\n",
    "authors": [
      "Mehrdad Pournaderi",
      "Yu Xiang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05402"
  },
  {
    "id": "arXiv:2109.05406",
    "title": "Guiding Topic Flows in the Generative Chatbot by Enhancing the  ConceptNet with the Conversation Corpora",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Pengda Si",
      "Yao Qiu",
      "Jinchao Zhang",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05406"
  },
  {
    "id": "arXiv:2109.05479",
    "title": "Efficient Re-parameterization Residual Attention Network For  Nonhomogeneous Image Dehazing",
    "abstract": "Efficient Re-parameterization Residual Attention Network For  Nonhomogeneous Image Dehazing",
    "descriptor": "",
    "authors": [
      "Tian Ye",
      "ErKang Chen",
      "XinRui Huang",
      "Peng Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05479"
  },
  {
    "id": "arXiv:2109.05704",
    "title": "Mitigating Language-Dependent Ethnic Bias in BERT",
    "abstract": "Comments: 17 pages including references and appendix. To appear in EMNLP 2021 (camera-ready ver.)",
    "descriptor": "\nComments: 17 pages including references and appendix. To appear in EMNLP 2021 (camera-ready ver.)\n",
    "authors": [
      "Jaimeen Ahn",
      "Alice Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05704"
  },
  {
    "id": "arXiv:2109.05729",
    "title": "CPT: A Pre-Trained Unbalanced Transformer for Both Chinese Language  Understanding and Generation",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yunfan Shao",
      "Zhichao Geng",
      "Yitao Liu",
      "Junqi Dai",
      "Fei Yang",
      "Li Zhe",
      "Hujun Bao",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05729"
  },
  {
    "id": "arXiv:2109.05750",
    "title": "Spatial-Separated Curve Rendering Network for Efficient and  High-Resolution Image Harmonization",
    "abstract": "Spatial-Separated Curve Rendering Network for Efficient and  High-Resolution Image Harmonization",
    "descriptor": "",
    "authors": [
      "Jingtang Liang",
      "Xiaodong Cun",
      "Chi-Man Pun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05750"
  },
  {
    "id": "arXiv:2109.05752",
    "title": "On the Age of Information of a Queuing System with Heterogeneous Servers",
    "abstract": "Comments: 6 pages, 4 figures. Appeared in NCC 2021, IIT Kanpur",
    "descriptor": "\nComments: 6 pages, 4 figures. Appeared in NCC 2021, IIT Kanpur\n",
    "authors": [
      "Anhad Bhati",
      "Sibi Raj B. Pillai",
      "Rahul Vaze"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.05752"
  },
  {
    "id": "arXiv:2109.05763",
    "title": "$\\mathcal{H}$-inverses for RBF interpolation",
    "abstract": "$\\mathcal{H}$-inverses for RBF interpolation",
    "descriptor": "",
    "authors": [
      "Niklas Angleitner",
      "Markus Faustmann",
      "Jens Markus Melenk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.05763"
  },
  {
    "id": "arXiv:2109.05789",
    "title": "ARGO: Modeling Heterogeneity in E-commerce Recommendation",
    "abstract": "Comments: Accepted by IEEE International Joint Conference on Neural Networks (IJCNN) 2021. arXiv admin note: text overlap with arXiv:2105.11876",
    "descriptor": "\nComments: Accepted by IEEE International Joint Conference on Neural Networks (IJCNN) 2021. arXiv admin note: text overlap with arXiv:2105.11876\n",
    "authors": [
      "Daqing Wu",
      "Xiao Luo",
      "Zeyu Ma",
      "Chong Chen",
      "Minghua Deng",
      "Jinwen Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.05789"
  },
  {
    "id": "arXiv:2109.05791",
    "title": "Unified Kinematic and Dynamical Modeling of a Soft Robotic Arm by a  Piecewise Universal Joint Model",
    "abstract": "Comments: 7 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 7 pages, 8 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zhanchi Wang",
      "Gaotian Wang",
      "Nikolaos M. Freris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.05791"
  },
  {
    "id": "arXiv:2109.05837",
    "title": "Categorical Semantics of Reversible Pattern-Matching",
    "abstract": "Comments: 10 pages, references, then 6 pages appendix. Submitted to MFPS 2021",
    "descriptor": "\nComments: 10 pages, references, then 6 pages appendix. Submitted to MFPS 2021\n",
    "authors": [
      "Louis Lemonnier",
      "Kostia Chardonnet",
      "Beno\u00eet Valiron"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05837"
  },
  {
    "id": "arXiv:2109.05877",
    "title": "Cardinality Estimation in DBMS: A Comprehensive Benchmark Evaluation",
    "abstract": "Cardinality Estimation in DBMS: A Comprehensive Benchmark Evaluation",
    "descriptor": "",
    "authors": [
      "Yuxing Han",
      "Ziniu Wu",
      "Peizhi Wu",
      "Rong Zhu",
      "Jingyi Yang",
      "Liang Wei Tan",
      "Kai Zeng",
      "Gao Cong",
      "Yanzhao Qin",
      "Andreas Pfadler",
      "Zhengping Qian",
      "Jingren Zhou",
      "Jiangneng Li",
      "Bin Cui"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05877"
  },
  {
    "id": "arXiv:2109.05897",
    "title": "Question Answering over Electronic Devices: A New Benchmark Dataset and  a Multi-Task Learning based QA Framework",
    "abstract": "Comments: EMNLP Findings 2021, Long",
    "descriptor": "\nComments: EMNLP Findings 2021, Long\n",
    "authors": [
      "Abhilash Nandy",
      "Soumya Sharma",
      "Shubham Maddhashiya",
      "Kapil Sachdeva",
      "Pawan Goyal",
      "Niloy Ganguly"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05897"
  },
  {
    "id": "arXiv:2109.06024",
    "title": "Formalizing and Estimating Distribution Inference Risks",
    "abstract": "Comments: Shorter version of work available at arXiv:2106.03699",
    "descriptor": "\nComments: Shorter version of work available at arXiv:2106.03699\n",
    "authors": [
      "Anshuman Suri",
      "David Evans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06024"
  },
  {
    "id": "arXiv:2109.06129",
    "title": "Can Language Models Encode Perceptual Structure Without Grounding? A  Case Study in Color",
    "abstract": "Comments: CoNLL 2021",
    "descriptor": "\nComments: CoNLL 2021\n",
    "authors": [
      "Mostafa Abdou",
      "Artur Kulmizev",
      "Daniel Hershcovich",
      "Stella Frank",
      "Ellie Pavlick",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06129"
  },
  {
    "id": "arXiv:2109.06152",
    "title": "Enumerating independent sets in Abelian Cayley graphs",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Aditya Potukuchi",
      "Liana Yepremyan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.06152"
  }
]
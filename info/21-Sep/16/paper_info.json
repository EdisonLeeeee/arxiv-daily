[
  {
    "id": "arXiv:2109.06873",
    "title": "Improving Robustness and Efficiency in Active Learning with Contrastive  Loss",
    "abstract": "This paper introduces supervised contrastive active learning (SCAL) by\nleveraging the contrastive loss for active learning in a supervised setting. We\npropose efficient query strategies in active learning to select unbiased and\ninformative data samples of diverse feature representations. We demonstrate our\nproposed method reduces sampling bias, achieves state-of-the-art accuracy and\nmodel calibration in an active learning setup with the query computation 11x\nfaster than CoreSet and 26x faster than Bayesian active learning by\ndisagreement. Our method yields well-calibrated models even with imbalanced\ndatasets. We also evaluate robustness to dataset shift and out-of-distribution\nin active learning setup and demonstrate our proposed SCAL method outperforms\nhigh performing compute-intensive methods by a bigger margin (average 8.9%\nhigher AUROC for out-of-distribution detection and average 7.2% lower ECE under\ndataset shift).",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.06321\n",
    "authors": [
      "Ranganath Krishnan",
      "Nilesh Ahuja",
      "Alok Sinha",
      "Mahesh Subedar",
      "Omesh Tickoo",
      "Ravi Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06873"
  },
  {
    "id": "arXiv:2109.06874",
    "title": "Agile, Antifragile, Artificial-Intelligence-Enabled, Command and Control",
    "abstract": "Artificial Intelligence (AI) is rapidly becoming integrated into military\nCommand and Control (C2) systems as a strategic priority for many defence\nforces. The successful implementation of AI is promising to herald a\nsignificant leap in C2 agility through automation. However, realistic\nexpectations need to be set on what AI can achieve in the foreseeable future.\nThis paper will argue that AI could lead to a fragility trap, whereby the\ndelegation of C2 functions to an AI could increase the fragility of C2,\nresulting in catastrophic strategic failures. This calls for a new framework\nfor AI in C2 to avoid this trap. We will argue that antifragility along with\nagility should form the core design principles for AI-enabled C2 systems. This\nduality is termed Agile, Antifragile, AI-Enabled Command and Control (A3IC2).\nAn A3IC2 system continuously improves its capacity to perform in the face of\nshocks and surprises through overcompensation from feedback during the C2\ndecision-making cycle. An A3IC2 system will not only be able to survive within\na complex operational environment, it will also thrive, benefiting from the\ninevitable shocks and volatility of war.",
    "descriptor": "\nComments: 12 pages, 7 figures, included in the 26th International Command and Control Research and Technology Symposium (ICCRTS)\n",
    "authors": [
      "Jacob Simpson",
      "Rudolph Oosthuizen",
      "Sondoss El Sawah",
      "Hussein Abbass"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06874"
  },
  {
    "id": "arXiv:2109.06875",
    "title": "Multi-Scale Aligned Distillation for Low-Resolution Detection",
    "abstract": "In instance-level detection tasks (e.g., object detection), reducing input\nresolution is an easy option to improve runtime efficiency. However, this\noption traditionally hurts the detection performance much. This paper focuses\non boosting the performance of low-resolution models by distilling knowledge\nfrom a high- or multi-resolution model. We first identify the challenge of\napplying knowledge distillation (KD) to teacher and student networks that act\non different input resolutions. To tackle it, we explore the idea of spatially\naligning feature maps between models of varying input resolutions by shifting\nfeature pyramid positions and introduce aligned multi-scale training to train a\nmulti-scale teacher that can distill its knowledge to a low-resolution student.\nFurther, we propose crossing feature-level fusion to dynamically fuse teacher's\nmulti-resolution features to guide the student better. On several\ninstance-level detection tasks and datasets, the low-resolution models trained\nvia our approach perform competitively with high-resolution models trained via\nconventional multi-scale training, while outperforming the latter's\nlow-resolution models by 2.1% to 3.6% in terms of mAP. Our code is made\npublicly available at https://github.com/dvlab-research/MSAD.",
    "descriptor": "\nComments: In CVPR 2021\n",
    "authors": [
      "Lu Qi",
      "Jason Kuen",
      "Jiuxiang Gu",
      "Zhe Lin",
      "Yi Wang",
      "Yukang Chen",
      "Yanwei Li",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06875"
  },
  {
    "id": "arXiv:2109.06896",
    "title": "Decision-Focused Summarization",
    "abstract": "Relevance in summarization is typically defined based on textual information\nalone, without incorporating insights about a particular decision. As a result,\nto support risk analysis of pancreatic cancer, summaries of medical notes may\ninclude irrelevant information such as a knee injury. We propose a novel\nproblem, decision-focused summarization, where the goal is to summarize\nrelevant information for a decision. We leverage a predictive model that makes\nthe decision based on the full text to provide valuable insights on how a\ndecision can be inferred from text. To build a summary, we then select\nrepresentative sentences that lead to similar model decisions as using the full\ntext while accounting for textual non-redundancy. To evaluate our method\n(DecSum), we build a testbed where the task is to summarize the first ten\nreviews of a restaurant in support of predicting its future rating on Yelp.\nDecSum substantially outperforms text-only summarization methods and\nmodel-based explanation methods in decision faithfulness and\nrepresentativeness. We further demonstrate that DecSum is the only method that\nenables humans to outperform random chance in predicting which restaurant will\nbe better rated in the future.",
    "descriptor": "\nComments: 16 pages, 10 figures, EMNLP 2021, code is available at this https URL\n",
    "authors": [
      "Chao-Chun Hsu",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06896"
  },
  {
    "id": "arXiv:2109.06906",
    "title": "Recovering individual emotional states from sparse ratings using  collaborative filtering",
    "abstract": "A fundamental challenge in emotion research is measuring feeling states with\nhigh granularity and temporal precision without disrupting the emotion\ngeneration process. Here we introduce and validate a new approach in which\nresponses are sparsely sampled and the missing data are recovered using a\ncomputational technique known as collaborative filtering (CF). This approach\nleverages structured covariation across individual experiences and is available\nin Neighbors, an open-source Python toolbox. We validate our approach across\nthree different experimental contexts by recovering dense individual ratings\nusing only a small subset of the original data. In dataset 1, participants\n(n=316) separately rated 112 emotional images on 6 different discrete emotions.\nIn dataset 2, participants (n=203) watched 8 short emotionally engaging\nautobiographical stories while simultaneously providing moment-by-moment\nratings of the intensity of their affective experience. In dataset 3,\nparticipants (n=60) with distinct social preferences made 76 decisions about\nhow much money to return in a hidden multiplier trust game. Across all\nexperimental contexts, CF was able to accurately recover missing data and\nimportantly outperformed mean imputation, particularly in contexts with greater\nindividual variability. This approach will enable new avenues for affective\nscience research by allowing researchers to acquire high dimensional ratings\nfrom emotional experiences with minimal disruption to the emotion-generation\nprocess.",
    "descriptor": "\nComments: 21 pages, 8 figures\n",
    "authors": [
      "Eshin Jolly",
      "Max Farrens",
      "Nathan Greenstein",
      "Hedwig Eisenbarth",
      "Marianne Reddan",
      "Eric Andrews",
      "Tor D. Wager",
      "Luke J. Chang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.06906"
  },
  {
    "id": "arXiv:2109.06907",
    "title": "Shape-adaptive Hysteresis Compensation for Tendon-driven Continuum  Manipulators",
    "abstract": "Tendon-driven continuum manipulators (TDCM) are commonly used in minimally\ninvasive surgical systems due to their long, thin, flexible structure that is\ncompliant in narrow or tortuous environments. There exist many researches for\nprecise tip control of the articulating section. However, these models do not\naccount for the proximal shaft shape of TDCM, affecting the tip controls in\npractical settings. In this paper, we propose a gradient-based shift detection\nmethod based on motor current that can easily find the offset of task space\nmodels (i.e., hysteresis). We analyze our proposed methods with multiple\nIntra-cardiac Echocardiography catheters, which are typical commercial example\nof TDCM. Our results show that the errors from varied proximal shape are\nconsiderably reduced, and the accuracy of the tip manipulation is improved when\nchanging external environmental structures.",
    "descriptor": "",
    "authors": [
      "Young-Ho Kim",
      "Tommaso Mansi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06907"
  },
  {
    "id": "arXiv:2109.06919",
    "title": "Deploying clinical machine learning? Consider the following...",
    "abstract": "Despite the intense attention and investment into clinical machine learning\n(CML) research, relatively few applications convert to clinical practice. While\nresearch is important in advancing the state-of-the-art, translation is equally\nimportant in bringing these technologies into a position to ultimately impact\npatient care and live up to extensive expectations surrounding AI in\nhealthcare. To better characterize a holistic perspective among researchers and\npractitioners, we survey several participants with experience in developing CML\nfor clinical deployment about their learned experiences. We collate these\ninsights and identify several main categories of barriers and pitfalls in order\nto better design and develop clinical machine learning applications.",
    "descriptor": "",
    "authors": [
      "Charles Lu",
      "Ken Chang",
      "Praveer Singh",
      "Stuart Pomerantz",
      "Sean Doyle",
      "Sujay Kakarmath",
      "Christopher Bridge",
      "Jayashree Kalpathy-Cramer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.06919"
  },
  {
    "id": "arXiv:2109.06922",
    "title": "Application of integral invariants to apictorial jigsaw puzzle assembly",
    "abstract": "We present a method for the automatic assembly of apictorial jigsaw puzzles.\nThis method relies on integral area invariants for shape matching and an\noptimization process to aggregate shape matches into a final puzzle assembly.\nAssumptions about individual piece shape or arrangement are not necessary. We\nillustrate our method by solving example puzzles of various shapes and sizes.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Peter Illig",
      "Robert Thompson",
      "Qimeng Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2109.06922"
  },
  {
    "id": "arXiv:2109.06923",
    "title": "Research Project 2: Drone-supported AI-based Generation of 3D Maps of  Indoor Radio Environments",
    "abstract": "A Radio Environment Map (REM) is a powerful tool in enhancing the experience\nof radio-enabled agents but building such a REM can be a laborious undertaking,\nespecially in three dimensions. This project shows how such a REM of an indoor\nthree-dimensional space can be generated in an autonomous and scalable way.\nBuilding on the results of the preceding Research Project 1, multiple drones\nare used to map the WiFi signals present in such a space in a real-world\nenvironment where the drones are each able to visit 36 waypoints and\ncollectively gather thousands of WiFi beacon data samples. This report also\nincludes an analysis of the collected data and concludes by proposing\nmachine-learning based techniques to predict the signal strength of known\naccess points in locations not visited by the drones.",
    "descriptor": "\nComments: 7 pages, 9 figures\n",
    "authors": [
      "Ken Mendes"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.06923"
  },
  {
    "id": "arXiv:2109.06926",
    "title": "A trainable monogenic ConvNet layer robust in front of large contrast  changes in image classification",
    "abstract": "Convolutional Neural Networks (ConvNets) at present achieve remarkable\nperformance in image classification tasks. However, current ConvNets cannot\nguarantee the capabilities of the mammalian visual systems such as invariance\nto contrast and illumination changes. Some ideas to overcome the illumination\nand contrast variations usually have to be tuned manually and tend to fail when\ntested with other types of data degradation. In this context, we present a new\nbio-inspired {entry} layer, M6, which detects low-level geometric features\n(lines, edges, and orientations) which are similar to patterns detected by the\nV1 visual cortex. This new trainable layer is capable of coping with image\nclassification even with large contrast variations. The explanation for this\nbehavior is the monogenic signal geometry, which represents each pixel value in\na 3D space using quaternions, a fact that confers a degree of explainability to\nthe networks. We compare M6 with a conventional convolutional layer (C) and a\ndeterministic quaternion local phase layer (Q9). The experimental setup {is\ndesigned to evaluate the robustness} of our M6 enriched ConvNet model and\nincludes three architectures, four datasets, three types of contrast\ndegradation (including non-uniform haze degradations). The numerical results\nreveal that the models with M6 are the most robust in front of any kind of\ncontrast variations. This amounts to a significant enhancement of the C models,\nwhich usually have reasonably good performance only when the same training and\ntest degradation are used, except for the case of maximum degradation.\nMoreover, the Structural Similarity Index Measure (SSIM) is used to analyze and\nexplain the robustness effect of the M6 feature maps under any kind of contrast\ndegradations.",
    "descriptor": "\nComments: \"For associated code, see this https URL\"\n",
    "authors": [
      "E. Ulises Moya-S\u00e1nchez",
      "Sebasti\u00e1 Xambo-Descamps",
      "Abraham S\u00e1nchez",
      "Sebasti\u00e1n Salazar-Colores",
      "Ulises Cort\u00e9s"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06926"
  },
  {
    "id": "arXiv:2109.06931",
    "title": "Measurement and Analysis of GPU-accelerated Applications with HPCToolkit",
    "abstract": "To address the challenge of performance analysis on the US DOE's forthcoming\nexascale supercomputers, Rice University has been extending its HPCToolkit\nperformance tools to support measurement and analysis of GPU-accelerated\napplications. To help developers understand the performance of accelerated\napplications as a whole, HPCToolkit's measurement and analysis tools attribute\nmetrics to calling contexts that span both CPUs and GPUs. To measure\nGPU-accelerated applications efficiently, HPCToolkit employs a novel wait-free\ndata structure to coordinate monitoring and attribution of GPU performance. To\nhelp developers understand the performance of complex GPU code generated from\nhigh-level programming models, HPCToolkit constructs sophisticated\napproximations of call path profiles for GPU computations. To support\nfine-grained analysis and tuning, HPCToolkit uses PC sampling and\ninstrumentation to measure and attribute GPU performance metrics to source\nlines, loops, and inlined code. To supplement fine-grained measurements,\nHPCToolkit can measure GPU kernel executions using hardware performance\ncounters. To provide a view of how an execution evolves over time, HPCToolkit\ncan collect, analyze, and visualize call path traces within and across nodes.\nFinally, on NVIDIA GPUs, HPCToolkit can derive and attribute a collection of\nuseful performance metrics based on measurements using GPU PC samples. We\nillustrate HPCToolkit's new capabilities for analyzing GPU-accelerated\napplications with several codes developed as part of the Exascale Computing\nProject.",
    "descriptor": "",
    "authors": [
      "Keren Zhou",
      "Laksono Adhianto",
      "Jonathon Anderson",
      "Aaron Cherian",
      "Dejan Grubisic",
      "Mark Krentel",
      "Yumeng Liu",
      "Xiaozhu Meng",
      "John Mellor-Crummey"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.06931"
  },
  {
    "id": "arXiv:2109.06932",
    "title": "A Crawler Architecture for Harvesting the Clear, Social, and Dark Web  for IoT-Related Cyber-Threat Intelligence",
    "abstract": "The clear, social, and dark web have lately been identified as rich sources\nof valuable cyber-security information that -given the appropriate tools and\nmethods-may be identified, crawled and subsequently leveraged to actionable\ncyber-threat intelligence. In this work, we focus on the information gathering\ntask, and present a novel crawling architecture for transparently harvesting\ndata from security websites in the clear web, security forums in the social\nweb, and hacker forums/marketplaces in the dark web. The proposed architecture\nadopts a two-phase approach to data harvesting. Initially a machine\nlearning-based crawler is used to direct the harvesting towards websites of\ninterest, while in the second phase state-of-the-art statistical language\nmodelling techniques are used to represent the harvested information in a\nlatent low-dimensional feature space and rank it based on its potential\nrelevance to the task at hand. The proposed architecture is realised using\nexclusively open-source tools, and a preliminary evaluation with crowdsourced\nresults demonstrates its effectiveness.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Paris Koloveas",
      "Thanasis Chantzios",
      "Christos Tryfonopoulos",
      "Spiros Skiadopoulos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06932"
  },
  {
    "id": "arXiv:2109.06935",
    "title": "On the Language-specificity of Multilingual BERT and the Impact of  Fine-tuning",
    "abstract": "Recent work has shown evidence that the knowledge acquired by multilingual\nBERT (mBERT) has two components: a language-specific and a language-neutral\none. This paper analyses the relationship between them, in the context of\nfine-tuning on two tasks -- POS tagging and natural language inference -- which\nrequire the model to bring to bear different degrees of language-specific\nknowledge. Visualisations reveal that mBERT loses the ability to cluster\nrepresentations by language after fine-tuning, a result that is supported by\nevidence from language identification experiments. However, further experiments\non 'unlearning' language-specific representations using gradient reversal and\niterative adversarial learning are shown not to add further improvement to the\nlanguage-independent component over and above the effect of fine-tuning. The\nresults presented here suggest that the process of fine-tuning causes a\nreorganisation of the model's limited representational capacity, enhancing\nlanguage-independent representations at the expense of language-specific ones.",
    "descriptor": "\nComments: 22 pages, 6 figures, 5 tables, to appear in BlackBoxNLP 2021\n",
    "authors": [
      "Marc Tanti",
      "Lonneke van der Plas",
      "Claudia Borg",
      "Albert Gatt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.06935"
  },
  {
    "id": "arXiv:2109.06939",
    "title": "The Stem Cell Hypothesis: Dilemma behind Multi-Task Learning with  Transformer Encoders",
    "abstract": "Multi-task learning with transformer encoders (MTL) has emerged as a powerful\ntechnique to improve performance on closely-related tasks for both accuracy and\nefficiency while a question still remains whether or not it would perform as\nwell on tasks that are distinct in nature. We first present MTL results on five\nNLP tasks, POS, NER, DEP, CON, and SRL, and depict its deficiency over\nsingle-task learning. We then conduct an extensive pruning analysis to show\nthat a certain set of attention heads get claimed by most tasks during MTL, who\ninterfere with one another to fine-tune those heads for their own objectives.\nBased on this finding, we propose the Stem Cell Hypothesis to reveal the\nexistence of attention heads naturally talented for many tasks that cannot be\njointly trained to create adequate embeddings for all of those tasks. Finally,\nwe design novel parameter-free probes to justify our hypothesis and demonstrate\nhow attention heads are transformed across the five tasks during MTL through\nlabel analysis.",
    "descriptor": "\nComments: Accepted to EMNLP 2021: The 2021 Conference on Empirical Methods in Natural Language Processing\n",
    "authors": [
      "Han He",
      "Jinho D. Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06939"
  },
  {
    "id": "arXiv:2109.06941",
    "title": "Monotone Complexity of Spanning Tree Polynomial Re-visited",
    "abstract": "We prove two results that shed new light on the monotone complexity of the\nspanning tree polynomial, a classic polynomial in algebraic complexity and\nbeyond.\nFirst, we show that the spanning tree polynomials having $n$ variables and\ndefined over constant-degree expander graphs, have monotone arithmetic\ncomplexity $2^{\\Omega(n)}$. This yields the first strongly exponential lower\nbound on the monotone arithmetic circuit complexity for a polynomial in VP.\nBefore this result, strongly exponential size monotone lower bounds were known\nonly for explicit polynomials in VNP (Gashkov-Sergeev'12, Raz-Yehudayoff'11,\nSrinivasan'20, Cavalar-Kumar-Rossman'20, Hrubes-Yehudayoff'21).\nRecently, Hrubes'20 initiated a program to prove lower bounds against general\narithmetic circuits by proving $\\epsilon$-sensitive lower bounds for monotone\narithmetic circuits for a specific range of values for $\\epsilon \\in (0,1)$. We\nconsider the spanning tree polynomial $ST_{n}$ defined over the complete graph\non $n$ vertices and show that the polynomials $F_{n-1,n} - \\epsilon \\cdot\nST_{n}$ and $F_{n-1,n} + \\epsilon \\cdot ST_{n}$ defined over $n^2$ variables,\nhave monotone circuit complexity $2^{\\Omega(n)}$ if $\\epsilon \\geq\n2^{-\\Omega(n)}$ and $F_{n-1,n} = \\prod_{i=2}^n (x_{i,1} +\\cdots + x_{i,n})$ is\nthe complete set-multilinear polynomial. This provides the first\n$\\epsilon$-sensitive exponential lower bound for a family of polynomials inside\nVP. En-route, we consider a problem in 2-party, best partition communication\ncomplexity of deciding whether two sets of oriented edges distributed among\nAlice and Bob form a spanning tree or not. We prove that there exists a fixed\ndistribution, under which the problem has low discrepancy with respect to every\nnearly-balanced partition. This result could be of interest beyond algebraic\ncomplexity.",
    "descriptor": "\nComments: 20 pages, 3 figures\n",
    "authors": [
      "Arkadev Chattopadhyay",
      "Rajit Datta",
      "Utsab Ghosal",
      "Partha Mukhopadhyay"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.06941"
  },
  {
    "id": "arXiv:2109.06944",
    "title": "Minimum Path Star Topology Algorithms for Weighted Regions and Obstacles",
    "abstract": "Shortest path algorithms have played a key role in the past century, paving\nthe way for modern day GPS systems to find optimal routes along static systems\nin fractions of a second. One application of these algorithms includes\noptimizing the total distance of power lines (specifically in star topological\nconfigurations). Due to the relevancy of discovering well-connected electrical\nsystems in certain areas, finding a minimum path that is able to account for\ngeological features would have far-reaching consequences in lowering the cost\nof electric power transmission. We initialize our research by proving the\nconvex hull as an effective bounding mechanism for star topological minimum\npath algorithms. Building off this bounding, we propose novel algorithms to\nmanage certain cases that lack existing methods (weighted regions and\nobstacles) by discretizing Euclidean space into squares and combining\npre-existing algorithms that calculate local minimums that we believe have a\npossibility of being the absolute minimum. We further designate ways to\nevaluate iterations necessary to reach some level of accuracy. Both of these\nnovel algorithms fulfill certain niches that past literature does not cover.",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Tyler King",
      "Michael Soltys"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06944"
  },
  {
    "id": "arXiv:2109.06950",
    "title": "Automatically Exposing Problems with Neural Dialog Models",
    "abstract": "Neural dialog models are known to suffer from problems such as generating\nunsafe and inconsistent responses. Even though these problems are crucial and\nprevalent, they are mostly manually identified by model designers through\ninteractions. Recently, some research instructs crowdworkers to goad the bots\ninto triggering such problems. However, humans leverage superficial clues such\nas hate speech, while leaving systematic problems undercover. In this paper, we\npropose two methods including reinforcement learning to automatically trigger a\ndialog model into generating problematic responses. We show the effect of our\nmethods in exposing safety and contradiction issues with state-of-the-art\ndialog models.",
    "descriptor": "",
    "authors": [
      "Dian Yu",
      "Kenji Sagae"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06950"
  },
  {
    "id": "arXiv:2109.06952",
    "title": "Residual Adapters for Parameter-Efficient ASR Adaptation to Atypical and  Accented Speech",
    "abstract": "Automatic Speech Recognition (ASR) systems are often optimized to work best\nfor speakers with canonical speech patterns. Unfortunately, these systems\nperform poorly when tested on atypical speech and heavily accented speech. It\nhas previously been shown that personalization through model fine-tuning\nsubstantially improves performance. However, maintaining such large models per\nspeaker is costly and difficult to scale. We show that by adding a relatively\nsmall number of extra parameters to the encoder layers via so-called residual\nadapter, we can achieve similar adaptation gains compared to model fine-tuning,\nwhile only updating a tiny fraction (less than 0.5%) of the model parameters.\nWe demonstrate this on two speech adaptation tasks (atypical and accented\nspeech) and for two state-of-the-art ASR architectures.",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Katrin Tomanek",
      "Vicky Zayats",
      "Dirk Padfield",
      "Kara Vaillancourt",
      "Fadi Biadsy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.06952"
  },
  {
    "id": "arXiv:2109.06956",
    "title": "A fast, high-order numerical method for the simulation of  single-excitation states in quantum optics",
    "abstract": "We consider the numerical solution of a nonlocal partial differential\nequation which models the process of collective spontaneous emission in a\ntwo-level atomic system containing a single photon. We reformulate the problem\nas an integro-differential equation for the atomic degrees of freedom, and\ndescribe an efficient solver for the case of a Gaussian atomic density. The\nproblem of history dependence arising from the integral formulation is\naddressed using sum-of-exponentials history compression. We demonstrate the\nsolver on two systems of physical interest: in the first, an initially-excited\natom decays into a photon by spontaneous emission, and in the second, a photon\npulse is used to an excite an atom, which then decays.",
    "descriptor": "",
    "authors": [
      "Jeremy Hoskins",
      "Jason Kaye",
      "Manas Rachh",
      "John C. Schotland"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.06956"
  },
  {
    "id": "arXiv:2109.06958",
    "title": "Probabilistic Analysis of Euclidean Capacitated Vehicle Routing",
    "abstract": "We give a probabilistic analysis of the unit-demand Euclidean capacitated\nvehicle routing problem in the random setting, where the input distribution\nconsists of $n$ unit-demand customers modeled as independent, identically\ndistributed uniform random points in the two-dimensional plane. The objective\nis to visit every customer using a set of routes of minimum total length, such\nthat each route visits at most $k$ customers, where $k$ is the capacity of a\nvehicle. All of the following results are in the random setting and hold\nasymptotically almost surely.\nThe best known polynomial-time approximation for this problem is the iterated\ntour partitioning (ITP) algorithm, introduced in 1985 by Haimovich and Rinnooy\nKan. They showed that the ITP algorithm is near-optimal when $k$ is either\n$o(\\sqrt{n})$ or $\\omega(\\sqrt{n})$, and they asked whether the ITP algorithm\nwas also effective in the intermediate range. In this work, we show that when\n$k=\\sqrt{n}$, the ITP algorithm is at best a $(1+c_0)$-approximation for some\npositive constant $c_0$.\nOn the other hand, the approximation ratio of the ITP algorithm was known to\nbe at most $0.995+\\alpha$ due to Bompadre, Dror, and Orlin, where $\\alpha$ is\nthe approximation ratio of an algorithm for the traveling salesman problem. In\nthis work, we improve the upper bound on the approximation ratio of the ITP\nalgorithm to $0.915+\\alpha$. Our analysis is based on a new lower bound on the\noptimal cost for the metric capacitated vehicle routing problem, which may be\nof independent interest.",
    "descriptor": "",
    "authors": [
      "Claire Mathieu",
      "Hang Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06958"
  },
  {
    "id": "arXiv:2109.06961",
    "title": "Building Accurate Simple Models with Multihop",
    "abstract": "Knowledge transfer from a complex high performing model to a simpler and\npotentially low performing one in order to enhance its performance has been of\ngreat interest over the last few years as it finds applications in important\nproblems such as explainable artificial intelligence, model compression, robust\nmodel building and learning from small data. Known approaches to this problem\n(viz. Knowledge Distillation, Model compression, ProfWeight, etc.) typically\ntransfer information directly (i.e. in a single/one hop) from the complex model\nto the chosen simple model through schemes that modify the target or reweight\ntraining examples on which the simple model is trained. In this paper, we\npropose a meta-approach where we transfer information from the complex model to\nthe simple model by dynamically selecting and/or constructing a sequence of\nintermediate models of decreasing complexity that are less intricate than the\noriginal complex model. Our approach can transfer information between\nconsecutive models in the sequence using any of the previously mentioned\napproaches as well as work in 1-hop fashion, thus generalizing these\napproaches. In the experiments on real data, we observe that we get consistent\ngains for different choices of models over 1-hop, which on average is more than\n2\\% and reaches up to 8\\% in a particular case. We also empirically analyze\nconditions under which the multi-hop approach is likely to be beneficial over\nthe traditional 1-hop approach, and report other interesting insights. To the\nbest of our knowledge, this is the first work that proposes such a multi-hop\napproach to perform knowledge transfer given a single high performing complex\nmodel, making it in our opinion, an important methodological contribution.",
    "descriptor": "",
    "authors": [
      "Amit Dhurandhar",
      "Tejaswini Pedapati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06961"
  },
  {
    "id": "arXiv:2109.06966",
    "title": "Searching for More Efficient Dynamic Programs",
    "abstract": "Computational models of human language often involve combinatorial problems.\nFor instance, a probabilistic parser may marginalize over exponentially many\ntrees to make predictions. Algorithms for such problems often employ dynamic\nprogramming and are not always unique. Finding one with optimal asymptotic\nruntime can be unintuitive, time-consuming, and error-prone. Our work aims to\nautomate this laborious process. Given an initial correct declarative program,\nwe search for a sequence of semantics-preserving transformations to improve its\nrunning time as much as possible. To this end, we describe a set of program\ntransformations, a simple metric for assessing the efficiency of a transformed\nprogram, and a heuristic search procedure to improve this metric. We show that\nin practice, automated search -- like the mental search performed by human\nprogrammers -- can find substantial improvements to the initial program.\nEmpirically, we show that many common speed-ups described in the NLP literature\ncould have been discovered automatically by our system.",
    "descriptor": "",
    "authors": [
      "Tim Vieira",
      "Ryan Cotterell",
      "Jason Eisner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06966"
  },
  {
    "id": "arXiv:2109.06967",
    "title": "Grounding-aware RRT* for Path Planning and Safe Navigation of Marine  Crafts in Confined Waters",
    "abstract": "The paper presents a path planning algorithm based on RRT* that addresses the\nrisk of grounding during evasive manoeuvres to avoid collision. The planner\nachieves this objective by integrating a collective navigation experience with\nthe systematic use of water depth information from the electronic navigational\nchart. Multivariate kernel density estimation is applied to historical AIS data\nto generate a probabilistic model describing seafarer's best practices while\nsailing in confined waters. This knowledge is then encoded into the RRT* cost\nfunction to penalize path deviations that would lead own ship to sail in\nshallow waters. Depth contours satisfying the own ship draught define the\nactual navigable area, and triangulation of this non-convex region is adopted\nto enable uniform sampling. This ensures the optimal path deviation.",
    "descriptor": "\nComments: Accepted for publication at the 13th IFAC Conference on Control Applications in Marine Systems, Robotics, and Vehicles, 2021 (CAMS)\n",
    "authors": [
      "Thomas T. Enevoldsen",
      "Roberto Galeazzi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06967"
  },
  {
    "id": "arXiv:2109.06969",
    "title": "Multi-modal Wound Classification using Wound Image and Location by Deep  Neural Network",
    "abstract": "Wound classification is an essential step of wound diagnosis. An efficient\nclassifier can assist wound specialists in classifying wound types with less\nfinancial and time costs and help them decide an optimal treatment procedure.\nThis study developed a deep neural network-based multi-modal classifier using\nwound images and their corresponding locations to categorize wound images into\nmultiple classes, including diabetic, pressure, surgical, and venous ulcers. A\nbody map is also developed to prepare the location data, which can help wound\nspecialists tag wound locations more efficiently. Three datasets containing\nimages and their corresponding location information are designed with the help\nof wound specialists. The multi-modal network is developed by concatenating the\nimage-based and location-based classifier's outputs with some other\nmodifications. The maximum accuracy on mixed-class classifications (containing\nbackground and normal skin) varies from 77.33% to 100% on different\nexperiments. The maximum accuracy on wound-class classifications (containing\nonly diabetic, pressure, surgical, and venous) varies from 72.95% to 98.08% on\ndifferent experiments. The proposed multi-modal network also shows a\nsignificant improvement in results from the previous works of literature.",
    "descriptor": "\nComments: 30 pages, 10 figures, 15 tables\n",
    "authors": [
      "D. M. Anisuzzaman",
      "Yash Patel",
      "Behrouz Rostami",
      "Jeffrey Niezgoda",
      "Sandeep Gopalakrishnan",
      "Zeyun Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06969"
  },
  {
    "id": "arXiv:2109.06974",
    "title": "Algorithmic Auditing and Social Justice: Lessons from the History of  Audit Studies",
    "abstract": "Algorithmic audits have been embraced as tools to investigate the functioning\nand consequences of sociotechnical systems. Though the term is used somewhat\nloosely in the algorithmic context and encompasses a variety of methods, it\nmaintains a close connection to audit studies in the social sciences--which\nhave, for decades, used experimental methods to measure the prevalence of\ndiscrimination across domains like housing and employment. In the social\nsciences, audit studies originated in a strong tradition of social justice and\nparticipatory action, often involving collaboration between researchers and\ncommunities; but scholars have argued that, over time, social science audits\nhave become somewhat distanced from these original goals and priorities. We\ndraw from this history in order to highlight difficult tensions that have\nshaped the development of social science audits, and to assess their\nimplications in the context of algorithmic auditing. In doing so, we put forth\nconsiderations to assist in the development of robust and engaged assessments\nof sociotechnical systems that draw from auditing's roots in racial equity and\nsocial justice.",
    "descriptor": "",
    "authors": [
      "Briana Vecchione",
      "Solon Barocas",
      "Karen Levy"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.06974"
  },
  {
    "id": "arXiv:2109.06976",
    "title": "GRiD: GPU-Accelerated Rigid Body Dynamics with Analytical Gradients",
    "abstract": "We introduce GRiD: a GPU-accelerated library for computing rigid body\ndynamics with analytical gradients. GRiD was designed to accelerate the\nnonlinear trajectory optimization subproblem used in state-of-the-art robotic\nplanning, control, and machine learning. Each iteration of nonlinear trajectory\noptimization requires tens to hundreds of naturally parallel computations of\nrigid body dynamics and their gradients. GRiD leverages URDF parsing and code\ngeneration to deliver optimized dynamics kernels that not only expose\nGPU-friendly computational patterns, but also take advantage of both\nfine-grained parallelism within each computation and coarse-grained parallelism\nbetween computations. Through this approach, when performing multiple\ncomputations of rigid body dynamics algorithms, GRiD provides as much as a 7.6x\nspeedup over a state-of-the-art, multi-threaded CPU implementation, and\nmaintains as much as a 2.6x speedup when accounting for I/O overhead. We\nrelease GRiD as an open-source library, so that it can be leveraged by the\nrobotics community to easily and efficiently accelerate rigid body dynamics on\nthe GPU.",
    "descriptor": "\nComments: 8 pages, 5 figures, 1 data table\n",
    "authors": [
      "Brian Plancher",
      "Sabrina M. Neuman",
      "Radhika Ghosal",
      "Scott Kuindersma",
      "Vijay Janapa Reddi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06976"
  },
  {
    "id": "arXiv:2109.06977",
    "title": "Design Guidelines for Prompt Engineering Text-to-Image Generative Models",
    "abstract": "Text-to-image generative models are a new and powerful way to generate visual\nartwork. The free-form nature of text as interaction is double-edged; while\nusers have access to an infinite range of generations, they also must engage in\nbrute-force trial and error with the text prompt when the result quality is\npoor. We conduct a study exploring what prompt components and model parameters\ncan help produce coherent outputs. In particular, we study prompts structured\nto include subject and style and investigate success and failure modes within\nthese dimensions. Our evaluation of 5493 generations over the course of five\nexperiments spans 49 abstract and concrete subjects as well as 51 abstract and\nfigurative styles. From this evaluation, we present design guidelines that can\nhelp people find better outcomes from text-to-image generative models.",
    "descriptor": "",
    "authors": [
      "Vivian Liu",
      "Lydia B. Chilton"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.06977"
  },
  {
    "id": "arXiv:2109.06978",
    "title": "Event-Triggered Distributed Stabilization of Interconnected Multiagent  Systems with Abnormal Agent and Control Layers: Theoretical Analysis",
    "abstract": "A graph theoretic framework recently has been proposed to stabilize\ninterconnected multiagent systems in a distributed fashion, while\nsystematically capturing the architectural aspect of cyber-physical systems\nwith separate agent or physical layer and control or cyber layer. Based on that\ndevelopment, in addition to the modeling uncertainties over the agent layer, we\nconsider a scenario where the control layer is subject to the denial of service\nattacks. We propose a step-by-step procedure to design a control layer that, in\nthe presence of the aforementioned abnormalities, guarantees a level of\nrobustness and resiliency for the final two-layer interconnected multiagent\nsystem. The incorporation of an event-triggered strategy further ensures an\neffective use of the limited energy and communication resources over the\ncontrol layer. We theoretically prove the resilient, robust, and Zeno-free\nconvergence of all state trajectories to the origin and, via a simulation\nstudy, discuss the feasibility of the proposed ideas.",
    "descriptor": "",
    "authors": [
      "Vahid Rezaei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.06978"
  },
  {
    "id": "arXiv:2109.06979",
    "title": "CORNET 2.0: A Co-Simulation Middleware forRobot Networks",
    "abstract": "We present a networked co-simulation framework for multi-robot systems\napplications. We require a simulation framework that captures both physical\ninteractions and communications aspects to effectively design such complex\nsystems. This is necessary to co-design the multi-robots' autonomy logic and\nthe communication protocols. The proposed framework extends existing tools to\nsimulate the robot's autonomy and network-related aspects. We have used Gazebo\nwith ROS/ROS2 to develop the autonomy logic for robots and mininet-WiFi as the\nnetwork simulator to capture the cyber-physical systems properties of the\nmulti-robot system. This framework addresses the need to seamlessly integrate\nthe two simulation environments by synchronizing mobility and time, allowing\nfor easy migration of the algorithms to real platforms.",
    "descriptor": "",
    "authors": [
      "Srikrishna Acharya",
      "Bharadwaj Amrutur",
      "Mukunda Bharatheesha",
      "Yogesh Simmhan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06979"
  },
  {
    "id": "arXiv:2109.06980",
    "title": "Explainable Identification of Dementia from Transcripts using  Transformer Networks",
    "abstract": "Alzheimer's disease (AD) is the main cause of dementia which is accompanied\nby loss of memory and may lead to severe consequences in peoples' everyday life\nif not diagnosed on time. Very few works have exploited transformer-based\nnetworks and despite the high accuracy achieved, little work has been done in\nterms of model interpretability. In addition, although Mini-Mental State Exam\n(MMSE) scores are inextricably linked with the identification of dementia,\nresearch works face the task of dementia identification and the task of the\nprediction of MMSE scores as two separate tasks. In order to address these\nlimitations, we employ several transformer-based models, with BERT achieving\nthe highest accuracy accounting for 85.56%. Concurrently, we propose an\ninterpretable method to detect AD patients based on siamese networks reaching\naccuracy up to 81.18%. Next, we introduce two multi-task learning models, where\nthe main task refers to the identification of dementia (binary classification),\nwhile the auxiliary one corresponds to the identification of the severity of\ndementia (multiclass classification). Our model obtains accuracy equal to\n84.99% on the detection of AD patients in the multi-task learning setting.\nFinally, we present some new methods to identify the linguistic patterns used\nby AD patients and non-AD ones, including text statistics, vocabulary\nuniqueness, word usage, correlations via a detailed linguistic analysis, and\nexplainability techniques (LIME). Findings indicate significant differences in\nlanguage between AD and non-AD patients.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Loukas Ilias",
      "Dimitris Askounis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06980"
  },
  {
    "id": "arXiv:2109.06982",
    "title": "Generalized Multivariable Grid-Forming Control Design for Power  Converters",
    "abstract": "The grid-forming converter is an important unit in the future power system\nwith more inverter-interfaced generators. However, improving its performance is\nstill a key challenge. This paper proposes a generalized architecture of the\ngrid-forming converter from the view of multivariable feedback control. As a\nresult, many of the existing popular control strategies, i.e., droop control,\npower synchronization control, virtual synchronous generator control, matching\ncontrol, dispatchable virtual oscillator control, and their improved forms are\nunified into a multivariable feedback control transfer matrix working on\nseveral linear and nonlinear error signals. Meanwhile, unlike the traditional\nassumptions of decoupling between AC and DC control, active power and reactive\npower control, the proposed configuration simultaneously takes all of them into\nconsideration, which therefore can provide better performance. As an example, a\nnew multi-input-multi-output-based grid-forming (MIMO-GFM) control is proposed\nbased on the generalized configuration. To cope with the multivariable\nfeedback, an optimal and structured $H_{\\infty}$ synthesis is used to design\nthe control parameters. At last, simulation and experimental results show\nsuperior performance and robustness of the proposed configuration and control.",
    "descriptor": "",
    "authors": [
      "Meng Chen",
      "Dao Zhou",
      "Ali Tayyebi",
      "Eduardo Prieto-Araujo",
      "Florian D\u00f6rfler",
      "Frede Blaabjerg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06982"
  },
  {
    "id": "arXiv:2109.06987",
    "title": "NOPE: A Corpus of Naturally-Occurring Presuppositions in English",
    "abstract": "Understanding language requires grasping not only the overtly stated content,\nbut also making inferences about things that were left unsaid. These inferences\ninclude presuppositions, a phenomenon by which a listener learns about new\ninformation through reasoning about what a speaker takes as given.\nPresuppositions require complex understanding of the lexical and syntactic\nproperties that trigger them as well as the broader conversational context. In\nthis work, we introduce the Naturally-Occurring Presuppositions in English\n(NOPE) Corpus to investigate the context-sensitivity of 10 different types of\npresupposition triggers and to evaluate machine learning models' ability to\npredict human inferences. We find that most of the triggers we investigate\nexhibit moderate variability. We further find that transformer-based models\ndraw correct inferences in simple cases involving presuppositions, but they\nfail to capture the minority of exceptional cases in which human judgments\nreveal complex interactions between context and triggers.",
    "descriptor": "\nComments: CoNLL 2021. Data and code available at this https URL\n",
    "authors": [
      "Alicia Parrish",
      "Sebastian Schuster",
      "Alex Warstadt",
      "Omar Agha",
      "Soo-Hwan Lee",
      "Zhuoye Zhao",
      "Samuel R. Bowman",
      "Tal Linzen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06987"
  },
  {
    "id": "arXiv:2109.06990",
    "title": "Personalization, Privacy, and Me",
    "abstract": "News recommendation and personalization is not a solved problem. People are\ngrowing concerned of their data being collected in excess in the name of\npersonalization and the usage of it for purposes other than the ones they would\nthink reasonable. Our experience in building personalization products for\npublishers while adhering to safeguard user privacy led us to investigate more\non the user perspective of privacy and personalization. We conducted a survey\nto explore people's experience with personalization and privacy and the\nviewpoints of different age groups. In this paper, we share our major findings\nwith publishers and the community that can inform algorithmic design and\nimplementation of the next generation of news recommender systems, which must\nput the human at its core and reach a balance between personalization\nexperiences and privacy to reap the benefits of both.",
    "descriptor": "\nComments: ACM CCS Concepts: Information systems~Recommender systems, Information systems~Personalization, Security and privacy~Human and societal aspects of security and privacy, General and reference~Surveys and overviews. Keywords: Personalization, Privacy, Survey\n",
    "authors": [
      "Reshma Narayanan Kutty",
      "Claudia Orellana-Rodriguez",
      "Igor Brigadir",
      "Ernesto Diaz-Aviles"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.06990"
  },
  {
    "id": "arXiv:2109.06992",
    "title": "ML-aided power allocation for Tactical MIMO",
    "abstract": "We study the problem of optimal power allocation in single-hop multi-antenna\nad-hoc wireless networks. A standard technique to solve this problem involves\noptimizing a tri-convex function under power constraints using a\nblock-coordinate-descent (BCD) based iterative algorithm. This approach, termed\nWMMSE, tends to be computationally complex and time consuming. Several\nlearning-based approaches have been proposed to speed up the power allocation\nprocess. A recent work, UWMMSE, learns an affine transformation of a WMMSE\nparameter in an unfolded structure to accelerate convergence. In spite of\nachieving promising results, its application is limited to single-antenna\nwireless networks. In this work, we present a UWMMSE framework for power\nallocation in (multiple-input multiple-output) MIMO interference networks.\nThrough an empirical study, we illustrate the superiority of our approach in\ncomparison to WMMSE and also analyze its robustness to changes in channel\nconditions and network size.",
    "descriptor": "\nComments: Under review at MILCOM 2021\n",
    "authors": [
      "Arindam Chowdhury",
      "Gunjan Verma",
      "Chirag Rao",
      "Ananthram Swami",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.06992"
  },
  {
    "id": "arXiv:2109.06998",
    "title": "$\\mathcal{L}_1$ Adaptive Augmentation for Geometric Tracking Control of  Quadrotors",
    "abstract": "This paper introduces an $\\mathcal{L}_1$ adaptive control augmentation for\ngeometric tracking control of quadrotors. In the proposed design, the\n$\\mathcal{L}_1$ augmentation handles nonlinear (time- and state-dependent)\nuncertainties in the quadrotor dynamics without assuming/enforcing parametric\nstructures, while the baseline geometric controller achieves stabilization of\nthe known nonlinear model of the system dynamics. The $\\mathcal{L}_1$\naugmentation applies to both the rotational and the translational dynamics.\nExperimental results demonstrate that the augmented geometric controller shows\nconsistent and (on average five times) smaller trajectory tracking errors\ncompared with the geometric controller alone when tested for different\ntrajectories and under various types of uncertainties/disturbances.",
    "descriptor": "",
    "authors": [
      "Zhuohuan Wu",
      "Sheng Cheng",
      "Kasey A. Ackerman",
      "Aditya Gahlawat",
      "Arun Lakshmanan",
      "Pan Zhao",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06998"
  },
  {
    "id": "arXiv:2109.06999",
    "title": "Behavior of k-NN as an Instance-Based Explanation Method",
    "abstract": "Adoption of DL models in critical areas has led to an escalating demand for\nsound explanation methods. Instance-based explanation methods are a popular\ntype that return selective instances from the training set to explain the\npredictions for a test sample. One way to connect these explanations with\nprediction is to ask the following counterfactual question - how does the loss\nand prediction for a test sample change when explanations are removed from the\ntraining set? Our paper answers this question for k-NNs which are natural\ncontenders for an instance-based explanation method. We first demonstrate\nempirically that the representation space induced by last layer of a neural\nnetwork is the best to perform k-NN in. Using this layer, we conduct our\nexperiments and compare them to influence functions (IFs)\n~\\cite{koh2017understanding} which try to answer a similar question. Our\nevaluations do indicate change in loss and predictions when explanations are\nremoved but we do not find a trend between $k$ and loss or prediction change.\nWe find significant stability in the predictions and loss of MNIST vs.\nCIFAR-10. Surprisingly, we do not observe much difference in the behavior of\nk-NNs vs. IFs on this question. We attribute this to training set subsampling\nfor IFs.",
    "descriptor": "",
    "authors": [
      "Chhavi Yadav",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06999"
  },
  {
    "id": "arXiv:2109.07000",
    "title": "Koopman Linearization for Data-Driven Batch State Estimation of  Control-Affine Systems",
    "abstract": "We present the Koopman State Estimator (KoopSE), a framework for model-free\nbatch state estimation of control-affine systems that makes no linearization\nassumptions, requires no problem-specific feature selections, and has an\ninference computational cost that is independent of the number of training\npoints. We lift the original nonlinear system into a higher-dimensional\nReproducing Kernel Hilbert Space (RKHS), where the system becomes bilinear. The\ntime-invariant model matrices can be learned by solving a least-squares problem\non training trajectories. At test time, the system is algebraically manipulated\ninto a linear time-varying system, where standard batch linear state estimation\ntechniques can be used to efficiently compute state means and covariances.\nRandom Fourier Features (RFF) are used to combine the computational efficiency\nof Koopman-based methods and the generality of kernel-embedding methods. KoopSE\nis validated experimentally on a localization task involving a mobile robot\nequipped with ultra-wideband receivers and wheel odometry. KoopSE estimates are\nmore accurate and consistent than the standard model-based extended\nRauch-Tung-Striebel (RTS) smoother, despite KoopSE having no prior knowledge of\nthe system's motion or measurement models.",
    "descriptor": "\nComments: 9 pages, 5 figures, 1 table. Submitted to IEEE RA-L. Note: version submitted to IEEE RA-L did not include the Appendix section present in this arXiv version\n",
    "authors": [
      "Zi Cong Guo",
      "Vassili Korotkine",
      "James R. Forbes",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07000"
  },
  {
    "id": "arXiv:2109.07001",
    "title": "ZFlow: Gated Appearance Flow-based Virtual Try-on with 3D Priors",
    "abstract": "Image-based virtual try-on involves synthesizing perceptually convincing\nimages of a model wearing a particular garment and has garnered significant\nresearch interest due to its immense practical applicability. Recent methods\ninvolve a two stage process: i) warping of the garment to align with the model\nii) texture fusion of the warped garment and target model to generate the\ntry-on output. Issues arise due to the non-rigid nature of garments and the\nlack of geometric information about the model or the garment. It often results\nin improper rendering of granular details. We propose ZFlow, an end-to-end\nframework, which seeks to alleviate these concerns regarding geometric and\ntextural integrity (such as pose, depth-ordering, skin and neckline\nreproduction) through a combination of gated aggregation of hierarchical flow\nestimates termed Gated Appearance Flow, and dense structural priors at various\nstage of the network. ZFlow achieves state-of-the-art results as observed\nqualitatively, and on quantitative benchmarks of image quality (PSNR, SSIM, and\nFID). The paper presents extensive comparisons with other existing solutions\nincluding a detailed user study and ablation studies to gauge the effect of\neach of our contributions on multiple datasets.",
    "descriptor": "\nComments: Accepted at ICCV 2021\n",
    "authors": [
      "Ayush Chopra",
      "Rishabh Jain",
      "Mayur Hemani",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07001"
  },
  {
    "id": "arXiv:2109.07006",
    "title": "A Three Step Training Approach with Data Augmentation for Morphological  Inflection",
    "abstract": "We present the BME submission for the SIGMORPHON 2021 Task 0 Part 1,\nGeneralization Across Typologically Diverse Languages shared task. We use an\nLSTM encoder-decoder model with three step training that is first trained on\nall languages, then fine-tuned on each language families and finally finetuned\non individual languages. We use a different type of data augmentation technique\nin the first two steps. Our system outperformed the only other submission.\nAlthough it remains worse than the Transformer baseline released by the\norganizers, our model is simpler and our data augmentation techniques are\neasily applicable to new languages. We perform ablation studies and show that\nthe augmentation techniques and the three training steps often help but\nsometimes have a negative effect.",
    "descriptor": "",
    "authors": [
      "Gabor Szolnok",
      "Botond Barta",
      "Dorina Lakatos",
      "Judit Acs"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07006"
  },
  {
    "id": "arXiv:2109.07008",
    "title": "HeMI: Multi-view Embedding in Heterogeneous Graphs",
    "abstract": "Many real-world graphs involve different types of nodes and relations between\nnodes, being heterogeneous by nature. The representation learning of\nheterogeneous graphs (HGs) embeds the rich structure and semantics of such\ngraphs into a low-dimensional space and facilitates various data mining tasks,\nsuch as node classification, node clustering, and link prediction. In this\npaper, we propose a self-supervised method that learns HG representations by\nrelying on knowledge exchange and discovery among different HG structural\nsemantics (meta-paths). Specifically, by maximizing the mutual information of\nmeta-path representations, we promote meta-path information fusion and\nconsensus, and ensure that globally shared semantics are encoded. By extensive\nexperiments on node classification, node clustering, and link prediction tasks,\nwe show that the proposed self-supervision both outperforms and improves\ncompeting methods by 1% and up to 10% for all tasks.",
    "descriptor": "",
    "authors": [
      "Costas Mavromatis",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07008"
  },
  {
    "id": "arXiv:2109.07009",
    "title": "Will this Question be Answered? Question Filtering via Answer Model  Distillation for Efficient Question Answering",
    "abstract": "In this paper we propose a novel approach towards improving the efficiency of\nQuestion Answering (QA) systems by filtering out questions that will not be\nanswered by them. This is based on an interesting new finding: the answer\nconfidence scores of state-of-the-art QA systems can be approximated well by\nmodels solely using the input question text. This enables preemptive filtering\nof questions that are not answered by the system due to their answer confidence\nscores being lower than the system threshold. Specifically, we learn\nTransformer-based question models by distilling Transformer-based answering\nmodels. Our experiments on three popular QA datasets and one industrial QA\nbenchmark demonstrate the ability of our question models to approximate the\nPrecision/Recall curves of the target QA system well. These question models,\nwhen used as filters, can effectively trade off lower computation cost of QA\nsystems for lower Recall, e.g., reducing computation by ~60%, while only losing\n~3-4% of Recall.",
    "descriptor": "\nComments: Accepted at EMNLP 2021 Main Conference (Long)\n",
    "authors": [
      "Siddhant Garg",
      "Alessandro Moschitti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07009"
  },
  {
    "id": "arXiv:2109.07012",
    "title": "Searching for Representation: A sociotechnical audit of googling for  members of U.S. Congress",
    "abstract": "High-quality online civic infrastructure is increasingly critical for the\nsuccess of democratic processes. There is a pervasive reliance on search\nengines to find facts and information necessary for political participation and\noversight. We find that approximately 10\\% of the top Google search results are\nlikely to mislead California information seekers who use search to identify\ntheir congressional representatives. 70\\% of the misleading results appear in\nfeatured snippets above the organic search results. We use both qualitative and\nquantitative methods to understand what aspects of the information ecosystem\nlead to this sociotechnical breakdown. Factors identified include Google's\nheavy reliance on Wikipedia, the lack of authoritative, machine parsable, high\naccuracy data about the identity of elected officials based on geographic\nlocation, and the search engine's treatment of under-specified queries. We\nrecommend steps that Google can take to meet its stated commitment to providing\nhigh quality civic information, and steps that information providers can take\nto improve the legibility and quality of information about congressional\nrepresentatives available to search algorithms.",
    "descriptor": "",
    "authors": [
      "Emma Lurie",
      "Deirdre K. Mulligan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.07012"
  },
  {
    "id": "arXiv:2109.07016",
    "title": "Graph Embedding via Diffusion-Wavelets-Based Node Feature Distribution  Characterization",
    "abstract": "Recent years have seen a rise in the development of representational learning\nmethods for graph data. Most of these methods, however, focus on node-level\nrepresentation learning at various scales (e.g., microscopic, mesoscopic, and\nmacroscopic node embedding). In comparison, methods for representation learning\non whole graphs are currently relatively sparse. In this paper, we propose a\nnovel unsupervised whole graph embedding method. Our method uses spectral graph\nwavelets to capture topological similarities on each k-hop sub-graph between\nnodes and uses them to learn embeddings for the whole graph. We evaluate our\nmethod against 12 well-known baselines on 4 real-world datasets and show that\nour method achieves the best performance across all experiments, outperforming\nthe current state-of-the-art by a considerable margin.",
    "descriptor": "\nComments: In CIKM 2021\n",
    "authors": [
      "Lili Wang",
      "Chenghan Huang",
      "Weicheng Ma",
      "Xinyuan Cao",
      "Soroush Vosoughi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.07016"
  },
  {
    "id": "arXiv:2109.07017",
    "title": "Written Justifications are Key to Aggregate Crowdsourced Forecasts",
    "abstract": "This paper demonstrates that aggregating crowdsourced forecasts benefits from\nmodeling the written justifications provided by forecasters. Our experiments\nshow that the majority and weighted vote baselines are competitive, and that\nthe written justifications are beneficial to call a question throughout its\nlife except in the last quarter. We also conduct an error analysis shedding\nlight into the characteristics that make a justification unreliable.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Saketh Kotamraju",
      "Eduardo Blanco"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07017"
  },
  {
    "id": "arXiv:2109.07020",
    "title": "Frequency Effects on Syntactic Rule Learning in Transformers",
    "abstract": "Pre-trained language models perform well on a variety of linguistic tasks\nthat require symbolic reasoning, raising the question of whether such models\nimplicitly represent abstract symbols and rules. We investigate this question\nusing the case study of BERT's performance on English subject-verb agreement.\nUnlike prior work, we train multiple instances of BERT from scratch, allowing\nus to perform a series of controlled interventions at pre-training time. We\nshow that BERT often generalizes well to subject-verb pairs that never occurred\nin training, suggesting a degree of rule-governed behavior. We also find,\nhowever, that performance is heavily influenced by word frequency, with\nexperiments showing that both the absolute frequency of a verb form, as well as\nthe frequency relative to the alternate inflection, are causally implicated in\nthe predictions BERT makes at inference time. Closer analysis of these\nfrequency effects reveals that BERT's behavior is consistent with a system that\ncorrectly applies the SVA rule in general but struggles to overcome strong\ntraining priors and to estimate agreement features (singular vs. plural) on\ninfrequent lexical items.",
    "descriptor": "\nComments: Camera ready for EMNLP 2021\n",
    "authors": [
      "Jason Wei",
      "Dan Garrette",
      "Tal Linzen",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07020"
  },
  {
    "id": "arXiv:2109.07022",
    "title": "How Does Counterfactually Augmented Data Impact Models for Social  Computing Constructs?",
    "abstract": "As NLP models are increasingly deployed in socially situated settings such as\nonline abusive content detection, it is crucial to ensure that these models are\nrobust. One way of improving model robustness is to generate counterfactually\naugmented data (CAD) for training models that can better learn to distinguish\nbetween core features and data artifacts. While models trained on this type of\ndata have shown promising out-of-domain generalizability, it is still unclear\nwhat the sources of such improvements are. We investigate the benefits of CAD\nfor social NLP models by focusing on three social computing constructs --\nsentiment, sexism, and hate speech. Assessing the performance of models trained\nwith and without CAD across different types of datasets, we find that while\nmodels trained on CAD show lower in-domain performance, they generalize better\nout-of-domain. We unpack this apparent discrepancy using machine explanations\nand find that CAD reduces model reliance on spurious features. Leveraging a\nnovel typology of CAD to analyze their relationship with model performance, we\nfind that CAD which acts on the construct directly or a diverse set of CAD\nleads to higher performance.",
    "descriptor": "\nComments: Preprint of a paper accepted to EMNLP 2021\n",
    "authors": [
      "Indira Sen",
      "Mattia Samory",
      "Fabian Floeck",
      "Claudia Wagner",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.07022"
  },
  {
    "id": "arXiv:2109.07023",
    "title": "Embedding Node Structural Role Identity Using Stress Majorization",
    "abstract": "Nodes in networks may have one or more functions that determine their role in\nthe system. As opposed to local proximity, which captures the local context of\nnodes, the role identity captures the functional \"role\" that nodes play in a\nnetwork, such as being the center of a group, or the bridge between two groups.\nThis means that nodes far apart in a network can have similar structural role\nidentities. Several recent works have explored methods for embedding the roles\nof nodes in networks. However, these methods all rely on either approximating\nor indirect modeling of structural equivalence. In this paper, we present a\nnovel and flexible framework using stress majorization, to transform the\nhigh-dimensional role identities in networks directly (without approximation or\nindirect modeling) to a low-dimensional embedding space. Our method is also\nflexible, in that it does not rely on specific structural similarity\ndefinitions. We evaluated our method on the tasks of node classification,\nclustering, and visualization, using three real-world and five synthetic\nnetworks. Our experiments show that our framework achieves superior results\nthan existing methods in learning node role representations.",
    "descriptor": "\nComments: In CIKM 2021\n",
    "authors": [
      "Lili Wang",
      "Chenghan Huang",
      "Weicheng Ma",
      "Ying Lu",
      "Soroush Vosoughi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07023"
  },
  {
    "id": "arXiv:2109.07024",
    "title": "DPMPC-Planner: A real-time UAV trajectory planning framework for complex  static environments with dynamic obstacles",
    "abstract": "Safe UAV navigation is challenging due to the complex environment structures,\ndynamic obstacles, and uncertainties from measurement noises and unpredictable\nmoving obstacle behaviors. Although plenty of recent works achieve safe\nnavigation in complex static environments with sophisticated mapping\nalgorithms, such as occupancy map and ESDF map, these methods cannot reliably\nhandle dynamic environments due to the mapping limitation from moving\nobstacles. To address the limitation, this paper proposes a trajectory planning\nframework to achieve safe navigation considering complex static environments\nwith dynamic obstacles. To reliably handle dynamic obstacles, we divide the\nenvironment representation into static mapping and dynamic object\nrepresentation, which can be obtained from computer vision methods. Our\nframework first generates a static trajectory based on the proposed iterative\ncorridor shrinking algorithm. Then, reactive chance-constrained model\npredictive control with temporal goal tracking is applied to avoid dynamic\nobstacles with uncertainties. The simulation results in various environments\ndemonstrate the ability of our algorithm to navigate safely in complex static\nenvironments with dynamic obstacles.",
    "descriptor": "\nComments: 7pages, 8 figures\n",
    "authors": [
      "Zhefan Xu",
      "Di Deng",
      "Yiping Dong",
      "Kenji Shimada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07024"
  },
  {
    "id": "arXiv:2109.07025",
    "title": "Globally-Attractive Logarithmic Geometric Control of a Quadrotor for  Aggressive Trajectory Tracking",
    "abstract": "We present a new quadrotor geometric control scheme that is capable of\ntracking highly aggressive trajectories. Unlike previous works, our geometric\ncontroller uses the logarithmic map of SO(3) to express rotational error in the\nLie algebra, allowing us to treat the manifold in a more effective and natural\nmanner, and can be shown to be globally attractive. We show the performance of\nour control scheme against highly aggressive trajectories in simulation\nexperiments. Additionally, we present an adaptation of this controller that\nallows us to interface effectively with the angular rate controllers on an\nonboard flight control unit and show the ability of this adapted control scheme\nto track aggressive trajectories on a quadrotor hardware platform.",
    "descriptor": "",
    "authors": [
      "Jacob Johnson",
      "Randal Beard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07025"
  },
  {
    "id": "arXiv:2109.07028",
    "title": "Avengers Ensemble! Improving Transferability of Authorship Obfuscation",
    "abstract": "Stylometric approaches have been shown to be quite effective for real-world\nauthorship attribution. To mitigate the privacy threat posed by authorship\nattribution, researchers have proposed automated authorship obfuscation\napproaches that aim to conceal the stylometric artefacts that give away the\nidentity of an anonymous document's author. Recent work has focused on\nauthorship obfuscation approaches that rely on black-box access to an\nattribution classifier to evade attribution while preserving semantics.\nHowever, to be useful under a realistic threat model, it is important that\nthese obfuscation approaches work well even when the adversary's attribution\nclassifier is different from the one used internally by the obfuscator.\nUnfortunately, existing authorship obfuscation approaches do not transfer well\nto unseen attribution classifiers. In this paper, we propose an ensemble-based\napproach for transferable authorship obfuscation. Our experiments show that if\nan obfuscator can evade an ensemble attribution classifier, which is based on\nmultiple base attribution classifiers, it is more likely to transfer to\ndifferent attribution classifiers. Our analysis shows that ensemble-based\nauthorship obfuscation achieves better transferability because it combines the\nknowledge from each of the base attribution classifiers by essentially\naveraging their decision boundaries.",
    "descriptor": "\nComments: Submitted to PETS 2021\n",
    "authors": [
      "Muhammad Haroon",
      "Muhammad Fareed Zaffar",
      "Padmini Srinivasan",
      "Zubair Shafiq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.07028"
  },
  {
    "id": "arXiv:2109.07033",
    "title": "An energy-based discontinuous Galerkin method for dynamic  Euler-Bernoulli beam equations",
    "abstract": "In this paper, an energy-based discontinuous Galerkin method for dynamic\nEuler-Bernoulli beam equations is developed. The resulting method is\nenergy-dissipating or energy-conserving depending on the simple,\nmesh-independent choice of numerical fluxes. By introducing a velocity field,\nthe original problem is transformed into a first-order in time system. In our\nformulation, the discontinuous Galerkin approximations for the original\ndisplacement field and the auxiliary velocity field are not restricted to be in\nthe same space. In particular, a given accuracy can be achieved with the fewest\ndegrees of freedom when the degree for the approximation space of the velocity\nfield is two orders lower than the degree of approximation space for the\ndisplacement field. In addition, we establish the error estimates in an energy\nnorm and demonstrate the corresponding optimal convergence in numerical\nexperiments.",
    "descriptor": "\nComments: 22\n",
    "authors": [
      "Lu Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.07033"
  },
  {
    "id": "arXiv:2109.07034",
    "title": "A discontinuous Galerkin method for nonlinear biharmonic Schr\u00f6dinger  equations",
    "abstract": "This paper proposes and analyzes an ultra-weak local discontinuous Galerkin\nscheme for one-dimensional nonlinear biharmonic Schr\\\"{o}dinger equations. We\ndevelop the paradigm of the local discontinuous Galerkin method by introducing\nthe second-order spatial derivative as an auxiliary variable instead of the\nconventional first-order derivative. The proposed semi-discrete scheme\npreserves a few physically relevant properties such as the conservation of mass\nand the conservation of Hamiltonian accompanied by its stability for the\ntargeted nonlinear biharmonic Schr\\\"{o}dinger equations. We also derive optimal\n$L^2$-error estimates of the scheme that measure both the solution and the\nauxiliary variable. Several numerical studies demonstrate and support our\ntheoretical findings.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Lu Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.07034"
  },
  {
    "id": "arXiv:2109.07035",
    "title": "Data Hunches: Incorporating Personal Knowledge into Visualizations",
    "abstract": "The trouble with data is that often it provides only an imperfect\nrepresentation of the phenomenon of interest. When reading and interpreting\ndata, personal knowledge about the data plays an important role. Data\nvisualization, however, has neither a concept defining personal knowledge about\ndatasets, nor the methods or tools to robustly integrate them into an analysis\nprocess, thus hampering analysts' ability to express their personal knowledge\nabout datasets, and others to learn from such knowledge. In this work, we\ndefine such personal knowledge about datasets as data hunches and elevate this\nknowledge to another form of data that can be externalized, visualized, and\nused for collaboration. We establish the implications of data hunches and\nprovide a design space for externalizing and communicating data hunches through\nvisualization techniques. We envision such a design space will empower users to\nexternalize their personal knowledge and support the ability to learn from\nothers' data hunches.",
    "descriptor": "",
    "authors": [
      "Haihan Lin",
      "Derya Akbaba",
      "Miriah Meyer",
      "Alexander Lex"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.07035"
  },
  {
    "id": "arXiv:2109.07036",
    "title": "PnP-DETR: Towards Efficient Visual Analysis with Transformers",
    "abstract": "Recently, DETR~\\cite{carion2020end} pioneered the solution of vision tasks\nwith transformers, it directly translates the image feature map into the object\ndetection result. Though effective, translating the full feature map can be\ncostly due to redundant computation on some area like the background. In this\nwork, we encapsulate the idea of reducing spatial redundancy into a novel poll\nand pool (PnP) sampling module, with which we build an end-to-end PnP-DETR\narchitecture that adaptively allocates its computation spatially to be more\nefficient. Concretely, the PnP module abstracts the image feature map into fine\nforeground object feature vectors and a small number of coarse background\ncontextual feature vectors. The transformer models information interaction\nwithin the fine-coarse feature space and translates the features into the\ndetection result. Moreover, the PnP-augmented model can instantly achieve\nvarious desired trade-offs between performance and computation with a single\nmodel by varying the sampled feature length, without requiring to train\nmultiple models as existing methods. Thus it offers greater flexibility for\ndeployment in diverse scenarios with varying computation constraint. We further\nvalidate the generalizability of the PnP module on \\textbf{panoptic\nsegmentation} and the recent transformer-based image recognition model\n{\\textbf{ViT}}~\\cite{dosovitskiy2020image} and show consistent efficiency gain.\nWe believe our method makes a step for efficient visual analysis with\ntransformers, wherein spatial redundancy is commonly observed. Code will be\navailable at \\url{https://github.com/twangnh/pnp-detr}.",
    "descriptor": "\nComments: accepted by ICCV 2021\n",
    "authors": [
      "Tao Wang",
      "Li Yuan",
      "Yunpeng Chen",
      "Jiashi Feng",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07036"
  },
  {
    "id": "arXiv:2109.07041",
    "title": "Coalition Game based User Association for mmWave Mobile Relay Systems in  Rail Traffic Scenarios",
    "abstract": "Rail transportation, especially, high-speed rails (HSR), is an important\ninfrastructure for the development of national economy and the promotion of\npassenger experience. Due to the large bandwidth, millimeter wave (mmWave)\ncommunication is regarded as a promising technology to meet the demand of high\ndata rates. However, since mmWave communication has the characteristic of high\nattenuation, mobile relay (MR) is considered in this paper. Also, full-duplex\n(FD) communications have been proposed to improve the spectral efficiency.\nHowever, because of the high speed, as well as the problem of penetration loss,\npassengers on the train have a poor quality of service. Consequently, an\neffective user association scheme for HSR in mmWave band is necessary. In this\npaper, we investigate the user association optimization problem in mmWave\nmobilerelay systems where the MRs operate in the FD mode. To maximize the\nsystem capacity, we propose a cooperative user association approach based on\ncoalition formation game, and develop a coalition formation algorithm to solve\nthe challenging NP-hard problem. We also prove the convergence and Nashstable\nproperty of the proposed algorithm. Extensive simulations are done to show the\nsystem performance of the proposed scheme under various network settings. It is\ndemonstrated that the proposed distributed low complexity scheme achieves a\nnearoptimal performance and outperforms two baseline schemes in terms of\naverage system throughput.",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Chen Chen",
      "Yong Niu",
      "Shiwen Mao",
      "Xiaodan Zhang",
      "Zhu Han",
      "Bo Ai",
      "Meilin Gao",
      "Huahua Xiao",
      "Ning Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.07041"
  },
  {
    "id": "arXiv:2109.07043",
    "title": "Attention Is Indeed All You Need: Semantically Attention-Guided Decoding  for Data-to-Text NLG",
    "abstract": "Ever since neural models were adopted in data-to-text language generation,\nthey have invariably been reliant on extrinsic components to improve their\nsemantic accuracy, because the models normally do not exhibit the ability to\ngenerate text that reliably mentions all of the information provided in the\ninput. In this paper, we propose a novel decoding method that extracts\ninterpretable information from encoder-decoder models' cross-attention, and\nuses it to infer which attributes are mentioned in the generated text, which is\nsubsequently used to rescore beam hypotheses. Using this decoding method with\nT5 and BART, we show on three datasets its ability to dramatically reduce\nsemantic errors in the generated outputs, while maintaining their\nstate-of-the-art quality.",
    "descriptor": "\nComments: Accepted to INLG 2021\n",
    "authors": [
      "Juraj Juraska",
      "Marilyn Walker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07043"
  },
  {
    "id": "arXiv:2109.07046",
    "title": "A Conditional Generative Matching Model for Multi-lingual Reply  Suggestion",
    "abstract": "We study the problem of multilingual automated reply suggestions (RS) model\nserving many languages simultaneously. Multilingual models are often challenged\nby model capacity and severe data distribution skew across languages. While\nprior works largely focus on monolingual models, we propose Conditional\nGenerative Matching models (CGM), optimized within a Variational Autoencoder\nframework to address challenges arising from multi-lingual RS. CGM does so with\nexpressive message conditional priors, mixture densities to enhance\nmulti-lingual data representation, latent alignment for language\ndiscrimination, and effective variational optimization techniques for training\nmulti-lingual RS. The enhancements result in performance that exceed\ncompetitive baselines in relevance (ROUGE score) by more than 10\\% on average,\nand 16\\% for low resource languages. CGM also shows remarkable improvements in\ndiversity (80\\%) illustrating its expressiveness in representation of\nmulti-lingual data.",
    "descriptor": "",
    "authors": [
      "Budhaditya Deb",
      "Guoqing Zheng",
      "Milad Shokouhi",
      "Ahmed Hassan Awadallah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07046"
  },
  {
    "id": "arXiv:2109.07047",
    "title": "The Promise of Dataflow Architectures in the Design of Processing  Systems for Autonomous Machines",
    "abstract": "The commercialization of autonomous machines is a thriving sector, and likely\nto be the next major computing demand driver, after PC, cloud computing, and\nmobile computing. Nevertheless, a suitable computer architecture for autonomous\nmachines is missing, and many companies are forced to develop ad hoc computing\nsolutions that are neither scalable nor extensible. In this article, we analyze\nthe demands of autonomous machine computing, and argue for the promise of\ndataflow architectures in autonomous machines.",
    "descriptor": "\nComments: Please note that this may be a special case in that Professor Gao sadly passed away on September 12th, just as we had put the finishing touches on this submission\n",
    "authors": [
      "Shaoshan Liu",
      "Yuhao Zhu",
      "Bo Yu",
      "Jean-Luc Gaudiot",
      "Guang R. Gao"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07047"
  },
  {
    "id": "arXiv:2109.07048",
    "title": "ARCH: Efficient Adversarial Regularized Training with Caching",
    "abstract": "Adversarial regularization can improve model generalization in many natural\nlanguage processing tasks. However, conventional approaches are computationally\nexpensive since they need to generate a perturbation for each sample in each\nepoch. We propose a new adversarial regularization method ARCH (adversarial\nregularization with caching), where perturbations are generated and cached once\nevery several epochs. As caching all the perturbations imposes memory usage\nconcerns, we adopt a K-nearest neighbors-based strategy to tackle this issue.\nThe strategy only requires caching a small amount of perturbations, without\nintroducing additional training time. We evaluate our proposed method on a set\nof neural machine translation and natural language understanding tasks. We\nobserve that ARCH significantly eases the computational burden (saves up to\n70\\% of computational time in comparison with conventional approaches). More\nsurprisingly, by reducing the variance of stochastic gradients, ARCH produces a\nnotably better (in most of the tasks) or comparable model generalization. Our\ncode is publicly available.",
    "descriptor": "",
    "authors": [
      "Simiao Zuo",
      "Chen Liang",
      "Haoming Jiang",
      "Pengcheng He",
      "Xiaodong Liu",
      "Jianfeng Gao",
      "Weizhu Chen",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07048"
  },
  {
    "id": "arXiv:2109.07049",
    "title": "Self-Training with Differentiable Teacher",
    "abstract": "Self-training achieves enormous success in various semi-supervised and\nweakly-supervised learning tasks. The method can be interpreted as a\nteacher-student framework, where the teacher generates pseudo-labels, and the\nstudent makes predictions. The two models are updated alternatingly. However,\nsuch a straightforward alternating update rule leads to training instability.\nThis is because a small change in the teacher may result in a significant\nchange in the student. To address this issue, we propose {\\ours}, short for\ndifferentiable self-training, that treats teacher-student as a Stackelberg\ngame. In this game, a leader is always in a more advantageous position than a\nfollower. In self-training, the student contributes to the prediction\nperformance, and the teacher controls the training process by generating\npseudo-labels. Therefore, we treat the student as the leader and the teacher as\nthe follower. The leader procures its advantage by acknowledging the follower's\nstrategy, which involves differentiable pseudo-labels and differentiable sample\nweights. Consequently, the leader-follower interaction can be effectively\ncaptured via Stackelberg gradient, obtained by differentiating the follower's\nstrategy. Experimental results on semi- and weakly-supervised classification\nand named entity recognition tasks show that our model outperforms existing\napproaches by large margins.",
    "descriptor": "",
    "authors": [
      "Simiao Zuo",
      "Yue Yu",
      "Chen Liang",
      "Haoming Jiang",
      "Siawpeng Er",
      "Chao Zhang",
      "Tuo Zhao",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07049"
  },
  {
    "id": "arXiv:2109.07050",
    "title": "The Elliptic Net Algorithm Revisited",
    "abstract": "Pairings have been widely used since their introduction to cryptography. They\ncan be applied to identity-based encryption, tripartite Diffie-Hellman key\nagreement, blockchain and other cryptographic schemes. The Acceleration of\npairing computations is crucial for these cryptographic schemes or protocols.\nIn this paper, we will focus on the Elliptic Net algorithm which can compute\npairings in polynomial time, but it requires more storage than Miller's\nalgorithm. We use several methods to speed up the Elliptic Net algorithm.\nFirstly, we eliminate the inverse operation in the improved Elliptic Net\nalgorithm. In some circumstance, this finding can achieve further improvements.\nSecondly, we apply lazy reduction technique to the Elliptic Net algorithm,\nwhich helps us achieve a faster implementation. Finally, we propose a new\nderivation of the formulas for the computation of the Optimal Ate pairing on\nthe twisted curve. Results show that the Elliptic Net algorithm can be\nsignificantly accelerated especially on the twisted curve. The algorithm can be\n$80\\%$ faster than the previous ones on the twisted 381-bit BLS12 curve and\n$71.5\\%$ faster on the twisted 676-bit KSS18 curve respectively.",
    "descriptor": "",
    "authors": [
      "Shiping Cai",
      "Zhi Hu",
      "Zheng-An Yao",
      "Chang-An Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Algebraic Geometry (math.AG)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2109.07050"
  },
  {
    "id": "arXiv:2109.07053",
    "title": "Image Synthesis via Semantic Composition",
    "abstract": "In this paper, we present a novel approach to synthesize realistic images\nbased on their semantic layouts. It hypothesizes that for objects with similar\nappearance, they share similar representation. Our method establishes\ndependencies between regions according to their appearance correlation,\nyielding both spatially variant and associated representations. Conditioning on\nthese features, we propose a dynamic weighted network constructed by spatially\nconditional computation (with both convolution and normalization). More than\npreserving semantic distinctions, the given dynamic network strengthens\nsemantic relevance, benefiting global structure and detail synthesis. We\ndemonstrate that our method gives the compelling generation performance\nqualitatively and quantitatively with extensive experiments on benchmarks.",
    "descriptor": "\nComments: Project page is at this https URL Accepted to ICCV 2021\n",
    "authors": [
      "Yi Wang",
      "Lu Qi",
      "Ying-Cong Chen",
      "Xiangyu Zhang",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07053"
  },
  {
    "id": "arXiv:2109.07054",
    "title": "Convergence of a Human-in-the-Loop Policy-Gradient Algorithm With  Eligibility Trace Under Reward, Policy, and Advantage Feedback",
    "abstract": "Fluid human-agent communication is essential for the future of\nhuman-in-the-loop reinforcement learning. An agent must respond appropriately\nto feedback from its human trainer even before they have significant experience\nworking together. Therefore, it is important that learning agents respond well\nto various feedback schemes human trainers are likely to provide. This work\nanalyzes the COnvergent Actor-Critic by Humans (COACH) algorithm under three\ndifferent types of feedback-policy feedback, reward feedback, and advantage\nfeedback. For these three feedback types, we find that COACH can behave\nsub-optimally. We propose a variant of COACH, episodic COACH (E-COACH), which\nwe prove converges for all three types. We compare our COACH variant with two\nother reinforcement-learning algorithms: Q-learning and TAMER.",
    "descriptor": "\nComments: Accepted into ICML 2021 workshops Human-AI Collaboration in Sequential Decision-Making and Human in the Loop Learning\n",
    "authors": [
      "Ishaan Shah",
      "David Halpern",
      "Kavosh Asadi",
      "Michael L. Littman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.07054"
  },
  {
    "id": "arXiv:2109.07055",
    "title": "ISPY: Automatic Issue-Solution Pair Extraction from Community Live Chats",
    "abstract": "Collaborative live chats are gaining popularity as a development\ncommunication tool. In community live chatting, developers are likely to post\nissues they encountered (e.g., setup issues and compile issues), and other\ndevelopers respond with possible solutions. Therefore, community live chats\ncontain rich sets of information for reported issues and their corresponding\nsolutions, which can be quite useful for knowledge sharing and future reuse if\nextracted and restored in time. However, it remains challenging to accurately\nmine such knowledge due to the noisy nature of interleaved dialogs in live chat\ndata. In this paper, we first formulate the problem of issue-solution pair\nextraction from developer live chat data, and propose an automated approach,\nnamed ISPY, based on natural language processing and deep learning techniques\nwith customized enhancements, to address the problem. Specifically, ISPY\nautomates three tasks: 1) Disentangle live chat logs, employing a feedforward\nneural network to disentangle a conversation history into separate dialogs\nautomatically; 2) Detect dialogs discussing issues, using a novel convolutional\nneural network (CNN), which consists of a BERT-based utterance embedding layer,\na context-aware dialog embedding layer, and an output layer; 3) Extract\nappropriate utterances and combine them as corresponding solutions, based on\nthe same CNN structure but with different feeding inputs. To evaluate ISPY, we\ncompare it with six baselines, utilizing a dataset with 750 dialogs including\n171 issue-solution pairs and evaluate ISPY from eight open source communities.\nThe results show that, for issue-detection, our approach achieves the F1 of\n76%, and outperforms all baselines by 30%. Our approach achieves the F1 of 63%\nfor solution-extraction and outperforms the baselines by 20%.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Lin Shi",
      "Ziyou Jiang",
      "Ye Yang",
      "Xiao Chen",
      "Yumin Zhang",
      "Fangwen Mu",
      "Hanzhi Jiang",
      "Qing Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.07055"
  },
  {
    "id": "arXiv:2109.07060",
    "title": "Analyzing Multiagent Interactions in Traffic Scenes via Topological  Braids",
    "abstract": "We focus on the problem of analyzing multiagent interactions in traffic\ndomains. Understanding the space of behavior of real-world traffic may offer\nsignificant advantages for algorithmic design, data-driven methodologies, and\nbenchmarking. However, the high dimensionality of the space and the\nstochasticity of human behavior may hinder the identification of important\ninteraction patterns. Our key insight is that traffic environments feature\nsignificant geometric and temporal structure, leading to highly organized\ncollective behaviors, often drawn from a small set of dominant modes. In this\nwork, we propose a representation based on the formalism of topological braids\nthat can summarize arbitrarily complex multiagent behavior into a compact\nobject of dual geometric and symbolic nature, capturing critical events of\ninteraction. This representation allows us to formally enumerate the space of\noutcomes in a traffic scene and characterize their complexity. We illustrate\nthe value of the proposed representation in summarizing critical aspects of\nreal-world traffic behavior through a case study on recent driving datasets. We\nshow that despite the density of real-world traffic, observed behavior tends to\nfollow highly organized patterns of low interaction. Our framework may be a\nvaluable tool for evaluating the richness of driving datasets, but also for\nsynthetically designing balanced training datasets or benchmarks.",
    "descriptor": "",
    "authors": [
      "Christoforos Mavrogiannis",
      "Jonathan DeCastro",
      "Siddhartha S. Srinivasa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07060"
  },
  {
    "id": "arXiv:2109.07061",
    "title": "Scalable Cell-Free Massive MIMO Systems with Finite Resolution ADCs/DACs  over Spatially Correlated Rician Fading Channels",
    "abstract": "In this paper, an analytical framework for evaluating the performance of\nscalable cell-free massive MIMO (SCF-mMIMO) systems in which all user\nequipments (UEs) and access points (APs) employ finite resolution\ndigital-to-analog converters (DACs) and analog-to-digital converters (ADCs) and\noperates under correlated Rician fading, is presented. By using maximal-ratio\ncombining (MRC) detection, generic expressions for the uplink (UL) spectral\nefficiency (SE) for both distributed and centralized schemes are derived. In\norder to further reduce the computational complexity (CC) of the original local\npartial MMSE (LP-MMSE) and partial MMSE (P-MMSE) detectors, two novel scalable\nlow complexity MMSE detectors are proposed for distributed and centralized\nschemes respectively, which achieves very similar SE performance. Furthermore,\nfor the distributed scheme a novel partial large-scale fading decoding (P-LSFD)\nweighting vector is introduced and its analytical SE performance is very\nsimilar to the performance of an equivalent unscalable LSFD vector. Finally, a\nscalable algorithm jointly consisting of AP cluster formation, pilot\nassignment, and power control is proposed, which outperforms the conventional\nrandom pilot assignment and user-group based pilot assignment policies and,\ncontrary to an equal power transmit strategy, it guarantees quality of service\n(QoS) fairness for all accessing UEs.",
    "descriptor": "\nComments: 14 pages, 9 figures, regular paper\n",
    "authors": [
      "Xiangjun Ma",
      "Xianfu Lei",
      "P. Takis Mathiopoulos",
      "Kai Yu",
      "Xiaohu Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.07061"
  },
  {
    "id": "arXiv:2109.07067",
    "title": "Improving Text Auto-Completion with Next Phrase Prediction",
    "abstract": "Language models such as GPT-2 have performed well on constructing\nsyntactically sound sentences for text auto-completion task. However, such\nmodels often require considerable training effort to adapt to specific writing\ndomains (e.g., medical). In this paper, we propose an intermediate training\nstrategy to enhance pre-trained language models' performance in the text\nauto-completion task and fastly adapt them to specific domains. Our strategy\nincludes a novel self-supervised training objective called Next Phrase\nPrediction (NPP), which encourages a language model to complete the partial\nquery with enriched phrases and eventually improve the model's text\nauto-completion performance. Preliminary experiments have shown that our\napproach is able to outperform the baselines in auto-completion for email and\nacademic writing domains.",
    "descriptor": "\nComments: 4 pages, 2 figures, 4 tables, Accepted in EMNLP 2021-Findings\n",
    "authors": [
      "Dong-Ho Lee",
      "Zhiqiang Hu",
      "Roy Ka-Wei Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07067"
  },
  {
    "id": "arXiv:2109.07069",
    "title": "F-CAM: Full Resolution CAM via Guided Parametric Upscaling",
    "abstract": "Class Activation Mapping (CAM) methods have recently gained much attention\nfor weakly-supervised object localization (WSOL) tasks, allowing for CNN\nvisualization and interpretation without training on fully annotated image\ndatasets. CAM methods are typically integrated within off-the-shelf CNN\nbackbones, such as ResNet50. Due to convolution and downsampling/pooling\noperations, these backbones yield low resolution CAMs with a down-scaling\nfactor of up to 32, making accurate localization more difficult. Interpolation\nis required to restore a full size CAMs, but without considering the\nstatistical properties of the objects, leading to activations with inconsistent\nboundaries and inaccurate localizations. As an alternative, we introduce a\ngeneric method for parametric upscaling of CAMs that allows constructing\naccurate full resolution CAMs (F-CAMs). In particular, we propose a trainable\ndecoding architecture that can be connected to any CNN classifier to produce\nmore accurate CAMs. Given an original (low resolution) CAM, foreground and\nbackground pixels are randomly sampled for fine-tuning the decoder. Additional\npriors such as image statistics, and size constraints are also considered to\nexpand and refine object boundaries. Extensive experiments using three CNN\nbackbones and six WSOL baselines on the CUB-200-2011 and OpenImages datasets,\nindicate that our F-CAM method yields a significant improvement in CAM\nlocalization accuracy. F-CAM performance is competitive with state-of-art WSOL\nmethods, yet it requires fewer computational resources during inference.",
    "descriptor": "\nComments: 23pages, under review\n",
    "authors": [
      "Soufiane Belharbi",
      "Aydin Sarraf",
      "Marco Pedersoli",
      "Ismail Ben Ayed",
      "Luke McCaffrey",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07069"
  },
  {
    "id": "arXiv:2109.07073",
    "title": "Globally Consistent 3D LiDAR Mapping with GPU-accelerated GICP Matching  Cost Factors",
    "abstract": "This paper presents a real-time 3D LiDAR mapping framework based on global\nmatching cost minimization. The proposed method constructs a factor graph that\ndirectly minimizes matching costs between frames over the entire map, unlike\npose graph-based approaches that minimize errors in the pose space. For\nreal-time global matching cost minimization, we use a voxel data\nassociation-based GICP matching cost factor that is able to fully leverage GPU\nparallel processing. The combination of the matching cost factor and GPU\ncomputation enables constraint of the relative pose between frames with a small\noverlap and creation of a densely connected factor graph. The mapping process\nis managed based on a voxel-based overlap metric that can quickly be evaluated\non a GPU. We incorporate the proposed method with an external loop detection\nmethod in order to help the voxel-based matching cost factors to avoid\nconvergence in a local solution. The experimental result on the KITTI dataset\nshows that the proposed approach improves the estimation accuracy of long\ntrajectories.",
    "descriptor": "\nComments: IEEE Robotics and Automation Letters, Video: this https URL\n",
    "authors": [
      "Kenji Koide",
      "Masashi Yokozuka",
      "Shuji Oishi",
      "Atsuhiko Banno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07073"
  },
  {
    "id": "arXiv:2109.07074",
    "title": "Anti-Tamper Protection for Internet of Things System Using Hyperledger  Fabric Blockchain Technology",
    "abstract": "Automated and industrial Internet of Things (IoT) devices are increasing\ndaily. As the number of IoT devices grows, the volume of data generated by them\nwill also grow. Managing these rapidly expanding IoT devices and enormous data\nefficiently to be available to all authorized users without compromising its\nintegrity will become essential in the near future. On the other side, many\ninformation security incidents have been recorded, increasing the requirement\nfor countermeasures. While safeguards against hostile third parties have been\ncommonplace until now, operators and parties have seen an increase in demand\nfor data falsification detection and blocking. Blockchain technology is\nwell-known for its privacy, immutability, and decentralized nature.\nSingle-board computers are becoming more powerful while also becoming more\naffordable as IoT platforms. These single-board computers are gaining traction\nin the automation industry. This study focuses on a paradigm of IoT-Blockchain\nintegration where the blockchain node runs autonomously on the IoT platform\nitself. It enables the system to conduct machine-to-machine transactions\nwithout the intervention of a person and to exert direct access control over\nIoT devices. This paper assumed that the readers are familiar with Hyperledger\nFabric basic operations and focus on the practical approach of integration. A\nbasic introduction is provided for the newbie on the blockchain.",
    "descriptor": "",
    "authors": [
      "Adnan Iftekhar",
      "Xiaohui Cui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.07074"
  },
  {
    "id": "arXiv:2109.07076",
    "title": "Real-Time Multi-Contact Model Predictive Control via ADMM",
    "abstract": "We propose a general hybrid model predictive control algorithm, consensus\ncomplementarity control (C3), for systems that make and break contact with\ntheir environment. Many state-of-the-art controllers for tasks which require\ninitiating contact with the environment, such as locomotion and manipulation,\nrequire a priori mode schedules or are so computationally complex that they\ncannot run at real-time rates. We present a method, based on the alternating\ndirection method of multipliers (ADMM), capable of highspeed reasoning over\npotential contact events. Via a consensus formulation, our approach enables\nparallelization of the contact scheduling problem. We validate our results on\nthree numerical examples, including two frictional contact problems, and\nphysical experimentation on an underactuated multi-contact system.",
    "descriptor": "",
    "authors": [
      "Alp Aydinoglu",
      "Michael Posa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07076"
  },
  {
    "id": "arXiv:2109.07078",
    "title": "DSOR: A Scalable Statistical Filter for Removing Falling Snow from LiDAR  Point Clouds in Severe Winter Weather",
    "abstract": "For autonomous vehicles to viably replace human drivers they must contend\nwith inclement weather. Falling rain and snow introduce noise in LiDAR returns\nresulting in both false positive and false negative object detections. In this\narticle we introduce the Winter Adverse Driving dataSet (WADS) collected in the\nsnow belt region of Michigan's Upper Peninsula. WADS is the first multi-modal\ndataset featuring dense point-wise labeled sequential LiDAR scans collected in\nsevere winter weather; weather that would cause an experienced driver to alter\ntheir driving behavior. We have labelled and will make available over 7 GB or\n3.6 billion labelled LiDAR points out of over 26 TB of total LiDAR and camera\ndata collected. We also present the Dynamic Statistical Outlier Removal (DSOR)\nfilter, a statistical PCL-based filter capable or removing snow with a higher\nrecall than the state of the art snow de-noising filter while being 28\\%\nfaster. Further, the DSOR filter is shown to have a lower time complexity\ncompared to the state of the art resulting in an improved scalability.\nOur labeled dataset and DSOR filter will be made available at\nhttps://bitbucket.org/autonomymtu/dsor_filter",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Akhil Kurup",
      "Jeremy Bos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07078"
  },
  {
    "id": "arXiv:2109.07079",
    "title": "Image-Based Multi-UAV Tracking System in a Cluttered Environment",
    "abstract": "A tracking controller for unmanned aerial vehicles (UAVs) is developed to\ntrack moving targets undergoing unknown translational and rotational motions.\nThe main challenges are to control both the relative positions and angles\nbetween the target and the UAVs to within desired values, and to guarantee that\nthe generated control inputs to the UAVs are feasible (i.e., within their\nmotion capabilities). Moreover, the UAVs are controlled to ensure that the\ntarget always remains within the fields of view of their onboard cameras. To\nthe best of our knowledge, this is the first work to apply multiple UAVs to\ncooperatively track a dynamic target while ensuring that the UAVs remain\nconnected and that both occlusion and collisions are avoided. To achieve these\ncontrol objectives, a designed controller solved based on the aforementioned\ntracking controller using quadratic programming can generate minimally invasive\ncontrol actions to achieve occlusion avoidance and collision avoidance.\nFurthermore, control barrier functions (CBFs) with a distributed design are\ndeveloped in order to reduce the amount of inter-UAV communication. Simulations\nwere performed to assess the efficacy and performance of the developed\nCBF-based controller for the multi-UAV system in tracking a target.",
    "descriptor": "",
    "authors": [
      "Hsin-Ai Hung",
      "Hao-Huan Hsu",
      "Teng-Hu Cheng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07079"
  },
  {
    "id": "arXiv:2109.07080",
    "title": "Transformer-based Lexically Constrained Headline Generation",
    "abstract": "This paper explores a variant of automatic headline generation methods, where\na generated headline is required to include a given phrase such as a company or\na product name. Previous methods using Transformer-based models generate a\nheadline including a given phrase by providing the encoder with additional\ninformation corresponding to the given phrase. However, these methods cannot\nalways include the phrase in the generated headline. Inspired by previous\nRNN-based methods generating token sequences in backward and forward directions\nfrom the given phrase, we propose a simple Transformer-based method that\nguarantees to include the given phrase in the high-quality generated headline.\nWe also consider a new headline generation strategy that takes advantage of the\ncontrollable generation order of Transformer. Our experiments with the Japanese\nNews Corpus demonstrate that our methods, which are guaranteed to include the\nphrase in the generated headline, achieve ROUGE scores comparable to previous\nTransformer-based methods. We also show that our generation strategy performs\nbetter than previous strategies.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Kosuke Yamada",
      "Yuta Hitomi",
      "Hideaki Tamori",
      "Ryohei Sasano",
      "Naoaki Okazaki",
      "Kentaro Inui",
      "Koichi Takeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07080"
  },
  {
    "id": "arXiv:2109.07082",
    "title": "Efficient and Probabilistic Adaptive VoxelnMapping for Accurate Online3D  SLAM",
    "abstract": "This paper proposes an efficient and probabilistic adaptive voxel mapping\nmethod for 3D SLAM. An accurate uncertainty model of point and plane is\nproposed for probabilistic plane representation. We analyze the need for\ncoarse-to-fine voxel mapping and then use a novel voxel map organized by a Hash\ntable and octrees to build and update the map efficiently. We apply the voxel\nmap to the iterated Kalman filter and construct the maximum posterior\nprobability problem for pose estimation. The experiments on the open KITTI\ndataset show the high accuracy and efficiency of our method in contrast with\nother state-of-the-art. Outdoor experiments on unstructured environments with\nnon-repetitive scanning LiDAR further verify the adaptability of our mapping\nmethod to different environments and LiDAR scanning patterns.",
    "descriptor": "\nComments: 7 pages, 9 figures, submitted to ICRA\n",
    "authors": [
      "Chongjian Yuan",
      "Wei xu",
      "Xiyuan Liu",
      "Xiaoping Hong",
      "Fu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07082"
  },
  {
    "id": "arXiv:2109.07084",
    "title": "Fast Extraction of Word Embedding from Q-contexts",
    "abstract": "The notion of word embedding plays a fundamental role in natural language\nprocessing (NLP). However, pre-training word embedding for very large-scale\nvocabulary is computationally challenging for most existing methods. In this\nwork, we show that with merely a small fraction of contexts (Q-contexts)which\nare typical in the whole corpus (and their mutual information with words), one\ncan construct high-quality word embedding with negligible errors. Mutual\ninformation between contexts and words can be encoded canonically as a sampling\nstate, thus, Q-contexts can be fast constructed. Furthermore, we present an\nefficient and effective WEQ method, which is capable of extracting word\nembedding directly from these typical contexts. In practical scenarios, our\nalgorithm runs 11$\\sim$13 times faster than well-established methods. By\ncomparing with well-known methods such as matrix factorization, word2vec,\nGloVeand fasttext, we demonstrate that our method achieves comparable\nperformance on a variety of downstream NLP tasks, and in the meanwhile\nmaintains run-time and resource advantages over all these baselines.",
    "descriptor": "\nComments: Accepted by CIKM 2021\n",
    "authors": [
      "Junsheng Kong",
      "Weizhao Li",
      "Zeyi Liu",
      "Ben Liao",
      "Jiezhong Qiu",
      "Chang-Yu Hsieh",
      "Yi Cai",
      "Shengyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07084"
  },
  {
    "id": "arXiv:2109.07087",
    "title": "Soft-Jig: A Flexible Sensing Jig for Simultaneously Fixing and  Estimating Orientation of Assembly Parts",
    "abstract": "For assembly tasks, it is essential to firmly fix target parts and to\naccurately estimate their poses. Several rigid jigs for individual parts are\nfrequently used in assembly factories to achieve precise and time-efficient\nproduct assembly. However, providing customized jigs is time-consuming. In this\nstudy, to address the lack of versatility in the shapes the jigs can be used\nfor, we developed a flexible jig with a soft membrane including transparent\nbeads and oil with a tuned refractive index. The bead-based jamming transition\nwas accomplished by discharging only oil enabling a part to be firmly fixed.\nBecause the two cameras under the jig are able to capture membrane shape\nchanges, we proposed a sensing method to estimate the orientation of the part\nbased on the behaviors of markers created on the jig's inner surface. Through\nestimation experiments, the proposed system could estimate the orientation of a\ncylindrical object with a diameter larger than 50 mm and an RMSE of less than 3\ndegrees.",
    "descriptor": "\nComments: 6 pages, 14 figures\n",
    "authors": [
      "Tatsuya Sakuma",
      "Takuya Kiyokawa",
      "Jun Takamatsu",
      "Takahiro Wada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07087"
  },
  {
    "id": "arXiv:2109.07095",
    "title": "Towards Document-Level Paraphrase Generation with Sentence Rewriting and  Reordering",
    "abstract": "Paraphrase generation is an important task in natural language processing.\nPrevious works focus on sentence-level paraphrase generation, while ignoring\ndocument-level paraphrase generation, which is a more challenging and valuable\ntask. In this paper, we explore the task of document-level paraphrase\ngeneration for the first time and focus on the inter-sentence diversity by\nconsidering sentence rewriting and reordering. We propose CoRPG (Coherence\nRelationship guided Paraphrase Generation), which leverages graph GRU to encode\nthe coherence relationship graph and get the coherence-aware representation for\neach sentence, which can be used for re-arranging the multiple (possibly\nmodified) input sentences. We create a pseudo document-level paraphrase dataset\nfor training CoRPG. Automatic evaluation results show CoRPG outperforms several\nstrong baseline models on the BERTScore and diversity scores. Human evaluation\nalso shows our model can generate document paraphrase with more diversity and\nsemantic preservation.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Zhe Lin",
      "Yitao Cai",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07095"
  },
  {
    "id": "arXiv:2109.07100",
    "title": "Hybrid Local-Global Transformer for Image Dehazing",
    "abstract": "Recently, the Vision Transformer (ViT) has shown impressive performance on\nhigh-level and low-level vision tasks. In this paper, we propose a new ViT\narchitecture, named Hybrid Local-Global Vision Transformer (HyLoG-ViT), for\nsingle image dehazing. The HyLoG-ViT block consists of two paths, the local ViT\npath and the global ViT path, which are used to capture local and global\ndependencies. The hybrid features are fused via convolution layers. As a\nresult, the HyLoG-ViT reduces the computational complexity and introduces\nlocality in the networks. Then, the HyLoG-ViT blocks are incorporated within\nour dehazing networks, which jointly learn the intrinsic image decomposition\nand image dehazing. Specifically, the network consists of one shared encoder\nand three decoders for reflectance prediction, shading prediction, and\nhaze-free image generation. The tasks of reflectance and shading prediction can\nproduce meaningful intermediate features that can serve as complementary\nfeatures for haze-free image generation. To effectively aggregate the\ncomplementary features, we propose a complementary features selection module\n(CFSM) to select the useful ones for image dehazing. Extensive experiments on\nhomogeneous, non-homogeneous, and nighttime dehazing tasks reveal that our\nproposed Transformer-based dehazing network can achieve comparable or even\nbetter performance than CNNs-based dehazing models.",
    "descriptor": "\nComments: 19 pages,17 figures\n",
    "authors": [
      "Dong Zhao",
      "Jia Li",
      "Hongyu Li",
      "Long Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07100"
  },
  {
    "id": "arXiv:2109.07101",
    "title": "Delay-aware Robust Control for Safe Autonomous Driving",
    "abstract": "With the advancement of affordable self-driving vehicles using complicated\nnonlinear optimization but limited computation resources, computation time\nbecomes a matter of concern. Other factors such as actuator dynamics and\nactuator command processing cost also unavoidably cause delays. In high-speed\nscenarios, these delays are critical to the safety of a vehicle. Recent works\nconsider these delays individually, but none unifies them all in the context of\nautonomous driving. Moreover, recent works inappropriately consider computation\ntime as a constant or a large upper bound, which makes the control either less\nresponsive or over-conservative. To deal with all these delays, we present a\nunified framework by 1) modeling actuation dynamics, 2) using robust tube model\npredictive control, 3) using a novel adaptive Kalman filter without assuminga\nknown process model and noise covariance, which makes the controller safe while\nminimizing conservativeness. On onehand, our approach can serve as a standalone\ncontroller; on theother hand, our approach provides a safety guard for a\nhigh-level controller, which assumes no delay. This can be used for\ncompensating the sim-to-real gap when deploying a black-box learning-enabled\ncontroller trained in a simplistic environment without considering delays for\npractical vehicle systems.",
    "descriptor": "\nComments: Under review at ICRA 2022\n",
    "authors": [
      "Dvij Kalaria",
      "Qin Lin",
      "John M. Dolan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07101"
  },
  {
    "id": "arXiv:2109.07102",
    "title": "Can Edge Probing Tasks Reveal Linguistic Knowledge in QA Models?",
    "abstract": "There have been many efforts to try to understand what grammatical knowledge\n(e.g., ability to understand the part of speech of a token) is encoded in large\npre-trained language models (LM). This is done through `Edge Probing' (EP)\ntests: simple ML models that predict the grammatical properties of a span\n(whether it has a particular part of speech) using \\textit{only} the LM's token\nrepresentations. However, most NLP applications use \\finetuned\\ LMs. Here, we\nask: if a LM is \\finetuned, does the encoding of linguistic information in it\nchange, as measured by EP tests? Conducting experiments on multiple\nquestion-answering (QA) datasets, we answer that question negatively: the EP\ntest results do not change significantly when the fine-tuned QA model performs\nwell or in adversarial situations where the model is forced to learn wrong\ncorrelations. However, a critical analysis of the EP task datasets reveals that\nEP models may rely on spurious correlations to make predictions. This indicates\neven if \\finetuning\\ changes the encoding of such knowledge, the EP tests might\nfail to measure it.",
    "descriptor": "",
    "authors": [
      "Sagnik Ray Choudhury",
      "Nikita Bhutani",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07102"
  },
  {
    "id": "arXiv:2109.07103",
    "title": "Automatic Symmetry Discovery with Lie Algebra Convolutional Network",
    "abstract": "Existing equivariant neural networks for continuous groups require\ndiscretization or group representations. All these approaches require detailed\nknowledge of the group parametrization and cannot learn entirely new\nsymmetries. We propose to work with the Lie algebra (infinitesimal generators)\ninstead of the Lie group.Our model, the Lie algebra convolutional network\n(L-conv) can learn potential symmetries and does not require discretization of\nthe group. We show that L-conv can serve as a building block to construct any\ngroup equivariant architecture. We discuss how CNNs and Graph Convolutional\nNetworks are related to and can be expressed as L-conv with appropriate groups.\nWe also derive the MSE loss for a single L-conv layer and find a deep relation\nwith Lagrangians used in physics, with some of the physics aiding in defining\ngeneralization and symmetries in the loss landscape. Conversely, L-conv could\nbe used to propose more general equivariant ans\\\"atze for scientific machine\nlearning.",
    "descriptor": "",
    "authors": [
      "Nima Dehmamy",
      "Robin Walters",
      "Yanchen Liu",
      "Dashun Wang",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.07103"
  },
  {
    "id": "arXiv:2109.07105",
    "title": "Local NMPC on Global Optimised Path for Autonomous Racing",
    "abstract": "The paper presents a strategy for the control of anautonomous racing car on a\npre-mapped track. Using a dynamic model of the vehicle, the optimal racing line\nis computed, taking track boundaries into account. With the optimal racing line\nas areference, a local nonlinear model predictive controller (NMPC) is\nproposed, which takes into account multiple local objectives like making more\nprogress along the race line, avoiding collision with opponent vehicles, and\nuse of drafting to achieve more progress.",
    "descriptor": "\nComments: ICRA workshop on Opportunities and Challenges with Autonomous Racing, 31 May, 2021(accepted)\n",
    "authors": [
      "Dvij Kalaria",
      "Parv Maheshwari",
      "Animesh Jha",
      "Arnesh Kumar Issar",
      "Debashish Chakravarty",
      "Sohel Anwar",
      "Andres Towar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07105"
  },
  {
    "id": "arXiv:2109.07106",
    "title": "WIP: Medical Incident Prediction Through Analysis of Electronic Medical  Records Using Machine Lerning: Fall Prediction",
    "abstract": "This paper reports our preliminary work on medical incident prediction in\ngeneral, and fall risk prediction in specific, using machine learning. Data for\nthe machine learning are generated only from the particular subset of the\nelectronic medical records (EMR) at Osaka Medical and Pharmaceutical University\nHospital. As a result of conducting three experiments such as (1) machine\nlearning algorithm comparison, (2) handling imbalance, and (3) investigation of\nexplanatory variable contribution to the fall incident prediction, we find the\ninvestigation of explanatory variables the most effective.",
    "descriptor": "\nComments: ICIEV/IVPR2021. Work-In-Progress paper. 6 pages. 5 tables. Emerging Researcher Award\n",
    "authors": [
      "Atsushi Yanagisawa",
      "Chintaka Premachandra",
      "Hiruharu Kawanaka",
      "Atsushi Inoue",
      "Takeo Hata",
      "Eiichiro Ueda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07106"
  },
  {
    "id": "arXiv:2109.07107",
    "title": "Anchor DETR: Query Design for Transformer-Based Detector",
    "abstract": "In this paper, we propose a novel query design for the transformer-based\ndetectors. In previous transformer-based detectors, the object queries are a\nset of learned embeddings. However, each learned embedding does not have an\nexplicit physical meaning and we can not explain where it will focus on. It is\ndifficult to optimize as the prediction slot of each object query does not have\na specific mode. In other words, each object query will not focus on a specific\nregion. To solved these problems, in our query design, object queries are based\non anchor points, which are widely used in CNN-based detectors. So each object\nquery focus on the objects near the anchor point. Moreover, our query design\ncan predict multiple objects at one position to solve the difficulty: \"one\nregion, multiple objects\". In addition, we design an attention variant, which\ncan reduce the memory cost while achieving similar or better performance than\nthe standard attention in DETR. Thanks to the query design and the attention\nvariant, the proposed detector that we called Anchor DETR, can achieve better\nperformance and run faster than the DETR with 10$\\times$ fewer training epochs.\nFor example, it achieves 44.2 AP with 16 FPS on the MSCOCO dataset when using\nthe ResNet50-DC5 feature for training 50 epochs. Extensive experiments on the\nMSCOCO benchmark prove the effectiveness of the proposed methods. Code is\navailable at https://github.com/megvii-model/AnchorDETR.",
    "descriptor": "",
    "authors": [
      "Yingming Wang",
      "Xiangyu Zhang",
      "Tong Yang",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07107"
  },
  {
    "id": "arXiv:2109.07111",
    "title": "Elastic Tracker: A Spatio-temporal Trajectory Planner Flexible Aerial  Tracking",
    "abstract": "This paper proposes Elastic Tracker, a flexible trajectory planning framework\nthat can deal with challenging tracking tasks with guaranteed safety and\nvisibility. Firstly, an object detection and intension-free motion prediction\nmethod is designed. Then an occlusion-aware path finding method is proposed to\nprovide a proper topology. A smart safe flight corridor generation strategy is\ndesigned with the guiding path. An analytical occlusion cost is evaluated.\nFinally, an effective trajectory optimization approach enables to generate a\nspatio-temporal optimal trajectory within the resultant flight corridor.\nParticular formulations are designed to guarantee both safety and visibility,\nwith all the above requirements optimized jointly. The experimental results\nshow that our method works more robustly but with less computation than the\nexisting methods, even in some challenging tracking tasks.",
    "descriptor": "\nComments: video: TODO summited to: ICRA2022\n",
    "authors": [
      "Jialin Ji",
      "Neng Pan",
      "Chao Xu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07111"
  },
  {
    "id": "arXiv:2109.07112",
    "title": "Learning Friction Model for Magnet-actuated Tethered Capsule Robot",
    "abstract": "The diagnostic application of magnetic control capsules in medical treatment\nis progressively increasing. At present, the accurate dynamic control of the\ncapsule robot is becoming more and more important. There is a significant aim\nto establish a friction model of the tethered capsule robot, and the friction\nmodel can be applied to simulate the drag force of the tethered and all\nfriction between the capsule and the environment. We confirmed the fifth-order\nlinear fitting relationship between the friction factor of the friction model\nand the speed of the external permanent magnet. With the learned friction\nmodel, effective speed ranges of three mediums are obtained on PVC, paper, and\npolyester-cloth. In the article, a tethered capsule robot system driven by a\nrobot manipulator is built, and a plane motion method to learn the friction\nmodel is proposed.",
    "descriptor": "\nComments: icra2022. arXiv admin note: text overlap with arXiv:2108.07151\n",
    "authors": [
      "Yi Wang",
      "Yuyang Tu",
      "Yuchen He",
      "Xutian Deng",
      "Ziwei Lei",
      "Jianwei Zhang",
      "Miao Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07112"
  },
  {
    "id": "arXiv:2109.07114",
    "title": "Backward diffusion-wave problem: stability, regularization and  approximation",
    "abstract": "We aim at the development and analysis of the numerical schemes for\napproximately solving the backward diffusion-wave problem, which involves a\nfractional derivative in time with order $\\alpha\\in(1,2)$. From terminal\nobservations at two time levels, i.e., $u(T_1)$ and $u(T_2)$, we simultaneously\nrecover two initial data $u(0)$ and $u_t(0)$ and hence the solution $u(t)$ for\nall $t > 0$. First of all, existence, uniqueness and Lipschitz stability of the\nbackward diffusion-wave problem were established under some conditions about\n$T_1$ and $T_2$. Moreover, for noisy data, we propose a quasi-boundary value\nscheme to regularize the \"mildly\" ill-posed problem, and show the convergence\nof the regularized solution. Next, to numerically solve the regularized\nproblem, a fully discrete scheme is proposed by applying finite element method\nin space and convolution quadrature in time. We establish error bounds of the\ndiscrete solution in both cases of smooth and nonsmooth data. The error\nestimate is very useful in practice since it indicates the way to choose\ndiscretization parameters and regularization parameter, according to the noise\nlevel. The theoretical results are supported by numerical experiments.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Zhengqi Zhang",
      "Zhi Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.07114"
  },
  {
    "id": "arXiv:2109.07117",
    "title": "Non-Asymptotic Analysis of Stochastic Approximation Algorithms for  Streaming Data",
    "abstract": "Motivated by the high-frequency data streams continuously generated,\nreal-time learning is becoming increasingly important. These data streams\nshould be processed sequentially with the property that the stream may change\nover time. In this streaming setting, we propose techniques for minimizing a\nconvex objective through unbiased estimates of its gradients, commonly referred\nto as stochastic approximation problems. Our methods rely on stochastic\napproximation algorithms due to their computationally advantage as they only\nuse the previous iterate as a parameter estimate. The reasoning includes\niterate averaging that guarantees optimal statistical efficiency under\nclassical conditions. Our non-asymptotic analysis shows accelerated convergence\nby selecting the learning rate according to the expected data streams. We show\nthat the average estimate converges optimally and robustly to any data stream\nrate. In addition, noise reduction can be achieved by processing the data in a\nspecific pattern, which is advantageous for large-scale machine learning. These\ntheoretical results are illustrated for various data streams, showing the\neffectiveness of the proposed algorithms.",
    "descriptor": "",
    "authors": [
      "Antoine Godichon-Baggioni",
      "Nicklas Werge",
      "Olivier Wintenberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.07117"
  },
  {
    "id": "arXiv:2109.07118",
    "title": "Low-Resource Named Entity Recognition Based on Multi-hop Dependency  Trigger",
    "abstract": "This paper presents a simple and effective approach in low-resource named\nentity recognition (NER) based on multi-hop dependency trigger. Dependency\ntrigger refer to salient nodes relative to a entity in the dependency graph of\na context sentence. Our main observation is that there often exists trigger\nwhich play an important role to recognize the location and type of entity in\nsentence. Previous research has used manual labelling of trigger. Our main\ncontribution is to propose use a syntactic parser to automatically annotate\ntrigger. Experiments on two English datasets (CONLL 2003 and BC5CDR) show that\nthe proposed method is comparable to the previous trigger-based NER model.",
    "descriptor": "",
    "authors": [
      "Jiangxu Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07118"
  },
  {
    "id": "arXiv:2109.07120",
    "title": "Infusing model predictive control into meta-reinforcement learning for  mobile robots in dynamic environments",
    "abstract": "The successful operation of mobile robots requires them to rapidly adapt to\nenvironmental changes. Toward developing an adaptive decision-making tool for\nmobile robots, we propose combining meta-reinforcement learning (meta-RL) with\nmodel predictive control (MPC). The key idea of our method is to switch between\na meta-learned policy and an MPC controller in an event-triggered fashion. Our\nmethod uses an off-policy meta-RL algorithm as a baseline to train a policy\nusing transition samples generated by MPC. The MPC module of our algorithm is\ncarefully designed to infer the movements of obstacles via Gaussian process\nregression (GPR) and to avoid collisions via conditional value-at-risk (CVaR)\nconstraints. Due to its design, our method benefits from the two complementary\ntools. First, high-performance action samples generated by the MPC controller\nenhance the learning performance and stability of the meta-RL algorithm.\nSecond, through the use of the meta-learned policy, the MPC controller is\ninfrequently activated, thereby significantly reducing computation time. The\nresults of our simulations on a restaurant service robot show that our\nalgorithm outperforms both of the baseline methods.",
    "descriptor": "",
    "authors": [
      "Jaeuk Shin",
      "Astghik Hakobyan",
      "Mingyu Park",
      "Yeoneung Kim",
      "Gihun Kim",
      "Insoon Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07120"
  },
  {
    "id": "arXiv:2109.07121",
    "title": "Enhancing Data-Driven Reachability Analysis using Temporal Logic Side  Information",
    "abstract": "This paper presents algorithms for performing data-driven reachability\nanalysis under temporal logic side information. In certain scenarios, the\ndata-driven reachable sets of a robot can be prohibitively conservative due to\nthe inherent noise in the robot's historical measurement data. In the same\nscenarios, we often have side information about the robot's expected motion\n(e.g., limits on how much a robot can move in a one-time step) that could be\nuseful for further specifying the reachability analysis. In this work, we show\nthat if we can model this side information using a signal temporal logic (STL)\nfragment, we can constrain the data-driven reachability analysis and safely\nlimit the conservatism of the computed reachable sets. Moreover, we provide\nformal guarantees that, even after incorporating side information, the computed\nreachable sets still properly over-approximate the robot's future states.\nLastly, we empirically validate the practicality of the over-approximation by\ncomputing constrained, data-driven reachable sets for the\nSmall-Vehicles-for-Autonomy (SVEA) hardware platform in two driving scenarios.",
    "descriptor": "",
    "authors": [
      "Amr Alanwar",
      "Frank J. Jiang",
      "Maryam Sharifi",
      "Dimos V. Dimarogonas",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07121"
  },
  {
    "id": "arXiv:2109.07125",
    "title": "Diagnosability of labeled max-plus automata",
    "abstract": "In this paper, \\emph{diagnosability} is characterized for a labeled max-plus\nautomaton $\\mathcal{A}^{\\mathcal{D}}$ over a dioid $\\mathcal{D}$ as a real-time\nsystem. In order to represent time elapsing, a special class of dioids called\n\\emph{progressive} are considered, in which there is a total canonical order,\nthere is at least one element greater than $\\textbf{1}$, the product of\nsufficiently many elements greater than $\\textbf{1}$ is arbitrarily large, and\nthe cancellative law is satisfied. Then a notion of diagnosability is\nformulated for $\\mathcal{A}^{\\mathcal{D}}$ over a progressive dioid\n$\\mathcal{D}$. By developing a notion of \\emph{concurrent composition}, a\nsufficient and necessary condition is given for diagnosability of automaton\n$\\mathcal{A}^{\\mathcal{D}}$. It is also proven that the problem of verifying\ndiagnosability of $\\mathcal{A}^{\\underline{\\mathbb{Q}}}$ is coNP-complete,\nwhere coNP-hardness even holds for deterministic, deadlock-free, and\ndivergence-free $\\mathcal{A}^{\\underline{\\mathbb{N}}}$, where\n$\\underline{\\mathbb{Q}}$ and $\\underline{\\mathbb{N}}$ are the max-plus dioids\nhaving elements in $\\mathbb{Q}\\cup\\{-\\infty\\}$ and $\\mathbb{N}\\cup\\{-\\infty\\}$,\nrespectively.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Kuize Zhang",
      "Joerg Raisch"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2109.07125"
  },
  {
    "id": "arXiv:2109.07127",
    "title": "A Survey on Data Cleaning Methods for Improved Machine Learning Model  Performance",
    "abstract": "Data cleaning is the initial stage of any machine learning project and is one\nof the most critical processes in data analysis. It is a critical step in\nensuring that the dataset is devoid of incorrect or erroneous data. It can be\ndone manually with data wrangling tools, or it can be completed automatically\nwith a computer program. Data cleaning entails a slew of procedures that, once\ndone, make the data ready for analysis. Given its significance in numerous\nfields, there is a growing interest in the development of efficient and\neffective data cleaning frameworks. In this survey, some of the most recent\nadvancements of data cleaning approaches are examined for their effectiveness\nand the future research directions are suggested to close the gap in each of\nthe methods.",
    "descriptor": "",
    "authors": [
      "Ga Young Lee",
      "Lubna Alzamil",
      "Bakhtiyar Doskenov",
      "Arash Termehchy"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.07127"
  },
  {
    "id": "arXiv:2109.07128",
    "title": "The interplay of different metrics for the construction of constant  dimension codes",
    "abstract": "A basic problem for constant dimension codes is to determine the maximum\npossible size $A_q(n,d;k)$ of a set of $k$-dimensional subspaces in\n$\\mathbb{F}_q^n$, called codewords, such that the subspace distance satisfies\n$d_S(U,W):=2k-2\\dim(U\\cap W)\\ge d$ for all pairs of different codewords $U$,\n$W$. Constant dimension codes have applications in e.g.\\ random linear network\ncoding, cryptography, and distributed storage. Bounds for $A_q(n,d;k)$ are the\ntopic of many recent research papers. Providing a general framework we survey\nmany of the latest constructions and show up the potential for further\nimprovements. As examples we give improved constructions for the cases\n$A_q(10,4;5)$, $A_q(11,4;4)$, $A_q(12,6;6)$, and $A_q(15,4;4)$. We also derive\ngeneral upper bounds for subcodes arising in those constructions.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Sascha Kurz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.07128"
  },
  {
    "id": "arXiv:2109.07129",
    "title": "What Does The User Want? Information Gain for Hierarchical Dialogue  Policy Optimisation",
    "abstract": "The dialogue management component of a task-oriented dialogue system is\ntypically optimised via reinforcement learning (RL). Optimisation via RL is\nhighly susceptible to sample inefficiency and instability. The hierarchical\napproach called Feudal Dialogue Management takes a step towards more efficient\nlearning by decomposing the action space. However, it still suffers from\ninstability due to the reward only being provided at the end of the dialogue.\nWe propose the usage of an intrinsic reward based on information gain to\naddress this issue. Our proposed reward favours actions that resolve\nuncertainty or query the user whenever necessary. It enables the policy to\nlearn how to retrieve the users' needs efficiently, which is an integral aspect\nin every task-oriented conversation. Our algorithm, which we call FeudalGain,\nachieves state-of-the-art results in most environments of the PyDial framework,\noutperforming much more complex approaches. We confirm the sample efficiency\nand stability of our algorithm through experiments in simulation and a human\ntrial.",
    "descriptor": "",
    "authors": [
      "Christian Geishauser",
      "Songbo Hu",
      "Hsien-chin Lin",
      "Nurul Lubis",
      "Michael Heck",
      "Shutong Feng",
      "Carel van Niekerk",
      "Milica Ga\u0161i\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07129"
  },
  {
    "id": "arXiv:2109.07131",
    "title": "HM-DDP: A Hybrid Multiple-shooting Differential Dynamic Programming  Method for Constrained Trajectory Optimization",
    "abstract": "Trajectory optimization has been used extensively in robotic systems. In\nparticular, Differential Dynamic Programming (DDP) has performed well as an\noff-line planner or an online nonlinear model predictive control solver, with a\nlower computational cost compared with other general-purpose nonlinear\nprogramming solvers. However, standard DDP cannot handle any constraints or\nperform reasonable initialization of a state trajectory. In this paper, we\npropose a hybrid constrained DDP variant with a multiple-shooting framework.\nThe main technical contributions are twofold: 1) In addition to inheriting the\nsimplicity of the initialization in multiple shooting, a two-stage framework is\ndeveloped to deal with state and control inequality constraints robustly\nwithout loss of the linear feedback term of DDP. Such a hybrid strategy offers\na fast convergence of constraint satisfaction. 2) An improved globalization\nstrategy is proposed to exploit the coupled effects between line-searching and\nregularization, which is able to enhance the numerical robustness of DDP-like\napproaches. Our approach is tested on three constrained trajectory optimization\nproblems with nonlinear inequality constraints and outperforms the\ncommonly-used collocation and shooting methods in terms of runtime and\nconstraint satisfaction.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Yunxi Tang",
      "Xiangyu Chu",
      "K. W. Samuel Au"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07131"
  },
  {
    "id": "arXiv:2109.07132",
    "title": "Parallel Constraint-Driven Inductive Logic Programming",
    "abstract": "Multi-core machines are ubiquitous. However, most inductive logic programming\n(ILP) approaches use only a single core, which severely limits their\nscalability. To address this limitation, we introduce parallel techniques based\non constraint-driven ILP where the goal is to accumulate constraints to\nrestrict the hypothesis space. Our experiments on two domains (program\nsynthesis and inductive general game playing) show that (i) parallelisation can\nsubstantially reduce learning times, and (ii) worker communication (i.e.\nsharing constraints) is important for good performance.",
    "descriptor": "\nComments: Paper under review\n",
    "authors": [
      "Andrew Cropper",
      "Oghenejokpeme Orhobor",
      "Cristian Dinu",
      "Rolf Morel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07132"
  },
  {
    "id": "arXiv:2109.07133",
    "title": "Combining Context Awareness and Planning to Learn Behavior Trees from  Demonstration",
    "abstract": "Fast changing tasks in unpredictable, collaborative environments are typical\nfor medium-small companies, where robotised applications are increasing. Thus,\nrobot programs should be generated in short time with small effort, and the\nrobot able to react dynamically to the environment. To address this we propose\na method that combines context awareness and planning to learn Behavior Trees\n(BTs), a reactive policy representation that is becoming more popular in\nrobotics and has been used successfully in many collaborative scenarios.\nContext awareness allows to infer from the demonstration the frames in which\nactions are executed and to capture relevant aspects of the task, while a\nplanner is used to automatically generate the BT from the sequence of actions\nfrom the demonstration. The learned BT is shown to solve non-trivial\nmanipulation tasks where learning the context is fundamental to achieve the\ngoal. Moreover, we collected non-expert demonstrations to study the\nperformances of the algorithm in industrial scenarios.",
    "descriptor": "\nComments: Submitted to ICRA 2022\n",
    "authors": [
      "Oscar Gustavsson",
      "Matteo Iovino",
      "Jonathan Styrud",
      "Christian Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07133"
  },
  {
    "id": "arXiv:2109.07134",
    "title": "ROW-SLAM: Under-Canopy Cornfield Semantic SLAM",
    "abstract": "We study a semantic SLAM problem faced by a robot tasked with autonomous\nweeding under the corn canopy. The goal is to detect corn stalks and localize\nthem in a global coordinate frame. This is a challenging setup for existing\nalgorithms because there is very little space between the camera and the\nplants, and the camera motion is primarily restricted to be along the row. To\novercome these challenges, we present a multi-camera system where a side camera\n(facing the plants) is used for detection whereas front and back cameras are\nused for motion estimation. Next, we show how semantic features in the\nenvironment (corn stalks, ground, and crop planes) can be used to develop a\nrobust semantic SLAM solution and present results from field trials performed\nthroughout the growing season across various cornfields.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Jiacheng Yuan",
      "Jungseok Hong",
      "Junaed Sattar",
      "Volkan Isler"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07134"
  },
  {
    "id": "arXiv:2109.07135",
    "title": "Co-Embedding: Discovering Communities on Bipartite Graphs through  Projection",
    "abstract": "Many datasets take the form of a bipartite graph where two types of nodes are\nconnected by relationships, like the movies watched by a user or the tags\nassociated with a file. The partitioning of the bipartite graph could be used\nto fasten recommender systems, or reduce the information retrieval system's\nindex size, by identifying groups of items with similar properties. This type\nof graph is often processed by algorithms using the Vector Space Model\nrepresentation, where a binary vector represents an item with 0 and 1. The main\nproblem with this representation is the dimension relatedness, like words'\nsynonymity, which is not considered. This article proposes a co-clustering\nalgorithm using items projection, allowing the measurement of features\nsimilarity. We evaluated our algorithm on a cluster retrieval task. Over\nvarious datasets, our algorithm produced well balanced clusters with coherent\nitems in, leading to high retrieval scores on this task.",
    "descriptor": "\nComments: Submitted and accepted to FICC 2022 (Future of Information and Communication Conference)\n",
    "authors": [
      "Ga\u00eblle Candel",
      "David Naccache"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07135"
  },
  {
    "id": "arXiv:2109.07137",
    "title": "Optimal Cycling of a Heterogenous Battery Bank via Reinforcement  Learning",
    "abstract": "We consider the problem of optimal charging/discharging of a bank of\nheterogenous battery units, driven by stochastic electricity generation and\ndemand processes. The batteries in the battery bank may differ with respect to\ntheir capacities, ramp constraints, losses, as well as cycling costs. The goal\nis to minimize the degradation costs associated with battery cycling in the\nlong run; this is posed formally as a Markov decision process. We propose a\nlinear function approximation based Q-learning algorithm for learning the\noptimal solution, using a specially designed class of kernel functions that\napproximate the structure of the value functions associated with the MDP. The\nproposed algorithm is validated via an extensive case study.",
    "descriptor": "\nComments: Appeared on IEEE SmartGridComm 2021 conference\n",
    "authors": [
      "Vivek Deulkar",
      "Jayakrishnan Nair"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07137"
  },
  {
    "id": "arXiv:2109.07138",
    "title": "Patch-based medical image segmentation using Quantum Tensor Networks",
    "abstract": "Tensor networks are efficient factorisations of high dimensional tensors into\na network of lower order tensors. They have been most commonly used to model\nentanglement in quantum many-body systems and more recently are witnessing\nincreased applications in supervised machine learning. In this work, we\nformulate image segmentation in a supervised setting with tensor networks. The\nkey idea is to first lift the pixels in image patches to exponentially high\ndimensional feature spaces and using a linear decision hyper-plane to classify\nthe input pixels into foreground and background classes. The high dimensional\nlinear model itself is approximated using the matrix product state (MPS) tensor\nnetwork. The MPS is weight-shared between the non-overlapping image patches\nresulting in our strided tensor network model. The performance of the proposed\nmodel is evaluated on three 2D- and one 3D- biomedical imaging datasets. The\nperformance of the proposed tensor network segmentation model is compared with\nrelevant baseline methods. In the 2D experiments, the tensor network model\nyeilds competitive performance compared to the baseline methods while being\nmore resource efficient.",
    "descriptor": "\nComments: Possible journal extension of our preliminary conference work \"Segmenting two-dimensional structures with strided tensor networks\", Selvan et al. 2021, available at arXiv:2102.06900. 22 pages, 12 figures. arXiv admin note: text overlap with arXiv:2102.06900\n",
    "authors": [
      "Raghavendra Selvan",
      "Erik B Dam",
      "S\u00f8ren Alexander Flensborg",
      "Jens Petersen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07138"
  },
  {
    "id": "arXiv:2109.07140",
    "title": "On the Universality of Deep COntextual Language Models",
    "abstract": "Deep Contextual Language Models (LMs) like ELMO, BERT, and their successors\ndominate the landscape of Natural Language Processing due to their ability to\nscale across multiple tasks rapidly by pre-training a single model, followed by\ntask-specific fine-tuning. Furthermore, multilingual versions of such models\nlike XLM-R and mBERT have given promising results in zero-shot cross-lingual\ntransfer, potentially enabling NLP applications in many under-served and\nunder-resourced languages. Due to this initial success, pre-trained models are\nbeing used as `Universal Language Models' as the starting point across diverse\ntasks, domains, and languages. This work explores the notion of `Universality'\nby identifying seven dimensions across which a universal model should be able\nto scale, that is, perform equally well or reasonably well, to be useful across\ndiverse settings. We outline the current theoretical and empirical results that\nsupport model performance across these dimensions, along with extensions that\nmay help address some of their current limitations. Through this survey, we lay\nthe foundation for understanding the capabilities and limitations of massive\ncontextual language models and help discern research gaps and directions for\nfuture work to make these LMs inclusive and fair to diverse applications,\nusers, and linguistic phenomena.",
    "descriptor": "",
    "authors": [
      "Shaily Bhatt",
      "Poonam Goyal",
      "Sandipan Dandapat",
      "Monojit Choudhury",
      "Sunayana Sitaram"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07140"
  },
  {
    "id": "arXiv:2109.07141",
    "title": "Beyond Glass-Box Features: Uncertainty Quantification Enhanced Quality  Estimation for Neural Machine Translation",
    "abstract": "Quality Estimation (QE) plays an essential role in applications of Machine\nTranslation (MT). Traditionally, a QE system accepts the original source text\nand translation from a black-box MT system as input. Recently, a few studies\nindicate that as a by-product of translation, QE benefits from the model and\ntraining data's information of the MT system where the translations come from,\nand it is called the \"glass-box QE\". In this paper, we extend the definition of\n\"glass-box QE\" generally to uncertainty quantification with both \"black-box\"\nand \"glass-box\" approaches and design several features deduced from them to\nblaze a new trial in improving QE's performance. We propose a framework to fuse\nthe feature engineering of uncertainty quantification into a pre-trained\ncross-lingual language model to predict the translation quality. Experiment\nresults show that our method achieves state-of-the-art performances on the\ndatasets of WMT 2020 QE shared task.",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2021\n",
    "authors": [
      "Ke Wang",
      "Yangbin Shi",
      "Jiayi Wang",
      "Yuqi Zhang",
      "Yu Zhao",
      "Xiaolin Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07141"
  },
  {
    "id": "arXiv:2109.07142",
    "title": "Universal Adversarial Attack on Deep Learning Based Prognostics",
    "abstract": "Deep learning-based time series models are being extensively utilized in\nengineering and manufacturing industries for process control and optimization,\nasset monitoring, diagnostic and predictive maintenance. These models have\nshown great improvement in the prediction of the remaining useful life (RUL) of\nindustrial equipment but suffer from inherent vulnerability to adversarial\nattacks. These attacks can be easily exploited and can lead to catastrophic\nfailure of critical industrial equipment. In general, different adversarial\nperturbations are computed for each instance of the input data. This is,\nhowever, difficult for the attacker to achieve in real time due to higher\ncomputational requirement and lack of uninterrupted access to the input data.\nHence, we present the concept of universal adversarial perturbation, a special\nimperceptible noise to fool regression based RUL prediction models. Attackers\ncan easily utilize universal adversarial perturbations for real-time attack\nsince continuous access to input data and repetitive computation of adversarial\nperturbations are not a prerequisite for the same. We evaluate the effect of\nuniversal adversarial attacks using NASA turbofan engine dataset. We show that\naddition of universal adversarial perturbation to any instance of the input\ndata increases error in the output predicted by the model. To the best of our\nknowledge, we are the first to study the effect of the universal adversarial\nperturbation on time series regression models. We further demonstrate the\neffect of varying the strength of perturbations on RUL prediction models and\nfound that model accuracy decreases with the increase in perturbation strength\nof the universal adversarial attack. We also showcase that universal\nadversarial perturbation can be transferred across different models.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Arghya Basak",
      "Pradeep Rathore",
      "Sri Harsha Nistala",
      "Sagar Srinivas",
      "Venkataramana Runkana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.07142"
  },
  {
    "id": "arXiv:2109.07143",
    "title": "Spline-PINN: Approaching PDEs without Data using Fast, Physics-Informed  Hermite-Spline CNNs",
    "abstract": "Partial Differential Equations (PDEs) are notoriously difficult to solve. In\ngeneral, closed-form solutions are not available and numerical approximation\nschemes are computationally expensive. In this paper, we propose to approach\nthe solution of PDEs based on a novel technique that combines the advantages of\ntwo recently emerging machine learning based approaches. First,\nphysics-informed neural networks (PINNs) learn continuous solutions of PDEs and\ncan be trained with little to no ground truth data. However, PINNs do not\ngeneralize well to unseen domains. Second, convolutional neural networks\nprovide fast inference and generalize but either require large amounts of\ntraining data or a physics-constrained loss based on finite differences that\ncan lead to inaccuracies and discretization artifacts. We leverage the\nadvantages of both of these approaches by using Hermite spline kernels in order\nto continuously interpolate a grid-based state representation that can be\nhandled by a CNN. This allows for training without any precomputed training\ndata using a physics-informed loss function only and provides fast, continuous\nsolutions that generalize to unseen domains. We demonstrate the potential of\nour method at the examples of the incompressible Navier-Stokes equation and the\ndamped wave equation. Our models are able to learn several intriguing phenomena\nsuch as Karman vortex streets, the Magnus effect, Doppler effect, interference\npatterns and wave reflections. Our quantitative assessment and an interactive\nreal-time demo show that we are narrowing the gap in accuracy of unsupervised\nML based methods to industrial CFD solvers while being orders of magnitude\nfaster.",
    "descriptor": "\nComments: Submitted to AAAI 2022\n",
    "authors": [
      "Nils Wandel",
      "Michael Weinmann",
      "Michael Neidlin",
      "Reinhard Klein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2109.07143"
  },
  {
    "id": "arXiv:2109.07148",
    "title": "Semantics of European poetry is shaped by conservative forces: The  relationship between poetic meter and meaning in accentual-syllabic verse",
    "abstract": "Recent advances in cultural analytics and large-scale computational studies\nof art, literature and film often show that long-term change in the features of\nartistic works happens gradually. These findings suggest that conservative\nforces that shape creative domains might be underestimated. To this end, we\nprovide the first large-scale formal evidence of the persistent association\nbetween poetic meter and semantics in 18-19th European literatures, using\nCzech, German and Russian collections with additional data from English poetry\nand early modern Dutch songs. Our study traces this association through a\nseries of clustering experiments using the abstracted semantic features of\n150,000 poems. With the aid of topic modeling we infer semantic features for\nindividual poems. Texts were also lexically simplified across collections to\nincrease generalizability and decrease the sparseness of word frequency\ndistributions. Topics alone enable recognition of the meters in each observed\nlanguage, as may be seen from highly robust clustering of same-meter samples\n(median Adjusted Rand Index between 0.48 and 1). In addition, this study shows\nthat the strength of the association between form and meaning tends to decrease\nover time. This may reflect a shift in aesthetic conventions between the 18th\nand 19th centuries as individual innovation was increasingly favored in\nliterature. Despite this decline, it remains possible to recognize semantics of\nthe meters from past or future, which suggests the continuity of semantic\ntraditions while also revealing the historical variability of conditions across\nlanguages. This paper argues that distinct metrical forms, which are often\ncopied in a language over centuries, also maintain long-term semantic inertia\nin poetry. Our findings, thus, highlight the role of the formal features of\ncultural items in influencing the pace and shape of cultural evolution.",
    "descriptor": "",
    "authors": [
      "Artjoms \u0160e\u013ca",
      "Petr Plech\u00e1\u010d",
      "Alie Lassche"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07148"
  },
  {
    "id": "arXiv:2109.07149",
    "title": "Fusion with Hierarchical Graphs for Mulitmodal Emotion Recognition",
    "abstract": "Automatic emotion recognition (AER) based on enriched multimodal inputs,\nincluding text, speech, and visual clues, is crucial in the development of\nemotionally intelligent machines. Although complex modality relationships have\nbeen proven effective for AER, they are still largely underexplored because\nprevious works predominantly relied on various fusion mechanisms with simply\nconcatenated features to learn multimodal representations for emotion\nclassification. This paper proposes a novel hierarchical fusion graph\nconvolutional network (HFGCN) model that learns more informative multimodal\nrepresentations by considering the modality dependencies during the feature\nfusion procedure. Specifically, the proposed model fuses multimodality inputs\nusing a two-stage graph construction approach and encodes the modality\ndependencies into the conversation representation. We verified the\ninterpretable capabilities of the proposed method by projecting the emotional\nstates to a 2D valence-arousal (VA) subspace. Extensive experiments showed the\neffectiveness of our proposed model for more accurate AER, which yielded\nstate-of-the-art results on two public datasets, IEMOCAP and MELD.",
    "descriptor": "",
    "authors": [
      "Shuyun Tang",
      "Zhaojie Luo",
      "Guoshun Nan",
      "Yuichiro Yoshikawa",
      "Ishiguro Hiroshi"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.07149"
  },
  {
    "id": "arXiv:2109.07150",
    "title": "Solving Occlusion in Terrain Mapping with Neural Networks",
    "abstract": "Accurate and complete terrain maps enhance the awareness of autonomous robots\nand enable safe and optimal path planning. Rocks and topography often create\nocclusions and lead to missing elevation information in the Digital Elevation\nMap (DEM). Currently, mostly traditional inpainting techniques based on\ndiffusion or patch-matching are used by autonomous mobile robots to fill-in\nincomplete DEMs. These methods cannot leverage the high-level terrain\ncharacteristics and the geometric constraints of line of sight we humans use\nintuitively to predict occluded areas. We propose to use neural networks to\nreconstruct the occluded areas in DEMs. We introduce a self-supervised learning\napproach capable of training on real-world data without a need for ground-truth\ninformation. We accomplish this by adding artificial occlusion to the\nincomplete elevation maps constructed on a real robot by performing ray\ncasting. We first evaluate a supervised learning approach on synthetic data for\nwhich we have the full ground-truth available and subsequently move to several\nreal-world datasets. These real-world datasets were recorded during autonomous\nexploration of both structured and unstructured terrain with a legged robot,\nand additionally in a planetary scenario on Lunar analogue terrain. We state a\nsignificant improvement compared to the Telea and Navier-Stokes baseline\nmethods both on synthetic terrain and for the real-world datasets. Our neural\nnetwork is able to run in real-time on both CPU and GPU with suitable sampling\nrates for autonomous ground robots.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Maximilian St\u00f6lzle",
      "Takahiro Miki",
      "Levin Gerdes",
      "Martin Azkarate",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07150"
  },
  {
    "id": "arXiv:2109.07152",
    "title": "Incorporating Residual and Normalization Layers into Analysis of Masked  Language Models",
    "abstract": "Transformer architecture has become ubiquitous in the natural language\nprocessing field. To interpret the Transformer-based models, their attention\npatterns have been extensively analyzed. However, the Transformer architecture\nis not only composed of the multi-head attention; other components can also\ncontribute to Transformers' progressive performance. In this study, we extended\nthe scope of the analysis of Transformers from solely the attention patterns to\nthe whole attention block, i.e., multi-head attention, residual connection, and\nlayer normalization. Our analysis of Transformer-based masked language models\nshows that the token-to-token interaction performed via attention has less\nimpact on the intermediate representations than previously assumed. These\nresults provide new intuitive explanations of existing reports; for example,\ndiscarding the learned attention patterns tends not to adversely affect the\nperformance. The codes of our experiments are publicly available.",
    "descriptor": "\nComments: 22 pages, accepted to EMNLP 2021 main conference\n",
    "authors": [
      "Goro Kobayashi",
      "Tatsuki Kuribayashi",
      "Sho Yokoi",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07152"
  },
  {
    "id": "arXiv:2109.07154",
    "title": "Can Language Models be Biomedical Knowledge Bases?",
    "abstract": "Pre-trained language models (LMs) have become ubiquitous in solving various\nnatural language processing (NLP) tasks. There has been increasing interest in\nwhat knowledge these LMs contain and how we can extract that knowledge,\ntreating LMs as knowledge bases (KBs). While there has been much work on\nprobing LMs in the general domain, there has been little attention to whether\nthese powerful LMs can be used as domain-specific KBs. To this end, we create\nthe BioLAMA benchmark, which is comprised of 49K biomedical factual knowledge\ntriples for probing biomedical LMs. We find that biomedical LMs with recently\nproposed probing methods can achieve up to 18.51% Acc@5 on retrieving\nbiomedical knowledge. Although this seems promising given the task difficulty,\nour detailed analyses reveal that most predictions are highly correlated with\nprompt templates without any subjects, hence producing similar results on each\nrelation and hindering their capabilities to be used as domain-specific KBs. We\nhope that BioLAMA can serve as a challenging benchmark for biomedical factual\nprobing.",
    "descriptor": "\nComments: EMNLP 2021. Code available at this https URL\n",
    "authors": [
      "Mujeen Sung",
      "Jinhyuk Lee",
      "Sean Yi",
      "Minji Jeon",
      "Sungdong Kim",
      "Jaewoo Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07154"
  },
  {
    "id": "arXiv:2109.07157",
    "title": "Learning to Match Job Candidates Using Multilingual Bi-Encoder BERT",
    "abstract": "In this talk, we will show how we used Randstad history of candidate\nplacements to generate labeled CV-vacancy pairs dataset. Afterwards we\nfine-tune a multilingual BERT with bi encoder structure over this dataset, by\nadding a cosine similarity log loss layer. We will explain how using the\nmentioned structure helps us overcome most of the challenges described above,\nand how it enables us to build a maintainable and scalable pipeline to match\nCVs and vacancies. In addition, we show how we gain a better semantic\nunderstanding, and learn to bridge the vocabulary gap. Finally, we highlight\nhow multilingual transformers help us handle cross language barrier and might\nreduce discrimination.",
    "descriptor": "\nComments: 2 pages, To be presented as a main talk at RecSys '21: Fifteenth ACM Conference on Recommender Systems. arXiv admin note: substantial text overlap with arXiv:2109.06501\n",
    "authors": [
      "Dor Lavi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.07157"
  },
  {
    "id": "arXiv:2109.07161",
    "title": "Resolution-robust Large Mask Inpainting with Fourier Convolutions",
    "abstract": "Modern image inpainting systems, despite the significant progress, often\nstruggle with large missing areas, complex geometric structures, and\nhigh-resolution images. We find that one of the main reasons for that is the\nlack of an effective receptive field in both the inpainting network and the\nloss function. To alleviate this issue, we propose a new method called large\nmask inpainting (LaMa). LaMa is based on i) a new inpainting network\narchitecture that uses fast Fourier convolutions, which have the image-wide\nreceptive field; ii) a high receptive field perceptual loss; and iii) large\ntraining masks, which unlocks the potential of the first two components. Our\ninpainting network improves the state-of-the-art across a range of datasets and\nachieves excellent performance even in challenging scenarios, e.g. completion\nof periodic structures. Our model generalizes surprisingly well to resolutions\nthat are higher than those seen at train time, and achieves this at lower\nparameter&compute costs than the competitive baselines. The code is available\nat https://github.com/saic-mdal/lama.",
    "descriptor": "",
    "authors": [
      "Roman Suvorov",
      "Elizaveta Logacheva",
      "Anton Mashikhin",
      "Anastasia Remizova",
      "Arsenii Ashukha",
      "Aleksei Silvestrov",
      "Naejin Kong",
      "Harshith Goka",
      "Kiwoong Park",
      "Victor Lempitsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.07161"
  },
  {
    "id": "arXiv:2109.07162",
    "title": "MISSFormer: An Effective Medical Image Segmentation Transformer",
    "abstract": "The CNN-based methods have achieved impressive results in medical image\nsegmentation, but it failed to capture the long-range dependencies due to the\ninherent locality of convolution operation. Transformer-based methods are\npopular in vision tasks recently because of its capacity of long-range\ndependencies and get a promising performance. However, it lacks in modeling\nlocal context, although some works attempted to embed convolutional layer to\novercome this problem and achieved some improvement, but it makes the feature\ninconsistent and fails to leverage the natural multi-scale features of\nhierarchical transformer, which limit the performance of models. In this paper,\ntaking medical image segmentation as an example, we present MISSFormer, an\neffective and powerful Medical Image Segmentation tranSFormer. MISSFormer is a\nhierarchical encoder-decoder network and has two appealing designs: 1) A feed\nforward network is redesigned with the proposed Enhanced Transformer Block,\nwhich makes features aligned adaptively and enhances the long-range\ndependencies and local context. 2) We proposed Enhanced Transformer Context\nBridge, a context bridge with the enhanced transformer block to model the\nlong-range dependencies and local context of multi-scale features generated by\nour hierarchical transformer encoder. Driven by these two designs, the\nMISSFormer shows strong capacity to capture more valuable dependencies and\ncontext in medical image segmentation. The experiments on multi-organ and\ncardiac segmentation tasks demonstrate the superiority, effectiveness and\nrobustness of our MISSFormer, the exprimental results of MISSFormer trained\nfrom scratch even outperforms state-of-the-art methods pretrained on ImageNet,\nand the core designs can be generalized to other visual segmentation tasks. The\ncode will be released in Github.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Xiaohong Huang",
      "Zhifang Deng",
      "Dandan Li",
      "Xueguang Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07162"
  },
  {
    "id": "arXiv:2109.07165",
    "title": "3D Annotation Of Arbitrary Objects In The Wild",
    "abstract": "Recent years have produced a variety of learning based methods in the context\nof computer vision and robotics. Most of the recently proposed methods are\nbased on deep learning, which require very large amounts of data compared to\ntraditional methods. The performance of the deep learning methods are largely\ndependent on the data distribution they were trained on, and it is important to\nuse data from the robot's actual operating domain during training. Therefore,\nit is not possible to rely on pre-built, generic datasets when deploying robots\nin real environments, creating a need for efficient data collection and\nannotation in the specific operating conditions the robots will operate in. The\nchallenge is then: how do we reduce the cost of obtaining such datasets to a\npoint where we can easily deploy our robots in new conditions, environments and\nto support new sensors? As an answer to this question, we propose a data\nannotation pipeline based on SLAM, 3D reconstruction, and 3D-to-2D geometry.\nThe pipeline allows creating 3D and 2D bounding boxes, along with per-pixel\nannotations of arbitrary objects without needing accurate 3D models of the\nobjects prior to data collection and annotation. Our results showcase almost\n90% Intersection-over-Union (IoU) agreement on both semantic segmentation and\n2D bounding box detection across a variety of objects and scenes, while\nspeeding up the annotation process by several orders of magnitude compared to\ntraditional manual annotation.",
    "descriptor": "\nComments: 6 pages, 4 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kenneth Blomqvist",
      "Julius Hietala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07165"
  },
  {
    "id": "arXiv:2109.07169",
    "title": "Disentangling Generative Factors in Natural Language with Discrete  Variational Autoencoders",
    "abstract": "The ability of learning disentangled representations represents a major step\nfor interpretable NLP systems as it allows latent linguistic features to be\ncontrolled. Most approaches to disentanglement rely on continuous variables,\nboth for images and text. We argue that despite being suitable for image\ndatasets, continuous variables may not be ideal to model features of textual\ndata, due to the fact that most generative factors in text are discrete. We\npropose a Variational Autoencoder based method which models language features\nas discrete variables and encourages independence between variables for\nlearning disentangled representations. The proposed model outperforms\ncontinuous and discrete baselines on several qualitative and quantitative\nbenchmarks for disentanglement as well as on a text style transfer downstream\napplication.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Giangiacomo Mercatali",
      "Andr\u00e9 Freitas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07169"
  },
  {
    "id": "arXiv:2109.07170",
    "title": "Powered Hawkes-Dirichlet Process: Challenging Textual Clustering using a  Flexible Temporal Prior",
    "abstract": "The textual content of a document and its publication date are intertwined.\nFor example, the publication of a news article on a topic is influenced by\nprevious publications on similar issues, according to underlying temporal\ndynamics. However, it can be challenging to retrieve meaningful information\nwhen textual information conveys little information or when temporal dynamics\nare hard to unveil. Furthermore, the textual content of a document is not\nalways linked to its temporal dynamics. We develop a flexible method to create\nclusters of textual documents according to both their content and publication\ntime, the Powered Dirichlet-Hawkes process (PDHP). We show PDHP yields\nsignificantly better results than state-of-the-art models when temporal\ninformation or textual content is weakly informative. The PDHP also alleviates\nthe hypothesis that textual content and temporal dynamics are always perfectly\ncorrelated. PDHP allows retrieving textual clusters, temporal clusters, or a\nmixture of both with high accuracy when they are not. We demonstrate that PDHP\ngeneralizes previous work --such as the Dirichlet-Hawkes process (DHP) and\nUniform process (UP). Finally, we illustrate the changes induced by PDHP over\nDHP and UP in a real-world application using Reddit data.",
    "descriptor": "",
    "authors": [
      "Ga\u00ebl Poux-M\u00e9dard",
      "Julien Velcin",
      "Sabine Loudcher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.07170"
  },
  {
    "id": "arXiv:2109.07171",
    "title": "Balancing detectability and performance of attacks on the control  channel of Markov Decision Processes",
    "abstract": "We investigate the problem of designing optimal stealthy poisoning attacks on\nthe control channel of Markov decision processes (MDPs). This research is\nmotivated by the recent interest of the research community for adversarial and\npoisoning attacks applied to MDPs, and reinforcement learning (RL) methods. The\npolicies resulting from these methods have been shown to be vulnerable to\nattacks perturbing the observations of the decision-maker. In such an attack,\ndrawing inspiration from adversarial examples used in supervised learning, the\namplitude of the adversarial perturbation is limited according to some norm,\nwith the hope that this constraint will make the attack imperceptible. However,\nsuch constraints do not grant any level of undetectability and do not take into\naccount the dynamic nature of the underlying Markov process. In this paper, we\npropose a new attack formulation, based on information-theoretical quantities,\nthat considers the objective of minimizing the detectability of the attack as\nwell as the performance of the controlled process. We analyze the trade-off\nbetween the efficiency of the attack and its detectability. We conclude with\nexamples and numerical simulations illustrating this trade-off.",
    "descriptor": "",
    "authors": [
      "Alessio Russo",
      "Alexandre Proutiere"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07171"
  },
  {
    "id": "arXiv:2109.07173",
    "title": "A Comparison of Code Embeddings and Beyond",
    "abstract": "Program representation learning is a fundamental task in software engineering\napplications. With the availability of \"big code\" and the development of deep\nlearning techniques, various program representation learning models have been\nproposed to understand the semantic properties of programs and applied on\ndifferent software engineering tasks. However, no previous study has\ncomprehensively assessed the generalizability of these deep models on different\ntasks, so that the pros and cons of the models are unclear. In this experience\npaper, we try to bridge this gap by systemically evaluating the performance of\neight program representation learning models on three common tasks, where six\nmodels are based on abstract syntax trees and two models are based on plain\ntext of source code. We kindly explain the criteria for selecting the models\nand tasks, as well as the method for enabling end-to-end learning in each task.\nThe results of performance evaluation show that they perform diversely in each\ntask and the performance of the AST-based models is generally unstable over\ndifferent tasks. In order to further explain the results, we apply a prediction\nattribution technique to find what elements are captured by the models and\nresponsible for the predictions in each task. Based on the findings, we discuss\nsome general principles for better capturing the information in the source\ncode, and hope to inspire researchers to improve program representation\nlearning methods for software engineering tasks.",
    "descriptor": "",
    "authors": [
      "Siqi Han",
      "DongXia Wang",
      "Wanting Li",
      "Xuesong Lu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.07173"
  },
  {
    "id": "arXiv:2109.07177",
    "title": "Adversarial Mixing Policy for Relaxing Locally Linear Constraints in  Mixup",
    "abstract": "Mixup is a recent regularizer for current deep classification networks.\nThrough training a neural network on convex combinations of pairs of examples\nand their labels, it imposes locally linear constraints on the model's input\nspace. However, such strict linear constraints often lead to under-fitting\nwhich degrades the effects of regularization. Noticeably, this issue is getting\nmore serious when the resource is extremely limited. To address these issues,\nwe propose the Adversarial Mixing Policy (AMP), organized in a min-max-rand\nformulation, to relax the Locally Linear Constraints in Mixup. Specifically,\nAMP adds a small adversarial perturbation to the mixing coefficients rather\nthan the examples. Thus, slight non-linearity is injected in-between the\nsynthetic examples and synthetic labels. By training on these data, the deep\nnetworks are further regularized, and thus achieve a lower predictive error\nrate. Experiments on five text classification benchmarks and five backbone\nmodels have empirically shown that our methods reduce the error rate over Mixup\nvariants in a significant margin (up to 31.3%), especially in low-resource\nconditions (up to 17.5%).",
    "descriptor": "\nComments: This paper is accepted to appear in the main conference of EMNLP2021\n",
    "authors": [
      "Guang Liu",
      "Yuzhao Mao",
      "Hailong Huang",
      "Weiguo Gao",
      "Xuan Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07177"
  },
  {
    "id": "arXiv:2109.07180",
    "title": "Back to Basics: Deep Reinforcement Learning in Traffic Signal Control",
    "abstract": "In this paper we revisit some of the fundamental premises for a reinforcement\nlearning (RL) approach to self-learning traffic lights. We propose RLight, a\ncombination of choices that offers robust performance and good generalization\nto unseen traffic flows. In particular, our main contributions are threefold:\nour lightweight and cluster-aware state representation leads to improved\nperformance; we reformulate the MDP such that it skips redundant timesteps of\nyellow light, speeding up learning by 30%; and we investigate the action space\nand provide insight into the difference in performance between acyclic and\ncyclic phase transitions. Additionally, we provide insights into the\ngeneralisation of the methods to unseen traffic. Evaluations using the\nreal-world Hangzhou traffic dataset show that RLight outperforms\nstate-of-the-art rule-based and deep reinforcement learning algorithms,\ndemonstrating the potential of RL-based methods to improve urban traffic flows.",
    "descriptor": "\nComments: 9 pages, 4 figures; code for this paper is available at this https URL\n",
    "authors": [
      "Sierk Kanis",
      "Laurens Samson",
      "Daan Bloembergen",
      "Tim Bakker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07180"
  },
  {
    "id": "arXiv:2109.07183",
    "title": "Residual viscosity stabilized RBF-FD methods for solving nonlinear  conservation laws",
    "abstract": "We formulate an oversampled radial basis function generated finite difference\n(RBF-FD) method to solve time-dependent nonlinear conservation laws. The\nanalytic solutions of these problems are known to be discontinuous, which leads\nto occurrence of non-physical oscillations (Gibbs phenomenon) that pollute the\nnumerical solutions and can make them unstable. We address these difficulties\nusing a residual based artificial viscosity stabilization, where the residual\nof the conservation law indicates the approximate location of the shocks. The\nlocation is then used to locally apply an upwind viscosity term, which\nstabilizes the Gibbs phenomenon and does not smear the solution away from the\nshocks. The proposed method is numerically tested and proves to be robust and\naccurate when solving scalar conservation laws and systems of conservation\nlaws, such as compressible Euler equations.",
    "descriptor": "",
    "authors": [
      "Igor Tominec",
      "Murtazo Nazarov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.07183"
  },
  {
    "id": "arXiv:2109.07185",
    "title": "Transformer-based Language Models for Factoid Question Answering at  BioASQ9b",
    "abstract": "In this work, we describe our experiments and participating systems in the\nBioASQ Task 9b Phase B challenge of biomedical question answering. We have\nfocused on finding the ideal answers and investigated multi-task fine-tuning\nand gradual unfreezing techniques on transformer-based language models. For\nfactoid questions, our ALBERT-based systems ranked first in test batch 1 and\nfourth in test batch 2. Our DistilBERT systems outperformed the ALBERT variants\nin test batches 4 and 5 despite having 81% fewer parameters than ALBERT.\nHowever, we observed that gradual unfreezing had no significant impact on the\nmodel's accuracy compared to standard fine-tuning.",
    "descriptor": "\nComments: 12 pages, 3 figures, 4 tables. Accepted at BioASQ Workshop, CLEF Working Notes\n",
    "authors": [
      "Urvashi Khanna",
      "Diego Moll\u00e1"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07185"
  },
  {
    "id": "arXiv:2109.07189",
    "title": "On Characterization of Finite Geometric Distributive Lattices",
    "abstract": "A Lattice is a partially ordered set where both least upper bound and\ngreatest lower bound of any pair of elements are unique and exist within the\nset. K\\\"{o}tter and Kschischang proved that codes in the linear lattice can be\nused for error and erasure-correction in random networks. Codes in the linear\nlattice have previously been shown to be special cases of codes in modular\nlattices. Two well known classifications of modular lattices are geometric and\ndistributive lattices. We have identified the unique criterion which makes a\ngeometric lattice distributive, thus characterizing all finite geometric\ndistributive lattices. Our characterization helps to prove a conjecture\nregarding the maximum size of a distributive sublattice of a finite geometric\nlattice and identify the maximal case. The Whitney numbers of the class of\ngeometric distributive lattices are also calculated. We present a few other\napplications of this unique characterization to derive certain results\nregarding linearity and complements in the linear lattice.",
    "descriptor": "\nComments: 11 pages, 2 figures, submitted to Journal of Combinatorial Theory, Series A\n",
    "authors": [
      "Pranab Basu"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.07189"
  },
  {
    "id": "arXiv:2109.07193",
    "title": "FCA: Learning a 3D Full-coverage Vehicle Camouflage for Multi-view  Physical Adversarial Attack",
    "abstract": "Physical adversarial attacks in object detection have attracted increasing\nattention. However, most previous works focus on hiding the objects from the\ndetector by generating an individual adversarial patch, which only covers the\nplanar part of the vehicle's surface and fails to attack the detector in\nphysical scenarios for multi-view, long-distance and partially occluded\nobjects. To bridge the gap between digital attacks and physical attacks, we\nexploit the full 3D vehicle surface to propose a robust Full-coverage\nCamouflage Attack (FCA) to fool detectors. Specifically, we first try rendering\nthe non-planar camouflage texture over the full vehicle surface. To mimic the\nreal-world environment conditions, we then introduce a transformation function\nto transfer the rendered camouflaged vehicle into a photo-realistic scenario.\nFinally, we design an efficient loss function to optimize the camouflage\ntexture. Experiments show that the full-coverage camouflage attack can not only\noutperform state-of-the-art methods under various test cases but also\ngeneralize to different environments, vehicles, and object detectors.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "DonghuaWang",
      "Tingsong Jiang",
      "Jialiang Sun",
      "Weien Zhou",
      "Xiaoya Zhang",
      "Zhiqiang Gong",
      "Wen Yao",
      "Xiaoqian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07193"
  },
  {
    "id": "arXiv:2109.07194",
    "title": "Multiagent Multimodal Categorization for Symbol Emergence: Emergent  Communication via Interpersonal Cross-modal Inference",
    "abstract": "This paper describes a computational model of multiagent multimodal\ncategorization that realizes emergent communication. We clarify whether the\ncomputational model can reproduce the following functions in a symbol emergence\nsystem, comprising two agents with different sensory modalities playing a\nnaming game. (1) Function for forming a shared lexical system that comprises\nperceptual categories and corresponding signs, formed by agents through\nindividual learning and semiotic communication between agents. (2) Function to\nimprove the categorization accuracy in an agent via semiotic communication with\nanother agent, even when some sensory modalities of each agent are missing. (3)\nFunction that an agent infers unobserved sensory information based on a sign\nsampled from another agent in the same manner as cross-modal inference. We\npropose an interpersonal multimodal Dirichlet mixture (Inter-MDM), which is\nderived by dividing an integrative probabilistic generative model, which is\nobtained by integrating two Dirichlet mixtures (DMs). The Markov chain Monte\nCarlo algorithm realizes emergent communication. The experimental results\ndemonstrated that Inter-MDM enables agents to form multimodal categories and\nappropriately share signs between agents. It is shown that emergent\ncommunication improves categorization accuracy, even when some sensory\nmodalities are missing. Inter-MDM enables an agent to predict unobserved\ninformation based on a shared sign.",
    "descriptor": "\nComments: 27 pages, 5 figures, 12 tables\n",
    "authors": [
      "Yoshinobu Hagiwara",
      "Kazuma Furukawa",
      "Akira Taniguchi",
      "Tadahiro Taniguchi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07194"
  },
  {
    "id": "arXiv:2109.07195",
    "title": "Target Languages (vs. Inductive Biases) for Learning to Act and Plan",
    "abstract": "Recent breakthroughs in AI have shown the remarkable power of deep learning\nand deep reinforcement learning. These developments, however, have been tied to\nspecific tasks, and progress in out-of-distribution generalization has been\nlimited. While it is assumed that these limitations can be overcome by\nincorporating suitable inductive biases, the notion of inductive biases itself\nis often left vague and does not provide meaningful guidance. In the paper, I\narticulate a different learning approach where representations do not emerge\nfrom biases in a neural architecture but are learned over a given target\nlanguage with a known semantics. The basic ideas are implicit in mainstream AI\nwhere representations have been encoded in languages ranging from fragments of\nfirst-order logic to probabilistic structural causal models. The challenge is\nto learn from data, the representations that have traditionally been crafted by\nhand. Generalization is then a result of the semantics of the language. The\ngoals of the paper and talk are to make these ideas explicit, to place them in\na broader context where the design of the target language is crucial, and to\nillustrate them in the context of learning to act and plan. For this, after a\ngeneral discussion, I consider learning representations of actions, general\npolicies, and general decompositions. In these cases, learning is formulated as\na combinatorial optimization problem but nothing prevents the use deep learning\ntechniques instead. Indeed, learning representations over languages with a\nknown semantics provides an account of what is to be learned, while learning\nrepresentations with neural nets provides a complementary account of how\nrepresentations can be learned. The challenge and the opportunity is to bring\nthe two together.",
    "descriptor": "",
    "authors": [
      "Hector Geffner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07195"
  },
  {
    "id": "arXiv:2109.07196",
    "title": "Whole-Body Control with Motion/Force Transmissibility for  Parallel-Legged Robot",
    "abstract": "Whole-body control (WBC) has been applied to the locomotion of legged robots.\nHowever, current WBC methods have not considered the intrinsic features of\nparallel mechanisms, especially motion/force transmissibility (MFT). In this\nwork, we propose an MFT-enhanced WBC scheme. Introducing MFT into a WBC is\nchallenging due to the nonlinear relationship between MFT indices and the robot\nconfiguration. To overcome this challenge, we establish the MFT preferable\nspace of the robot and formulate it as a polyhedron in the joint space at the\nacceleration level. Then, the WBC employs the polyhedron as a soft constraint.\nAs a result, the robot possesses high-speed and high-acceleration capabilities\nby satisfying this constraint as well as staying away from its singularity. In\ncontrast with the WBC without considering MFT, our proposed scheme is more\nrobust to external disturbances, e.g., push recovery and uneven terrain\nlocomotion. simulations and experiments on a parallel-legged bipedal robot are\nprovided to demonstrate the performance and robustness of the proposed method.",
    "descriptor": "\nComments: 6 pages, 7 figures, submitted to ICRA 2022\n",
    "authors": [
      "Jiajun Wang",
      "Gang Han",
      "Xiaozhu Ju",
      "Mingguo Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07196"
  },
  {
    "id": "arXiv:2109.07201",
    "title": "Expectable Motion Unit: Avoiding Hazards From Human Involuntary Motions  in Human-Robot Interaction",
    "abstract": "In robotics, many control and planning schemes have been developed that\nensure the human physical safety in human-robot interaction. The human\npsychological state and expectation towards the robot, however, are typically\nneglected. Even if the robot behaviour is regarded as biomechanically safe,\nhumans may still react with rapid involuntary motion (IM) caused by startle or\nsurprise. Obviously, such sudden, uncontrolled motions can jeopardize safety\nand should be prevented by any means. In this paper, we propose the Expectable\nMotion Unit (EMU) concept which ensures that a certain probability of IM\noccurrence is not exceeded in a typical HRI setting. Based on a model of IM\noccurrence that we generate through an experiment with 29 participants, the\nmapping between robot velocity, robot-human distance, and the relative\nfrequency of IM occurrence is established. This mapping is processed towards a\nreal-time capable robot motion generator, which limits the robot velocity\nduring task execution if necessary. The EMU is combined with the\nwell-established Safe Motion Unit in order to integrate both physical and\npsychological safety knowledge and data into a holistic safety framework. In a\nvalidation experiment, it was shown that the EMU successfully avoids human IM\nin five out of six cases.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Robin Jeanne Kirschner",
      "Henning Mayer",
      "Lisa Burr",
      "Nico Mansfeld",
      "Saeed Abdolshah",
      "Sami Haddadin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07201"
  },
  {
    "id": "arXiv:2109.07202",
    "title": "Deep 3D Mesh Watermarking with Self-Adaptive Robustness",
    "abstract": "Robust 3D mesh watermarking is a traditional research topic in computer\ngraphics, which provides an efficient solution to the copyright protection for\n3D meshes. Traditionally, researchers need manually design watermarking\nalgorithms to achieve sufficient robustness for the actual application\nscenarios. In this paper, we propose the first deep learning-based 3D mesh\nwatermarking framework, which can solve this problem once for all. In detail,\nwe propose an end-to-end network, consisting of a watermark embedding\nsub-network, a watermark extracting sub-network and attack layers. We adopt the\ntopology-agnostic graph convolutional network (GCN) as the basic convolution\noperation for 3D meshes, so our network is not limited by registered meshes\n(which share a fixed topology). For the specific application scenario, we can\nintegrate the corresponding attack layers to guarantee adaptive robustness\nagainst possible attacks. To ensure the visual quality of watermarked 3D\nmeshes, we design a curvature-based loss function to constrain the local\ngeometry smoothness of watermarked meshes. Experimental results show that the\nproposed method can achieve more universal robustness and faster watermark\nembedding than baseline methods while guaranteeing comparable visual quality.",
    "descriptor": "",
    "authors": [
      "Feng Wang",
      "Hang Zhou",
      "Han Fang",
      "Xiaojuan Dong",
      "Weiming Zhang",
      "Xi Yang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.07202"
  },
  {
    "id": "arXiv:2109.07203",
    "title": "Sentiment Analysis in Poems in Misurata Sub-dialect -- A Sentiment  Detection in an Arabic Sub-dialect",
    "abstract": "Over the recent decades, there has been a significant increase and\ndevelopment of resources for Arabic natural language processing. This includes\nthe task of exploring Arabic Language Sentiment Analysis (ALSA) from Arabic\nutterances in both Modern Standard Arabic (MSA) and different Arabic dialects.\nThis study focuses on detecting sentiment in poems written in Misurata Arabic\nsub-dialect spoken in Misurata, Libya. The tools used to detect sentiment from\nthe dataset are Sklearn as well as Mazajak sentiment tool 1. Logistic\nRegression, Random Forest, Naive Bayes (NB), and Support Vector Machines (SVM)\nclassifiers are used with Sklearn, while the Convolutional Neural Network (CNN)\nis implemented with Mazajak. The results show that the traditional classifiers\nscore a higher level of accuracy as compared to Mazajak which is built on an\nalgorithm that includes deep learning techniques. More research is suggested to\nanalyze Arabic sub-dialect poetry in order to investigate the aspects that\ncontribute to sentiments in these multi-line texts; for example, the use of\nfigurative language such as metaphors.",
    "descriptor": "",
    "authors": [
      "Azza Abugharsa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07203"
  },
  {
    "id": "arXiv:2109.07204",
    "title": "Realization of Neural Network-based Optical Channel Equalizer in  Restricted Hardware",
    "abstract": "We quantify the achievable reduction of the processing complexity of\nartificial neural network-based equalizers in a coherent optical channel using\nthe pruning and quantization techniques. First, we explain how to correctly\ncompute the complexity of the compressed equalizer in the DSP sense. Then,\nconsidering a basic neural network architecture, a multiplayer perceptron, we,\nfor the first time, assess the complexity reduction attainable noticeable\nperformance degradation, considering 30GBd 1000km transmission over a standard\nsingle-mode fiber. We demonstrate a possibility of reducing the equalizer's\nmemory by up to 95.7%, and the complexity up to 91.5%, without noticeable\nperformance degradation. Finally, the compressed equalizer's functioning is\ndemonstrated experimentally using popular resource-constrained hardware: the\nRaspberry Pi, which would not have been possible without model compression.",
    "descriptor": "\nComments: Neural network, Nonlinear equalizer, Pruning, Quantization, Raspberry pi, Coherent detection\n",
    "authors": [
      "Diego R. Arguello",
      "Pedro J. Freire",
      "Jaroslaw E. Prilepsky",
      "Antonio Napoli",
      "Morteza Kamalian-Kopae",
      "Sergei K. Turitsyn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07204"
  },
  {
    "id": "arXiv:2109.07205",
    "title": "A Relation-Oriented Clustering Method for Open Relation Extraction",
    "abstract": "The clustering-based unsupervised relation discovery method has gradually\nbecome one of the important methods of open relation extraction (OpenRE).\nHowever, high-dimensional vectors can encode complex linguistic information\nwhich leads to the problem that the derived clusters cannot explicitly align\nwith the relational semantic classes. In this work, we propose a\nrelation-oriented clustering model and use it to identify the novel relations\nin the unlabeled data. Specifically, to enable the model to learn to cluster\nrelational data, our method leverages the readily available labeled data of\npre-defined relations to learn a relation-oriented representation. We minimize\ndistance between the instance with same relation by gathering the instances\ntowards their corresponding relation centroids to form a cluster structure, so\nthat the learned representation is cluster-friendly. To reduce the clustering\nbias on predefined classes, we optimize the model by minimizing a joint\nobjective on both labeled and unlabeled data. Experimental results show that\nour method reduces the error rate by 29.2% and 15.7%, on two datasets\nrespectively, compared with current SOTA methods.",
    "descriptor": "\nComments: 12 pages, 6figures, emnlp2021\n",
    "authors": [
      "Jun Zhao",
      "Tao Gui",
      "Qi Zhang",
      "Yaqian Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07205"
  },
  {
    "id": "arXiv:2109.07206",
    "title": "Signaling Design for Cooperative Resource Allocation and its Impact to  Reliability",
    "abstract": "Decentralized cooperative resource allocation schemes for robotic swarms are\nessential to enable high reliability in high throughput data exchanges. These\ncooperative schemes require control signaling with the aim to avoid half-duplex\nproblems at the receiver and mitigate interference. We propose two cooperative\nresource allocation schemes, device sequential and group scheduling, and\nintroduce a control signaling design. We observe that failure in the reception\nof these control signals leads to non-cooperative behavior and to significant\nperformance degradation. The cause of these failures are identified and\nspecific countermeasures are proposed and evaluated. We compare the proposed\nresource allocation schemes against the NR sidelink mode 2 resource allocation\nand show that even though signaling has an important impact on the resource\nallocation performance, our proposed device sequential and group scheduling\nresource allocation schemes improve reliability by an order of magnitude\ncompared to sidelink mode 2.",
    "descriptor": "",
    "authors": [
      "Rasmus Liborius Bruun",
      "C. Santiago Morej\u00f3n Garc\u00eda",
      "Troels B. S\u00f8rensen",
      "Nuno K. Pratas",
      "Tatiana Kozlova Madsen",
      "Preben Mogensen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.07206"
  },
  {
    "id": "arXiv:2109.07207",
    "title": "Fusing Visuo-Tactile Perception into Kernelized Synergies for Robust  Grasping and Fine Manipulation of Non-rigid Objects",
    "abstract": "Handling non-rigid objects using robot hands necessities a framework that\ndoes not only incorporate human-level dexterity and cognition but also the\nmulti-sensory information and system dynamics for robust and fine interactions.\nIn this research, our previously developed kernelized synergies framework,\ninspired from human behaviour on reusing same subspace for grasping and\nmanipulation, is augmented with visuo-tactile perception for autonomous and\nflexible adaptation to unknown objects. To detect objects and estimate their\nposes, a simplified visual pipeline using RANSAC algorithm with Euclidean\nclustering and SVM classifier is exploited. To modulate interaction efforts\nwhile grasping and manipulating non-rigid objects, the tactile feedback using\nT40S shokac chip sensor, generating 3D force information, is incorporated.\nMoreover, different kernel functions are examined in the kernelized synergies\nframework, to evaluate its performance and potential against task\nreproducibility, execution, generalization and synergistic re-usability.\nExperiments performed with robot arm-hand system validates the capability and\nusability of upgraded framework on stably grasping and dexterously manipulating\nthe non-rigid objects.",
    "descriptor": "\nComments: IEEE ICRA 2022 (under review)\n",
    "authors": [
      "Sunny Katyara",
      "Nikhil Deshpande",
      "Fanny Ficuciello",
      "Fei Chen",
      "Bruno Siciliano",
      "Darwin G. Caldwell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07207"
  },
  {
    "id": "arXiv:2109.07210",
    "title": "Life-Long Multi-Task Learning of Adaptive Path Tracking Policy for  Autonomous Vehicle",
    "abstract": "This paper proposes a life-long adaptive path tracking policy learning method\nfor autonomous vehicles that can self-evolve and self-adapt with multi-task\nknowledge. Firstly, the proposed method can learn a model-free control policy\nfor path tracking directly from the historical driving experience, where the\nproperty of vehicle dynamics and corresponding control strategy can be learned\nsimultaneously. Secondly, by utilizing the life-long learning method, the\nproposed method can learn the policy with task-incremental knowledge without\nencountering catastrophic forgetting. Thus, with continual multi-task knowledge\nlearned, the policy can iteratively adapt to new tasks and improve its\nperformance with knowledge from new tasks. Thirdly, a memory evaluation and\nupdating method is applied to optimize memory structure for life-long learning\nwhich enables the policy to learn toward selected directions. Experiments are\nconducted using a high-fidelity vehicle dynamic model in a complex curvy road\nto evaluate the performance of the proposed method. Results show that the\nproposed method can effectively evolve with continual multi-task knowledge and\nadapt to the new environment, where the performance of the proposed method can\nalso surpass two commonly used baseline methods after evolving.",
    "descriptor": "",
    "authors": [
      "Cheng Gong",
      "Jianwei Gong",
      "Chao Lu",
      "Zhe Liu",
      "Zirui Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07210"
  },
  {
    "id": "arXiv:2109.07212",
    "title": "Optimising Rolling Stock Planning including Maintenance with Constraint  Programming and Quantum Annealing",
    "abstract": "We developed and compared Constraint Programming (CP) and Quantum Annealing\n(QA) approaches for rolling stock optimisation considering necessary\nmaintenance tasks. To deal with such problems in CP we investigated specialised\npruning rules and implemented them in a global constraint. For the QA approach,\nwe developed quadratic unconstrained binary optimisation (QUBO) models. For\ntesting, we use data sets based on real data from Deutsche Bahn and run the QA\napproach on real quantum computers from D-Wave. Classical computers are used to\nrun the CP approach as well as tabu search for the QUBO models. We find that\nboth approaches tend at the current development stage of the physical quantum\nannealers to produce comparable results, with the caveat that QUBO does not\nalways guarantee that the maintenance constraints hold, which we fix by\nadjusting the QUBO model in preprocessing, based on how close the trains are to\na maintenance threshold distance.",
    "descriptor": "",
    "authors": [
      "Cristian Grozea",
      "Ronny Hans",
      "Matthias Koch",
      "Christina Riehn",
      "Armin Wolf"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2109.07212"
  },
  {
    "id": "arXiv:2109.07217",
    "title": "Progressive Hard-case Mining across Pyramid Levels in Object Detection",
    "abstract": "In object detection, multi-level prediction (e.g., FPN, YOLO) and resampling\nskills (e.g., focal loss, ATSS) have drastically improved one-stage detector\nperformance. However, how to improve the performance by optimizing the feature\npyramid level-by-level remains unexplored. We find that, during training, the\nratio of positive over negative samples varies across pyramid levels\n(\\emph{level imbalance}), which is not addressed by current one-stage\ndetectors. To mediate the influence of level imbalance, we propose a Unified\nMulti-level Optimization Paradigm (UMOP) consisting of two components: 1) an\nindependent classification loss supervising each pyramid level with individual\nresampling considerations; 2) a progressive hard-case mining loss defining all\nlosses across the pyramid levels without extra level-wise settings. With UMOP\nas a plug-and-play scheme, modern one-stage detectors can attain a ~1.5 AP\nimprovement with fewer training iterations and no additional computation\noverhead. Our best model achieves 55.1 AP on COCO test-dev. Code is available\nat https://github.com/zimoqingfeng/UMOP.",
    "descriptor": "",
    "authors": [
      "Binghong Wu",
      "Yehui Yang",
      "Dalu Yang",
      "Junde Wu",
      "Haifeng Huang",
      "Lei Wang",
      "Junwei Liu",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07217"
  },
  {
    "id": "arXiv:2109.07218",
    "title": "Limitations of the Invertible-Map Equivalences",
    "abstract": "This note draws conclusions that arise by combining two recent papers, by\nAnuj Dawar, Erich Gr\\\"adel, and Wied Pakusa, published at ICALP 2019 and by\nMoritz Lichter, published at LICS 2021. In both papers, the main technical\nresults rely on the combinatorial and algebraic analysis of the invertible-map\nequivalences $\\equiv^\\text{IM}_{k,Q}$ on certain variants of\nCai-F\\\"urer-Immerman (CFI) structures. These\n$\\equiv^\\text{IM}_{k,Q}$-equivalences, for a natural number $k$ and a set of\nprimes $Q$, refine the well-known Weisfeiler-Leman equivalences used in\nalgorithms for graph isomorphism. The intuition is that two graphs $G\n\\equiv^\\text{IM}_{k,Q} H$ cannot be distinguished by iterative refinements of\nequivalences on $k$-tuples defined via linear operators on vector spaces over\nfields of characteristic $p \\in Q$.\nIn the first paper it has been shown that for a prime $q \\notin Q$, the\n$\\equiv^\\text{IM}_{k,Q}$ equivalences are not strong enough to distinguish\nbetween non-isomorphic CFI-structures over the field $\\mathbb{F}_q$. In the\nsecond paper, a similar but not identical construction for CFI-structures over\nthe rings $\\mathbb{Z}_{2^i}$ has been shown to be indistinguishable with\nrespect to $\\equiv^\\text{IM}_{k,\\{2\\}}$. Together with earlier work on rank\nlogic, this second result suffices to separate rank logic from polynomial time.\nWe show here that the two approaches can be unified to prove that\nCFI-structures over the rings $\\mathbb{Z}_{2^i}$ are indistinguishable with\nrespect to $\\equiv^\\text{IM}_{k,\\mathbb{P}}$, for the set $\\mathbb{P}$ of all\nprimes. This implies the following two results.\n1. There is no fixed $k$ such that the invertible-map equivalence\n$\\equiv^\\text{IM}_{k,\\mathbb{P}}$ coincides with isomorphism on all finite\ngraphs.\n2. No extension of fixed-point logic by linear-algebraic operators over\nfields can capture polynomial time.",
    "descriptor": "",
    "authors": [
      "Anuj Dawar",
      "Erich Gr\u00e4del",
      "Moritz Lichter"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.07218"
  },
  {
    "id": "arXiv:2109.07222",
    "title": "{E}fficient{BERT}: Progressively Searching Multilayer Perceptron via  Warm-up Knowledge Distillation",
    "abstract": "Pre-trained language models have shown remarkable results on various NLP\ntasks. Nevertheless, due to their bulky size and slow inference speed, it is\nhard to deploy them on edge devices. In this paper, we have a critical insight\nthat improving the feed-forward network (FFN) in BERT has a higher gain than\nimproving the multi-head attention (MHA) since the computational cost of FFN is\n2$\\sim$3 times larger than MHA. Hence, to compact BERT, we are devoted to\ndesigning efficient FFN as opposed to previous works that pay attention to MHA.\nSince FFN comprises a multilayer perceptron (MLP) that is essential in BERT\noptimization, we further design a thorough search space towards an advanced MLP\nand perform a coarse-to-fine mechanism to search for an efficient BERT\narchitecture. Moreover, to accelerate searching and enhance model\ntransferability, we employ a novel warm-up knowledge distillation strategy at\neach search stage. Extensive experiments show our searched EfficientBERT is\n6.9$\\times$ smaller and 4.4$\\times$ faster than BERT$\\rm_{BASE}$, and has\ncompetitive performances on GLUE and SQuAD Benchmarks. Concretely,\nEfficientBERT attains a 77.7 average score on GLUE \\emph{test}, 0.7 higher than\nMobileBERT$\\rm_{TINY}$, and achieves an 85.3/74.5 F1 score on SQuAD v1.1/v2.0\n\\emph{dev}, 3.2/2.7 higher than TinyBERT$_4$ even without data augmentation.\nThe code is released at https://github.com/cheneydon/efficient-bert.",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Chenhe Dong",
      "Guangrun Wang",
      "Hang Xu",
      "Jiefeng Peng",
      "Xiaozhe Ren",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07222"
  },
  {
    "id": "arXiv:2109.07227",
    "title": "How Much do Lyrics Matter? Analysing Lyrical Simplicity Preferences for  Individuals At Risk of Depression",
    "abstract": "Music affects and in some cases reflects one's emotional state. Key to this\ninfluence is lyrics and their meaning in conjunction with the acoustic\nproperties of the track. Recent work has focused on analysing these acoustic\nproperties and showing that individuals prone to depression primarily consume\nlow valence and low energy music. However, no studies yet have explored lyrical\ncontent preferences in relation to online music consumption of such\nindividuals. In the current study, we examine lyrical simplicity, measured as\nthe Compressibility and Absolute Information Content of the text, associated\nwith preferences of individuals at risk for depression. Using the six-month\nlistening history of 541 Last.fm users, we compare lyrical simplicity trends\nfor users grouped as being at risk (At-Risk) of depression from those that are\nnot (No-Risk). Our findings reveal that At-Risk individuals prefer songs with\ngreater information content (lower Compressibility) on average, especially for\nsongs characterised as Sad. Furthermore, we found that At-Risk individuals also\nhave greater variability of Absolute Information Content across their listening\nhistory. We discuss the results in light of existing socio-psychological\nlab-based research on music habits associated with depression and their\nrelevance to naturally occurring online music listening behaviour.",
    "descriptor": "\nComments: In Proceedings of the Speech, Music and Mind Workshop 2021, a satellite workshop of INTERSPEECH 2021\n",
    "authors": [
      "Jaidev Shriram",
      "Sreeharsha Paruchuri",
      "Vinoo Alluri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07227"
  },
  {
    "id": "arXiv:2109.07228",
    "title": "Dialog speech sentiment classification for imbalanced datasets",
    "abstract": "Speech is the most common way humans express their feelings, and sentiment\nanalysis is the use of tools such as natural language processing and\ncomputational algorithms to identify the polarity of these feelings. Even\nthough this field has seen tremendous advancements in the last two decades, the\ntask of effectively detecting under represented sentiments in different kinds\nof datasets is still a challenging task. In this paper, we use single and\nbi-modal analysis of short dialog utterances and gain insights on the main\nfactors that aid in sentiment detection, particularly in the underrepresented\nclasses, in datasets with and without inherent sentiment component.\nFurthermore, we propose an architecture which uses a learning rate scheduler\nand different monitoring criteria and provides state-of-the-art results for the\nSWITCHBOARD imbalanced sentiment dataset.",
    "descriptor": "\nComments: To be published in SPECOM & ICR 2021 Electronic Proceedings by the Springer Nature\n",
    "authors": [
      "Sergis Nicolaou",
      "Lambros Mavrides",
      "Georgina Tryfou",
      "Kyriakos Tolias",
      "Konstantinos Panousis",
      "Sotirios Chatzis",
      "Sergios Theodoridis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07228"
  },
  {
    "id": "arXiv:2109.07230",
    "title": "Learning Mathematical Properties of Integers",
    "abstract": "Embedding words in high-dimensional vector spaces has proven valuable in many\nnatural language applications. In this work, we investigate whether\nsimilarly-trained embeddings of integers can capture concepts that are useful\nfor mathematical applications. We probe the integer embeddings for mathematical\nknowledge, apply them to a set of numerical reasoning tasks, and show that by\nlearning the representations from mathematical sequence data, we can\nsubstantially improve over number embeddings learned from English text corpora.",
    "descriptor": "\nComments: BlackboxNLP 2021\n",
    "authors": [
      "Maria Ryskina",
      "Kevin Knight"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07230"
  },
  {
    "id": "arXiv:2109.07231",
    "title": "SWEAT: Scoring Polarization of Topics across Different Corpora",
    "abstract": "Understanding differences of viewpoints across corpora is a fundamental task\nfor computational social sciences. In this paper, we propose the Sliced Word\nEmbedding Association Test (SWEAT), a novel statistical measure to compute the\nrelative polarization of a topical wordset across two distributional\nrepresentations. To this end, SWEAT uses two additional wordsets, deemed to\nhave opposite valence, to represent two different poles. We validate our\napproach and illustrate a case study to show the usefulness of the introduced\nmeasure.",
    "descriptor": "\nComments: Published as a conference paper at EMNLP2021\n",
    "authors": [
      "Federico Bianchi",
      "Marco Marelli",
      "Paolo Nicoli",
      "Matteo Palmonari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07231"
  },
  {
    "id": "arXiv:2109.07234",
    "title": "The Unreasonable Effectiveness of the Baseline: Discussing SVMs in Legal  Text Classification",
    "abstract": "We aim to highlight an interesting trend to contribute to the ongoing debate\naround advances within legal Natural Language Processing. Recently, the focus\nfor most legal text classification tasks has shifted towards large pre-trained\ndeep learning models such as BERT. In this paper, we show that a more\ntraditional approach based on Support Vector Machine classifiers reaches\ncompetitive performance with deep learning models. We also highlight that error\nreduction obtained by using specialised BERT-based models over baselines is\nnoticeably smaller in the legal domain when compared to general language tasks.\nWe discuss some hypotheses for these results to support future discussions.",
    "descriptor": "",
    "authors": [
      "Benjamin Clavi\u00e9",
      "Marc Alphonsus"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07234"
  },
  {
    "id": "arXiv:2109.07236",
    "title": "Recursive Hierarchical Projection for Whole-Body Control with Task  Priority Transition",
    "abstract": "Redundant robots are desired to execute multitasks with different priorities\nsimultaneously. The task priorities are necessary to be transitioned for\ncomplex task scheduling of whole-body control (WBC). Many methods focused on\nguaranteeing the control continuity during task priority transition, however\neither increased the computation consumption or sacrificed the accuracy of\ntasks inevitably. This work formulates the WBC problem with task priority\ntransition as an Hierarchical Quadratic Programming (HQP) with Recursive\nHierarchical Projection (RHP) matrices. The tasks of each level are solved\nrecursively through HQP. We propose the RHP matrix to form the continuously\nchanging projection of each level so that the task priority transition is\nachieved without increasing computation consumption. Additionally, the\nrecursive approach solves the WBC problem without losing the accuracy of tasks.\nWe verify the effectiveness of this scheme by the comparative simulations of\nthe reactive collision avoidance through multi-tasks priority transitions.",
    "descriptor": "\nComments: 6 pages, 9 figures, submitted to ICRA 2022\n",
    "authors": [
      "Gang Han",
      "Jiajun Wang",
      "Xiaozhu Ju",
      "Mingguo Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07236"
  },
  {
    "id": "arXiv:2109.07239",
    "title": "Internet of Behavior (IoB) and Explainable AI Systems for Influencing  IoT Behavior",
    "abstract": "Pandemics and natural disasters over the years have changed the behavior of\npeople, which has had a tremendous impact on all life aspects. With the\ntechnologies available in each era, governments, organizations, and companies\nhave used these technologies to track, control, and influence the behavior of\nindividuals for a benefit. Nowadays, the use of the Internet of Things (IoT),\ncloud computing, and artificial intelligence (AI) have made it easier to track\nand change the behavior of users through changing IoT behavior. This article\nintroduces and discusses the concept of the Internet of Behavior (IoB) and its\nintegration with Explainable AI (XAI) techniques to provide trusted and evident\nexperience in the process of changing IoT behavior to ultimately improving\nusers' behavior. Therefore, a system based on IoB and XAI has been proposed in\na use case scenario of electrical power consumption that aims to influence user\nconsuming behavior to reduce power consumption and cost. The scenario results\nshowed a decrease of 522.2 kW of active power when compared to original\nconsumption over a 200-hours period. It also showed a total power cost saving\nof 95.04 Euro for the same period. Moreover, decreasing the global active power\nwill reduce the power intensity through the positive correlation.",
    "descriptor": "\nComments: Submitted to IEEE Network\n",
    "authors": [
      "Haya Elayan",
      "Moayad Aloqaily",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07239"
  },
  {
    "id": "arXiv:2109.07242",
    "title": "Regressive Ensemble for Machine Translation Quality Evaluation",
    "abstract": "This work introduces a simple regressive ensemble for evaluating machine\ntranslation quality based on a set of novel and established metrics. We\nevaluate the ensemble using a correlation to expert-based MQM scores of the WMT\n2021 Metrics workshop. In both monolingual and zero-shot cross-lingual\nsettings, we show a significant performance improvement over single metrics. In\nthe cross-lingual settings, we also demonstrate that an ensemble approach is\nwell-applicable to unseen languages. Furthermore, we identify a strong\nreference-free baseline that consistently outperforms the commonly-used BLEU\nand METEOR measures and significantly improves our ensemble's performance.",
    "descriptor": "\nComments: 8 pages incl. references, Proceedings of EMNLP 2021 Sixth Conference on Machine Translation (WMT 21)\n",
    "authors": [
      "Michal \u0160tef\u00e1nik",
      "V\u00edt Novotn\u00fd",
      "Petr Sojka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07242"
  },
  {
    "id": "arXiv:2109.07243",
    "title": "Enhancing Clinical Information Extraction with Transferred Contextual  Embeddings",
    "abstract": "The Bidirectional Encoder Representations from Transformers (BERT) model has\nachieved the state-of-the-art performance for many natural language processing\n(NLP) tasks. Yet, limited research has been contributed to studying its\neffectiveness when the target domain is shifted from the pre-training corpora,\nfor example, for biomedical or clinical NLP applications. In this paper, we\napplied it to a widely studied a hospital information extraction (IE) task and\nanalyzed its performance under the transfer learning setting. Our application\nbecame the new state-of-the-art result by a clear margin, compared with a range\nof existing IE models. Specifically, on this nursing handover data set, the\nmacro-average F1 score from our model was 0.438, whilst the previous best deep\nlearning models had 0.416. In conclusion, we showed that BERT based\npre-training models can be transferred to health-related documents under mild\nconditions and with a proper fine-tuning process.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Zimin Wan",
      "Chenchen Xu",
      "Hanna Suominen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07243"
  },
  {
    "id": "arXiv:2109.07245",
    "title": "Navigation-Oriented Scene Understanding for Robotic Autonomy: Learning  to Segment Driveability in Egocentric Images",
    "abstract": "This work tackles scene understanding for outdoor robotic navigation, solely\nrelying on images captured by an on-board camera. Conventional visual scene\nunderstanding interprets the environment based on specific descriptive\ncategories. However, such a representation is not directly interpretable for\ndecision-making and constrains robot operation to a specific domain. Thus, we\npropose to segment egocentric images directly in terms of how a robot can\nnavigate in them, and tailor the learning problem to an autonomous navigation\ntask. Building around an image segmentation network, we present a generic and\nscalable affordance-based definition consisting of 3 driveability levels which\ncan be applied to arbitrary scenes. By encoding these levels with soft ordinal\nlabels, we incorporate inter-class distances during learning which improves\nsegmentation compared to standard one-hot labelling. In addition, we propose a\nnavigation-oriented pixel-wise loss weighting method which assigns higher\nimportance to safety-critical areas. We evaluate our approach on large-scale\npublic image segmentation datasets spanning off-road and urban scenes. In a\nzero-shot cross-dataset generalization experiment, we show that our affordance\nlearning scheme can be applied across a diverse mix of datasets and improves\ndriveability estimation in unseen environments compared to general-purpose,\nsingle-dataset segmentation.",
    "descriptor": "\nComments: Submitted to Robotics and Automation Letters. Supplementary video available at this https URL\n",
    "authors": [
      "Galadrielle Humblot-Renaux",
      "Letizia Marchegiani",
      "Thomas B. Moeslund",
      "Rikke Gade"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07245"
  },
  {
    "id": "arXiv:2109.07246",
    "title": "RGB-D Saliency Detection via Cascaded Mutual Information Minimization",
    "abstract": "Existing RGB-D saliency detection models do not explicitly encourage RGB and\ndepth to achieve effective multi-modal learning. In this paper, we introduce a\nnovel multi-stage cascaded learning framework via mutual information\nminimization to \"explicitly\" model the multi-modal information between RGB\nimage and depth data. Specifically, we first map the feature of each mode to a\nlower dimensional feature vector, and adopt mutual information minimization as\na regularizer to reduce the redundancy between appearance features from RGB and\ngeometric features from depth. We then perform multi-stage cascaded learning to\nimpose the mutual information minimization constraint at every stage of the\nnetwork. Extensive experiments on benchmark RGB-D saliency datasets illustrate\nthe effectiveness of our framework. Further, to prosper the development of this\nfield, we contribute the largest (7x larger than NJU2K) dataset, which contains\n15,625 image pairs with high quality\npolygon-/scribble-/object-/instance-/rank-level annotations. Based on these\nrich labels, we additionally construct four new benchmarks with strong\nbaselines and observe some interesting phenomena, which can motivate future\nmodel design. Source code and dataset are available at\n\"https://github.com/JingZhang617/cascaded_rgbd_sod\".",
    "descriptor": "\nComments: Accepted as ICCV2021 paper\n",
    "authors": [
      "Jing Zhang",
      "Deng-Ping Fan",
      "Yuchao Dai",
      "Xin Yu",
      "Yiran Zhong",
      "Nick Barnes",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07246"
  },
  {
    "id": "arXiv:2109.07247",
    "title": "Towards Precise Pruning Points Detection using Semantic-Instance-Aware  Plant Models for Grapevine Winter Pruning Automation",
    "abstract": "Grapevine winter pruning is a complex task, that requires skilled workers to\nexecute it correctly. The complexity makes it time consuming. It is an\noperation that requires about 80-120 hours per hectare annually, making an\nautomated robotic system that helps in speeding up the process a crucial tool\nin large-size vineyards. We will describe (a) a novel expert annotated dataset\nfor grapevine segmentation, (b) a state of the art neural network\nimplementation and (c) generation of pruning points following agronomic rules,\nleveraging the simplified structure of the plant. With this approach, we are\nable to generate a set of pruning points on the canes, paving the way towards a\ncorrect automation of grapevine winter pruning.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.04208\n",
    "authors": [
      "Miguel Fernandes",
      "Antonello Scaldaferri",
      "Paolo Guadagna",
      "Giuseppe Fiameni",
      "Tao Teng",
      "Matteo Gatti",
      "Stefano Poni",
      "Claudio Semini",
      "Darwin Caldwell",
      "Fei Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07247"
  },
  {
    "id": "arXiv:2109.07249",
    "title": "Temporal Parameter-free Deep Skinning of Animated Meshes",
    "abstract": "In computer graphics, animation compression is essential for efficient\nstorage, streaming and reproduction of animated meshes. Previous work has\npresented efficient techniques for compression by deriving skinning\ntransformations and weights using clustering of vertices based on geometric\nfeatures of vertices over time. In this work we present a novel approach that\nassigns vertices to bone-influenced clusters and derives weights using deep\nlearning through a training set that consists of pairs of vertex trajectories\n(temporal vertex sequences) and the corresponding weights drawn from fully\nrigged animated characters. The approximation error of the resulting linear\nblend skinning scheme is significantly lower than the error of competent\nprevious methods by producing at the same time a minimal number of bones.\nFurthermore, the optimal set of transformation and vertices is derived in fewer\niterations due to the better initial positioning in the multidimensional\nvariable space. Our method requires no parameters to be determined or tuned by\nthe user during the entire process of compressing a mesh animation sequence.",
    "descriptor": "\nComments: CGI 2021, LNCS Proceedings, to appear. For video and presentation and other info please see this http URL\n",
    "authors": [
      "Anastasia Moutafidou",
      "Vasileios Toulatzis",
      "Ioannis Fudos"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07249"
  },
  {
    "id": "arXiv:2109.07251",
    "title": "Towards a new approach of continuous process improvement based on CMMI  and PMBOK",
    "abstract": "A process-centric approach helps an organization to improve the way it works\nwith. It allows scalability and provides a way to capitalize knowledge on best\npractices. It also makes better use of resources and helps to understand\ntrends. PMBOK is a project management methodology, while CMMI is a model for\nprocess improvement. In this paper, we conduct a study on PMBOK and CMMI\nframeworks to show that they can be converged and complementary. We expect this\npaper research will be useful for organizations to deploy a new approach of\ncontinuous process improvement based on pooling CMMI and PMBOK.",
    "descriptor": "",
    "authors": [
      "Yassine Rdiouat",
      "Naima Nakabi",
      "Khadija Kahtani",
      "Alami Semma"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.07251"
  },
  {
    "id": "arXiv:2109.07252",
    "title": "Modeling Ice Friction for Vehicle Dynamics of a Bobsled with Application  in Driver Evaluation and Driving Simulation",
    "abstract": "We provide an ice friction model for vehicle dynamics of a two-man bobsled\nwhich can be used for driver evaluation and in a driver-in-the-loop simulator.\nLongitudinal friction is modeled by combining experimental results with finite\nelement simulations to yield a correlation between contact pressure and\nfriction. To model lateral friction, we collect data from 44 bobsleigh runs\nusing special sensors. Non-linear regression is used to fit a bob-specific\none-track vehicle dynamics model to the data. It is applied in driving\nsimulation and enables a novel method for bob driver evaluation. Bob drivers\nwith various levels of experience are investigated. It shows that a similar\nperformance of the top drivers results from different driving styles.",
    "descriptor": "\nComments: Preprint submitted to Tribology International\n",
    "authors": [
      "Julian von Schleinitz",
      "Lukas W\u00f6rle",
      "Michael Graf",
      "Andreas Schr\u00f6der"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07252"
  },
  {
    "id": "arXiv:2109.07253",
    "title": "Integrating Sensing and Communication in Cellular Networks via NR  Sidelink",
    "abstract": "RF-sensing, the analysis and interpretation of movement or\nenvironment-induced patterns in received electromagnetic signals, has been\nactively investigated for more than a decade. Since electromagnetic signals,\nthrough cellular communication systems, are omnipresent, RF sensing has the\npotential to become a universal sensing mechanism with applications in smart\nhome, retail, localization, gesture recognition, intrusion detection, etc.\nSpecifically, existing cellular network installations might be dual-used for\nboth communication and sensing. Such communications and sensing convergence is\nenvisioned for future communication networks. We propose the use of NR-sidelink\ndirect device-to-device communication to achieve device-initiated,flexible\nsensing capabilities in beyond 5G cellular communication systems. In this\narticle, we specifically investigate a common issue related to sidelink-based\nRF-sensing, which is its angle and rotation dependence. In particular, we\ndiscuss transformations of mmWave point-cloud data which achieve rotational\ninvariance, as well as distributed processing based on such rotational\ninvariant inputs, at angle and distance diverse devices. To process the\ndistributed data, we propose a graph based encoder to capture spatio-temporal\nfeatures of the data and propose four approaches for multi-angle learning. The\napproaches are compared on a newly recorded and openly available dataset\ncomprising 15 subjects, performing 21 gestures which are recorded from 8\nangles.",
    "descriptor": "\nComments: The paper is submitted to JSAC and it is still under review\n",
    "authors": [
      "Dariush Salami",
      "Ramin Hasibi",
      "Stefano Savazzi",
      "Tom Michoel",
      "Stephan Sigg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07253"
  },
  {
    "id": "arXiv:2109.07255",
    "title": "Learning What Others Know",
    "abstract": "We propose a number of powerful dynamic-epistemic logics for multi-agent\ninformation sharing and acts of publicly or privately accessing other agents'\ninformation databases. The static base of our logics is obtained by adding to\nstandard epistemic logic comparative epistemic assertions, that can express\nepistemic superiority between groups or individuals, as well as a common\ndistributed knowledge operator (that combines features of both common knowledge\nand distributed knowledge). On the dynamic side, we introduce actions by which\nepistemic superiority can be acquired: \"sharing all one knows\" (by e.g. giving\naccess to one's information database to all or some of the other agents), as\nwell as more complex informational events, such as hacking. We completely\naxiomatize several such logics and prove their decidability.",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Alexandru Baltag",
      "Sonja Smets"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.07255"
  },
  {
    "id": "arXiv:2109.07258",
    "title": "Federated Learning of Molecular Properties in a Heterogeneous Setting",
    "abstract": "Chemistry research has both high material and computational costs to conduct\nexperiments. Institutions thus consider chemical data to be valuable and there\nhave been few efforts to construct large public datasets for machine learning.\nAnother challenge is that different intuitions are interested in different\nclasses of molecules, creating heterogeneous data that cannot be easily joined\nby conventional distributed training. In this work, we introduce federated\nheterogeneous molecular learning to address these challenges. Federated\nlearning allows end-users to build a global model collaboratively while\npreserving the training data distributed over isolated clients. Due to the lack\nof related research, we first simulate a federated heterogeneous benchmark\ncalled FedChem. FedChem is constructed by jointly performing scaffold splitting\nand Latent Dirichlet Allocation on existing datasets. Our results on FedChem\nshow that significant learning challenges arise when working with heterogeneous\nmolecules. We then propose a method to alleviate the problem, namely Federated\nLearning by Instance reweighTing (FLIT). FLIT can align the local training\nacross heterogeneous clients by improving the performance for uncertain\nsamples. Comprehensive experiments conducted on our new benchmark FedChem\nvalidate the advantages of this method over other federated learning schemes.\nFedChem should enable a new type of collaboration for improving AI in chemistry\nthat mitigates concerns about valuable chemical data.",
    "descriptor": "",
    "authors": [
      "Wei Zhu",
      "Andrew White",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.07258"
  },
  {
    "id": "arXiv:2109.07260",
    "title": "Evaluation of Distributed Databases in Hybrid Clouds and Edge Computing:  Energy, Bandwidth, and Storage Consumption",
    "abstract": "A benchmark study of modern distributed databases is an important source of\ninformation to select the right technology for managing data in the cloud-edge\nparadigms. To make the right decision, it is required to conduct an extensive\nexperimental study on a variety of hardware infrastructures. While most of the\nstate-of-the-art studies have investigated only response time and scalability\nof distributed databases, focusing on other various metrics (e.g., energy,\nbandwidth, and storage consumption) is essential to fully understand the\nresources consumption of the distributed databases. Also, existing studies have\nexplored the response time and scalability of these databases either in private\nor public cloud. Hence, there is a paucity of investigation into the evaluation\nof these databases deployed in a hybrid cloud, which is the seamless\nintegration of public and private cloud. To address these research gaps, in\nthis paper, we investigate energy, bandwidth and storage consumption of the\nmost used and common distributed databases. For this purpose, we have evaluated\nfour open-source databases (Cassandra, Mongo, Redis and MySQL) on the hybrid\ncloud spanning over local OpenStack and Microsoft Azure, and a variety of edge\ncomputing nodes including Raspberry Pi, a cluster of Raspberry Pi, and low and\nhigh power servers. Our extensive experimental results reveal several helpful\ninsights for the deployment selection of modern distributed databases in\nedge-cloud environments.",
    "descriptor": "",
    "authors": [
      "Yaser Mansouri",
      "Victor Prokhorenko",
      "Faheem Ullah",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.07260"
  },
  {
    "id": "arXiv:2109.07262",
    "title": "Linear-Time Contact and Friction Dynamics in Maximal Coordinates using  Variational Integrators",
    "abstract": "Simulation of contact and friction dynamics is an important basis for\ncontrol- and learning-based algorithms. However, the numerical difficulties of\ncontact interactions pose a challenge for robust and efficient simulators. A\nmaximal-coordinate representation of the dynamics enables efficient solving\nalgorithms, but current methods in maximal coordinates require constraint\nstabilization schemes. Therefore, we propose an interior-point algorithm for\nthe numerically robust treatment of rigid-body dynamics with contact\ninteractions in maximal coordinates. Additionally, we discretize the dynamics\nwith a variational integrator to prevent constraint drift. Our algorithm\nachieves linear-time complexity both in the number of contact points and the\nnumber of bodies, which is shown theoretically and demonstrated with an\nimplementation. Furthermore, we simulate two robotic systems to highlight the\napplicability of the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Jan Br\u00fcdigam",
      "Jana Janeva",
      "Stefan Sosnowski",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07262"
  },
  {
    "id": "arXiv:2109.07263",
    "title": "End-to-End Learning of Flowchart Grounded Task-Oriented Dialogs",
    "abstract": "We propose a novel problem within end-to-end learning of task-oriented\ndialogs (TOD), in which the dialog system mimics a troubleshooting agent who\nhelps a user by diagnosing their problem (e.g., car not starting). Such dialogs\nare grounded in domain-specific flowcharts, which the agent is supposed to\nfollow during the conversation. Our task exposes novel technical challenges for\nneural TOD, such as grounding an utterance to the flowchart without explicit\nannotation, referring to additional manual pages when user asks a clarification\nquestion, and ability to follow unseen flowcharts at test time. We release a\ndataset (FloDial) consisting of 2,738 dialogs grounded on 12 different\ntroubleshooting flowcharts. We also design a neural model, FloNet, which uses a\nretrieval-augmented generation architecture to train the dialog agent. Our\nexperiments find that FloNet can do zero-shot transfer to unseen flowcharts,\nand sets a strong baseline for future research.",
    "descriptor": "\nComments: D. Raghu and S.Agarwal contributed equally to this work\n",
    "authors": [
      "Dinesh Raghu",
      "Shantanu Agarwal",
      "Sachindra Joshi",
      "Mausam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07263"
  },
  {
    "id": "arXiv:2109.07264",
    "title": "Scope resolution of predicted negation cues: A two-step neural  network-based approach",
    "abstract": "Neural network-based methods are the state of the art in negation scope\nresolution. However, they often use the unrealistic assumption that cue\ninformation is completely accurate. Even if this assumption holds, there\nremains a dependency on engineered features from state-of-the-art machine\nlearning methods. The current study adopted a two-step negation resolving\napporach to assess whether a Bidirectional Long Short-Term Memory-based method\ncan be used for cue detection as well, and how inaccurate cue predictions would\naffect the scope resolution performance. Results suggest that this method is\nnot suitable for negation detection. Scope resolution performance is most\nrobust against inaccurate information for models with a recurrent layer only,\ncompared to extensions with a Conditional Random Fields layer or a\npost-processing algorithm. We advocate for more research into the application\nof deep learning on negation detection and the effect of imperfect information\non scope resolution.",
    "descriptor": "",
    "authors": [
      "Daan de Jong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07264"
  },
  {
    "id": "arXiv:2109.07266",
    "title": "Modelling Major Disease Outbreaks in the 21st Century: A Causal Approach",
    "abstract": "Epidemiologists aiming to model the dynamics of global events face a\nsignificant challenge in identifying the factors linked with anomalies such as\ndisease outbreaks. In this paper, we present a novel method for identifying the\nmost important development sectors sensitive to disease outbreaks by using\nglobal development indicators as markers. We use statistical methods to assess\nthe causative linkages between these indicators and disease outbreaks, as well\nas to find the most often ranked indicators. We used data imputation techniques\nin addition to statistical analysis to convert raw real-world data sets into\nmeaningful data for causal inference. The application of various algorithms for\nthe detection of causal linkages between the indicators is the subject of this\nresearch. Despite the fact that disparities in governmental policies between\ncountries account for differences in causal linkages, several indicators emerge\nas important determinants sensitive to disease outbreaks over the world in the\n21st Century.",
    "descriptor": "\nComments: Accepted at Special Interest Group on Knowledge Discovery and Data Mining (SIGKDD-epiDAMIK) 2021: The 4th International Workshop on Epidemiology meets Data Mining and Knowledge discovery\n",
    "authors": [
      "Abli Marathe",
      "Saloni Parekh",
      "Harsh Sakhrani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.07266"
  },
  {
    "id": "arXiv:2109.07267",
    "title": "JUBILEE: Secure Debt Relief and Forgiveness",
    "abstract": "JUBILEE is a securely computed mechanism for debt relief and forgiveness in a\nfrictionless manner without involving trusted third parties, leading to more\nharmonious debt settlements by incentivising the parties to truthfully reveal\ntheir private information. JUBILEE improves over all previous methods:\n- individually rational, incentive-compatible, truthful/strategy-proof,\nex-post efficient, optimal mechanism for debt relief and forgiveness with\nprivate information\n- by the novel introduction of secure computation techniques to debt relief,\nthe \"blessing of the debtor\" is hereby granted for the first time: debt\nsettlements with higher expected profits and a higher probability of success\nthan without using secure computation\nA simple and practical implementation is included for \"The Secure\nSpreadsheet\". Another implementation is realised using Raziel smart contracts\non a blockchain with Pravuil consensus.",
    "descriptor": "",
    "authors": [
      "David Cerezo S\u00e1nchez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2109.07267"
  },
  {
    "id": "arXiv:2109.07269",
    "title": "Random Sampling Plus Fake Data: Multidimensional Frequency Estimates  With Local Differential Privacy",
    "abstract": "With local differential privacy (LDP), users can privatize their data and\nthus guarantee privacy properties before transmitting it to the server (a.k.a.\nthe aggregator). One primary objective of LDP is frequency (or histogram)\nestimation, in which the aggregator estimates the number of users for each\npossible value. In practice, when a study with rich content on a population is\ndesired, the interest is in the multiple attributes of the population, that is\nto say, in multidimensional data ($d \\geq 2$). However, contrary to the problem\nof frequency estimation of a single attribute (the majority of the works), the\nmultidimensional aspect imposes to pay particular attention to the privacy\nbudget. This one can indeed grow extremely quickly due to the composition\ntheorem. To the authors' knowledge, two solutions seem to stand out for this\ntask: 1) splitting the privacy budget for each attribute, i.e., send each value\nwith $\\frac{\\epsilon}{d}$-LDP (Spl), and 2) random sampling a single attribute\nand spend all the privacy budget to send it with $\\epsilon$-LDP (Smp). Although\nSmp adds additional sampling error, it has proven to provide higher data\nutility than the former Spl solution. However, we argue that aggregators (who\nare also seen as attackers) are aware of the sampled attribute and its LDP\nvalue, which is protected by a \"less strict\" $e^{\\epsilon}$ probability bound\n(rather than $e^{\\epsilon/d}$). This way, we propose a solution named Random\nSampling plus Fake Data (RS+FD), which allows creating uncertainty over the\nsampled attribute by generating fake data for each non-sampled attribute; RS+FD\nfurther benefits from amplification by sampling. We theoretically and\nexperimentally validate our proposed solution on both synthetic and real-world\ndatasets to show that RS+FD achieves nearly the same or better utility than the\nstate-of-the-art Smp solution.",
    "descriptor": "",
    "authors": [
      "H\u00e9ber H. Arcolezi",
      "Jean-Fran\u00e7ois Couchot",
      "Bechara Al Bouna",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.07269"
  },
  {
    "id": "arXiv:2109.07270",
    "title": "Distract Your Attention: Multi-head Cross Attention Network for Facial  Expression Recognition",
    "abstract": "We present a novel facial expression recognition network, called Distract\nyour Attention Network (DAN). Our method is based on two key observations.\nFirstly, multiple classes share inherently similar underlying facial\nappearance, and their differences could be subtle. Secondly, facial expressions\nexhibit themselves through multiple facial regions simultaneously, and the\nrecognition requires a holistic approach by encoding high-order interactions\namong local features. To address these issues, we propose our DAN with three\nkey components: Feature Clustering Network (FCN), Multi-head cross Attention\nNetwork (MAN), and Attention Fusion Network (AFN). The FCN extracts robust\nfeatures by adopting a large-margin learning objective to maximize class\nseparability. In addition, the MAN instantiates a number of attention heads to\nsimultaneously attend to multiple facial areas and build attention maps on\nthese regions. Further, the AFN distracts these attentions to multiple\nlocations before fusing the attention maps to a comprehensive one. Extensive\nexperiments on three public datasets (including AffectNet, RAF-DB, and SFEW\n2.0) verified that the proposed method consistently achieves state-of-the-art\nfacial expression recognition performance. Code will be made available at\nhttps://github.com/yaoing/DAN.",
    "descriptor": "",
    "authors": [
      "Zhengyao Wen",
      "Wenzhong Lin",
      "Tao Wang",
      "Ge Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07270"
  },
  {
    "id": "arXiv:2109.07273",
    "title": "NBcoded: network attack classifiers based on Encoder and Naive Bayes  model for resource limited devices",
    "abstract": "In the recent years, cybersecurity has gained high relevance, converting the\ndetection of attacks or intrusions into a key task. In fact, a small breach in\na system, application, or network, can cause huge damage for the companies.\nHowever, when this attack detection encounters the Artificial Intelligence\nparadigm, it can be addressed using high-quality classifiers which often need\nhigh resource demands in terms of computation or memory usage. This situation\nhas a high impact when the attack classifiers need to be used with limited\nresourced devices or without overloading the performance of the devices, as it\nhappens for example in IoT devices, or in industrial systems. For overcoming\nthis issue, NBcoded, a novel light attack classification tool is proposed in\nthis work. NBcoded works in a pipeline combining the removal of noisy data\nproperties of the encoders with the low resources and timing consuming obtained\nby the Naive Bayes classifier. This work compares three different NBcoded\nimplementations based on three different Naive Bayes likelihood distribution\nassumptions (Gaussian, Complement and Bernoulli). Then, the best NBcoded is\ncompared with state of the art classifiers like Multilayer Perceptron and\nRandom Forest. Our implementation shows to be the best model reducing the\nimpact of training time and disk usage, even if it is outperformed by the other\ntwo in terms of Accuracy and F1-score (~ 2%).",
    "descriptor": "\nComments: It will be published in \"Communications in Computer and Information Science\" and presented in the 3rd Workshop of Machine Learning for Cybersecurity (MLCS)\n",
    "authors": [
      "Lander Segurola-Gil",
      "Francesco Zola",
      "Xabier Echeberria-Barrio",
      "Raul Orduna-Urrutia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.07273"
  },
  {
    "id": "arXiv:2109.07275",
    "title": "DROMO: Distributionally Robust Offline Model-based Policy Optimization",
    "abstract": "We consider the problem of offline reinforcement learning with model-based\ncontrol, whose goal is to learn a dynamics model from the experience replay and\nobtain a pessimism-oriented agent under the learned model. Current model-based\nconstraint includes explicit uncertainty penalty and implicit conservative\nregularization that pushes Q-values of out-of-distribution state-action pairs\ndown and the in-distribution up. While the uncertainty estimation, on which the\nformer relies on, can be loosely calibrated for complex dynamics, the latter\nperforms slightly better. To extend the basic idea of regularization without\nuncertainty quantification, we propose distributionally robust offline\nmodel-based policy optimization (DROMO), which leverages the ideas in\ndistributionally robust optimization to penalize a broader range of\nout-of-distribution state-action pairs beyond the standard empirical\nout-of-distribution Q-value minimization. We theoretically show that our method\noptimizes a lower bound on the ground-truth policy evaluation, and it can be\nincorporated into any existing policy gradient algorithms. We also analyze the\ntheoretical properties of DROMO's linear and non-linear instantiations.",
    "descriptor": "\nComments: Under review of S.-T. Yau Award 2021 of Computer Science\n",
    "authors": [
      "Ruizhen Liu",
      "Dazhi Zhong",
      "Zhicong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07275"
  },
  {
    "id": "arXiv:2109.07276",
    "title": "Sequence Length is a Domain: Length-based Overfitting in Transformer  Models",
    "abstract": "Transformer-based sequence-to-sequence architectures, while achieving\nstate-of-the-art results on a large number of NLP tasks, can still suffer from\noverfitting during training. In practice, this is usually countered either by\napplying regularization methods (e.g. dropout, L2-regularization) or by\nproviding huge amounts of training data. Additionally, Transformer and other\narchitectures are known to struggle when generating very long sequences. For\nexample, in machine translation, the neural-based systems perform worse on very\nlong sequences when compared to the preceding phrase-based translation\napproaches (Koehn and Knowles, 2017).\nWe present results which suggest that the issue might also be in the mismatch\nbetween the length distributions of the training and validation data combined\nwith the aforementioned tendency of the neural networks to overfit to the\ntraining data. We demonstrate on a simple string editing task and a machine\ntranslation task that the Transformer model performance drops significantly\nwhen facing sequences of length diverging from the length distribution in the\ntraining data. Additionally, we show that the observed drop in performance is\ndue to the hypothesis length corresponding to the lengths seen by the model\nduring training rather than the length of the input sequence.",
    "descriptor": "",
    "authors": [
      "Du\u0161an Vari\u0161",
      "Ond\u0159ej Bojar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07276"
  },
  {
    "id": "arXiv:2109.07281",
    "title": "Measuring and improving information systems agility through the balanced  scorecard approach",
    "abstract": "Facing an environment increasingly complex, uncertain and changing, even in\ncrisis, organizations are driven to be agile in order to survive. Agility, at\nthe core heart of business strategy, represents the ability to grow in a\ncompetitive environment of continuous and unpredictable changes with\ninformation systems perceived as one of its main enablers. In other words, to\nbe agile, organizations must be able to rely on agile enterprise information\nsystems/information technology (IT/IS). Since, the agility needs are not the\nsame among stakeholders, the objective of this research is to develop a\nconceptual model for the achievement and assessment of IT/IS agility from\nbalanced perspectives to support agile organizations. Several researches have\nindicated that the IT balanced scorecard (BSC) approach is an appropriate\ntechnique for evaluating IT performance. This paper provides a\nbalanced-scorecard based framework to evaluate the IS agility through four\nperspectives: business contribution, user orientation, operation excellence and\ninnovation and competitiveness. The proposed framework, called IS Agility BSC,\npropose a three layer structure for each of the four perspectives: mission, key\nsuccess factors, and agility evaluation criteria. According to this conceptual\nmodel, enterprise information systems agility is measured according to 14\nagility key success factors, over the four BSC Perspectives, using 42 agility\nevaluation criteria that are identified based on literature survey methodology.\nThis paper explores agility in the broader context of the enterprise\ninformation systems. The findings will provide, for both researchers and\npractitioners, a practical approach for achieving and measuring IS agility\nperformance to support organizations in attempt to become agile as a new\ncondition of surviving in the new business world.",
    "descriptor": "",
    "authors": [
      "Yassine Rdiouat",
      "Samir Bahsani",
      "Mouhsine Lakhdissi",
      "Alami Semma"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.07281"
  },
  {
    "id": "arXiv:2109.07285",
    "title": "Take a deep breath. Benefits of neuroplasticity practices for software  developers and computer workers in a family of experiments",
    "abstract": "Context. Computer workers in general, and software developers specifically,\nare under a high amount of stress due to continuous deadlines and, often,\nover-commitment. Objective. This study investigates the effects of a\nneuroplasticity practice, a specific breathing practice, on the attention\nawareness, well-being, perceived productivity, and self-efficacy of computer\nworkers. Method. We created a questionnaire mainly from existing, validated\nscales as entry and exit survey for data points for comparison before and after\nthe intervention. The intervention was a 12-week program with a weekly live\nsession that included a talk on a well-being topic and a facilitated group\nbreathing session. During the intervention period, we solicited one daily\njournal note and one weekly well-being rating. We replicated the intervention\nin a similarly structured 8-week program. The data was analyzed using a\nBayesian multi-level model for the quantitative part and thematic analysis for\nthe qualitative part. Results. The intervention showed improvements in\nparticipants' experienced inner states despite an ongoing pandemic and intense\nouter circumstances for most. Over the course of the study, we found an\nimprovement in the participants' ratings of how often they found themselves in\ngood spirits as well as in a calm and relaxed state. We also aggregate a large\nnumber of deep inner reflections and growth processes that may not have\nsurfaced for the participants without deliberate engagement in such a program.\nConclusion. The data indicates usefulness and effectiveness of an intervention\nfor computer workers in terms of increasing well-being and resilience. Everyone\nneeds a way to deliberately relax, unplug, and recover. Breathing practice is a\nsimple way to do so, and the results call for establishing a larger body of\nwork to make this common practice.",
    "descriptor": "",
    "authors": [
      "Birgit Penzenstadler",
      "Richard Torkar",
      "Cristina Martinez Montes"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.07285"
  },
  {
    "id": "arXiv:2109.07288",
    "title": "Two algorithms for vehicular obstacle detection in sparse pointcloud",
    "abstract": "One of the main components of an autonomous vehicle is the obstacle detection\npipeline. Most prototypes, both from research and industry, rely on lidars for\nthis task. Pointcloud information from lidar is usually combined with data from\ncameras and radars, but the backbone of the architecture is mainly based on 3D\nbounding boxes computed from lidar data. To retrieve an accurate\nrepresentation, sensors with many planes, e.g., greater than 32 planes, are\nusually employed. The returned pointcloud is indeed dense and well defined, but\nhigh-resolution sensors are still expensive and often require powerful GPUs to\nbe processed. Lidars with fewer planes are cheaper, but the returned data are\nnot dense enough to be processed with state of the art deep learning approaches\nto retrieve 3D bounding boxes. In this paper, we propose two solutions based on\noccupancy grid and geometric refinement to retrieve a list of 3D bounding boxes\nemploying lidar with a low number of planes (i.e., 16 and 8 planes). Our\nsolutions have been validated on a custom acquired dataset with accurate ground\ntruth to prove its feasibility and accuracy.",
    "descriptor": "",
    "authors": [
      "Simone Mentasti",
      "Matteo Matteucci",
      "Stefano Arrigoni",
      "Federico Cheli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07288"
  },
  {
    "id": "arXiv:2109.07293",
    "title": "Unsupervised Keyphrase Extraction by Jointly Modeling Local and Global  Context",
    "abstract": "Embedding based methods are widely used for unsupervised keyphrase extraction\n(UKE) tasks. Generally, these methods simply calculate similarities between\nphrase embeddings and document embedding, which is insufficient to capture\ndifferent context for a more effective UKE model. In this paper, we propose a\nnovel method for UKE, where local and global contexts are jointly modeled. From\na global view, we calculate the similarity between a certain phrase and the\nwhole document in the vector space as transitional embedding based models do.\nIn terms of the local view, we first build a graph structure based on the\ndocument where phrases are regarded as vertices and the edges are similarities\nbetween vertices. Then, we proposed a new centrality computation method to\ncapture local salient information based on the graph structure. Finally, we\nfurther combine the modeling of global and local context for ranking. We\nevaluate our models on three public benchmarks (Inspec, DUC 2001, SemEval 2010)\nand compare with existing state-of-the-art models. The results show that our\nmodel outperforms most models while generalizing better on input documents with\ndifferent domains and length. Additional ablation study shows that both the\nlocal and global information is crucial for unsupervised keyphrase extraction\ntasks.",
    "descriptor": "\nComments: 10 pages, 4 figures, EMNLP 2021,code: this https URL\n",
    "authors": [
      "Xinnian Liang",
      "Shuangzhi Wu",
      "Mu Li",
      "Zhoujun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07293"
  },
  {
    "id": "arXiv:2109.07295",
    "title": "New Perspective on Progressive GANs Distillationfor One-class Novelty  Detection",
    "abstract": "One-class novelty detection is conducted to iden-tify anomalous instances,\nwith different distributions from theexpected normal instances. In this paper,\nthe Generative Adver-sarial Network based on the Encoder-Decoder-Encoder\nscheme(EDE-GAN) achieves state-of-the-art performance. The two fac-tors bellow\nserve the above purpose: 1) The EDE-GAN calculatesthe distance between two\nlatent vectors as the anomaly score,which is unlike the previous methods by\nutilizing the reconstruc-tion error between images. 2) The model obtains best\nresultswhen the batch size is set to 1. To illustrate their superiority,we\ndesign a new GAN architecture, and compareperformances according to different\nbatch sizes. Moreover, withexperimentation leads to discovery, our result\nimplies there is alsoevidence of just how beneficial constraint on the latent\nspace arewhen engaging in model training.In an attempt to learn compact and\nfast models, we present anew technology, Progressive Knowledge Distillation\nwith GANs(P-KDGAN), which connects two standard GANs through thedesigned\ndistillation loss. Two-step progressive learning continu-ously augments the\nperformance of student GANs with improvedresults over single-step approach. Our\nexperimental results onCIFAR-10, MNIST, and FMNIST datasets illustrate that\nP-KDGAN improves the performance of the student GAN by2.44%, 1.77%, and 1.73%\nwhen compressing the computationat ratios of 24.45:1, 311.11:1, and 700:1,\nrespectively.",
    "descriptor": "\nComments: 11 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2007.06963\n",
    "authors": [
      "Zhiwei Zhang",
      "Yu Dong",
      "Hanyu Peng",
      "Shifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07295"
  },
  {
    "id": "arXiv:2109.07296",
    "title": "Predicting Anti-Asian Hateful Users on Twitter during COVID-19",
    "abstract": "We investigate predictors of anti-Asian hate among Twitter users throughout\nCOVID-19. With the rise of xenophobia and polarization that has accompanied\nwidespread social media usage in many nations, online hate has become a major\nsocial issue, attracting many researchers. Here, we apply natural language\nprocessing techniques to characterize social media users who began to post\nanti-Asian hate messages during COVID-19. We compare two user groups -- those\nwho posted anti-Asian slurs and those who did not -- with respect to a rich set\nof features measured with data prior to COVID-19 and show that it is possible\nto predict who later publicly posted anti-Asian slurs. Our analysis of\npredictive features underlines the potential impact of news media and\ninformation sources that report on online hate and calls for further\ninvestigation into the role of polarized communication networks and news media.",
    "descriptor": "\nComments: Accepted at Findings of EMNLP 2021. Please cite our EMNLP Findings 2021 paper!\n",
    "authors": [
      "Jisun An",
      "Haewoon Kwak",
      "Claire Seungeun Lee",
      "Bogang Jun",
      "Yong-Yeol Ahn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.07296"
  },
  {
    "id": "arXiv:2109.07298",
    "title": "FFAVOD: Feature Fusion Architecture for Video Object Detection",
    "abstract": "A significant amount of redundancy exists between consecutive frames of a\nvideo. Object detectors typically produce detections for one image at a time,\nwithout any capabilities for taking advantage of this redundancy. Meanwhile,\nmany applications for object detection work with videos, including intelligent\ntransportation systems, advanced driver assistance systems and video\nsurveillance. Our work aims at taking advantage of the similarity between video\nframes to produce better detections. We propose FFAVOD, standing for feature\nfusion architecture for video object detection. We first introduce a novel\nvideo object detection architecture that allows a network to share feature maps\nbetween nearby frames. Second, we propose a feature fusion module that learns\nto merge feature maps to enhance them. We show that using the proposed\narchitecture and the fusion module can improve the performance of three base\nobject detectors on two object detection benchmarks containing sequences of\nmoving road users. Additionally, to further increase performance, we propose an\nimprovement to the SpotNet attention module. Using our architecture on the\nimproved SpotNet detector, we obtain the state-of-the-art performance on the\nUA-DETRAC public benchmark as well as on the UAVDT dataset. Code is available\nat https://github.com/hu64/FFAVOD.",
    "descriptor": "\nComments: Accepted for publication in Pattern Recognition Letters\n",
    "authors": [
      "Hughes Perreault",
      "Guillaume-Alexandre Bilodeau",
      "Nicolas Saunier",
      "Maguelonne H\u00e9ritier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07298"
  },
  {
    "id": "arXiv:2109.07301",
    "title": "What Vision-Language Models `See' when they See Scenes",
    "abstract": "Images can be described in terms of the objects they contain, or in terms of\nthe types of scene or place that they instantiate. In this paper we address to\nwhat extent pretrained Vision and Language models can learn to align\ndescriptions of both types with images. We compare 3 state-of-the-art models,\nVisualBERT, LXMERT and CLIP. We find that (i) V&L models are susceptible to\nstylistic biases acquired during pretraining; (ii) only CLIP performs\nconsistently well on both object- and scene-level descriptions. A follow-up\nablation study shows that CLIP uses object-level information in the visual\nmodality to align with scene-level textual descriptions.",
    "descriptor": "",
    "authors": [
      "Michele Cafagna",
      "Kees van Deemter",
      "Albert Gatt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07301"
  },
  {
    "id": "arXiv:2109.07302",
    "title": "A Characterization of Individualization-Refinement Trees",
    "abstract": "Individualization-Refinement (IR) algorithms form the standard method and\ncurrently the only practical method for symmetry computations of graphs and\ncombinatorial objects in general. Through backtracking, on each graph an\nIR-algorithm implicitly creates an IR-tree whose order is the determining\nfactor of the running time of the algorithm.\nWe give a precise and constructive characterization which trees are IR-trees.\nThis characterization is applicable both when the tree is regarded as an\nuncolored object but also when regarded as a colored object where vertex colors\nstem from a node invariant. We also provide a construction that given a tree\nproduces a corresponding graph whenever possible. This provides a constructive\nproof that our necessary conditions are also sufficient for the\ncharacterization.",
    "descriptor": "\nComments: to appear at ISAAC 2021\n",
    "authors": [
      "Markus Anders",
      "Jendrik Brachter",
      "Pascal Schweitzer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.07302"
  },
  {
    "id": "arXiv:2109.07305",
    "title": "Distributed flexibility as a cost-effective alternative to grid  reinforcement",
    "abstract": "The deployment of distributed photovoltaics (PV) in low-voltage networks may\ncause technical issues such as voltage rises, line ampacity violations, and\ntransformer overloading for distribution system operators (DSOs). These\nproblems may induce high grid reinforcement costs. In this work, we assume the\nDSO can control each prosumer's battery and PV system. Under such assumptions,\nwe evaluate the cost of providing flexibility and compare it with grid\nreinforcement costs. Our results highlight that using distributed flexibility\nis more profitable than reinforcing a low-voltage network until the PV\ngeneration covers 145% of the network annual energy demand.",
    "descriptor": "",
    "authors": [
      "Jordan Holweger",
      "Christophe Ballif",
      "Nicolas Wyrsch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07305"
  },
  {
    "id": "arXiv:2109.07306",
    "title": "Allocating Large Vocabulary Capacity for Cross-lingual Language Model  Pre-training",
    "abstract": "Compared to monolingual models, cross-lingual models usually require a more\nexpressive vocabulary to represent all languages adequately. We find that many\nlanguages are under-represented in recent cross-lingual language models due to\nthe limited vocabulary capacity. To this end, we propose an algorithm VoCap to\ndetermine the desired vocabulary capacity of each language. However, increasing\nthe vocabulary size significantly slows down the pre-training speed. In order\nto address the issues, we propose k-NN-based target sampling to accelerate the\nexpensive softmax. Our experiments show that the multilingual vocabulary\nlearned with VoCap benefits cross-lingual language model pre-training.\nMoreover, k-NN-based target sampling mitigates the side-effects of increasing\nthe vocabulary size while achieving comparable performance and faster\npre-training speed. The code and the pretrained multilingual vocabularies are\navailable at https://github.com/bozheng-hit/VoCapXLM.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Bo Zheng",
      "Li Dong",
      "Shaohan Huang",
      "Saksham Singhal",
      "Wanxiang Che",
      "Ting Liu",
      "Xia Song",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07306"
  },
  {
    "id": "arXiv:2109.07307",
    "title": "Expertise Affects Drone Racing Performance",
    "abstract": "First-person view drone racing has become a popular televised sport. However,\nvery little is known about the perceptual and motor skills of professional\ndrone racing pilots. A better understanding of these skills may inform path\nplanning and control algorithms for autonomous multirotor flight. By using a\nreal-world drone racing track and a large-scale position tracking system, we\ncompare the drone racing performance of five professional and five beginner\npilots. Results show that professional pilots consistently outperform beginner\npilots by achieving faster lap times, higher velocity, and more efficiently\nexecuting the challenging maneuvers. Trajectory analysis shows that experienced\npilots choose more optimal racing lines than beginner pilots. Our results\nprovide strong evidence for a contribution of expertise to performances in\nreal-world human-piloted drone racing. We discuss the implications of these\nresults for future work on autonomous fast and agile flight. We make our data\nopenly available.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Christian Pfeiffer",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.07307"
  },
  {
    "id": "arXiv:2109.07308",
    "title": "A Self-rescue Mechanism for an In-pipe Robot for Large Obstacle  Negotiation in Water Distribution Systems",
    "abstract": "Water distribution systems (WDS) carry potable water with millions of miles\nof pipelines and deliver purified water to residential areas. The incidents in\nthe WDS cause leak and water loss, which imposes pressure gradient and public\nhealth crisis. Hence, utility managers need to assess the condition of\npipelines periodically and localize the leak location (in case it is reported).\nIn our previous works, we designed and developed a size-adaptable modular\nin-pipe robot [1] and controlled its motion in in-service WDS. However, due to\nthe linearization of the dynamical equations of the robot, the stabilizer\ncontroller which is a linear quadratic regulator (LQR) cannot stabilize the\nlarge deviations of the stabilizing states due to the presence of obstacles\nthat fails the robot during operation. To this aim, we design a self-rescue\nmechanism for the robot in which three auxiliary gear-motors retract and extend\nthe arm modules with the designed controller towards a reliable motion in the\nnegotiation of large obstacles and non-straight configurations. Simulation\nresults show that the proposed mechanism along with the motion controller\nenables the robot to have an improved motion in pipelines.",
    "descriptor": "",
    "authors": [
      "MSaber Kazeminasab",
      "Moein Razavi",
      "Sajad Dehghani",
      "Morteza Khosrotabar",
      "M. Katherine Banks"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07308"
  },
  {
    "id": "arXiv:2109.07311",
    "title": "MD-CSDNetwork: Multi-Domain Cross Stitched Network for Deepfake  Detection",
    "abstract": "The rapid progress in the ease of creating and spreading ultra-realistic\nmedia over social platforms calls for an urgent need to develop a generalizable\ndeepfake detection technique. It has been observed that current deepfake\ngeneration methods leave discriminative artifacts in the frequency spectrum of\nfake images and videos. Inspired by this observation, in this paper, we present\na novel approach, termed as MD-CSDNetwork, for combining the features in the\nspatial and frequency domains to mine a shared discriminative representation\nfor classifying \\textit{deepfakes}. MD-CSDNetwork is a novel cross-stitched\nnetwork with two parallel branches carrying the spatial and frequency\ninformation, respectively. We hypothesize that these multi-domain input data\nstreams can be considered as related supervisory signals. The supervision from\nboth branches ensures better performance and generalization. Further, the\nconcept of cross-stitch connections is utilized where they are inserted between\nthe two branches to learn an optimal combination of domain-specific and shared\nrepresentations from other domains automatically. Extensive experiments are\nconducted on the popular benchmark dataset namely FaceForeniscs++ for forgery\nclassification. We report improvements over all the manipulation types in\nFaceForensics++ dataset and comparable results with state-of-the-art methods\nfor cross-database evaluation on the Celeb-DF dataset and the Deepfake\nDetection Dataset.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Aayushi Agarwal",
      "Akshay Agarwal",
      "Sayan Sinha",
      "Mayank Vatsa",
      "Richa Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07311"
  },
  {
    "id": "arXiv:2109.07313",
    "title": "Approximately EFX Allocations for Indivisible Chores",
    "abstract": "In this paper we study how to fairly allocate a set of m indivisible chores\nto a group of n agents, each of which has a general additive cost function on\nthe items. Since envy-free (EF) allocation is not guaranteed to exist, we\nconsider the notion of envy-freeness up to any item (EFX). In contrast to the\nfruitful results regarding the (approximation of) EFX allocations for goods,\nvery little is known for the allocation of chores. Prior to our work, for the\nallocation of chores, it is known that EFX allocations always exist for two\nagents, or general number of agents with IDO cost functions. For general\ninstances, no non-trivial approximation result regarding EFX allocation is\nknown. In this paper we make some progress in this direction by showing that\nfor three agents we can always compute a 5-approximation of EFX allocation in\npolynomial time. For n>=4 agents, our algorithm always computes an allocation\nthat achieves an approximation ratio of O(n^2) regarding EFX.",
    "descriptor": "\nComments: 13 pages, 1 figures\n",
    "authors": [
      "Shengwei Zhou",
      "Xiaowei Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.07313"
  },
  {
    "id": "arXiv:2109.07316",
    "title": "Reinshard: An optimally sharded dual-blockchain for concurrency  resolution",
    "abstract": "Decentralized control, low-complexity, flexible and efficient communications\nare the requirements of an architecture that aims to scale blockchains beyond\nthe current state. Such properties are attainable by reducing ledger size and\nproviding parallel operations in the blockchain. Sharding is one of the\napproaches that lower the burden of the nodes and enhance performance. However,\nthe current solutions lack the features for resolving concurrency during\ncross-shard communications. With multiple participants belonging to different\nshards, handling concurrent operations is essential for optimal sharding. This\nissue becomes prominent due to the lack of architectural support and requires\nadditional consensus for cross-shard communications. Inspired by hybrid\nProof-of-Work/Proof-of-Stake (PoW/PoS), like Ethereum, hybrid consensus and\n2-hop blockchain, we propose Reinshard, a new blockchain that inherits the\nproperties of hybrid consensus for optimal sharding. Reinshard uses PoW and PoS\nchain-pairs with PoS sub-chains for all the valid chain-pairs where the hybrid\nconsensus is attained through Verifiable Delay Function (VDF). Our architecture\nprovides a secure method of arranging nodes in shards and resolves concurrency\nconflicts using the delay factor of VDF. The applicability of Reinshard is\ndemonstrated through security and experimental evaluations. A practical\nconcurrency problem is considered to show the efficacy of Reinshard in\nproviding optimal sharding.",
    "descriptor": "\nComments: 14 pages, 9 figures, 3 tables\n",
    "authors": [
      "Vishal Sharma",
      "Zengpeng Li",
      "Pawel Szalachowski",
      "Teik Guan Tan",
      "Jianying Zhou"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.07316"
  },
  {
    "id": "arXiv:2109.07319",
    "title": "Embedding Convolutions for Short Text Extreme Classification with  Millions of Labels",
    "abstract": "Automatic annotation of short-text data to a large number of target labels,\nreferred to as Short Text Extreme Classification, has recently found numerous\napplications in prediction of related searches and product recommendation\ntasks. The conventional usage of Convolutional Neural Network (CNN) to capture\nn-grams in text-classification relies heavily on uniformity in word-ordering\nand the presence of long input sequences to convolve over. However, this is\nmissing in short and unstructured text sequences encountered in search and\nrecommendation. In order to tackle this, we propose an orthogonal approach by\nrecasting the convolution operation to capture coupled semantics along the\nembedding dimensions, and develop a word-order agnostic embedding enhancement\nmodule to deal with the lack of structure in such queries. Benefitting from the\ncomputational efficiency of the convolution operation, Embedding Convolutions,\nwhen applied on the enriched word embeddings, result in a light-weight and yet\npowerful encoder (InceptionXML) that is robust to the inherent lack of\nstructure in short-text extreme classification.\nTowards scaling our model to problems with millions of labels, we also\npropose InceptionXML+, which addresses the shortcomings of the dynamic\nhard-negative mining framework in the recently proposed LightXML by improving\nthe alignment between the label-shortlister and extreme classifier. On popular\nbenchmark datasets, we empirically demonstrate that the proposed method\noutperforms state-of-the-art deep extreme classifiers such as Astec by an\naverage of 5% and 8% on the P@k and propensity-scored PSP@k metrics\nrespectively.",
    "descriptor": "",
    "authors": [
      "Siddhant Kharbanda",
      "Atmadeep Banerjee",
      "Akash Palrecha",
      "Rohit Babbar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07319"
  },
  {
    "id": "arXiv:2109.07320",
    "title": "Error estimation and adaptivity for stochastic collocation finite  elements Part I: single-level approximation",
    "abstract": "A general adaptive refinement strategy for solving linear elliptic partial\ndifferential equation with random data is proposed and analysed herein. The\nadaptive strategy extends the a posteriori error estimation framework\nintroduced by Guignard and Nobile in 2018 (SIAM J. Numer. Anal., 56,\n3121--3143) to cover problems with a nonaffine parametric coefficient\ndependence. A suboptimal, but nonetheless reliable and convenient\nimplementation of the strategy involves approximation of the decoupled PDE\nproblems with a common finite element approximation space. Computational\nresults obtained using such a single-level strategy are presented in this paper\n(part I). Results obtained using a potentially more efficient multilevel\napproximation strategy, where meshes are individually tailored, will be\ndiscussed in part II of this work. The codes used to generate the numerical\nresults are available online.",
    "descriptor": "\nComments: 20 pages; 9 figures\n",
    "authors": [
      "Alex Bespalov",
      "David Silvester",
      "Feng Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.07320"
  },
  {
    "id": "arXiv:2109.07321",
    "title": "PoWareMatch: a Quality-aware Deep Learning Approach to Improve Human  Schema Matching",
    "abstract": "Schema matching is a core task of any data integration process. Being\ninvestigated in the fields of databases, AI, Semantic Web and data mining for\nmany years, the main challenge remains the ability to generate quality matches\namong data concepts (e.g., database attributes). In this work, we examine a\nnovel angle on the behavior of humans as matchers, studying match creation as a\nprocess. We analyze the dynamics of common evaluation measures (precision,\nrecall, and f-measure), with respect to this angle and highlight the need for\nunbiased matching to support this analysis. Unbiased matching, a newly defined\nconcept that describes the common assumption that human decisions represent\nreliable assessments of schemata correspondences, is, however, not an inherent\nproperty of human matchers. In what follows, we design PoWareMatch that makes\nuse of a deep learning mechanism to calibrate and filter human matching\ndecisions adhering the quality of a match, which are then combined with\nalgorithmic matching to generate better match results. We provide an empirical\nevidence, established based on an experiment with more than 200 human matchers\nover common benchmarks, that PoWareMatch predicts well the benefit of extending\nthe match with an additional correspondence and generates high quality matches.\nIn addition, PoWareMatch outperforms state-of-the-art matching algorithms.",
    "descriptor": "\nComments: Technical report of the paper {\\sf PoWareMatch}: a Quality-aware Deep Learning Approach to Improve Human Schema Matching, accepted to ACM Journal of Data and Information Quality (JDIQ), Special Issue on Deep Learning for Data Quality\n",
    "authors": [
      "Roee Shraga",
      "Avigdor Gal"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07321"
  },
  {
    "id": "arXiv:2109.07323",
    "title": "FORTAP: Using Formulae for Numerical-Reasoning-Aware Table Pretraining",
    "abstract": "Tables store rich numerical data, but numerical reasoning over tables is\nstill a challenge. In this paper, we find that the spreadsheet formula, which\nperforms calculations on numerical values in tables, is naturally a strong\nsupervision of numerical reasoning. More importantly, large amounts of\nspreadsheets with expert-made formulae are available on the web and can be\nobtained easily. FORTAP is the first method for numerical-reasoning-aware table\npretraining by leveraging large corpus of spreadsheet formulae. We design two\nformula pretraining tasks to explicitly guide FORTAP to learn numerical\nreference and calculation in semi-structured tables. FORTAP achieves\nstate-of-the-art results on two representative downstream tasks, cell type\nclassification and formula prediction, showing great potential of\nnumerical-reasoning-aware pretraining.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Zhoujun Cheng",
      "Haoyu Dong",
      "Fan Cheng",
      "Ran Jia",
      "Pengfei Wu",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07323"
  },
  {
    "id": "arXiv:2109.07324",
    "title": "PointManifoldCut: Point-wise Augmentation in the Manifold for Point  Clouds",
    "abstract": "Augmentation can benefit point cloud learning due to the limited availability\nof large-scale public datasets. This paper proposes a mix-up augmentation\napproach, PointManifoldCut, which replaces the neural network embedded points,\nrather than the Euclidean space coordinates. This approach takes the advantage\nthat points at the higher levels of the neural network are already trained to\nembed its neighbors relations and mixing these representation will not mingle\nthe relation between itself and its label. This allows to regularize the\nparameter space as the other augmentation methods but without worrying about\nthe proper label of the replaced points. The experiments show that our proposed\napproach provides a competitive performance on point cloud classification and\nsegmentation when it is combined with the cutting-edge vanilla point cloud\nnetworks. The result shows a consistent performance boosting compared to other\nstate-of-the-art point cloud augmentation method, such as PointMixup and\nPointCutMix. The code of this paper is available at:\nhttps://github.com/fun0515/PointManifoldCut.",
    "descriptor": "",
    "authors": [
      "Tianfang Zhu",
      "Yue Guan",
      "Anan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07324"
  },
  {
    "id": "arXiv:2109.07334",
    "title": "A Systematic Literature Review on Wearable Health Data Publishing under  Differential Privacy",
    "abstract": "Wearable devices generate different types of physiological data about the\nindividuals. These data can provide valuable insights for medical researchers\nand clinicians that cannot be availed through traditional measures. Researchers\nhave historically relied on survey responses or observed behavior.\nInterestingly, physiological data can provide a richer amount of user cognition\nthan that obtained from any other sources, including the user himself.\nTherefore, the inexpensive consumer-grade wearable devices have become a point\nof interest for the health researchers. In addition, they are also used in\ncontinuous remote health monitoring and sometimes by the insurance companies.\nHowever, the biggest concern for such kind of use cases is the privacy of the\nindividuals. There are a few privacy mechanisms, such as abstraction and\nk-anonymity, are widely used in information systems. Recently, Differential\nPrivacy (DP) has emerged as a proficient technique to publish privacy sensitive\ndata, including data from wearable devices. In this paper, we have conducted a\nSystematic Literature Review (SLR) to identify, select and critically appraise\nresearches in DP as well as to understand different techniques and exiting use\nof DP in wearable data publishing. Based on our study we have identified the\nlimitations of proposed solutions and provided future directions.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Munshi Saifuzzaman",
      "Tajkia Nuri Ananna",
      "Mohammad Jabed Morshed Chowdhury",
      "Md Sadek Ferdous",
      "Farida Chowdhury"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.07334"
  },
  {
    "id": "arXiv:2109.07335",
    "title": "Comparing decision mining approaches with regard to the meaningfulness  of their results",
    "abstract": "Decisions and the underlying rules are indispensable for driving process\nexecution during runtime, i.e., for routing process instances at alternative\nbranches based on the values of process data. Decision rules can comprise unary\ndata conditions, e.g., age > 40, binary data conditions where the relation\nbetween two or more variables is relevant, e.g. temperature1 < temperature2,\nand more complex conditions that refer to, for example, parts of a medical\nimage. Decision discovery aims at automatically deriving decision rules from\nprocess event logs. Existing approaches focus on the discovery of unary, or in\nsome instances binary data conditions. The discovered decision rules are\nusually evaluated using accuracy, but not with regards to their semantics and\nmeaningfulness, although this is crucial for validation and the subsequent\nimplementation/adaptation of the decision rules. Hence, this paper compares\nthree decision mining approaches, i.e., two existing ones and one newly\ndescribed approach, with respect to the meaningfulness of their results. For\ncomparison, we use one synthetic data set for a realistic manufacturing case\nand the two real-world BPIC 2017/2020 logs. The discovered rules are discussed\nwith regards to their semantics and meaningfulness.",
    "descriptor": "",
    "authors": [
      "Beate Scheibel",
      "Stefanie Rinderle-Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07335"
  },
  {
    "id": "arXiv:2109.07339",
    "title": "S3LAM: Structured Scene SLAM",
    "abstract": "We propose a new general SLAM system that uses the semantic segmentation of\nobjects and structures in the scene. Semantic information is relevant as it\ncontains high level information which may make SLAM more accurate and robust.\nOur contribution is threefold: i) A new SLAM system based on ORB-SLAM2 that\ncreates a semantic map made of clusters of points corresponding to objects\ninstances and structures in the scene. ii) A modification of the classical\nBundle Adjustment formulation to constrain each cluster using geometrical\npriors, which improves both camera localization and reconstruction and enables\na better understanding of the scene. iii) A new Bundle Adjustment formulation\nat the level of clusters to improve the convergence of classical Bundle\nAdjustment. We evaluate our approach on several sequences from a public dataset\nand show that, with respect to ORB-SLAM2 it improves camera pose estimation.",
    "descriptor": "",
    "authors": [
      "Mathieu Gonzalez",
      "Eric Marchand",
      "Amine Kacete",
      "J\u00e9r\u00f4me Royan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07339"
  },
  {
    "id": "arXiv:2109.07342",
    "title": "Sequential Point Cloud Prediction in Interactive Scenarios: A Survey",
    "abstract": "Point cloud has been widely used in the field of autonomous driving since it\ncan provide a more comprehensive three-dimensional representation of the\nenvironment than 2D images. Point-wise prediction based on point cloud sequence\n(PCS) is an essential part of environment understanding, which can assist in\nthe decision-making and motion-planning of autonomous vehicles. However, PCS\nprediction has not been deeply researched in the literature. This paper\nproposes a brief review of the sequential point cloud prediction methods,\nfocusing on interactive scenarios. Firstly, we define the PCS prediction\nproblem and introduce commonly-used frameworks. Secondly, by reviewing\nnon-predictive problems, we analyze and summarize the spatio-temporal feature\nextraction methods based on PCS. On this basis, we review two types of PCS\nprediction tasks, scene flow estimation (SFE) and point cloud location\nprediction (PCLP), highlighting their connections and differences. Finally, we\ndiscuss some opening issues and point out some potential research directions.",
    "descriptor": "",
    "authors": [
      "Haowen Wang",
      "Zirui Li",
      "Jianwei Gong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07342"
  },
  {
    "id": "arXiv:2109.07343",
    "title": "Mi\u00f0eind's WMT 2021 submission",
    "abstract": "We present Mi{\\dh}eind's submission for the English$\\to$Icelandic and\nIcelandic$\\to$English subsets of the 2021 WMT news translation task.\nTransformer-base models are trained for translation on parallel data to\ngenerate backtranslations iteratively. A pretrained mBART-25 model is then\nadapted for translation using parallel data as well as the last backtranslation\niteration. This adapted pretrained model is then used to re-generate\nbacktranslations, and the training of the adapted model is continued.",
    "descriptor": "",
    "authors": [
      "Haukur Barri S\u00edmonarson",
      "V\u00e9steinn Sn\u00e6bjarnarson",
      "P\u00e9tur Orri Ragnarsson",
      "Haukur P\u00e1ll J\u00f3nsson",
      "Vilhj\u00e1lmur \u00deorsteinsson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07343"
  },
  {
    "id": "arXiv:2109.07346",
    "title": "Introducing an Abusive Language Classification Framework for Telegram to  Investigate the German Hater Community",
    "abstract": "Since traditional social media platforms ban more and more actors that\ndistribute hate speech or other forms of abusive language (deplatforming),\nthese actors migrate to alternative platforms that do not moderate the users'\ncontent. One known platform that is relevant for the German hater community is\nTelegram, for which there have only been made limited research efforts so far.\nThe goal of this study is to develop a broad framework that consists of (i)\nan abusive language classification model for German Telegram messages and (ii)\na classification model for the hatefulness of Telegram channels. For the first\npart, we employ existing abusive language datasets containing posts from other\nplatforms to build our classification models. For the channel classification\nmodel, we develop a method that combines channel specific content information\ncoming from a topic model with a social graph to predict the hatefulness of\nchannels. Furthermore, we complement these two approaches for hate speech\ndetection with insightful results on the evolution of the hater community on\nTelegram in Germany. Moreover, we propose methods to the hate speech research\ncommunity for scalable network analyses for social media platforms. As an\nadditional output of the study, we release an annotated abusive language\ndataset containing 1,149 annotated Telegram messages.",
    "descriptor": "",
    "authors": [
      "Maximilian Wich",
      "Adrian Gorniak",
      "Tobias Eder",
      "Daniel Bartmann",
      "Burak Enes \u00c7akici",
      "Georg Groh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07346"
  },
  {
    "id": "arXiv:2109.07348",
    "title": "Cross-lingual Transfer of Monolingual Models",
    "abstract": "Recent studies in zero-shot cross-lingual learning using multilingual models\nhave falsified the previous hypothesis that shared vocabulary and joint\npre-training are the keys to cross-lingual generalization. Inspired by this\nadvancement, we introduce a cross-lingual transfer method for monolingual\nmodels based on domain adaptation. We study the effects of such transfer from\nfour different languages to English. Our experimental results on GLUE show that\nthe transferred models outperform the native English model independently of the\nsource language. After probing the English linguistic knowledge encoded in the\nrepresentations before and after transfer, we find that semantic information is\nretained from the source language, while syntactic information is learned\nduring transfer. Additionally, the results of evaluating the transferred models\nin source language tasks reveal that their performance in the source domain\ndeteriorates after transfer.",
    "descriptor": "",
    "authors": [
      "Evangelia Gogoulou",
      "Ariel Ekgren",
      "Tim Isbister",
      "Magnus Sahlgren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07348"
  },
  {
    "id": "arXiv:2109.07351",
    "title": "The ELITR ECA Corpus",
    "abstract": "We present the ELITR ECA corpus, a multilingual corpus derived from\npublications of the European Court of Auditors. We use automatic translation\ntogether with Bleualign to identify parallel sentence pairs in all 506\ntranslation directions. The result is a corpus comprising 264k document pairs\nand 41.9M sentence pairs.",
    "descriptor": "",
    "authors": [
      "Philip Williams",
      "Barry Haddow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07351"
  },
  {
    "id": "arXiv:2109.07353",
    "title": "Learning Dynamical Human-Joint Affinity for 3D Pose Estimation in Videos",
    "abstract": "Graph Convolution Network (GCN) has been successfully used for 3D human pose\nestimation in videos. However, it is often built on the fixed human-joint\naffinity, according to human skeleton. This may reduce adaptation capacity of\nGCN to tackle complex spatio-temporal pose variations in videos. To alleviate\nthis problem, we propose a novel Dynamical Graph Network (DG-Net), which can\ndynamically identify human-joint affinity, and estimate 3D pose by adaptively\nlearning spatial/temporal joint relations from videos. Different from\ntraditional graph convolution, we introduce Dynamical Spatial/Temporal Graph\nconvolution (DSG/DTG) to discover spatial/temporal human-joint affinity for\neach video exemplar, depending on spatial distance/temporal movement similarity\nbetween human joints in this video. Hence, they can effectively understand\nwhich joints are spatially closer and/or have consistent motion, for reducing\ndepth ambiguity and/or motion uncertainty when lifting 2D pose to 3D pose. We\nconduct extensive experiments on three popular benchmarks, e.g., Human3.6M,\nHumanEva-I, and MPI-INF-3DHP, where DG-Net outperforms a number of recent SOTA\napproaches with fewer input frames and model size.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Image Processing\n",
    "authors": [
      "Junhao Zhang",
      "Yali Wang",
      "Zhipeng Zhou",
      "Tianyu Luan",
      "Zhe Wang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07353"
  },
  {
    "id": "arXiv:2109.07359",
    "title": "Modular Neural Ordinary Differential Equations",
    "abstract": "The laws of physics have been written in the language of dif-ferential\nequations for centuries. Neural Ordinary Differen-tial Equations (NODEs) are a\nnew machine learning architecture which allows these differential equations to\nbe learned from a dataset. These have been applied to classical dynamics\nsimulations in the form of Lagrangian Neural Net-works (LNNs) and Second Order\nNeural Differential Equations (SONODEs). However, they either cannot represent\nthe most general equations of motion or lack interpretability. In this paper,\nwe propose Modular Neural ODEs, where each force component is learned with\nseparate modules. We show how physical priors can be easily incorporated into\nthese models. Through a number of experiments, we demonstrate these result in\nbetter performance, are more interpretable, and add flexibility due to their\nmodularity.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Max Zhu",
      "Prof. P Lio",
      "Jacob Moss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07359"
  },
  {
    "id": "arXiv:2109.07364",
    "title": "Towards Incremental Transformers: An Empirical Analysis of Transformer  Models for Incremental NLU",
    "abstract": "Incremental processing allows interactive systems to respond based on partial\ninputs, which is a desirable property e.g. in dialogue agents. The currently\npopular Transformer architecture inherently processes sequences as a whole,\nabstracting away the notion of time. Recent work attempts to apply Transformers\nincrementally via restart-incrementality by repeatedly feeding, to an unchanged\nmodel, increasingly longer input prefixes to produce partial outputs. However,\nthis approach is computationally costly and does not scale efficiently for long\nsequences. In parallel, we witness efforts to make Transformers more efficient,\ne.g. the Linear Transformer (LT) with a recurrence mechanism. In this work, we\nexamine the feasibility of LT for incremental NLU in English. Our results show\nthat the recurrent LT model has better incremental performance and faster\ninference speed compared to the standard Transformer and LT with\nrestart-incrementality, at the cost of part of the non-incremental (full\nsequence) quality. We show that the performance drop can be mitigated by\ntraining the model to wait for right context before committing to an output and\nthat training with input prefixes is beneficial for delivering correct partial\noutputs.",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Patrick Kahardipraja",
      "Brielen Madureira",
      "David Schlangen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07364"
  },
  {
    "id": "arXiv:2109.07365",
    "title": "Maneuver-based Trajectory Prediction for Self-driving Cars Using  Spatio-temporal Convolutional Networks",
    "abstract": "The ability to predict the future movements of other vehicles is a\nsubconscious and effortless skill for humans and key to safe autonomous\ndriving. Therefore, trajectory prediction for autonomous cars has gained a lot\nof attention in recent years. It is, however, still a hard task to achieve\nhuman-level performance. Interdependencies between vehicle behaviors and the\nmultimodal nature of future intentions in a dynamic and complex driving\nenvironment render trajectory prediction a challenging problem. In this work,\nwe propose a new, data-driven approach for predicting the motion of vehicles in\na road environment. The model allows for inferring future intentions from the\npast interaction among vehicles in highway driving scenarios. Using our\nneighborhood-based data representation, the proposed system jointly exploits\ncorrelations in the spatial and temporal domain using convolutional neural\nnetworks. Our system considers multiple possible maneuver intentions and their\ncorresponding motion and predicts the trajectory for five seconds into the\nfuture. We implemented our approach and evaluated it on two highway datasets\ntaken in different countries and are able to achieve a competitive prediction\nperformance.",
    "descriptor": "\nComments: Accepted for IROS 2021\n",
    "authors": [
      "Benedikt Mersch",
      "Thomas H\u00f6llen",
      "Kun Zhao",
      "Cyrill Stachniss",
      "Ribana Roscher"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07365"
  },
  {
    "id": "arXiv:2109.07368",
    "title": "UniST: Unified End-to-end Model for Streaming and Non-streaming Speech  Translation",
    "abstract": "This paper presents a unified end-to-end frame-work for both streaming and\nnon-streamingspeech translation. While the training recipes for non-streaming\nspeech translation have been mature, the recipes for streaming\nspeechtranslation are yet to be built. In this work, wefocus on developing a\nunified model (UniST) which supports streaming and non-streaming ST from the\nperspective of fundamental components, including training objective, attention\nmechanism and decoding policy. Experiments on the most popular speech-to-text\ntranslation benchmark dataset, MuST-C, show that UniST achieves significant\nimprovement for non-streaming ST, and a better-learned trade-off for BLEU score\nand latency metrics for streaming ST, compared with end-to-end baselines and\nthe cascaded models. We will make our codes and evaluation tools publicly\navailable.",
    "descriptor": "",
    "authors": [
      "Qianqian Dong",
      "Yaoming Zhu",
      "Mingxuan Wang",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.07368"
  },
  {
    "id": "arXiv:2109.07370",
    "title": "Direct and Sparse Deformable Tracking",
    "abstract": "Deformable Monocular SLAM algorithms recover the localization of a camera in\nan unknown deformable environment. Current approaches use a template-based\ndeformable tracking to recover the camera pose and the deformation of the map.\nThese template-based methods use an underlying global deformation model. In\nthis paper, we introduce a novel deformable camera tracking method with a local\ndeformation model for each point. Each map point is defined as a single\ntextured surfel that moves independently of the other map points. Thanks to a\ndirect photometric error cost function, we can track the position and\norientation of the surfel without an explicit global deformation model. In our\nexperiments, we validate the proposed system and observe that our local\ndeformation model estimates more accurately and robustly the targeted\ndeformations of the map in both laboratory-controlled experiments and in-body\nscenarios undergoing non-isometric deformations, with changing topology or\ndiscontinuities.",
    "descriptor": "\nComments: 8 pages, 5 figures, submitted to RAL with ICRA\n",
    "authors": [
      "Jose Lamarca",
      "Juan J. Gomez Rodriguez",
      "Juan D. Tardos",
      "J.M.M. Montiel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07370"
  },
  {
    "id": "arXiv:2109.07371",
    "title": "Self-learn to Explain Siamese Networks Robustly",
    "abstract": "Learning to compare two objects are essential in applications, such as\ndigital forensics, face recognition, and brain network analysis, especially\nwhen labeled data is scarce and imbalanced. As these applications make\nhigh-stake decisions and involve societal values like fairness and\ntransparency, it is critical to explain the learned models. We aim to study\npost-hoc explanations of Siamese networks (SN) widely used in learning to\ncompare. We characterize the instability of gradient-based explanations due to\nthe additional compared object in SN, in contrast to architectures with a\nsingle input instance. We propose an optimization framework that derives global\ninvariance from unlabeled data using self-learning to promote the stability of\nlocal explanations tailored for specific query-reference pairs. The\noptimization problems can be solved using gradient descent-ascent (GDA) for\nconstrained optimization, or SGD for KL-divergence regularized unconstrained\noptimization, with convergence proofs, especially when the objective functions\nare nonconvex due to the Siamese architecture. Quantitative results and case\nstudies on tabular and graph data from neuroscience and chemical engineering\nshow that the framework respects the self-learned invariance while robustly\noptimizing the faithfulness and simplicity of the explanation. We further\ndemonstrate the convergence of GDA experimentally.",
    "descriptor": "\nComments: Accepted to ICDM 2021\n",
    "authors": [
      "Chao Chen",
      "Yifan Shen",
      "Guixiang Ma",
      "Xiangnan Kong",
      "Srinivas Rangarajan",
      "Xi Zhang",
      "Sihong Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07371"
  },
  {
    "id": "arXiv:2109.07373",
    "title": "A Unified Framework for Biphasic Facial Age Translation with  Noisy-Semantic Guided Generative Adversarial Networks",
    "abstract": "Biphasic facial age translation aims at predicting the appearance of the\ninput face at any age. Facial age translation has received considerable\nresearch attention in the last decade due to its practical value in cross-age\nface recognition and various entertainment applications. However, most existing\nmethods model age changes between holistic images, regardless of the human face\nstructure and the age-changing patterns of individual facial components.\nConsequently, the lack of semantic supervision will cause infidelity of\ngenerated faces in detail. To this end, we propose a unified framework for\nbiphasic facial age translation with noisy-semantic guided generative\nadversarial networks. Structurally, we project the class-aware noisy semantic\nlayouts to soft latent maps for the following injection operation on the\nindividual facial parts. In particular, we introduce two sub-networks,\nProjectionNet and ConstraintNet. ProjectionNet introduces the low-level\nstructural semantic information with noise map and produces soft latent maps.\nConstraintNet disentangles the high-level spatial features to constrain the\nsoft latent maps, which endows more age-related context into the soft latent\nmaps. Specifically, attention mechanism is employed in ConstraintNet for\nfeature disentanglement. Meanwhile, in order to mine the strongest mapping\nability of the network, we embed two types of learning strategies in the\ntraining procedure, supervised self-driven generation and unsupervised\ncondition-driven cycle-consistent generation. As a result, extensive\nexperiments conducted on MORPH and CACD datasets demonstrate the prominent\nability of our proposed method which achieves state-of-the-art performance.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Muyi Sun",
      "Jian Wang",
      "Yunfan Liu",
      "Qi Li",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07373"
  },
  {
    "id": "arXiv:2109.07377",
    "title": "Topic Transferable Table Question Answering",
    "abstract": "Weakly-supervised table question-answering(TableQA) models have achieved\nstate-of-art performance by using pre-trained BERT transformer to jointly\nencoding a question and a table to produce structured query for the question.\nHowever, in practical settings TableQA systems are deployed over table corpora\nhaving topic and word distributions quite distinct from BERT's pretraining\ncorpus. In this work we simulate the practical topic shift scenario by\ndesigning novel challenge benchmarks WikiSQL-TS and WikiTQ-TS, consisting of\ntrain-dev-test splits in five distinct topic groups, based on the popular\nWikiSQL and WikiTableQuestions datasets. We empirically show that, despite\npre-training on large open-domain text, performance of models degrades\nsignificantly when they are evaluated on unseen topics. In response, we propose\nT3QA (Topic Transferable Table Question Answering) a pragmatic adaptation\nframework for TableQA comprising of: (1) topic-specific vocabulary injection\ninto BERT, (2) a novel text-to-text transformer generator (such as T5, GPT2)\nbased natural language question generation pipeline focused on generating topic\nspecific training data, and (3) a logical form reranker. We show that T3QA\nprovides a reasonably good baseline for our topic shift benchmarks. We believe\nour topic split benchmarks will lead to robust TableQA solutions that are\nbetter suited for practical deployment.",
    "descriptor": "\nComments: To appear at EMNLP 2021\n",
    "authors": [
      "Saneem Ahmed Chemmengath",
      "Vishwajeet Kumar",
      "Samarth Bharadwaj",
      "Jaydeep Sen",
      "Mustafa Canim",
      "Soumen Chakrabarti",
      "Alfio Gliozzo",
      "Karthik Sankaranarayanan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07377"
  },
  {
    "id": "arXiv:2109.07380",
    "title": "DCUR: Data Curriculum for Teaching via Samples with Reinforcement  Learning",
    "abstract": "Deep reinforcement learning (RL) has shown great empirical successes, but\nsuffers from brittleness and sample inefficiency. A potential remedy is to use\na previously-trained policy as a source of supervision. In this work, we refer\nto these policies as teachers and study how to transfer their expertise to new\nstudent policies by focusing on data usage. We propose a framework, Data\nCUrriculum for Reinforcement learning (DCUR), which first trains teachers using\nonline deep RL, and stores the logged environment interaction history. Then,\nstudents learn by running either offline RL or by using teacher data in\ncombination with a small amount of self-generated data. DCUR's central idea\ninvolves defining a class of data curricula which, as a function of training\ntime, limits the student to sampling from a fixed subset of the full teacher\ndata. We test teachers and students using state-of-the-art deep RL algorithms\nacross a variety of data curricula. Results suggest that the choice of data\ncurricula significantly impacts student learning, and that it is beneficial to\nlimit the data during early training stages while gradually letting the data\navailability grow over time. We identify when the student can learn offline and\nmatch teacher performance without relying on specialized offline RL algorithms.\nFurthermore, we show that collecting a small fraction of online data provides\ncomplementary benefits with the data curriculum. Supplementary material is\navailable at https://tinyurl.com/teach-dcur.",
    "descriptor": "\nComments: Supplementary material is available at this https URL\n",
    "authors": [
      "Daniel Seita",
      "Abhinav Gopal",
      "Zhao Mandi",
      "John Canny"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07380"
  },
  {
    "id": "arXiv:2109.07382",
    "title": "Toward Modern Fortran Tooling and a Thriving Developer Community",
    "abstract": "Fortran is the oldest high-level programming language that remains in use\ntoday and is one of the dominant languages used for compute-intensive\nscientific and engineering applications. However, Fortran has not kept up with\nthe modern software development practices and tooling in the internet era. As a\nconsequence, the Fortran developer experience has diminished. Specifically,\nlack of a rich general-purpose library ecosystem, modern tools for building and\npackaging Fortran libraries and applications, and online learning resources,\nhas made it difficult for Fortran to attract and retain new users. To address\nthis problem, an open source community has formed on GitHub in 2019 and began\nto work on the initial set of core tools: a standard library, a build system\nand package manager, and a community-curated website for Fortran. In this paper\nwe report on the progress to date and outline the next steps.",
    "descriptor": "\nComments: Submitted to ACM Fortran Forum\n",
    "authors": [
      "Milan Curcic",
      "Ond\u0159ej \u010cert\u00edk",
      "Brad Richardson",
      "Sebastian Ehlert",
      "Laurence Kedward",
      "Arjen Markus",
      "Ivan Pribec",
      "J\u00e9r\u00e9mie Vandenplas"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.07382"
  },
  {
    "id": "arXiv:2109.07383",
    "title": "RankNAS: Efficient Neural Architecture Search by Pairwise Ranking",
    "abstract": "This paper addresses the efficiency challenge of Neural Architecture Search\n(NAS) by formulating the task as a ranking problem. Previous methods require\nnumerous training examples to estimate the accurate performance of\narchitectures, although the actual goal is to find the distinction between\n\"good\" and \"bad\" candidates. Here we do not resort to performance predictors.\nInstead, we propose a performance ranking method (RankNAS) via pairwise\nranking. It enables efficient architecture search using much fewer training\nexamples. Moreover, we develop an architecture selection method to prune the\nsearch space and concentrate on more promising candidates. Extensive\nexperiments on machine translation and language modeling tasks show that\nRankNAS can design high-performance architectures while being orders of\nmagnitude faster than state-of-the-art NAS systems.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 Long Paper\n",
    "authors": [
      "Chi Hu",
      "Chenglong Wang",
      "Xiangnan Ma",
      "Xia Meng",
      "Yinqiao Li",
      "Tong Xiao",
      "Jingbo Zhu",
      "Changliang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07383"
  },
  {
    "id": "arXiv:2109.07395",
    "title": "Can one hear the shape of a neural network?: Snooping the GPU via  Magnetic Side Channel",
    "abstract": "Neural network applications have become popular in both enterprise and\npersonal settings. Network solutions are tuned meticulously for each task, and\ndesigns that can robustly resolve queries end up in high demand. As the\ncommercial value of accurate and performant machine learning models increases,\nso too does the demand to protect neural architectures as confidential\ninvestments. We explore the vulnerability of neural networks deployed as black\nboxes across accelerated hardware through electromagnetic side channels. We\nexamine the magnetic flux emanating from a graphics processing unit's power\ncable, as acquired by a cheap $3 induction sensor, and find that this signal\nbetrays the detailed topology and hyperparameters of a black-box neural network\nmodel. The attack acquires the magnetic signal for one query with unknown input\nvalues, but known input dimensions. The network reconstruction is possible due\nto the modular layer sequence in which deep neural networks are evaluated. We\nfind that each layer component's evaluation produces an identifiable magnetic\nsignal signature, from which layer topology, width, function type, and sequence\norder can be inferred using a suitably trained classifier and a joint\nconsistency optimization based on integer programming. We study the extent to\nwhich network specifications can be recovered, and consider metrics for\ncomparing network similarity. We demonstrate the potential accuracy of this\nside channel attack in recovering the details for a broad range of network\narchitectures, including random designs. We consider applications that may\nexploit this novel side channel exposure, such as adversarial transfer attacks.\nIn response, we discuss countermeasures to protect against our method and other\nsimilar snooping techniques.",
    "descriptor": "\nComments: 14 pages, accepted to USENIX Security 2022\n",
    "authors": [
      "Henrique Teles Maia",
      "Chang Xiao",
      "Dingzeyu Li",
      "Eitan Grinspun",
      "Changxi Zheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07395"
  },
  {
    "id": "arXiv:2109.07396",
    "title": "Constraint based Knowledge Base Distillation in End-to-End Task Oriented  Dialogs",
    "abstract": "End-to-End task-oriented dialogue systems generate responses based on dialog\nhistory and an accompanying knowledge base (KB). Inferring those KB entities\nthat are most relevant for an utterance is crucial for response generation.\nExisting state of the art scales to large KBs by softly filtering over\nirrelevant KB information. In this paper, we propose a novel filtering\ntechnique that consists of (1) a pairwise similarity based filter that\nidentifies relevant information by respecting the n-ary structure in a KB\nrecord. and, (2) an auxiliary loss that helps in separating contextually\nunrelated KB information. We also propose a new metric -- multiset entity F1\nwhich fixes a correctness issue in the existing entity F1 metric. Experimental\nresults on three publicly available task-oriented dialog datasets show that our\nproposed approach outperforms existing state-of-the-art models.",
    "descriptor": "\nComments: D. Raghu and A. Jain contributed equally to this work\n",
    "authors": [
      "Dinesh Raghu",
      "Atishya Jain",
      "Mausam",
      "Sachindra Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07396"
  },
  {
    "id": "arXiv:2109.07401",
    "title": "Matching with Transformers in MELT",
    "abstract": "One of the strongest signals for automated matching of ontologies and\nknowledge graphs are the textual descriptions of the concepts. The methods that\nare typically applied (such as character- or token-based comparisons) are\nrelatively simple, and therefore do not capture the actual meaning of the\ntexts. With the rise of transformer-based language models, text comparison\nbased on meaning (rather than lexical features) is possible. In this paper, we\nmodel the ontology matching task as classification problem and present\napproaches based on transformer models. We further provide an easy to use\nimplementation in the MELT framework which is suited for ontology and knowledge\ngraph matching. We show that a transformer-based filter helps to choose the\ncorrect correspondences given a high-recall alignment and already achieves a\ngood result with simple alignment post-processing methods.",
    "descriptor": "\nComments: accepted at the Ontology Matching Workshop at the International Semantic Web Conference (ISWC 2021)\n",
    "authors": [
      "Sven Hertling",
      "Jan Portisch",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07401"
  },
  {
    "id": "arXiv:2109.07402",
    "title": "Multi View Spatial-Temporal Model for Travel Time Estimation",
    "abstract": "Taxi arrival time prediction is an essential part of building intelligent\ntransportation systems. Traditional arrival time estimation methods mainly rely\non traffic map feature extraction, which can not model complex situations and\nnonlinear spatial and temporal relationships. Therefore, we propose a\nMulti-View Spatial-Temporal Model (MVSTM) to capture the dependence of\nspatial-temporal and trajectory. Specifically, we use graph2vec to model the\nspatial view, dual-channel temporal module to model the trajectory view, and\nstructural embedding to model the traffic semantics. Experiments on large-scale\ntaxi trajectory data show that our approach is more effective than the novel\nmethod. The source code can be obtained from\nhttps://github.com/775269512/SIGSPATIAL-2021-GISCUP-4th-Solution.",
    "descriptor": "",
    "authors": [
      "ZiChuan Liu",
      "Zhaoyang Wu",
      "Meng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.07402"
  },
  {
    "id": "arXiv:2109.07403",
    "title": "BERT is Robust! A Case Against Synonym-Based Adversarial Examples in  Text Classification",
    "abstract": "Deep Neural Networks have taken Natural Language Processing by storm. While\nthis led to incredible improvements across many tasks, it also initiated a new\nresearch field, questioning the robustness of these neural networks by\nattacking them. In this paper, we investigate four word substitution-based\nattacks on BERT. We combine a human evaluation of individual word substitutions\nand a probabilistic analysis to show that between 96% and 99% of the analyzed\nattacks do not preserve semantics, indicating that their success is mainly\nbased on feeding poor data to the model. To further confirm that, we introduce\nan efficient data augmentation procedure and show that many adversarial\nexamples can be prevented by including data similar to the attacks during\ntraining. An additional post-processing step reduces the success rates of\nstate-of-the-art attacks below 5%. Finally, by looking at more reasonable\nthresholds on constraints for word substitutions, we conclude that BERT is a\nlot more robust than research on attacks suggests.",
    "descriptor": "\nComments: 12 pages with appendix, 7 figures\n",
    "authors": [
      "Jens Hauser",
      "Zhao Meng",
      "Dami\u00e1n Pascual",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07403"
  },
  {
    "id": "arXiv:2109.07407",
    "title": "Semi-supervised Contrastive Learning for Label-efficient Medical Image  Segmentation",
    "abstract": "The success of deep learning methods in medical image segmentation tasks\nheavily depends on a large amount of labeled data to supervise the training. On\nthe other hand, the annotation of biomedical images requires domain knowledge\nand can be laborious. Recently, contrastive learning has demonstrated great\npotential in learning latent representation of images even without any label.\nExisting works have explored its application to biomedical image segmentation\nwhere only a small portion of data is labeled, through a pre-training phase\nbased on self-supervised contrastive learning without using any labels followed\nby a supervised fine-tuning phase on the labeled portion of data only. In this\npaper, we establish that by including the limited label in formation in the\npre-training phase, it is possible to boost the performance of contrastive\nlearning. We propose a supervised local contrastive loss that leverages limited\npixel-wise annotation to force pixels with the same label to gather around in\nthe embedding space. Such loss needs pixel-wise computation which can be\nexpensive for large images, and we further propose two strategies, downsampling\nand block division, to address the issue. We evaluate our methods on two public\nbiomedical image datasets of different modalities. With different amounts of\nlabeled data, our methods consistently outperform the state-of-the-art\ncontrast-based methods and other semi-supervised learning techniques.",
    "descriptor": "\nComments: 9 pages, accepted to MICCAI 2021\n",
    "authors": [
      "Xinrong Hu",
      "Dewen Zeng",
      "Xiaowei Xu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07407"
  },
  {
    "id": "arXiv:2109.07409",
    "title": "Sporting the government: Twitter as a window into sportspersons'  engagement with causes in India and USA",
    "abstract": "With the ubiquitous reach of social media, influencers are increasingly\ncentral to articulation of political agendas on a range of topics. We curate a\nsample of tweets from the 200 most followed sportspersons in India and the\nUnited States respectively since 2019, map their connections with politicians,\nand visualize their engagements with key topics online. We find significant\ndifferences between the ways in which Indian and US sportspersons engage with\npolitics online-while leading Indian sportspersons tend to align closely with\nthe ruling party and engage minimally in dissent, American sportspersons engage\nwith a range of political issues and are willing to publicly criticize\npoliticians or policy. Our findings suggest that the ownership and governmental\ncontrol of sports impact public stances on issues that professional\nsportspersons are willing to engage in online. It might also be inferred,\ndepending upon the government of the day, that the costs of speaking up against\nthe state and the government in power have different socio-economic costs in\nthe US and India.",
    "descriptor": "\nComments: 22 pages, 18 images, 2 tables\n",
    "authors": [
      "Dibyendu Mishra",
      "Ronojoy Sen",
      "Joyojeet Pal"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.07409"
  },
  {
    "id": "arXiv:2109.07410",
    "title": "Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked  Claims in a Document",
    "abstract": "Given the recent proliferation of false claims online, there has been a lot\nof manual fact-checking effort. As this is very time-consuming, human\nfact-checkers can benefit from tools that can support them and make them more\nefficient. Here, we focus on building a system that could provide such support.\nGiven an input document, it aims to detect all sentences that contain a claim\nthat can be verified by some previously fact-checked claims (from a given\ndatabase). The output is a re-ranked list of the document sentences, so that\nthose that can be verified are ranked as high as possible, together with\ncorresponding evidence. Unlike previous work, which has looked into claim\nretrieval, here we take a document-level perspective. We create a new manually\nannotated dataset for the task, and we propose suitable evaluation measures. We\nfurther experiment with a learning-to-rank approach, achieving sizable\nperformance gains over several strong baselines. Our analysis demonstrates the\nimportance of modeling text similarity and stance, while also taking into\naccount the veracity of the retrieved previously fact-checked claims. We\nbelieve that this research would be of interest to fact-checkers, journalists,\nmedia, and regulatory authorities.",
    "descriptor": "\nComments: detecting previously fact-checked claims, fact-checking, disinformation, fake news, social media, political debates\n",
    "authors": [
      "Shaden Shaar",
      "Firoj Alam",
      "Giovanni Da San Martino",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07410"
  },
  {
    "id": "arXiv:2109.07411",
    "title": "AliMe MKG: A Multi-modal Knowledge Graph for Live-streaming E-commerce",
    "abstract": "Live streaming is becoming an increasingly popular trend of sales in\nE-commerce. The core of live-streaming sales is to encourage customers to\npurchase in an online broadcasting room. To enable customers to better\nunderstand a product without jumping out, we propose AliMe MKG, a multi-modal\nknowledge graph that aims at providing a cognitive profile for products,\nthrough which customers are able to seek information about and understand a\nproduct. Based on the MKG, we build an online live assistant that highlights\nproduct search, product exhibition and question answering, allowing customers\nto skim over item list, view item details, and ask item-related questions. Our\nsystem has been launched online in the Taobao app, and currently serves\nhundreds of thousands of customers per day.",
    "descriptor": "\nComments: CIKM2021\n",
    "authors": [
      "Guohai Xu",
      "Hehong Chen",
      "Feng-Lin Li",
      "Fu Sun",
      "Yunzhou Shi",
      "Zhixiong Zeng",
      "Wei Zhou",
      "Zhongzhou Zhao",
      "Ji Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07411"
  },
  {
    "id": "arXiv:2109.07419",
    "title": "Union: A Unified HW-SW Co-Design Ecosystem in MLIR for Evaluating Tensor  Operations on Spatial Accelerators",
    "abstract": "To meet the extreme compute demands for deep learning across commercial and\nscientific applications, dataflow accelerators are becoming increasingly\npopular. While these \"domain-specific\" accelerators are not fully programmable\nlike CPUs and GPUs, they retain varying levels of flexibility with respect to\ndata orchestration, i.e., dataflow and tiling optimizations to enhance\nefficiency. There are several challenges when designing new algorithms and\nmapping approaches to execute the algorithms for a target problem on new\nhardware. Previous works have addressed these challenges individually. To\naddress this challenge as a whole, in this work, we present a HW-SW co-design\necosystem for spatial accelerators called Union within the popular MLIR\ncompiler infrastructure. Our framework allows exploring different algorithms\nand their mappings on several accelerator cost models. Union also includes a\nplug-and-play library of accelerator cost models and mappers which can easily\nbe extended. The algorithms and accelerator cost models are connected via a\nnovel mapping abstraction that captures the map space of spatial accelerators\nwhich can be systematically pruned based on constraints from the hardware,\nworkload, and mapper. We demonstrate the value of Union for the community with\nseveral case studies which examine offloading different tensor\noperations(CONV/GEMM/Tensor Contraction) on diverse accelerator architectures\nusing different mapping schemes.",
    "descriptor": "\nComments: This paper is accepted to PACT 2021\n",
    "authors": [
      "Geonhwa Jeong",
      "Gokcen Kestor",
      "Prasanth Chatarasi",
      "Angshuman Parashar",
      "Po-An Tsai",
      "Sivasankaran Rajamanickam",
      "Roberto Gioiosa",
      "Tushar Krishna"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07419"
  },
  {
    "id": "arXiv:2109.07424",
    "title": "SupCL-Seq: Supervised Contrastive Learning for Downstream Optimized  Sequence Representations",
    "abstract": "While contrastive learning is proven to be an effective training strategy in\ncomputer vision, Natural Language Processing (NLP) is only recently adopting it\nas a self-supervised alternative to Masked Language Modeling (MLM) for\nimproving sequence representations. This paper introduces SupCL-Seq, which\nextends the supervised contrastive learning from computer vision to the\noptimization of sequence representations in NLP. By altering the dropout mask\nprobability in standard Transformer architectures, for every representation\n(anchor), we generate augmented altered views. A supervised contrastive loss is\nthen utilized to maximize the system's capability of pulling together similar\nsamples (e.g., anchors and their altered views) and pushing apart the samples\nbelonging to the other classes. Despite its simplicity, SupCLSeq leads to large\ngains in many sequence classification tasks on the GLUE benchmark compared to a\nstandard BERTbase, including 6% absolute improvement on CoLA, 5.4% on MRPC,\n4.7% on RTE and 2.6% on STSB. We also show consistent gains over self\nsupervised contrastively learned representations, especially in non-semantic\ntasks. Finally we show that these gains are not solely due to augmentation, but\nrather to a downstream optimized sequence representation. Code:\nhttps://github.com/hooman650/SupCL-Seq",
    "descriptor": "\nComments: short paper, EMNLP 2021, Findings\n",
    "authors": [
      "Hooman Sedghamiz",
      "Shivam Raval",
      "Enrico Santus",
      "Tuka Alhanai",
      "Mohammad Ghassemi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07424"
  },
  {
    "id": "arXiv:2109.07428",
    "title": "A Wide-area, Low-latency, and Power-efficient 6-DoF Pose Tracking System  for Rigid Objects",
    "abstract": "Position sensitive detectors (PSDs) offer possibility to track single active\nmarker's two (or three) degrees of freedom (DoF) position with a high accuracy,\nwhile having a fast response time with high update frequency and low latency,\nall using a very simple signal processing circuit. However they are not\nparticularly suitable for 6-DoF object pose tracking system due to lack of\norientation measurement, limited tracking range, and sensitivity to\nenvironmental variation. We propose a novel 6-DoF pose tracking system for a\nrigid object tracking requiring a single active marker. The proposed system\nuses a stereo-based PSD pair and multiple Inertial Measurement Units (IMUs).\nThis is done based on a practical approach to identify and control the power of\nInfrared-Light Emitting Diode (IR-LED) active markers, with an aim to increase\nthe tracking work space and reduce the power consumption. Our proposed tracking\nsystem is validated with three different work space sizes and for static and\ndynamic positional accuracy using robotic arm manipulator with three different\ndynamic motion patterns. The results show that the static position\nroot-mean-square (RMS) error is 0.6mm. The dynamic position RMS error is\n0.7-0.9mm. The orientation RMS error is between 0.04 and 0.9 degree at varied\ndynamic motion. Overall, our proposed tracking system is capable of tracking a\nrigid object pose with sub-millimeter accuracy at the mid range of the work\nspace and sub-degree accuracy for all work space under a lab setting.",
    "descriptor": "",
    "authors": [
      "Young-Ho Kim",
      "Ankur Kapoor",
      "Tommaso Mansi",
      "Ali Kamen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07428"
  },
  {
    "id": "arXiv:2109.07429",
    "title": "Towards a Game-Theoretic Security Analysis of Off-Chain Protocols",
    "abstract": "Off-chain protocols constitute one of the most promising approaches to solve\nthe inherent scalability issue of blockchain technologies. The core idea is to\nlet parties transact on-chain only once to establish a channel between them,\nleveraging later on the resulting channel paths to perform arbitrarily many\npeer-to-peer transactions off-chain. While significant progress has been made\nin terms of proof techniques for off-chain protocols, existing approaches do\nnot capture the game-theoretic incentives at the core of their design, which\nled to overlooking significant attack vectors like the Wormhole attack in the\npast.\nThis work introduces the first game-theoretic model that is expressive enough\nto reason about the security of off-chain protocols. We advocate the use of\nExtensive Form Games - EFGs and introduce two instances of EFGs to capture\nsecurity properties of the closing and the routing of the Lightning Network.\nSpecifically, we model the closing protocol, which relies on punishment\nmechanisms to disincentivize the uploading on-chain of old channel states, as\nwell as the routing protocol, thereby formally characterizing the Wormhole\nattack, a vulnerability that undermines the fee-based incentive mechanism\nunderlying the Lightning Network.",
    "descriptor": "",
    "authors": [
      "Sophie Rain",
      "Zeta Avarikioti",
      "Laura Kov\u00e1cs",
      "Matteo Maffei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.07429"
  },
  {
    "id": "arXiv:2109.07431",
    "title": "Contact-Aware Retargeting of Skinned Motion",
    "abstract": "This paper introduces a motion retargeting method that preserves\nself-contacts and prevents interpenetration. Self-contacts, such as when hands\ntouch each other or the torso or the head, are important attributes of human\nbody language and dynamics, yet existing methods do not model or preserve these\ncontacts. Likewise, interpenetration, such as a hand passing into the torso,\nare a typical artifact of motion estimation methods. The input to our method is\na human motion sequence and a target skeleton and character geometry. The\nmethod identifies self-contacts and ground contacts in the input motion, and\noptimizes the motion to apply to the output skeleton, while preserving these\ncontacts and reducing interpenetration. We introduce a novel\ngeometry-conditioned recurrent network with an encoder-space optimization\nstrategy that achieves efficient retargeting while satisfying contact\nconstraints. In experiments, our results quantitatively outperform previous\nmethods and we conduct a user study where our retargeted motions are rated as\nhigher-quality than those produced by recent works. We also show our method\ngeneralizes to motion estimated from human videos where we improve over\nprevious works that produce noticeable interpenetration.",
    "descriptor": "\nComments: International Conference on Computer Vision (ICCV)\n",
    "authors": [
      "Ruben Villegas",
      "Duygu Ceylan",
      "Aaron Hertzmann",
      "Jimei Yang",
      "Jun Saito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.07431"
  },
  {
    "id": "arXiv:2109.07433",
    "title": "Encoding and Decoding with Partitioned Complementary Sequences for  Low-PAPR OFDM",
    "abstract": "In this study, we propose partitioned complementary sequences (CSs) where the\ngaps between the clusters encode information bits to achieve low\npeak-to-average-power ratio (PAPR) orthogonal frequency division multiplexing\n(OFDM) symbols. We show that the partitioning rule without losing the feature\nof being a CS coincides with the non-squashing partitions of a positive integer\nand leads to a symmetric separation of clusters. We analytically derive the\nnumber of partitioned CSs for given bandwidth and a minimum distance constraint\nand obtain the corresponding recursive methods for enumerating the values of\nseparations. We show that partitioning can increase the spectral efficiency\n(SE) without changing the alphabet of the nonzero elements of the CS, i.e.,\nstandard CSs relying on Reed-Muller (RM) code. We also develop an encoder for\npartitioned CSs and a maximum-likelihood-based recursive decoder for additive\nwhite Gaussian noise (AWGN) and fading channels. Our results indicate that the\npartitioned CSs under a minimum distance constraint can perform similar to the\nstandard CSs in terms of average block error rate (BLER) and provide a higher\nSE at the expense of a limited signal-to-noise ratio (SNR) loss.",
    "descriptor": "\nComments: 13 pages, to appear in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Alphan Sahin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.07433"
  },
  {
    "id": "arXiv:2109.07434",
    "title": "Discriminative and Generative Transformer-based Models For Situation  Entity Classification",
    "abstract": "We re-examine the situation entity (SE) classification task with varying\namounts of available training data. We exploit a Transformer-based variational\nautoencoder to encode sentences into a lower dimensional latent space, which is\nused to generate the text and learn a SE classifier. Test set and cross-genre\nevaluations show that when training data is plentiful, the proposed model can\nimprove over the previous discriminative state-of-the-art models. Our approach\nperforms disproportionately better with smaller amounts of training data, but\nwhen faced with extremely small sets (4 instances per label), generative RNN\nmethods outperform transformers. Our work provides guidance for future efforts\non SE and semantic prediction tasks, and low-label training regimes.",
    "descriptor": "",
    "authors": [
      "Mehdi Rezaee",
      "Kasra Darvish",
      "Gaoussou Youssouf Kebe",
      "Francis Ferraro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07434"
  },
  {
    "id": "arXiv:2109.07436",
    "title": "Synthesizing Policies That Account For Human Execution Errors Caused By  StateAliasing In Markov Decision Processes",
    "abstract": "When humans are given a policy to execute, there can be pol-icy execution\nerrors and deviations in execution if there is un-certainty in identifying a\nstate. So an algorithm that computesa policy for a human to execute ought to\nconsider these effectsin its computations. An optimal MDP policy that is poorly\nex-ecuted (because of a human agent) maybe much worse thananother policy that\nis executed with fewer errors. In this pa-per, we consider the problems of\nerroneous execution and ex-ecution delay when computing policies for a human\nagent thatwould act in a setting modeled by a Markov Decision Process(MDP). We\npresent a framework to model the likelihood ofpolicy execution errors and\nlikelihood of non-policy actionslike inaction (delays) due to state\nuncertainty. This is followedby a hill climbing algorithm to search for good\npolicies thataccount for these errors. We then use the best policy found byhill\nclimbing with a branch and bound algorithm to find theoptimal policy. We show\nexperimental results in a Gridworlddomain and analyze the performance of the\ntwo algorithms.We also present human studies that verify if our assumptionson\npolicy execution by humans under state-aliasing are rea-sonable.",
    "descriptor": "\nComments: 7 page paper, 6 pages supplemental material\n",
    "authors": [
      "Sriram Gopalakrishnan",
      "Mudit Verma",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07436"
  },
  {
    "id": "arXiv:2109.07437",
    "title": "Should We Be Pre-training? An Argument for End-task Aware Training as an  Alternative",
    "abstract": "Pre-training, where models are trained on an auxiliary objective with\nabundant data before being fine-tuned on data from the downstream task, is now\nthe dominant paradigm in NLP. In general, the pre-training step relies on\nlittle to no direct knowledge of the task on which the model will be\nfine-tuned, even when the end-task is known in advance. Our work challenges\nthis status-quo of end-task agnostic pre-training. First, on three different\nlow-resource NLP tasks from two domains, we demonstrate that multi-tasking the\nend-task and auxiliary objectives results in significantly better downstream\ntask performance than the widely-used task-agnostic continued pre-training\nparadigm of Gururangan et al. (2020). We next introduce an online meta-learning\nalgorithm that learns a set of multi-task weights to better balance among our\nmultiple auxiliary objectives, achieving further improvements on end task\nperformance and data efficiency.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Lucio M. Dery",
      "Paul Michel",
      "Ameet Talwalkar",
      "Graham Neubig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07437"
  },
  {
    "id": "arXiv:2109.07438",
    "title": "CAMul: Calibrated and Accurate Multi-view Time-Series Forecasting",
    "abstract": "Probabilistic time-series forecasting enables reliable decision making across\nmany domains. Most forecasting problems have diverse sources of data containing\nmultiple modalities and structures. Leveraging information as well as\nuncertainty from these data sources for well-calibrated and accurate forecasts\nis an important challenging problem. Most previous work on multi-modal learning\nand forecasting simply aggregate intermediate representations from each data\nview by simple methods of summation or concatenation and do not explicitly\nmodel uncertainty for each data-view. We propose a general probabilistic\nmulti-view forecasting framework CAMul, that can learn representations and\nuncertainty from diverse data sources. It integrates the knowledge and\nuncertainty from each data view in a dynamic context-specific manner assigning\nmore importance to useful views to model a well-calibrated forecast\ndistribution. We use CAMul for multiple domains with varied sources and\nmodalities and show that CAMul outperforms other state-of-art probabilistic\nforecasting models by over 25\\% in accuracy and calibration.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Harshavardhan Kamarthi",
      "Lingkai Kong",
      "Alexander Rodr\u00edguez",
      "Chao Zhang",
      "B. Aditya Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.07438"
  },
  {
    "id": "arXiv:2109.07439",
    "title": "Is \"moby dick\" a Whale or a Bird? Named Entities and Terminology in  Speech Translation",
    "abstract": "Automatic translation systems are known to struggle with rare words. Among\nthese, named entities (NEs) and domain-specific terms are crucial, since errors\nin their translation can lead to severe meaning distortions. Despite their\nimportance, previous speech translation (ST) studies have neglected them, also\ndue to the dearth of publicly available resources tailored to their specific\nevaluation. To fill this gap, we i) present the first systematic analysis of\nthe behavior of state-of-the-art ST systems in translating NEs and terminology,\nand ii) release NEuRoparl-ST, a novel benchmark built from European Parliament\nspeeches annotated with NEs and terminology. Our experiments on the three\nlanguage directions covered by our benchmark (en->es/fr/it) show that ST\nsystems correctly translate 75-80% of terms and 65-70% of NEs, with very low\nperformance (37-40%) on person names.",
    "descriptor": "\nComments: Accepted at EMNLP2021\n",
    "authors": [
      "Marco Gaido",
      "Susana Rodr\u00edguez",
      "Matteo Negri",
      "Luisa Bentivogli",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07439"
  },
  {
    "id": "arXiv:2109.07440",
    "title": "Private Attacks in Longest Chain Proof-of-stake Protocols with Single  Secret Leader Elections",
    "abstract": "Single Secret Leader Elections have recently been proposed as an improved\nleader election mechanism for proof-of-stake (PoS) blockchains. However, the\nsecurity gain they provide has not been quantified. In this work, we present a\ncomparison of PoS longest-chain protocols that are based on Single Secret\nLeader Elections (SSLE) - that elect exactly one leader per round - versus\nthose based on Probabilistic Leader Elections (PLE) - where one leader is\nelected on expectation. Our analysis shows that when considering the private\nattack - the worst attack on longest-chain protocols - the security gained from\nusing SSLE is substantial: the settlement time is decreased by roughly 25% for\na 33% or 25% adversary. Furthermore, when considering grinding attacks, we find\nthat the security threshold is increased by 10% (from 0.26 in the PLE case to\n0.36 inthe SSLE case) and the settlement time is decreased by roughly 70% for a\n20% adversary in the SSLE case.",
    "descriptor": "\nComments: To appear in the proceedings of the 3rd ACM Conference on Advances in Financial Technologies\n",
    "authors": [
      "Sarah Azouvi",
      "Daniele Cappelletti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.07440"
  },
  {
    "id": "arXiv:2109.07441",
    "title": "DPGen: Automated Program Synthesis for Differential Privacy",
    "abstract": "Differential privacy has become a de facto standard for releasing data in a\nprivacy-preserving way. Creating a differentially private algorithm is a\nprocess that often starts with a noise-free (non-private) algorithm. The\ndesigner then decides where to add noise, and how much of it to add. This can\nbe a non-trivial process -- if not done carefully, the algorithm might either\nviolate differential privacy or have low utility.\nIn this paper, we present DPGen, a program synthesizer that takes in\nnon-private code (without any noise) and automatically synthesizes its\ndifferentially private version (with carefully calibrated noise). Under the\nhood, DPGen uses novel algorithms to automatically generate a sketch program\nwith candidate locations for noise, and then optimize privacy proof and noise\nscales simultaneously on the sketch program. Moreover, DPGen can synthesize\nsophisticated mechanisms that adaptively process queries until a specified\nprivacy budget is exhausted. When evaluated on standard benchmarks, DPGen is\nable to generate differentially private mechanisms that optimize simple utility\nfunctions within 120 seconds. It is also powerful enough to synthesize adaptive\nprivacy mechanisms.",
    "descriptor": "\nComments: CCS'21\n",
    "authors": [
      "Yuxin Wang",
      "Zeyu Ding",
      "Yingtai Xiao",
      "Daniel Kifer",
      "Danfeng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.07441"
  },
  {
    "id": "arXiv:2109.07445",
    "title": "Challenges in Detoxifying Language Models",
    "abstract": "Large language models (LM) generate remarkably fluent text and can be\nefficiently adapted across NLP tasks. Measuring and guaranteeing the quality of\ngenerated text in terms of safety is imperative for deploying LMs in the real\nworld; to this end, prior work often relies on automatic evaluation of LM\ntoxicity. We critically discuss this approach, evaluate several toxicity\nmitigation strategies with respect to both automatic and human evaluation, and\nanalyze consequences of toxicity mitigation in terms of model bias and LM\nquality. We demonstrate that while basic intervention strategies can\neffectively optimize previously established automatic metrics on the\nRealToxicityPrompts dataset, this comes at the cost of reduced LM coverage for\nboth texts about, and dialects of, marginalized groups. Additionally, we find\nthat human raters often disagree with high automatic toxicity scores after\nstrong toxicity reduction interventions -- highlighting further the nuances\ninvolved in careful evaluation of LM toxicity.",
    "descriptor": "\nComments: 23 pages, 6 figures, published in Findings of EMNLP 2021\n",
    "authors": [
      "Johannes Welbl",
      "Amelia Glaese",
      "Jonathan Uesato",
      "Sumanth Dathathri",
      "John Mellor",
      "Lisa Anne Hendricks",
      "Kirsty Anderson",
      "Pushmeet Kohli",
      "Ben Coppin",
      "Po-Sen Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07445"
  },
  {
    "id": "arXiv:2109.07446",
    "title": "When Does Translation Require Context? A Data-driven, Multilingual  Exploration",
    "abstract": "Although proper handling of discourse phenomena significantly contributes to\nthe quality of machine translation (MT), common translation quality metrics do\nnot adequately capture them. Recent works in context-aware MT attempt to target\na small set of these phenomena during evaluation. In this paper, we propose a\nnew metric, P-CXMI, which allows us to identify translations that require\ncontext systematically and confirm the difficulty of previously studied\nphenomena as well as uncover new ones that have not been addressed in previous\nwork. We then develop the Multilingual Discourse-Aware (MuDA) benchmark, a\nseries of taggers for these phenomena in 14 different language pairs, which we\nuse to evaluate context-aware MT. We find that state-of-the-art context-aware\nMT models find marginal improvements over context-agnostic models on our\nbenchmark, which suggests current models do not handle these ambiguities\neffectively. We release code and data to invite the MT research community to\nincrease efforts on context-aware translation on discourse phenomena and\nlanguages that are currently overlooked.",
    "descriptor": "",
    "authors": [
      "Kayo Yin",
      "Patrick Fernandes",
      "Andr\u00e9 F. T. Martins",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07446"
  },
  {
    "id": "arXiv:2109.07448",
    "title": "Neural Human Performer: Learning Generalizable Radiance Fields for Human  Performance Rendering",
    "abstract": "In this paper, we aim at synthesizing a free-viewpoint video of an arbitrary\nhuman performance using sparse multi-view cameras. Recently, several works have\naddressed this problem by learning person-specific neural radiance fields\n(NeRF) to capture the appearance of a particular human. In parallel, some work\nproposed to use pixel-aligned features to generalize radiance fields to\narbitrary new scenes and objects. Adopting such generalization approaches to\nhumans, however, is highly challenging due to the heavy occlusions and dynamic\narticulations of body parts. To tackle this, we propose Neural Human Performer,\na novel approach that learns generalizable neural radiance fields based on a\nparametric human body model for robust performance capture. Specifically, we\nfirst introduce a temporal transformer that aggregates tracked visual features\nbased on the skeletal body motion over time. Moreover, a multi-view transformer\nis proposed to perform cross-attention between the temporally-fused features\nand the pixel-aligned features at each time step to integrate observations on\nthe fly from multiple views. Experiments on the ZJU-MoCap and AIST datasets\nshow that our method significantly outperforms recent generalizable NeRF\nmethods on unseen identities and poses. The video results and code are\navailable at https://youngjoongunc.github.io/nhp.",
    "descriptor": "",
    "authors": [
      "Youngjoong Kwon",
      "Dahun Kim",
      "Duygu Ceylan",
      "Henry Fuchs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.07448"
  },
  {
    "id": "arXiv:2109.07449",
    "title": "WikiGUM: Exhaustive Entity Linking for Wikification in 12 Genres",
    "abstract": "Previous work on Entity Linking has focused on resources targeting non-nested\nproper named entity mentions, often in data from Wikipedia, i.e. Wikification.\nIn this paper, we present and evaluate WikiGUM, a fully wikified dataset,\ncovering all mentions of named entities, including their non-named and\npronominal mentions, as well as mentions nested within other mentions. The\ndataset covers a broad range of 12 written and spoken genres, most of which\nhave not been included in Entity Linking efforts to date, leading to poor\nperformance by a pretrained SOTA system in our evaluation. The availability of\na variety of other annotations for the same data also enables further research\non entities in context.",
    "descriptor": "",
    "authors": [
      "Jessica Lin",
      "Amir Zeldes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07449"
  },
  {
    "id": "arXiv:2109.07452",
    "title": "Can Machines Read Coding Manuals Yet? -- A Benchmark for Building Better  Language Models for Code Understanding",
    "abstract": "Code understanding is an increasingly important application of Artificial\nIntelligence. A fundamental aspect of understanding code is understanding text\nabout code, e.g., documentation and forum discussions. Pre-trained language\nmodels (e.g., BERT) are a popular approach for various NLP tasks, and there are\nnow a variety of benchmarks, such as GLUE, to help improve the development of\nsuch models for natural language understanding. However, little is known about\nhow well such models work on textual artifacts about code, and we are unaware\nof any systematic set of downstream tasks for such an evaluation. In this\npaper, we derive a set of benchmarks (BLANCA - Benchmarks for LANguage models\non Coding Artifacts) that assess code understanding based on tasks such as\npredicting the best answer to a question in a forum post, finding related forum\nposts, or predicting classes related in a hierarchy from class documentation.\nWe evaluate the performance of current state-of-the-art language models on\nthese tasks and show that there is a significant improvement on each task from\nfine tuning. We also show that multi-task training over BLANCA tasks helps\nbuild better language models for code understanding.",
    "descriptor": "",
    "authors": [
      "Ibrahim Abdelaziz",
      "Julian Dolby",
      "Jamie McCusker",
      "Kavitha Srinivas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07452"
  },
  {
    "id": "arXiv:2109.07455",
    "title": "Deep Bregman Divergence for Contrastive Learning of Visual  Representations",
    "abstract": "Deep Bregman divergence measures divergence of data points using neural\nnetworks which is beyond Euclidean distance and capable of capturing divergence\nover distributions. In this paper, we propose deep Bregman divergences for\ncontrastive learning of visual representation and we aim to enhance contrastive\nloss used in self-supervised learning by training additional networks based on\nfunctional Bregman divergence. In contrast to the conventional contrastive\nlearning methods which are solely based on divergences between single points,\nour framework can capture the divergence between distributions which improves\nthe quality of learned representation. By combining conventional contrastive\nloss with the proposed divergence loss, our method outperforms baseline and\nmost of previous methods for self-supervised and semi-supervised learning on\nmultiple classifications and object detection tasks and datasets. The source\ncode of the method and of all the experiments are available at supplementary.",
    "descriptor": "",
    "authors": [
      "Mina Rezaei",
      "Farzin Soleymani",
      "Bernd Bischl",
      "Shekoofeh Azizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07455"
  },
  {
    "id": "arXiv:2109.07458",
    "title": "Comparing Text Representations: A Theory-Driven Approach",
    "abstract": "Much of the progress in contemporary NLP has come from learning\nrepresentations, such as masked language model (MLM) contextual embeddings,\nthat turn challenging problems into simple classification tasks. But how do we\nquantify and explain this effect? We adapt general tools from computational\nlearning theory to fit the specific characteristics of text datasets and\npresent a method to evaluate the compatibility between representations and\ntasks. Even though many tasks can be easily solved with simple bag-of-words\n(BOW) representations, BOW does poorly on hard natural language inference\ntasks. For one such task we find that BOW cannot distinguish between real and\nrandomized labelings, while pre-trained MLM representations show 72x greater\ndistinction between real and random labelings than BOW. This method provides a\ncalibrated, quantitative measure of the difficulty of a classification-based\nNLP task, enabling comparisons between representations without requiring\nempirical evaluations that may be sensitive to initializations and\nhyperparameters. The method provides a fresh perspective on the patterns in a\ndataset and the alignment of those patterns with specific labels.",
    "descriptor": "",
    "authors": [
      "Gregory Yauney",
      "David Mimno"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07458"
  },
  {
    "id": "arXiv:2109.07459",
    "title": "Timely Updating with Intermittent Energy and Data for Multiple Sources  over Erasure Channels",
    "abstract": "A status updating system is considered in which multiple data sources\ngenerate packets to be delivered to a destination through a shared energy\nharvesting sensor. Only one source's data, when available, can be transmitted\nby the sensor at a time, subject to energy availability. Transmissions are\nprune to erasures, and each successful transmission constitutes a status update\nfor its corresponding source at the destination. The goal is to schedule source\ntransmissions such that the collective long-term average age-of-information\n(AoI) is minimized. AoI is defined as the time elapsed since the latest\nsuccessfully-received data has been generated at its source. To solve this\nproblem, the case with a single source is first considered, with a focus on\nthreshold waiting policies, in which the sensor attempts transmission only if\nthe time until both energy and data are available grows above a certain\nthreshold. The distribution of the AoI is fully characterized under such a\npolicy. This is then used to analyze the performance of the multiple sources\ncase under maximum-age-first scheduling, in which the sensor's resources are\ndedicated to the source with the maximum AoI at any given time. The achievable\ncollective long-term average AoI is derived in closed-form. Multiple numerical\nevaluations are demonstrated to show how the optimal threshold value behaves as\na function of the system parameters, and showcase the benefits of a\nthreshold-based waiting policy with intermittent energy and data arrivals.",
    "descriptor": "\nComments: Appeared in the International Symposium on Wireless Communication Systems (ISWCS) 2021, special session on Age of Information\n",
    "authors": [
      "Christopher Daniel Jr.",
      "Ahmed Arafa"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.07459"
  },
  {
    "id": "arXiv:2109.07460",
    "title": "Efficient Domain Adaptation of Language Models via Adaptive Tokenization",
    "abstract": "Contextual embedding-based language models trained on large data sets, such\nas BERT and RoBERTa, provide strong performance across a wide range of tasks\nand are ubiquitous in modern NLP. It has been observed that fine-tuning these\nmodels on tasks involving data from domains different from that on which they\nwere pretrained can lead to suboptimal performance. Recent work has explored\napproaches to adapt pretrained language models to new domains by incorporating\nadditional pretraining using domain-specific corpora and task data. We propose\nan alternative approach for transferring pretrained language models to new\ndomains by adapting their tokenizers. We show that domain-specific subword\nsequences can be efficiently determined directly from divergences in the\nconditional token distributions of the base and domain-specific corpora. In\ndatasets from four disparate domains, we find adaptive tokenization on a\npretrained RoBERTa model provides >97% of the performance benefits of domain\nspecific pretraining. Our approach produces smaller models and less training\nand inference time than other approaches using tokenizer augmentation. While\nadaptive tokenization incurs a 6% increase in model parameters in our\nexperimentation, due to the introduction of 10k new domain-specific tokens, our\napproach, using 64 vCPUs, is 72x faster than further pretraining the language\nmodel on domain-specific corpora on 8 TPUs.",
    "descriptor": "\nComments: 11 pages. SustaiNLP workshop at EMNLP 2021\n",
    "authors": [
      "Vin Sachidananda",
      "Jason S. Kessler",
      "Yi-an Lai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07460"
  },
  {
    "id": "arXiv:2109.07461",
    "title": "MPC-Friendly Commitments for Publicly Verifiable Covert Security",
    "abstract": "We address the problem of efficiently verifying a commitment in a two-party\ncomputation. This addresses the scenario where a party P1 commits to a value\n$x$ to be used in a subsequent secure computation with another party P2 that\nwants to receive assurance that P1 did not cheat, i.e. that $x$ was indeed the\nvalue inputted into the secure computation. Our constructions operate in the\npublicly verifiable covert (PVC) security model, which is a relaxation of the\nmalicious model of MPC appropriate in settings where P1 faces a reputational\nharm if caught cheating.\nWe introduce the notion of PVC commitment scheme and indexed hash functions\nto build commitments schemes tailored to the PVC framework, and propose\nconstructions for both arithmetic and Boolean circuits that result in very\nefficient circuits. From a practical standpoint, our constructions for Boolean\ncircuits are $60\\times$ faster to evaluate securely, and use $36\\times$ less\ncommunication than baseline methods based on hashing. Moreover, we show that\nour constructions are tight in terms of required non-linear operations, by\nproving lower bounds on the nonlinear gate count of commitment verification\ncircuits. Finally, we present a technique to amplify the security properties\nour constructions that allows to efficiently recover malicious guarantees with\nstatistical security.",
    "descriptor": "\nComments: To appear at ACM CCS 2021\n",
    "authors": [
      "Nitin Agrawal",
      "James Bell",
      "Adri\u00e0 Gasc\u00f3n",
      "Matt J. Kusner"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07461"
  },
  {
    "id": "arXiv:2109.07464",
    "title": "AnnIE: An Annotation Platform for Constructing Complete Open Information  Extraction Benchmark",
    "abstract": "Open Information Extraction (OIE) is the task of extracting facts from\nsentences in the form of relations and their corresponding arguments in\nschema-free manner. Intrinsic performance of OIE systems is difficult to\nmeasure due to the incompleteness of existing OIE benchmarks: the ground truth\nextractions do not group all acceptable surface realizations of the same fact\nthat can be extracted from a sentence. To measure performance of OIE systems\nmore realistically, it is necessary to manually annotate complete facts (i.e.,\nclusters of all acceptable surface realizations of the same fact) from input\nsentences. We propose AnnIE: an interactive annotation platform that\nfacilitates such challenging annotation tasks and supports creation of complete\nfact-oriented OIE evaluation benchmarks. AnnIE is modular and flexible in order\nto support different use case scenarios (i.e., benchmarks covering different\ntypes of facts). We use AnnIE to build two complete OIE benchmarks: one with\nverb-mediated facts and another with facts encompassing named entities.\nFinally, we evaluate several OIE systems on our complete benchmarks created\nwith AnnIE. Our results suggest that existing incomplete benchmarks are overly\nlenient, and that OIE systems are not as robust as previously reported. We\npublicly release AnnIE under non-restrictive license.",
    "descriptor": "",
    "authors": [
      "Niklas Friedrich",
      "Kiril Gashteovski",
      "Mingying Yu",
      "Bhushan Kotnis",
      "Carolin Lawrence",
      "Mathias Niepert",
      "Goran Glava\u0161"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07464"
  },
  {
    "id": "arXiv:2109.07465",
    "title": "On the Limits of Minimal Pairs in Contrastive Evaluation",
    "abstract": "Minimal sentence pairs are frequently used to analyze the behavior of\nlanguage models. It is often assumed that model behavior on contrastive pairs\nis predictive of model behavior at large. We argue that two conditions are\nnecessary for this assumption to hold: First, a tested hypothesis should be\nwell-motivated, since experiments show that contrastive evaluation can lead to\nfalse positives. Secondly, test data should be chosen such as to minimize\ndistributional discrepancy between evaluation time and deployment time. For a\ngood approximation of deployment-time decoding, we recommend that minimal pairs\nare created based on machine-generated text, as opposed to human-written\nreferences. We present a contrastive evaluation suite for English-German MT\nthat implements this recommendation.",
    "descriptor": "\nComments: BlackboxNLP 2021\n",
    "authors": [
      "Jannis Vamvas",
      "Rico Sennrich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07465"
  },
  {
    "id": "arXiv:2109.06909",
    "title": "Hardware-aware Real-time Myocardial Segmentation Quality Control in  Contrast Echocardiography",
    "abstract": "Automatic myocardial segmentation of contrast echocardiography has shown\ngreat potential in the quantification of myocardial perfusion parameters.\nSegmentation quality control is an important step to ensure the accuracy of\nsegmentation results for quality research as well as its clinical application.\nUsually, the segmentation quality control happens after the data acquisition.\nAt the data acquisition time, the operator could not know the quality of the\nsegmentation results. On-the-fly segmentation quality control could help the\noperator to adjust the ultrasound probe or retake data if the quality is\nunsatisfied, which can greatly reduce the effort of time-consuming manual\ncorrection. However, it is infeasible to deploy state-of-the-art DNN-based\nmodels because the segmentation module and quality control module must fit in\nthe limited hardware resource on the ultrasound machine while satisfying strict\nlatency constraints. In this paper, we propose a hardware-aware neural\narchitecture search framework for automatic myocardial segmentation and quality\ncontrol of contrast echocardiography. We explicitly incorporate the hardware\nlatency as a regularization term into the loss function during training. The\nproposed method searches the best neural network architecture for the\nsegmentation module and quality prediction module with strict latency.",
    "descriptor": "\nComments: 4 pages, DAC'21 invited paper\n",
    "authors": [
      "Dewen Zeng",
      "Yukun Ding",
      "Haiyun Yuan",
      "Meiping Huang",
      "Xiaowei Xu",
      "Jian Zhuang",
      "Jingtong Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.06909"
  },
  {
    "id": "arXiv:2109.06911",
    "title": "Learning and Decision-Making with Data: Optimal Formulations and Phase  Transitions",
    "abstract": "We study the problem of designing optimal learning and decision-making\nformulations when only historical data is available. Prior work typically\ncommits to a particular class of data-driven formulation and subsequently tries\nto establish out-of-sample performance guarantees. We take here the opposite\napproach. We define first a sensible yard stick with which to measure the\nquality of any data-driven formulation and subsequently seek to find an optimal\nsuch formulation. Informally, any data-driven formulation can be seen to\nbalance a measure of proximity of the estimated cost to the actual cost while\nguaranteeing a level of out-of-sample performance. Given an acceptable level of\nout-of-sample performance, we construct explicitly a data-driven formulation\nthat is uniformly closer to the true cost than any other formulation enjoying\nthe same out-of-sample performance. We show the existence of three distinct\nout-of-sample performance regimes (a superexponential regime, an exponential\nregime and a subexponential regime) between which the nature of the optimal\ndata-driven formulation experiences a phase transition. The optimal data-driven\nformulations can be interpreted as a classically robust formulation in the\nsuperexponential regime, an entropic distributionally robust formulation in the\nexponential regime and finally a variance penalized formulation in the\nsubexponential regime. This final observation unveils a surprising connection\nbetween these three, at first glance seemingly unrelated, data-driven\nformulations which until now remained hidden.",
    "descriptor": "",
    "authors": [
      "M. Amine Bennouna",
      "Bart P.G. Van Parys"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2109.06911"
  },
  {
    "id": "arXiv:2109.06912",
    "title": "fairseq S^2: A Scalable and Integrable Speech Synthesis Toolkit",
    "abstract": "This paper presents fairseq S^2, a fairseq extension for speech synthesis. We\nimplement a number of autoregressive (AR) and non-AR text-to-speech models, and\ntheir multi-speaker variants. To enable training speech synthesis models with\nless curated data, a number of preprocessing tools are built and their\nimportance is shown empirically. To facilitate faster iteration of development\nand analysis, a suite of automatic metrics is included. Apart from the features\nadded specifically for this extension, fairseq S^2 also benefits from the\nscalability offered by fairseq and can be easily integrated with other\nstate-of-the-art systems provided in this framework. The code, documentation,\nand pre-trained models are available at\nhttps://github.com/pytorch/fairseq/tree/master/examples/speech_synthesis.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 Demo\n",
    "authors": [
      "Changhan Wang",
      "Wei-Ning Hsu",
      "Yossi Adi",
      "Adam Polyak",
      "Ann Lee",
      "Peng-Jen Chen",
      "Jiatao Gu",
      "Juan Pino"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.06912"
  },
  {
    "id": "arXiv:2109.06915",
    "title": "Reconstruction on Trees and Low-Degree Polynomials",
    "abstract": "The study of Markov processes and broadcasting on trees has deep connections\nto a variety of areas including statistical physics, phylogenetic\nreconstruction, MCMC algorithms, and community detection in random graphs.\nNotably, the celebrated Belief Propagation (BP) algorithm achieves\nBayes-optimal performance for the reconstruction problem of predicting the\nvalue of the Markov process at the root of the tree from its values at the\nleaves.\nRecently, the analysis of low-degree polynomials has emerged as a valuable\ntool for predicting computational-to-statistical gaps. In this work, we\ninvestigate the performance of low-degree polynomials for the reconstruction\nproblem on trees. Perhaps surprisingly, we show that there are simple tree\nmodels with $N$ leaves where (1) nontrivial reconstruction of the root value is\npossible with a simple polynomial time algorithm and with robustness to noise,\nbut not with any polynomial of degree $N^{c}$ for $c > 0$ a constant, and (2)\nwhen the tree is unknown and given multiple samples with correlated root\nassignments, nontrivial reconstruction of the root value is possible with a\nsimple, noise-robust, and computationally efficient SQ (Statistical Query)\nalgorithm but not with any polynomial of degree $N^c$. These results clarify\nsome of the limitations of low-degree polynomials vs. polynomial time\nalgorithms for Bayesian estimation problems. They also complement recent work\nof Moitra, Mossel, and Sandon who studied the circuit complexity of Belief\nPropagation. We pose related open questions about low-degree polynomials and\nthe Kesten-Stigum threshold.",
    "descriptor": "\nComments: 20 pages, comments welcome\n",
    "authors": [
      "Frederic Koehler",
      "Elchanan Mossel"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2109.06915"
  },
  {
    "id": "arXiv:2109.06917",
    "title": "Open Problems Related to Quantum Query Complexity",
    "abstract": "I offer a case that quantum query complexity still has loads of enticing and\nfundamental open problems -- from relativized QMA versus QCMA and BQP versus\nIP, to time/space tradeoffs for collision and element distinctness, to\npolynomial degree versus quantum query complexity for partial functions, to the\nUnitary Synthesis Problem and more.",
    "descriptor": "\nComments: 11 pages, to appear in ACM Transactions on Quantum Computing\n",
    "authors": [
      "Scott Aaronson"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2109.06917"
  },
  {
    "id": "arXiv:2109.06949",
    "title": "Targeted Cross-Validation",
    "abstract": "In many applications, we have access to the complete dataset but are only\ninterested in the prediction of a particular region of predictor variables. A\nstandard approach is to find the globally best modeling method from a set of\ncandidate methods. However, it is perhaps rare in reality that one candidate\nmethod is uniformly better than the others. A natural approach for this\nscenario is to apply a weighted $L_2$ loss in performance assessment to reflect\nthe region-specific interest. We propose a targeted cross-validation (TCV) to\nselect models or procedures based on a general weighted $L_2$ loss. We show\nthat the TCV is consistent in selecting the best performing candidate under the\nweighted $L_2$ loss. Experimental studies are used to demonstrate the use of\nTCV and its potential advantage over the global CV or the approach of using\nonly local data for modeling a local region.\nPrevious investigations on CV have relied on the condition that when the\nsample size is large enough, the ranking of two candidates stays the same.\nHowever, in many applications with the setup of changing data-generating\nprocesses or highly adaptive modeling methods, the relative performance of the\nmethods is not static as the sample size varies. Even with a fixed\ndata-generating process, it is possible that the ranking of two methods\nswitches infinitely many times. In this work, we broaden the concept of the\nselection consistency by allowing the best candidate to switch as the sample\nsize varies, and then establish the consistency of the TCV. This flexible\nframework can be applied to high-dimensional and complex machine learning\nscenarios where the relative performances of modeling procedures are dynamic.",
    "descriptor": "",
    "authors": [
      "Jiawei Zhang",
      "Jie Ding",
      "Yuhong Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06949"
  },
  {
    "id": "arXiv:2109.06972",
    "title": "Combining GEDI and Sentinel-2 for wall-to-wall mapping of tall and short  crops",
    "abstract": "High resolution crop type maps are an important tool for improving food\nsecurity, and remote sensing is increasingly used to create such maps in\nregions that possess ground truth labels for model training. However, these\nlabels are absent in many regions, and models trained in other regions on\ntypical satellite features, such as those from optical sensors, often exhibit\nlow performance when transferred. Here we explore the use of NASA's Global\nEcosystem Dynamics Investigation (GEDI) spaceborne lidar instrument, combined\nwith Sentinel-2 optical data, for crop type mapping. Using data from three\nmajor cropped regions (in China, France, and the United States) we first\ndemonstrate that GEDI energy profiles are capable of reliably distinguishing\nmaize, a crop typically above 2m in height, from crops like rice and soybean\nthat are shorter. We further show that these GEDI profiles provide much more\ninvariant features across geographies compared to spectral and phenological\nfeatures detected by passive optical sensors. GEDI is able to distinguish maize\nfrom other crops within each region with accuracies higher than 84%, and able\nto transfer across regions with accuracies higher than 82% compared to 64% for\ntransfer of optical features. Finally, we show that GEDI profiles can be used\nto generate training labels for models based on optical imagery from\nSentinel-2, thereby enabling the creation of 10m wall-to-wall maps of tall\nversus short crops in label-scarce regions. As maize is the second most widely\ngrown crop in the world and often the only tall crop grown within a landscape,\nwe conclude that GEDI offers great promise for improving global crop type maps.",
    "descriptor": "",
    "authors": [
      "Stefania Di Tommaso",
      "Sherrie Wang",
      "David B. Lobell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06972"
  },
  {
    "id": "arXiv:2109.06996",
    "title": "Scalable Average Consensus with Compressed Communications",
    "abstract": "We propose a new decentralized average consensus algorithm with compressed\ncommunication that scales linearly with the network size n. We prove that the\nproposed method converges to the average of the initial values held locally by\nthe agents of a network when agents are allowed to communicate with compressed\nmessages. The proposed algorithm works for a broad class of compression\noperators (possibly biased), where agents interact over arbitrary static,\nundirected, and connected networks. We further present numerical experiments\nthat confirm our theoretical results and illustrate the scalability and\ncommunication efficiency of our algorithm.",
    "descriptor": "",
    "authors": [
      "Mohammad Taha Toghani",
      "C\u00e9sar A. Uribe"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.06996"
  },
  {
    "id": "arXiv:2109.07005",
    "title": "WaveCorr: Correlation-savvy Deep Reinforcement Learning for Portfolio  Management",
    "abstract": "The problem of portfolio management represents an important and challenging\nclass of dynamic decision making problems, where rebalancing decisions need to\nbe made over time with the consideration of many factors such as investors\npreferences, trading environments, and market conditions. In this paper, we\npresent a new portfolio policy network architecture for deep reinforcement\nlearning (DRL)that can exploit more effectively cross-asset dependency\ninformation and achieve better performance than state-of-the-art architectures.\nIn particular, we introduce a new property, referred to as \\textit{asset\npermutation invariance}, for portfolio policy networks that exploit multi-asset\ntime series data, and design the first portfolio policy network, named\nWaveCorr, that preserves this invariance property when treating asset\ncorrelation information. At the core of our design is an innovative permutation\ninvariant correlation processing layer. An extensive set of experiments are\nconducted using data from both Canadian (TSX) and American stock markets (S&P\n500), and WaveCorr consistently outperforms other architectures with an\nimpressive 3%-25% absolute improvement in terms of average annual return, and\nup to more than 200% relative improvement in average Sharpe ratio. We also\nmeasured an improvement of a factor of up to 5 in the stability of performance\nunder random choices of initial asset ordering and weights. The stability of\nthe network has been found as particularly valuable by our industrial partner.",
    "descriptor": "",
    "authors": [
      "Saeed Marzban",
      "Erick Delage",
      "Jonathan Yumeng Li",
      "Jeremie Desgagne-Bouchard",
      "Carl Dussault"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07005"
  },
  {
    "id": "arXiv:2109.07011",
    "title": "Testing Self-Organized Criticality Across the Main Sequence using  Stellar Flares from TESS",
    "abstract": "Stars produce explosive flares, which are believed to be powered by the\nrelease of energy stored in coronal magnetic field configurations. It has been\nshown that solar flares exhibit energy distributions typical of self-organized\ncritical systems. This study applies a novel flare detection technique to data\nobtained by NASA's TESS mission and identifies $\\sim10^6$ flaring events on\n$\\sim10^5$ stars across spectral types. Our results suggest that magnetic\nreconnection events that maintain the topology of the magnetic field in a\nself-organized critical state are ubiquitous among stellar coronae.",
    "descriptor": "\nComments: 6 pages, 3 figures, Submitted to journal\n",
    "authors": [
      "Adina D. Feinstein",
      "Darryl Z. Seligman",
      "Maximilian N. G\u00fcnther",
      "Fred C. Adams"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2109.07011"
  },
  {
    "id": "arXiv:2109.07018",
    "title": "Non-linear Independent Dual System (NIDS) for Discretization-independent  Surrogate Modeling over Complex Geometries",
    "abstract": "Numerical solution of partial differential equations (PDEs) require expensive\nsimulations, limiting their application in design optimization routines,\nmodel-based control, or solution of large-scale inverse problems. Existing\nConvolutional Neural Network-based frameworks for surrogate modeling require\nlossy pixelization and data-preprocessing, which is not suitable for realistic\nengineering applications. Therefore, we propose non-linear independent dual\nsystem (NIDS), which is a deep learning surrogate model for\ndiscretization-independent, continuous representation of PDE solutions, and can\nbe used for prediction over domains with complex, variable geometries and mesh\ntopologies. NIDS leverages implicit neural representations to develop a\nnon-linear mapping between problem parameters and spatial coordinates to state\npredictions by combining evaluations of a case-wise parameter network and a\npoint-wise spatial network in a linear output layer. The input features of the\nspatial network include physical coordinates augmented by a minimum distance\nfunction evaluation to implicitly encode the problem geometry. The form of the\noverall output layer induces a dual system, where each term in the map is\nnon-linear and independent. Further, we propose a minimum distance\nfunction-driven weighted sum of NIDS models using a shared parameter network to\nenforce boundary conditions by construction under certain restrictions. The\nframework is applied to predict solutions around complex,\nparametrically-defined geometries on non-parametrically-defined meshes with\nsolution obtained many orders of magnitude faster than the full order models.\nTest cases include a vehicle aerodynamics problem with complex geometry and\ndata scarcity, enabled by a training method in which more cases are gradually\nadded as training progresses.",
    "descriptor": "",
    "authors": [
      "James Duvall",
      "Karthik Duraisamy",
      "Shaowu Pan"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07018"
  },
  {
    "id": "arXiv:2109.07027",
    "title": "Guaranteed Safe Spacecraft Docking with Control Barrier Functions",
    "abstract": "This paper presents a strategy for control of a spacecraft docking with a\nnon-maneuvering target in the presence of safety constraints and bounded\ndisturbances. The presence of disturbances prevents convergence to a unique\ndocking state, so in our formulation, docking is defined as occurring within a\nset constructed using prescribed tolerances. Safety is ensured via application\nof Robust Control Barrier Functions to render a designated safe set forward\ninvariant for any allowable disturbance. However, this safety strategy\nnecessarily presumes a worst-case disturbance, and thus restricts trajectories\nto a subset of the safe set when a worst-case disturbance is not present. The\npresented controller accounts for this restriction, and guarantees that the\nspacecraft both remains safe and achieves docking in finite time for any\nallowable disturbance. The controller is then validated in simulation for a\nspacecraft landing on an asteroid, and two spacecraft docking in low Earth\norbit.",
    "descriptor": "\nComments: Submitted to IEEE Controls Systems Letters, under review\n",
    "authors": [
      "Joseph Breeden",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07027"
  },
  {
    "id": "arXiv:2109.07029",
    "title": "Seeking an Optimal Approach for Computer-Aided Pulmonary Embolism  Detection",
    "abstract": "Pulmonary embolism (PE) represents a thrombus (\"blood clot\"), usually\noriginating from a lower extremity vein, that travels to the blood vessels in\nthe lung, causing vascular obstruction and in some patients, death. This\ndisorder is commonly diagnosed using CT pulmonary angiography (CTPA). Deep\nlearning holds great promise for the computer-aided CTPA diagnosis (CAD) of PE.\nHowever, numerous competing methods for a given task in the deep learning\nliterature exist, causing great confusion regarding the development of a CAD PE\nsystem. To address this confusion, we present a comprehensive analysis of\ncompeting deep learning methods applicable to PE diagnosis using CTPA at the\nboth image and exam levels. At the image level, we compare convolutional neural\nnetworks (CNNs) with vision transformers, and contrast self-supervised learning\n(SSL) with supervised learning, followed by an evaluation of transfer learning\ncompared with training from scratch. At the exam level, we focus on comparing\nconventional classification (CC) with multiple instance learning (MIL). Our\nextensive experiments consistently show: (1) transfer learning consistently\nboosts performance despite differences between natural images and CT scans, (2)\ntransfer learning with SSL surpasses its supervised counterparts; (3) CNNs\noutperform vision transformers, which otherwise show satisfactory performance;\nand (4) CC is, surprisingly, superior to MIL. Compared with the state of the\nart, our optimal approach provides an AUC gain of 0.2\\% and 1.05\\% for\nimage-level and exam-level, respectively.",
    "descriptor": "",
    "authors": [
      "Nahid Ul Islam",
      "Shiv Gehlot",
      "Zongwei Zhou",
      "Michael B Gotway",
      "Jianming Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07029"
  },
  {
    "id": "arXiv:2109.07045",
    "title": "Uncertainty Quantification in Medical Image Segmentation with  Multi-decoder U-Net",
    "abstract": "Accurate medical image segmentation is crucial for diagnosis and analysis.\nHowever, the models without calibrated uncertainty estimates might lead to\nerrors in downstream analysis and exhibit low levels of robustness. Estimating\nthe uncertainty in the measurement is vital to making definite, informed\nconclusions. Especially, it is difficult to make accurate predictions on\nambiguous areas and focus boundaries for both models and radiologists, even\nharder to reach a consensus with multiple annotations. In this work, the\nuncertainty under these areas is studied, which introduces significant\ninformation with anatomical structure and is as important as segmentation\nperformance. We exploit the medical image segmentation uncertainty\nquantification by measuring segmentation performance with multiple annotations\nin a supervised learning manner and propose a U-Net based architecture with\nmultiple decoders, where the image representation is encoded with the same\nencoder, and segmentation referring to each annotation is estimated with\nmultiple decoders. Nevertheless, a cross-loss function is proposed for bridging\nthe gap between different branches. The proposed architecture is trained in an\nend-to-end manner and able to improve predictive uncertainty estimates. The\nmodel achieves comparable performance with fewer parameters to the integrated\ntraining model that ranked the runner-up in the MICCAI-QUBIQ 2020 challenge.",
    "descriptor": "\nComments: MICCAI_QUBIQ challenge, conference, Uncertainty qualification\n",
    "authors": [
      "Yanwu Yang",
      "Xutao Guo",
      "Yiwei Pan",
      "Pengcheng Shi",
      "Haiyan Lv",
      "Ting Ma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07045"
  },
  {
    "id": "arXiv:2109.07075",
    "title": "Guarding a Target Set from a Single Attacker in the Euclidean Space",
    "abstract": "This paper addresses a two-player target defense game in the $n$-dimensional\nEuclidean space where an attacker attempts to enter a closed convex target set\nwhile a defender strives to capture the attacker beforehand. We provide a\ncomplete and universal differential game-based solution which not only\nencompasses recent work associated with similar problems whose target sets have\nsimple, low-dimensional geometric shapes, but can also address problems that\ninvolve nontrivial geometric shapes of high-dimensional target sets. The value\nfunctions of the game are derived in a semi-analytical form that includes a\nconvex optimization problem. When the latter problem has a closed-form\nsolution, one of the value functions is used to analytically construct the\nbarrier surface that divides the state space of the game into the winning sets\nof players. For the case where the barrier surface has no analytical expression\nbut the target set has a smooth boundary, the bijective map between the target\nboundary and the projection of the barrier surface is obtained. By using\nHamilton-Jacobi-Isaacs equation, we verify that the proposed optimal state\nfeedback strategies always constitute the game's unique saddle point whether or\nnot the optimization problem has a closed-form solution. We illustrate our\nsolutions via numerical simulations.",
    "descriptor": "",
    "authors": [
      "Yoonjae Lee",
      "Efstathios Bakolas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07075"
  },
  {
    "id": "arXiv:2109.07099",
    "title": "Self-powered InP Nanowire Photodetector for Single Photon Level  Detection at Room Temperature",
    "abstract": "Highly sensitive photodetectors with single photon level detection is one of\nthe key components to a range of emerging technologies, in particular the\never-growing field of optical communication, remote sensing, and quantum\ncomputing. Currently, most of the single-photon detection technologies require\nexternal biasing at high voltages and/or cooling to low temperatures, posing\ngreat limitations for wider applications. Here, we demonstrate InP nanowire\narray photodetectors that can achieve single-photon level light detection at\nroom temperature without an external bias. We use top-down etched, heavily\ndoped p-type InP nanowires and n-type AZO/ZnO carrier selective contact to form\na radial p-n junction with a built-in electric field exceeding 3x10^5 V/cm at 0\nV. The device exhibits broadband light sensitivity and can distinguish a single\nphoton per pulse from the dark noise at 0 V, enabled by its design to realize\nnear-ideal broadband absorption, extremely low dark current, and highly\nefficient charge carrier separation. Meanwhile, the bandwidth of the device\nreaches above 600 MHz with a timing jitter of 538 ps. The proposed device\ndesign provides a new pathway towards low-cost, high-sensitivity, self-powered\nphotodetectors for numerous future applications.",
    "descriptor": "",
    "authors": [
      "Yi Zhu",
      "Vidur Raj",
      "Ziyuan Li",
      "Hark Hoe Tan",
      "Chennupati Jagadish",
      "Lan Fu"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.07099"
  },
  {
    "id": "arXiv:2109.07181",
    "title": "\u03b1-Indirect Control in Onion-like Networks",
    "abstract": "Tens of thousands of parent companies control millions of subsidiaries\nthrough long chains ofintermediary entities in global corporate networks.\nConversely, tens of millions of entities aredirectly held by sole owners. We\npropose an algorithm for identification of ultimate controllingentities in such\nnetworks that unifies direct and indirect control and allows for\ncontinuousinterpolation between the two concepts via a factor damping long\npaths. By exploiting onion-likeproperties of ownership networks the algorithm\nscales linearly with the network size and handlescircular ownership by design.\nWe apply it to the universe of 4.2 mln UK companies and 4 mln oftheir holders\nto understand the distribution of control in the country. Furthermore, we\nprovidethe first independent evaluation of the control identification results.\nWe reveal that the proposed{\\alpha}-ICON algorithm identifies more than 96% of\nbeneficiary entities from the evaluation set andsupersedes the existing\napproaches reported in the literature. We refer the superiority\nof{\\alpha}-ICONalgorithm to its ability to correctly identify the parents long\naway from their subsidiaries in thenetwork.",
    "descriptor": "",
    "authors": [
      "Kirill Polovnikov",
      "Nikita Pospelov",
      "Dmitriy Skougarevskiy"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.07181"
  },
  {
    "id": "arXiv:2109.07208",
    "title": "Channel Estimation Based on Machine Learning Paradigm for Spatial  Modulation OFDM",
    "abstract": "In this paper, deep neural network (DNN) is integrated with spatial\nmodulation-orthogonal frequency division multiplexing (SM-OFDM) technique for\nend-to-end data detection over Rayleigh fading channel. This proposed system\ndirectly demodulates the received symbols, leaving the channel estimation done\nonly implicitly. Furthermore, an ensemble network is also proposed for this\nsystem. Simulation results show that the proposed DNN detection scheme has a\nsignificant advantage over classical methods when the pilot overhead and cyclic\nprefix (CP) are reduced, owing to its ability to learn and adjust to\ncomplicated channel conditions. Finally, the ensemble network is shown to\nimprove the generalization of the proposed scheme, while also showing a slight\nimprovement in its performance.",
    "descriptor": "\nComments: 4 pages, 5 figures, 2021 IEEE 1st International Maghreb Meeting of the Conference on Sciences and Techniques of Automatic Control and Computer Engineering MI-STA\n",
    "authors": [
      "Ahmed M. Badi",
      "Taissir Y. Elganimi",
      "Osama A. S. Alkishriwo",
      "Nadia Adem"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07208"
  },
  {
    "id": "arXiv:2109.07211",
    "title": "Risk Measurement, Risk Entropy, and Autonomous Driving Risk Modeling",
    "abstract": "It has been for a long time to use big data of autonomous vehicles for\nperception, prediction, planning, and control of driving. Naturally, it is\nincreasingly questioned why not using this big data for risk management and\nactuarial modeling. This article examines the emerging technical difficulties,\nnew ideas, and methods of risk modeling under autonomous driving scenarios.\nCompared with the traditional risk model, the novel model is more consistent\nwith the real road traffic and driving safety performance. More importantly, it\nprovides technical feasibility for realizing risk assessment and car insurance\npricing under a computer simulation environment.",
    "descriptor": "\nComments: 11 pages, 5 figures, IME 2021\n",
    "authors": [
      "Jiamin Yu"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07211"
  },
  {
    "id": "arXiv:2109.07259",
    "title": "Evolutionary Reinforcement Learning Dynamics with Irreducible  Environmental Uncertainty",
    "abstract": "In this work we derive and present evolutionary reinforcement learning\ndynamics in which the agents are irreducibly uncertain about the current state\nof the environment. We evaluate the dynamics across different classes of\npartially observable agent-environment systems and find that irreducible\nenvironmental uncertainty can lead to better learning outcomes faster,\nstabilize the learning process and overcome social dilemmas. However, as\nexpected, we do also find that partial observability may cause worse learning\noutcomes, for example, in the form of a catastrophic limit cycle. Compared to\nfully observant agents, learning with irreducible environmental uncertainty\noften requires more exploration and less weight on future rewards to obtain the\nbest learning outcomes. Furthermore, we find a range of dynamical effects\ninduced by partial observability, e.g., a critical slowing down of the learning\nprocesses between reward regimes and the separation of the learning dynamics\ninto fast and slow directions. The presented dynamics are a practical tool for\nresearchers in biology, social science and machine learning to systematically\ninvestigate the evolutionary effects of environmental uncertainty.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Wolfram Barfuss",
      "Richard P. Mann"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.07259"
  },
  {
    "id": "arXiv:2109.07274",
    "title": "Binaural rendering from microphone array signals of arbitrary geometry",
    "abstract": "A method of binaural rendering from microphone array signals of arbitrary\ngeometry is proposed. To reproduce binaural signals from microphone array\nrecordings at a remote location, a spherical microphone array is generally used\nfor capturing a soundfield. However, owing to the lack of flexibility in the\nmicrophone arrangement, the single spherical array is sometimes impractical for\nestimating a large region of a soundfield. We propose a method based on\nharmonic analysis of infinite order, which allows the use of arbitrarily placed\nmicrophones. In the synthesis of the estimated soundfield, a\nspherical-wave-decomposition-based binaural rendering is also formulated to\ntake into consideration the distance in measuring head-related transfer\nfunctions. We develop and evaluate a composite microphone array consisting of\nmultiple small arrays. Experimental results including those of listening tests\nindicate that our proposed method is robust against change in listening\nposition in the recording area.",
    "descriptor": "\nComments: The following article has been accepted by Journal of the Acoustical Society of America (JASA). After it is published, it will be found at this http URL\n",
    "authors": [
      "Naoto Iijima",
      "Shoichi Koyama",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.07274"
  },
  {
    "id": "arXiv:2109.07277",
    "title": "Photon detection probability prediction using one-dimensional generative  neural network",
    "abstract": "Photon detection is important for liquid argon detectors for direct dark\nmatter searches or neutrino property measurements. Precise simulation of photon\ntransport is widely used to understand the probability of photon detection in\nliquid argon detectors. Traditional photon transport simulation, which tracks\nevery photon using theGeant4simulation toolkit, is a major computational\nchallenge for kilo-tonne-scale liquid argon detectors and GeV-level energy\ndepositions. In this work, we propose a one-dimensional generative model which\nefficiently generates features using an OuterProduct-layer. This model bypasses\nphoton transport simulation and predicts the number of photons detected by\nparticular photon detectors at the same level of detail as theGeant4simulation.\nThe application to simulating photon detection systems in kilo-tonne-scale\nliquid argon detectors demonstrates this novel generative model is able to\nreproduceGeant4simulation with good accuracy and 20 to 50 times faster. This\ngenerative model can be used to quickly predict photon detection probability in\nhuge liquid argon detectors like ProtoDUNE or DUNE.",
    "descriptor": "",
    "authors": [
      "Wei Mu",
      "Alexander I. Himmel",
      "Bryan Ramson"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2109.07277"
  },
  {
    "id": "arXiv:2109.07282",
    "title": "Universality for Sets of Three-Valued Qubit (qutrit) Gates",
    "abstract": "How to find universal sets quantum gates (gates whose composition can form\nany othergate within a given range) is an important part of the development of\nquantum computation science that has been explored in the past with success.\nHowever, there has not been much development in extending this very same theory\nto a generalization of qubits known as quregisters or as we call them here\nqunits (quantum units of information analogous to qubits that use any natural\nnumber n of basis states instead of 2 as qubits do). In this paper we will\nfirst do a review of the theory behind some essential proofs of quantum gate\nuniversality for qubit gates. After that we will show a new way of extending\nthose statements to arbitrary qutrit gates in an analogous manner. We also\nmention how could this be extended to any qunit gate.",
    "descriptor": "\nComments: 13 pages, 23 figures, as presented on the GOL2021 conferece (this https URL)\n",
    "authors": [
      "Carlos Efrain Quintero Narvaez"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2109.07282"
  },
  {
    "id": "arXiv:2109.07284",
    "title": "Quantitative reconstruction of defects in multi-layered bonded  composites using fully convolutional network-based ultrasonic inversion",
    "abstract": "Ultrasonic methods have great potential applications to detect and\ncharacterize defects in multi-layered bonded composites. However, it remains\nchallenging to quantitatively reconstruct defects, such as disbonds and kissing\nbonds, that influence the integrity of adhesive bonds and seriously reduce the\nstrength of assemblies. In this work, an ultrasonic method based on the\nsupervised fully convolutional network (FCN) is proposed to quantitatively\nreconstruct defects hidden in multi-layered bonded composites. In the training\nprocess of this method, an FCN establishes a non-linear mapping from measured\nultrasonic data to the corresponding velocity models of multi-layered bonded\ncomposites. In the predicting process, the trained network obtained from the\ntraining process is used to directly reconstruct the velocity models from the\nnew measured ultrasonic data of adhesively bonded composites. The presented\nFCN-based inversion method can automatically extract useful features in\nmulti-layered composites. Although this method is computationally expensive in\nthe training process, the prediction itself in the online phase takes only\nseconds. The numerical results show that the FCN-based ultrasonic inversion\nmethod is capable to accurately reconstruct ultrasonic velocity models of the\nhigh contrast defects, which has great potential for online detection of\nadhesively bonded composites.",
    "descriptor": "",
    "authors": [
      "Jing Rao",
      "Fangshu Yang",
      "Huadong Mo",
      "Stefan Kollmannsberger",
      "Ernst Rank"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07284"
  },
  {
    "id": "arXiv:2109.07322",
    "title": "DeFungi: Direct Mycological Examination of Microscopic Fungi Images",
    "abstract": "Traditionally, diagnosis and treatment of fungal infections in humans depend\nheavily on face-to-face consultations or examinations made by specialized\nlaboratory scientists known as mycologists. In many cases, such as the recent\nmucormycosis spread in the COVID-19 pandemic, an initial treatment can be\nsafely suggested to the patient during the earliest stage of the mycological\ndiagnostic process by performing a direct examination of biopsies or samples\nthrough a microscope. Computer-aided diagnosis systems using deep learning\nmodels have been trained and used for the late mycological diagnostic stages.\nHowever, there are no reference literature works made for the early stages. A\nmycological laboratory in Colombia donated the images used for the development\nof this research work. They were manually labelled into five classes and\ncurated with a subject matter expert assistance. The images were later cropped\nand patched with automated code routines to produce the final dataset. This\npaper presents experimental results classifying five fungi types using two\ndifferent deep learning approaches and three different convolutional neural\nnetwork models, VGG16, Inception V3, and ResNet50. The first approach\nbenchmarks the classification performance for the models trained from scratch,\nwhile the second approach benchmarks the classification performance using\npre-trained models based on the ImageNet dataset. Using k-fold cross-validation\ntesting on the 5-class dataset, the best performing model trained from scratch\nwas Inception V3, reporting 73.2% accuracy. Also, the best performing model\nusing transfer learning was VGG16 reporting 85.04%. The statistics provided by\nthe two approaches create an initial point of reference to encourage future\nresearch works to improve classification performance. Furthermore, the dataset\nbuilt is published in Kaggle and GitHub to foster future research.",
    "descriptor": "",
    "authors": [
      "Camilo Javier Pineda Sopo",
      "Farshid Hajati",
      "Soheila Gheisari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07322"
  },
  {
    "id": "arXiv:2109.07327",
    "title": "Improving Streaming Transformer Based ASR Under a Framework of  Self-supervised Learning",
    "abstract": "Recently self-supervised learning has emerged as an effective approach to\nimprove the performance of automatic speech recognition (ASR). Under such a\nframework, the neural network is usually pre-trained with massive unlabeled\ndata and then fine-tuned with limited labeled data. However, the non-streaming\narchitecture like bidirectional transformer is usually adopted by the neural\nnetwork to achieve competitive results, which can not be used in streaming\nscenarios. In this paper, we mainly focus on improving the performance of\nstreaming transformer under the self-supervised learning framework.\nSpecifically, we propose a novel two-stage training method during fine-tuning,\nwhich combines knowledge distilling and self-training. The proposed training\nmethod achieves 16.3% relative word error rate (WER) reduction on Librispeech\nnoisy test set. Finally, by only using the 100h clean subset of Librispeech as\nthe labeled data and the rest (860h) as the unlabeled data, our streaming\ntransformer based model obtains competitive WERs 3.5/8.7 on Librispeech\nclean/noisy test sets.",
    "descriptor": "\nComments: INTERSPEECH2021\n",
    "authors": [
      "Songjun Cao",
      "Yueteng Kang",
      "Yanzhe Fu",
      "Xiaoshuo Xu",
      "Sining Sun",
      "Yike Zhang",
      "Long Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.07327"
  },
  {
    "id": "arXiv:2109.07340",
    "title": "Distribution-free Contextual Dynamic Pricing",
    "abstract": "Contextual dynamic pricing aims to set personalized prices based on\nsequential interactions with customers. At each time period, a customer who is\ninterested in purchasing a product comes to the platform. The customer's\nvaluation for the product is a linear function of contexts, including product\nand customer features, plus some random market noise. The seller does not\nobserve the customer's true valuation, but instead needs to learn the valuation\nby leveraging contextual information and historical binary purchase feedbacks.\nExisting models typically assume full or partial knowledge of the random noise\ndistribution. In this paper, we consider contextual dynamic pricing with\nunknown random noise in the valuation model. Our distribution-free pricing\npolicy learns both the contextual function and the market noise simultaneously.\nA key ingredient of our method is a novel perturbed linear bandit framework,\nwhere a modified linear upper confidence bound algorithm is proposed to balance\nthe exploration of market noise and the exploitation of the current knowledge\nfor better pricing. We establish the regret upper bound and a matching lower\nbound of our policy in the perturbed linear bandit framework and prove a\nsub-linear regret bound in the considered pricing problem. Finally, we\ndemonstrate the superior performance of our policy on simulations and a\nreal-life auto-loan dataset.",
    "descriptor": "",
    "authors": [
      "Yiyun Luo",
      "Will Wei Sun",
      "and Yufeng Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2109.07340"
  },
  {
    "id": "arXiv:2109.07344",
    "title": "The potential of self-supervised networks for random noise suppression  in seismic data",
    "abstract": "Noise suppression is an essential step in any seismic processing workflow. A\nportion of this noise, particularly in land datasets, presents itself as random\nnoise. In recent years, neural networks have been successfully used to denoise\nseismic data in a supervised fashion. However, supervised learning always comes\nwith the often unachievable requirement of having noisy-clean data pairs for\ntraining. Using blind-spot networks, we redefine the denoising task as a\nself-supervised procedure where the network uses the surrounding noisy samples\nto estimate the noise-free value of a central sample. Based on the assumption\nthat noise is statistically independent between samples, the network struggles\nto predict the noise component of the sample due to its randomnicity, whilst\nthe signal component is accurately predicted due to its spatio-temporal\ncoherency. Illustrated on synthetic examples, the blind-spot network is shown\nto be an efficient denoiser of seismic data contaminated by random noise with\nminimal damage to the signal; therefore, providing improvements in both the\nimage domain and down-the-line tasks, such as inversion. To conclude the study,\nthe suggested approach is applied to field data and the results are compared\nwith two commonly used random denoising techniques: FX-deconvolution and\nCurvelet transform. By demonstrating that blind-spot networks are an efficient\nsuppressor of random noise, we believe this is just the beginning of utilising\nself-supervised learning in seismic applications.",
    "descriptor": "",
    "authors": [
      "Claire Birnie",
      "Matteo Ravasi",
      "Tariq Alkhalifah",
      "Sixiu Liu"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07344"
  },
  {
    "id": "arXiv:2109.07349",
    "title": "Improving Accent Identification and Accented Speech Recognition Under a  Framework of Self-supervised Learning",
    "abstract": "Recently, self-supervised pre-training has gained success in automatic speech\nrecognition (ASR). However, considering the difference between speech accents\nin real scenarios, how to identify accents and use accent features to improve\nASR is still challenging. In this paper, we employ the self-supervised\npre-training method for both accent identification and accented speech\nrecognition tasks. For the former task, a standard deviation constraint loss\n(SDC-loss) based end-to-end (E2E) architecture is proposed to identify accents\nunder the same language. As for accented speech recognition task, we design an\naccent-dependent ASR system, which can utilize additional accent input\nfeatures. Furthermore, we propose a frame-level accent feature, which is\nextracted based on the proposed accent identification model and can be\ndynamically adjusted. We pre-train our models using 960 hours unlabeled\nLibriSpeech dataset and fine-tune them on AESRC2020 speech dataset. The\nexperimental results show that our proposed accent-dependent ASR system is\nsignificantly ahead of the AESRC2020 baseline and achieves $6.5\\%$ relative\nword error rate (WER) reduction compared with our accent-independent ASR\nsystem.",
    "descriptor": "\nComments: INTERSPEECH2021\n",
    "authors": [
      "Keqi Deng",
      "Songjun Cao",
      "Long Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.07349"
  },
  {
    "id": "arXiv:2109.07361",
    "title": "A hybrid phase field method for fluid-structure interactions in viscous  fluids",
    "abstract": "We present a novel computational modeling framework to numerically\ninvestigate fluid-structure interaction in viscous fluids using the phase field\nembedding method. Each rigid body or elastic structure immersed in the\nincompressible viscous fluid matrix, grossly referred to as the particle in\nthis paper, is identified by a volume preserving phase field. The motion of the\nparticle is driven by the fluid velocity in the matrix for passive particles or\ncombined with its self-propelling velocity for active particles. The excluded\nvolume effect between a pair of particles or between a particle and the\nboundary is modeled by a repulsive potential force. The drag exerted to the\nfluid by a particle is assumed proportional to its velocity. When the particle\nis rigid, its state is described by a zero velocity gradient tensor within the\nnonzero phase field that defines its profile and a constraining stress exists\ntherein. While the particle is elastic, a linear constitutive equation for the\nelastic stress is provided within the particle domain. A hybrid,\nthermodynamically consistent hydrodynamic model valid in the entire\ncomputational domain is then derived for the fluid-particle ensemble using the\ngeneralized Onsager principle accounting for both rigid and elastic particles.\nStructure-preserving numerical algorithms are subsequently developed for the\nthermodynamically consistent model. Numerical tests in 2D and 3D space are\ncarried out to verify the rate of convergence and numerical examples are given\nto demonstrate the usefulness of the computational framework for simulating\nfluid-structure interactions for passive as well as self-propelling active\nparticles in a viscous fluid matrix.",
    "descriptor": "",
    "authors": [
      "Qi Hong",
      "Qi Wang"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.07361"
  },
  {
    "id": "arXiv:2109.07384",
    "title": "How to use KL-divergence to construct conjugate priors, with  well-defined non-informative limits, for the multivariate Gaussian",
    "abstract": "The Wishart distribution is the standard conjugate prior for the precision of\nthe multivariate Gaussian likelihood, when the mean is known -- while the\nnormal-Wishart can be used when the mean is also unknown. It is however not so\nobvious how to assign values to the hyperparameters of these distributions. In\nparticular, when forming non-informative limits of these distributions, the\nshape (or degrees of freedom) parameter of the Wishart must be handled with\ncare. The intuitive solution of directly interpreting the shape as a\npseudocount and letting it go to zero, as proposed by some authors, violates\nthe restrictions on the shape parameter. We show how to use the scaled\nKL-divergence between multivariate Gaussians as an energy function to construct\nWishart and normal-Wishart conjugate priors. When used as informative priors,\nthe salient feature of these distributions is the mode, while the KL scaling\nfactor serves as the pseudocount. The scale factor can be taken down to the\nlimit at zero, to form non-informative priors that do not violate the\nrestrictions on the Wishart shape parameter. This limit is non-informative in\nthe sense that the posterior mode is identical to the maximum likelihood\nestimate of the Gaussian likelihood parameters.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Niko Br\u00fcmmer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2109.07384"
  },
  {
    "id": "arXiv:2109.07397",
    "title": "An Improved Approach to Orbital Determination and Prediction of  Near-Earth Asteroids: Computer Simulation, Modeling and Test Measurements",
    "abstract": "In this article, theory-based analytical methodologies of astrophysics\nemployed in the modern era are suitably operated alongside a test\nresearch-grade telescope to image and determine the orbit of a near-earth\nasteroid from original observations, measurements, and calculations.\nSubsequently, its intrinsic orbital path has been calculated including the\nchance it would likely impact Earth in the time ahead. More so specifically,\nthis case-study incorporates the most effective, feasible, and novel Gauss's\nMethod in order to maneuver the orbital plane components of a planetesimal,\nfurther elaborating and extending our probes on a selected near-earth asteroid\n(namely the 12538-1998 OH) through the observational data acquired over a six\nweek period. Utilizing the CCD (Charge Coupled Device) snapshots captured, we\nsimulate and calculate the orbit of our asteroid as outlined in quite detailed\nexplanations. The uncertainties and deviations from the expected values are\nderived to reach a judgement whether our empirical findings are truly reliable\nand representative measurements by partaking a statistical analysis based\nsystematic approach. Concluding the study by narrating what could have caused\nsuch discrepancy of findings in the first place, if any, measures are put\nforward that could be undertaken to improve the test-case for future\ninvestigations. Following the calculation of orbital elements and their\nuncertainties using Monte Carlo analysis, simulations were executed with\nvarious sample celestial bodies to derive a plausible prediction regarding the\nfate of Asteroid 1998 OH. Finally, the astrometric and photometric data, after\ntheir precise verification, were officially submitted to the Minor Planet\nCenter: an organization hosted by the Center for Astrophysics, Harvard and\nSmithsonian and funded by NASA, for keeping track of the asteroid's potential\ntrajectories.",
    "descriptor": "",
    "authors": [
      "Muhammad Farae",
      "Cameron Woo",
      "Anka Hu"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.07397"
  },
  {
    "id": "arXiv:2109.07399",
    "title": "Disentangling Generative Factors of Physical Fields Using Variational  Autoencoders",
    "abstract": "The ability to extract generative parameters from high-dimensional fields of\ndata in an unsupervised manner is a highly desirable yet unrealized goal in\ncomputational physics. This work explores the use of variational autoencoders\n(VAEs) for non-linear dimension reduction with the aim of disentangling the\nlow-dimensional latent variables to identify independent physical parameters\nthat generated the data. A disentangled decomposition is interpretable and can\nbe transferred to a variety of tasks including generative modeling, design\noptimization, and probabilistic reduced order modelling. A major emphasis of\nthis work is to characterize disentanglement using VAEs while minimally\nmodifying the classic VAE loss function (i.e. the ELBO) to maintain high\nreconstruction accuracy. Disentanglement is shown to be highly sensitive to\nrotations of the latent space, hyperparameters, random initializations and the\nlearning schedule. The loss landscape is characterized by over-regularized\nlocal minima which surrounds desirable solutions. We illustrate comparisons\nbetween disentangled and entangled representations by juxtaposing learned\nlatent distributions and the 'true' generative factors in a model porous flow\nproblem. Implementing hierarchical priors (HP) is shown to better facilitate\nthe learning of disentangled representations over the classic VAE. The choice\nof the prior distribution is shown to have a dramatic effect on\ndisentanglement. In particular, the regularization loss is unaffected by latent\nrotation when training with rotationally-invariant priors, and thus learning\nnon-rotationally-invariant priors aids greatly in capturing the properties of\ngenerative factors, improving disentanglement. Some issues inherent to training\nVAEs, such as the convergence to over-regularized local minima are illustrated\nand investigated, and potential techniques for mitigation are presented.",
    "descriptor": "",
    "authors": [
      "Christian Jacobsen",
      "Karthik Duraisamy"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07399"
  },
  {
    "id": "arXiv:2109.07466",
    "title": "Neural network optimal feedback control with enhanced closed loop  stability",
    "abstract": "Recent research has shown that supervised learning can be an effective tool\nfor designing optimal feedback controllers for high-dimensional nonlinear\ndynamic systems. But the behavior of these neural network (NN) controllers is\nstill not well understood. In this paper we use numerical simulations to\ndemonstrate that typical test accuracy metrics do not effectively capture the\nability of an NN controller to stabilize a system. In particular, some NNs with\nhigh test accuracy can fail to stabilize the dynamics. To address this we\npropose two NN architectures which locally approximate a linear quadratic\nregulator (LQR). Numerical simulations confirm our intuition that the proposed\narchitectures reliably produce stabilizing feedback controllers without\nsacrificing performance. In addition, we introduce a preliminary theoretical\nresult describing some stability properties of such NN-controlled systems.",
    "descriptor": "",
    "authors": [
      "Tenavi Nakamura-Zimmerer",
      "Qi Gong",
      "Wei Kang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.07466"
  },
  {
    "id": "arXiv:1608.04834",
    "title": "Asymptotic approximation of central binomial coefficients with rigorous  error bounds",
    "abstract": "Comments: 11 pages, 1 table; added more references in v3, minor corrections in v4",
    "descriptor": "\nComments: 11 pages, 1 table; added more references in v3, minor corrections in v4\n",
    "authors": [
      "Richard P. Brent"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1608.04834"
  },
  {
    "id": "arXiv:1707.07221",
    "title": "Packing Topological Minors Half-Integrally",
    "abstract": "Packing Topological Minors Half-Integrally",
    "descriptor": "",
    "authors": [
      "Chun-Hung Liu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1707.07221"
  },
  {
    "id": "arXiv:1902.02060",
    "title": "On ADMM in Deep Learning: Convergence and Saturation-Avoidance",
    "abstract": "Comments: This is a revised version of our previous one entitled \"A Convergence Analysis of Nonlinearly Constrained ADMM in Deep Learning, arXiv:1902.02060\" with some significantly changes",
    "descriptor": "\nComments: This is a revised version of our previous one entitled \"A Convergence Analysis of Nonlinearly Constrained ADMM in Deep Learning, arXiv:1902.02060\" with some significantly changes\n",
    "authors": [
      "Jinshan Zeng",
      "Shao-Bo Lin",
      "Yuan Yao",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.02060"
  },
  {
    "id": "arXiv:1903.01287",
    "title": "Safety Verification and Robustness Analysis of Neural Networks via  Quadratic Constraints and Semidefinite Programming",
    "abstract": "Safety Verification and Robustness Analysis of Neural Networks via  Quadratic Constraints and Semidefinite Programming",
    "descriptor": "",
    "authors": [
      "Mahyar Fazlyab",
      "Manfred Morari",
      "George J. Pappas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1903.01287"
  },
  {
    "id": "arXiv:1906.00389",
    "title": "Disparate Vulnerability to Membership Inference Attacks",
    "abstract": "Comments: To appear in Privacy-Enhancing Technologies Symposium (PETS) 2022",
    "descriptor": "\nComments: To appear in Privacy-Enhancing Technologies Symposium (PETS) 2022\n",
    "authors": [
      "Mohammad Yaghini",
      "Bogdan Kulynych",
      "Giovanni Cherubin",
      "Michael Veale",
      "Carmela Troncoso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.00389"
  },
  {
    "id": "arXiv:1906.03622",
    "title": "On a Combination of Alternating Minimization and Nesterov's Momentum",
    "abstract": "Comments: Compared to previous versions: dual WB problem and complexity analysis for WB problem corrected, updated and extended experiments",
    "descriptor": "\nComments: Compared to previous versions: dual WB problem and complexity analysis for WB problem corrected, updated and extended experiments\n",
    "authors": [
      "Sergey Guminov",
      "Pavel Dvurechensky",
      "Nazarii Tupitsa",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1906.03622"
  },
  {
    "id": "arXiv:1910.08288",
    "title": "Hierarchical Attentive Knowledge Graph Embedding for Personalized  Recommendation",
    "abstract": "Hierarchical Attentive Knowledge Graph Embedding for Personalized  Recommendation",
    "descriptor": "",
    "authors": [
      "Xiao Sha",
      "Zhu Sun",
      "Jie Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.08288"
  },
  {
    "id": "arXiv:2001.04425",
    "title": "Negative Statements Considered Useful",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Hiba Arnaout",
      "Simon Razniewski",
      "Gerhard Weikum",
      "Jeff Z. Pan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2001.04425"
  },
  {
    "id": "arXiv:2002.00071",
    "title": "Rigorous Guarantees for Tyler's M-estimator via quantum expansion",
    "abstract": "Comments: Fixed Lemma 5.18 bug",
    "descriptor": "\nComments: Fixed Lemma 5.18 bug\n",
    "authors": [
      "Cole Franks",
      "Ankur Moitra"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2002.00071"
  },
  {
    "id": "arXiv:2003.01900",
    "title": "Minimum Enclosing Parallelogram with Outliers",
    "abstract": "Minimum Enclosing Parallelogram with Outliers",
    "descriptor": "",
    "authors": [
      "Zhengyang Guo",
      "Yi Li"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2003.01900"
  },
  {
    "id": "arXiv:2004.08596",
    "title": "DAPnet: A Double Self-attention Convolutional Network for Point Cloud  Semantic Labeling",
    "abstract": "Comments: 12 pages, 7 figures",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Li Chen",
      "Zewei Xu",
      "Yongjian Fu",
      "Haozhe Huang",
      "Shaowen Wang",
      "Haifeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2004.08596"
  },
  {
    "id": "arXiv:2004.12187",
    "title": "Cost Automata, Safe Schemes, and Downward Closures",
    "abstract": "Comments: journal submission",
    "descriptor": "\nComments: journal submission\n",
    "authors": [
      "David Barozzini",
      "Lorenzo Clemente",
      "Thomas Colcombet",
      "Pawe\u0142 Parys"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2004.12187"
  },
  {
    "id": "arXiv:2004.13018",
    "title": "An Extension of Pl\u00fccker Relations with Applications to Subdeterminant  Maximization",
    "abstract": "An Extension of Pl\u00fccker Relations with Applications to Subdeterminant  Maximization",
    "descriptor": "",
    "authors": [
      "Nima Anari",
      "Thuy-Duong Vuong"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2004.13018"
  },
  {
    "id": "arXiv:2006.07218",
    "title": "An Accurate, Scalable and Verifiable Protocol for Federated  Differentially Private Averaging",
    "abstract": "Comments: 41 pages",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "C\u00e9sar Sabater",
      "Aur\u00e9lien Bellet",
      "Jan Ramon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07218"
  },
  {
    "id": "arXiv:2006.08251",
    "title": "Adversarial Weighting for Domain Adaptation in Regression",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Antoine de Mathelin",
      "Guillaume Richard",
      "Francois Deheeger",
      "Mathilde Mougeot",
      "Nicolas Vayatis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08251"
  },
  {
    "id": "arXiv:2006.11580",
    "title": "Finite-size scaling, phase coexistence, and algorithms for the random  cluster model on random graphs",
    "abstract": "Comments: This update includes new results on the slow mixing of Markov chains (Theorem 6)",
    "descriptor": "\nComments: This update includes new results on the slow mixing of Markov chains (Theorem 6)\n",
    "authors": [
      "Tyler Helmuth",
      "Matthew Jenssen",
      "Will Perkins"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2006.11580"
  },
  {
    "id": "arXiv:2006.15717",
    "title": "Calculating Great Britains half-hourly electrical demand from publicly  available data",
    "abstract": "Comments: 33 pages, 3 Figures, 6 tables",
    "descriptor": "\nComments: 33 pages, 3 Figures, 6 tables\n",
    "authors": [
      "IA Grant Wilson",
      "Shivangi Sharma",
      "Joseph Day",
      "Noah Godfrey"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2006.15717"
  },
  {
    "id": "arXiv:2007.04001",
    "title": "Supervised machine learning techniques for data matching based on  similarity metrics",
    "abstract": "Supervised machine learning techniques for data matching based on  similarity metrics",
    "descriptor": "",
    "authors": [
      "Pim Verschuuren",
      "Serena Palazzo",
      "Tom Powell",
      "Steve Sutton",
      "Alfred Pilgrim",
      "Michele Faucci Giannelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.04001"
  },
  {
    "id": "arXiv:2007.14863",
    "title": "Automatic Detection of Aedes aegypti Breeding Grounds Based on Deep  Networks with Spatio-Temporal Consistency",
    "abstract": "Automatic Detection of Aedes aegypti Breeding Grounds Based on Deep  Networks with Spatio-Temporal Consistency",
    "descriptor": "",
    "authors": [
      "Wesley L. Passos",
      "Gabriel M. Araujo",
      "Amaro A. de Lima",
      "Sergio L. Netto",
      "Eduardo A. B. da Silva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2007.14863"
  },
  {
    "id": "arXiv:2008.02258",
    "title": "Expected Size of Random Tukey Layers and Convex Layers",
    "abstract": "Expected Size of Random Tukey Layers and Convex Layers",
    "descriptor": "",
    "authors": [
      "Zhengyang Guo",
      "Yi Li",
      "Shaoyu Pei"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2008.02258"
  },
  {
    "id": "arXiv:2008.04998",
    "title": "Blockchain-Enabled Internet-of-Things Platform for End-to-End Industrial  Hemp Supply Chain",
    "abstract": "Comments: 18 pages, 9 figures",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Keqi Wang",
      "Wei Xie",
      "Wencen Wu",
      "Jinxiang Pei",
      "Qi Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2008.04998"
  },
  {
    "id": "arXiv:2009.05236",
    "title": "An Efficient Quantitative Approach for Optimizing Convolutional Neural  Networks",
    "abstract": "An Efficient Quantitative Approach for Optimizing Convolutional Neural  Networks",
    "descriptor": "",
    "authors": [
      "Yuke Wang",
      "Boyuan Feng",
      "Xueqiao Peng",
      "Yufei Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2009.05236"
  },
  {
    "id": "arXiv:2009.09734",
    "title": "Electing the Executive Branch",
    "abstract": "Electing the Executive Branch",
    "descriptor": "",
    "authors": [
      "Ehud Shapiro",
      "Nimrod Talmon"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2009.09734"
  },
  {
    "id": "arXiv:2009.12250",
    "title": "Trace-Checking CPS Properties: Bridging the Cyber-Physical Gap",
    "abstract": "Trace-Checking CPS Properties: Bridging the Cyber-Physical Gap",
    "descriptor": "",
    "authors": [
      "Claudio Menghi",
      "Enrico Vigan\u00f2",
      "Domenico Bianculli",
      "Lionel C. Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2009.12250"
  },
  {
    "id": "arXiv:2009.12436",
    "title": "FLC tuned with Gravitational Search Algorithm for Nonlinear Pose Filter",
    "abstract": "Comments: 2020 IEEE International Conference on Systems, Man and Cybernetics (SMC). arXiv admin note: text overlap with arXiv:2008.07595",
    "descriptor": "\nComments: 2020 IEEE International Conference on Systems, Man and Cybernetics (SMC). arXiv admin note: text overlap with arXiv:2008.07595\n",
    "authors": [
      "Trenton S Sieb",
      "Ajay Singh",
      "Lorelei Guidos",
      "Hashim A Hashim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.12436"
  },
  {
    "id": "arXiv:2009.12623",
    "title": "Lossy Checkpoint Compression in Full Waveform Inversion: a case study  with ZFPv0.5.5 and the Overthrust Model",
    "abstract": "Lossy Checkpoint Compression in Full Waveform Inversion: a case study  with ZFPv0.5.5 and the Overthrust Model",
    "descriptor": "",
    "authors": [
      "Navjot Kukreja",
      "Jan Hueckelheim",
      "Mathias Louboutin",
      "John Washbourne",
      "Paul H.J. Kelly",
      "Gerard J. Gorman"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.12623"
  },
  {
    "id": "arXiv:2009.14742",
    "title": "A Generalization of Bohr-Mollerup's Theorem for Higher Order Convex  Functions",
    "abstract": "Comments: To appear in the book series: Developments in Mathematics, Springer, 2021-2022",
    "descriptor": "\nComments: To appear in the book series: Developments in Mathematics, Springer, 2021-2022\n",
    "authors": [
      "Jean-Luc Marichal",
      "Na\u00efm Z\u00e9na\u00efdi"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2009.14742"
  },
  {
    "id": "arXiv:2010.01678",
    "title": "Optimal Neural Program Synthesis from Multimodal Specifications",
    "abstract": "Comments: Findings of EMNLP 2021",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Xi Ye",
      "Qiaochu Chen",
      "Isil Dillig",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2010.01678"
  },
  {
    "id": "arXiv:2010.10343",
    "title": "Provenance Graph Kernel",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "David Kohan Marzag\u00e3o",
      "Trung Dong Huynh",
      "Ayah Helal",
      "Sean Baccas",
      "Luc Moreau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2010.10343"
  },
  {
    "id": "arXiv:2010.10726",
    "title": "MINVO Basis: Finding Simplexes with Minimum Volume Enclosing Polynomial  Curves",
    "abstract": "Comments: 23 pages, 21 figures",
    "descriptor": "\nComments: 23 pages, 21 figures\n",
    "authors": [
      "Jesus Tordesillas",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.10726"
  },
  {
    "id": "arXiv:2010.14377",
    "title": "Designing optimal networks for multi-commodity transport problem",
    "abstract": "Comments: 13 pages, 7 figures",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Alessandro Lonardi",
      "Enrico Facca",
      "Mario Putti",
      "Caterina De Bacco"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2010.14377"
  },
  {
    "id": "arXiv:2011.03618",
    "title": "Learning Human Search Behavior from Egocentric Visual Inputs",
    "abstract": "Comments: The proceeding of EUROGRAPHICS 2021",
    "descriptor": "\nComments: The proceeding of EUROGRAPHICS 2021\n",
    "authors": [
      "Maks Sorokin",
      "Wenhao Yu",
      "Sehoon Ha",
      "C. Karen Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2011.03618"
  },
  {
    "id": "arXiv:2011.05953",
    "title": "$(f,\u0393)$-Divergences: Interpolating between $f$-Divergences and  Integral Probability Metrics",
    "abstract": "Comments: 49 pages",
    "descriptor": "\nComments: 49 pages\n",
    "authors": [
      "Jeremiah Birrell",
      "Paul Dupuis",
      "Markos A. Katsoulakis",
      "Yannis Pantazis",
      "Luc Rey-Bellet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.05953"
  },
  {
    "id": "arXiv:2011.09148",
    "title": "Binary Classification of Gaussian Mixtures: Abundance of Support  Vectors, Benign Overfitting and Regularization",
    "abstract": "Comments: New results: Extensions to model with label noise",
    "descriptor": "\nComments: New results: Extensions to model with label noise\n",
    "authors": [
      "Ke Wang",
      "Christos Thrampoulidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2011.09148"
  },
  {
    "id": "arXiv:2011.13127",
    "title": "Copy-and-Patch Compilation: A fast compilation algorithm for high-level  languages and bytecode",
    "abstract": "Copy-and-Patch Compilation: A fast compilation algorithm for high-level  languages and bytecode",
    "descriptor": "",
    "authors": [
      "Haoran Xu",
      "Fredrik Kjolstad"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2011.13127"
  },
  {
    "id": "arXiv:2011.15084",
    "title": "Likelihood-Based Diverse Sampling for Trajectory Forecasting",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Yecheng Jason Ma",
      "Jeevana Priya Inala",
      "Dinesh Jayaraman",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.15084"
  },
  {
    "id": "arXiv:2012.01410",
    "title": "Ontological Smart Contracts in OASIS: Ontology for Agents, Systems, and  Integration of Services (Extended Version)",
    "abstract": "Comments: This work has been accepted for publication at The 14th International Symposium on Intelligent Distributed Computing, 16--18 September 2021 - Online. Paper accepted on 8 September 2020",
    "descriptor": "\nComments: This work has been accepted for publication at The 14th International Symposium on Intelligent Distributed Computing, 16--18 September 2021 - Online. Paper accepted on 8 September 2020\n",
    "authors": [
      "Domenico Cantone",
      "Carmelo Fabio Longo",
      "Marianna Nicolosi-Asmundo",
      "Daniele Francesco Santamaria",
      "Corrado Santoro"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.01410"
  },
  {
    "id": "arXiv:2012.04882",
    "title": "Infusing Multi-Source Knowledge with Heterogeneous Graph Neural Network  for Emotional Conversation Generation",
    "abstract": "Comments: Accepted at AAAI 2021, Code:this https URL",
    "descriptor": "\nComments: Accepted at AAAI 2021, Code:this https URL\n",
    "authors": [
      "Yunlong Liang",
      "Fandong Meng",
      "Ying Zhang",
      "Jinan Xu",
      "Yufeng Chen",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.04882"
  },
  {
    "id": "arXiv:2012.05688",
    "title": "DA-HGT: Domain Adaptive Heterogeneous Graph Transformer",
    "abstract": "DA-HGT: Domain Adaptive Heterogeneous Graph Transformer",
    "descriptor": "",
    "authors": [
      "Tiancheng Huang",
      "Ke Xu",
      "Donglin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.05688"
  },
  {
    "id": "arXiv:2012.09335",
    "title": "Decentralized and Communication-Free Multi-Robot Navigation through  Distributed Games",
    "abstract": "Decentralized and Communication-Free Multi-Robot Navigation through  Distributed Games",
    "descriptor": "",
    "authors": [
      "Brian Reily",
      "Terran Mott",
      "Hao Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.09335"
  },
  {
    "id": "arXiv:2012.09962",
    "title": "Making Contrastive Learning Robust to Shortcuts",
    "abstract": "Comments: The first two authors contributed equally to this paper",
    "descriptor": "\nComments: The first two authors contributed equally to this paper\n",
    "authors": [
      "Tianhong Li",
      "Lijie Fan",
      "Yuan Yuan",
      "Hao He",
      "Yonglong Tian",
      "Rogerio Feris",
      "Piotr Indyk",
      "Dina Katabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.09962"
  },
  {
    "id": "arXiv:2012.13537",
    "title": "LSTM-Aided Hybrid Random Access Scheme for 6G Machine Type Communication  Networks",
    "abstract": "LSTM-Aided Hybrid Random Access Scheme for 6G Machine Type Communication  Networks",
    "descriptor": "",
    "authors": [
      "Huimei Han",
      "Fuhui Zhou",
      "Wenchao Zhai",
      "Lei Liu",
      "Jinsong Wu",
      "Ning Zhang",
      "Jun Zhao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2012.13537"
  },
  {
    "id": "arXiv:2012.15455",
    "title": "Fully Synthetic Data Improves Neural Machine Translation with Knowledge  Distillation",
    "abstract": "Fully Synthetic Data Improves Neural Machine Translation with Knowledge  Distillation",
    "descriptor": "",
    "authors": [
      "Alham Fikri Aji",
      "Kenneth Heafield"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.15455"
  },
  {
    "id": "arXiv:2101.06963",
    "title": "Uncertainty-Aware Body Composition Analysis with Deep Regression  Ensembles on UK Biobank MRI",
    "abstract": "Uncertainty-Aware Body Composition Analysis with Deep Regression  Ensembles on UK Biobank MRI",
    "descriptor": "",
    "authors": [
      "Taro Langner",
      "Fredrik K. Gustafsson",
      "Benny Avelin",
      "Robin Strand",
      "H\u00e5kan Ahlstr\u00f6m",
      "Joel Kullberg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.06963"
  },
  {
    "id": "arXiv:2101.07034",
    "title": "AGRNet: Adaptive Graph Representation Learning and Reasoning for Face  Parsing",
    "abstract": "AGRNet: Adaptive Graph Representation Learning and Reasoning for Face  Parsing",
    "descriptor": "",
    "authors": [
      "Gusi Te",
      "Wei Hu",
      "Yinglu Liu",
      "Hailin Shi",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.07034"
  },
  {
    "id": "arXiv:2101.07663",
    "title": "Salient Object Detection via Integrity Learning",
    "abstract": "Salient Object Detection via Integrity Learning",
    "descriptor": "",
    "authors": [
      "Mingchen Zhuge",
      "Deng-Ping Fan",
      "Nian Liu",
      "Dingwen Zhang",
      "Dong Xu",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.07663"
  },
  {
    "id": "arXiv:2101.08248",
    "title": "Data-to-text Generation by Splicing Together Nearest Neighbors",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Sam Wiseman",
      "Arturs Backurs",
      "Karl Stratos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.08248"
  },
  {
    "id": "arXiv:2101.09592",
    "title": "Point-hyperplane incidence geometry and the log-rank conjecture",
    "abstract": "Comments: 13 pages, no figures. Discussion is revised",
    "descriptor": "\nComments: 13 pages, no figures. Discussion is revised\n",
    "authors": [
      "Noah Singer",
      "Madhu Sudan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2101.09592"
  },
  {
    "id": "arXiv:2101.09783",
    "title": "Termination Analysis Without the Tears",
    "abstract": "Termination Analysis Without the Tears",
    "descriptor": "",
    "authors": [
      "Shaowei Zhu",
      "Zachary Kincaid"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2101.09783"
  },
  {
    "id": "arXiv:2102.00050",
    "title": "Sequential prediction under log-loss and misspecification",
    "abstract": "Sequential prediction under log-loss and misspecification",
    "descriptor": "",
    "authors": [
      "Meir Feder",
      "Yury Polyanskiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.00050"
  },
  {
    "id": "arXiv:2102.02315",
    "title": "Real-Time Optimal Trajectory Planning for Autonomous Vehicles and Lap  Time Simulation Using Machine Learning",
    "abstract": "Real-Time Optimal Trajectory Planning for Autonomous Vehicles and Lap  Time Simulation Using Machine Learning",
    "descriptor": "",
    "authors": [
      "Sam Garlick",
      "Andrew Bradley"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.02315"
  },
  {
    "id": "arXiv:2102.03973",
    "title": "Solid Texture Synthesis using Generative Adversarial Networks",
    "abstract": "Solid Texture Synthesis using Generative Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Xin Zhao",
      "Jifeng Guo",
      "Lin Wang",
      "Fanqi Li",
      "Junteng Zheng",
      "Bo Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2102.03973"
  },
  {
    "id": "arXiv:2102.05347",
    "title": "From Sampling to Optimization on Discrete Domains with Applications to  Determinant Maximization",
    "abstract": "From Sampling to Optimization on Discrete Domains with Applications to  Determinant Maximization",
    "descriptor": "",
    "authors": [
      "Nima Anari",
      "Thuy-Duong Vuong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.05347"
  },
  {
    "id": "arXiv:2102.08442",
    "title": "SCAPE: Learning Stiffness Control from Augmented Position Control  Experiences",
    "abstract": "Comments: Accepted at CoRL 2021",
    "descriptor": "\nComments: Accepted at CoRL 2021\n",
    "authors": [
      "Mincheol Kim",
      "Scott Niekum",
      "Ashish D. Deshpande"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2102.08442"
  },
  {
    "id": "arXiv:2102.11121",
    "title": "Direct Estimation of Appearance Models for Segmentation",
    "abstract": "Comments: To appear in the SIAM Journal on Imaging Sciences (SIIMS)",
    "descriptor": "\nComments: To appear in the SIAM Journal on Imaging Sciences (SIIMS)\n",
    "authors": [
      "Jeova F. S. Rocha Neto",
      "Pedro Felzenszwalb",
      "Marilyn Vazquez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.11121"
  },
  {
    "id": "arXiv:2102.11625",
    "title": "Assessing the Readability of Policy Documents on the Digital Single  Market of the European Union",
    "abstract": "Comments: Proceedings of the Eighth International Conference on eDemocracy & eGovernment (ICEDEG 2021), Quito (online), IEEE, pp. 205-209",
    "descriptor": "\nComments: Proceedings of the Eighth International Conference on eDemocracy & eGovernment (ICEDEG 2021), Quito (online), IEEE, pp. 205-209\n",
    "authors": [
      "Jukka Ruohonen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2102.11625"
  },
  {
    "id": "arXiv:2102.12459",
    "title": "When Attention Meets Fast Recurrence: Training Language Models with  Reduced Compute",
    "abstract": "When Attention Meets Fast Recurrence: Training Language Models with  Reduced Compute",
    "descriptor": "",
    "authors": [
      "Tao Lei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.12459"
  },
  {
    "id": "arXiv:2103.02334",
    "title": "Developing NOMA to Next Generation Multiple Access (NGMA): Future Vision  and Research Opportunities",
    "abstract": "Comments: 7 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 7 pages, 5 figures, 1 table\n",
    "authors": [
      "Yuanwei Liu",
      "Wenqiang Yi",
      "Zhiguo Ding",
      "Xiao Liu",
      "Octavia Dobre",
      "Naofal Al-Dhahir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2103.02334"
  },
  {
    "id": "arXiv:2103.02429",
    "title": "Land Cover Mapping in Limited Labels Scenario: A Survey",
    "abstract": "Comments: 8 pages, 1 figure",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Rahul Ghosh",
      "Xiaowei Jia",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.02429"
  },
  {
    "id": "arXiv:2103.06359",
    "title": "Hiding Leader's Identity in Leader-Follower Navigation through  Multi-Agent Reinforcement Learning",
    "abstract": "Hiding Leader's Identity in Leader-Follower Navigation through  Multi-Agent Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Ankur Deka",
      "Wenhao Luo",
      "Huao Li",
      "Michael Lewis",
      "Katia Sycara"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2103.06359"
  },
  {
    "id": "arXiv:2103.08764",
    "title": "Fast and Accurate: Video Enhancement using Sparse Depth",
    "abstract": "Fast and Accurate: Video Enhancement using Sparse Depth",
    "descriptor": "",
    "authors": [
      "Yu Feng",
      "Patrick Hansen",
      "Paul N. Whatmough",
      "Guoyu Lu",
      "Yuhao Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.08764"
  },
  {
    "id": "arXiv:2103.11070",
    "title": "Attribute Alignment: Controlling Text Generation from Pre-trained  Language Models",
    "abstract": "Attribute Alignment: Controlling Text Generation from Pre-trained  Language Models",
    "descriptor": "",
    "authors": [
      "Dian Yu",
      "Zhou Yu",
      "Kenji Sagae"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.11070"
  },
  {
    "id": "arXiv:2103.11648",
    "title": "D3p -- A Python Package for Differentially-Private Probabilistic  Programming",
    "abstract": "D3p -- A Python Package for Differentially-Private Probabilistic  Programming",
    "descriptor": "",
    "authors": [
      "Lukas Prediger",
      "Niki Loppi",
      "Samuel Kaski",
      "Antti Honkela"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.11648"
  },
  {
    "id": "arXiv:2103.14010",
    "title": "Self-Supervised Training Enhances Online Continual Learning",
    "abstract": "Self-Supervised Training Enhances Online Continual Learning",
    "descriptor": "",
    "authors": [
      "Jhair Gallardo",
      "Tyler L. Hayes",
      "Christopher Kanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14010"
  },
  {
    "id": "arXiv:2103.14146",
    "title": "Describing and Localizing Multiple Changes with Transformers",
    "abstract": "Comments: Accepted by ICCV2021. 18 pages, 15 figures, project page: this https URL",
    "descriptor": "\nComments: Accepted by ICCV2021. 18 pages, 15 figures, project page: this https URL\n",
    "authors": [
      "Yue Qiu",
      "Shintaro Yamamoto",
      "Kodai Nakashima",
      "Ryota Suzuki",
      "Kenji Iwata",
      "Hirokatsu Kataoka",
      "Yutaka Satoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14146"
  },
  {
    "id": "arXiv:2103.14373",
    "title": "D2C-SR: A Divergence to Convergence Approach for Real-World Image  Super-Resolution",
    "abstract": "Comments: 14 pages, 12 figures",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Youwei Li",
      "Haibin Huang",
      "Lanpeng Jia",
      "Haoqiang Fan",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14373"
  },
  {
    "id": "arXiv:2103.15009",
    "title": "Unclonable Encryption, Revisited",
    "abstract": "Unclonable Encryption, Revisited",
    "descriptor": "",
    "authors": [
      "Prabhanjan Ananth",
      "Fatih Kaleoglu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2103.15009"
  },
  {
    "id": "arXiv:2103.15429",
    "title": "Efficient Explanations from Empirical Explainers",
    "abstract": "Comments: Accepted to the EMNLP 2021 Workshop on Analyzing and Interpreting Neural Networks for NLP (BlackboxNLP)",
    "descriptor": "\nComments: Accepted to the EMNLP 2021 Workshop on Analyzing and Interpreting Neural Networks for NLP (BlackboxNLP)\n",
    "authors": [
      "Robert Schwarzenberg",
      "Nils Feldhus",
      "Sebastian M\u00f6ller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.15429"
  },
  {
    "id": "arXiv:2104.02412",
    "title": "Applying splitting methods with complex coefficients to the numerical  integration of unitary problems",
    "abstract": "Comments: 18 pages, 7 figures. To be published in Journal of Computational Dynamics",
    "descriptor": "\nComments: 18 pages, 7 figures. To be published in Journal of Computational Dynamics\n",
    "authors": [
      "S. Blanes",
      "F. Casas",
      "A. Escorihuela-Tom\u00e0s"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.02412"
  },
  {
    "id": "arXiv:2104.04886",
    "title": "Adversarial Regularization as Stackelberg Game: An Unrolled Optimization  Approach",
    "abstract": "Adversarial Regularization as Stackelberg Game: An Unrolled Optimization  Approach",
    "descriptor": "",
    "authors": [
      "Simiao Zuo",
      "Chen Liang",
      "Haoming Jiang",
      "Xiaodong Liu",
      "Pengcheng He",
      "Jianfeng Gao",
      "Weizhu Chen",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.04886"
  },
  {
    "id": "arXiv:2104.05158",
    "title": "Software-Hardware Co-design for Fast and Scalable Training of Deep  Learning Recommendation Models",
    "abstract": "Software-Hardware Co-design for Fast and Scalable Training of Deep  Learning Recommendation Models",
    "descriptor": "",
    "authors": [
      "Dheevatsa Mudigere",
      "Yuchen Hao",
      "Jianyu Huang",
      "Zhihao Jia",
      "Andrew Tulloch",
      "Srinivas Sridharan",
      "Xing Liu",
      "Mustafa Ozdal",
      "Jade Nie",
      "Jongsoo Park",
      "Liang Luo",
      "Jie Amy Yang",
      "Leon Gao",
      "Dmytro Ivchenko",
      "Aarti Basant",
      "Yuxi Hu",
      "Jiyan Yang",
      "Ehsan K. Ardestani",
      "Xiaodong Wang",
      "Rakesh Komuravelli",
      "Ching-Hsiang Chu",
      "Serhat Yilmaz",
      "Huayu Li",
      "Jiyuan Qian",
      "Zhuobo Feng",
      "Yinbin Ma",
      "Junjie Yang",
      "Ellie Wen",
      "Hong Li",
      "Lin Yang",
      "Chonglin Sun",
      "Whitney Zhao",
      "Dimitry Melts",
      "Krishna Dhulipala",
      "KR Kishore",
      "Tyler Graf",
      "Assaf Eisenman",
      "Kiran Kumar Matam",
      "Adi Gangidi",
      "Guoqiang Jerry Chen",
      "Manoj Krishnan",
      "Avinash Nayak",
      "Krishnakumar Nair",
      "Bharath Muthiah",
      "Mahmoud khorashadi",
      "Pallab Bhattacharya",
      "Petr Lapukhov",
      "Maxim Naumov",
      "Ajit Mathews",
      "Lin Qiao",
      "Mikhail Smelyanskiy",
      "Bill Jia",
      "Vijay Rao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2104.05158"
  },
  {
    "id": "arXiv:2104.05932",
    "title": "VR3Dense: Voxel Representation Learning for 3D Object Detection and  Monocular Dense Depth Reconstruction",
    "abstract": "Comments: Accepted at IJCAI 2021 Artificial Intelligence for Autonomous Driving Workshop",
    "descriptor": "\nComments: Accepted at IJCAI 2021 Artificial Intelligence for Autonomous Driving Workshop\n",
    "authors": [
      "Shubham Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05932"
  },
  {
    "id": "arXiv:2104.06476",
    "title": "Incremental Multi-Target Domain Adaptation for Object Detection with  Efficient Domain Transfer",
    "abstract": "Comments: Submitted for Pattern Recognition",
    "descriptor": "\nComments: Submitted for Pattern Recognition\n",
    "authors": [
      "Le Thanh Nguyen-Meidine",
      "Madhu Kiran",
      "Marco Pedersoli",
      "Jose Dolz",
      "Louis-Antoine Blais-Morin",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.06476"
  },
  {
    "id": "arXiv:2104.07275",
    "title": "Span Pointer Networks for Non-Autoregressive Task-Oriented Semantic  Parsing",
    "abstract": "Span Pointer Networks for Non-Autoregressive Task-Oriented Semantic  Parsing",
    "descriptor": "",
    "authors": [
      "Akshat Shrivastava",
      "Pierce Chuang",
      "Arun Babu",
      "Shrey Desai",
      "Abhinav Arora",
      "Alexander Zotov",
      "Ahmed Aly"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.07275"
  },
  {
    "id": "arXiv:2104.08211",
    "title": "Robust Open-Vocabulary Translation from Visual Text Representations",
    "abstract": "Comments: Accepted to EMNLP 2021",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Elizabeth Salesky",
      "David Etter",
      "Matt Post"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08211"
  },
  {
    "id": "arXiv:2104.08313",
    "title": "Does language help generalization in vision models?",
    "abstract": "Comments: Paper accepted at the CoNLL 2021 conference. This version: section added on the performance of the visual and visio-linguistic models on linquistic tasks",
    "descriptor": "\nComments: Paper accepted at the CoNLL 2021 conference. This version: section added on the performance of the visual and visio-linguistic models on linquistic tasks\n",
    "authors": [
      "Benjamin Devillers",
      "Bhavin Choksi",
      "Romain Bielawski",
      "Rufin VanRullen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08313"
  },
  {
    "id": "arXiv:2104.08718",
    "title": "CLIPScore: A Reference-free Evaluation Metric for Image Captioning",
    "abstract": "CLIPScore: A Reference-free Evaluation Metric for Image Captioning",
    "descriptor": "",
    "authors": [
      "Jack Hessel",
      "Ari Holtzman",
      "Maxwell Forbes",
      "Ronan Le Bras",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08718"
  },
  {
    "id": "arXiv:2104.10157",
    "title": "VideoGPT: Video Generation using VQ-VAE and Transformers",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Wilson Yan",
      "Yunzhi Zhang",
      "Pieter Abbeel",
      "Aravind Srinivas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.10157"
  },
  {
    "id": "arXiv:2104.10749",
    "title": "Constantine: Automatic Side-Channel Resistance Using Efficient Control  and Data Flow Linearization",
    "abstract": "Comments: Proceedings of the ACM Conference on Computer and Communications Security (CCS) 2021. Code and BibTeX entry available at this https URL",
    "descriptor": "\nComments: Proceedings of the ACM Conference on Computer and Communications Security (CCS) 2021. Code and BibTeX entry available at this https URL\n",
    "authors": [
      "Pietro Borrello",
      "Daniele Cono D'Elia",
      "Leonardo Querzoni",
      "Cristiano Giuffrida"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2104.10749"
  },
  {
    "id": "arXiv:2104.12167",
    "title": "A Novel Unified Stereo Stimuli based Binocular Eye-Tracking System for  Accurate 3D Gaze Estimation",
    "abstract": "Comments: Add new experimental results",
    "descriptor": "\nComments: Add new experimental results\n",
    "authors": [
      "Sunjing Lin",
      "Yu Liu",
      "Shaochu Wang",
      "Chang Li",
      "Han Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.12167"
  },
  {
    "id": "arXiv:2104.12810",
    "title": "Classical and Quantum algorithms for generic Syndrome Decoding problems  and applications to the Lee metric",
    "abstract": "Classical and Quantum algorithms for generic Syndrome Decoding problems  and applications to the Lee metric",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Chailloux",
      "Thomas Debris-Alazard",
      "Simona Etinski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.12810"
  },
  {
    "id": "arXiv:2104.12999",
    "title": "Separating Rank Logic from Polynomial Time",
    "abstract": "Comments: 54 pages. Full version of a paper appeared at LICS 2021. [v3] Fixed some minor mistakes/typos in the proofs [v4] Fixed a mistake in the CFI construction",
    "descriptor": "\nComments: 54 pages. Full version of a paper appeared at LICS 2021. [v3] Fixed some minor mistakes/typos in the proofs [v4] Fixed a mistake in the CFI construction\n",
    "authors": [
      "Moritz Lichter"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.12999"
  },
  {
    "id": "arXiv:2104.13542",
    "title": "STORM: An Integrated Framework for Fast Joint-Space Model-Predictive  Control for Reactive Manipulation",
    "abstract": "Comments: Accepted for oral presentation at the Conference on Robot Learning (CoRL), 2021. Code available at: this https URL",
    "descriptor": "\nComments: Accepted for oral presentation at the Conference on Robot Learning (CoRL), 2021. Code available at: this https URL\n",
    "authors": [
      "Mohak Bhardwaj",
      "Balakumar Sundaralingam",
      "Arsalan Mousavian",
      "Nathan Ratliff",
      "Dieter Fox",
      "Fabio Ramos",
      "Byron Boots"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2104.13542"
  },
  {
    "id": "arXiv:2104.14282",
    "title": "VIRDOCD: a VIRtual DOCtor to Predict Dengue Fatality",
    "abstract": "Comments: 17 pages, 5 figures, 8 tables",
    "descriptor": "\nComments: 17 pages, 5 figures, 8 tables\n",
    "authors": [
      "Amit K Chattopadhyay",
      "Subhagata Chattopadhyay"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.14282"
  },
  {
    "id": "arXiv:2105.00404",
    "title": "A Joint Design for STAR-RIS enhanced NOMA-CoMP Networks: A  Simultaneous-Signal-Enhancement-and-Cancellation-based (SSECB) Design",
    "abstract": "A Joint Design for STAR-RIS enhanced NOMA-CoMP Networks: A  Simultaneous-Signal-Enhancement-and-Cancellation-based (SSECB) Design",
    "descriptor": "",
    "authors": [
      "Tianwei Hou",
      "Jun Wang",
      "Yuanwei Liu",
      "Xin Sun",
      "Anna Li",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.00404"
  },
  {
    "id": "arXiv:2105.01595",
    "title": "Self-Improving Semantic Perception for Indoor Localisation",
    "abstract": "Comments: A summary video can be accessed at this https URL",
    "descriptor": "\nComments: A summary video can be accessed at this https URL\n",
    "authors": [
      "Hermann Blum",
      "Francesco Milano",
      "Ren\u00e9 Zurbr\u00fcgg",
      "Roland Siegward",
      "Cesar Cadena",
      "Abel Gawel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.01595"
  },
  {
    "id": "arXiv:2105.01650",
    "title": "Stochastic gradient descent with noise of machine learning type. Part I:  Discrete time analysis",
    "abstract": "Stochastic gradient descent with noise of machine learning type. Part I:  Discrete time analysis",
    "descriptor": "",
    "authors": [
      "Stephan Wojtowytsch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.01650"
  },
  {
    "id": "arXiv:2105.02132",
    "title": "Self-Supervised Learning from Automatically Separated Sound Scenes",
    "abstract": "Self-Supervised Learning from Automatically Separated Sound Scenes",
    "descriptor": "",
    "authors": [
      "Eduardo Fonseca",
      "Aren Jansen",
      "Daniel P. W. Ellis",
      "Scott Wisdom",
      "Marco Tagliasacchi",
      "John R. Hershey",
      "Manoj Plakal",
      "Shawn Hershey",
      "R. Channing Moore",
      "Xavier Serra"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2105.02132"
  },
  {
    "id": "arXiv:2105.03247",
    "title": "MOTR: End-to-End Multiple-Object Tracking with TRansformer",
    "abstract": "Comments: Revised version. Code is available at this https URL",
    "descriptor": "\nComments: Revised version. Code is available at this https URL\n",
    "authors": [
      "Fangao Zeng",
      "Bin Dong",
      "Tiancai Wang",
      "Xiangyu Zhang",
      "Yichen Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.03247"
  },
  {
    "id": "arXiv:2105.03531",
    "title": "On the Complexity of Verification of Time-Sensitive Distributed Systems:  Technical Report",
    "abstract": "Comments: This Technical Report updates and subsumes the technical report arXiv:1606.07886. arXiv admin note: text overlap with arXiv:1606.07886",
    "descriptor": "\nComments: This Technical Report updates and subsumes the technical report arXiv:1606.07886. arXiv admin note: text overlap with arXiv:1606.07886\n",
    "authors": [
      "Max Kanovich",
      "Tajana Ban Kirigin",
      "Vivek Nigam",
      "Andre Scedrov",
      "Carolyn Talcott"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.03531"
  },
  {
    "id": "arXiv:2105.06162",
    "title": "Variable Coded Batch Matrix Multiplication",
    "abstract": "Comments: 8 pages, 3 figures, to be published in IEEE Global Communications Conference (GLOBECOM) 2021",
    "descriptor": "\nComments: 8 pages, 3 figures, to be published in IEEE Global Communications Conference (GLOBECOM) 2021\n",
    "authors": [
      "Lev Tauz",
      "Lara Dolecek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.06162"
  },
  {
    "id": "arXiv:2105.06232",
    "title": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with  Adapters",
    "abstract": "Comments: The first two authors contribute equally",
    "descriptor": "\nComments: The first two authors contribute equally\n",
    "authors": [
      "Yan Xu",
      "Etsuko Ishii",
      "Samuel Cahyawijaya",
      "Zihan Liu",
      "Genta Indra Winata",
      "Andrea Madotto",
      "Dan Su",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06232"
  },
  {
    "id": "arXiv:2105.06631",
    "title": "Ordering-Based Causal Discovery with Reinforcement Learning",
    "abstract": "Comments: Accepted to IJCAI'2021",
    "descriptor": "\nComments: Accepted to IJCAI'2021\n",
    "authors": [
      "Xiaoqiang Wang",
      "Yali Du",
      "Shengyu Zhu",
      "Liangjun Ke",
      "Zhitang Chen",
      "Jianye Hao",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06631"
  },
  {
    "id": "arXiv:2105.06965",
    "title": "Counterfactual Interventions Reveal the Causal Effect of Relative Clause  Representations on Agreement Prediction",
    "abstract": "Comments: Equal contribution by SR and GP. Accepted in CoNLL 2021",
    "descriptor": "\nComments: Equal contribution by SR and GP. Accepted in CoNLL 2021\n",
    "authors": [
      "Shauli Ravfogel",
      "Grusha Prasad",
      "Tal Linzen",
      "Yoav Goldberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.06965"
  },
  {
    "id": "arXiv:2105.07044",
    "title": "SA-GAN: Structure-Aware GAN for Organ-Preserving Synthetic CT Generation",
    "abstract": "Comments: Accepted to MICCAI 2021",
    "descriptor": "\nComments: Accepted to MICCAI 2021\n",
    "authors": [
      "Hajar Emami",
      "Ming Dong",
      "Siamak Nejad-Davarani",
      "Carri Glide-Hurst"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07044"
  },
  {
    "id": "arXiv:2105.07111",
    "title": "Prescriptive Process Monitoring for Cost-Aware Cycle Time Reduction",
    "abstract": "Prescriptive Process Monitoring for Cost-Aware Cycle Time Reduction",
    "descriptor": "",
    "authors": [
      "Zahra Dasht Bozorgi",
      "Irene Teinemaa",
      "Marlon Dumas",
      "Marcello La Rosa",
      "Artem Polyvyanyy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.07111"
  },
  {
    "id": "arXiv:2105.07605",
    "title": "Utility Maximization for Multihop Wireless Networks Employing BATS Codes",
    "abstract": "Comments: This paper was presented in part at 2020 IEEE International Conference on Communications",
    "descriptor": "\nComments: This paper was presented in part at 2020 IEEE International Conference on Communications\n",
    "authors": [
      "Yanyan Dong",
      "Sheng Jin",
      "Yanzuo Chen",
      "Shenghao Yang",
      "Hoover H. F. Yin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.07605"
  },
  {
    "id": "arXiv:2105.07609",
    "title": "Intrablock Interleaving for Batched Network Coding with Blockwise  Adaptive Recoding",
    "abstract": "Comments: This paper was presented in part at 2021 IEEE International Symposium on Information Theory",
    "descriptor": "\nComments: This paper was presented in part at 2021 IEEE International Symposium on Information Theory\n",
    "authors": [
      "Hoover H. F. Yin",
      "Ka Hei Ng",
      "Allen Z. Zhong",
      "Raymond W. Yeung",
      "Shenghao Yang",
      "Ian Y. Y. Chan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.07609"
  },
  {
    "id": "arXiv:2105.07614",
    "title": "A Unified Adaptive Recoding Framework for Batched Network Coding",
    "abstract": "Comments: This paper was presented in part at 2019 IEEE International Symposium on Information Theory",
    "descriptor": "\nComments: This paper was presented in part at 2019 IEEE International Symposium on Information Theory\n",
    "authors": [
      "Hoover H. F. Yin",
      "Bin Tang",
      "Ka Hei Ng",
      "Shenghao Yang",
      "Xishi Wang",
      "Qiaoqiao Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.07614"
  },
  {
    "id": "arXiv:2105.09136",
    "title": "Periodic Freight Demand Estimation for Large-scale Tactical Planning",
    "abstract": "Periodic Freight Demand Estimation for Large-scale Tactical Planning",
    "descriptor": "",
    "authors": [
      "Greta Laage",
      "Emma Frejinger",
      "Gilles Savard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.09136"
  },
  {
    "id": "arXiv:2105.09601",
    "title": "See, Hear, Read: Leveraging Multimodality with Guided Attention for  Abstractive Text Summarization",
    "abstract": "Comments: Journal paper accepted in Knowledge Based Systems",
    "descriptor": "\nComments: Journal paper accepted in Knowledge Based Systems\n",
    "authors": [
      "Yash Kumar Atri",
      "Shraman Pramanick",
      "Vikram Goyal",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.09601"
  },
  {
    "id": "arXiv:2105.11103",
    "title": "Dissecting Click Fraud Autonomy in the Wild",
    "abstract": "Comments: Accepted to ACM CCS 2021",
    "descriptor": "\nComments: Accepted to ACM CCS 2021\n",
    "authors": [
      "Tong Zhu",
      "Yan Meng",
      "Haotian Hu",
      "Xiaokuan Zhang",
      "Minhui Xue",
      "Haojin Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.11103"
  },
  {
    "id": "arXiv:2105.11259",
    "title": "PTR: Prompt Tuning with Rules for Text Classification",
    "abstract": "PTR: Prompt Tuning with Rules for Text Classification",
    "descriptor": "",
    "authors": [
      "Xu Han",
      "Weilin Zhao",
      "Ning Ding",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.11259"
  },
  {
    "id": "arXiv:2105.11609",
    "title": "Polarimetric Spatio-Temporal Light Transport Probing",
    "abstract": "Polarimetric Spatio-Temporal Light Transport Probing",
    "descriptor": "",
    "authors": [
      "Seung-Hwan Baek",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.11609"
  },
  {
    "id": "arXiv:2105.13509",
    "title": "Learning to Stylize Novel Views",
    "abstract": "Comments: Project page: this https URL Code: this https URL",
    "descriptor": "\nComments: Project page: this https URL Code: this https URL\n",
    "authors": [
      "Hsin-Ping Huang",
      "Hung-Yu Tseng",
      "Saurabh Saini",
      "Maneesh Singh",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13509"
  },
  {
    "id": "arXiv:2105.13753",
    "title": "New Encoder Learning for Captioning Heavy Rain Images via Semantic  Visual Feature Matching",
    "abstract": "New Encoder Learning for Captioning Heavy Rain Images via Semantic  Visual Feature Matching",
    "descriptor": "",
    "authors": [
      "Chang-Hwan Son",
      "Pung-Hwi Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13753"
  },
  {
    "id": "arXiv:2105.13790",
    "title": "Concentration Inequalities for Cross-validation in Scattered Data  Approximation",
    "abstract": "Concentration Inequalities for Cross-validation in Scattered Data  Approximation",
    "descriptor": "",
    "authors": [
      "Felix Bartel",
      "Ralf Hielscher"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13790"
  },
  {
    "id": "arXiv:2105.14685",
    "title": "DeepChange: A Long-Term Person Re-Identification Benchmark",
    "abstract": "DeepChange: A Long-Term Person Re-Identification Benchmark",
    "descriptor": "",
    "authors": [
      "Peng Xu",
      "Xiatian Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14685"
  },
  {
    "id": "arXiv:2105.14707",
    "title": "Emergence and algorithmic information dynamics of systems and observers",
    "abstract": "Emergence and algorithmic information dynamics of systems and observers",
    "descriptor": "",
    "authors": [
      "Felipe S. Abrah\u00e3o",
      "Hector Zenil"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.14707"
  },
  {
    "id": "arXiv:2106.00589",
    "title": "Improving Long-Term Metrics in Recommendation Systems using  Short-Horizon Reinforcement Learning",
    "abstract": "Improving Long-Term Metrics in Recommendation Systems using  Short-Horizon Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Bogdan Mazoure",
      "Paul Mineiro",
      "Pavithra Srinath",
      "Reza Sharifi Sedeh",
      "Doina Precup",
      "Adith Swaminathan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00589"
  },
  {
    "id": "arXiv:2106.01621",
    "title": "ERANNs: Efficient Residual Audio Neural Networks for Audio Pattern  Recognition",
    "abstract": "ERANNs: Efficient Residual Audio Neural Networks for Audio Pattern  Recognition",
    "descriptor": "",
    "authors": [
      "Sergey Verbitskiy",
      "Vladimir Berikov",
      "Viacheslav Vyshegorodtsev"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.01621"
  },
  {
    "id": "arXiv:2106.02588",
    "title": "Stochastic gradient descent with noise of machine learning type. Part  II: Continuous time analysis",
    "abstract": "Stochastic gradient descent with noise of machine learning type. Part  II: Continuous time analysis",
    "descriptor": "",
    "authors": [
      "Stephan Wojtowytsch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02588"
  },
  {
    "id": "arXiv:2106.03821",
    "title": "Active Speaker Detection as a Multi-Objective Optimization with  Uncertainty-based Multimodal Fusion",
    "abstract": "Comments: In INTERSPEECH 2021",
    "descriptor": "\nComments: In INTERSPEECH 2021\n",
    "authors": [
      "Baptiste Pouthier",
      "Laurent Pilati",
      "Leela K. Gudupudi",
      "Charles Bouveyron",
      "Frederic Precioso"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.03821"
  },
  {
    "id": "arXiv:2106.03919",
    "title": "Learning to Detect Multi-Modal Grasps for Dexterous Grasping in Dense  Clutter",
    "abstract": "Comments: IROS 2021 Accepted Version",
    "descriptor": "\nComments: IROS 2021 Accepted Version\n",
    "authors": [
      "Matt Corsaro",
      "Stefanie Tellex",
      "George Konidaris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.03919"
  },
  {
    "id": "arXiv:2106.04112",
    "title": "Harnessing Unrecognizable Faces for Improving Face Recognition",
    "abstract": "Harnessing Unrecognizable Faces for Improving Face Recognition",
    "descriptor": "",
    "authors": [
      "Siqi Deng",
      "Yuanjun Xiong",
      "Meng Wang",
      "Wei Xia",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04112"
  },
  {
    "id": "arXiv:2106.04280",
    "title": "Optimizing a Binary Intelligent Reflecting Surface for OFDM  Communications under Mutual Coupling",
    "abstract": "Comments: To appear at the 25th International ITG Workshop on Smart Antennas (WSA 2021), 6 pages, 6 figures. The code and dataset is available at this https URL",
    "descriptor": "\nComments: To appear at the 25th International ITG Workshop on Smart Antennas (WSA 2021), 6 pages, 6 figures. The code and dataset is available at this https URL\n",
    "authors": [
      "Emil Bj\u00f6rnson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.04280"
  },
  {
    "id": "arXiv:2106.04803",
    "title": "CoAtNet: Marrying Convolution and Attention for All Data Sizes",
    "abstract": "CoAtNet: Marrying Convolution and Attention for All Data Sizes",
    "descriptor": "",
    "authors": [
      "Zihang Dai",
      "Hanxiao Liu",
      "Quoc V. Le",
      "Mingxing Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04803"
  },
  {
    "id": "arXiv:2106.07487",
    "title": "pix2rule: End-to-end Neuro-symbolic Rule Learning",
    "abstract": "Comments: IJCLR-NeSy, 41 pages",
    "descriptor": "\nComments: IJCLR-NeSy, 41 pages\n",
    "authors": [
      "Nuri Cingillioglu",
      "Alessandra Russo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.07487"
  },
  {
    "id": "arXiv:2106.10533",
    "title": "Learning to Reach, Swim, Walk and Fly in One Trial: Data-Driven Control  with Scarce Data and Side Information",
    "abstract": "Comments: Initial submission",
    "descriptor": "\nComments: Initial submission\n",
    "authors": [
      "Franck Djeumou",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.10533"
  },
  {
    "id": "arXiv:2106.10852",
    "title": "CUDA-GHR: Controllable Unsupervised Domain Adaptation for Gaze and Head  Redirection",
    "abstract": "Comments: 21 pages, 6 figures",
    "descriptor": "\nComments: 21 pages, 6 figures\n",
    "authors": [
      "Swati Jindal",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10852"
  },
  {
    "id": "arXiv:2106.12995",
    "title": "Userfault Objects: Transparent Programmable Memory",
    "abstract": "Comments: In Proceedings of ICOOLPS '21: Workshop on Implementation, Compilation, Optimization of OO Languages, Programs and Systems (ICOOOLPS '21). UFOs repository: this https URL",
    "descriptor": "\nComments: In Proceedings of ICOOLPS '21: Workshop on Implementation, Compilation, Optimization of OO Languages, Programs and Systems (ICOOOLPS '21). UFOs repository: this https URL\n",
    "authors": [
      "Konrad Siek",
      "Colette Kerr"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.12995"
  },
  {
    "id": "arXiv:2106.13092",
    "title": "BotRGCN: Twitter Bot Detection with Relational Graph Convolutional  Networks",
    "abstract": "Comments: accepted at ASONAM 2021 as short paper; this is the full paper version at the time of submission. arXiv admin note: text overlap with arXiv:2106.13089",
    "descriptor": "\nComments: accepted at ASONAM 2021 as short paper; this is the full paper version at the time of submission. arXiv admin note: text overlap with arXiv:2106.13089\n",
    "authors": [
      "Shangbin Feng",
      "Herun Wan",
      "Ningnan Wang",
      "Minnan Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13092"
  },
  {
    "id": "arXiv:2106.13233",
    "title": "Post-Selections in AI and How to Avoid Them",
    "abstract": "Comments: 29 pages, 5 figures. An earlier vision of the first part has been accepted as an IJCNN 2021 paper and an earlier version of the second part has been accepted as an ICDL 2021 paper",
    "descriptor": "\nComments: 29 pages, 5 figures. An earlier vision of the first part has been accepted as an IJCNN 2021 paper and an earlier version of the second part has been accepted as an ICDL 2021 paper\n",
    "authors": [
      "Juyang Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.13233"
  },
  {
    "id": "arXiv:2107.01518",
    "title": "Hierarchical Policies for Cluttered-Scene Grasping with Latent Plans",
    "abstract": "Hierarchical Policies for Cluttered-Scene Grasping with Latent Plans",
    "descriptor": "",
    "authors": [
      "Lirui Wang",
      "Yu Xiang",
      "Xiangyun Meng",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.01518"
  },
  {
    "id": "arXiv:2107.02104",
    "title": "RATCHET: Medical Transformer for Chest X-ray Diagnosis and Reporting",
    "abstract": "RATCHET: Medical Transformer for Chest X-ray Diagnosis and Reporting",
    "descriptor": "",
    "authors": [
      "Benjamin Hou",
      "Georgios Kaissis",
      "Ronald Summers",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.02104"
  },
  {
    "id": "arXiv:2107.02823",
    "title": "Deep Learning based Micro-expression Recognition: A Survey",
    "abstract": "Comments: 23 pages, 12 figures",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Yante Li",
      "Jinsheng Wei",
      "Seyednavid Mohammadifoumani",
      "Yang Liu",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2107.02823"
  },
  {
    "id": "arXiv:2107.02993",
    "title": "Embedding digital chronotherapy into medical devices -- A canine  validation for controlling status epilepticus through multi-scale rhythmic  brain stimulation",
    "abstract": "Comments: 6 text pages, 4 main figures, Fig 1 has 4 panels, Fig 2 has 3 panels, Fig 4 has 2 panels. 2 text pages of supplementary material, 1 supplementary figure",
    "descriptor": "\nComments: 6 text pages, 4 main figures, Fig 1 has 4 panels, Fig 2 has 3 panels, Fig 4 has 2 panels. 2 text pages of supplementary material, 1 supplementary figure\n",
    "authors": [
      "Mayela Zamora",
      "Sebastian Meller",
      "Filip Kajin",
      "James J Sermon",
      "Robert Toth",
      "Moaad Benjaber",
      "Derk-Jan Dijk",
      "Rafal Bogacz",
      "Gregory A Worrell",
      "Antonio Valentin",
      "Benoit Duchet",
      "Holger A Volk",
      "Timothy Denison"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2107.02993"
  },
  {
    "id": "arXiv:2107.05252",
    "title": "OmniLytics: A Blockchain-based Secure Data Market for Decentralized  Machine Learning",
    "abstract": "Comments: An initial version of the article has been published in International Workshop on Federated Learning for User Privacy and Data Confidentiality in Conjunction with ICML 2021(this http URL). This version has been submmited to AAAI'22",
    "descriptor": "\nComments: An initial version of the article has been published in International Workshop on Federated Learning for User Privacy and Data Confidentiality in Conjunction with ICML 2021(this http URL). This version has been submmited to AAAI'22\n",
    "authors": [
      "Jiacheng Liang",
      "Songze Li",
      "Wensi Jiang",
      "Bochuan Cao",
      "Chaoyang He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.05252"
  },
  {
    "id": "arXiv:2107.06011",
    "title": "Teaching Agents how to Map: Spatial Reasoning for Multi-Object  Navigation",
    "abstract": "Teaching Agents how to Map: Spatial Reasoning for Multi-Object  Navigation",
    "descriptor": "",
    "authors": [
      "Pierre Marza",
      "Laetitia Matignon",
      "Olivier Simonin",
      "Christian Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.06011"
  },
  {
    "id": "arXiv:2107.09698",
    "title": "Mono2Micro: A Practical and Effective Tool for Decomposing Monolithic  Java Applications to Microservices",
    "abstract": "Mono2Micro: A Practical and Effective Tool for Decomposing Monolithic  Java Applications to Microservices",
    "descriptor": "",
    "authors": [
      "Anup Kalia",
      "Jin Xiao",
      "Rahul Krishna",
      "Saurabh Sinha",
      "Maja Vukovic",
      "Debasish Banerjee"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.09698"
  },
  {
    "id": "arXiv:2107.10302",
    "title": "Adversarial for Good? How the Adversarial ML Community's Values Impede  Socially Beneficial Uses of Attacks",
    "abstract": "Comments: Author list is ordered alphabetically as there is equal contribution. 4 pages Accepted by the ICML 2021 workshop on \"A Blessing in Disguise:The Prospects and Perils of Adversarial Machine Learning\"",
    "descriptor": "\nComments: Author list is ordered alphabetically as there is equal contribution. 4 pages Accepted by the ICML 2021 workshop on \"A Blessing in Disguise:The Prospects and Perils of Adversarial Machine Learning\"\n",
    "authors": [
      "Kendra Albert",
      "Maggie Delano",
      "Bogdan Kulynych",
      "Ram Shankar Siva Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.10302"
  },
  {
    "id": "arXiv:2107.11921",
    "title": "Compensation Learning",
    "abstract": "Compensation Learning",
    "descriptor": "",
    "authors": [
      "Rujing Yao",
      "Ou Wu",
      "Mengyang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.11921"
  },
  {
    "id": "arXiv:2107.12499",
    "title": "CalCROP21: A Georeferenced multi-spectral dataset of Satellite Imagery  and Crop Labels",
    "abstract": "Comments: 13 pages; 11 figures",
    "descriptor": "\nComments: 13 pages; 11 figures\n",
    "authors": [
      "Rahul Ghosh",
      "Praveen Ravirathinam",
      "Xiaowei Jia",
      "Ankush Khandelwal",
      "David Mulla",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.12499"
  },
  {
    "id": "arXiv:2107.12514",
    "title": "Language Grounding with 3D Objects",
    "abstract": "Comments: Conference on Robot Learning (CoRL) 2021",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL) 2021\n",
    "authors": [
      "Jesse Thomason",
      "Mohit Shridhar",
      "Yonatan Bisk",
      "Chris Paxton",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.12514"
  },
  {
    "id": "arXiv:2107.14581",
    "title": "Causality in Higher Order Process Theories",
    "abstract": "Comments: In Proceedings QPL 2021, arXiv:2109.04886",
    "descriptor": "\nComments: In Proceedings QPL 2021, arXiv:2109.04886\n",
    "authors": [
      "Matt Wilson",
      "Giulio Chiribella"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2107.14581"
  },
  {
    "id": "arXiv:2108.00082",
    "title": "Towards Continual Entity Learning in Language Models for Conversational  Agents",
    "abstract": "Comments: Submitted to NeurIPS 2021. Paper is under review",
    "descriptor": "\nComments: Submitted to NeurIPS 2021. Paper is under review\n",
    "authors": [
      "Ravi Teja Gadde",
      "Ivan Bulyko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.00082"
  },
  {
    "id": "arXiv:2108.00490",
    "title": "A survey of Monte Carlo methods for noisy and costly densities with  application to reinforcement learning",
    "abstract": "A survey of Monte Carlo methods for noisy and costly densities with  application to reinforcement learning",
    "descriptor": "",
    "authors": [
      "F. Llorente",
      "L. Martino",
      "J. Read",
      "D. Delgado"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.00490"
  },
  {
    "id": "arXiv:2108.00966",
    "title": "Rationality and Reciprocity of Opinion Dynamics in Games",
    "abstract": "Rationality and Reciprocity of Opinion Dynamics in Games",
    "descriptor": "",
    "authors": [
      "Shinkyu Park",
      "Anastasia Bizyaeva",
      "Mari Kawakatsu",
      "Alessio Franci",
      "Naomi Ehrich Leonard"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.00966"
  },
  {
    "id": "arXiv:2108.02093",
    "title": "Free Lunch for Co-Saliency Detection: Context Adjustment",
    "abstract": "Free Lunch for Co-Saliency Detection: Context Adjustment",
    "descriptor": "",
    "authors": [
      "Lingdong Kong",
      "Prakhar Ganesh",
      "Tan Wang",
      "Junhao Liu",
      "Le Zhang",
      "Yao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.02093"
  },
  {
    "id": "arXiv:2108.02938",
    "title": "ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models",
    "abstract": "Comments: ICCV 2021 (oral)",
    "descriptor": "\nComments: ICCV 2021 (oral)\n",
    "authors": [
      "Jooyoung Choi",
      "Sungwon Kim",
      "Yonghyun Jeong",
      "Youngjune Gwon",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.02938"
  },
  {
    "id": "arXiv:2108.04990",
    "title": "Perturbing Inputs for Fragile Interpretations in Deep Natural Language  Processing",
    "abstract": "Comments: EMNLP-BlackboxNLP, 2021",
    "descriptor": "\nComments: EMNLP-BlackboxNLP, 2021\n",
    "authors": [
      "Sanchit Sinha",
      "Hanjie Chen",
      "Arshdeep Sekhon",
      "Yangfeng Ji",
      "Yanjun Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.04990"
  },
  {
    "id": "arXiv:2108.05274",
    "title": "Instance-weighted Central Similarity for Multi-label Image Retrieval",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Zhiwei Zhang",
      "Allen Peng",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.05274"
  },
  {
    "id": "arXiv:2108.05481",
    "title": "Ships, Splashes, and Waves on a Vast Ocean",
    "abstract": "Ships, Splashes, and Waves on a Vast Ocean",
    "descriptor": "",
    "authors": [
      "Libo Huang",
      "Ziyin Qu",
      "Xun Tan",
      "Xinxin Zhang",
      "Dominik L. Michels",
      "Chenfanfu Jiang"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2108.05481"
  },
  {
    "id": "arXiv:2108.06259",
    "title": "VulnEx: Exploring Open-Source Software Vulnerabilities in Large  Development Organizations to Understand Risk Exposure",
    "abstract": "Comments: 5 pages, 3 figures, LaTeX; corrected typos and wording",
    "descriptor": "\nComments: 5 pages, 3 figures, LaTeX; corrected typos and wording\n",
    "authors": [
      "Frederik L. Dennig",
      "Eren Cakmak",
      "Henrik Plate",
      "Daniel A. Keim"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.06259"
  },
  {
    "id": "arXiv:2108.06962",
    "title": "Multi-Target Adversarial Frameworks for Domain Adaptation in Semantic  Segmentation",
    "abstract": "Comments: Accepted at the 2021 International Conference on Computer Vision (ICCV)",
    "descriptor": "\nComments: Accepted at the 2021 International Conference on Computer Vision (ICCV)\n",
    "authors": [
      "Antoine Saporta",
      "Tuan-Hung Vu",
      "Matthieu Cord",
      "Patrick P\u00e9rez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06962"
  },
  {
    "id": "arXiv:2108.08236",
    "title": "LOKI: Long Term and Key Intentions for Trajectory Prediction",
    "abstract": "Comments: ICCV 2021 (The dataset is available at this https URL)",
    "descriptor": "\nComments: ICCV 2021 (The dataset is available at this https URL)\n",
    "authors": [
      "Harshayu Girase",
      "Haiming Gang",
      "Srikanth Malla",
      "Jiachen Li",
      "Akira Kanehara",
      "Karttikeya Mangalam",
      "Chiho Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.08236"
  },
  {
    "id": "arXiv:2108.08923",
    "title": "CenterPoly: real-time instance segmentation using bounding polygons",
    "abstract": "Comments: Accepted to the 2nd Autonomous Vehicle Vision Workshop (AVVision)",
    "descriptor": "\nComments: Accepted to the 2nd Autonomous Vehicle Vision Workshop (AVVision)\n",
    "authors": [
      "Hughes Perreault",
      "Guillaume-Alexandre Bilodeau",
      "Nicolas Saunier",
      "Maguelonne H\u00e9ritier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.08923"
  },
  {
    "id": "arXiv:2108.10539",
    "title": "Counterfactual Explainable Recommendation",
    "abstract": "Comments: To be published at the 30th ACM International Conference on Information and Knowledge Management (CIKM 2021)",
    "descriptor": "\nComments: To be published at the 30th ACM International Conference on Information and Knowledge Management (CIKM 2021)\n",
    "authors": [
      "Juntao Tan",
      "Shuyuan Xu",
      "Yingqiang Ge",
      "Yunqi Li",
      "Xu Chen",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.10539"
  },
  {
    "id": "arXiv:2108.10723",
    "title": "Improving 3D Object Detection with Channel-wise Transformer",
    "abstract": "Comments: Accepted by ICCV2021",
    "descriptor": "\nComments: Accepted by ICCV2021\n",
    "authors": [
      "Hualian Sheng",
      "Sijia Cai",
      "Yuan Liu",
      "Bing Deng",
      "Jianqiang Huang",
      "Xian-Sheng Hua",
      "Min-Jian Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10723"
  },
  {
    "id": "arXiv:2108.12043",
    "title": "A Tutorial on Learning Disentangled Representations in the Imaging  Domain",
    "abstract": "Comments: We welcome any comments and suggestions for this draft. We will update the draft accordingly before submission. This draft follows a tutorial style but also surveys a considerable (200 citations) number of works",
    "descriptor": "\nComments: We welcome any comments and suggestions for this draft. We will update the draft accordingly before submission. This draft follows a tutorial style but also surveys a considerable (200 citations) number of works\n",
    "authors": [
      "Xiao Liu",
      "Pedro Sanchez",
      "Spyridon Thermos",
      "Alison Q. O'Neil",
      "Sotirios A.Tsaftaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.12043"
  },
  {
    "id": "arXiv:2108.12529",
    "title": "Designing for Multiple Centers of Power: A Taxonomy of Multi-level  Governance in Online Social Platforms",
    "abstract": "Designing for Multiple Centers of Power: A Taxonomy of Multi-level  Governance in Online Social Platforms",
    "descriptor": "",
    "authors": [
      "Shagun Jhaver",
      "Seth Frey",
      "Amy Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2108.12529"
  },
  {
    "id": "arXiv:2108.12848",
    "title": "Span Fine-tuning for Pre-trained Language Models",
    "abstract": "Comments: Accepted by EMNLP 2021 Finding(early version)",
    "descriptor": "\nComments: Accepted by EMNLP 2021 Finding(early version)\n",
    "authors": [
      "Rongzhou Bao",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.12848"
  },
  {
    "id": "arXiv:2108.13265",
    "title": "Predicting Road Flooding Risk with Machine Learning Approaches Using  Crowdsourced Reports and Fine-grained Traffic Data",
    "abstract": "Comments: 17 pages, 7 figures",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Faxi Yuan",
      "William Mobley",
      "Hamed Farahmand",
      "Yuanchang Xu",
      "Russell Blessing",
      "Shangjia Dong",
      "Ali Mostafavi",
      "Samuel D. Brody"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13265"
  },
  {
    "id": "arXiv:2109.00301",
    "title": "$\\infty$-former: Infinite Memory Transformer",
    "abstract": "$\\infty$-former: Infinite Memory Transformer",
    "descriptor": "",
    "authors": [
      "Pedro Henrique Martins",
      "Zita Marinho",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.00301"
  },
  {
    "id": "arXiv:2109.00993",
    "title": "LegaLMFiT: Efficient Short Legal Text Classification with LSTM Language  Model Pre-Training",
    "abstract": "LegaLMFiT: Efficient Short Legal Text Classification with LSTM Language  Model Pre-Training",
    "descriptor": "",
    "authors": [
      "Benjamin Clavi\u00e9",
      "Akshita Gheewala",
      "Paul Briton",
      "Marc Alphonsus",
      "Rym Laabiyad",
      "Francesco Piccoli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.00993"
  },
  {
    "id": "arXiv:2109.02363",
    "title": "From Alignment to Assignment: Frustratingly Simple Unsupervised Entity  Alignment",
    "abstract": "Comments: 11 pages; Accepted by EMNLP2021 (Main Conf)",
    "descriptor": "\nComments: 11 pages; Accepted by EMNLP2021 (Main Conf)\n",
    "authors": [
      "Xin Mao",
      "Wenting Wang",
      "Yuanbin Wu",
      "Man Lan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.02363"
  },
  {
    "id": "arXiv:2109.02789",
    "title": "Mixed Attention Transformer for Leveraging Word-Level Knowledge to  Neural Cross-Lingual Information Retrieval",
    "abstract": "Mixed Attention Transformer for Leveraging Word-Level Knowledge to  Neural Cross-Lingual Information Retrieval",
    "descriptor": "",
    "authors": [
      "Zhiqi Huang",
      "Hamed Bonab",
      "Sheikh Muhammad Sarwar",
      "Razieh Rahimi",
      "James Allan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.02789"
  },
  {
    "id": "arXiv:2109.02899",
    "title": "Blockchains through ontologies: the case study of the Ethereum ERC721  standard in OASIS (Extended Version)",
    "abstract": "Comments: Extended version of Blockchains through ontologies: the case study of the Ethereum ERC721 standard in OASIS, Proceedings of IDC 2021",
    "descriptor": "\nComments: Extended version of Blockchains through ontologies: the case study of the Ethereum ERC721 standard in OASIS, Proceedings of IDC 2021\n",
    "authors": [
      "Giampaolo Bella",
      "Domenico Cantone",
      "Cristiano Longo",
      "Marianna Nicolosi-Asmundo",
      "Daniele Francesco Santamaria"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.02899"
  },
  {
    "id": "arXiv:2109.03413",
    "title": "YouRefIt: Embodied Reference Understanding with Language and Gesture",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Yixin Chen",
      "Qing Li",
      "Deqian Kong",
      "Yik Lun Kei",
      "Song-Chun Zhu",
      "Tao Gao",
      "Yixin Zhu",
      "Siyuan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03413"
  },
  {
    "id": "arXiv:2109.03667",
    "title": "Energy Footprint of Blockchain Consensus Mechanisms Beyond Proof-of-Work",
    "abstract": "Energy Footprint of Blockchain Consensus Mechanisms Beyond Proof-of-Work",
    "descriptor": "",
    "authors": [
      "Moritz Platt",
      "Johannes Sedlmeir",
      "Daniel Platt",
      "Paolo Tasca",
      "Jiahua Xu",
      "Nikhil Vadgama",
      "Juan Ignacio Iba\u00f1ez"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.03667"
  },
  {
    "id": "arXiv:2109.03781",
    "title": "Highly Scalable and Provably Accurate Classification in Poincare Balls",
    "abstract": "Comments: A short version of this paper appears in ICDM 2021",
    "descriptor": "\nComments: A short version of this paper appears in ICDM 2021\n",
    "authors": [
      "Eli Chien",
      "Chao Pan",
      "Puoya Tabaghi",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03781"
  },
  {
    "id": "arXiv:2109.04453",
    "title": "Tube-Certified Trajectory Tracking for Nonlinear Systems With Robust  Control Contraction Metrics",
    "abstract": "Comments: Shorter version submitted to IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: Shorter version submitted to IEEE Robotics and Automation Letters\n",
    "authors": [
      "Pan Zhao",
      "Arun Lakshmanan",
      "Kasey Ackerman",
      "Aditya Gahlawat",
      "Marco Pavone",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04453"
  },
  {
    "id": "arXiv:2109.04566",
    "title": "SanitAIs: Unsupervised Data Augmentation to Sanitize Trojaned Neural  Networks",
    "abstract": "Comments: 7 pages, 10 figures",
    "descriptor": "\nComments: 7 pages, 10 figures\n",
    "authors": [
      "Kiran Karra",
      "Chace Ashcraft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04566"
  },
  {
    "id": "arXiv:2109.04966",
    "title": "Binarized P-Network: Deep Reinforcement Learning of Robot Control from  Raw Images on FPGA",
    "abstract": "Comments: 8 pages, Accepted by Robotics and Automation Letters",
    "descriptor": "\nComments: 8 pages, Accepted by Robotics and Automation Letters\n",
    "authors": [
      "Yuki Kadokawa",
      "Yoshihisa Tsurumine",
      "Takamitsu Matsubara"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04966"
  },
  {
    "id": "arXiv:2109.05186",
    "title": "Total Recall: a Customized Continual Learning Method for Neural Semantic  Parsers",
    "abstract": "Comments: 9 pages, accepted to EMNLP2021",
    "descriptor": "\nComments: 9 pages, accepted to EMNLP2021\n",
    "authors": [
      "Zhuang Li",
      "Lizhen Qu",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05186"
  },
  {
    "id": "arXiv:2109.05211",
    "title": "RobustART: Benchmarking Robustness on Architecture Design and Training  Techniques",
    "abstract": "RobustART: Benchmarking Robustness on Architecture Design and Training  Techniques",
    "descriptor": "",
    "authors": [
      "Shiyu Tang",
      "Ruihao Gong",
      "Yan Wang",
      "Aishan Liu",
      "Jiakai Wang",
      "Xinyun Chen",
      "Fengwei Yu",
      "Xianglong Liu",
      "Dawn Song",
      "Alan Yuille",
      "Philip H.S. Torr",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05211"
  },
  {
    "id": "arXiv:2109.05222",
    "title": "Fundamental limits of over-the-air optimization: Are analog schemes  optimal?",
    "abstract": "Comments: Few typos fixed and one reference added. An abridged version of this paper will appear in the proceedings of IEEE Global Communications Conference (GLOBECOM), Spain, 2021",
    "descriptor": "\nComments: Few typos fixed and one reference added. An abridged version of this paper will appear in the proceedings of IEEE Global Communications Conference (GLOBECOM), Spain, 2021\n",
    "authors": [
      "Shubham K Jha",
      "Prathamesh Mayekar",
      "Himanshu Tyagi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.05222"
  },
  {
    "id": "arXiv:2109.05602",
    "title": "Good-Enough Example Extrapolation",
    "abstract": "Comments: Camera-ready for EMNLP 2021 main conference. V2 is corrected with SMOTE citation and model setup language is clarified",
    "descriptor": "\nComments: Camera-ready for EMNLP 2021 main conference. V2 is corrected with SMOTE citation and model setup language is clarified\n",
    "authors": [
      "Jason Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05602"
  },
  {
    "id": "arXiv:2109.05700",
    "title": "Exploiting Heterogeneity in Robust Federated Best-Arm Identification",
    "abstract": "Exploiting Heterogeneity in Robust Federated Best-Arm Identification",
    "descriptor": "",
    "authors": [
      "Aritra Mitra",
      "Hamed Hassani",
      "George Pappas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.05700"
  },
  {
    "id": "arXiv:2109.05804",
    "title": "MLFW: A Database for Face Recognition on Masked Faces",
    "abstract": "MLFW: A Database for Face Recognition on Masked Faces",
    "descriptor": "",
    "authors": [
      "Chengrui Wang",
      "Han Fang",
      "Yaoyao Zhong",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05804"
  },
  {
    "id": "arXiv:2109.05877",
    "title": "Cardinality Estimation in DBMS: A Comprehensive Benchmark Evaluation",
    "abstract": "Cardinality Estimation in DBMS: A Comprehensive Benchmark Evaluation",
    "descriptor": "",
    "authors": [
      "Yuxing Han",
      "Ziniu Wu",
      "Peizhi Wu",
      "Rong Zhu",
      "Jingyi Yang",
      "Liang Wei Tan",
      "Kai Zeng",
      "Gao Cong",
      "Yanzhao Qin",
      "Andreas Pfadler",
      "Zhengping Qian",
      "Jingren Zhou",
      "Jiangneng Li",
      "Bin Cui"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05877"
  },
  {
    "id": "arXiv:2109.05958",
    "title": "Not All Models Localize Linguistic Knowledge in the Same Place: A  Layer-wise Probing on BERToids' Representations",
    "abstract": "Comments: Accepted to BlackboxNLP Workshop at EMNLP 2021",
    "descriptor": "\nComments: Accepted to BlackboxNLP Workshop at EMNLP 2021\n",
    "authors": [
      "Mohsen Fayyaz",
      "Ehsan Aghazadeh",
      "Ali Modarressi",
      "Hosein Mohebbi",
      "Mohammad Taher Pilehvar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05958"
  },
  {
    "id": "arXiv:2109.06160",
    "title": "Augmenting Decision Making via Interactive What-If Analysis",
    "abstract": "Comments: This version has been removed by arXiv administrators due to privacy policy",
    "descriptor": "\nComments: This version has been removed by arXiv administrators due to privacy policy\n",
    "authors": [
      "Sneha Gathani",
      "Madelon Hulsebos",
      "James Gale",
      "Peter J. Haas",
      "\u00c7a\u011fatay Demiralp"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06160"
  },
  {
    "id": "arXiv:2109.06232",
    "title": "The Emergence of the Shape Bias Results from Communicative Efficiency",
    "abstract": "Comments: Accepted at CoNLL 2021",
    "descriptor": "\nComments: Accepted at CoNLL 2021\n",
    "authors": [
      "Eva Portelance",
      "Michael C. Frank",
      "Dan Jurafsky",
      "Alessandro Sordoni",
      "Romain Laroche"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.06232"
  },
  {
    "id": "arXiv:2109.06264",
    "title": "Post-OCR Document Correction with large Ensembles of Character Sequence  Models",
    "abstract": "Post-OCR Document Correction with large Ensembles of Character Sequence  Models",
    "descriptor": "",
    "authors": [
      "Juan Ramirez-Orta",
      "Eduardo Xamena",
      "Ana Maguitman",
      "Evangelos Milios",
      "Axel J. Soto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06264"
  },
  {
    "id": "arXiv:2109.06432",
    "title": "Improved Few-shot Segmentation by Redefinition of the Roles of  Multi-level CNN Features",
    "abstract": "Improved Few-shot Segmentation by Redefinition of the Roles of  Multi-level CNN Features",
    "descriptor": "",
    "authors": [
      "Zhijie Wang",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06432"
  },
  {
    "id": "arXiv:2109.06442",
    "title": "Domain Sparsification of Discrete Distributions using Entropic  Independence",
    "abstract": "Domain Sparsification of Discrete Distributions using Entropic  Independence",
    "descriptor": "",
    "authors": [
      "Nima Anari",
      "Micha\u0142 Derezi\u0144ski",
      "Thuy-Duong Vuong",
      "Elizabeth Yang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.06442"
  },
  {
    "id": "arXiv:2109.06505",
    "title": "Optimal To-Do List Gamification for Long Term Planning",
    "abstract": "Optimal To-Do List Gamification for Long Term Planning",
    "descriptor": "",
    "authors": [
      "Saksham Consul",
      "Jugoslav Stojcheski",
      "Valkyrie Felso",
      "Falk Lieder"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06505"
  },
  {
    "id": "arXiv:2109.06590",
    "title": "High-Fidelity GAN Inversion for Image Attribute Editing",
    "abstract": "Comments: Project Page is at this https URL",
    "descriptor": "\nComments: Project Page is at this https URL\n",
    "authors": [
      "Tengfei Wang",
      "Yong Zhang",
      "Yanbo Fan",
      "Jue Wang",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06590"
  },
  {
    "id": "arXiv:2109.06595",
    "title": "GPT-2C: A GPT-2 parser for Cowrie honeypot logs",
    "abstract": "GPT-2C: A GPT-2 parser for Cowrie honeypot logs",
    "descriptor": "",
    "authors": [
      "Febrian Setianto",
      "Erion Tsani",
      "Fatima Sadiq",
      "Georgios Domalis",
      "Dimitris Tsakalidis",
      "Panos Kostakos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.06595"
  },
  {
    "id": "arXiv:2109.06619",
    "title": "Sampling Network Guided Cross-Entropy Method for Unsupervised Point  Cloud Registration",
    "abstract": "Comments: Accepted by ICCV-2021",
    "descriptor": "\nComments: Accepted by ICCV-2021\n",
    "authors": [
      "Haobo Jiang",
      "Yaqi Shen",
      "Jin Xie",
      "Jun Li",
      "Jianjun Qian",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.06619"
  },
  {
    "id": "arXiv:2109.06630",
    "title": "Detecting Layout Templates in Complex Multiregion Files",
    "abstract": "Detecting Layout Templates in Complex Multiregion Files",
    "descriptor": "",
    "authors": [
      "Gerardo Vitagliano",
      "Lan Jiang",
      "Felix Naumann"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.06630"
  },
  {
    "id": "arXiv:2109.06638",
    "title": "Learnable Discrete Wavelet Pooling (LDW-Pooling) For Convolutional  Networks",
    "abstract": "Learnable Discrete Wavelet Pooling (LDW-Pooling) For Convolutional  Networks",
    "descriptor": "",
    "authors": [
      "Jun-Wei Hsieh",
      "Ming-Ching Chang",
      "Bor-Shiun Wang",
      "Ping-Yang Chen",
      "Lipeng Ke",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06638"
  },
  {
    "id": "arXiv:2109.06661",
    "title": "Expert Knowledge-Guided Length-Variant Hierarchical Label Generation for  Proposal Classification",
    "abstract": "Comments: 10 pages, Accepted as regular paper by ICDM 2021",
    "descriptor": "\nComments: 10 pages, Accepted as regular paper by ICDM 2021\n",
    "authors": [
      "Meng Xiao",
      "Ziyue Qiao",
      "Yanjie Fu",
      "Yi Du",
      "Pengyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06661"
  },
  {
    "id": "arXiv:2109.06662",
    "title": "Identifying partial mouse brain microscopy images from Allen reference  atlas using a contrastively learned semantic space",
    "abstract": "Comments: Source code available at this https URL 7 pages, 5 figures. Version 2: Fix to 2nd author name and additional acknowledgments",
    "descriptor": "\nComments: Source code available at this https URL 7 pages, 5 figures. Version 2: Fix to 2nd author name and additional acknowledgments\n",
    "authors": [
      "Justinas Antanavicius",
      "Roberto Leiras",
      "Raghavendra Selvan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.06662"
  },
  {
    "id": "arXiv:2109.06668",
    "title": "Exploration in Deep Reinforcement Learning: A Comprehensive Survey",
    "abstract": "Comments: Repolishment is made, revise some incorrect descriptions",
    "descriptor": "\nComments: Repolishment is made, revise some incorrect descriptions\n",
    "authors": [
      "Tianpei Yang",
      "Hongyao Tang",
      "Chenjia Bai",
      "Jinyi Liu",
      "Jianye Hao",
      "Zhaopeng Meng",
      "Peng Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.06668"
  },
  {
    "id": "arXiv:2109.06719",
    "title": "Sparse Fuzzy Attention for Structured Sentiment Analysis",
    "abstract": "Sparse Fuzzy Attention for Structured Sentiment Analysis",
    "descriptor": "",
    "authors": [
      "Letain Peng",
      "Zuchao Li",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06719"
  },
  {
    "id": "arXiv:2109.06732",
    "title": "Tuna-AI: tuna biomass estimation with Machine Learning models trained on  oceanography and echosounder FAD data",
    "abstract": "Tuna-AI: tuna biomass estimation with Machine Learning models trained on  oceanography and echosounder FAD data",
    "descriptor": "",
    "authors": [
      "Daniel Precioso",
      "Manuel Navarro-Garc\u00eda",
      "Kathryn Gavira-O'Neill",
      "Alberto Torres-Barr\u00e1n",
      "David Gordo",
      "Victor Gallego-Alcal\u00e1",
      "David G\u00f3mez-Ullate"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06732"
  },
  {
    "id": "arXiv:2109.06768",
    "title": "MotionHint: Self-Supervised Monocular Visual Odometry with Motion  Constraints",
    "abstract": "MotionHint: Self-Supervised Monocular Visual Odometry with Motion  Constraints",
    "descriptor": "",
    "authors": [
      "Cong Wang",
      "Yu-Ping Wang",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06768"
  },
  {
    "id": "arXiv:2109.06838",
    "title": "ePiC: Employing Proverbs in Context as a Benchmark for Abstract Language  Understanding",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Sayan Ghosh",
      "Shashank Srivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06838"
  },
  {
    "id": "arXiv:2109.06862",
    "title": "Legal Transformer Models May Not Always Help",
    "abstract": "Legal Transformer Models May Not Always Help",
    "descriptor": "",
    "authors": [
      "Saibo Geng",
      "R\u00e9mi Lebret",
      "Karl Aberer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06862"
  }
]
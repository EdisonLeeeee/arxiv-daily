[
  {
    "id": "arXiv:2108.13446",
    "title": "Benchmarking the Accuracy and Robustness of Feedback Alignment  Algorithms",
    "abstract": "Backpropagation is the default algorithm for training deep neural networks\ndue to its simplicity, efficiency and high convergence rate. However, its\nrequirements make it impossible to be implemented in a human brain. In recent\nyears, more biologically plausible learning methods have been proposed. Some of\nthese methods can match backpropagation accuracy, and simultaneously provide\nother extra benefits such as faster training on specialized hardware (e.g.,\nASICs) or higher robustness against adversarial attacks. While the interest in\nthe field is growing, there is a necessity for open-source libraries and\ntoolkits to foster research and benchmark algorithms. In this paper, we present\nBioTorch, a software framework to create, train, and benchmark biologically\nmotivated neural networks. In addition, we investigate the performance of\nseveral feedback alignment methods proposed in the literature, thereby\nunveiling the importance of the forward and backward weight initialization and\noptimizer choice. Finally, we provide a novel robustness study of these methods\nagainst state-of-the-art white and black-box adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Albert Jim\u00e9nez Sanfiz",
      "Mohamed Akrout"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13446"
  },
  {
    "id": "arXiv:2108.13448",
    "title": "Machine Learning Methods for Management UAV Flocks -- a Survey",
    "abstract": "The development of unmanned aerial vehicles (UAVs) has been gaining momentum\nin recent years owing to technological advances and a significant reduction in\ntheir cost. UAV technology can be used in a wide range of domains, including\ncommunication, agriculture, security, and transportation. It may be useful to\ngroup the UAVs into clusters/flocks in certain domains, and various challenges\nassociated with UAV usage can be alleviated by clustering. Several\ncomputational challenges arise in UAV flock management, which can be solved by\nusing machine learning (ML) methods. In this survey, we describe the basic\nterms relating to UAVS and modern ML methods, and we provide an overview of\nrelated tutorials and surveys. We subsequently consider the different\nchallenges that appear in UAV flocks. For each issue, we survey several machine\nlearning-based methods that have been suggested in the literature to handle the\nassociated challenges. Thereafter, we describe various open issues in which ML\ncan be applied to solve the different challenges of flocks, and we suggest\nmeans of using ML methods for this purpose. This comprehensive review may be\nuseful for both researchers and developers in providing a wide view of various\naspects of state-of-the-art ML technologies that are applicable to flock\nmanagement.",
    "descriptor": "",
    "authors": [
      "Rina Azoulay",
      "Yoram Haddad",
      "Shulamit Reches"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13448"
  },
  {
    "id": "arXiv:2108.13449",
    "title": "Population Protocols: Beyond Runtime Analysis",
    "abstract": "I survey our recent work on the verification of population protocols and\ntheir state complexity.",
    "descriptor": "",
    "authors": [
      "Javier Esparza"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.13449"
  },
  {
    "id": "arXiv:2108.13450",
    "title": "Modularity and Heavy-Tailed Degree Distributions",
    "abstract": "Identifying clusters of vertices in graphs continues to be an important\nproblem, and modularity continues to be used as a tool for solving the problem.\nModularity, which measures the quality of a division of the vertices into\nclusters, explicitly treats vertices of different degrees differently, imposing\na larger penalty when high-degree vertices are put in the same cluster. We\nclaim that this unequal treatment negatively impacts the performance of\nclustering algorithms based on modularity for graphs with heavy-tailed degree\ndistributions. We used the Greedy Modularity hill-climb to find clusters in\ngraphs with power-law degree distributions and observed that it performed\npoorly clustering low-degree vertices. We propose a simple variant of\nmodularity that we call flat modularity. We found that, using the same\nalgorithm with the modified score instead, we improved the performance of the\nclustering algorithm on low-degree vertices and the overall performance as\nwell. We believe that the small change -- from modularity to flat modularity --\ncould improve the output in the many real-world processes that rely on\nmodularity to measure the quality of a division into clusters with only a small\nchange, which is really a simplification, to the implementation.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Larry Wilson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.13450"
  },
  {
    "id": "arXiv:2108.13454",
    "title": "Improving Query Representations for Dense Retrieval with Pseudo  Relevance Feedback",
    "abstract": "Dense retrieval systems conduct first-stage retrieval using embedded\nrepresentations and simple similarity metrics to match a query to documents.\nIts effectiveness depends on encoded embeddings to capture the semantics of\nqueries and documents, a challenging task due to the shortness and ambiguity of\nsearch queries. This paper proposes ANCE-PRF, a new query encoder that uses\npseudo relevance feedback (PRF) to improve query representations for dense\nretrieval. ANCE-PRF uses a BERT encoder that consumes the query and the top\nretrieved documents from a dense retrieval model, ANCE, and it learns to\nproduce better query embeddings directly from relevance labels. It also keeps\nthe document index unchanged to reduce overhead. ANCE-PRF significantly\noutperforms ANCE and other recent dense retrieval systems on several datasets.\nAnalysis shows that the PRF encoder effectively captures the relevant and\ncomplementary information from PRF documents, while ignoring the noise with its\nlearned attention mechanism.",
    "descriptor": "\nComments: Accepted at CIKM 2021\n",
    "authors": [
      "HongChien Yu",
      "Chenyan Xiong",
      "Jamie Callan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13454"
  },
  {
    "id": "arXiv:2108.13459",
    "title": "LSD-StructureNet: Modeling Levels of Structural Detail in 3D Part  Hierarchies",
    "abstract": "Generative models for 3D shapes represented by hierarchies of parts can\ngenerate realistic and diverse sets of outputs. However, existing models suffer\nfrom the key practical limitation of modelling shapes holistically and thus\ncannot perform conditional sampling, i.e. they are not able to generate\nvariants on individual parts of generated shapes without modifying the rest of\nthe shape. This is limiting for applications such as 3D CAD design that involve\nadjusting created shapes at multiple levels of detail. To address this, we\nintroduce LSD-StructureNet, an augmentation to the StructureNet architecture\nthat enables re-generation of parts situated at arbitrary positions in the\nhierarchies of its outputs. We achieve this by learning individual,\nprobabilistic conditional decoders for each hierarchy depth. We evaluate\nLSD-StructureNet on the PartNet dataset, the largest dataset of 3D shapes\nrepresented by hierarchies of parts. Our results show that contrarily to\nexisting methods, LSD-StructureNet can perform conditional sampling without\nimpacting inference speed or the realism and diversity of its outputs.",
    "descriptor": "\nComments: accepted by ICCV 2021\n",
    "authors": [
      "Dominic Roberts",
      "Ara Danielyan",
      "Hang Chu",
      "Mani Golparvar-Fard",
      "David Forsyth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2108.13459"
  },
  {
    "id": "arXiv:2108.13461",
    "title": "Time Series Prediction using Deep Learning Methods in Healthcare",
    "abstract": "Traditional machine learning methods face two main challenges in dealing with\nhealthcare predictive analytics tasks. First, the high-dimensional nature of\nhealthcare data needs labor-intensive and time-consuming processes to select an\nappropriate set of features for each new task. Secondly, these methods depend\non feature engineering to capture the sequential nature of patient data, which\nmay not adequately leverage the temporal patterns of the medical events and\ntheir dependencies. Recent deep learning methods have shown promising\nperformance for various healthcare prediction tasks by addressing the\nhigh-dimensional and temporal challenges of medical data. These methods can\nlearn useful representations of key factors (e.g., medical concepts or\npatients) and their interactions from high-dimensional raw (or\nminimally-processed) healthcare data. In this paper we systemically reviewed\nstudies focused on using deep learning as the prediction model to leverage\npatient time series data for a healthcare prediction task from methodological\nperspective. To identify relevant studies, MEDLINE, IEEE, Scopus and ACM\ndigital library were searched for studies published up to February 7th 2021. We\nfound that researchers have contributed to deep time series prediction\nliterature in ten research streams: deep learning models, missing value\nhandling, irregularity handling, patient representation, static data inclusion,\nattention mechanisms, interpretation, incorporating medical ontologies,\nlearning strategies, and scalability. This study summarizes research insights\nfrom these literature streams, identifies several critical research gaps, and\nsuggests future research opportunities for deep learning in patient time series\ndata.",
    "descriptor": "",
    "authors": [
      "Mohammad Amin Morid",
      "Olivia R. Liu Sheng",
      "Joseph Dunbar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13461"
  },
  {
    "id": "arXiv:2108.13465",
    "title": "Full-Cycle Energy Consumption Benchmark for Low-Carbon Computer Vision",
    "abstract": "The energy consumption of deep learning models is increasing at a\nbreathtaking rate, which raises concerns due to potential negative effects on\ncarbon neutrality in the context of global warming and climate change. With the\nprogress of efficient deep learning techniques, e.g., model compression,\nresearchers can obtain efficient models with fewer parameters and smaller\nlatency. However, most of the existing efficient deep learning methods do not\nexplicitly consider energy consumption as a key performance indicator.\nFurthermore, existing methods mostly focus on the inference costs of the\nresulting efficient models, but neglect the notable energy consumption\nthroughout the entire life cycle of the algorithm. In this paper, we present\nthe first large-scale energy consumption benchmark for efficient computer\nvision models, where a new metric is proposed to explicitly evaluate the\nfull-cycle energy consumption under different model usage intensity. The\nbenchmark can provide insights for low carbon emission when selecting efficient\ndeep learning algorithms in different model usage scenarios.",
    "descriptor": "\nComments: ArXiv Preprint\n",
    "authors": [
      "Bo Li",
      "Xinyang Jiang",
      "Donglin Bai",
      "Yuge Zhang",
      "Ningxin Zheng",
      "Xuanyi Dong",
      "Lu Liu",
      "Yuqing Yang",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13465"
  },
  {
    "id": "arXiv:2108.13468",
    "title": "A Boundary-Layer Preconditioner for Singularly Perturbed Convection  Diffusion",
    "abstract": "Motivated by a wide range of real-world problems whose solutions exhibit\nboundary and interior layers, the numerical analysis of discretizations of\nsingularly perturbed differential equations is an established sub-discipline\nwithin the study of the numerical approximation of solutions to differential\nequations. Consequently, much is known about how to accurately and stably\ndiscretize such equations on a priori adapted meshes, in order to properly\nresolve the layer structure present in their continuum solutions. However,\ndespite being a key step in the numerical simulation process, much less is\nknown about the efficient and accurate solution of the linear systems of\nequations corresponding to these discretizations. In this paper, we develop a\npreconditioning strategy that is tuned to the matrix structure induced by using\nlayer-adapted meshes for convection-diffusion equations, proving a strong\ncondition-number bound on the preconditioned system in one spatial dimension,\nand a weaker bound in two spatial dimensions. Numerical results confirm the\nefficiency of the resulting preconditioners in one and two dimensions, with\ntime-to-solution of less than one second for representative problems on\n$1024\\times 1024$ meshes and up to $40\\times$ speedup over standard sparse\ndirect solvers.",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Scott P. MacLachlan",
      "Niall Madden",
      "Th\u00e1i Anh Nhan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.13468"
  },
  {
    "id": "arXiv:2108.13475",
    "title": "An Analysis Of Entire Space Multi-Task Models For Post-Click Conversion  Prediction",
    "abstract": "Industrial recommender systems are frequently tasked with approximating\nprobabilities for multiple, often closely related, user actions. For example,\npredicting if a user will click on an advertisement and if they will then\npurchase the advertised product. The conceptual similarity between these tasks\nhas promoted the use of multi-task learning: a class of algorithms that aim to\nbring positive inductive transfer from related tasks. Here, we empirically\nevaluate multi-task learning approaches with neural networks for an online\nadvertising task. Specifically, we consider approximating the probability of\npost-click conversion events (installs) (CVR) for mobile app advertising on a\nlarge-scale advertising platform, using the related click events (CTR) as an\nauxiliary task. We use an ablation approach to systematically study recent\napproaches that incorporate both multitask learning and \"entire space modeling\"\nwhich train the CVR on all logged examples rather than learning a conditional\nlikelihood of conversion given clicked. Based on these results we show that\nseveral different approaches result in similar levels of positive transfer from\nthe data-abundant CTR task to the CVR task and offer some insight into how the\nmulti-task design choices address the two primary problems affecting the CVR\ntask: data sparsity and data bias. Our findings add to the growing body of\nevidence suggesting that standard multi-task learning is a sensible approach to\nmodelling related events in real-world large-scale applications and suggest the\nspecific multitask approach can be guided by ease of implementation in an\nexisting system.",
    "descriptor": "\nComments: RecSys 21 Late Breaking Results\n",
    "authors": [
      "Conor O'Brien",
      "Kin Sum Liu",
      "James Neufeld",
      "Rafael Barreto",
      "Jonathan J Hunt"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13475"
  },
  {
    "id": "arXiv:2108.13477",
    "title": "Toward a Socioeconomic-Aware HCI: Five Facets",
    "abstract": "Although inequities and biases relating to people in low socioeconomic\nsituations are starting to capture widespread attention in the popular press,\nlittle attention has been given to how such inequities and biases might pervade\ntechnology user experiences. Without understanding such inequities in user\nexperiences, technology designers can unwittingly introduce inequities tied to\nusers' socioeconomic status (SES). To enable the HCI community to address this\nproblem, in this paper, we consider a wide body of research that contributes to\nhow a user's socioeconomic status potentially shapes their interactions and\nuser experiences. We organize that research into 20 aspects of socioeconomic\nstatus; then derive a core set of five SES \"facets\" (attribute types and value\nranges) with differing impacts on user experiences for different SES strata;\nand finally, present actionable paths forward for HCI researchers and\npractitioners to draw upon these facets, to bring socioeconomic awareness to\nHCI.",
    "descriptor": "",
    "authors": [
      "Catherine Hu",
      "Christopher Perdriau",
      "Christopher Mendez",
      "Caroline Gao",
      "Abrar Fallatah",
      "Margaret Burnett"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2108.13477"
  },
  {
    "id": "arXiv:2108.13482",
    "title": "On Comparing and Enhancing Common Approaches to Network Community  Detection",
    "abstract": "In this work, we explore four common algorithms for community detection in\nnetworks, namely Agglomerative Hierarchical Clustering, Divisive Hierarchical\nClustering (Girvan-Newman), Fastgreedy and the Louvain Method. We investigate\ntheir mechanics and compare their differences in terms of implementation and\nresults of the clustering behavior on a standard dataset. We further propose\nsome enhancements to these algorithms that show promising results in our\nevaluations, such as self-neighboring for Neighbor Matrix constructions, a\ndeterministic slightly faster version of the Louvain Method that favors less\nbigger clusters and various implementation changes to the Fastgreedy algorithm.",
    "descriptor": "",
    "authors": [
      "Niko Motschnig",
      "Alexander Ramharter",
      "Oliver Schweiger",
      "Philipp Zabka",
      "Klaus-Tycho Foerster"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.13482"
  },
  {
    "id": "arXiv:2108.13487",
    "title": "Want To Reduce Labeling Cost? GPT-3 Can Help",
    "abstract": "Data annotation is a time-consuming and labor-intensive process for many NLP\ntasks. Although there exist various methods to produce pseudo data labels, they\nare often task-specific and require a decent amount of labeled data to start\nwith. Recently, the immense language model GPT-3 with 175 billion parameters\nhas achieved tremendous improvement across many few-shot learning tasks. In\nthis paper, we explore ways to leverage GPT-3 as a low-cost data labeler to\ntrain other models. We find that, to make the downstream model achieve the same\nperformance on a variety of NLU and NLG tasks, it costs 50% to 96% less to use\nlabels from GPT-3 than using labels from humans. Furthermore, we propose a\nnovel framework of combining pseudo labels from GPT-3 with human labels, which\nleads to even better performance with limited labeling budget. These results\npresent a cost-effective data labeling methodology that is generalizable to\nmany practical applications.",
    "descriptor": "\nComments: Findings of EMNLP 2021, 11 pages\n",
    "authors": [
      "Shuohang Wang",
      "Yang Liu",
      "Yichong Xu",
      "Chenguang Zhu",
      "Michael Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13487"
  },
  {
    "id": "arXiv:2108.13488",
    "title": "Structural Properties of Optimal Test Channels for Gaussian Multivariate  Partially Observable Distributed Sources",
    "abstract": "In this paper, we analyze the operational information rate distortion\nfunction (RDF) ${R}_{S;Z|Y}(\\Delta_X)$, introduced by Draper and Wornell\n\\cite{draper-wornell2004}, for a triple of jointly independent and identically\ndistributed, multivariate Gaussian random variables (RVs), $(X^n, S^n, Y^n)=\n\\{(X_{t}, S_t, Y_{t}): t=1,2, \\ldots,n\\}$, where $X^n$ is the source, $S^n$ is\na measurement of $X^n$, available to the encoder, $Y^n$ is side information\navailable to the decoder only, $Z^n$ is the auxiliary RV available to the\ndecoder, with respect to the square-error fidelity, between the source $X^n$\nand its reconstruction $\\widehat{X}^n$. We also analyze the RDF\n${R}_{S;\\widehat{X}|Y}(\\Delta_X)$ that corresponds to the above set up, when\nside information $Y^n$ is available to the encoder and decoder. The main\nresults include,\n(1) Structural properties of test channel realizations that induce\ndistributions, which achieve the two RDFs,\n(2) Water-filling solutions of the two RDFs, based on parallel channel\nrealizations of test channels,\n(3) A proof of equality ${R}_{S;Z|Y}(\\Delta_X) =\n{R}_{S;\\widehat{X}|Y}(\\Delta_X)$, i.e., side information $Y^n$ at both the\nencoder and decoder does not incur smaller compression, and\n(4) Relations to other RDFs, as degenerate cases, which show past literature,\ncontain oversights related to the optimal test channel realizations and value\nof the RDF ${R}_{S;Z|Y}(\\Delta_X)$.",
    "descriptor": "",
    "authors": [
      "Michail Gkagkos",
      "Evagoras Stylianou",
      "Charalambos D. Charalambous"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.13488"
  },
  {
    "id": "arXiv:2108.13490",
    "title": "Reactive and Risk-Aware Control for Signal Temporal Logic",
    "abstract": "The deployment of autonomous systems in uncertain and dynamic environments\nhas raised fundamental questions. Addressing these is pivotal to build fully\nautonomous systems and requires a systematic integration of planning and\ncontrol. We first propose reactive risk signal interval temporal logic\n(ReRiSITL) as an extension of signal temporal logic (STL) to formulate complex\nspatiotemporal specifications. Unlike STL, ReRiSITL allows to consider\nuncontrollable propositions that may model humans as well as random\nenvironmental events such as sensor failures. Additionally, ReRiSITL allows to\nincorporate risk measures, such as (but not limited to) the Conditional\nValue-at-Risk, to measure the risk of violating certain spatial specifications.\nSecond, we propose an algorithm to check if an ReRiSITL specification is\nsatisfiable. For this purpose, we abstract the ReRiSITL specification into a\ntimed signal transducer and devise a game-based approach. Third, we propose a\nreactive planning and control framework for dynamical control systems under\nReRiSITL specifications.",
    "descriptor": "\nComments: Conditionally accepted in the IEEE Transactions on Automatic Control\n",
    "authors": [
      "Lars Lindemann",
      "George J. Pappas",
      "Dimos V. Dimarogonas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2108.13490"
  },
  {
    "id": "arXiv:2108.13493",
    "title": "Semi-Supervised Exaggeration Detection of Health Science Press Releases",
    "abstract": "Public trust in science depends on honest and factual communication of\nscientific papers. However, recent studies have demonstrated a tendency of news\nmedia to misrepresent scientific papers by exaggerating their findings. Given\nthis, we present a formalization of and study into the problem of exaggeration\ndetection in science communication. While there are an abundance of scientific\npapers and popular media articles written about them, very rarely do the\narticles include a direct link to the original paper, making data collection\nchallenging. We address this by curating a set of labeled press\nrelease/abstract pairs from existing expert annotated studies on exaggeration\nin press releases of scientific papers suitable for benchmarking the\nperformance of machine learning models on the task. Using limited data from\nthis and previous studies on exaggeration detection in science, we introduce\nMT-PET, a multi-task version of Pattern Exploiting Training (PET), which\nleverages knowledge from complementary cloze-style QA tasks to improve few-shot\nlearning. We demonstrate that MT-PET outperforms PET and supervised learning\nboth when data is limited, as well as when there is an abundance of data for\nthe main task.",
    "descriptor": "\nComments: Accepted to EMNLP 2021; 13 pages, 6 figures, 9 tables\n",
    "authors": [
      "Dustin Wright",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13493"
  },
  {
    "id": "arXiv:2108.13499",
    "title": "Scene Synthesis via Uncertainty-Driven Attribute Synchronization",
    "abstract": "Developing deep neural networks to generate 3D scenes is a fundamental\nproblem in neural synthesis with immediate applications in architectural CAD,\ncomputer graphics, as well as in generating virtual robot training\nenvironments. This task is challenging because 3D scenes exhibit diverse\npatterns, ranging from continuous ones, such as object sizes and the relative\nposes between pairs of shapes, to discrete patterns, such as occurrence and\nco-occurrence of objects with symmetrical relationships. This paper introduces\na novel neural scene synthesis approach that can capture diverse feature\npatterns of 3D scenes. Our method combines the strength of both neural\nnetwork-based and conventional scene synthesis approaches. We use the\nparametric prior distributions learned from training data, which provide\nuncertainties of object attributes and relative attributes, to regularize the\noutputs of feed-forward neural models. Moreover, instead of merely predicting a\nscene layout, our approach predicts an over-complete set of attributes. This\nmethodology allows us to utilize the underlying consistency constraints among\nthe predicted attributes to prune infeasible predictions. Experimental results\nshow that our approach outperforms existing methods considerably. The generated\n3D scenes interpolate the training data faithfully while preserving both\ncontinuous and discrete feature patterns.",
    "descriptor": "",
    "authors": [
      "Haitao Yang",
      "Zaiwei Zhang",
      "Siming Yan",
      "Haibin Huang",
      "Chongyang Ma",
      "Yi Zheng",
      "Chandrajit Bajaj",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13499"
  },
  {
    "id": "arXiv:2108.13502",
    "title": "Generalizing Weighted Trees: A Bridge from Bitcoin to GHOST",
    "abstract": "Despite the tremendous interest in cryptocurrencies like Bitcoin and Ethereum\ntoday, many aspects of the underlying consensus protocols are poorly\nunderstood. Therefore, the search for protocols that improve either throughput\nor security (or both) continues. Bitcoin always selects the longest chain\n(i.e., the one with most work). Forks may occur when two miners extend the same\nblock simultaneously, and the frequency of forks depends on how fast blocks are\npropagated in the network. In the GHOST protocol, used by Ethereum, all blocks\ninvolved in the fork contribute to the security. However, the greedy chain\nselection rule of GHOST does not consider the full information available in the\nblock tree, which has led to some concerns about its security.\nThis paper introduces a new family of protocols, called Medium, which takes\nthe structure of the whole block tree into account, by weighting blocks\ndifferently according to their depths. Bitcoin and GHOST result as special\ncases. This protocol leads to new insights about the security of Bitcoin and\nGHOST and paves the way for developing network- and application-specific\nprotocols, in which the influence of forks on the chain-selection process can\nbe controlled. It is shown that almost all protocols in this family achieve\nstrictly greater throughput than Bitcoin (at the same security level) and\nresist attacks that can be mounted against GHOST.",
    "descriptor": "",
    "authors": [
      "Ignacio Amores-Sesar",
      "Christian Cachin",
      "Anna Parker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.13502"
  },
  {
    "id": "arXiv:2108.13509",
    "title": "An FEA surrogate model with Boundary Oriented Graph Embedding approach",
    "abstract": "In this work, we present a Boundary Oriented Graph Embedding (BOGE) approach\nfor the Graph Neural Network (GNN) to serve as a general surrogate model for\nregressing physical fields and solving boundary value problems. Providing\nshortcuts for both boundary elements and local neighbor elements, the BOGE\napproach can embed structured mesh elements into the graph and performs an\nefficient regression on large-scale triangular-mesh-based FEA results, which\ncannot be realized by other machine-learning-based surrogate methods. Focusing\non the cantilever beam problem, our BOGE approach cannot only fit the\ndistribution of stress fields but also regresses the topological optimization\nresults, which show its potential of realizing abstract decision-making design\nprocess. The BOGE approach with 3-layer DeepGCN model \\textcolor{blue}{achieves\nthe regression with MSE of 0.011706 (2.41\\% MAPE) for stress field prediction\nand 0.002735 MSE (with 1.58\\% elements having error larger than 0.01) for\ntopological optimization.} The overall concept of the BOGE approach paves the\nway for a general and efficient deep-learning-based FEA simulator that will\nbenefit both industry and design-related areas.",
    "descriptor": "",
    "authors": [
      "Xingyu Fu",
      "Fengfeng Zhou",
      "Dheeraj Peddireddy",
      "Zhengyang Kang",
      "Martin Byung-Guk Jun",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13509"
  },
  {
    "id": "arXiv:2108.13512",
    "title": "Energy-Efficient Massive MIMO for Serving Multiple Federated Learning  Groups",
    "abstract": "With its privacy preservation and communication efficiency, federated\nlearning (FL) has emerged as a learning framework that suits beyond 5G and\ntowards 6G systems. This work looks into a future scenario in which there are\nmultiple groups with different learning purposes and participating in different\nFL processes. We give energy-efficient solutions to demonstrate that this\nscenario can be realistic. First, to ensure a stable operation of multiple FL\nprocesses over wireless channels, we propose to use a massive multiple-input\nmultiple-output network to support the local and global FL training updates,\nand let the iterations of these FL processes be executed within the same\nlarge-scale coherence time. Then, we develop asynchronous and synchronous\ntransmission protocols where these iterations are asynchronously and\nsynchronously executed, respectively, using the downlink unicasting and\nconventional uplink transmission schemes. Zero-forcing processing is utilized\nfor both uplink and downlink transmissions. Finally, we propose an algorithm\nthat optimally allocates power and computation resources to save energy at both\nbase station and user sides, while guaranteeing a given maximum execution time\nthreshold of each FL iteration. Compared to the baseline schemes, the proposed\nalgorithm significantly reduces the energy consumption, especially when the\nnumber of base station antennas is large.",
    "descriptor": "\nComments: Accepted to appear in Proc. IEEE Global Communications Conference (GLOBECOM), Madrid, Spain, Dec. 2021. arXiv admin note: text overlap with arXiv:2107.09577\n",
    "authors": [
      "Tung T. Vu",
      "Hien Quoc Ngo",
      "Duy T. Ngo",
      "Minh N Dao",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.13512"
  },
  {
    "id": "arXiv:2108.13514",
    "title": "ConVIScope: Visual Analytics for Exploring Patient Conversations",
    "abstract": "The proliferation of text messaging for mobile health is generating a large\namount of patient-doctor conversations that can be extremely valuable to health\ncare professionals. We present ConVIScope, a visual text analytic system that\ntightly integrates interactive visualization with natural language processing\nin analyzing patient-doctor conversations. ConVIScope was developed in\ncollaboration with healthcare professionals following a user-centered iterative\ndesign. Case studies with six domain experts suggest the potential utility of\nConVIScope and reveal lessons for further developments.",
    "descriptor": "\nComments: 5 pages, 3 figures, accepted as short paper at IEEE VIS 2021\n",
    "authors": [
      "Raymond Li",
      "Enamul Hoque",
      "Giuseppe Carenini",
      "Richard Lester",
      "Raymond Chau"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13514"
  },
  {
    "id": "arXiv:2108.13515",
    "title": "SURENA IV: Towards A Cost-effective Full-size Humanoid Robot for  Real-world Scenarios",
    "abstract": "This paper describes the hardware, software framework, and experimental\ntesting of SURENA IV humanoid robotics platform. SURENA IV has 43 degrees of\nfreedom (DoFs), including seven DoFs for each arm, six DoFs for each hand, and\nsix DoFs for each leg, with a height of 170 cm and a mass of 68 kg and\nmorphological and mass properties similar to an average adult human. SURENA IV\naims to realize a cost-effective and anthropomorphic humanoid robot for\nreal-world scenarios. In this way, we demonstrate a locomotion framework based\non a novel and inexpensive predictive foot sensor that enables walking with 7cm\nfoot position error because of accumulative error of links and connections'\ndeflection(that has been manufactured by the tools which are available in the\nUniversities). Thanks to this sensor, the robot can walk on unknown obstacles\nwithout any force feedback, by online adaptation of foot height and\norientation. Moreover, the arm and hand of the robot have been designed to\ngrasp the objects with different stiffness and geometries that enable the robot\nto do drilling, visual servoing of a moving object, and writing his name on the\nwhite-board.",
    "descriptor": "",
    "authors": [
      "Aghil Yousefi-Koma",
      "Behnam Maleki",
      "Hessam Maleki",
      "Amin Amani",
      "Mohammad Ali Bazrafshani",
      "Hossein Keshavarz",
      "Ala Iranmanesh",
      "Alireza Yazdanpanah",
      "Hamidreza Alai",
      "Sahel Salehi",
      "Mahyar Ashkvari",
      "Milad Mousavi",
      "Milad Shafiee Ashtiani"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13515"
  },
  {
    "id": "arXiv:2108.13517",
    "title": "A Convolutional Neural Network-based Approach to Field Reconstruction",
    "abstract": "This work has been submitted to the IEEE for possible publication. Copyright\nmay be transferred without notice, after which this version may no longer be\naccessible.\nIn many applications, the spatial distribution of a field needs to be\ncarefully monitored to detect spikes, discontinuities or dangerous\nheterogeneities, but invasive monitoring approaches cannot be used. Besides,\ntechnical specifications about the process might not be available by preventing\nthe adoption of an accurate model of the system. In this work, a\nphysics-informed, data-driven algorithm that allows addressing these\nrequirements is presented. The approach is based on the implementation of a\nboundary element method (BEM)-scheme within a convolutional neural network.\nThanks to the capability of representing any continuous mathematical function\nwith a reduced number of parameters, the network allows predicting the field\nvalue in any point of the domain, given the boundary conditions and few\nmeasurements within the domain. The proposed approach was applied to\nreconstruct a field described by the Helmholtz equation over a\nthree-dimensional domain. A sensitivity analysis was also performed by\ninvestigating different physical conditions and different network\nconfigurations. Since the only assumption is the applicability of BEM, the\ncurrent approach can be applied to the monitoring of a wide range of processes,\nfrom the localization of the source of pollutant within a water reservoir to\nthe monitoring of the neutron flux in a nuclear reactor.",
    "descriptor": "",
    "authors": [
      "Roberto Ponciroli",
      "Andrea Rovinelli",
      "Lander Ibarra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2108.13517"
  },
  {
    "id": "arXiv:2108.13518",
    "title": "DoWhy: Addressing Challenges in Expressing and Validating Causal  Assumptions",
    "abstract": "Estimation of causal effects involves crucial assumptions about the\ndata-generating process, such as directionality of effect, presence of\ninstrumental variables or mediators, and whether all relevant confounders are\nobserved. Violation of any of these assumptions leads to significant error in\nthe effect estimate. However, unlike cross-validation for predictive models,\nthere is no global validator method for a causal estimate. As a result,\nexpressing different causal assumptions formally and validating them (to the\nextent possible) becomes critical for any analysis. We present DoWhy, a\nframework that allows explicit declaration of assumptions through a causal\ngraph and provides multiple validation tests to check a subset of these\nassumptions. Our experience with DoWhy highlights a number of open questions\nfor future research: developing new ways beyond causal graphs to express\nassumptions, the role of causal discovery in learning relevant parts of the\ngraph, and developing validation tests that can better detect errors, both for\naverage and conditional treatment effects. DoWhy is available at\nhttps://github.com/microsoft/dowhy.",
    "descriptor": "\nComments: Presented at ICML 2021 Workshop on the Neglected Assumptions in Causal Inference(NACI)\n",
    "authors": [
      "Amit Sharma",
      "Vasilis Syrgkanis",
      "Cheng Zhang",
      "Emre K\u0131c\u0131man"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13518"
  },
  {
    "id": "arXiv:2108.13521",
    "title": "ExaWorks: Workflows for Exascale",
    "abstract": "Exascale computers will offer transformative capabilities to combine\ndata-driven and learning-based approaches with traditional simulation\napplications to accelerate scientific discovery and insight. These software\ncombinations and integrations, however, are difficult to achieve due to\nchallenges of coordination and deployment of heterogeneous software components\non diverse and massive platforms. We present the ExaWorks project, which can\naddress many of these challenges: ExaWorks is leading a co-design process to\ncreate a workflow software development Toolkit (SDK) consisting of a wide range\nof workflow management tools that can be composed and interoperate through\ncommon interfaces. We describe the initial set of tools and interfaces\nsupported by the SDK, efforts to make them easier to apply to complex science\nchallenges, and examples of their application to exemplar cases. Furthermore,\nwe discuss how our project is working with the workflows community, large\ncomputing facilities as well as HPC platform vendors to sustainably address the\nrequirements of workflows at the exascale.",
    "descriptor": "",
    "authors": [
      "Aymen Al-Saadi",
      "Dong H. Ahn",
      "Yadu Babuji",
      "Kyle Chard",
      "James Corbett",
      "Mihael Hategan",
      "Stephen Herbein",
      "Shantenu Jha",
      "Daniel Laney",
      "Andre Merzky",
      "Todd Munson",
      "Michael Salim",
      "Mikhail Titov",
      "Matteo Turilli",
      "Justin M. Wozniak"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.13521"
  },
  {
    "id": "arXiv:2108.13522",
    "title": "The UW Virtual Brain Project: An immersive approach to teaching  functional neuroanatomy",
    "abstract": "Learning functional neuroanatomy requires forming mental representations of\n3D structure, but forming such representations from 2D textbook diagrams can be\nchallenging. We address this challenge in the UW Virtual Brain Project by\ndeveloping 3D narrated diagrams, which are interactive, guided tours through 3D\nmodels of perceptual systems. Lessons can be experienced in virtual realty (VR)\nor on a personal computer monitor (PC). We predicted participants would learn\nfrom lessons presented on both VR and PC devices (comparing pre-test/post-test\nscores), but that VR would be more effective for achieving both content-based\nlearning outcomes (i.e test performance) and experience-based learning outcomes\n(i.e., reported enjoyment and ease of use). All participants received lessons\nabout the visual system and auditory system, one in VR and one on a PC(order\ncounterbalanced). We assessed content learning using a drawing/labeling task on\npaper (2D drawing) in Experiment 1 and a Looking Glass autostereoscopic display\n(3D drawing) in Experiment 2. In both experiments, we found that the UW Virtual\nBrain Project lessons were effective for teaching functional neuroanatomy, with\nno difference between devices. However, participants reported VR was more\nenjoyable and easier to use. We also evaluated the VR lessons in our Classroom\nImplementation during an undergraduate course on perception. Students reported\nthat the VR lessons helped them make progress on course learning outcomes,\nespecially for learning system pathways. They suggested lessons could be\nimproved byadding more examples and providing more time to explore in VR.",
    "descriptor": "\nComments: To appear in Translational Issues in Psychological Science\n",
    "authors": [
      "Karen B. Schloss",
      "Melissa A. Schoenlein",
      "Ross Tredinnick",
      "Simon Smith",
      "Nathaniel Miller",
      "Chris Racey",
      "Christian Castro",
      "Bas Rokers"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2108.13522"
  },
  {
    "id": "arXiv:2108.13526",
    "title": "Computational Design of Active 3D-Printed Multi-State Structures for  Shape Morphing",
    "abstract": "Active structures have the ability to change their shape, properties, and\nfunctionality as a response to changing operational conditions, which makes\nthem more versatile than their static counterparts. However, most active\nstructures currently lack the capability to achieve multiple, different target\nstates with a single input actuation or require a tedious material programming\nstep. Furthermore, the systematic design and fabrication of active structures\nis still a challenge as many structures are designed by hand in a trial and\nerror process and thus are limited by engineers' knowledge and experience. In\nthis work, a computational design and fabrication framework is proposed to\ngenerate structures with multiple target states for one input actuation that\ndon't require a separate training step. A material dithering scheme based on\nmulti-material 3D printing is combined with locally applied copper coil heating\nelements and sequential heating patterns to control the thermo-mechanical\nproperties of the structures and switch between the different deformation\nmodes. A novel topology optimization approach based on power diagrams is used\nto encode the different target states in the structure while ensuring the\nfabricability of the structures and the compatibility with the drop-in heating\nelements. The versatility of the proposed framework is demonstrated for four\ndifferent example structures from engineering and computer graphics. The\nnumerical and experimental results show that the optimization framework can\nproduce structures that show the desired motion, but experimental accuracy is\nlimited by current fabrication methods. The generality of the proposed method\nmakes it suitable for the development of structures for applications in many\ndifferent fields from aerospace to robotics to animated fabrication in computer\ngraphics.",
    "descriptor": "",
    "authors": [
      "Thomas S. Lumpe",
      "Michael Tao",
      "Kristina Shea",
      "David I. W. Levin"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2108.13526"
  },
  {
    "id": "arXiv:2108.13530",
    "title": "Towards Consistent Document-level Entity Linking: Joint Models for  Entity Linking and Coreference Resolution",
    "abstract": "We consider the task of document-level entity linking (EL), where it is\nimportant to make consistent decisions for entity mentions over the full\ndocument jointly. We aim to leverage explicit \"connections\" among mentions\nwithin the document itself: we propose to join the EL task with that of\ncoreference resolution (coref). This is complementary to related works that\nexploit either (i) implicit document information (e.g., latent relations among\nentity mentions, or general language models) or (ii) connections between the\ncandidate links (e.g, as inferred from the external knowledge base).\nSpecifically, we cluster mentions that are linked via coreference, and enforce\na single EL for all of the clustered mentions together. The latter constraint\nhas the added benefit of increased coverage by joining EL candidate lists for\nthe thus clustered mentions. We formulate the coref+EL problem as a structured\nprediction task over directed trees and use a globally normalized model to\nsolve it. Experimental results on two datasets show a boost of up to +5%\nF1-score on both coref and EL tasks, compared to their standalone counterparts.\nFor a subset of hard cases, with individual mentions lacking the correct EL in\ntheir candidate entity list, we obtain a +50% increase in accuracy.",
    "descriptor": "",
    "authors": [
      "Klim Zaporojets",
      "Johannes Deleu",
      "Thomas Demeester",
      "Chris Develder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13530"
  },
  {
    "id": "arXiv:2108.13544",
    "title": "Approximation algorithms for priority Steiner tree problems",
    "abstract": "In the Priority Steiner Tree (PST) problem, we are given an undirected graph\n$G=(V,E)$ with a source $s \\in V$ and terminals $T \\subseteq V \\setminus\n\\{s\\}$, where each terminal $v \\in T$ requires a nonnegative priority $P(v)$.\nThe goal is to compute a minimum weight Steiner tree containing edges of\nvarying rates such that the path from $s$ to each terminal $v$ consists of\nedges of rate greater than or equal to $P(v)$. The PST problem with $k$\npriorities admits a $\\min\\{2 \\ln |T| + 2, k\\rho\\}$-approximation [Charikar et\nal., 2004], and is hard to approximate with ratio $c \\log \\log n$ for some\nconstant $c$ [Chuzhoy et al., 2008]. In this paper, we first strengthen the\nanalysis provided by [Charikar et al., 2004] for the $(2 \\ln |T| +\n2)$-approximation to show an approximation ratio of $\\lceil \\log_2 |T| \\rceil +\n1 \\le 1.443 \\ln |T| + 2$, then provide a very simple, parallelizable algorithm\nwhich achieves the same approximation ratio. We then consider a more difficult\nnode-weighted version of the PST problem, and provide a $(2 \\ln\n|T|+2)$-approximation using extensions of the spider decomposition by [Klein \\&\nRavi, 1995]. This is the first result for the PST problem in node-weighted\ngraphs. Moreover, the approximation ratios for all above algorithms are tight.",
    "descriptor": "",
    "authors": [
      "Faryad Darabi Sahneh",
      "Stephen Kobourov",
      "Richard Spence"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.13544"
  },
  {
    "id": "arXiv:2108.13551",
    "title": "Regularizing (Stabilizing) Deep Learning Based Reconstruction Algorithms",
    "abstract": "It's well-known that inverse problems are ill-posed and to solve them\nmeaningfully one has to employ regularization methods. Traditionally, popular\nregularization methods have been the penalized Variational approaches. In\nrecent years, the classical regularized-reconstruction approaches have been\noutclassed by the (deep-learning-based) learned reconstruction algorithms.\nHowever, unlike the traditional regularization methods, the theoretical\nunderpinnings, such as stability and regularization, have been insufficient for\nsuch learned reconstruction algorithms. Hence, the results obtained from such\nalgorithms, though empirically outstanding, can't always be completely trusted,\nas they may contain certain instabilities or (hallucinated) features arising\nfrom the learned process. In fact, it has been shown that such learning\nalgorithms are very susceptible to small (adversarial) noises in the data and\ncan lead to severe instabilities in the recovered solution, which can be quite\ndifferent than the inherent instabilities of the ill-posed (inverse) problem.\nWhereas, the classical regularization methods can handle such (adversarial)\nnoises very well and can produce stable recovery. Here, we try to present\ncertain regularization methods to stabilize such (unstable) learned\nreconstruction methods and recover a regularized solution, even in the presence\nof adversarial noises. For this, we need to extend the classical notion of\nregularization and incorporate it in the learned reconstruction algorithms. We\nalso present some regularization techniques to regularize two of the most\npopular learning reconstruction algorithms, the Learned Post-Processing\nReconstruction and the Learned Unrolling Reconstruction.",
    "descriptor": "",
    "authors": [
      "Abinash Nayak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2108.13551"
  },
  {
    "id": "arXiv:2108.13553",
    "title": "Study of the Utility of Text Classification Based Software Architecture  Recovery Method RELAX for Maintenance",
    "abstract": "Background. The software architecture recovery method RELAX produces a\nconcern-based architectural view of a software system graphically and textually\nfrom that system's source code. The method has been implemented in software\nwhich can be run on subject systems whose source code is written in Java. Aims.\nOur aim was to find out whether the availability of architectural views\nproduced by RELAX can help maintainers who are new to a project in becoming\nproductive with development tasks sooner, and find out how they felt about\nworking in such an environment. Method. We conducted a user study with nine\nparticipants. They were subjected to a controlled experiment in which\nmaintenance success and speed with and without access to RELAX recovery results\nwere compared to each other. Results. We have observed that employing\narchitecture views produced by RELAX helped participants reduce time to get\nstarted on maintenance tasks by a factor of 5.38 or more. While most\nparticipants were unable to finish their tasks within the allotted time when\nthey did not have recovery results available, all of them finished them\nsuccessfully when they did. Additionally, participants reported that these\nviews were easy to understand, helped them to learn the system's structure and\nenabled them to compare different versions of the system. Conclusions. In the\nspeedup experienced to the start of maintenance experienced by the participants\nas well as in their experience-based opinions, RELAX has shown itself to be a\nvaluable help that could form the basis for further tools that specifically\nsupport the development process with a focus on maintenance.",
    "descriptor": "\nComments: To be published in ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM) (ESEM '21)\n",
    "authors": [
      "Daniel Link",
      "Kamonphop Srisopha",
      "Barry Boehm"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.13553"
  },
  {
    "id": "arXiv:2108.13555",
    "title": "Adaptive Label Smoothing To Regularize Large-Scale Graph Training",
    "abstract": "Graph neural networks (GNNs), which learn the node representations by\nrecursively aggregating information from its neighbors, have become a\npredominant computational tool in many domains. To handle large-scale graphs,\nmost of the existing methods partition the input graph into multiple sub-graphs\n(e.g., through node clustering) and apply batch training to save memory cost.\nHowever, such batch training will lead to label bias within each batch, and\nthen result in over-confidence in model predictions. Since the connected nodes\nwith positively related labels tend to be assigned together, the traditional\ncross-entropy minimization process will attend on the predictions of biased\nclasses in the batch, and may intensify the overfitting issue. To overcome the\nlabel bias problem, we propose the adaptive label smoothing (ALS) method to\nreplace the one-hot hard labels with smoothed ones, which learns to allocate\nlabel confidences from the biased classes to the others. Specifically, ALS\npropagates node labels to aggregate the neighborhood label distribution in a\npre-processing step, and then updates the optimal smoothed labels online to\nadapt to specific graph structure. Experiments on the real-world datasets\ndemonstrate that ALS can be generally applied to the main scalable learning\nframeworks to calibrate the biased labels and improve generalization\nperformances.",
    "descriptor": "",
    "authors": [
      "Kaixiong Zhou",
      "Ninghao Liu",
      "Fan Yang",
      "Zirui Liu",
      "Rui Chen",
      "Li Li",
      "Soo-Hyun Choi",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13555"
  },
  {
    "id": "arXiv:2108.13556",
    "title": "Linguistic Characterization of Divisive Topics Online: Case Studies on  Contentiousness in Abortion, Climate Change, and Gun Control",
    "abstract": "As public discourse continues to move and grow online, conversations about\ndivisive topics on social media platforms have also increased. These divisive\ntopics prompt both contentious and non-contentious conversations. Although what\ndistinguishes these conversations, often framed as what makes these\nconversations contentious, is known in broad strokes, much less is known about\nthe linguistic signature of these conversations. Prior work has shown that\ncontentious content and structure can be a predictor for this task, however,\nmost of them have been focused on conversation in general, very specific\nevents, or complex structural analysis. Additionally, many models used in prior\nwork have lacked interpret-ability, a key factor in online moderation. Our work\nfills these gaps by focusing on conversations from highly divisive topics\n(abortion, climate change, and gun control), operationalizing a set of novel\nlinguistic and conversational characteristics and user factors, and\nincorporating them to build interpretable models. We demonstrate that such\ncharacteristics can largely improve the performance of prediction on this task,\nand also enable nuanced interpretability. Our case studies on these three\ncontentious topics suggest that certain generic linguistic characteristics are\nhighly correlated with contentiousness in conversations while others\ndemonstrate significant contextual influences on specific divisive topics.",
    "descriptor": "",
    "authors": [
      "Jacob Beel",
      "Tong Xiang",
      "Sandeep Soni",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.13556"
  },
  {
    "id": "arXiv:2108.13557",
    "title": "Towards Observability for Machine Learning Pipelines",
    "abstract": "Software organizations are increasingly incorporating machine learning (ML)\ninto their product offerings, driving a need for new data management tools.\nMany of these tools facilitate the initial development and deployment of ML\napplications, contributing to a crowded landscape of disconnected solutions\ntargeted at different stages, or components, of the ML lifecycle. A lack of\nend-to-end ML pipeline visibility makes it hard to address any issues that may\narise after a production deployment, such as unexpected output values or\nlower-quality predictions. In this paper, we propose a system that wraps around\nexisting tools in the ML development stack and offers end-to-end observability.\nWe introduce our prototype and our vision for mltrace, a platform-agnostic\nsystem that provides observability to ML practitioners by (1) executing\npredefined tests and monitoring ML-specific metrics at component runtime, (2)\ntracking end-to-end data flow, and (3) allowing users to ask arbitrary post-hoc\nquestions about pipeline health.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Shreya Shankar",
      "Aditya Parameswaran"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2108.13557"
  },
  {
    "id": "arXiv:2108.13560",
    "title": "CWmin Estimation and Collision Identification in Wi-Fi Systems",
    "abstract": "Wi-Fi networks are susceptible to aggressive behavior caused by selfish or\nmalicious devices that reduce their minimum contention window size (CWmin) to\nbelow the standard CWmin. In this paper, we propose a scheme called Minimum\nContention Window Estimation (CWE) to detect aggressive stations with low\nCWmin's, where the AP estimates the CWmin value of all stations transmitting\nuplink by monitoring their backoff values over a period of time and keeping\ntrack of the idle time each station spends during backoff. To correctly\nestimate each backoff value, we present a cross-correlation-based technique\nthat uses the frequency offset between the AP and each station to identify\nstations involved in uplink collisions. The AP constructs empirical\ndistributions for the monitored backoff values and compares them with a set of\nnominal PMF's, created via Markov analysis of the DCF protocol to estimate\nCWmin of various stations. After detecting the aggressive stations, the AP can\nchoose to stop serving those stations. Simulation results show that the\naccuracy of our collision detection technique is 96%, 94%, and 88% when there\nare 3, 6, and 9 stations in the WLAN, respectively. For the former WLAN\nsettings, the estimation accuracy of CWE scheme is 100%, 98.81%, and 96.3%,\nrespectively.",
    "descriptor": "\nComments: Accepted to appear in proceedings of IEEE MASS 2021\n",
    "authors": [
      "Amir-Hossein Yazdani-Abyaneh",
      "Marwan Krunz"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13560"
  },
  {
    "id": "arXiv:2108.13562",
    "title": "Adversarial Example Devastation and Detection on Speech Recognition  System by Adding Random Noise",
    "abstract": "The automatic speech recognition (ASR) system based on deep neural network is\neasy to be attacked by an adversarial example due to the vulnerability of\nneural network, which is a hot topic in recent years. The adversarial example\ndoes harm to the ASR system, especially if the common-dependent ASR goes wrong,\nit will lead to serious consequences. To improve the robustness and security of\nthe ASR system, the defense method against adversarial examples must be\nproposed. Based on this idea, we propose an algorithm of devastation and\ndetection on adversarial examples which can attack the current advanced ASR\nsystem. We choose advanced text-dependent and command-dependent ASR system as\nour target system. Generating adversarial examples by the OPT on text-dependent\nASR and the GA-based algorithm on command-dependent ASR. The main idea of our\nmethod is input transformation of the adversarial examples. Different random\nintensities and kinds of noise are added to the adversarial examples to\ndevastate the perturbation previously added to the normal examples. From the\nexperimental results, the method performs well. For the devastation of\nexamples, the original speech similarity before and after adding noise can\nreach 99.68%, the similarity of the adversarial examples can reach 0%, and the\ndetection rate of the adversarial examples can reach 94%.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Mingyu Dong",
      "Diqun Yan",
      "Yongkang Gong",
      "Rangding Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2108.13562"
  },
  {
    "id": "arXiv:2108.13570",
    "title": "Fast Multi-label Learning",
    "abstract": "Embedding approaches have become one of the most pervasive techniques for\nmulti-label classification. However, the training process of embedding methods\nusually involves a complex quadratic or semidefinite programming problem, or\nthe model may even involve an NP-hard problem. Thus, such methods are\nprohibitive on large-scale applications. More importantly, much of the\nliterature has already shown that the binary relevance (BR) method is usually\ngood enough for some applications. Unfortunately, BR runs slowly due to its\nlinear dependence on the size of the input data. The goal of this paper is to\nprovide a simple method, yet with provable guarantees, which can achieve\ncompetitive performance without a complex training process. To achieve our\ngoal, we provide a simple stochastic sketch strategy for multi-label\nclassification and present theoretical results from both algorithmic and\nstatistical learning perspectives. Our comprehensive empirical studies\ncorroborate our theoretical findings and demonstrate the superiority of the\nproposed methods.",
    "descriptor": "",
    "authors": [
      "Xiuwen Gong",
      "Dong Yuan",
      "Wei Bao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.13570"
  },
  {
    "id": "arXiv:2108.13576",
    "title": "Dead Pixel Test Using Effective Receptive Field",
    "abstract": "Deep neural networks have been used in various fields, but their internal\nbehavior is not well known. In this study, we discuss two counterintuitive\nbehaviors of convolutional neural networks (CNNs). First, we evaluated the size\nof the receptive field. Previous studies have attempted to increase or control\nthe size of the receptive field. However, we observed that the size of the\nreceptive field does not describe the classification accuracy. The size of the\nreceptive field would be inappropriate for representing superiority in\nperformance because it reflects only depth or kernel size and does not reflect\nother factors such as width or cardinality. Second, using the effective\nreceptive field, we examined the pixels contributing to the output.\nIntuitively, each pixel is expected to equally contribute to the final output.\nHowever, we found that there exist pixels in a partially dead state with little\ncontribution to the output. We reveal that the reason for this lies in the\narchitecture of CNN and discuss solutions to reduce the phenomenon.\nInterestingly, for general classification tasks, the existence of dead pixels\nimproves the training of CNNs. However, in a task that captures small\nperturbation, dead pixels degrade the performance. Therefore, the existence of\nthese dead pixels should be understood and considered in practical applications\nof CNN.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Bum Jun Kim",
      "Hyeyeon Choi",
      "Hyeonah Jang",
      "Dong Gu Lee",
      "Wonseok Jeong",
      "Sang Woo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13576"
  },
  {
    "id": "arXiv:2108.13577",
    "title": "Rapidly and accurately estimating brain strain and strain rate across  head impact types with transfer learning and data fusion",
    "abstract": "Brain strain and strain rate are effective in predicting traumatic brain\ninjury (TBI) caused by head impacts. However, state-of-the-art finite element\nmodeling (FEM) demands considerable computational time in the computation,\nlimiting its application in real-time TBI risk monitoring. To accelerate,\nmachine learning head models (MLHMs) were developed, and the model accuracy was\nfound to decrease when the training/test datasets were from different head\nimpacts types. However, the size of dataset for specific impact types may not\nbe enough for model training. To address the computational cost of FEM, the\nlimited strain rate prediction, and the generalizability of MLHMs to on-field\ndatasets, we propose data fusion and transfer learning to develop a series of\nMLHMs to predict the maximum principal strain (MPS) and maximum principal\nstrain rate (MPSR). We trained and tested the MLHMs on 13,623 head impacts from\nsimulations, American football, mixed martial arts, car crash, and compared\nagainst the models trained on only simulations or only on-field impacts. The\nMLHMs developed with transfer learning are significantly more accurate in\nestimating MPS and MPSR than other models, with a mean absolute error (MAE)\nsmaller than 0.03 in predicting MPS and smaller than 7 (1/s) in predicting MPSR\non all impact datasets. The MLHMs can be applied to various head impact types\nfor rapidly and accurately calculating brain strain and strain rate. Besides\nthe clinical applications in real-time brain strain and strain rate monitoring,\nthis model helps researchers estimate the brain strain and strain rate caused\nby head impacts more efficiently than FEM.",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Xianghao Zhan",
      "Yuzhe Liu",
      "Nicholas J. Cecchi",
      "Olivier Gevaert",
      "Michael M. Zeineh",
      "Gerald A. Grant",
      "David B. Camarillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2108.13577"
  },
  {
    "id": "arXiv:2108.13578",
    "title": "$\\ell_p$-Spread Properties of Sparse Matrices",
    "abstract": "Random subspaces $X$ of $\\mathbb{R}^n$ of dimension proportional to $n$ are,\nwith high probability, well-spread with respect to the $\\ell_p$-norm (for $p\n\\in [1,2]$). Namely, every nonzero $x \\in X$ is \"robustly non-sparse\" in the\nfollowing sense: $x$ is $\\varepsilon \\|x\\|_p$-far in $\\ell_p$-distance from all\n$\\delta n$-sparse vectors, for positive constants $\\varepsilon, \\delta$ bounded\naway from $0$. This \"$\\ell_p$-spread\" property is the natural counterpart, for\nsubspaces over the reals, of the minimum distance of linear codes over finite\nfields, and, for $p = 2$, corresponds to $X$ being a Euclidean section of the\n$\\ell_1$ unit ball. Explicit $\\ell_p$-spread subspaces of dimension\n$\\Omega(n)$, however, are not known except for $p=1$. The construction for\n$p=1$, as well as the best known constructions for $p \\in (1,2]$ (which achieve\nweaker spread properties), are analogs of low density parity check (LDPC) codes\nover the reals, i.e., they are kernels of sparse matrices.\nWe study the spread properties of the kernels of sparse random matrices.\nRather surprisingly, we prove that with high probability such subspaces contain\nvectors $x$ that are $o(1)\\cdot \\|x\\|_2$-close to $o(n)$-sparse with respect to\nthe $\\ell_2$-norm, and in particular are not $\\ell_2$-spread.\nOn the other hand, for $p < 2$ we prove that such subspaces are\n$\\ell_p$-spread with high probability. Moreover, we show that a random sparse\nmatrix has the stronger restricted isometry property (RIP) with respect to the\n$\\ell_p$ norm, and this follows solely from the unique expansion of a random\nbiregular graph, yielding a somewhat unexpected generalization of a similar\nresult for the $\\ell_1$ norm [BGI+08]. Instantiating this with explicit\nexpanders, we obtain the first explicit constructions of $\\ell_p$-spread\nsubspaces and $\\ell_p$-RIP matrices for $1 \\leq p < p_0$, where $1 < p_0 < 2$\nis an absolute constant.",
    "descriptor": "",
    "authors": [
      "Venkatesan Guruswami",
      "Peter Manohar",
      "Jonathan Mosheiff"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2108.13578"
  },
  {
    "id": "arXiv:2108.13580",
    "title": "Planning for Dexterous Ungrasping: Secure Ungrasping through Dexterous  Manipulation",
    "abstract": "This paper presents a robotic manipulation technique for dexterous\nungrasping. It refers to the capability of securely transferring a grasped\nobject from the gripper to the robot's environment, i.e. the inverse of\ngrasping or picking, through dexterous manipulation. The game of Go offers an\nexample: consider how the player would typically place an initially\npinch-grasped stone onto the board through the dexterous interaction between\nthe fingers, the stone, and the board. Likewise, dexterous ungrasping addresses\nthe necessity of changing the object's configuration relative to the gripper or\nthe environment in order to securely keep hold of the object. In particular, we\npresent a planning framework for determining a feasible minimum-cost motion\npath that completes dexterous ungrasping. Digit asymmetry in a gripper, i.e.\ndifference in digit lengths, is discovered as the key to feasible and secure\nungrasping. A set of experiments show the effectiveness of dexterous ungrasping\nin practical placement tasks.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Chung Hee Kim",
      "Ka Hei Mak",
      "Jungwon Seo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13580"
  },
  {
    "id": "arXiv:2108.13581",
    "title": "DoGR: Disaggregated Gaussian Regression for Reproducible Analysis of  Heterogeneous Data",
    "abstract": "Quantitative analysis of large-scale data is often complicated by the\npresence of diverse subgroups, which reduce the accuracy of inferences they\nmake on held-out data. To address the challenge of heterogeneous data analysis,\nwe introduce DoGR, a method that discovers latent confounders by simultaneously\npartitioning the data into overlapping clusters (disaggregation) and modeling\nthe behavior within them (regression). When applied to real-world data, our\nmethod discovers meaningful clusters and their characteristic behaviors, thus\ngiving insight into group differences and their impact on the outcome of\ninterest. By accounting for latent confounders, our framework facilitates\nexploratory analysis of noisy, heterogeneous data and can be used to learn\npredictive models that better generalize to new data. We provide the code to\nenable others to use DoGR within their data analytic workflows.",
    "descriptor": "",
    "authors": [
      "Nazanin Alipourfard",
      "Keith Burghardt",
      "Kristina Lerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13581"
  },
  {
    "id": "arXiv:2108.13583",
    "title": "A New Approach to Multilinear Dynamical Systems and Control",
    "abstract": "The current paper presents a new approach to multilinear dynamical systems\nanalysis and control. The approach is based upon recent developments in tensor\ndecompositions and a newly defined algebra of circulants. In particular, it is\nshown that under the right tensor multiplication operator, a third order tensor\ncan be written as a product of third order tensors that is analogous to a\ntraditional matrix eigenvalue decomposition where the \"eigenvectors\" become\neigenmatrices and the \"eigenvalues\" become eigen-tuples. This new development\nallows for a proper tensor eigenvalue decomposition to be defined and has\nnatural extension to linear systems theory through a\n\\textit{tensor-exponential}. Through this framework we extend many of\ntraditional techniques used in linear system theory to their multilinear\ncounterpart.",
    "descriptor": "",
    "authors": [
      "Randy C. Hoover",
      "Kyle Caudle",
      "Karen Braman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.13583"
  },
  {
    "id": "arXiv:2108.13584",
    "title": "Spectral Splitting and Aggregation Network for Hyperspectral Face  Super-Resolution",
    "abstract": "High-resolution (HR) hyperspectral face image plays an important role in face\nrelated computer vision tasks under uncontrolled conditions, such as low-light\nenvironment and spoofing attacks. However, the dense spectral bands of\nhyperspectral face images come at the cost of limited amount of photons reached\na narrow spectral window on average, which greatly reduces the spatial\nresolution of hyperspectral face images. In this paper, we investigate how to\nadapt the deep learning techniques to hyperspectral face image super-resolution\n(HFSR), especially when the training samples are very limited. Benefiting from\nthe amount of spectral bands, in which each band can be seen as an image, we\npresent a spectral splitting and aggregation network (SSANet) for HFSR with\nlimited training samples. In the shallow layers, we split the hyperspectral\nimage into different spectral groups and take each of them as an individual\ntraining sample (in the sense that each group will be fed into the same\nnetwork). Then, we gradually aggregate the neighbor bands at the deeper layers\nto exploit the spectral correlations. By this spectral splitting and\naggregation strategy (SSAS), we can divide the original hyperspectral image\ninto multiple samples to support the efficient training of the network and\neffectively exploit the spectral correlations among spectrum. To cope with the\nchallenge of small training sample size (S3) problem, we propose to expand the\ntraining samples by a self-representation model and symmetry-induced\naugmentation. Experiments show that the introduced SSANet can well model the\njoint correlations of spatial and spectral information. By expanding the\ntraining samples, our proposed method can effectively alleviate the S3 problem.\nThe comparison results demonstrate that our proposed method can outperform the\nstate-of-the-arts.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Junjun Jiang",
      "Chenyang Wang",
      "Kui Jiang",
      "Xianming Liu",
      "Jiayi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13584"
  },
  {
    "id": "arXiv:2108.13587",
    "title": "T3-Vis: a visual analytic framework for Training and fine-Tuning  Transformers in NLP",
    "abstract": "Transformers are the dominant architecture in NLP, but their training and\nfine-tuning is still very challenging. In this paper, we present the design and\nimplementation of a visual analytic framework for assisting researchers in such\nprocess, by providing them with valuable insights about the model's intrinsic\nproperties and behaviours. Our framework offers an intuitive overview that\nallows the user to explore different facets of the model (e.g., hidden states,\nattention) through interactive visualization, and allows a suite of built-in\nalgorithms that compute the importance of model components and different parts\nof the input sequence. Case studies and feedback from a user focus group\nindicate that the framework is useful, and suggest several improvements.",
    "descriptor": "\nComments: 10 pages, 4 figures, accepted to EMNLP 2021 System Demonstration\n",
    "authors": [
      "Raymond Li",
      "Wen Xiao",
      "Lanjun Wang",
      "Hyeju Jang",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2108.13587"
  },
  {
    "id": "arXiv:2108.13588",
    "title": "SMAC-Seg: LiDAR Panoptic Segmentation via Sparse Multi-directional  Attention Clustering",
    "abstract": "Panoptic segmentation aims to address semantic and instance segmentation\nsimultaneously in a unified framework. However, an efficient solution of\npanoptic segmentation in applications like autonomous driving is still an open\nresearch problem. In this work, we propose a novel LiDAR-based panoptic system,\ncalled SMAC-Seg. We present a learnable sparse multi-directional attention\nclustering to segment multi-scale foreground instances. SMAC-Seg is a real-time\nclustering-based approach, which removes the complex proposal network to\nsegment instances. Most existing clustering-based methods use the difference of\nthe predicted and ground truth center offset as the only loss to supervise the\ninstance centroid regression. However, this loss function only considers the\ncentroid of the current object, but its relative position with respect to the\nneighbouring objects is not considered when learning to cluster. Thus, we\npropose to use a novel centroid-aware repel loss as an additional term to\neffectively supervise the network to differentiate each object cluster with its\nneighbours. Our experimental results show that SMAC-Seg achieves\nstate-of-the-art performance among all real-time deployable networks on both\nlarge-scale public SemanticKITTI and nuScenes panoptic segmentation datasets.",
    "descriptor": "",
    "authors": [
      "Enxu Li",
      "Ryan Razani",
      "Yixuan Xu",
      "Liu Bingbing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13588"
  },
  {
    "id": "arXiv:2108.13591",
    "title": "AIP: Adversarial Iterative Pruning Based on Knowledge Transfer for  Convolutional Neural Networks",
    "abstract": "With the increase of structure complexity, convolutional neural networks\n(CNNs) take a fair amount of computation cost. Meanwhile, existing research\nreveals the salient parameter redundancy in CNNs. The current pruning methods\ncan compress CNNs with little performance drop, but when the pruning ratio\nincreases, the accuracy loss is more serious. Moreover, some iterative pruning\nmethods are difficult to accurately identify and delete unimportant parameters\ndue to the accuracy drop during pruning. We propose a novel adversarial\niterative pruning method (AIP) for CNNs based on knowledge transfer. The\noriginal network is regarded as the teacher while the compressed network is the\nstudent. We apply attention maps and output features to transfer information\nfrom the teacher to the student. Then, a shallow fully-connected network is\ndesigned as the discriminator to allow the output of two networks to play an\nadversarial game, thereby it can quickly recover the pruned accuracy among\npruning intervals. Finally, an iterative pruning scheme based on the importance\nof channels is proposed. We conduct extensive experiments on the image\nclassification tasks CIFAR-10, CIFAR-100, and ILSVRC-2012 to verify our pruning\nmethod can achieve efficient compression for CNNs even without accuracy loss.\nOn the ILSVRC-2012, when removing 36.78% parameters and 45.55% floating-point\noperations (FLOPs) of ResNet-18, the Top-1 accuracy drop are only 0.66%. Our\nmethod is superior to some state-of-the-art pruning schemes in terms of\ncompressing rate and accuracy. Moreover, we further demonstrate that AIP has\ngood generalization on the object detection task PASCAL VOC.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Jingfei Chang",
      "Yang Lu",
      "Ping Xue",
      "Yiqun Xu",
      "Zhen Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13591"
  },
  {
    "id": "arXiv:2108.13592",
    "title": "Zero Shot on the Cold-Start Problem: Model-Agnostic Interest Learning  for Recommender Systems",
    "abstract": "User behavior has been validated to be effective in revealing personalized\npreferences for commercial recommendations. However, few user-item interactions\ncan be collected for new users, which results in a null space for their\ninterests, i.e., the cold-start dilemma. In this paper, a two-tower framework,\nnamely, the model-agnostic interest learning (MAIL) framework, is proposed to\naddress the cold-start recommendation (CSR) problem for recommender systems. In\nMAIL, one unique tower is constructed to tackle the CSR from a zero-shot view,\nand the other tower focuses on the general ranking task. Specifically, the\nzero-shot tower first performs cross-modal reconstruction with dual\nauto-encoders to obtain virtual behavior data from highly aligned hidden\nfeatures for new users; and the ranking tower can then output recommendations\nfor users based on the completed data by the zero-shot tower. Practically, the\nranking tower in MAIL is model-agnostic and can be implemented with any\nembedding-based deep models. Based on the co-training of the two towers, the\nMAIL presents an end-to-end method for recommender systems that shows an\nincremental performance improvement. The proposed method has been successfully\ndeployed on the live recommendation system of NetEase Cloud Music to achieve a\nclick-through rate improvement of 13% to 15% for millions of users. Offline\nexperiments on real-world datasets also show its superior performance in CSR.\nOur code is available.",
    "descriptor": "",
    "authors": [
      "Philip J. Feng",
      "Pingjun Pan",
      "Tingting Zhou",
      "Hongxiang Chen",
      "Chuanjiang Luo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13592"
  },
  {
    "id": "arXiv:2108.13597",
    "title": "Self-balanced Learning For Domain Generalization",
    "abstract": "Domain generalization aims to learn a prediction model on multi-domain source\ndata such that the model can generalize to a target domain with unknown\nstatistics. Most existing approaches have been developed under the assumption\nthat the source data is well-balanced in terms of both domain and class.\nHowever, real-world training data collected with different composition biases\noften exhibits severe distribution gaps for domain and class, leading to\nsubstantial performance degradation. In this paper, we propose a self-balanced\ndomain generalization framework that adaptively learns the weights of losses to\nalleviate the bias caused by different distributions of the multi-domain source\ndata. The self-balanced scheme is based on an auxiliary reweighting network\nthat iteratively updates the weight of loss conditioned on the domain and class\ninformation by leveraging balanced meta data. Experimental results demonstrate\nthe effectiveness of our method overwhelming state-of-the-art works for domain\ngeneralization.",
    "descriptor": "\nComments: Accepted at International Conference on Image Processing (ICIP) 2021\n",
    "authors": [
      "Jin Kim",
      "Jiyoung Lee",
      "Jungin Park",
      "Dongbo Min",
      "Kwanghoon Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13597"
  },
  {
    "id": "arXiv:2108.13599",
    "title": "Through the Looking Glass: Diminishing Occlusions in Robot Vision  Systems with Mirror Reflections",
    "abstract": "The quality of robot vision greatly affects the performance of automation\nsystems, where occlusions stand as one of the biggest challenges. If the target\nis occluded from the sensor, detecting and grasping such objects become very\nchallenging. For example, when multiple robot arms cooperate in a single\nworkplace, occlusions will be created under the robot arm itself and hide\nobjects underneath. While occlusions can be greatly reduced by installing\nmultiple sensors, the increase in sensor costs cannot be ignored. Moreover, the\nsensor placements must be rearranged every time the robot operation routine and\nlayout change.\nTo diminish occlusions, we propose the first robot vision system with\ntilt-type mirror reflection sensing. By instantly tilting the sensor itself, we\nobtain two sensing results with different views: conventional direct\nline-of-sight sensing and non-line-of-sight sensing via mirror reflections. Our\nproposed system removes occlusions adaptively by detecting the occlusions in\nthe scene and dynamically configuring the sensor tilt angle to sense the\ndetected occluded area. Thus, sensor rearrangements are not required even after\nchanges in robot operation or layout. Since the required hardware is the\ntilt-unit and a commercially available mirror, the cost increase is marginal.\nThrough experiments, we show that our system can achieve a similar detection\naccuracy as systems with multiple sensors, regardless of the single-sensor\nimplementation.",
    "descriptor": "\nComments: Accepted to IROS 2021\n",
    "authors": [
      "Kentaro Yoshioka",
      "Hidenori Okuni",
      "Tuan Thanh Ta",
      "Akihide Sai"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13599"
  },
  {
    "id": "arXiv:2108.13602",
    "title": "How Does Adversarial Fine-Tuning Benefit BERT?",
    "abstract": "Adversarial training (AT) is one of the most reliable methods for defending\nagainst adversarial attacks in machine learning. Variants of this method have\nbeen used as regularization mechanisms to achieve SOTA results on NLP\nbenchmarks, and they have been found to be useful for transfer learning and\ncontinual learning. We search for the reasons for the effectiveness of AT by\ncontrasting vanilla and adversarially fine-tuned BERT models. We identify\npartial preservation of BERT's syntactic abilities during fine-tuning as the\nkey to the success of AT. We observe that adversarially fine-tuned models\nremain more faithful to BERT's language modeling behavior and are more\nsensitive to the word order. As concrete examples of syntactic abilities, an\nadversarially fine-tuned model could have an advantage of up to 38% on anaphora\nagreement and up to 11% on dependency parsing. Our analysis demonstrates that\nvanilla fine-tuning oversimplifies the sentence representation by focusing\nheavily on one or a few label-indicative words. AT, however, moderates the\neffect of these influential words and encourages representational diversity.\nThis allows for a more hierarchical representation of a sentence and leads to\nthe mitigation of BERT's loss of syntactic abilities.",
    "descriptor": "",
    "authors": [
      "Javid Ebrahimi",
      "Hao Yang",
      "Wei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13602"
  },
  {
    "id": "arXiv:2108.13603",
    "title": "Energy Minimization for IRS-aided WPCNs with Non-linear Energy  Harvesting Model",
    "abstract": "This paper considers an intelligent reflecting surface(IRS)-aided wireless\npowered communication network (WPCN), where devices first harvest energy from a\npower station (PS) in the downlink (DL) and then transmit information using\nnon-orthogonal multiple access (NOMA) to a data sink in the uplink (UL).\nHowever, most existing works on WPCNs adopted the simplified linear\nenergy-harvesting model and also cannot guarantee strict user\nquality-of-service requirements. To address these issues, we aim to minimize\nthe total transmit energy consumption at the PS by jointly optimizing the\nresource allocation and IRS phase shifts over time, subject to the minimum\nthroughput requirements of all devices. The formulated problem is decomposed\ninto two subproblems, and solved iteratively in an alternative manner by\nemploying difference of convex functions programming, successive convex\napproximation, and penalty-based algorithm. Numerical results demonstrate the\nsignificant performance gains achieved by the proposed algorithm over benchmark\nschemes and reveal the benefits of integrating IRS into WPCNs. In particular,\nemploying different IRS phase shifts over UL and DL outperforms the case with\nstatic IRS beamforming.",
    "descriptor": "\nComments: Submitted to IEEE WCL\n",
    "authors": [
      "Piao Zeng",
      "Qingqing Wu",
      "Deli Qiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.13603"
  },
  {
    "id": "arXiv:2108.13606",
    "title": "BotNet: A Simulator for Studying the Effects of Accurate Communication  Models on Multi-agent and Swarm Control",
    "abstract": "Decentralized control in multi-robot systems is dependent on accurate and\nreliable communication between agents. Important communication factors, such as\nlatency and packet delivery ratio, are strong functions of the number of agents\nin the network. Findings from studies of mobile and high node-count\nradio-frequency (RF) mesh networks have only been transferred to the domain of\nmulti-robot systems to a limited extent, and typical multi-agent robotic\nsimulators often depend on simple propagation models that do not reflect the\nbehavior of realistic RF networks. In this paper, we present a new open source\nswarm robotics simulator, BotNet, with an embedded standards-compliant\ntime-synchronized channel hopping (6TiSCH) RF mesh network simulator. Using\nthis simulator we show how more accurate communications models can limit even\nsimple multi-robot control tasks such as flocking and formation control, with\nagent counts ranging from 10 up to 2500 agents. The experimental results are\nused to motivate changes to the inter-robot communication propagation models\nand other networking components currently used in practice in order to bridge\nthe sim-to-real gap.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Mark Selden",
      "Jason Zhou",
      "Felipe Campos",
      "Nathan Lambert",
      "Daniel Drew",
      "Kristofer S. J. Pister"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13606"
  },
  {
    "id": "arXiv:2108.13609",
    "title": "Upper bounds on the length function for covering codes",
    "abstract": "The length function $\\ell_q(r,R)$ is the smallest length of a $ q $-ary\nlinear code with codimension (redundancy) $r$ and covering radius $R$. In this\nwork, new upper bounds on $\\ell_q(tR+1,R)$ are obtained in the following forms:\n\\begin{equation*} \\begin{split}\n&(a)~\\ell_q(r,R)\\le cq^{(r-R)/R}\\cdot\\sqrt[R]{\\ln q},~ R\\ge3,~r=tR+1,~t\\ge1,\n&\\phantom{(a)~} q\\text{ is an arbitrary prime power},~c\\text{ is independent\nof }q.\n\\end{split} \\end{equation*} \\begin{equation*} \\begin{split}\n&(b)~\\ell_q(r,R)< 4.5Rq^{(r-R)/R}\\cdot\\sqrt[R]{\\ln q},~ R\\ge3,~r=tR+1,~t\\ge1,\n&\\phantom{(b)~} q\\text{ is an arbitrary prime power},~q\\text{ is large\nenough}.\n\\end{split} \\end{equation*} In the literature, for $q=(q')^R$ with $q'$ a\nprime power, smaller upper bounds are known; however, when $q$ is an arbitrary\nprime power, the bounds of this paper are better than the known ones.\nFor $t=1$, we use a one-to-one correspondence between $[n,n-(R+1)]_qR$ codes\nand $(R-1)$-saturating $n$-sets in the projective space $\\mathrm{PG}(R,q)$. A\nnew construction of such saturating sets providing sets of small size is\nproposed. Then the $[n,n-(R+1)]_qR$ codes, obtained by geometrical methods, are\ntaken as the starting ones in the lift-constructions (so-called\n\"$q^m$-concatenating constructions\") for covering codes to obtain infinite\nfamilies of codes with growing codimension $r=tR+1$, $t\\ge1$.",
    "descriptor": "\nComments: 28 pages, 1 figure, 52 references\n",
    "authors": [
      "Alexander A. Davydov",
      "Stefano Marcugini",
      "Fernanda Pambianco"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2108.13609"
  },
  {
    "id": "arXiv:2108.13616",
    "title": "An Efficient Finite Element Iterative Method for Solving a Nonuniform  Size Modified Poisson-Boltzmann Ion Channel Model",
    "abstract": "In this paper, a nonuniform size modified Poisson-Boltzmann ion channel\n(nuSMPBIC) model is presented as a nonlinear system of an electrostatic\npotential and multiple ionic concentrations. It mixes nonlinear algebraic\nequations with a Poisson boundary value problem involving Dirichlet-Neumann\nmixed boundary value conditions and a membrane surface charge density to\nreflect the effects of ion sizes and membrane charges on electrostatics and\nionic concentrations. To overcome the difficulties of strong singularities and\nexponential nonlinearities, it is split into three submodels with a solution of\nModel 1 collecting all the singular points and Models 2 and 3 much easier to\nsolve numerically than the original nuSMPBIC model. A damped two-block\niterative method is then presented to solve Model 3, along with a novel\nmodified Newton iterative scheme for solving each related nonlinear algebraic\nsystem. To this end, an effective nuSMPBIC finite element solver is derived and\nthen implemented as a program package that works for an ion channel protein\nwith a three-dimensional molecular structure and a mixture solution of multiple\nionic species. Numerical results for a voltage-dependent anion channel (VDAC)\nin a mixture of four ionic species demonstrate a fast convergence rate of the\ndamped two-block iterative method, the high performance of the software\npackage, and the importance of considering nonuniform ion sizes. Moreover, the\nnuSMPBIC model is validated by the anion selectivity property of VDAC.",
    "descriptor": "\nComments: 22 pages, 9 figures\n",
    "authors": [
      "Dexuan Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2108.13616"
  },
  {
    "id": "arXiv:2108.13617",
    "title": "Segmentation Fault: A Cheap Defense Against Adversarial Machine Learning",
    "abstract": "Recently published attacks against deep neural networks (DNNs) have stressed\nthe importance of methodologies and tools to assess the security risks of using\nthis technology in critical systems. Efficient techniques for detecting\nadversarial machine learning helps establishing trust and boost the adoption of\ndeep learning in sensitive and security systems. In this paper, we propose a\nnew technique for defending deep neural network classifiers, and convolutional\nones in particular. Our defense is cheap in the sense that it requires less\ncomputation power despite a small cost to pay in terms of detection accuracy.\nThe work refers to a recently published technique called ML-LOO. We replace the\ncostly pixel by pixel leave-one-out approach of ML-LOO by adopting\ncoarse-grained leave-one-out. We evaluate and compare the efficiency of\ndifferent segmentation algorithms for this task. Our results show that a large\ngain in efficiency is possible, even though penalized by a marginal decrease in\ndetection accuracy.",
    "descriptor": "",
    "authors": [
      "Doha Al Bared",
      "Mohamed Nassar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13617"
  },
  {
    "id": "arXiv:2108.13619",
    "title": "A review of mobile robot motion planning methods: from classical motion  planning workflows to reinforcement learning-based architectures",
    "abstract": "Motion planning is critical to realize the autonomous operation of mobile\nrobots. As the complexity and stochasticity of robot application scenarios\nincrease, the planning capability of the classical hierarchical motion planners\nis challenged. In recent years, with the development of intelligent computation\ntechnology, the deep reinforcement learning (DRL) based motion planning\nalgorithm has gradually become a research hotspot due to its advantageous\nfeatures such as not relying on the map prior, model-free, and unified global\nand local planning paradigms. In this paper, we provide a systematic review of\nvarious motion planning methods. First, we summarize the representative and\ncutting-edge algorithms for each submodule of the classical motion planning\narchitecture, and analyze their performance limitations. For the rest part, we\nfocus on reviewing RL-based motion planning approaches, including RL\noptimization motion planners, map-free end-to-end methods that integrate\nsensing and decision-making, and multi-robot cooperative planning methods. In\nthe last section, we analyze the urgent challenges faced by these methods in\ndetail, review some state-of-the-art works for these issues, and propose\nsuggestions for future research.",
    "descriptor": "",
    "authors": [
      "Zichen He",
      "Jiawei Wang",
      "Chunwei Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13619"
  },
  {
    "id": "arXiv:2108.13620",
    "title": "Cross-Lingual Text Classification of Transliterated Hindi and Malayalam",
    "abstract": "Transliteration is very common on social media, but transliterated text is\nnot adequately handled by modern neural models for various NLP tasks. In this\nwork, we combine data augmentation approaches with a Teacher-Student training\nscheme to address this issue in a cross-lingual transfer setting for\nfine-tuning state-of-the-art pre-trained multilingual language models such as\nmBERT and XLM-R. We evaluate our method on transliterated Hindi and Malayalam,\nalso introducing new datasets for benchmarking on real-world scenarios: one on\nsentiment classification in transliterated Malayalam, and another on crisis\ntweet classification in transliterated Hindi and Malayalam (related to the 2013\nNorth India and 2018 Kerala floods). Our method yielded an average improvement\nof +5.6% on mBERT and +4.7% on XLM-R in F1 scores over their strong baselines.",
    "descriptor": "\nComments: 12 pages, 5 tables, 7 Figures\n",
    "authors": [
      "Jitin Krishnan",
      "Antonios Anastasopoulos",
      "Hemant Purohit",
      "Huzefa Rangwala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13620"
  },
  {
    "id": "arXiv:2108.13621",
    "title": "Spike time displacement based error backpropagation in convolutional  spiking neural networks",
    "abstract": "We recently proposed the STiDi-BP algorithm, which avoids backward recursive\ngradient computation, for training multi-layer spiking neural networks (SNNs)\nwith single-spike-based temporal coding. The algorithm employs a linear\napproximation to compute the derivative of the spike latency with respect to\nthe membrane potential and it uses spiking neurons with piecewise linear\npostsynaptic potential to reduce the computational cost and the complexity of\nneural processing. In this paper, we extend the STiDi-BP algorithm to employ it\nin deeper and convolutional architectures. The evaluation results on the image\nclassification task based on two popular benchmarks, MNIST and Fashion-MNIST\ndatasets with the accuracies of respectively 99.2% and 92.8%, confirm that this\nalgorithm has been applicable in deep SNNs. Another issue we consider is the\nreduction of memory storage and computational cost. To do so, we consider a\nconvolutional SNN (CSNN) with two sets of weights: real-valued weights that are\nupdated in the backward pass and their signs, binary weights, that are employed\nin the feedforward process. We evaluate the binary CSNN on two datasets of\nMNIST and Fashion-MNIST and obtain acceptable performance with a negligible\naccuracy drop with respect to real-valued weights (about $0.6%$ and $0.8%$\ndrops, respectively).",
    "descriptor": "",
    "authors": [
      "Maryam Mirsadeghi",
      "Majid Shalchian",
      "Saeed Reza Kheradpisheh",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13621"
  },
  {
    "id": "arXiv:2108.13622",
    "title": "Exponential Integrators for MHD: Matrix-free Leja interpolation and  efficient adaptive time stepping",
    "abstract": "We propose a novel algorithm for the temporal integration of the\nmagnetohydrodynamics (MHD) equations. The approach is based on exponential\nRosenbrock schemes in combination with Leja interpolation. It naturally\npreserves Gauss's law for magnetism and is unencumbered by the stability\nconstraints observed for explicit methods. Remarkable progress has been\nachieved in designing exponential integrators and computing the required matrix\nfunctions efficiently. However, employing them in realistic MHD scenarios\nrequire matrix-free implementations that are competent on modern computer\nhardware. We show how an efficient algorithm based on Leja interpolation that\nonly uses the right-hand side of the differential equation (i.e. matrix-free),\ncan be constructed. We further demonstrate that it outperforms, in the context\nof magnetic reconnection and the Kelvin--Helmholtz instability, earlier work on\nKrylov-based exponential integrators as well as explicit methods. Furthermore,\nan adaptive step size strategy is employed that gives an excellent and\npredictable performance, particularly in the lenient to intermediate tolerance\nregime that is often of importance in practical applications.",
    "descriptor": "\nComments: Submitted to MNRAS\n",
    "authors": [
      "Pranab Deka",
      "Lukas Einkemmer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.13622"
  },
  {
    "id": "arXiv:2108.13624",
    "title": "Towards Out-Of-Distribution Generalization: A Survey",
    "abstract": "Classic machine learning methods are built on the $i.i.d.$ assumption that\ntraining and testing data are independent and identically distributed. However,\nin real scenarios, the $i.i.d.$ assumption can hardly be satisfied, rendering\nthe sharp drop of classic machine learning algorithms' performances under\ndistributional shifts, which indicates the significance of investigating the\nOut-of-Distribution generalization problem. Out-of-Distribution (OOD)\ngeneralization problem addresses the challenging setting where the testing\ndistribution is unknown and different from the training. This paper serves as\nthe first effort to systematically and comprehensively discuss the OOD\ngeneralization problem, from the definition, methodology, evaluation to the\nimplications and future directions. Firstly, we provide the formal definition\nof the OOD generalization problem. Secondly, existing methods are categorized\ninto three parts based on their positions in the whole learning pipeline,\nnamely unsupervised representation learning, supervised model learning and\noptimization, and typical methods for each category are discussed in detail. We\nthen demonstrate the theoretical connections of different categories, and\nintroduce the commonly used datasets and evaluation metrics. Finally, we\nsummarize the whole literature and raise some future directions for OOD\ngeneralization problem. The summary of OOD generalization methods reviewed in\nthis survey can be found at this http URL",
    "descriptor": "",
    "authors": [
      "Zheyan Shen",
      "Jiashuo Liu",
      "Yue He",
      "Xingxuan Zhang",
      "Renzhe Xu",
      "Han Yu",
      "Peng Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13624"
  },
  {
    "id": "arXiv:2108.13628",
    "title": "Learning Optimal Prescriptive Trees from Observational Data",
    "abstract": "We consider the problem of learning an optimal prescriptive tree (i.e., a\npersonalized treatment assignment policy in the form of a binary tree) of\nmoderate depth, from observational data. This problem arises in numerous\nsocially important domains such as public health and personalized medicine,\nwhere interpretable and data-driven interventions are sought based on data\ngathered in deployment, through passive collection of data, rather than from\nrandomized trials. We propose a method for learning optimal prescriptive trees\nusing mixed-integer optimization (MIO) technology. We show that under mild\nconditions our method is asymptotically exact in the sense that it converges to\nan optimal out-of-sample treatment assignment policy as the number of\nhistorical data samples tends to infinity. This sets us apart from existing\nliterature on the topic which either requires data to be randomized or imposes\nstringent assumptions on the trees. Based on extensive computational\nexperiments on both synthetic and real data, we demonstrate that our asymptotic\nguarantees translate to significant out-of-sample performance improvements even\nin finite samples.",
    "descriptor": "",
    "authors": [
      "Nathanael Jo",
      "Sina Aghaei",
      "Andr\u00e9s G\u00f3mez",
      "Phebe Vayanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.13628"
  },
  {
    "id": "arXiv:2108.13629",
    "title": "Dynamic Sliding Window for Meeting Summarization",
    "abstract": "Recently abstractive spoken language summarization raises emerging research\ninterest, and neural sequence-to-sequence approaches have brought significant\nperformance improvement. However, summarizing long meeting transcripts remains\nchallenging. Due to the large length of source contents and targeted summaries,\nneural models are prone to be distracted on the context, and produce summaries\nwith degraded quality. Moreover, pre-trained language models with input length\nlimitations cannot be readily applied to long sequences. In this work, we first\nanalyze the linguistic characteristics of meeting transcripts on a\nrepresentative corpus, and find that the sentences comprising the summary\ncorrelate with the meeting agenda. Based on this observation, we propose a\ndynamic sliding window strategy for meeting summarization. Experimental results\nshow that performance benefit from the proposed method, and outputs obtain\nhigher factual consistency than the base model.",
    "descriptor": "\nComments: SummDial@SIGDial 2021\n",
    "authors": [
      "Zhengyuan Liu",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13629"
  },
  {
    "id": "arXiv:2108.13630",
    "title": "SimulLR: Simultaneous Lip Reading Transducer with Attention-Guided  Adaptive Memory",
    "abstract": "Lip reading, aiming to recognize spoken sentences according to the given\nvideo of lip movements without relying on the audio stream, has attracted great\ninterest due to its application in many scenarios. Although prior works that\nexplore lip reading have obtained salient achievements, they are all trained in\na non-simultaneous manner where the predictions are generated requiring access\nto the full video. To breakthrough this constraint, we study the task of\nsimultaneous lip reading and devise SimulLR, a simultaneous lip Reading\ntransducer with attention-guided adaptive memory from three aspects: (1) To\naddress the challenge of monotonic alignments while considering the syntactic\nstructure of the generated sentences under simultaneous setting, we build a\ntransducer-based model and design several effective training strategies\nincluding CTC pre-training, model warm-up and curriculum learning to promote\nthe training of the lip reading transducer. (2) To learn better spatio-temporal\nrepresentations for simultaneous encoder, we construct a truncated 3D\nconvolution and time-restricted self-attention layer to perform the\nframe-to-frame interaction within a video segment containing fixed number of\nframes. (3) The history information is always limited due to the storage in\nreal-time scenarios, especially for massive video data. Therefore, we devise a\nnovel attention-guided adaptive memory to organize semantic information of\nhistory segments and enhance the visual representations with acceptable\ncomputation-aware latency. The experiments show that the SimulLR achieves the\ntranslation speedup 9.10$\\times$ compared with the state-of-the-art\nnon-simultaneous methods, and also obtains competitive results, which indicates\nthe effectiveness of our proposed methods.",
    "descriptor": "\nComments: ACMMM 2021\n",
    "authors": [
      "Zhijie Lin",
      "Zhou Zhao",
      "Haoyuan Li",
      "Jinglin Liu",
      "Meng Zhang",
      "Xingshan Zeng",
      "Xiaofei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13630"
  },
  {
    "id": "arXiv:2108.13637",
    "title": "When are Deep Networks really better than Random Forests at small sample  sizes?",
    "abstract": "Random forests (RF) and deep networks (DN) are two of the most popular\nmachine learning methods in the current scientific literature and yield\ndiffering levels of performance on different data modalities. We wish to\nfurther explore and establish the conditions and domains in which each approach\nexcels, particularly in the context of sample size and feature dimension. To\naddress these issues, we tested the performance of these approaches across\ntabular, image, and audio settings using varying model parameters and\narchitectures. Our focus is on datasets with at most 10,000 samples, which\nrepresent a large fraction of scientific and biomedical datasets. In general,\nwe found RF to excel at tabular and structured data (image and audio) with\nsmall sample sizes, whereas DN performed better on structured data with larger\nsample sizes. Although we plan to continue updating this technical report in\nthe coming months, we believe the current preliminary results may be of\ninterest to others.",
    "descriptor": "",
    "authors": [
      "Haoyin Xu",
      "Michael Ainsworth",
      "Yu-Chung Peng",
      "Madi Kusmanov",
      "Sambit Panda",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13637"
  },
  {
    "id": "arXiv:2108.13640",
    "title": "Module-Power Prediction from PL Measurements using Deep Learning",
    "abstract": "The individual causes for power loss of photovoltaic modules are investigated\nfor quite some time. Recently, it has been shown that the power loss of a\nmodule is, for example, related to the fraction of inactive areas. While these\nareas can be easily identified from electroluminescense (EL) images, this is\nmuch harder for photoluminescence (PL) images. With this work, we close the gap\nbetween power regression from EL and PL images. We apply a deep convolutional\nneural network to predict the module power from PL images with a mean absolute\nerror (MAE) of 4.4% or 11.7WP. Furthermore, we depict that regression maps\ncomputed from the embeddings of the trained network can be used to compute the\nlocalized power loss. Finally, we show that these regression maps can be used\nto identify inactive regions in PL images as well.",
    "descriptor": "",
    "authors": [
      "Mathis Hoffmann",
      "Johannes Hepp",
      "Bernd Doll",
      "Claudia Buerhop-Lutz",
      "Ian Marius Peters",
      "Christoph Brabec",
      "Andreas Maier",
      "Vincent Christlein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13640"
  },
  {
    "id": "arXiv:2108.13643",
    "title": "Learning to Synthesize Programs as Interpretable and Generalizable  Policies",
    "abstract": "Recently, deep reinforcement learning (DRL) methods have achieved impressive\nperformance on tasks in a variety of domains. However, neural network policies\nproduced with DRL methods are not human-interpretable and often have difficulty\ngeneralizing to novel scenarios. To address these issues, prior works explore\nlearning programmatic policies that are more interpretable and structured for\ngeneralization. Yet, these works either employ limited policy representations\n(e.g. decision trees, state machines, or predefined program templates) or\nrequire stronger supervision (e.g. input/output state pairs or expert\ndemonstrations). We present a framework that instead learns to synthesize a\nprogram, which details the procedure to solve a task in a flexible and\nexpressive manner, solely from reward signals. To alleviate the difficulty of\nlearning to compose programs to induce the desired agent behavior from scratch,\nwe propose to first learn a program embedding space that continuously\nparameterizes diverse behaviors in an unsupervised manner and then search over\nthe learned program embedding space to yield a program that maximizes the\nreturn for a given task. Experimental results demonstrate that the proposed\nframework not only learns to reliably synthesize task-solving programs but also\noutperforms DRL and program synthesis baselines while producing interpretable\nand more generalizable policies. We also justify the necessity of the proposed\ntwo-stage learning scheme as well as analyze various methods for learning the\nprogram embedding.",
    "descriptor": "\nComments: 52 pages, 16 figures, 12 tables\n",
    "authors": [
      "Dweep Trivedi",
      "Jesse Zhang",
      "Shao-Hua Sun",
      "Joseph J. Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.13643"
  },
  {
    "id": "arXiv:2108.13647",
    "title": "A Mechanically Verified Theory of Contracts",
    "abstract": "Cyber-physical systems (CPS) are assemblies of networked, heterogeneous,\nhardware, and software components sensing, evaluating, and actuating a physical\nenvironment. This heterogeneity induces complexity that makes CPSs challenging\nto model correctly. Since CPSs often have critical functions, it is however of\nutmost importance to formally verify them in order to provide the highest\nguarantees of safety. Faced with CPS complexity, model abstraction becomes\nparamount to make verification attainable. To this end, assume/guarantee\ncontracts enable component model abstraction to support a sound, structured,\nand modular verification process. While abstractions of models by contracts are\nusually proved sound, none of the related contract frameworks themselves have,\nto the best of our knowledge, been formally proved correct so far. In this aim,\nwe present the formalization of a generic assume/guarantee contract theory in\nthe proof assistant Coq. We identify and prove theorems that ensure its\ncorrectness. Our theory is generic, or parametric, in that it can be\ninstantiated and used with any given logic, in particular hybrid logics, in\nwhich highly complex cyber-physical systems can uniformly be described.",
    "descriptor": "",
    "authors": [
      "St\u00e9phane Kastenbaum",
      "Beno\u00eet Boyer",
      "Jean-Pierre Talpin"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2108.13647"
  },
  {
    "id": "arXiv:2108.13648",
    "title": "Autonomous Rollator: A Case Study in the Agebots Project",
    "abstract": "In this paper, we present an iterative development process for a functional\nmodel of an autonomous, location-orienting rollator. An interdisciplinary team\nwas involved in the development, working closely with the end-users. This\nexample shows that the design thinking method is suitable for the development\nof frontier technology devices in the care sector.",
    "descriptor": "",
    "authors": [
      "Jonas Frei",
      "Anina Havelka",
      "Markus W\u00fcst",
      "Einar Nielsen",
      "Andreas Ziltner",
      "Katrin S. Lohan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13648"
  },
  {
    "id": "arXiv:2108.13650",
    "title": "Heterogeneous Graph Neural Network with Multi-view Representation  Learning",
    "abstract": "Graph neural networks for heterogeneous graph embedding is to project nodes\ninto a low-dimensional space by exploring the heterogeneity and semantics of\nthe heterogeneous graph. However, on the one hand, most of existing\nheterogeneous graph embedding methods either insufficiently model the local\nstructure under specific semantic, or neglect the heterogeneity when\naggregating information from it. On the other hand, representations from\nmultiple semantics are not comprehensively integrated to obtain versatile node\nembeddings. To address the problem, we propose a Heterogeneous Graph Neural\nNetwork with Multi-View Representation Learning (named MV-HetGNN) for\nheterogeneous graph embedding by introducing the idea of multi-view\nrepresentation learning. The proposed model consists of node feature\ntransformation, view-specific ego graph encoding and auto multi-view fusion to\nthoroughly learn complex structural and semantic information for generating\ncomprehensive node representations. Extensive experiments on three real-world\nheterogeneous graph datasets show that the proposed MV-HetGNN model\nconsistently outperforms all the state-of-the-art GNN baselines in various\ndownstream tasks, e.g., node classification, node clustering, and link\nprediction.",
    "descriptor": "",
    "authors": [
      "Zezhi Shao",
      "Yongjun Xu",
      "Wei Wei",
      "Fei Wang",
      "Zhao Zhang",
      "Feida Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13650"
  },
  {
    "id": "arXiv:2108.13653",
    "title": "Explaining Classes through Word Attribution",
    "abstract": "In recent years, several methods have been proposed for explaining individual\npredictions of deep learning models, yet there has been little study of how to\naggregate these predictions to explain how such models view classes as a whole\nin text classification tasks. In this work, we propose a method for explaining\nclasses using deep learning models and the Integrated Gradients feature\nattribution technique by aggregating explanations of individual examples in\ntext classification to general descriptions of the classes. We demonstrate the\napproach on Web register (genre) classification using the XML-R model and the\nCorpus of Online Registers of English (CORE), finding that the method\nidentifies plausible and discriminative keywords characterizing all but the\nsmallest class.",
    "descriptor": "",
    "authors": [
      "Samuel R\u00f6nnqvist",
      "Amanda Myntti",
      "Aki-Juhani Kyr\u00f6l\u00e4inen",
      "Sampo Pyysalo",
      "Veronika Laippala",
      "Filip Ginter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13653"
  },
  {
    "id": "arXiv:2108.13654",
    "title": "Discretized Integrated Gradients for Explaining Language Models",
    "abstract": "As a prominent attribution-based explanation algorithm, Integrated Gradients\n(IG) is widely adopted due to its desirable explanation axioms and the ease of\ngradient computation. It measures feature importance by averaging the model's\noutput gradient interpolated along a straight-line path in the input data\nspace. However, such straight-line interpolated points are not representative\nof text data due to the inherent discreteness of the word embedding space. This\nquestions the faithfulness of the gradients computed at the interpolated points\nand consequently, the quality of the generated explanations. Here we propose\nDiscretized Integrated Gradients (DIG), which allows effective attribution\nalong non-linear interpolation paths. We develop two interpolation strategies\nfor the discrete word embedding space that generates interpolation points that\nlie close to actual words in the embedding space, yielding more faithful\ngradient computation. We demonstrate the effectiveness of DIG over IG through\nexperimental and human evaluations on multiple sentiment classification\ndatasets. We provide the source code of DIG to encourage reproducible research.",
    "descriptor": "\nComments: Accepted in EMNLP 2021\n",
    "authors": [
      "Soumya Sanyal",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13654"
  },
  {
    "id": "arXiv:2108.13655",
    "title": "MELM: Data Augmentation with Masked Entity Language Modeling for  Cross-lingual NER",
    "abstract": "Data augmentation for cross-lingual NER requires fine-grained control over\ntoken labels of the augmented text. Existing augmentation approach based on\nmasked language modeling may replace a labeled entity with words of a different\nclass, which makes the augmented sentence incompatible with the original label\nsequence, and thus hurts the performance.We propose a data augmentation\nframework with Masked-Entity Language Modeling (MELM) which effectively ensures\nthe replacing entities fit the original labels. Specifically, MELM linearizes\nNER labels into sentence context, and thus the fine-tuned MELM is able to\npredict masked tokens by explicitly conditioning on their labels. Our MELM is\nagnostic to the source of data to be augmented. Specifically, when MELM is\napplied to augment training data of the source language, it achieves up to 3.5%\nF1 score improvement for cross-lingual NER. When unlabeled target data is\navailable and MELM can be further applied to augment pseudo-labeled target\ndata, the performance gain reaches 5.7%. Moreover, MELM consistently\noutperforms multiple baseline methods for data augmentation.",
    "descriptor": "",
    "authors": [
      "Ran Zhou",
      "Ruidan He",
      "Xin Li",
      "Lidong Bing",
      "Erik Cambria",
      "Luo Si",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13655"
  },
  {
    "id": "arXiv:2108.13658",
    "title": "Automatic Rule Generation for Time Expression Normalization",
    "abstract": "The understanding of time expressions includes two sub-tasks: recognition and\nnormalization. In recent years, significant progress has been made in the\nrecognition of time expressions while research on normalization has lagged\nbehind. Existing SOTA normalization methods highly rely on rules or grammars\ndesigned by experts, which limits their performance on emerging corpora, such\nas social media texts. In this paper, we model time expression normalization as\na sequence of operations to construct the normalized temporal value, and we\npresent a novel method called ARTime, which can automatically generate\nnormalization rules from training data without expert interventions.\nSpecifically, ARTime automatically captures possible operation sequences from\nannotated data and generates normalization rules on time expressions with\ncommon surface forms. The experimental results show that ARTime can\nsignificantly surpass SOTA methods on the Tweets benchmark, and achieves\ncompetitive results with existing expert-engineered rule methods on the\nTempEval-3 benchmark.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Wentao Ding",
      "Jianhao Chen",
      "Jinmao Li",
      "Yuzhong Qu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13658"
  },
  {
    "id": "arXiv:2108.13659",
    "title": "Gray Cycles of Maximum Length Related to k-Character Substitutions",
    "abstract": "Given a word binary relation $\\tau$ we define a $\\tau$-Gray cycle over a\nfinite language $X$ to be a permutation $\\left(w_{[i]}\\right)_{0\\le i\\le\n|X|-1}$ of $X$ such that each word $w_i$ is an image of the previous word\n$w_{i-1}$ by $\\tau$. In that framework, we introduce the complexity measure\n$\\lambda(n)$, equal to the largest cardinality of a language $X$ having words\nof length at most $n$, and such that a $\\tau$-Gray cycle over $X$ exists. The\npresent paper is concerned with the relation $\\tau=\\sigma_k$, the so-called\n$k$-character substitution, where $(u,v)$ belongs to $\\sigma_k$ if, and only\nif, the Hamming distance of $u$ and $v$ is $k$. We compute the bound\n$\\lambda(n)$ for all cases of the alphabet cardinality and the argument $n$.",
    "descriptor": "",
    "authors": [
      "Jean N\u00e9raud"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2108.13659"
  },
  {
    "id": "arXiv:2108.13660",
    "title": "Formalizing the Gromov-Hausdorff space",
    "abstract": "The Gromov-Hausdorff space is usually defined in textbooks as \"the space of\nall compact metric spaces up to isometry\". We describe a formalization of this\nnotion in the Lean proof assistant, insisting on how we need to depart from the\nusual informal viewpoint of mathematicians on this object to get a rigorous\nformalization.",
    "descriptor": "",
    "authors": [
      "S\u00e9bastien Gou\u00ebzel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2108.13660"
  },
  {
    "id": "arXiv:2108.13664",
    "title": "Lane level context and hidden space characterization for autonomous  driving",
    "abstract": "For an autonomous vehicle, situation understand-ing is a key capability\ntowards safe and comfortable decision-making and navigation. Information is in\ngeneral provided bymultiple sources. Prior information about the road topology\nandtraffic laws can be given by a High Definition (HD) map whilethe perception\nsystem provides the description of the spaceand of road entities evolving in\nthe vehicle surroundings. Incomplex situations such as those encountered in\nurban areas,the road user behaviors are governed by strong interactionswith the\nothers, and with the road network. In such situations,reliable situation\nunderstanding is therefore mandatory to avoidinappropriate decisions.\nNevertheless, situation understandingis a complex task that requires access to\na consistent andnon-misleading representation of the vehicle surroundings.\nThispaper proposes a formalism (an interaction lane grid) whichallows to\nrepresent, with different levels of abstraction, thenavigable and interacting\nspaces which must be considered forsafe navigation. A top-down approach is\nchosen to assess andcharacterize the relevant information of the situation. On\na highlevel of abstraction, the identification of the areas of interestwhere\nthe vehicle should pay attention is depicted. On a lowerlevel, it enables to\ncharacterize the spatial information in aunified representation and to infer\nadditional information inoccluded areas by reasoning with dynamic objects.",
    "descriptor": "",
    "authors": [
      "Alexandre Armand",
      "Corentin Sanchez",
      "Philippe Xu",
      "Alexandre Arm",
      "Philippe Bonnifait"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13664"
  },
  {
    "id": "arXiv:2108.13665",
    "title": "Is First Person Vision Challenging for Object Tracking?",
    "abstract": "Understanding human-object interactions is fundamental in First Person Vision\n(FPV). Tracking algorithms which follow the objects manipulated by the camera\nwearer can provide useful cues to effectively model such interactions. Visual\ntracking solutions available in the computer vision literature have\nsignificantly improved their performance in the last years for a large variety\nof target objects and tracking scenarios. However, despite a few previous\nattempts to exploit trackers in FPV applications, a methodical analysis of the\nperformance of state-of-the-art trackers in this domain is still missing. In\nthis paper, we fill the gap by presenting the first systematic study of object\ntracking in FPV. Our study extensively analyses the performance of recent\nvisual trackers and baseline FPV trackers with respect to different aspects and\nconsidering a new performance measure. This is achieved through TREK-150, a\nnovel benchmark dataset composed of 150 densely annotated video sequences. Our\nresults show that object tracking in FPV is challenging, which suggests that\nmore research efforts should be devoted to this problem so that tracking could\nbenefit FPV tasks.",
    "descriptor": "\nComments: IEEE/CVF International Conference on Computer Vision (ICCV) 2021, Visual Object Tracking Challenge VOT2021 workshop. arXiv admin note: text overlap with arXiv:2011.12263\n",
    "authors": [
      "Matteo Dunnhofer",
      "Antonino Furnari",
      "Giovanni Maria Farinella",
      "Christian Micheloni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13665"
  },
  {
    "id": "arXiv:2108.13672",
    "title": "Medical SANSformers: Training self-supervised transformers without  attention for Electronic Medical Records",
    "abstract": "We leverage deep sequential models to tackle the problem of predicting\nhealthcare utilization for patients, which could help governments to better\nallocate resources for future healthcare use. Specifically, we study the\nproblem of \\textit{divergent subgroups}, wherein the outcome distribution in a\nsmaller subset of the population considerably deviates from that of the general\npopulation. The traditional approach for building specialized models for\ndivergent subgroups could be problematic if the size of the subgroup is very\nsmall (for example, rare diseases). To address this challenge, we first develop\na novel attention-free sequential model, SANSformers, instilled with inductive\nbiases suited for modeling clinical codes in electronic medical records. We\nthen design a task-specific self-supervision objective and demonstrate its\neffectiveness, particularly in scarce data settings, by pre-training each model\non the entire health registry (with close to one million patients) before\nfine-tuning for downstream tasks on the divergent subgroups. We compare the\nnovel SANSformer architecture with the LSTM and Transformer models using two\ndata sources and a multi-task learning objective that aids healthcare\nutilization prediction. Empirically, the attention-free SANSformer models\nperform consistently well across experiments, outperforming the baselines in\nmost cases by at least $\\sim 10$\\%. Furthermore, the self-supervised\npre-training boosts performance significantly throughout, for example by over\n$\\sim 50$\\% (and as high as $800$\\%) on $R^2$ score when predicting the number\nof hospital visits.",
    "descriptor": "\nComments: 25 pages, 8 figures, 5 tables, Submitted to a journal\n",
    "authors": [
      "Yogesh Kumar",
      "Alexander Ilin",
      "Henri Salo",
      "Sangita Kulathinal",
      "Maarit K. Leinonen",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13672"
  },
  {
    "id": "arXiv:2108.13673",
    "title": "Semi-supervised Image Classification with Grad-CAM Consistency",
    "abstract": "Consistency training, which exploits both supervised and unsupervised\nlearning with different augmentations on image, is an effective method of\nutilizing unlabeled data in semi-supervised learning (SSL) manner. Here, we\npresent another version of the method with Grad-CAM consistency loss, so it can\nbe utilized in training model with better generalization and adjustability. We\nshow that our method improved the baseline ResNet model with at most 1.44 % and\n0.31 $\\pm$ 0.59 %p accuracy improvement on average with CIFAR-10 dataset. We\nconducted ablation study comparing to using only psuedo-label for consistency\ntraining. Also, we argue that our method can adjust in different environments\nwhen targeted to different units in the model. The code is available:\nhttps://github.com/gimme1dollar/gradcam-consistency-semi-sup.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Juyong Lee",
      "Seunghyuk Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13673"
  },
  {
    "id": "arXiv:2108.13677",
    "title": "Development of User-friendly Smart Grid Architecture",
    "abstract": "As systems like smart grid continue to become complex on a daily basis,\nemerging issues demand complex solutions that can deal with parameters in\nmultiple domains of engineering. The complex solutions further demand a\nfriendly interface for the users to express their requirements. Cyber-Physical\nsystems deals with the study of techniques that are committed to modeling,\nsimulating and solving the problems that emerge from a multi-disciplinary\noutlook towards futuristic systems. This thesis is mainly concerned with the\ndevelopment of user-friendly cyber-physical frameworks that can tackle various\nissues faced by the utilities and users of smart grid through a suitable choice\nof smart microgrid architecture.",
    "descriptor": "",
    "authors": [
      "Swaroop Mishra"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2108.13677"
  },
  {
    "id": "arXiv:2108.13679",
    "title": "Task-Oriented Dialogue System as Natural Language Generation",
    "abstract": "In this paper, we propose to formulate the task-oriented dialogue system as\nthe purely natural language generation task, so as to fully leverage the\nlarge-scale pre-trained models like GPT-2 and simplify complicated\ndelexicalization prepossessing. However, directly applying this method heavily\nsuffers from the dialogue entity inconsistency caused by the removal of\ndelexicalized tokens, as well as the catastrophic forgetting problem of the\npre-trained model during fine-tuning, leading to unsatisfactory performance. To\nalleviate these problems, we design a novel GPT-Adapter-CopyNet network, which\nincorporates the lightweight adapter and CopyNet modules into GPT-2 to achieve\nbetter performance on transfer learning and dialogue entity generation.\nExperimental results conducted on the DSTC8 Track 1 benchmark and MultiWOZ\ndataset demonstrate that our proposed approach significantly outperforms\nbaseline models with a remarkable performance on automatic and human\nevaluations.",
    "descriptor": "",
    "authors": [
      "Weizhi Wang",
      "Zhirui Zhang",
      "Junliang Guo",
      "Boxing Chen",
      "Weihua Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13679"
  },
  {
    "id": "arXiv:2108.13680",
    "title": "Learning Practically Feasible Policies for Online 3D Bin Packing",
    "abstract": "We tackle the Online 3D Bin Packing Problem, a challenging yet practically\nuseful variant of the classical Bin Packing Problem. In this problem, the items\nare delivered to the agent without informing the full sequence information.\nAgent must directly pack these items into the target bin stably without\nchanging their arrival order, and no further adjustment is permitted. Online\n3D-BPP can be naturally formulated as Markov Decision Process (MDP). We adopt\ndeep reinforcement learning, in particular, the on-policy actor-critic\nframework, to solve this MDP with constrained action space. To learn a\npractically feasible packing policy, we propose three critical designs. First,\nwe propose an online analysis of packing stability based on a novel stacking\ntree. It attains a high analysis accuracy while reducing the computational\ncomplexity from $O(N^2)$ to $O(N \\log N)$, making it especially suited for RL\ntraining. Second, we propose a decoupled packing policy learning for different\ndimensions of placement which enables high-resolution spatial discretization\nand hence high packing precision. Third, we introduce a reward function that\ndictates the robot to place items in a far-to-near order and therefore\nsimplifies the collision avoidance in movement planning of the robotic arm.\nFurthermore, we provide a comprehensive discussion on several key implemental\nissues. The extensive evaluation demonstrates that our learned policy\noutperforms the state-of-the-art methods significantly and is practically\nusable for real-world applications.",
    "descriptor": "",
    "authors": [
      "Hang Zhao",
      "Chenyang Zhu",
      "Xin Xu",
      "Hui Huang",
      "Kai Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13680"
  },
  {
    "id": "arXiv:2108.13684",
    "title": "Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness  Trade-off in Abstractive Summarization",
    "abstract": "Despite recent progress in abstractive summarization, systems still suffer\nfrom faithfulness errors. While prior work has proposed models that improve\nfaithfulness, it is unclear whether the improvement comes from an increased\nlevel of extractiveness of the model outputs as one naive way to improve\nfaithfulness is to make summarization models more extractive. In this work, we\npresent a framework for evaluating the effective faithfulness of summarization\nsystems, by generating a faithfulnessabstractiveness trade-off curve that\nserves as a control at different operating points on the abstractiveness\nspectrum. We then show that the Maximum Likelihood Estimation (MLE) baseline as\nwell as a recently proposed method for improving faithfulness, are both worse\nthan the control at the same level of abstractiveness. Finally, we learn a\nselector to identify the most faithful and abstractive summary for a given\ndocument, and show that this system can attain higher faithfulness scores in\nhuman evaluations while being more abstractive than the baseline system on two\ndatasets. Moreover, we show that our system is able to achieve a better\nfaithfulness-abstractiveness trade-off than the control at the same level of\nabstractiveness.",
    "descriptor": "",
    "authors": [
      "Faisal Ladhak",
      "Esin Durmus",
      "He He",
      "Claire Cardie",
      "Kathleen McKeown"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13684"
  },
  {
    "id": "arXiv:2108.13686",
    "title": "Knowledge-Grounded Dialogue with Reward-Driven Knowledge Selection",
    "abstract": "Knowledge-grounded dialogue is a task of generating a fluent and informative\nresponse based on both conversation context and a collection of external\nknowledge, in which knowledge selection plays an important role and attracts\nmore and more research interest. However, most existing models either select\nonly one knowledge or use all knowledge for responses generation. The former\nmay lose valuable information in discarded knowledge, while the latter may\nbring a lot of noise. At the same time, many approaches need to train the\nknowledge selector with knowledge labels that indicate ground-truth knowledge,\nbut these labels are difficult to obtain and require a large number of manual\nannotations. Motivated by these issues, we propose Knoformer, a dialogue\nresponse generation model based on reinforcement learning, which can\nautomatically select one or more related knowledge from the knowledge pool and\ndoes not need knowledge labels during training. Knoformer is evaluated on two\nknowledge-guided conversation datasets, and achieves state-of-the-art\nperformance.",
    "descriptor": "\nComments: NLPCC 2021\n",
    "authors": [
      "Shilei Liu",
      "Xiaofeng Zhao",
      "Bochao Li",
      "Feiliang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13686"
  },
  {
    "id": "arXiv:2108.13689",
    "title": "An asymptotic-preserving discretization scheme for gas transport in pipe  networks",
    "abstract": "We consider the simulation of barotropic flow of gas in long pipes and pipe\nnetworks. Based on a Hamiltonian reformulation of the governing system, a fully\ndiscrete approximation scheme is proposed using mixed finite elements in space\nand an implicit Euler method in time. Assuming the existence of a smooth\nsubsonic solution bounded away from vacuum, a full convergence analysis is\npresented based on relative energy estimates. Particular attention is paid to\nestablishing error bounds that are uniform in the friction parameter. As a\nconsequence, the method and results also cover the parabolic problem arising in\nthe asymptotic large friction limit. The error estimates are derived in detail\nfor a single pipe, but using appropriate coupling conditions and the particular\nstructure of the problem and its discretization, the main results directly\ngeneralize to pipe networks. Numerical tests are presented for illustration.",
    "descriptor": "",
    "authors": [
      "H. Egger",
      "J. Giesselmann",
      "T. Kunkel",
      "N. Philippi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.13689"
  },
  {
    "id": "arXiv:2108.13696",
    "title": "Phy-Q: A Benchmark for Physical Reasoning",
    "abstract": "Humans are well-versed in reasoning about the behaviors of physical objects\nwhen choosing actions to accomplish tasks, while it remains a major challenge\nfor AI. To facilitate research addressing this problem, we propose a new\nbenchmark that requires an agent to reason about physical scenarios and take an\naction accordingly. Inspired by the physical knowledge acquired in infancy and\nthe capabilities required for robots to operate in real-world environments, we\nidentify 15 essential physical scenarios. For each scenario, we create a wide\nvariety of distinct task templates, and we ensure all the task templates within\nthe same scenario can be solved by using one specific physical rule. By having\nsuch a design, we evaluate two distinct levels of generalization, namely the\nlocal generalization and the broad generalization. We conduct an extensive\nevaluation with human players, learning agents with varying input types and\narchitectures, and heuristic agents with different strategies. The benchmark\ngives a Phy-Q (physical reasoning quotient) score that reflects the physical\nreasoning ability of the agents. Our evaluation shows that 1) all agents fail\nto reach human performance, and 2) learning agents, even with good local\ngeneralization ability, struggle to learn the underlying physical reasoning\nrules and fail to generalize broadly. We encourage the development of\nintelligent agents with broad generalization abilities in physical domains.",
    "descriptor": "\nComments: For the associated website, see this https URL\n",
    "authors": [
      "Cheng Xue",
      "Vimukthini Pinto",
      "Chathura Gamage",
      "Ekaterina Nikonova",
      "Peng Zhang",
      "Jochen Renz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13696"
  },
  {
    "id": "arXiv:2108.13697",
    "title": "Attention-based Multi-Reference Learning for Image Super-Resolution",
    "abstract": "This paper proposes a novel Attention-based Multi-Reference Super-resolution\nnetwork (AMRSR) that, given a low-resolution image, learns to adaptively\ntransfer the most similar texture from multiple reference images to the\nsuper-resolution output whilst maintaining spatial coherence. The use of\nmultiple reference images together with attention-based sampling is\ndemonstrated to achieve significantly improved performance over\nstate-of-the-art reference super-resolution approaches on multiple benchmark\ndatasets. Reference super-resolution approaches have recently been proposed to\novercome the ill-posed problem of image super-resolution by providing\nadditional information from a high-resolution reference image. Multi-reference\nsuper-resolution extends this approach by providing a more diverse pool of\nimage features to overcome the inherent information deficit whilst maintaining\nmemory efficiency. A novel hierarchical attention-based sampling approach is\nintroduced to learn the similarity between low-resolution image features and\nmultiple reference images based on a perceptual loss. Ablation demonstrates the\ncontribution of both multi-reference and hierarchical attention-based sampling\nto overall performance. Perceptual and quantitative ground-truth evaluation\ndemonstrates significant improvement in performance even when the reference\nimages deviate significantly from the target image. The project website can be\nfound at https://marcopesavento.github.io/AMRSR/",
    "descriptor": "",
    "authors": [
      "Marco Pesavento",
      "Marco Volino",
      "Adrian Hilton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13697"
  },
  {
    "id": "arXiv:2108.13699",
    "title": "End-to-End Monocular Vanishing Point Detection Exploiting Lane  Annotations",
    "abstract": "Vanishing points (VPs) play a vital role in various computer vision tasks,\nespecially for recognizing the 3D scenes from an image. In the real-world\nscenario of automobile applications, it is costly to manually obtain the\nexternal camera parameters when the camera is attached to the vehicle or the\nattachment is accidentally perturbed. In this paper we introduce a simple but\neffective end-to-end vanishing point detection. By automatically calculating\nintersection of the extrapolated lane marker annotations, we obtain\ngeometrically consistent VP labels and mitigate human annotation errors caused\nby manual VP labeling. With the calculated VP labels we train end-to-end VP\nDetector via heatmap estimation. The VP Detector realizes higher accuracy than\nthe methods utilizing manual annotation or lane detection, paving the way for\naccurate online camera calibration.",
    "descriptor": "",
    "authors": [
      "Hiroto Honda",
      "Motoki Kimura",
      "Takumi Karasawa",
      "Yusuke Uchida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13699"
  },
  {
    "id": "arXiv:2108.13700",
    "title": "TNNT: The Named Entity Recognition Toolkit",
    "abstract": "Extraction of categorised named entities from text is a complex task given\nthe availability of a variety of Named Entity Recognition (NER) models and the\nunstructured information encoded in different source document formats.\nProcessing the documents to extract text, identifying suitable NER models for a\ntask, and obtaining statistical information is important in data analysis to\nmake informed decisions. This paper presents TNNT, a toolkit that automates the\nextraction of categorised named entities from unstructured information encoded\nin source documents, using diverse state-of-the-art Natural Language Processing\n(NLP) tools and NER models. TNNT integrates 21 different NER models as part of\na Knowledge Graph Construction Pipeline (KGCP) that takes a document set as\ninput and processes it based on the defined settings, applying the selected\nblocks of NER models to output the results. The toolkit generates all results\nwith an integrated summary of the extracted entities, enabling enhanced data\nanalysis to support the KGCP, and also, to aid further NLP tasks.",
    "descriptor": "\nComments: This demo paper will be submitted at K-Cap 2021\n",
    "authors": [
      "Sandaru Seneviratne",
      "Sergio J. Rodr\u00edguez M\u00e9ndez",
      "Xuecheng Zhang",
      "Pouya G. Omran",
      "Kerry Taylor",
      "Armin Haller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.13700"
  },
  {
    "id": "arXiv:2108.13702",
    "title": "SemIE: Semantically-aware Image Extrapolation",
    "abstract": "We propose a semantically-aware novel paradigm to perform image extrapolation\nthat enables the addition of new object instances. All previous methods are\nlimited in their capability of extrapolation to merely extending the already\nexisting objects in the image. However, our proposed approach focuses not only\non (i) extending the already present objects but also on (ii) adding new\nobjects in the extended region based on the context. To this end, for a given\nimage, we first obtain an object segmentation map using a state-of-the-art\nsemantic segmentation method. The, thus, obtained segmentation map is fed into\na network to compute the extrapolated semantic segmentation and the\ncorresponding panoptic segmentation maps. The input image and the obtained\nsegmentation maps are further utilized to generate the final extrapolated\nimage. We conduct experiments on Cityscapes and ADE20K-bedroom datasets and\nshow that our method outperforms all baselines in terms of FID, and similarity\nin object co-occurrence statistics.",
    "descriptor": "\nComments: To appear in International Conference on Computer Vision (ICCV) 2021. Project URL: this https URL\n",
    "authors": [
      "Bholeshwar Khurana",
      "Soumya Ranjan Dash",
      "Abhishek Bhatia",
      "Aniruddha Mahapatra",
      "Hrituraj Singh",
      "Kuldeep Kulkarni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13702"
  },
  {
    "id": "arXiv:2108.13714",
    "title": "Control Scenarios for Probabilistic SIR Epidemics on Social-Connection  Graphs",
    "abstract": "A probabilistic approach to epidemic evolution on realistic social-connection\ngraphs allows for characteristic differences among subjects, including the\nindividual structure and number of social contacts (`ego networks') and the\nindividual infection and recovery rates according to age or medical\npreconditions. Within our probabilistic Susceptible-Infectious-Removed (SIR)\nmodel on graphs, we compare the infection load and proxy cost of control\nscenarios by confinement, vaccination, and their combinations. The epidemic\ndiffusion is explored on random social-connection graphs designed for more\nrealistic person-person characteristics.",
    "descriptor": "\nComments: preprint submitted to journal\n",
    "authors": [
      "Jan B. Broekaert",
      "Davide La Torre"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2108.13714"
  },
  {
    "id": "arXiv:2108.13716",
    "title": "A log-linear $(2+5/6)$-approximation algorithm for parallel machine  scheduling with a single orthogonal resource",
    "abstract": "As the gap between compute and I/O performance tends to grow, modern\nHigh-Performance Computing (HPC) architectures include a new resource type: an\nintermediate persistent fast memory layer, called burst buffers. This is just\none of many kinds of renewable resources which are orthogonal to the processors\nthemselves, such as network bandwidth or software licenses. Ignoring orthogonal\nresources while making scheduling decisions just for processors may lead to\nunplanned delays of jobs of which resource requirements cannot be immediately\nsatisfied. We focus on a classic problem of makespan minimization for\nparallel-machine scheduling of independent sequential jobs with additional\nrequirements on the amount of a single renewable orthogonal resource. We\npresent an easily-implementable log-linear algorithm that we prove is\n$2\\frac56$-approximation. In simulation experiments, we compare our algorithm\nto standard greedy list-scheduling heuristics and show that, compared to LPT,\nresource-based algorithms generate significantly shorter schedules.",
    "descriptor": "",
    "authors": [
      "Adrian Naruszko",
      "Bart\u0142omiej Przybylski",
      "Krzysztof Rzadca"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.13716"
  },
  {
    "id": "arXiv:2108.13720",
    "title": "Riemannian Optimization for Distance Geometric Inverse Kinematics",
    "abstract": "Solving the inverse kinematics problem is a fundamental challenge in motion\nplanning, control, and calibration for articulated robots. Kinematic models for\nthese robots are typically parameterized by joint angles, generating a\ncomplicated mapping between a robot's configuration and end-effector pose.\nAlternatively, the kinematic model and task constraints can be represented\nusing invariant distances between points attached to the robot. In this paper,\nwe formalize the equivalence of distance-based inverse kinematics and the\ndistance geometry problem for a large class of articulated robots and task\nconstraints. Unlike previous approaches, we use the connection between distance\ngeometry and low-rank matrix completion to find inverse kinematics solutions by\ncompleting a partial Euclidean distance matrix through local optimization.\nFurthermore, we parameterize the space of Euclidean distance matrices with the\nRiemannian manifold of fixed-rank Gram matrices, allowing us to leverage a\nvariety of mature Riemannian optimization methods. Finally, we show that bound\nsmoothing can be used to generate informed initializations without significant\ncomputational overhead, improving convergence. We demonstrate that our novel\ninverse kinematics solver achieves higher success rates than traditional\ntechniques, and significantly outperforms them on problems that involve many\nworkspace constraints.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Robotics\n",
    "authors": [
      "Filip Mari\u0107",
      "Matthew Giamou",
      "Adam W. Hall",
      "Soroush Khoubyarian",
      "Ivan Petrovi\u0107",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13720"
  },
  {
    "id": "arXiv:2108.13728",
    "title": "Pruning with Compensation: Efficient Channel Pruning for Deep  Convolutional Neural Networks",
    "abstract": "Channel pruning is a promising technique to compress the parameters of deep\nconvolutional neural networks(DCNN) and to speed up the inference. This paper\naims to address the long-standing inefficiency of channel pruning. Most channel\npruning methods recover the prediction accuracy by re-training the pruned model\nfrom the remaining parameters or random initialization. This re-training\nprocess is heavily dependent on the sufficiency of computational resources,\ntraining data, and human interference(tuning the training strategy). In this\npaper, a highly efficient pruning method is proposed to significantly reduce\nthe cost of pruning DCNN. The main contributions of our method include: 1)\npruning compensation, a fast and data-efficient substitute of re-training to\nminimize the post-pruning reconstruction loss of features, 2)\ncompensation-aware pruning(CaP), a novel pruning algorithm to remove redundant\nor less-weighted channels by minimizing the loss of information, and 3) binary\nstructural search with step constraint to minimize human interference. On\nbenchmarks including CIFAR-10/100 and ImageNet, our method shows competitive\npruning performance among the state-of-the-art retraining-based pruning methods\nand, more importantly, reduces the processing time by 95% and data usage by\n90%.",
    "descriptor": "",
    "authors": [
      "Zhouyang Xie",
      "Yan Fu",
      "Shengzhao Tian",
      "Junlin Zhou",
      "Duanbing Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13728"
  },
  {
    "id": "arXiv:2108.13732",
    "title": "Deep Learning on Edge TPUs",
    "abstract": "Computing at the edge is important in remote settings, however, conventional\nhardware is not optimized for utilizing deep neural networks. The Google Edge\nTPU is an emerging hardware accelerator that is cost, power and speed\nefficient, and is available for prototyping and production purposes. Here, I\nreview the Edge TPU platform, the tasks that have been accomplished using the\nEdge TPU, and which steps are necessary to deploy a model to the Edge TPU\nhardware. The Edge TPU is not only capable of tackling common computer vision\ntasks, but also surpasses other hardware accelerators, especially when the\nentire model can be deployed to the Edge TPU. Co-embedding the Edge TPU in\ncameras allows a seamless analysis of primary data. In summary, the Edge TPU is\na maturing system that has proven its usability across multiple tasks.",
    "descriptor": "\nComments: 8 pages, 3 figures, 3 tables\n",
    "authors": [
      "Andreas M Kist"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13732"
  },
  {
    "id": "arXiv:2108.13735",
    "title": "Hierarchical Bitmap Indexing for Range and Membership Queries on  Multidimensional Arrays",
    "abstract": "Traditional indexing techniques commonly employed in da\\-ta\\-ba\\-se systems\nperform poorly on multidimensional array scientific data. Bitmap indices are\nwidely used in commercial databases for processing complex queries, due to\ntheir effective use of bit-wise operations and space-efficiency. However,\nbitmap indices apply natively to relational or linearized datasets, which is\nespecially notable in binned or compressed indices.\nWe propose a new method for multidimensional array indexing that overcomes\nthe dimensionality-induced inefficiencies. The hierarchical indexing method is\nbased on $n$-di\\-men\\-sional sparse trees for dimension partitioning, with\nbound number of individual, adaptively binned indices for attribute\npartitioning. This indexing performs well on range involving both dimensions\nand attributes, as it prunes the search space early, avoids reading entire\nindex data, and does at most a single index traversal. Moreover, the indexing\nis easily extensible to membership queries.\nThe indexing method was implemented on top of a state of the art bitmap\nindexing library Fastbit. We show that the hierarchical bitmap index\noutperforms conventional bitmap indexing built on auxiliary attribute for each\ndimension. Furthermore, the adaptive binning significantly reduces the amount\nof bins and therefore memory requirements.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Lubo\u0161 Kr\u010d\u00e1l",
      "Shen-Shyang Ho",
      "Jan Holub"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.13735"
  },
  {
    "id": "arXiv:2108.13739",
    "title": "Super-Resolution Appearance Transfer for 4D Human Performances",
    "abstract": "A common problem in the 4D reconstruction of people from multi-view video is\nthe quality of the captured dynamic texture appearance which depends on both\nthe camera resolution and capture volume. Typically the requirement to frame\ncameras to capture the volume of a dynamic performance ($>50m^3$) results in\nthe person occupying only a small proportion $<$ 10% of the field of view. Even\nwith ultra high-definition 4k video acquisition this results in sampling the\nperson at less-than standard definition 0.5k video resolution resulting in\nlow-quality rendering. In this paper we propose a solution to this problem\nthrough super-resolution appearance transfer from a static high-resolution\nappearance capture rig using digital stills cameras ($> 8k$) to capture the\nperson in a small volume ($<8m^3$). A pipeline is proposed for super-resolution\nappearance transfer from high-resolution static capture to dynamic video\nperformance capture to produce super-resolution dynamic textures. This\naddresses two key problems: colour mapping between different camera systems;\nand dynamic texture map super-resolution using a learnt model. Comparative\nevaluation demonstrates a significant qualitative and quantitative improvement\nin rendering the 4D performance capture with super-resolution dynamic texture\nappearance. The proposed approach reproduces the high-resolution detail of the\nstatic capture whilst maintaining the appearance dynamics of the captured\nvideo.",
    "descriptor": "",
    "authors": [
      "Marco Pesavento",
      "Marco Volino",
      "Adrian Hilton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2108.13739"
  },
  {
    "id": "arXiv:2108.13740",
    "title": "Plan-then-Generate: Controlled Data-to-Text Generation via Planning",
    "abstract": "Recent developments in neural networks have led to the advance in\ndata-to-text generation. However, the lack of ability of neural models to\ncontrol the structure of generated output can be limiting in certain real-world\napplications. In this study, we propose a novel Plan-then-Generate (PlanGen)\nframework to improve the controllability of neural data-to-text models.\nExtensive experiments and analyses are conducted on two benchmark datasets,\nToTTo and WebNLG. The results show that our model is able to control both the\nintra-sentence and inter-sentence structure of the generated output.\nFurthermore, empirical comparisons against previous state-of-the-art methods\nshow that our model improves the generation quality as well as the output\ndiversity as judged by human and automatic evaluations.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Yixuan Su",
      "David Vandyke",
      "Sihui Wang",
      "Yimai Fang",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13740"
  },
  {
    "id": "arXiv:2108.13741",
    "title": "Monolingual versus Multilingual BERTology for Vietnamese Extractive  Multi-Document Summarization",
    "abstract": "Recent researches have demonstrated that BERT shows potential in a wide range\nof natural language processing tasks. It is adopted as an encoder for many\nstate-of-the-art automatic summarizing systems, which achieve excellent\nperformance. However, so far, there is not much work done for Vietnamese. In\nthis paper, we showcase how BERT can be implemented for extractive text\nsummarization in Vietnamese. We introduce a novel comparison between different\nmultilingual and monolingual BERT models. The experiment results indicate that\nmonolingual models produce promising results compared to other multilingual\nmodels and previous text summarizing models for Vietnamese.",
    "descriptor": "",
    "authors": [
      "Huy To Quoc",
      "Kiet Van Nguyen",
      "Ngan Luu-Thuy Nguyen",
      "Anh Gia-Tuan Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13741"
  },
  {
    "id": "arXiv:2108.13744",
    "title": "The Horn Non-Clausal Class and its Polynomiality",
    "abstract": "The expressiveness of propositional non-clausal (NC) formulas is\nexponentially richer than that of clausal formulas. Yet, clausal efficiency\noutperforms non-clausal one. Indeed, a major weakness of the latter is that,\nwhile Horn clausal formulas, along with Horn algorithms, are crucial for the\nhigh efficiency of clausal reasoning, no Horn-like formulas in non-clausal form\nhad been proposed. To overcome such weakness, we define the hybrid class\n$\\mathbb{H_{NC}}$ of Horn Non-Clausal (Horn-NC) formulas, by adequately lifting\nthe Horn pattern to NC form, and argue that $\\mathbb{H_{NC}}$, along with\nfuture Horn-NC algorithms, shall increase non-clausal efficiency just as the\nHorn class has increased clausal efficiency. Secondly, we: (i) give the\ncompact, inductive definition of $\\mathbb{H_{NC}}$; (ii) prove that\nsyntactically $\\mathbb{H_{NC}}$ subsumes the Horn class but semantically both\nclasses are equivalent, and (iii) characterize the non-clausal formulas\nbelonging to $\\mathbb{H_{NC}}$. Thirdly, we define the Non-Clausal\nUnit-Resolution calculus, $UR_{NC}$, and prove that it checks the\nsatisfiability of $\\mathbb{H_{NC}}$ in polynomial time. This fact, to our\nknowledge, makes $\\mathbb{H_{NC}}$ the first characterized polynomial class in\nNC reasoning. Finally, we prove that $\\mathbb{H_{NC}}$ is linearly\nrecognizable, and also that it is both strictly succincter and exponentially\nricher than the Horn class. We discuss that in NC automated reasoning, e.g.\nsatisfiability solving, theorem proving, logic programming, etc., can directly\nbenefit from $\\mathbb{H_{NC}}$ and $UR_{NC}$ and that, as a by-product of its\nproved properties, $\\mathbb{H_{NC}}$ arises as a new alternative to analyze\nHorn functions and implication systems.",
    "descriptor": "\nComments: 59 pages, 6 figures, submitted version\n",
    "authors": [
      "Gonzalo E. Imaz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13744"
  },
  {
    "id": "arXiv:2108.13747",
    "title": "In-body Bionanosensor Localization for Anomaly Detection via Inertial  Positioning and THz Backscattering Communication",
    "abstract": "Nanotechnology is enabling the development of a new generation of devices\nwhich are able to sense, process and communicate, while being in the scale of\ntens to hundreds of cubic nanometers. Such small, imperceptible devices enhance\nnot only current applications but enable entirely new paradigms especially for\nin-body environments. This paper introduces a localization and tracking concept\nfor bionanosensors floating in the human bloodstream to detect anomalies in the\nbody. Besides the nanoscale sensors, the proposed system also comprises\nmacroscale anchor nodes attached to the skin of the monitored person. To\nrealize autonomous localization and resource-efficient wireless communication\nbetween sensors and anchors, we propose to exploit inertial positioning and\nsub-terahertz backscattering. The proposed system is a first step towards early\ndisease detection as it aims at localizing body regions which show anomalies.\nSimulations are conducted to enable a systematical evaluation on the\nfeasibility of the approach.",
    "descriptor": "\nComments: 10 pages, 10 figures, submitted to IEEE Transactions on NanoBioscience\n",
    "authors": [
      "Jennifer Simonjan",
      "Bige D. Unluturk",
      "Ian F. Akyildiz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13747"
  },
  {
    "id": "arXiv:2108.13750",
    "title": "Suboptimal nonlinear moving horizon estimation",
    "abstract": "In this paper, we propose a suboptimal moving horizon estimator for a general\nclass of nonlinear systems. For the stability analysis, we transfer the\n\"feasibility-implies-stability/robustness\" paradigm from model predictive\ncontrol to the context of moving horizon estimation in the following sense:\nUsing a suitably defined, feasible candidate solution based on an auxiliary\nobserver, robust stability of the proposed suboptimal estimator is inherited\nindependently of the horizon length and even if no optimization is performed.\nMoreover, the proposed design allows for the choice between two cost functions\ndifferent in structure: the former in the manner of a standard least-squares\napproach, which is typically used in practice, and the latter following a\ntime-discounted modification, resulting in better theoretical guarantees. In\naddition, we are able to feed back improved suboptimal estimates from the past\ninto the auxiliary observer through a re-initialization strategy. We apply the\nproposed suboptimal estimator to a set of batch chemical reactions and, after\nnumerically verifying the theoretical assumptions, show that even a few\niterations of the optimizer are sufficient to significantly improve the\nestimation results of the auxiliary observer.",
    "descriptor": "",
    "authors": [
      "Julian D. Schiller",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13750"
  },
  {
    "id": "arXiv:2108.13751",
    "title": "A Search Engine for Discovery of Biomedical Challenges and Directions",
    "abstract": "The ability to keep track of scientific challenges, advances and emerging\ndirections is a fundamental part of research. However, researchers face a flood\nof papers that hinders discovery of important knowledge. In biomedicine, this\ndirectly impacts human lives. To address this problem, we present a novel task\nof extraction and search of scientific challenges and directions, to facilitate\nrapid knowledge discovery. We construct and release an expert-annotated corpus\nof texts sampled from full-length papers, labeled with novel semantic\ncategories that generalize across many types of challenges and directions. We\nfocus on a large corpus of interdisciplinary work relating to the COVID-19\npandemic, ranging from biomedicine to areas such as AI and economics. We apply\na model trained on our data to identify challenges and directions across the\ncorpus and build a dedicated search engine for this information. In studies\nwith researchers, including those working directly on COVID-19, we outperform a\npopular scientific search engine in assisting knowledge discovery. Finally, we\nshow that models trained on our resource generalize to the wider biomedical\ndomain, highlighting its broad utility. We make our data, model and search\nengine publicly available. https://challenges.apps.allenai.org",
    "descriptor": "",
    "authors": [
      "Dan Lahav",
      "Jon Saad Falcon",
      "Bailey Kuehl",
      "Sophie Johnson",
      "Sravanthi Parasa",
      "Noam Shomron",
      "Duen Horng Chau",
      "Diyi Yang",
      "Eric Horvitz",
      "Daniel S. Weld",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.13751"
  },
  {
    "id": "arXiv:2108.13757",
    "title": "Automatic labelling of urban point clouds using data fusion",
    "abstract": "In this paper we describe an approach to semi-automatically create a labelled\ndataset for semantic segmentation of urban street-level point clouds. We use\ndata fusion techniques using public data sources such as elevation data and\nlarge-scale topographical maps to automatically label parts of the point cloud,\nafter which only limited human effort is needed to check the results and make\namendments where needed. This drastically limits the time needed to create a\nlabelled dataset that is extensive enough to train deep semantic segmentation\nmodels. We apply our method to point clouds of the Amsterdam region, and\nsuccessfully train a RandLA-Net semantic segmentation model on the labelled\ndataset. These results demonstrate the potential of smart data fusion and\nsemantic segmentation for the future of smart city planning and management.",
    "descriptor": "\nComments: 5 pages, 5 figures; code for this paper is available at this https URL\n",
    "authors": [
      "Daan Bloembergen",
      "Chris Eijgenstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13757"
  },
  {
    "id": "arXiv:2108.13759",
    "title": "Enjoy the Salience: Towards Better Transformer-based Faithful  Explanations with Word Salience",
    "abstract": "Pretrained transformer-based models such as BERT have demonstrated\nstate-of-the-art predictive performance when adapted into a range of natural\nlanguage processing tasks. An open problem is how to improve the faithfulness\nof explanations (rationales) for the predictions of these models. In this\npaper, we hypothesize that salient information extracted a priori from the\ntraining data can complement the task-specific information learned by the model\nduring fine-tuning on a downstream task. In this way, we aim to help BERT not\nto forget assigning importance to informative input tokens when making\npredictions by proposing SaLoss; an auxiliary loss function for guiding the\nmulti-head attention mechanism during training to be close to salient\ninformation extracted a priori using TextRank. Experiments for explanation\nfaithfulness across five datasets, show that models trained with SaLoss\nconsistently provide more faithful explanations across four different feature\nattribution methods compared to vanilla BERT. Using the rationales extracted\nfrom vanilla BERT and SaLoss models to train inherently faithful classifiers,\nwe further show that the latter result in higher predictive performance in\ndownstream tasks.",
    "descriptor": "\nComments: EMNLP 2021 Pre-print\n",
    "authors": [
      "George Chrysostomou",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13759"
  },
  {
    "id": "arXiv:2108.13760",
    "title": "A Hierarchical Stitching Algorithm for Coded Compressed Sensing",
    "abstract": "Recently, a novel coded compressed sensing (CCS) approach was proposed in [1]\nfor dealing with the scalability problem for large sensing matrices in massive\nmachine-type communications. The approach is to divide the compressed sensing\n(CS) problem into smaller CS sub-problems. However, such an approach requires\nstitching the results from the sub-problems to recover the result in the\noriginal CS problem. For this stitching problem, we propose a hierarchical\nstitching algorithm that is easier to implement in hardware for parallelization\nthan the tree coding algorithm in [1]. For our algorithm, we also derive an\nupper bound on the probability of recovery errors.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Yi-Jheng Lin",
      "Chia-Ming Chang",
      "Cheng-Shang Chang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.13760"
  },
  {
    "id": "arXiv:2108.13765",
    "title": "Triple-Structured Compressive Sensing-based Channel Estimation for  RIS-aided MU-MIMO Systems",
    "abstract": "Reconfigurable intelligent surface (RIS) has been recognized as a potential\ntechnology for 5G beyond and attracted tremendous research attention. However,\nchannel estimation in RIS-aided system is still a critical challenge due to the\nexcessive amount of parameters in cascaded channel. The existing compressive\nsensing (CS)-based RIS estimation schemes only adopt incomplete sparsity, which\ninduces redundant pilot consumption. In this paper, we exploit the specific\ntriple-structured sparsity of the cascaded channel, i.e., the common column\nsparsity, structured row sparsity after offset compensation and the common\noffsets among all users. Then a novel multi-user joint estimation algorithm is\nproposed. Simulation results show that our approach can significantly reduce\npilot overhead in both ULA and UPA scenarios.",
    "descriptor": "\nComments: accepted and to appear, Globecom2021\n",
    "authors": [
      "Xu Shi",
      "Jintao Wang",
      "Guozhi Chen",
      "Jian Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.13765"
  },
  {
    "id": "arXiv:2108.13766",
    "title": "The five Is: Key principles for interpretable and safe conversational AI",
    "abstract": "In this position paper, we present five key principles, namely\ninterpretability, inherent capability to explain, independent data, interactive\nlearning, and inquisitiveness, for the development of conversational AI that,\nunlike the currently popular black box approaches, is transparent and\naccountable. At present, there is a growing concern with the use of black box\nstatistical language models: While displaying impressive average performance,\nsuch systems are also prone to occasional spectacular failures, for which there\nis no clear remedy. In an effort to initiate a discussion on possible\nalternatives, we outline and exemplify how our five principles enable the\ndevelopment of conversational AI systems that are transparent and thus safer\nfor use. We also present some of the challenges inherent in the implementation\nof those principles.",
    "descriptor": "\nComments: 6 pages, one figure\n",
    "authors": [
      "Mattias Wahde",
      "Marco Virgolin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13766"
  },
  {
    "id": "arXiv:2108.13767",
    "title": "Stochastic Discontinuous Galerkin Methods for Robust Deterministic  Control of Convection Diffusion Equations with Uncertain Coefficients",
    "abstract": "We investigate a numerical behaviour of robust deterministic optimal control\nproblem governed by a convection diffusion equation with random coefficients by\napproximating statistical moments of the solution. Stochastic Galerkin\napproach, turning the original stochastic problem into a system of\ndeterministic problems, is used to handle the stochastic domain, whereas a\ndiscontinuous Galerkin method is used to discretize the spatial domain due to\nits better convergence behaviour for convection dominated optimal control\nproblems. A priori error estimates are derived for the state and adjoint in the\nenergy norm and for the deterministic control in $L^2$-norm. To handle the\ncurse of dimensionality of the stochastic Galerkin method, we take advantage of\nthe low-rank variant of GMRES method, which reduces both the storage\nrequirements and the computational complexity by exploiting a Kronecker-product\nstructure of the system matrices. The efficiency of the proposed methodology is\nillustrated by numerical experiments on the benchmark problems with and without\ncontrol constraints.",
    "descriptor": "\nComments: 49 pages, 8 figures, 6 tables. arXiv admin note: text overlap with arXiv:2011.02443\n",
    "authors": [
      "Pelin \u00c7ilo\u011flu",
      "Hamdullah Y\u00fccel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.13767"
  },
  {
    "id": "arXiv:2108.13770",
    "title": "Open-stub based spurious harmonic suppression method for Microstrip  Coupled Line Filter",
    "abstract": "In this paper, first, we review a straightforward analytical technique based\non image impedance concept for designing traditional microwave microstrip\ncoupled line filters using distributed elements. In the introduced approach, we\ncharacterize a quarter-wave coupled line section, and then these discrete\nsections can be connected in series to synthesis the final desired frequency\nresponse. Next, we use a novel open-stub based technique to suppress spurious\nharmonic frequencies. Finally, using proposed technique, we design and simulate\na band pass filter (BPF). The simulation results prove the usefulness of the\nproposed technique.",
    "descriptor": "\nComments: 5 pages, 8 figures\n",
    "authors": [
      "Mohammad Hossein Koohi Ghamsari",
      "Erfan Azizkhani",
      "Javad Ghalibafan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13770"
  },
  {
    "id": "arXiv:2108.13772",
    "title": "Artificial Intelligence Algorithms for Natural Language Processing and  the Semantic Web Ontology Learning",
    "abstract": "Evolutionary clustering algorithms have considered as the most popular and\nwidely used evolutionary algorithms for minimising optimisation and practical\nproblems in nearly all fields. In this thesis, a new evolutionary clustering\nalgorithm star (ECA*) is proposed. Additionally, a number of experiments were\nconducted to evaluate ECA* against five state-of-the-art approaches. For this,\n32 heterogeneous and multi-featured datasets were used to examine their\nperformance using internal and external clustering measures, and to measure the\nsensitivity of their performance towards dataset features in the form of\noperational framework. The results indicate that ECA* overcomes its competitive\ntechniques in terms of the ability to find the right clusters. Based on its\nsuperior performance, exploiting and adapting ECA* on the ontology learning had\na vital possibility. In the process of deriving concept hierarchies from\ncorpora, generating formal context may lead to a time-consuming process.\nTherefore, formal context size reduction results in removing uninterested and\nerroneous pairs, taking less time to extract the concept lattice and concept\nhierarchies accordingly. In this premise, this work aims to propose a framework\nto reduce the ambiguity of the formal context of the existing framework using\nan adaptive version of ECA*. In turn, an experiment was conducted by applying\n385 sample corpora from Wikipedia on the two frameworks to examine the\nreduction of formal context size, which leads to yield concept lattice and\nconcept hierarchy. The resulting lattice of formal context was evaluated to the\noriginal one using concept lattice-invariants. Accordingly, the homomorphic\nbetween the two lattices preserves the quality of resulting concept hierarchies\nby 89% in contrast to the basic ones, and the reduced concept lattice inherits\nthe structural relation of the original one.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1911.13011, arXiv:2102.08361\n",
    "authors": [
      "Bryar A. Hassan",
      "Tarik A. Rashid"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13772"
  },
  {
    "id": "arXiv:2108.13775",
    "title": "Discriminative Semantic Feature Pyramid Network with Guided Anchoring  for Logo Detection",
    "abstract": "Recently, logo detection has received more and more attention for its wide\napplications in the multimedia field, such as intellectual property protection,\nproduct brand management, and logo duration monitoring. Unlike general object\ndetection, logo detection is a challenging task, especially for small logo\nobjects and large aspect ratio logo objects in the real-world scenario. In this\npaper, we propose a novel approach, named Discriminative Semantic Feature\nPyramid Network with Guided Anchoring (DSFP-GA), which can address these\nchallenges via aggregating the semantic information and generating different\naspect ratio anchor boxes. More specifically, our approach mainly consists of\nDiscriminative Semantic Feature Pyramid (DSFP) and Guided Anchoring (GA).\nConsidering that low-level feature maps that are used to detect small logo\nobjects lack semantic information, we propose the DSFP, which can enrich more\ndiscriminative semantic features of low-level feature maps and can achieve\nbetter performance on small logo objects. Furthermore, preset anchor boxes are\nless efficient for detecting large aspect ratio logo objects. We therefore\nintegrate the GA into our method to generate large aspect ratio anchor boxes to\nmitigate this issue. Extensive experimental results on four benchmarks\ndemonstrate the effectiveness of our proposed DSFP-GA. Moreover, we further\nconduct visual analysis and ablation studies to illustrate the advantage of our\nmethod in detecting small and large aspect logo objects. The code and models\ncan be found at https://github.com/Zhangbaisong/DSFP-GA.",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Baisong Zhang",
      "Weiqing Min",
      "Jing Wang",
      "Sujuan Hou",
      "Qiang Hou",
      "Yuanjie Zheng",
      "Shuqiang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13775"
  },
  {
    "id": "arXiv:2108.13780",
    "title": "Stiffened gas approximation and GRP resolution for fluid flows of real  materials",
    "abstract": "The equation of state (EOS) embodies thermodynamic properties of compressible\nfluid materials and usually has very complicated forms in real engineering\napplications, subject to the physical requirements of thermodynamics. The\ncomplexity of EOS in form gives rise to the difficulty in analyzing relevant\nwave patterns. Concerning the design of numerical algorithms, the complex EOS\ncauses the inefficiency of Riemann solvers and even the loss of robustness,\nwhich hampers the development of Godunov-type numerical schemes.\nIn this paper, a strategy of local stiffened gas approximation is proposed\nfor real materials. The stiffened gas EOS is used to approximate general EOS\nlocally at each interface of computational control volumes so that the Riemann\nsolver can be significantly simplified. In the meantime, the generalized\nRiemann problem (GRP) solver is adopted not only for high resolution purpose\nbut effective reflection of the local thermodynamics as well. The resulting\nscheme is demonstrated to be efficient and robust and numerical examples\ndisplay the excellent performance of such an approximation.",
    "descriptor": "",
    "authors": [
      "Yue Wang",
      "Jiequan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.13780"
  },
  {
    "id": "arXiv:2108.13782",
    "title": "Robust Symbol-Level Precoding and Passive Beamforming for IRS-Aided  Communications",
    "abstract": "This paper investigates a joint beamforming design in a multiuser\nmultiple-input single-output (MISO) communication network aided with an\nintelligent reflecting surface (IRS) panel. The symbol-level precoding (SLP) is\nadopted to enhance the system performance by exploiting the multiuser\ninterference (MUI) with consideration of bounded channel uncertainty. The joint\nbeamforming design is formulated into a nonconvex worst-case robust programming\nto minimize the transmit power subject to single-to-noise ratio (SNR)\nrequirements. To address the challenges due to the constant modulus and the\ncoupling of the beamformers, we first study the single-user case. Specifically,\nwe propose and compare two algorithms based on the semidefinite relaxation\n(SDR) and alternating optimization (AO) methods, respectively. It turns out\nthat the AO-based algorithm has much lower computational complexity but with\nalmost the same power to the SDR-based algorithm. Then, we apply the AO\ntechnique to the multiuser case and thereby develop an algorithm based on the\nproximal gradient descent (PGD) method. The algorithm can be generalized to the\ncase of finite-resolution IRS and the scenario with direct links from the\ntransmitter to the users. Numerical results show that the SLP can significantly\nimprove the system performance. Meanwhile, 3-bit phase shifters can achieve\nnear-optimal power performance.",
    "descriptor": "",
    "authors": [
      "Guangyang Zhang",
      "Chao Shen",
      "Bo Ai",
      "Zhangdui Zhong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.13782"
  },
  {
    "id": "arXiv:2108.13783",
    "title": "Synbit: Synthesizing Bidirectional Programs using Unidirectional  Sketches",
    "abstract": "We propose a technique for synthesizing bidirectional programs from the\ncorresponding unidirectional code plus a few input/output examples. The core\nideas are: (1) constructing a sketch using the given unidirectional program as\na specification, and (2) filling the sketch in a modular fashion by exploiting\nthe properties of bidirectional programs. These ideas are enabled by our choice\nof programming language, HOBiT, which is specifically designed to maintain the\nunidirectional program structure in bidirectional programming, and keep the\nparts that control bidirectional behavior modular. To evaluate our approach, we\nimplemented it in a tool called Synbit and used it to generate bidirectional\nprograms for intricate microbenchmarks, as well as for a few larger, more\nrealistic problems. We also compared Synbit to a state-of-the-art\nunidirectional synthesis tool on the task of synthesizing backward\ncomputations.",
    "descriptor": "\nComments: Full version of a paper submitted to OOPSLA 2021\n",
    "authors": [
      "Masaomi Yamaguchi",
      "Kazutaka Matsuda",
      "Cristina David",
      "Meng Wang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.13783"
  },
  {
    "id": "arXiv:2108.13785",
    "title": "DLPFS: The Data Leakage Prevention FileSystem",
    "abstract": "Shared folders are still a common practice for granting third parties access\nto data files, regardless of the advances in data sharing technologies.\nServices like Google Drive, Dropbox, Box, and others, provide infrastructures\nand interfaces to manage file sharing. The human factor is the weakest link and\ndata leaks caused by human error are regrettable common news. This takes place\nas both mishandled data, for example stored to the wrong directory, or via\nmisconfigured or failing applications dumping data incorrectly. We present Data\nLeakage Prevention FileSystem (DLPFS), a first attempt to systematically\nprotect against data leakage caused by misconfigured application or human\nerror. This filesystem interface provides a privacy protection layer on top of\nthe POSIX filesystem interface, allowing for seamless integration with existing\ninfrastructures and applications, simply augmenting existing security controls.\nAt the same time, DLPFS allows data administrators to protect files shared\nwithin an organisation by preventing unauthorised parties to access potentially\nsensitive content. DLPFS achieves this by transparently integrating with\nexisting access control mechanisms. We empirically evaluate the impact of DLPFS\non system's performances to demonstrate the feasibility of the proposed\nsolution.",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Stefano Braghin",
      "Marco Simioni",
      "Mathieu Sinn"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.13785"
  },
  {
    "id": "arXiv:2108.13790",
    "title": "Decentralized Robust Interval Type-2 Fuzzy Model Predictive Control for  Takagi-Sugeno Large-Scale Systems",
    "abstract": "In this manuscript, decentralized robust interval type-2 fuzzy model\npredictive control for Takagi-Sugeno large-scale systems is studied. The\nmentioned large-scale system consists a number of interval type-2 (IT2) fuzzy\nTakagi-Sugeno (T-S) subsystems. An important matter and necessities that limit\nthe practical application of model predictive control are the online\ncomputational cost and burden of the existence frameworks. For model predictive\ncontrol of T-S fuzzy large-scale systems, the online computational burden is\neven worse and in some cases, they cannot be solved in an expected time.\nEspecially for severe large-scale systems with disturbances, existing model\npredictive control of T-S fuzzy large-scale systems usually leads to a very\nconservative solution. So, researchers have many challenges and difficulties in\nfinding a reasonable solution in a short time. Although, more relaxed results\ncan be achieved by the proposed fuzzy model predictive control approach which\nadopts T-S large-scale systems with nonlinear subsystems, many restrictions are\nnot considered in these approaches. In this paper, challenges are solved and\nthe MPC is designed for a nonlinear IT2 fuzzy large-scale system with\nuncertainties and disturbances. Besides, online optimization problem is solved\nand results are proposed. Consequently, online computational cost of the\noptimization problem is reduced considerably. At the end, by two practical\nexamples, the effectiveness of the proposed algorithm is illustrated.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.11186\n",
    "authors": [
      "Mohammad Sarbaz",
      "Iman Zamani",
      "Mohammad Manthouri",
      "Asier Ibeas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13790"
  },
  {
    "id": "arXiv:2108.13796",
    "title": "Addressing the IEEE AV Test Challenge with Scenic and VerifAI",
    "abstract": "This paper summarizes our formal approach to testing autonomous vehicles\n(AVs) in simulation for the IEEE AV Test Challenge. We demonstrate a systematic\ntesting framework leveraging our previous work on formally-driven simulation\nfor intelligent cyber-physical systems. First, to model and generate\ninteractive scenarios involving multiple agents, we used Scenic, a\nprobabilistic programming language for specifying scenarios. A Scenic program\ndefines an abstract scenario as a distribution over configurations of physical\nobjects and their behaviors over time. Sampling from an abstract scenario\nyields many different concrete scenarios which can be run as test cases for the\nAV. Starting from a Scenic program encoding an abstract driving scenario, we\ncan use the VerifAI toolkit to search within the scenario for failure cases\nwith respect to multiple AV evaluation metrics. We demonstrate the\neffectiveness of our testing framework by identifying concrete failure\nscenarios for an open-source autopilot, Apollo, starting from a variety of\nrealistic traffic scenarios.",
    "descriptor": "\nComments: Accepted to the IEEE AITest Conference 2021\n",
    "authors": [
      "Kesav Viswanadha",
      "Francis Indaheng",
      "Justin Wong",
      "Edward Kim",
      "Ellen Kalvan",
      "Yash Pant",
      "Daniel J. Fremont",
      "Sanjit A. Seshia"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13796"
  },
  {
    "id": "arXiv:2108.13797",
    "title": "Sample Efficient Detection and Classification of Adversarial Attacks via  Self-Supervised Embeddings",
    "abstract": "Adversarial robustness of deep models is pivotal in ensuring safe deployment\nin real world settings, but most modern defenses have narrow scope and\nexpensive costs. In this paper, we propose a self-supervised method to detect\nadversarial attacks and classify them to their respective threat models, based\non a linear model operating on the embeddings from a pre-trained\nself-supervised encoder. We use a SimCLR encoder in our experiments, since we\nshow the SimCLR embedding distance is a good proxy for human perceptibility,\nenabling it to encapsulate many threat models at once. We call our method\nSimCat since it uses SimCLR encoder to catch and categorize various types of\nadversarial attacks, including L_p and non-L_p evasion attacks, as well as data\npoisonings. The simple nature of a linear classifier makes our method efficient\nin both time and sample complexity. For example, on SVHN, using only five pairs\nof clean and adversarial examples computed with a PGD-L_inf attack, SimCat's\ndetection accuracy is over 85%. Moreover, on ImageNet, using only 25 examples\nfrom each threat model, SimCat can classify eight different attack types such\nas PGD-L_2, PGD-L_inf, CW-L_2, PPGD, LPA, StAdv, ReColor, and JPEG-L_inf, with\nover 40% accuracy. On STL10 data, we apply SimCat as a defense against\npoisoning attacks, such as BP, CP, FC, CLBD, HTBD, halving the success rate\nwhile using only twenty total poisons for training. We find that the detectors\ngeneralize well to unseen threat models. Lastly, we investigate the performance\nof our detection method under adaptive attacks and further boost its robustness\nagainst such attacks via adversarial training.",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Mazda Moayeri",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13797"
  },
  {
    "id": "arXiv:2108.13799",
    "title": "A Novel Robust Extended Dissipativity State Feedback Control system  design for Interval Type-2 Fuzzy Takagi-Sugeno Large-Scale Systems",
    "abstract": "In this paper, we use the advantage of large-scale systems modeling based on\nthe type-2 fuzzy Takagi-Sugeno model to cover the uncertainties caused by\nlarge-scale systems modeling. The advantage of using membership function\ninformation is the reduction of conservatism resulting from stability analysis.\nAlso, this paper uses the extended dissipativity robust control performance\nindex to reduce the effect of external perturbations on the large-scale system,\nwhich is a generalization of H, L, passive, and dissipativity performance\nindexes and control gains can be achieved through solving linear matrix\ninequalities (LMIs), so the whole closed-loop fuzzy large-scale system is\nasymptotically stable.. Finally, the effectiveness of the proposed method is\ndemonstrated by a numerical example of a double inverted pendulum system.",
    "descriptor": "",
    "authors": [
      "Mojtaba Asadi Jokar",
      "Iman Zamani",
      "Mohamad Manthouri",
      "Mohammad Sarbaz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13799"
  },
  {
    "id": "arXiv:2108.13800",
    "title": "Network psychometrics and cognitive network science open new ways for  detecting, understanding and tackling the complexity of math anxiety: A  review",
    "abstract": "Math anxiety is a clinical pathology impairing cognitive processing in\nmath-related contexts. Originally thought to affect only inexperienced,\nlow-achieving students, recent investigations show how math anxiety is vastly\ndiffused even among high-performing learners. This review of data-informed\nstudies outlines math anxiety as a complex system that: (i) cripples\nwell-being, self-confidence and information processing on both conscious and\nsubconscious levels, (ii) can be transmitted by social interactions, like a\npathogen, and worsened by distorted perceptions, (iii) affects roughly 20% of\nstudents in 63 out of 64 worldwide educational systems but correlates weakly\nwith academic performance, and (iv) poses a concrete threat to students'\nwell-being, computational literacy and career prospects in science. These\npatterns underline the crucial need to go beyond performance for estimating\nmath anxiety. Recent advances with network psychometrics and cognitive network\nscience provide ideal frameworks for detecting, interpreting and intervening\nupon such clinical condition. Merging education research, psychology and data\nscience, the approaches reviewed here reconstruct psychological constructs as\ncomplex systems, represented either as multivariate correlation models (e.g.\ngraph exploratory analysis) or as cognitive networks of semantic/emotional\nassociations (e.g. free association networks or forma mentis networks). Not\nonly can these interconnected networks detect otherwise hidden levels of math\nanxiety but - more crucially - they can unveil the specific layout of\ninteracting factors, e.g. key sources and targets, behind math anxiety in a\ngiven cohort. As discussed here, these network approaches open concrete ways\nfor unveiling students' perceptions, emotions and mental well-being, and can\nenable future powerful data-informed interventions untangling math anxiety.",
    "descriptor": "",
    "authors": [
      "Massimo Stella"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "History and Overview (math.HO)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.13800"
  },
  {
    "id": "arXiv:2108.13801",
    "title": "Optimal Latency-Oriented Scheduling in Parallel Queuing Systems",
    "abstract": "Today, more and more interactive applications, such as augmented/virtual\nreality, haptic Internet, and Industrial Internet of Things, require\ncommunication services with guaranteed end-to-end latency limits, which are\ndifficult to provide over shared communication networks, particularly in the\npresence of wireless links. Robustness against disturbances affecting\nindividual links can be obtained by coding the information flow in multiple\nstreams to be forwarded across parallel transmission links. This approach,\nhowever, requires coding and scheduling algorithms that can adapt to the state\nof links to take full advantage of path diversity and avoid self-induced\ncongestion on some links. To gain some fundamental insights on this challenging\nproblem, in this paper we resort to Markov Decision Process (MDP) theory and\nabstract the parallel paths as independent queuing systems, whose arrival\nprocesses are managed by a common controller that determines the amount of\nredundancy to be applied to the source messages and the number of (coded)\npackets to be sent to each queue. The objective is to find the joint coding and\nscheduling policy that maximizes a certain utility function, e.g., the fraction\nof source blocks delivered to the destination within a predetermined deadline,\ndespite the variability of the individual connections. We find the optimal\nredundancy and scheduling strategies by using policy iteration methods. We then\nanalyze the optimal policy in a series of scenarios, highlighting its most\nimportant aspects and analyzing ways to improve existing heuristics from the\nliterature.",
    "descriptor": "\nComments: 30 pages, 13 figures. Submitted to IEEE Transactions on Communications\n",
    "authors": [
      "Andrea Bedin",
      "Federico Chiariotti",
      "Stepan Kucera",
      "Andrea Zanella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.13801"
  },
  {
    "id": "arXiv:2108.13802",
    "title": "Curatio et Innovatio",
    "abstract": "The Middle Ages focused obsessively on the old; our era is totally absorbed\nwith the new. In medio stat virtus. In this short note, I advocate a strategy\nthat blends copyright and copyleft for disseminating research results in the\nsciences. I argue that such a blend may be beneficial in fields such as\nmathematics and computer science, that it may facilitate the evolution and\nemergence of improved problem descriptions, whilst at the same time preserving\nauthor's rights, and easing researchers' work.",
    "descriptor": "\nComments: 10 pages, working draft\n",
    "authors": [
      "Roberto Rossi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2108.13802"
  },
  {
    "id": "arXiv:2108.13803",
    "title": "Manipulation of Camera Sensor Data via Fault Injection for Anomaly  Detection Studies in Verification and Validation Activities For AI",
    "abstract": "In this study, the creation of a database consisting of images obtained as a\nresult of deformation in the images recorded by these cameras by injecting\nerrors into the robot camera nodes and the alternative uses of this database\nare explained. The study is based on an existing camera fault injection\nsoftware that injects faults into the cameras of the ROKOS robot arms while the\nsystem is running and collects the normal and faulty images recorded during\nthis injection. The database obtained in the study is a source for detecting\nanomalies that may occur in robotic systems. The ROKOS system has been\ndeveloped on the inspection of the parts in a bus body-in-white with the help\nof the cameras on the ROKOS robot arms, right and left. The simulation-based\nrobot verification testing tool (SRVT) system is a system that has emerged by\nsimulating these robots and the chassis in the Gazebo environment, performing\nand implementing the trajectory planning with the MoveIt planner, and\nintegrating the ROS Smach structure and mission communication. This system is\nbeing developed within the scope of the VALU3S project to create a V&V system\nin the robotics field. Within the scope of this study, a database of 10000\nimages was created, consisting of 5000 normal and 5000 faulty images. Faulty\npictures were obtained by injecting seven different image fault types,\nincluding erosion, dilusion, opening, closing, gradient, motion-blur and\npartial loss, at different times when the robot was in operation. This database\nconsists of images taken by the ROKOS system from the vehicle during a bus\nchassis inspection mission.",
    "descriptor": "\nComments: 12 pages, 16 figures, Provided by Inovasyon Muhendislik\n",
    "authors": [
      "Alim Kerem Erdogmus",
      "Assist. Prof. Dr. Ugur Yayan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13803"
  },
  {
    "id": "arXiv:2108.13807",
    "title": "Identifying Ransomware Actors in the Bitcoin Network",
    "abstract": "Due to the pseudo-anonymity of the Bitcoin network, users can hide behind\ntheir bitcoin addresses that can be generated in unlimited quantity, on the\nfly, without any formal links between them. Thus, it is being used for payment\ntransfer by the actors involved in ransomware and other illegal activities. The\nother activity we consider is related to gambling since gambling is often used\nfor transferring illegal funds. The question addressed here is that given\ntemporally limited graphs of Bitcoin transactions, to what extent can one\nidentify common patterns associated with these fraudulent activities and apply\nthem to find other ransomware actors. The problem is rather complex, given that\nthousands of addresses can belong to the same actor without any obvious links\nbetween them and any common pattern of behavior. The main contribution of this\npaper is to introduce and apply new algorithms for local clustering and\nsupervised graph machine learning for identifying malicious actors. We show\nthat very local subgraphs of the known such actors are sufficient to\ndifferentiate between ransomware, random and gambling actors with 85%\nprediction accuracy on the test data set.",
    "descriptor": "",
    "authors": [
      "Siddhartha Dalal",
      "Zihe Wang",
      "Siddhanth Sabharwal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13807"
  },
  {
    "id": "arXiv:2108.13808",
    "title": "On the formulation of fractional Adams-Bashforth method with  Atangana-Baleanu-Caputo derivative to model chaotic problems",
    "abstract": "Mathematical analysis with numerical application of the newly formulated\nfractional version of the Adams-Bashforth method using the Atangana-Baleanu\nderivative which has nonlocal and nonsingular properties is considered in this\npaper. We adopt the fixed point theory and approximation method to prove the\nexistence and uniqueness of the solution via general two-component\ntime-fractional differential equations. The method is tested with three\nnonlinear chaotic dynamical systems in which the integer-order derivative is\nmodeled with the proposed fractional-order case. Simulation result for\ndifferent $\\alpha$ values in $(0,1]$ is presented.",
    "descriptor": "\nComments: 11 figures, fractional Adams-Bashforth method and corrections\n",
    "authors": [
      "Kolade M. Owolabi",
      "Abdon Atangana"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.13808"
  },
  {
    "id": "arXiv:2108.13810",
    "title": "Max-Utility Based Arm Selection Strategy For Sequential Query  Recommendations",
    "abstract": "We consider the query recommendation problem in closed loop interactive\nlearning settings like online information gathering and exploratory analytics.\nThe problem can be naturally modelled using the Multi-Armed Bandits (MAB)\nframework with countably many arms. The standard MAB algorithms for countably\nmany arms begin with selecting a random set of candidate arms and then applying\nstandard MAB algorithms, e.g., UCB, on this candidate set downstream. We show\nthat such a selection strategy often results in higher cumulative regret and to\nthis end, we propose a selection strategy based on the maximum utility of the\narms. We show that in tasks like online information gathering, where sequential\nquery recommendations are employed, the sequences of queries are correlated and\nthe number of potentially optimal queries can be reduced to a manageable size\nby selecting queries with maximum utility with respect to the currently\nexecuting query. Our experimental results using a recent real online literature\ndiscovery service log file demonstrate that the proposed arm selection strategy\nimproves the cumulative regret substantially with respect to the\nstate-of-the-art baseline algorithms. % and commonly used random selection\nstrategy for a variety of contextual multi-armed bandit algorithms. Our data\nmodel and source code are available at\n~\\url{https://anonymous.4open.science/r/0e5ad6b7-ac02-4577-9212-c9d505d3dbdb/}.",
    "descriptor": "",
    "authors": [
      "Shameem A. Puthiya Parambath",
      "Christos Anagnostopoulos",
      "Roderick Murray-Smith",
      "Sean MacAvaney",
      "Evangelos Zervas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13810"
  },
  {
    "id": "arXiv:2108.13811",
    "title": "TREND: Trigger-Enhanced Relation-Extraction Network for Dialogues",
    "abstract": "The goal of dialogue relation extraction (DRE) is to identify the relation\nbetween two entities in a given dialogue. During conversations, speakers may\nexpose their relations to certain entities by some clues, such evidences called\n\"triggers\". However, none of the existing work on DRE tried to detect triggers\nand leverage the information for enhancing the performance. This paper proposes\nTREND, a multi-tasking BERT-based model which learns to identify triggers for\nimproving relation extraction. The experimental results show that the proposed\nmethod achieves the state-of-the-art on the benchmark datasets.",
    "descriptor": "\nComments: The first two authors contributed to this work equally\n",
    "authors": [
      "Po-Wei Lin",
      "Shang-Yu Su",
      "Yun-Nung Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13811"
  },
  {
    "id": "arXiv:2108.13817",
    "title": "Unsupervised Open-Domain Question Answering",
    "abstract": "Open-domain Question Answering (ODQA) has achieved significant results in\nterms of supervised learning manner. However, data annotation cannot also be\nirresistible for its huge demand in an open domain. Though unsupervised QA or\nunsupervised Machine Reading Comprehension (MRC) has been tried more or less,\nunsupervised ODQA has not been touched according to our best knowledge. This\npaper thus pioneers the work of unsupervised ODQA by formally introducing the\ntask and proposing a series of key data construction methods. Our exploration\nin this work inspiringly shows unsupervised ODQA can reach up to 86%\nperformance of supervised ones.",
    "descriptor": "",
    "authors": [
      "Pengfei Zhu",
      "Xiaoguang Li",
      "Jian Li",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13817"
  },
  {
    "id": "arXiv:2108.13818",
    "title": "Cats vs. Spectre: An Axiomatic Approach to Modeling Speculative  Execution Attacks",
    "abstract": "The Spectre family of speculative execution attacks have required a\nrethinking of formal methods for security. Approaches based on operational\nspeculative semantics have made initial inroads towards finding vulnerable code\nand validating defenses. However, with each new attack grows the amount of\nmicroarchitectural detail that has to be integrated into the underlying\nsemantics. We propose an alternative, light-weight and axiomatic approach to\nspecifying speculative semantics that relies on insights from memory models for\nconcurrency. We use the CAT modeling language for memory consistency to specify\nexecution models that capture speculative control flow, store-to-load\nforwarding, predictive store forwarding, and memory ordering machine clears. We\npresent a bounded model checking framework parametrized by our speculative CAT\nmodels and evaluate its implementation against the state of the art. Due to the\naxiomatic approach, our models can be rapidly extended to allow our framework\nto detect new types of attacks and validate defenses against them.",
    "descriptor": "",
    "authors": [
      "Hern\u00e1n Ponce-de-Le\u00f3n",
      "Johannes Kinder"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.13818"
  },
  {
    "id": "arXiv:2108.13821",
    "title": "GeodesicEmbedding (GE): A High-Dimensional Embedding Approach for Fast  Geodesic Distance Queries",
    "abstract": "In this paper, we develop a novel method for fast geodesic distance queries.\nThe key idea is to embed the mesh into a high-dimensional space, such that the\nEuclidean distance in the high-dimensional space can induce the geodesic\ndistance in the original manifold surface. However, directly solving the\nhigh-dimensional embedding problem is not feasible due to the large number of\nvariables and the fact that the embedding problem is highly nonlinear. We\novercome the challenges with two novel ideas. First, instead of taking all\nvertices as variables, we embed only the saddle vertices, which greatly reduces\nthe problem complexity. We then compute a local embedding for each non-saddle\nvertex. Second, to reduce the large approximation error resulting from the\npurely Euclidean embedding, we propose a cascaded optimization approach that\nrepeatedly introduces additional embedding coordinates with a non-Euclidean\nfunction to reduce the approximation residual. Using the precomputation data,\nour approach can determine the geodesic distance between any two vertices in\nnear-constant time. Computational testing results show that our method is more\ndesirable than previous geodesic distance queries methods.",
    "descriptor": "\nComments: Presented at Computational Visual Media 2021; to be published in IEEE Transactions on Visualization and Computer Graphics\n",
    "authors": [
      "Qianwei Xia",
      "Juyong Zhang",
      "Zheng Fang",
      "Jin Li",
      "Mingyue Zhang",
      "Bailin Deng",
      "Ying He"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2108.13821"
  },
  {
    "id": "arXiv:2108.13822",
    "title": "Chi-square Loss for Softmax: an Echo of Neural Network Structure",
    "abstract": "Softmax working with cross-entropy is widely used in classification, which\nevaluates the similarity between two discrete distribution columns (predictions\nand true labels). Inspired by chi-square test, we designed a new loss function\ncalled chi-square loss, which is also works for Softmax. Chi-square loss has a\nstatistical background. We proved that it is unbiased in optimization, and\nclarified its using conditions (its formula determines that it must work with\nlabel smoothing). In addition, we studied the sample distribution of this loss\nfunction by visualization and found that the distribution is related to the\nneural network structure, which is distinct compared to cross-entropy. In the\npast, the influence of structure was often ignored when visualizing. Chi-square\nloss can notice changes in neural network structure because it is very strict,\nand we explained the reason for this strictness. We also studied the influence\nof label smoothing and discussed the relationship between label smoothing and\ntraining accuracy and stability. Since the chi-square loss is very strict, the\nperformance will degrade when dealing samples of very many classes.",
    "descriptor": "",
    "authors": [
      "Zeyu Wang",
      "Meiqing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13822"
  },
  {
    "id": "arXiv:2108.13824",
    "title": "Aligning Hotel Embeddings using Domain Adaptation for Next-Item  Recommendation",
    "abstract": "In online platforms it is often the case to have multiple brands under the\nsame group which may target different customer profiles, or have different\ndomains. For example, in the hospitality domain, Expedia Group has multiple\nbrands like Brand Expedia, Hotels.com and Wotif which have either different\ntraveler profiles or are more relevant in a local context.\nIn this context, learning embeddings for hotels that can be leveraged in\nrecommendation tasks in multiple brands requires to have a common embedding\nthat can be induced using alignment approaches. In the same time, one needs to\nensure that this common embedding space does not degrade the performance in any\nof the brands.\nIn this work we build upon the hotel2vec model and propose a simple\nregularization approach for aligning hotel embeddings of different brands via\ndomain adaptation. We also explore alignment methods previously used in\ncross-lingual embeddings to align spaces of different languages. We present\nresults on the task of next-hotel prediction using click sessions from two\nbrands. The results show that the proposed approach can align the two embedding\nspaces while achieving good performance in both brands. Additionally, with\nrespect to single-brand training we show that the proposed approach can\nsignificantly reduce training time and improve the predictive performance.",
    "descriptor": "\nComments: ACM SIGIR Workshop on eCommerce, July 15, 2021, Virtual Event, Montreal, Canada\n",
    "authors": [
      "Ioannis Partalas"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13824"
  },
  {
    "id": "arXiv:2108.13826",
    "title": "Self-Calibrating Neural Radiance Fields",
    "abstract": "In this work, we propose a camera self-calibration algorithm for generic\ncameras with arbitrary non-linear distortions. We jointly learn the geometry of\nthe scene and the accurate camera parameters without any calibration objects.\nOur camera model consists of a pinhole model, a fourth order radial distortion,\nand a generic noise model that can learn arbitrary non-linear camera\ndistortions. While traditional self-calibration algorithms mostly rely on\ngeometric constraints, we additionally incorporate photometric consistency.\nThis requires learning the geometry of the scene, and we use Neural Radiance\nFields (NeRF). We also propose a new geometric loss function, viz., projected\nray distance loss, to incorporate geometric consistency for complex non-linear\ncamera models. We validate our approach on standard real image datasets and\ndemonstrate that our model can learn the camera intrinsics and extrinsics\n(pose) from scratch without COLMAP initialization. Also, we show that learning\naccurate camera models in a differentiable manner allows us to improve PSNR\nover baselines. Our module is an easy-to-use plugin that can be applied to NeRF\nvariants to improve performance. The code and data are currently available at\nhttps://github.com/POSTECH-CVLab/SCNeRF",
    "descriptor": "\nComments: Accepted in ICCV21\n",
    "authors": [
      "Yoonwoo Jeong",
      "Seokjun Ahn",
      "Christopher Choy",
      "Animashree Anandkumar",
      "Minsu Cho",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13826"
  },
  {
    "id": "arXiv:2108.13828",
    "title": "PACE: Posthoc Architecture-Agnostic Concept Extractor for Explaining  CNNs",
    "abstract": "Deep CNNs, though have achieved the state of the art performance in image\nclassification tasks, remain a black-box to a human using them. There is a\ngrowing interest in explaining the working of these deep models to improve\ntheir trustworthiness. In this paper, we introduce a Posthoc\nArchitecture-agnostic Concept Extractor (PACE) that automatically extracts\nsmaller sub-regions of the image called concepts relevant to the black-box\nprediction. PACE tightly integrates the faithfulness of the explanatory\nframework to the black-box model. To the best of our knowledge, this is the\nfirst work that extracts class-specific discriminative concepts in a posthoc\nmanner automatically. The PACE framework is used to generate explanations for\ntwo different CNN architectures trained for classifying the AWA2 and\nImagenet-Birds datasets. Extensive human subject experiments are conducted to\nvalidate the human interpretability and consistency of the explanations\nextracted by PACE. The results from these experiments suggest that over 72% of\nthe concepts extracted by PACE are human interpretable.",
    "descriptor": "\nComments: Accepted at International Joint Conference on Neural Networks (IJCNN 2021)\n",
    "authors": [
      "Vidhya Kamakshi",
      "Uday Gupta",
      "Narayanan C Krishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13828"
  },
  {
    "id": "arXiv:2108.13831",
    "title": "Deep Learning of Transferable MIMO Channel Modes for 6G V2X  Communications",
    "abstract": "In the emerging high mobility Vehicle-to-Everything (V2X) communications\nusing millimeter Wave (mmWave) and sub-THz, Multiple-Input Multiple-Output\n(MIMO) channel estimation is an extremely challenging task. At mmWaves/sub-THz\nfrequencies, MIMO channels exhibit few leading paths in the space-time domain\n(i.e., directions or arrival/departure and delays). Algebraic Low-rank (LR)\nchannel estimation exploits space-time channel sparsity through the computation\nof position-dependent MIMO channel eigenmodes leveraging recurrent training\nvehicle passages in the coverage cell. LR requires vehicles' geographical\npositions and tens to hundreds of training vehicles' passages for each\nposition, leading to significant complexity and control signalling overhead.\nHere we design a DL-based LR channel estimation method to infer MIMO channel\neigenmodes in V2X urban settings, starting from a single LS channel estimate\nand without needing vehicle's position information. Numerical results show that\nthe proposed method attains comparable Mean Squared Error (MSE) performance as\nthe position-based LR. Moreover, we show that the proposed model can be trained\non a reference scenario and be effectively transferred to urban contexts with\ndifferent space-time channel features, providing comparable MSE performance\nwithout an explicit transfer learning procedure. This result eases the\ndeployment in arbitrary dense urban scenarios.",
    "descriptor": "",
    "authors": [
      "Lorenzo Cazzella",
      "Dario Tagliaferri",
      "Marouan Mizmizi",
      "Damiano Badini",
      "Christian Mazzucco",
      "Matteo Matteucci",
      "Umberto Spagnolini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.13831"
  },
  {
    "id": "arXiv:2108.13836",
    "title": "Explainable AI for engineering design: A unified approach of systems  engineering and component-based deep learning",
    "abstract": "Data-driven models created by machine learning gain in importance in all\nfields of design and engineering. They have high potential to assists\ndecision-makers in creating novel artefacts with a better performance and\nsustainability. However, limited generalization and the black-box nature of\nthese models induce limited explainability and reusability. These drawbacks\nprovide significant barriers retarding adoption in engineering design. To\novercome this situation, we propose a component-based approach to create\npartial component models by machine learning (ML). This component-based\napproach aligns deep learning to systems engineering (SE). By means of the\nexample of energy efficient building design, we first demonstrate\ngeneralization of the component-based method by accurately predicting the\nperformance of designs with random structure different from training data.\nSecond, we illustrate explainability by local sampling, sensitivity information\nand rules derived from low-depth decision trees and by evaluating this\ninformation from an engineering design perspective. The key for explainability\nis that activations at interfaces between the components are interpretable\nengineering quantities. In this way, the hierarchical component system forms a\ndeep neural network (DNN) that directly integrates information for engineering\nexplainability. The large range of possible configurations in composing\ncomponents allows the examination of novel unseen design cases with\nunderstandable data-driven models. The matching of parameter ranges of\ncomponents by similar probability distribution produces reusable,\nwell-generalizing, and trustworthy models. The approach adapts the model\nstructure to engineering methods of systems engineering and domain knowledge.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Philipp Geyer",
      "Manav Mahan Singh",
      "Xia Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13836"
  },
  {
    "id": "arXiv:2108.13837",
    "title": "Towards a Common Testing Terminology for Software Engineering and  Artificial Intelligence Experts",
    "abstract": "Analytical quality assurance, especially testing, is an integral part of\nsoftware-intensive system development. With the increased usage of Artificial\nIntelligence (AI) and Machine Learning (ML) as part of such systems, this\nbecomes more difficult as well-understood software testing approaches cannot be\napplied directly to the AI-enabled parts of the system. The required adaptation\nof classical testing approaches and development of new concepts for AI would\nbenefit from a deeper understanding and exchange between AI and software\nengineering experts. A major obstacle on this way, we see in the different\nterminologies used in the two communities. As we consider a mutual\nunderstanding of the testing terminology as a key, this paper contributes a\nmapping between the most important concepts from classical software testing and\nAI testing. In the mapping, we highlight differences in relevance and naming of\nthe mapped concepts.",
    "descriptor": "\nComments: Submitted, currently under review\n",
    "authors": [
      "Lisa J\u00f6ckel",
      "Thomas Bauer",
      "Michael Kl\u00e4s",
      "Marc P. Hauer",
      "Janek Gro\u00df"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13837"
  },
  {
    "id": "arXiv:2108.13838",
    "title": "The Interaction Flow Editor: A New Human-Robot Interaction  RapidPrototyping Interface",
    "abstract": "Human-robot interaction can be regarded as a flow between users and robots.\nDesigning good interaction flows takes a lot of effort and needs to be field\ntested. Unfortunately, the interaction flow design process is often very\ndisjointed, with users experiencing prototypes, designers forming those\nprototypes, and developers implementing them as independent processes. In this\npaper, we present the Interaction Flow Editor (IFE), a new human-robot\ninteraction prototyping tool that enables everyday users to create and modify\ntheir own interactions, while still providing a full suite of features that is\npowerful enough for developers and designers to create complex interactions. We\nalso discuss the Flow Engine, a flexible and adaptable framework for executing\nrobot interaction flows authors through the IFE. Finally, we present our case\nstudy results that demonstrates how older adults, aged 70 and above, can design\nand iterate interactions in real-time on a robot using the IFE.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Matthew Huggins",
      "Anastasia K. Ostrowski",
      "Andrew Rapo",
      "Eric Woudenberg",
      "Cynthia Breazeal",
      "Hae Won Park"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13838"
  },
  {
    "id": "arXiv:2108.13843",
    "title": "Self-Supervised Learning Based Domain Adaptation for Robust Speaker  Verification",
    "abstract": "Large performance degradation is often observed for speaker ver-ification\nsystems when applied to a new domain dataset. Givenan unlabeled target-domain\ndataset, unsupervised domain adaptation(UDA) methods, which usually leverage\nadversarial training strate-gies, are commonly used to bridge the performance\ngap caused bythe domain mismatch. However, such adversarial training\nstrategyonly uses the distribution information of target domain data and cannot\nensure the performance improvement on the target domain. Inthis paper, we\nincorporate self-supervised learning strategy to the un-supervised domain\nadaptation system and proposed a self-supervisedlearning based domain\nadaptation approach (SSDA). Compared tothe traditional UDA method, the new SSDA\ntraining strategy canfully leverage the potential label information from target\ndomainand adapt the speaker discrimination ability from source\ndomainsimultaneously. We evaluated the proposed approach on the Vox-Celeb\n(labeled source domain) and CnCeleb (unlabeled target do-main) datasets, and\nthe best SSDA system obtains 10.2% Equal ErrorRate (EER) on the CnCeleb dataset\nwithout using any speaker labelson CnCeleb, which also can achieve the\nstate-of-the-art results onthis corpus.",
    "descriptor": "\nComments: Published in: ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n",
    "authors": [
      "Zhengyang Chen",
      "Shuai Wang",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2108.13843"
  },
  {
    "id": "arXiv:2108.13854",
    "title": "Contrastive Domain Adaptation for Question Answering using Limited Text  Corpora",
    "abstract": "Question generation has recently shown impressive results in customizing\nquestion answering (QA) systems to new domains. These approaches circumvent the\nneed for manually annotated training data from the new domain and, instead,\ngenerate synthetic question-answer pairs that are used for training. However,\nexisting methods for question generation rely on large amounts of synthetically\ngenerated datasets and costly computational resources, which render these\ntechniques widely inaccessible when the text corpora is of limited size. This\nis problematic as many niche domains rely on small text corpora, which\nnaturally restricts the amount of synthetic data that can be generated. In this\npaper, we propose a novel framework for domain adaptation called contrastive\ndomain adaptation for QA (CAQA). Specifically, CAQA combines techniques from\nquestion generation and domain-invariant learning to answer out-of-domain\nquestions in settings with limited text corpora. Here, we train a QA system on\nboth source data and generated data from the target domain with a contrastive\nadaptation loss that is incorporated in the training objective. By combining\ntechniques from question generation and domain-invariant learning, our model\nachieved considerable improvements compared to state-of-the-art baselines.",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Zhenrui Yue",
      "Bernhard Kratzwald",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13854"
  },
  {
    "id": "arXiv:2108.13855",
    "title": "Successful Recovery Performance Guarantees of Noisy SOMP",
    "abstract": "The simultaneous orthogonal matching pursuit (SOMP) is a popular, greedy\napproach for common support recovery of a row-sparse matrix. The support\nrecovery guarantee of SOMP has been extensively studied under the noiseless\nscenario. Compared to the noiseless scenario, the performance analysis of noisy\nSOMP is still nascent, in which only the restricted isometry property\n(RIP)-based analysis has been studied. In this paper, we present the mutual\nincoherence property (MIP)-based study for performance analysis of noisy SOMP.\nSpecifically, when noise is bounded, we provide the condition on which the\nexact support recovery is guaranteed in terms of the MIP. When noise is\nunbounded, we instead derive a bound on the successful recovery probability\n(SRP) that depends on the specific distribution of noise. Then we focus on the\ncommon case when noise is random Gaussian and show that the lower bound of SRP\nfollows Tracy-Widom law distribution. The analysis reveals the number of\nmeasurements, noise level, the number of sparse vectors, and the value of MIP\nconstant that are required to guarantee a predefined recovery performance.\nTheoretically, we show that the MIP constant of the measurement matrix must\nincrease proportional to the noise standard deviation, and the number of sparse\nvectors needs to grow proportional to the noise variance. Finally, we\nextensively validate the derived analysis through numerical simulations.",
    "descriptor": "",
    "authors": [
      "Wei Zhang",
      "Taejoon Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.13855"
  },
  {
    "id": "arXiv:2108.13858",
    "title": "GRP-FED: Addressing Client Imbalance in Federated Learning via  Global-Regularized Personalization",
    "abstract": "Since data is presented long-tailed in reality, it is challenging for\nFederated Learning (FL) to train across decentralized clients as practical\napplications. We present Global-Regularized Personalization (GRP-FED) to tackle\nthe data imbalanced issue by considering a single global model and multiple\nlocal models for each client. With adaptive aggregation, the global model\ntreats multiple clients fairly and mitigates the global long-tailed issue. Each\nlocal model is learned from the local data and aligns with its distribution for\ncustomization. To prevent the local model from just overfitting, GRP-FED\napplies an adversarial discriminator to regularize between the learned\nglobal-local features. Extensive results show that our GRP-FED improves under\nboth global and local scenarios on real-world MIT-BIH and synthesis CIFAR-10\ndatasets, achieving comparable performance and addressing client imbalance.",
    "descriptor": "\nComments: (FL-ICML'21) International Workshop on Federated Learning for User Privacy and Data Confidentiality in Conjunction with ICML 2021\n",
    "authors": [
      "Yen-Hsiu Chou",
      "Shenda Hong",
      "Chenxi Sun",
      "Derun Cai",
      "Moxian Song",
      "Hongyan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13858"
  },
  {
    "id": "arXiv:2108.13861",
    "title": "An Artificial Intelligence Life Cycle: From Conception to Production",
    "abstract": "Drawing on our experience of more than a decade of AI in academic research,\ntechnology development, industry engagement, postgraduate teaching, doctoral\nsupervision and organisational consultancy, we present the 'CDAC AI Life\nCycle', a comprehensive life cycle for the design, development and deployment\nof Artificial Intelligence (AI) systems and solutions. It consists of three\nphases, Design, Develop and Deploy, and 17 constituent stages across the three\nphases from conception to production of any AI initiative. The 'Design' phase\nhighlights the importance of contextualising a problem description by reviewing\npublic domain and service-based literature on state-of-the-art AI applications,\nalgorithms, pre-trained models and equally importantly ethics guidelines and\nframeworks, which then informs the data, or Big Data, acquisition and\npreparation. The 'Develop' phase is technique-oriented, as it transforms data\nand algorithms into AI models that are benchmarked, evaluated and explained.\nThe 'Deploy' phase evaluates computational performance, which then apprises\npipelines for model operationalisation, culminating in the hyperautomation of a\nprocess or system as a complete AI solution, that is continuously monitored and\nevaluated to inform the next iteration of the life cycle. An ontological\nmapping of AI algorithms to applications, followed by an organisational context\nfor the AI life cycle are further contributions of this article.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Daswin De Silva",
      "Damminda Alahakoon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.13861"
  },
  {
    "id": "arXiv:2108.13863",
    "title": "On computing derivatives of transfer operators and linear responses in  higher dimensions",
    "abstract": "We show that the derivative of the transfer operator with respect to\nperturbations of the map is a divergence. We show that, in high dimensions,\napproximating singular measures by isotropic finite-elements, and computing the\nderivative operator on such approximate measures, are both expensive. We show\nthe equivalence between the operator and ensemble version of the linear\nresponse formula, and discuss how to combine both formula, as done by the fast\nlinear response algorithm, to reduce cost.",
    "descriptor": "\nComments: 13 pages, no figure. Comments are welcome!\n",
    "authors": [
      "Angxiu Ni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.13863"
  },
  {
    "id": "arXiv:2108.13865",
    "title": "InSeGAN: A Generative Approach to Segmenting Identical Instances in  Depth Images",
    "abstract": "In this paper, we present InSeGAN, an unsupervised 3D generative adversarial\nnetwork (GAN) for segmenting (nearly) identical instances of rigid objects in\ndepth images. Using an analysis-by-synthesis approach, we design a novel GAN\narchitecture to synthesize a multiple-instance depth image with independent\ncontrol over each instance. InSeGAN takes in a set of code vectors (e.g.,\nrandom noise vectors), each encoding the 3D pose of an object that is\nrepresented by a learned implicit object template. The generator has two\ndistinct modules. The first module, the instance feature generator, uses each\nencoded pose to transform the implicit template into a feature map\nrepresentation of each object instance. The second module, the depth image\nrenderer, aggregates all of the single-instance feature maps output by the\nfirst module and generates a multiple-instance depth image. A discriminator\ndistinguishes the generated multiple-instance depth images from the\ndistribution of true depth images. To use our model for instance segmentation,\nwe propose an instance pose encoder that learns to take in a generated depth\nimage and reproduce the pose code vectors for all of the object instances. To\nevaluate our approach, we introduce a new synthetic dataset, \"Insta-10\",\nconsisting of 100,000 depth images, each with 5 instances of an object from one\nof 10 classes. Our experiments on Insta-10, as well as on real-world noisy\ndepth images, show that InSeGAN achieves state-of-the-art performance, often\noutperforming prior methods by large margins.",
    "descriptor": "\nComments: Accepted at ICCV 2021\n",
    "authors": [
      "Anoop Cherian",
      "Goncalo Dias Pais",
      "Siddarth Jain",
      "Tim K. Marks",
      "Alan Sullivan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13865"
  },
  {
    "id": "arXiv:2108.13871",
    "title": "Building Time-Triggered Schedules for typed-DAG Tasks with alternative  implementations",
    "abstract": "Hard real-time systems like image processing, autonomous driving, etc.\nrequire an increasing need of computational power that classical multi-core\nplatforms can not provide, to fulfill with their timing constraints.\nHeterogeneous Instruction Set Architecture (ISA) platforms allow accelerating\nreal-time workloads on application-specific cores (e.g. GPU, DSP, ASICs) etc.\nand are suitable for these applications. In addition, these platforms provide\nlarger design choices as a given functionnality can be implemented onto several\ntypes of compute elements. HPC-DAG (Heterogeneous Parallel Directed Acyclic\nGraph) task model has been recently proposed to capture real-time workload\nexecution on heterogeneous platforms. It expresses the ISA heterogeneity, and\nsome specific characteristics of hardware accelerators, as the absence of\npreemption or costly preemption, alternative implementations and on-line\nconditional execution. In this paper, we propose a time-table scheduling\napproach to allocate and schedule a set of HPC-DAG tasks onto a set of\nheterogeneous cores, by the mean Integer Linear Programming (ILP). Our design\nallows to handle heterogeniety of resources, on-line execution costs, and a\nfaster solving time, by exploring gradually the design space",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1901.02450\n",
    "authors": [
      "Houssam-Eddine Zahaf",
      "Nicola Capodieci"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13871"
  },
  {
    "id": "arXiv:2108.13872",
    "title": "Reinforcement Learning Based Sparse Black-box Adversarial Attack on  Video Recognition Models",
    "abstract": "We explore the black-box adversarial attack on video recognition models.\nAttacks are only performed on selected key regions and key frames to reduce the\nhigh computation cost of searching adversarial perturbations on a video due to\nits high dimensionality. To select key frames, one way is to use heuristic\nalgorithms to evaluate the importance of each frame and choose the essential\nones. However, it is time inefficient on sorting and searching. In order to\nspeed up the attack process, we propose a reinforcement learning based frame\nselection strategy. Specifically, the agent explores the difference between the\noriginal class and the target class of videos to make selection decisions. It\nreceives rewards from threat models which indicate the quality of the\ndecisions. Besides, we also use saliency detection to select key regions and\nonly estimate the sign of gradient instead of the gradient itself in zeroth\norder optimization to further boost the attack process. We can use the trained\nmodel directly in the untargeted attack or with little fine-tune in the\ntargeted attack, which saves computation time. A range of empirical results on\nreal datasets demonstrate the effectiveness and efficiency of the proposed\nmethod.",
    "descriptor": "\nComments: Accepted as a conference paper of IJCAI-21 (the 30th International Joint Conference on Artificial Intelligence)\n",
    "authors": [
      "Zeyuan Wang",
      "Chaofeng Sha",
      "Su Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13872"
  },
  {
    "id": "arXiv:2108.13873",
    "title": "Beyond Model Extraction: Imitation Attack for Black-Box NLP APIs",
    "abstract": "Machine-learning-as-a-service (MLaaS) has attracted millions of users to\ntheir outperforming sophisticated models. Although published as black-box APIs,\nthe valuable models behind these services are still vulnerable to imitation\nattacks. Recently, a series of works have demonstrated that attackers manage to\nsteal or extract the victim models. Nonetheless, none of the previous stolen\nmodels can outperform the original black-box APIs. In this work, we take the\nfirst step of showing that attackers could potentially surpass victims via\nunsupervised domain adaptation and multi-victim ensemble. Extensive experiments\non benchmark datasets and real-world APIs validate that the imitators can\nsucceed in outperforming the original black-box models. We consider this as a\nmilestone in the research of imitation attack, especially on NLP APIs, as the\nsuperior performance could influence the defense or even publishing strategy of\nAPI providers.",
    "descriptor": "",
    "authors": [
      "Qiongkai Xu",
      "Xuanli He",
      "Lingjuan Lyu",
      "Lizhen Qu",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13873"
  },
  {
    "id": "arXiv:2108.13875",
    "title": "When Retriever-Reader Meets Scenario-Based Multiple-Choice Questions",
    "abstract": "Scenario-based question answering (SQA) requires retrieving and reading\nparagraphs from a large corpus to answer a question which is contextualized by\na long scenario description. Since a scenario contains both keyphrases for\nretrieval and much noise, retrieval for SQA is extremely difficult. Moreover,\nit can hardly be supervised due to the lack of relevance labels of paragraphs\nfor SQA. To meet the challenge, in this paper we propose a joint\nretriever-reader model called JEEVES where the retriever is implicitly\nsupervised only using QA labels via a novel word weighting mechanism. JEEVES\nsignificantly outperforms a variety of strong baselines on multiple-choice\nquestions in three SQA datasets.",
    "descriptor": "\nComments: 10 pages, accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Zixian Huang",
      "Ao Wu",
      "Yulin Shen",
      "Gong Cheng",
      "Yuzhong Qu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.13875"
  },
  {
    "id": "arXiv:2108.13876",
    "title": "One-shot domain adaptation for semantic face editing of real world  images using StyleALAE",
    "abstract": "Semantic face editing of real world facial images is an important application\nof generative models. Recently, multiple works have explored possible\ntechniques to generate such modifications using the latent structure of\npre-trained GAN models. However, such approaches often require training an\nencoder network and that is typically a time-consuming and resource intensive\nprocess. A possible alternative to such a GAN-based architecture can be\nstyleALAE, a latent-space based autoencoder that can generate photo-realistic\nimages of high quality. Unfortunately, the reconstructed image in styleALAE\ndoes not preserve the identity of the input facial image. This limits the\napplication of styleALAE for semantic face editing of images with known\nidentities. In our work, we use a recent advancement in one-shot domain\nadaptation to address this problem. Our work ensures that the identity of the\nreconstructed image is the same as the given input image. We further generate\nsemantic modifications over the reconstructed image by using the latent space\nof the pre-trained styleALAE model. Results show that our approach can generate\nsemantic modifications on any real world facial image while preserving the\nidentity.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Ravi Kiran Reddy",
      "Kumar Shubham",
      "Gopalakrishnan Venkatesh",
      "Sriram Gandikota",
      "Sarthak Khoche",
      "Dinesh Babu Jayagopi",
      "Gopalakrishnan Srinivasaraghavan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13876"
  },
  {
    "id": "arXiv:2108.13880",
    "title": "Using a one dimensional parabolic model of the full-batch loss to  estimate learning rates during training",
    "abstract": "A fundamental challenge in Deep Learning is to find optimal step sizes for\nstochastic gradient descent. In traditional optimization, line searches are a\ncommonly used method to determine step sizes. One problem in Deep Learning is\nthat finding appropriate step sizes on the full-batch loss is unfeasible\nexpensive. Therefore, classical line search approaches, designed for losses\nwithout inherent noise, are usually not applicable. Recent empirical findings\nsuggest that the full-batch loss behaves locally parabolically in the direction\nof noisy update step directions. Furthermore, the trend of the optimal update\nstep size is changing slowly. By exploiting these findings, this work\nintroduces a line-search method that approximates the full-batch loss with a\nparabola estimated over several mini-batches. Learning rates are derived from\nsuch parabolas during training. In the experiments conducted, our approach\nmostly outperforms SGD tuned with a piece-wise constant learning rate schedule\nand other line search approaches for Deep Learning across models, datasets, and\nbatch sizes on validation and test accuracy.",
    "descriptor": "",
    "authors": [
      "Maximus Mutschler",
      "Andreas Zell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13880"
  },
  {
    "id": "arXiv:2108.13886",
    "title": "Structure-Aware Hard Negative Mining for Heterogeneous Graph Contrastive  Learning",
    "abstract": "Recently, heterogeneous Graph Neural Networks (GNNs) have become a de facto\nmodel for analyzing HGs, while most of them rely on a relative large number of\nlabeled data. In this work, we investigate Contrastive Learning (CL), a key\ncomponent in self-supervised approaches, on HGs to alleviate the label scarcity\nproblem. We first generate multiple semantic views according to metapaths and\nnetwork schemas. Then, by pushing node embeddings corresponding to different\nsemantic views close to each other (positives) and pulling other embeddings\napart (negatives), one can obtain informative representations without human\nannotations. However, this CL approach ignores the relative hardness of\nnegative samples, which may lead to suboptimal performance. Considering the\ncomplex graph structure and the smoothing nature of GNNs, we propose a\nstructure-aware hard negative mining scheme that measures hardness by\nstructural characteristics for HGs. By synthesizing more negative nodes, we\ngive larger weights to harder negatives with limited computational overhead to\nfurther boost the performance. Empirical studies on three real-world datasets\nshow the effectiveness of our proposed method. The proposed method consistently\noutperforms existing state-of-the-art methods and notably, even surpasses\nseveral supervised counterparts.",
    "descriptor": "\nComments: KDD Workshop on Deep Learning on Graphs: Method and Applications (DLG@KDD 2021)\n",
    "authors": [
      "Yanqiao Zhu",
      "Yichen Xu",
      "Hejie Cui",
      "Carl Yang",
      "Qiang Liu",
      "Shu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.13886"
  },
  {
    "id": "arXiv:2108.13888",
    "title": "Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning",
    "abstract": "\\textbf{P}re-\\textbf{T}rained \\textbf{M}odel\\textbf{s} have been widely\napplied and recently proved vulnerable under backdoor attacks: the released\npre-trained weights can be maliciously poisoned with certain triggers. When the\ntriggers are activated, even the fine-tuned model will predict pre-defined\nlabels, causing a security threat. These backdoors generated by the poisoning\nmethods can be erased by changing hyper-parameters during fine-tuning or\ndetected by finding the triggers. In this paper, we propose a stronger\nweight-poisoning attack method that introduces a layerwise weight poisoning\nstrategy to plant deeper backdoors; we also introduce a combinatorial trigger\nthat cannot be easily detected. The experiments on text classification tasks\nshow that previous defense methods cannot resist our weight-poisoning method,\nwhich indicates that our method can be widely applied and may provide hints for\nfuture model robustness studies.",
    "descriptor": "\nComments: Accepted by EMNLP2021 main conference\n",
    "authors": [
      "Linyang Li",
      "Demin Song",
      "Xiaonan Li",
      "Jiehang Zeng",
      "Ruotian Ma",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13888"
  },
  {
    "id": "arXiv:2108.13889",
    "title": "Robotic Lime Picking by Considering Leaves as Permeable Obstacles",
    "abstract": "The problem of robotic lime picking is challenging; lime plants have dense\nfoliage which makes it difficult for a robotic arm to grasp a lime without\ncoming in contact with leaves. Existing approaches either do not consider\nleaves, or treat them as obstacles and completely avoid them, often resulting\nin undesirable or infeasible plans. We focus on reaching a lime in the presence\nof dense foliage by considering the leaves of a plant as 'permeable obstacles'\nwith a collision cost. We then adapt the rapidly exploring random tree star\n(RRT*) algorithm for the problem of fruit harvesting by incorporating the cost\nof collision with leaves into the path cost. To reduce the time required for\nfinding low-cost paths to goal, we bias the growth of the tree using an\nartificial potential field (APF). We compare our proposed method with prior\nwork in a 2-D environment and a 6-DOF robot simulation. Our experiments and a\nreal-world demonstration on a robotic lime picking task demonstrate the\napplicability of our approach.",
    "descriptor": "\nComments: 7 pages, 6 figures, Conference: 2021 International Conference on Intelligent Robots and Systems, Supplementary video: this https URL\n",
    "authors": [
      "Heramb Nemlekar",
      "Ziang Liu",
      "Suraj Kothawade",
      "Sherdil Niyaz",
      "Barath Raghavan",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13889"
  },
  {
    "id": "arXiv:2108.13892",
    "title": "Like Article, Like Audience: Enforcing Multimodal Correlations for  Disinformation Detection",
    "abstract": "User-generated content (e.g., tweets and profile descriptions) and shared\ncontent between users (e.g., news articles) reflect a user's online identity.\nThis paper investigates whether correlations between user-generated and\nuser-shared content can be leveraged for detecting disinformation in online\nnews articles. We develop a multimodal learning algorithm for disinformation\ndetection. The latent representations of news articles and user-generated\ncontent allow that during training the model is guided by the profile of users\nwho prefer content similar to the news article that is evaluated, and this\neffect is reinforced if that content is shared among different users. By only\nleveraging user information during model optimization, the model does not rely\non user profiling when predicting an article's veracity. The algorithm is\nsuccessfully applied to three widely used neural classifiers, and results are\nobtained on different datasets. Visualization techniques show that the proposed\nmodel learns feature representations of unseen news articles that better\ndiscriminate between fake and real news texts.",
    "descriptor": "",
    "authors": [
      "Liesbeth Allein",
      "Marie-Francine Moens",
      "Domenico Perrotta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.13892"
  },
  {
    "id": "arXiv:2108.13897",
    "title": "mMARCO: A Multilingual Version of MS MARCO Passage Ranking Dataset",
    "abstract": "The MS MARCO ranking dataset has been widely used for training deep learning\nmodels for IR tasks, achieving considerable effectiveness on diverse zero-shot\nscenarios. However, this type of resource is scarce in other languages than\nEnglish. In this work we present mMARCO, a multilingual version of the MS MARCO\npassage ranking dataset comprising 8 languages that was created using machine\ntranslation. We evaluated mMARCO by fine-tuning mono and multilingual\nre-ranking models on it. Experimental results demonstrate that multilingual\nmodels fine-tuned on our translated dataset achieve superior effectiveness than\nmodels fine-tuned on the original English version alone. Also, our distilled\nmultilingual re-ranker is competitive with non-distilled models while having\n5.4 times fewer parameters. The translated datasets as well as fine-tuned\nmodels are available at https://github.com/unicamp-dl/mMARCO.git.",
    "descriptor": "",
    "authors": [
      "Luiz Henrique Bonifacio",
      "Israel Campiotti",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13897"
  },
  {
    "id": "arXiv:2108.13898",
    "title": "The emojification of sentiment on social media: Collection and analysis  of a longitudinal Twitter sentiment dataset",
    "abstract": "Social media, as a means for computer-mediated communication, has been\nextensively used to study the sentiment expressed by users around events or\ntopics. There is however a gap in the longitudinal study of how sentiment\nevolved in social media over the years. To fill this gap, we develop TM-Senti,\na new large-scale, distantly supervised Twitter sentiment dataset with over 184\nmillion tweets and covering a time period of over seven years. We describe and\nassess our methodology to put together a large-scale, emoticon- and emoji-based\nlabelled sentiment analysis dataset, along with an analysis of the resulting\ndataset. Our analysis highlights interesting temporal changes, among others in\nthe increasing use of emojis over emoticons. We publicly release the dataset\nfor further research in tasks including sentiment analysis and text\nclassification of tweets. The dataset can be fully rehydrated including tweet\nmetadata and without missing tweets thanks to the archive of tweets publicly\navailable on the Internet Archive, which the dataset is based on.",
    "descriptor": "",
    "authors": [
      "Wenjie Yin",
      "Rabab Alkhalifa",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2108.13898"
  },
  {
    "id": "arXiv:2108.13902",
    "title": "Estimation of Air Pollution with Remote Sensing Data: Revealing  Greenhouse Gas Emissions from Space",
    "abstract": "Air pollution is a major driver of climate change. Anthropogenic emissions\nfrom the burning of fossil fuels for transportation and power generation emit\nlarge amounts of problematic air pollutants, including Greenhouse Gases (GHGs).\nDespite the importance of limiting GHG emissions to mitigate climate change,\ndetailed information about the spatial and temporal distribution of GHG and\nother air pollutants is difficult to obtain. Existing models for surface-level\nair pollution rely on extensive land-use datasets which are often locally\nrestricted and temporally static. This work proposes a deep learning approach\nfor the prediction of ambient air pollution that only relies on remote sensing\ndata that is globally available and frequently updated. Combining optical\nsatellite imagery with satellite-based atmospheric column density air pollution\nmeasurements enables the scaling of air pollution estimates (in this case\nNO$_2$) to high spatial resolution (up to $\\sim$10m) at arbitrary locations and\nadds a temporal component to these estimates. The proposed model performs with\nhigh accuracy when evaluated against air quality measurements from ground\nstations (mean absolute error $<$6$~\\mu g/m^3$). Our results enable the\nidentification and temporal monitoring of major sources of air pollution and\nGHGs.",
    "descriptor": "\nComments: for associated codebase, see this https URL\n",
    "authors": [
      "Linus Scheibenreif",
      "Michael Mommert",
      "Damian Borth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13902"
  },
  {
    "id": "arXiv:2108.13906",
    "title": "Spectral and Energy Efficiency of ACO-OFDM in Visible Light  Communication Systems",
    "abstract": "In this paper, we study the spectral efficiency (SE) and energy efficiency\n(EE) of asymmetrically clipped optical orthogonal frequency division\nmultiplexing (ACO-OFDM) for visible light communication (VLC). Firstly, we\nderive the achiev-able rates for Gaussian distributions inputs and practical\nfinite-alphabet inputs. Then, we investigate the SE maximization problems\nsubject to both the total transmit power constraint and the average optical\npower constraint with the above two inputs, respectively. By exploiting the\nrelationship between the mutual information and the minimum mean-squared error,\nan optimal power allocation scheme is proposed to maximize the SE with\nfinite-alphabet inputs. To reduce the computational complexity of the power\nallocation scheme, we derive a closed-form lower bound of the SE. Also,\nconsidering the quality of service, we further tackle the non-convex EE\nmaximization problems of ACO-OFDM with the two inputs, respectively. The\nproblems are solved by the proposed Dinkelbach-type iterative algorithm. In\neach iteration, the interior point algorithm is applied to obtain the optimal\npower allocation.The performance of the proposed power allocation schemes for\nthe SE and EE maximization are validated through numerical analysis.",
    "descriptor": "\nComments: 14 pages, 10 figures, accepted by IEEE Trans. Wireless Commun\n",
    "authors": [
      "Shuai Ma",
      "Ruixin Yang",
      "Xiong Deng",
      "Xintong Ling",
      "Xun Zhang",
      "Fuhui Zhou",
      "Shiyin Li",
      "Derrick Wing Kwan Ng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.13906"
  },
  {
    "id": "arXiv:2108.13909",
    "title": "More WiFi for Everyone: Increasing Spectral Efficiency in WiFi6 Networks  using OBSS/PD Mechanism",
    "abstract": "This study aims to enhance spatial reuse by using the new features of IEEE\n802.11ax WLANs. Since the wireless medium is a shared medium and there may be\nmultiple basic service sets (BSS) in the same vicinity, BSSs may overlap, and\ninterference occurs. In this situation, BSSs cannot transmit simultaneously due\nto the exposed node problem. The IEEE 802.11ax standard has a couple of\nmechanisms to resolve these spectral efficiency problems. One of the most\neffective mechanisms that address these problems is the overlapping BSS\npreamble detection (OBSS/PD) mechanism. OBSS/PD mechanism uses the color\nmechanism to distinguish OBSS signals. By using a signal threshold, the\nmechanism can ignore some of the signals, which cause interference. In this\npaper, we propose a rate-adaptive dynamic OBSS/PD threshold algorithm that\ntracks the changes in transmission rate and dynamically adjusts the threshold\nstep by step considering the changes.",
    "descriptor": "\nComments: 6 figures\n",
    "authors": [
      "Ali Karako\u00e7",
      "Mehmet \u015e\u00fckr\u00fc Kuran",
      "H. Birkan Yilmaz"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.13909"
  },
  {
    "id": "arXiv:2108.13910",
    "title": "A manifold learning perspective on representation learning: Learning  decoder and representations without an encoder",
    "abstract": "Autoencoders are commonly used in representation learning. They consist of an\nencoder and a decoder, which provide a straightforward way to map\n$n$-dimensional data in input space to a lower $m$-dimensional representation\nspace and back. The decoder itself defines an $m$-dimensional manifold in input\nspace. Inspired by manifold learning, we show that the decoder can be trained\non its own by learning the representations of the training samples along with\nthe decoder weights using gradient descent. A sum-of-squares loss then\ncorresponds to optimizing the manifold to have the smallest Euclidean distance\nto the training samples, and similarly for other loss functions. We derive\nexpressions for the number of samples needed to specify the encoder and decoder\nand show that the decoder generally requires much less training samples to be\nwell-specified compared to the encoder. We discuss training of autoencoders in\nthis perspective and relate to previous work in the field that use noisy\ntraining examples and other types of regularization. On the natural image data\nsets MNIST and CIFAR10, we demonstrate that the decoder is much better suited\nto learn a low-dimensional representation, especially when trained on small\ndata sets. Using simulated gene regulatory data, we further show that the\ndecoder alone leads to better generalization and meaningful representations.\nOur approach of training the decoder alone facilitates representation learning\neven on small data sets and can lead to improved training of autoencoders. We\nhope that the simple analyses presented will also contribute to an improved\nconceptual understanding of representation learning.",
    "descriptor": "",
    "authors": [
      "Viktoria Schuster",
      "Anders Krogh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13910"
  },
  {
    "id": "arXiv:2108.13912",
    "title": "Automatic digital twin data model generation of building energy systems  from piping and instrumentation diagrams",
    "abstract": "Buildings directly and indirectly emit a large share of current CO2\nemissions. There is a high potential for CO2 savings through modern control\nmethods in building automation systems (BAS) like model predictive control\n(MPC). For a proper control, MPC needs mathematical models to predict the\nfuture behavior of the controlled system. For this purpose, digital twins of\nthe building can be used. However, with current methods in existing buildings,\na digital twin set up is usually labor-intensive. Especially connecting the\ndifferent components of the technical system to an overall digital twin of the\nbuilding is time-consuming. Piping and instrument diagrams (P&ID) can provide\nthe needed information, but it is necessary to extract the information and\nprovide it in a standardized format to process it further.\nIn this work, we present an approach to recognize symbols and connections of\nP&ID from buildings in a completely automated way. There are various standards\nfor graphical representation of symbols in P&ID of building energy systems.\nTherefore, we use different data sources and standards to generate a holistic\ntraining data set. We apply algorithms for symbol recognition, line recognition\nand derivation of connections to the data sets. Furthermore, the result is\nexported to a format that provides semantics of building energy systems.\nThe symbol recognition, line recognition and connection recognition show good\nresults with an average precision of 93.7%, which can be used in further\nprocesses like control generation, (distributed) model predictive control or\nfault detection. Nevertheless, the approach needs further research.",
    "descriptor": "",
    "authors": [
      "Florian Stinner",
      "Martin Wiecek",
      "Marc Baranski",
      "Alexander K\u00fcmpel",
      "Dirk M\u00fcller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13912"
  },
  {
    "id": "arXiv:2108.13922",
    "title": "Stockade: Hardware Hardening for Distributed Trusted Sandboxes",
    "abstract": "The widening availability of hardware-based trusted execution environments\n(TEEs) has been accelerating the adaptation of new applications using TEEs.\nRecent studies showed that a cloud application consists of multiple distributed\nsoftware modules provided by mutually distrustful parties. The applications use\nmultiple TEEs (enclaves) communicating through software-encrypted memory\nchannels. Such execution model requires bi-directional protection: protecting\nthe rest of the system from the enclave module with sandboxing and protecting\nthe enclave module from a third-part module and operating systems. However, the\ncurrent TEE model, such as Intel SGX, cannot efficiently represent such\ndistributed sandbox applications. To overcome the lack of hardware supports for\nsandboxed TEEs, this paper proposes an extended enclave model called Stockade,\nwhich supports distributed sandboxes hardened by hardware. Stockade proposes\nnew three key techniques. First, it extends the hardware-based memory isolation\nin SGX to confine a user software module only within its enclave. Second, it\nproposes a trusted monitor enclave that filters and validates systems calls\nfrom enclaves. Finally, it allows hardware-protected memory sharing between a\npair of enclaves for efficient protected communication without software-based\nencryption. Using an emulated SGX platform with the proposed extensions, this\npaper shows that distributed sandbox applications can be effectively supported\nwith small changes of SGX hardware.",
    "descriptor": "",
    "authors": [
      "Joongun Park",
      "Seunghyo Kang",
      "Sanghyeon Lee",
      "Taehoon Kim",
      "Jongse Park",
      "Youngjin Kwon",
      "Jaehyuk Huh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2108.13922"
  },
  {
    "id": "arXiv:2108.13923",
    "title": "TrackerSift: Untangling Mixed Tracking and Functional Web Resources",
    "abstract": "Trackers typically circumvent filter lists used by privacy-enhancing content\nblocking tools by changing the domains or URLs of their resources. Filter list\nmaintainers painstakingly attempt to keep up in the ensuing arms race by\nfrequently updating the filter lists. Trackers have recently started to mix\ntracking and functional resources, putting content blockers in a bind: risk\nbreaking legitimate functionality if they act and risk missing privacy-invasive\nadvertising and tracking if they do not. In this paper, we conduct a\nlarge-scale measurement study of such mixed (i.e., both tracking and\nfunctional) resources on 100K websites. We propose TRACKERSIFT, an approach\nthat progressively classifies and untangles mixed web resources at multiple\ngranularities of analysis (domain, hostname, script, and method). Using\nTRACKERSIFT, we find that 83% of the domains can be separated as tracking or\nfunctional, and the remaining 17% (11.8K) domains are classified as mixed. For\nthe mixed domains, 52% of the hostnames can be separated, and the remaining 48%\n(12.3K) hostnames are classified as mixed. For the mixed hostnames, 94% of the\njavascript snippets can be separated, and the remaining 6%(21.1K) scripts are\nclassified as mixed. For the mixed scripts,91% of the JavaScript methods can be\nseparated, and the remaining 9% (5.5K) methods are classified as mixed.\nOverall, TRACKERSIFT is able to attribute 98% of all requests to tracking or\nfunctional resources at the finest level of granularity. Our analysis shows\nthat mixed resources at different granularities are typically served from CDNs\nor as inlined and bundled scripts. Our results highlight opportunities for\nfine-grained content blocking to remove mixed resources without breaking\nlegitimate functionality.",
    "descriptor": "",
    "authors": [
      "Abdul Haddi Amjad",
      "Danial Saleem",
      "Fareed Zaffar",
      "Muhammad Ali Gulzar",
      "Zubair Shafiq"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.13923"
  },
  {
    "id": "arXiv:2108.13927",
    "title": "Extremal Binary PFAs in a Cerny Family",
    "abstract": "The largest known reset thresholds for DFAs are equal to (n-1)^2, where n is\nthe number of states. This is conjectured to be the maximum possible. PFAs\n(with partial transition function) can have exponentially large reset\nthresholds. This is still true if we restrict to binary PFAs. However,\nasymptotics do not give conclusions for fixed n. We prove that the maximal\nreset threshold for binary PFAs is strictly greater than (n-1)^2 if and only if\nn > 5. These results are mostly based on the analysis of synchronizing word\nlengths for a certain family of binary PFAs. This family has the following\nproperties: it contains the well-known Cerny automata; for n < 11 it contains a\nbinary PFA with maximal possible reset threshold; for all n > 5 it contains a\nPFA with reset threshold larger than the maximum known for DFAs. Analysis of\nthis family reveals remarkable patterns involving the Fibonacci numbers and\nrelated sequences such as the Padovan sequence. We derive explicit formulas for\nthe reset thresholds in terms of these recurrent sequences. Furthermore, we\nprove that the family asymptotically still gives reset thresholds of polynomial\norder.",
    "descriptor": "\nComments: Extended version of a publication in the proceedings of DLT 2021\n",
    "authors": [
      "Stijn Cambie",
      "Michiel de Bondt",
      "Henk Don"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2108.13927"
  },
  {
    "id": "arXiv:2108.13930",
    "title": "EG-Booster: Explanation-Guided Booster of ML Evasion Attacks",
    "abstract": "The widespread usage of machine learning (ML) in a myriad of domains has\nraised questions about its trustworthiness in security-critical environments.\nPart of the quest for trustworthy ML is robustness evaluation of ML models to\ntest-time adversarial examples. Inline with the trustworthy ML goal, a useful\ninput to potentially aid robustness evaluation is feature-based explanations of\nmodel predictions. In this paper, we present a novel approach called EG-Booster\nthat leverages techniques from explainable ML to guide adversarial example\ncrafting for improved robustness evaluation of ML models before deploying them\nin security-critical settings. The key insight in EG-Booster is the use of\nfeature-based explanations of model predictions to guide adversarial example\ncrafting by adding consequential perturbations likely to result in model\nevasion and avoiding non-consequential ones unlikely to contribute to evasion.\nEG-Booster is agnostic to model architecture, threat model, and supports\ndiverse distance metrics used previously in the literature. We evaluate\nEG-Booster using image classification benchmark datasets, MNIST and CIFAR10.\nOur findings suggest that EG-Booster significantly improves evasion rate of\nstate-of-the-art attacks while performing less number of perturbations. Through\nextensive experiments that covers four white-box and three black-box attacks,\nwe demonstrate the effectiveness of EG-Booster against two undefended neural\nnetworks trained on MNIST and CIFAR10, and another adversarially-trained ResNet\nmodel trained on CIFAR10. Furthermore, we introduce a stability assessment\nmetric and evaluate the reliability of our explanation-based approach by\nobserving the similarity between the model's classification outputs across\nmultiple runs of EG-Booster.",
    "descriptor": "",
    "authors": [
      "Abderrahmen Amich",
      "Birhanu Eshete"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13930"
  },
  {
    "id": "arXiv:2108.13934",
    "title": "Robust Retrieval Augmented Generation for Zero-shot Slot Filling",
    "abstract": "Automatically inducing high quality knowledge graphs from a given collection\nof documents still remains a challenging problem in AI. One way to make headway\nfor this problem is through advancements in a related task known as slot\nfilling. In this task, given an entity query in form of [Entity, Slot, ?], a\nsystem is asked to fill the slot by generating or extracting the missing value\nexploiting evidence extracted from relevant passage(s) in the given document\ncollection. The recent works in the field try to solve this task in an\nend-to-end fashion using retrieval-based language models. In this paper, we\npresent a novel approach to zero-shot slot filling that extends dense passage\nretrieval with hard negatives and robust training procedures for retrieval\naugmented generation models. Our model reports large improvements on both T-REx\nand zsRE slot filling datasets, improving both passage retrieval and slot value\ngeneration, and ranking at the top-1 position in the KILT leaderboard.\nMoreover, we demonstrate the robustness of our system showing its domain\nadaptation capability on a new variant of the TACRED dataset for slot filling,\nthrough a combination of zero/few-shot learning. We release the source code and\npre-trained models.",
    "descriptor": "\nComments: Accepted at EMNLP 2021. arXiv admin note: substantial text overlap with arXiv:2104.08610\n",
    "authors": [
      "Michael Glass",
      "Gaetano Rossiello",
      "Md Faisal Mahbub Chowdhury",
      "Alfio Gliozzo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.13934"
  },
  {
    "id": "arXiv:2108.13939",
    "title": "ScatSimCLR: self-supervised contrastive learning with pretext task  regularization for small-scale datasets",
    "abstract": "In this paper, we consider a problem of self-supervised learning for\nsmall-scale datasets based on contrastive loss between multiple views of the\ndata, which demonstrates the state-of-the-art performance in classification\ntask. Despite the reported results, such factors as the complexity of training\nrequiring complex architectures, the needed number of views produced by data\naugmentation, and their impact on the classification accuracy are understudied\nproblems. To establish the role of these factors, we consider an architecture\nof contrastive loss system such as SimCLR, where baseline model is replaced by\ngeometrically invariant \"hand-crafted\" network ScatNet with small trainable\nadapter network and argue that the number of parameters of the whole system and\nthe number of views can be considerably reduced while practically preserving\nthe same classification accuracy. In addition, we investigate the impact of\nregularization strategies using pretext task learning based on an estimation of\nparameters of augmentation transform such as rotation and jigsaw permutation\nfor both traditional baseline models and ScatNet based models. Finally, we\ndemonstrate that the proposed architecture with pretext task learning\nregularization achieves the state-of-the-art classification performance with a\nsmaller number of trainable parameters and with reduced number of views.",
    "descriptor": "",
    "authors": [
      "Vitaliy Kinakh",
      "Olga Taran",
      "Svyatoslav Voloshynovskiy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13939"
  },
  {
    "id": "arXiv:2108.13941",
    "title": "Bubblewrap: Online tiling and real-time flow prediction on neural  manifolds",
    "abstract": "While most classic studies of function in experimental neuroscience have\nfocused on the coding properties of individual neurons, recent developments in\nrecording technologies have resulted in an increasing emphasis on the dynamics\nof neural populations. This has given rise to a wide variety of models for\nanalyzing population activity in relation to experimental variables, but direct\ntesting of many neural population hypotheses requires intervening in the system\nbased on current neural state, necessitating models capable of inferring neural\nstate online. Existing approaches, primarily based on dynamical systems,\nrequire strong parametric assumptions that are easily violated in the\nnoise-dominated regime and do not scale well to the thousands of data channels\nin modern experiments. To address this problem, we propose a method that\ncombines fast, stable dimensionality reduction with a soft tiling of the\nresulting neural manifold, allowing dynamics to be approximated as a\nprobability flow between tiles. This method can be fit efficiently using online\nexpectation maximization, scales to tens of thousands of tiles, and outperforms\nexisting methods when dynamics are noise-dominated or feature multi-modal\ntransition probabilities. The resulting model can be trained at kiloHertz data\nrates, produces accurate approximations of neural dynamics within minutes, and\ngenerates predictions on submillisecond time scales. It retains predictive\nperformance throughout many time steps into the future and is fast enough to\nserve as a component of closed-loop causal experiments.",
    "descriptor": "",
    "authors": [
      "Anne Draelos",
      "Pranjal Gupta",
      "Na Young Jun",
      "Chaichontat Sriworarat",
      "John Pearson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.13941"
  },
  {
    "id": "arXiv:2108.13949",
    "title": "Latency-Redundancy Tradeoff in Distributed Read-Write Systems",
    "abstract": "Data is replicated and stored redundantly over multiple servers for\navailability in distributed databases. We focus on databases with frequent\nreads and writes, where both read and write latencies are important. This is in\ncontrast to databases designed primarily for either read or write applications.\nRedundancy has contrasting effects on read and write latency. Read latency can\nbe reduced by potential parallel access from multiple servers, whereas write\nlatency increases as a larger number of replicas have to be updated. We\nquantify this tradeoff between read and write latency as a function of\nredundancy, and provide a closed-form approximation when the request arrival is\nPoisson and the service is memoryless. We empirically show that this\napproximation is tight across all ranges of system parameters. Thus, we provide\nguidelines for redundancy selection in distributed databases.",
    "descriptor": "",
    "authors": [
      "Saraswathy Ramanathan",
      "Gaurav Gautam",
      "Vikram Srinivasan",
      "Parimal Parag"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.13949"
  },
  {
    "id": "arXiv:2108.13952",
    "title": "Morphence: Moving Target Defense Against Adversarial Examples",
    "abstract": "Robustness to adversarial examples of machine learning models remains an open\ntopic of research. Attacks often succeed by repeatedly probing a fixed target\nmodel with adversarial examples purposely crafted to fool it. In this paper, we\nintroduce Morphence, an approach that shifts the defense landscape by making a\nmodel a moving target against adversarial examples. By regularly moving the\ndecision function of a model, Morphence makes it significantly challenging for\nrepeated or correlated attacks to succeed. Morphence deploys a pool of models\ngenerated from a base model in a manner that introduces sufficient randomness\nwhen it responds to prediction queries. To ensure repeated or correlated\nattacks fail, the deployed pool of models automatically expires after a query\nbudget is reached and the model pool is seamlessly replaced by a new model pool\ngenerated in advance. We evaluate Morphence on two benchmark image\nclassification datasets (MNIST and CIFAR10) against five reference attacks (2\nwhite-box and 3 black-box). In all cases, Morphence consistently outperforms\nthe thus-far effective defense, adversarial training, even in the face of\nstrong white-box attacks, while preserving accuracy on clean data.",
    "descriptor": "",
    "authors": [
      "Abderrahmen Amich",
      "Birhanu Eshete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.13952"
  },
  {
    "id": "arXiv:2108.13953",
    "title": "Non-homotopic Loops with a Bounded Number of Pairwise Intersections",
    "abstract": "Let $V_n$ be a set of $n$ points in the plane and let $x \\notin V_n$. An\n$x$-loop is a continuous closed curve not containing any point of $V_n$. We say\nthat two $x$-loops are non-homotopic if they cannot be transformed continuously\ninto each other without passing through a point of $V_n$. For $n=2$, we give an\nupper bound $e^{O\\left(\\sqrt{k}\\right)}$ on the maximum size of a family of\npairwise non-homotopic $x$-loops such that every loop has fewer than $k$\nself-intersections and any two loops have fewer than $k$ intersections. The\nexponent $O\\big(\\sqrt{k}\\big)$ is asymptotically tight. The previous upper\nbound bound $2^{(2k)^4}$ was proved by Pach, Tardos, and T\\'oth [Graph Drawing\n2020]. We prove the above result by proving the asymptotic upper bound\n$e^{O\\left(\\sqrt{k}\\right)}$ for a similar problem when $x \\in V_n$, and by\nproving a close relation between the two problems.",
    "descriptor": "\nComments: Appears in the Proceedings of the 29th International Symposium on Graph Drawing and Network Visualization (GD 2021)\n",
    "authors": [
      "V\u00e1clav Bla\u017eej",
      "Michal Opler",
      "Matas \u0160ileikis",
      "Pavel Valtr"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2108.13953"
  },
  {
    "id": "arXiv:2108.13956",
    "title": "APS: Active Pretraining with Successor Features",
    "abstract": "We introduce a new unsupervised pretraining objective for reinforcement\nlearning. During the unsupervised reward-free pretraining phase, the agent\nmaximizes mutual information between tasks and states induced by the policy.\nOur key contribution is a novel lower bound of this intractable quantity. We\nshow that by reinterpreting and combining variational successor\nfeatures~\\citep{Hansen2020Fast} with nonparametric entropy\nmaximization~\\citep{liu2021behavior}, the intractable mutual information can be\nefficiently optimized. The proposed method Active Pretraining with Successor\nFeature (APS) explores the environment via nonparametric entropy maximization,\nand the explored data can be efficiently leveraged to learn behavior by\nvariational successor features. APS addresses the limitations of existing\nmutual information maximization based and entropy maximization based\nunsupervised RL, and combines the best of both worlds. When evaluated on the\nAtari 100k data-efficiency benchmark, our approach significantly outperforms\nprevious methods combining unsupervised pretraining with task-specific\nfinetuning.",
    "descriptor": "\nComments: Appeared in ICML 2021\n",
    "authors": [
      "Hao Liu",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13956"
  },
  {
    "id": "arXiv:2108.13958",
    "title": "A Novel Dataset for Keypoint Detection of quadruped Animals from Images",
    "abstract": "In this paper, we studied the problem of localizing a generic set of\nkeypoints across multiple quadruped or four-legged animal species from images.\nDue to the lack of large scale animal keypoint dataset with ground truth\nannotations, we developed a novel dataset, AwA Pose, for keypoint detection of\nquadruped animals from images. Our dataset contains significantly more\nkeypoints per animal and has much more diverse animals than the existing\ndatasets for animal keypoint detection. We benchmarked the dataset with a\nstate-of-the-art deep learning model for different keypoint detection tasks,\nincluding both seen and unseen animal cases. Experimental results showed the\neffectiveness of the dataset. We believe that this dataset will help the\ncomputer vision community in the design and evaluation of improved models for\nthe generalized quadruped animal keypoint detection problem.",
    "descriptor": "",
    "authors": [
      "Prianka Banik",
      "Lin Li",
      "Xishuang Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13958"
  },
  {
    "id": "arXiv:2108.13961",
    "title": "Thermostat: A Large Collection of NLP Model Explanations and Analysis  Tools",
    "abstract": "In the language domain, as in other domains, neural explainability takes an\never more important role, with feature attribution methods on the forefront.\nMany such methods require considerable computational resources and expert\nknowledge about implementation details and parameter choices. To facilitate\nresearch, we present Thermostat which consists of a large collection of model\nexplanations and accompanying analysis tools. Thermostat allows easy access to\nover 200k explanations for the decisions of prominent state-of-the-art models\nspanning across different NLP tasks, generated with multiple explainers. The\ndataset took over 10k GPU hours (> one year) to compile; compute time that the\ncommunity now saves. The accompanying software tools allow to analyse\nexplanations instance-wise but also accumulatively on corpus level. Users can\ninvestigate and compare models, datasets and explainers without the need to\norchestrate implementation details. Thermostat is fully open source,\ndemocratizes explainability research in the language domain, circumvents\nredundant computations and increases comparability and replicability.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 System Demonstrations\n",
    "authors": [
      "Nils Feldhus",
      "Robert Schwarzenberg",
      "Sebastian M\u00f6ller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13961"
  },
  {
    "id": "arXiv:2108.13962",
    "title": "DepthTrack : Unveiling the Power of RGBD Tracking",
    "abstract": "RGBD (RGB plus depth) object tracking is gaining momentum as RGBD sensors\nhave become popular in many application fields such as robotics.However, the\nbest RGBD trackers are extensions of the state-of-the-art deep RGB trackers.\nThey are trained with RGB data and the depth channel is used as a sidekick for\nsubtleties such as occlusion detection. This can be explained by the fact that\nthere are no sufficiently large RGBD datasets to 1) train deep depth trackers\nand to 2) challenge RGB trackers with sequences for which the depth cue is\nessential. This work introduces a new RGBD tracking dataset - Depth-Track -\nthat has twice as many sequences (200) and scene types (40) than in the largest\nexisting dataset, and three times more objects (90). In addition, the average\nlength of the sequences (1473), the number of deformable objects (16) and the\nnumber of annotated tracking attributes (15) have been increased. Furthermore,\nby running the SotA RGB and RGBD trackers on DepthTrack, we propose a new RGBD\ntracking baseline, namely DeT, which reveals that deep RGBD tracking indeed\nbenefits from genuine training data. The code and dataset is available at\nhttps://github.com/xiaozai/DeT",
    "descriptor": "\nComments: Accepted to ICCV2021\n",
    "authors": [
      "Song Yan",
      "Jinyu Yang",
      "Jani K\u00e4pyl\u00e4",
      "Feng Zheng",
      "Ale\u0161 Leonardis",
      "Joni-Kristian K\u00e4m\u00e4r\u00e4inen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13962"
  },
  {
    "id": "arXiv:2108.13965",
    "title": "Approximation Methods for Partially Observed Markov Decision Processes  (POMDPs)",
    "abstract": "POMDPs are useful models for systems where the true underlying state is not\nknown completely to an outside observer; the outside observer incompletely\nknows the true state of the system, and observes a noisy version of the true\nsystem state. When the number of system states is large in a POMDP that often\nnecessitates the use of approximation methods to obtain near optimal solutions\nfor control. This survey is centered around the origins, theory, and\napproximations of finite-state POMDPs. In order to understand POMDPs, it is\nrequired to have an understanding of finite-state Markov Decision Processes\n(MDPs) in \\autoref{mdp} and Hidden Markov Models (HMMs) in \\autoref{hmm}. For\nthis background theory, I provide only essential details on MDPs and HMMs and\nleave longer expositions to textbook treatments before diving into the main\ntopics of POMDPs. Once the required background is covered, the POMDP is\nintroduced in \\autoref{pomdp}. The origins of the POMDP are explained in the\nclassical papers section \\autoref{classical}. Once the high computational\nrequirements are understood from the exact methodological point of view, the\nmain approximation methods are surveyed in \\autoref{approximations}. Then, I\nend the survey with some new research directions in \\autoref{conclusion}.",
    "descriptor": "",
    "authors": [
      "Caleb M. Bowyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13965"
  },
  {
    "id": "arXiv:2108.13968",
    "title": "Absent Subsequences in Words",
    "abstract": "An absent factor of a string $w$ is a string $u$ which does not occur as a\ncontiguous substring (a.k.a. factor) inside $w$. We extend this well-studied\nnotion and define absent subsequences: a string $u$ is an absent subsequence of\na string $w$ if $u$ does not occur as subsequence (a.k.a. scattered factor)\ninside $w$. Of particular interest to us are minimal absent subsequences, i.e.,\nabsent subsequences whose every subsequence is not absent, and shortest absent\nsubsequences, i.e., absent subsequences of minimal length. We show a series of\ncombinatorial and algorithmic results regarding these two notions. For\ninstance: we give combinatorial characterisations of the sets of minimal and,\nrespectively, shortest absent subsequences in a word, as well as compact\nrepresentations of these sets; we show how we can test efficiently if a string\nis a shortest or minimal absent subsequence in a word, and we give efficient\nalgorithms computing the lexicographically smallest absent subsequence of each\nkind; also, we show how a data structure for answering shortest absent\nsubsequence-queries for the factors of a given string can be efficiently\ncomputed.",
    "descriptor": "\nComments: An extended abstract will appear in the proceedings of the 15th International Conference on Reachability Problems RP2021\n",
    "authors": [
      "Maria Kosche",
      "Tore Ko\u00df",
      "Florin Manea",
      "Stefan Siemer"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.13968"
  },
  {
    "id": "arXiv:2108.13969",
    "title": "S4-Crowd: Semi-Supervised Learning with Self-Supervised Regularisation  for Crowd Counting",
    "abstract": "Crowd counting has drawn more attention because of its wide application in\nsmart cities. Recent works achieved promising performance but relied on the\nsupervised paradigm with expensive crowd annotations. To alleviate annotation\ncost, in this work we proposed a semi-supervised learning framework S4-Crowd,\nwhich can leverage both unlabeled/labeled data for robust crowd modelling. In\nthe unsupervised pathway, two self-supervised losses were proposed to simulate\nthe crowd variations such as scale, illumination, etc., based on which and the\nsupervised information pseudo labels were generated and gradually refined. We\nalso proposed a crowd-driven recurrent unit Gated-Crowd-Recurrent-Unit (GCRU),\nwhich can preserve discriminant crowd information by extracting second-order\nstatistics, yielding pseudo labels with improved quality. A joint loss\nincluding both unsupervised/supervised information was proposed, and a dynamic\nweighting strategy was employed to balance the importance of the unsupervised\nloss and supervised loss at different training stages. We conducted extensive\nexperiments on four popular crowd counting datasets in semi-supervised\nsettings. Experimental results suggested the effectiveness of each proposed\ncomponent in our S4-Crowd framework. Our method also outperformed other\nstate-of-the-art semi-supervised learning approaches on these crowd datasets.",
    "descriptor": "",
    "authors": [
      "Haoran Duan",
      "Yu Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13969"
  },
  {
    "id": "arXiv:2108.13973",
    "title": "Solver-Free Heuristics to Retrieve Feasible Points for Offshore Wind  Farm Collection System",
    "abstract": "A set of solver-free heuristics for the offshore wind collection system\nproblem are presented. Currently, methods of this type are not able to cope\nwith typical constraints, and most of their variations minimize only for\naccumulated cable length. The first algorithm is a two-steps decision process,\nwhere the output is the design of a tree network satisfying cable thermal\nlimits constraints, but vulnerable to violate planarity constraints.\nSubsequently, a cable crossings repair heuristic is introduced in order to fix\ninfeasible points from the first heuristic. Finally, a refining heuristic\n(negative cycle cancelling refining heuristic) takes over to improve feasible\npoints. The latter iteratively swaps cables, intending to find cycles with\nnegative costs that will lead to investment savings. The sequence of heuristics\nsupports the most important restrictions of the problem. The applicability of\nthe workflow is empirically demonstrated by means of a set of large-scale\nreal-world offshore wind farms. The numerical results indicate that: (i)\nfeasible points can be retrieved in computing times in order of seconds, and\n(ii) warm-starting can help solvers to converge significantly faster for\nproblems with solution time in order of several hours.",
    "descriptor": "",
    "authors": [
      "Juan-Andr\u00e9s P\u00e9rez-R\u00faa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.13973"
  },
  {
    "id": "arXiv:2108.13975",
    "title": "Extrapolated DIscontinuity Tracking for complex 2D shock interactions",
    "abstract": "A new shock-tracking technique that avoids re-meshing the computational grid\naround the moving shock-front was recently proposed by the authors [1]. This\npaper describes further algorithmic improvements which make the extrapolated\nDiscontinuity Tracking Technique (eDIT) capable of dealing with complex\nshock-topologies featuring shock-shock and shock-wall interactions. Various\ntest-cases are included to describe the key features of the methodology and\nprove its order-of-convergence properties.",
    "descriptor": "",
    "authors": [
      "Mirco Ciallella",
      "Mario Ricchiuto",
      "Renato Paciorri",
      "Aldo Bonfiglioli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2108.13975"
  },
  {
    "id": "arXiv:2108.13976",
    "title": "WarpDrive: Extremely Fast End-to-End Deep Multi-Agent Reinforcement  Learning on a GPU",
    "abstract": "Deep reinforcement learning (RL) is a powerful framework to train\ndecision-making models in complex dynamical environments. However, RL can be\nslow as it learns through repeated interaction with a simulation of the\nenvironment. Accelerating RL requires both algorithmic and engineering\ninnovations. In particular, there are key systems engineering bottlenecks when\nusing RL in complex environments that feature multiple agents or\nhigh-dimensional state, observation, or action spaces, for example. We present\nWarpDrive, a flexible, lightweight, and easy-to-use open-source RL framework\nthat implements end-to-end multi-agent RL on a single GPU (Graphics Processing\nUnit), building on PyCUDA and PyTorch. Using the extreme parallelization\ncapability of GPUs, WarpDrive enables orders-of-magnitude faster RL compared to\ncommon implementations that blend CPU simulations and GPU models. Our design\nruns simulations and the agents in each simulation in parallel. It eliminates\ndata copying between CPU and GPU. It also uses a single simulation data store\non the GPU that is safely updated in-place. Together, this allows the user to\nrun thousands of concurrent multi-agent simulations and train on extremely\nlarge batches of experience. For example, WarpDrive yields 2.9 million\nenvironment steps/second with 2000 environments and 1000 agents (at least 100x\nhigher throughput compared to a CPU implementation) in a benchmark Tag\nsimulation. WarpDrive provides a lightweight Python interface and environment\nwrappers to simplify usage and promote flexibility and extensions. As such,\nWarpDrive provides a framework for building high-throughput RL systems.",
    "descriptor": "\nComments: TL and SS contributed equally. Code is available at this https URL 14 pages, 7 figures\n",
    "authors": [
      "Tian Lan",
      "Sunil Srinivasa",
      "Stephan Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2108.13976"
  },
  {
    "id": "arXiv:2108.13980",
    "title": "Incorporating Deception into CyberBattleSim for Autonomous Defense",
    "abstract": "Deceptive elements, including honeypots and decoys, were incorporated into\nthe Microsoft CyberBattleSim experimentation and research platform. The\ndefensive capabilities of the deceptive elements were tested using\nreinforcement learning based attackers in the provided capture the flag\nenvironment. The attacker's progress was found to be dependent on the number\nand location of the deceptive elements. This is a promising step toward\nreproducibly testing attack and defense algorithms in a simulated enterprise\nnetwork with deceptive defensive elements.",
    "descriptor": "\nComments: Presented at 1st International Workshop on Adaptive Cyber Defense, 2021 (arXiv:2108.08476)\n",
    "authors": [
      "Erich Walter",
      "Kimberly Ferguson-Walter",
      "Ahmad Ridley"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13980"
  },
  {
    "id": "arXiv:2108.13983",
    "title": "Detecting Mitosis against Domain Shift using a Fused Detector and Deep  Ensemble Classification Model for MIDOG Challenge",
    "abstract": "Mitotic figure count is an important marker of tumor proliferation and has\nbeen shown to be associated with patients' prognosis. Deep learning based\nmitotic figure detection methods have been utilized to automatically locate the\ncell in mitosis using hematoxylin \\& eosin (H\\&E) stained images. However, the\nmodel performance deteriorates due to the large variation of color tone and\nintensity in H\\&E images. In this work, we proposed a two stage mitotic figure\ndetection framework by fusing a detector and a deep ensemble classification\nmodel. To alleviate the impact of color variation in H\\&E images, we utilize\nboth stain normalization and data augmentation, aiding model to learn color\nirrelevant features. The proposed model obtains an F1 score of 0.7550 on the\npreliminary testing set released by the MIDOG challenge.",
    "descriptor": "",
    "authors": [
      "Jingtang Liang",
      "Cheng Wang",
      "Yujie Cheng",
      "Zheng Wang",
      "Fang Wang",
      "Liyu Huang",
      "Zhibin Yu",
      "Yubo Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13983"
  },
  {
    "id": "arXiv:2108.13989",
    "title": "DeepTaskAPT: Insider APT detection using Task-tree based Deep Learning",
    "abstract": "APT, known as Advanced Persistent Threat, is a difficult challenge for cyber\ndefence. These threats make many traditional defences ineffective as the\nvulnerabilities exploited by these threats are insiders who have access to and\nare within the network. This paper proposes DeepTaskAPT, a heterogeneous\ntask-tree based deep learning method to construct a baseline model based on\nsequences of tasks using a Long Short-Term Memory (LSTM) neural network that\ncan be applied across different users to identify anomalous behaviour. Rather\nthan applying the model to sequential log entries directly, as most current\napproaches do, DeepTaskAPT applies a process tree based task generation method\nto generate sequential log entries for the deep learning model. To assess the\nperformance of DeepTaskAPT, we use a recently released synthetic dataset, DARPA\nOperationally Transparent Computing (OpTC) dataset and a real-world dataset,\nLos Alamos National Laboratory (LANL) dataset. Both of them are composed of\nhost-based data collected from sensors. Our results show that DeepTaskAPT\noutperforms similar approaches e.g. DeepLog and the DeepTaskAPT baseline model\ndemonstrate its capability to detect malicious traces in various attack\nscenarios while having high accuracy and low false-positive rates. To the best\nof knowledge this is the very first attempt of using recently introduced OpTC\ndataset for cyber threat detection.",
    "descriptor": "\nComments: Conference: IEEE Trustcom 2021\n",
    "authors": [
      "Mohammad Mamun",
      "Kevin Shi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13989"
  },
  {
    "id": "arXiv:2108.13990",
    "title": "Effective Sequence-to-Sequence Dialogue State Tracking",
    "abstract": "Sequence-to-sequence models have been applied to a wide variety of NLP tasks,\nbut how to properly use them for dialogue state tracking has not been\nsystematically investigated. In this paper, we study this problem from the\nperspectives of pre-training objectives as well as the formats of context\nrepresentations. We demonstrate that the choice of pre-training objective makes\na significant difference to the state tracking quality. In particular, we find\nthat masked span prediction is more effective than auto-regressive language\nmodeling. We also explore using Pegasus, a span prediction-based pre-training\nobjective for text summarization, for the state tracking model. We found that\npre-training for the seemingly distant summarization task works surprisingly\nwell for dialogue state tracking. In addition, we found that while recurrent\nstate context representation works also reasonably well, the model may have a\nhard time recovering from earlier mistakes. We conducted experiments on the\nMultiWOZ 2.1-2.4 data sets with consistent observations.",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Jeffrey Zhao",
      "Mahdis Mahdieh",
      "Ye Zhang",
      "Yuan Cao",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13990"
  },
  {
    "id": "arXiv:2108.13993",
    "title": "Designing Rotationally Invariant Neural Networks from PDEs and  Variational Methods",
    "abstract": "Partial differential equation (PDE) models and their associated variational\nenergy formulations are often rotationally invariant by design. This ensures\nthat a rotation of the input results in a corresponding rotation of the output,\nwhich is desirable in applications such as image analysis. Convolutional neural\nnetworks (CNNs) do not share this property, and existing remedies are often\ncomplex. The goal of our paper is to investigate how diffusion and variational\nmodels achieve rotation invariance and transfer these ideas to neural networks.\nAs a core novelty we propose activation functions which couple network channels\nby combining information from several oriented filters. This guarantees\nrotation invariance within the basic building blocks of the networks while\nstill allowing for directional filtering. The resulting neural architectures\nare inherently rotationally invariant. With only a few small filters, they can\nachieve the same invariance as existing techniques which require a fine-grained\nsampling of orientations. Our findings help to translate diffusion and\nvariational models into mathematically well-founded network architectures, and\nprovide novel concepts for model-based CNN design.",
    "descriptor": "",
    "authors": [
      "Tobias Alt",
      "Karl Schrader",
      "Joachim Weickert",
      "Pascal Peter",
      "Matthias Augustin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.13993"
  },
  {
    "id": "arXiv:2108.13995",
    "title": "Realistic Hands: A Hybrid Model for 3D Hand Reconstruction",
    "abstract": "Estimating 3D hand meshes from RGB images robustly is a highly desirable\ntask, made challenging due to the numerous degrees of freedom, and issues such\nas self similarity and occlusions. Previous methods generally either use\nparametric 3D hand models or follow a model-free approach. While the former can\nbe considered more robust, e.g. to occlusions, they are less expressive. We\npropose a hybrid approach, utilizing a deep neural network and differential\nrendering based optimization to demonstrably achieve the best of both worlds.\nIn addition, we explore Virtual Reality (VR) as an application. Most VR\nheadsets are nowadays equipped with multiple cameras, which we can leverage by\nextending our method to the egocentric stereo domain. This extension proves to\nbe more resilient to the above mentioned issues. Finally, as a use-case, we\nshow that the improved image-model alignment can be used to acquire the user's\nhand texture, which leads to a more realistic virtual hand representation.",
    "descriptor": "",
    "authors": [
      "Michael Seeber",
      "Martin R. Oswald",
      "Roi Poranne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13995"
  },
  {
    "id": "arXiv:2108.13996",
    "title": "Quantization of Generative Adversarial Networks for Efficient Inference:  a Methodological Study",
    "abstract": "Generative adversarial networks (GANs) have an enormous potential impact on\ndigital content creation, e.g., photo-realistic digital avatars, semantic\ncontent editing, and quality enhancement of speech and images. However, the\nperformance of modern GANs comes together with massive amounts of computations\nperformed during the inference and high energy consumption. That complicates,\nor even makes impossible, their deployment on edge devices. The problem can be\nreduced with quantization -- a neural network compression technique that\nfacilitates hardware-friendly inference by replacing floating-point\ncomputations with low-bit integer ones. While quantization is well established\nfor discriminative models, the performance of modern quantization techniques in\napplication to GANs remains unclear. GANs generate content of a more complex\nstructure than discriminative models, and thus quantization of GANs is\nsignificantly more challenging. To tackle this problem, we perform an extensive\nexperimental study of state-of-art quantization techniques on three diverse GAN\narchitectures, namely StyleGAN, Self-Attention GAN, and CycleGAN. As a result,\nwe discovered practical recipes that allowed us to successfully quantize these\nmodels for inference with 4/8-bit weights and 8-bit activations while\npreserving the quality of the original full-precision models.",
    "descriptor": "",
    "authors": [
      "Pavel Andreev",
      "Alexander Fritzler",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13996"
  },
  {
    "id": "arXiv:2108.14004",
    "title": "EthClipper: A Clipboard Meddling Attack on Hardware Wallets with Address  Verification Evasion",
    "abstract": "Hardware wallets are designed to withstand malware attacks by isolating their\nprivate keys from the cyberspace, but they are vulnerable to the attacks that\nfake an address stored in a clipboard. To prevent such attacks, a hardware\nwallet asks the user to verify the recipient address shown on the wallet\ndisplay. Since crypto addresses are long sequences of random symbols, their\nmanual verification becomes a difficult task. Consequently, many users of\nhardware wallets elect to verify only a few symbols in the address, and this\ncan be exploited by an attacker. In this work, we introduce EthClipper, an\nattack that targets owners of hardware wallets on the Ethereum platform.\nEthClipper malware queries a distributed database of pre-mined accounts in\norder to select the address with maximum visual similarity to the original one.\nWe design and implement a EthClipper malware, which we test on Trezor, Ledger,\nand KeepKey wallets. To deliver computation and storage resources for the\nattack, we implement a distributed service, ClipperCloud, and test it on\ndifferent deployment environments. Our evaluation shows that with off-the-shelf\nPCs and NAS storage, an attacker would be able to mine a database capable of\nmatching 25% of the digits in an address to achieve a 50% chance of finding a\nfitting fake address. For responsible disclosure, we have contacted the\nmanufactures of the hardware wallets used in the attack evaluation, and they\nall confirm the danger of EthClipper.",
    "descriptor": "\nComments: IEEE Conference on Communications and Network Security (CNS 2021)\n",
    "authors": [
      "Nikolay Ivanov",
      "Qiben Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.14004"
  },
  {
    "id": "arXiv:2108.14006",
    "title": "A Generative Approach for Mitigating Structural Biases in Natural  Language Inference",
    "abstract": "Many natural language inference (NLI) datasets contain biases that allow\nmodels to perform well by only using a biased subset of the input, without\nconsidering the remainder features. For instance, models are able to make a\nclassification decision by only using the hypothesis, without learning the true\nrelationship between it and the premise. These structural biases lead\ndiscriminative models to learn unintended superficial features and to\ngeneralize poorly out of the training distribution. In this work, we\nreformulate the NLI task as a generative task, where a model is conditioned on\nthe biased subset of the input and the label and generates the remaining subset\nof the input. We show that by imposing a uniform prior, we obtain a provably\nunbiased model. Through synthetic experiments, we find that this approach is\nhighly robust to large amounts of bias. We then demonstrate empirically on two\ntypes of natural bias that this approach leads to fully unbiased models in\npractice. However, we find that generative models are difficult to train and\nthey generally perform worse than discriminative baselines. We highlight the\ndifficulty of the generative modeling task in the context of NLI as a cause for\nthis worse performance. Finally, by fine-tuning the generative model with a\ndiscriminative objective, we reduce the performance gap between the generative\nmodel and the discriminative baseline, while allowing for a small amount of\nbias.",
    "descriptor": "",
    "authors": [
      "Dimion Asael",
      "Zachary Ziegler",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.14006"
  },
  {
    "id": "arXiv:2011.03293",
    "title": "On the Stability Properties and the Optimization Landscape of Training  Problems with Squared Loss for Neural Networks and General Nonlinear Conic  Approximation Schemes",
    "abstract": "We study the optimization landscape and the stability properties of training\nproblems with squared loss for neural networks and general nonlinear conic\napproximation schemes. It is demonstrated that, if a nonlinear conic\napproximation scheme is considered that is (in an appropriately defined sense)\nmore expressive than a classical linear approximation approach and if there\nexist unrealizable label vectors, then a training problem with squared loss is\nnecessarily unstable in the sense that its solution set depends discontinuously\non the label vector in the training data. We further prove that the same\neffects that are responsible for these instability properties are also the\nreason for the emergence of saddle points and spurious local minima, which may\nbe arbitrarily far away from global solutions, and that neither the instability\nof the training problem nor the existence of spurious local minima can, in\ngeneral, be overcome by adding a regularization term to the objective function\nthat penalizes the size of the parameters in the approximation scheme. The\nlatter results are shown to be true regardless of whether the assumption of\nrealizability is satisfied or not. We demonstrate that our analysis in\nparticular applies to training problems for free-knot interpolation schemes and\ndeep and shallow neural networks with variable widths that involve an arbitrary\nmixture of various activation functions (e.g., binary, sigmoid, tanh, arctan,\nsoft-sign, ISRU, soft-clip, SQNL, ReLU, leaky ReLU, soft-plus, bent identity,\nSILU, ISRLU, and ELU). In summary, the findings of this paper illustrate that\nthe improved approximation properties of neural networks and general nonlinear\nconic approximation instruments are linked in a direct and quantifiable way to\nundesirable properties of the optimization problems that have to be solved in\norder to train them.",
    "descriptor": "\nComments: Some comments and explanations have been added. The result on regularized training problems has been strengthened\n",
    "authors": [
      "Constantin Christof"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.03293"
  },
  {
    "id": "arXiv:2108.13414",
    "title": "Astrocytes mediate analogous memory in a multi-layer neuron-astrocytic  network",
    "abstract": "Modeling the neuronal processes underlying short-term working memory remains\nthe focus of many theoretical studies in neuroscience. Here we propose a\nmathematical model of spiking neuron network (SNN) demonstrating how a piece of\ninformation can be maintained as a robust activity pattern for several seconds\nthen completely disappear if no other stimuli come. Such short-term memory\ntraces are preserved due to the activation of astrocytes accompanying the SNN.\nThe astrocytes exhibit calcium transients at a time scale of seconds. These\ntransients further modulate the efficiency of synaptic transmission and, hence,\nthe firing rate of neighboring neurons at diverse timescales through\ngliotransmitter release. We show how such transients continuously encode\nfrequencies of neuronal discharges and provide robust short-term storage of\nanalogous information. This kind of short-term memory can keep operative\ninformation for seconds, then completely forget it to avoid overlapping with\nforthcoming patterns. The SNN is inter-connected with the astrocytic layer by\nlocal inter-cellular diffusive connections. The astrocytes are activated only\nwhen the neighboring neurons fire quite synchronously, e.g. when an information\npattern is loaded. For illustration, we took greyscale photos of people's faces\nwhere the grey level encoded the level of applied current stimulating the\nneurons. The astrocyte feedback modulates (facilitates) synaptic transmission\nby varying the frequency of neuronal firing. We show how arbitrary patterns can\nbe loaded, then stored for a certain interval of time, and retrieved if the\nappropriate clue pattern is applied to the input.",
    "descriptor": "\nComments: 18 pages, 6 figures, 1 table, Appendix\n",
    "authors": [
      "Yuliya Tsybina",
      "Innokentiy Kastalskiy",
      "Mikhail Krivonosov",
      "Alexey Zaikin",
      "Victor Kazantsev",
      "Alexander Gorban",
      "Susanna Gordleeva"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.13414"
  },
  {
    "id": "arXiv:2108.13415",
    "title": "A nonlinear cross-diffusion epidemic with time-dependent SIRD system:  Multiscale derivation and computational analysis",
    "abstract": "A nonlinear cross-diffusion epidemic with a time-dependent\nSusceptible-Infected-Recovered-Died system is proposed in this paper. This\nsystem is derived from kinetic theory model by multiscale approach, which leads\nto an equivalent system coupled the microscopic and macroscopic equations.\nSubsequently, numerical investigations to design asymptotic preserving scheme\nproperty is developed and validated by various numerical tests. Finally, the\nnumerical computational results of the proposed system are discussed in two\ndimensional space using the finite volume method.",
    "descriptor": "",
    "authors": [
      "Mohamed Zagour"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.13415"
  },
  {
    "id": "arXiv:2108.13421",
    "title": "Recent advances for quantum classifiers",
    "abstract": "Machine learning has achieved dramatic success in a broad spectrum of\napplications. Its interplay with quantum physics may lead to unprecedented\nperspectives for both fundamental research and commercial applications, giving\nrise to an emergent research frontier of quantum machine learning. Along this\nline, quantum classifiers, which are quantum devices that aim to solve\nclassification problems in machine learning, have attracted tremendous\nattention recently. In this review, we give a relatively comprehensive overview\nfor the studies of quantum classifiers, with a focus on recent advances. First,\nwe will review a number of quantum classification algorithms, including quantum\nsupport vector machine, quantum kernel methods, quantum decision tree, and\nquantum nearest neighbor algorithm. Then, we move on to introduce the\nvariational quantum classifiers, which are essentially variational quantum\ncircuits for classifications. We will review different architectures for\nconstructing variational quantum classifiers and introduce the barren plateau\nproblem, where the training of quantum classifiers might be hindered by the\nexponentially vanishing gradient. In addition, the vulnerability aspect of\nquantum classifiers in the setting of adversarial learning and the recent\nexperimental progress on different quantum classifiers will also be discussed.",
    "descriptor": "\nComments: invited review, 21 pages, 10 figures\n",
    "authors": [
      "Weikang Li",
      "Dong-Ling Deng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13421"
  },
  {
    "id": "arXiv:2108.13441",
    "title": "On Integers Whose Sum is the Reverse of their Product",
    "abstract": "We determine all pairs of positive integers $(a,b)$ such that $a+b$ and $a\n\\times b$ have the same decimal digits in reverse order: \\[ (2,2), (9,9),\n(3,24), (2,47), (2,497), (2,4997), (2,49997), \\ldots \\] We use deterministic\nfinite automata to describe our approach, which naturally extends to all other\nnumerical bases.",
    "descriptor": "\nComments: 18 pages; 4 figures; Python experimentation/visualization code available at this https URL\n",
    "authors": [
      "Xander Faber",
      "Jon Grantham"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2108.13441"
  },
  {
    "id": "arXiv:2108.13458",
    "title": "The Application of Convolutional Neural Networks for Tomographic  Reconstruction of Hyperspectral Images",
    "abstract": "A novel method, utilizing convolutional neural networks (CNNs), is proposed\nto reconstruct hyperspectral cubes from computed tomography imaging\nspectrometer (CTIS) images. Current reconstruction algorithms are usually\nsubject to long reconstruction times and mediocre precision in cases of a large\nnumber of spectral channels. The constructed CNNs deliver higher precision and\nshorter reconstruction time than a standard expectation maximization algorithm.\nIn addition, the network can handle two different types of real-world images at\nthe same time -- specifically ColorChecker and carrot spectral images are\nconsidered. This work paves the way toward real-time reconstruction of\nhyperspectral cubes from CTIS images.",
    "descriptor": "\nComments: 22 pages, 12 figures and 3 tables\n",
    "authors": [
      "Wei-Chih Huang",
      "Mads Svanborg Peters",
      "Mads Juul Ahlebaek",
      "Mads Toudal Frandsen",
      "Ren\u00e9 Lynge Eriksen",
      "Bjarke J\u00f8rgensen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13458"
  },
  {
    "id": "arXiv:2108.13523",
    "title": "On the Number of Faces and Radii of Cells Induced by Gaussian Spherical  Tessellations",
    "abstract": "We study a geometric property related to spherical hyperplane tessellations\nin $\\mathbb{R}^{d}$. We first consider a fixed $x$ on the Euclidean sphere and\ntessellations with $M \\gg d$ hyperplanes passing through the origin having\nnormal vectors distributed according to a Gaussian distribution. We show that\nwith high probability there exists a subset of the hyperplanes whose\ncardinality is on the order of $d\\log(d)\\log(M)$ such that the radius of the\ncell containing $x$ induced by these hyperplanes is bounded above by, up to\nconstants, $d\\log(d)\\log(M)/M$. We extend this result to hold for all cells in\nthe tessellation with high probability. Up to logarithmic terms, this upper\nbound matches the previously established lower bound of Goyal et al. (IEEE T.\nInform. Theory 44(1):16-31, 1998).",
    "descriptor": "",
    "authors": [
      "Eric Lybrand",
      "Anna Ma",
      "Rayan Saab"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.13523"
  },
  {
    "id": "arXiv:2108.13525",
    "title": "Identifying optimal cycles in quantum thermal machines with  reinforcement-learning",
    "abstract": "The optimal control of open quantum systems is a challenging task but has a\nkey role in improving existing quantum information processing technologies. We\nintroduce a general framework based on Reinforcement Learning to discover\noptimal thermodynamic cycles that maximize the power of out-of-equilibrium\nquantum heat engines and refrigerators. We apply our method, based on the soft\nactor-critic algorithm, to three systems: a benchmark two-level system heat\nengine, where we find the optimal known cycle; an experimentally realistic\nrefrigerator based on a superconducting qubit that generates coherence, where\nwe find a non-intuitive control sequence that outperform previous cycles\nproposed in literature; a heat engine based on a quantum harmonic oscillator,\nwhere we find a cycle with an elaborate structure that outperforms the\noptimized Otto cycle. We then evaluate the corresponding efficiency at maximum\npower.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Paolo Andrea Erdman",
      "Frank No\u00e9"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13525"
  },
  {
    "id": "arXiv:2108.13527",
    "title": "Double sparse quantum state preparation",
    "abstract": "Initializing classical data in a quantum device is an essential step in many\nquantum algorithms. As a consequence of measurement and noisy operations, some\nalgorithms need to reinitialize the prepared state several times during its\nexecution. In this work, we propose a quantum state preparation algorithm\ncalled CVO-QRAM with computational cost O(kM), where M is the number of nonzero\nprobability amplitudes and $k$ is the maximum number of bits with value 1 in\nthe patterns to be stored. The proposed algorithm can be an alternative to\ncreate sparse states in future NISQ devices.",
    "descriptor": "",
    "authors": [
      "Tiago M.L. de Veras",
      "Leon D. da Silva",
      "Adenilton J. da Silva"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2108.13527"
  },
  {
    "id": "arXiv:2108.13559",
    "title": "Music Demixing Challenge at ISMIR 2021",
    "abstract": "Music source separation has been intensively studied in the last decade and\ntremendous progress with the advent of deep learning could be observed.\nEvaluation campaigns such as MIREX or SiSEC connected state-of-the-art models\nand corresponding papers, which can help researchers integrate the best\npractices into their models. In recent years, however, it has become\nincreasingly difficult to measure real-world performance as the music\nseparation community had to rely on a limited amount of test data and was\nbiased towards specific genres and mixing styles. To address these issues, we\ndesigned the Music Demixing (MDX) Challenge on a crowd-based machine learning\ncompetition platform where the task is to separate stereo songs into four\ninstrument stems (Vocals, Drums, Bass, Other). The main differences compared\nwith the past challenges are 1) the competition is designed to more easily\nallow machine learning practitioners from other disciplines to participate and\n2) evaluation is done on a hidden test set created by music professionals\ndedicated exclusively to the challenge to assure the transparency of the\nchallenge, i.e., the test set is not included in the training set. In this\npaper, we provide the details of the datasets, baselines, evaluation metrics,\nevaluation results, and technical challenges for future competitions.",
    "descriptor": "",
    "authors": [
      "Yuki Mitsufuji",
      "Giorgio Fabbro",
      "Stefan Uhlich",
      "Fabian-Robert St\u00f6ter"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2108.13559"
  },
  {
    "id": "arXiv:2108.13610",
    "title": "Iterative Filter Adaptive Network for Single Image Defocus Deblurring",
    "abstract": "We propose a novel end-to-end learning-based approach for single image\ndefocus deblurring. The proposed approach is equipped with a novel Iterative\nFilter Adaptive Network (IFAN) that is specifically designed to handle\nspatially-varying and large defocus blur. For adaptively handling\nspatially-varying blur, IFAN predicts pixel-wise deblurring filters, which are\napplied to defocused features of an input image to generate deblurred features.\nFor effectively managing large blur, IFAN models deblurring filters as stacks\nof small-sized separable filters. Predicted separable deblurring filters are\napplied to defocused features using a novel Iterative Adaptive Convolution\n(IAC) layer. We also propose a training scheme based on defocus disparity\nestimation and reblurring, which significantly boosts the deblurring quality.\nWe demonstrate that our method achieves state-of-the-art performance both\nquantitatively and qualitatively on real-world images.",
    "descriptor": "\nComments: CVPR 2021\n",
    "authors": [
      "Junyong Lee",
      "Hyeongseok Son",
      "Jaesung Rim",
      "Sunghyun Cho",
      "Seungyong Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13610"
  },
  {
    "id": "arXiv:2108.13669",
    "title": "Unit-Modulus Wireless Federated Learning Via Penalty Alternating  Minimization",
    "abstract": "Wireless federated learning (FL) is an emerging machine learning paradigm\nthat trains a global parametric model from distributed datasets via wireless\ncommunications. This paper proposes a unit-modulus wireless FL (UMWFL)\nframework, which simultaneously uploads local model parameters and computes\nglobal model parameters via optimized phase shifting. The proposed framework\navoids sophisticated baseband signal processing, leading to both low\ncommunication delays and implementation costs. A training loss bound is derived\nand a penalty alternating minimization (PAM) algorithm is proposed to minimize\nthe nonconvex nonsmooth loss bound. Experimental results in the Car Learning to\nAct (CARLA) platform show that the proposed UMWFL framework with PAM algorithm\nachieves smaller training losses and testing errors than those of the benchmark\nscheme.",
    "descriptor": "\nComments: IEEE Global Communications Conference 2021. arXiv admin note: substantial text overlap with arXiv:2101.12051\n",
    "authors": [
      "Shuai Wang",
      "Dachuan Li",
      "Rui Wang",
      "Qi Hao",
      "Yik-Chung Wu",
      "Derrick Wing Kwan Ng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13669"
  },
  {
    "id": "arXiv:2108.13703",
    "title": "Evaluating the Robustness of Off-Policy Evaluation",
    "abstract": "Off-policy Evaluation (OPE), or offline evaluation in general, evaluates the\nperformance of hypothetical policies leveraging only offline log data. It is\nparticularly useful in applications where the online interaction involves high\nstakes and expensive setting such as precision medicine and recommender\nsystems. Since many OPE estimators have been proposed and some of them have\nhyperparameters to be tuned, there is an emerging challenge for practitioners\nto select and tune OPE estimators for their specific application.\nUnfortunately, identifying a reliable estimator from results reported in\nresearch papers is often difficult because the current experimental procedure\nevaluates and compares the estimators' performance on a narrow set of\nhyperparameters and evaluation policies. Therefore, it is difficult to know\nwhich estimator is safe and reliable to use. In this work, we develop\nInterpretable Evaluation for Offline Evaluation (IEOE), an experimental\nprocedure to evaluate OPE estimators' robustness to changes in hyperparameters\nand/or evaluation policies in an interpretable manner. Then, using the IEOE\nprocedure, we perform extensive evaluation of a wide variety of existing\nestimators on Open Bandit Dataset, a large-scale public real-world dataset for\nOPE. We demonstrate that our procedure can evaluate the estimators' robustness\nto the hyperparamter choice, helping us avoid using unsafe estimators. Finally,\nwe apply IEOE to real-world e-commerce platform data and demonstrate how to use\nour protocol in practice.",
    "descriptor": "\nComments: Accepted at RecSys2021\n",
    "authors": [
      "Yuta Saito",
      "Takuma Udagawa",
      "Haruka Kiyohara",
      "Kazuki Mogi",
      "Yusuke Narita",
      "Kei Tateno"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13703"
  },
  {
    "id": "arXiv:2108.13753",
    "title": "Disentanglement Analysis with Partial Information Decomposition",
    "abstract": "Given data generated from multiple factors of variation that cooperatively\ntransform their appearance, disentangled representations aim at reversing the\nprocess by mapping data to multiple random variables that individually capture\ndistinct generative factors. As the concept is intuitive but abstract, one\nneeds to quantify it with disentanglement metrics to evaluate and compare the\nquality of disentangled representations between different models. Current\ndisentanglement metrics are designed to measure the concentration, e.g.,\nabsolute deviation, variance, or entropy, of each variable conditioned by each\ngenerative factor, optionally offset by the concentration of its marginal\ndistribution, and compare it among different variables. When representations\nconsist of more than two variables, such metrics may fail to detect the\ninterplay between them as they only measure pairwise interactions. In this\nwork, we use the Partial Information Decomposition framework to evaluate\ninformation sharing between more than two variables, and build a framework,\nincluding a new disentanglement metric, for analyzing how the representations\nencode the generative factors distinctly, redundantly, and cooperatively. We\nestablish an experimental protocol to assess how each metric evaluates\nincreasingly entangled representations and confirm through artificial and\nrealistic settings that the proposed metric correctly responds to entanglement.\nOur results are expected to promote information theoretic understanding of\ndisentanglement and lead to further development of metrics as well as learning\nmethods.",
    "descriptor": "",
    "authors": [
      "Seiya Tokui",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13753"
  },
  {
    "id": "arXiv:2108.13823",
    "title": "Temporal Deep Learning Architecture for Prediction of COVID-19 Cases in  India",
    "abstract": "To combat the recent coronavirus disease 2019 (COVID-19), academician and\nclinician are in search of new approaches to predict the COVID-19 outbreak\ndynamic trends that may slow down or stop the pandemic. Epidemiological models\nlike Susceptible-Infected-Recovered (SIR) and its variants are helpful to\nunderstand the dynamics trend of pandemic that may be used in decision making\nto optimize possible controls from the infectious disease. But these\nepidemiological models based on mathematical assumptions may not predict the\nreal pandemic situation. Recently the new machine learning approaches are being\nused to understand the dynamic trend of COVID-19 spread. In this paper, we\ndesigned the recurrent and convolutional neural network models: vanilla LSTM,\nstacked LSTM, ED-LSTM, Bi-LSTM, CNN, and hybrid CNN+LSTM model to capture the\ncomplex trend of COVID-19 outbreak and perform the forecasting of COVID-19\ndaily confirmed cases of 7, 14, 21 days for India and its four most affected\nstates (Maharashtra, Kerala, Karnataka, and Tamil Nadu). The root mean square\nerror (RMSE) and mean absolute percentage error (MAPE) evaluation metric are\ncomputed on the testing data to demonstrate the relative performance of these\nmodels. The results show that the stacked LSTM and hybrid CNN+LSTM models\nperform best relative to other models.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Hanuman Verma",
      "Saurav Mandal",
      "Akshansh Gupta"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13823"
  },
  {
    "id": "arXiv:2108.13844",
    "title": "Fiducial marker recovery and detection from severely truncated data in  navigation assisted spine surgery",
    "abstract": "Fiducial markers are commonly used in navigation assisted minimally invasive\nspine surgery (MISS) and they help transfer image coordinates into real world\ncoordinates. In practice, these markers might be located outside the\nfield-of-view (FOV), due to the limited detector sizes of C-arm cone-beam\ncomputed tomography (CBCT) systems used in intraoperative surgeries. As a\nconsequence, reconstructed markers in CBCT volumes suffer from artifacts and\nhave distorted shapes, which sets an obstacle for navigation. In this work, we\npropose two fiducial marker detection methods: direct detection from distorted\nmarkers (direct method) and detection after marker recovery (recovery method).\nFor direct detection from distorted markers in reconstructed volumes, an\nefficient automatic marker detection method using two neural networks and a\nconventional circle detection algorithm is proposed. For marker recovery, a\ntask-specific learning strategy is proposed to recover markers from severely\ntruncated data. Afterwards, a conventional marker detection algorithm is\napplied for position detection. The two methods are evaluated on simulated data\nand real data, both achieving a marker registration error smaller than 0.2 mm.\nOur experiments demonstrate that the direct method is capable of detecting\ndistorted markers accurately and the recovery method with task-specific\nlearning has high robustness and generalizability on various data sets. In\naddition, the task-specific learning is able to reconstruct other structures of\ninterest accurately, e.g. ribs for image-guided needle biopsy, from severely\ntruncated data, which empowers CBCT systems with new potential applications.",
    "descriptor": "",
    "authors": [
      "Fuxin Fan",
      "Bj\u00f6rn Kreher",
      "Holger Keil",
      "Maier Andreas",
      "Yixing Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13844"
  },
  {
    "id": "arXiv:2108.13847",
    "title": "Harmonic Radar with Adaptively Phase-Coherent Auxiliary Transmitters",
    "abstract": "In harmonic radar (HR), the radio frequency transmitter illuminates a\nnonlinear target (the tag), causing the return signal to consist of harmonics\nat multiples of the transmitted carrier frequency. Of them, the second harmonic\nis usually the strongest and the one to which the receiver is tuned. This\nfrequency difference distinguishes the tag reflection from environmental\nclutter, which remains at the uplink (transmitter to tag) frequency. However,\nthe passive nature of HR tags severely limits the reflected power, and\ntherefore the range of the downlink (tag to receiver) path. We propose to\nincrease the range and/or signal to noise ratio (SNR) by novel restructuring at\nthe physical and signal levels. For this, we accompany the original transmitter\nwith auxiliary transmitters able to send simple tones that are synchronized to\narrive at the tag in phase, and we design the receiver to detect an\nintermodulation component. The resulting range and SNR are much greater than\nthose of the original, conventional HR system, and greater even than if the\noriginal system were to transmit with power equal to the aggregate power of our\nnew system. Achieving mutually coherent, i.e., in phase, arrival of the tones\nat the tag is the focus of the present paper. We provide a system framework\nthat models the tag and the uplink and downlink, then present the adaptive\nphase coherence algorithm and analyze the probabilistic growth of the output\nsignal power. We also account for the effects of frequency shifts due to\ntransmitter mobility and the frequency offset errors in the transmitter local\noscillators.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Anastasia Lavrenko",
      "James K. Cavers",
      "Graeme K. Woodward"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13847"
  },
  {
    "id": "arXiv:2108.13884",
    "title": "Graphs with minimum degree-based entropy",
    "abstract": "The degree-based entropy of a graph is defined as the Shannon entropy based\non the information functional that associates the vertices of the graph with\nthe corresponding degrees. In this paper, we study extremal problems of finding\nthe graphs attaining the minimum degree-based graph entropy among graphs and\nbipartite graphs with a given number of vertices and edges. We characterize the\nunique extremal graph achieving the minimum value among graphs with a given\nnumber of vertices and edges and present a lower bound for the degree-based\nentropy of bipartite graphs and characterize all the extremal graphs which\nachieve the lower bound. This implies the known result due to Cao et al. (2014)\nthat the star attains the minimum value of the degree-based entropy among trees\nwith a given number of vertices.",
    "descriptor": "",
    "authors": [
      "Yanni Dong",
      "Maximilien Gadouleau",
      "Pengfei Wan",
      "Shenggui Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.13884"
  },
  {
    "id": "arXiv:2108.13895",
    "title": "Modeling and simulations of moving droplet in a Rarefied gas",
    "abstract": "We study a two phase flow with interactions of liquid and rarefied gas inside\nthe gas phase. The gas phase is modeled by the BGK model of the Boltzmann\nequation. The liquid phase is modeled by the incompressible Navier-Stokes\nequations. In this paper we have excluded the heat transfer between two phases.\nThe interface boundary conditions for the liquid and gas phases is presented.\nThe BGK model is solved by a semi-Lagrangian scheme with a meshfree\nreconstruction since the droplet moves inside the gas phase and its interface\ndeforms with respect to time and space. Therefore, the similar meshfree\nparticle method is also suitable to solve the incompressible Navier-Stokes\nequations for liquid phase. To validate the coupled solutions of the BGK model\nand the incompressible Navier-Stokes equations, we have compared the results of\nthe BGK model and the incompressible Navier-Stokes equations, with those of the\nBoltzmann and the incompressible Navier-Stokes equations, where the Boltzmann\nequation is solved by a DSMC method. Results in $1D$ and $2D$ physical spaces\nare presented.",
    "descriptor": "",
    "authors": [
      "S. Tiwari",
      "A. Klar",
      "G. Russo"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.13895"
  },
  {
    "id": "arXiv:2108.13904",
    "title": "Simultaneous Nuclear Instance and Layer Segmentation in Oral Epithelial  Dysplasia",
    "abstract": "Oral epithelial dysplasia (OED) is a pre-malignant histopathological\ndiagnosis given to lesions of the oral cavity. Predicting OED grade or whether\na case will transition to malignancy is critical for early detection and\nappropriate treatment. OED typically begins in the lower third of the\nepithelium before progressing upwards with grade severity, thus we have\nsuggested that segmenting intra-epithelial layers, in addition to individual\nnuclei, may enable researchers to evaluate important layer-specific\nmorphological features for grade/malignancy prediction. We present HoVer-Net+,\na deep learning framework to simultaneously segment (and classify) nuclei and\n(intra-)epithelial layers in H&E stained slides from OED cases. The proposed\narchitecture consists of an encoder branch and four decoder branches for\nsimultaneous instance segmentation of nuclei and semantic segmentation of the\nepithelial layers. We show that the proposed model achieves the\nstate-of-the-art (SOTA) performance in both tasks, with no additional costs\nwhen compared to previous SOTA methods for each task. To the best of our\nknowledge, ours is the first method for simultaneous nuclear instance\nsegmentation and semantic tissue segmentation, with potential for use in\ncomputational pathology for other similar simultaneous tasks and for future\nstudies into malignancy prediction.",
    "descriptor": "\nComments: 10 pages, 3 figures, conference\n",
    "authors": [
      "Adam J. Shephard",
      "Simon Graham",
      "R.M. Saad Bashir",
      "Mostafa Jahanifar",
      "Hanya Mahmood",
      "Syed Ali Khurram",
      "Nasir M. Rajpoot"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13904"
  },
  {
    "id": "arXiv:2108.13908",
    "title": "Modeling the effect of the vaccination campaign on the Covid-19 pandemic",
    "abstract": "Population-wide vaccination is critical for containing the SARS-CoV-2\n(Covid-19) pandemic when combined with restrictive and prevention measures. In\nthis study, we introduce SAIVR, a mathematical model able to forecast the\nCovid-19 epidemic evolution during the vaccination campaign. SAIVR extends the\nwidely used Susceptible-Infectious-Removed (SIR) model by considering the\nAsymptomatic (A) and Vaccinated (V) compartments. The model contains several\nparameters and initial conditions that are estimated by employing a\nsemi-supervised machine learning procedure. After training an unsupervised\nneural network to solve the SAIVR differential equations, a supervised\nframework then estimates the optimal conditions and parameters that best fit\nrecent infectious curves of 27 countries. Instructed by these results, we\nperformed an extensive study on the temporal evolution of the pandemic under\nvarying values of roll-out daily rates, vaccine efficacy, and a broad range of\nsocietal vaccine hesitancy/denial levels. The concept of herd immunity is\nquestioned by studying future scenarios which involve different vaccination\nefforts and more infectious Covid-19 variants.",
    "descriptor": "",
    "authors": [
      "Mattia Angeli",
      "Georgios Neofotistos",
      "Marios Mattheakis",
      "Efthimios Kaxiras"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13908"
  },
  {
    "id": "arXiv:2108.13914",
    "title": "On the interpretation of black-box default prediction models: an Italian  Small and Medium Enterprises case",
    "abstract": "Academic research and the financial industry have recently paid great\nattention to Machine Learning algorithms due to their power to solve complex\nlearning tasks. In the field of firms' default prediction, however, the lack of\ninterpretability has prevented the extensive adoption of the black-box type of\nmodels. To overcome this drawback and maintain the high performances of\nblack-boxes, this paper relies on a model-agnostic approach. Accumulated Local\nEffects and Shapley values are used to shape the predictors' impact on the\nlikelihood of default and rank them according to their contribution to the\nmodel outcome. Prediction is achieved by two Machine Learning algorithms\n(eXtreme Gradient Boosting and FeedForward Neural Network) compared with three\nstandard discriminant models. Results show that our analysis of the Italian\nSmall and Medium Enterprises manufacturing industry benefits from the overall\nhighest classification power by the eXtreme Gradient Boosting algorithm without\ngiving up a rich interpretation framework.",
    "descriptor": "",
    "authors": [
      "Lisa Crosato",
      "Caterina Liberati",
      "Marco Repetto"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2108.13914"
  },
  {
    "id": "arXiv:2108.13947",
    "title": "Decision Tree-Based Predictive Models for Academic Achievement Using  College Students' Support Networks",
    "abstract": "In this study, we examine a set of primary data collected from 484 students\nenrolled in a large public university in the Mid-Atlantic United States region\nduring the early stages of the COVID-19 pandemic. The data, called Ties data,\nincluded students' demographic and support network information. The support\nnetwork data comprised of information that highlighted the type of support,\n(i.e. emotional or educational; routine or intense). Using this data set,\nmodels for predicting students' academic achievement, quantified by their\nself-reported GPA, were created using Chi-Square Automatic Interaction\nDetection (CHAID), a decision tree algorithm, and cforest, a random forest\nalgorithm that uses conditional inference trees. We compare the methods'\naccuracy and variation in the set of important variables suggested by each\nalgorithm. Each algorithm found different variables important for different\nstudent demographics with some overlap. For White students, different types of\neducational support were important in predicting academic achievement, while\nfor non-White students, different types of emotional support were important in\npredicting academic achievement. The presence of differing types of routine\nsupport were important in predicting academic achievement for cisgender women,\nwhile differing types of intense support were important in predicting academic\nachievement for cisgender men.",
    "descriptor": "",
    "authors": [
      "Anthony Frazier",
      "Joethi Silva",
      "Rachel Meilak",
      "Indranil Sahoo",
      "David Chan",
      "Michael Broda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13947"
  },
  {
    "id": "arXiv:2108.13963",
    "title": "Clustering of Pain Dynamics in Sickle Cell Disease from Sparse, Uneven  Samples",
    "abstract": "Irregularly sampled time series data are common in a variety of fields. Many\ntypical methods for drawing insight from data fail in this case. Here we\nattempt to generalize methods for clustering trajectories to irregularly and\nsparsely sampled data. We first construct synthetic data sets, then propose and\nassess four methods of data alignment to allow for application of spectral\nclustering. We also repeat the same process for real data drawn from medical\nrecords of patients with sickle cell disease -- patients whose subjective\nexperiences of pain were tracked for several months via a mobile app.\nWe find that different methods for aligning irregularly sampled sparse data\nsets can lead to different optimal numbers of clusters, even for synthetic data\nwith known properties. For the case of sickle cell disease, we find that three\nclusters is a reasonable choice, and these appear to correspond to (1) a low\npain group with occasionally acute pain, (2) a group which experiences moderate\nmean pain that fluctuates often from low to high, and (3) a group that\nexperiences persistent high levels of pain.\nOur results may help physicians and patients better understand and manage\npatients' pain levels over time, and we expect that the methods we develop will\napply to a wide range of other data sources in medicine and beyond.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Gary K. Nave Jr.",
      "Swati Padhee",
      "Amanuel Alambo",
      "Tanvi Banerjee",
      "Nirmish Shah",
      "Daniel M. Abrams"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13963"
  },
  {
    "id": "arXiv:2108.13979",
    "title": "Toward AI-enhanced online-characterization and shaping of ultrashort  X-ray free-electron laser pulses",
    "abstract": "X-ray free-electron lasers (XFELs) as the world`s most brilliant light\nsources provide ultrashort X-ray pulses with durations typically on the order\nof femtoseconds. Recently, they have approached and entered the attosecond\nregime, which holds new promises for single-molecule imaging and studying\nnonlinear and ultrafast phenomena like localized electron dynamics. The\ntechnological evolution of XFELs toward well-controllable light sources for\nprecise metrology of ultrafast processes was, however, hampered by the\ndiagnostic capabilities for characterizing X-ray pulses at the attosecond\nfrontier. In this regard, the spectroscopic technique of photoelectron angular\nstreaking has successfully proven how to non-destructively retrieve the exact\ntime-energy structure of XFEL pulses on a single-shot basis. By using\nartificial intelligence algorithms, in particular convolutional neural\nnetworks, we here show how this technique can be leveraged from its\nproof-of-principle stage toward routine diagnostics at XFELs, thus enhancing\nand refining their scientific access in all related disciplines.",
    "descriptor": "",
    "authors": [
      "Kristina Dingel",
      "Thorsten Otto",
      "Lutz Marder",
      "Lars Funke",
      "Arne Held",
      "Sara Savio",
      "Andreas Hans",
      "Gregor Hartmann",
      "David Meier",
      "Jens Viefhaus",
      "Bernhard Sick",
      "Arno Ehresmann",
      "Markus Ilchen",
      "Wolfram Helml"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Artificial Intelligence (cs.AI)",
      "Accelerator Physics (physics.acc-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2108.13979"
  },
  {
    "id": "arXiv:2108.13984",
    "title": "A Subsampling Based Method for Causal Discovery on Discrete Data",
    "abstract": "Inferring causal directions on discrete and categorical data is an important\nyet challenging problem. Even though the additive noise models (ANMs) approach\ncan be adapted to the discrete data, the functional structure assumptions make\nit not applicable on categorical data. Inspired by the principle that the cause\nand mechanism are independent, various methods have been developed, leveraging\nindependence tests such as the distance correlation measure. In this work, we\ntake an alternative perspective and propose a subsampling-based method to test\nthe independence between the generating schemes of the cause and that of the\nmechanism. Our methodology works for both discrete and categorical data and\ndoes not imply any functional model on the data, making it a more flexible\napproach. To demonstrate the efficacy of our methodology, we compare it with\nexisting baselines over various synthetic data and real data experiments.",
    "descriptor": "\nComments: Accepted to the 2021 IEEE Statistical Signal Processing Workshop\n",
    "authors": [
      "Austin Goddard",
      "Yu Xiang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13984"
  },
  {
    "id": "arXiv:2108.13987",
    "title": "OARnet: Automated organs-at-risk delineation in Head and Neck CT images",
    "abstract": "A 3D deep learning model (OARnet) is developed and used to delineate 28 H&N\nOARs on CT images. OARnet utilizes a densely connected network to detect the\nOAR bounding-box, then delineates the OAR within the box. It reuses information\nfrom any layer to subsequent layers and uses skip connections to combine\ninformation from different dense block levels to progressively improve\ndelineation accuracy. Training uses up to 28 expert manual delineated (MD) OARs\nfrom 165 CTs. Dice similarity coefficient (DSC) and the 95th percentile\nHausdorff distance (HD95) with respect to MD is assessed for 70 other CTs.\nMean, maximum, and root-mean-square dose differences with respect to MD are\nassessed for 56 of the 70 CTs. OARnet is compared with UaNet, AnatomyNet, and\nMulti-Atlas Segmentation (MAS). Wilcoxon signed-rank tests using 95% confidence\nintervals are used to assess significance. Wilcoxon signed ranked tests show\nthat, compared with UaNet, OARnet improves (p<0.05) the DSC (23/28 OARs) and\nHD95 (17/28). OARnet outperforms both AnatomyNet and MAS for DSC (28/28) and\nHD95 (27/28). Compared with UaNet, OARnet improves median DSC up to 0.05 and\nHD95 up to 1.5mm. Compared with AnatomyNet and MAS, OARnet improves median\n(DSC, HD95) by up to (0.08, 2.7mm) and (0.17, 6.3mm). Dosimetrically, OARnet\noutperforms UaNet (Dmax 7/28; Dmean 10/28), AnatomyNet (Dmax 21/28; Dmean\n24/28), and MAS (Dmax 22/28; Dmean 21/28). The DenseNet architecture is\noptimized using a hybrid approach that performs OAR-specific bounding box\ndetection followed by feature recognition. Compared with other auto-delineation\nmethods, OARnet is better than or equal to UaNet for all but one geometric\n(Temporal Lobe L, HD95) and one dosimetric (Eye L, mean dose) endpoint for the\n28 H&N OARs, and is better than or equal to both AnatomyNet and MAS for all\nOARs.",
    "descriptor": "",
    "authors": [
      "Mumtaz Hussain Soomro",
      "Hamidreza Nourzadeh",
      "Victor Gabriel Leandro Alves",
      "Wookjin Choi",
      "Jeffrey V. Siebers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.13987"
  },
  {
    "id": "arXiv:2108.13992",
    "title": "Bayesian learning of forest and tree graphical models",
    "abstract": "In Bayesian learning of Gaussian graphical model structure, it is common to\nrestrict attention to certain classes of graphs and approximate the posterior\ndistribution by repeatedly moving from one graph to another, using MCMC or\nmethods such as stochastic shotgun search (SSS). I give two corrected versions\nof an algorithm for non-decomposable graphs and discuss random graph\ndistributions, in particular as prior distributions. The main topic of the\nthesis is Bayesian structure-learning with forests or trees. Restricting\nattention to these graphs can be justified using theorems on random graphs. I\ndescribe how to use the Chow$\\unicode{x2013}$Liu algorithm and the Matrix Tree\nTheorem to find the MAP forest and certain quantities in the posterior\ndistribution on trees. I give adapted versions of MCMC and SSS for\napproximating the posterior distribution for forests and trees, and systems for\nstoring these graphs so that it is easy to choose moves to neighbouring graphs.\nExperiments show that SSS with trees does well when the true graph is a tree or\nsparse graph. SSS with trees or forests does better than SSS with decomposable\ngraphs in certain cases. Graph priors improve detection of hubs but need large\nranges of probabilities. MCMC on forests fails to mix well and MCMC on trees is\nslower than SSS. (For a longer abstract see the thesis.)",
    "descriptor": "\nComments: PhD thesis, 2013, University of Bristol; 148 pages, 24 figures\n",
    "authors": [
      "Edmund Jones"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13992"
  },
  {
    "id": "arXiv:1502.07549",
    "title": "Model-checking branching-time properties of probabilistic automata and  probabilistic one-counter automata",
    "abstract": "Comments: This paper is no interesting today from the author's viewpoint, so withdrawn",
    "descriptor": "\nComments: This paper is no interesting today from the author's viewpoint, so withdrawn\n",
    "authors": [
      "T. Lin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/1502.07549"
  },
  {
    "id": "arXiv:1505.02213",
    "title": "Measuring dependence powerfully and equitably",
    "abstract": "Comments: YAR and DNR are co-first authors, PCS and MMM are co-last authors. This paper, together with arXiv:1505.02212, subsumes arXiv:1408.4908. v3 includes new analyses and exposition. v4 is identical to v3 except for this comment. An error was found in the argument showing the consistency of the MIC estimator; see arXiv:2107.03836 for discussion and a corrected argument",
    "descriptor": "\nComments: YAR and DNR are co-first authors, PCS and MMM are co-last authors. This paper, together with arXiv:1505.02212, subsumes arXiv:1408.4908. v3 includes new analyses and exposition. v4 is identical to v3 except for this comment. An error was found in the argument showing the consistency of the MIC estimator; see arXiv:2107.03836 for discussion and a corrected argument\n",
    "authors": [
      "Yakir A. Reshef",
      "David N. Reshef",
      "Hilary K. Finucane",
      "Pardis C. Sabeti",
      "Michael M. Mitzenmacher"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1505.02213"
  },
  {
    "id": "arXiv:1706.05225",
    "title": "Minimum Reload Cost Cycle Cover in Complete Graphs",
    "abstract": "Comments: This work is supported by TUBITAK-CNRS under grant no. 114E731",
    "descriptor": "\nComments: This work is supported by TUBITAK-CNRS under grant no. 114E731\n",
    "authors": [
      "Yasemin B\u00fcy\u00fck\u00e7olak",
      "Didem G\u00f6z\u00fcpek",
      "Sibel \u00d6zkan"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1706.05225"
  },
  {
    "id": "arXiv:1805.08357",
    "title": "Multi-UAV Cooperative Trajectory for Servicing Dynamic Demands and  Charging Battery",
    "abstract": "Multi-UAV Cooperative Trajectory for Servicing Dynamic Demands and  Charging Battery",
    "descriptor": "",
    "authors": [
      "Kai Wang",
      "Xiao Zhang",
      "Lingjie Duan",
      "Jun Tie"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/1805.08357"
  },
  {
    "id": "arXiv:1901.07865",
    "title": "Cooperative coevolution of real predator robots and virtual robots in  the pursuit domain",
    "abstract": "Cooperative coevolution of real predator robots and virtual robots in  the pursuit domain",
    "descriptor": "",
    "authors": [
      "Lijun Sun",
      "Chao Lyu",
      "Yuhui Shi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/1901.07865"
  },
  {
    "id": "arXiv:1905.11240",
    "title": "HUMBO: Bridging Response Generation and Facial Expression Synthesis",
    "abstract": "Comments: The first two authors contributed to this work equally",
    "descriptor": "\nComments: The first two authors contributed to this work equally\n",
    "authors": [
      "Shang-Yu Su",
      "Po-Wei Lin",
      "Yun-Nung Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/1905.11240"
  },
  {
    "id": "arXiv:1908.08483",
    "title": "Improved bounds for the sunflower lemma",
    "abstract": "Comments: Took into account comments from the Annals of Mathematics",
    "descriptor": "\nComments: Took into account comments from the Annals of Mathematics\n",
    "authors": [
      "Ryan Alweiss",
      "Shachar Lovett",
      "Kewen Wu",
      "Jiapeng Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1908.08483"
  },
  {
    "id": "arXiv:1911.10364",
    "title": "Universal Adversarial Robustness of Texture and Shape-Biased Models",
    "abstract": "Comments: In Proceedings of the 28th IEEE International Conference on Image Processing (ICIP 2021), code available at: this https URL",
    "descriptor": "\nComments: In Proceedings of the 28th IEEE International Conference on Image Processing (ICIP 2021), code available at: this https URL\n",
    "authors": [
      "Kenneth T. Co",
      "Luis Mu\u00f1oz-Gonz\u00e1lez",
      "Leslie Kanthan",
      "Ben Glocker",
      "Emil C. Lupu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1911.10364"
  },
  {
    "id": "arXiv:1912.02572",
    "title": "Dynamic Pricing on E-commerce Platform with Deep Reinforcement Learning:  A Field Experiment",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Jiaxi Liu",
      "Yidong Zhang",
      "Xiaoqing Wang",
      "Yuming Deng",
      "Xingyu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.02572"
  },
  {
    "id": "arXiv:1912.03437",
    "title": "Early Prediction for Merged vs Abandoned Code Changes in Modern Code  Reviews",
    "abstract": "Early Prediction for Merged vs Abandoned Code Changes in Modern Code  Reviews",
    "descriptor": "",
    "authors": [
      "Md. Khairul Islam",
      "Toufique Ahmed",
      "Rifat Shahriyar",
      "Anindya Iqbal",
      "Gias Uddin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.03437"
  },
  {
    "id": "arXiv:1912.10340",
    "title": "Bandit Multiclass Linear Classification for the Group Linear Separable  Case",
    "abstract": "Comments: This work is first published in iSAI-NLP 2019, Chiang Mai, Thailand. This version contains larger experiments and fixes calculation errors",
    "descriptor": "\nComments: This work is first published in iSAI-NLP 2019, Chiang Mai, Thailand. This version contains larger experiments and fixes calculation errors\n",
    "authors": [
      "Jittat Fakcharoenphol",
      "Chayutpong Prompak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.10340"
  },
  {
    "id": "arXiv:2001.04420",
    "title": "FASTER: Fast and Safe Trajectory Planner for Navigation in Unknown  Environments",
    "abstract": "Comments: This paper has been accepted for publication in IEEE Transactions on Robotics. arXiv admin note: text overlap with arXiv:1903.03558",
    "descriptor": "\nComments: This paper has been accepted for publication in IEEE Transactions on Robotics. arXiv admin note: text overlap with arXiv:1903.03558\n",
    "authors": [
      "Jesus Tordesillas",
      "Brett T. Lopez",
      "Michael Everett",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2001.04420"
  },
  {
    "id": "arXiv:2002.11219",
    "title": "Convex Geometry and Duality of Over-parameterized Neural Networks",
    "abstract": "Comments: Accepted to the Journal of Machine Learning Research (JMLR)",
    "descriptor": "\nComments: Accepted to the Journal of Machine Learning Research (JMLR)\n",
    "authors": [
      "Tolga Ergen",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.11219"
  },
  {
    "id": "arXiv:2003.03664",
    "title": "Quasi-random words and limits of word sequences",
    "abstract": "Quasi-random words and limits of word sequences",
    "descriptor": "",
    "authors": [
      "Hi\u00eap H\u00e0n",
      "Marcos Kiwi",
      "Mat\u00edas Pavez-Sign\u00e9"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2003.03664"
  },
  {
    "id": "arXiv:2003.12296",
    "title": "Generalizable Model-agnostic Semantic Segmentation via Target-specific  Normalization",
    "abstract": "Comments: Accepted by Pattern Recognition (PR)",
    "descriptor": "\nComments: Accepted by Pattern Recognition (PR)\n",
    "authors": [
      "Jian Zhang",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2003.12296"
  },
  {
    "id": "arXiv:2004.00759",
    "title": "Safe Zero-Shot Model-Based Learning and Control: A Wasserstein  Distributionally Robust Approach",
    "abstract": "Safe Zero-Shot Model-Based Learning and Control: A Wasserstein  Distributionally Robust Approach",
    "descriptor": "",
    "authors": [
      "Aaron Kandel",
      "Scott J. Moura"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2004.00759"
  },
  {
    "id": "arXiv:2004.06243",
    "title": "Physics-Incorporated Convolutional Recurrent Neural Networks for Source  Identification and Forecasting of Dynamical Systems",
    "abstract": "Comments: 15 pages, 16 figures. This manuscript has been accepted for publication in Neural Networks",
    "descriptor": "\nComments: 15 pages, 16 figures. This manuscript has been accepted for publication in Neural Networks\n",
    "authors": [
      "Priyabrata Saha",
      "Saurabh Dash",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.06243"
  },
  {
    "id": "arXiv:2004.06698",
    "title": "Reasoning Visual Dialog with Sparse Graph Learning and Knowledge  Transfer",
    "abstract": "Comments: EMNLP 2021 Findings",
    "descriptor": "\nComments: EMNLP 2021 Findings\n",
    "authors": [
      "Gi-Cheon Kang",
      "Junseok Park",
      "Hwaran Lee",
      "Byoung-Tak Zhang",
      "Jin-Hwa Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2004.06698"
  },
  {
    "id": "arXiv:2004.08025",
    "title": "STT-CBS: A Conflict-Based Search Algorithm for Multi-Agent Path Finding  with Stochastic Travel Times",
    "abstract": "STT-CBS: A Conflict-Based Search Algorithm for Multi-Agent Path Finding  with Stochastic Travel Times",
    "descriptor": "",
    "authors": [
      "Oriana Peltzer",
      "Kyle Brown",
      "Mac Schwager",
      "Mykel J. Kochenderfer",
      "Martin Sehr"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2004.08025"
  },
  {
    "id": "arXiv:2004.12919",
    "title": "First return, then explore",
    "abstract": "Comments: 84 pages, 25 figures, 5 tables, 3 algorithms; reorganized sections and modified SI text extensively; added reference to the published version, changed title to published title; updated entire article to match the published version; added reference to published version again",
    "descriptor": "\nComments: 84 pages, 25 figures, 5 tables, 3 algorithms; reorganized sections and modified SI text extensively; added reference to the published version, changed title to published title; updated entire article to match the published version; added reference to published version again\n",
    "authors": [
      "Adrien Ecoffet",
      "Joost Huizinga",
      "Joel Lehman",
      "Kenneth O. Stanley",
      "Jeff Clune"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2004.12919"
  },
  {
    "id": "arXiv:2005.02324",
    "title": "Neural CRF Model for Sentence Alignment in Text Simplification",
    "abstract": "Comments: The paper has been accepted to ACL 2020",
    "descriptor": "\nComments: The paper has been accepted to ACL 2020\n",
    "authors": [
      "Chao Jiang",
      "Mounica Maddela",
      "Wuwei Lan",
      "Yang Zhong",
      "Wei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2005.02324"
  },
  {
    "id": "arXiv:2005.11671",
    "title": "Arms Race in Adversarial Malware Detection: A Survey",
    "abstract": "Comments: 35 pages, 5 figures",
    "descriptor": "\nComments: 35 pages, 5 figures\n",
    "authors": [
      "Deqiang Li",
      "Qianmu Li",
      "Yanfang Ye",
      "Shouhuai Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.11671"
  },
  {
    "id": "arXiv:2005.13189",
    "title": "Decentralized Optimization On Time-Varying Directed Graphs Under  Communication Constraints",
    "abstract": "Decentralized Optimization On Time-Varying Directed Graphs Under  Communication Constraints",
    "descriptor": "",
    "authors": [
      "Yiyue Chen",
      "Abolfazl Hashemi",
      "Haris Vikalo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2005.13189"
  },
  {
    "id": "arXiv:2006.01236",
    "title": "Aperiodicity, Star-freeness, and First-order Definability of Structured  Context-Free Languages",
    "abstract": "Comments: We added an improved background, with a gentler presentation of Operator Precedence Languages",
    "descriptor": "\nComments: We added an improved background, with a gentler presentation of Operator Precedence Languages\n",
    "authors": [
      "Dino Mandrioli",
      "Matteo Pradella",
      "Stefano Crespi Reghizzi"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2006.01236"
  },
  {
    "id": "arXiv:2006.05433",
    "title": "A program for the full axiom of choice",
    "abstract": "A program for the full axiom of choice",
    "descriptor": "",
    "authors": [
      "Jean-Louis Krivine"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2006.05433"
  },
  {
    "id": "arXiv:2006.08801",
    "title": "Analysis of parallel Schwarz algorithms for time-harmonic problems using  block Toeplitz matrices",
    "abstract": "Analysis of parallel Schwarz algorithms for time-harmonic problems using  block Toeplitz matrices",
    "descriptor": "",
    "authors": [
      "Niall Bootland",
      "Victorita Dolean",
      "Alexandros Kyriakis",
      "Jennifer Pestana"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.08801"
  },
  {
    "id": "arXiv:2007.00862",
    "title": "Noticing Motion Patterns: Temporal CNN with a Novel Convolution Operator  for Human Trajectory Prediction",
    "abstract": "Comments: Published by IEEE Robotics and Automation Letters (RA-L) (this https URL)",
    "descriptor": "\nComments: Published by IEEE Robotics and Automation Letters (RA-L) (this https URL)\n",
    "authors": [
      "Dapeng Zhao",
      "Jean Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2007.00862"
  },
  {
    "id": "arXiv:2007.01002",
    "title": "DeepOPF: A Feasibility-Optimized Deep Neural Network Approach for AC  Optimal Power Flow Problems",
    "abstract": "Comments: 12 pages, 2 figures",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Xiang Pan",
      "Minghua Chen",
      "Tianyu Zhao",
      "Steven H. Low"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.01002"
  },
  {
    "id": "arXiv:2007.03502",
    "title": "srMO-BO-3GP: A sequential regularized multi-objective constrained  Bayesian optimization for design applications",
    "abstract": "srMO-BO-3GP: A sequential regularized multi-objective constrained  Bayesian optimization for design applications",
    "descriptor": "",
    "authors": [
      "Anh Tran",
      "Mike Eldred",
      "Scott McCann",
      "Yan Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2007.03502"
  },
  {
    "id": "arXiv:2008.07191",
    "title": "Deep Variational Generative Models for Audio-visual Speech Separation",
    "abstract": "Comments: Accepted to the 31st IEEE International Workshop on Machine Learning for Signal Processing (MLSP), Oct. 25-28, 2021, Gold Coast, Queensland, Australia",
    "descriptor": "\nComments: Accepted to the 31st IEEE International Workshop on Machine Learning for Signal Processing (MLSP), Oct. 25-28, 2021, Gold Coast, Queensland, Australia\n",
    "authors": [
      "Viet-Nhat Nguyen",
      "Mostafa Sadeghi",
      "Elisa Ricci",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2008.07191"
  },
  {
    "id": "arXiv:2008.08530",
    "title": "The Transpension Type: Technical Report",
    "abstract": "Comments: 44 pages, 1 figure. Changes: {\\S}2.3.3 new result prop 2.3.4 {\\S}2.3.5 fix some theorems about fullness. Added {\\S}2.3.6 {\\S}3-4 indirect (original) vs direct example 3.3.9 not connection-free example 3.3.10 require pushouts pushouts. prop 4.2.1 Remove wrong clauses. Ultimate results unchanged. {\\S}6 Cleanup theorems and proofs",
    "descriptor": "\nComments: 44 pages, 1 figure. Changes: {\\S}2.3.3 new result prop 2.3.4 {\\S}2.3.5 fix some theorems about fullness. Added {\\S}2.3.6 {\\S}3-4 indirect (original) vs direct example 3.3.9 not connection-free example 3.3.10 require pushouts pushouts. prop 4.2.1 Remove wrong clauses. Ultimate results unchanged. {\\S}6 Cleanup theorems and proofs\n",
    "authors": [
      "Andreas Nuyts"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2008.08530"
  },
  {
    "id": "arXiv:2008.11009",
    "title": "Protect, Show, Attend and Tell: Empowering Image Captioning Models with  Ownership Protection",
    "abstract": "Comments: Accepted at Pattern Recognition, 17 pages",
    "descriptor": "\nComments: Accepted at Pattern Recognition, 17 pages\n",
    "authors": [
      "Jian Han Lim",
      "Chee Seng Chan",
      "Kam Woh Ng",
      "Lixin Fan",
      "Qiang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2008.11009"
  },
  {
    "id": "arXiv:2008.13336",
    "title": "Shape Defense Against Adversarial Attacks",
    "abstract": "Shape Defense Against Adversarial Attacks",
    "descriptor": "",
    "authors": [
      "Ali Borji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.13336"
  },
  {
    "id": "arXiv:2009.01454",
    "title": "Learning Fair Graph Neural Networks with Limited and Private Sensitive  Attribute Information",
    "abstract": "Learning Fair Graph Neural Networks with Limited and Private Sensitive  Attribute Information",
    "descriptor": "",
    "authors": [
      "Enyan Dai",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.01454"
  },
  {
    "id": "arXiv:2009.02798",
    "title": "CSI-Based Multi-Antenna and Multi-Point Indoor Positioning Using  Probability Fusion",
    "abstract": "Comments: To appear in the IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: To appear in the IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Emre G\u00f6n\u00fclta\u015f",
      "Eric Lei",
      "Jack Langerman",
      "Howard Huang",
      "Christoph Studer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2009.02798"
  },
  {
    "id": "arXiv:2009.09541",
    "title": "Foundations",
    "abstract": "Comments: For the forthcoming Handbook of Proof Assistants and Their Applications in Mathematics and Computer Science, edited by Jasmin Blanchette and Assia Mahboubi",
    "descriptor": "\nComments: For the forthcoming Handbook of Proof Assistants and Their Applications in Mathematics and Computer Science, edited by Jasmin Blanchette and Assia Mahboubi\n",
    "authors": [
      "Jeremy Avigad"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2009.09541"
  },
  {
    "id": "arXiv:2009.14381",
    "title": "AutoDSE: Enabling Software Programmers to Design Efficient FPGA  Accelerators",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Atefeh Sohrabizadeh",
      "Cody Hao Yu",
      "Min Gao",
      "Jason Cong"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2009.14381"
  },
  {
    "id": "arXiv:2010.12081",
    "title": "Singularity of random integer matrices with large entries",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Sankeerth Rao Karingula",
      "Shachar Lovett"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2010.12081"
  },
  {
    "id": "arXiv:2011.03030",
    "title": "Fast Rates for Contextual Linear Optimization",
    "abstract": "Fast Rates for Contextual Linear Optimization",
    "descriptor": "",
    "authors": [
      "Yichun Hu",
      "Nathan Kallus",
      "Xiaojie Mao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2011.03030"
  },
  {
    "id": "arXiv:2011.03334",
    "title": "Occlusion-Aware Search for Object Retrieval in Clutter",
    "abstract": "Occlusion-Aware Search for Object Retrieval in Clutter",
    "descriptor": "",
    "authors": [
      "Wissam Bejjani",
      "Wisdom C. Agboh",
      "Mehmet R. Dogar",
      "Matteo Leonetti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.03334"
  },
  {
    "id": "arXiv:2011.03907",
    "title": "Multiscale Reduced-Order Modeling of a Titanium Skin Panel Subjected to  Thermo-Mechanical Loading",
    "abstract": "Comments: 25 pages, 11 figures",
    "descriptor": "\nComments: 25 pages, 11 figures\n",
    "authors": [
      "Xiang Zhang",
      "Yang Liu",
      "Caglar Oskay"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2011.03907"
  },
  {
    "id": "arXiv:2011.04193",
    "title": "Micron-level Optimal Obstacle-avoidance Trajectory Planning for a  Free-floating Space Robot with Predefined-time Convergence",
    "abstract": "Comments: There are huge mistakes in this article, which need to be corrected. The data of the article need to be modified and the theory needs to be rebuilt. The corrected article will be submitted in the future",
    "descriptor": "\nComments: There are huge mistakes in this article, which need to be corrected. The data of the article need to be modified and the theory needs to be rebuilt. The corrected article will be submitted in the future\n",
    "authors": [
      "Wen Yan",
      "Yicheng Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.04193"
  },
  {
    "id": "arXiv:2012.06103",
    "title": "Fairness-Oriented Multiple RISs-Aided MmWave Transmission: Stochastic  Optimization Methods",
    "abstract": "Comments: Keywords: Reconfigurable intelligent surface (RIS), intelligent reflecting surface (IRS)",
    "descriptor": "\nComments: Keywords: Reconfigurable intelligent surface (RIS), intelligent reflecting surface (IRS)\n",
    "authors": [
      "Gui Zhou",
      "Cunhua Pan",
      "Hong Ren",
      "Kezhi Wang",
      "Marco Di Renzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2012.06103"
  },
  {
    "id": "arXiv:2012.06757",
    "title": "Blindfolded Attackers Still Threatening: Strict Black-Box Adversarial  Attacks on Graphs",
    "abstract": "Blindfolded Attackers Still Threatening: Strict Black-Box Adversarial  Attacks on Graphs",
    "descriptor": "",
    "authors": [
      "Jiarong Xu",
      "Yizhou Sun",
      "Xin Jiang",
      "Yanhao Wang",
      "Yang Yang",
      "Chunping Wang",
      "Jiangang Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2012.06757"
  },
  {
    "id": "arXiv:2012.09359",
    "title": "Speech Enhancement with Zero-Shot Model Selection",
    "abstract": "Comments: Accepted in EUSIPCO 2021",
    "descriptor": "\nComments: Accepted in EUSIPCO 2021\n",
    "authors": [
      "Ryandhimas E. Zezario",
      "Chiou-Shann Fuh",
      "Hsin-Min Wang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2012.09359"
  },
  {
    "id": "arXiv:2012.14756",
    "title": "Dialogue Response Selection with Hierarchical Curriculum Learning",
    "abstract": "Comments: Accepted as long paper to the main conference of ACL2021",
    "descriptor": "\nComments: Accepted as long paper to the main conference of ACL2021\n",
    "authors": [
      "Yixuan Su",
      "Deng Cai",
      "Qingyu Zhou",
      "Zibo Lin",
      "Simon Baker",
      "Yunbo Cao",
      "Shuming Shi",
      "Nigel Collier",
      "Yan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.14756"
  },
  {
    "id": "arXiv:2101.08331",
    "title": "A posteriori error estimates for hierarchical mixed-dimensional elliptic  equations",
    "abstract": "A posteriori error estimates for hierarchical mixed-dimensional elliptic  equations",
    "descriptor": "",
    "authors": [
      "Jhabriel Varela",
      "Elyes Ahmed",
      "Eirik Keilegavlen",
      "Jan Martin Nordbotten",
      "Florin Adrian Radu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.08331"
  },
  {
    "id": "arXiv:2101.08387",
    "title": "A Survey on Ensemble Learning under the Era of Deep Learning",
    "abstract": "Comments: 42 pages, 9 figures, 15 tables",
    "descriptor": "\nComments: 42 pages, 9 figures, 15 tables\n",
    "authors": [
      "Yongquan Yang",
      "Haijun Lv",
      "Ning Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.08387"
  },
  {
    "id": "arXiv:2101.09552",
    "title": "Stochastic Image Denoising by Sampling from the Posterior Distribution",
    "abstract": "Stochastic Image Denoising by Sampling from the Posterior Distribution",
    "descriptor": "",
    "authors": [
      "Bahjat Kawar",
      "Gregory Vaksman",
      "Michael Elad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.09552"
  },
  {
    "id": "arXiv:2101.09840",
    "title": "TLRM: Task-level Relation Module for GNN-based Few-Shot Learning",
    "abstract": "Comments: VCIP 2021. arXiv admin note: substantial text overlap with arXiv:2101.08527",
    "descriptor": "\nComments: VCIP 2021. arXiv admin note: substantial text overlap with arXiv:2101.08527\n",
    "authors": [
      "Yurong Guo",
      "Zhanyu Ma",
      "Xiaoxu Li",
      "Yuan Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.09840"
  },
  {
    "id": "arXiv:2102.01496",
    "title": "Gaussian Experts Selection using Graphical Models",
    "abstract": "Gaussian Experts Selection using Graphical Models",
    "descriptor": "",
    "authors": [
      "Hamed Jalali",
      "Martin Pawelczyk",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.01496"
  },
  {
    "id": "arXiv:2102.05716",
    "title": "Auctus: A Dataset Search Engine for Data Augmentation",
    "abstract": "Auctus: A Dataset Search Engine for Data Augmentation",
    "descriptor": "",
    "authors": [
      "Sonia Castelo",
      "R\u00e9mi Rampin",
      "A\u00e9cio Santos",
      "Aline Bessa",
      "Fernando Chirigati",
      "Juliana Freire"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2102.05716"
  },
  {
    "id": "arXiv:2102.06254",
    "title": "Securing RPL using Network Coding: The Chained Secure Mode (CSM)",
    "abstract": "Comments: 11 pages, 21 figures, 2 tables, Accepted for publication at the IEEE IoT Journal for review. This is an significantly extended version of arXiv:2006.00310 which was published in NCA 2020 (available at IEEExplore)",
    "descriptor": "\nComments: 11 pages, 21 figures, 2 tables, Accepted for publication at the IEEE IoT Journal for review. This is an significantly extended version of arXiv:2006.00310 which was published in NCA 2020 (available at IEEExplore)\n",
    "authors": [
      "Ahmed Raoof",
      "Chung-Horng Lung",
      "Ashraf Matrawy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.06254"
  },
  {
    "id": "arXiv:2102.06408",
    "title": "Supervised training of spiking neural networks for robust deployment on  mixed-signal neuromorphic processors",
    "abstract": "Supervised training of spiking neural networks for robust deployment on  mixed-signal neuromorphic processors",
    "descriptor": "",
    "authors": [
      "Julian B\u00fcchel",
      "Dmitrii Zendrikov",
      "Sergio Solinas",
      "Giacomo Indiveri",
      "Dylan R. Muir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06408"
  },
  {
    "id": "arXiv:2102.06563",
    "title": "Querying collections of tree-structured records in the presence of  within-record referential constraints",
    "abstract": "Querying collections of tree-structured records in the presence of  within-record referential constraints",
    "descriptor": "",
    "authors": [
      "Foto N. Afrati",
      "Matthew Damigos"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2102.06563"
  },
  {
    "id": "arXiv:2102.06810",
    "title": "Understanding self-supervised Learning Dynamics without Contrastive  Pairs",
    "abstract": "Comments: ICML 2021 camera ready + Fix minor typo in Fig. 4",
    "descriptor": "\nComments: ICML 2021 camera ready + Fix minor typo in Fig. 4\n",
    "authors": [
      "Yuandong Tian",
      "Xinlei Chen",
      "Surya Ganguli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.06810"
  },
  {
    "id": "arXiv:2102.07053",
    "title": "Linear Convergence in Federated Learning: Tackling Client Heterogeneity  and Sparse Gradients",
    "abstract": "Comments: Compared to the previous version, this version contains an additional result pertaining to a general stochastic oracle model. It also includes additional comparisons of our algorithm and results with relevant existing works",
    "descriptor": "\nComments: Compared to the previous version, this version contains an additional result pertaining to a general stochastic oracle model. It also includes additional comparisons of our algorithm and results with relevant existing works\n",
    "authors": [
      "Aritra Mitra",
      "Rayana Jaafar",
      "George J. Pappas",
      "Hamed Hassani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.07053"
  },
  {
    "id": "arXiv:2102.09166",
    "title": "Latency Modeling of Hyperledger Fabric for Blockchain-enabled IoT  Networks",
    "abstract": "Comments: 11 pages, 10 figures, 2 tables; This paper has been submitted to IEEE Internet of Things Journal",
    "descriptor": "\nComments: 11 pages, 10 figures, 2 tables; This paper has been submitted to IEEE Internet of Things Journal\n",
    "authors": [
      "Sungho Lee",
      "Minsu Kim",
      "Jemin Lee",
      "Ruei-Hau Hsu",
      "Min-Soo Kim",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2102.09166"
  },
  {
    "id": "arXiv:2102.09777",
    "title": "Progressive Transformer-Based Generation of Radiology Reports",
    "abstract": "Comments: Accepted to findings of EMNLP 2021",
    "descriptor": "\nComments: Accepted to findings of EMNLP 2021\n",
    "authors": [
      "Farhad Nooralahzadeh",
      "Nicolas Perez Gonzalez",
      "Thomas Frauenfelder",
      "Koji Fujimoto",
      "Michael Krauthammer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.09777"
  },
  {
    "id": "arXiv:2102.11872",
    "title": "Dont Just Divide; Polarize and Conquer!",
    "abstract": "Comments: 13 Pages, 7 figures",
    "descriptor": "\nComments: 13 Pages, 7 figures\n",
    "authors": [
      "Shivin Srivastava",
      "Siddharth Bhatia",
      "Lingxiao Huang",
      "Lim Jun Heng",
      "Kenji Kawaguchi",
      "Vaibhav Rajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.11872"
  },
  {
    "id": "arXiv:2103.01551",
    "title": "Signal recovery from a few linear measurements of its high-order spectra",
    "abstract": "Signal recovery from a few linear measurements of its high-order spectra",
    "descriptor": "",
    "authors": [
      "Tamir Bendory",
      "Dan Edidin",
      "Shay Kreymer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2103.01551"
  },
  {
    "id": "arXiv:2103.02182",
    "title": "Distributed statistical inference with pyhf enabled through funcX",
    "abstract": "Comments: 10 pages, 2 figures, 2 listings, 1 table, presented at the 25th International Conference on Computing in High Energy & Nuclear Physics",
    "descriptor": "\nComments: 10 pages, 2 figures, 2 listings, 1 table, presented at the 25th International Conference on Computing in High Energy & Nuclear Physics\n",
    "authors": [
      "Matthew Feickert",
      "Lukas Heinrich",
      "Giordon Stark",
      "Ben Galewsky"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2103.02182"
  },
  {
    "id": "arXiv:2103.05690",
    "title": "Multitask 3D CBCT-to-CT Translation and Organs-at-Risk Segmentation  Using Physics-Based Data Augmentation",
    "abstract": "Comments: Medical Physics 2021",
    "descriptor": "\nComments: Medical Physics 2021\n",
    "authors": [
      "Navdeep Dahiya",
      "Sadegh R Alam",
      "Pengpeng Zhang",
      "Si-Yuan Zhang",
      "Anthony Yezzi",
      "Saad Nadeem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.05690"
  },
  {
    "id": "arXiv:2103.07899",
    "title": "GVINS: Tightly Coupled GNSS-Visual-Inertial Fusion for Smooth and  Consistent State Estimation",
    "abstract": "GVINS: Tightly Coupled GNSS-Visual-Inertial Fusion for Smooth and  Consistent State Estimation",
    "descriptor": "",
    "authors": [
      "Shaozu Cao",
      "Xiuyuan Lu",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.07899"
  },
  {
    "id": "arXiv:2103.08753",
    "title": "Adaptive Gradient Online Control",
    "abstract": "Adaptive Gradient Online Control",
    "descriptor": "",
    "authors": [
      "Deepan Muthirayan",
      "Jianjun Yuan",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.08753"
  },
  {
    "id": "arXiv:2103.11900",
    "title": "About an efficiency functional implementing the principle of least  effort",
    "abstract": "Comments: 22 pages, 5 figures",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "A. El Kaabouchi",
      "F.X. Machu",
      "R. Wang",
      "Y.Y. Zhu",
      "Q.A. Wang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.11900"
  },
  {
    "id": "arXiv:2104.01106",
    "title": "Personalizing image enhancement for critical visual tasks: improved  legibility of papyri using color processing and visual illusions",
    "abstract": "Comments: Article accepted for publication by the International Journal on Document Analysis and Recognition (IJDAR) on 2021.08.27. Open Source software accessible at this https URL Comments to version 2: Extendend Sections 3.2 Machine learning, 5.3.5 Comparisons and 6 Paradim; added supplemental material; other improvements throughout the article",
    "descriptor": "\nComments: Article accepted for publication by the International Journal on Document Analysis and Recognition (IJDAR) on 2021.08.27. Open Source software accessible at this https URL Comments to version 2: Extendend Sections 3.2 Machine learning, 5.3.5 Comparisons and 6 Paradim; added supplemental material; other improvements throughout the article\n",
    "authors": [
      "Vlad Atanasiu",
      "Isabelle Marthot-Santaniello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Digital Libraries (cs.DL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.01106"
  },
  {
    "id": "arXiv:2104.03772",
    "title": "(Integral-)ISS of switched and time-varying impulsive systems based on  global state weak linearization",
    "abstract": "Comments: Submitted to IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Jos\u00e9 L. Mancilla-Aguilar",
      "Hernan Haimovich"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.03772"
  },
  {
    "id": "arXiv:2104.03954",
    "title": "De-rendering the World's Revolutionary Artefacts",
    "abstract": "Comments: CVPR 2021. Project page: this https URL",
    "descriptor": "\nComments: CVPR 2021. Project page: this https URL\n",
    "authors": [
      "Shangzhe Wu",
      "Ameesh Makadia",
      "Jiajun Wu",
      "Noah Snavely",
      "Richard Tucker",
      "Angjoo Kanazawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2104.03954"
  },
  {
    "id": "arXiv:2104.05994",
    "title": "Fairness in Rankings and Recommendations: An Overview",
    "abstract": "Fairness in Rankings and Recommendations: An Overview",
    "descriptor": "",
    "authors": [
      "Evaggelia Pitoura",
      "Kostas Stefanidis",
      "Georgia Koutrika"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2104.05994"
  },
  {
    "id": "arXiv:2104.06979",
    "title": "TSDAE: Using Transformer-based Sequential Denoising Auto-Encoder for  Unsupervised Sentence Embedding Learning",
    "abstract": "Comments: Accepted at EMNLP 2021 Findings",
    "descriptor": "\nComments: Accepted at EMNLP 2021 Findings\n",
    "authors": [
      "Kexin Wang",
      "Nils Reimers",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.06979"
  },
  {
    "id": "arXiv:2104.07021",
    "title": "Dressing in Order: Recurrent Person Image Generation for Pose Transfer,  Virtual Try-on and Outfit Editing",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Aiyu Cui",
      "Daniel McKee",
      "Svetlana Lazebnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.07021"
  },
  {
    "id": "arXiv:2104.08315",
    "title": "Surface Form Competition: Why the Highest Probability Answer Isn't  Always Right",
    "abstract": "Surface Form Competition: Why the Highest Probability Answer Isn't  Always Right",
    "descriptor": "",
    "authors": [
      "Ari Holtzman",
      "Peter West",
      "Vered Shwartz",
      "Yejin Choi",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08315"
  },
  {
    "id": "arXiv:2104.08821",
    "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings",
    "abstract": "Comments: Accepted to EMNLP 2021. The code and pre-trained models are available at this https URL",
    "descriptor": "\nComments: Accepted to EMNLP 2021. The code and pre-trained models are available at this https URL\n",
    "authors": [
      "Tianyu Gao",
      "Xingcheng Yao",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08821"
  },
  {
    "id": "arXiv:2104.10201",
    "title": "Bayesian Optimization is Superior to Random Search for Machine Learning  Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020",
    "abstract": "Bayesian Optimization is Superior to Random Search for Machine Learning  Hyperparameter Tuning: Analysis of the Black-Box Optimization Challenge 2020",
    "descriptor": "",
    "authors": [
      "Ryan Turner",
      "David Eriksson",
      "Michael McCourt",
      "Juha Kiili",
      "Eero Laaksonen",
      "Zhen Xu",
      "Isabelle Guyon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.10201"
  },
  {
    "id": "arXiv:2104.12546",
    "title": "The Effects of Air Quality on the Spread of the COVID-19 Pandemic in  Italy: An Artificial Intelligence Approach",
    "abstract": "The Effects of Air Quality on the Spread of the COVID-19 Pandemic in  Italy: An Artificial Intelligence Approach",
    "descriptor": "",
    "authors": [
      "Andrea Loreggia",
      "Anna Passarelli",
      "Maria Silvia Pini"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.12546"
  },
  {
    "id": "arXiv:2104.12888",
    "title": "Backscatter-Assisted Wireless Powered Communication Networks Empowered  by Intelligent Reflecting Surface",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Parisa Ramezani",
      "Abbas Jamalipour"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.12888"
  },
  {
    "id": "arXiv:2104.13184",
    "title": "Efficient channel charting via phase-insensitive distance computation",
    "abstract": "Comments: IEEE Wireless Communications Letters, IEEE comsoc, In press",
    "descriptor": "\nComments: IEEE Wireless Communications Letters, IEEE comsoc, In press\n",
    "authors": [
      "Luc Le Magoarou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.13184"
  },
  {
    "id": "arXiv:2104.13626",
    "title": "Self-Bounding Majority Vote Learning Algorithms by the Direct  Minimization of a Tight PAC-Bayesian C-Bound",
    "abstract": "Self-Bounding Majority Vote Learning Algorithms by the Direct  Minimization of a Tight PAC-Bayesian C-Bound",
    "descriptor": "",
    "authors": [
      "Paul Viallard",
      "Pascal Germain",
      "Amaury Habrard",
      "Emilie Morvant"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.13626"
  },
  {
    "id": "arXiv:2104.14281",
    "title": "Leveraging Online Shopping Behaviors as a Proxy for Personal Lifestyle  Choices: New Insights into Chronic Disease Prevention Literacy",
    "abstract": "Comments: 64 pages with appendices, 5 figures, 17 tables",
    "descriptor": "\nComments: 64 pages with appendices, 5 figures, 17 tables\n",
    "authors": [
      "Yongzhen Wang",
      "Xiaozhong Liu",
      "Katy B\u00f6rner",
      "Jun Lin",
      "Yingnan Ju",
      "Changlong Sun",
      "Luo Si"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2104.14281"
  },
  {
    "id": "arXiv:2104.14945",
    "title": "Anomaly Detection with Prototype-Guided Discriminative Latent Embeddings",
    "abstract": "Comments: Accepted by ICDM 2021",
    "descriptor": "\nComments: Accepted by ICDM 2021\n",
    "authors": [
      "Yuandu Lai",
      "Yahong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.14945"
  },
  {
    "id": "arXiv:2105.01060",
    "title": "Curious Representation Learning for Embodied Intelligence",
    "abstract": "Comments: To apear at ICCV 2021. Code is available at this https URL",
    "descriptor": "\nComments: To apear at ICCV 2021. Code is available at this https URL\n",
    "authors": [
      "Yilun Du",
      "Chuang Gan",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.01060"
  },
  {
    "id": "arXiv:2105.01738",
    "title": "Priority Promotion with Parysian Flair",
    "abstract": "Priority Promotion with Parysian Flair",
    "descriptor": "",
    "authors": [
      "Massimo Benerecetti",
      "Daniele Dell'Erba",
      "Fabio Mogavero",
      "Sven Schewe",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.01738"
  },
  {
    "id": "arXiv:2105.01764",
    "title": "Surveilling Surveillance: Estimating the Prevalence of Surveillance  Cameras with Street View Data",
    "abstract": "Comments: We now credit Turtiainen et al. (2020) both for creating a state-of-the-art camera detection model and for suggesting that computer vision could, in theory, be applied to street view data to map surveillance cameras. Also, we discovered a coding error in our image sampling strategy that corrupted our analysis of camera density over time. We have now removed the results of that analysis",
    "descriptor": "\nComments: We now credit Turtiainen et al. (2020) both for creating a state-of-the-art camera detection model and for suggesting that computer vision could, in theory, be applied to street view data to map surveillance cameras. Also, we discovered a coding error in our image sampling strategy that corrupted our analysis of camera density over time. We have now removed the results of that analysis\n",
    "authors": [
      "Hao Sheng",
      "Keniel Yao",
      "Sharad Goel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.01764"
  },
  {
    "id": "arXiv:2105.01794",
    "title": "Real-time Deep Dynamic Characters",
    "abstract": "Real-time Deep Dynamic Characters",
    "descriptor": "",
    "authors": [
      "Marc Habermann",
      "Lingjie Liu",
      "Weipeng Xu",
      "Michael Zollhoefer",
      "Gerard Pons-Moll",
      "Christian Theobalt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.01794"
  },
  {
    "id": "arXiv:2105.03178",
    "title": "Graph Entropy Guided Node Embedding Dimension Selection for Graph Neural  Networks",
    "abstract": "Graph Entropy Guided Node Embedding Dimension Selection for Graph Neural  Networks",
    "descriptor": "",
    "authors": [
      "Gongxu Luo",
      "Jianxin Li",
      "Jianlin Su",
      "Hao Peng",
      "Carl Yang",
      "Lichao Sun",
      "Philip S. Yu",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03178"
  },
  {
    "id": "arXiv:2105.03491",
    "title": "Uniform Convergence, Adversarial Spheres and a Simple Remedy",
    "abstract": "Uniform Convergence, Adversarial Spheres and a Simple Remedy",
    "descriptor": "",
    "authors": [
      "Gregor Bachmann",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.03491"
  },
  {
    "id": "arXiv:2105.04854",
    "title": "Improving Molecular Graph Neural Network Explainability with  Orthonormalization and Induced Sparsity",
    "abstract": "Comments: Fixed typo and reference",
    "descriptor": "\nComments: Fixed typo and reference\n",
    "authors": [
      "Ryan Henderson",
      "Djork-Arn\u00e9 Clevert",
      "Floriane Montanari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.04854"
  },
  {
    "id": "arXiv:2105.06009",
    "title": "Verification of the Incremental Merkle Tree Algorithm with Dafny",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Franck Cassez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.06009"
  },
  {
    "id": "arXiv:2105.07402",
    "title": "Is cell ratio important in deep learning? A robust comparison of deep  learning methods for multi-scale cytopathology cell image classification:  from convolutional neural networks to visual transformers",
    "abstract": "Is cell ratio important in deep learning? A robust comparison of deep  learning methods for multi-scale cytopathology cell image classification:  from convolutional neural networks to visual transformers",
    "descriptor": "",
    "authors": [
      "Wanli Liu",
      "Chen Li",
      "Md Mamunur Rahamana",
      "Hongzan Sun",
      "Weiming Hu",
      "Haoyuan Chen",
      "Changhao Sun",
      "Yudong Yao",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.07402"
  },
  {
    "id": "arXiv:2105.07443",
    "title": "How Can Robots Trust Each Other For Better Cooperation? A Relative Needs  Entropy Based Robot-Robot Trust Assessment Model",
    "abstract": "Comments: the SMC 2021 conference final submitted version",
    "descriptor": "\nComments: the SMC 2021 conference final submitted version\n",
    "authors": [
      "Qin Yang",
      "Ramviyas Parasuraman"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.07443"
  },
  {
    "id": "arXiv:2105.08364",
    "title": "Deep Learning-based Physical-Layer Secret Key Generation for FDD Systems",
    "abstract": "Comments: Accepted for publication in IEEE Internet of Things Journal",
    "descriptor": "\nComments: Accepted for publication in IEEE Internet of Things Journal\n",
    "authors": [
      "Xinwei Zhang",
      "Guyue Li",
      "Junqing Zhang",
      "Aiqun Hu",
      "Zongyue Hou",
      "Bin Xiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.08364"
  },
  {
    "id": "arXiv:2105.09040",
    "title": "Advances in integration of end-to-end neural and clustering-based  diarization for real conversational speech",
    "abstract": "Comments: 5 pages, 1 figure, Interspeech2021. (Update to include a reference to the code)",
    "descriptor": "\nComments: 5 pages, 1 figure, Interspeech2021. (Update to include a reference to the code)\n",
    "authors": [
      "Keisuke Kinoshita",
      "Marc Delcroix",
      "Naohiro Tawara"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2105.09040"
  },
  {
    "id": "arXiv:2105.10766",
    "title": "Embedding Information onto a Dynamical System",
    "abstract": "Embedding Information onto a Dynamical System",
    "descriptor": "",
    "authors": [
      "G Manjunath"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.10766"
  },
  {
    "id": "arXiv:2106.00083",
    "title": "Composing Networks of Automated Market Makers",
    "abstract": "Composing Networks of Automated Market Makers",
    "descriptor": "",
    "authors": [
      "Daniel Engel",
      "Maurice Herlihy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.00083"
  },
  {
    "id": "arXiv:2106.04847",
    "title": "UniKeyphrase: A Unified Extraction and Generation Framework for  Keyphrase Prediction",
    "abstract": "Comments: 11pages, 6 figures, 6 tables, published in ACL 2021 findings",
    "descriptor": "\nComments: 11pages, 6 figures, 6 tables, published in ACL 2021 findings\n",
    "authors": [
      "Huanqin Wu",
      "Wei Liu",
      "Lei Li",
      "Dan Nie",
      "Tao Chen",
      "Feng Zhang",
      "Di Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.04847"
  },
  {
    "id": "arXiv:2106.07560",
    "title": "Allocating Stimulus Checks in Times of Crisis",
    "abstract": "Comments: Colorblind-friendly figures; Fix typos; Restructured Introduction; Reorganized approximation algorithm proofs; Add acknowledgements. To be presented at EAAMO '21 (non-archival track)",
    "descriptor": "\nComments: Colorblind-friendly figures; Fix typos; Restructured Introduction; Reorganized approximation algorithm proofs; Add acknowledgements. To be presented at EAAMO '21 (non-archival track)\n",
    "authors": [
      "Marios Papachristou",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.07560"
  },
  {
    "id": "arXiv:2106.09076",
    "title": "Deformation Driven Seq2Seq Longitudinal Tumor and Organs-at-Risk  Prediction for Radiotherapy",
    "abstract": "Comments: Medical Physics 2021, Saad Nadeem and Yu-Chi Hu contributed equally",
    "descriptor": "\nComments: Medical Physics 2021, Saad Nadeem and Yu-Chi Hu contributed equally\n",
    "authors": [
      "Donghoon Lee",
      "Sadegh R Alam",
      "Jue Jiang",
      "Pengpeng Zhang",
      "Saad Nadeem",
      "Yu-Chi Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09076"
  },
  {
    "id": "arXiv:2106.09754",
    "title": "Towards Real-Time Routing Optimization with Deep Reinforcement Learning:  Open Challenges",
    "abstract": "Comments: 6 pages, 4 figures",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Paul Almasan",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Bo Wu",
      "Shihan Xiao",
      "Pere Barlet-Ros",
      "Albert Cabellos-Aparicio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.09754"
  },
  {
    "id": "arXiv:2106.10122",
    "title": "Asymptotic elimination of partially continuous aggregation functions in  directed graphical models",
    "abstract": "Comments: The previous version of the article had an error which is now removed by instead using the semantics of Lukasiewicz logic for the connectives. The essential changes are: 1) The definition of the semantics of PLA is changed. 2) A new lemma is added just before Section 4.1 which shows that asymptotic probability is preserved under the connectives. 3) The proof of Corollary 7.12 is modified",
    "descriptor": "\nComments: The previous version of the article had an error which is now removed by instead using the semantics of Lukasiewicz logic for the connectives. The essential changes are: 1) The definition of the semantics of PLA is changed. 2) A new lemma is added just before Section 4.1 which shows that asymptotic probability is preserved under the connectives. 3) The proof of Corollary 7.12 is modified\n",
    "authors": [
      "Vera Koponen",
      "Felix Weitk\u00e4mper"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.10122"
  },
  {
    "id": "arXiv:2106.10912",
    "title": "Certifying a probabilistic parallel modular algorithm for rational  univariate representation",
    "abstract": "Certifying a probabilistic parallel modular algorithm for rational  univariate representation",
    "descriptor": "",
    "authors": [
      "Bernard Parisse"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2106.10912"
  },
  {
    "id": "arXiv:2106.12805",
    "title": "Retrospective Interference Regeneration Schemes for Relay-Aided K-user  MIMO Downlink Networks",
    "abstract": "Comments: 31 pages, 8 figures",
    "descriptor": "\nComments: 31 pages, 8 figures\n",
    "authors": [
      "Jingfu Li",
      "Zehui Xiong",
      "Dusit Niyato",
      "Weifeng Su",
      "Wenjiang Feng",
      "Weiheng Jiang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2106.12805"
  },
  {
    "id": "arXiv:2107.00986",
    "title": "Unsupervised Single Image Super-resolution Under Complex Noise",
    "abstract": "Unsupervised Single Image Super-resolution Under Complex Noise",
    "descriptor": "",
    "authors": [
      "Zongsheng Yue",
      "Qian Zhao",
      "Jianwen Xie",
      "Lei Zhang",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00986"
  },
  {
    "id": "arXiv:2107.03158",
    "title": "A Survey on Data Augmentation for Text Classification",
    "abstract": "Comments: 35 pages, 6 figures, 8 tables",
    "descriptor": "\nComments: 35 pages, 6 figures, 8 tables\n",
    "authors": [
      "Markus Bayer",
      "Marc-Andr\u00e9 Kaufhold",
      "Christian Reuter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.03158"
  },
  {
    "id": "arXiv:2107.05699",
    "title": "Linear and Reed Solomon Codes Against Adversarial Insertions and  Deletions",
    "abstract": "Linear and Reed Solomon Codes Against Adversarial Insertions and  Deletions",
    "descriptor": "",
    "authors": [
      "Roni Con",
      "Amir Shpilka",
      "Itzhak Tamo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.05699"
  },
  {
    "id": "arXiv:2107.06941",
    "title": "Mutually improved endoscopic image synthesis and landmark detection in  unpaired image-to-image translation",
    "abstract": "Comments: Accepted for IEEE JBHI 2021, 13 pages, 8 figures, 4 tables",
    "descriptor": "\nComments: Accepted for IEEE JBHI 2021, 13 pages, 8 figures, 4 tables\n",
    "authors": [
      "Lalith Sharan",
      "Gabriele Romano",
      "Sven Koehler",
      "Halvar Kelm",
      "Matthias Karck",
      "Raffaele De Simone",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06941"
  },
  {
    "id": "arXiv:2107.10160",
    "title": "Pre-proceedings of the 31st International Symposium on Logic-Based  Program Synthesis and Transformation (LOPSTR 2021)",
    "abstract": "Comments: Papers selected for presentation at LOPSTR 2021, Invited talks and Tutorial",
    "descriptor": "\nComments: Papers selected for presentation at LOPSTR 2021, Invited talks and Tutorial\n",
    "authors": [
      "Emanuele De Angelis",
      "Wim Vanhoof"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.10160"
  },
  {
    "id": "arXiv:2107.10419",
    "title": "Triplet is All You Need with Random Mappings for Unsupervised Visual  Representation Learning",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Wenbin Li",
      "Xuesong Yang",
      "Meihao Kong",
      "Lei Wang",
      "Jing Huo",
      "Yang Gao",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.10419"
  },
  {
    "id": "arXiv:2107.12079",
    "title": "An Argumentative Dialogue System for COVID-19 Vaccine Information",
    "abstract": "Comments: 9 pages, 2 figures, Accepted at CLAR 2021",
    "descriptor": "\nComments: 9 pages, 2 figures, Accepted at CLAR 2021\n",
    "authors": [
      "Bettina Fazzinga",
      "Andrea Galassi",
      "Paolo Torroni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.12079"
  },
  {
    "id": "arXiv:2107.13189",
    "title": "Goal-Oriented Script Construction",
    "abstract": "Comments: INLG2021 (14th International Conference on Natural Language Generation)",
    "descriptor": "\nComments: INLG2021 (14th International Conference on Natural Language Generation)\n",
    "authors": [
      "Qing Lyu",
      "Li Zhang",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.13189"
  },
  {
    "id": "arXiv:2107.13625",
    "title": "Generalizing Fairness: Discovery and Mitigation of Unknown Sensitive  Attributes",
    "abstract": "Generalizing Fairness: Discovery and Mitigation of Unknown Sensitive  Attributes",
    "descriptor": "",
    "authors": [
      "William Paul",
      "Philippe Burlina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.13625"
  },
  {
    "id": "arXiv:2107.13799",
    "title": "Mapping Human Muscle Force to Supernumerary Robotics Device for Overhead  Task Assistance",
    "abstract": "Mapping Human Muscle Force to Supernumerary Robotics Device for Overhead  Task Assistance",
    "descriptor": "",
    "authors": [
      "Jianwen Luo",
      "Sicong Liu",
      "Chengyu Lin",
      "Yong Zhou",
      "Zixuan Fan",
      "Zheng Wang",
      "Chaoyang Song",
      "H. Harry Asada",
      "Chenglong Fu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.13799"
  },
  {
    "id": "arXiv:2107.14132",
    "title": "Multi-Task Learning in Utterance-Level and Segmental-Level Spoof  Detection",
    "abstract": "Comments: Submitted to ASVspoof 2021 Workshop",
    "descriptor": "\nComments: Submitted to ASVspoof 2021 Workshop\n",
    "authors": [
      "Lin Zhang",
      "Xin Wang",
      "Erica Cooper",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.14132"
  },
  {
    "id": "arXiv:2108.00483",
    "title": "Modeling and Analysis of mMTC Traffic in 5G Base Stations",
    "abstract": "Modeling and Analysis of mMTC Traffic in 5G Base Stations",
    "descriptor": "",
    "authors": [
      "Fidan Mehmeti",
      "Thomas F. La Porta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.00483"
  },
  {
    "id": "arXiv:2108.00694",
    "title": "A Novel Internet-of-Drones and Blockchain-based System Architecture for  Search and Rescue",
    "abstract": "Comments: 8 figures and 11 pages",
    "descriptor": "\nComments: 8 figures and 11 pages\n",
    "authors": [
      "Tri Nguyen",
      "Risto Katila",
      "Tuan Nguyen Gia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.00694"
  },
  {
    "id": "arXiv:2108.01955",
    "title": "Log-based Anomaly Detection Without Log Parsing",
    "abstract": "Log-based Anomaly Detection Without Log Parsing",
    "descriptor": "",
    "authors": [
      "Van-Hoang Le",
      "Hongyu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.01955"
  },
  {
    "id": "arXiv:2108.02854",
    "title": "GENder-IT: An Annotated English-Italian Parallel Challenge Set for  Cross-Linguistic Natural Gender Phenomena",
    "abstract": "GENder-IT: An Annotated English-Italian Parallel Challenge Set for  Cross-Linguistic Natural Gender Phenomena",
    "descriptor": "",
    "authors": [
      "Eva Vanmassenhove",
      "Johanna Monti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.02854"
  },
  {
    "id": "arXiv:2108.05921",
    "title": "Hatemoji: A Test Suite and Adversarially-Generated Dataset for  Benchmarking and Detecting Emoji-based Hate",
    "abstract": "Hatemoji: A Test Suite and Adversarially-Generated Dataset for  Benchmarking and Detecting Emoji-based Hate",
    "descriptor": "",
    "authors": [
      "Hannah Rose Kirk",
      "Bertram Vidgen",
      "Paul R\u00f6ttger",
      "Tristan Thrush",
      "Scott A. Hale"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.05921"
  },
  {
    "id": "arXiv:2108.06455",
    "title": "PTT: Point-Track-Transformer Module for 3D Single Object Tracking in  Point Clouds",
    "abstract": "Comments: Figure 2 has a mistake which could make readers misunderstand the architecture; Figure 5 and 6 are unclear; The reference papers needs update",
    "descriptor": "\nComments: Figure 2 has a mistake which could make readers misunderstand the architecture; Figure 5 and 6 are unclear; The reference papers needs update\n",
    "authors": [
      "Jiayao Shan",
      "Sifan Zhou",
      "Zheng Fang",
      "Yubo Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06455"
  },
  {
    "id": "arXiv:2108.08418",
    "title": "Optimised Multithreaded CV-QKD Reconciliation for Global Quantum  Networks",
    "abstract": "Comments: Details on LDPC codes used and typographical errors fixed",
    "descriptor": "\nComments: Details on LDPC codes used and typographical errors fixed\n",
    "authors": [
      "Xiaoyu Ai",
      "Robert Malaney"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.08418"
  },
  {
    "id": "arXiv:2108.09484",
    "title": "CushLEPOR: Customised hLEPOR Metric Using LABSE Distilled Knowledge  Model to Improve Agreement with Human Judgements",
    "abstract": "Comments: Extended work from MT SUMMIT 2021: Gleb Erofeev, Irina Sorokina, Lifeng Han, and Serge Gladkoff. 2021. cushLEPOR uses LABSE distilled knowledge to improve correlation with human translation evaluations. In Proceedings for the MT summit 2021. Fixed a bug regarding &lt;Figure 3: RMSE: hLEPOR vs cushLEPOR to pSQM&gt; in last arXiv version v1",
    "descriptor": "\nComments: Extended work from MT SUMMIT 2021: Gleb Erofeev, Irina Sorokina, Lifeng Han, and Serge Gladkoff. 2021. cushLEPOR uses LABSE distilled knowledge to improve correlation with human translation evaluations. In Proceedings for the MT summit 2021. Fixed a bug regarding &lt;Figure 3: RMSE: hLEPOR vs cushLEPOR to pSQM&gt; in last arXiv version v1\n",
    "authors": [
      "Lifeng Han",
      "Irina Sorokina",
      "Gleb Erofeev",
      "Serge Gladkoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.09484"
  },
  {
    "id": "arXiv:2108.09897",
    "title": "A Weakly Supervised Amodal Segmenter with Boundary Uncertainty  Estimation",
    "abstract": "Comments: Accepted to ICCV 2021",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Khoi Nguyen",
      "Sinisa Todorovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.09897"
  },
  {
    "id": "arXiv:2108.09924",
    "title": "Sarcasm Detection in Twitter -- Performance Impact while using Data  Augmentation: Word Embeddings",
    "abstract": "Comments: 7 pages, 4 figures",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Alif Tri Handoyo",
      "Hidayaturrahman",
      "Derwin Suhartono"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.09924"
  },
  {
    "id": "arXiv:2108.11020",
    "title": "Logarithmic Euler Maruyama Scheme for Multi Dimensional Stochastic Delay  Differential Equation",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Nishant Agrawal",
      "Yaozhong Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.11020"
  },
  {
    "id": "arXiv:2108.11250",
    "title": "YOLOP: You Only Look Once for Panoptic Driving Perception",
    "abstract": "YOLOP: You Only Look Once for Panoptic Driving Perception",
    "descriptor": "",
    "authors": [
      "Dong Wu",
      "Manwen Liao",
      "Weitian Zhang",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.11250"
  },
  {
    "id": "arXiv:2108.11514",
    "title": "Bilateral Denoising Diffusion Models",
    "abstract": "Bilateral Denoising Diffusion Models",
    "descriptor": "",
    "authors": [
      "Max W. Y. Lam",
      "Jun Wang",
      "Rongjie Huang",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.11514"
  },
  {
    "id": "arXiv:2108.11651",
    "title": "Scalable and Modular Robustness Analysis of Deep Neural Networks",
    "abstract": "Scalable and Modular Robustness Analysis of Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Yuyi Zhong",
      "Quang-Trung Ta",
      "Tianzuo Luo",
      "Fanlong Zhang",
      "Siau-Cheng Khoo"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.11651"
  },
  {
    "id": "arXiv:2108.11673",
    "title": "Why Adversarial Reprogramming Works, When It Fails, and How to Tell the  Difference",
    "abstract": "Why Adversarial Reprogramming Works, When It Fails, and How to Tell the  Difference",
    "descriptor": "",
    "authors": [
      "Yang Zheng",
      "Xiaoyi Feng",
      "Zhaoqiang Xia",
      "Xiaoyue Jiang",
      "Ambra Demontis",
      "Maura Pintor",
      "Battista Biggio",
      "Fabio Roli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.11673"
  },
  {
    "id": "arXiv:2108.12189",
    "title": "Query-Focused Extractive Summarisation for Finding Ideal Answers to  Biomedical and COVID-19 Questions",
    "abstract": "Comments: 12 pages, 2 figures, 6 tables. Accepted at BioASQ workshop, CLEF 2021",
    "descriptor": "\nComments: 12 pages, 2 figures, 6 tables. Accepted at BioASQ workshop, CLEF 2021\n",
    "authors": [
      "Diego Moll\u00e1",
      "Urvashi Khanna",
      "Dima Galat",
      "Vincent Nguyen",
      "Maciej Rybinski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2108.12189"
  },
  {
    "id": "arXiv:2108.12427",
    "title": "Why and How Governments Should Monitor AI Development",
    "abstract": "Why and How Governments Should Monitor AI Development",
    "descriptor": "",
    "authors": [
      "Jess Whittlestone",
      "Jack Clark"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.12427"
  },
  {
    "id": "arXiv:2108.12516",
    "title": "Few-Shot Table-to-Text Generation with Prototype Memory",
    "abstract": "Comments: Accepted to Findings of EMNLP 2021",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Yixuan Su",
      "Zaiqiao Meng",
      "Simon Baker",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.12516"
  },
  {
    "id": "arXiv:2108.12533",
    "title": "Image-to-Graph Convolutional Network for Deformable Shape Reconstruction  from a Single Projection Image",
    "abstract": "Comments: This paper will be appeared in MICCAI 2021",
    "descriptor": "\nComments: This paper will be appeared in MICCAI 2021\n",
    "authors": [
      "M. Nakao",
      "F. Tong",
      "M. Nakamura",
      "T. Matsuda"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12533"
  },
  {
    "id": "arXiv:2108.12582",
    "title": "Distilling the Knowledge of Large-scale Generative Models into Retrieval  Models for Efficient Open-domain Conversation",
    "abstract": "Comments: EMNLP21-Findings",
    "descriptor": "\nComments: EMNLP21-Findings\n",
    "authors": [
      "Beomsu Kim",
      "Seokjun Seo",
      "Seungju Han",
      "Enkhbayar Erdenee",
      "Buru Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.12582"
  },
  {
    "id": "arXiv:2108.12673",
    "title": "Tracing app technology: An ethical review in the COVID-19 era and  directions for post-COVID-19",
    "abstract": "Tracing app technology: An ethical review in the COVID-19 era and  directions for post-COVID-19",
    "descriptor": "",
    "authors": [
      "Saleh Afroogh",
      "Amir Esmalian",
      "Ali Mostafavi",
      "Ali Akbari",
      "Kambiz Rasoulkhani",
      "Shahriar Esmaeili",
      "Ehsan Hajiramezanali"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2108.12673"
  },
  {
    "id": "arXiv:2108.12883",
    "title": "A Closed Loop Gradient Descent Algorithm applied to Rosenbrock's  function",
    "abstract": "Comments: This paper has been accepted for the 2021 Australia and New Zealand Control Conference, to be held in November, 2021",
    "descriptor": "\nComments: This paper has been accepted for the 2021 Australia and New Zealand Control Conference, to be held in November, 2021\n",
    "authors": [
      "Subhransu Bhattacharjee",
      "Ian Petersen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.12883"
  },
  {
    "id": "arXiv:2108.12963",
    "title": "Scheduled Sampling Based on Decoding Steps for Neural Machine  Translation",
    "abstract": "Comments: Code is at this https URL To appear in EMNLP-2021 main conference. arXiv admin note: text overlap with arXiv:2107.10427",
    "descriptor": "\nComments: Code is at this https URL To appear in EMNLP-2021 main conference. arXiv admin note: text overlap with arXiv:2107.10427\n",
    "authors": [
      "Yijin Liu",
      "Fandong Meng",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.12963"
  },
  {
    "id": "arXiv:2108.13009",
    "title": "Communication-Computation Efficient Device-Edge Co-Inference via AutoML",
    "abstract": "Communication-Computation Efficient Device-Edge Co-Inference via AutoML",
    "descriptor": "",
    "authors": [
      "Xinjie Zhang",
      "Jiawei Shao",
      "Yuyi Mao",
      "Jun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.13009"
  },
  {
    "id": "arXiv:2108.13011",
    "title": "Robust Tube-based Model Predictive Control with Koopman  Operators--Extended Version",
    "abstract": "Comments: 18 pages, 9 figures",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Xinglong Zhang",
      "Wei Pan",
      "Riccardo Scattolini",
      "Shuyou Yu",
      "Xin Xu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13011"
  },
  {
    "id": "arXiv:2108.13161",
    "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot  Learners",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Ningyu Zhang",
      "Luoqiu Li",
      "Xiang Chen",
      "Shumin Deng",
      "Zhen Bi",
      "Chuanqi Tan",
      "Fei Huang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13161"
  },
  {
    "id": "arXiv:2108.13308",
    "title": "GoPRONTO: a Feedback-based Framework for Nonlinear Optimal Control",
    "abstract": "Comments: 37 pages, 11 figures",
    "descriptor": "\nComments: 37 pages, 11 figures\n",
    "authors": [
      "Lorenzo Sforni",
      "Sara Spedicato",
      "Ivano Notarnicola",
      "Giuseppe Notarstefano"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13308"
  }
]
[
  {
    "id": "arXiv:2109.03818",
    "title": "Online Learning for Cooperative Multi-Player Multi-Armed Bandits",
    "abstract": "We introduce a framework for decentralized online learning for multi-armed\nbandits (MAB) with multiple cooperative players. The reward obtained by the\nplayers in each round depends on the actions taken by all the players. It's a\nteam setting, and the objective is common. Information asymmetry is what makes\nthe problem interesting and challenging. We consider three types of information\nasymmetry: action information asymmetry when the actions of the players can't\nbe observed but the rewards received are common; reward information asymmetry\nwhen the actions of the other players are observable but rewards received are\nIID from the same distribution; and when we have both action and reward\ninformation asymmetry. For the first setting, we propose a UCB-inspired\nalgorithm that achieves $O(\\log T)$ regret whether the rewards are IID or\nMarkovian. For the second section, we offer an environment such that the\nalgorithm given for the first setting gives linear regret. For the third\nsetting, we show that a variation of the `explore then commit' algorithm\nachieves almost log regret.",
    "descriptor": "",
    "authors": [
      "William Chang",
      "Mehdi Jafarnia-Jahromi",
      "Rahul Jain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03818"
  },
  {
    "id": "arXiv:2109.03819",
    "title": "Powering Comparative Classification with Sentiment Analysis via Domain  Adaptive Knowledge Transfer",
    "abstract": "We study Comparative Preference Classification (CPC) which aims at predicting\nwhether a preference comparison exists between two entities in a given sentence\nand, if so, which entity is preferred over the other. High-quality CPC models\ncan significantly benefit applications such as comparative question answering\nand review-based recommendations. Among the existing approaches, non-deep\nlearning methods suffer from inferior performances. The state-of-the-art graph\nneural network-based ED-GAT (Ma et al., 2020) only considers syntactic\ninformation while ignoring the critical semantic relations and the sentiments\nto the compared entities. We proposed sentiment Analysis Enhanced COmparative\nNetwork (SAECON) which improves CPC ac-curacy with a sentiment analyzer that\nlearns sentiments to individual entities via domain adaptive knowledge\ntransfer. Experiments on the CompSent-19 (Panchenko et al., 2019) dataset\npresent a significant improvement on the F1 scores over the best existing CPC\napproaches.",
    "descriptor": "\nComments: 13 pages; EMNLP-2021 Main Conference\n",
    "authors": [
      "Zeyu Li",
      "Yilong Qin",
      "Zihan Liu",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03819"
  },
  {
    "id": "arXiv:2109.03820",
    "title": "Tom: Leveraging trend of the observed gradients for faster convergence",
    "abstract": "The success of deep learning can be attributed to various factors such as\nincrease in computational power, large datasets, deep convolutional neural\nnetworks, optimizers etc. Particularly, the choice of optimizer affects the\ngeneralization, convergence rate, and training stability. Stochastic Gradient\nDescent (SGD) is a first order iterative optimizer that updates the gradient\nuniformly for all parameters. This uniform update may not be suitable across\nthe entire training phase. A rudimentary solution for this is to employ a\nfine-tuned learning rate scheduler which decreases learning rate as a function\nof iteration. To eliminate the dependency of learning rate schedulers, adaptive\ngradient optimizers such as AdaGrad, AdaDelta, RMSProp, Adam employ a\nparameter-wise scaling term for learning rate which is a function of the\ngradient itself. We propose Tom (Trend over Momentum) optimizer, which is a\nnovel variant of Adam that takes into account of the trend which is observed\nfor the gradients in the loss landscape traversed by the neural network. In the\nproposed Tom optimizer, an additional smoothing equation is introduced to\naddress the trend observed during the process of optimization. The smoothing\nparameter introduced for the trend requires no tuning and can be used with\ndefault values. Experimental results for classification datasets such as\nCIFAR-10, CIFAR-100 and CINIC-10 image datasets show that Tom outperforms\nAdagrad, Adadelta, RMSProp and Adam in terms of both accuracy and has a faster\nconvergence. The source code is publicly made available at\nhttps://github.com/AnirudhMaiya/Tom",
    "descriptor": "",
    "authors": [
      "Anirudh Maiya",
      "Inumella Sricharan",
      "Anshuman Pandey",
      "Srinivas K. S"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03820"
  },
  {
    "id": "arXiv:2109.03821",
    "title": "Recommend for a Reason: Unlocking the Power of Unsupervised  Aspect-Sentiment Co-Extraction",
    "abstract": "Compliments and concerns in reviews are valuable for understanding users'\nshopping interests and their opinions with respect to specific aspects of\ncertain items. Existing review-based recommenders favor large and complex\nlanguage encoders that can only learn latent and uninterpretable text\nrepresentations. They lack explicit user attention and item property modeling,\nwhich however could provide valuable information beyond the ability to\nrecommend items. Therefore, we propose a tightly coupled two-stage approach,\nincluding an Aspect-Sentiment Pair Extractor (ASPE) and an\nAttention-Property-aware Rating Estimator (APRE). Unsupervised ASPE mines\nAspect-Sentiment pairs (AS-pairs) and APRE predicts ratings using AS-pairs as\nconcrete aspect-level evidence. Extensive experiments on seven real-world\nAmazon Review Datasets demonstrate that ASPE can effectively extract AS-pairs\nwhich enable APRE to deliver superior accuracy over the leading baselines.",
    "descriptor": "\nComments: 16 pages; Accepted to Findings of EMNLP-2021\n",
    "authors": [
      "Zeyu Li",
      "Wei Cheng",
      "Reema Kshetramade",
      "John Houser",
      "Haifeng Chen",
      "Wei Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03821"
  },
  {
    "id": "arXiv:2109.03839",
    "title": "Mean-Square Analysis with An Application to Optimal Dimension Dependence  of Langevin Monte Carlo",
    "abstract": "Sampling algorithms based on discretizations of Stochastic Differential\nEquations (SDEs) compose a rich and popular subset of MCMC methods. This work\nprovides a general framework for the non-asymptotic analysis of sampling error\nin 2-Wasserstein distance, which also leads to a bound of mixing time. The\nmethod applies to any consistent discretization of contractive SDEs. When\napplied to Langevin Monte Carlo algorithm, it establishes\n$\\tilde{\\mathcal{O}}\\left( \\frac{\\sqrt{d}}{\\epsilon} \\right)$ mixing time,\nwithout warm start, under the common log-smooth and log-strongly-convex\nconditions, plus a growth condition on the 3rd-order derivative of the\npotential of target measures at infinity. This bound improves the best\npreviously known $\\tilde{\\mathcal{O}}\\left( \\frac{d}{\\epsilon} \\right)$ result\nand is optimal (in terms of order) in both dimension $d$ and accuracy tolerance\n$\\epsilon$ for target measures satisfying the aforementioned assumptions. Our\ntheoretical analysis is further validated by numerical experiments.",
    "descriptor": "\nComments: Submitted to NeurIPS 2021 on May 28, 2021 (the submission deadline)\n",
    "authors": [
      "Ruilin Li",
      "Hongyuan Zha",
      "Molei Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.03839"
  },
  {
    "id": "arXiv:2109.03845",
    "title": "StripBrush: A Constraint-Relaxed 3D Brush Reduces Physical Effort and  Enhances the Quality of Spatial Drawing",
    "abstract": "Spatial drawing using ruled-surface brush strokes is a popular mode of\ncontent creation in immersive VR, yet little is known about the usability of\nexisting spatial drawing interfaces or potential improvements. We address these\nquestions in a three-phase study. (1) Our exploratory need-finding study (N=8)\nindicates that popular spatial brushes require users to perform large wrist\nmotions, causing physical strain. We speculate that this is partly due to\nconstraining users to align their 3D controllers with their intended stroke\nnormal orientation. (2) We designed and implemented a new brush interface that\nsignificantly reduces the physical effort and wrist motion involved in VR\ndrawing, with the additional benefit of increasing drawing accuracy. We achieve\nthis by relaxing the normal alignment constraints, allowing users to control\nstroke rulings, and estimating normals from them instead. (3) Our comparative\nevaluation of StripBrush (N=17) against the traditional brush shows that\nStripBrush requires significantly less physical effort and allows users to more\naccurately depict their intended shapes while offering competitive ease-of-use\nand speed.",
    "descriptor": "\nComments: 12 pages, 13 figures, for associated video and supplementary files, see this https URL\n",
    "authors": [
      "Enrique Rosales",
      "Jafet Rodriguez",
      "Chrystiano Ara\u00fajo",
      "Nicholas Vining",
      "Dongwook Yoon",
      "Alla Sheffer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.03845"
  },
  {
    "id": "arXiv:2109.03848",
    "title": "Knowledge mining of unstructured information: application to  cyber-domain",
    "abstract": "Cyber intelligence is widely and abundantly available in numerous open online\nsources with reports on vulnerabilities and incidents. This constant stream of\nnoisy information requires new tools and techniques if it is to be used for the\nbenefit of analysts and investigators in various organizations. In this paper\nwe present and implement a novel knowledge graph and knowledge mining framework\nfor extracting relevant information from free-form text about incidents in the\ncyber domain. Our framework includes a machine learning based pipeline as well\nas crawling methods for generating graphs of entities, attackers and the\nrelated information with our non-technical cyber ontology. We test our\nframework on publicly available cyber incident datasets to evaluate the\naccuracy of our knowledge mining methods as well as the usefulness of the\nframework in the use of cyber analysts. Our results show analyzing the\nknowledge graph constructed using the novel framework, an analyst can infer\nadditional information from the current cyber landscape in terms of risk to\nvarious entities and the propagation of risk between industries and countries.\nExpanding the framework to accommodate more technical and operational level\ninformation can increase the accuracy and explainability of trends and risk in\nthe knowledge graph.",
    "descriptor": "",
    "authors": [
      "Tuomas Takko",
      "Kunal Bhattacharya",
      "Martti Lehto",
      "Pertti Jalasvirta",
      "Aapo Cederberg",
      "Kimmo Kaski"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03848"
  },
  {
    "id": "arXiv:2109.03849",
    "title": "OSSR-PID: One-Shot Symbol Recognition in P&ID Sheets using Path Sampling  and GCN",
    "abstract": "Piping and Instrumentation Diagrams (P&ID) are ubiquitous in several\nmanufacturing, oil and gas enterprises for representing engineering schematics\nand equipment layout. There is an urgent need to extract and digitize\ninformation from P&IDs without the cost of annotating a varying set of symbols\nfor each new use case. A robust one-shot learning approach for symbol\nrecognition i.e., localization followed by classification, would therefore go a\nlong way towards this goal. Our method works by sampling pixels sequentially\nalong the different contour boundaries in the image. These sampled points form\npaths which are used in the prototypical line diagram to construct a graph that\ncaptures the structure of the contours. Subsequently, the prototypical graphs\nare fed into a Dynamic Graph Convolutional Neural Network (DGCNN) which is\ntrained to classify graphs into one of the given symbol classes. Further, we\nappend embeddings from a Resnet-34 network which is trained on symbol images\ncontaining sampled points to make the classification network more robust.\nSince, many symbols in P&ID are structurally very similar to each other, we\nutilize Arcface loss during DGCNN training which helps in maximizing symbol\nclass separability by producing highly discriminative embeddings. The images\nconsist of components attached on the pipeline (straight line). The sampled\npoints segregated around the symbol regions are used for the classification\ntask. The proposed pipeline, named OSSR-PID, is fast and gives outstanding\nperformance for recognition of symbols on a synthetic dataset of 100 P&ID\ndiagrams. We also compare our method against prior-work on a real-world private\ndataset of 12 P&ID sheets and obtain comparable/superior results. Remarkably,\nit is able to achieve such excellent performance using only one prototypical\nexample per symbol.",
    "descriptor": "",
    "authors": [
      "Shubham Paliwal",
      "Monika Sharma",
      "Lovekesh Vig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03849"
  },
  {
    "id": "arXiv:2109.03853",
    "title": "A Bayesian Framework for Information-Theoretic Probing",
    "abstract": "Pimentel et al. (2020) recently analysed probing from an\ninformation-theoretic perspective. They argue that probing should be seen as\napproximating a mutual information. This led to the rather unintuitive\nconclusion that representations encode exactly the same information about a\ntarget task as the original sentences. The mutual information, however, assumes\nthe true probability distribution of a pair of random variables is known,\nleading to unintuitive results in settings where it is not. This paper proposes\na new framework to measure what we term Bayesian mutual information, which\nanalyses information from the perspective of Bayesian agents -- allowing for\nmore intuitive findings in scenarios with finite data. For instance, under\nBayesian MI we have that data can add information, processing can help, and\ninformation can hurt, which makes it more intuitive for machine learning\napplications. Finally, we apply our framework to probing where we believe\nBayesian mutual information naturally operationalises ease of extraction by\nexplicitly limiting the available background knowledge to solve a task.",
    "descriptor": "\nComments: Accepted for publication in EMNLP 2021. Code available in this https URL\n",
    "authors": [
      "Tiago Pimentel",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.03853"
  },
  {
    "id": "arXiv:2109.03856",
    "title": "Local Augmentation for Graph Neural Networks",
    "abstract": "Data augmentation has been widely used in image data and linguistic data but\nremains under-explored on graph-structured data. Existing methods focus on\naugmenting the graph data from a global perspective and largely fall into two\ngenres: structural manipulation and adversarial training with feature noise\ninjection. However, the structural manipulation approach suffers information\nloss issues while the adversarial training approach may downgrade the feature\nquality by injecting noise. In this work, we introduce the local augmentation,\nwhich enhances node features by its local subgraph structures. Specifically, we\nmodel the data argumentation as a feature generation process. Given the central\nnode's feature, our local augmentation approach learns the conditional\ndistribution of its neighbors' features and generates the neighbors' optimal\nfeature to boost the performance of downstream tasks. Based on the local\naugmentation, we further design a novel framework: LA-GNN, which can apply to\nany GNN models in a plug-and-play manner. Extensive experiments and analyses\nshow that local augmentation consistently yields performance improvement for\nvarious GNN architectures across a diverse set of benchmarks. Code is available\nat https://github.com/Soughing0823/LAGNN.",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Songtao Liu",
      "Hanze Dong",
      "Lanqing Li",
      "Tingyang Xu",
      "Yu Rong",
      "Peilin Zhao",
      "Junzhou Huang",
      "Dinghao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03856"
  },
  {
    "id": "arXiv:2109.03857",
    "title": "Robust Optimal Classification Trees Against Adversarial Examples",
    "abstract": "Decision trees are a popular choice of explainable model, but just like\nneural networks, they suffer from adversarial examples. Existing algorithms for\nfitting decision trees robust against adversarial examples are greedy\nheuristics and lack approximation guarantees. In this paper we propose ROCT, a\ncollection of methods to train decision trees that are optimally robust against\nuser-specified attack models. We show that the min-max optimization problem\nthat arises in adversarial learning can be solved using a single minimization\nformulation for decision trees with 0-1 loss. We propose such formulations in\nMixed-Integer Linear Programming and Maximum Satisfiability, which widely\navailable solvers can optimize. We also present a method that determines the\nupper bound on adversarial accuracy for any model using bipartite matching. Our\nexperimental results demonstrate that the existing heuristics achieve close to\noptimal scores while ROCT achieves state-of-the-art scores.",
    "descriptor": "",
    "authors": [
      "Dani\u00ebl Vos",
      "Sicco Verwer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03857"
  },
  {
    "id": "arXiv:2109.03858",
    "title": "Collecting a Large-Scale Gender Bias Dataset for Coreference Resolution  and Machine Translation",
    "abstract": "Recent works have found evidence of gender bias in models of machine\ntranslation and coreference resolution using mostly synthetic diagnostic\ndatasets. While these quantify bias in a controlled experiment, they often do\nso on a small scale and consist mostly of artificial, out-of-distribution\nsentences. In this work, we find grammatical patterns indicating stereotypical\nand non-stereotypical gender-role assignments (e.g., female nurses versus male\ndancers) in corpora from three domains, resulting in a first large-scale gender\nbias dataset of 108K diverse real-world English sentences. We manually verify\nthe quality of our corpus and use it to evaluate gender bias in various\ncoreference resolution and machine translation models. We find that all tested\nmodels tend to over-rely on gender stereotypes when presented with natural\ninputs, which may be especially harmful when deployed in commercial systems.\nFinally, we show that our dataset lends itself to finetuning a coreference\nresolution model, finding it mitigates bias on a held out set. Our dataset and\nmodels are publicly available at www.github.com/SLAB-NLP/BUG. We hope they will\nspur future research into gender bias evaluation mitigation techniques in\nrealistic settings.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Shahar Levy",
      "Koren Lazar",
      "abriel Stanovsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03858"
  },
  {
    "id": "arXiv:2109.03859",
    "title": "Leveraging Code Clones and Natural Language Processing for Log Statement  Prediction",
    "abstract": "Software developers embed logging statements inside the source code as an\nimperative duty in modern software development as log files are necessary for\ntracking down runtime system issues and troubleshooting system management\ntasks. Prior research has emphasized the importance of logging statements in\nthe operation and debugging of software systems. However, the current logging\nprocess is mostly manual and ad hoc, and thus, proper placement and content of\nlogging statements remain as challenges. To overcome these challenges, methods\nthat aim to automate log placement and log content, i.e., 'where, what, and how\nto log', are of high interest. Thus, we propose to accomplish the goal of this\nresearch, that is \"to predict the log statements by utilizing source code\nclones and natural language processing (NLP)\", as these approaches provide\nadditional context and advantage for log prediction. We pursue the following\nfour research objectives: (RO1) investigate whether source code clones can be\nleveraged for log statement location prediction, (RO2) propose a clone-based\napproach for log statement prediction, (RO3) predict log statement's\ndescription with code-clone and NLP models, and (RO4) examine approaches to\nautomatically predict additional details of the log statement, such as its\nverbosity level and variables. For this purpose, we perform an experimental\nanalysis on seven open-source java projects, extract their method-level code\nclones, investigate their attributes, and utilize them for log location and\ndescription prediction. Our work demonstrates the effectiveness of log-aware\nclone detection for automated log location and description prediction and\noutperforms the prior work.",
    "descriptor": "\nComments: ASE '21: Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering - Doctoral Symposium\n",
    "authors": [
      "Sina Gholamian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03859"
  },
  {
    "id": "arXiv:2109.03861",
    "title": "Recurrent Neural Network Controllers Synthesis with Stability Guarantees  for Partially Observed Systems",
    "abstract": "Neural network controllers have become popular in control tasks thanks to\ntheir flexibility and expressivity. Stability is a crucial property for\nsafety-critical dynamical systems, while stabilization of partially observed\nsystems, in many cases, requires controllers to retain and process long-term\nmemories of the past. We consider the important class of recurrent neural\nnetworks (RNN) as dynamic controllers for nonlinear uncertain\npartially-observed systems, and derive convex stability conditions based on\nintegral quadratic constraints, S-lemma and sequential convexification. To\nensure stability during the learning and control process, we propose a\nprojected policy gradient method that iteratively enforces the stability\nconditions in the reparametrized space taking advantage of mild additional\ninformation on system dynamics. Numerical experiments show that our method\nlearns stabilizing controllers while using fewer samples and achieving higher\nfinal performance compared with policy gradient.",
    "descriptor": "",
    "authors": [
      "Fangda Gu",
      "He Yin",
      "Laurent El Ghaoui",
      "Murat Arcak",
      "Peter Seiler",
      "Ming Jin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03861"
  },
  {
    "id": "arXiv:2109.03862",
    "title": "Juvenile state hypothesis: What we can learn from lottery ticket  hypothesis researches?",
    "abstract": "The proposition of lottery ticket hypothesis revealed the relationship\nbetween network structure and initialization parameters and the learning\npotential of neural networks. The original lottery ticket hypothesis performs\npruning and weight resetting after training convergence, exposing it to the\nproblem of forgotten learning knowledge and potential high cost of training.\nTherefore, we propose a strategy that combines the idea of neural network\nstructure search with a pruning algorithm to alleviate this problem. This\nalgorithm searches and extends the network structure on existing winning ticket\nsub-network to producing new winning ticket recursively. This allows the\ntraining and pruning process to continue without compromising performance. A\nnew winning ticket sub-network with deeper network structure, better\ngeneralization ability and better test performance can be obtained in this\nrecursive manner. This method can solve: the difficulty of training or\nperformance degradation of the sub-networks after pruning, the forgetting of\nthe weights of the original lottery ticket hypothesis and the difficulty of\ngenerating winning ticket sub-network when the final network structure is not\ngiven. We validate this strategy on the MNIST and CIFAR-10 datasets. And after\nrelating it to similar biological phenomena and relevant lottery ticket\nhypothesis studies in recent years, we will further propose a new hypothesis to\ndiscuss which factors that can keep a network juvenile, i.e., those possible\nfactors that influence the learning potential or generalization performance of\na neural network during training.",
    "descriptor": "\nComments: 7 pages, 8 figures, Under the review of AAAI2022\n",
    "authors": [
      "Di Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03862"
  },
  {
    "id": "arXiv:2109.03867",
    "title": "LSB: Local Self-Balancing MCMC in Discrete Spaces",
    "abstract": "Markov Chain Monte Carlo (MCMC) methods are promising solutions to sample\nfrom target distributions in high dimensions. While MCMC methods enjoy nice\ntheoretical properties, like guaranteed convergence and mixing to the true\ntarget, in practice their sampling efficiency depends on the choice of the\nproposal distribution and the target at hand. This work considers using machine\nlearning to adapt the proposal distribution to the target, in order to improve\nthe sampling efficiency in the purely discrete domain. Specifically, (i) it\nproposes a new parametrization for a family of proposal distributions, called\nlocally balanced proposals, (ii) it defines an objective function based on\nmutual information and (iii) it devises a learning procedure to adapt the\nparameters of the proposal to the target, thus achieving fast convergence and\nfast mixing. We call the resulting sampler as the Locally Self-Balancing\nSampler (LSB). We show through experimental analysis on the Ising model and\nBayesian networks that LSB is indeed able to improve the efficiency over a\nstate-of-the-art sampler based on locally balanced proposals, thus reducing the\nnumber of iterations required to converge, while achieving comparable mixing\nperformance.",
    "descriptor": "",
    "authors": [
      "Emanuele Sansone"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.03867"
  },
  {
    "id": "arXiv:2109.03870",
    "title": "Secure Blockchain-Based Supply Chain Management with Verifiable Digital  Twins",
    "abstract": "A major problem in blockchain-based supply chain management is the unclear\nvalidity of digital twins when dealing with digital representations of physical\ngoods. Indeed, the use of blockchain technology to trace goods is ineffective\nif there is no strong correspondence between what is physically exchanged and\nthe digital information that appears in blockchain transactions. In this work\nwe propose a model for strengthening the supply chain management of physical\ngoods leveraging blockchain technology through a digital-twin verification\nfeature. Our model can be instantiated in various scenarios and we have in\nparticular considered the popular case of food traceability. In contrast to\nweaker models known in the literature that propose their own ad-hoc properties\nto assess the robustness of their supply chain management systems, in this work\nwe use the formalism of secure computation, where processes are described\nthrough generic and natural ideal functionalities.",
    "descriptor": "",
    "authors": [
      "Vincenzo Botta",
      "Laura Fusco",
      "Attilio Mondelli",
      "Ivan Visconti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.03870"
  },
  {
    "id": "arXiv:2109.03876",
    "title": "Automated LoD-2 Model Reconstruction from Very-HighResolution  Satellite-derived Digital Surface Model and Orthophoto",
    "abstract": "In this paper, we propose a model-driven method that reconstructs LoD-2\nbuilding models following a \"decomposition-optimization-fitting\" paradigm. The\nproposed method starts building detection results through a deep learning-based\ndetector and vectorizes individual segments into polygons using a \"three-step\"\npolygon extraction method, followed by a novel grid-based decomposition method\nthat decomposes the complex and irregularly shaped building polygons to tightly\ncombined elementary building rectangles ready to fit elementary building\nmodels. We have optionally introduced OpenStreetMap (OSM) and Graph-Cut (GC)\nlabeling to further refine the orientation of 2D building rectangle. The 3D\nmodeling step takes building-specific parameters such as hip lines, as well as\nnon-rigid and regularized transformations to optimize the flexibility for using\na minimal set of elementary models. Finally, roof type of building models s\nrefined and adjacent building models in one building segment are merged into\nthe complex polygonal model. Our proposed method has addressed a few technical\ncaveats over existing methods, resulting in practically high-quality results,\nbased on our evaluation and comparative study on a diverse set of experimental\ndatasets of cities with different urban patterns.",
    "descriptor": "\nComments: 16 figures, 31 pages\n",
    "authors": [
      "Shengxi Gui",
      "Rongjun Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03876"
  },
  {
    "id": "arXiv:2109.03877",
    "title": "Computational Polarization: An Information-theoretic Method for  Resilient Computing",
    "abstract": "We introduce an error resilient distributed computing method based on an\nextension of the channel polarization phenomenon to distributed algorithms. The\nmethod leverages an algorithmic split operation that transforms two identical\ncompute nodes to slow and fast workers, which parallels the channel split\noperation in Polar Codes. This operation preserves the average runtime,\nanalogous to the conservation of Shannon capacity in channel polarization. By\nleveraging a recursive construction in a similar spirit to the Fast Fourier\nTransform, this method synthesizes virtual compute nodes with dispersed return\ntime distributions, which we call computational polarization. We show that the\nruntime distributions form a functional martingale processes, identify their\nlimiting distributions in closed-form expressions together with non-asymptotic\nconvergence rates, and prove strong convergence results in Banach spaces. We\nprovide an information-theoretic lower bound on the overall runtime of any\ncoded computation method and show that the computational polarization approach\nasymptotically achieves the optimal runtime for computing linear functions. An\nimportant advantage is the near linear time decoding procedure, which is\nsignificantly cheaper than Maximum Distance Separable codes.",
    "descriptor": "",
    "authors": [
      "Mert Pilanci"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.03877"
  },
  {
    "id": "arXiv:2109.03878",
    "title": "Unsupervised Detection and Clustering of Malicious TLS Flows",
    "abstract": "Malware abuses TLS to encrypt its malicious traffic, preventing examination\nby content signatures and deep packet inspection. Network detection of\nmalicious TLS flows is an important, but challenging, problem. Prior works have\nproposed supervised machine learning detectors using TLS features. However, by\ntrying to represent all malicious traffic, supervised binary detectors produce\nmodels that are too loose, thus introducing errors. Furthermore, they do not\ndistinguish flows generated by different malware. On the other hand, supervised\nmulti-class detectors produce tighter models and can classify flows by malware\nfamily, but require family labels, which are not available for many samples. To\naddress these limitations, this work proposes a novel unsupervised approach to\ndetect and cluster malicious TLS flows. Our approach takes as input network\ntraces from sandboxes. It clusters similar TLS flows using 90 features that\ncapture properties of the TLS client, TLS server, certificate, and encrypted\npayload; and uses the clusters to build an unsupervised detector that can\nassign a malicious flow to the cluster it belongs to, or determine it is\nbenign. We evaluate our approach using 972K traces from a commercial sandbox\nand 35M TLS flows from a research network. Our unsupervised detector achieves a\nF1 score of 0.91, compared to 0.82 for the state-of-the-art supervised\ndetector. The false detection rate of our detector is 0.032% measured over four\nmonths of traffic.",
    "descriptor": "",
    "authors": [
      "Gibran G\u00f3mez",
      "Platon Kotzias",
      "Matteo Dell'Amico",
      "Leyla Bilge",
      "Juan Caballero"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.03878"
  },
  {
    "id": "arXiv:2109.03880",
    "title": "Integrated and Adaptive Guidance and Control for Endoatmospheric  Missiles via Reinforcement Learning",
    "abstract": "We apply the meta reinforcement learning framework to optimize an integrated\nand adaptive guidance and flight control system for an air-to-air missile,\nimplementing the system as a deep neural network (the policy). The policy maps\nobservations directly to commanded rates of change for the missile's control\nsurface deflections, with the observations derived with minimal processing from\nthe computationally stabilized line of sight unit vector measured by a strap\ndown seeker, estimated rotational velocity from rate gyros, and control surface\ndeflection angles. The system induces intercept trajectories against a\nmaneuvering target that satisfy control constraints on fin deflection angles,\nand path constraints on look angle and load. We test the optimized system in a\nsix degrees-of-freedom simulator that includes a non-linear radome model and a\nstrapdown seeker model. Through extensive simulation, we demonstrate that the\nsystem can adapt to a large flight envelope and off nominal flight conditions\nthat include perturbation of aerodynamic coefficient parameters and center of\npressure locations. Moreover, we find that the system is robust to the\nparasitic attitude loop induced by radome refraction, imperfect seeker\nstabilization, and sensor scale factor errors. Finally, we compare our system's\nperformance to two benchmarks: a proportional navigation guidance system\nbenchmark in a simplified 3-DOF environment, which we take as an upper bound on\nperformance attainable with separate guidance and flight control systems, and a\nlongitudinal model of proportional navigation coupled with a three loop\nautopilot. We find that our system moderately outperforms the former, and\noutperforms the latter by a large margin.",
    "descriptor": "",
    "authors": [
      "Brian Gaudet",
      "Isaac Charcos",
      "Roberto Furfaro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03880"
  },
  {
    "id": "arXiv:2109.03888",
    "title": "Sparsity and Sentence Structure in Encoder-Decoder Attention of  Summarization Systems",
    "abstract": "Transformer models have achieved state-of-the-art results in a wide range of\nNLP tasks including summarization. Training and inference using large\ntransformer models can be computationally expensive. Previous work has focused\non one important bottleneck, the quadratic self-attention mechanism in the\nencoder. Modified encoder architectures such as LED or LoBART use local\nattention patterns to address this problem for summarization. In contrast, this\nwork focuses on the transformer's encoder-decoder attention mechanism. The cost\nof this attention becomes more significant in inference or training approaches\nthat require model-generated histories. First, we examine the complexity of the\nencoder-decoder attention. We demonstrate empirically that there is a sparse\nsentence structure in document summarization that can be exploited by\nconstraining the attention mechanism to a subset of input sentences, whilst\nmaintaining system performance. Second, we propose a modified architecture that\nselects the subset of sentences to constrain the encoder-decoder attention.\nExperiments are carried out on abstractive summarization tasks, including\nCNN/DailyMail, XSum, Spotify Podcast, and arXiv.",
    "descriptor": "\nComments: EMNLP 2021 (short paper, main conference)\n",
    "authors": [
      "Potsawee Manakul",
      "Mark J. F. Gales"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03888"
  },
  {
    "id": "arXiv:2109.03890",
    "title": "Model Explanations via the Axiomatic Causal Lens",
    "abstract": "Explaining the decisions of black-box models has been a central theme in the\nstudy of trustworthy ML. Numerous measures have been proposed in the\nliterature; however, none of them have been able to adopt a provably causal\ntake on explainability. Building upon Halpern and Pearl's formal definition of\na causal explanation, we derive an analogous set of axioms for the\nclassification setting, and use them to derive three explanation measures. Our\nfirst measure is a natural adaptation of Chockler and Halpern's notion of\ncausal responsibility, whereas the other two correspond to existing\ngame-theoretic influence measures. We present an axiomatic treatment for our\nproposed indices, showing that they can be uniquely characterized by a set of\ndesirable properties. We compliment this with computational analysis, providing\nprobabilistic approximation schemes for all of our proposed measures. Thus, our\nwork is the first to formally bridge the gap between model explanations,\ngame-theoretic influence, and causal analysis.",
    "descriptor": "",
    "authors": [
      "Vignesh Viswanathan",
      "Yair Zick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03890"
  },
  {
    "id": "arXiv:2109.03891",
    "title": "SORNet: Spatial Object-Centric Representations for Sequential  Manipulation",
    "abstract": "Sequential manipulation tasks require a robot to perceive the state of an\nenvironment and plan a sequence of actions leading to a desired goal state,\nwhere the ability to reason about spatial relationships among object entities\nfrom raw sensor inputs is crucial. Prior works relying on explicit state\nestimation or end-to-end learning struggle with novel objects. In this work, we\npropose SORNet (Spatial Object-Centric Representation Network), which extracts\nobject-centric representations from RGB images conditioned on canonical views\nof the objects of interest. We show that the object embeddings learned by\nSORNet generalize zero-shot to unseen object entities on three spatial\nreasoning tasks: spatial relationship classification, skill precondition\nclassification and relative direction regression, significantly outperforming\nbaselines. Further, we present real-world robotic experiments demonstrating the\nusage of the learned object embeddings in task planning for sequential\nmanipulation.",
    "descriptor": "",
    "authors": [
      "Wentao Yuan",
      "Chris Paxton",
      "Karthik Desingh",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03891"
  },
  {
    "id": "arXiv:2109.03892",
    "title": "Retrieve, Caption, Generate: Visual Grounding for Enhancing Commonsense  in Text Generation Models",
    "abstract": "We investigate the use of multimodal information contained in images as an\neffective method for enhancing the commonsense of Transformer models for text\ngeneration. We perform experiments using BART and T5 on concept-to-text\ngeneration, specifically the task of generative commonsense reasoning, or\nCommonGen. We call our approach VisCTG: Visually Grounded Concept-to-Text\nGeneration. VisCTG involves captioning images representing appropriate everyday\nscenarios, and using these captions to enrich and steer the generation process.\nComprehensive evaluation and analysis demonstrate that VisCTG noticeably\nimproves model performance while successfully addressing several issues of the\nbaseline generations, including poor commonsense, fluency, and specificity.",
    "descriptor": "",
    "authors": [
      "Steven Y. Feng",
      "Kevin Lu",
      "Zhuofu Tao",
      "Malihe Alikhani",
      "Teruko Mitamura",
      "Eduard Hovy",
      "Varun Gangal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03892"
  },
  {
    "id": "arXiv:2109.03893",
    "title": "Interpretable Run-Time Prediction and Planning in Co-Robotic  Environments",
    "abstract": "Mobile robots are traditionally developed to be reactive and avoid collisions\nwith surrounding humans, often moving in unnatural ways without following\nsocial protocols, forcing people to behave very differently from human-human\ninteraction rules. Humans, on the other hand, are seamlessly able to understand\nwhy they may interfere with surrounding humans and change their behavior based\non their reasoning, resulting in smooth, intuitive avoiding behaviors. In this\npaper, we propose an approach for a mobile robot to avoid interfering with the\ndesired paths of surrounding humans. We leverage a library of previously\nobserved trajectories to design a decision-tree based interpretable monitor\nthat: i) predicts whether the robot is interfering with surrounding humans, ii)\nexplains what behaviors are causing either prediction, and iii) plans\ncorrective behaviors if interference is predicted. We also propose a validation\nscheme to improve the predictive model at run-time. The proposed approach is\nvalidated with simulations and experiments involving an unmanned ground vehicle\n(UGV) performing go-to-goal operations in the presence of humans, demonstrating\nnon-interfering behaviors and run-time learning.",
    "descriptor": "\nComments: Final version to be presented at IROS 2021\n",
    "authors": [
      "Rahul Peddi",
      "Nicola Bezzo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03893"
  },
  {
    "id": "arXiv:2109.03901",
    "title": "Renovation of EdgeCloudSim: An Efficient Discrete-Event Approach",
    "abstract": "Due to the growing popularity of the Internet of Things, edge computing\nconcept has been widely studied to relieve the load on the original cloud and\nnetworks while improving the service quality for end-users. To simulate such a\ncomplex environment involving edge and cloud computing, EdgeCloudSim has been\nwidely adopted. However, it suffers from certain efficiency and scalability\nissues due to the ignorance of the deficiency in the originally adopted data\nstructures and maintenance strategies. Specifically, it generates all events at\nbeginning of the simulation and stores unnecessary historical information, both\nresult in unnecessarily high complexity for search operations. In this work, by\nfixing the mismatches on the concept of discrete-event simulation, we propose\nenhancement of EdgeCloudSim which improves not only the runtime efficiency of\nsimulation, but also the flexibility and scalability. Through extensive\nexperiments with statistical methods, we show that the enhancement does not\naffect the expressiveness of simulations while obtaining 2 orders of magnitude\nspeedup, especially when the device count is large.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Raphael Freymann",
      "Junjie Shi",
      "Jian-Jia Chen",
      "Kuan-Hsun Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.03901"
  },
  {
    "id": "arXiv:2109.03903",
    "title": "ELIT: Emory Language and Information Toolkit",
    "abstract": "We introduce ELIT, the Emory Language and Information Toolkit, which is a\ncomprehensive NLP framework providing transformer-based end-to-end models for\ncore tasks with a special focus on memory efficiency while maintaining\nstate-of-the-art accuracy and speed. Compared to existing toolkits, ELIT\nfeatures an efficient Multi-Task Learning (MTL) model with many downstream\ntasks that include lemmatization, part-of-speech tagging, named entity\nrecognition, dependency parsing, constituency parsing, semantic role labeling,\nand AMR parsing. The backbone of ELIT's MTL framework is a pre-trained\ntransformer encoder that is shared across tasks to speed up their inference.\nELIT provides pre-trained models developed on a remix of eight datasets. To\nscale up its service, ELIT also integrates a RESTful Client/Server combination.\nOn the server side, ELIT extends its functionality to cover other tasks such as\ntokenization and coreference resolution, providing an end user with agile\nresearch experience. All resources including the source codes, documentation,\nand pre-trained models are publicly available at\nhttps://github.com/emorynlp/elit.",
    "descriptor": "",
    "authors": [
      "Han He",
      "Liyan Xu",
      "Jinho D. Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03903"
  },
  {
    "id": "arXiv:2109.03905",
    "title": "A Convergence Analysis of the Parallel Schwarz Solution of the  Continuous Closest Point Method",
    "abstract": "The discretization of surface intrinsic PDEs has challenges that one might\nnot face in the flat space. The closest point method (CPM) is an embedding\nmethod that represents surfaces using a function that maps points in the flat\nspace to their closest points on the surface. This mapping brings intrinsic\ndata onto the embedding space, allowing us to numerically approximate PDEs by\nthe standard methods in the tubular neighborhood of the surface. Here, we solve\nthe surface intrinsic positive Helmholtz equation by the CPM paired with finite\ndifferences which usually yields a large, sparse, and non-symmetric system.\nDomain decomposition methods, especially Schwarz methods, are robust algorithms\nto solve these linear systems. While there have been substantial works on\nSchwarz methods, Schwarz methods for solving surface differential equations\nhave not been widely analyzed. In this work, we investigate the convergence of\nthe CPM coupled with Schwarz method on 1-manifolds in d-dimensional space of\nreal numbers.",
    "descriptor": "\nComments: To appear in the proceedings of the 26th Domain Decomposition meeting in Hong Kong\n",
    "authors": [
      "Alireza Yazdani",
      "Ronald D. Haynes",
      "Steven J. Ruuth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.03905"
  },
  {
    "id": "arXiv:2109.03906",
    "title": "Dynamic Locomotion Teleoperation of a Wheeled Humanoid Robot Reduced  Model with a Whole-Body Human-Machine Interface",
    "abstract": "Bilateral teleoperation provides humanoid robots with human planning\nintelligence while enabling the human to feel what the robot feels. It has the\npotential to transform physically capable humanoid robots into dynamically\nintelligent ones. However, dynamic bilateral locomotion teleoperation remains\nas a challenge due to the complex dynamics it involves. This work presents our\ninitial step to tackle this challenge via the concept of wheeled humanoid robot\nlocomotion teleoperation by body tilt. Specifically, we developed a\nforce-feedback-capable whole-body human-machine interface (HMI), and designed a\nforce feedback mapping and two teleoperation mappings that map the human's body\ntilt to the robot's velocity or acceleration. We compared the two mappings and\nstudied the force feedback's effect via an experiment, where seven human\nsubjects teleoperated a simulated robot with the HMI to perform dynamic target\ntracking tasks. The experimental results suggest that all subjects accomplished\nthe tasks with both mappings after practice, and the force feedback improved\ntheir performances. However, the subjects exhibited two distinct teleoperation\nstyles, which benefited from the force feedback differently. Moreover, the\nforce feedback affected the subjects' preferences on the teleoperation\nmappings, though most subjects performed better with the velocity mapping.",
    "descriptor": "",
    "authors": [
      "Sunyu Wang",
      "Joao Ramos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03906"
  },
  {
    "id": "arXiv:2109.03907",
    "title": "A Generalized Theory of Power",
    "abstract": "The complex representation of real-valued instantaneous power may be written\nas the sum of two complex powers, one Hermitian and the other non-Hermitian, or\ncomplementary. A virtue of this representation is that it consists of a power\ntriangle rotating around a fixed phasor, thus clarifying what should be meant\nby the power triangle. The in-phase and quadrature components of complementary\npower encode for active and non-active power. When instantaneous power is\ndefined for a Thevenin equivalent circuit, these are time-varying real and\nreactive power components. These claims hold for sinusoidal voltage and\ncurrent, and for non-sinusoidal voltage and current. Spectral representations\nof Hermitian, complementary, and instantaneous power show that,\nfrequency-by-frequency, these powers behave exactly as they behave in the\nsingle frequency sinusoidal case. Simple hardware diagrams show how\ninstantaneous active and non-active power may be extracted from metered voltage\nand current, even in certain non-sinusoidal cases.",
    "descriptor": "\nComments: 8 pages, 4 figures, submitted to IEEE Trans. on Power Systems\n",
    "authors": [
      "Louis L. Schar",
      "Dongliang Duan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.03907"
  },
  {
    "id": "arXiv:2109.03908",
    "title": "Iterative Respacing of Polygonal Curves",
    "abstract": "A $\\textit{polygonal curve}$ is a collection of $m$ connected line segments\nspecified as the linear interpolation of a list of points $\\{p_0, p_1, \\ldots,\np_m\\}$. These curves may be obtained by sampling points from an oriented curve\nin $\\mathbb{R}^n$. In applications it can be useful for this sample of points\nto be close to \\textit{equilateral}, with equal distance between consecutive\npoints. We present a computationally efficient method for respacing the points\nof a polygonal curve and show that iteration of this method converges to an\nequilateral polygonal curve.",
    "descriptor": "\nComments: For accompanying Mathematica implementation see: this https URL\n",
    "authors": [
      "Marcella Manivel",
      "Milena Silva",
      "Robert Thompson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.03908"
  },
  {
    "id": "arXiv:2109.03910",
    "title": "A Recipe For Arbitrary Text Style Transfer with Large Language Models",
    "abstract": "In this paper, we leverage large language models (LMs) to perform zero-shot\ntext style transfer. We present a prompting method that we call augmented\nzero-shot learning, which frames style transfer as a sentence rewriting task\nand requires only a natural language instruction, without model fine-tuning or\nexemplars in the target style. Augmented zero-shot learning is simple and\ndemonstrates promising results not just on standard style transfer tasks such\nas sentiment, but also on arbitrary transformations such as \"make this\nmelodramatic\" or \"insert a metaphor.\"",
    "descriptor": "",
    "authors": [
      "Emily Reif",
      "Daphne Ippolito",
      "Ann Yuan",
      "Andy Coenen",
      "Chris Callison-Burch",
      "Jason Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03910"
  },
  {
    "id": "arXiv:2109.03912",
    "title": "Weighted tensor Golub-Kahan-Tikhonov-type methods applied to image  processing using a t-product",
    "abstract": "This paper discusses weighted tensor Golub-Kahan-type bidiagonalization\nprocesses using the t-product. This product was introduced in [M. E. Kilmer and\nC. D. Martin, Factorization strategies for third order tensors, Linear Algebra\nAppl., 435 (2011), pp.~641--658]. A few steps of a bidiagonalization process\nwith a weighted least squares norm are carried out to reduce a large-scale\nlinear discrete ill-posed problem to a problem of small size. The weights are\ndetermined by symmetric positive definite (SPD) tensors. Tikhonov\nregularization is applied to the reduced problem. An algorithm for tensor\nCholesky factorization of SPD tensors is presented. The data is a laterally\noriented matrix or a general third order tensor. The use of a weighted\nFrobenius norm in the fidelity term of Tikhonov minimization problems is\nappropriate when the noise in the data has a known covariance matrix that is\nnot the identity. We use the discrepancy principle to determine both the\nregularization parameter in Tikhonov regularization and the number of\nbidiagonalization steps. Applications to image and video restoration are\nconsidered.",
    "descriptor": "",
    "authors": [
      "Lothar Reichel",
      "Ugochukwu O Ugwu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.03912"
  },
  {
    "id": "arXiv:2109.03913",
    "title": "BMS: Secure Decentralized Reconfiguration for Blockchain and BFT Systems",
    "abstract": "Reconfiguration of long-lived blockchain and Byzantine fault-tolerant (BFT)\nsystems poses fundamental security challenges. In case of state-of-the-art\nProof-of-Stake (PoS) blockchains, stake reconfiguration enables so-called\nlong-range attacks, which can lead to forks. Similarly, permissioned blockchain\nsystems, typically based on BFT, reconfigure internally, which makes them\nsusceptible to a similar \"I still work here\" attack.\nIn this work, we propose BMS (Blockchain/BFT Membership Service) offering a\nsecure and dynamic reconfiguration service for BFT and blockchain systems,\npreventing long-range and similar attacks. In particular: (1) we propose a root\nBMS for permissioned blockchains, implemented as an Ethereum smart contract and\nevaluate it reconfiguring the recently proposed Mir-BFT protocol, (2) we\ndiscuss how our BMS extends to PoS blockchains and how it can reduce PoS stake\nunbonding time from weeks/months to the order of minutes, and (3) we discuss\npossible extensions of BMS to hierarchical deployments as well as to multiple\nroot BMSs.",
    "descriptor": "",
    "authors": [
      "Selma Steinhoff",
      "Chrysoula Stathakopoulou",
      "Matej Pavlovic",
      "Marko Vukoli\u0107"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.03913"
  },
  {
    "id": "arXiv:2109.03914",
    "title": "Ensemble Fine-tuned mBERT for Translation Quality Estimation",
    "abstract": "Quality Estimation (QE) is an important component of the machine translation\nworkflow as it assesses the quality of the translated output without consulting\nreference translations. In this paper, we discuss our submission to the WMT\n2021 QE Shared Task. We participate in Task 2 sentence-level sub-task that\nchallenge participants to predict the HTER score for sentence-level\npost-editing effort. Our proposed system is an ensemble of multilingual BERT\n(mBERT)-based regression models, which are generated by fine-tuning on\ndifferent input settings. It demonstrates comparable performance with respect\nto the Pearson's correlation and beats the baseline system in MAE/ RMSE for\nseveral language pairs. In addition, we adapt our system for the zero-shot\nsetting by exploiting target language-relevant language pairs and\npseudo-reference translations.",
    "descriptor": "\nComments: The Sixth Conference on Machine Translation, WMT 2021\n",
    "authors": [
      "Shaika Chowdhury",
      "Naouel Baili",
      "Brian Vannah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03914"
  },
  {
    "id": "arXiv:2109.03915",
    "title": "Follow the guides: disentangling human and algorithmic curation in  online music consumption",
    "abstract": "The role of recommendation systems in the diversity of content consumption on\nplatforms is a much-debated issue. The quantitative state of the art often\noverlooks the existence of individual attitudes toward guidance, and eventually\nof different categories of users in this regard. Focusing on the case of music\nstreaming, we analyze the complete listening history of about 9k users over one\nyear and demonstrate that there is no blanket answer to the intertwinement of\nrecommendation use and consumption diversity: it depends on users. First we\ncompute for each user the relative importance of different access modes within\ntheir listening history, introducing a trichotomy distinguishing so-called\n`organic' use from algorithmic and editorial guidance. We thereby identify four\ncategories of users. We then focus on two scales related to content diversity,\nboth in terms of dispersion -- how much users consume the same content\nrepeatedly -- and popularity -- how popular is the content they consume. We\nshow that the two types of recommendation offered by music platforms --\nalgorithmic and editorial -- may drive the consumption of more or less diverse\ncontent in opposite directions, depending also strongly on the type of users.\nFinally, we compare users' streaming histories with the music programming of a\nselection of popular French radio stations during the same period. While radio\nprograms are usually more tilted toward repetition than users' listening\nhistories, they often program more songs from less popular artists. On the\nwhole, our results highlight the nontrivial effects of platform-mediated\nrecommendation on consumption, and lead us to speak of `filter niches' rather\nthan `filter bubbles'. They hint at further ramifications for the study and\ndesign of recommendation systems.",
    "descriptor": "\nComments: (c) The Authors 2021. To be published in Proc. 15th ACM Conference on Recommender Systems (RecSys '21), Sep 27-Oct 1, 2021, Amsterdam, NL. 16 pages, 6 figures, 3 tables. This is the authors' version of the work. It is posted here for your personal use. Not for redistribution\n",
    "authors": [
      "Quentin Villermet",
      "J\u00e9r\u00e9mie Poiroux",
      "Manuel Moussallam",
      "Thomas Louail",
      "Camille Roth"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.03915"
  },
  {
    "id": "arXiv:2109.03918",
    "title": "Quality-Diversity Meta-Evolution: customising behaviour spaces to a  meta-objective",
    "abstract": "Quality-Diversity (QD) algorithms evolve behaviourally diverse and\nhigh-performing solutions. To illuminate the elite solutions for a space of\nbehaviours, QD algorithms require the definition of a suitable behaviour space.\nIf the behaviour space is high-dimensional, a suitable dimensionality reduction\ntechnique is required to maintain a limited number of behavioural niches. While\ncurrent methodologies for automated behaviour spaces focus on changing the\ngeometry or on unsupervised learning, there remains a need for customising\nbehavioural diversity to a particular meta-objective specified by the end-user.\nIn the newly emerging framework of QD Meta-Evolution, or QD-Meta for short, one\nevolves a population of QD algorithms, each with different algorithmic and\nrepresentational characteristics, to optimise the algorithms and their\nresulting archives to a user-defined meta-objective. Despite promising results\ncompared to traditional QD algorithms, QD-Meta has yet to be compared to\nstate-of-the-art behaviour space automation methods such as Centroidal Voronoi\nTessellations Multi-dimensional Archive of Phenotypic Elites Algorithm\n(CVT-MAP-Elites) and Autonomous Robots Realising their Abilities (AURORA). This\npaper performs an empirical study of QD-Meta on function optimisation and\nmultilegged robot locomotion benchmarks. Results demonstrate that QD-Meta\narchives provide improved average performance and faster adaptation to a priori\nunknown changes to the environment when compared to CVT-MAP-Elites and AURORA.\nA qualitative analysis shows how the resulting archives are tailored to the\nmeta-objectives provided by the end-user.",
    "descriptor": "",
    "authors": [
      "David M. Bossens",
      "Danesh Tarapore"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03918"
  },
  {
    "id": "arXiv:2109.03919",
    "title": "Age-Aware Stochastic Hybrid Systems: Stability, Solutions, and  Applications",
    "abstract": "In this paper, we analyze status update systems modeled through the\nStochastic Hybrid Systems (SHSs) tool. Contrary to previous works, we allow the\nsystem's transition dynamics to be functions of the Age of Information (AoI).\nThis dependence allows us to encapsulate many applications and opens the door\nfor more sophisticated systems to be studied. However, this same dependence on\nthe AoI engenders technical and analytical difficulties that we address in this\npaper. Specifically, we first showcase several characteristics of the age\nprocesses modeled through the SHSs tool. Then, we provide a framework to\nestablish the Lagrange stability and positive recurrence of these processes.\nBuilding on this, we provide an approach to compute the m-th moment of the age\nprocesses. Interestingly, this technique allows us to approximate the average\nage by solving a simple set of linear equations. Equipped with this approach,\nwe also provide a sequential convex approximation method to optimize the\naverage age by calibrating the parameters of the system. Finally, we consider\nan age-dependent CSMA environment where the backoff duration depends on the\ninstantaneous age. By leveraging our analysis, we contrast its performance to\nthe age-blind CSMA and showcase the age performance gain provided by the\nformer.",
    "descriptor": "",
    "authors": [
      "Ali Maatouk",
      "Mohamad Assaad",
      "Anthony Ephremides"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.03919"
  },
  {
    "id": "arXiv:2109.03926",
    "title": "Transformers in the loop: Polarity in neural models of language",
    "abstract": "Representation of linguistic phenomena in computational language models is\ntypically assessed against the predictions of existing linguistic theories of\nthese phenomena. Using the notion of polarity as a case study, we show that\nthis is not always the most adequate set-up. We probe polarity via so-called\n'negative polarity items' (in particular, English 'any') in two pre-trained\nTransformer-based models (BERT and GPT-2). We show that -- at least for\npolarity -- metrics derived from language models are more consistent with data\nfrom psycholinguistic experiments than linguistic theory predictions.\nEstablishing this allows us to more adequately evaluate the performance of\nlanguage models and also to use language models to discover new insights into\nnatural language grammar beyond existing linguistic theories. Overall, our\nresults encourage a closer tie between experiments with human subjects and with\nlanguage models. We propose methods to enable this closer tie, with language\nmodels as part of experimental pipeline, and show this pipeline at work.",
    "descriptor": "",
    "authors": [
      "Lisa Bylinina",
      "Alexey Tikhonov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03926"
  },
  {
    "id": "arXiv:2109.03934",
    "title": "Resistive Neural Hardware Accelerators",
    "abstract": "Deep Neural Networks (DNNs), as a subset of Machine Learning (ML) techniques,\nentail that real-world data can be learned and that decisions can be made in\nreal-time. However, their wide adoption is hindered by a number of software and\nhardware limitations. The existing general-purpose hardware platforms used to\naccelerate DNNs are facing new challenges associated with the growing amount of\ndata and are exponentially increasing the complexity of computations. An\nemerging non-volatile memory (NVM) devices and processing-in-memory (PIM)\nparadigm is creating a new hardware architecture generation with increased\ncomputing and storage capabilities. In particular, the shift towards\nReRAM-based in-memory computing has great potential in the implementation of\narea and power efficient inference and in training large-scale neural network\narchitectures. These can accelerate the process of the IoT-enabled AI\ntechnologies entering our daily life. In this survey, we review the\nstate-of-the-art ReRAM-based DNN many-core accelerators, and their superiority\ncompared to CMOS counterparts was shown. The review covers different aspects of\nhardware and software realization of DNN accelerators, their present\nlimitations, and future prospectives. In particular, comparison of the\naccelerators shows the need for the introduction of new performance metrics and\nbenchmarking standards. In addition, the major concerns regarding the efficient\ndesign of accelerators include a lack of accuracy in simulation tools for\nsoftware and hardware co-design.",
    "descriptor": "",
    "authors": [
      "Kamilya Smagulova",
      "Mohammed E. Fouda",
      "Fadi Kurdahi",
      "Khaled Salama",
      "Ahmed Eltawil"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.03934"
  },
  {
    "id": "arXiv:2109.03938",
    "title": "Capacity and Stability Regions for Layered Packet Erasure Broadcast  Channels with Feedback",
    "abstract": "This paper focuses on the Layered Packet Erasure Broadcast Channel (LPE-BC)\nwith Channel Output Feedback (COF) available at the transmitter. The LPE-BC is\na high-SNR approximation of the fading Gaussian BC recently proposed by Tse and\nYates, who characterized the capacity region for any number of users and any\nnumber of layers when there is no COF. This paper provides a comparative\noverview of this channel model along the following lines: First, inner and\nouter bounds to the capacity region (set of achievable rates with backlogged\narrivals) are presented: a) a new outer bound based on the idea of the\nphysically degraded broadcast channel, and b) an inner bound of the LPE-BC with\nCOF for the case of two users and any number of layers. Next, an inner bound on\nthe stability region (set of exogenous arrival rates for which packet arrival\nqueues are stable) for the same model is derived. The capacity region inner\nbound generalizes past results for the two-user erasure BC, which is a special\ncase of the LPE-BC with COF with only one layer. The novelty lies in the use of\ninter-user and inter-layer network coding retransmissions (for those packets\nthat have only been received by the unintended user), where each random linear\ncombination may involve packets intended for any user originally sent on any of\nthe layers. For the case of $K = 2$ users and $Q \\geq 1$ layers, the inner\nbounds to the capacity region and the stability region coincide; both\nstrategically employ the novel retransmission protocol. For the case of $Q = 2$\nlayers, sufficient conditions are derived by Fourier-Motzkin elimination for\nthe inner bound on the stability region to coincide with the capacity outer\nbound, thus showing that in those cases the capacity and stability regions\ncoincide.",
    "descriptor": "",
    "authors": [
      "Siyao Li",
      "Daniela Tuninetti",
      "Natasha Devroye",
      "Hulya Seferoglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.03938"
  },
  {
    "id": "arXiv:2109.03939",
    "title": "What's Hidden in a One-layer Randomly Weighted Transformer?",
    "abstract": "We demonstrate that, hidden within one-layer randomly weighted neural\nnetworks, there exist subnetworks that can achieve impressive performance,\nwithout ever modifying the weight initializations, on machine translation\ntasks. To find subnetworks for one-layer randomly weighted neural networks, we\napply different binary masks to the same weight matrix to generate different\nlayers. Hidden within a one-layer randomly weighted Transformer, we find that\nsubnetworks that can achieve 29.45/17.29 BLEU on IWSLT14/WMT14. Using a fixed\npre-trained embedding layer, the previously found subnetworks are smaller than,\nbut can match 98%/92% (34.14/25.24 BLEU) of the performance of, a trained\nTransformer small/base on IWSLT14/WMT14. Furthermore, we demonstrate the\neffectiveness of larger and deeper transformers in this setting, as well as the\nimpact of different initialization methods. We released the source code at\nhttps://github.com/sIncerass/one_layer_lottery_ticket.",
    "descriptor": "\nComments: EMNLP 2021 (short)\n",
    "authors": [
      "Sheng Shen",
      "Zhewei Yao",
      "Douwe Kiela",
      "Kurt Keutzer",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03939"
  },
  {
    "id": "arXiv:2109.03941",
    "title": "Unsupervised Pre-training with Structured Knowledge for Improving  Natural Language Inference",
    "abstract": "While recent research on natural language inference has considerably\nbenefited from large annotated datasets, the amount of inference-related\nknowledge (including commonsense) provided in the annotated data is still\nrather limited. There have been two lines of approaches that can be used to\nfurther address the limitation: (1) unsupervised pretraining can leverage\nknowledge in much larger unstructured text data; (2) structured (often\nhuman-curated) knowledge has started to be considered in neural-network-based\nmodels for NLI. An immediate question is whether these two approaches\ncomplement each other, or how to develop models that can bring together their\nadvantages. In this paper, we propose models that leverage structured knowledge\nin different components of pre-trained models. Our results show that the\nproposed models perform better than previous BERT-based state-of-the-art\nmodels. Although our models are proposed for NLI, they can be easily extended\nto other sentence or sentence-pair classification problems.",
    "descriptor": "",
    "authors": [
      "Xiaoyu Yang",
      "Xiaodan Zhu",
      "Zhan Shi",
      "Tianda Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03941"
  },
  {
    "id": "arXiv:2109.03942",
    "title": "A Formal Description of Sorani Kurdish Morphology",
    "abstract": "Sorani Kurdish, also known as Central Kurdish, has a complex morphology,\nparticularly due to the patterns in which morphemes appear. Although several\naspects of Kurdish morphology have been studied, such as pronominal endoclitics\nand Izafa constructions, Sorani Kurdish morphology has received trivial\nattention in computational linguistics. Moreover, some morphemes, such as the\nemphasis endoclitic =\\^i\\c{s}, and derivational morphemes have not been\npreviously studied. To tackle the complex morphology of Sorani, we provide a\nthorough description of Sorani Kurdish morphological and morphophonological\nconstructions in a formal way such that they can be used as finite-state\ntransducers for morphological analysis and synthesis.",
    "descriptor": "\nComments: It should be noted that the current manuscript is being completed. Any suggestions or reporting of errors will be highly appreciated. 36 Pages\n",
    "authors": [
      "Sina Ahmadi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03942"
  },
  {
    "id": "arXiv:2109.03945",
    "title": "Vulnerabilities and Attacks Against Industrial Control Systems and  Critical Infrastructures",
    "abstract": "Critical infrastructures (CI) and industrial organizations aggressively move\ntowards integrating elements of modern Information Technology (IT) into their\nmonolithic Operational Technology (OT) architectures. Yet, as OT systems\nprogressively become more and more interconnected, they silently have turned\ninto alluring targets for diverse groups of adversaries. Meanwhile, the\ninherent complexity of these systems, along with their advanced-in-age nature,\nprevents defenders from fully applying contemporary security controls in a\ntimely manner. Forsooth, the combination of these hindering factors has led to\nsome of the most severe cybersecurity incidents of the past years. This work\ncontributes a full-fledged and up-to-date survey of the most prominent threats\nagainst Industrial Control Systems (ICS) along with the communication protocols\nand devices adopted in these environments. Our study highlights that threats\nagainst CI follow an upward spiral due to the mushrooming of commodity tools\nand techniques that can facilitate either the early or late stages of attacks.\nFurthermore, our survey exposes that existing vulnerabilities in the design and\nimplementation of several of the OT-specific network protocols may easily grant\nadversaries the ability to decisively impact physical processes. We provide a\ncategorization of such threats and the corresponding vulnerabilities based on\nvarious criteria. As far as we are aware, this is the first time an exhaustive\nand detailed survey of this kind is attempted.",
    "descriptor": "",
    "authors": [
      "Georgios Michail Makrakis",
      "Constantinos Kolias",
      "Georgios Kambourakis",
      "Craig Rieger",
      "Jacob Benjamin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.03945"
  },
  {
    "id": "arXiv:2109.03947",
    "title": "SensiX++: Bringing MLOPs and Multi-tenant Model Serving to Sensory Edge  Devices",
    "abstract": "We present SensiX++ - a multi-tenant runtime for adaptive model execution\nwith integrated MLOps on edge devices, e.g., a camera, a microphone, or IoT\nsensors. SensiX++ operates on two fundamental principles - highly modular\ncomponentisation to externalise data operations with clear abstractions and\ndocument-centric manifestation for system-wide orchestration. First, a data\ncoordinator manages the lifecycle of sensors and serves models with correct\ndata through automated transformations. Next, a resource-aware model server\nexecutes multiple models in isolation through model abstraction, pipeline\nautomation and feature sharing. An adaptive scheduler then orchestrates the\nbest-effort executions of multiple models across heterogeneous accelerators,\nbalancing latency and throughput. Finally, microservices with REST APIs serve\nsynthesised model predictions, system statistics, and continuous deployment.\nCollectively, these components enable SensiX++ to serve multiple models\nefficiently with fine-grained control on edge devices while minimising data\noperation redundancy, managing data and device heterogeneity, reducing resource\ncontention and removing manual MLOps. We benchmark SensiX++ with ten different\nvision and acoustics models across various multi-tenant configurations on\ndifferent edge accelerators (Jetson AGX and Coral TPU) designed for sensory\ndevices. We report on the overall throughput and quantified benefits of various\nautomation components of SensiX++ and demonstrate its efficacy to significantly\nreduce operational complexity and lower the effort to deploy, upgrade,\nreconfigure and serve embedded models on edge devices.",
    "descriptor": "\nComments: 13 pages, 15 figures\n",
    "authors": [
      "Chulhong Min",
      "Akhil Mathur",
      "Utku Gunay Acer",
      "Alessandro Montanari",
      "Fahim Kawsar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03947"
  },
  {
    "id": "arXiv:2109.03950",
    "title": "Study of the Subtyping Machine of Nominal Subtyping with Variance (full  version)",
    "abstract": "This is a study of the computing power of the subtyping machine behind\nKennedy and Pierce's nominal subtyping with variance. We depict the lattice of\nfragments of Kennedy and Pierce's type system and characterize their computing\npower in terms of regular, context-free, deterministic, and non-deterministic\ntree languages. Based on the theory, we present Treetop -- a generator of C#\nimplementations of subtyping machines. The software artifact constitutes the\nfirst feasible (yet POC) fluent API generator to support context-free API\nprotocols in a decidable type system fragment.",
    "descriptor": "",
    "authors": [
      "Ori Roth"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.03950"
  },
  {
    "id": "arXiv:2109.03951",
    "title": "Learning the Physics of Particle Transport via Transformers",
    "abstract": "Particle physics simulations are the cornerstone of nuclear engineering\napplications. Among them radiotherapy (RT) is crucial for society, with 50% of\ncancer patients receiving radiation treatments. For the most precise targeting\nof tumors, next generation RT treatments aim for real-time correction during\nradiation delivery, necessitating particle transport algorithms that yield\nprecise dose distributions in sub-second times even in highly heterogeneous\npatient geometries. This is infeasible with currently available, purely physics\nbased simulations. In this study, we present a data-driven dose calculation\nalgorithm predicting the dose deposited by mono-energetic proton beams for\narbitrary energies and patient geometries. Our approach frames particle\ntransport as sequence modeling, where convolutional layers extract important\nspatial features into tokens and the transformer self-attention mechanism\nroutes information between such tokens in the sequence and a beam energy token.\nWe train our network and evaluate prediction accuracy using computationally\nexpensive but accurate Monte Carlo (MC) simulations, considered the gold\nstandard in particle physics. Our proposed model is 33 times faster than\ncurrent clinical analytic pencil beam algorithms, improving upon their accuracy\nin the most heterogeneous and challenging geometries. With a relative error of\n0.34% and very high gamma pass rate of 99.59% (1%, 3 mm), it also greatly\noutperforms the only published similar data-driven proton dose algorithm, even\nat a finer grid resolution. Offering MC precision 400 times faster, our model\ncould overcome a major obstacle that has so far prohibited real-time adaptive\nproton treatments and significantly increase cancer treatment efficacy. Its\npotential to model physics interactions of other particles could also boost\nheavy ion treatment planning procedures limited by the speed of traditional\nmethods.",
    "descriptor": "",
    "authors": [
      "Oscar Pastor-Serrano",
      "Zolt\u00e1n Perk\u00f3"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03951"
  },
  {
    "id": "arXiv:2109.03952",
    "title": "Attributing Fair Decisions with Attention Interventions",
    "abstract": "The widespread use of Artificial Intelligence (AI) in consequential domains,\nsuch as healthcare and parole decision-making systems, has drawn intense\nscrutiny on the fairness of these methods. However, ensuring fairness is often\ninsufficient as the rationale for a contentious decision needs to be audited,\nunderstood, and defended. We propose that the attention mechanism can be used\nto ensure fair outcomes while simultaneously providing feature attributions to\naccount for how a decision was made. Toward this goal, we design an\nattention-based model that can be leveraged as an attribution framework. It can\nidentify features responsible for both performance and fairness of the model\nthrough attention interventions and attention weight manipulation. Using this\nattribution framework, we then design a post-processing bias mitigation\nstrategy and compare it with a suite of baselines. We demonstrate the\nversatility of our approach by conducting experiments on two distinct data\ntypes, tabular and textual.",
    "descriptor": "",
    "authors": [
      "Ninareh Mehrabi",
      "Umang Gupta",
      "Fred Morstatter",
      "Greg Ver Steeg",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03952"
  },
  {
    "id": "arXiv:2109.03955",
    "title": "NU:BRIEF -- A Privacy-aware Newsletter Personalization Engine for  Publishers",
    "abstract": "Newsletters have (re-) emerged as a powerful tool for publishers to engage\nwith their readers directly and more effectively. Despite the diversity in\ntheir audiences, publishers' newsletters remain largely a one-size-fits-all\noffering, which is suboptimal. In this paper, we present NU:BRIEF, a web\napplication for publishers that enables them to personalize their newsletters\nwithout harvesting personal data. Personalized newsletters build a habit and\nbecome a great conversion tool for publishers, providing an alternative\nreaders-generated revenue model to a declining ad/clickbait-centered business\nmodel.",
    "descriptor": "\nComments: Fifteenth ACM Conference on Recommender Systems (RecSys '21), September 27-October 1, 2021, Amsterdam, Netherlands\n",
    "authors": [
      "Ernesto Diaz-Aviles",
      "Claudia Orellana-Rodriguez",
      "Igor Brigadir",
      "Reshma Narayanan Kutty"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03955"
  },
  {
    "id": "arXiv:2109.03956",
    "title": "AdjointNet: Constraining machine learning models with physics-based  codes",
    "abstract": "Physics-informed Machine Learning has recently become attractive for learning\nphysical parameters and features from simulation and observation data. However,\nmost existing methods do not ensure that the physics, such as balance laws\n(e.g., mass, momentum, energy conservation), are constrained. Some recent works\n(e.g., physics-informed neural networks) softly enforce physics constraints by\nincluding partial differential equation (PDE)-based loss functions but need\nre-discretization of the PDEs using auto-differentiation. Training these neural\nnets on observational data showed that one could solve forward and inverse\nproblems in one shot. They evaluate the state variables and the parameters in a\nPDE. This re-discretization of PDEs is not necessarily an attractive option for\ndomain scientists that work with physics-based codes that have been developed\nfor decades with sophisticated discretization techniques to solve complex\nprocess models and advanced equations of state. This paper proposes a physics\nconstrained machine learning framework, AdjointNet, allowing domain scientists\nto embed their physics code in neural network training workflows. This\nembedding ensures that physics is constrained everywhere in the domain.\nAdditionally, the mathematical properties such as consistency, stability, and\nconvergence vital to the numerical solution of a PDE are still satisfied. We\nshow that the proposed AdjointNet framework can be used for parameter\nestimation (and uncertainty quantification by extension) and experimental\ndesign using active learning. The applicability of our framework is\ndemonstrated for four flow cases. Results show that AdjointNet-based inversion\ncan estimate process model parameters with reasonable accuracy. These examples\ndemonstrate the applicability of using existing software with no changes in\nsource code to perform accurate and reliable inversion of model parameters.",
    "descriptor": "",
    "authors": [
      "Satish Karra",
      "Bulbul Ahmmed",
      "Maruti K. Mudunuru"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2109.03956"
  },
  {
    "id": "arXiv:2109.03958",
    "title": "TrAISformer-A generative transformer for AIS trajectory prediction",
    "abstract": "Modelling trajectory in general, and vessel trajectory in particular, is a\ndifficult task because of the multimodal and complex nature of motion data. In\nthis paper, we present TrAISformer-a novel deep learning architecture that can\nforecast vessel positions using AIS (Automatic Identification System)\nobservations. We address the multimodality by introducing a discrete\nrepresentation of AIS data and re-frame the prediction, which is originally a\nregression problem, as a classification problem. The model encodes complex\nmovement patterns in AIS data in high-dimensional vectors, then applies a\ntransformer to extract useful long-term correlations from sequences of those\nembeddings to sample future vessel positions. Experimental results on real,\npublic AIS data demonstrate that TrAISformer significantly outperforms\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Duong Nguyen",
      "Ronan Fablet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03958"
  },
  {
    "id": "arXiv:2109.03961",
    "title": "Improving Building Segmentation for Off-Nadir Satellite Imagery",
    "abstract": "Automatic building segmentation is an important task for satellite imagery\nanalysis and scene understanding. Most existing segmentation methods focus on\nthe case where the images are taken from directly overhead (i.e., low\noff-nadir/viewing angle). These methods often fail to provide accurate results\non satellite images with larger off-nadir angles due to the higher noise level\nand lower spatial resolution. In this paper, we propose a method that is able\nto provide accurate building segmentation for satellite imagery captured from a\nlarge range of off-nadir angles. Based on Bayesian deep learning, we explicitly\ndesign our method to learn the data noise via aleatoric and epistemic\nuncertainty modeling. Satellite image metadata (e.g., off-nadir angle and\nground sample distance) is also used in our model to further improve the\nresult. We show that with uncertainty modeling and metadata injection, our\nmethod achieves better performance than the baseline method, especially for\nnoisy images taken from large off-nadir angles.",
    "descriptor": "\nComments: This is an extended version of our ACM SIGSPATIAL'21 conference paper\n",
    "authors": [
      "Hanxiang Hao",
      "Sriram Baireddy",
      "Kevin LaTourette",
      "Latisha Konz",
      "Moses Chan",
      "Mary L. Comer",
      "Edward J. Delp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03961"
  },
  {
    "id": "arXiv:2109.03962",
    "title": "Learning-based Moving Horizon Estimation through Differentiable Convex  Optimization Layers",
    "abstract": "For control it is essential to obtain an accurate estimate of the current\nsystem state, based on uncertain sensor measurements and existing system\nknowledge. An optimization-based moving horizon estimation (MHE) approach uses\na dynamical model of the system, and further allows to integrate physical\nconstraints on system states and uncertainties, to obtain a trajectory of state\nestimates. In this work, we address the problem of state estimation in case of\nconstrained linear systems with parametric uncertainty. The proposed approach\nmakes use of differentiable convex optimization layers to formulate an MHE\nstate estimator, for systems with uncertain parameters. This formulation allows\nus to obtain the gradient of a squared output error, based on sensor\nmeasurements and state estimates, with respect to the uncertain system\nparameters, and update the believe of the parameters online using stochastic\ngradient descent (SGD). In a numerical example of estimating temperatures of a\ngroup of manufacturing machines, we show the performance of learning the\nunknown system parameters and the benefits of integrating physical state\nconstraints in the MHE formulation.",
    "descriptor": "",
    "authors": [
      "Simon Muntwiler",
      "Kim P. Wabersich",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.03962"
  },
  {
    "id": "arXiv:2109.03966",
    "title": "Sensitive Samples Revisited: Detecting Neural Network Attacks Using  Constraint Solvers",
    "abstract": "Neural Networks are used today in numerous security- and safety-relevant\ndomains and are, as such, a popular target of attacks that subvert their\nclassification capabilities, by manipulating the network parameters. Prior work\nhas introduced sensitive samples -- inputs highly sensitive to parameter\nchanges -- to detect such manipulations, and proposed a gradient ascent-based\napproach to compute them. In this paper we offer an alternative, using symbolic\nconstraint solvers. We model the network and a formal specification of a\nsensitive sample in the language of the solver and ask for a solution. This\napproach supports a rich class of queries, corresponding, for instance, to the\npresence of certain types of attacks. Unlike earlier techniques, our approach\ndoes not depend on convex search domains, or on the suitability of a starting\npoint for the search. We address the performance limitations of constraint\nsolvers by partitioning the search space for the solver, and exploring the\npartitions according to a balanced schedule that still retains completeness of\nthe search. We demonstrate the impact of the use of solvers in terms of\nfunctionality and search efficiency, using a case study for the detection of\nTrojan attacks on Neural Networks.",
    "descriptor": "\nComments: In Proceedings SCSS 2021, arXiv:2109.02501\n",
    "authors": [
      "Amel Nestor Docena",
      "Thomas Wahl",
      "Trevor Pearce",
      "Yunsi Fei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.03966"
  },
  {
    "id": "arXiv:2109.03969",
    "title": "Multilingual Speech Recognition for Low-Resource Indian Languages using  Multi-Task conformer",
    "abstract": "Transformers have recently become very popular for sequence-to-sequence\napplications such as machine translation and speech recognition. In this work,\nwe propose a multi-task learning-based transformer model for low-resource\nmultilingual speech recognition for Indian languages. Our proposed model\nconsists of a conformer [1] encoder and two parallel transformer decoders. We\nuse a phoneme decoder (PHN-DEC) for the phoneme recognition task and a grapheme\ndecoder (GRP-DEC) to predict grapheme sequence. We consider the phoneme\nrecognition task as an auxiliary task for our multi-task learning framework. We\njointly optimize the network for both phoneme and grapheme recognition tasks\nusing Joint CTC-Attention [2] training. We use a conditional decoding scheme to\ninject the language information into the model before predicting the grapheme\nsequence. Our experiments show that our proposed approach can obtain\nsignificant improvement over previous approaches [4]. We also show that our\nconformer-based dual-decoder approach outperforms both the transformer-based\ndual-decoder approach and single decoder approach. Finally, We compare\nmonolingual ASR models with our proposed multilingual ASR approach.",
    "descriptor": "\nComments: 5 pages. arXiv admin note: substantial text overlap with arXiv:2109.03277\n",
    "authors": [
      "Krishna D N"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.03969"
  },
  {
    "id": "arXiv:2109.03970",
    "title": "PowerGym: A Reinforcement Learning Environment for Volt-Var Control in  Power Distribution Systems",
    "abstract": "We introduce PowerGym, an open-source reinforcement learning environment for\nVolt-Var control in power distribution systems. Following OpenAI Gym APIs,\nPowerGym targets minimizing power loss and voltage violations under physical\nnetworked constraints. PowerGym provides four distribution systems (13Bus,\n34Bus, 123Bus, and 8500Node) based on IEEE benchmark systems and design\nvariants for various control difficulties. To foster generalization, PowerGym\noffers a detailed customization guide for users working with their distribution\nsystems. As a demonstration, we examine state-of-the-art reinforcement learning\nalgorithms in PowerGym and validate the environment by studying controller\nbehaviors.",
    "descriptor": "",
    "authors": [
      "Ting-Han Fan",
      "Xian Yeow Lee",
      "Yubo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03970"
  },
  {
    "id": "arXiv:2109.03975",
    "title": "Where Did You Learn That From? Surprising Effectiveness of Membership  Inference Attacks Against Temporally Correlated Data in Deep Reinforcement  Learning",
    "abstract": "While significant research advances have been made in the field of deep\nreinforcement learning, a major challenge to widespread industrial adoption of\ndeep reinforcement learning that has recently surfaced but little explored is\nthe potential vulnerability to privacy breaches. In particular, there have been\nno concrete adversarial attack strategies in literature tailored for studying\nthe vulnerability of deep reinforcement learning algorithms to membership\ninference attacks. To address this gap, we propose an adversarial attack\nframework tailored for testing the vulnerability of deep reinforcement learning\nalgorithms to membership inference attacks. More specifically, we design a\nseries of experiments to investigate the impact of temporal correlation, which\nnaturally exists in reinforcement learning training data, on the probability of\ninformation leakage. Furthermore, we study the differences in the performance\nof \\emph{collective} and \\emph{individual} membership attacks against deep\nreinforcement learning algorithms. Experimental results show that the proposed\nadversarial attack framework is surprisingly effective at inferring the data\nused during deep reinforcement training with an accuracy exceeding $84\\%$ in\nindividual and $97\\%$ in collective mode on two different control tasks in\nOpenAI Gym, which raises serious privacy concerns in the deployment of models\nresulting from deep reinforcement learning. Moreover, we show that the learning\nstate of a reinforcement learning algorithm significantly influences the level\nof the privacy breach.",
    "descriptor": "",
    "authors": [
      "Maziar Gomrokchi",
      "Susan Amin",
      "Hossein Aboutalebi",
      "Alexander Wong",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.03975"
  },
  {
    "id": "arXiv:2109.03976",
    "title": "Active Multi-Object Exploration and Recognition via Tactile Whiskers",
    "abstract": "Robotic exploration under uncertain environments is challenging when optical\ninformation is not available. In this paper, we propose an autonomous solution\nof exploring an unknown task space based on tactile sensing alone. We first\ndesigned a whisker sensor based on MEMS barometer devices. This sensor can\nacquire contact information by interacting with the environment\nnon-intrusively.\nThis sensor is accompanied by a planning technique to generate exploration\ntrajectories by using mere tactile perception. This technique relies on a\nhybrid policy for tactile exploration, which includes a proactive informative\npath planner for object searching, and a reactive Hopf oscillator for contour\ntracing. Results indicate that the hybrid exploration policy can increase the\nefficiency of object discovery.\nLast, scene understanding was facilitated by segmenting objects and\nclassification. A classifier was developed to recognize the object categories\nbased on the geometric features collected by the whisker sensor. Such an\napproach demonstrates the whisker sensor, together with the tactile\nintelligence, can provide sufficiently discriminative features to distinguish\nobjects.",
    "descriptor": "",
    "authors": [
      "Chenxi Xiao",
      "Shujia Xu",
      "Wenzhuo Wu",
      "Juan Wachs"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03976"
  },
  {
    "id": "arXiv:2109.03988",
    "title": "Proceedings 8th Workshop on Horn Clauses for Verification and Synthesis",
    "abstract": "This volume contains the post-proceedings of the 8th Workshop on Horn Clauses\nfor Verification and Synthesis (HCVS), which took place virtually due to\nCovid-19 pandemic as an affiliated workshop of ETAPS.",
    "descriptor": "",
    "authors": [
      "Hossein Hojjat",
      "Bishoksan Kafle"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.03988"
  },
  {
    "id": "arXiv:2109.03989",
    "title": "Detecting Attacks on IoT Devices using Featureless 1D-CNN",
    "abstract": "The generalization of deep learning has helped us, in the past, address\nchallenges such as malware identification and anomaly detection in the network\nsecurity domain. However, as effective as it is, scarcity of memory and\nprocessing power makes it difficult to perform these tasks in Internet of\nThings (IoT) devices. This research finds an easy way out of this bottleneck by\ndepreciating the need for feature engineering and subsequent processing in\nmachine learning techniques. In this study, we introduce a Featureless machine\nlearning process to perform anomaly detection. It uses unprocessed byte streams\nof packets as training data. Featureless machine learning enables a low cost\nand low memory time-series analysis of network traffic. It benefits from\neliminating the significant investment in subject matter experts and the time\nrequired for feature engineering.",
    "descriptor": "",
    "authors": [
      "Arshiya Khan",
      "Chase Cotton"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03989"
  },
  {
    "id": "arXiv:2109.03991",
    "title": "The challenge of reproducible ML: an empirical study on the impact of  bugs",
    "abstract": "Reproducibility is a crucial requirement in scientific research. When results\nof research studies and scientific papers have been found difficult or\nimpossible to reproduce, we face a challenge which is called reproducibility\ncrisis. Although the demand for reproducibility in Machine Learning (ML) is\nacknowledged in the literature, a main barrier is inherent non-determinism in\nML training and inference. In this paper, we establish the fundamental factors\nthat cause non-determinism in ML systems. A framework, ReproduceML, is then\nintroduced for deterministic evaluation of ML experiments in a real, controlled\nenvironment. ReproduceML allows researchers to investigate software\nconfiguration effects on ML training and inference. Using ReproduceML, we run a\ncase study: investigation of the impact of bugs inside ML libraries on\nperformance of ML experiments. This study attempts to quantify the impact that\nthe occurrence of bugs in a popular ML framework, PyTorch, has on the\nperformance of trained models. To do so, a comprehensive methodology is\nproposed to collect buggy versions of ML libraries and run deterministic ML\nexperiments using ReproduceML. Our initial finding is that there is no evidence\nbased on our limited dataset to show that bugs which occurred in PyTorch do\naffect the performance of trained models. The proposed methodology as well as\nReproduceML can be employed for further research on non-determinism and bugs.",
    "descriptor": "",
    "authors": [
      "Emilio Rivera-Landos",
      "Foutse Khomh",
      "Amin Nikanjam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03991"
  },
  {
    "id": "arXiv:2109.03992",
    "title": "Stationary Density Estimation of It\u00f4 Diffusions Using Deep Learning",
    "abstract": "In this paper, we consider the density estimation problem associated with the\nstationary measure of ergodic It\\^o diffusions from a discrete-time series that\napproximate the solutions of the stochastic differential equations. To take an\nadvantage of the characterization of density function through the stationary\nsolution of a parabolic-type Fokker-Planck PDE, we proceed as follows. First,\nwe employ deep neural networks to approximate the drift and diffusion terms of\nthe SDE by solving appropriate supervised learning tasks. Subsequently, we\nsolve a steady-state Fokker-Plank equation associated with the estimated drift\nand diffusion coefficients with a neural-network-based least-squares method. We\nestablish the convergence of the proposed scheme under appropriate mathematical\nassumptions, accounting for the generalization errors induced by regressing the\ndrift and diffusion coefficients, and the PDE solvers. This theoretical study\nrelies on a recent perturbation theory of Markov chain result that shows a\nlinear dependence of the density estimation to the error in estimating the\ndrift term, and generalization error results of nonparametric regression and of\nPDE regression solution obtained with neural-network models. The effectiveness\nof this method is reflected by numerical simulations of a two-dimensional\nStudent's t distribution and a 20-dimensional Langevin dynamics.",
    "descriptor": "",
    "authors": [
      "Yiqi Gu",
      "John Harlim",
      "Senwei Liang",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.03992"
  },
  {
    "id": "arXiv:2109.03993",
    "title": "The Emotional Roller Coaster of Responding to Requirements Changes in  Software Engineering",
    "abstract": "Background: A preliminary study we conducted showed that software\npractitioners respond to requirements changes(RCs) with different emotions, and\nthat their emotions vary at stages of the RC handling life cycle, such as\nreceiving, developing, and delivering RCs. Objective: We wanted to study more\ncomprehensively how practitioners emotionally respond to RCs. Method: We\nconducted a world-wide survey with the participation of 201 software\npractitioners. In our survey, we used the Job-related Affective Well-being\nScale (JAWS) and open-ended questions to capture participants emotions when\nhandling RCs in their work and query about the different circumstances when\nthey feel these emotions. We used a combined approach of statistical analysis,\nJAWS, and Socio-Technical Grounded Theory (STGT) for Data Analysis to analyse\nour survey data. Findings: We identified (1) emotional responses to RCs, i.e.,\nthe most common emotions felt by practitioners when handling RCs; (2) different\nstimuli -- such as the RC, the practitioner, team, manager, customer -- that\ntrigger these emotions through their own different characteristics; (3)emotion\ndynamics, i.e., the changes in emotions during the project and RC handling life\ncycles; (4) distinct events where particular emotions are triggered:project\nmilestones, and RC stages; (5) and time related matters that regulate the\nemotion dynamics. Conclusion: Practitioners are not pleased with receiving RCs\nall the time. Last minute RCs introduced closer to a deadline especially\nviolate emotional well-being of practitioners. We present some practical\nrecommendations for practitioners to follow, including a dual-purpose\nemotion-centric decision guide to help decide when to introduce or accept an\nRC, and some future key research directions.",
    "descriptor": "\nComments: 16 pages, 7 tables, 10 figures, under review at IEEE Transactions on Software Engineering\n",
    "authors": [
      "Kashumi Madampe",
      "Rashina Hoda",
      "John Grundy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.03993"
  },
  {
    "id": "arXiv:2109.03994",
    "title": "Fractional Crank-Nicolson-Galerkin finite element methods for nonlinear  time fractional parabolic problems with time delay",
    "abstract": "A linearized numerical scheme is proposed to solve the nonlinear time\nfractional parabolic problems with time delay. The scheme is based on the\nstandard Galerkin finite element method in the spatial direction, the\nfractional Crank-Nicolson method and extrapolation methods in the temporal\ndirection. A novel discrete fractional Gr\\\"{o}nwall inequality is established.\nThanks to the inequality, the error estimate of fully discrete scheme is\nobtained. Several numerical examples are provided to verify the effectiveness\nof the fully discrete numerical method.",
    "descriptor": "",
    "authors": [
      "Lili Li",
      "Mianfu She",
      "Yuanling Niu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.03994"
  },
  {
    "id": "arXiv:2109.03997",
    "title": "Any Regular Polyhedron Can Transform to Another by O(1) Refoldings",
    "abstract": "We show that several classes of polyhedra are joined by a sequence of O(1)\nrefolding steps, where each refolding step unfolds the current polyhedron\n(allowing cuts anywhere on the surface and allowing overlap) and folds that\nunfolding into exactly the next polyhedron; in other words, a polyhedron is\nrefoldable into another polyhedron if they share a common unfolding.\nSpecifically, assuming equal surface area, we prove that (1) any two\ntetramonohedra are refoldable to each other, (2) any doubly covered triangle is\nrefoldable to a tetramonohedron, (3) any (augmented) regular prismatoid and\ndoubly covered regular polygon is refoldable to a tetramonohedron, (4) any\ntetrahedron has a 3-step refolding sequence to a tetramonohedron, and (5) the\nregular dodecahedron has a 4-step refolding sequence to a tetramonohedron. In\nparticular, we obtain at most 6-step refolding sequence between any pair of\nPlatonic solids, applying (5) for the dodecahedron and (1) and/or (2) for all\nother Platonic solids. As far as the authors know, this is the first result\nabout common unfolding involving the regular dodecahedron.",
    "descriptor": "",
    "authors": [
      "Erik D. Demaine",
      "Martin L. Demaine",
      "Yevhenii Diomidov",
      "Tonan Kamata",
      "Ryuhei Uehara",
      "Hanyu Alice Zhang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2109.03997"
  },
  {
    "id": "arXiv:2109.03998",
    "title": "LEASH: Enhancing Micro-architectural Attack Detection with a Reactive  Process Scheduler",
    "abstract": "Micro-architectural attacks use information leaked through shared resources\nto break hardware-enforced isolation. These attacks have been used to steal\nprivate information ranging from cryptographic keys to privileged Operating\nSystem (OS) data in devices ranging from mobile phones to cloud servers. Most\nexisting software countermeasures either have unacceptable overheads or\nconsiderable false positives. Further, they are designed for specific attacks\nand cannot readily adapt to new variants.\nIn this paper, we propose a framework called LEASH, which works from the OS\nscheduler to stymie micro-architectural attacks with minimal overheads,\nnegligible impact of false positives, and is capable of handling a wide range\nof attacks. LEASH works by starving maliciously behaving threads at runtime,\nproviding insufficient time and resources to carry out an attack. The CPU\nallocation for a falsely flagged thread found to be benign is boosted to\nminimize overheads. To demonstrate the framework, we modify Linux's Completely\nFair Scheduler with LEASH and evaluate it with seven micro-architectural\nattacks ranging from Meltdown and Rowhammer to a TLB covert channel. The\nruntime overheads are evaluated with a range of real-world applications and\nfound to be less than 1% on average.",
    "descriptor": "",
    "authors": [
      "Nikhilesh Singh",
      "Chester Rebeiro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.03998"
  },
  {
    "id": "arXiv:2109.03999",
    "title": "System Optimization in Synchronous Federated Training: A Survey",
    "abstract": "The unprecedented demand for collaborative machine learning in a\nprivacy-preserving manner gives rise to a novel machine learning paradigm\ncalled federated learning (FL). Given a sufficient level of privacy guarantees,\nthe practicality of an FL system mainly depends on its time-to-accuracy\nperformance during the training process. Despite bearing some resemblance with\ntraditional distributed training, FL has four distinct challenges that\ncomplicate the optimization towards shorter time-to-accuracy: information\ndeficiency, coupling for contrasting factors, client heterogeneity, and huge\nconfiguration space. Motivated by the need for inspiring related research, in\nthis paper we survey highly relevant attempts in the FL literature and organize\nthem by the related training phases in the standard workflow: selection,\nconfiguration, and reporting. We also review exploratory work including\nmeasurement studies and benchmarking tools to friendly support FL developers.\nAlthough a few survey articles on FL already exist, our work differs from them\nin terms of the focus, classification, and implications.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Zhifeng Jiang",
      "Wei Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.03999"
  },
  {
    "id": "arXiv:2109.04002",
    "title": "Competence-based Curriculum Learning for Multilingual Machine  Translation",
    "abstract": "Currently, multilingual machine translation is receiving more and more\nattention since it brings better performance for low resource languages (LRLs)\nand saves more space. However, existing multilingual machine translation models\nface a severe challenge: imbalance. As a result, the translation performance of\ndifferent languages in multilingual translation models are quite different. We\nargue that this imbalance problem stems from the different learning\ncompetencies of different languages. Therefore, we focus on balancing the\nlearning competencies of different languages and propose Competence-based\nCurriculum Learning for Multilingual Machine Translation, named CCL-M.\nSpecifically, we firstly define two competencies to help schedule the high\nresource languages (HRLs) and the low resource languages: 1) Self-evaluated\nCompetence, evaluating how well the language itself has been learned; and 2)\nHRLs-evaluated Competence, evaluating whether an LRL is ready to be learned\naccording to HRLs' Self-evaluated Competence. Based on the above competencies,\nwe utilize the proposed CCL-M algorithm to gradually add new languages into the\ntraining set in a curriculum learning manner. Furthermore, we propose a novel\ncompetenceaware dynamic balancing sampling strategy for better selecting\ntraining samples in multilingual training. Experimental results show that our\napproach has achieved a steady and significant performance gain compared to the\nprevious state-of-the-art approach on the TED talks dataset.",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2021. We release the codes at this https URL\n",
    "authors": [
      "Mingliang Zhang",
      "Fandong Meng",
      "Yunhai Tong",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04002"
  },
  {
    "id": "arXiv:2109.04003",
    "title": "Improving Deep Metric Learning by Divide and Conquer",
    "abstract": "Deep metric learning (DML) is a cornerstone of many computer vision\napplications. It aims at learning a mapping from the input domain to an\nembedding space, where semantically similar objects are located nearby and\ndissimilar objects far from another. The target similarity on the training data\nis defined by user in form of ground-truth class labels. However, while the\nembedding space learns to mimic the user-provided similarity on the training\ndata, it should also generalize to novel categories not seen during training.\nBesides user-provided groundtruth training labels, a lot of additional visual\nfactors (such as viewpoint changes or shape peculiarities) exist and imply\ndifferent notions of similarity between objects, affecting the generalization\non the images unseen during training. However, existing approaches usually\ndirectly learn a single embedding space on all available training data,\nstruggling to encode all different types of relationships, and do not\ngeneralize well. We propose to build a more expressive representation by\njointly splitting the embedding space and the data hierarchically into smaller\nsub-parts. We successively focus on smaller subsets of the training data,\nreducing its variance and learning a different embedding subspace for each data\nsubset. Moreover, the subspaces are learned jointly to cover not only the\nintricacies, but the breadth of the data as well. Only after that, we build the\nfinal embedding from the subspaces in the conquering stage. The proposed\nalgorithm acts as a transparent wrapper that can be placed around arbitrary\nexisting DML methods. Our approach significantly improves upon the\nstate-of-the-art on image retrieval, clustering, and re-identification tasks\nevaluated using CUB200-2011, CARS196, Stanford Online Products, In-shop\nClothes, and PKU VehicleID datasets.",
    "descriptor": "\nComments: Accepted to PAMI. Source code: this https URL\n",
    "authors": [
      "Artsiom Sanakoyeu",
      "Pingchuan Ma",
      "Vadim Tschernezki",
      "Bj\u00f6rn Ommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04003"
  },
  {
    "id": "arXiv:2109.04004",
    "title": "OpenClinicalAI: enabling AI to diagnose diseases in real-world clinical  settings",
    "abstract": "This paper quantitatively reveals the state-of-the-art and\nstate-of-the-practice AI systems only achieve acceptable performance on the\nstringent conditions that all categories of subjects are known, which we call\nclosed clinical settings, but fail to work in real-world clinical settings.\nCompared to the diagnosis task in the closed setting, real-world clinical\nsettings pose severe challenges, and we must treat them differently. We build a\nclinical AI benchmark named Clinical AIBench to set up real-world clinical\nsettings to facilitate researches. We propose an open, dynamic machine learning\nframework and develop an AI system named OpenClinicalAI to diagnose diseases in\nreal-world clinical settings. The first versions of Clinical AIBench and\nOpenClinicalAI target Alzheimer's disease. In the real-world clinical setting,\nOpenClinicalAI significantly outperforms the state-of-the-art AI system. In\naddition, OpenClinicalAI develops personalized diagnosis strategies to avoid\nunnecessary testing and seamlessly collaborates with clinicians. It is\npromising to be embedded in the current medical systems to improve medical\nservices.",
    "descriptor": "",
    "authors": [
      "Yunyou Huang",
      "Nana Wang",
      "Suqin Tang",
      "Li Ma",
      "Tianshu Hao",
      "Zihan Jiang",
      "Fan Zhang",
      "Guoxin Kang",
      "Xiuxia Miao",
      "Xianglong Guan",
      "Ruchang Zhang",
      "Zhifei Zhang",
      "Jianfeng Zhan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04004"
  },
  {
    "id": "arXiv:2109.04008",
    "title": "Graph Based Network with Contextualized Representations of Turns in  Dialogue",
    "abstract": "Dialogue-based relation extraction (RE) aims to extract relation(s) between\ntwo arguments that appear in a dialogue. Because dialogues have the\ncharacteristics of high personal pronoun occurrences and low information\ndensity, and since most relational facts in dialogues are not supported by any\nsingle sentence, dialogue-based relation extraction requires a comprehensive\nunderstanding of dialogue. In this paper, we propose the TUrn COntext awaRE\nGraph Convolutional Network (TUCORE-GCN) modeled by paying attention to the way\npeople understand dialogues. In addition, we propose a novel approach which\ntreats the task of emotion recognition in conversations (ERC) as a\ndialogue-based RE. Experiments on a dialogue-based RE dataset and three ERC\ndatasets demonstrate that our model is very effective in various dialogue-based\nnatural language understanding tasks. In these experiments, TUCORE-GCN\noutperforms the state-of-the-art models on most of the benchmark datasets. Our\ncode is available at https://github.com/BlackNoodle/TUCORE-GCN.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Bongseok Lee",
      "Yong Suk Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04008"
  },
  {
    "id": "arXiv:2109.04013",
    "title": "New stabilized $P_1\\times P_0$ finite element methods for nearly  inviscid and incompressible flows",
    "abstract": "This work proposes a new stabilized $P_1\\times P_0$ finite element method for\nsolving the incompressible Navier--Stokes equations. The numerical scheme is\nbased on a reduced Bernardi--Raugel element with statically condensed face\nbubbles and is pressure-robust in the small viscosity regime. For the Stokes\nproblem, an error estimate uniform with respect to the kinematic viscosity is\nshown. For the Navier--Stokes equation, the nonlinear convection term is\ndiscretized using an edge-averaged finite element method. In comparison with\nclassical schemes, the proposed method does not require tuning of parameters\nand is validated for competitiveness on several benchmark problems in 2 and 3\ndimensional space.",
    "descriptor": "",
    "authors": [
      "Yuwen Li",
      "Ludmil Zikatanov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04013"
  },
  {
    "id": "arXiv:2109.04014",
    "title": "Weakly-Supervised Visual-Retriever-Reader for Knowledge-based Question  Answering",
    "abstract": "Knowledge-based visual question answering (VQA) requires answering questions\nwith external knowledge in addition to the content of images. One dataset that\nis mostly used in evaluating knowledge-based VQA is OK-VQA, but it lacks a gold\nstandard knowledge corpus for retrieval. Existing work leverage different\nknowledge bases (e.g., ConceptNet and Wikipedia) to obtain external knowledge.\nBecause of varying knowledge bases, it is hard to fairly compare models'\nperformance. To address this issue, we collect a natural language knowledge\nbase that can be used for any VQA system. Moreover, we propose a Visual\nRetriever-Reader pipeline to approach knowledge-based VQA. The visual retriever\naims to retrieve relevant knowledge, and the visual reader seeks to predict\nanswers based on given knowledge. We introduce various ways to retrieve\nknowledge using text and images and two reader styles: classification and\nextraction. Both the retriever and reader are trained with weak supervision.\nOur experimental results show that a good retriever can significantly improve\nthe reader's performance on the OK-VQA challenge. The code and corpus are\nprovided in https://github.com/luomancs/retriever\\_reader\\_for\\_okvqa.git",
    "descriptor": "\nComments: accepted at EMNLP 2021\n",
    "authors": [
      "Man Luo",
      "Yankai Zeng",
      "Pratyay Banerjee",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04014"
  },
  {
    "id": "arXiv:2109.04015",
    "title": "Generation, augmentation, and alignment: A pseudo-source domain based  method for source-free domain adaptation",
    "abstract": "Conventional unsupervised domain adaptation (UDA) methods need to access both\nlabeled source samples and unlabeled target samples simultaneously to train the\nmodel. While in some scenarios, the source samples are not available for the\ntarget domain due to data privacy and safety. To overcome this challenge,\nrecently, source-free domain adaptation (SFDA) has attracted the attention of\nresearchers, where both a trained source model and unlabeled target samples are\ngiven. Existing SFDA methods either adopt a pseudo-label based strategy or\ngenerate more samples. However, these methods do not explicitly reduce the\ndistribution shift across domains, which is the key to a good adaptation.\nAlthough there are no source samples available, fortunately, we find that some\ntarget samples are very similar to the source domain and can be used to\napproximate the source domain. This approximated domain is denoted as the\npseudo-source domain. In this paper, inspired by this observation, we propose a\nnovel method based on the pseudo-source domain. The proposed method firstly\ngenerates and augments the pseudo-source domain, and then employs distribution\nalignment with four novel losses based on pseudo-label based strategy. Among\nthem, a domain adversarial loss is introduced between the pseudo-source domain\nthe remaining target domain to reduce the distribution shift. The results on\nthree real-world datasets verify the effectiveness of the proposed method.",
    "descriptor": "\nComments: Submitted to AAAI 2022\n",
    "authors": [
      "Yuntao Du",
      "Haiyang Yang",
      "Mingcai Chen",
      "Juan Jiang",
      "Hongtao Luo",
      "Chongjun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04015"
  },
  {
    "id": "arXiv:2109.04018",
    "title": "Graphine: A Dataset for Graph-aware Terminology Definition Generation",
    "abstract": "Precisely defining the terminology is the first step in scientific\ncommunication. Developing neural text generation models for definition\ngeneration can circumvent the labor-intensity curation, further accelerating\nscientific discovery. Unfortunately, the lack of large-scale terminology\ndefinition dataset hinders the process toward definition generation. In this\npaper, we present a large-scale terminology definition dataset Graphine\ncovering 2,010,648 terminology definition pairs, spanning 227 biomedical\nsubdisciplines. Terminologies in each subdiscipline further form a directed\nacyclic graph, opening up new avenues for developing graph-aware text\ngeneration models. We then proposed a novel graph-aware definition generation\nmodel Graphex that integrates transformer with graph neural network. Our model\noutperforms existing text generation models by exploiting the graph structure\nof terminologies. We further demonstrated how Graphine can be used to evaluate\npretrained language models, compare graph representation learning methods and\npredict sentence granularity. We envision Graphine to be a unique resource for\ndefinition generation and many other NLP tasks in biomedicine.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Zequn Liu",
      "Shukai Wang",
      "Yiyang Gu",
      "Ruiyi Zhang",
      "Ming Zhang",
      "Sheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04018"
  },
  {
    "id": "arXiv:2109.04020",
    "title": "Distributionally Robust Multilingual Machine Translation",
    "abstract": "Multilingual neural machine translation (MNMT) learns to translate multiple\nlanguage pairs with a single model, potentially improving both the accuracy and\nthe memory-efficiency of deployed models. However, the heavy data imbalance\nbetween languages hinders the model from performing uniformly across language\npairs. In this paper, we propose a new learning objective for MNMT based on\ndistributionally robust optimization, which minimizes the worst-case expected\nloss over the set of language pairs. We further show how to practically\noptimize this objective for large translation corpora using an iterated best\nresponse scheme, which is both effective and incurs negligible additional\ncomputational cost compared to standard empirical risk minimization. We perform\nextensive experiments on three sets of languages from two datasets and show\nthat our method consistently outperforms strong baseline methods in terms of\naverage and per-language performance under both many-to-one and one-to-many\ntranslation settings.",
    "descriptor": "\nComments: Long paper accepted by EMNLP2021 main conference\n",
    "authors": [
      "Chunting Zhou",
      "Daniel Levy",
      "Xian Li",
      "Marjan Ghazvininejad",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04020"
  },
  {
    "id": "arXiv:2109.04021",
    "title": "Modified Supervised Contrastive Learning for Detecting Anomalous Driving  Behaviours",
    "abstract": "Detecting distracted driving behaviours is important to reduce millions of\ndeaths and injuries occurring worldwide. Distracted or anomalous driving\nbehaviours are deviations from the 'normal' driving that need to be identified\ncorrectly to alert the driver. However, these driving behaviours do not\ncomprise of one specific type of driving style and their distribution can be\ndifferent during training and testing phases of a classifier. We formulate this\nproblem as a supervised contrastive learning approach to learn a visual\nrepresentation to detect normal, and seen and unseen anomalous driving\nbehaviours. We made a change to the standard contrastive loss function to\nadjust the similarity of negative pairs to aid the optimization. Normally, the\n(self) supervised contrastive framework contains an encoder followed by a\nprojection head, which is omitted during testing phase as the encoding layers\nare considered to contain general visual representative information. However,\nwe assert that for supervised contrastive learning task, including projection\nhead will be beneficial. We showed our results on a Driver Anomaly Detection\ndataset that contains 783 minutes of video recordings of normal and anomalous\ndriving behaviours of 31 drivers from various from top and front cameras (both\ndepth and infrared). We also performed an extra step of fine tuning the labels\nin this dataset. Out of 9 video modalities combinations, our modified\ncontrastive approach improved the ROC AUC on 7 in comparison to the baseline\nmodels (from 3.12% to 8.91% for different modalities); the remaining two models\nalso had manual labelling. We performed statistical tests that showed evidence\nthat our modifications perform better than the baseline contrastive models.\nFinally, the results showed that the fusion of depth and infrared modalities\nfrom top and front view achieved the best AUC ROC of 0.9738 and AUC PR of\n0.9772.",
    "descriptor": "\nComments: 9 pages, 2 figures, 5 tables\n",
    "authors": [
      "Shehroz S. Khan",
      "Ziting Shen",
      "Haoying Sun",
      "Ax Patel",
      "Ali Abedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04021"
  },
  {
    "id": "arXiv:2109.04022",
    "title": "Multi-Tensor Network Representation for High-Order Tensor Completion",
    "abstract": "This work studies the problem of high-dimensional data (referred to tensors)\ncompletion from partially observed samplings. We consider that a tensor is a\nsuperposition of multiple low-rank components. In particular, each component\ncan be represented as multilinear connections over several latent factors and\nnaturally mapped to a specific tensor network (TN) topology. In this paper, we\npropose a fundamental tensor decomposition (TD) framework: Multi-Tensor Network\nRepresentation (MTNR), which can be regarded as a linear combination of a range\nof TD models, e.g., CANDECOMP/PARAFAC (CP) decomposition, Tensor Train (TT),\nand Tensor Ring (TR). Specifically, MTNR represents a high-order tensor as the\naddition of multiple TN models, and the topology of each TN is automatically\ngenerated instead of manually pre-designed. For the optimization phase, an\nadaptive topology learning (ATL) algorithm is presented to obtain latent\nfactors of each TN based on a rank incremental strategy and a projection error\nmeasurement strategy. In addition, we theoretically establish the fundamental\nmultilinear operations for the tensors with TN representation, and reveal the\nstructural transformation of MTNR to a single TN. Finally, MTNR is applied to a\ntypical task, tensor completion, and two effective algorithms are proposed for\nthe exact recovery of incomplete data based on the Alternating Least Squares\n(ALS) scheme and Alternating Direction Method of Multiplier (ADMM) framework.\nExtensive numerical experiments on synthetic data and real-world datasets\ndemonstrate the effectiveness of MTNR compared with the start-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Chang Nie",
      "Huan Wang",
      "Zhihui Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04022"
  },
  {
    "id": "arXiv:2109.04023",
    "title": "Rethinking Immersive Virtual Reality and Empathy",
    "abstract": "In this position paper, we aim to spark more discussions surrounding the use\nof empathy as the intended outcome of many studies on immersive virtual reality\nexperiences. As a construct, empathy has many significant flaws that may lead\nto unintended and negative outcomes, going against our original goal of\nemploying these technologies for the betterment of society. We highlight the\npossible advantages of designing for rational compassion instead, and propose\nalternative research directions and outcome measurements for immersive virtual\nreality that urgently warrant our attention.",
    "descriptor": "\nComments: 4 pages, ACM CSCW 2021 workshop, arttech: Performance and Embodiment in Technology for Resilience and Mental Health\n",
    "authors": [
      "Ken Jen Lee",
      "Edith Law"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.04023"
  },
  {
    "id": "arXiv:2109.04024",
    "title": "On the Approximation of Cooperative Heterogeneous Multi-Agent  Reinforcement Learning (MARL) using Mean Field Control (MFC)",
    "abstract": "Mean field control (MFC) is an effective way to mitigate the curse of\ndimensionality of cooperative multi-agent reinforcement learning (MARL)\nproblems. This work considers a collection of $N_{\\mathrm{pop}}$ heterogeneous\nagents that can be segregated into $K$ classes such that the $k$-th class\ncontains $N_k$ homogeneous agents. We aim to prove approximation guarantees of\nthe MARL problem for this heterogeneous system by its corresponding MFC\nproblem. We consider three scenarios where the reward and transition dynamics\nof all agents are respectively taken to be functions of $(1)$ joint state and\naction distributions across all classes, $(2)$ individual distributions of each\nclass, and $(3)$ marginal distributions of the entire population. We show that,\nin these cases, the $K$-class MARL problem can be approximated by MFC with\nerrors given as\n$e_1=\\mathcal{O}(\\frac{\\sqrt{|\\mathcal{X}||\\mathcal{U}|}}{N_{\\mathrm{pop}}}\\sum_{k}\\sqrt{N_k})$,\n$e_2=\\mathcal{O}(\\sqrt{|\\mathcal{X}||\\mathcal{U}|}\\sum_{k}\\frac{1}{\\sqrt{N_k}})$\nand\n$e_3=\\mathcal{O}\\left(\\sqrt{|\\mathcal{X}||\\mathcal{U}|}\\left[\\frac{A}{N_{\\mathrm{pop}}}\\sum_{k\\in[K]}\\sqrt{N_k}+\\frac{B}{\\sqrt{N_{\\mathrm{pop}}}}\\right]\\right)$,\nrespectively, where $A, B$ are some constants and $|\\mathcal{X}|,|\\mathcal{U}|$\nare the sizes of state and action spaces of each agent. Finally, we design a\nNatural Policy Gradient (NPG) based algorithm that, in the three cases stated\nabove, can converge to an optimal MARL policy within $\\mathcal{O}(e_j)$ error\nwith a sample complexity of $\\mathcal{O}(e_j^{-3})$, $j\\in\\{1,2,3\\}$,\nrespectively.",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Washim Uddin Mondal",
      "Mridul Agarwal",
      "Vaneet Aggarwal",
      "Satish V. Ukkusuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.04024"
  },
  {
    "id": "arXiv:2109.04025",
    "title": "Improved Hardness of BDD and SVP Under Gap-(S)ETH",
    "abstract": "$\\newcommand{\\Z}{\\mathbb{Z}}$ We show improved fine-grained hardness of two\nkey lattice problems in the $\\ell_p$ norm: Bounded Distance Decoding to within\nan $\\alpha$ factor of the minimum distance ($\\mathrm{BDD}_{p, \\alpha}$) and the\n(decisional) $\\gamma$-approximate Shortest Vector Problem\n($\\mathrm{SVP}_{p,\\gamma}$), assuming variants of the Gap (Strong) Exponential\nTime Hypothesis (Gap-(S)ETH). Specifically, we show:\n1. For all $p \\in [1, \\infty)$, there is no $2^{o(n)}$-time algorithm for\n$\\mathrm{BDD}_{p, \\alpha}$ for any constant $\\alpha > \\alpha_\\mathsf{kn}$,\nwhere $\\alpha_\\mathsf{kn} = 2^{-c_\\mathsf{kn}} < 0.98491$ and $c_\\mathsf{kn}$\nis the $\\ell_2$ kissing-number constant, unless non-uniform Gap-ETH is false.\n2. For all $p \\in [1, \\infty)$, there is no $2^{o(n)}$-time algorithm for\n$\\mathrm{BDD}_{p, \\alpha}$ for any constant $\\alpha > \\alpha^\\ddagger_p$, where\n$\\alpha^\\ddagger_p$ is explicit and satisfies $\\alpha^\\ddagger_p = 1$ for $1\n\\leq p \\leq 2$, $\\alpha^\\ddagger_p < 1$ for all $p > 2$, and $\\alpha^\\ddagger_p\n\\to 1/2$ as $p \\to \\infty$, unless randomized Gap-ETH is false.\n3. For all $p \\in [1, \\infty) \\setminus 2 \\Z$, all $C > 1$, and all\n$\\varepsilon > 0$, there is no $2^{(1-\\varepsilon)n/C}$-time algorithm for\n$\\mathrm{BDD}_{p, \\alpha}$ for any constant $\\alpha > \\alpha^\\dagger_{p, C}$,\nwhere $\\alpha^\\dagger_{p, C}$ is explicit and satisfies $\\alpha^\\dagger_{p, C}\n\\to 1$ as $C \\to \\infty$ for any fixed $p \\in [1, \\infty)$, unless non-uniform\nGap-SETH is false.\n4. For all $p > p_0 \\approx 2.1397$, $p \\notin 2\\Z$, and all $\\varepsilon >\n0$, there is no $2^{(1-\\varepsilon)n/C_p}$-time algorithm for $\\mathrm{SVP}_{p,\n\\gamma}$ for some constant $\\gamma = \\gamma(p, \\varepsilon) > 1$ and explicit\nconstant $C_p > 0$ where $C_p \\to 1$ as $p \\to \\infty$, unless randomized\nGap-SETH is false.",
    "descriptor": "",
    "authors": [
      "Huck Bennett",
      "Chris Peikert",
      "Yi Tang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.04025"
  },
  {
    "id": "arXiv:2109.04026",
    "title": "Learning Performance Bounds for Safety-Critical Systems",
    "abstract": "As the complexity of control systems increases, the need for systematic\nmethods to guarantee their efficacy grows as well. However, direct testing of\nthese systems is oftentimes costly, difficult, or impractical. As a result, the\ntest and evaluation ideal would be to verify the efficacy of a system simulator\nand use this verification result to make a statement on true system\nperformance. This paper formalizes that performance translation for a specific\nclass of desired system behaviors. In that vein, our contribution is twofold.\nFirst, we detail a variant on existing Bayesian Optimization Algorithms that\nidentifies minimal upper bounds to maximization problems, with some minimum\nprobability. Second, we use this Algorithm to $i)$ lower bound the minimum\nsimulator robustness and $ii)$ upper bound the expected deviance between true\nand simulated systems. Then, for the specific class of desired behaviors\nstudied, we leverage these bounds to lower bound the minimum true system\nrobustness, without directly testing the true system. Finally, we compare a\nhigh-fidelity ROS simulator of a Segway, with a significantly noisier version\nof itself, and show that our probabilistic verification bounds are indeed\nsatisfied.",
    "descriptor": "",
    "authors": [
      "Prithvi Akella",
      "Ugo Rosolia",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04026"
  },
  {
    "id": "arXiv:2109.04027",
    "title": "Taxim: An Example-based Simulation Model for GelSight Tactile Sensors",
    "abstract": "Simulation is widely used in robotics for system verification and large-scale\ndata collection. However, simulating sensors, including tactile sensors, has\nbeen a long-standing challenge. In this paper, we propose Taxim, a realistic\nand high-speed simulation model for a vision-based tactile sensor, GelSight. A\nGelSight sensor uses a piece of soft elastomer as the medium of contact and\nembeds optical structures to capture the deformation of the elastomer, which\ninfers the geometry and forces applied at the contact surface. We propose an\nexample-based method for simulating GelSight: we simulate the optical response\nto the deformation with a polynomial look-up table. This table maps the\ndeformed geometries to pixel intensity sampled by the embedded camera. In order\nto simulate the surface markers' motion that is caused by the surface stretch\nof the elastomer, we apply the linear elastic deformation theory and the\nsuperposition principle. The simulation model is calibrated with less than 100\ndata points from a real sensor. The example-based approach enables the model to\neasily migrate to other GelSight sensors or its variations. To the best of our\nknowledge, our simulation framework is the first to incorporate marker motion\nfield simulation that derives from elastomer deformation together with the\noptical simulation, creating a comprehensive and computationally efficient\ntactile simulation framework. Experiments reveal that our optical simulation\nhas the lowest pixel-wise intensity errors compared to prior work and can run\nonline with CPU computing.",
    "descriptor": "",
    "authors": [
      "Zilin Si",
      "Wenzhen Yuan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04027"
  },
  {
    "id": "arXiv:2109.04029",
    "title": "Automated Security Assessment for the Internet of Things",
    "abstract": "Internet of Things (IoT) based applications face an increasing number of\npotential security risks, which need to be systematically assessed and\naddressed. Expert-based manual assessment of IoT security is a predominant\napproach, which is usually inefficient. To address this problem, we propose an\nautomated security assessment framework for IoT networks. Our framework first\nleverages machine learning and natural language processing to analyze\nvulnerability descriptions for predicting vulnerability metrics. The predicted\nmetrics are then input into a two-layered graphical security model, which\nconsists of an attack graph at the upper layer to present the network\nconnectivity and an attack tree for each node in the network at the bottom\nlayer to depict the vulnerability information. This security model\nautomatically assesses the security of the IoT network by capturing potential\nattack paths. We evaluate the viability of our approach using a\nproof-of-concept smart building system model which contains a variety of\nreal-world IoT devices and potential vulnerabilities. Our evaluation of the\nproposed framework demonstrates its effectiveness in terms of automatically\npredicting the vulnerability metrics of new vulnerabilities with more than 90%\naccuracy, on average, and identifying the most vulnerable attack paths within\nan IoT network. The produced assessment results can serve as a guideline for\ncybersecurity professionals to take further actions and mitigate risks in a\ntimely manner.",
    "descriptor": "\nComments: Accepted for publication at the 26th IEEE Pacific Rim International Symposium on Dependable Computing (PRDC 2021)\n",
    "authors": [
      "Xuanyu Duan",
      "Mengmeng Ge",
      "Triet H. M. Le",
      "Faheem Ullah",
      "Shang Gao",
      "Xuequan Lu",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04029"
  },
  {
    "id": "arXiv:2109.04030",
    "title": "Bag of Tricks for Optimizing Transformer Efficiency",
    "abstract": "Improving Transformer efficiency has become increasingly attractive recently.\nA wide range of methods has been proposed, e.g., pruning, quantization, new\narchitectures and etc. But these methods are either sophisticated in\nimplementation or dependent on hardware. In this paper, we show that the\nefficiency of Transformer can be improved by combining some simple and\nhardware-agnostic methods, including tuning hyper-parameters, better design\nchoices and training strategies. On the WMT news translation tasks, we improve\nthe inference efficiency of a strong Transformer system by 3.80X on CPU and\n2.52X on GPU. The code is publicly available at\nhttps://github.com/Lollipop321/mini-decoder-network.",
    "descriptor": "\nComments: accepted by EMNLP (Findings) 2021\n",
    "authors": [
      "Ye Lin",
      "Yanyang Li",
      "Tong Xiao",
      "Jingbo Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04030"
  },
  {
    "id": "arXiv:2109.04033",
    "title": "Versions of Gradient Temporal Difference Learning",
    "abstract": "Sutton, Szepesv\\'{a}ri and Maei introduced the first gradient\ntemporal-difference (GTD) learning algorithms compatible with both linear\nfunction approximation and off-policy training. The goal of this paper is (a)\nto propose some variants of GTDs with extensive comparative analysis and (b) to\nestablish new theoretical analysis frameworks for the GTDs. These variants are\nbased on convex-concave saddle-point interpretations of GTDs, which effectively\nunify all the GTDs into a single framework, and provide simple stability\nanalysis based on recent results on primal-dual gradient dynamics. Finally,\nnumerical comparative analysis is given to evaluate these approaches.",
    "descriptor": "",
    "authors": [
      "Donghwan Lee",
      "Han-Dong Lim",
      "Jihoon Park",
      "Okyong Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04033"
  },
  {
    "id": "arXiv:2109.04037",
    "title": "Trust-ya: design of a multiplayer game for the study of small group  processes",
    "abstract": "This paper presents the design of a cooperative multi-player betting game,\nTrust-ya, as a model of some elements of status processes in human groups. The\ngame is designed to elicit status-driven leader-follower behaviours as a means\nto observe and influence social hierarchy. It involves a Bach/Stravinsky game\nof deference in a group, in which people on each turn can either invest with\nanother player or hope someone invests with them. Players who receive\ninvestment capital are able to gamble for payoffs from a central pool which\nthen can be shared back with those who invested (but a portion of it may be\nkept, including all of it). The bigger gambles (people with more investors) get\nbigger payoffs. Thus, there is a natural tendency for players to coalesce as\ninvestors around a 'leader' who gambles, but who also shares sufficiently from\ntheir winnings to keep the investors 'hanging on'. The 'leader' will want to\nkeep as much as possible for themselves, however. The game is played\nanonymously, but a set of 'status symbols' can be purchased which have no value\nin the game itself, but can serve as a 'cheap talk' communication device with\nother players. This paper introduces the game, relates it to status theory in\nsocial psychology, and shows some simple simulated and human experiments that\ndemonstrate how the game can be used to study status processes and dynamics in\nhuman groups.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Jerry Huang",
      "Joshua Jung",
      "Neil Budnarain",
      "Benn McGregor",
      "Jesse Hoey"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04037"
  },
  {
    "id": "arXiv:2109.04038",
    "title": "A series acceleration algorithm for the gamma-Pareto (type I)  convolution and related functions of interest for pharmacokinetics",
    "abstract": "The gamma-Pareto type I convolution (GPC type I) distribution, which has a\npower function tail, was recently shown to describe the disposition kinetics of\nmetformin in dogs precisely and better than sums of exponentials. However, this\nhad very long run times and lost precision for its functional values at long\ntimes following intravenous injection. An accelerated algorithm and its\ncomputer code is now presented comprising two separate routines for short and\nlong times and which, when applied to the dog data, completes in approximately\n3 minutes per case. The new algorithm is a more practical research tool.\nPotential pharmacokinetic applications are discussed.",
    "descriptor": "\nComments: In Press for the Journal of Pharmacokinetics and Pharmacodynamics, DOI will activate soon, Open Access\n",
    "authors": [
      "Carl A. Wesolowski",
      "Jane Alcorn",
      "Geoffrey T. Tucker"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2109.04038"
  },
  {
    "id": "arXiv:2109.04041",
    "title": "Keeping an Eye on Things: Deep Learned Features for Long-Term Visual  Localization",
    "abstract": "In this paper, we learn visual features that we use to first build a map and\nthen localize a robot driving autonomously across a full day of lighting\nchange, including in the dark. We train a neural network to predict sparse\nkeypoints with associated descriptors and scores that can be used together with\na classical pose estimator for localization. Our training pipeline includes a\ndifferentiable pose estimator such that training can be supervised with ground\ntruth poses from data collected earlier, in our case from 2016 and 2017\ngathered with multi-experience Visual Teach and Repeat (VT&R). We then insert\nthe learned features into the existing VT&R pipeline to perform closed-loop\npath-following in unstructured outdoor environments. We show successful path\nfollowing across all lighting conditions despite the robot's map being\nconstructed using daylight conditions. Moreover, we explore generalizability of\nthe features by driving the robot across all lighting conditions in two new\nareas not present in the feature training dataset. In all, we validated our\napproach with 30 km of autonomous path-following experiments in challenging\nconditions.",
    "descriptor": "",
    "authors": [
      "Mona Gridseth",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04041"
  },
  {
    "id": "arXiv:2109.04047",
    "title": "ACP++: Action Co-occurrence Priors for Human-Object Interaction  Detection",
    "abstract": "A common problem in the task of human-object interaction (HOI) detection is\nthat numerous HOI classes have only a small number of labeled examples,\nresulting in training sets with a long-tailed distribution. The lack of\npositive labels can lead to low classification accuracy for these classes.\nTowards addressing this issue, we observe that there exist natural correlations\nand anti-correlations among human-object interactions. In this paper, we model\nthe correlations as action co-occurrence matrices and present techniques to\nlearn these priors and leverage them for more effective training, especially on\nrare classes. The efficacy of our approach is demonstrated experimentally,\nwhere the performance of our approach consistently improves over the\nstate-of-the-art methods on both of the two leading HOI detection benchmark\ndatasets, HICO-Det and V-COCO.",
    "descriptor": "\nComments: IEEE TIP accepted. Journal extension of our ECCV 2020 paper (arXiv:2007.08728). Source code: this https URL\n",
    "authors": [
      "Dong-Jin Kim",
      "Xiao Sun",
      "Jinsoo Choi",
      "Stephen Lin",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04047"
  },
  {
    "id": "arXiv:2109.04048",
    "title": "Application of the Singular Spectrum Analysis on electroluminescence  images of thin-film photovoltaic modules",
    "abstract": "This paper discusses an application of the singular spectrum analysis method\n(SSA) in the context of electroluminescence (EL) images of thin-film\nphotovoltaic (PV) modules. We propose an EL image decomposition as a sum of\nthree components: global intensity, cell, and aperiodic components. A\nparametric model of the extracted signal is used to perform several image\nprocessing tasks. The cell component is used to identify interconnection lines\nbetween PV cells at sub-pixel accuracy, as well as to correct incorrect\nstitching of EL images. Furthermore, an explicit expression of the cell\ncomponent signal is used to estimate the inverse characteristic length, a\nphysical parameter related to the resistances in a PV module.",
    "descriptor": "",
    "authors": [
      "Evgenii Sovetkin",
      "Bart E. Pieters"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.04048"
  },
  {
    "id": "arXiv:2109.04049",
    "title": "BeamTransformer: Microphone Array-based Overlapping Speech Detection",
    "abstract": "We propose BeamTransformer, an efficient architecture to leverage\nbeamformer's edge in spatial filtering and transformer's capability in context\nsequence modeling. BeamTransformer seeks to optimize modeling of sequential\nrelationship among signals from different spatial direction. Overlapping speech\ndetection is one of the tasks where such optimization is favorable. In this\npaper we effectively apply BeamTransformer to detect overlapping segments.\nComparing to single-channel approach, BeamTransformer exceeds in learning to\nidentify the relationship among different beam sequences and hence able to make\npredictions not only from the acoustic signals but also the localization of the\nsource. The results indicate that a successful incorporation of microphone\narray signals can lead to remarkable gains. Moreover, BeamTransformer takes one\nstep further, as speech from overlapped speakers have been internally separated\ninto different beams.",
    "descriptor": "",
    "authors": [
      "Siqi Zheng",
      "Shiliang Zhang",
      "Weilong Huang",
      "Qian Chen",
      "Hongbin Suo",
      "Ming Lei",
      "Jinwei Feng",
      "Zhijie Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.04049"
  },
  {
    "id": "arXiv:2109.04053",
    "title": "Table-based Fact Verification with Salience-aware Learning",
    "abstract": "Tables provide valuable knowledge that can be used to verify textual\nstatements. While a number of works have considered table-based fact\nverification, direct alignments of tabular data with tokens in textual\nstatements are rarely available. Moreover, training a generalized fact\nverification model requires abundant labeled training data. In this paper, we\npropose a novel system to address these problems. Inspired by counterfactual\ncausality, our system identifies token-level salience in the statement with\nprobing-based salience estimation. Salience estimation allows enhanced learning\nof fact verification from two perspectives. From one perspective, our system\nconducts masked salient token prediction to enhance the model for alignment and\nreasoning between the table and the statement. From the other perspective, our\nsystem applies salience-aware data augmentation to generate a more diverse set\nof training instances by replacing non-salient terms. Experimental results on\nTabFact show the effective improvement by the proposed salience-aware learning\ntechniques, leading to the new SOTA performance on the benchmark. Our code is\npublicly available at https://github.com/luka-group/Salience-aware-Learning .",
    "descriptor": "\nComments: EMNLP 2021 (Findings)\n",
    "authors": [
      "Fei Wang",
      "Kexuan Sun",
      "Jay Pujara",
      "Pedro Szekely",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04053"
  },
  {
    "id": "arXiv:2109.04065",
    "title": "Malware Sight-Seeing: Accelerating Reverse-Engineering via  Point-of-Interest-Beacons",
    "abstract": "New types of malware are emerging at concerning rates. However, analyzing\nmalware via reverse engineering is still a time-consuming and mostly manual\ntask. For this reason, it is necessary to develop techniques that automate\nparts of the reverse engineering process and that can evade the built-in\ncountermeasures of modern malware. The main contribution of this paper is a\nnovel method to automatically find so-called Points-of-Interest (POIs) in\nexecuted programs. POIs are instructions that interact with data that is known\nto an analyst. They can be used as beacons in the analysis of malware and can\nhelp to guide the analyst to the interesting parts of the malware. Furthermore,\nwe propose a metric for POIs , the so-called confidence score that estimates\nhow exclusively a POI will process data relevant to the malware. With the goal\nof automatically extract peers in P2P botnet malware, we demonstrate and\nevaluate our approach by applying it on four botnets (ZeroAccess, Sality,\nNugache, and Kelihos). We looked into the identified POIs for known IPs and\nports and, by using this information, leverage it to successfully monitor the\nbotnets. Furthermore, using our scoring system, we show that we can extract\npeers for each botnet with high accuracy.",
    "descriptor": "",
    "authors": [
      "August See",
      "Maximilian Gehring",
      "Max M\u00fchlh\u00e4user",
      "Mathias Fischer",
      "Shankar Karuppayah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.04065"
  },
  {
    "id": "arXiv:2109.04066",
    "title": "Enhanced Speaker-aware Multi-party Multi-turn Dialogue Comprehension",
    "abstract": "Multi-party multi-turn dialogue comprehension brings unprecedented challenges\non handling the complicated scenarios from multiple speakers and criss-crossed\ndiscourse relationship among speaker-aware utterances. Most existing methods\ndeal with dialogue contexts as plain texts and pay insufficient attention to\nthe crucial speaker-aware clues. In this work, we propose an enhanced\nspeaker-aware model with masking attention and heterogeneous graph networks to\ncomprehensively capture discourse clues from both sides of speaker property and\nspeaker-aware relationships. With such comprehensive speaker-aware modeling,\nexperimental results show that our speaker-aware model helps achieves\nstate-of-the-art performance on the benchmark dataset Molweni. Case analysis\nshows that our model enhances the connections between utterances and their own\nspeakers and captures the speaker-aware discourse relations, which are critical\nfor dialogue modeling.",
    "descriptor": "",
    "authors": [
      "Xinbei Ma",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04066"
  },
  {
    "id": "arXiv:2109.04067",
    "title": "Towards Sustainable Energy-Efficient Data Centers in Africa",
    "abstract": "Developing nations are particularly susceptible to the adverse effects of\nglobal warming. By 2040, 14 percent of global emissions will come from data\ncenters. This paper presents early findings in the use AI and digital twins to\nmodel and optimize data center operations.",
    "descriptor": "\nComments: Presented at OCP Future Technologies Symposium, San Jose, California | Nov 8, 2021\n",
    "authors": [
      "David Ojika",
      "Jayson Strayer",
      "Gaurav Kaul"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.04067"
  },
  {
    "id": "arXiv:2109.04075",
    "title": "Self Supervision to Distillation for Long-Tailed Visual Recognition",
    "abstract": "Deep learning has achieved remarkable progress for visual recognition on\nlarge-scale balanced datasets but still performs poorly on real-world\nlong-tailed data. Previous methods often adopt class re-balanced training\nstrategies to effectively alleviate the imbalance issue, but might be a risk of\nover-fitting tail classes. The recent decoupling method overcomes over-fitting\nissues by using a multi-stage training scheme, yet, it is still incapable of\ncapturing tail class information in the feature learning stage. In this paper,\nwe show that soft label can serve as a powerful solution to incorporate label\ncorrelation into a multi-stage training scheme for long-tailed recognition. The\nintrinsic relation between classes embodied by soft labels turns out to be\nhelpful for long-tailed recognition by transferring knowledge from head to tail\nclasses.\nSpecifically, we propose a conceptually simple yet particularly effective\nmulti-stage training scheme, termed as Self Supervised to Distillation (SSD).\nThis scheme is composed of two parts. First, we introduce a self-distillation\nframework for long-tailed recognition, which can mine the label relation\nautomatically. Second, we present a new distillation label generation module\nguided by self-supervision. The distilled labels integrate information from\nboth label and data domains that can model long-tailed distribution\neffectively. We conduct extensive experiments and our method achieves the\nstate-of-the-art results on three long-tailed recognition benchmarks:\nImageNet-LT, CIFAR100-LT and iNaturalist 2018. Our SSD outperforms the strong\nLWS baseline by from $2.7\\%$ to $4.5\\%$ on various datasets. The code is\navailable at https://github.com/MCG-NJU/SSD-LT.",
    "descriptor": "\nComments: ICCV 2021 camera-ready version\n",
    "authors": [
      "Tianhao Li",
      "Limin Wang",
      "Gangshan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04075"
  },
  {
    "id": "arXiv:2109.04080",
    "title": "Low-Resource Dialogue Summarization with Domain-Agnostic Multi-Source  Pretraining",
    "abstract": "With the rapid increase in the volume of dialogue data from daily life, there\nis a growing demand for dialogue summarization. Unfortunately, training a large\nsummarization model is generally infeasible due to the inadequacy of dialogue\ndata with annotated summaries. Most existing works for low-resource dialogue\nsummarization directly pretrain models in other domains, e.g., the news domain,\nbut they generally neglect the huge difference between dialogues and\nconventional articles. To bridge the gap between out-of-domain pretraining and\nin-domain fine-tuning, in this work, we propose a multi-source pretraining\nparadigm to better leverage the external summary data. Specifically, we exploit\nlarge-scale in-domain non-summary data to separately pretrain the dialogue\nencoder and the summary decoder. The combined encoder-decoder model is then\npretrained on the out-of-domain summary data using adversarial critics, aiming\nto facilitate domain-agnostic summarization. The experimental results on two\npublic datasets show that with only limited training data, our approach\nachieves competitive performance and generalizes well in different dialogue\nscenarios.",
    "descriptor": "\nComments: Accepted by EMNLP 2021, 12 pages\n",
    "authors": [
      "Yicheng Zou",
      "Bolin Zhu",
      "Xingwu Hu",
      "Tao Gui",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04080"
  },
  {
    "id": "arXiv:2109.04081",
    "title": "DeepEMO: Deep Learning for Speech Emotion Recognition",
    "abstract": "We proposed the industry level deep learning approach for speech emotion\nrecognition task. In industry, carefully proposed deep transfer learning\ntechnology shows real results due to mostly low amount of training data\navailability, machine training cost, and specialized learning on dedicated AI\ntasks. The proposed speech recognition framework, called DeepEMO, consists of\ntwo main pipelines such that preprocessing to extract efficient main features\nand deep transfer learning model to train and recognize. Main source code is in\nhttps://github.com/enkhtogtokh/deepemo repository",
    "descriptor": "",
    "authors": [
      "Enkhtogtokh Togootogtokh",
      "Christian Klasen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.04081"
  },
  {
    "id": "arXiv:2109.04082",
    "title": "Risk-Averse Decision Making Under Uncertainty",
    "abstract": "A large class of decision making under uncertainty problems can be described\nvia Markov decision processes (MDPs) or partially observable MDPs (POMDPs),\nwith application to artificial intelligence and operations research, among\nothers. Traditionally, policy synthesis techniques are proposed such that a\ntotal expected cost or reward is minimized or maximized. However, optimality in\nthe total expected cost sense is only reasonable if system behavior in the\nlarge number of runs is of interest, which has limited the use of such policies\nin practical mission-critical scenarios, wherein large deviations from the\nexpected behavior may lead to mission failure. In this paper, we consider the\nproblem of designing policies for MDPs and POMDPs with objectives and\nconstraints in terms of dynamic coherent risk measures, which we refer to as\nthe constrained risk-averse problem. For MDPs, we reformulate the problem into\na infsup problem via the Lagrangian framework and propose an optimization-based\nmethod to synthesize Markovian policies. For MDPs, we demonstrate that the\nformulated optimization problems are in the form of difference convex programs\n(DCPs) and can be solved by the disciplined convex-concave programming (DCCP)\nframework. We show that these results generalize linear programs for\nconstrained MDPs with total discounted expected costs and constraints. For\nPOMDPs, we show that, if the coherent risk measures can be defined as a Markov\nrisk transition mapping, an infinite-dimensional optimization can be used to\ndesign Markovian belief-based policies. For stochastic finite-state controllers\n(FSCs), we show that the latter optimization simplifies to a\n(finite-dimensional) DCP and can be solved by the DCCP framework. We\nincorporate these DCPs in a policy iteration algorithm to design risk-averse\nFSCs for POMDPs.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.02423\n",
    "authors": [
      "Mohamadreza Ahmadi",
      "Ugo Rosolia",
      "Michel D. Ingham",
      "Richard M. Murray",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.04082"
  },
  {
    "id": "arXiv:2109.04083",
    "title": "User Tampering in Reinforcement Learning Recommender Systems",
    "abstract": "This paper provides the first formalisation and empirical demonstration of a\nparticular safety concern in reinforcement learning (RL)-based news and social\nmedia recommendation algorithms. This safety concern is what we call \"user\ntampering\" -- a phenomenon whereby an RL-based recommender system may\nmanipulate a media user's opinions, preferences and beliefs via its\nrecommendations as part of a policy to increase long-term user engagement. We\nprovide a simulation study of a media recommendation problem constrained to the\nrecommendation of political content, and demonstrate that a Q-learning\nalgorithm consistently learns to exploit its opportunities to 'polarise'\nsimulated 'users' with its early recommendations in order to have more\nconsistent success with later recommendations catering to that polarisation.\nFinally, we argue that given our findings, designing an RL-based recommender\nsystem which cannot learn to exploit user tampering requires making the metric\nfor the recommender's success independent of observable signals of user\nengagement, and thus that a media recommendation system built solely with RL is\nnecessarily either unsafe, or almost certainly commercially unviable.",
    "descriptor": "\nComments: Accepted for presentation at the 4th FAccTRec Workshop on Responsible Recommendation (FAccTRec '21)\n",
    "authors": [
      "Charles Evans",
      "Atoosa Kasirzadeh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04083"
  },
  {
    "id": "arXiv:2109.04084",
    "title": "Thinking Clearly, Talking Fast: Concept-Guided Non-Autoregressive  Generation for Open-Domain Dialogue Systems",
    "abstract": "Human dialogue contains evolving concepts, and speakers naturally associate\nmultiple concepts to compose a response. However, current dialogue models with\nthe seq2seq framework lack the ability to effectively manage concept\ntransitions and can hardly introduce multiple concepts to responses in a\nsequential decoding manner. To facilitate a controllable and coherent dialogue,\nin this work, we devise a concept-guided non-autoregressive model (CG-nAR) for\nopen-domain dialogue generation. The proposed model comprises a multi-concept\nplanning module that learns to identify multiple associated concepts from a\nconcept graph and a customized Insertion Transformer that performs\nconcept-guided non-autoregressive generation to complete a response. The\nexperimental results on two public datasets show that CG-nAR can produce\ndiverse and coherent responses, outperforming state-of-the-art baselines in\nboth automatic and human evaluations with substantially faster inference speed.",
    "descriptor": "\nComments: Accepted by EMNLP 2021, 12 pages\n",
    "authors": [
      "Yicheng Zou",
      "Zhihua Liu",
      "Xingwu Hu",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04084"
  },
  {
    "id": "arXiv:2109.04086",
    "title": "Mapping Research Topics in Software Testing: A Bibliometric Analysis",
    "abstract": "In this study, we apply co-word analysis - a text mining technique based on\nthe co-occurrence of terms - to map the topology of software testing research\ntopics, with the goal of providing current and prospective researchers with a\nmap, and observations about the evolution, of the software testing field. Our\nanalysis enables the mapping of software testing research into clusters of\nconnected topics, from which emerge a total of 16 high-level research themes\nand a further 18 subthemes. This map also suggests topics that are growing in\nimportance, including topics related to web and mobile applications and\nartificial intelligence. Exploration of author and country-based collaboration\npatterns offers similar insight into the implicit and explicit factors that\ninfluence collaboration and suggests emerging sources of collaboration for\nfuture work. We make our observations - and the underlying mapping of research\ntopics and research collaborations - available so that researchers can gain a\ndeeper understanding of the topology of the software testing field, inspiration\nregarding new areas and connections to explore, and collaborators who will\nbroaden their perspectives.",
    "descriptor": "\nComments: Under submission to Journal of Systems and Software\n",
    "authors": [
      "Alireza Salahirad",
      "Gregory Gay",
      "Ehsan Mohammadi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.04086"
  },
  {
    "id": "arXiv:2109.04087",
    "title": "Learning Cross-Scale Visual Representations for Real-Time Image  Geo-Localization",
    "abstract": "Robot localization remains a challenging task in GPS denied environments.\nState estimation approaches based on local sensors, e.g. cameras or IMUs, are\ndrifting-prone for long-range missions as error accumulates. In this study, we\naim to address this problem by localizing image observations in a 2D\nmulti-modal geospatial map. We introduce the cross-scale dataset and a\nmethodology to produce additional data from cross-modality sources. We propose\na framework that learns cross-scale visual representations without supervision.\nExperiments are conducted on data from two different domains, underwater and\naerial. In contrast to existing studies in cross-view image geo-localization,\nour approach a) performs better on smaller-scale multi-modal maps; b) is more\ncomputationally efficient for real-time applications; c) can serve directly in\nconcert with state estimation pipelines.",
    "descriptor": "",
    "authors": [
      "Tianyi Zhang",
      "Matthew Johnson-Roberson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04087"
  },
  {
    "id": "arXiv:2109.04094",
    "title": "An Experimental Study of Class Imbalance in Federated Learning",
    "abstract": "Federated learning is a distributed machine learning paradigm that trains a\nglobal model for prediction based on a number of local models at clients while\nlocal data privacy is preserved. Class imbalance is believed to be one of the\nfactors that degrades the global model performance. However, there has been\nvery little research on if and how class imbalance can affect the global\nperformance. class imbalance in federated learning is much more complex than\nthat in traditional non-distributed machine learning, due to different class\nimbalance situations at local clients. Class imbalance needs to be re-defined\nin distributed learning environments. In this paper, first, we propose two new\nmetrics to define class imbalance -- the global class imbalance degree (MID)\nand the local difference of class imbalance among clients (WCS). Then, we\nconduct extensive experiments to analyze the impact of class imbalance on the\nglobal performance in various scenarios based on our definition. Our results\nshow that a higher MID and a larger WCS degrade more the performance of the\nglobal model. Besides, WCS is shown to slow down the convergence of the global\nmodel by misdirecting the optimization.",
    "descriptor": "",
    "authors": [
      "C. Xiao",
      "S. Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04094"
  },
  {
    "id": "arXiv:2109.04095",
    "title": "Debiasing Methods in Natural Language Understanding Make Bias More  Accessible",
    "abstract": "Model robustness to bias is often determined by the generalization on\ncarefully designed out-of-distribution datasets. Recent debiasing methods in\nnatural language understanding (NLU) improve performance on such datasets by\npressuring models into making unbiased predictions. An underlying assumption\nbehind such methods is that this also leads to the discovery of more robust\nfeatures in the model's inner representations. We propose a general\nprobing-based framework that allows for post-hoc interpretation of biases in\nlanguage models, and use an information-theoretic approach to measure the\nextractability of certain biases from the model's representations. We\nexperiment with several NLU datasets and known biases, and show that,\ncounter-intuitively, the more a language model is pushed towards a debiased\nregime, the more bias is actually encoded in its inner representations.",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Michael Mendelson",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04095"
  },
  {
    "id": "arXiv:2109.04096",
    "title": "A Three-Stage Learning Framework for Low-Resource Knowledge-Grounded  Dialogue Generation",
    "abstract": "Neural conversation models have shown great potentials towards generating\nfluent and informative responses by introducing external background knowledge.\nNevertheless, it is laborious to construct such knowledge-grounded dialogues,\nand existing models usually perform poorly when transfer to new domains with\nlimited training samples. Therefore, building a knowledge-grounded dialogue\nsystem under the low-resource setting is a still crucial issue. In this paper,\nwe propose a novel three-stage learning framework based on weakly supervised\nlearning which benefits from large scale ungrounded dialogues and unstructured\nknowledge base. To better cooperate with this framework, we devise a variant of\nTransformer with decoupled decoder which facilitates the disentangled learning\nof response generation and knowledge incorporation. Evaluation results on two\nbenchmarks indicate that our approach can outperform other state-of-the-art\nmethods with less training data, and even in zero-resource scenario, our\napproach still performs well.",
    "descriptor": "\nComments: Accepted by EMNLP 2021 main conference\n",
    "authors": [
      "Shilei Liu",
      "Xiaofeng Zhao",
      "Bochao Li",
      "Feiliang Ren",
      "Longhui Zhang",
      "Shujuan Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04096"
  },
  {
    "id": "arXiv:2109.04098",
    "title": "ARMAN: Pre-training with Semantically Selecting and Reordering of  Sentences for Persian Abstractive Summarization",
    "abstract": "Abstractive text summarization is one of the areas influenced by the\nemergence of pre-trained language models. Current pre-training works in\nabstractive summarization give more points to the summaries with more words in\ncommon with the main text and pay less attention to the semantic similarity\nbetween generated sentences and the original document. We propose ARMAN, a\nTransformer-based encoder-decoder model pre-trained with three novel objectives\nto address this issue. In ARMAN, salient sentences from a document are selected\naccording to a modified semantic score to be masked and form a pseudo summary.\nTo summarize more accurately and similar to human writing patterns, we applied\nmodified sentence reordering. We evaluated our proposed models on six\ndownstream Persian summarization tasks. Experimental results show that our\nproposed model achieves state-of-the-art performance on all six summarization\ntasks measured by ROUGE and BERTScore. Our models also outperform prior works\nin textual entailment, question paraphrasing, and multiple choice question\nanswering. Finally, we established a human evaluation and show that using the\nsemantic score significantly improves summarization results.",
    "descriptor": "",
    "authors": [
      "Alireza Salemi",
      "Emad Kebriaei",
      "Ghazal Neisi Minaei",
      "Azadeh Shakery"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04098"
  },
  {
    "id": "arXiv:2109.04100",
    "title": "Taming Self-Supervised Learning for Presentation Attack Detection:  In-Image De-Folding and Out-of-Image De-Mixing",
    "abstract": "Biometric systems are vulnerable to the Presentation Attacks (PA) performed\nusing various Presentation Attack Instruments (PAIs). Even though there are\nnumerous Presentation Attack Detection (PAD) techniques based on both deep\nlearning and hand-crafted features, the generalization of PAD for unknown PAI\nis still a challenging problem. The common problem with existing deep\nlearning-based PAD techniques is that they may struggle with local optima,\nresulting in weak generalization against different PAs. In this work, we\npropose to use self-supervised learning to find a reasonable initialization\nagainst local trap, so as to improve the generalization ability in detecting\nPAs on the biometric system.The proposed method, denoted as IF-OM, is based on\na global-local view coupled with De-Folding and De-Mixing to derive the\ntask-specific representation for PAD.During De-Folding, the proposed technique\nwill learn region-specific features to represent samples in a local pattern by\nexplicitly maximizing cycle consistency. While, De-Mixing drives detectors to\nobtain the instance-specific features with global information for more\ncomprehensive representation by maximizing topological consistency. Extensive\nexperimental results show that the proposed method can achieve significant\nimprovements in terms of both face and fingerprint PAD in more complicated and\nhybrid datasets, when compared with the state-of-the-art methods. Specifically,\nwhen training in CASIA-FASD and Idiap Replay-Attack, the proposed method can\nachieve 18.60% Equal Error Rate (EER) in OULU-NPU and MSU-MFSD, exceeding\nbaseline performance by 9.54%. Code will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Haozhe Liu",
      "Zhe Kong",
      "Raghavendra Ramachandra",
      "Feng Liu",
      "Linlin Shen",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04100"
  },
  {
    "id": "arXiv:2109.04101",
    "title": "TimeTraveler: Reinforcement Learning for Temporal Knowledge Graph  Forecasting",
    "abstract": "Temporal knowledge graph (TKG) reasoning is a crucial task that has gained\nincreasing research interest in recent years. Most existing methods focus on\nreasoning at past timestamps to complete the missing facts, and there are only\na few works of reasoning on known TKGs to forecast future facts. Compared with\nthe completion task, the forecasting task is more difficult that faces two main\nchallenges: (1) how to effectively model the time information to handle future\ntimestamps? (2) how to make inductive inference to handle previously unseen\nentities that emerge over time? To address these challenges, we propose the\nfirst reinforcement learning method for forecasting. Specifically, the agent\ntravels on historical knowledge graph snapshots to search for the answer. Our\nmethod defines a relative time encoding function to capture the timespan\ninformation, and we design a novel time-shaped reward based on Dirichlet\ndistribution to guide the model learning. Furthermore, we propose a novel\nrepresentation method for unseen entities to improve the inductive inference\nability of the model. We evaluate our method for this link prediction task at\nfuture timestamps. Extensive experiments on four benchmark datasets demonstrate\nsubstantial performance improvement meanwhile with higher explainability, less\ncalculation, and fewer parameters when compared with existing state-of-the-art\nmethods.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Haohai Sun",
      "Jialun Zhong",
      "Yunpu Ma",
      "Zhen Han",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04101"
  },
  {
    "id": "arXiv:2109.04106",
    "title": "Function recovery on manifolds using scattered data",
    "abstract": "We consider the task of recovering a Sobolev function on a connected compact\nRiemannian manifold $M$ when given a sample on a finite point set. We prove\nthat the quality of the sample is given by the $L_\\gamma(M)$-average of the\ngeodesic distance to the point set and determine the value of $\\gamma\\in\n(0,\\infty]$. This extends our findings on bounded convex domains\n[arXiv:2009.11275, 2020]. Further, a limit theorem for moments of the average\ndistance to a set consisting of i.i.d. uniform points is proven. This yields\nthat a random sample is asymptotically as good as an optimal sample in\nprecisely those cases with $\\gamma<\\infty$. In particular, we obtain that\ncubature formulas with random nodes are asymptotically as good as optimal\ncubature formulas if the weights are chosen correctly. This closes a\nlogarithmic gap left open by Ehler, Gr\\\"af and Oates [Stat. Comput.,\n29:1203-1214, 2019].",
    "descriptor": "",
    "authors": [
      "David Krieg",
      "Mathias Sonnleitner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04106"
  },
  {
    "id": "arXiv:2109.04108",
    "title": "MapRE: An Effective Semantic Mapping Approach for Low-resource Relation  Extraction",
    "abstract": "Neural relation extraction models have shown promising results in recent\nyears; however, the model performance drops dramatically given only a few\ntraining samples. Recent works try leveraging the advance in few-shot learning\nto solve the low resource problem, where they train label-agnostic models to\ndirectly compare the semantic similarities among context sentences in the\nembedding space. However, the label-aware information, i.e., the relation label\nthat contains the semantic knowledge of the relation itself, is often neglected\nfor prediction. In this work, we propose a framework considering both\nlabel-agnostic and label-aware semantic mapping information for low resource\nrelation extraction. We show that incorporating the above two types of mapping\ninformation in both pretraining and fine-tuning can significantly improve the\nmodel performance on low-resource relation extraction tasks.",
    "descriptor": "\nComments: Accepted as a long paper in the main conference of EMNLP 2021\n",
    "authors": [
      "Manqing Dong",
      "Chunguang Pan",
      "Zhipeng Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04108"
  },
  {
    "id": "arXiv:2109.04114",
    "title": "Fixing exposure bias with imitation learning needs powerful oracles",
    "abstract": "We apply imitation learning (IL) to tackle the NMT exposure bias problem with\nerror-correcting oracles, and evaluate an SMT lattice-based oracle which,\ndespite its excellent performance in an unconstrained oracle translation task,\nturned out to be too pruned and idiosyncratic to serve as the oracle for IL.",
    "descriptor": "",
    "authors": [
      "Luca Hormann",
      "Artem Sokolov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04114"
  },
  {
    "id": "arXiv:2109.04115",
    "title": "AutoSmart: An Efficient and Automatic Machine Learning framework for  Temporal Relational Data",
    "abstract": "Temporal relational data, perhaps the most commonly used data type in\nindustrial machine learning applications, needs labor-intensive feature\nengineering and data analyzing for giving precise model predictions. An\nautomatic machine learning framework is needed to ease the manual efforts in\nfine-tuning the models so that the experts can focus more on other problems\nthat really need humans' engagement such as problem definition, deployment, and\nbusiness services. However, there are three main challenges for building\nautomatic solutions for temporal relational data: 1) how to effectively and\nautomatically mining useful information from the multiple tables and the\nrelations from them? 2) how to be self-adjustable to control the time and\nmemory consumption within a certain budget? and 3) how to give generic\nsolutions to a wide range of tasks? In this work, we propose our solution that\nsuccessfully addresses the above issues in an end-to-end automatic way. The\nproposed framework, AutoSmart, is the winning solution to the KDD Cup 2019 of\nthe AutoML Track, which is one of the largest AutoML competition to date (860\nteams with around 4,955 submissions). The framework includes automatic data\nprocessing, table merging, feature engineering, and model tuning, with a\ntime\\&memory controller for efficiently and automatically formulating the\nmodels. The proposed framework outperforms the baseline solution significantly\non several datasets in various domains.",
    "descriptor": "\nComments: Accepted in the ADS track at the SIGKDD 2021 conference\n",
    "authors": [
      "Zhipeng Luo",
      "Zhixing He",
      "Jin Wang",
      "Manqing Dong",
      "Jianqiang Huang",
      "Mingjian Chen",
      "Bohang Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04115"
  },
  {
    "id": "arXiv:2109.04117",
    "title": "Machine Learning-Enabled Data Rate Prediction for 5G NSA  Vehicle-to-Cloud Communications",
    "abstract": "In order to satisfy the ever-growing Quality of Service (QoS) requirements of\ninnovative services, cellular communication networks are constantly evolving.\nRecently, the 5G NonStandalone (NSA) mode has been deployed as an intermediate\nstrategy to deliver high-speed connectivity to early adopters of 5G by\nincorporating Long Term Evolution (LTE) network infrastructure. In addition to\nthe technological advancements, novel communication paradigms such as\nanticipatory mobile networking aim to achieve a more intelligent usage of the\navailable network resources through exploitation of context knowledge. For this\npurpose, novel methods for proactive prediction of the end-to-end behavior are\nseen as key enablers. In this paper, we present a first empirical analysis of\nclient-based end-to-end data rate prediction for 5G NSA vehicle-to-cloud\ncommunications. Although this operation mode is characterized by massive\nfluctuations of the observed data rate, the results show that conventional\nmachine learning methods can utilize locally acquirable measurements for\nachieving comparably accurate estimations of the end-to-end behavior.",
    "descriptor": "",
    "authors": [
      "Benjamin Sliwa",
      "Hendrik Schippers",
      "Christian Wietfeld"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.04117"
  },
  {
    "id": "arXiv:2109.04119",
    "title": "HSMD: An object motion detection algorithm using a Hybrid Spiking Neural  Network Architecture",
    "abstract": "The detection of moving objects is a trivial task performed by vertebrate\nretinas, yet a complex computer vision task. Object-motion-sensitive ganglion\ncells (OMS-GC) are specialised cells in the retina that sense moving objects.\nOMS-GC take as input continuous signals and produce spike patterns as output,\nthat are transmitted to the Visual Cortex via the optic nerve. The Hybrid\nSensitive Motion Detector (HSMD) algorithm proposed in this work enhances the\nGSOC dynamic background subtraction (DBS) algorithm with a customised 3-layer\nspiking neural network (SNN) that outputs spiking responses akin to the OMS-GC.\nThe algorithm was compared against existing background subtraction (BS)\napproaches, available on the OpenCV library, specifically on the 2012 change\ndetection (CDnet2012) and the 2014 change detection (CDnet2014) benchmark\ndatasets. The results show that the HSMD was ranked overall first among the\ncompeting approaches and has performed better than all the other algorithms on\nfour of the categories across all the eight test metrics. Furthermore, the HSMD\nproposed in this paper is the first to use an SNN to enhance an existing state\nof the art DBS (GSOC) algorithm and the results demonstrate that the SNN\nprovides near real-time performance in realistic applications.",
    "descriptor": "",
    "authors": [
      "Pedro Machado",
      "Andreas Oikonomou",
      "Joao Filipe Ferreira",
      "T.M. McGinnity"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.04119"
  },
  {
    "id": "arXiv:2109.04120",
    "title": "Privacy-Protecting Techniques for Behavioral Data: A Survey",
    "abstract": "Our behavior (the way we talk, walk, or think) is unique and can be used as a\nbiometric trait. It also correlates with sensitive attributes like emotions.\nHence, techniques to protect individuals privacy against unwanted inferences\nare required. To consolidate knowledge in this area, we systematically reviewed\napplicable anonymization techniques. We taxonomize and compare existing\nsolutions regarding privacy goals, conceptual operation, advantages, and\nlimitations. Our analysis shows that some behavioral traits (e.g., voice) have\nreceived much attention, while others (e.g., eye-gaze, brainwaves) are mostly\nneglected. We also find that the evaluation methodology of behavioral\nanonymization techniques can be further improved.",
    "descriptor": "",
    "authors": [
      "Simon Hanisch",
      "Patricia Arias-Cabarcos",
      "Javier Parra-Arnau",
      "Thorsten Strufe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.04120"
  },
  {
    "id": "arXiv:2109.04127",
    "title": "Word-Level Coreference Resolution",
    "abstract": "Recent coreference resolution models rely heavily on span representations to\nfind coreference links between word spans. As the number of spans is $O(n^2)$\nin the length of text and the number of potential links is $O(n^4)$, various\npruning techniques are necessary to make this approach computationally\nfeasible. We propose instead to consider coreference links between individual\nwords rather than word spans and then reconstruct the word spans. This reduces\nthe complexity of the coreference model to $O(n^2)$ and allows it to consider\nall potential mentions without pruning any of them out. We also demonstrate\nthat, with these changes, SpanBERT for coreference resolution will be\nsignificantly outperformed by RoBERTa. While being highly efficient, our model\nperforms competitively with recent coreference resolution systems on the\nOntoNotes benchmark.",
    "descriptor": "\nComments: Accepted to EMNLP-2021\n",
    "authors": [
      "Vladimir Dobrovolskii"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04127"
  },
  {
    "id": "arXiv:2109.04129",
    "title": "Fast Power Series Solution of Large 3-D Electrodynamic Integral Equation  for PEC Scatterers",
    "abstract": "This paper presents a new fast power series solution method to solve the\nHierarchal Method of Moment(MoM) matrix for a large complex,perfectly electric\nconducting (PEC) 3D structures. The proposed power series solution converges in\njust two iterations which is faster than the conventional fast solver-based\niterative solution. The method is purely algebraic in nature and, as such\napplicable to existing conventional methods. The method uses regular fast\nsolver Hierarchal Matrix (H-Matrix) and can also be applied to Multilevel Fast\nMultipole Method Algorithm(MLFMA). In the proposed method, we use the scaling\nof the symmetric near-field matrix to develop a diagonally dominant overall\nmatrix to enable a power series solution. Left and right block scaling\ncoefficients are required for scaling near-field blocks to diagonal blocks\nusing Schur's complement method. However,only the right-hand scaling\ncoefficients are computed for symmetric near-field matrix leading to saving of\ncomputation time and memory. Due to symmetric property, the left side-block\nscaling coefficients are just the transpose of the right-scaling blocks. Next,\nthe near-field blocks are replaced by scaled near-field diagonal blocks. Now\nthe scaled near-field blocks in combination with far-field and scaling\ncoefficients are subjected to power series solution terminating after only two\nterms. As all the operations are performed on the near-field blocks, the\ncomplexity of scaling coefficient computation is retained as O(N). The power\nseries solution only involves the matrix-vector product of the far-field,\nscaling coefficients blocks, and inverse of scaled near-field blocks. Hence,\nthe solution cost remains O(NlogN). Several numerical results are presented to\nvalidate the efficiency and robustness of the proposed numerical method.",
    "descriptor": "",
    "authors": [
      "Yoginder Kumar Negi",
      "N. Balakrishnan",
      "Sadasiva M. Rao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04129"
  },
  {
    "id": "arXiv:2109.04131",
    "title": "The uniform sparse FFT with application to PDEs with random coefficients",
    "abstract": "We develop an efficient, non-intrusive, adaptive algorithm for the solution\nof elliptic partial differential equations with random coefficients. The sparse\nFast Fourier Transform detects the most important frequencies in a given search\ndomain and therefore adaptively generates a suitable Fourier basis\ncorresponding to the approximately largest Fourier coefficients of the\nfunction. Our uniform sFFT does this w.r.t. the stochastic domain\nsimultaneously for every node of a finite element mesh in the spatial domain\nand creates a suitable approximation space for all spatial nodes by joining the\ndetected frequency sets. This strategy allows for a faster and more efficient\ncomputation, than just using the full sFFT algorithm for each node separately.\nWe then test the usFFT for different examples using periodic, affine and\nlognormal random coefficients. The results are significantly better than when\nusing given standard frequency sets and the algorithm does not require any a\npriori information about the solution.",
    "descriptor": "",
    "authors": [
      "Lutz K\u00e4mmerer",
      "Daniel Potts",
      "Fabian Taubert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04131"
  },
  {
    "id": "arXiv:2109.04132",
    "title": "Survey about cyberattack protection motivation in higher education:  Academics at Slovenian universities, 2017",
    "abstract": "This paper reports on a study aiming to explore factors associated with\nmotivation of individuals in organizations to protect against cyberattacks. The\nobjectives of this study were to determine how fear of cyberattacks, perceived\nseverity, perceived vulnerability, perceived threats, measure efficacy,\nself-efficacy, measure costs, mandatoriness and psychological reactance are\nassociated with protection motivation of individuals in organizations. The\nstudy employed a cross-sectional research design. A survey was conducted among\nacademics at six Slovenian universities between June and September 2017. A\ntotal of 324 respondents completed the survey (7.6 percent response rate)\nproviding for N=255 useful responses after excluding poorly completed\nresponses. The survey questionnaire was developed in English. A Slovenian\ntranslation of the survey questionnaire is available.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.07712, arXiv:2109.00837\n",
    "authors": [
      "Luka Jelov\u010dan",
      "Simon Vrhovec",
      "An\u017ee Miheli\u010d"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.04132"
  },
  {
    "id": "arXiv:2109.04134",
    "title": "Tiny CNN for feature point description for document analysis: approach  and dataset",
    "abstract": "In this paper, we study the problem of feature points description in the\ncontext of document analysis and template matching. Our study shows that the\nspecific training data is required for the task especially if we are to train a\nlightweight neural network that will be usable on devices with limited\ncomputational resources. In this paper, we construct and provide a dataset with\na method of training patches retrieval. We prove the effectiveness of this data\nby training a lightweight neural network and show how it performs in both\ndocuments and general patches matching. The training was done on the provided\ndataset in comparison with HPatches training dataset and for the testing we use\nHPatches testing framework and two publicly available datasets with various\ndocuments pictured on complex backgrounds: MIDV-500 and MIDV-2019.",
    "descriptor": "\nComments: 8 pages, 5 figures, submitted to Computer Optics\n",
    "authors": [
      "A. Sheshkus",
      "A. Chirvonaya",
      "V.L. Arlazarov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04134"
  },
  {
    "id": "arXiv:2109.04137",
    "title": "Fusing task-oriented and open-domain dialogues in conversational agents",
    "abstract": "The goal of building intelligent dialogue systems has largely been\n\\textit{separately} pursued under two paradigms: task-oriented dialogue (TOD)\nsystems, which perform goal-oriented functions, and open-domain dialogue (ODD)\nsystems, which focus on non-goal-oriented chitchat. The two dialogue modes can\npotentially be intertwined together seamlessly in the same conversation, as\neasily done by a friendly human assistant. Such ability is desirable in\nconversational agents, as the integration makes them more accessible and\nuseful. Our paper addresses this problem of fusing TODs and ODDs in multi-turn\ndialogues. Based on the popular TOD dataset MultiWOZ, we build a new dataset\nFusedChat, by rewriting the existing TOD turns and adding new ODD turns. This\nprocedure constructs conversation sessions containing exchanges from both\ndialogue modes. It features inter-mode contextual dependency, i.e., the\ndialogue turns from the two modes depend on each other. Rich dependency\npatterns including co-reference and ellipsis are features. The new dataset,\nwith 60k new human-written ODD turns and 5k re-written TOD turns, offers a\nbenchmark to test a dialogue model's ability to perform inter-mode\nconversations. This is a more challenging task since the model has to determine\nthe appropriate dialogue mode and generate the response based on the inter-mode\ncontext. But such models would better mimic human-level conversation\ncapabilities. We evaluate baseline models on this task, including\n\\textit{classification-based} two-stage models and \\textit{two-in-one} fused\nmodels. We publicly release FusedChat and the baselines to propel future work\non inter-mode dialogue systems https://github.com/tomyoung903/FusedChat.",
    "descriptor": "",
    "authors": [
      "Tom Young",
      "Frank Xing",
      "Vlad Pandelea",
      "Jinjie Ni",
      "Erik Cambria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04137"
  },
  {
    "id": "arXiv:2109.04138",
    "title": "Multilingual Audio-Visual Smartphone Dataset And Evaluation",
    "abstract": "Smartphones have been employed with biometric-based verification systems to\nprovide security in highly sensitive applications. Audio-visual biometrics are\ngetting popular due to the usability and also it will be challenging to spoof\nbecause of multi-modal nature. In this work, we present an audio-visual\nsmartphone dataset captured in five different recent smartphones. This new\ndataset contains 103 subjects captured in three different sessions considering\nthe different real-world scenarios. Three different languages are acquired in\nthis dataset to include the problem of language dependency of the speaker\nrecognition systems. These unique characteristics of this dataset will pave the\nway to implement novel state-of-the-art unimodal or audio-visual speaker\nrecognition systems. We also report the performance of the bench-marked\nbiometric verification systems on our dataset. The robustness of biometric\nalgorithms is evaluated towards multiple dependencies like signal noise,\ndevice, language and presentation attacks like replay and synthesized signals\nwith extensive experiments. The obtained results raised many concerns about the\ngeneralization properties of state-of-the-art biometrics methods in\nsmartphones.",
    "descriptor": "",
    "authors": [
      "Hareesh Mandalapu",
      "Aravinda Reddy P N",
      "Raghavendra Ramachandra",
      "K Sreenivasa Rao",
      "Pabitra Mitra",
      "S R Mahadeva Prasanna",
      "Christoph Busch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04138"
  },
  {
    "id": "arXiv:2109.04139",
    "title": "Robot Localization and Navigation through Predictive Processing using  LiDAR",
    "abstract": "Knowing the position of the robot in the world is crucial for navigation.\nNowadays, Bayesian filters, such as Kalman and particle-based, are standard\napproaches in mobile robotics. Recently, end-to-end learning has allowed for\nscaling-up to high-dimensional inputs and improved generalization. However,\nthere are still limitations to providing reliable laser navigation. Here we\nshow a proof-of-concept of the predictive processing-inspired approach to\nperception applied for localization and navigation using laser sensors, without\nthe need for odometry. We learn the generative model of the laser through\nself-supervised learning and perform both online state-estimation and\nnavigation through stochastic gradient descent on the variational free-energy\nbound. We evaluated the algorithm on a mobile robot (TIAGo Base) with a laser\nsensor (SICK) in Gazebo. Results showed improved state-estimation performance\nwhen comparing to a state-of-the-art particle filter in the absence of\nodometry. Furthermore, conversely to standard Bayesian estimation approaches\nour method also enables the robot to navigate when providing the desired goal\nby inferring the actions that minimize the prediction error.",
    "descriptor": "\nComments: 2nd International Workshop on Active Inference IWAI2021, European Conference on Machine Learning (ECML/PCKDD 2021)\n",
    "authors": [
      "Daniel Burghardt",
      "Pablo Lanillos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04139"
  },
  {
    "id": "arXiv:2109.04142",
    "title": "An Effective Parallel Program Debugging Approach Based on Timing  Annotation",
    "abstract": "We propose an effective parallel program debugging approach based on the\ntiming annotation technique. With prevalent multi-core platforms, parallel\nprogramming is required to fully utilize the computing power. However, the\nnon-determinism property and the associated concurrency bugs are notorious and\nremain to be great challenge to designers. We hence propose an effective\nprogram debugging approach using the timing annotation technique derived from\nthe deterministic Multi-Core Instruction Set Simulation (MCISS) technology. We\nhence construct a deterministic execution environment for parallel program\ndebugging and devise a few unique, effective and easy-to-use parallel debugging\nfunctions. We modify QEMU and GDB to implement and demonstrate our proposed\nidea. The usage of our debugger is almost identical to the conventional GDB\ndebugger. Therefore, users may learn how to use the tool seamlessly.",
    "descriptor": "",
    "authors": [
      "Yun Chang",
      "Hsin-I Wu",
      "Ren-Song Tsay"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.04142"
  },
  {
    "id": "arXiv:2109.04144",
    "title": "Avoiding Inference Heuristics in Few-shot Prompt-based Finetuning",
    "abstract": "Recent prompt-based approaches allow pretrained language models to achieve\nstrong performances on few-shot finetuning by reformulating downstream tasks as\na language modeling problem. In this work, we demonstrate that, despite its\nadvantages on low data regimes, finetuned prompt-based models for sentence pair\nclassification tasks still suffer from a common pitfall of adopting inference\nheuristics based on lexical overlap, e.g., models incorrectly assuming a\nsentence pair is of the same meaning because they consist of the same set of\nwords. Interestingly, we find that this particular inference heuristic is\nsignificantly less present in the zero-shot evaluation of the prompt-based\nmodel, indicating how finetuning can be destructive to useful knowledge learned\nduring the pretraining. We then show that adding a regularization that\npreserves pretraining weights is effective in mitigating this destructive\ntendency of few-shot finetuning. Our evaluation on three datasets demonstrates\npromising improvements on the three corresponding challenge datasets used to\ndiagnose the inference heuristics.",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Prasetya Ajie Utama",
      "Nafise Sadat Moosavi",
      "Victor Sanh",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04144"
  },
  {
    "id": "arXiv:2109.04145",
    "title": "PIMNet: A Parallel, Iterative and Mimicking Network for Scene Text  Recognition",
    "abstract": "Nowadays, scene text recognition has attracted more and more attention due to\nits various applications. Most state-of-the-art methods adopt an\nencoder-decoder framework with attention mechanism, which generates text\nautoregressively from left to right. Despite the convincing performance, the\nspeed is limited because of the one-by-one decoding strategy. As opposed to\nautoregressive models, non-autoregressive models predict the results in\nparallel with a much shorter inference time, but the accuracy falls behind the\nautoregressive counterpart considerably. In this paper, we propose a Parallel,\nIterative and Mimicking Network (PIMNet) to balance accuracy and efficiency.\nSpecifically, PIMNet adopts a parallel attention mechanism to predict the text\nfaster and an iterative generation mechanism to make the predictions more\naccurate. In each iteration, the context information is fully explored. To\nimprove learning of the hidden layer, we exploit the mimicking learning in the\ntraining phase, where an additional autoregressive decoder is adopted and the\nparallel decoder mimics the autoregressive decoder with fitting outputs of the\nhidden layer. With the shared backbone between the two decoders, the proposed\nPIMNet can be trained end-to-end without pre-training. During inference, the\nbranch of the autoregressive decoder is removed for a faster speed. Extensive\nexperiments on public benchmarks demonstrate the effectiveness and efficiency\nof PIMNet. Our code will be available at https://github.com/Pay20Y/PIMNet.",
    "descriptor": "\nComments: Accepted by ACM MM 2021\n",
    "authors": [
      "Zhi Qiao",
      "Yu Zhou",
      "Jin Wei",
      "Wei Wang",
      "Yuan Zhang",
      "Ning Jiang",
      "Hongbin Wang",
      "Weiping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04145"
  },
  {
    "id": "arXiv:2109.04148",
    "title": "Automatic Timing-Coherent Transactor Generation for Mixed-level  Simulations",
    "abstract": "In this paper we extend the concept of the traditional transactor, which\nfocuses on correct content transfer, to a new timing-coherent transactor that\nalso accurately aligns the timing of each transaction boundary so that\ndesigners can perform precise concurrent system behavior analysis in\nmixed-abstraction-level system simulations which are essential to increasingly\ncomplex system designs. To streamline the process, we also developed an\nautomatic approach for timing-coherent transactor generation. Our approach is\nactually applied in mixed-level simulations and the results show that it\nachieves 100% timing accuracy while the conventional approach produces results\nof 25% to 44% error rate.",
    "descriptor": "",
    "authors": [
      "Li-Chun Chen",
      "Hsin-I Wu",
      "Ren-Song Tsay"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2109.04148"
  },
  {
    "id": "arXiv:2109.04149",
    "title": "DROP: Deep relocating option policy for optimal ride-hailing vehicle  repositioning",
    "abstract": "In a ride-hailing system, an optimal relocation of vacant vehicles can\nsignificantly reduce fleet idling time and balance the supply-demand\ndistribution, enhancing system efficiency and promoting driver satisfaction and\nretention. Model-free deep reinforcement learning (DRL) has been shown to\ndynamically learn the relocating policy by actively interacting with the\nintrinsic dynamics in large-scale ride-hailing systems. However, the issues of\nsparse reward signals and unbalanced demand and supply distribution place\ncritical barriers in developing effective DRL models. Conventional exploration\nstrategy (e.g., the $\\epsilon$-greedy) may barely work under such an\nenvironment because of dithering in low-demand regions distant from\nhigh-revenue regions. This study proposes the deep relocating option policy\n(DROP) that supervises vehicle agents to escape from oversupply areas and\neffectively relocate to potentially underserved areas. We propose to learn the\nLaplacian embedding of a time-expanded relocation graph, as an approximation\nrepresentation of the system relocation policy. The embedding generates\ntask-agnostic signals, which in combination with task-dependent signals,\nconstitute the pseudo-reward function for generating DROPs. We present a\nhierarchical learning framework that trains a high-level relocation policy and\na set of low-level DROPs. The effectiveness of our approach is demonstrated\nusing a custom-built high-fidelity simulator with real-world trip record data.\nWe report that DROP significantly improves baseline models with 15.7% more\nhourly revenue and can effectively resolve the dithering issue in low-demand\nareas.",
    "descriptor": "",
    "authors": [
      "Xinwu Qian",
      "Shuocheng Guo",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04149"
  },
  {
    "id": "arXiv:2109.04150",
    "title": "Self-supervised Reinforcement Learning with Independently Controllable  Subgoals",
    "abstract": "To successfully tackle challenging manipulation tasks, autonomous agents must\nlearn a diverse set of skills and how to combine them. Recently,\nself-supervised agents that set their own abstract goals by exploiting the\ndiscovered structure in the environment were shown to perform well on many\ndifferent tasks. In particular, some of them were applied to learn basic\nmanipulation skills in compositional multi-object environments. However, these\nmethods learn skills without taking the dependencies between objects into\naccount. Thus, the learned skills are difficult to combine in realistic\nenvironments. We propose a novel self-supervised agent that estimates relations\nbetween environment components and uses them to independently control different\nparts of the environment state. In addition, the estimated relations between\nobjects can be used to decompose a complex goal into a compatible sequence of\nsubgoals. We show that, by using this framework, an agent can efficiently and\nautomatically learn manipulation tasks in multi-object environments with\ndifferent relations between objects.",
    "descriptor": "",
    "authors": [
      "Andrii Zadaianchuk",
      "Georg Martius",
      "Fanny Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04150"
  },
  {
    "id": "arXiv:2109.04152",
    "title": "Lexico-semantic and affective modelling of Spanish poetry: A  semi-supervised learning approach",
    "abstract": "Text classification tasks have improved substantially during the last years\nby the usage of transformers. However, the majority of researches focus on\nprose texts, with poetry receiving less attention, specially for Spanish\nlanguage. In this paper, we propose a semi-supervised learning approach for\ninferring 21 psychological categories evoked by a corpus of 4572 sonnets, along\nwith 10 affective and lexico-semantic multiclass ones. The subset of poems used\nfor training an evaluation includes 270 sonnets. With our approach, we achieve\nan AUC beyond 0.7 for 76% of the psychological categories, and an AUC over 0.65\nfor 60% on the multiclass ones. The sonnets are modelled using transformers,\nthrough sentence embeddings, along with lexico-semantic and affective features,\nobtained by using external lexicons. Consequently, we see that this approach\nprovides an AUC increase of up to 0.12, as opposed to using transformers alone.",
    "descriptor": "\nComments: 24 pages, 8 figures, 7 tables\n",
    "authors": [
      "Alberto Barbado",
      "Mar\u00eda Dolores Gonz\u00e1lez",
      "D\u00e9bora Carrera"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04152"
  },
  {
    "id": "arXiv:2109.04153",
    "title": "Single Image 3D Object Estimation with Primitive Graph Networks",
    "abstract": "Reconstructing 3D object from a single image (RGB or depth) is a fundamental\nproblem in visual scene understanding and yet remains challenging due to its\nill-posed nature and complexity in real-world scenes. To address those\nchallenges, we adopt a primitive-based representation for 3D object, and\npropose a two-stage graph network for primitive-based 3D object estimation,\nwhich consists of a sequential proposal module and a graph reasoning module.\nGiven a 2D image, our proposal module first generates a sequence of 3D\nprimitives from input image with local feature attention. Then the graph\nreasoning module performs joint reasoning on a primitive graph to capture the\nglobal shape context for each primitive. Such a framework is capable of taking\ninto account rich geometry and semantic constraints during 3D structure\nrecovery, producing 3D objects with more coherent structure even under\nchallenging viewing conditions. We train the entire graph neural network in a\nstage-wise strategy and evaluate it on three benchmarks: Pix3D, ModelNet and\nNYU Depth V2. Extensive experiments show that our approach outperforms the\nprevious state of the arts with a considerable margin.",
    "descriptor": "\nComments: Accepted by ACM MM'21\n",
    "authors": [
      "Qian He",
      "Desen Zhou",
      "Bo Wan",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04153"
  },
  {
    "id": "arXiv:2109.04155",
    "title": "Deep Active Inference for Pixel-Based Discrete Control: Evaluation on  the Car Racing Problem",
    "abstract": "Despite the potential of active inference for visual-based control, learning\nthe model and the preferences (priors) while interacting with the environment\nis challenging. Here, we study the performance of a deep active inference\n(dAIF) agent on OpenAI's car racing benchmark, where there is no access to the\ncar's state. The agent learns to encode the world's state from high-dimensional\ninput through unsupervised representation learning. State inference and control\nare learned end-to-end by optimizing the expected free energy. Results show\nthat our model achieves comparable performance to deep Q-learning. However,\nvanilla dAIF does not reach state-of-the-art performance compared to other\nworld model approaches. Hence, we discuss the current model implementation's\nlimitations and potential architectures to overcome them.",
    "descriptor": "\nComments: 2nd International Workshop on Active Inference IWAI2021, European Conference on Machine Learning (ECML/PCKDD 2021)\n",
    "authors": [
      "Niels van Hoeffelen",
      "Pablo Lanillos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.04155"
  },
  {
    "id": "arXiv:2109.04160",
    "title": "Compositional Affinity Propagation: When Clusters Have Compositional  Structure",
    "abstract": "We consider a new kind of clustering problem in which clusters need not be\nindependent of each other, but rather can have compositional relationships with\nother clusters (e.g., an image set consists of rectangles, circles, as well as\ncombinations of rectangles and circles). This task is motivated by recent work\nin few-shot learning on compositional embedding models that structure the\nembedding space to distinguish the label sets, not just the individual labels,\nassigned to the examples. To tackle this clustering problem, we propose a new\nalgorithm called Compositional Affinity Propagation (CAP). In contrast to\nstandard Affinity Propagation as well as other algorithms for multi-view and\nhierarchical clustering, CAP can deduce compositionality among clusters\nautomatically. We show promising results, compared to several existing\nclustering algorithms, on the MultiMNIST, OmniGlot, and LibriSpeech datasets.\nOur work has applications to multi-object image recognition and speaker\ndiarization with simultaneous speech from multiple speakers.",
    "descriptor": "",
    "authors": [
      "Jacob Whitehill",
      "Zeqian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04160"
  },
  {
    "id": "arXiv:2109.04165",
    "title": "Modelling GDPR-Compliant Explanations for Trustworthy AI",
    "abstract": "Through the General Data Protection Regulation (GDPR), the European Union has\nset out its vision for Automated Decision- Making (ADM) and AI, which must be\nreliable and human-centred. In particular we are interested on the Right to\nExplanation, that requires industry to produce explanations of ADM. The\nHigh-Level Expert Group on Artificial Intelligence (AI-HLEG), set up to support\nthe implementation of this vision, has produced guidelines discussing the types\nof explanations that are appropriate for user-centred (interactive) Explanatory\nTools. In this paper we propose our version of Explanatory Narratives (EN),\nbased on user-centred concepts drawn from ISO 9241, as a model for user-centred\nexplanations aligned with the GDPR and the AI-HLEG guidelines. Through the use\nof ENs we convert the problem of generating explanations for ADM into the\nidentification of an appropriate path over an Explanatory Space, allowing\nexplainees to interactively explore it and produce the explanation best suited\nto their needs. To this end we list suitable exploration heuristics, we study\nthe properties and structure of explanations, and discuss the proposed model\nidentifying its weaknesses and strengths.",
    "descriptor": "",
    "authors": [
      "Francesco Sovrano",
      "Fabio Vitali",
      "Monica Palmirani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04165"
  },
  {
    "id": "arXiv:2109.04168",
    "title": "An oscillation free local discontinuous Galerkin method for nonlinear  degenerate parabolic equations",
    "abstract": "In this paper, we develop an oscillation free local discontinuous Galerkin\n(OFLDG) method for solving nonlinear degenerate parabolic equations. Following\nthe idea of our recent work [J. Lu, Y. Liu, and C.-W. Shu, SIAM J. Numer. Anal.\n59(2021), pp. 1299-1324.], we add the damping terms to the LDG scheme to\ncontrol the spurious oscillations when solutions have a large gradient. The\n$L^2$-stability and optimal priori error estimates for the semi-discrete scheme\nare established. The numerical experiments demonstrate that the proposed method\nmaintains the high-order accuracy and controls the spurious oscillations well.",
    "descriptor": "\nComments: 29 pages, 7 figures\n",
    "authors": [
      "Qi Tao",
      "Yong Liu",
      "Yan Jiang",
      "Jianfang Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04168"
  },
  {
    "id": "arXiv:2109.04171",
    "title": "From Philosophy to Interfaces: an Explanatory Method and a Tool Inspired  by Achinstein's Theory of Explanation",
    "abstract": "We propose a new method for explanations in Artificial Intelligence (AI) and\na tool to test its expressive power within a user interface. In order to bridge\nthe gap between philosophy and human-computer interfaces, we show a new\napproach for the generation of interactive explanations based on a\nsophisticated pipeline of AI algorithms for structuring natural language\ndocuments into knowledge graphs, answering questions effectively and\nsatisfactorily. Among the mainstream philosophical theories of explanation we\nidentified one that in our view is more easily applicable as a practical model\nfor user-centric tools: Achinstein's Theory of Explanation. With this work we\naim to prove that the theory proposed by Achinstein can be actually adapted for\nbeing implemented into a concrete software application, as an interactive\nprocess answering questions. To this end we found a way to handle the generic\n(archetypal) questions that implicitly characterise an explanatory processes as\npreliminary overviews rather than as answers to explicit questions, as commonly\nunderstood. To show the expressive power of this approach we designed and\nimplemented a pipeline of AI algorithms for the generation of interactive\nexplanations under the form of overviews, focusing on this aspect of\nexplanations rather than on existing interfaces and presentation logic layers\nfor question answering. We tested our hypothesis on a well-known XAI-powered\ncredit approval system by IBM, comparing CEM, a static explanatory tool for\npost-hoc explanations, with an extension we developed adding interactive\nexplanations based on our model. The results of the user study, involving more\nthan 100 participants, showed that our proposed solution produced a\nstatistically relevant improvement on effectiveness (U=931.0, p=0.036) over the\nbaseline, thus giving evidence in favour of our theory.",
    "descriptor": "",
    "authors": [
      "Francesco Sovrano",
      "Fabio Vitali"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04171"
  },
  {
    "id": "arXiv:2109.04173",
    "title": "Relating Graph Neural Networks to Structural Causal Models",
    "abstract": "Causality can be described in terms of a structural causal model (SCM) that\ncarries information on the variables of interest and their mechanistic\nrelations. For most processes of interest the underlying SCM will only be\npartially observable, thus causal inference tries to leverage any exposed\ninformation. Graph neural networks (GNN) as universal approximators on\nstructured input pose a viable candidate for causal learning, suggesting a\ntighter integration with SCM. To this effect we present a theoretical analysis\nfrom first principles that establishes a novel connection between GNN and SCM\nwhile providing an extended view on general neural-causal models. We then\nestablish a new model class for GNN-based causal inference that is necessary\nand sufficient for causal effect identification. Our empirical illustration on\nsimulations and standard benchmarks validate our theoretical proofs.",
    "descriptor": "\nComments: Main paper: 7 pages, References: 2 pages, Appendix: 10 pages; Main paper: 5 figures, Appendix: 3 figures\n",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Petar Veli\u010dkovi\u0107",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04173"
  },
  {
    "id": "arXiv:2109.04175",
    "title": "Safe, Deterministic Trajectory Planning for Unstructured and Partially  Occluded Environments",
    "abstract": "Ensuring safe behavior for automated vehicles in unregulated traffic areas\nposes a complex challenge for the industry. It is an open problem to provide\nscalable and certifiable solutions to this challenge. We derive a trajectory\nplanner based on model predictive control which interoperates with a monitoring\nsystem for pedestrian safety based on cellular automata. The combined\nplanner-monitor system is demonstrated on the example of a narrow indoor\nparking environment. The system features deterministic behavior, mitigating the\nimmanent risk of black boxes and offering full certifiability. By using\nfundamental and conservative prediction models of pedestrians the monitor is\nable to determine a safe drivable area in the partially occluded and\nunstructured parking environment. The information is fed to the trajectory\nplanner which ensures the vehicle remains in the safe drivable area at any time\nthrough constrained optimization. We show how the approach enables solving\nplenty of situations in tight parking garage scenarios. Even though\nconservative prediction models are applied, evaluations indicate a performant\nsystem for the tested low-speed navigation.",
    "descriptor": "",
    "authors": [
      "Sebastian vom Dorff",
      "Maximilian Kneissl",
      "Martin Fr\u00e4nzle"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04175"
  },
  {
    "id": "arXiv:2109.04176",
    "title": "Towards Transferable Adversarial Attacks on Vision Transformers",
    "abstract": "Vision transformers (ViTs) have demonstrated impressive performance on a\nseries of computer vision tasks, yet they still suffer from adversarial\nexamples. In this paper, we posit that adversarial attacks on transformers\nshould be specially tailored for their architecture, jointly considering both\npatches and self-attention, in order to achieve high transferability. More\nspecifically, we introduce a dual attack framework, which contains a Pay No\nAttention (PNA) attack and a PatchOut attack, to improve the transferability of\nadversarial samples across different ViTs. We show that skipping the gradients\nof attention during backpropagation can generate adversarial examples with high\ntransferability. In addition, adversarial perturbations generated by optimizing\nrandomly sampled subsets of patches at each iteration achieve higher attack\nsuccess rates than attacks using all patches. We evaluate the transferability\nof attacks on state-of-the-art ViTs, CNNs and robustly trained CNNs. The\nresults of these experiments demonstrate that the proposed dual attack can\ngreatly boost transferability between ViTs and from ViTs to CNNs. In addition,\nthe proposed method can easily be combined with existing transfer methods to\nboost performance.",
    "descriptor": "",
    "authors": [
      "Zhipeng Wei",
      "Jingjing Chen",
      "Micah Goldblum",
      "Zuxuan Wu",
      "Tom Goldstein",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04176"
  },
  {
    "id": "arXiv:2109.04177",
    "title": "Comfort and Sickness while Virtually Aboard an Autonomous Telepresence  Robot",
    "abstract": "In this paper, we analyze how different path aspects affect a user's\nexperience, mainly VR sickness and overall comfort, while immersed in an\nautonomously moving telepresence robot through a virtual reality headset. In\nparticular, we focus on how the robot turns and the distance it keeps from\nobjects, with the goal of planning suitable trajectories for an autonomously\nmoving immersive telepresence robot in mind; rotational acceleration is known\nfor causing the majority of VR sickness, and distance to objects modulates the\noptical flow. We ran a within-subjects user study (n = 36, women = 18) in which\nthe participants watched three panoramic videos recorded in a virtual museum\nwhile aboard an autonomously moving telepresence robot taking three different\npaths varying in aspects such as turns, speeds, or distances to walls and\nobjects. We found a moderate correlation between the users' sickness as\nmeasured by the SSQ and comfort on a 6-point Likert scale across all paths.\nHowever, we detected no association between sickness and the choice of the most\ncomfortable path, showing that sickness is not the only factor affecting the\ncomfort of the user. The subjective experience of turn speed did not correlate\nwith either the SSQ scores or comfort, even though people often mentioned\nturning speed as a source of discomfort in the open-ended questions. Through\nexploring the open-ended answers more carefully, a possible reason is that the\nlength and lack of predictability also play a large role in making people\nobserve turns as uncomfortable. A larger subjective distance from walls and\nobjects increased comfort and decreased sickness both in quantitative and\nqualitative data. Finally, the SSQ subscales and total weighted scores showed\ndifferences by age group and by gender.",
    "descriptor": "\nComments: Accepted for publication in EuroXR 2021\n",
    "authors": [
      "Markku Suomalainen",
      "Katherine J. Mimnaugh",
      "Israel Becerra",
      "Eliezer Lozano",
      "Rafael Murrieta-Cid",
      "Steven M. LaValle"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04177"
  },
  {
    "id": "arXiv:2109.04178",
    "title": "Multiple Oracle Algorithm For General-Sum Continuous Games",
    "abstract": "Continuous games have compact strategy sets and continuous utility functions.\nSuch games can have a highly complicated structure of Nash equilibria.\nAlgorithms and numerical methods for the equilibrium computation are known only\nfor particular classes of continuous games such as two-person polynomial games\nor games with pure equilibria. This contribution focuses on the computation and\napproximation of a mixed strategy equilibrium for the whole class of\nmultiplayer general-sum continuous games. We extend vastly the scope of\napplicability of the double oracle algorithm, which was initially designed and\nproved to converge only for two-person zero-sum games. Specifically, we propose\nan iterative strategy generation technique, which splits the original problem\ninto the master problem with only a finite subset of strategies being\nconsidered, and the subproblem in which an oracle finds the best response of\neach player. This simple method is guaranteed to recover an approximate\nequilibrium in finitely many iterations. Further, we argue that the Wasserstein\ndistance (the earth mover's distance) is the right metric on the space of mixed\nstrategies for our purposes. Our main result is the convergence of this\nalgorithm in the Wasserstein distance to an equilibrium of the original\ncontinuous game. The numerical experiments show the performance of our method\non several examples of games appearing in the literature.",
    "descriptor": "",
    "authors": [
      "T. Kroupa",
      "T. Votroubek"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.04178"
  },
  {
    "id": "arXiv:2109.04186",
    "title": "Fine-grained Data Distribution Alignment for Post-Training Quantization",
    "abstract": "While post-training quantization receives popularity mostly due to its\nevasion in accessing the original complete training dataset, its poor\nperformance also stems from this limitation. To alleviate this limitation, in\nthis paper, we leverage the synthetic data introduced by zero-shot quantization\nwith calibration dataset and we propose a fine-grained data distribution\nalignment (FDDA) method to boost the performance of post-training quantization.\nThe method is based on two important properties of batch normalization\nstatistics (BNS) we observed in deep layers of the trained network, i.e.,\ninter-class separation and intra-class incohesion. To preserve this\nfine-grained distribution information: 1) We calculate the per-class BNS of the\ncalibration dataset as the BNS centers of each class and propose a\nBNS-centralized loss to force the synthetic data distributions of different\nclasses to be close to their own centers. 2) We add Gaussian noise into the\ncenters to imitate the incohesion and propose a BNS-distorted loss to force the\nsynthetic data distribution of the same class to be close to the distorted\ncenters. By introducing these two fine-grained losses, our method shows the\nstate-of-the-art performance on ImageNet, especially when the first and last\nlayers are quantized to low-bit as well. Our project is available at\nhttps://github.com/viperit/FDDA.",
    "descriptor": "",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Mengzhao Chen",
      "Ke Li",
      "Yunhang Shen",
      "Fei Chao",
      "Yongjian Wu",
      "Feiyue Huang",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04186"
  },
  {
    "id": "arXiv:2109.04193",
    "title": "OGRe: An Object-Oriented General Relativity Package for Mathematica",
    "abstract": "We present OGRe, a modern Mathematica package for tensor calculus, designed\nto be both powerful and user-friendly. The package can be used in a variety of\ncontexts where tensor calculations are needed, in both mathematics and physics,\nbut it is especially suitable for general relativity. By implementing an\nobject-oriented design paradigm, OGRe allows calculating arbitrarily\ncomplicated tensor formulas easily, and automatically transforms between index\nconfigurations and coordinate systems behind the scenes as needed, eliminating\nuser errors by making it impossible for the user to combine tensors in\ninconsistent ways. Other features include displaying tensors in various forms,\nautomatic calculation of curvature tensors and geodesic equations, easy\nimporting and exporting of tensors between sessions, optimized algorithms and\nparallelization for improved performance, and more.",
    "descriptor": "\nComments: 92 pages, source code available at this https URL\n",
    "authors": [
      "Barak Shoshany"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Symbolic Computation (cs.SC)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2109.04193"
  },
  {
    "id": "arXiv:2109.04194",
    "title": "Novel Time Domain Based Upper-Limb Prosthesis Control using Incremental  Learning Approach",
    "abstract": "The upper limb of the body is a vital for various kind of activities for\nhuman. The complete or partial loss of the upper limb would lead to a\nsignificant impact on daily activities of the amputees. EMG carries important\ninformation of human physique which helps to decode the various functionalities\nof human arm. EMG signal based bionics and prosthesis have gained huge research\nattention over the past decade. Conventional EMG-PR based prosthesis struggles\nto give accurate performance due to off-line training used and incapability to\ncompensate for electrode position shift and change in arm position. This work\nproposes online training and incremental learning based system for upper limb\nprosthetic application. This system consists of ADS1298 as AFE (analog front\nend) and a 32 bit arm cortex-m4 processor for DSP (digital signal processing).\nThe system has been tested for both intact and amputated subjects. Time\nderivative moment based features have been implemented and utilized for\neffective pattern classification. Initially, system have been trained for four\nclasses using the on-line training process later on the number of classes have\nbeen incremented on user demand till eleven, and system performance has been\nevaluated. The system yielded a completion rate of 100% for healthy and\namputated subjects when four motions have been considered. Further 94.33% and\n92% completion rate have been showcased by the system when the number of\nclasses increased to eleven for healthy and amputees respectively. The motion\nefficacy test is also evaluated for all the subjects. The highest efficacy rate\nof 91.23% and 88.64% are observed for intact and amputated subjects\nrespectively.",
    "descriptor": "",
    "authors": [
      "Sidharth Pancholi",
      "Amit M. Joshi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.04194"
  },
  {
    "id": "arXiv:2109.04196",
    "title": "Failure Analysis of Hadoop Schedulers using an Integration of Model  Checking and Simulation",
    "abstract": "The Hadoop scheduler is a centerpiece of Hadoop, the leading processing\nframework for data-intensive applications in the cloud. Given the impact of\nfailures on the performance of applications running on Hadoop, testing and\nverifying the performance of the Hadoop scheduler is critical. Existing\napproaches such as performance simulation and analytical modeling are\ninadequate because they are not able to ascertain a complete verification of a\nHadoop scheduler. This is due to the wide range of constraints and aspects\ninvolved in Hadoop. In this paper, we propose a novel methodology that\nintegrates and combines simulation and model checking techniques to perform a\nformal verification of Hadoop schedulers, focusing on the following properties:\nschedulability, fairness and resources-deadlock freeness. We use the CSP\nlanguage to formally describe a Hadoop scheduler, and the PAT model checker to\nverify its properties. Next, we use the proposed formal model to analyze the\nscheduler of OpenCloud, a Hadoop-based cluster that simulates the Hadoop load,\nin order to illustrate the usability and benefits of our work. Results show\nthat our proposed methodology can help identify several tasks failures (up to\n78%) early on, i.e., before the tasks are executed on the cluster.",
    "descriptor": "\nComments: In Proceedings SCSS 2021, arXiv:2109.02501\n",
    "authors": [
      "Mbarka Soualhia",
      "Foutse Khomh",
      "Sofiene Tahar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2109.04196"
  },
  {
    "id": "arXiv:2109.04197",
    "title": "A distillation-based approach integrating continual learning and  federated learning for pervasive services",
    "abstract": "Federated Learning, a new machine learning paradigm enhancing the use of edge\ndevices, is receiving a lot of attention in the pervasive community to support\nthe development of smart services. Nevertheless, this approach still needs to\nbe adapted to the specificity of the pervasive domain. In particular, issues\nrelated to continual learning need to be addressed. In this paper, we present a\ndistillation-based approach dealing with catastrophic forgetting in federated\nlearning scenario. Specifically, Human Activity Recognition tasks are used as a\ndemonstration domain.",
    "descriptor": "",
    "authors": [
      "Anastasiia Usmanova",
      "Fran\u00e7ois Portet",
      "Philippe Lalanda",
      "German Vega"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04197"
  },
  {
    "id": "arXiv:2109.04200",
    "title": "Double-Scale Self-Supervised Hypergraph Learning for Group  Recommendation",
    "abstract": "With the prevalence of social media, there has recently been a proliferation\nof recommenders that shift their focus from individual modeling to group\nrecommendation. Since the group preference is a mixture of various\npredilections from group members, the fundamental challenge of group\nrecommendation is to model the correlations among members. Existing methods\nmostly adopt heuristic or attention-based preference aggregation strategies to\nsynthesize group preferences. However, these models mainly focus on the\npairwise connections of users and ignore the complex high-order interactions\nwithin and beyond groups. Besides, group recommendation suffers seriously from\nthe problem of data sparsity due to severely sparse group-item interactions. In\nthis paper, we propose a self-supervised hypergraph learning framework for\ngroup recommendation to achieve two goals: (1) capturing the intra- and\ninter-group interactions among users; (2) alleviating the data sparsity issue\nwith the raw data itself. Technically, for (1), a hierarchical hypergraph\nconvolutional network based on the user- and group-level hypergraphs is\ndeveloped to model the complex tuplewise correlations among users within and\nbeyond groups. For (2), we design a double-scale node dropout strategy to\ncreate self-supervision signals that can regularize user representations with\ndifferent granularities against the sparsity issue. The experimental analysis\non multiple benchmark datasets demonstrates the superiority of the proposed\nmodel and also elucidates the rationality of the hypergraph modeling and the\ndouble-scale self-supervision.",
    "descriptor": "\nComments: 11 pages, 6 figures, CIKM 2021\n",
    "authors": [
      "Junwei Zhang",
      "Min Gao",
      "Junliang Yu",
      "Lei Guo",
      "Jundong Li",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04200"
  },
  {
    "id": "arXiv:2109.04205",
    "title": "DAN: Decentralized Attention-based Neural Network to Solve the MinMax  Multiple Traveling Salesman Problem",
    "abstract": "The multiple traveling salesman problem (mTSP) is a well-known NP-hard\nproblem with numerous real-world applications. In particular, this work\naddresses MinMax mTSP, where the objective is to minimize the max tour length\n(sum of Euclidean distances) among all agents. The mTSP is normally considered\nas a combinatorial optimization problem, but due to its computational\ncomplexity, search-based exact and heuristic algorithms become inefficient as\nthe number of cities increases. Encouraged by the recent developments in deep\nreinforcement learning (dRL), this work considers the mTSP as a cooperative\ntask and introduces a decentralized attention-based neural network method to\nsolve the MinMax mTSP, named DAN. In DAN, agents learn fully decentralized\npolicies to collaboratively construct a tour, by predicting the future\ndecisions of other agents. Our model relies on the Transformer architecture,\nand is trained using multi-agent RL with parameter sharing, which provides\nnatural scalability to the numbers of agents and cities. We experimentally\ndemonstrate our model on small- to large-scale mTSP instances, which involve 50\nto 1000 cities and 5 to 20 agents, and compare against state-of-the-art\nbaselines. For small-scale problems (fewer than 100 cities), DAN is able to\nclosely match the performance of the best solver available (OR Tools, a\nmeta-heuristic solver) given the same computation time budget. In larger-scale\ninstances, DAN outperforms both conventional and dRL-based solvers, while\nkeeping computation times low, and exhibits enhanced collaboration among\nagents.",
    "descriptor": "\nComments: Submitted to IEEE Robotics and Automation Letters (RA-L) on September 9, 2021\n",
    "authors": [
      "Yuhong Cao",
      "Zhanhong Sun",
      "Guillaume Sartoretti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.04205"
  },
  {
    "id": "arXiv:2109.04206",
    "title": "QUINT: Node embedding using network hashing",
    "abstract": "Representation learning using network embedding has received tremendous\nattention due to its efficacy to solve downstream tasks. Popular embedding\nmethods (such as deepwalk, node2vec, LINE) are based on a neural architecture,\nthus unable to scale on large networks both in terms of time and space usage.\nRecently, we proposed BinSketch, a sketching technique for compressing binary\nvectors to binary vectors. In this paper, we show how to extend BinSketch and\nuse it for network hashing. Our proposal named QUINT is built upon BinSketch,\nand it embeds nodes of a sparse network onto a low-dimensional space using\nsimple bi-wise operations. QUINT is the first of its kind that provides\ntremendous gain in terms of speed and space usage without compromising much on\nthe accuracy of the downstream tasks. Extensive experiments are conducted to\ncompare QUINT with seven state-of-the-art network embedding methods for two end\ntasks - link prediction and node classification. We observe huge performance\ngain for QUINT in terms of speedup (up to 7000x) and space saving (up to 800x)\ndue to its bit-wise nature to obtain node embedding. Moreover, QUINT is a\nconsistent top-performer for both the tasks among the baselines across all the\ndatasets. Our empirical observations are backed by rigorous theoretical\nanalysis to justify the effectiveness of QUINT. In particular, we prove that\nQUINT retains enough structural information which can be used further to\napproximate many topological properties of networks with high confidence.",
    "descriptor": "\nComments: Accepted in IEEE TKDE\n",
    "authors": [
      "Debajyoti Bera",
      "Rameshwar Pratap",
      "Bhisham Dev Verma",
      "Biswadeep Sen",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04206"
  },
  {
    "id": "arXiv:2109.04207",
    "title": "Surrogate Parameters Optimization for Data and Model Fusion of COVID-19  Time-series Data",
    "abstract": "Our research focuses on developing a computational framework to simulate the\ntransmission dynamics of COVID-19 pandemic. We examine the development of a\nsystem named ADRIANA for the simulation using South Africa as a case study. The\ndesign of the ADRIANA system interconnects three sub-models to establish a\ncomputational technique to advise policy regarding lockdown measures to reduce\nthe transmission pattern of COVID-19 in South Africa. Additionally, the output\nof the ADRIANA can be used by healthcare administration to predict peak demand\ntime for resources needed to treat infected individuals. ABM is suited for our\nresearch experiment, but to prevent the computational constraints of using\nABM-based framework for this research, we develop an SEIR compartmental model,\na discrete event simulator, and an optimized surrogate model to form a system\nnamed ADRIANA. We also ensure that the surrogate's findings are accurate enough\nto provide optimal solutions. We use the Genetic Algorithm (GA) for the\noptimization by estimating the optimal hyperparameter configuration for the\nsurrogate. We concluded this study by discussing the solutions presented by the\nADRIANA system, which aligns with the primary goal of our study to present an\noptimal guide to lockdown policy by the government and resource management by\nthe hospital administrators.",
    "descriptor": "\nComments: 7pages, 7figures, 2tables, 1 equation, conference paper to for a computational solution to COVID-19 pandemic\n",
    "authors": [
      "Timilehin Ogundare",
      "Terence Van Zyl"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.04207"
  },
  {
    "id": "arXiv:2109.04210",
    "title": "Performance, Precision, and Payloads: Adaptive Nonlinear MPC for  Quadrotors",
    "abstract": "Agile quadrotor flight in challenging environments has the potential to\nrevolutionize shipping, transportation, and search and rescue applications.\nNonlinear model predictive control (NMPC) has recently shown promising results\nfor agile quadrotor control, but relies on highly accurate models for maximum\nperformance. Hence, model uncertainties in the form of unmodeled complex\naerodynamic effects, varying payloads and parameter mismatch will degrade\noverall system performance. In this paper, we propose L1-NMPC, a novel hybrid\nadaptive NMPC to learn model uncertainties online and immediately compensate\nfor them, drastically improving performance over the non-adaptive baseline with\nminimal computational overhead. Our proposed architecture generalizes to many\ndifferent environments from which we evaluate wind, unknown payloads, and\nhighly agile flight conditions. The proposed method demonstrates immense\nflexibility and robustness, with more than 90% tracking error reduction over\nnon-adaptive NMPC under large unknown disturbances and without any gain tuning.\nIn addition, the same controller with identical gains can accurately fly highly\nagile racing trajectories exhibiting top speeds of 70 km/h, offering tracking\nperformance improvements of around 50% relative to the non-adaptive NMPC\nbaseline. We will release our code fully open-sourced upon acceptance.",
    "descriptor": "\nComments: 8 Pages, 5 figures, submitted to RAL + ICRA 22\n",
    "authors": [
      "Drew Hanover",
      "Philipp Foehn",
      "Sihao Sun",
      "Elia Kaufmann",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04210"
  },
  {
    "id": "arXiv:2109.04212",
    "title": "Efficient Nearest Neighbor Language Models",
    "abstract": "Non-parametric neural language models (NLMs) learn predictive distributions\nof text utilizing an external datastore, which allows them to learn through\nexplicitly memorizing the training datapoints. While effective, these models\noften require retrieval from a large datastore at test time, significantly\nincreasing the inference overhead and thus limiting the deployment of\nnon-parametric NLMs in practical applications. In this paper, we take the\nrecently proposed $k$-nearest neighbors language model (Khandelwal et al.,\n2019) as an example, exploring methods to improve its efficiency along various\ndimensions. Experiments on the standard WikiText-103 benchmark and\ndomain-adaptation datasets show that our methods are able to achieve up to a 6x\nspeed-up in inference speed while retaining comparable performance. The\nempirical analysis we present may provide guidelines for future research\nseeking to develop or deploy more efficient non-parametric NLMs.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Junxian He",
      "Graham Neubig",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04212"
  },
  {
    "id": "arXiv:2109.04221",
    "title": "Multi-Constraint Shortest Path using Forest Hop Labeling",
    "abstract": "The \\textit{Multi-Constraint Shortest Path (MCSP)} problem aims to find the\nshortest path between two nodes in a network subject to a given constraint set.\nIt is typically processed as a \\textit{skyline path} problem. However, the\nnumber of intermediate skyline paths becomes larger as the network size\nincreases and the constraint number grows, which brings about the dramatical\ngrowth of computational cost and further makes the existing index-based methods\nhardly capable of obtaining the complete exact results. In this paper, we\npropose a novel high-dimensional skyline path concatenation method to avoid the\nexpensive skyline path search, which then supports the efficient construction\nof hop labeling index for \\textit{MCSP} queries. Specifically, a set of\ninsightful observations and techniques are proposed to improve the efficiency\nof concatenating two skyline path set, a \\textit{n-Cube} technique is designed\nto prune the concatenation space among multiple hops, and a \\textit{constraint\npruning} method is used to avoid the unnecessary computation. Furthermore, to\nscale up to larger networks, we propose a novel \\textit{forest hop labeling}\nwhich enables the parallel label construction from different network\npartitions. Our approach is the first method that can achieve both accuracy and\nefficiency for \\textit{MCSP} query answering. Extensive experiments on\nreal-life road networks demonstrate the superiority of our method over the\nstate-of-the-art solutions.",
    "descriptor": "",
    "authors": [
      "Ziyi Liu",
      "Lei Li",
      "Mengxuan Zhang",
      "Wen Hua",
      "Xiaofang Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.04221"
  },
  {
    "id": "arXiv:2109.04222",
    "title": "Learning Forceful Manipulation Skills from Multi-modal Human  Demonstrations",
    "abstract": "Learning from Demonstration (LfD) provides an intuitive and fast approach to\nprogram robotic manipulators. Task parameterized representations allow easy\nadaptation to new scenes and online observations. However, this approach has\nbeen limited to pose-only demonstrations and thus only skills with spatial and\ntemporal features. In this work, we extend the LfD framework to address\nforceful manipulation skills, which are of great importance for industrial\nprocesses such as assembly. For such skills, multi-modal demonstrations\nincluding robot end-effector poses, force and torque readings, and operation\nscene are essential. Our objective is to reproduce such skills reliably\naccording to the demonstrated pose and force profiles within different scenes.\nThe proposed method combines our previous work on task-parameterized\noptimization and attractor-based impedance control. The learned skill model\nconsists of (i) the attractor model that unifies the pose and force features,\nand (ii) the stiffness model that optimizes the stiffness for different stages\nof the skill. Furthermore, an online execution algorithm is proposed to adapt\nthe skill execution to real-time observations of robot poses, measured forces,\nand changed scenes. We validate this method rigorously on a 7-DoF robot arm\nover several steps of an E-bike motor assembly process, which require different\ntypes of forceful interaction such as insertion, sliding and twisting.",
    "descriptor": "",
    "authors": [
      "An T. Le",
      "Meng Guo",
      "Niels van Duijkeren",
      "Leonel Rozo",
      "Robert Krug",
      "Andras G. Kupcsik",
      "Mathias Buerger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04222"
  },
  {
    "id": "arXiv:2109.04223",
    "title": "KELM: Knowledge Enhanced Pre-Trained Language Representations with  Message Passing on Hierarchical Relational Graphs",
    "abstract": "Incorporating factual knowledge into pre-trained language models (PLM) such\nas BERT is an emerging trend in recent NLP studies. However, most of the\nexisting methods combine the external knowledge integration module with a\nmodified pre-training loss and re-implement the pre-training process on the\nlarge-scale corpus. Re-pretraining these models is usually resource-consuming,\nand difficult to adapt to another domain with a different knowledge graph (KG).\nBesides, those works either cannot embed knowledge context dynamically\naccording to textual context or struggle with the knowledge ambiguity issue. In\nthis paper, we propose a novel knowledge-aware language model framework based\non fine-tuning process, which equips PLM with a unified knowledge-enhanced text\ngraph that contains both text and multi-relational sub-graphs extracted from\nKG. We design a hierarchical relational-graph-based message passing mechanism,\nwhich can allow the representations of injected KG and text to mutually update\neach other and can dynamically select ambiguous mentioned entities that share\nthe same text. Our empirical results show that our model can efficiently\nincorporate world knowledge from KGs into existing language models such as\nBERT, and achieve significant improvement on the machine reading comprehension\n(MRC) task compared with other knowledge-enhanced models.",
    "descriptor": "",
    "authors": [
      "Yinquan Lu",
      "Haonan Lu",
      "Guirong Fu",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04223"
  },
  {
    "id": "arXiv:2109.04226",
    "title": "Incentivizing an Unknown Crowd",
    "abstract": "Motivated by the common strategic activities in crowdsourcing labeling, we\nstudy the problem of sequential eliciting information without verification\n(EIWV) for workers with a heterogeneous and unknown crowd. We propose a\nreinforcement learning-based approach that is effective against a wide range of\nsettings including potential irrationality and collusion among workers. With\nthe aid of a costly oracle and the inference method, our approach dynamically\ndecides the oracle calls and gains robustness even under the presence of\nfrequent collusion activities. Extensive experiments show the advantage of our\napproach. Our results also present the first comprehensive experiments of EIWV\non large-scale real datasets and the first thorough study of the effects of\nenvironmental variables.",
    "descriptor": "",
    "authors": [
      "Jing Dong",
      "Shuai Li",
      "Baoxiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04226"
  },
  {
    "id": "arXiv:2109.04230",
    "title": "A Systematic Approach to Group Fairness in Automated Decision Making",
    "abstract": "While the field of algorithmic fairness has brought forth many ways to\nmeasure and improve the fairness of machine learning models, these findings are\nstill not widely used in practice. We suspect that one reason for this is that\nthe field of algorithmic fairness came up with a lot of definitions of\nfairness, which are difficult to navigate. The goal of this paper is to provide\ndata scientists with an accessible introduction to group fairness metrics and\nto give some insight into the philosophical reasoning for caring about these\nmetrics. We will do this by considering in which sense socio-demographic groups\nare compared for making a statement on fairness.",
    "descriptor": "\nComments: Accepted full paper at SDS2021, the 8th Swiss Conference on Data Science\n",
    "authors": [
      "Corinna Hertweck",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04230"
  },
  {
    "id": "arXiv:2109.04234",
    "title": "On Discrete Truthful Heterogeneous Two-Facility Location",
    "abstract": "We revisit the discrete heterogeneous two-facility location problem, in which\nthere is a set of agents that occupy nodes of a line graph, and have private\napproval preferences over two facilities. When the facilities are located at\nsome nodes of the line, each agent derives a cost that is equal to her total\ndistance from the facilities she approves. The goal is to decide where to\nlocate the two facilities, so as to (a) incentivize the agents to truthfully\nreport their preferences, and (b) achieve a good approximation of the minimum\ntotal (social) cost or the maximum cost among all agents. For both objectives,\nwe design deterministic strategyproof mechanisms with approximation ratios that\nsignificantly outperform the state-of-the-art, and complement these results\nwith (almost) tight lower bounds.",
    "descriptor": "",
    "authors": [
      "Panagiotis Kanellopoulos",
      "Alexandros A. Voudouris",
      "Rongsen Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.04234"
  },
  {
    "id": "arXiv:2109.04236",
    "title": "ECQ$^{\\text{x}}$: Explainability-Driven Quantization for Low-Bit and  Sparse DNNs",
    "abstract": "The remarkable success of deep neural networks (DNNs) in various applications\nis accompanied by a significant increase in network parameters and arithmetic\noperations. Such increases in memory and computational demands make deep\nlearning prohibitive for resource-constrained hardware platforms such as mobile\ndevices. Recent efforts aim to reduce these overheads, while preserving model\nperformance as much as possible, and include parameter reduction techniques,\nparameter quantization, and lossless compression techniques.\nIn this chapter, we develop and describe a novel quantization paradigm for\nDNNs: Our method leverages concepts of explainable AI (XAI) and concepts of\ninformation theory: Instead of assigning weight values based on their distances\nto the quantization clusters, the assignment function additionally considers\nweight relevances obtained from Layer-wise Relevance Propagation (LRP) and the\ninformation content of the clusters (entropy optimization). The ultimate goal\nis to preserve the most relevant weights in quantization clusters of highest\ninformation content.\nExperimental results show that this novel Entropy-Constrained and\nXAI-adjusted Quantization (ECQ$^{\\text{x}}$) method generates ultra\nlow-precision (2-5 bit) and simultaneously sparse neural networks while\nmaintaining or even improving model performance. Due to reduced parameter\nprecision and high number of zero-elements, the rendered networks are highly\ncompressible in terms of file size, up to $103\\times$ compared to the\nfull-precision unquantized DNN model. Our approach was evaluated on different\ntypes of models and datasets (including Google Speech Commands and CIFAR-10)\nand compared with previous work.",
    "descriptor": "\nComments: 21 pages, 10 figures, 1 table\n",
    "authors": [
      "Daniel Becking",
      "Maximilian Dreyer",
      "Wojciech Samek",
      "Karsten M\u00fcller",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04236"
  },
  {
    "id": "arXiv:2109.04240",
    "title": "MetaXT: Meta Cross-Task Transfer between Disparate Label Spaces",
    "abstract": "Albeit the universal representational power of pre-trained language models,\nadapting them onto a specific NLP task still requires a considerably large\namount of labeled data. Effective task fine-tuning meets challenges when only a\nfew labeled examples are present for the task. In this paper, we aim to the\naddress of the problem of few shot task learning by exploiting and transferring\nfrom a different task which admits a related but disparate label space.\nSpecifically, we devise a label transfer network (LTN) to transform the labels\nfrom source task to the target task of interest for training. Both the LTN and\nthe model for task prediction are learned via a bi-level optimization\nframework, which we term as MetaXT. MetaXT offers a principled solution to best\nadapt a pre-trained language model to the target task by transferring knowledge\nfrom the source task. Empirical evaluations on cross-task transfer settings for\nfour NLP tasks, from two different types of label space disparities,\ndemonstrate the effectiveness of MetaXT, especially when the labeled data in\nthe target task is limited.",
    "descriptor": "",
    "authors": [
      "Srinagesh Sharma",
      "Guoqing Zheng",
      "Ahmed Hassan Awadallah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04240"
  },
  {
    "id": "arXiv:2109.04242",
    "title": "IICNet: A Generic Framework for Reversible Image Conversion",
    "abstract": "Reversible image conversion (RIC) aims to build a reversible transformation\nbetween specific visual content (e.g., short videos) and an embedding image,\nwhere the original content can be restored from the embedding when necessary.\nThis work develops Invertible Image Conversion Net (IICNet) as a generic\nsolution to various RIC tasks due to its strong capacity and task-independent\ndesign. Unlike previous encoder-decoder based methods, IICNet maintains a\nhighly invertible structure based on invertible neural networks (INNs) to\nbetter preserve the information during conversion. We use a relation module and\na channel squeeze layer to improve the INN nonlinearity to extract cross-image\nrelations and the network flexibility, respectively. Experimental results\ndemonstrate that IICNet outperforms the specifically-designed methods on\nexisting RIC tasks and can generalize well to various newly-explored tasks.\nWith our generic IICNet, we no longer need to hand-engineer task-specific\nembedding networks for rapidly occurring visual content. Our source codes are\navailable at: https://github.com/felixcheng97/IICNet.",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Ka Leong Cheng",
      "Yueqi Xie",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04242"
  },
  {
    "id": "arXiv:2109.04243",
    "title": "Understanding Cycling Mobility: Bologna Case Study",
    "abstract": "Understanding human mobility in urban environments is of the utmost\nimportance to manage traffic and for deploying new resources and services. In\nrecent years, the problem is exacerbated due to rapid urbanization and climate\nchanges. In an urban context, human mobility has many facets, and cycling\nrepresents one of the most eco-friendly and efficient/effective ways to move in\ntouristic and historical cities. The main objective of this work is to study\nthe cycling mobility within the city of Bologna, Italy. We used six months\ndataset that consists of 320,118 self-reported bike trips. In particular, we\nperformed several descriptive analysis to understand spatial and temporal\npatterns of bike users for understanding popular roads, and most favorite\npoints within the city. This analysis involved several other public datasets in\norder to explore variables that can possibly affect the cycling activity, such\nas weather, pollution, and events. The main results of this study indicate that\nbike usage is more correlated to temperature, and precipitation and has no\ncorrelation to wind speed and pollution. In addition, we also exploited various\nmachine learning and deep learning approaches for predicting short-term trips\nin the near future (that is for the following 30, and 60 minutes), that could\nhelp local governmental agencies for urban planning. Our best model achieved an\nR square of 0.91, a Mean Absolute Error of 5.38 and a Root Mean Squared Error\nof 8.12 for the 30-minutes time interval.",
    "descriptor": "",
    "authors": [
      "Taron Davtian",
      "Flavio Bertini",
      "Rajesh Sharma"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.04243"
  },
  {
    "id": "arXiv:2109.04247",
    "title": "DAE : Discriminatory Auto-Encoder for multivariate time-series anomaly  detection in air transportation",
    "abstract": "The Automatic Dependent Surveillance Broadcast protocol is one of the latest\ncompulsory advances in air surveillance. While it supports the tracking of the\never-growing number of aircraft in the air, it also introduces cybersecurity\nissues that must be mitigated e.g., false data injection attacks where an\nattacker emits fake surveillance information. The recent data sources and tools\navailable to obtain flight tracking records allow the researchers to create\ndatasets and develop Machine Learning models capable of detecting such\nanomalies in En-Route trajectories. In this context, we propose a novel\nmultivariate anomaly detection model called Discriminatory Auto-Encoder (DAE).\nIt uses the baseline of a regular LSTM-based auto-encoder but with several\ndecoders, each getting data of a specific flight phase (e.g. climbing, cruising\nor descending) during its training.To illustrate the DAE's efficiency, an\nevaluation dataset was created using real-life anomalies as well as\nrealistically crafted ones, with which the DAE as well as three anomaly\ndetection models from the literature were evaluated. Results show that the DAE\nachieves better results in both accuracy and speed of detection. The dataset,\nthe models implementations and the evaluation results are available in an\nonline repository, thereby enabling replicability and facilitating future\nexperiments.",
    "descriptor": "",
    "authors": [
      "Antoine Chevrot",
      "Alexandre Vernotte",
      "Bruno Legeard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04247"
  },
  {
    "id": "arXiv:2109.04253",
    "title": "Dubhe: Towards Data Unbiasedness with Homomorphic Encryption in  Federated Learning Client Selection",
    "abstract": "Federated learning (FL) is a distributed machine learning paradigm that\nallows clients to collaboratively train a model over their own local data. FL\npromises the privacy of clients and its security can be strengthened by\ncryptographic methods such as additively homomorphic encryption (HE). However,\nthe efficiency of FL could seriously suffer from the statistical heterogeneity\nin both the data distribution discrepancy among clients and the global\ndistribution skewness. We mathematically demonstrate the cause of performance\ndegradation in FL and examine the performance of FL over various datasets. To\ntackle the statistical heterogeneity problem, we propose a pluggable\nsystem-level client selection method named Dubhe, which allows clients to\nproactively participate in training, meanwhile preserving their privacy with\nthe assistance of HE. Experimental results show that Dubhe is comparable with\nthe optimal greedy method on the classification accuracy, with negligible\nencryption and communication overhead.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Shulai Zhang",
      "Zirui Li",
      "Quan Chen",
      "Wenli Zheng",
      "Jingwen Leng",
      "Minyi Guo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04253"
  },
  {
    "id": "arXiv:2109.04255",
    "title": "Optimal Reservoir Operations using Long Short-Term Memory Network",
    "abstract": "A reliable forecast of inflows to the reservoir is a key factor in the\noptimal operation of reservoirs. Real-time operation of the reservoir based on\nforecasts of inflows can lead to substantial economic gains. However, the\nforecast of inflow is an intricate task as it has to incorporate the impacts of\nclimate and hydrological changes. Therefore, the major objective of the present\nwork is to develop a novel approach based on long short-term memory (LSTM) for\nthe forecast of inflows. Real-time inflow forecast, in other words, daily\ninflow at the reservoir helps in efficient operation of water resources. Also,\ndaily variations in the release can be monitored efficiently and the\nreliability of operation is improved. This work proposes a naive anomaly\ndetection algorithm baseline based on LSTM. In other words, a strong baseline\nto forecast flood and drought for any deep learning-based prediction model. The\npracticality of the approach has been demonstrated using the observed daily\ndata of the past 20 years from Bhakra Dam in India. The results of the\nsimulations conducted herein clearly indicate the supremacy of the LSTM\napproach over the traditional methods of forecasting. Although, experiments are\nrun on data from Bhakra Dam Reservoir in India, LSTM model, and anomaly\ndetection algorithm are general purpose and can be applied to any basin with\nminimal changes. A distinct practical advantage of the LSTM method presented\nherein is that it can adequately simulate non-stationarity and non-linearity in\nthe historical data.",
    "descriptor": "",
    "authors": [
      "Asha Devi Singh",
      "Anurag Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04255"
  },
  {
    "id": "arXiv:2109.04256",
    "title": "Cataloging Dependency Injection Anti-patterns in Software Systems",
    "abstract": "Context: Dependency Injection (DI) is a commonly applied mechanism to\ndecouple classes from their dependencies in order to provide higher\nmodularization. However, bad DI practices often lead to negative consequences,\nsuch as increasing coupling. Although white literature conjectures about the\nexistence of DI anti-patterns, there is no evidence on their practical\nrelevance, usefulness, and generality. Objective: The objective of this study\nis to propose and evaluate a catalog of Java DI anti-patterns. Methodology: We\nreviewed the reported DI anti-patterns in order to analyze their completeness\nand propose a catalog containing 12 Java DI anti-patterns. We developed a tool\nto statically analyze the occurrence level of the candidate DI anti-patterns in\nopen-source and industry projects. Next, we survey practitioners to assess\ntheir perception on the relevance, usefulness, and their willingness on\nrefactoring anti-pattern instances of the catalog. Results: Our static code\nanalyzer tool showed a relative recall of 92.19% and high average precision. It\nrevealed that at least 9 different DI anti-patterns appeared frequently in the\nanalyzed projects. Besides, our survey confirmed the perceived relevance of the\ncatalog and developers expressed their willingness to refactor instances of\nanti-patterns from source code. Conclusion: The catalog contains Java DI\nanti-patterns that occur in practice and that are perceived as useful. Sharing\nit with practitioners may help them to avoid such anti-patterns, thus improving\nsource-code quality.",
    "descriptor": "",
    "authors": [
      "Rodrigo Laigner",
      "Diogo Mendon\u00e7a",
      "Alessandro Garcia",
      "Marcos Kalinowski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.04256"
  },
  {
    "id": "arXiv:2109.04257",
    "title": "GNisi: A graph network for reconstructing Ising models from multivariate  binarized data",
    "abstract": "Ising models are a simple generative approach to describing interacting\nbinary variables. They have proven useful in a number of biological settings\nbecause they enable one to represent observed many-body correlations as the\nseparable consequence of many direct, pairwise statistical interactions. The\ninference of Ising models from data can be computationally very challenging and\noften one must be satisfied with numerical approximations or limited precision.\nIn this paper we present a novel method for the determination of Ising\nparameters from data, called GNisi, which uses a Graph Neural network trained\non known Ising models in order to construct the parameters for unseen data. We\nshow that GNisi is more accurate than the existing state of the art software,\nand we illustrate our method by applying GNisi to gene expression data.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Emma Slade",
      "Sonya Kiselgof",
      "Lena Granovsky",
      "Jeremy L. England"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.04257"
  },
  {
    "id": "arXiv:2109.04258",
    "title": "A Derivative-based Parser Generator for Visibly Pushdown Grammars",
    "abstract": "In this paper, we present a derivative-based, functional recognizer and\nparser generator for visibly pushdown grammars. The generated parser accepts\nambiguous grammars and produces a parse forest containing all valid parse trees\nfor an input string in linear time. Each parse tree in the forest can then be\nextracted also in linear time. Besides the parser generator, to allow more\nflexible forms of the visibly pushdown grammars, we also present a translator\nthat converts a tagged CFG to a visibly pushdown grammar in a sound way, and\nthe parse trees of the tagged CFG are further produced by running the semantic\nactions embedded in the parse trees of the translated visibly pushdown grammar.\nThe performance of the parser is compared with a popular parsing tool ANTLR and\nother popular hand-crafted parsers. The correctness of the core parsing\nalgorithm is formally verified in the proof assistant Coq.",
    "descriptor": "",
    "authors": [
      "Xiaodong Jia",
      "Ashish Kuma",
      "Gang Tan"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2109.04258"
  },
  {
    "id": "arXiv:2109.04260",
    "title": "Online Enhanced Semantic Hashing: Towards Effective and Efficient  Retrieval for Streaming Multi-Modal Data",
    "abstract": "With the vigorous development of multimedia equipment and applications,\nefficient retrieval of large-scale multi-modal data has become a trendy\nresearch topic. Thereinto, hashing has become a prevalent choice due to its\nretrieval efficiency and low storage cost. Although multi-modal hashing has\ndrawn lots of attention in recent years, there still remain some problems. The\nfirst point is that existing methods are mainly designed in batch mode and not\nable to efficiently handle streaming multi-modal data. The second point is that\nall existing online multi-modal hashing methods fail to effectively handle\nunseen new classes which come continuously with streaming data chunks. In this\npaper, we propose a new model, termed Online enhAnced SemantIc haShing (OASIS).\nWe design novel semantic-enhanced representation for data, which could help\nhandle the new coming classes, and thereby construct the enhanced semantic\nobjective function. An efficient and effective discrete online optimization\nalgorithm is further proposed for OASIS. Extensive experiments show that our\nmethod can exceed the state-of-the-art models. For good reproducibility and\nbenefiting the community, our code and data are already available in\nsupplementary material and will be made publicly available.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Xiao-Ming Wu",
      "Xin Luo",
      "Yu-Wei Zhan",
      "Chen-Lu Ding",
      "Zhen-Duo Chen",
      "Xin-Shun Xu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04260"
  },
  {
    "id": "arXiv:2109.04264",
    "title": "Solving Simultaneous Target Assignment and Path Planning Efficiently  with Time-Independent Execution",
    "abstract": "Real-time planning for a combined problem of target assignment and path\nplanning for multiple agents, also known as the unlabeled version of\nMulti-Agent Path Finding (MAPF), is crucial for high-level coordination in\nmulti-agent systems, e.g., pattern formation by robot swarms. This paper\nstudies two aspects of unlabeled-MAPF: (1) offline scenario: solving large\ninstances by centralized approaches with small computation time, and (2) online\nscenario: executing unlabeled-MAPF despite timing uncertainties of real robots.\nFor this purpose, we propose TSWAP, a novel complete algorithm consisting of\ntarget assignment with lazy evaluation and path planning with target swapping.\nTSWAP can adapt to both offline and online scenarios. We empirically\ndemonstrate that Offline TSWAP is highly scalable; providing near-optimal\nsolutions while reducing runtime by orders of magnitude compared to existing\napproaches. In addition, we present the benefits of Online TSWAP, such as delay\ntolerance, through real-robot demos.",
    "descriptor": "\nComments: 19 pages, preprint\n",
    "authors": [
      "Keisuke Okumura",
      "Xavier D\u00e9fago"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.04264"
  },
  {
    "id": "arXiv:2109.04266",
    "title": "An objective function for order preserving hierarchical clustering",
    "abstract": "We present an objective function for similarity based hierarchical clustering\nof partially ordered data that preserves the partial order in the sense that if\n$x \\leq y$, and if $[x]$ and $[y]$ are the respective clusters of $x$ and $y$,\nthen there is an order relation $\\leq'$ on the clusters for which $[x] \\leq'\n|y]$. The model distinguishes itself from existing methods and models for\nclustering of ordered data in that the order relation and the similarity are\ncombined to obtain an optimal hierarchical clustering seeking to satisfy both,\nand that the order relation is equipped with a pairwise level of comparability\nin the range $[0,1]$. In particular, if the similarity and the order relation\nare not aligned, then order preservation may have to yield in favor of\nclustering. Finding an optimal solution is NP-hard, so we provide a polynomial\ntime approximation algorithm, with a relative performance guarantee of\n$O(\\log^{3/2}n)$, based on successive applications of directed sparsest cut.\nThe model is an extension of the Dasgupta cost function for divisive\nhierarchical clustering.",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Daniel Bakkelund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.04266"
  },
  {
    "id": "arXiv:2109.04269",
    "title": "Asynchronous Federated Learning on Heterogeneous Devices: A Survey",
    "abstract": "Federated learning (FL) is experiencing a fast booming with the wave of\ndistributed machine learning and ever-increasing privacy concerns. In the FL\nparadigm, global model aggregation is handled by a centralized aggregate server\nbased on local updated gradients trained on local nodes, which mitigates\nprivacy leakage caused by the collection of sensitive information. With the\nincreased computing and communicating capabilities of edge and IoT devices,\napplying FL on heterogeneous devices to train machine learning models becomes a\ntrend. The synchronous aggregation strategy in the classic FL paradigm cannot\neffectively use the resources, especially on heterogeneous devices, due to its\nwaiting for straggler devices before aggregation in each training round.\nFurthermore, in real-world scenarios, the disparity of data dispersed on\ndevices (i.e. data heterogeneity) downgrades the accuracy of models. As a\nresult, many asynchronous FL (AFL) paradigms are presented in various\napplication scenarios to improve efficiency, performance, privacy, and\nsecurity. This survey comprehensively analyzes and summarizes existing variants\nof AFL according to a novel classification mechanism, including device\nheterogeneity, data heterogeneity, privacy and security on heterogeneous\ndevices, and applications on heterogeneous devices. Finally, this survey\nreveals rising challenges and presents potentially promising research\ndirections in this under-investigated field.",
    "descriptor": "",
    "authors": [
      "Chenhao Xu",
      "Youyang Qu",
      "Yong Xiang",
      "Longxiang Gao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.04269"
  },
  {
    "id": "arXiv:2109.04270",
    "title": "Toward a Perspectivist Turn in Ground Truthing for Predictive Computing",
    "abstract": "Most Artificial Intelligence applications are based on supervised machine\nlearning (ML), which ultimately grounds on manually annotated data. The\nannotation process is often performed in terms of a majority vote and this has\nbeen proved to be often problematic, as highlighted by recent studies on the\nevaluation of ML models. In this article we describe and advocate for a\ndifferent paradigm, which we call data perspectivism, which moves away from\ntraditional gold standard datasets, towards the adoption of methods that\nintegrate the opinions and perspectives of the human subjects involved in the\nknowledge representation step of ML processes. Drawing on previous works which\ninspired our proposal we describe the potential of our proposal for not only\nthe more subjective tasks (e.g. those related to human language) but also to\ntasks commonly understood as objective (e.g. medical decision making), and\npresent the main advantages of adopting a perspectivist stance in ML, as well\nas possible disadvantages, and various ways in which such a stance can be\nimplemented in practice. Finally, we share a set of recommendations and outline\na research agenda to advance the perspectivist stance in ML.",
    "descriptor": "\nComments: 16 pages, Accepted at ItaIS2021 this http URL\n",
    "authors": [
      "Valerio Basile",
      "Federico Cabitza",
      "Andrea Campagner",
      "Michael Fell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04270"
  },
  {
    "id": "arXiv:2109.04275",
    "title": "M5Product: A Multi-modal Pretraining Benchmark for E-commercial Product  Downstream Tasks",
    "abstract": "In this paper, we aim to advance the research of multi-modal pre-training on\nE-commerce and subsequently contribute a large-scale dataset, named M5Product,\nwhich consists of over 6 million multimodal pairs, covering more than 6,000\ncategories and 5,000 attributes. Generally, existing multi-modal datasets are\neither limited in scale or modality diversity. Differently, our M5Product is\nfeatured from the following aspects. First, the M5Product dataset is 500 times\nlarger than the public multimodal dataset with the same number of modalities\nand nearly twice larger compared with the largest available text-image\ncross-modal dataset. Second, the dataset contains rich information of multiple\nmodalities including image, text, table, video and audio, in which each\nmodality can capture different views of semantic information (e.g. category,\nattributes, affordance, brand, preference) and complements the other. Third, to\nbetter accommodate with real-world problems, a few portion of M5Product\ncontains incomplete modality pairs and noises while having the long-tailed\ndistribution, which aligns well with real-world scenarios. Finally, we provide\na baseline model M5-MMT that makes the first attempt to integrate the different\nmodality configuration into an unified model for feature fusion to address the\ngreat challenge for semantic alignment. We also evaluate various multi-model\npre-training state-of-the-arts for benchmarking their capabilities in learning\nfrom unlabeled data under the different number of modalities on the M5Product\ndataset. We conduct extensive experiments on four downstream tasks and provide\nsome interesting findings on these modalities. Our dataset and related code are\navailable at https://xiaodongsuper.github.io/M5Product_dataset.",
    "descriptor": "",
    "authors": [
      "Xiao Dong",
      "Xunlin Zhan",
      "Yangxin Wu",
      "Yunchao Wei",
      "Xiaoyong Wei",
      "Minlong Lu",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.04275"
  },
  {
    "id": "arXiv:2109.04282",
    "title": "Cartography Active Learning",
    "abstract": "We propose Cartography Active Learning (CAL), a novel Active Learning (AL)\nalgorithm that exploits the behavior of the model on individual instances\nduring training as a proxy to find the most informative instances for labeling.\nCAL is inspired by data maps, which were recently proposed to derive insights\ninto dataset quality (Swayamdipta et al., 2020). We compare our method on\npopular text classification tasks to commonly used AL strategies, which instead\nrely on post-training behavior. We demonstrate that CAL is competitive to other\ncommon AL methods, showing that training dynamics derived from small seed data\ncan be successfully used for AL. We provide insights into our new AL method by\nanalyzing batch-level statistics utilizing the data maps. Our results further\nshow that CAL results in a more data-efficient learning strategy, achieving\ncomparable or better results with considerably less training data.",
    "descriptor": "\nComments: Findings EMNLP 2021\n",
    "authors": [
      "Mike Zhang",
      "Barbara Plank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04282"
  },
  {
    "id": "arXiv:2109.04284",
    "title": "Towards Robust Cross-domain Image Understanding with Unsupervised Noise  Removal",
    "abstract": "Deep learning models usually require a large amount of labeled data to\nachieve satisfactory performance. In multimedia analysis, domain adaptation\nstudies the problem of cross-domain knowledge transfer from a label rich source\ndomain to a label scarce target domain, thus potentially alleviates the\nannotation requirement for deep learning models. However, we find that\ncontemporary domain adaptation methods for cross-domain image understanding\nperform poorly when source domain is noisy. Weakly Supervised Domain Adaptation\n(WSDA) studies the domain adaptation problem under the scenario where source\ndata can be noisy. Prior methods on WSDA remove noisy source data and align the\nmarginal distribution across domains without considering the fine-grained\nsemantic structure in the embedding space, which have the problem of class\nmisalignment, e.g., features of cats in the target domain might be mapped near\nfeatures of dogs in the source domain. In this paper, we propose a novel\nmethod, termed Noise Tolerant Domain Adaptation, for WSDA. Specifically, we\nadopt the cluster assumption and learn cluster discriminatively with class\nprototypes in the embedding space. We propose to leverage the location\ninformation of the data points in the embedding space and model the location\ninformation with a Gaussian mixture model to identify noisy source data. We\nthen design a network which incorporates the Gaussian mixture noise model as a\nsub-module for unsupervised noise removal and propose a novel cluster-level\nadversarial adaptation method which aligns unlabeled target data with the less\nnoisy class prototypes for mapping the semantic structure across domains. We\nconduct extensive experiments to evaluate the effectiveness of our method on\nboth general images and medical images from COVID-19 and e-commerce datasets.\nThe results show that our method significantly outperforms state-of-the-art\nWSDA methods.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Lei Zhu",
      "Zhaojing Luo",
      "Wei Wang",
      "Meihui Zhang",
      "Gang Chen",
      "Kaiping Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.04284"
  },
  {
    "id": "arXiv:2109.04285",
    "title": "Energy-Efficient Mobile Robot Control via Run-time Monitoring of  Environmental Complexity and Computing Workload",
    "abstract": "We propose an energy-efficient controller to minimize the energy consumption\nof a mobile robot by dynamically manipulating the mechanical and computational\nactuators of the robot. The mobile robot performs real-time vision-based\napplications based on an event-based camera. The actuators of the controller\nare CPU voltage/frequency for the computation part and motor voltage for the\nmechanical part. We show that independently considering speed control of the\nrobot and voltage/frequency control of the CPU does not necessarily result in\nan energy-efficient solution. In fact, to obtain the highest efficiency, the\ncomputation and mechanical parts should be controlled together in synergy. We\npropose a fast hill-climbing optimization algorithm to allow the controller to\nfind the best CPU/motor configuration at run-time and whenever the mobile robot\nis facing a new environment during its travel. Experimental results on a robot\nwith Brushless DC Motors, Jetson TX2 board as the computing unit, and a\nDAVIS-346 event-based camera show that the proposed control algorithm can save\nbattery energy by an average of 50.5%, 41%, and 30%, in low-complexity,\nmedium-complexity, and high-complexity environments, over baselines.",
    "descriptor": "\nComments: Accepted to be published on 2021 International Conference on Intelligent Robots and Systems (IROS)\n",
    "authors": [
      "Sherif A.S. Mohamed",
      "Mohammad-Hashem Haghbayan",
      "Antonio Miele",
      "Onur Mutlu",
      "Juha Plosila"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04285"
  },
  {
    "id": "arXiv:2109.04286",
    "title": "NTS-NOTEARS: Learning Nonparametric Temporal DAGs With Time-Series Data  and Prior Knowledge",
    "abstract": "We propose a score-based DAG structure learning method for time-series data\nthat captures linear, nonlinear, lagged and instantaneous relations among\nvariables while ensuring acyclicity throughout the entire graph. The proposed\nmethod extends nonparametric NOTEARS, a recent continuous optimization approach\nfor learning nonparametric instantaneous DAGs. The proposed method is faster\nthan constraint-based methods using nonlinear conditional independence tests.\nWe also promote the use of optimization constraints to incorporate prior\nknowledge into the structure learning process. A broad set of experiments with\nsimulated data demonstrates that the proposed method discovers better DAG\nstructures than several recent comparison methods. We also evaluate the\nproposed method on complex real-world data acquired from NHL ice hockey games\ncontaining a mixture of continuous and discrete variables. The code is\navailable at https://github.com/xiangyu-sun-789/NTS-NOTEARS/.",
    "descriptor": "\nComments: Preprint, under review\n",
    "authors": [
      "Xiangyu Sun",
      "Guiliang Liu",
      "Pascal Poupart",
      "Oliver Schulte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04286"
  },
  {
    "id": "arXiv:2109.04290",
    "title": "Improving Video-Text Retrieval by Multi-Stream Corpus Alignment and Dual  Softmax Loss",
    "abstract": "Employing large-scale pre-trained model CLIP to conduct video-text retrieval\ntask (VTR) has become a new trend, which exceeds previous VTR methods. Though,\ndue to the heterogeneity of structures and contents between video and text,\nprevious CLIP-based models are prone to overfitting in the training phase,\nresulting in relatively poor retrieval performance. In this paper, we propose a\nmulti-stream Corpus Alignment network with single gate Mixture-of-Experts\n(CAMoE) and a novel Dual Softmax Loss (DSL) to solve the two heterogeneity. The\nCAMoE employs Mixture-of-Experts (MoE) to extract multi-perspective video\nrepresentations, including action, entity, scene, etc., then align them with\nthe corresponding part of the text. In this stage, we conduct massive\nexplorations towards the feature extraction module and feature alignment\nmodule. DSL is proposed to avoid the one-way optimum-match which occurs in\nprevious contrastive methods. Introducing the intrinsic prior of each pair in a\nbatch, DSL serves as a reviser to correct the similarity matrix and achieves\nthe dual optimal match. DSL is easy to implement with only one-line code but\nimproves significantly. The results show that the proposed CAMoE and DSL are of\nstrong efficiency, and each of them is capable of achieving State-of-The-Art\n(SOTA) individually on various benchmarks such as MSR-VTT, MSVD, and LSMDC.\nFurther, with both of them, the performance is advanced to a big extend,\nsurpassing the previous SOTA methods for around 4.6\\% R@1 in MSR-VTT.",
    "descriptor": "",
    "authors": [
      "Xing Cheng",
      "Hezheng Lin",
      "Xiangyu Wu",
      "Fan Yang",
      "Dong Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04290"
  },
  {
    "id": "arXiv:2109.04292",
    "title": "Generalised Unsupervised Domain Adaptation of Neural Machine Translation  with Cross-Lingual Data Selection",
    "abstract": "This paper considers the unsupervised domain adaptation problem for neural\nmachine translation (NMT), where we assume the access to only monolingual text\nin either the source or target language in the new domain. We propose a\ncross-lingual data selection method to extract in-domain sentences in the\nmissing language side from a large generic monolingual corpus. Our proposed\nmethod trains an adaptive layer on top of multilingual BERT by contrastive\nlearning to align the representation between the source and target language.\nThis then enables the transferability of the domain classifier between the\nlanguages in a zero-shot manner. Once the in-domain data is detected by the\nclassifier, the NMT model is then adapted to the new domain by jointly learning\ntranslation and domain discrimination tasks. We evaluate our cross-lingual data\nselection method on NMT across five diverse domains in three language pairs, as\nwell as a real-world scenario of translation for COVID-19. The results show\nthat our proposed method outperforms other selection baselines up to +1.5 BLEU\nscore.",
    "descriptor": "\nComments: EMNLP2021\n",
    "authors": [
      "Thuy-Trang Vu",
      "Xuanli He",
      "Dinh Phung",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04292"
  },
  {
    "id": "arXiv:2109.04300",
    "title": "Energy Attack: On Transferring Adversarial Examples",
    "abstract": "In this work we propose Energy Attack, a transfer-based black-box\n$L_\\infty$-adversarial attack. The attack is parameter-free and does not\nrequire gradient approximation. In particular, we first obtain white-box\nadversarial perturbations of a surrogate model and divide these perturbations\ninto small patches. Then we extract the unit component vectors and eigenvalues\nof these patches with principal component analysis (PCA). Base on the\neigenvalues, we can model the energy distribution of adversarial perturbations.\nWe then perform black-box attacks by sampling from the perturbation patches\naccording to their energy distribution, and tiling the sampled patches to form\na full-size adversarial perturbation. This can be done without the available\naccess to victim models. Extensive experiments well demonstrate that the\nproposed Energy Attack achieves state-of-the-art performance in black-box\nattacks on various models and several datasets. Moreover, the extracted\ndistribution is able to transfer among different model architectures and\ndifferent datasets, and is therefore intrinsic to vision architectures.",
    "descriptor": "\nComments: Under Review for AAAI-22\n",
    "authors": [
      "Ruoxi Shi",
      "Borui Yang",
      "Yangzhou Jiang",
      "Chenglong Zhao",
      "Bingbing Ni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04300"
  },
  {
    "id": "arXiv:2109.04301",
    "title": "On the use of Wasserstein metric in topological clustering of  distributional data",
    "abstract": "This paper deals with a clustering algorithm for histogram data based on a\nSelf-Organizing Map (SOM) learning. It combines a dimension reduction by SOM\nand the clustering of the data in a reduced space. Related to the kind of data,\na suitable dissimilarity measure between distributions is introduced: the $L_2$\nWasserstein distance. Moreover, the number of clusters is not fixed in advance\nbut it is automatically found according to a local data density estimation in\nthe original space. Applications on synthetic and real data sets corroborate\nthe proposed strategy.",
    "descriptor": "",
    "authors": [
      "Gu\u00e9na\u00ebl Cabanes",
      "Youn\u00e8s Bennani",
      "Rosanna Verde",
      "Antonio Irpino"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04301"
  },
  {
    "id": "arXiv:2109.04304",
    "title": "DAE-PINN: A Physics-Informed Neural Network Model for Simulating  Differential-Algebraic Equations with Application to Power Networks",
    "abstract": "Deep learning-based surrogate modeling is becoming a promising approach for\nlearning and simulating dynamical systems. Deep-learning methods, however, find\nvery challenging learning stiff dynamics. In this paper, we develop DAE-PINN,\nthe first effective deep-learning framework for learning and simulating the\nsolution trajectories of nonlinear differential-algebraic equations (DAE),\nwhich present a form of infinite stiffness and describe, for example, the\ndynamics of power networks. Our DAE-PINN bases its effectiveness on the synergy\nbetween implicit Runge-Kutta time-stepping schemes (designed specifically for\nsolving DAEs) and physics-informed neural networks (PINN) (deep neural networks\nthat we train to satisfy the dynamics of the underlying problem). Furthermore,\nour framework (i) enforces the neural network to satisfy the DAEs as\n(approximate) hard constraints using a penalty-based method and (ii) enables\nsimulating DAEs for long-time horizons. We showcase the effectiveness and\naccuracy of DAE-PINN by learning and simulating the solution trajectories of a\nthree-bus power network.",
    "descriptor": "",
    "authors": [
      "Christian Moya",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04304"
  },
  {
    "id": "arXiv:2109.04306",
    "title": "Social Media Monitoring for IoT Cyber-Threats",
    "abstract": "The rapid development of IoT applications and their use in various fields of\neveryday life has resulted in an escalated number of different possible\ncyber-threats, and has consequently raised the need of securing IoT devices.\nCollecting Cyber-Threat Intelligence (e.g., zero-day vulnerabilities or\ntrending exploits) from various online sources and utilizing it to proactively\nsecure IoT systems or prepare mitigation scenarios has proven to be a promising\ndirection. In this work, we focus on social media monitoring and investigate\nreal-time Cyber-Threat Intelligence detection from the Twitter stream.\nInitially, we compare and extensively evaluate six different machine-learning\nbased classification alternatives trained with vulnerability descriptions and\ntested with real-world data from the Twitter stream to identify the\nbest-fitting solution. Subsequently, based on our findings, we propose a novel\nsocial media monitoring system tailored to the IoT domain; the system allows\nusers to identify recent/trending vulnerabilities and exploits on IoT devices.\nFinally, to aid research on the field and support the reproducibility of our\nresults we publicly release all annotated datasets created during this process.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Sofia Alevizopoulou",
      "Paris Koloveas",
      "Christos Tryfonopoulos",
      "Paraskevi Raftopoulou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04306"
  },
  {
    "id": "arXiv:2109.04307",
    "title": "OPIRL: Sample Efficient Off-Policy Inverse Reinforcement Learning via  Distribution Matching",
    "abstract": "Inverse Reinforcement Learning (IRL) is attractive in scenarios where reward\nengineering can be tedious. However, prior IRL algorithms use on-policy\ntransitions, which require intensive sampling from the current policy for\nstable and optimal performance. This limits IRL applications in the real world,\nwhere environment interactions can become highly expensive. To tackle this\nproblem, we present Off-Policy Inverse Reinforcement Learning (OPIRL), which\n(1) adopts off-policy data distribution instead of on-policy and enables\nsignificant reduction of the number of interactions with the environment, (2)\nlearns a stationary reward function that is transferable with high\ngeneralization capabilities on changing dynamics, and (3) leverages\nmode-covering behavior for faster convergence. We demonstrate that our method\nis considerably more sample efficient and generalizes to novel environments\nthrough the experiments. Our method achieves better or comparable results on\npolicy performance baselines with significantly fewer interactions.\nFurthermore, we empirically show that the recovered reward function generalizes\nto different tasks where prior arts are prone to fail.",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Hana Hoshino",
      "Kei Ota",
      "Asako Kanezaki",
      "Rio Yokota"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04307"
  },
  {
    "id": "arXiv:2109.04310",
    "title": "Deep Hough Voting for Robust Global Registration",
    "abstract": "Point cloud registration is the task of estimating the rigid transformation\nthat aligns a pair of point cloud fragments. We present an efficient and robust\nframework for pairwise registration of real-world 3D scans, leveraging Hough\nvoting in the 6D transformation parameter space. First, deep geometric features\nare extracted from a point cloud pair to compute putative correspondences. We\nthen construct a set of triplets of correspondences to cast votes on the 6D\nHough space, representing the transformation parameters in sparse tensors.\nNext, a fully convolutional refinement module is applied to refine the noisy\nvotes. Finally, we identify the consensus among the correspondences from the\nHough space, which we use to predict our final transformation parameters. Our\nmethod outperforms state-of-the-art methods on 3DMatch and 3DLoMatch benchmarks\nwhile achieving comparable performance on KITTI odometry dataset. We further\ndemonstrate the generalizability of our approach by setting a new\nstate-of-the-art on ICL-NUIM dataset, where we integrate our module into a\nmulti-way registration pipeline.",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Junha Lee",
      "Seungwook Kim",
      "Minsu Cho",
      "Jaesik Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04310"
  },
  {
    "id": "arXiv:2109.04312",
    "title": "MATE: Multi-view Attention for Table Transformer Efficiency",
    "abstract": "This work presents a sparse-attention Transformer architecture for modeling\ndocuments that contain large tables. Tables are ubiquitous on the web, and are\nrich in information. However, more than 20% of relational tables on the web\nhave 20 or more rows (Cafarella et al., 2008), and these large tables present a\nchallenge for current Transformer models, which are typically limited to 512\ntokens. Here we propose MATE, a novel Transformer architecture designed to\nmodel the structure of web tables. MATE uses sparse attention in a way that\nallows heads to efficiently attend to either rows or columns in a table. This\narchitecture scales linearly with respect to speed and memory, and can handle\ndocuments containing more than 8000 tokens with current accelerators. MATE also\nhas a more appropriate inductive bias for tabular data, and sets a new\nstate-of-the-art for three table reasoning datasets. For HybridQA (Chen et al.,\n2020b), a dataset that involves large documents containing tables, we improve\nthe best prior result by 19 points.",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Julian Martin Eisenschlos",
      "Maharshi Gor",
      "Thomas M\u00fcller",
      "William W. Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04312"
  },
  {
    "id": "arXiv:2109.04313",
    "title": "Continuous Event-Line Constraint for Closed-Form Velocity Initialization",
    "abstract": "Event cameras trigger events asynchronously and independently upon a\nsufficient change of the logarithmic brightness level. The neuromorphic sensor\nhas several advantages over standard cameras including low latency, absence of\nmotion blur, and high dynamic range. Event cameras are particularly well suited\nto sense motion dynamics in agile scenarios. We propose the continuous\nevent-line constraint, which relies on a constant-velocity motion assumption as\nwell as trifocal tensor geometry in order to express a relationship between\nline observations given by event clusters as well as first-order camera\ndynamics. Our core result is a closed-form solver for up-to-scale linear camera\nvelocity {with known angular velocity}. Nonlinear optimization is adopted to\nimprove the performance of the algorithm. The feasibility of the approach is\ndemonstrated through a careful analysis on both simulated and real data.",
    "descriptor": "",
    "authors": [
      "Peng Xin",
      "Xu Wangting",
      "Yang Jiaqi",
      "Kneip Laurent"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04313"
  },
  {
    "id": "arXiv:2109.04314",
    "title": "Variational Latent-State GPT for Semi-supervised Task-Oriented Dialog  Systems",
    "abstract": "Recently, two approaches, fine-tuning large pre-trained language models and\nvariational training, have attracted significant interests, separately, for\nsemi-supervised end-to-end task-oriented dialog (TOD) systems. In this paper,\nwe propose Variational Latent-State GPT model (VLS-GPT), which is the first to\ncombine the strengths of the two approaches. Among many options of models, we\npropose the generative model and the inference model for variational learning\nof the end-to-end TOD system, both as auto-regressive language models based on\nGPT-2, which can be further trained over a mix of labeled and unlabeled dialog\ndata in a semi-supervised manner. We develop the strategy of\nsampling-then-forward-computation, which successfully overcomes the memory\nexplosion issue of using GPT in variational learning and speeds up training.\nSemi-supervised TOD experiments are conducted on two benchmark multi-domain\ndatasets of different languages - MultiWOZ2.1 and CrossWOZ. VLS-GPT is shown to\nsignificantly outperform both supervised-only and semi-supervised baselines.",
    "descriptor": "",
    "authors": [
      "Hong Liu",
      "Yucheng Cai",
      "Zhenru Lin",
      "Zhijian Ou",
      "Yi Huang",
      "Junlan Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04314"
  },
  {
    "id": "arXiv:2109.04316",
    "title": "Accounting for Variations in Speech Emotion Recognition with  Nonparametric Hierarchical Neural Network",
    "abstract": "In recent years, deep-learning-based speech emotion recognition models have\noutperformed classical machine learning models. Previously, neural network\ndesigns, such as Multitask Learning, have accounted for variations in emotional\nexpressions due to demographic and contextual factors. However, existing models\nface a few constraints: 1) they rely on a clear definition of domains (e.g.\ngender, noise condition, etc.) and the availability of domain labels; 2) they\noften attempt to learn domain-invariant features while emotion expressions can\nbe domain-specific. In the present study, we propose the Nonparametric\nHierarchical Neural Network (NHNN), a lightweight hierarchical neural network\nmodel based on Bayesian nonparametric clustering. In comparison to Multitask\nLearning approaches, the proposed model does not require domain/task labels. In\nour experiments, the NHNN models generally outperform the models with similar\nlevels of complexity and state-of-the-art models in within-corpus and\ncross-corpus tests. Through clustering analysis, we show that the NHNN models\nare able to learn group-specific features and bridge the performance gap\nbetween groups.",
    "descriptor": "\nComments: 9 pages, manuscript under peer review\n",
    "authors": [
      "Lance Ying",
      "Amrit Romana",
      "Emily Mower Provost"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04316"
  },
  {
    "id": "arXiv:2109.04318",
    "title": "Estimation of Corporate Greenhouse Gas Emissions via Machine Learning",
    "abstract": "As an important step to fulfill the Paris Agreement and achieve net-zero\nemissions by 2050, the European Commission adopted the most ambitious package\nof climate impact measures in April 2021 to improve the flow of capital towards\nsustainable activities. For these and other international measures to be\nsuccessful, reliable data is key. The ability to see the carbon footprint of\ncompanies around the world will be critical for investors to comply with the\nmeasures. However, with only a small portion of companies volunteering to\ndisclose their greenhouse gas (GHG) emissions, it is nearly impossible for\ninvestors to align their investment strategies with the measures. By training a\nmachine learning model on disclosed GHG emissions, we are able to estimate the\nemissions of other companies globally who do not disclose their emissions. In\nthis paper, we show that our model provides accurate estimates of corporate GHG\nemissions to investors such that they are able to align their investments with\nthe regulatory measures and achieve net-zero goals.",
    "descriptor": "\nComments: Accepted for the Tackling Climate Change with Machine Learning Workshop at ICML 2021\n",
    "authors": [
      "You Han",
      "Achintya Gopal",
      "Liwen Ouyang",
      "Aaron Key"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04318"
  },
  {
    "id": "arXiv:2109.04319",
    "title": "Translate & Fill: Improving Zero-Shot Multilingual Semantic Parsing with  Synthetic Data",
    "abstract": "While multilingual pretrained language models (LMs) fine-tuned on a single\nlanguage have shown substantial cross-lingual task transfer capabilities, there\nis still a wide performance gap in semantic parsing tasks when target language\nsupervision is available. In this paper, we propose a novel Translate-and-Fill\n(TaF) method to produce silver training data for a multilingual semantic\nparser. This method simplifies the popular Translate-Align-Project (TAP)\npipeline and consists of a sequence-to-sequence filler model that constructs a\nfull parse conditioned on an utterance and a view of the same parse. Our filler\nis trained on English data only but can accurately complete instances in other\nlanguages (i.e., translations of the English training utterances), in a\nzero-shot fashion. Experimental results on three multilingual semantic parsing\ndatasets show that data augmentation with TaF reaches accuracies competitive\nwith similar systems which rely on traditional alignment techniques.",
    "descriptor": "\nComments: Accepted to EMNLP 2021 (Findings)\n",
    "authors": [
      "Massimo Nicosia",
      "Zhongdi Qu",
      "Yasemin Altun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04319"
  },
  {
    "id": "arXiv:2109.04320",
    "title": "COLUMBUS: Automated Discovery of New Multi-Level Features for Domain  Generalization via Knowledge Corruption",
    "abstract": "Machine learning models that can generalize to unseen domains are essential\nwhen applied in real-world scenarios involving strong domain shifts. We address\nthe challenging domain generalization (DG) problem, where a model trained on a\nset of source domains is expected to generalize well in unseen domains without\nany exposure to their data. The main challenge of DG is that the features\nlearned from the source domains are not necessarily present in the unseen\ntarget domains, leading to performance deterioration. We assume that learning a\nricher set of features is crucial to improve the transfer to a wider set of\nunknown domains. For this reason, we propose COLUMBUS, a method that enforces\nnew feature discovery via a targeted corruption of the most relevant input and\nmulti-level representations of the data. We conduct an extensive empirical\nevaluation to demonstrate the effectiveness of the proposed approach which\nachieves new state-of-the-art results by outperforming 18 DG algorithms on\nmultiple DG benchmark datasets in the DomainBed framework.",
    "descriptor": "",
    "authors": [
      "Ahmed Frikha",
      "Denis Krompa\u00df",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04320"
  },
  {
    "id": "arXiv:2109.04321",
    "title": "Smoothed Contrastive Learning for Unsupervised Sentence Embedding",
    "abstract": "Contrastive learning has been gradually applied to learn high-quality\nunsupervised sentence embedding. Among the previous un-supervised methods, the\nlatest state-of-the-art method, as far as we know, is unsupervised SimCSE\n(unsup-SimCSE). Unsup-SimCSE uses the InfoNCE1loss function in the training\nstage by pulling semantically similar sentences together and pushing apart\ndis-similar ones.Theoretically, we expect to use larger batches in unsup-SimCSE\nto get more adequate comparisons among samples and avoid overfitting. However,\nincreasing the batch size does not always lead to improvements, but instead\neven lead to performance degradation when the batch size exceeds a threshold.\nThrough statistical observation, we find that this is probably due to the\nintroduction of low-confidence negative pairs after in-creasing the batch size.\nTo alleviate this problem, we introduce a simple smoothing strategy upon the\nInfoNCE loss function, termedGaussian Smoothing InfoNCE\n(GS-InfoNCE).Specifically, we add random Gaussian noise vectors as negative\nsamples, which act asa smoothing of the negative sample space.Though being\nsimple, the proposed smooth-ing strategy brings substantial improvements to\nunsup-SimCSE. We evaluate GS-InfoNCEon the standard semantic text similarity\n(STS)task. GS-InfoNCE outperforms the state-of-the-art unsup-SimCSE by an\naverage Spear-man correlation of 1.38%, 0.72%, 1.17% and0.28% on the base of\nBERT-base, BERT-large,RoBERTa-base and RoBERTa-large, respectively.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Xing Wu",
      "Chaochen Gao",
      "Liangjun Zang",
      "Jizhong Han",
      "Zhongyuan Wang",
      "Songlin Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04321"
  },
  {
    "id": "arXiv:2109.04322",
    "title": "Learning Vision-Guided Dynamic Locomotion Over Challenging Terrains",
    "abstract": "Legged robots are becoming increasingly powerful and popular in recent years\nfor their potential to bring the mobility of autonomous agents to the next\nlevel. This work presents a deep reinforcement learning approach that learns a\nrobust Lidar-based perceptual locomotion policy in a partially observable\nenvironment using Proximal Policy Optimisation. Visual perception is critical\nto actively overcome challenging terrains, and to do so, we propose a novel\nlearning strategy: Dynamic Reward Strategy (DRS), which serves as effective\nheuristics to learn a versatile gait using a neural network architecture\nwithout the need to access the history data. Moreover, in a modified version of\nthe OpenAI gym environment, the proposed work is evaluated with scores over 90%\nsuccess rate in all tested challenging terrains.",
    "descriptor": "\nComments: 9 pages, 27 figures, 1 table\n",
    "authors": [
      "Zhaocheng Liu",
      "Fernando Acero",
      "Zhibin Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04322"
  },
  {
    "id": "arXiv:2109.04325",
    "title": "Learning Opinion Summarizers by Selecting Informative Reviews",
    "abstract": "Opinion summarization has been traditionally approached with unsupervised,\nweakly-supervised and few-shot learning techniques. In this work, we collect a\nlarge dataset of summaries paired with user reviews for over 31,000 products,\nenabling supervised training. However, the number of reviews per product is\nlarge (320 on average), making summarization - and especially training a\nsummarizer - impractical. Moreover, the content of many reviews is not\nreflected in the human-written summaries, and, thus, the summarizer trained on\nrandom review subsets hallucinates. In order to deal with both of these\nchallenges, we formulate the task as jointly learning to select informative\nsubsets of reviews and summarizing the opinions expressed in these subsets. The\nchoice of the review subset is treated as a latent variable, predicted by a\nsmall and simple selector. The subset is then fed into a more powerful\nsummarizer. For joint training, we use amortized variational inference and\npolicy gradient methods. Our experiments demonstrate the importance of\nselecting informative reviews resulting in improved quality of summaries and\nreduced hallucinations.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Arthur Bra\u017einskas",
      "Mirella Lapata",
      "Ivan Titov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04325"
  },
  {
    "id": "arXiv:2109.04330",
    "title": "On iterated interpolation",
    "abstract": "Matrices resulting from the discretization of a kernel function, e.g., in the\ncontext of integral equations or sampling probability distributions, can\nfrequently be approximated by interpolation. In order to improve the\nefficiency, a multi-level approach can be employed that involves interpolating\nthe kernel functions and its approximations multiple times.\nThis article presents a new approach to analyze the error incurred by these\niterated interpolation procedures that is considerably more elegant than its\npredecessors and allows us to treat not only the kernel function itself, but\nalso its derivatives.",
    "descriptor": "",
    "authors": [
      "Steffen B\u00f6rm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04330"
  },
  {
    "id": "arXiv:2109.04332",
    "title": "PPT: Pre-trained Prompt Tuning for Few-shot Learning",
    "abstract": "Prompts for pre-trained language models (PLMs) have shown remarkable\nperformance by bridging the gap between pre-training tasks and various\ndownstream tasks. Among these methods, prompt tuning, which freezes PLMs and\nonly tunes soft prompts, provides an efficient and effective solution for\nadapting large-scale PLMs to downstream tasks. However, prompt tuning is yet to\nbe fully explored. In our pilot experiments, we find that prompt tuning\nperforms comparably with conventional full-model fine-tuning when downstream\ndata are sufficient, whereas it performs much worse under few-shot learning\nsettings, which may hinder the application of prompt tuning in practice. We\nattribute this low performance to the manner of initializing soft prompts.\nTherefore, in this work, we propose to pre-train prompts by adding soft prompts\ninto the pre-training stage to obtain a better initialization. We name this\nPre-trained Prompt Tuning framework \"PPT\". To ensure the generalization of PPT,\nwe formulate similar classification tasks into a unified task form and\npre-train soft prompts for this unified task. Extensive experiments show that\ntuning pre-trained prompts for downstream tasks can reach or even outperform\nfull-model fine-tuning under both full-data and few-shot settings. Our approach\nis effective and efficient for using large-scale PLMs in practice.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Yuxian Gu",
      "Xu Han",
      "Zhiyuan Liu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04332"
  },
  {
    "id": "arXiv:2109.04335",
    "title": "UCTransNet: Rethinking the Skip Connections in U-Net from a Channel-wise  Perspective with Transformer",
    "abstract": "Most recent semantic segmentation methods adopt a U-Net framework with an\nencoder-decoder architecture. It is still challenging for U-Net with a simple\nskip connection scheme to model the global multi-scale context: 1) Not each\nskip connection setting is effective due to the issue of incompatible feature\nsets of encoder and decoder stage, even some skip connection negatively\ninfluence the segmentation performance; 2) The original U-Net is worse than the\none without any skip connection on some datasets. Based on our findings, we\npropose a new segmentation framework, named UCTransNet (with a proposed CTrans\nmodule in U-Net), from the channel perspective with attention mechanism.\nSpecifically, the CTrans module is an alternate of the U-Net skip connections,\nwhich consists of a sub-module to conduct the multi-scale Channel Cross fusion\nwith Transformer (named CCT) and a sub-module Channel-wise Cross-Attention\n(named CCA) to guide the fused multi-scale channel-wise information to\neffectively connect to the decoder features for eliminating the ambiguity.\nHence, the proposed connection consisting of the CCT and CCA is able to replace\nthe original skip connection to solve the semantic gaps for an accurate\nautomatic medical image segmentation. The experimental results suggest that our\nUCTransNet produces more precise segmentation performance and achieves\nconsistent improvements over the state-of-the-art for semantic segmentation\nacross different datasets and conventional architectures involving transformer\nor U-shaped framework. Code: https://github.com/McGregorWwww/UCTransNet.",
    "descriptor": "",
    "authors": [
      "Haonan Wang",
      "Peng Cao",
      "Jiaqi Wang",
      "Osmar R.Zaiane"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.04335"
  },
  {
    "id": "arXiv:2109.04337",
    "title": "PATRIOT: Anti-Repackaging for IoT Firmware",
    "abstract": "IoT repackaging refers to an attack devoted to tampering with a legitimate\nfirmware package by modifying its content (e.g., injecting some malicious code)\nand re-distributing it in the wild. In such a scenario, the firmware delivery\nand update processes play a central role in ensuring firmware integrity.\nUnfortunately, most of the existing solutions lack proper integrity\nverification, leaving firmware exposed to repackaging attacks, such as the one\nreported in [1]. If this is not the case, they still require an external trust\nanchor (e.g., a signing certificate), which could limit their adoption in\nresource-constrained environments. To mitigate such a problem, in this paper,\nwe introduce PATRIOT, a novel self-protecting scheme for IoT that allows the\ninjection of integrity checks, called anti-tampering (AT) controls, directly\ninto the firmware. The AT controls enable the runtime detection of repackaging\nattempts without the need for external trust anchors or computationally\nexpensive systems. Also, we have implemented this scheme into PATRIOTIC, a\nprototype to automatically protect C/C++ IoT firmware. The evaluation phase of\n33 real-world firmware samples demonstrated the feasibility of the proposed\nmethodology and its robustness against practical repackaging attacks without\naltering the firmware behavior or severe performance issues.",
    "descriptor": "",
    "authors": [
      "Luca Verderame",
      "Antonio Ruggia",
      "Alessio Merlo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.04337"
  },
  {
    "id": "arXiv:2109.04340",
    "title": "Online Search for a Hyperplane in High-Dimensional Euclidean Space",
    "abstract": "We consider the online search problem in which a server starting at the\norigin of a $d$-dimensional Euclidean space has to find an arbitrary\nhyperplane. The best-possible competitive ratio and the length of the shortest\ncurve from which each point on the $d$-dimensional unit sphere can be seen are\nwithin a constant factor of each other. We show that this length is in\n$\\Omega(d)\\cap O(d^{3/2})$.",
    "descriptor": "\nComments: Pages: 7, Figures: 2\n",
    "authors": [
      "Antonios Antoniadis",
      "Ruben Hoeksma",
      "S\u00e1ndor Kisfaludi-Bak",
      "Kevin Schewior"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.04340"
  },
  {
    "id": "arXiv:2109.04343",
    "title": "Eliciting Information with Partial Signals in Repeated Games",
    "abstract": "We consider an information elicitation game where the center needs the agent\nto self-report her actual usage of a service and charges her a payment\naccordingly. The center can only observe a partial signal, representing part of\nthe agent's true consumption, that is generated randomly from a publicly known\ndistribution. The agent can report any information, as long as it does not\ncontradict the signal, and the center issues a payment based on the reported\ninformation. Such problems find application in prosumer pricing, tax filing,\netc., when the agent's actual consumption of a service is masked from the\ncenter and verification of the submitted reports is impractical. The key\ndifference between the current problem and classic information elicitation\nproblems is that the agent gets to observe the full signal and act\nstrategically, but the center can only see the partial signal. For this\nseemingly impossible problem, we propose a penalty mechanism that elicits\ntruthful self-reports in a repeated game. In particular, besides charging the\nagent the reported value, the mechanism charges a penalty proportional to her\ninconsistent reports. We show how a combination of the penalty rate and the\nlength of the game incentivizes the agent to be truthful for the entire game, a\nphenomenon we call \"fear of tomorrow verification\". We show how approximate\nresults for arbitrary distributions can be obtained by analyzing Bernoulli\ndistributions. We extend our mechanism to a multi-agent cost sharing setting\nand give equilibrium results.",
    "descriptor": "\nComments: 24 pages, 4 figures\n",
    "authors": [
      "Yutong Wu",
      "Ali Khodabakhsh",
      "Bo Li",
      "Evdokia Nikolova",
      "Emmanouil Pountourakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04343"
  },
  {
    "id": "arXiv:2109.04344",
    "title": "EvilModel 2.0: Hiding Malware Inside of Neural Network Models",
    "abstract": "While artificial intelligence (AI) is widely applied in various areas, it is\nalso being used maliciously. It is necessary to study and predict AI-powered\nattacks to prevent them in advance. Turning neural network models into\nstegomalware is a malicious use of AI, which utilizes the features of neural\nnetwork models to hide malware while maintaining the performance of the models.\nHowever, the existing methods have a low malware embedding rate and a high\nimpact on the model performance, making it not practical. Therefore, by\nanalyzing the composition of the neural network models, this paper proposes new\nmethods to embed malware in models with high capacity and no service quality\ndegradation. We used 19 malware samples and 10 mainstream models to build 550\nmalware-embedded models and analyzed the models' performance on ImageNet\ndataset. A new evaluation method that combines the embedding rate, the model\nperformance impact and the embedding effort is proposed to evaluate the\nexisting methods. This paper also designs a trigger and proposes an application\nscenario in attack tasks combining EvilModel with WannaCry. This paper further\nstudies the relationship between neural network models' embedding capacity and\nthe model structure, layer and size. With the widespread application of\nartificial intelligence, utilizing neural networks for attacks is becoming a\nforwarding trend. We hope this work can provide a reference scenario for the\ndefense of neural network-assisted attacks.",
    "descriptor": "\nComments: This paper is an extended version of work that was first presented in September, 2021 at the 26th IEEE Symposium on Computers and Communications (ISCC 2021). arXiv admin note: text overlap with arXiv:2107.08590\n",
    "authors": [
      "Zhi Wang",
      "Chaoge Liu",
      "Xiang Cui",
      "Jie Yin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04344"
  },
  {
    "id": "arXiv:2109.04347",
    "title": "Clockwork Finance: Automated Analysis of Economic Security in Smart  Contracts",
    "abstract": "We introduce the Clockwork Finance Framework (CFF), a general purpose, formal\nverification framework for mechanized reasoning about the economic security\nproperties of composed decentralized-finance (DeFi) smart contracts.\nCFF features three key properties. It is contract complete, meaning that it\ncan model any smart contract platform and all its contracts -- Turing complete\nor otherwise. It does so with asymptotically optimal model size. It is also\nattack-exhaustive by construction, meaning that it can automatically and\nmechanically extract all possible economic attacks on users' cryptocurrency\nacross modeled contracts.\nThanks to these properties, CFF can support multiple goals: economic security\nanalysis of contracts by developers, analysis of DeFi trading risks by users,\nand optimization of arbitrage opportunities by bots or miners. Because CFF\noffers composability, it can support these goals with reasoning over any\ndesired set of potentially interacting smart contract models.\nWe instantiate CFF as an executable model for Ethereum contracts that\nincorporates a state-of-the-art deductive verifier. Building on previous work,\nwe introduce extractable value (EV), a new formal notion of economic security\nin composed DeFi contracts that is both a basis for CFF analyses and of general\ninterest.\nWe construct modular, human-readable, composable CFF models of four popular,\ndeployed DeFi protocols in Ethereum: Uniswap, Uniswap V2, Sushiswap, and\nMakerDAO, representing a combined 17 billion USD in value as of August 2021. We\nuses these models to show experimentally that CFF is practical and can drive\nuseful, data-based EV-based insights from real world transaction activity.\nWithout any explicitly programmed attack strategies, CFF uncovers on average an\nexpected \\$56 million of EV per month in the recent past.",
    "descriptor": "",
    "authors": [
      "Kushal Babel",
      "Philip Daian",
      "Mahimna Kelkar",
      "Ari Juels"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.04347"
  },
  {
    "id": "arXiv:2109.04348",
    "title": "VAINE: Visualization and AI for Natural Experiments",
    "abstract": "Natural experiments are observational studies where the assignment of\ntreatment conditions to different populations occurs by chance \"in the wild\".\nResearchers from fields such as economics, healthcare, and the social sciences\nleverage natural experiments to conduct hypothesis testing and causal effect\nestimation for treatment and outcome variables that would otherwise be costly,\ninfeasible, or unethical. In this paper, we introduce VAINE (Visualization and\nAI for Natural Experiments), a visual analytics tool for identifying and\nunderstanding natural experiments from observational data. We then demonstrate\nhow VAINE can be used to validate causal relationships, estimate average\ntreatment effects, and identify statistical phenomena such as Simpson's paradox\nthrough two usage scenarios.",
    "descriptor": "\nComments: 5 pages, 4 figures, accepted as short paper at IEEE VIS 2021\n",
    "authors": [
      "Grace Guo",
      "Maria Glenski",
      "ZhuanYi Shaw",
      "Emily Saldanha",
      "Alex Endert",
      "Svitlana Volkova",
      "Dustin Arendt"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04348"
  },
  {
    "id": "arXiv:2109.04349",
    "title": "Uncertainty Measures in Neural Belief Tracking and the Effects on  Dialogue Policy Performance",
    "abstract": "The ability to identify and resolve uncertainty is crucial for the robustness\nof a dialogue system. Indeed, this has been confirmed empirically on systems\nthat utilise Bayesian approaches to dialogue belief tracking. However, such\nsystems consider only confidence estimates and have difficulty scaling to more\ncomplex settings. Neural dialogue systems, on the other hand, rarely take\nuncertainties into account. They are therefore overconfident in their decisions\nand less robust. Moreover, the performance of the tracking task is often\nevaluated in isolation, without consideration of its effect on the downstream\npolicy optimisation. We propose the use of different uncertainty measures in\nneural belief tracking. The effects of these measures on the downstream task of\npolicy optimisation are evaluated by adding selected measures of uncertainty to\nthe feature space of the policy and training policies through interaction with\na user simulator. Both human and simulated user results show that incorporating\nthese measures leads to improvements both of the performance and of the\nrobustness of the downstream dialogue policy. This highlights the importance of\ndeveloping neural dialogue belief trackers that take uncertainty into account.",
    "descriptor": "\nComments: 14 pages, 2 figures, accepted at EMNLP 2021 Main conference, Code at: this https URL\n",
    "authors": [
      "Carel van Niekerk",
      "Andrey Malinin",
      "Christian Geishauser",
      "Michael Heck",
      "Hsien-chin Lin",
      "Nurul Lubis",
      "Shutong Feng",
      "Milica Ga\u0161i\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04349"
  },
  {
    "id": "arXiv:2109.04351",
    "title": "NeuralFMU: Towards Structural Integration of FMUs into Neural Networks",
    "abstract": "This paper covers two major subjects: First, the presentation of a new\nopen-source library called FMI.jl for integrating FMI into the Julia\nprogramming environment by providing the possibility to load, parameterize and\nsimulate FMUs. Further, an extension to this library called FMIFlux.jl is\nintroduced, that allows the integration of FMUs into a neural network topology\nto obtain a NeuralFMU. This structural combination of an industry typical\nblack-box model and a data-driven machine learning model combines the different\nadvantages of both modeling approaches in one single development environment.\nThis allows for the usage of advanced data driven modeling techniques for\nphysical effects that are difficult to model based on first principles.",
    "descriptor": "",
    "authors": [
      "Tobias Thummerer",
      "Josef Kircher",
      "Lars Mikelsons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04351"
  },
  {
    "id": "arXiv:2109.04353",
    "title": "Cross DQN: Cross Deep Q Network for Ads Allocation in Feed",
    "abstract": "E-commerce platforms usually display a mixed list of ads and organic items in\nfeed. One key problem is to allocate the limited slots in the feed to maximize\nthe overall revenue as well as improve user experience, which requires a good\nmodel for user preference. Instead of modeling the influence of individual\nitems on user behaviors, the arrangement signal models the influence of the\narrangement of items and may lead to a better allocation strategy. However,\nmost of previous strategies fail to model such a signal and therefore result in\nsuboptimal performance. To this end, we propose Cross Deep Q Network (Cross\nDQN) to extract the arrangement signal by crossing the embeddings of different\nitems and processing the crossed sequence in the feed. Our model results in\nhigher revenue and better user experience than state-of-the-art baselines in\noffline experiments. Moreover, our model demonstrates a significant improvement\nin the online A/B test and has been fully deployed on Meituan feed to serve\nmore than 300 millions of customers.",
    "descriptor": "",
    "authors": [
      "Guogang Liao",
      "Ze Wang",
      "Xiaoxu Wu",
      "Xiaowen Shi",
      "Chuheng Zhang",
      "Yongkang Wang",
      "Xingxing Wang",
      "Dong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04353"
  },
  {
    "id": "arXiv:2109.04367",
    "title": "Multi-granularity Textual Adversarial Attack with Behavior Cloning",
    "abstract": "Recently, the textual adversarial attack models become increasingly popular\ndue to their successful in estimating the robustness of NLP models. However,\nexisting works have obvious deficiencies. (1) They usually consider only a\nsingle granularity of modification strategies (e.g. word-level or\nsentence-level), which is insufficient to explore the holistic textual space\nfor generation; (2) They need to query victim models hundreds of times to make\na successful attack, which is highly inefficient in practice. To address such\nproblems, in this paper we propose MAYA, a Multi-grAnularitY Attack model to\neffectively generate high-quality adversarial samples with fewer queries to\nvictim models. Furthermore, we propose a reinforcement-learning based method to\ntrain a multi-granularity attack agent through behavior cloning with the expert\nknowledge from our MAYA algorithm to further reduce the query times.\nAdditionally, we also adapt the agent to attack black-box models that only\noutput labels without confidence scores. We conduct comprehensive experiments\nto evaluate our attack models by attacking BiLSTM, BERT and RoBERTa in two\ndifferent black-box attack settings and three benchmark datasets. Experimental\nresults show that our models achieve overall better attacking performance and\nproduce more fluent and grammatical adversarial samples compared to baseline\nmodels. Besides, our adversarial attack agent significantly reduces the query\ntimes in both attack settings. Our codes are released at\nhttps://github.com/Yangyi-Chen/MAYA.",
    "descriptor": "\nComments: Accepted by the main conference of EMNLP 2021\n",
    "authors": [
      "Yangyi Chen",
      "Jin Su",
      "Wei Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04367"
  },
  {
    "id": "arXiv:2109.04368",
    "title": "Worbel: Aggregating Point Labels into Word Clouds",
    "abstract": "Point feature labeling is a classical problem in cartography and GIS that has\nbeen extensively studied for geospatial point data. At the same time, word\nclouds are a popular visualization tool to show the most important words in\ntext data which has also been extended to visualize geospatial data (Buchin et\nal. PacificVis 2016).\nIn this paper, we study a hybrid visualization, which combines aspects of\nword clouds and point labeling. In the considered setting, the input data\nconsists of a set of points grouped into categories and our aim is to place\nmultiple disjoint and axis-aligned rectangles, each representing a category,\nsuch that they cover points of (mostly) the same category under some natural\nquality constraints. In our visualization, we then place category names inside\nthe computed rectangles to produce a labeling of the covered points which\nsummarizes the predominant categories globally (in a word-cloud-like fashion)\nwhile locally avoiding excessive misrepresentation of points (i.e., retaining\nthe precision of point labeling).\nWe show that computing a minimum set of such rectangles is NP-hard. Hence, we\nturn our attention to developing heuristics and exact SAT models to compute our\nvisualizations. We evaluate our algorithms quantitatively, measuring running\ntime and quality of the produced solutions, on several artificial and\nreal-world data sets. Our experiments show that the heuristics produce\nsolutions of comparable quality to the SAT models while running much faster.",
    "descriptor": "\nComments: 22 pages, 11 figures (21 subfigures), accepted by sigspatial 2021\n",
    "authors": [
      "Sujoy Bhore",
      "Robert Ganian",
      "Guangping Li",
      "Martin N\u00f6llenburg",
      "Jules Wulms"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04368"
  },
  {
    "id": "arXiv:2109.04369",
    "title": "Tracking Turbulence Through Financial News During COVID-19",
    "abstract": "Grave human toll notwithstanding, the COVID-19 pandemic created uniquely\nunstable conditions in financial markets. In this work we uncover and discuss\nrelationships involving sentiment in financial publications during the 2020\npandemic-motivated U.S. financial crash. First, we introduce a set of expert\nannotations of financial sentiment for articles from major American financial\nnews publishers. After an exploratory data analysis, we then describe a\nCNN-based architecture to address the task of predicting financial sentiment in\nthis anomalous, tumultuous setting. Our best performing model achieves a\nmaximum weighted F1 score of 0.746, establishing a strong performance\nbenchmark. Using predictions from our top performing model, we close by\nconducting a statistical correlation study with real stock market data, finding\ninteresting and strong relationships between financial news and the S\\&P 500\nindex, trading volume, market volatility, and different single-factor ETFs.",
    "descriptor": "",
    "authors": [
      "Philip Hossu",
      "Natalie Parde"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04369"
  },
  {
    "id": "arXiv:2109.04374",
    "title": "IFBiD: Inference-Free Bias Detection",
    "abstract": "This paper is the first to explore an automatic way to detect bias in deep\nconvolutional neural networks by simply looking at their weights. Furthermore,\nit is also a step towards understanding neural networks and how they work. We\nshow that it is indeed possible to know if a model is biased or not simply by\nlooking at its weights, without the model inference for an specific input. We\nanalyze how bias is encoded in the weights of deep networks through a toy\nexample using the Colored MNIST database and we also provide a realistic case\nstudy in gender detection from face images using state-of-the-art methods and\nexperimental resources. To do so, we generated two databases with 36K and 48K\nbiased models each. In the MNIST models we were able to detect whether they\npresented a strong or low bias with more than 99% accuracy, and we were also\nable to classify between four levels of bias with more than 70% accuracy. For\nthe face models, we achieved 90% accuracy in distinguishing between models\nbiased towards Asian, Black, or Caucasian ethnicity.",
    "descriptor": "",
    "authors": [
      "Ignacio Serna",
      "Aythami Morales",
      "Julian Fierrez",
      "Javier Ortega-Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04374"
  },
  {
    "id": "arXiv:2109.04378",
    "title": "Dynamic Modeling of Hand-Object Interactions via Tactile Sensing",
    "abstract": "Tactile sensing is critical for humans to perform everyday tasks. While\nsignificant progress has been made in analyzing object grasping from vision, it\nremains unclear how we can utilize tactile sensing to reason about and model\nthe dynamics of hand-object interactions. In this work, we employ a\nhigh-resolution tactile glove to perform four different interactive activities\non a diversified set of objects. We build our model on a cross-modal learning\nframework and generate the labels using a visual processing pipeline to\nsupervise the tactile model, which can then be used on its own during the test\ntime. The tactile model aims to predict the 3d locations of both the hand and\nthe object purely from the touch data by combining a predictive model and a\ncontrastive learning module. This framework can reason about the interaction\npatterns from the tactile data, hallucinate the changes in the environment,\nestimate the uncertainty of the prediction, and generalize to unseen objects.\nWe also provide detailed ablation studies regarding different system designs as\nwell as visualizations of the predicted trajectories. This work takes a step on\ndynamics modeling in hand-object interactions from dense tactile sensing, which\nopens the door for future applications in activity learning, human-computer\ninteractions, and imitation learning for robotics.",
    "descriptor": "\nComments: IROS 2021. First two authors contributed equally. Project page: this http URL\n",
    "authors": [
      "Qiang Zhang",
      "Yunzhu Li",
      "Yiyue Luo",
      "Wan Shou",
      "Michael Foshey",
      "Junchi Yan",
      "Joshua B. Tenenbaum",
      "Wojciech Matusik",
      "Antonio Torralba"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04378"
  },
  {
    "id": "arXiv:2109.04379",
    "title": "Preservational Learning Improves Self-supervised Medical Image Models by  Reconstructing Diverse Contexts",
    "abstract": "Preserving maximal information is one of principles of designing\nself-supervised learning methodologies. To reach this goal, contrastive\nlearning adopts an implicit way which is contrasting image pairs. However, we\nbelieve it is not fully optimal to simply use the contrastive estimation for\npreservation. Moreover, it is necessary and complemental to introduce an\nexplicit solution to preserve more information. From this perspective, we\nintroduce Preservational Learning to reconstruct diverse image contexts in\norder to preserve more information in learned representations. Together with\nthe contrastive loss, we present Preservational Contrastive Representation\nLearning (PCRL) for learning self-supervised medical representations. PCRL\nprovides very competitive results under the pretraining-finetuning protocol,\noutperforming both self-supervised and supervised counterparts in 5\nclassification/segmentation tasks substantially.",
    "descriptor": "\nComments: Accepted by ICCV 2021. Codes are available at this https URL\n",
    "authors": [
      "Hong-Yu Zhou",
      "Chixiang Lu",
      "Sibei Yang",
      "Xiaoguang Han",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04379"
  },
  {
    "id": "arXiv:2109.04380",
    "title": "ESimCSE: Enhanced Sample Building Method for Contrastive Learning of  Unsupervised Sentence Embedding",
    "abstract": "Contrastive learning has been attracting much attention for learning\nunsupervised sentence embeddings. The current state-of-the-art unsupervised\nmethod is the unsupervised SimCSE (unsup-SimCSE). Unsup-SimCSE takes dropout as\na minimal data augmentation method, and passes the same input sentence to a\npre-trained Transformer encoder (with dropout turned on) twice to obtain the\ntwo corresponding embeddings to build a positive pair. As the length\ninformation of a sentence will generally be encoded into the sentence\nembeddings due to the usage of position embedding in Transformer, each positive\npair in unsup-SimCSE actually contains the same length information. And thus\nunsup-SimCSE trained with these positive pairs is probably biased, which would\ntend to consider that sentences of the same or similar length are more similar\nin semantics. Through statistical observations, we find that unsup-SimCSE does\nhave such a problem. To alleviate it, we apply a simple repetition operation to\nmodify the input sentence, and then pass the input sentence and its modified\ncounterpart to the pre-trained Transformer encoder, respectively, to get the\npositive pair. Additionally, we draw inspiration from the community of computer\nvision and introduce a momentum contrast, enlarging the number of negative\npairs without additional calculations. The proposed two modifications are\napplied on positive and negative pairs separately, and build a new sentence\nembedding method, termed Enhanced Unsup-SimCSE (ESimCSE). We evaluate the\nproposed ESimCSE on several benchmark datasets w.r.t the semantic text\nsimilarity (STS) task. Experimental results show that ESimCSE outperforms the\nstate-of-the-art unsup-SimCSE by an average Spearman correlation of 2.02% on\nBERT-base.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Xing Wu",
      "Chaochen Gao",
      "Liangjun Zang",
      "Jizhong Han",
      "Zhongyuan Wang",
      "Songlin Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04380"
  },
  {
    "id": "arXiv:2109.04381",
    "title": "Copy-Move Image Forgery Detection Based on Evolving Circular Domains  Coverage",
    "abstract": "The aim of this paper is to improve the accuracy of copy-move forgery\ndetection (CMFD) in image forensics by proposing a novel scheme. The proposed\nscheme integrates both block-based and keypoint-based forgery detection\nmethods. Firstly, speed-up robust feature (SURF) descriptor in log-polar space\nand scale invariant feature transform (SIFT) descriptor are extracted from an\nentire forged image. Secondly, generalized 2 nearest neighbor (g2NN) is\nemployed to get massive matched pairs. Then, random sample consensus (RANSAC)\nalgorithm is employed to filter out mismatched pairs, thus allowing rough\nlocalization of the counterfeit areas. To present more accurately these forgery\nareas more accurately, we propose an efficient and accurate algorithm, evolving\ncircular domains coverage (ECDC), to cover present them. This algorithm aims to\nfind satisfactory threshold areas by extracting block features from jointly\nevolving circular domains, which are centered on the matched pairs. Finally,\nmorphological operation is applied to refine the detected forgery areas. The\nexperimental results indicate that the proposed CMFD scheme can achieve better\ndetection performance under various attacks compared with other\nstate-of-the-art CMFD schemes.",
    "descriptor": "",
    "authors": [
      "Shilin Lu",
      "Xinghong Hu",
      "Chengyou Wang",
      "Lu Chen",
      "Shulu Han",
      "Yuejia Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04381"
  },
  {
    "id": "arXiv:2109.04385",
    "title": "Contrasting Human- and Machine-Generated Word-Level Adversarial Examples  for Text Classification",
    "abstract": "Research shows that natural language processing models are generally\nconsidered to be vulnerable to adversarial attacks; but recent work has drawn\nattention to the issue of validating these adversarial inputs against certain\ncriteria (e.g., the preservation of semantics and grammaticality). Enforcing\nconstraints to uphold such criteria may render attacks unsuccessful, raising\nthe question of whether valid attacks are actually feasible. In this work, we\ninvestigate this through the lens of human language ability. We report on\ncrowdsourcing studies in which we task humans with iteratively modifying words\nin an input text, while receiving immediate model feedback, with the aim of\ncausing a sentiment classification model to misclassify the example. Our\nfindings suggest that humans are capable of generating a substantial amount of\nadversarial examples using semantics-preserving word substitutions. We analyze\nhow human-generated adversarial examples compare to the recently proposed\nTextFooler, Genetic, BAE and SememePSO attack algorithms on the dimensions\nnaturalness, preservation of sentiment, grammaticality and substitution rate.\nOur findings suggest that human-generated adversarial examples are not more\nable than the best algorithms to generate natural-reading, sentiment-preserving\nexamples, though they do so by being much more computationally efficient.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Maximilian Mozes",
      "Max Bartolo",
      "Pontus Stenetorp",
      "Bennett Kleinberg",
      "Lewis D. Griffin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04385"
  },
  {
    "id": "arXiv:2109.04386",
    "title": "ErfAct: Non-monotonic smooth trainable Activation Functions",
    "abstract": "An activation function is a crucial component of a neural network that\nintroduces non-linearity in the network. The state-of-the-art performance of a\nneural network depends on the perfect choice of an activation function. We\npropose two novel non-monotonic smooth trainable activation functions, called\nErfAct-1 and ErfAct-2. Experiments suggest that the proposed functions improve\nthe network performance significantly compared to the widely used activations\nlike ReLU, Swish, and Mish. Replacing ReLU by ErfAct-1 and ErfAct-2, we have\n5.21% and 5.04% improvement for top-1 accuracy on PreactResNet-34 network in\nCIFAR100 dataset, 2.58% and 2.76% improvement for top-1 accuracy on\nPreactResNet-34 network in CIFAR10 dataset, 1.0%, and 1.0% improvement on mean\naverage precision (mAP) on SSD300 model in Pascal VOC dataset.",
    "descriptor": "",
    "authors": [
      "Koushik Biswas",
      "Sandeep Kumar",
      "Shilpak Banerjee",
      "Ashish Kumar Pandey"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04386"
  },
  {
    "id": "arXiv:2109.04390",
    "title": "1-Bit MIMO for Terahertz Channels",
    "abstract": "This paper tackles the problem of single-user multiple-input multiple-output\ncommunication with 1-bit digital-to-analog and analog-to-digital converters.\nWith the information-theoretic capacity as benchmark, the complementary\nstrategies of beamforming and equiprobable signaling are contrasted in the\nregimes of operational interest, and the ensuing spectral efficiencies are\ncharacterized. Various canonical channel types are considered, with emphasis on\nline-of-sight settings under both spherical and planar wavefronts, respectively\nrepresentative of short and long transmission ranges at mmWave and terahertz\nfrequencies. In all cases, a judicious combination of beamforming and\nequiprobable signaling is shown to operate within a modest gap from capacity.",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Angel Lozano"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.04390"
  },
  {
    "id": "arXiv:2109.04398",
    "title": "Neural-IMLS: Learning Implicit Moving Least-Squares for Surface  Reconstruction from Unoriented Point clouds",
    "abstract": "Surface reconstruction from noisy, non-uniformly, and unoriented point clouds\nis a fascinating yet difficult problem in computer vision and computer\ngraphics. In this paper, we propose Neural-IMLS, a novel approach that learning\nnoise-resistant signed distance function (SDF) for reconstruction. Instead of\nexplicitly learning priors with the ground-truth signed distance values, our\nmethod learns the SDF from raw point clouds directly in a self-supervised\nfashion by minimizing the loss between the couple of SDFs, one obtained by the\nimplicit moving least-square function (IMLS) and the other by our network.\nFinally, a watertight and smooth 2-manifold triangle mesh is yielded by running\nMarching Cubes. We conduct extensive experiments on various benchmarks to\ndemonstrate the performance of Neural-IMLS, especially for point clouds with\nnoise.",
    "descriptor": "",
    "authors": [
      "Zixiong Wang",
      "Pengfei Wang",
      "Qiujie Dong",
      "Junjie Gao",
      "Shuangmin Chen",
      "Shiqing Xin",
      "Changhe Tu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.04398"
  },
  {
    "id": "arXiv:2109.04399",
    "title": "Gradual (In)Compatibility of Fairness Criteria",
    "abstract": "Impossibility results show that important fairness measures (independence,\nseparation, sufficiency) cannot be satisfied at the same time under reasonable\nassumptions. This paper explores whether we can satisfy and/or improve these\nfairness measures simultaneously to a certain degree. We introduce\ninformation-theoretic formulations of the fairness measures and define degrees\nof fairness based on these formulations. The information-theoretic formulations\nsuggest unexplored theoretical relations between the three fairness measures.\nIn the experimental part, we use the information-theoretic expressions as\nregularizers to obtain fairness-regularized predictors for three standard\ndatasets. Our experiments show that a) fairness regularization directly\nincreases fairness measures, in line with existing work, and b) some fairness\nregularizations indirectly increase other fairness measures, as suggested by\nour theoretical findings. This establishes that it is possible to increase the\ndegree to which some fairness measures are satisfied at the same time -- some\nfairness measures are gradually compatible.",
    "descriptor": "\nComments: Code available on GitHub: this https URL\n",
    "authors": [
      "Corinna Hertweck",
      "Tim R\u00e4z"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04399"
  },
  {
    "id": "arXiv:2109.04400",
    "title": "Cross-lingual Transfer for Text Classification with Dictionary-based  Heterogeneous Graph",
    "abstract": "In cross-lingual text classification, it is required that task-specific\ntraining data in high-resource source languages are available, where the task\nis identical to that of a low-resource target language. However, collecting\nsuch training data can be infeasible because of the labeling cost, task\ncharacteristics, and privacy concerns. This paper proposes an alternative\nsolution that uses only task-independent word embeddings of high-resource\nlanguages and bilingual dictionaries. First, we construct a dictionary-based\nheterogeneous graph (DHG) from bilingual dictionaries. This opens the\npossibility to use graph neural networks for cross-lingual transfer. The\nremaining challenge is the heterogeneity of DHG because multiple languages are\nconsidered. To address this challenge, we propose dictionary-based\nheterogeneous graph neural network (DHGNet) that effectively handles the\nheterogeneity of DHG by two-step aggregations, which are word-level and\nlanguage-level aggregations. Experimental results demonstrate that our method\noutperforms pretrained models even though it does not access to large corpora.\nFurthermore, it can perform well even though dictionaries contain many\nincorrect translations. Its robustness allows the usage of a wider range of\ndictionaries such as an automatically constructed dictionary and crowdsourced\ndictionary, which are convenient for real-world applications.",
    "descriptor": "\nComments: Published in Findings of EMNLP 2021\n",
    "authors": [
      "Nuttapong Chairatanakul",
      "Noppayut Sriwatanasakdi",
      "Nontawat Charoenphakdee",
      "Xin Liu",
      "Tsuyoshi Murata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04400"
  },
  {
    "id": "arXiv:2109.04404",
    "title": "All Bark and No Bite: Rogue Dimensions in Transformer Language Models  Obscure Representational Quality",
    "abstract": "Similarity measures are a vital tool for understanding how language models\nrepresent and process language. Standard representational similarity measures\nsuch as cosine similarity and Euclidean distance have been successfully used in\nstatic word embedding models to understand how words cluster in semantic space.\nRecently, these measures have been applied to embeddings from contextualized\nmodels such as BERT and GPT-2. In this work, we call into question the\ninformativity of such measures for contextualized language models. We find that\na small number of rogue dimensions, often just 1-3, dominate these measures.\nMoreover, we find a striking mismatch between the dimensions that dominate\nsimilarity measures and those which are important to the behavior of the model.\nWe show that simple postprocessing techniques such as standardization are able\nto correct for rogue dimensions and reveal underlying representational quality.\nWe argue that accounting for rogue dimensions is essential for any\nsimilarity-based analysis of contextual language models.",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "William Timkey",
      "Marten van Schijndel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04404"
  },
  {
    "id": "arXiv:2109.04408",
    "title": "Learning from Uneven Training Data: Unlabeled, Single Label, and  Multiple Labels",
    "abstract": "Training NLP systems typically assumes access to annotated data that has a\nsingle human label per example. Given imperfect labeling from annotators and\ninherent ambiguity of language, we hypothesize that single label is not\nsufficient to learn the spectrum of language interpretation. We explore new\nlabel annotation distribution schemes, assigning multiple labels per example\nfor a small subset of training examples. Introducing such multi label examples\nat the cost of annotating fewer examples brings clear gains on natural language\ninference task and entity typing task, even when we simply first train with a\nsingle label data and then fine tune with multi label examples. Extending a\nMixUp data augmentation framework, we propose a learning algorithm that can\nlearn from uneven training examples (with zero, one, or multiple labels). This\nalgorithm efficiently combines signals from uneven training data and brings\nadditional gains in low annotation budget and cross domain settings. Together,\nour method achieves consistent gains in both accuracy and label distribution\nmetrics in two tasks, suggesting training with uneven training data can be\nbeneficial for many NLP tasks.",
    "descriptor": "\nComments: EMNLP 2021; Our code is publicly available at this https URL\n",
    "authors": [
      "Shujian Zhang",
      "Chengyue Gong",
      "Eunsol Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04408"
  },
  {
    "id": "arXiv:2109.04409",
    "title": "Reconstructing and grounding narrated instructional videos in 3D",
    "abstract": "Narrated instructional videos often show and describe manipulations of\nsimilar objects, e.g., repairing a particular model of a car or laptop. In this\nwork we aim to reconstruct such objects and to localize associated narrations\nin 3D. Contrary to the standard scenario of instance-level 3D reconstruction,\nwhere identical objects or scenes are present in all views, objects in\ndifferent instructional videos may have large appearance variations given\nvarying conditions and versions of the same product. Narrations may also have\nlarge variation in natural language expressions. We address these challenges by\nthree contributions. First, we propose an approach for correspondence\nestimation combining learnt local features and dense flow. Second, we design a\ntwo-step divide and conquer reconstruction approach where the initial 3D\nreconstructions of individual videos are combined into a 3D alignment graph.\nFinally, we propose an unsupervised approach to ground natural language in\nobtained 3D reconstructions. We demonstrate the effectiveness of our approach\nfor the domain of car maintenance. Given raw instructional videos and no manual\nsupervision, our method successfully reconstructs engines of different car\nmodels and associates textual descriptions with corresponding objects in 3D.",
    "descriptor": "",
    "authors": [
      "Dimitri Zhukov",
      "Ignacio Rocco",
      "Ivan Laptev",
      "Josef Sivic",
      "Johannes L. Schnberger",
      "Bugra Tekin",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04409"
  },
  {
    "id": "arXiv:2109.04410",
    "title": "Degrees of randomized computability: decomposition into atoms",
    "abstract": "In this paper we study structural properties of LV-degrees of the algebra of\ncollections of sequences that are non-negligible in the sense that they can be\ncomputed by a probabilistic algorithm with positive probability. We construct\natoms and infinitely divisible elements of this algebra generated by sequences,\nwhich cannot be Martin-L\\\"of random and, moreover, these sequences cannot be\nTuring equivalent to random sequences. The constructions are based on the\ncorresponding templates which can be used for defining the special LV-degrees.\nIn particular, we present the template for defining atoms of the algebra of\nLV-degrees and obtain the decomposition of the maximal LV-degree into a\ncountable sequence of atoms and their non-zero complement -- infinitely\ndivisible LV-degree. We apply the templates to establish new facts about\nspecific LV-degrees, such as the LV-degree of the collection of sequences of\nhyperimmune degree. We construct atoms defined by collections of hyperimmune\nsequences, moreover, a representation of LV-degree of the collection of all\nhyperimmune sequences will be obtained in the form of a union of an infinite\nsequence of atoms and an infinitely divisible element.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Vladimir V. V'yugin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.04410"
  },
  {
    "id": "arXiv:2109.04413",
    "title": "AStitchInLanguageModels: Dataset and Methods for the Exploration of  Idiomaticity in Pre-Trained Language Models",
    "abstract": "Despite their success in a variety of NLP tasks, pre-trained language models,\ndue to their heavy reliance on compositionality, fail in effectively capturing\nthe meanings of multiword expressions (MWEs), especially idioms. Therefore,\ndatasets and methods to improve the representation of MWEs are urgently needed.\nExisting datasets are limited to providing the degree of idiomaticity of\nexpressions along with the literal and, where applicable, (a single)\nnon-literal interpretation of MWEs. This work presents a novel dataset of\nnaturally occurring sentences containing MWEs manually classified into a\nfine-grained set of meanings, spanning both English and Portuguese. We use this\ndataset in two tasks designed to test i) a language model's ability to detect\nidiom usage, and ii) the effectiveness of a language model in generating\nrepresentations of sentences containing idioms. Our experiments demonstrate\nthat, on the task of detecting idiomatic usage, these models perform reasonably\nwell in the one-shot and few-shot scenarios, but that there is significant\nscope for improvement in the zero-shot scenario. On the task of representing\nidiomaticity, we find that pre-training is not always effective, while\nfine-tuning could provide a sample efficient method of learning representations\nof sentences containing MWEs.",
    "descriptor": "\nComments: Findings of EMNLP 2021. Code available at: this https URL\n",
    "authors": [
      "Harish Tayyar Madabushi",
      "Edward Gow-Smith",
      "Carolina Scarton",
      "Aline Villavicencio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04413"
  },
  {
    "id": "arXiv:2109.04415",
    "title": "Algorithms and Certificates for Boolean CSP Refutation: \"Smoothed is no  harder than Random\"",
    "abstract": "We present an algorithm for strongly refuting smoothed instances of all\nBoolean CSPs. The smoothed model is a hybrid between worst and average-case\ninput models, where the input is an arbitrary instance of the CSP with only the\nnegation patterns of the literals re-randomized with some small probability.\nFor an $n$-variable smoothed instance of a $k$-arity CSP, our algorithm runs in\n$n^{O(\\ell)}$ time, and succeeds with high probability in bounding the optimum\nfraction of satisfiable constraints away from $1$, provided that the number of\nconstraints is at least $\\tilde{O}(n) (\\frac{n}{\\ell})^{\\frac{k}{2} - 1}$. This\nmatches, up to polylogarithmic factors in $n$, the trade-off between running\ntime and the number of constraints of the state-of-the-art algorithms for\nrefuting fully random instances of CSPs [RRS17].\nWe also make a surprising new connection between our algorithm and even\ncovers in hypergraphs, which we use to positively resolve Feige's 2008\nconjecture, an extremal combinatorics conjecture on the existence of even\ncovers in sufficiently dense hypergraphs that generalizes the well-known Moore\nbound for the girth of graphs. As a corollary, we show that polynomial-size\nrefutation witnesses exist for arbitrary smoothed CSP instances with number of\nconstraints a polynomial factor below the \"spectral threshold\" of $n^{k/2}$,\nextending the celebrated result for random 3-SAT of Feige, Kim and Ofek\n[FKO06].",
    "descriptor": "",
    "authors": [
      "Venkatesan Guruswami",
      "Pravesh K. Kothari",
      "Peter Manohar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.04415"
  },
  {
    "id": "arXiv:2109.04422",
    "title": "TxT: Crossmodal End-to-End Learning with Transformers",
    "abstract": "Reasoning over multiple modalities, e.g. in Visual Question Answering (VQA),\nrequires an alignment of semantic concepts across domains. Despite the\nwidespread success of end-to-end learning, today's multimodal pipelines by and\nlarge leverage pre-extracted, fixed features from object detectors, typically\nFaster R-CNN, as representations of the visual world. The obvious downside is\nthat the visual representation is not specifically tuned to the multimodal task\nat hand. At the same time, while transformer-based object detectors have gained\npopularity, they have not been employed in today's multimodal pipelines. We\naddress both shortcomings with TxT, a transformer-based crossmodal pipeline\nthat enables fine-tuning both language and visual components on the downstream\ntask in a fully end-to-end manner. We overcome existing limitations of\ntransformer-based detectors for multimodal reasoning regarding the integration\nof global context and their scalability. Our transformer-based multimodal model\nachieves considerable gains from end-to-end learning for multimodal question\nanswering.",
    "descriptor": "\nComments: To appear at the 43rd DAGM German Conference on Pattern Recognition (GCPR) 2021\n",
    "authors": [
      "Jan-Martin O. Steitz",
      "Jonas Pfeiffer",
      "Iryna Gurevych",
      "Stefan Roth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04422"
  },
  {
    "id": "arXiv:2109.04424",
    "title": "Mini Cheetah, the Falling Cat: A Case Study in Machine Learning and  Trajectory Optimization for Robot Acrobatics",
    "abstract": "Seemingly in defiance of basic physics, cats consistently land on their feet\nafter falling. In this paper, we design a controller that lands the Mini\nCheetah quadruped robot on its feet as well. Specifically, we explore how\ntrajectory optimization and machine learning can work together to enable highly\ndynamic bioinspired behaviors. We find that a reflex approach, in which a\nneural network learns entire state trajectories, outperforms a policy approach,\nin which a neural network learns a mapping from states to control inputs. We\nvalidate our proposed controller in both simulation and hardware experiments,\nand are able to land the robot on its feet from falls with initial pitch angles\nbetween -90 and 90 degrees.",
    "descriptor": "",
    "authors": [
      "Vince Kurtz",
      "He Li",
      "Patrick M. Wensing",
      "Hai Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04424"
  },
  {
    "id": "arXiv:2109.04425",
    "title": "Talk-to-Edit: Fine-Grained Facial Editing via Dialog",
    "abstract": "Facial editing is an important task in vision and graphics with numerous\napplications. However, existing works are incapable to deliver a continuous and\nfine-grained editing mode (e.g., editing a slightly smiling face to a big\nlaughing one) with natural interactions with users. In this work, we propose\nTalk-to-Edit, an interactive facial editing framework that performs\nfine-grained attribute manipulation through dialog between the user and the\nsystem. Our key insight is to model a continual \"semantic field\" in the GAN\nlatent space. 1) Unlike previous works that regard the editing as traversing\nstraight lines in the latent space, here the fine-grained editing is formulated\nas finding a curving trajectory that respects fine-grained attribute landscape\non the semantic field. 2) The curvature at each step is location-specific and\ndetermined by the input image as well as the users' language requests. 3) To\nengage the users in a meaningful dialog, our system generates language feedback\nby considering both the user request and the current state of the semantic\nfield.\nWe also contribute CelebA-Dialog, a visual-language facial editing dataset to\nfacilitate large-scale study. Specifically, each image has manually annotated\nfine-grained attribute annotations as well as template-based textual\ndescriptions in natural language. Extensive quantitative and qualitative\nexperiments demonstrate the superiority of our framework in terms of 1) the\nsmoothness of fine-grained editing, 2) the identity/attribute preservation, and\n3) the visual photorealism and dialog fluency. Notably, user study validates\nthat our overall system is consistently favored by around 80% of the\nparticipants. Our project page is https://www.mmlab-ntu.com/project/talkedit/.",
    "descriptor": "\nComments: To appear in ICCV2021. Project Page: this https URL, Code: this https URL\n",
    "authors": [
      "Yuming Jiang",
      "Ziqi Huang",
      "Xingang Pan",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04425"
  },
  {
    "id": "arXiv:2109.04428",
    "title": "Improved Online Algorithm for Fractional Knapsack in the Random Order  Model",
    "abstract": "The fractional knapsack problem is one of the classical problems in\ncombinatorial optimization, which is well understood in the offline setting.\nHowever, the corresponding online setting has been handled only briefly in the\ntheoretical computer science literature so far, although it appears in several\napplications. Even the previously best known guarantee for the competitive\nratio was worse than the best known for the integral problem in the popular\nrandom order model. We show that there is an algorithm for the online\nfractional knapsack problem that admits a competitive ratio of 4.39. Our result\nsignificantly improves over the previously best known competitive ratio of 9.37\nand surpasses the current best 6.65-competitive algorithm for the integral\ncase. Moreover, our algorithm is deterministic in contrast to the randomized\nalgorithms achieving the results mentioned above.",
    "descriptor": "",
    "authors": [
      "Jeff Giliberti",
      "Andreas Karrenbauer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.04428"
  },
  {
    "id": "arXiv:2109.04432",
    "title": "Detecting and Mitigating Test-time Failure Risks via Model-agnostic  Uncertainty Learning",
    "abstract": "Reliably predicting potential failure risks of machine learning (ML) systems\nwhen deployed with production data is a crucial aspect of trustworthy AI. This\npaper introduces Risk Advisor, a novel post-hoc meta-learner for estimating\nfailure risks and predictive uncertainties of any already-trained black-box\nclassification model. In addition to providing a risk score, the Risk Advisor\ndecomposes the uncertainty estimates into aleatoric and epistemic uncertainty\ncomponents, thus giving informative insights into the sources of uncertainty\ninducing the failures. Consequently, Risk Advisor can distinguish between\nfailures caused by data variability, data shifts and model limitations and\nadvise on mitigation actions (e.g., collecting more data to counter data\nshift). Extensive experiments on various families of black-box classification\nmodels and on real-world and synthetic datasets covering common ML failure\nscenarios show that the Risk Advisor reliably predicts deployment-time failure\nrisks in all the scenarios, and outperforms strong baselines.",
    "descriptor": "\nComments: To appear in the 21st IEEE International Conference on Data Mining (ICDM 2021), Auckland, New Zealand\n",
    "authors": [
      "Preethi Lahoti",
      "Krishna P. Gummadi",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.04432"
  },
  {
    "id": "arXiv:2109.04440",
    "title": "'1e0a': A Computational Approach to Rhythm Training",
    "abstract": "We present a computational assessment system that promotes the learning of\nbasic rhythmic patterns. The system is capable of generating multiple rhythmic\npatterns with increasing complexity within various cycle lengths. For a\ngenerated rhythm pattern the performance assessment of the learner is carried\nout through the statistical deviations calculated from the onset detection and\ntemporal assessment of a learner's performance. This is compared with the\ngenerated pattern, and their performance accuracy forms the feedback to the\nlearner. The system proceeds to generate a new pattern of increased complexity\nwhen performance assessment results are within certain error bounds. The system\nthus mimics a learner-teacher relationship as the learner progresses in their\nfeedback-based learning. The choice of progression within a cycle for each\npattern is determined by a predefined complexity metric. This metric is based\non a coded element model for the perceptual processing of sequential stimuli.\nThe model earlier proposed for a sequence of tones and non-tones, is now used\nfor onsets and silences. This system is developed into a web-based application\nand provides accessibility for learning purposes. Analysis of the performance\nassessments shows that the complexity metric is indicative of the perceptual\nprocessing of rhythm patterns and can be used for rhythm learning.",
    "descriptor": "",
    "authors": [
      "Noel Alben",
      "Ranjani H.G"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.04440"
  },
  {
    "id": "arXiv:2109.04442",
    "title": "fGOT: Graph Distances based on Filters and Optimal Transport",
    "abstract": "Graph comparison deals with identifying similarities and dissimilarities\nbetween graphs. A major obstacle is the unknown alignment of graphs, as well as\nthe lack of accurate and inexpensive comparison metrics. In this work we\nintroduce the filter graph distance. It is an optimal transport based distance\nwhich drives graph comparison through the probability distribution of filtered\ngraph signals. This creates a highly flexible distance, capable of prioritising\ndifferent spectral information in observed graphs, offering a wide range of\nchoices for a comparison metric. We tackle the problem of graph alignment by\ncomputing graph permutations that minimise our new filter distances, which\nimplicitly solves the graph comparison problem. We then propose a new\napproximate cost function that circumvents many computational difficulties\ninherent to graph comparison and permits the exploitation of fast algorithms\nsuch as mirror gradient descent, without grossly sacrificing the performance.\nWe finally propose a novel algorithm derived from a stochastic version of\nmirror gradient descent, which accommodates the non-convexity of the alignment\nproblem, offering a good trade-off between performance accuracy and speed. The\nexperiments on graph alignment and classification show that the flexibility\ngained through filter graph distances can have a significant impact on\nperformance, while the difference in speed offered by the approximation cost\nmakes the framework applicable in practical settings.",
    "descriptor": "",
    "authors": [
      "Hermina Petric Maretic",
      "Mireille El Gheche",
      "Giovanni Chierchia",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04442"
  },
  {
    "id": "arXiv:2109.04443",
    "title": "HintedBT: Augmenting Back-Translation with Quality and Transliteration  Hints",
    "abstract": "Back-translation (BT) of target monolingual corpora is a widely used data\naugmentation strategy for neural machine translation (NMT), especially for\nlow-resource language pairs. To improve effectiveness of the available BT data,\nwe introduce HintedBT -- a family of techniques which provides hints (through\ntags) to the encoder and decoder. First, we propose a novel method of using\nboth high and low quality BT data by providing hints (as source tags on the\nencoder) to the model about the quality of each source-target pair. We don't\nfilter out low quality data but instead show that these hints enable the model\nto learn effectively from noisy data. Second, we address the problem of\npredicting whether a source token needs to be translated or transliterated to\nthe target language, which is common in cross-script translation tasks (i.e.,\nwhere source and target do not share the written script). For such cases, we\npropose training the model with additional hints (as target tags on the\ndecoder) that provide information about the operation required on the source\n(translation or both translation and transliteration). We conduct experiments\nand detailed analyses on standard WMT benchmarks for three cross-script\nlow/medium-resource language pairs: {Hindi,Gujarati,Tamil}-to-English. Our\nmethods compare favorably with five strong and well established baselines. We\nshow that using these hints, both separately and together, significantly\nimproves translation quality and leads to state-of-the-art performance in all\nthree language pairs in corresponding bilingual settings.",
    "descriptor": "\nComments: 17 pages including references and appendix. Accepted at EMNLP 2021\n",
    "authors": [
      "Sahana Ramnath",
      "Melvin Johnson",
      "Abhirut Gupta",
      "Aravindan Raghuveer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04443"
  },
  {
    "id": "arXiv:2109.04448",
    "title": "Vision-and-Language or Vision-for-Language? On Cross-Modal Influence in  Multimodal Transformers",
    "abstract": "Pretrained vision-and-language BERTs aim to learn representations that\ncombine information from both modalities. We propose a diagnostic method based\non cross-modal input ablation to assess the extent to which these models\nactually integrate cross-modal information. This method involves ablating\ninputs from one modality, either entirely or selectively based on cross-modal\ngrounding alignments, and evaluating the model prediction performance on the\nother modality. Model performance is measured by modality-specific tasks that\nmirror the model pretraining objectives (e.g. masked language modelling for\ntext). Models that have learned to construct cross-modal representations using\nboth modalities are expected to perform worse when inputs are missing from a\nmodality. We find that recently proposed models have much greater relative\ndifficulty predicting text when visual information is ablated, compared to\npredicting visual object categories when text is ablated, indicating that these\nmodels are not symmetrically cross-modal.",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Stella Frank",
      "Emanuele Bugliarello",
      "Desmond Elliott"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04448"
  },
  {
    "id": "arXiv:2109.04452",
    "title": "Analysis of Language Change in Collaborative Instruction Following",
    "abstract": "We analyze language change over time in a collaborative, goal-oriented\ninstructional task, where utility-maximizing participants form conventions and\nincrease their expertise. Prior work studied such scenarios mostly in the\ncontext of reference games, and consistently found that language complexity is\nreduced along multiple dimensions, such as utterance length, as conventions are\nformed. In contrast, we find that, given the ability to increase instruction\nutility, instructors increase language complexity along these previously\nstudied dimensions to better collaborate with increasingly skilled instruction\nfollowers.",
    "descriptor": "\nComments: Findings of EMNLP 2021 Short Paper\n",
    "authors": [
      "Anna Effenberger",
      "Eva Yan",
      "Rhia Singh",
      "Alane Suhr",
      "Yoav Artzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.04452"
  },
  {
    "id": "arXiv:2109.04453",
    "title": "Tube-Certified Trajectory Tracking for Nonlinear Systems With Robust  Control Contraction Metrics",
    "abstract": "This paper presents an approach to guaranteed trajectory tracking for\nnonlinear control-affine systems subject to external disturbances based on\nrobust control contraction metrics (CCM) that aim to minimize the\n$\\mathcal{L}_\\infty$ gain from the disturbances to the deviation of actual\nvariables of interests from their nominal counterparts. The guarantee is in the\nform of invariant tubes, computed offline, around any nominal trajectories in\nwhich the actual states and inputs of the system are guaranteed to stay despite\ndisturbances. Under mild assumptions, we prove that the proposed robust CCM\n(RCCM) approach yields tighter tubes than an existing approach based on CCM and\ninput-to-state stability analysis. We show how the RCCM-based tracking\ncontroller together with tubes can be incorporated into a feedback motion\nplanning framework to plan safe-guaranteed trajectories for robotic systems.\nSimulation results for a planar quadrotor illustrate the effectiveness of the\nproposed method and also empirically demonstrate significantly reduced\nconservatism compared to the CCM-based approach.",
    "descriptor": "",
    "authors": [
      "Pan Zhao",
      "Arun Lakshmanan",
      "Kasey Ackerman",
      "Aditya Gahlawat",
      "Marco Pavone",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04453"
  },
  {
    "id": "arXiv:2109.04454",
    "title": "ConvMLP: Hierarchical Convolutional MLPs for Vision",
    "abstract": "MLP-based architectures, which consist of a sequence of consecutive\nmulti-layer perceptron blocks, have recently been found to reach comparable\nresults to convolutional and transformer-based methods. However, most adopt\nspatial MLPs which take fixed dimension inputs, therefore making it difficult\nto apply them to downstream tasks, such as object detection and semantic\nsegmentation. Moreover, single-stage designs further limit performance in other\ncomputer vision tasks and fully connected layers bear heavy computation. To\ntackle these problems, we propose ConvMLP: a hierarchical Convolutional MLP for\nvisual recognition, which is a light-weight, stage-wise, co-design of\nconvolution layers, and MLPs. In particular, ConvMLP-S achieves 76.8% top-1\naccuracy on ImageNet-1k with 9M parameters and 2.4G MACs (15% and 19% of\nMLP-Mixer-B/16, respectively). Experiments on object detection and semantic\nsegmentation further show that visual representation learned by ConvMLP can be\nseamlessly transferred and achieve competitive results with fewer parameters.\nOur code and pre-trained models are publicly available at\nhttps://github.com/SHI-Labs/Convolutional-MLPs.",
    "descriptor": "",
    "authors": [
      "Jiachen Li",
      "Ali Hassani",
      "Steven Walton",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.04454"
  },
  {
    "id": "arXiv:2109.04456",
    "title": "NEAT: Neural Attention Fields for End-to-End Autonomous Driving",
    "abstract": "Efficient reasoning about the semantic, spatial, and temporal structure of a\nscene is a crucial prerequisite for autonomous driving. We present NEural\nATtention fields (NEAT), a novel representation that enables such reasoning for\nend-to-end imitation learning models. NEAT is a continuous function which maps\nlocations in Bird's Eye View (BEV) scene coordinates to waypoints and\nsemantics, using intermediate attention maps to iteratively compress\nhigh-dimensional 2D image features into a compact representation. This allows\nour model to selectively attend to relevant regions in the input while ignoring\ninformation irrelevant to the driving task, effectively associating the images\nwith the BEV representation. In a new evaluation setting involving adverse\nenvironmental conditions and challenging scenarios, NEAT outperforms several\nstrong baselines and achieves driving scores on par with the privileged CARLA\nexpert used to generate its training data. Furthermore, visualizing the\nattention maps for models with NEAT intermediate representations provides\nimproved interpretability.",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Kashyap Chitta",
      "Aditya Prakash",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04456"
  },
  {
    "id": "arXiv:2109.04459",
    "title": "SONIC: A Sparse Neural Network Inference Accelerator with Silicon  Photonics for Energy-Efficient Deep Learning",
    "abstract": "Sparse neural networks can greatly facilitate the deployment of neural\nnetworks on resource-constrained platforms as they offer compact model sizes\nwhile retaining inference accuracy. Because of the sparsity in parameter\nmatrices, sparse neural networks can, in principle, be exploited in accelerator\narchitectures for improved energy-efficiency and latency. However, to realize\nthese improvements in practice, there is a need to explore sparsity-aware\nhardware-software co-design. In this paper, we propose a novel silicon\nphotonics-based sparse neural network inference accelerator called SONIC. Our\nexperimental analysis shows that SONIC can achieve up to 5.8x better\nperformance-per-watt and 8.4x lower energy-per-bit than state-of-the-art sparse\nelectronic neural network accelerators; and up to 13.8x better\nperformance-per-watt and 27.6x lower energy-per-bit than the best known\nphotonic neural network accelerators.",
    "descriptor": "",
    "authors": [
      "Febin Sunny",
      "Mahdi Nikdast",
      "Sudeep Pasricha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.04459"
  },
  {
    "id": "arXiv:2109.04463",
    "title": "Neural Latents Benchmark '21: Evaluating latent variable models of  neural population activity",
    "abstract": "Advances in neural recording present increasing opportunities to study neural\nactivity in unprecedented detail. Latent variable models (LVMs) are promising\ntools for analyzing this rich activity across diverse neural systems and\nbehaviors, as LVMs do not depend on known relationships between the activity\nand external experimental variables. However, progress in latent variable\nmodeling is currently impeded by a lack of standardization, resulting in\nmethods being developed and compared in an ad hoc manner. To coordinate these\nmodeling efforts, we introduce a benchmark suite for latent variable modeling\nof neural population activity. We curate four datasets of neural spiking\nactivity from cognitive, sensory, and motor areas to promote models that apply\nto the wide variety of activity seen across these areas. We identify\nunsupervised evaluation as a common framework for evaluating models across\ndatasets, and apply several baselines that demonstrate benchmark diversity. We\nrelease this benchmark through EvalAI. this http URL",
    "descriptor": "",
    "authors": [
      "Felix Pei",
      "Joel Ye",
      "David Zoltowski",
      "Anqi Wu",
      "Raeed H. Chowdhury",
      "Hansem Sohn",
      "Joseph E. O'Doherty",
      "Krishna V. Shenoy",
      "Matthew T. Kaufman",
      "Mark Churchland",
      "Mehrdad Jazayeri",
      "Lee E. Miller",
      "Jonathan Pillow",
      "Il Memming Park",
      "Eva L. Dyer",
      "Chethan Pandarinath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.04463"
  },
  {
    "id": "arXiv:2109.04467",
    "title": "Mining Points of Interest via Address Embeddings: An Unsupervised  Approach",
    "abstract": "Digital maps are commonly used across the globe for exploring places that\nusers are interested in, commonly referred to as points of interest (PoI). In\nonline food delivery platforms, PoIs could represent any major private\ncompounds where customers could order from such as hospitals, residential\ncomplexes, office complexes, educational institutes and hostels. In this work,\nwe propose an end-to-end unsupervised system design for obtaining polygon\nrepresentations of PoIs (PoI polygons) from address locations and address\ntexts. We preprocess the address texts using locality names and generate\nembeddings for the address texts using a deep learning-based architecture, viz.\nRoBERTa, trained on our internal address dataset. The PoI candidates are\nidentified by jointly clustering the anonymised customer phone GPS locations\n(obtained during address onboarding) and the embeddings of the address texts.\nThe final list of PoI polygons is obtained from these PoI candidates using\nnovel post-processing steps. This algorithm identified 74.8 % more PoIs than\nthose obtained using the Mummidi-Krumm baseline algorithm run on our internal\ndataset. The proposed algorithm achieves a median area precision of 98 %, a\nmedian area recall of 8 %, and a median F-score of 0.15. In order to improve\nthe recall of the algorithmic polygons, we post-process them using building\nfootprint polygons from the OpenStreetMap (OSM) database. The post-processing\nalgorithm involves reshaping the algorithmic polygon using intersecting\npolygons and closed private roads from the OSM database, and accounting for\nintersection with public roads on the OSM database. We achieve a median area\nrecall of 70 %, a median area precision of 69 %, and a median F-score of 0.69\non these post-processed polygons.",
    "descriptor": "\nComments: 18 pages, single column\n",
    "authors": [
      "Abhinav Ganesan",
      "Anubhav Gupta",
      "Jose Mathew"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.04467"
  },
  {
    "id": "arXiv:2109.04468",
    "title": "Leveraging Local Domains for Image-to-Image Translation",
    "abstract": "Image-to-image (i2i) networks struggle to capture local changes because they\ndo not affect the global scene structure. For example, translating from highway\nscenes to offroad, i2i networks easily focus on global color features but\nignore obvious traits for humans like the absence of lane markings. In this\npaper, we leverage human knowledge about spatial domain characteristics which\nwe refer to as 'local domains' and demonstrate its benefit for image-to-image\ntranslation. Relying on a simple geometrical guidance, we train a patch-based\nGAN on few source data and hallucinate a new unseen domain which subsequently\neases transfer learning to target. We experiment on three tasks ranging from\nunstructured environments to adverse weather. Our comprehensive evaluation\nsetting shows we are able to generate realistic translations, with minimal\npriors, and training only on a few images. Furthermore, when trained on our\ntranslations images we show that all tested proxy tasks are significantly\nimproved, without ever seeing target domain at training.",
    "descriptor": "\nComments: Submitted to conference\n",
    "authors": [
      "Anthony Dell'Eva",
      "Fabio Pizzati",
      "Massimo Bertozzi",
      "Raoul de Charette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04468"
  },
  {
    "id": "arXiv:2109.03866",
    "title": "Learning the hypotheses space from data through a U-curve algorithm: a  statistically consistent complexity regularizer for Model Selection",
    "abstract": "This paper proposes a data-driven systematic, consistent and non-exhaustive\napproach to Model Selection, that is an extension of the classical agnostic PAC\nlearning model. In this approach, learning problems are modeled not only by a\nhypothesis space $\\mathcal{H}$, but also by a Learning Space\n$\\mathbb{L}(\\mathcal{H})$, a poset of subspaces of $\\mathcal{H}$, which covers\n$\\mathcal{H}$ and satisfies a property regarding the VC dimension of related\nsubspaces, that is a suitable algebraic search space for Model Selection\nalgorithms. Our main contributions are a data-driven general learning algorithm\nto perform regularized Model Selection on $\\mathbb{L}(\\mathcal{H})$ and a\nframework under which one can, theoretically, better estimate a target\nhypothesis with a given sample size by properly modeling\n$\\mathbb{L}(\\mathcal{H})$ and employing high computational power. A remarkable\nconsequence of this approach are conditions under which a non-exhaustive search\nof $\\mathbb{L}(\\mathcal{H})$ can return an optimal solution. The results of\nthis paper lead to a practical property of Machine Learning, that the lack of\nexperimental data may be mitigated by a high computational capacity. In a\ncontext of continuous popularization of computational power, this property may\nhelp understand why Machine Learning has become so important, even where data\nis expensive and hard to get.",
    "descriptor": "\nComments: This is work is a merger of arXiv:2001.09532 and arXiv:2001.11578\n",
    "authors": [
      "Diego Marcondes",
      "Adilson Simonis",
      "Junior Barrera"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03866"
  },
  {
    "id": "arXiv:2109.03874",
    "title": "Initialization for Nonnegative Matrix Factorization: a Comprehensive  Review",
    "abstract": "Non-negative matrix factorization (NMF) has become a popular method for\nrepresenting meaningful data by extracting a non-negative basis feature from an\nobserved non-negative data matrix. Some of the unique features of this method\nin identifying hidden data put this method amongst the powerful methods in the\nmachine learning area. The NMF is a known non-convex optimization problem and\nthe initial point has a significant effect on finding an efficient local\nsolution. In this paper, we investigate the most popular initialization\nprocedures proposed for NMF so far. We describe each method and present some of\ntheir advantages and disadvantages. Finally, some numerical results to\nillustrate the performance of each algorithm are presented.",
    "descriptor": "",
    "authors": [
      "Sajad Fathi Hafshejani",
      "Zahra Moaberfard"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03874"
  },
  {
    "id": "arXiv:2109.03882",
    "title": "On the estimation of discrete choice models to capture irrational  customer behaviors",
    "abstract": "The Random Utility Maximization model is by far the most adopted framework to\nestimate consumer choice behavior. However, behavioral economics has provided\nstrong empirical evidence of irrational choice behavior, such as halo effects,\nthat are incompatible with this framework. Models belonging to the Random\nUtility Maximization family may therefore not accurately capture such\nirrational behavior. Hence, more general choice models, overcoming such\nlimitations, have been proposed. However, the flexibility of such models comes\nat the price of increased risk of overfitting. As such, estimating such models\nremains a challenge. In this work, we propose an estimation method for the\nrecently proposed Generalized Stochastic Preference choice model, which\nsubsumes the family of Random Utility Maximization models and is capable of\ncapturing halo effects. Specifically, we show how to use partially-ranked\npreferences to efficiently model rational and irrational customer types from\ntransaction data. Our estimation procedure is based on column generation, where\nrelevant customer types are efficiently extracted by expanding a tree-like data\nstructure containing the customer behaviors. Further, we propose a new\ndominance rule among customer types whose effect is to prioritize low orders of\ninteractions among products. An extensive set of experiments assesses the\npredictive accuracy of the proposed approach. Our results show that accounting\nfor irrational preferences can boost predictive accuracy by 12.5% on average,\nwhen tested on a real-world dataset from a large chain of grocery and drug\nstores.",
    "descriptor": "",
    "authors": [
      "Sanjay Dominik Jena",
      "Andrea Lodi",
      "Claudio Sole"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.03882"
  },
  {
    "id": "arXiv:2109.03900",
    "title": "Machine learning modeling of family wide enzyme-substrate specificity  screens",
    "abstract": "Biocatalysis is a promising approach to sustainably synthesize\npharmaceuticals, complex natural products, and commodity chemicals at scale.\nHowever, the adoption of biocatalysis is limited by our ability to select\nenzymes that will catalyze their natural chemical transformation on non-natural\nsubstrates. While machine learning and in silico directed evolution are\nwell-posed for this predictive modeling challenge, efforts to date have\nprimarily aimed to increase activity against a single known substrate, rather\nthan to identify enzymes capable of acting on new substrates of interest. To\naddress this need, we curate 6 different high-quality enzyme family screens\nfrom the literature that each measure multiple enzymes against multiple\nsubstrates. We compare machine learning-based compound-protein interaction\n(CPI) modeling approaches from the literature used for predicting drug-target\ninteractions. Surprisingly, comparing these interaction-based models against\ncollections of independent (single task) enzyme-only or substrate-only models\nreveals that current CPI approaches are incapable of learning interactions\nbetween compounds and proteins in the current family level data regime. We\nfurther validate this observation by demonstrating that our no-interaction\nbaseline can outperform CPI-based models from the literature used to guide the\ndiscovery of kinase inhibitors. Given the high performance of non-interaction\nbased models, we introduce a new structure-based strategy for pooling residue\nrepresentations across a protein sequence. Altogether, this work motivates a\nprincipled path forward in order to build and evaluate meaningful predictive\nmodels for biocatalysis and other drug discovery applications.",
    "descriptor": "",
    "authors": [
      "Samuel Goldman",
      "Ria Das",
      "Kevin K. Yang",
      "Connor W. Coley"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03900"
  },
  {
    "id": "arXiv:2109.03902",
    "title": "Simplified Quantum Algorithm for the Oracle Identification Problem",
    "abstract": "In the oracle identification problem we have oracle access to bits of an\nunknown string $x$ of length $n$, with the promise that it belongs to a known\nset $C\\subseteq\\{0,1\\}^n$. The goal is to identify $x$ using as few queries to\nthe oracle as possible. We develop a quantum query algorithm for this problem\nwith query complexity $O\\left(\\sqrt{\\frac{n\\log M }{\\log(n/\\log M)+1}}\\right)$,\nwhere $M$ is the size of $C$. This bound is already derived by Kothari in 2014,\nfor which we provide a more elegant simpler proof.",
    "descriptor": "\nComments: 7 pages, 3 images\n",
    "authors": [
      "Leila Taghavi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03902"
  },
  {
    "id": "arXiv:2109.03930",
    "title": "Matrix Completion of World Trade",
    "abstract": "This work applies Matrix Completion (MC) -- a class of machine-learning\nmethods commonly used in the context of recommendation systems -- to analyse\neconomic complexity. MC is applied to reconstruct the Revealed Comparative\nAdvantage (RCA) matrix, whose elements express the relative advantage of\ncountries in given classes of products, as evidenced by yearly trade flows. A\nhigh-accuracy binary classifier is derived from the application of MC, with the\naim of discriminating between elements of the RCA matrix that are,\nrespectively, higher or lower than one. We introduce a novel Matrix cOmpletion\niNdex of Economic complexitY (MONEY) based on MC, which is related to the\npredictability of countries' RCA (the lower the predictability, the higher the\ncomplexity). Differently from previously-developed indices of economic\ncomplexity, the MONEY index takes into account the various singular vectors of\nthe matrix reconstructed by MC, whereas other indices are based only on one/two\neigenvectors of a suitable symmetric matrix, derived from the RCA matrix.\nFinally, MC is compared with a state-of-the-art economic complexity index\n(GENEPY). We show that the false positive rate per country of a binary\nclassifier constructed starting from the average entry-wise output of MC can be\nused as a proxy of GENEPY.",
    "descriptor": "\nComments: The main paper contains 11 pages with the Appendix. Supplemental material is also reported\n",
    "authors": [
      "Gnecco Giorgio",
      "Nutarelli Federico",
      "Riccaboni Massimo"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03930"
  },
  {
    "id": "arXiv:2109.03943",
    "title": "Sharp regret bounds for empirical Bayes and compound decision problems",
    "abstract": "We consider the classical problems of estimating the mean of an\n$n$-dimensional normally (with identity covariance matrix) or Poisson\ndistributed vector under the squared loss. In a Bayesian setting the optimal\nestimator is given by the prior-dependent conditional mean. In a frequentist\nsetting various shrinkage methods were developed over the last century. The\nframework of empirical Bayes, put forth by Robbins (1956), combines Bayesian\nand frequentist mindsets by postulating that the parameters are independent but\nwith an unknown prior and aims to use a fully data-driven estimator to compete\nwith the Bayesian oracle that knows the true prior. The central figure of merit\nis the regret, namely, the total excess risk over the Bayes risk in the worst\ncase (over the priors). Although this paradigm was introduced more than 60\nyears ago, little is known about the asymptotic scaling of the optimal regret\nin the nonparametric setting.\nWe show that for the Poisson model with compactly supported and\nsubexponential priors, the optimal regret scales as $\\Theta((\\frac{\\log\nn}{\\log\\log n})^2)$ and $\\Theta(\\log^3 n)$, respectively, both attained by the\noriginal estimator of Robbins. For the normal mean model, the regret is shown\nto be at least $\\Omega((\\frac{\\log n}{\\log\\log n})^2)$ and $\\Omega(\\log^2 n)$\nfor compactly supported and subgaussian priors, respectively, the former of\nwhich resolves the conjecture of Singh (1979) on the impossibility of achieving\nbounded regret; before this work, the best regret lower bound was $\\Omega(1)$.\n%Analogous results for subgaussian or subexponential priors are also obtained.\nIn addition to the empirical Bayes setting, these results are shown to hold in\nthe compound setting where the parameters are deterministic. As a side\napplication, the construction in this paper also leads to improved or new lower\nbounds for mixture density estimation.",
    "descriptor": "",
    "authors": [
      "Yury Polyanskiy",
      "Yihong Wu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.03943"
  },
  {
    "id": "arXiv:2109.03946",
    "title": "Quantitative form of Ball's Cube slicing in $\\mathbb{R}^n$ and equality  cases in the min-entropy power inequality",
    "abstract": "We prove a quantitative form of the celebrated Ball's theorem on cube slicing\nin $\\mathbb{R}^n$ and obtain, as a consequence, equality cases in the\nmin-entropy power inequality. Independently, we also give a quantitative form\nof Khintchine's inequality in the special case $p=1$.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "James Melbourne",
      "Cyril Roberto"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2109.03946"
  },
  {
    "id": "arXiv:2109.03973",
    "title": "Iterated Vector Fields and Conservatism, with Applications to Federated  Learning",
    "abstract": "We study iterated vector fields and investigate whether they are\nconservative, in the sense that they are the gradient of some scalar-valued\nfunction. We analyze the conservatism of various iterated vector fields,\nincluding gradient vector fields associated to loss functions of generalized\nlinear models. We relate this study to optimization and derive novel\nconvergence results for federated learning algorithms. In particular, we show\nthat for certain classes of functions (including non-convex functions),\nfederated averaging is equivalent to gradient descent on a surrogate loss\nfunction. Finally, we discuss a variety of open questions spanning topics in\ngeometry, dynamical systems, and optimization.",
    "descriptor": "",
    "authors": [
      "Zachary Charles",
      "Keith Rush"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2109.03973"
  },
  {
    "id": "arXiv:2109.03974",
    "title": "Constants of Motion: The Antidote to Chaos in Optimization and Game  Dynamics",
    "abstract": "Several recent works in online optimization and game dynamics have\nestablished strong negative complexity results including the formal emergence\nof instability and chaos even in small such settings, e.g., $2\\times 2$ games.\nThese results motivate the following question: Which methodological tools can\nguarantee the regularity of such dynamics and how can we apply them in standard\nsettings of interest such as discrete-time first-order optimization dynamics?\nWe show how proving the existence of invariant functions, i.e., constant of\nmotions, is a fundamental contribution in this direction and establish a\nplethora of such positive results (e.g. gradient descent, multiplicative\nweights update, alternating gradient descent and manifold gradient descent)\nboth in optimization as well as in game settings. At a technical level, for\nsome conservation laws we provide an explicit and concise closed form, whereas\nfor other ones we present non-constructive proofs using tools from dynamical\nsystems.",
    "descriptor": "",
    "authors": [
      "Georgios Piliouras",
      "Xiao Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03974"
  },
  {
    "id": "arXiv:2109.04001",
    "title": "Deep Reinforcement Learning for Equal Risk Pricing and Hedging under  Dynamic Expectile Risk Measures",
    "abstract": "Recently equal risk pricing, a framework for fair derivative pricing, was\nextended to consider dynamic risk measures. However, all current\nimplementations either employ a static risk measure that violates time\nconsistency, or are based on traditional dynamic programming solution schemes\nthat are impracticable in problems with a large number of underlying assets\n(due to the curse of dimensionality) or with incomplete asset dynamics\ninformation. In this paper, we extend for the first time a famous off-policy\ndeterministic actor-critic deep reinforcement learning (ACRL) algorithm to the\nproblem of solving a risk averse Markov decision process that models risk using\na time consistent recursive expectile risk measure. This new ACRL algorithm\nallows us to identify high quality time consistent hedging policies (and equal\nrisk prices) for options, such as basket options, that cannot be handled using\ntraditional methods, or in context where only historical trajectories of the\nunderlying assets are available. Our numerical experiments, which involve both\na simple vanilla option and a more exotic basket option, confirm that the new\nACRL algorithm can produce 1) in simple environments, nearly optimal hedging\npolicies, and highly accurate prices, simultaneously for a range of maturities\n2) in complex environments, good quality policies and prices using reasonable\namount of computing resources; and 3) overall, hedging strategies that actually\noutperform the strategies produced using static risk measures when the risk is\nevaluated at later points of time.",
    "descriptor": "",
    "authors": [
      "Saeed Marzban",
      "Erick Delage",
      "Jonathan Yumeng Li"
    ],
    "subjectives": [
      "Pricing of Securities (q-fin.PR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04001"
  },
  {
    "id": "arXiv:2109.04007",
    "title": "MaterialsAtlas.org: A Materials Informatics Web App Platform for  Materials Discovery and Survey of State-of-the-Art",
    "abstract": "The availability and easy access of large scale experimental and\ncomputational materials data have enabled the emergence of accelerated\ndevelopment of algorithms and models for materials property prediction,\nstructure prediction, and generative design of materials. However, lack of\nuser-friendly materials informatics web servers has severely constrained the\nwide adoption of such tools in the daily practice of materials screening,\ntinkering, and design space exploration by materials scientists. Herein we\nfirst survey current materials informatics web apps and then propose and\ndevelop MaterialsAtlas.org, a web based materials informatics toolbox for\nmaterials discovery, which includes a variety of routinely needed tools for\nexploratory materials discovery, including materials composition and structure\ncheck (e.g. for neutrality, electronegativity balance, dynamic stability,\nPauling rules), materials property prediction (e.g. band gap, elastic moduli,\nhardness, thermal conductivity), and search for hypothetical materials. These\nuser-friendly tools can be freely accessed at \\url{www.materialsatlas.org}. We\nargue that such materials informatics apps should be widely developed by the\ncommunity to speed up the materials discovery processes.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jianjun Hu",
      "Stanislav Stefanov",
      "Yuqi Song",
      "Sadman Sadeed Omee",
      "Steph-Yves Louis",
      "Edirisuriya M. D. Siriwardane",
      "Yong Zhao"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04007"
  },
  {
    "id": "arXiv:2109.04010",
    "title": "Popularity Adjusted Block Models are Generalized Random Dot Product  Graphs",
    "abstract": "We connect two random graph models, the Popularity Adjusted Block Model\n(PABM) and the Generalized Random Dot Product Graph (GRDPG), by demonstrating\nthat the PABM is a special case of the GRDPG in which communities correspond to\nmutually orthogonal subspaces of latent vectors. This insight allows us to\nconstruct new algorithms for community detection and parameter estimation for\nthe PABM, as well as improve an existing algorithm that relies on Sparse\nSubspace Clustering. Using established asymptotic properties of Adjacency\nSpectral Embedding for the GRDPG, we derive asymptotic properties of these\nalgorithms. In particular, we demonstrate that the absolute number of community\ndetection errors tends to zero as the number of graph vertices tends to\ninfinity. Simulation experiments illustrate these properties.",
    "descriptor": "\nComments: 33 pages, 7 figures\n",
    "authors": [
      "John Koo",
      "Minh Tang",
      "Michael W. Trosset"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04010"
  },
  {
    "id": "arXiv:2109.04052",
    "title": "Continuum limits for discrete Dirac operators on 2D square lattices",
    "abstract": "We discuss the continuum limit of discrete Dirac operators on the square\nlattice in $\\mathbb R^2$ as the mesh size tends to zero. To this end, we\npropose a natural and simple embedding of $\\ell^2(\\mathbb Z_h^d)$ into\n$L^2(\\mathbb R^d)$ that enables us to compare the discrete Dirac operators with\nthe continuum Dirac operators in the same Hilbert space $L^2(\\mathbb R^2)^2$.\nIn particular, we prove strong resolvent convergence. Potentials are assumed to\nbe bounded and uniformly continuous functions on $\\mathbb R^2$ and allowed to\nbe complex matrix-valued.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Karl Michael Schmidt",
      "Tomio Umeda"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.04052"
  },
  {
    "id": "arXiv:2109.04070",
    "title": "The IDLAB VoxCeleb Speaker Recognition Challenge 2021 System Description",
    "abstract": "This technical report describes the IDLab submission for track 1 and 2 of the\nVoxCeleb Speaker Recognition Challenge 2021 (VoxSRC-21). This speaker\nverification competition focuses on short duration test recordings and\ncross-lingual trials. Currently, both Time Delay Neural Networks (TDNNs) and\nResNets achieve state-of-the-art results in speaker verification. We opt to use\na system fusion of hybrid architectures in our final submission. An ECAPA-TDNN\nbaseline is enhanced with a 2D convolutional stem to transfer some of the\nstrong characteristics of a ResNet based model to this hybrid CNN-TDNN\narchitecture. Similarly, we incorporate absolute frequency positional\ninformation in the SE-ResNet architectures. All models are trained with a\nspecial mini-batch data sampling technique which constructs mini-batches with\ndata that is the most challenging for the system on the level of intra-speaker\nvariability. This intra-speaker variability is mainly caused by differences in\nlanguage and background conditions between the speaker's utterances. The\ncross-lingual effects on the speaker verification scores are further\ncompensated by introducing a binary cross-linguality trial feature in the\nlogistic regression based system calibration. The final system fusion with two\nECAPA CNN-TDNNs and three SE-ResNets enhanced with frequency positional\ninformation achieved a third place on the VoxSRC-21 leaderboard for both track\n1 and 2 with a minDCF of 0.1291 and 0.1313 respectively.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.02370\n",
    "authors": [
      "Jenthe Thienpondt",
      "Brecht Desplanques",
      "Kris Demuynck"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.04070"
  },
  {
    "id": "arXiv:2109.04141",
    "title": "Nonlocal reaction traffic flow model with on-off ramps",
    "abstract": "We present a non-local version of a scalar balance law modeling traffic flow\nwith on-ramps and off-ramps. The source term is used to describe the traffic\nflow over the on-ramp and off-ramps. We approximate the problem using an\nupwind-type numerical scheme and we provide L^\\infty and BV estimates for the\nsequence of approximate solutions. Together with a discrete entropy inequality,\nwe also show the well-posedness of the considered class of scalar balance laws.\nSome numerical simulations illustrate the behaviour of solutions in sample\ncases.",
    "descriptor": "",
    "authors": [
      "F. A. Chiarello",
      "H. D. Contreras",
      "L. M. Villada"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04141"
  },
  {
    "id": "arXiv:2109.04179",
    "title": "Optimal Mapping for Near-Term Quantum Architectures based on Rydberg  Atoms",
    "abstract": "Quantum algorithms promise quadratic or exponential speedups for applications\nin cryptography, chemistry and material sciences. The topologies of today's\nquantum computers offer limited connectivity, leading to significant overheads\nfor implementing such quantum algorithms. One-dimensional topology\ndisplacements that remedy these limits have been recently demonstrated for\narchitectures based on Rydberg atoms, and they are possible in principle in\nphotonic and ion trap architectures. We present the first optimal quantum\ncircuit-to-architecture mapping algorithm that exploits such one-dimensional\ntopology displacements. We benchmark our method on quantum circuits with up to\n15 qubits and investigate the improvements compared with conventional mapping\nbased on inserting swap gates into the quantum circuits. Depending on\nunderlying technology parameters, our approach can decrease the quantum circuit\ndepth by up to 58% and increase the fidelity by up to 29%. We also study\nruntime and fidelity requirements on one-dimensional displacements and swap\ngates to derive conditions under which one-dimensional topology displacements\nprovide benefits.",
    "descriptor": "\nComments: to appear in ICCAD'21\n",
    "authors": [
      "Sebastian Brandhofer",
      "Hans Peter B\u00fcchler",
      "Ilia Polian"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2109.04179"
  },
  {
    "id": "arXiv:2109.04188",
    "title": "Towards Fully Automated Segmentation of Rat Cardiac MRI by Leveraging  Deep Learning Frameworks",
    "abstract": "Automated segmentation of human cardiac magnetic resonance datasets has been\nsteadily improving during recent years. However, these methods are not directly\napplicable in preclinical context due to limited datasets and lower image\nresolution. Successful application of deep architectures for rat cardiac\nsegmentation, although of critical importance for preclinical evaluation of\ncardiac function, has to our knowledge not yet been reported. We developed\nsegmentation models that expand on the standard U-Net architecture and\nevaluated separate models for systole and diastole phases, 2MSA, and one model\nfor all timepoints, 1MSA. Furthermore, we calibrated model outputs using a\nGaussian Process (GP)-based prior to improve phase selection. Resulting models\napproach human performance in terms of left ventricular segmentation quality\nand ejection fraction (EF) estimation in both 1MSA and 2MSA settings\n(S{\\o}rensen-Dice score 0.91 +/- 0.072 and 0.93 +/- 0.032, respectively). 2MSA\nachieved a mean absolute difference between estimated and reference EF of 3.5\n+/- 2.5 %, while 1MSA resulted in 4.1 +/- 3.0 %. Applying Gaussian Processes to\n1MSA allows to automate the selection of systole and diastole phases. Combined\nwith a novel cardiac phase selection strategy, our work presents an important\nfirst step towards a fully automated segmentation pipeline in the context of\nrat cardiac analysis.",
    "descriptor": "\nComments: 29 pages + 22 pages (supplementary information), 8 figures + 8 supplementary figures\n",
    "authors": [
      "Daniel Fernandez-Llaneza",
      "Andrea Gondova",
      "Harris Vince",
      "Arijit Patra",
      "Magdalena Zurek",
      "Peter Konings",
      "Patrik Kagelid",
      "Leif Hultin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04188"
  },
  {
    "id": "arXiv:2109.04192",
    "title": "Detection of Abrupt Change in Channel Covariance Matrix for  Multi-Antenna Communication",
    "abstract": "The knowledge of channel covariance matrices is of paramount importance to\nthe estimation of instantaneous channels and the design of beamforming vectors\nin multi-antenna systems. In practice, an abrupt change in channel covariance\nmatrices may occur due to the change in the environment and the user location.\nAlthough several works have proposed efficient algorithms to estimate the\nchannel covariance matrices after any change occurs, how to detect such a\nchange accurately and quickly is still an open problem in the literature. In\nthis paper, we focus on channel covariance change detection between a\nmulti-antenna base station (BS) and a single-antenna user equipment (UE). To\nprovide theoretical performance limit, we first propose a genie-aided change\ndetector based on the log-likelihood ratio (LLR) test assuming the channel\ncovariance matrix after change is known, and characterize the corresponding\nmissed detection and false alarm probabilities. Then, this paper considers the\npractical case where the channel covariance matrix after change is unknown. The\nmaximum likelihood (ML) estimation technique is used to predict the covariance\nmatrix based on the received pilot signals over a certain number of coherence\nblocks, building upon which the LLR-based change detector is employed.\nNumerical results show that our proposed scheme can detect the change with low\nerror probability even when the number of channel samples is small such that\nthe estimation of the covariance matrix is not that accurate. This result\nverifies the possibility to detect the channel covariance change both\naccurately and quickly in practice.",
    "descriptor": "\nComments: accepted by Globecom 2021\n",
    "authors": [
      "Runnan Liu",
      "Liang Liu",
      "Dazhi He",
      "Wenjun Zhang",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.04192"
  },
  {
    "id": "arXiv:2109.04202",
    "title": "IMG2SMI: Translating Molecular Structure Images to Simplified  Molecular-input Line-entry System",
    "abstract": "Like many scientific fields, new chemistry literature has grown at a\nstaggering pace, with thousands of papers released every month. A large portion\nof chemistry literature focuses on new molecules and reactions between\nmolecules. Most vital information is conveyed through 2-D images of molecules,\nrepresenting the underlying molecules or reactions described. In order to\nensure reproducible and machine-readable molecule representations, text-based\nmolecule descriptors like SMILES and SELFIES were created. These text-based\nmolecule representations provide molecule generation but are unfortunately\nrarely present in published literature. In the absence of molecule descriptors,\nthe generation of molecule descriptors from the 2-D images present in the\nliterature is necessary to understand chemistry literature at scale. Successful\nmethods such as Optical Structure Recognition Application (OSRA), and\nChemSchematicResolver are able to extract the locations of molecules structures\nin chemistry papers and infer molecular descriptions and reactions. While\neffective, existing systems expect chemists to correct outputs, making them\nunsuitable for unsupervised large-scale data mining. Leveraging the task\nformulation of image captioning introduced by DECIMER, we introduce IMG2SMI, a\nmodel which leverages Deep Residual Networks for image feature extraction and\nan encoder-decoder Transformer layers for molecule description generation.\nUnlike previous Neural Network-based systems, IMG2SMI builds around the task of\nmolecule description generation, which enables IMG2SMI to outperform OSRA-based\nsystems by 163% in molecule similarity prediction as measured by the molecular\nMACCS Fingerprint Tanimoto Similarity. Additionally, to facilitate further\nresearch on this task, we release a new molecule prediction dataset. including\n81 million molecules for molecule description generation",
    "descriptor": "",
    "authors": [
      "Daniel Campos",
      "Heng Ji"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.04202"
  },
  {
    "id": "arXiv:2109.04204",
    "title": "An optimal decision support framework for vaccine distribution across a  multi-tier cold chain network",
    "abstract": "The importance of vaccination and the logistics involved in the procurement,\nstorage and distribution of vaccines across their cold chain has come to the\nforefront during the COVID-19 pandemic. In this paper, we present a decision\nsupport framework for optimizing multiple aspects of vaccine distribution\nacross a multi-tier cold chain network. We propose two multi-period\noptimization formulations within this framework: first to minimize inventory,\nordering, transportation, personnel and shortage costs associated with a single\nvaccine; the second being an extension of the first for the case when multiple\nvaccines with differing efficacies and costs are available for the same\ndisease. Vaccine transportation and administration lead times are also\nincorporated within the models. We use the case of the Indian state of Bihar\nand COVID-19 vaccines to illustrate the implementation of the framework. We\npresent computational experiments to demonstrate: (a) the organization of the\nmodel outputs; (b) how the models can be used to assess the impact of storage\ncapacities at the cold chain points, transportation vehicle capacities, and\nmanufacturer capacities on the optimal vaccine distribution pattern; and (c)\nthe impact of vaccine efficacies and associated costs such as ordering and\ntransportation costs on the vaccine selection decision informed by the model.\nWe then consider the computational expense of the framework for realistic\nproblem instances, and suggest multiple preprocessing techniques to reduce\ntheir computational burden. Our study presents public health authorities and\nother stakeholders with a vaccine distribution and capacity planning tool for\nmulti-tier cold chain networks.",
    "descriptor": "",
    "authors": [
      "Shanmukhi Sripada",
      "Ayush Jain",
      "Prasanna Ramamoorthy",
      "Varun Ramamohan"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04204"
  },
  {
    "id": "arXiv:2109.04228",
    "title": "Coordinate Descent Methods for DC Minimization",
    "abstract": "Difference-of-Convex (DC) minimization, referring to the problem of\nminimizing the difference of two convex functions, has been found rich\napplications in statistical learning and studied extensively for decades.\nHowever, existing methods are primarily based on multi-stage convex relaxation,\nonly leading to weak optimality of critical points. This paper proposes a\ncoordinate descent method for minimizing DC functions based on sequential\nnonconvex approximation. Our approach iteratively solves a nonconvex\none-dimensional subproblem globally, and it is guaranteed to converge to a\ncoordinate-wise stationary point. We prove that this new optimality condition\nis always stronger than the critical point condition and the directional point\ncondition when the objective function is weakly convex. For comparisons, we\nalso include a naive variant of coordinate descent methods based on sequential\nconvex approximation in our study. When the objective function satisfies an\nadditional regularity condition called \\emph{sharpness}, coordinate descent\nmethods with an appropriate initialization converge \\emph{linearly} to the\noptimal solution set. Also, for many applications of interest, we show that the\nnonconvex one-dimensional subproblem can be computed exactly and efficiently\nusing a breakpoint searching method. We present some discussions and extensions\nof our proposed method. Finally, we have conducted extensive experiments on\nseveral statistical learning tasks to show the superiority of our approach.\nKeywords: Coordinate Descent, DC Minimization, DC Programming,\nDifference-of-Convex Programs, Nonconvex Optimization, Sparse Optimization,\nBinary Optimization.",
    "descriptor": "",
    "authors": [
      "Ganzhao Yuan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04228"
  },
  {
    "id": "arXiv:2109.04235",
    "title": "EEGDnet: Fusing Non-Local and Local Self-Similarity for 1-D EEG Signal  Denoising with 2-D Transformer",
    "abstract": "Electroencephalogram (EEG) has shown a useful approach to produce a\nbrain-computer interface (BCI). One-dimensional (1-D) EEG signal is yet easily\ndisturbed by certain artifacts (a.k.a. noise) due to the high temporal\nresolution. Thus, it is crucial to remove the noise in received EEG signal.\nRecently, deep learning-based EEG signal denoising approaches have achieved\nimpressive performance compared with traditional ones. It is well known that\nthe characteristics of self-similarity (including non-local and local ones) of\ndata (e.g., natural images and time-domain signals) are widely leveraged for\ndenoising. However, existing deep learning-based EEG signal denoising methods\nignore either the non-local self-similarity (e.g., 1-D convolutional neural\nnetwork) or local one (e.g., fully connected network and recurrent neural\nnetwork). To address this issue, we propose a novel 1-D EEG signal denoising\nnetwork with 2-D transformer, namely EEGDnet. Specifically, we comprehensively\ntake into account the non-local and local self-similarity of EEG signal through\nthe transformer module. By fusing non-local self-similarity in self-attention\nblocks and local self-similarity in feed forward blocks, the negative impact\ncaused by noises and outliers can be reduced significantly. Extensive\nexperiments show that, compared with other state-of-the-art models, EEGDnet\nachieves much better performance in terms of both quantitative and qualitative\nmetrics.",
    "descriptor": "",
    "authors": [
      "Peng Yi",
      "Kecheng Chen",
      "Zhaoqi Ma",
      "Di Zhao",
      "Xiaorong Pu",
      "Yazhou Ren"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04235"
  },
  {
    "id": "arXiv:2109.04241",
    "title": "Robust single- and multi-loudspeaker least-squares-based equalization  for hearing devices",
    "abstract": "To improve the sound quality of hearing devices, equalization filters can be\nused that aim at achieving acoustic transparency, i.e., listening with the\ndevice in the ear is perceptually similar to the open ear. The equalization\nfilter needs to ensure that the superposition of the equalized signal played by\nthe device and the signal leaking through the device into the ear canal matches\na processed version of the signal reaching the eardrum of the open ear.\nDepending on the processing delay of the hearing device, comb-filtering\nartifacts can occur due to this superposition, which may degrade the perceived\nsound quality. In this paper we propose a unified least-squares-based procedure\nto design single- and multi-loudspeaker equalization filters for hearing\ndevices aiming at achieving acoustic transparency. To account for non-minimum\nphase components, we introduce a so-called acausality management. To reduce\ncomb-filtering artifacts, we propose to use a frequency-dependent\nregularization. Experimental results using measured acoustic transfer functions\nfrom a multi-loudspeaker earpiece show that the proposed equalization filter\ndesign procedure enables to achieve robust acoustic transparency and reduces\nthe impact of comb-filtering artifacts. A comparison between single- and\nmulti-loudspeaker equalization shows that for both cases a robust equalization\nperformance can be achieved for different desired open ear transfer functions.",
    "descriptor": "",
    "authors": [
      "Henning Schepker",
      "Florian Denk",
      "Birger Kollmeier",
      "Simon Doclo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.04241"
  },
  {
    "id": "arXiv:2109.04244",
    "title": "Supervised Linear Dimension-Reduction Methods: Review, Extensions, and  Comparisons",
    "abstract": "Principal component analysis (PCA) is a well-known linear dimension-reduction\nmethod that has been widely used in data analysis and modeling. It is an\nunsupervised learning technique that identifies a suitable linear subspace for\nthe input variable that contains maximal variation and preserves as much\ninformation as possible. PCA has also been used in prediction models where the\noriginal, high-dimensional space of predictors is reduced to a smaller, more\nmanageable, set before conducting regression analysis. However, this approach\ndoes not incorporate information in the response during the dimension-reduction\nstage and hence can have poor predictive performance. To address this concern,\nseveral supervised linear dimension-reduction techniques have been proposed in\nthe literature. This paper reviews selected techniques, extends some of them,\nand compares their performance through simulations. Two of these techniques,\npartial least squares (PLS) and least-squares PCA (LSPCA), consistently\noutperform the others in this study.",
    "descriptor": "",
    "authors": [
      "Shaojie Xu",
      "Joel Vaughan",
      "Jie Chen",
      "Agus Sudjianto",
      "Vijayan Nair"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04244"
  },
  {
    "id": "arXiv:2109.04261",
    "title": "Memory semantization through perturbed and adversarial dreaming",
    "abstract": "Classical theories of memory consolidation emphasize the importance of replay\nin extracting semantic information from episodic memories. However, the\ncharacteristic creative nature of dreams suggests that memory semantization may\ngo beyond merely replaying previous experiences. We propose that\nrapid-eye-movement (REM) dreaming is essential for efficient memory\nsemantization by randomly combining episodic memories to create new, virtual\nsensory experiences. We support this hypothesis by implementing a cortical\narchitecture with hierarchically organized feedforward and feedback pathways,\ninspired by generative adversarial networks (GANs). Learning in our model is\norganized across three different global brain states mimicking wakefulness,\nnon-REM (NREM) and REM sleep, optimizing different, but complementary objective\nfunctions. We train the model in an unsupervised fashion on standard datasets\nof natural images and evaluate the quality of the learned representations. Our\nresults suggest that adversarial dreaming during REM sleep is essential for\nextracting memory contents, while perturbed dreaming during NREM sleep improves\nrobustness of the latent representation to noisy sensory inputs. The model\nprovides a new computational perspective on sleep states, memory replay and\ndreams and suggests a cortical implementation of GANs.",
    "descriptor": "\nComments: 27 pages, 13 figures; ; Jakob Jordan and Walter Senn share senior authorship\n",
    "authors": [
      "Nicolas Deperrois",
      "Mihai A. Petrovici",
      "Walter Senn",
      "Jakob Jordan"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04261"
  },
  {
    "id": "arXiv:2109.04298",
    "title": "Quantum Machine Learning for Finance",
    "abstract": "Quantum computers are expected to surpass the computational capabilities of\nclassical computers during this decade, and achieve disruptive impact on\nnumerous industry sectors, particularly finance. In fact, finance is estimated\nto be the first industry sector to benefit from Quantum Computing not only in\nthe medium and long terms, but even in the short term. This review paper\npresents the state of the art of quantum algorithms for financial applications,\nwith particular focus to those use cases that can be solved via Machine\nLearning.",
    "descriptor": "",
    "authors": [
      "Marco Pistoia",
      "Syed Farhan Ahmad",
      "Akshay Ajagekar",
      "Alexander Buts",
      "Shouvanik Chakrabarti",
      "Dylan Herman",
      "Shaohan Hu",
      "Andrew Jena",
      "Pierre Minssen",
      "Pradeep Niroula",
      "Arthur Rattew",
      "Yue Sun",
      "Romina Yalovetzky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04298"
  },
  {
    "id": "arXiv:2109.04323",
    "title": "Adaptive importance sampling for seismic fragility curve estimation",
    "abstract": "As part of Probabilistic Risk Assessment studies, it is necessary to study\nthe fragility of mechanical and civil engineered structures when subjected to\nseismic loads. This risk can be measured with fragility curves, which express\nthe probability of failure of the structure conditionally to a seismic\nintensity measure. The estimation of fragility curves relies on time-consuming\nnumerical simulations, so that careful experimental design is required in order\nto gain the maximum information on the structure's fragility with a limited\nnumber of code evaluations. We propose and implement an active learning\nmethodology based on adaptive importance sampling in order to reduce the\nvariance of the training loss. The efficiency of the proposed method in terms\nof bias, standard deviation and prediction interval coverage are theoretically\nand numerically characterized.",
    "descriptor": "",
    "authors": [
      "Clement Gauchy",
      "Cyril Feau",
      "Josselin Garnier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.04323"
  },
  {
    "id": "arXiv:2109.04346",
    "title": "Goodness-of-Fit Testing for H\u00f6lder-Continuous Densities: Sharp Local  Minimax Rates",
    "abstract": "We consider the goodness-of fit testing problem for H\\\"older smooth densities\nover $\\mathbb{R}^d$: given $n$ iid observations with unknown density $p$ and\ngiven a known density $p_0$, we investigate how large $\\rho$ should be to\ndistinguish, with high probability, the case $p=p_0$ from the composite\nalternative of all H\\\"older-smooth densities $p$ such that $\\|p-p_0\\|_t \\geq\n\\rho$ where $t \\in [1,2]$. The densities are assumed to be defined over\n$\\mathbb{R}^d$ and to have H\\\"older smoothness parameter $\\alpha>0$. In the\npresent work, we solve the case $\\alpha \\leq 1$ and handle the case $\\alpha>1$\nusing an additional technical restriction on the densities. We identify\nmatching upper and lower bounds on the local minimax rates of testing, given\nexplicitly in terms of $p_0$. We propose novel test statistics which we believe\ncould be of independent interest. We also establish the first definition of an\nexplicit cutoff $u_B$ allowing us to split $\\mathbb{R}^d$ into a bulk part\n(defined as the subset of $\\mathbb{R}^d$ where $p_0$ takes only values greater\nthan or equal to $u_B$) and a tail part (defined as the complementary of the\nbulk), each part involving fundamentally different contributions to the local\nminimax rates of testing.",
    "descriptor": "\nComments: 76 pages\n",
    "authors": [
      "Julien Chhor",
      "Alexandra Carpentier"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.04346"
  },
  {
    "id": "arXiv:2109.04352",
    "title": "PhysGNN: A Physics-Driven Graph Neural Network Based Model for  Predicting Soft Tissue Deformation in Image-Guided Neurosurgery",
    "abstract": "Correctly capturing intraoperative brain shift in image-guided neurosurgical\nprocedures is a critical task for aligning preoperative data with\nintraoperative geometry, ensuring effective surgical navigation and optimal\nsurgical precision. While the finite element method (FEM) is a proven technique\nto effectively approximate soft tissue deformation through biomechanical\nformulations, their degree of success boils down to a trade-off between\naccuracy and speed. To circumvent this problem, the most recent works in this\ndomain have proposed leveraging data-driven models obtained by training various\nmachine learning algorithms, e.g. random forests, artificial neural networks\n(ANNs), with the results of finite element analysis (FEA) to speed up tissue\ndeformation approximations by prediction. These methods, however, do not\naccount for the structure of the finite element (FE) mesh during training that\nprovides information on node connectivities as well as the distance between\nthem, which can aid with approximating tissue deformation based on the\nproximity of force load points with the rest of the mesh nodes. Therefore, this\nwork proposes a novel framework, PhysGNN, a data-driven model that approximates\nthe solution of FEA by leveraging graph neural networks (GNNs), which are\ncapable of accounting for the mesh structural information and inductive\nlearning over unstructured grids and complex topological structures.\nEmpirically, we demonstrate that the proposed architecture, PhysGNN, promises\naccurate and fast soft tissue deformation approximations while remaining\ncomputationally feasible, suitable for neurosurgical settings.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yasmin Salehi",
      "Dennis Giannacopoulos"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04352"
  },
  {
    "id": "arXiv:2109.04355",
    "title": "Multi-sensor Joint Adaptive Birth Sampler for Labeled Random Finite Set  Tracking",
    "abstract": "This paper provides a scalable, multi-sensor measurement adaptive track\ninitiation technique for labeled random finite set filters. A naive\nconstruction of the multi-sensor measurement adaptive birth set leads to an\nexponential number of newborn components in the number of sensors. A truncation\ncriterion is established for a multi-sensor measurement-generated labeled\nmulti-Bernoulli random finite set that provably minimizes the L1-truncation\nerror in the generalized labeled multi-Bernoulli posterior distribution. This\ncriterion is used to construct a Gibbs sampler that produces a truncated\nmeasurement-generated labeled multi-Bernoulli birth distribution with quadratic\ncomplexity in the number of sensors. A closed form solution of the conditional\nsampling distribution assuming linear (or linearized) Gaussian likelihoods is\nprovided, alongside an approximate solution using Monte Carlo importance\nsampling. Multiple simulation results are provided to verify the efficacy of\nthe truncation criterion, as well as the reduction in complexity.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Signal Processing\n",
    "authors": [
      "Anthony Trezza",
      "Donald J. Bucci Jr.",
      "Pramod K. Varshney"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04355"
  },
  {
    "id": "arXiv:2109.04356",
    "title": "Assessing Machine Learning Approaches to Address IoT Sensor Drift",
    "abstract": "The proliferation of IoT sensors and their deployment in various industries\nand applications has brought about numerous analysis opportunities in this Big\nData era. However, drift of those sensor measurements poses major challenges to\nautomate data analysis and the ability to effectively train and deploy models\non a continuous basis. In this paper we study and test several approaches from\nthe literature with regard to their ability to cope with and adapt to sensor\ndrift under realistic conditions. Most of these approaches are recent and thus\nare representative of the current state-of-the-art. The testing was performed\non a publicly available gas sensor dataset exhibiting drift over time. The\nresults show substantial drops in sensing performance due to sensor drift in\nspite of the approaches. We then discuss several issues identified with current\napproaches and outline directions for future research to tackle them.",
    "descriptor": "\nComments: 6 pages, The 4th International Workshop on Artificial Intelligence of Things, In conjunction with the 27th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2021), Virtual conference, Aug. 14-18th\n",
    "authors": [
      "Haining Zheng",
      "Antonio Paiva"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.04356"
  },
  {
    "id": "arXiv:2109.04357",
    "title": "Rainbow-link: Beam-Alignment-Free and Grant-Free mmW Multiple Access  using True-Time-Delay Array",
    "abstract": "In this paper we propose a novel millimeter wave (mmW) multiple access method\nthat exploits unique frequency dependent beamforming capabilities of True Time\nDelay (TTD) array architecture. The proposed protocol combines a\ncontentionbased grant-free access and orthogonal frequency-division multiple\naccess (OFDMA) scheme for uplink machine type communications. By exploiting\nabundant time-frequency resource blocks in mmW spectrum, we design a simple\nprotocol that can achieve low collision rate and high network reliability for\nshort packets and sporadic transmissions. We analyze the impact of various\nsystem parameters on system performance during synchronization and contention\nperiod. We exploit unique advantages of frequency dependent beamforming,\nreferred as rainbow beam, to eliminate beam training overhead and analyze its\nimpact on rates, latency, and coverage. The proposed system and protocol can\nflexibly accommodate different low latency applications with moderate rate\nrequirements for a very large number of narrowband single antenna devices. By\nharnessing abundant resources in mmW spectrum and beamforming gain of TTD\narrays rainbow link based system can simultaneously satisfy ultra-reliability\nand massive multiple access requirements.",
    "descriptor": "",
    "authors": [
      "Ruifu Li",
      "Han Yan",
      "Danijela Cabric"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04357"
  },
  {
    "id": "arXiv:2109.04360",
    "title": "Measuring Uncertainty in Signal Fingerprinting with Gaussian Processes  Going Deep",
    "abstract": "In indoor positioning, signal fluctuation is highly location-dependent.\nHowever, signal uncertainty is one critical yet commonly overlooked dimension\nof the radio signal to be fingerprinted. This paper reviews the commonly used\nGaussian Processes (GP) for probabilistic positioning and points out the\npitfall of using GP to model signal fingerprint uncertainty. This paper also\nproposes Deep Gaussian Processes (DGP) as a more informative alternative to\naddress the issue. How DGP better measures uncertainty in signal fingerprinting\nis evaluated via simulated and realistically collected datasets.",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Ran Guan",
      "Andi Zhang",
      "Mengchao Li",
      "Yongliang Wang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04360"
  },
  {
    "id": "arXiv:2109.04361",
    "title": "MutualGraphNet: A novel model for motor imagery classification",
    "abstract": "Motor imagery classification is of great significance to humans with mobility\nimpairments, and how to extract and utilize the effective features from motor\nimagery electroencephalogram(EEG) channels has always been the focus of\nattention. There are many different methods for the motor imagery\nclassification, but the limited understanding on human brain requires more\neffective methods for extracting the features of EEG data. Graph neural\nnetworks(GNNs) have demonstrated its effectiveness in classifying graph\nstructures; and the use of GNN provides new possibilities for brain structure\nconnection feature extraction. In this paper we propose a novel graph neural\nnetwork based on the mutual information of the raw EEG channels called\nMutualGraphNet. We use the mutual information as the adjacency matrix combined\nwith the spatial temporal graph convolution network(ST-GCN) could extract the\ntransition rules of the motor imagery electroencephalogram(EEG) channels data\nmore effectively. Experiments are conducted on motor imagery EEG data set and\nwe compare our model with the current state-of-the-art approaches and the\nresults suggest that MutualGraphNet is robust enough to learn the interpretable\nfeatures and outperforms the current state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yan Li",
      "Ning Zhong",
      "David Taniar",
      "Haolan Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.04361"
  },
  {
    "id": "arXiv:2109.04364",
    "title": "Detection of Epileptic Seizures on EEG Signals Using ANFIS Classifier,  Autoencoders and Fuzzy Entropies",
    "abstract": "Epilepsy is one of the most crucial neurological disorders, and its early\ndiagnosis will help the clinicians to provide accurate treatment for the\npatients. The electroencephalogram (EEG) signals are widely used for epileptic\nseizures detection, which provides specialists with substantial information\nabout the functioning of the brain. In this paper, a novel diagnostic procedure\nusing fuzzy theory and deep learning techniques are introduced. The proposed\nmethod is evaluated on the Bonn University dataset with six classification\ncombinations and also on the Freiburg dataset. The tunable-Q wavelet transform\n(TQWT) is employed to decompose the EEG signals into different sub-bands. In\nthe feature extraction step, 13 different fuzzy entropies are calculated from\ndifferent sub-bands of TQWT, and their computational complexities are\ncalculated to help researchers choose the best feature sets. In the following,\nan autoencoder (AE) with six layers is employed for dimensionality reduction.\nFinally, the standard adaptive neuro-fuzzy inference system (ANFIS), and also\nits variants with grasshopper optimization algorithm (ANFIS-GOA), particle\nswarm optimization (ANFIS-PSO), and breeding swarm optimization (ANFIS-BS)\nmethods are used for classification. Using our proposed method, ANFIS-BS method\nhas obtained an accuracy of 99.74% in classifying into two classes and an\naccuracy of 99.46% in ternary classification on the Bonn dataset and 99.28% on\nthe Freiburg dataset, reaching state-of-the-art performances on both of them.",
    "descriptor": "",
    "authors": [
      "Afshin Shoeibi",
      "Navid Ghassemi",
      "Marjane Khodatars",
      "Parisa Moridian",
      "Roohallah Alizadehsani",
      "Assef Zare",
      "Abbas Khosravi",
      "Abdulhamit Subasi",
      "U. Rajendra Acharya",
      "J. Manuel Gorriz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04364"
  },
  {
    "id": "arXiv:2109.04392",
    "title": "Fair Conformal Predictors for Applications in Medical Imaging",
    "abstract": "Deep learning has the potential to augment many components of the clinical\nworkflow, such as medical image interpretation. However, the translation of\nthese black box algorithms into clinical practice has been marred by the\nrelative lack of transparency compared to conventional machine learning\nmethods, hindering in clinician trust in the systems for critical medical\ndecision-making. Specifically, common deep learning approaches do not have\nintuitive ways of expressing uncertainty with respect to cases that might\nrequire further human review. Furthermore, the possibility of algorithmic bias\nhas caused hesitancy regarding the use of developed algorithms in clinical\nsettings. To these ends, we explore how conformal methods can complement deep\nlearning models by providing both clinically intuitive way (by means of\nconfidence prediction sets) of expressing model uncertainty as well as\nfacilitating model transparency in clinical workflows. In this paper, we\nconduct a field survey with clinicians to assess clinical use-cases of\nconformal predictions. Next, we conduct experiments with a mammographic breast\ndensity and dermatology photography datasets to demonstrate the utility of\nconformal predictions in \"rule-in\" and \"rule-out\" disease scenarios. Further,\nwe show that conformal predictors can be used to equalize coverage with respect\nto patient demographics such as race and skin tone. We find that a conformal\npredictions to be a promising framework with potential to increase clinical\nusability and transparency for better collaboration between deep learning\nalgorithms and clinicians.",
    "descriptor": "",
    "authors": [
      "Charles Lu",
      "Andreanne Lemay",
      "Ken Chang",
      "Katharina Hoebel",
      "Jayashree Kalpathy-Cramer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04392"
  },
  {
    "id": "arXiv:2109.04405",
    "title": "An Accelerated Proximal Gradient-based Robust Model Predictive Control  Algorithm",
    "abstract": "In this letter, an accelerated robust model predictive control (RMPC)\nalgorithm for linear systems with additive disturbance is proposed based on the\ntube technique and the proximal gradient method. Our study consists of two\nparts. First, the tube cross sections are minimized in the RMPC objective,\nwhich make the description of the additive disturbance less conservative. Then,\nsuch RMPC problem is solved iteratively by a novel proximal gradient-based\nalgorithm, which can accelerate the iteration convergence rate. A case study\nand several numerical experiments are provided to show the effectiveness of the\nproposed approach.",
    "descriptor": "",
    "authors": [
      "Jia Wang",
      "Ying Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04405"
  },
  {
    "id": "arXiv:2109.04411",
    "title": "Non-autoregressive End-to-end Speech Translation with Parallel  Autoregressive Rescoring",
    "abstract": "This article describes an efficient end-to-end speech translation (E2E-ST)\nframework based on non-autoregressive (NAR) models. End-to-end speech\ntranslation models have several advantages over traditional cascade systems\nsuch as inference latency reduction. However, conventional AR decoding methods\nare not fast enough because each token is generated incrementally. NAR models,\nhowever, can accelerate the decoding speed by generating multiple tokens in\nparallel on the basis of the token-wise conditional independence assumption. We\npropose a unified NAR E2E-ST framework called Orthros, which has an NAR decoder\nand an auxiliary shallow AR decoder on top of the shared encoder. The auxiliary\nshallow AR decoder selects the best hypothesis by rescoring multiple candidates\ngenerated from the NAR decoder in parallel (parallel AR rescoring). We adopt\nconditional masked language model (CMLM) and a connectionist temporal\nclassification (CTC)-based model as NAR decoders for Orthros, referred to as\nOrthros-CMLM and Orthros-CTC, respectively. We also propose two training\nmethods to enhance the CMLM decoder. Experimental evaluations on three\nbenchmark datasets with six language directions demonstrated that Orthros\nachieved large improvements in translation quality with a very small overhead\ncompared with the baseline NAR model. Moreover, the Conformer encoder\narchitecture enabled large quality improvements, especially for CTC-based\nmodels. Orthros-CTC with the Conformer encoder increased decoding speed by\n3.63x on CPU with translation quality comparable to that of an AR model.",
    "descriptor": "",
    "authors": [
      "Hirofumi Inaguma",
      "Yosuke Higuchi",
      "Kevin Duh",
      "Tatsuya Kawahara",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2109.04411"
  },
  {
    "id": "arXiv:2109.04433",
    "title": "Extreme Bandits using Robust Statistics",
    "abstract": "We consider a multi-armed bandit problem motivated by situations where only\nthe extreme values, as opposed to expected values in the classical bandit\nsetting, are of interest. We propose distribution free algorithms using robust\nstatistics and characterize the statistical properties. We show that the\nprovided algorithms achieve vanishing extremal regret under weaker conditions\nthan existing algorithms. Performance of the algorithms is demonstrated for the\nfinite-sample setting using numerical experiments. The results show superior\nperformance of the proposed algorithms compared to the well known algorithms.",
    "descriptor": "",
    "authors": [
      "Sujay Bhatt",
      "Ping Li",
      "Gennady Samorodnitsky"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04433"
  },
  {
    "id": "arXiv:2109.04441",
    "title": "Exponential bases for partitions of intervals",
    "abstract": "For a partition of $[0,1]$ into intervals $I_1,\\ldots,I_n$ we prove the\nexistence of a partition of $\\mathbb{Z}$ into $\\Lambda_1,\\ldots, \\Lambda_n$\nsuch that the complex exponential functions with frequencies in $ \\Lambda_k$\nform a Riesz basis for $L^2(I_k)$, and furthermore, that for any\n$J\\subseteq\\{1,\\,2,\\,\\dots,\\,n\\}$, the exponential functions with frequencies\nin $ \\bigcup_{j\\in J}\\Lambda_j$ form a Riesz basis for $L^2(I)$ for any\ninterval $I$ with length $|I|=\\sum_{j\\in J}|I_j|$. The construction extends to\ninfinite partitions of $[0,1]$, but with size limitations on the subsets\n$J\\subseteq \\mathbb{Z}$; it combines the ergodic properties of subsequences of\n$\\mathbb{Z}$ known as Beatty-Fraenkel sequences with a theorem of Avdonin on\nexponential Riesz bases.",
    "descriptor": "",
    "authors": [
      "Goetz Pfander",
      "Shauna Revay",
      "David Walnut"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.04441"
  },
  {
    "id": "arXiv:2109.04447",
    "title": "Modeling Massive Spatial Datasets Using a Conjugate Bayesian Linear  Regression Framework",
    "abstract": "Geographic Information Systems (GIS) and related technologies have generated\nsubstantial interest among statisticians with regard to scalable methodologies\nfor analyzing large spatial datasets. A variety of scalable spatial process\nmodels have been proposed that can be easily embedded within a hierarchical\nmodeling framework to carry out Bayesian inference. While the focus of\nstatistical research has mostly been directed toward innovative and more\ncomplex model development, relatively limited attention has been accorded to\napproaches for easily implementable scalable hierarchical models for the\npracticing scientist or spatial analyst. This article discusses how\npoint-referenced spatial process models can be cast as a conjugate Bayesian\nlinear regression that can rapidly deliver inference on spatial processes. The\napproach allows exact sampling directly (avoids iterative algorithms such as\nMarkov chain Monte Carlo) from the joint posterior distribution of regression\nparameters, the latent process and the predictive random variables, and can be\neasily implemented on statistical programming environments such as R.",
    "descriptor": "",
    "authors": [
      "Sudipto Banerjee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04447"
  },
  {
    "id": "arXiv:2109.04460",
    "title": "Protein Folding Neural Networks Are Not Robust",
    "abstract": "Deep neural networks such as AlphaFold and RoseTTAFold predict remarkably\naccurate structures of proteins compared to other algorithmic approaches. It is\nknown that biologically small perturbations in the protein sequence do not lead\nto drastic changes in the protein structure. In this paper, we demonstrate that\nRoseTTAFold does not exhibit such a robustness despite its high accuracy, and\nbiologically small perturbations for some input sequences result in radically\ndifferent predicted protein structures. This raises the challenge of detecting\nwhen these predicted protein structures cannot be trusted. We define the\nrobustness measure for the predicted structure of a protein sequence to be the\ninverse of the root-mean-square distance (RMSD) in the predicted structure and\nthe structure of its adversarially perturbed sequence. We use adversarial\nattack methods to create adversarial protein sequences, and show that the RMSD\nin the predicted protein structure ranges from 0.119\\r{A} to 34.162\\r{A} when\nthe adversarial perturbations are bounded by 20 units in the BLOSUM62 distance.\nThis demonstrates very high variance in the robustness measure of the predicted\nstructures. We show that the magnitude of the correlation (0.917) between our\nrobustness measure and the RMSD between the predicted structure and the ground\ntruth is high, that is, the predictions with low robustness measure cannot be\ntrusted. This is the first paper demonstrating the susceptibility of\nRoseTTAFold to adversarial attacks.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Sumit Kumar Jha",
      "Arvind Ramanathan",
      "Rickard Ewetz",
      "Alvaro Velasquez",
      "Susmit Jha"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04460"
  },
  {
    "id": "arXiv:1704.05232",
    "title": "On the k-Means/Median Cost Function",
    "abstract": "Comments: This update includes minor improvements and a new section on Dimension Estimation",
    "descriptor": "\nComments: This update includes minor improvements and a new section on Dimension Estimation\n",
    "authors": [
      "Anup Bhattacharya",
      "Yoav Freund",
      "Ragesh Jaiswal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1704.05232"
  },
  {
    "id": "arXiv:1712.04182",
    "title": "A Generic Model for Swarm Intelligence and Its Validations",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Wenpin Jiao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1712.04182"
  },
  {
    "id": "arXiv:1809.08169",
    "title": "On sets of terms with a given intersection type",
    "abstract": "On sets of terms with a given intersection type",
    "descriptor": "",
    "authors": [
      "Richard Statman",
      "Andrew Polonsky"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1809.08169"
  },
  {
    "id": "arXiv:1901.09018",
    "title": "Provably efficient RL with Rich Observations via Latent State Decoding",
    "abstract": "Comments: The ICML 2019 version omitted the second constraint on $\\epsilon$ in Theorem 4.1. We thank Yonathan Efroni for calling this to our attention",
    "descriptor": "\nComments: The ICML 2019 version omitted the second constraint on $\\epsilon$ in Theorem 4.1. We thank Yonathan Efroni for calling this to our attention\n",
    "authors": [
      "Simon S. Du",
      "Akshay Krishnamurthy",
      "Nan Jiang",
      "Alekh Agarwal",
      "Miroslav Dud\u00edk",
      "John Langford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.09018"
  },
  {
    "id": "arXiv:1909.12205",
    "title": "Adaptive Binary-Ternary Quantization",
    "abstract": "Adaptive Binary-Ternary Quantization",
    "descriptor": "",
    "authors": [
      "Gr\u00e9goire Morin",
      "Ryan Razani",
      "Vahid Partovi Nia",
      "Eyy\u00fcb Sari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.12205"
  },
  {
    "id": "arXiv:1911.03063",
    "title": "Is a Classification Procedure Good Enough? A Goodness-of-Fit Assessment  Tool for Classification Learning",
    "abstract": "Is a Classification Procedure Good Enough? A Goodness-of-Fit Assessment  Tool for Classification Learning",
    "descriptor": "",
    "authors": [
      "Jiawei Zhang",
      "Jie Ding",
      "Yuhong Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.03063"
  },
  {
    "id": "arXiv:1911.03437",
    "title": "SMART: Robust and Efficient Fine-Tuning for Pre-trained Natural Language  Models through Principled Regularized Optimization",
    "abstract": "Comments: The 58th annual meeting of the Association for Computational Linguistics (ACL 2020)",
    "descriptor": "\nComments: The 58th annual meeting of the Association for Computational Linguistics (ACL 2020)\n",
    "authors": [
      "Haoming Jiang",
      "Pengcheng He",
      "Weizhu Chen",
      "Xiaodong Liu",
      "Jianfeng Gao",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1911.03437"
  },
  {
    "id": "arXiv:1911.06346",
    "title": "On the Behaviour of Coalgebras with Side Effects and Algebras with  Effectful Iteration",
    "abstract": "Comments: journal version",
    "descriptor": "\nComments: journal version\n",
    "authors": [
      "Stefan Milius",
      "Ji\u0159\u00ed Ad\u00e1mek",
      "Henning Urbat"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/1911.06346"
  },
  {
    "id": "arXiv:2001.01290",
    "title": "General Partial Label Learning via Dual Bipartite Graph Autoencoder",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Brian Chen",
      "Bo Wu",
      "Alireza Zareian",
      "Hanwang Zhang",
      "Shih-Fu Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2001.01290"
  },
  {
    "id": "arXiv:2001.02878",
    "title": "Positive algorithmic bias cannot stop fragmentation in homophilic  networks",
    "abstract": "Comments: Cite as: Chris Blex & Taha Yasseri (2020) Positive algorithmic bias cannot stop fragmentation in homophilic networks, The Journal of Mathematical Sociology, DOI: 10.1080/0022250X.2020.1818078",
    "descriptor": "\nComments: Cite as: Chris Blex & Taha Yasseri (2020) Positive algorithmic bias cannot stop fragmentation in homophilic networks, The Journal of Mathematical Sociology, DOI: 10.1080/0022250X.2020.1818078\n",
    "authors": [
      "Chris Blex",
      "Taha Yasseri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2001.02878"
  },
  {
    "id": "arXiv:2003.00295",
    "title": "Adaptive Federated Optimization",
    "abstract": "Comments: Published as a conference paper at ICLR 2021",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2021\n",
    "authors": [
      "Sashank Reddi",
      "Zachary Charles",
      "Manzil Zaheer",
      "Zachary Garrett",
      "Keith Rush",
      "Jakub Kone\u010dn\u00fd",
      "Sanjiv Kumar",
      "H. Brendan McMahan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.00295"
  },
  {
    "id": "arXiv:2003.05285",
    "title": "A Supervised Machine Learning Model For Imputing Missing Boarding Stops  In Smart Card Data",
    "abstract": "A Supervised Machine Learning Model For Imputing Missing Boarding Stops  In Smart Card Data",
    "descriptor": "",
    "authors": [
      "Nadav Shalit",
      "Michael Fire",
      "Eran Ben-Elia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.05285"
  },
  {
    "id": "arXiv:2004.05582",
    "title": "Sharing Matters for Generalization in Deep Metric Learning",
    "abstract": "Comments: IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Timo Milbich",
      "Karsten Roth",
      "Biagio Brattoli",
      "Bj\u00f6rn Ommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2004.05582"
  },
  {
    "id": "arXiv:2004.06533",
    "title": "Fundamental Performance Limitations for Average Consensus in Open  Multi-Agent Systems",
    "abstract": "Comments: 14 pages, 9 figures, submitted to IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: 14 pages, 9 figures, submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Charles Monnoyer de Galland",
      "Julien M. Hendrickx"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2004.06533"
  },
  {
    "id": "arXiv:2004.06866",
    "title": "On the Linguistic Capacity of Real-Time Counter Automata",
    "abstract": "Comments: Updated to fix a minor typo in the semilinearity proof",
    "descriptor": "\nComments: Updated to fix a minor typo in the semilinearity proof\n",
    "authors": [
      "William Merrill"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2004.06866"
  },
  {
    "id": "arXiv:2004.12488",
    "title": "Order preserving hierarchical agglomerative clustering",
    "abstract": "Comments: 47 pages",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Daniel Bakkelund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.12488"
  },
  {
    "id": "arXiv:2004.13002",
    "title": "A Black-box Adversarial Attack Strategy with Adjustable Sparsity and  Generalizability for Deep Image Classifiers",
    "abstract": "A Black-box Adversarial Attack Strategy with Adjustable Sparsity and  Generalizability for Deep Image Classifiers",
    "descriptor": "",
    "authors": [
      "Arka Ghosh",
      "Sankha Subhra Mullick",
      "Shounak Datta",
      "Swagatam Das",
      "Rammohan Mallipeddi",
      "Asit Kr. Das"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.13002"
  },
  {
    "id": "arXiv:2005.05070",
    "title": "Faster Exponential-time Algorithms for Approximately Counting  Independent Sets",
    "abstract": "Comments: 52pp",
    "descriptor": "\nComments: 52pp\n",
    "authors": [
      "Leslie Ann Goldberg",
      "John Lapinskas",
      "David Richerby"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2005.05070"
  },
  {
    "id": "arXiv:2005.12366",
    "title": "Robust exact differentiators with predefined convergence time",
    "abstract": "Robust exact differentiators with predefined convergence time",
    "descriptor": "",
    "authors": [
      "Richard Seeber",
      "Hernan Haimovich",
      "Martin Horn",
      "Leonid Fridman",
      "Hern\u00e1n De Battista"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2005.12366"
  },
  {
    "id": "arXiv:2006.01512",
    "title": "A fast and simple modification of Newton's method helping to avoid  saddle points",
    "abstract": "Comments: Main part: 43 pages, Appendix: 21 pages. Some misprints corrected. Add comparison to a relevant circle of ideas by Goldfarb, Gould et al, and others. Add applications to finding roots of a univariate meromorphic function",
    "descriptor": "\nComments: Main part: 43 pages, Appendix: 21 pages. Some misprints corrected. Add comparison to a relevant circle of ideas by Goldfarb, Gould et al, and others. Add applications to finding roots of a univariate meromorphic function\n",
    "authors": [
      "Tuyen Trung Truong",
      "Tat Dat To",
      "Tuan Hang Nguyen",
      "Thu Hang Nguyen",
      "Hoang Phuong Nguyen",
      "Maged Helmy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.01512"
  },
  {
    "id": "arXiv:2006.15607",
    "title": "Localization Uncertainty Estimation for Anchor-Free Object Detection",
    "abstract": "Localization Uncertainty Estimation for Anchor-Free Object Detection",
    "descriptor": "",
    "authors": [
      "Youngwan Lee",
      "Joong-won Hwang",
      "Hyung-Il Kim",
      "Kimin Yun",
      "Yongjin Kwon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.15607"
  },
  {
    "id": "arXiv:2007.04225",
    "title": "Commutator-free Lie group methods with minimum storage requirements and  reuse of exponentials",
    "abstract": "Comments: 41 pages, 10 figures. Minor revisions to bring the preprint in line with the final published version. The published version is slightly shortened in the introductory part",
    "descriptor": "\nComments: 41 pages, 10 figures. Minor revisions to bring the preprint in line with the final published version. The published version is slightly shortened in the introductory part\n",
    "authors": [
      "Alexei Bazavov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2007.04225"
  },
  {
    "id": "arXiv:2008.01511",
    "title": "A divide-and-conquer algorithm for quantum state preparation",
    "abstract": "A divide-and-conquer algorithm for quantum state preparation",
    "descriptor": "",
    "authors": [
      "Israel F. Araujo",
      "Daniel K. Park",
      "Francesco Petruccione",
      "Adenilton J. da Silva"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.01511"
  },
  {
    "id": "arXiv:2008.04723",
    "title": "Economical Visual Attention Test for Elderly Drivers",
    "abstract": "Economical Visual Attention Test for Elderly Drivers",
    "descriptor": "",
    "authors": [
      "Akinari Onishi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2008.04723"
  },
  {
    "id": "arXiv:2008.08721",
    "title": "The Quantum Supremacy Tsirelson Inequality",
    "abstract": "Comments: 26 pages. V2: corrected typos, added additional discussion, added journal reference. V3: additional minor corrections. V4: final journal version, various writing improvements",
    "descriptor": "\nComments: 26 pages. V2: corrected typos, added additional discussion, added journal reference. V3: additional minor corrections. V4: final journal version, various writing improvements\n",
    "authors": [
      "William Kretschmer"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2008.08721"
  },
  {
    "id": "arXiv:2008.12537",
    "title": "The UU-test for Statistical Modeling of Unimodal Data",
    "abstract": "Comments: 32 pages, 20 figures, 6 tables",
    "descriptor": "\nComments: 32 pages, 20 figures, 6 tables\n",
    "authors": [
      "Paraskevi Chasani",
      "Aristidis Likas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.12537"
  },
  {
    "id": "arXiv:2009.02995",
    "title": "Collaborative Management of Benchmark Instances and their Attributes",
    "abstract": "Collaborative Management of Benchmark Instances and their Attributes",
    "descriptor": "",
    "authors": [
      "Markus Iser",
      "Luca Springer",
      "Carsten Sinz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2009.02995"
  },
  {
    "id": "arXiv:2009.06402",
    "title": "Time-Aware Evidence Ranking for Fact-Checking",
    "abstract": "Comments: 16 pages, accepted for publication in Journal of Web Semantics - Special Issue on Content Credibility",
    "descriptor": "\nComments: 16 pages, accepted for publication in Journal of Web Semantics - Special Issue on Content Credibility\n",
    "authors": [
      "Liesbeth Allein",
      "Isabelle Augenstein",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.06402"
  },
  {
    "id": "arXiv:2009.09363",
    "title": "Understanding Mention Detector-Linker Interaction in Neural Coreference  Resolution",
    "abstract": "Comments: CRAC @ EMNLP 2021",
    "descriptor": "\nComments: CRAC @ EMNLP 2021\n",
    "authors": [
      "Zhaofeng Wu",
      "Matt Gardner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2009.09363"
  },
  {
    "id": "arXiv:2009.10207",
    "title": "Synthesizing Inductive Lemmas for Reasoning with First-Order Logic with  Least Fixpoints",
    "abstract": "Synthesizing Inductive Lemmas for Reasoning with First-Order Logic with  Least Fixpoints",
    "descriptor": "",
    "authors": [
      "Adithya Murali",
      "Lucas Pe\u00f1a",
      "Eion Blanchard",
      "Christof L\u00f6ding",
      "P. Madhusudan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2009.10207"
  },
  {
    "id": "arXiv:2010.03060",
    "title": "Contrastive Cross-Modal Pre-Training: A General Strategy for Small  Sample Medical Imaging",
    "abstract": "Comments: This work is accepted to the IEEE Journal of Biomedical and Health Informatics",
    "descriptor": "\nComments: This work is accepted to the IEEE Journal of Biomedical and Health Informatics\n",
    "authors": [
      "Gongbo Liang",
      "Connor Greenwell",
      "Yu Zhang",
      "Xiaoqin Wang",
      "Ramakanth Kavuluru",
      "Nathan Jacobs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2010.03060"
  },
  {
    "id": "arXiv:2010.06196",
    "title": "Mathematical Word Problem Generation from Commonsense Knowledge Graph  and Equations",
    "abstract": "Comments: EMNLP'21: The 2021 Conference on Empirical Methods in Natural Language Processing, 2021",
    "descriptor": "\nComments: EMNLP'21: The 2021 Conference on Empirical Methods in Natural Language Processing, 2021\n",
    "authors": [
      "Tianqiao Liu",
      "Qiang Fang",
      "Wenbiao Ding",
      "Hang Li",
      "Zhongqin Wu",
      "Zitao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.06196"
  },
  {
    "id": "arXiv:2010.11818",
    "title": "Compositional Generalization via Semantic Tagging",
    "abstract": "Comments: EMNLP 2021, Findings",
    "descriptor": "\nComments: EMNLP 2021, Findings\n",
    "authors": [
      "Hao Zheng",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.11818"
  },
  {
    "id": "arXiv:2010.12758",
    "title": "NUANCED: Natural Utterance Annotation for Nuanced Conversation with  Estimated Distributions",
    "abstract": "Comments: Findings of EMNLP 2021",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Zhiyu Chen",
      "Honglei Liu",
      "Hu Xu",
      "Seungwhan Moon",
      "Hao Zhou",
      "Bing Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.12758"
  },
  {
    "id": "arXiv:2010.14693",
    "title": "AM-RRT*: Informed Sampling-based Planning with Assisting Metric",
    "abstract": "Comments: To appear in the proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA). 6 pages, 2 figures",
    "descriptor": "\nComments: To appear in the proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA). 6 pages, 2 figures\n",
    "authors": [
      "Daniel Armstrong",
      "Andr\u00e9 Jonasson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.14693"
  },
  {
    "id": "arXiv:2011.04558",
    "title": "Spectral clustering on spherical coordinates under the degree-corrected  stochastic blockmodel",
    "abstract": "Spectral clustering on spherical coordinates under the degree-corrected  stochastic blockmodel",
    "descriptor": "",
    "authors": [
      "Francesco Sanna Passino",
      "Nicholas A. Heard",
      "Patrick Rubin-Delanchy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.04558"
  },
  {
    "id": "arXiv:2011.06228",
    "title": "DSAM: A Distance Shrinking with Angular Marginalizing Loss for High  Performance Vehicle Re-identificatio",
    "abstract": "DSAM: A Distance Shrinking with Angular Marginalizing Loss for High  Performance Vehicle Re-identificatio",
    "descriptor": "",
    "authors": [
      "Jiangtao Kong",
      "Yu Cheng",
      "Benjia Zhou",
      "Kai Li",
      "Junliang Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.06228"
  },
  {
    "id": "arXiv:2011.09769",
    "title": "Data-Driven Robust Optimization using Unsupervised Deep Learning",
    "abstract": "Data-Driven Robust Optimization using Unsupervised Deep Learning",
    "descriptor": "",
    "authors": [
      "Marc Goerigk",
      "Jannis Kurtz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.09769"
  },
  {
    "id": "arXiv:2011.11498",
    "title": "HoHoNet: 360 Indoor Holistic Understanding with Latent Horizontal  Features",
    "abstract": "Comments: Code at this https URL Video at this https URL",
    "descriptor": "\nComments: Code at this https URL Video at this https URL\n",
    "authors": [
      "Cheng Sun",
      "Min Sun",
      "Hwann-Tzong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.11498"
  },
  {
    "id": "arXiv:2011.15122",
    "title": "Deep controlled learning of MDP policies with an application to  lost-sales inventory control",
    "abstract": "Deep controlled learning of MDP policies with an application to  lost-sales inventory control",
    "descriptor": "",
    "authors": [
      "Willem van Jaarsveld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.15122"
  },
  {
    "id": "arXiv:2012.01067",
    "title": "Making Weak Memory Models Fair",
    "abstract": "Comments: 43 pages, 2 figures",
    "descriptor": "\nComments: 43 pages, 2 figures\n",
    "authors": [
      "Ori Lahav",
      "Egor Namakonov",
      "Jonas Oberhauser",
      "Anton Podkopaev",
      "Viktor Vafeiadis"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2012.01067"
  },
  {
    "id": "arXiv:2012.01789",
    "title": "Distributed Thompson Sampling",
    "abstract": "Comments: The paper is not finished and will not be updated",
    "descriptor": "\nComments: The paper is not finished and will not be updated\n",
    "authors": [
      "Jing Dong",
      "Tan Li",
      "Shaolei Ren",
      "Linqi Song"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.01789"
  },
  {
    "id": "arXiv:2012.02164",
    "title": "People Still Care About Facts: Twitter Users Engage More with Factual  Discourse than Misinformation--A Comparison Between COVID and General  Narratives on Twitter",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Mirela Silva",
      "Fabr\u00edcio Ceschin",
      "Prakash Shrestha",
      "Christopher Brant",
      "Shlok Gilda",
      "Juliana Fernandes",
      "Catia S. Silva",
      "Andr\u00e9 Gr\u00e9gio",
      "Daniela Oliveira",
      "Luiz Giovanini"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.02164"
  },
  {
    "id": "arXiv:2012.05009",
    "title": "A Gumbel-based activation function for imbalanced datasets",
    "abstract": "Comments: 13",
    "descriptor": "\nComments: 13\n",
    "authors": [
      "Yuexin Wu",
      "Tianyu Gao",
      "Hongtao Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2012.05009"
  },
  {
    "id": "arXiv:2012.07913",
    "title": "Quantizing data for distributed learning",
    "abstract": "Quantizing data for distributed learning",
    "descriptor": "",
    "authors": [
      "Osama A. Hanna",
      "Yahya H. Ezzeldin",
      "Christina Fragouli",
      "Suhas Diggavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.07913"
  },
  {
    "id": "arXiv:2012.08181",
    "title": "Fast-Convergent Dynamics for Distributed Allocation of Resources Over  Switching Sparse Networks with Quantized Communication Links",
    "abstract": "Fast-Convergent Dynamics for Distributed Allocation of Resources Over  Switching Sparse Networks with Quantized Communication Links",
    "descriptor": "",
    "authors": [
      "Mohammadreza Doostmohammadian",
      "Alireza Aghasi",
      "Mohammad Pirani",
      "Ehsan Nekouei",
      "Usman A. Khan",
      "Themistoklis Charalambous"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2012.08181"
  },
  {
    "id": "arXiv:2012.09913",
    "title": "Quantifying the unknown impact of segmentation uncertainty on  image-based simulations",
    "abstract": "Quantifying the unknown impact of segmentation uncertainty on  image-based simulations",
    "descriptor": "",
    "authors": [
      "Michael C. Krygier",
      "Tyler LaBonte",
      "Carianne Martinez",
      "Chance Norris",
      "Krish Sharma",
      "Lincoln N. Collins",
      "Partha P. Mukherjee",
      "Scott A. Roberts"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2012.09913"
  },
  {
    "id": "arXiv:2012.10713",
    "title": "Fundamental Limits and Tradeoffs in Invariant Representation Learning",
    "abstract": "Fundamental Limits and Tradeoffs in Invariant Representation Learning",
    "descriptor": "",
    "authors": [
      "Han Zhao",
      "Chen Dan",
      "Bryon Aragam",
      "Tommi S. Jaakkola",
      "Geoffrey J. Gordon",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.10713"
  },
  {
    "id": "arXiv:2012.14838",
    "title": "The Price is (Probably) Right: Learning Market Equilibria from Samples",
    "abstract": "The Price is (Probably) Right: Learning Market Equilibria from Samples",
    "descriptor": "",
    "authors": [
      "Vignesh Viswanathan",
      "Omer Lev",
      "Neel Patel",
      "Yair Zick"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.14838"
  },
  {
    "id": "arXiv:2101.00297",
    "title": "Understanding Few-Shot Commonsense Knowledge Models",
    "abstract": "Comments: AKBC 2021",
    "descriptor": "\nComments: AKBC 2021\n",
    "authors": [
      "Jeff Da",
      "Ronan Le Bras",
      "Ximing Lu",
      "Yejin Choi",
      "Antoine Bosselut"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00297"
  },
  {
    "id": "arXiv:2101.01016",
    "title": "A Second-Order Nonlocal Approximation for Manifold Poisson Model with  Dirichlet Boundary",
    "abstract": "Comments: 58 pages, 4 figures",
    "descriptor": "\nComments: 58 pages, 4 figures\n",
    "authors": [
      "Yajie Zhang",
      "Zuoqiang Shi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2101.01016"
  },
  {
    "id": "arXiv:2101.09298",
    "title": "Safe Learning Reference Governor: Theory and Application to Fuel Truck  Rollover Avoidance",
    "abstract": "Comments: 16 pages, 18 figures",
    "descriptor": "\nComments: 16 pages, 18 figures\n",
    "authors": [
      "Kaiwen Liu",
      "Nan Li",
      "Ilya Kolmanovsky",
      "Denise Rizzo",
      "Anouck Girard"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.09298"
  },
  {
    "id": "arXiv:2101.10985",
    "title": "Classical simulations of communication channels",
    "abstract": "Comments: 16 pages. The presentation has been improved. Sections 3 and 4 are new",
    "descriptor": "\nComments: 16 pages. The presentation has been improved. Sections 3 and 4 are new\n",
    "authors": [
      "P\u00e9ter E. Frenkel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2101.10985"
  },
  {
    "id": "arXiv:2101.12699",
    "title": "Exploring Deep Neural Networks via Layer-Peeled Model: Minority Collapse  in Imbalanced Training",
    "abstract": "Comments: Accepted at Proceedings of the National Academy of Sciences (PNAS); Changed the title",
    "descriptor": "\nComments: Accepted at Proceedings of the National Academy of Sciences (PNAS); Changed the title\n",
    "authors": [
      "Cong Fang",
      "Hangfeng He",
      "Qi Long",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.12699"
  },
  {
    "id": "arXiv:2102.05174",
    "title": "On the Hardness of PAC-learning stabilizer States with Noise",
    "abstract": "On the Hardness of PAC-learning stabilizer States with Noise",
    "descriptor": "",
    "authors": [
      "Aravind Gollakota",
      "Daniel Liang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05174"
  },
  {
    "id": "arXiv:2102.05281",
    "title": "Biomedical Question Answering: A Survey of Approaches and Challenges",
    "abstract": "Comments: In submission to ACM Computing Surveys",
    "descriptor": "\nComments: In submission to ACM Computing Surveys\n",
    "authors": [
      "Qiao Jin",
      "Zheng Yuan",
      "Guangzhi Xiong",
      "Qianlan Yu",
      "Huaiyuan Ying",
      "Chuanqi Tan",
      "Mosha Chen",
      "Songfang Huang",
      "Xiaozhong Liu",
      "Sheng Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.05281"
  },
  {
    "id": "arXiv:2102.08079",
    "title": "Just Noticeable Difference for Machine Perception and Generation of  Regularized Adversarial Images with Minimal Perturbation",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Adil Kaan Akan",
      "Emre Akbas",
      "Fatos T. Yarman Vural"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2102.08079"
  },
  {
    "id": "arXiv:2102.09858",
    "title": "ISCL: Interdependent Self-Cooperative Learning for Unpaired Image  Denoising",
    "abstract": "ISCL: Interdependent Self-Cooperative Learning for Unpaired Image  Denoising",
    "descriptor": "",
    "authors": [
      "Kanggeun Lee",
      "Won-Ki Jeong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2102.09858"
  },
  {
    "id": "arXiv:2102.11090",
    "title": "Position Information in Transformers: An Overview",
    "abstract": "Comments: First two authors contributed equally",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Philipp Dufter",
      "Martin Schmitt",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.11090"
  },
  {
    "id": "arXiv:2102.11960",
    "title": "Design and Analysis of a Logless Dynamic Reconfiguration Protocol",
    "abstract": "Comments: 35 pages, 2 figures",
    "descriptor": "\nComments: 35 pages, 2 figures\n",
    "authors": [
      "William Schultz",
      "Siyuan Zhou",
      "Ian Dardik",
      "Stavros Tripakis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.11960"
  },
  {
    "id": "arXiv:2103.00453",
    "title": "Self-Diagnosis and Self-Debiasing: A Proposal for Reducing Corpus-Based  Bias in NLP",
    "abstract": "Comments: Accepted at TACL",
    "descriptor": "\nComments: Accepted at TACL\n",
    "authors": [
      "Timo Schick",
      "Sahana Udupa",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.00453"
  },
  {
    "id": "arXiv:2103.00674",
    "title": "BEAUTY Powered BEAST",
    "abstract": "BEAUTY Powered BEAST",
    "descriptor": "",
    "authors": [
      "Kai Zhang",
      "Zhigen Zhao",
      "Wen Zhou"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.00674"
  },
  {
    "id": "arXiv:2103.03817",
    "title": "Proactive and AoI-aware Failure Recovery for Stateful NFV-enabled  Zero-Touch 6G Networks: Model-Free DRL Approach",
    "abstract": "Comments: Accepted in IEEE TNSM Code is available this https URL in this https URL",
    "descriptor": "\nComments: Accepted in IEEE TNSM Code is available this https URL in this https URL\n",
    "authors": [
      "Amirhossein Shaghaghi",
      "Abolfazl Zakeri",
      "Nader Mokari",
      "Mohammad Reza Javan",
      "Mohammad Behdadfar",
      "Eduard A Jorswieck"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.03817"
  },
  {
    "id": "arXiv:2103.05245",
    "title": "Learning Dependencies in Distributed Cloud Applications to Identify and  Localize Anomalies",
    "abstract": "Comments: 6 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 6 pages, 5 figures, 3 tables\n",
    "authors": [
      "Dominik Scheinert",
      "Alexander Acker",
      "Lauritz Thamsen",
      "Morgan K. Geldenhuys",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.05245"
  },
  {
    "id": "arXiv:2103.07119",
    "title": "Goal-Driven Autonomous Exploration Through Deep Reinforcement Learning",
    "abstract": "Goal-Driven Autonomous Exploration Through Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Reinis Cimurs",
      "Il Hong Suh",
      "Jin Han Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.07119"
  },
  {
    "id": "arXiv:2103.07656",
    "title": "Optimal Embedding Calibration for Symbolic Music Similarity",
    "abstract": "Optimal Embedding Calibration for Symbolic Music Similarity",
    "descriptor": "",
    "authors": [
      "Xinran Zhang",
      "Maosong Sun",
      "Jiafeng Liu",
      "Xiaobing Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.07656"
  },
  {
    "id": "arXiv:2103.12235",
    "title": "Mitigating False-Negative Contexts in Multi-document Question Answering  with Retrieval Marginalization",
    "abstract": "Comments: Accepted to EMNLP 2021 (main conference)",
    "descriptor": "\nComments: Accepted to EMNLP 2021 (main conference)\n",
    "authors": [
      "Ansong Ni",
      "Matt Gardner",
      "Pradeep Dasigi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.12235"
  },
  {
    "id": "arXiv:2103.12827",
    "title": "Fisher Task Distance and Its Applications in Transfer Learning and  Neural Architecture Search",
    "abstract": "Fisher Task Distance and Its Applications in Transfer Learning and  Neural Architecture Search",
    "descriptor": "",
    "authors": [
      "Cat P. Le",
      "Mohammadreza Soltani",
      "Juncheng Dong",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.12827"
  },
  {
    "id": "arXiv:2103.14222",
    "title": "Adversarial Attacks are Reversible with Natural Supervision",
    "abstract": "Adversarial Attacks are Reversible with Natural Supervision",
    "descriptor": "",
    "authors": [
      "Chengzhi Mao",
      "Mia Chiquier",
      "Hao Wang",
      "Junfeng Yang",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.14222"
  },
  {
    "id": "arXiv:2103.14235",
    "title": "Socio-Technical Grounded Theory for Software Engineering",
    "abstract": "Comments: Accepted to IEEE Transactions on Software Engineering (Aug 2021); This author preprint is 26 pages, the final IEEE version is 25 pages due to reformatting, content is same. More details: this https URL",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Software Engineering (Aug 2021); This author preprint is 26 pages, the final IEEE version is 25 pages due to reformatting, content is same. More details: this https URL\n",
    "authors": [
      "Rashina Hoda"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2103.14235"
  },
  {
    "id": "arXiv:2103.14273",
    "title": "LightSAL: Lightweight Sign Agnostic Learning for Implicit Surface  Representation",
    "abstract": "LightSAL: Lightweight Sign Agnostic Learning for Implicit Surface  Representation",
    "descriptor": "",
    "authors": [
      "Abol Basher",
      "Muhammad Sarmad",
      "Jani Boutellier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14273"
  },
  {
    "id": "arXiv:2103.16424",
    "title": "Two-stage Robust Energy Storage Planning with Probabilistic Guarantees:  A Data-driven Approach",
    "abstract": "Two-stage Robust Energy Storage Planning with Probabilistic Guarantees:  A Data-driven Approach",
    "descriptor": "",
    "authors": [
      "Chao Yan",
      "Xinbo Geng",
      "Zhaohong Bie",
      "Le Xie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.16424"
  },
  {
    "id": "arXiv:2104.00245",
    "title": "High-Dimensional Differentially-Private EM Algorithm: Methods and  Near-Optimal Statistical Guarantees",
    "abstract": "Comments: 68 pages, 3 figures",
    "descriptor": "\nComments: 68 pages, 3 figures\n",
    "authors": [
      "Zhe Zhang",
      "Linjun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2104.00245"
  },
  {
    "id": "arXiv:2104.01002",
    "title": "HAConvGNN: Hierarchical Attention Based Convolutional Graph Neural  Network for Code Documentation Generation in Jupyter Notebooks",
    "abstract": "HAConvGNN: Hierarchical Attention Based Convolutional Graph Neural  Network for Code Documentation Generation in Jupyter Notebooks",
    "descriptor": "",
    "authors": [
      "Xuye Liu",
      "Dakuo Wang",
      "April Wang",
      "Yufang Hou",
      "Lingfei Wu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01002"
  },
  {
    "id": "arXiv:2104.01650",
    "title": "City-scale Simulation of Covid-19 Pandemic and Intervention Policies  using Agent-based Modelling",
    "abstract": "City-scale Simulation of Covid-19 Pandemic and Intervention Policies  using Agent-based Modelling",
    "descriptor": "",
    "authors": [
      "Gaurav Suryawanshi",
      "Varun Madhavan",
      "Adway Mitra",
      "Partha Pratim Chakrabarti"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2104.01650"
  },
  {
    "id": "arXiv:2104.02583",
    "title": "Limitations and Improvements of the Intelligent Driver Model (IDM)",
    "abstract": "Comments: 28 pages, 20 Figures",
    "descriptor": "\nComments: 28 pages, 20 Figures\n",
    "authors": [
      "Saleh Albeaik",
      "Alexandre Bayen",
      "Maria Teresa Chiri",
      "Xiaoqian Gong",
      "Amaury Hayat",
      "Nicolas Kardous",
      "Alexander Keimer",
      "Sean T. McQuade",
      "Benedetto Piccoli",
      "Yiling You"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.02583"
  },
  {
    "id": "arXiv:2104.05532",
    "title": "GhostMinion: A Strictness-Ordered Cache System for Spectre Mitigation",
    "abstract": "GhostMinion: A Strictness-Ordered Cache System for Spectre Mitigation",
    "descriptor": "",
    "authors": [
      "Sam Ainsworth"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2104.05532"
  },
  {
    "id": "arXiv:2104.06669",
    "title": "NAREOR: The Narrative Reordering Problem",
    "abstract": "NAREOR: The Narrative Reordering Problem",
    "descriptor": "",
    "authors": [
      "Varun Gangal",
      "Steven Y. Feng",
      "Malihe Alikhani",
      "Teruko Mitamura",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.06669"
  },
  {
    "id": "arXiv:2104.06751",
    "title": "Is Multi-Hop Reasoning Really Explainable? Towards Benchmarking  Reasoning Interpretability",
    "abstract": "Is Multi-Hop Reasoning Really Explainable? Towards Benchmarking  Reasoning Interpretability",
    "descriptor": "",
    "authors": [
      "Xin Lv",
      "Yixin Cao",
      "Lei Hou",
      "Juanzi Li",
      "Zhiyuan Liu",
      "Yichi Zhang",
      "Zelin Dai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.06751"
  },
  {
    "id": "arXiv:2104.07650",
    "title": "KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization  for Relation Extraction",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Xiang Chen",
      "Ningyu Zhang",
      "Xin Xie",
      "Shumin Deng",
      "Yunzhi Yao",
      "Chuanqi Tan",
      "Fei Huang",
      "Luo Si",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.07650"
  },
  {
    "id": "arXiv:2104.07705",
    "title": "How to Train BERT with an Academic Budget",
    "abstract": "How to Train BERT with an Academic Budget",
    "descriptor": "",
    "authors": [
      "Peter Izsak",
      "Moshe Berchansky",
      "Omer Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07705"
  },
  {
    "id": "arXiv:2104.08027",
    "title": "Fast, Effective, and Self-Supervised: Transforming Masked Language  Models into Universal Lexical and Sentence Encoders",
    "abstract": "Comments: EMNLP 2021 camera-ready version",
    "descriptor": "\nComments: EMNLP 2021 camera-ready version\n",
    "authors": [
      "Fangyu Liu",
      "Ivan Vuli\u0107",
      "Anna Korhonen",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08027"
  },
  {
    "id": "arXiv:2104.08047",
    "title": "Cell-Free Massive MIMO with Large-Scale Fading Decoding and Dynamic  Cooperation Clustering",
    "abstract": "Comments: 6 pages, 2 figures, accepted for publication in the conference WSA 2021",
    "descriptor": "\nComments: 6 pages, 2 figures, accepted for publication in the conference WSA 2021\n",
    "authors": [
      "\u00d6zlem Tu\u011ffe Demir",
      "Emil Bj\u00f6rnson",
      "Luca Sanguinetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.08047"
  },
  {
    "id": "arXiv:2104.08164",
    "title": "Editing Factual Knowledge in Language Models",
    "abstract": "Comments: Accepted at EMNLP2021 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. Code at this https URL . 16 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: Accepted at EMNLP2021 Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. Code at this https URL . 16 pages, 6 figures, 2 tables\n",
    "authors": [
      "Nicola De Cao",
      "Wilker Aziz",
      "Ivan Titov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08164"
  },
  {
    "id": "arXiv:2104.08202",
    "title": "$Q^{2}$: Evaluating Factual Consistency in Knowledge-Grounded Dialogues  via Question Generation and Question Answering",
    "abstract": "Comments: Accepted to EMNLP 2021",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Or Honovich",
      "Leshem Choshen",
      "Roee Aharoni",
      "Ella Neeman",
      "Idan Szpektor",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08202"
  },
  {
    "id": "arXiv:2104.08530",
    "title": "The Topic Confusion Task: A Novel Scenario for Authorship Attribution",
    "abstract": "Comments: 15 pages (9 + ref./appin.), 6 figures, Accepted to Findings of EMNLP 2021",
    "descriptor": "\nComments: 15 pages (9 + ref./appin.), 6 figures, Accepted to Findings of EMNLP 2021\n",
    "authors": [
      "Malik H. Altakrori",
      "Jackie Chi Kit Cheung",
      "Benjamin C. M. Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08530"
  },
  {
    "id": "arXiv:2104.08700",
    "title": "Efficient Weight Pruning using Pre-trained Lottery Jackpots",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Yuxin Zhang",
      "Mingbao Lin",
      "Fei Chao",
      "Guannan Jiang",
      "Yan Wang",
      "Yongjian Wu",
      "Wei Zhang",
      "Mingliang Xu",
      "Yonghong Tian",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08700"
  },
  {
    "id": "arXiv:2104.08801",
    "title": "Back-Training excels Self-Training at Unsupervised Domain Adaptation of  Question Generation and Passage Retrieval",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Devang Kulshreshtha",
      "Robert Belfer",
      "Iulian Vlad Serban",
      "Siva Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08801"
  },
  {
    "id": "arXiv:2104.08803",
    "title": "Consistent Accelerated Inference via Confident Adaptive Transformers",
    "abstract": "Comments: EMNLP 2021",
    "descriptor": "\nComments: EMNLP 2021\n",
    "authors": [
      "Tal Schuster",
      "Adam Fisch",
      "Tommi Jaakkola",
      "Regina Barzilay"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08803"
  },
  {
    "id": "arXiv:2104.08825",
    "title": "Flexible Generation of Natural Language Deductions",
    "abstract": "Comments: Accepted to EMNLP 2021 (long paper). 9 pages (13 with references and appendix), 8 figures",
    "descriptor": "\nComments: Accepted to EMNLP 2021 (long paper). 9 pages (13 with references and appendix), 8 figures\n",
    "authors": [
      "Kaj Bostrom",
      "Xinyu Zhao",
      "Swarat Chaudhuri",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.08825"
  },
  {
    "id": "arXiv:2104.08836",
    "title": "LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich  Document Understanding",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Yiheng Xu",
      "Tengchao Lv",
      "Lei Cui",
      "Guoxin Wang",
      "Yijuan Lu",
      "Dinei Florencio",
      "Cha Zhang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08836"
  },
  {
    "id": "arXiv:2104.09785",
    "title": "Model-predictive control and reinforcement learning in multi-energy  system case studies",
    "abstract": "Comments: 43 pages, 29 figures",
    "descriptor": "\nComments: 43 pages, 29 figures\n",
    "authors": [
      "Glenn Ceusters",
      "Rom\u00e1n Cant\u00fa Rodr\u00edguez",
      "Alberte Bouso Garc\u00eda",
      "R\u00fcdiger Franke",
      "Geert Deconinck",
      "Lieve Helsen",
      "Ann Now\u00e9",
      "Maarten Messagie",
      "Luis Ramirez Camargo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.09785"
  },
  {
    "id": "arXiv:2104.10274",
    "title": "Rich Specifications for Ethereum Smart Contract Verification",
    "abstract": "Rich Specifications for Ethereum Smart Contract Verification",
    "descriptor": "",
    "authors": [
      "Christian Br\u00e4m",
      "Marco Eilers",
      "Peter M\u00fcller",
      "Robin Sierra",
      "Alexander J. Summers"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2104.10274"
  },
  {
    "id": "arXiv:2104.12210",
    "title": "Generative Adversarial Network: Some Analytical Perspectives",
    "abstract": "Comments: Contributed to the book, \"Machine Learning in Financial Markets: A Guide to Contemporary Practice\", edited by Agostino Capponi and Charles-Albert Lehalle",
    "descriptor": "\nComments: Contributed to the book, \"Machine Learning in Financial Markets: A Guide to Contemporary Practice\", edited by Agostino Capponi and Charles-Albert Lehalle\n",
    "authors": [
      "Haoyang Cao",
      "Xin Guo"
    ],
    "subjectives": [
      "Mathematical Finance (q-fin.MF)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.12210"
  },
  {
    "id": "arXiv:2105.03814",
    "title": "Benchmarking a New Paradigm: An Experimental Analysis of a Real  Processing-in-Memory Architecture",
    "abstract": "Comments: Our open source software is available at this https URL",
    "descriptor": "\nComments: Our open source software is available at this https URL\n",
    "authors": [
      "Juan G\u00f3mez-Luna",
      "Izzat El Hajj",
      "Ivan Fernandez",
      "Christina Giannoula",
      "Geraldo F. Oliveira",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.03814"
  },
  {
    "id": "arXiv:2105.03857",
    "title": "Attention-Based 3D Seismic Fault Segmentation Training by a Few 2D Slice  Labels",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "YiMin Dou",
      "Kewen Li",
      "Jianbing Zhu",
      "Xiao Li",
      "Yingjie Xi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.03857"
  },
  {
    "id": "arXiv:2105.08667",
    "title": "Image Cropping on Twitter: Fairness Metrics, their Limitations, and the  Importance of Representation, Design, and Agency",
    "abstract": "Comments: Accepted to CSCW 2021",
    "descriptor": "\nComments: Accepted to CSCW 2021\n",
    "authors": [
      "Kyra Yee",
      "Uthaipon Tantipongpipat",
      "Shubhanshu Mishra"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08667"
  },
  {
    "id": "arXiv:2105.10331",
    "title": "A Self-Guided Approach for Navigation in a Minimalistic Foraging Robotic  Swarm",
    "abstract": "A Self-Guided Approach for Navigation in a Minimalistic Foraging Robotic  Swarm",
    "descriptor": "",
    "authors": [
      "Steven Adams",
      "Daniel Jarne Ornia",
      "Manuel Mazo Jr"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.10331"
  },
  {
    "id": "arXiv:2105.11236",
    "title": "Parallel Finite Volume Code for Plasma with Unstructured Adaptive Mesh  Refinement",
    "abstract": "Parallel Finite Volume Code for Plasma with Unstructured Adaptive Mesh  Refinement",
    "descriptor": "",
    "authors": [
      "Imad Kissami",
      "Souhail Maazioui",
      "Fayssal Benkhaldoun"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.11236"
  },
  {
    "id": "arXiv:2105.12224",
    "title": "Leaky Frontends: Security Vulnerabilities in Processor Frontends",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Shuwen Deng",
      "Bowen Huang",
      "Jakub Szefer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.12224"
  },
  {
    "id": "arXiv:2105.12697",
    "title": "Intriguing Parameters of Structural Causal Models",
    "abstract": "Comments: Main paper: 7 pages, References: 1 page, Supplement: 3 pages. Main paper: 5 figures, Supplement: 1 figure",
    "descriptor": "\nComments: Main paper: 7 pages, References: 1 page, Supplement: 3 pages. Main paper: 5 figures, Supplement: 1 figure\n",
    "authors": [
      "Matej Ze\u010devi\u0107",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.12697"
  },
  {
    "id": "arXiv:2105.12880",
    "title": "The Petascale DTN Project: High Performance Data Transfer for HPC  Facilities",
    "abstract": "The Petascale DTN Project: High Performance Data Transfer for HPC  Facilities",
    "descriptor": "",
    "authors": [
      "Eli Dart",
      "William Allcock",
      "Wahid Bhimji",
      "Tim Boerner",
      "Ravinderjeet Cheema",
      "Andrew Cherry",
      "Brent Draney",
      "Salman Habib",
      "Damian Hazen",
      "Jason Hill",
      "Matt Kollross",
      "Suzanne Parete-Koon",
      "Daniel Pelfrey",
      "Adrian Pope",
      "Jeff Porter",
      "David Wheeler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.12880"
  },
  {
    "id": "arXiv:2105.14431",
    "title": "Contact Mode Guided Motion Planning for Quasidynamic Dexterous  Manipulation in 3D",
    "abstract": "Contact Mode Guided Motion Planning for Quasidynamic Dexterous  Manipulation in 3D",
    "descriptor": "",
    "authors": [
      "Xianyi Cheng",
      "Eric Huang",
      "Yifan Hou",
      "Matthew T. Mason"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14431"
  },
  {
    "id": "arXiv:2105.14694",
    "title": "Combining resampling and reweighting for faithful stochastic  optimization",
    "abstract": "Comments: More results are added in Section 3",
    "descriptor": "\nComments: More results are added in Section 3\n",
    "authors": [
      "Jing An",
      "Lexing Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.14694"
  },
  {
    "id": "arXiv:2105.15010",
    "title": "QueryNet: An Attack Framework with Surrogates Carrying Multiple  Identities",
    "abstract": "Comments: QueryNet reduces queries by about an order of magnitude against SOTA black-box attacks. 21 pages, 6 figures",
    "descriptor": "\nComments: QueryNet reduces queries by about an order of magnitude against SOTA black-box attacks. 21 pages, 6 figures\n",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.15010"
  },
  {
    "id": "arXiv:2105.15061",
    "title": "All-in-one: Certifiable Optimal Distributed Kalman Filter under Unknown  Correlations",
    "abstract": "Comments: This paper has been accepted at 60th 2021 IEEE Conference on Decision and Control (CDC)",
    "descriptor": "\nComments: This paper has been accepted at 60th 2021 IEEE Conference on Decision and Control (CDC)\n",
    "authors": [
      "Eduardo Sebasti\u00e1n",
      "Eduardo Montijano",
      "Carlos Sag\u00fc\u00e9s"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.15061"
  },
  {
    "id": "arXiv:2106.00952",
    "title": "End-to-End Information Extraction by Character-Level Embedding and  Multi-Stage Attentional U-Net",
    "abstract": "Comments: Accepted to BMVC 2019",
    "descriptor": "\nComments: Accepted to BMVC 2019\n",
    "authors": [
      "Tuan-Anh Nguyen Dang",
      "Dat-Thanh Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.00952"
  },
  {
    "id": "arXiv:2106.03353",
    "title": "Understanding Neural Code Intelligence Through Program Simplification",
    "abstract": "Comments: The 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE'21)",
    "descriptor": "\nComments: The 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE'21)\n",
    "authors": [
      "Md Rafiqul Islam Rabin",
      "Vincent J. Hellendoorn",
      "Mohammad Amin Alipour"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.03353"
  },
  {
    "id": "arXiv:2106.06455",
    "title": "Certifying the LTL Formula p Until q in Hybrid Systems",
    "abstract": "Comments: 20 pages. The technical report accompanying \"Certifying the LTL Formula p Until q in Hybrid Systems\" submitted to IEEE Transactions on Automatic Control, 2021",
    "descriptor": "\nComments: 20 pages. The technical report accompanying \"Certifying the LTL Formula p Until q in Hybrid Systems\" submitted to IEEE Transactions on Automatic Control, 2021\n",
    "authors": [
      "Hyejin Han",
      "Mohamed Maghenem",
      "Ricardo G. Sanfelice"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06455"
  },
  {
    "id": "arXiv:2106.07258",
    "title": "GitTables: A Large-Scale Corpus of Relational Tables",
    "abstract": "GitTables: A Large-Scale Corpus of Relational Tables",
    "descriptor": "",
    "authors": [
      "Madelon Hulsebos",
      "\u00c7a\u011fatay Demiralp",
      "Paul Groth"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07258"
  },
  {
    "id": "arXiv:2106.07843",
    "title": "Teacher-Student MixIT for Unsupervised and Semi-supervised Speech  Separation",
    "abstract": "Comments: Accepted to Interspeech 2021",
    "descriptor": "\nComments: Accepted to Interspeech 2021\n",
    "authors": [
      "Jisi Zhang",
      "Catalin Zorila",
      "Rama Doddipatla",
      "Jon Barker"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.07843"
  },
  {
    "id": "arXiv:2106.10251",
    "title": "Active Offline Policy Selection",
    "abstract": "Active Offline Policy Selection",
    "descriptor": "",
    "authors": [
      "Ksenia Konyushkova",
      "Yutian Chen",
      "Tom Le Paine",
      "Caglar Gulcehre",
      "Cosmin Paduraru",
      "Daniel J Mankowitz",
      "Misha Denil",
      "Nando de Freitas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10251"
  },
  {
    "id": "arXiv:2106.13061",
    "title": "Fea2Fea: Exploring Structural Feature Correlations via Graph Neural  Networks",
    "abstract": "Comments: In proceddings of ECML-PKDD 2021 workshop",
    "descriptor": "\nComments: In proceddings of ECML-PKDD 2021 workshop\n",
    "authors": [
      "Jiaqing Xie",
      "Rex Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.13061"
  },
  {
    "id": "arXiv:2106.13489",
    "title": "Semialgebras and Weak Distributive Laws",
    "abstract": "Semialgebras and Weak Distributive Laws",
    "descriptor": "",
    "authors": [
      "Daniela Petri{\u015f}an",
      "Ralph Sarkis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2106.13489"
  },
  {
    "id": "arXiv:2106.14166",
    "title": "Indoor Panorama Planar 3D Reconstruction via Divide and Conquer",
    "abstract": "Comments: Code at this https URL Video at this https URL",
    "descriptor": "\nComments: Code at this https URL Video at this https URL\n",
    "authors": [
      "Cheng Sun",
      "Chi-Wei Hsiao",
      "Ning-Hsu Wang",
      "Min Sun",
      "Hwann-Tzong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14166"
  },
  {
    "id": "arXiv:2106.14997",
    "title": "Sharp Lower Bounds on the Approximation Rate of Shallow Neural Networks",
    "abstract": "Comments: This paper has been merged with arXiv:2101.12365",
    "descriptor": "\nComments: This paper has been merged with arXiv:2101.12365\n",
    "authors": [
      "Jonathan W. Siegel",
      "Jinchao Xu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2106.14997"
  },
  {
    "id": "arXiv:2107.01198",
    "title": "DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature",
    "abstract": "Comments: Accepted at EMNLP-2021 (System Demonstration Track)",
    "descriptor": "\nComments: Accepted at EMNLP-2021 (System Demonstration Track)\n",
    "authors": [
      "Abheesht Sharma",
      "Gunjan Chhablani",
      "Harshit Pandey",
      "Rajaswa Patil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01198"
  },
  {
    "id": "arXiv:2107.01272",
    "title": "Physics-Guided Deep Learning for Dynamical Systems: A Survey",
    "abstract": "Physics-Guided Deep Learning for Dynamical Systems: A Survey",
    "descriptor": "",
    "authors": [
      "Rui Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01272"
  },
  {
    "id": "arXiv:2107.03601",
    "title": "Superpoint-guided Semi-supervised Semantic Segmentation of 3D Point  Clouds",
    "abstract": "Superpoint-guided Semi-supervised Semantic Segmentation of 3D Point  Clouds",
    "descriptor": "",
    "authors": [
      "Shuang Deng",
      "Qiulei Dong",
      "Bo Liu",
      "Zhanyi Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.03601"
  },
  {
    "id": "arXiv:2107.07579",
    "title": "A Channel Coding Benchmark for Meta-Learning",
    "abstract": "A Channel Coding Benchmark for Meta-Learning",
    "descriptor": "",
    "authors": [
      "Rui Li",
      "Ondrej Bohdal",
      "Rajesh Mishra",
      "Hyeji Kim",
      "Da Li",
      "Nicholas Lane",
      "Timothy Hospedales"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07579"
  },
  {
    "id": "arXiv:2107.09144",
    "title": "Wave-Informed Matrix Factorization with Global Optimality Guarantees",
    "abstract": "Wave-Informed Matrix Factorization with Global Optimality Guarantees",
    "descriptor": "",
    "authors": [
      "Harsha Vardhan Tetali",
      "Joel B. Harley",
      "Benjamin D. Haeffele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.09144"
  },
  {
    "id": "arXiv:2107.09404",
    "title": "Maximizing the Set Cardinality of Users Scheduled for Ultra-dense uRLLC  Networks",
    "abstract": "Comments: 4 pages, 3 figures",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Shiwen He",
      "Jun Yuan",
      "Zhenyu An",
      "Yunshan Yi",
      "Yongming Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.09404"
  },
  {
    "id": "arXiv:2107.10325",
    "title": "A Multi-objective Evolutionary Algorithm for EEG Inverse Problem",
    "abstract": "Comments: 11 pages, 4 figures, 18 references",
    "descriptor": "\nComments: 11 pages, 4 figures, 18 references\n",
    "authors": [
      "Jos\u00e9 Enrique Alvarez Iglesias",
      "Mayrim Vega-Hern\u00e1ndez",
      "Eduardo Mart\u00ednez-Montes"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2107.10325"
  },
  {
    "id": "arXiv:2107.11644",
    "title": "A Tensor-Train Dictionary Learning algorithm based on Spectral Proximal  Alternating Linearized Minimization",
    "abstract": "A Tensor-Train Dictionary Learning algorithm based on Spectral Proximal  Alternating Linearized Minimization",
    "descriptor": "",
    "authors": [
      "Domitilla Brandoni",
      "Margherita Porcelli",
      "Valeria Simoncini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.11644"
  },
  {
    "id": "arXiv:2107.12809",
    "title": "Bayesian Optimisation for Sequential Experimental Design with  Applications in Additive Manufacturing",
    "abstract": "Bayesian Optimisation for Sequential Experimental Design with  Applications in Additive Manufacturing",
    "descriptor": "",
    "authors": [
      "Mimi Zhang",
      "Andrew Parnell",
      "Dermot Brabazon",
      "Alessio Benavoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2107.12809"
  },
  {
    "id": "arXiv:2107.13123",
    "title": "No extremal square-free words over large alphabets",
    "abstract": "Comments: 8 pages, no figures. Found a small mistake in Proposition 2.2 that slightly weakens our bound",
    "descriptor": "\nComments: 8 pages, no figures. Found a small mistake in Proposition 2.2 that slightly weakens our bound\n",
    "authors": [
      "Letong Hong",
      "Shengtong Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.13123"
  },
  {
    "id": "arXiv:2107.14415",
    "title": "Compression Network with Transformer for Approximate Nearest Neighbor  Search",
    "abstract": "Comments: 8 pages and 3 figures",
    "descriptor": "\nComments: 8 pages and 3 figures\n",
    "authors": [
      "Haokui Zhang",
      "Wenze Hu",
      "Buzhou Tang",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.14415"
  },
  {
    "id": "arXiv:2108.00745",
    "title": "Multi-objective Conflict-based Search Using Safe-interval Path Planning",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Zhongqiang Ren",
      "Sivakumar Rathinam",
      "Howie Choset"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.00745"
  },
  {
    "id": "arXiv:2108.01390",
    "title": "Evo-ViT: Slow-Fast Token Evolution for Dynamic Vision Transformer",
    "abstract": "Comments: We propose a novel and effective design for dynamic vision transformer to achieve better computational efficiency. The code is available at this https URL",
    "descriptor": "\nComments: We propose a novel and effective design for dynamic vision transformer to achieve better computational efficiency. The code is available at this https URL\n",
    "authors": [
      "Yifan Xu",
      "Zhijie Zhang",
      "Mengdan Zhang",
      "Kekai Sheng",
      "Ke Li",
      "Weiming Dong",
      "Liqing Zhang",
      "Changsheng Xu",
      "Xing Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01390"
  },
  {
    "id": "arXiv:2108.03372",
    "title": "Neighborhood Consensus Contrastive Learning for Backward-Compatible  Representation",
    "abstract": "Neighborhood Consensus Contrastive Learning for Backward-Compatible  Representation",
    "descriptor": "",
    "authors": [
      "Shengsen Wu",
      "Liang Chen",
      "Yihang Lou",
      "Yan Bai",
      "Tao Bai",
      "Minghua Deng",
      "Lingyu Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.03372"
  },
  {
    "id": "arXiv:2108.04556",
    "title": "SynCoBERT: Syntax-Guided Multi-Modal Contrastive Pre-Training for Code  Representation",
    "abstract": "Comments: 9 pages, 3 figures, 5 tables",
    "descriptor": "\nComments: 9 pages, 3 figures, 5 tables\n",
    "authors": [
      "Xin Wang",
      "Yasheng Wang",
      "Fei Mi",
      "Pingyi Zhou",
      "Yao Wan",
      "Xiao Liu",
      "Li Li",
      "Hao Wu",
      "Jin Liu",
      "Xin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.04556"
  },
  {
    "id": "arXiv:2108.04619",
    "title": "An Uncertainty-Aware Performance Measure for Multi-Object Tracking",
    "abstract": "Comments: Accepted to IEEE Signal Processing Letters 2021",
    "descriptor": "\nComments: Accepted to IEEE Signal Processing Letters 2021\n",
    "authors": [
      "Juliano Pinto",
      "Yuxuan Xia",
      "Lennart Svensson",
      "Henk Wymeersch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.04619"
  },
  {
    "id": "arXiv:2108.05045",
    "title": "Semi-Supervised Domain Generalizable Person Re-Identification",
    "abstract": "Semi-Supervised Domain Generalizable Person Re-Identification",
    "descriptor": "",
    "authors": [
      "Lingxiao He",
      "Wu Liu",
      "Jian Liang",
      "Kecheng Zheng",
      "Xingyu Liao",
      "Peng Cheng",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.05045"
  },
  {
    "id": "arXiv:2108.05170",
    "title": "ProAI: An Efficient Embedded AI Hardware for Automotive Applications --  a Benchmark Study",
    "abstract": "Comments: Accepted by IEEE International Conference on Computer Vision (ICCV) 2021",
    "descriptor": "\nComments: Accepted by IEEE International Conference on Computer Vision (ICCV) 2021\n",
    "authors": [
      "Sven Mantowsky",
      "Falk Heuer",
      "Syed Saqib Bukhari",
      "Michael Keckeisen",
      "Georg Schneider"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.05170"
  },
  {
    "id": "arXiv:2108.07465",
    "title": "Star transposition Gray codes for multiset permutations",
    "abstract": "Star transposition Gray codes for multiset permutations",
    "descriptor": "",
    "authors": [
      "Petr Gregor",
      "Arturo Merino",
      "Torsten M\u00fctze"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2108.07465"
  },
  {
    "id": "arXiv:2108.10097",
    "title": "Graph Attention Multi-Layer Perceptron",
    "abstract": "Comments: 12 pages, 4 figures",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Wentao Zhang",
      "Ziqi Yin",
      "Zeang Sheng",
      "Wen Ouyang",
      "Xiaosen Li",
      "Yangyu Tao",
      "Zhi Yang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.10097"
  },
  {
    "id": "arXiv:2108.10511",
    "title": "CMML: Contextual Modulation Meta Learning for Cold-Start Recommendation",
    "abstract": "Comments: corresponding to &lt;xidong.feng.20@ucl.ac.uk&gt;; Accepted by CIKM 2021",
    "descriptor": "\nComments: corresponding to &lt;xidong.feng.20@ucl.ac.uk&gt;; Accepted by CIKM 2021\n",
    "authors": [
      "Xidong Feng",
      "Chen Chen",
      "Dong Li",
      "Mengchen Zhao",
      "Jianye Hao",
      "Jun Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.10511"
  },
  {
    "id": "arXiv:2108.12463",
    "title": "Automatic Text Evaluation through the Lens of Wasserstein Barycenters",
    "abstract": "Automatic Text Evaluation through the Lens of Wasserstein Barycenters",
    "descriptor": "",
    "authors": [
      "Pierre Colombo",
      "Guillaume Staerman",
      "Chloe Clavel",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.12463"
  },
  {
    "id": "arXiv:2108.12465",
    "title": "Code-switched inspired losses for generic spoken dialog representations",
    "abstract": "Code-switched inspired losses for generic spoken dialog representations",
    "descriptor": "",
    "authors": [
      "Emile Chapuis",
      "Pierre Colombo",
      "Matthieu Labeau",
      "Chloe Clavel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.12465"
  },
  {
    "id": "arXiv:2108.12870",
    "title": "Multiplex Graph Neural Network for Extractive Text Summarization",
    "abstract": "Comments: Accepted by EMNLP'2021",
    "descriptor": "\nComments: Accepted by EMNLP'2021\n",
    "authors": [
      "Baoyu Jing",
      "Zeyu You",
      "Tao Yang",
      "Wei Fan",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.12870"
  },
  {
    "id": "arXiv:2108.13039",
    "title": "An Interpretable Web-based Glioblastoma Multiforme Prognosis Prediction  Tool using Random Forest Model",
    "abstract": "Comments: This version of preprint has some issues regarding methods and results",
    "descriptor": "\nComments: This version of preprint has some issues regarding methods and results\n",
    "authors": [
      "Yeseul Kim",
      "Kyung Hwan Kim",
      "Junyoung Park",
      "Hong In Yoon",
      "Wonmo Sung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13039"
  },
  {
    "id": "arXiv:2108.13055",
    "title": "Efficient Visual Recognition with Deep Neural Networks: A Survey on  Recent Advances and New Directions",
    "abstract": "Efficient Visual Recognition with Deep Neural Networks: A Survey on  Recent Advances and New Directions",
    "descriptor": "",
    "authors": [
      "Yang Wu",
      "Dingheng Wang",
      "Xiaotong Lu",
      "Fan Yang",
      "Guoqi Li",
      "Weisheng Dong",
      "Jianbo Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13055"
  },
  {
    "id": "arXiv:2109.00101",
    "title": "Position-based Hash Embeddings For Scaling Graph Neural Networks",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Maria Kalantzi",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.00101"
  },
  {
    "id": "arXiv:2109.00228",
    "title": "Deployable Networks for Public Safety in 5G and Beyond: A Coverage and  Interference Study",
    "abstract": "Deployable Networks for Public Safety in 5G and Beyond: A Coverage and  Interference Study",
    "descriptor": "",
    "authors": [
      "Zhiqiang Qi",
      "Adri\u00e1n Lahuerta-Lavieja",
      "Jingya Li",
      "Keerthi Kumar Nagalapur"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.00228"
  },
  {
    "id": "arXiv:2109.00709",
    "title": "An Information-Theoretic View of Stochastic Localization",
    "abstract": "Comments: 8 pages; v2 corrects an annoying typo in the statement of the main theorem",
    "descriptor": "\nComments: 8 pages; v2 corrects an annoying typo in the statement of the main theorem\n",
    "authors": [
      "Ahmed El Alaoui",
      "Andrea Montanari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.00709"
  },
  {
    "id": "arXiv:2109.00720",
    "title": "LightNER: A Lightweight Generative Framework with Prompt-guided  Attention for Low-resource NER",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Xiang Chen",
      "Ningyu Zhang",
      "Lei Li",
      "Xin Xie",
      "Shumin Deng",
      "Chuanqi Tan",
      "Fei Huang",
      "Luo Si",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.00720"
  },
  {
    "id": "arXiv:2109.00922",
    "title": "Improving Multimodal fusion via Mutual Dependency Maximisation",
    "abstract": "Improving Multimodal fusion via Mutual Dependency Maximisation",
    "descriptor": "",
    "authors": [
      "Pierre Colombo",
      "Emile Chapuis",
      "Matthieu Labeau",
      "Chloe Clavel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.00922"
  },
  {
    "id": "arXiv:2109.00968",
    "title": "Self-supervised Representation Learning for Trip Recommendation",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Qiang Gao",
      "Wei Wang",
      "Kunpeng Zhang",
      "Xin Yang",
      "Congcong Miao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.00968"
  },
  {
    "id": "arXiv:2109.01049",
    "title": "Image-Binary Automata",
    "abstract": "Comments: Full version of paper published at DCFS'21",
    "descriptor": "\nComments: Full version of paper published at DCFS'21\n",
    "authors": [
      "Stefan Kiefer",
      "Cas Widdershoven"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2109.01049"
  },
  {
    "id": "arXiv:2109.01417",
    "title": "Event-Based Communication in Multi-Agent Distributed Q-Learning",
    "abstract": "Event-Based Communication in Multi-Agent Distributed Q-Learning",
    "descriptor": "",
    "authors": [
      "Daniel Jarne Ornia",
      "Manuel Mazo Jr"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.01417"
  },
  {
    "id": "arXiv:2109.02008",
    "title": "Sparse-MLP: A Fully-MLP Architecture with Conditional Computation",
    "abstract": "Sparse-MLP: A Fully-MLP Architecture with Conditional Computation",
    "descriptor": "",
    "authors": [
      "Yuxuan Lou",
      "Fuzhao Xue",
      "Zangwei Zheng",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.02008"
  },
  {
    "id": "arXiv:2109.02066",
    "title": "Hierarchical Object-to-Zone Graph for Object Navigation",
    "abstract": "Comments: Accepted by ICCV21",
    "descriptor": "\nComments: Accepted by ICCV21\n",
    "authors": [
      "Sixian Zhang",
      "Xinhang Song",
      "Yubing Bai",
      "Weijie Li",
      "Yakui Chu",
      "Shuqiang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.02066"
  },
  {
    "id": "arXiv:2109.02095",
    "title": "Linear complexity over ${\\mathbb{F}_{q}}$ and 2-adic complexity of a  class of binary generalized cyclotomic sequences with low-value  autocorrelation",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Yan Wang",
      "Xilin Han",
      "Weiqiong Wang",
      "Ziling Heng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.02095"
  },
  {
    "id": "arXiv:2109.02747",
    "title": "WhyAct: Identifying Action Reasons in Lifestyle Vlogs",
    "abstract": "Comments: Accepted at EMNLP 2021",
    "descriptor": "\nComments: Accepted at EMNLP 2021\n",
    "authors": [
      "Oana Ignat",
      "Santiago Castro",
      "Hanwen Miao",
      "Weiji Li",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.02747"
  },
  {
    "id": "arXiv:2109.03002",
    "title": "Analysis and computation of a pressure-robust method for the rotation  form of the stationary incompressible Navier-Stokes equations by using  high-order finite elements",
    "abstract": "Comments: 43 pages, 28 figures",
    "descriptor": "\nComments: 43 pages, 28 figures\n",
    "authors": [
      "Di Yang",
      "Yinnian He"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.03002"
  },
  {
    "id": "arXiv:2109.03082",
    "title": "Perceptual Learned Video Compression with Recurrent Conditional GAN",
    "abstract": "Perceptual Learned Video Compression with Recurrent Conditional GAN",
    "descriptor": "",
    "authors": [
      "Ren Yang",
      "Luc Van Gool",
      "Radu Timofte"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03082"
  },
  {
    "id": "arXiv:2109.03152",
    "title": "Acceleration of the order of convergence of a family of fractional fixed  point methods and its implementation in the solution of a nonlinear algebraic  system related to hybrid solar receivers",
    "abstract": "Acceleration of the order of convergence of a family of fractional fixed  point methods and its implementation in the solution of a nonlinear algebraic  system related to hybrid solar receivers",
    "descriptor": "",
    "authors": [
      "A. Torres-Hernandez",
      "F. Brambila-Paz",
      "R. Montufar-Chaveznava"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.03152"
  },
  {
    "id": "arXiv:2109.03158",
    "title": "Idiosyncratic but not Arbitrary: Learning Idiolects in Online Registers  Reveals Distinctive yet Consistent Individual Styles",
    "abstract": "Comments: EMNLP 2021 main conference",
    "descriptor": "\nComments: EMNLP 2021 main conference\n",
    "authors": [
      "Jian Zhu",
      "David Jurgens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03158"
  },
  {
    "id": "arXiv:2109.03160",
    "title": "How much pretraining data do language models need to learn syntax?",
    "abstract": "Comments: To be published in proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP 2021)",
    "descriptor": "\nComments: To be published in proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP 2021)\n",
    "authors": [
      "Laura P\u00e9rez-Mayos",
      "Miguel Ballesteros",
      "Leo Wanner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03160"
  },
  {
    "id": "arXiv:2109.03201",
    "title": "nnFormer: Interleaved Transformer for Volumetric Segmentation",
    "abstract": "Comments: Codes and models are available at this https URL",
    "descriptor": "\nComments: Codes and models are available at this https URL\n",
    "authors": [
      "Hong-Yu Zhou",
      "Jiansen Guo",
      "Yinghao Zhang",
      "Lequan Yu",
      "Liansheng Wang",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03201"
  },
  {
    "id": "arXiv:2109.03237",
    "title": "MRI Reconstruction Using Deep Energy-Based Model",
    "abstract": "Comments: 36 pages, 9 figures",
    "descriptor": "\nComments: 36 pages, 9 figures\n",
    "authors": [
      "Yu Guan",
      "Zongjiang Tu",
      "Shanshan Wang",
      "Qiegen Liu",
      "Yuhao Wang",
      "Dong Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03237"
  },
  {
    "id": "arXiv:2109.03385",
    "title": "RoadAtlas: Intelligent Platform for Automated Road Defect Detection and  Asset Management",
    "abstract": "Comments: Demonstration slides attached. To view attachments, please download the file listed under \"Ancillary files\"",
    "descriptor": "\nComments: Demonstration slides attached. To view attachments, please download the file listed under \"Ancillary files\"\n",
    "authors": [
      "Zhuoxiao Chen",
      "Yiyun Zhang",
      "Yadan Luo",
      "Zijian Wang",
      "Jinjiang Zhong",
      "Anthony Southon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2109.03385"
  },
  {
    "id": "arXiv:2109.03393",
    "title": "Learning to Discriminate Information for Online Action Detection:  Analysis and Application",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: substantial text overlap with arXiv:1912.04461",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: substantial text overlap with arXiv:1912.04461\n",
    "authors": [
      "Sumin Lee",
      "Hyunjun Eun",
      "Jinyoung Moon",
      "Seokeon Choi",
      "Yoonhyung Kim",
      "Chanho Jung",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03393"
  },
  {
    "id": "arXiv:2109.03423",
    "title": "It is AI's Turn to Ask Human a Question: Question and Answer Pair  Generation for Children Storybooks in FairytaleQA Dataset",
    "abstract": "It is AI's Turn to Ask Human a Question: Question and Answer Pair  Generation for Children Storybooks in FairytaleQA Dataset",
    "descriptor": "",
    "authors": [
      "Bingsheng Yao",
      "Dakuo Wang",
      "Tongshuang Wu",
      "Tran Hoang",
      "Branda Sun",
      "Toby Jia-Jun Li",
      "Mo Yu",
      "Ying Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03423"
  },
  {
    "id": "arXiv:2109.03438",
    "title": "ArchivalQA: A Large-scale Benchmark Dataset for Open Domain Question  Answering over Archival News Collections",
    "abstract": "ArchivalQA: A Large-scale Benchmark Dataset for Open Domain Question  Answering over Archival News Collections",
    "descriptor": "",
    "authors": [
      "Jiexin Wang",
      "Adam Jatowt",
      "Masatoshi Yoshikawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03438"
  },
  {
    "id": "arXiv:2109.03484",
    "title": "Shuffled Patch-Wise Supervision for Presentation Attack Detection",
    "abstract": "Comments: Accepted to 20th International Conference of the Biometrics Special Interest Group (BIOSIG 2021) as Oral paper",
    "descriptor": "\nComments: Accepted to 20th International Conference of the Biometrics Special Interest Group (BIOSIG 2021) as Oral paper\n",
    "authors": [
      "Alperen Kantarc\u0131",
      "Hasan Dertli",
      "Haz\u0131m Kemal Ekenel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03484"
  },
  {
    "id": "arXiv:2109.03486",
    "title": "Contrarian effect in opinion forming: insights from Greta Thunberg  phenomenon",
    "abstract": "Contrarian effect in opinion forming: insights from Greta Thunberg  phenomenon",
    "descriptor": "",
    "authors": [
      "Elisa Iacomini",
      "Pierluigi Vellucci"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.03486"
  },
  {
    "id": "arXiv:2109.03523",
    "title": "The convergence of the Regula Falsi method",
    "abstract": "The convergence of the Regula Falsi method",
    "descriptor": "",
    "authors": [
      "Trung Nguyen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.03523"
  },
  {
    "id": "arXiv:2109.03540",
    "title": "A Survey of Deep Reinforcement Learning in Recommender Systems: A  Systematic Review and Future Directions",
    "abstract": "A Survey of Deep Reinforcement Learning in Recommender Systems: A  Systematic Review and Future Directions",
    "descriptor": "",
    "authors": [
      "Xiaocong Chen",
      "Lina Yao",
      "Julian McAuley",
      "Guanglin Zhou",
      "Xianzhi Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.03540"
  },
  {
    "id": "arXiv:2109.03602",
    "title": "SecRSL: Security Separation Logic for C11 Release-Acquire Concurrency  (Extended version with technical appendices)",
    "abstract": "Comments: Extended version of conference paper published at OOPSLA 2021",
    "descriptor": "\nComments: Extended version of conference paper published at OOPSLA 2021\n",
    "authors": [
      "Pengbo Yan",
      "Toby Murray"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.03602"
  },
  {
    "id": "arXiv:2109.03667",
    "title": "Energy Footprint of Blockchain Consensus Mechanisms Beyond Proof-of-Work",
    "abstract": "Energy Footprint of Blockchain Consensus Mechanisms Beyond Proof-of-Work",
    "descriptor": "",
    "authors": [
      "Moritz Platt",
      "Johannes Sedlmeir",
      "Daniel Platt",
      "Ulrich Gallersd\u00f6rfer",
      "Paolo Tasca",
      "Jiahua Xu",
      "Nikhil Vadgama",
      "Juan Ignacio Iba\u00f1ez"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.03667"
  },
  {
    "id": "arXiv:2109.03781",
    "title": "Highly Scalable and Provably Accurate Classification in Poincare Balls",
    "abstract": "Comments: A short version of this paper appears in ICDM 2021",
    "descriptor": "\nComments: A short version of this paper appears in ICDM 2021\n",
    "authors": [
      "Eli Chien",
      "Chao Pan",
      "Puoya Tabaghi",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03781"
  }
]
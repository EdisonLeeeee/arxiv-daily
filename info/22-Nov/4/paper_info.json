[
  {
    "id": "arXiv:2211.01369",
    "title": "Gravitational Dimensionality Reduction Using Newtonian Gravity and  Einstein's General Relativity",
    "abstract": "Due to the effectiveness of using machine learning in physics, it has been\nwidely received increased attention in the literature. However, the notion of\napplying physics in machine learning has not been given much awareness to. This\nwork is a hybrid of physics and machine learning where concepts of physics are\nused in machine learning. We propose the supervised Gravitational\nDimensionality Reduction (GDR) algorithm where the data points of every class\nare moved to each other for reduction of intra-class variances and better\nseparation of classes. For every data point, the other points are considered to\nbe gravitational particles, such as stars, where the point is attracted to the\npoints of its class by gravity. The data points are first projected onto a\nspacetime manifold using principal component analysis. We propose two variants\nof GDR -- one with the Newtonian gravity and one with the Einstein's general\nrelativity. The former uses Newtonian gravity in a straight line between points\nbut the latter moves data points along the geodesics of spacetime manifold. For\nGDR with relativity gravitation, we use both Schwarzschild and Minkowski metric\ntensors to cover both general relativity and special relativity. Our\nsimulations show the effectiveness of GDR in discrimination of classes.",
    "descriptor": "",
    "authors": [
      "Benyamin Ghojogh",
      "Smriti Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.01369"
  },
  {
    "id": "arXiv:2211.01370",
    "title": "Class Interference of Deep Neural Networks",
    "abstract": "Recognizing and telling similar objects apart is even hard for human beings.\nIn this paper, we show that there is a phenomenon of class interference with\nall deep neural networks. Class interference represents the learning difficulty\nin data, and it constitutes the largest percentage of generalization errors by\ndeep networks. To understand class interference, we propose cross-class tests,\nclass ego directions and interference models. We show how to use these\ndefinitions to study minima flatness and class interference of a trained model.\nWe also show how to detect class interference during training through label\ndancing pattern and class dancing notes.",
    "descriptor": "",
    "authors": [
      "Dongcui Diao",
      "Hengshuai Yao",
      "Bei Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01370"
  },
  {
    "id": "arXiv:2211.01407",
    "title": "On the Informativeness of Supervision Signals",
    "abstract": "Learning transferable representations by training a classifier is a\nwell-established technique in deep learning (e.g., ImageNet pretraining), but\nit remains an open theoretical question why this kind of task-specific\npre-training should result in ''good'' representations that actually capture\nthe underlying structure of the data. We conduct an information-theoretic\nanalysis of several commonly-used supervision signals from contrastive learning\nand classification to determine how they contribute to representation learning\nperformance and how the dynamics of learning are affected by training\nparameters such as the number of labels, classes, and dimensions in the\ntraining dataset. We validate these results empirically in a series of\nsimulations and conduct a cost-benefit analysis to establish a tradeoff curve\nthat enables users to optimize the cost of supervising representation learning\non their own datasets.",
    "descriptor": "",
    "authors": [
      "Ilia Sucholutsky",
      "Raja Marjieh",
      "Nori Jacoby",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01407"
  },
  {
    "id": "arXiv:2211.01412",
    "title": "CAMANet: Class Activation Map Guided Attention Network for Radiology  Report Generation",
    "abstract": "Radiology report generation (RRG) has gained increasing research attention\nbecause of its huge potential to mitigate medical resource shortages and aid\nthe process of disease decision making by radiologists. Recent advancements in\nRadiology Report Generation (RRG) are largely driven by improving models'\ncapabilities in encoding single-modal feature representations, while few\nstudies explore explicitly the cross-modal alignment between image regions and\nwords. Radiologists typically focus first on abnormal image regions before they\ncompose the corresponding text descriptions, thus cross-modal alignment is of\ngreat importance to learn an abnormality-aware RRG model. Motivated by this, we\npropose a Class Activation Map guided Attention Network (CAMANet) which\nexplicitly promotes cross-modal alignment by employing the aggregated class\nactivation maps to supervise the cross-modal attention learning, and\nsimultaneously enriches the discriminative information. Experimental results\ndemonstrate that CAMANet outperforms previous SOTA methods on two commonly used\nRRG benchmarks.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Jun Wang",
      "Abhir Bhalerao",
      "Terry Yin",
      "Simon See",
      "Yulan He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01412"
  },
  {
    "id": "arXiv:2211.01413",
    "title": "XAI-Increment: A Novel Approach Leveraging LIME Explanations for  Improved Incremental Learning",
    "abstract": "Explainability of neural network prediction is essential to understand\nfeature importance and gain interpretable insight into neural network\nperformance. In this work, model explanations are fed back to the feed-forward\ntraining to help the model generalize better. To this extent, a custom weighted\nloss where the weights are generated by considering the Euclidean distances\nbetween true LIME (Local Interpretable Model-Agnostic Explanations)\nexplanations and model-predicted LIME explanations is proposed. Also, in\npractical training scenarios, developing a solution that can help the model\nlearn sequentially without losing information on previous data distribution is\nimperative due to the unavailability of all the training data at once. Thus,\nthe framework known as XAI-Increment incorporates the custom weighted loss\ndeveloped with elastic weight consolidation (EWC), to maintain performance in\nsequential testing sets. Finally, the training procedure involving the custom\nweighted loss shows around 1% accuracy improvement compared to the traditional\nloss based training for the keyword spotting task on the Google Speech Commands\ndataset and also shows low loss of information when coupled with EWC in the\nincremental learning setup.",
    "descriptor": "",
    "authors": [
      "Arnab Neelim Mazumder",
      "Niall Lyons",
      "Anand Dubey",
      "Ashutosh Pandey",
      "Avik Santra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01413"
  },
  {
    "id": "arXiv:2211.01426",
    "title": "Reciprocity, Homophily, and Social Network Effects in Pictorial  Communication: A Case Study of Bitmoji Stickers",
    "abstract": "Pictorial emojis and stickers are commonly used in online social networking\nto facilitate and aid communications. We delve into the use of Bitmoji\nstickers, a highly expressive form of pictorial communication using avatars\nresembling actual users. We collect a large-scale dataset of the metadata of 3\nbillion Bitmoji stickers shared among 300 million Snapchat users. We find that\nindividual Bitmoji sticker usage patterns can be characterized jointly on\ndimensions of reciprocity and selectivity: Users are either both reciprocal and\nselective about whom they use Bitmoji stickers with or neither reciprocal nor\nselective. We additionally provide evidence of network homophily in that\nfriends use Bitmoji stickers at similar rates. Finally, using a\nquasi-experimental approach, we show that receiving Bitmoji stickers from a\nfriend encourages future Bitmoji sticker usage and overall Snapchat engagement.\nWe discuss broader implications of our work towards a better understanding of\npictorial communication behaviors in social networks.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Julie Jiang",
      "Ron Dotsch",
      "Mireia Triguero Roura",
      "Yozen Liu",
      "Vitor Silva",
      "Maarten W. Bos",
      "Francesco Barbieri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.01426"
  },
  {
    "id": "arXiv:2211.01427",
    "title": "TextCraft: Zero-Shot Generation of High-Fidelity and Diverse Shapes from  Text",
    "abstract": "Language is one of the primary means by which we describe the 3D world around\nus. While rapid progress has been made in text-to-2D-image synthesis, similar\nprogress in text-to-3D-shape synthesis has been hindered by the lack of paired\n(text, shape) data. Moreover, extant methods for text-to-shape generation have\nlimited shape diversity and fidelity. We introduce TextCraft, a method to\naddress these limitations by producing high-fidelity and diverse 3D shapes\nwithout the need for (text, shape) pairs for training. TextCraft achieves this\nby using CLIP and using a multi-resolution approach by first generating in a\nlow-dimensional latent space and then upscaling to a higher resolution,\nimproving the fidelity of the generated shape. To improve shape diversity, we\nuse a discrete latent space which is modelled using a bidirectional transformer\nconditioned on the interchangeable image-text embedding space induced by CLIP.\nMoreover, we present a novel variant of classifier-free guidance, which further\nimproves the accuracy-diversity trade-off. Finally, we perform extensive\nexperiments that demonstrate that TextCraft outperforms state-of-the-art\nbaselines.",
    "descriptor": "",
    "authors": [
      "Aditya Sanghi",
      "Rao Fu",
      "Vivian Liu",
      "Karl Willis",
      "Hooman Shayani",
      "Amir Hosein Khasahmadi",
      "Srinath Sridhar",
      "Daniel Ritchie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01427"
  },
  {
    "id": "arXiv:2211.01430",
    "title": "Hierarchies over Vector Space: Orienting Word and Graph Embeddings",
    "abstract": "Word and graph embeddings are widely used in deep learning applications. We\npresent a data structure that captures inherent hierarchical properties from an\nunordered flat embedding space, particularly a sense of direction between pairs\nof entities. Inspired by the notion of \\textit{distributional generality}, our\nalgorithm constructs an arborescence (a directed rooted tree) by inserting\nnodes in descending order of entity power (e.g., word frequency), pointing each\nentity to the closest more powerful node as its parent.\nWe evaluate the performance of the resulting tree structures on three tasks:\nhypernym relation discovery, least-common-ancestor (LCA) discovery among words,\nand Wikipedia page link recovery. We achieve average 8.98\\% and 2.70\\% for\nhypernym and LCA discovery across five languages and 62.76\\% accuracy on\ndirected Wiki-page link recovery, with both substantially above baselines.\nFinally, we investigate the effect of insertion order, the power/similarity\ntrade-off and various power sources to optimize parent selection.",
    "descriptor": "",
    "authors": [
      "Xingzhi Guo",
      "Steven Skiena"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01430"
  },
  {
    "id": "arXiv:2211.01432",
    "title": "Cross-stitching Text and Knowledge Graph Encoders for Distantly  Supervised Relation Extraction",
    "abstract": "Bi-encoder architectures for distantly-supervised relation extraction are\ndesigned to make use of the complementary information found in text and\nknowledge graphs (KG). However, current architectures suffer from two\ndrawbacks. They either do not allow any sharing between the text encoder and\nthe KG encoder at all, or, in case of models with KG-to-text attention, only\nshare information in one direction. Here, we introduce cross-stitch\nbi-encoders, which allow full interaction between the text encoder and the KG\nencoder via a cross-stitch mechanism. The cross-stitch mechanism allows sharing\nand updating representations between the two encoders at any layer, with the\namount of sharing being dynamically controlled via cross-attention-based gates.\nExperimental results on two relation extraction benchmarks from two different\ndomains show that enabling full interaction between the two encoders yields\nstrong improvements.",
    "descriptor": "",
    "authors": [
      "Qin Dai",
      "Benjamin Heinzerling",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01432"
  },
  {
    "id": "arXiv:2211.01434",
    "title": "Spectral Graph Complexity",
    "abstract": "We introduce a spectral notion of graph complexity derived from the Weyl's\nlaw. We experimentally demonstrate its correlation to how well the graph can be\nembedded in a low-dimensional Euclidean space.",
    "descriptor": "\nComments: BigNet workshop at the Web conferece'2019\n",
    "authors": [
      "Anton Tsitsulin",
      "Davide Mottin",
      "Panagiotis Karras",
      "Alex Bronstein",
      "Emmanuel M\u00fcller"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.01434"
  },
  {
    "id": "arXiv:2211.01442",
    "title": "Towards Statistical Methods for Minimizing Effects of Failure Cascades",
    "abstract": "This paper concerns the potential of corrective actions, such as generation\nand load dispatch on minimizing the effects of transmission line failures in\nelectric power systems. Three loss functions (grid-centric, consumer-centric,\nand influence localization) are used to statistically evaluate the criticality\nof initial contingent failures. A learning scheme for both AC and DC grid\nmodels combine a Monte Carlo approach with a convex dynamic programming\nformulation and introduces an adaptive selection process, illustrated on the\nIEEE-30 bus system.",
    "descriptor": "\nComments: Pre-print submitted to ACC 2023\n",
    "authors": [
      "Siyu Liu",
      "Marija Ilic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01442"
  },
  {
    "id": "arXiv:2211.01443",
    "title": "Improved Inapproximability of VC Dimension and Littlestone's Dimension  via (Unbalanced) Biclique",
    "abstract": "We study the complexity of computing (and approximating) VC Dimension and\nLittlestone's Dimension when we are given the concept class explicitly. We give\na simple reduction from Maximum (Unbalanced) Biclique problem to approximating\nVC Dimension and Littlestone's Dimension. With this connection, we derive a\nrange of hardness of approximation results and running time lower bounds. For\nexample, under the (randomized) Gap-Exponential Time Hypothesis or the\nStrongish Planted Clique Hypothesis, we show a tight inapproximability result:\nboth dimensions are hard to approximate to within a factor of $o(\\log n)$ in\npolynomial-time. These improve upon constant-factor inapproximability results\nfrom [Manurangsi and Rubinstein, COLT 2017].",
    "descriptor": "\nComments: To appear in ITCS 2023\n",
    "authors": [
      "Pasin Manurangsi"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01443"
  },
  {
    "id": "arXiv:2211.01446",
    "title": "FUNCK: Information Funnels and Bottlenecks for Invariant Representation  Learning",
    "abstract": "Learning invariant representations that remain useful for a downstream task\nis still a key challenge in machine learning. We investigate a set of related\ninformation funnels and bottleneck problems that claim to learn invariant\nrepresentations from the data. We also propose a new element to this family of\ninformation-theoretic objectives: The Conditional Privacy Funnel with Side\nInformation, which we investigate in fully and semi-supervised settings. Given\nthe generally intractable objectives, we derive tractable approximations using\namortized variational inference parameterized by neural networks and study the\nintrinsic trade-offs of these objectives. We describe empirically the proposed\napproach and show that with a few labels it is possible to learn fair\nclassifiers and generate useful representations approximately invariant to\nunwanted sources of variation. Furthermore, we provide insights about the\napplicability of these methods in real-world scenarios with ordinary tabular\ndatasets when the data is scarce.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Jo\u00e3o Machado de Freitas",
      "Bernhard C. Geiger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01446"
  },
  {
    "id": "arXiv:2211.01451",
    "title": "Privacy-preserving Non-negative Matrix Factorization with Outliers",
    "abstract": "Non-negative matrix factorization is a popular unsupervised machine learning\nalgorithm for extracting meaningful features from data which are inherently\nnon-negative. However, such data sets may often contain privacy-sensitive user\ndata, and therefore, we may need to take necessary steps to ensure the privacy\nof the users while analyzing the data. In this work, we focus on developing a\nNon-negative matrix factorization algorithm in the privacy-preserving\nframework. More specifically, we propose a novel privacy-preserving algorithm\nfor non-negative matrix factorisation capable of operating on private data,\nwhile achieving results comparable to those of the non-private algorithm. We\ndesign the framework such that one has the control to select the degree of\nprivacy grantee based on the utility gap. We show our proposed framework's\nperformance in six real data sets. The experimental results show that our\nproposed method can achieve very close performance with the non-private\nalgorithm under some parameter regime, while ensuring strict privacy.",
    "descriptor": "",
    "authors": [
      "Swapnil Saha",
      "Hafiz Imtiaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01451"
  },
  {
    "id": "arXiv:2211.01452",
    "title": "MPCFormer: fast, performant and private Transformer inference with MPC",
    "abstract": "Enabling private inference is crucial for many cloud inference services that\nare based on Transformer models. However, existing private inference solutions\nfor Transformers can increase the inference latency by more than 60x or\nsignificantly compromise the quality of inference results. In this paper, we\ndesign the framework MPCFORMER using secure multi-party computation (MPC) and\nKnowledge Distillation (KD). It can be used in tandem with many specifically\ndesigned MPC-friendly approximations and trained Transformer models. MPCFORMER\nsignificantly speeds up Transformer model inference in MPC settings while\nachieving similar ML performance to the input model. We evaluate MPCFORMER with\nvarious settings in MPC. On the IMDb dataset, we achieve similar performance to\nBERTBASE, while being 5.3x faster. On the GLUE benchmark, we achieve 97%\nperformance of BERTBASE with a 2.2x speedup. We show that MPCFORMER remains\neffective with different trained Transformer weights such as ROBERTABASE and\nlarger models including BERTLarge. In particular, we achieve similar\nperformance to BERTLARGE, while being 5.93x faster on the IMDb dataset.",
    "descriptor": "",
    "authors": [
      "Dacheng Li",
      "Rulin Shao",
      "Hongyi Wang",
      "Han Guo",
      "Eric P. Xing",
      "Hao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01452"
  },
  {
    "id": "arXiv:2211.01454",
    "title": "Speeding up NAS with Adaptive Subset Selection",
    "abstract": "A majority of recent developments in neural architecture search (NAS) have\nbeen aimed at decreasing the computational cost of various techniques without\naffecting their final performance. Towards this goal, several low-fidelity and\nperformance prediction methods have been considered, including those that train\nonly on subsets of the training data. In this work, we present an adaptive\nsubset selection approach to NAS and present it as complementary to\nstate-of-the-art NAS approaches. We uncover a natural connection between\none-shot NAS algorithms and adaptive subset selection and devise an algorithm\nthat makes use of state-of-the-art techniques from both areas. We use these\ntechniques to substantially reduce the runtime of DARTS-PT (a leading one-shot\nNAS algorithm), as well as BOHB and DEHB (leading multifidelity optimization\nalgorithms), without sacrificing accuracy. Our results are consistent across\nmultiple datasets, and towards full reproducibility, we release our code at\nhttps: //anonymous.4open.science/r/SubsetSelection NAS-B132.",
    "descriptor": "",
    "authors": [
      "Vishak Prasad C",
      "Colin White",
      "Paarth Jain",
      "Sibasis Nayak",
      "Ganesh Ramakrishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01454"
  },
  {
    "id": "arXiv:2211.01455",
    "title": "PI is back! Switching Acquisition Functions in Bayesian Optimization",
    "abstract": "Bayesian Optimization (BO) is a powerful, sample-efficient technique to\noptimize expensive-to-evaluate functions. Each of the BO components, such as\nthe surrogate model, the acquisition function (AF), or the initial design, is\nsubject to a wide range of design choices. Selecting the right components for a\ngiven optimization task is a challenging task, which can have significant\nimpact on the quality of the obtained results. In this work, we initiate the\nanalysis of which AF to favor for which optimization scenarios. To this end, we\nbenchmark SMAC3 using Expected Improvement (EI) and Probability of Improvement\n(PI) as acquisition functions on the 24 BBOB functions of the COCO environment.\nWe compare their results with those of schedules switching between AFs. One\nschedule aims to use EI's explorative behavior in the early optimization steps,\nand then switches to PI for a better exploitation in the final steps. We also\ncompare this to a random schedule and round-robin selection of EI and PI. We\nobserve that dynamic schedules oftentimes outperform any single static one. Our\nresults suggest that a schedule that allocates the first 25 % of the\noptimization budget to EI and the last 75 % to PI is a reliable default.\nHowever, we also observe considerable performance differences for the 24\nfunctions, suggesting that a per-instance allocation, possibly learned on the\nfly, could offer significant improvement over the state-of-the-art BO designs.",
    "descriptor": "\nComments: 2022 NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems\n",
    "authors": [
      "Carolin Benjamins",
      "Elena Raponi",
      "Anja Jankovic",
      "Koen van der Blom",
      "Maria Laura Santoni",
      "Marius Lindauer",
      "Carola Doerr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01455"
  },
  {
    "id": "arXiv:2211.01458",
    "title": "Towards Zero-Shot Code-Switched Speech Recognition",
    "abstract": "In this work, we seek to build effective code-switched (CS) automatic speech\nrecognition systems (ASR) under the zero-shot setting where no transcribed CS\nspeech data is available for training. Previously proposed frameworks which\nconditionally factorize the bilingual task into its constituent monolingual\nparts are a promising starting point for leveraging monolingual data\nefficiently. However, these methods require the monolingual modules to perform\nlanguage segmentation. That is, each monolingual module has to simultaneously\ndetect CS points and transcribe speech segments of one language while ignoring\nthose of other languages -- not a trivial task. We propose to simplify each\nmonolingual module by allowing them to transcribe all speech segments\nindiscriminately with a monolingual script (i.e. transliteration). This simple\nmodification passes the responsibility of CS point detection to subsequent\nbilingual modules which determine the final output by considering multiple\nmonolingual transliterations along with external language model information. We\napply this transliteration-based approach in an end-to-end differentiable\nneural network and demonstrate its efficacy for zero-shot CS ASR on\nMandarin-English SEAME test sets.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Brian Yan",
      "Matthew Wiesner",
      "Ondrej Klejch",
      "Preethi Jyothi",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01458"
  },
  {
    "id": "arXiv:2211.01462",
    "title": "Drift approximation by the modified Boris algorithm of charged-particle  dynamics in toroidal geometry",
    "abstract": "In this paper, we study the charged-particle dynamics under strong magnetic\nfield in a toroidal axi-symmetric geometry. Using modulated Fourier expansions\nof the exact and numerical solutions, the long-term drift motion of the exact\nsolution in toroidal geometry is derived and the error analysis of the\nlarge-stepsize modified Boris algorithm over long time scales is provided.\nNumerical experiments illustrate the theoretical results.",
    "descriptor": "",
    "authors": [
      "Yanyan Shi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.01462"
  },
  {
    "id": "arXiv:2211.01466",
    "title": "Inverse Kinematics with Dual-Quaternions, Exponential-Maps, and Joint  Limits",
    "abstract": "We present a novel approach for solving articulated inverse kinematic\nproblems (e.g., character structures) by means of an iterative dual-quaternion\nand exponentialmapping approach. As dual-quaternions are a break from the norm\nand offer a straightforward and computationally efficient technique for\nrepresenting kinematic transforms (i.e., position and translation).\nDual-quaternions are capable of represent both translation and rotation in a\nunified state space variable with its own set of algebraic equations for\nconcatenation and manipulation. Hence, an articulated structure can be\nrepresented by a set of dual-quaternion transforms, which we can manipulate\nusing inverse kinematics (IK) to accomplish specific goals (e.g., moving\nend-effectors towards targets). We use the projected Gauss-Seidel iterative\nmethod to solve the IK problem with joint limits. Our approach is flexible and\nrobust enough for use in interactive applications, such as games. We use\nnumerical examples to demonstrate our approach, which performed successfully in\nall our test cases and produced pleasing visual results.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2211.00330\n",
    "authors": [
      "Ben Kenwright"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.01466"
  },
  {
    "id": "arXiv:2211.01467",
    "title": "Generative Entity-to-Entity Stance Detection with Knowledge Graph  Augmentation",
    "abstract": "Stance detection is typically framed as predicting the sentiment in a given\ntext towards a target entity. However, this setup overlooks the importance of\nthe source entity, i.e., who is expressing the opinion. In this paper, we\nemphasize the need for studying interactions among entities when inferring\nstances. We first introduce a new task, entity-to-entity (E2E) stance\ndetection, which primes models to identify entities in their canonical names\nand discern stances jointly. To support this study, we curate a new dataset\nwith 10,619 annotations labeled at the sentence-level from news articles of\ndifferent ideological leanings. We present a novel generative framework to\nallow the generation of canonical names for entities as well as stances among\nthem. We further enhance the model with a graph encoder to summarize entity\nactivities and external knowledge surrounding the entities. Experiments show\nthat our model outperforms strong comparisons by large margins. Further\nanalyses demonstrate the usefulness of E2E stance detection for understanding\nmedia quotation and stance landscape, as well as inferring entity ideology.",
    "descriptor": "\nComments: EMNLP'22 Main Conference\n",
    "authors": [
      "Xinliang Frederick Zhang",
      "Nick Beauchamp",
      "Lu Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01467"
  },
  {
    "id": "arXiv:2211.01468",
    "title": "A New Approach to Estimating Effective Resistances and Counting Spanning  Trees in Expander Graphs",
    "abstract": "We demonstrate that for expander graphs, for all $\\epsilon > 0,$ there exists\na data structure of size $\\widetilde{O}(n\\epsilon^{-1})$ which can be used to\nreturn $(1 + \\epsilon)$-approximations to effective resistances in\n$\\widetilde{O}(1)$ time per query. Short of storing all effective resistances,\nprevious best approaches could achieve $\\widetilde{O}(n\\epsilon^{-2})$ size and\n$\\widetilde{O}(\\epsilon^{-2})$ time per query by storing Johnson-Lindenstrauss\nvectors for each vertex, or $\\widetilde{O}(n\\epsilon^{-1})$ size and\n$\\widetilde{O}(n\\epsilon^{-1})$ time per query by storing a spectral sketch.\nOur construction is based on two key ideas: 1) $\\epsilon^{-1}$-sparse,\n$\\epsilon$-additive approximations to $DL^+1_u$ for all $u,$ can be used to\nrecover $(1 + \\epsilon)$-approximations to the effective resistances, 2) In\nexpander graphs, only $\\widetilde{O}(\\epsilon^{-1})$ coordinates of a vector\nsimilar to $DL^+1_u$ are larger than $\\epsilon.$ We give an efficient\nconstruction for such a data structure in $\\widetilde{O}(m + n\\epsilon^{-2})$\ntime via random walks. This results in an algorithm for computing\n$(1+\\epsilon)$-approximate effective resistances for $s$ vertex pairs in\nexpanders that runs in $\\widetilde{O}(m + n\\epsilon^{-2} + s)$ time, improving\nover the previously best known running time of $m^{1 + o(1)} + (n +\ns)n^{o(1)}\\epsilon^{-1.5}$ for $s = \\omega(n\\epsilon^{-0.5}).$\nWe employ the above algorithm to compute a $(1+\\delta)$-approximation to the\nnumber of spanning trees in an expander graph, or equivalently, approximating\nthe (pseudo)determinant of its Laplacian in $\\widetilde{O}(m +\nn^{1.5}\\delta^{-1})$ time. This improves on the previously best known result of\n$m^{1+o(1)} + n^{1.875+o(1)}\\delta^{-1.75}$ time, and matches the best known\nsize of determinant sparsifiers.",
    "descriptor": "",
    "authors": [
      "Lawrence Li",
      "Sushant Sachdeva"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.01468"
  },
  {
    "id": "arXiv:2211.01471",
    "title": "Dual Generator Offline Reinforcement Learning",
    "abstract": "In offline RL, constraining the learned policy to remain close to the data is\nessential to prevent the policy from outputting out-of-distribution (OOD)\nactions with erroneously overestimated values. In principle, generative\nadversarial networks (GAN) can provide an elegant solution to do so, with the\ndiscriminator directly providing a probability that quantifies distributional\nshift. However, in practice, GAN-based offline RL methods have not performed as\nwell as alternative approaches, perhaps because the generator is trained to\nboth fool the discriminator and maximize return -- two objectives that can be\nat odds with each other. In this paper, we show that the issue of conflicting\nobjectives can be resolved by training two generators: one that maximizes\nreturn, with the other capturing the ``remainder'' of the data distribution in\nthe offline dataset, such that the mixture of the two is close to the behavior\npolicy. We show that not only does having two generators enable an effective\nGAN-based offline RL method, but also approximates a support constraint, where\nthe policy does not need to match the entire data distribution, but only the\nslice of the data that leads to high long term performance. We name our method\nDASCO, for Dual-Generator Adversarial Support Constrained Offline RL. On\nbenchmark tasks that require learning from sub-optimal data, DASCO\nsignificantly outperforms prior methods that enforce distribution constraint.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Quan Vuong",
      "Aviral Kumar",
      "Sergey Levine",
      "Yevgen Chebotar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01471"
  },
  {
    "id": "arXiv:2211.01473",
    "title": "Fluent APIs in Functional Languages (full version)",
    "abstract": "Fluent API is an object-oriented pattern for smart and elegant embedded DSLs.\nAs fluent API designs typically rely on function overloading, they are hard to\nrealize in functional programming languages. We show how to write functional\nfluent APIs using parametric polymorphism and unification instead of\noverloading. Our designs support all regular and deterministic context-free\nDSLs and beyond.",
    "descriptor": "",
    "authors": [
      "Ori Roth",
      "Yossi Gil"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.01473"
  },
  {
    "id": "arXiv:2211.01476",
    "title": "Integrated Photonic Tensor Processing Unit for a Matrix Multiply: a  Review",
    "abstract": "The explosion of artificial intelligence and machine-learning algorithms,\nconnected to the exponential growth of the exchanged data, is driving a search\nfor novel application-specific hardware accelerators. Among the many, the\nphotonics field appears to be in the perfect spotlight for this global data\nexplosion, thanks to its almost infinite bandwidth capacity associated with\nlimited energy consumption. In this review, we will overview the major\nadvantages that photonics has over electronics for hardware accelerators,\nfollowed by a comparison between the major architectures implemented on\nPhotonics Integrated Circuits (PIC) for both the linear and nonlinear parts of\nNeural Networks. By the end, we will highlight the main driving forces for the\nnext generation of photonic accelerators, as well as the main limits that must\nbe overcome.",
    "descriptor": "",
    "authors": [
      "Nicola Peserico",
      "Bhavin J. Shastri",
      "Volker J. Sorger"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.01476"
  },
  {
    "id": "arXiv:2211.01478",
    "title": "A machine learning model to identify corruption in M\u00e9xico's public  procurement contracts",
    "abstract": "The costs and impacts of government corruption range from impairing a\ncountry's economic growth to affecting its citizens' well-being and safety.\nPublic contracting between government dependencies and private sector\ninstances, referred to as public procurement, is a fertile land of opportunity\nfor corrupt practices, generating substantial monetary losses worldwide. Thus,\nidentifying and deterring corrupt activities between the government and the\nprivate sector is paramount. However, due to several factors, corruption in\npublic procurement is challenging to identify and track, leading to corrupt\npractices going unnoticed. This paper proposes a machine learning model based\non an ensemble of random forest classifiers, which we call hyper-forest, to\nidentify and predict corrupt contracts in M\\'exico's public procurement data.\nThis method's results correctly detect most of the corrupt and non-corrupt\ncontracts evaluated in the dataset. Furthermore, we found that the most\ncritical predictors considered in the model are those related to the\nrelationship between buyers and suppliers rather than those related to features\nof individual contracts. Also, the method proposed here is general enough to be\ntrained with data from other countries. Overall, our work presents a tool that\ncan help in the decision-making process to identify, predict and analyze\ncorruption in public procurement contracts.",
    "descriptor": "\nComments: 16 pages, 8 figures. On revision in Journal of Quantitative Criminology\n",
    "authors": [
      "Andr\u00e9s Aldana",
      "Andrea Falc\u00f3n-Cort\u00e9s",
      "Hern\u00e1n Larralde"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01478"
  },
  {
    "id": "arXiv:2211.01480",
    "title": "Over-communicate no more: Situated RL agents learn concise communication  protocols",
    "abstract": "While it is known that communication facilitates cooperation in multi-agent\nsettings, it is unclear how to design artificial agents that can learn to\neffectively and efficiently communicate with each other. Much research on\ncommunication emergence uses reinforcement learning (RL) and explores\nunsituated communication in one-step referential tasks -- the tasks are not\ntemporally interactive and lack time pressures typically present in natural\ncommunication. In these settings, agents may successfully learn to communicate,\nbut they do not learn to exchange information concisely -- they tend towards\nover-communication and an inefficient encoding. Here, we explore situated\ncommunication in a multi-step task, where the acting agent has to forgo an\nenvironmental action to communicate. Thus, we impose an opportunity cost on\ncommunication and mimic the real-world pressure of passing time. We compare\ncommunication emergence under this pressure against learning to communicate\nwith a cost on articulation effort, implemented as a per-message penalty (fixed\nand progressively increasing). We find that while all tested pressures can\ndisincentivise over-communication, situated communication does it most\neffectively and, unlike the cost on effort, does not negatively impact\nemergence. Implementing an opportunity cost on communication in a temporally\nextended environment is a step towards embodiment, and might be a pre-condition\nfor incentivising efficient, human-like communication.",
    "descriptor": "",
    "authors": [
      "Aleksandra Kalinowska",
      "Elnaz Davoodi",
      "Florian Strub",
      "Kory W Mathewson",
      "Ivana Kajic",
      "Michael Bowling",
      "Todd D Murphey",
      "Patrick M Pilarski"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.01480"
  },
  {
    "id": "arXiv:2211.01481",
    "title": "Physics-inspired machine learning for power grid frequency modelling",
    "abstract": "The operation of power systems is affected by diverse technical, economic and\nsocial factors. Social behaviour determines load patterns, electricity markets\nregulate the generation and weather-dependent renewables introduce power\nfluctuations. Thus, power system dynamics must be regarded as a non-autonomous\nsystem whose parameters vary strongly with time. However, the external driving\nfactors are usually only available on coarse scales and the actual dependencies\nof the dynamic system parameters are generally unknown. Here, we propose a\nphysics-inspired machine learning model that bridges the gap between\nlarge-scale drivers and short-term dynamics of the power system. Integrating\nstochastic differential equations and artificial neural networks, we construct\na probabilistic model of the power grid frequency dynamics in Continental\nEurope. Its probabilistic prediction outperforms the daily average profile,\nwhich is an important benchmark. Using the integrated model, we identify and\nexplain the parameters of the dynamical system from the data, which reveals\ntheir strong time-dependence and their relation to external drivers such as\nwind power feed-in and fast generation ramps. Finally, we generate synthetic\ntime series from the model, which successfully reproduce central\ncharacteristics of the grid frequency such as their heavy-tailed distribution.\nAll in all, our work emphasises the importance of modelling power system\ndynamics as a stochastic non-autonomous system with both intrinsic dynamics and\nexternal drivers.",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Johannes Kruse",
      "Eike Cramer",
      "Benjamin Sch\u00e4fer",
      "Dirk Witthaut"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.01481"
  },
  {
    "id": "arXiv:2211.01482",
    "title": "RQUGE: Reference-Free Metric for Evaluating Question Generation by  Answering the Question",
    "abstract": "Existing metrics for evaluating the quality of automatically generated\nquestions such as BLEU, ROUGE, BERTScore, and BLEURT compare the reference and\npredicted questions, providing a high score when there is a considerable\nlexical overlap or semantic similarity between the candidate and the reference\nquestions. This approach has two major shortcomings. First, we need expensive\nhuman-provided reference questions. Second, it penalises valid questions that\nmay not have high lexical or semantic similarity to the reference questions. In\nthis paper, we propose a new metric, RQUGE, based on the answerability of the\ncandidate question given the context. The metric consists of a\nquestion-answering and a span scorer module, in which we use pre-trained models\nfrom the existing literature, and therefore, our metric can be used without\nfurther training. We show that RQUGE has a higher correlation with human\njudgment without relying on the reference question. RQUGE is shown to be\nsignificantly more robust to several adversarial corruptions. Additionally, we\nillustrate that we can significantly improve the performance of QA models on\nout-of-domain datasets by fine-tuning on the synthetic data generated by a\nquestion generation model and re-ranked by RQUGE.",
    "descriptor": "\nComments: 19 pages, 8 figures\n",
    "authors": [
      "Alireza Mohammadshahi",
      "Thomas Scialom",
      "Majid Yazdani",
      "Pouya Yanki",
      "Angela Fan",
      "James Henderson",
      "Marzieh Saeidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01482"
  },
  {
    "id": "arXiv:2211.01484",
    "title": "The Lottery Ticket Hypothesis for Vision Transformers",
    "abstract": "The conventional lottery ticket hypothesis (LTH) claims that there exists a\nsparse subnetwork within a dense neural network and a proper random\ninitialization method, called the winning ticket, such that it can be trained\nfrom scratch to almost as good as the dense counterpart. Meanwhile, the\nresearch of LTH in vision transformers (ViTs) is scarcely evaluated. In this\npaper, we first show that the conventional winning ticket is hard to find at\nweight level of ViTs by existing methods. Then, we generalize the LTH for ViTs\nto input images consisting of image patches inspired by the input dependence of\nViTs. That is, there exists a subset of input image patches such that a ViT can\nbe trained from scratch by using only this subset of patches and achieve\nsimilar accuracy to the ViTs trained by using all image patches. We call this\nsubset of input patches the winning tickets, which represent a significant\namount of information in the input. Furthermore, we present a simple yet\neffective method to find the winning tickets in input patches for various types\nof ViT, including DeiT, LV-ViT, and Swin Transformers. More specifically, we\nuse a ticket selector to generate the winning tickets based on the\ninformativeness of patches. Meanwhile, we build another randomly selected\nsubset of patches for comparison, and the experiments show that there is clear\ndifference between the performance of models trained with winning tickets and\nrandomly selected subsets.",
    "descriptor": "",
    "authors": [
      "Xuan Shen",
      "Zhenglun Kong",
      "Minghai Qin",
      "Peiyan Dong",
      "Geng Yuan",
      "Xin Meng",
      "Hao Tang",
      "Xiaolong Ma",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01484"
  },
  {
    "id": "arXiv:2211.01486",
    "title": "Assessing Resource-Performance Trade-off of Natural Language Models  using Data Envelopment Analysis",
    "abstract": "Natural language models are often summarized through a high-dimensional set\nof descriptive metrics including training corpus size, training time, the\nnumber of trainable parameters, inference times, and evaluation statistics that\nassess performance across tasks. The high dimensional nature of these metrics\nyields challenges with regard to objectively comparing models; in particular it\nis challenging to assess the trade-off models make between performance and\nresources (compute time, memory, etc.).\nWe apply Data Envelopment Analysis (DEA) to this problem of assessing the\nresource-performance trade-off. DEA is a nonparametric method that measures\nproductive efficiency of abstract units that consume one or more inputs and\nyield at least one output. We recast natural language models as units suitable\nfor DEA, and we show that DEA can be used to create an effective framework for\nquantifying model performance and efficiency. A central feature of DEA is that\nit identifies a subset of models that live on an efficient frontier of\nperformance. DEA is also scalable, having been applied to problems with\nthousands of units. We report empirical results of DEA applied to 14 different\nlanguage models that have a variety of architectures, and we show that DEA can\nbe used to identify a subset of models that effectively balance resource\ndemands against performance.",
    "descriptor": "\nComments: 9 pages, 1 figure, Eval4NLP workshop\n",
    "authors": [
      "Zachary Zhou",
      "Alisha Zachariah",
      "Devin Conathan",
      "Jeffery Kline"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.01486"
  },
  {
    "id": "arXiv:2211.01487",
    "title": "Multi-vehicle Conflict Resolution in Highly Constrained Spaces by  Merging Optimal Control and Reinforcement Learning",
    "abstract": "We present a novel method in this work to address the problem of\nmulti-vehicle conflict resolution in highly constrained spaces. A high-fidelity\noptimal control problem is formulated to incorporate nonlinear, non-holonomic\nvehicle dynamics and exact collision avoidance constraints. Despite being\nhigh-dimensional and non-convex, we can obtain an optimal solution by learning\nconfiguration strategies with reinforcement learning (RL) in a simplified\ndiscrete environment and approaching high-quality initial guesses\nprogressively. The simulation results show that our method can explore\nefficient actions to resolve conflicts in confined space and generate dexterous\nmaneuvers that are both collision-free and kinematically feasible.",
    "descriptor": "",
    "authors": [
      "Xu Shen",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01487"
  },
  {
    "id": "arXiv:2211.01488",
    "title": "A study linking patient EHR data to external death data at Stanford  Medicine",
    "abstract": "This manuscript explores linking real-world patient data with external death\ndata in the context of research Clinical Data Warehouses (r-CDWs). We\nspecifically present the linking of Electronic Health Records (EHR) data for\nStanford Health Care (SHC) patients and data from the Social Security\nAdministration (SSA) Limited Access Death Master File (LADMF) made available by\nthe US Department of Commerce's National Technical Information Service (NTIS).\nThe data analysis framework presented in this manuscript extends prior\napproaches and is generalizable to linking any two cross-organizational\nreal-world patient data sources. Electronic Health Record (EHR) data and NTIS\nLADMF are heavily used resources at other medical centers and we expect that\nthe methods and learnings presented here will be valuable to others. Our\nfindings suggest that strong linkages are incomplete and weak linkages are\nnoisy i.e., there is no good linkage rule that provides coverage and accuracy.\nFurthermore, the best linkage rule for any two datasets is different from the\nbest linkage rule for two other datasets i.e., there is no generalization of\nlinkage rules. Finally, LADMF, a commonly used external death data resource for\nr-CDWs, has a significant gap in death data making it necessary for r-CDWs to\nseek out more than one external death data source. We anticipate that\npresentation of multiple linkages will make it hard to present the linkage\noutcome to the end user.\nThis manuscript is a resource in support of Stanford Medicine STARR (STAnford\nmedicine Research data Repository) r-CDWs. The data are stored and analyzed as\nPHI in our HIPAA-compliant data center and are used under research and\ndevelopment (R&D) activities of STARR IRB.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Alvaro Andres Alvarez Peralta",
      "Priya Desai",
      "Somalee Datta"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.01488"
  },
  {
    "id": "arXiv:2211.01494",
    "title": "Regression Compatible Listwise Objectives for Calibrated Ranking",
    "abstract": "As Learning-to-Rank (LTR) approaches primarily seek to improve ranking\nquality, their output scores are not scale-calibrated by design -- for example,\nadding a constant to the score of each item on the list will not affect the\nlist ordering. This fundamentally limits LTR usage in score-sensitive\napplications. Though a simple multi-objective approach that combines a\nregression and a ranking objective can effectively learn scale-calibrated\nscores, we argue that the two objectives can be inherently conflicting, which\nmakes the trade-off far from ideal for both of them. In this paper, we propose\na novel regression compatible ranking (RCR) approach to achieve a better\ntrade-off. The advantage of the proposed approach is that the regression and\nranking components are well aligned which brings new opportunities for\nharmonious regression and ranking. Theoretically, we show that the two\ncomponents share the same minimizer at global minima while the regression\ncomponent ensures scale calibration. Empirically, we show that the proposed\napproach performs well on both regression and ranking metrics on several public\nLTR datasets, and significantly improves the Pareto frontiers in the context of\nmulti-objective optimization. Furthermore, we evaluated the proposed approach\non YouTube Search and found that it not only improved the ranking quality of\nthe production pCTR model, but also brought gains to the click prediction\naccuracy.",
    "descriptor": "",
    "authors": [
      "Aijun Bai",
      "Rolf Jagerman",
      "Zhen Qin",
      "Pratyush Kar",
      "Bing-Rong Lin",
      "Xuanhui Wang",
      "Michael Bendersky",
      "Marc Najork"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.01494"
  },
  {
    "id": "arXiv:2211.01496",
    "title": "Max Markov Chain",
    "abstract": "In this paper, we introduce Max Markov Chain (MMC), a novel representation\nfor a useful subset of High-order Markov Chains (HMCs) with sparse correlations\namong the states. MMC is parsimony while retaining the expressiveness of HMCs.\nEven though parameter optimization is generally intractable as with HMC\napproximate models, it has an analytical solution, better sample efficiency,\nand the desired spatial and computational advantages over HMCs and approximate\nHMCs. Simultaneously, efficient approximate solutions exist for this type of\nchains as we show empirically, which allow MMCs to scale to large domains where\nHMCs and approximate HMCs would struggle to perform. We compare MMC with HMC,\nfirst-order Markov chain, and an approximate HMC model in synthetic domains\nwith various data types to demonstrate that MMC is a valuable alternative for\nmodeling stochastic processes and has many potential applications.",
    "descriptor": "",
    "authors": [
      "Yu Zhang",
      "Mitchell Bucklew"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01496"
  },
  {
    "id": "arXiv:2211.01498",
    "title": "On the Safety of Interpretable Machine Learning: A Maximum Deviation  Approach",
    "abstract": "Interpretable and explainable machine learning has seen a recent surge of\ninterest. We focus on safety as a key motivation behind the surge and make the\nrelationship between interpretability and safety more quantitative. Toward\nassessing safety, we introduce the concept of maximum deviation via an\noptimization problem to find the largest deviation of a supervised learning\nmodel from a reference model regarded as safe. We then show how\ninterpretability facilitates this safety assessment. For models including\ndecision trees, generalized linear and additive models, the maximum deviation\ncan be computed exactly and efficiently. For tree ensembles, which are not\nregarded as interpretable, discrete optimization techniques can still provide\ninformative bounds. For a broader class of piecewise Lipschitz functions, we\nleverage the multi-armed bandit literature to show that interpretability\nproduces tighter (regret) bounds on the maximum deviation. We present case\nstudies, including one on mortgage approval, to illustrate our methods and the\ninsights about models that may be obtained from deviation maximization.",
    "descriptor": "\nComments: Published at NeurIPS 2022\n",
    "authors": [
      "Dennis Wei",
      "Rahul Nair",
      "Amit Dhurandhar",
      "Kush R. Varshney",
      "Elizabeth M. Daly",
      "Moninder Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01498"
  },
  {
    "id": "arXiv:2211.01499",
    "title": "Angle-free cluster robust Ritz value bounds for restarted block  eigensolvers",
    "abstract": "Convergence rates of block iterations for solving eigenvalue problems\ntypically measure errors of Ritz values approximating eigenvalues. The errors\nof the Ritz values are commonly bounded in terms of principal angles between\nthe initial or iterative subspace and the invariant subspace associated with\nthe target eigenvalues. Such bounds thus cannot be applied repeatedly as needed\nfor restarted block eigensolvers, since the left- and right-hand sides of the\nbounds use different terms. They must be combined with additional bounds which\ncould cause an overestimation. Alternative repeatable bounds that are\nangle-free and depend only on the errors of the Ritz values have been pioneered\nfor Hermitian eigenvalue problems in doi:10.1515/rnam.1987.2.5.371 but only for\na single extreme Ritz value. We extend this result to all Ritz values and\nachieve robustness for clustered eigenvalues by utilizing nonconsecutive\neigenvalues. Our new bounds cover the restarted block Lanczos method and its\nmodifications with shift-and-invert and deflation, and are numerically\nadvantageous.",
    "descriptor": "\nComments: 24 pages, 4 figures\n",
    "authors": [
      "Ming Zhou",
      "Andrew V. Knyazev",
      "Klaus Neymeyr"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.01499"
  },
  {
    "id": "arXiv:2211.01500",
    "title": "Learning to Grasp the Ungraspable with Emergent Extrinsic Dexterity",
    "abstract": "A simple gripper can solve more complex manipulation tasks if it can utilize\nthe external environment such as pushing the object against the table or a\nvertical wall, known as \"Extrinsic Dexterity.\" Previous work in extrinsic\ndexterity usually has careful assumptions about contacts which impose\nrestrictions on robot design, robot motions, and the variations of the physical\nparameters. In this work, we develop a system based on reinforcement learning\n(RL) to address these limitations. We study the task of \"Occluded Grasping\"\nwhich aims to grasp the object in configurations that are initially occluded;\nthe robot needs to move the object into a configuration from which these grasps\ncan be achieved. We present a system with model-free RL that successfully\nachieves this task using a simple gripper with extrinsic dexterity. The policy\nlearns emergent behaviors of pushing the object against the wall to rotate and\nthen grasp it without additional reward terms on extrinsic dexterity. We\ndiscuss important components of the system including the design of the RL\nproblem, multi-grasp training and selection, and policy generalization with\nautomatic curriculum. Most importantly, the policy trained in simulation is\nzero-shot transferred to a physical robot. It demonstrates dynamic and\ncontact-rich motions with a simple gripper that generalizes across objects with\nvarious size, density, surface friction, and shape with a 78% success rate.\nVideos can be found at https://sites.google.com/view/grasp-ungraspable/.",
    "descriptor": "",
    "authors": [
      "Wenxuan Zhou",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01500"
  },
  {
    "id": "arXiv:2211.01508",
    "title": "Partially-Observable Security Games for Automating Attack-Defense  Analysis",
    "abstract": "Network systems often contain vulnerabilities that remain unfixed in a\nnetwork for various reasons, such as the lack of a patch or knowledge to fix\nthem. With the presence of such residual vulnerabilities, the network\nadministrator should properly react to the malicious activities or proactively\nprevent them, by applying suitable countermeasures that minimize the likelihood\nof an attack by the attacker. In this paper, we propose a stochastic\ngame-theoretic approach for analyzing network security and synthesizing defense\nstrategies to protect a network. To support analysis under partial observation,\nwhere some of the attacker's activities are unobservable or undetectable by the\ndefender, we construct a one-sided partially observable security game and\ntransform it into a perfect game for further analysis. We prove that this\ntransformation is sound for a sub-class of security games and a subset of\nproperties specified in the logic rPATL. We implement a prototype that fully\nautomates our approach, and evaluate it by conducting experiments on a\nreal-life network.",
    "descriptor": "",
    "authors": [
      "Narges Khakpour",
      "David Parker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.01508"
  },
  {
    "id": "arXiv:2211.01512",
    "title": "Convergence in KL Divergence of the Inexact Langevin Algorithm with  Application to Score-based Generative Models",
    "abstract": "We study the Inexact Langevin Algorithm (ILA) for sampling using estimated\nscore function when the target distribution satisfies log-Sobolev inequality\n(LSI), motivated by Score-based Generative Modeling (SGM). We prove a long-term\nconvergence in Kullback-Leibler (KL) divergence under a sufficient assumption\nthat the error of the score estimator has a bounded Moment Generating Function\n(MGF). Our assumption is weaker than $L^\\infty$ (which is too strong to hold in\npractice) and stronger than $L^2$ error assumption, which we show not\nsufficient to guarantee convergence in general. Under the $L^\\infty$ error\nassumption, we additionally prove convergence in R\\'enyi divergence, which is\nstronger than KL divergence. We then study how to get a provably accurate score\nestimator which satisfies bounded MGF assumption for LSI target distributions,\nby using an estimator based on kernel density estimation. Together with the\nconvergence results, we yield the first end-to-end convergence guarantee for\nILA in the population level. Last, we generalize our convergence analysis to\nSGM and derive a complexity guarantee in KL divergence for data satisfying LSI\nunder MGF-accurate score estimator.",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Andre Wibisono",
      "Kaylee Yingxi Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.01512"
  },
  {
    "id": "arXiv:2211.01513",
    "title": "Optimizing Fiducial Marker Placement for Improved Visual Localization",
    "abstract": "Adding fiducial markers to a scene is a well-known strategy for making visual\nlocalization algorithms more robust. Traditionally, these marker locations are\nselected by humans who are familiar with visual localization techniques. This\npaper explores the problem of automatic marker placement within a scene.\nSpecifically, given a predetermined set of markers and a scene model, we\ncompute optimized marker positions within the scene that can improve accuracy\nin visual localization. Our main contribution is a novel framework for modeling\ncamera localizability that incorporates both natural scene features and\nartificial fiducial markers added to the scene. We present optimized marker\nplacement (OMP), a greedy algorithm that is based on the camera localizability\nframework. We have also designed a simulation framework for testing marker\nplacement algorithms on 3D models and images generated from synthetic scenes.\nWe have evaluated OMP within this testbed and demonstrate an improvement in the\nlocalization rate by up to 20 percent on three different scenes.",
    "descriptor": "",
    "authors": [
      "Qiangqiang Huang",
      "Joseph DeGol",
      "Victor Fragoso",
      "Sudipta N. Sinha",
      "John J. Leonard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01513"
  },
  {
    "id": "arXiv:2211.01522",
    "title": "Losses Can Be Blessings: Routing Self-Supervised Speech Representations  Towards Efficient Multilingual and Multitask Speech Processing",
    "abstract": "Self-supervised learning (SSL) for rich speech representations has achieved\nempirical success in low-resource Automatic Speech Recognition (ASR) and other\nspeech processing tasks, which can mitigate the necessity of a large amount of\ntranscribed speech and thus has driven a growing demand for on-device ASR and\nother speech processing. However, advanced speech SSL models have become\nincreasingly large, which contradicts the limited on-device resources. This gap\ncould be more severe in multilingual/multitask scenarios requiring\nsimultaneously recognizing multiple languages or executing multiple speech\nprocessing tasks. Additionally, strongly overparameterized speech SSL models\ntend to suffer from overfitting when being finetuned on low-resource speech\ncorpus. This work aims to enhance the practical usage of speech SSL models\ntowards a win-win in both enhanced efficiency and alleviated overfitting via\nour proposed S$^3$-Router framework, which for the first time discovers that\nsimply discarding no more than 10\\% of model weights via only finetuning model\nconnections of speech SSL models can achieve better accuracy over standard\nweight finetuning on downstream speech processing tasks. More importantly,\nS$^3$-Router can serve as an all-in-one technique to enable (1) a new\nfinetuning scheme, (2) an efficient multilingual/multitask solution, (3) a\nstate-of-the-art ASR pruning technique, and (4) a new tool to quantitatively\nanalyze the learned speech representation. We believe S$^3$-Router has provided\na new perspective for practical deployment of speech SSL models. Our codes are\navailable at: https://github.com/GATECH-EIC/S3-Router.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Yonggan Fu",
      "Yang Zhang",
      "Kaizhi Qian",
      "Zhifan Ye",
      "Zhongzhi Yu",
      "Cheng-I Lai",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01522"
  },
  {
    "id": "arXiv:2211.01524",
    "title": "Addressing harm in online gaming communities -- the opportunities and  challenges for a restorative justice approach",
    "abstract": "Most platforms implement some form of content moderation to address\ninterpersonal harms such as harassment. Content moderation relies on\noffender-centered, punitive justice approaches such as bans and content\nremovals. We consider an alternative justice framework, restorative justice,\nwhich aids victims to heal, supports offenders to repair the harm, and engages\ncommunity members to address the harm collectively. To understand the utility\nof restorative justice in addressing online harm, we interviewed 23 users from\nOverwatch gaming communities, including moderators, victims, and offenders. We\nunderstand how they currently handle harm cases through the lens of restorative\njustice and identify their attitudes toward implementing restorative justice\nprocesses. Our analysis reveals that while online communities have needs for\nand existing structures to support restorative justice, there are structural,\ncultural, and resource-related obstacles to implementing this new approach\nwithin the existing punitive framework. We discuss the opportunities and\nchallenges for applying restorative justice in online spaces.",
    "descriptor": "",
    "authors": [
      "Sijia Xiao",
      "Shagun Jhaver",
      "Niloufar Salehi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.01524"
  },
  {
    "id": "arXiv:2211.01527",
    "title": "Sensor Control for Information Gain in Dynamic, Sparse and Partially  Observed Environments",
    "abstract": "We present an approach for autonomous sensor control for information\ngathering under partially observable, dynamic and sparsely sampled\nenvironments. We consider the problem of controlling a sensor that makes\npartial observations in some space of interest such that it maximizes\ninformation about entities present in that space. We describe our approach for\nthe task of Radio-Frequency (RF) spectrum monitoring, where the goal is to\nsearch for and track unknown, dynamic signals in the environment. To this end,\nwe develop and demonstrate enhancements of the Deep Anticipatory Network (DAN)\nReinforcement Learning (RL) framework that uses prediction and information-gain\nrewards to learn information-maximization policies in reward-sparse\nenvironments. We also extend this problem to situations in which taking samples\nfrom the actual RF spectrum/field is limited and expensive, and propose a\nmodel-based version of the original RL algorithm that fine-tunes the controller\nusing a model of the environment that is iteratively improved from limited\nsamples taken from the RF field. Our approach was thoroughly validated by\ntesting against baseline expert-designed controllers in simulated RF\nenvironments of different complexity, using different rewards schemes and\nevaluation metrics. The results show that our system outperforms the standard\nDAN architecture and is more flexible and robust than several hand-coded\nagents. We also show that our approach is adaptable to non-stationary\nenvironments where the agent has to learn to adapt to changes from the emitting\nsources.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "J. Brian Burns",
      "Aravind Sundaresan",
      "Pedro Sequeira",
      "Vidyasagar Sadhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01527"
  },
  {
    "id": "arXiv:2211.01528",
    "title": "Fair and Optimal Classification via Transports to Wasserstein-Barycenter",
    "abstract": "Fairness in automated decision-making systems has gained increasing attention\nas their applications expand to real-world high-stakes domains. To facilitate\nthe design of fair ML systems, it is essential to understand the potential\ntrade-offs between fairness and predictive power, and the construction of the\noptimal predictor under a given fairness constraint. In this paper, for general\nclassification problems under the group fairness criterion of demographic\nparity (DP), we precisely characterize the trade-off between DP and\nclassification accuracy, referred to as the minimum cost of fairness. Our\ninsight comes from the key observation that finding the optimal fair classifier\nis equivalent to solving a Wasserstein-barycenter problem under $\\ell_1$-norm\nrestricted to the vertices of the probability simplex. Inspired by our\ncharacterization, we provide a construction of an optimal fair classifier\nachieving this minimum cost via the composition of the Bayes regressor and\noptimal transports from its output distributions to the barycenter. Our\nconstruction naturally leads to an algorithm for post-processing any\npre-trained predictor to satisfy DP fairness, complemented with finite sample\nguarantees. Experiments on real-world datasets verify and demonstrate the\neffectiveness of our approaches.",
    "descriptor": "\nComments: Code is at this https URL\n",
    "authors": [
      "Ruicheng Xian",
      "Lang Yin",
      "Han Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01528"
  },
  {
    "id": "arXiv:2211.01531",
    "title": "Adaptive sparse grid discontinuous Galerkin method: review and software  implementation",
    "abstract": "This paper reviews the adaptive sparse grid discontinuous Galerkin (aSG-DG)\nmethod for computing high dimensional partial differential equations (PDEs) and\nits software implementation. The C\\texttt{++} software package called AdaM-DG,\nimplementing the aSG-DG method, is available on Github at\n\\url{https://github.com/JuntaoHuang/adaptive-multiresolution-DG}. The package\nis capable of treating a large class of high dimensional linear and nonlinear\nPDEs. We review the essential components of the algorithm and the functionality\nof the software, including the multiwavelets used, assembling of bilinear\noperators, fast matrix-vector product for data with hierarchical structures. We\nfurther demonstrate the performance of the package by reporting numerical error\nand CPU cost for several benchmark test, including linear transport equations,\nwave equations and Hamilton-Jacobi equations.",
    "descriptor": "",
    "authors": [
      "Juntao Huang",
      "Wei Guo",
      "Yingda Cheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.01531"
  },
  {
    "id": "arXiv:2211.01535",
    "title": "Reliable Malware Analysis and Detection using Topology Data Analysis",
    "abstract": "Increasingly, malwares are becoming complex and they are spreading on\nnetworks targeting different infrastructures and personal-end devices to\ncollect, modify, and destroy victim information. Malware behaviors are\npolymorphic, metamorphic, persistent, able to hide to bypass detectors and\nadapt to new environments, and even leverage machine learning techniques to\nbetter damage targets. Thus, it makes them difficult to analyze and detect with\ntraditional endpoint detection and response, intrusion detection and prevention\nsystems. To defend against malwares, recent work has proposed different\ntechniques based on signatures and machine learning. In this paper, we propose\nto use an algebraic topological approach called topological-based data analysis\n(TDA) to efficiently analyze and detect complex malware patterns. Next, we\ncompare the different TDA techniques (i.e., persistence homology, tomato, TDA\nMapper) and existing techniques (i.e., PCA, UMAP, t-SNE) using different\nclassifiers including random forest, decision tree, xgboost, and lightgbm. We\nalso propose some recommendations to deploy the best-identified models for\nmalware detection at scale. Results show that TDA Mapper (combined with PCA) is\nbetter for clustering and for identifying hidden relationships between malware\nclusters compared to PCA. Persistent diagrams are better to identify\noverlapping malware clusters with low execution time compared to UMAP and\nt-SNE. For malware detection, malware analysts can use Random Forest and\nDecision Tree with t-SNE and Persistent Diagram to achieve better performance\nand robustness on noised data.",
    "descriptor": "",
    "authors": [
      "Lionel Nganyewou Tidjon",
      "Foutse Khomh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01535"
  },
  {
    "id": "arXiv:2211.01538",
    "title": "$D^2$SLAM: Decentralized and Distributed Collaborative Visual-inertial  SLAM System for Aerial Swarm",
    "abstract": "In recent years, aerial swarm technology has developed rapidly. In order to\naccomplish a fully autonomous aerial swarm, a key technology is decentralized\nand distributed collaborative SLAM (CSLAM) for aerial swarms, which estimates\nthe relative pose and the consistent global trajectories. In this paper, we\npropose $D^2$SLAM: a decentralized and distributed ($D^2$) collaborative SLAM\nalgorithm. This algorithm has high local accuracy and global consistency, and\nthe distributed architecture allows it to scale up. $D^2$SLAM covers swarm\nstate estimation in two scenarios: near-field state estimation for high\nreal-time accuracy at close range and far-field state estimation for globally\nconsistent trajectories estimation at the long-range between UAVs. Distributed\noptimization algorithms are adopted as the backend to achieve the $D^2$ goal.\n$D^2$SLAM is robust to transient loss of communication, network delays, and\nother factors. Thanks to the flexible architecture, $D^2$SLAM has the potential\nof applying in various scenarios.",
    "descriptor": "",
    "authors": [
      "Hao Xu",
      "Peize Liu",
      "Xinyi Chen",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01538"
  },
  {
    "id": "arXiv:2211.01539",
    "title": "Conformal Prediction for STL Runtime Verification",
    "abstract": "We are interested in predicting failures of cyber-physical systems during\ntheir operation. Particularly, we consider stochastic systems and signal\ntemporal logic specifications, and we want to calculate the probability that\nthe current system trajectory violates the specification. The paper presents\ntwo predictive runtime verification algorithms that predict future system\nstates from the current observed system trajectory. As these predictions may\nnot be accurate, we construct prediction regions that quantify prediction\nuncertainty by using conformal prediction, a statistical tool for uncertainty\nquantification. Our first algorithm directly constructs a prediction region for\nthe satisfaction measure of the specification so that we can predict\nspecification violations with a desired confidence. The second algorithm\nconstructs prediction regions for future system states first, and uses these to\nobtain a prediction region for the satisfaction measure. To the best of our\nknowledge, these are the first formal guarantees for a predictive runtime\nverification algorithm that applies to widely used trajectory predictors such\nas RNNs and LSTMs, while being computationally simple and making no assumptions\non the underlying distribution. We present numerical experiments of an F-16\naircraft and a self-driving car.",
    "descriptor": "",
    "authors": [
      "Lars Lindemann",
      "Xin Qin",
      "Jyotirmoy V. Deshmukh",
      "George J. Pappas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Logic in Computer Science (cs.LO)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01539"
  },
  {
    "id": "arXiv:2211.01542",
    "title": "Continual Learning of Neural Machine Translation within Low Forgetting  Risk Regions",
    "abstract": "This paper considers continual learning of large-scale pretrained neural\nmachine translation model without accessing the previous training data or\nintroducing model separation. We argue that the widely used\nregularization-based methods, which perform multi-objective learning with an\nauxiliary loss, suffer from the misestimate problem and cannot always achieve a\ngood balance between the previous and new tasks. To solve the problem, we\npropose a two-stage training method based on the local features of the real\nloss. We first search low forgetting risk regions, where the model can retain\nthe performance on the previous task as the parameters are updated, to avoid\nthe catastrophic forgetting problem. Then we can continually train the model\nwithin this region only with the new training data to fit the new task.\nSpecifically, we propose two methods to search the low forgetting risk regions,\nwhich are based on the curvature of loss and the impacts of the parameters on\nthe model output, respectively. We conduct experiments on domain adaptation and\nmore challenging language adaptation tasks, and the experimental results show\nthat our method can achieve significant improvements compared with several\nstrong baselines.",
    "descriptor": "\nComments: EMNLP 2020 Main Conference Long Paper\n",
    "authors": [
      "Shuhao Gu",
      "Bojie Hu",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01542"
  },
  {
    "id": "arXiv:2211.01548",
    "title": "INGREX: An Interactive Explanation Framework for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) are widely used in many modern applications,\nnecessitating explanations for their decisions. However, the complexity of GNNs\nmakes it difficult to explain predictions. Even though several methods have\nbeen proposed lately, they can only provide simple and static explanations,\nwhich are difficult for users to understand in many scenarios. Therefore, we\nintroduce INGREX, an interactive explanation framework for GNNs designed to aid\nusers in comprehending model predictions. Our framework is implemented based on\nmultiple explanation algorithms and advanced libraries. We demonstrate our\nframework in three scenarios covering common demands for GNN explanations to\npresent its effectiveness and helpfulness.",
    "descriptor": "\nComments: 4 pages, 5 figures, This paper is under review for IEEE ICDE 2023\n",
    "authors": [
      "Tien-Cuong Bui",
      "Van-Duc Le",
      "Wen-Syan Li",
      "Sang Kyun Cha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01548"
  },
  {
    "id": "arXiv:2211.01549",
    "title": "Client Selection in Federated Learning: Principles, Challenges, and  Opportunities",
    "abstract": "As a privacy-preserving paradigm for training Machine Learning (ML) models,\nFederated Learning (FL) has received tremendous attention from both industry\nand academia. In a typical FL scenario, clients exhibit significant\nheterogeneity in terms of data distribution and hardware configurations. Thus,\nrandomly sampling clients in each training round may not fully exploit the\nlocal updates from heterogeneous clients, resulting in lower model accuracy,\nslower convergence rate, degraded fairness, etc. To tackle the FL client\nheterogeneity problem, various client selection algorithms have been developed,\nshowing promising performance improvement. In this paper, we systematically\npresent recent advances in the emerging field of FL client selection and its\nchallenges and research opportunities. We hope to facilitate practitioners in\nchoosing the most suitable client selection mechanisms for their applications,\nas well as inspire researchers and newcomers to better understand this exciting\nresearch topic.",
    "descriptor": "",
    "authors": [
      "Lei Fu",
      "Huanle Zhang",
      "Ge Gao",
      "Huajie Wang",
      "Mi Zhang",
      "Xin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01549"
  },
  {
    "id": "arXiv:2211.01551",
    "title": "Crime Prediction using Machine Learning with a Novel Crime Dataset",
    "abstract": "Crime is an unlawful act that carries legal repercussions. Bangladesh has a\nhigh crime rate due to poverty, population growth, and many other\nsocio-economic issues. For law enforcement agencies, understanding crime\npatterns is essential for preventing future criminal activity. For this\npurpose, these agencies need structured crime database. This paper introduces a\nnovel crime dataset that contains temporal, geographic, weather, and\ndemographic data about 6574 crime incidents of Bangladesh. We manually gather\ncrime news articles of a seven year time span from a daily newspaper archive.\nWe extract basic features from these raw text. Using these basic features, we\nthen consult standard service-providers of geo-location and weather data in\norder to garner these information related to the collected crime incidents.\nFurthermore, we collect demographic information from Bangladesh National Census\ndata. All these information are combined that results in a standard machine\nlearning dataset. Together, 36 features are engineered for the crime prediction\ntask. Five supervised machine learning classification algorithms are then\nevaluated on this newly built dataset and satisfactory results are achieved. We\nalso conduct exploratory analysis on various aspects the dataset. This dataset\nis expected to serve as the foundation for crime incidence prediction systems\nfor Bangladesh and other countries. The findings of this study will help law\nenforcement agencies to forecast and contain crime as well as to ensure optimal\nresource allocation for crime patrol and prevention.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Faisal Tareque Shohan",
      "Abu Ubaida Akash",
      "Muhammad Ibrahim",
      "Mohammad Shafiul Alam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.01551"
  },
  {
    "id": "arXiv:2211.01553",
    "title": "User or Labor: An Interaction Framework for Human-Machine Relationships  in NLP",
    "abstract": "The bridging research between Human-Computer Interaction and Natural Language\nProcessing is developing quickly these years. However, there is still a lack of\nformative guidelines to understand the human-machine interaction in the NLP\nloop. When researchers crossing the two fields talk about humans, they may\nimply a user or labor. Regarding a human as a user, the human is in control,\nand the machine is used as a tool to achieve the human's goals. Considering a\nhuman as a laborer, the machine is in control, and the human is used as a\nresource to achieve the machine's goals. Through a systematic literature review\nand thematic analysis, we present an interaction framework for understanding\nhuman-machine relationships in NLP. In the framework, we propose four types of\nhuman-machine interactions: Human-Teacher and Machine-Learner, Machine-Leading,\nHuman-Leading, and Human-Machine Collaborators. Our analysis shows that the\ntype of interaction is not fixed but can change across tasks as the\nrelationship between the human and the machine develops. We also discuss the\nimplications of this framework for the future of NLP and human-machine\nrelationships.",
    "descriptor": "",
    "authors": [
      "Ruyuan Wan",
      "Naome Etori",
      "Karla Badillo-Urquiola",
      "Dongyeop Kang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.01553"
  },
  {
    "id": "arXiv:2211.01554",
    "title": "Embed and Emulate: Learning to estimate parameters of dynamical systems  with uncertainty quantification",
    "abstract": "This paper explores learning emulators for parameter estimation with\nuncertainty estimation of high-dimensional dynamical systems. We assume access\nto a computationally complex simulator that inputs a candidate parameter and\noutputs a corresponding multichannel time series. Our task is to accurately\nestimate a range of likely values of the underlying parameters. Standard\niterative approaches necessitate running the simulator many times, which is\ncomputationally prohibitive. This paper describes a novel framework for\nlearning feature embeddings of observed dynamics jointly with an emulator that\ncan replace high-cost simulators for parameter estimation. Leveraging a\ncontrastive learning approach, our method exploits intrinsic data properties\nwithin and across parameter and trajectory domains. On a coupled\n396-dimensional multiscale Lorenz 96 system, our method significantly\noutperforms a typical parameter estimation method based on predefined metrics\nand a classical numerical simulator, and with only 1.19% of the baseline's\ncomputation time. Ablation studies highlight the potential of explicitly\ndesigning learned emulators for parameter estimation by leveraging contrastive\nlearning.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Ruoxi Jiang",
      "Rebecca Willett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.01554"
  },
  {
    "id": "arXiv:2211.01556",
    "title": "Ground Plane Matters: Picking Up Ground Plane Prior in Monocular 3D  Object Detection",
    "abstract": "The ground plane prior is a very informative geometry clue in monocular 3D\nobject detection (M3OD). However, it has been neglected by most mainstream\nmethods. In this paper, we identify two key factors that limit the\napplicability of ground plane prior: the projection point localization issue\nand the ground plane tilt issue. To pick up the ground plane prior for M3OD, we\npropose a Ground Plane Enhanced Network (GPENet) which resolves both issues at\none go. For the projection point localization issue, instead of using the\nbottom vertices or bottom center of the 3D bounding box (BBox), we leverage the\nobject's ground contact points, which are explicit pixels in the image and easy\nfor the neural network to detect. For the ground plane tilt problem, our GPENet\nestimates the horizon line in the image and derives a novel mathematical\nexpression to accurately estimate the ground plane equation. An unsupervised\nvertical edge mining algorithm is also proposed to address the occlusion of the\nhorizon line. Furthermore, we design a novel 3D bounding box deduction method\nbased on a dynamic back projection algorithm, which could take advantage of the\naccurate contact points and the ground plane equation. Additionally, using only\nM3OD labels, contact point and horizon line pseudo labels can be easily\ngenerated with NO extra data collection and label annotation cost. Extensive\nexperiments on the popular KITTI benchmark show that our GPENet can outperform\nother methods and achieve state-of-the-art performance, well demonstrating the\neffectiveness and the superiority of the proposed approach. Moreover, our\nGPENet works better than other methods in cross-dataset evaluation on the\nnuScenes dataset. Our code and models will be published.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Fan Yang",
      "Xinhao Xu",
      "Hui Chen",
      "Yuchen Guo",
      "Jungong Han",
      "Kai Ni",
      "Guiguang Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01556"
  },
  {
    "id": "arXiv:2211.01559",
    "title": "The ProfessionAl Go annotation datasEt (PAGE)",
    "abstract": "The game of Go has been highly under-researched due to the lack of game\nrecords and analysis tools. In recent years, the increasing number of\nprofessional competitions and the advent of AlphaZero-based algorithms provide\nan excellent opportunity for analyzing human Go games on a large scale. In this\npaper, we present the ProfessionAl Go annotation datasEt (PAGE), containing\n98,525 games played by 2,007 professional players and spans over 70 years. The\ndataset includes rich AI analysis results for each move. Moreover, PAGE\nprovides detailed metadata for every player and game after manual cleaning and\nlabeling. Beyond the preliminary analysis of the dataset, we provide sample\ntasks that benefit from our dataset to demonstrate the potential application of\nPAGE in multiple research directions. To the best of our knowledge, PAGE is the\nfirst dataset with extensive annotation in the game of Go. This work is an\nextended version of [1] where we perform a more detailed description, analysis,\nand application.",
    "descriptor": "\nComments: Journal version of arXiv:2205.00254, under review\n",
    "authors": [
      "Yifan Gao",
      "Danni Zhang",
      "Haoyue Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.01559"
  },
  {
    "id": "arXiv:2211.01562",
    "title": "PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales",
    "abstract": "Neural language models (LMs) have achieved impressive results on various\nlanguage-based reasoning tasks by utilizing latent knowledge encoded in their\nown pretrained parameters. To make this reasoning process more explicit, recent\nworks retrieve a rationalizing LM's internal knowledge by training or prompting\nit to generate free-text rationales, which can be used to guide task\npredictions made by either the same LM or a separate reasoning LM. However,\nrationalizing LMs require expensive rationale annotation and/or computation,\nwithout any assurance that their generated rationales improve LM task\nperformance or faithfully reflect LM decision-making. In this paper, we propose\nPINTO, an LM pipeline that rationalizes via prompt-based learning, and learns\nto faithfully reason over rationales via counterfactual regularization. First,\nPINTO maps out a suitable reasoning process for the task input by prompting a\nfrozen rationalizing LM to generate a free-text rationale. Second, PINTO's\nreasoning LM is fine-tuned to solve the task using the generated rationale as\ncontext, while regularized to output less confident predictions when the\nrationale is perturbed. Across four datasets, we show that PINTO significantly\nimproves the generalization ability of the reasoning LM, yielding higher\nperformance on both in-distribution and out-of-distribution test sets. Also, we\nfind that PINTO's rationales are more faithful to its task predictions than\nthose generated by competitive baselines.",
    "descriptor": "\nComments: 18 pages, 6 figures, preprint\n",
    "authors": [
      "Peifeng Wang",
      "Aaron Chan",
      "Filip Ilievski",
      "Muhao Chen",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01562"
  },
  {
    "id": "arXiv:2211.01566",
    "title": "NaRPA: Navigation and Rendering Pipeline for Astronautics",
    "abstract": "This paper presents Navigation and Rendering Pipeline for Astronautics\n(NaRPA) - a novel ray-tracing-based computer graphics engine to model and\nsimulate light transport for space-borne imaging. NaRPA incorporates lighting\nmodels with attention to atmospheric and shading effects for the synthesis of\nspace-to-space and ground-to-space virtual observations. In addition to image\nrendering, the engine also possesses point cloud, depth, and contour map\ngeneration capabilities to simulate passive and active vision-based sensors and\nto facilitate the designing, testing, or verification of visual navigation\nalgorithms. Physically based rendering capabilities of NaRPA and the efficacy\nof the proposed rendering algorithm are demonstrated using applications in\nrepresentative space-based environments. A key demonstration includes NaRPA as\na tool for generating stereo imagery and application in 3D coordinate\nestimation using triangulation. Another prominent application of NaRPA includes\na novel differentiable rendering approach for image-based attitude estimation\nis proposed to highlight the efficacy of the NaRPA engine for simulating\nvision-based navigation and guidance operations.",
    "descriptor": "\nComments: 49 pages, 22 figures\n",
    "authors": [
      "Roshan Thomas Eapen",
      "Ramchander Rao Bhaskara",
      "Manoranjan Majji"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01566"
  },
  {
    "id": "arXiv:2211.01568",
    "title": "Fine-Tuning Language Models via Epistemic Neural Networks",
    "abstract": "Large language models are now part of a powerful new paradigm in machine\nlearning. These models learn a wide range of capabilities from training on\nlarge unsupervised text corpora. In many applications, these capabilities are\nthen fine-tuned through additional training on specialized data to improve\nperformance in that setting. In this paper, we augment these models with an\nepinet: a small additional network architecture that helps to estimate model\nuncertainty and form an epistemic neural network (ENN). ENNs are neural\nnetworks that can know what they don't know. We show that, using an epinet to\nprioritize uncertain data, we can fine-tune BERT on GLUE tasks to the same\nperformance while using 2x less data. We also investigate performance in\nsynthetic neural network generative models designed to build understanding. In\neach setting, using an epinet outperforms heuristic active learning schemes.",
    "descriptor": "",
    "authors": [
      "Ian Osband",
      "Seyed Mohammad Asghari",
      "Benjamin Van Roy",
      "Nat McAleese",
      "John Aslanides",
      "Geoffrey Irving"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01568"
  },
  {
    "id": "arXiv:2211.01572",
    "title": "FedTP: Federated Learning by Transformer Personalization",
    "abstract": "Federated learning is an emerging learning paradigm where multiple clients\ncollaboratively train a machine learning model in a privacy-preserving manner.\nPersonalized federated learning extends this paradigm to overcome heterogeneity\nacross clients by learning personalized models. Recently, there have been some\ninitial attempts to apply Transformers to federated learning. However, the\nimpacts of federated learning algorithms on self-attention have not yet been\nstudied. This paper investigates this relationship and reveals that federated\naveraging algorithms actually have a negative impact on self-attention where\nthere is data heterogeneity. These impacts limit the capabilities of the\nTransformer model in federated learning settings. Based on this, we propose\nFedTP, a novel Transformer-based federated learning framework that learns\npersonalized self-attention for each client while aggregating the other\nparameters among the clients. Instead of using a vanilla personalization\nmechanism that maintains personalized self-attention layers of each client\nlocally, we develop a learn-to-personalize mechanism to further encourage the\ncooperation among clients and to increase the scablability and generalization\nof FedTP. Specifically, the learn-to-personalize is realized by learning a\nhypernetwork on the server that outputs the personalized projection matrices of\nself-attention layers to generate client-wise queries, keys and values.\nFurthermore, we present the generalization bound for FedTP with the\nlearn-to-personalize mechanism. Notably, FedTP offers a convenient environment\nfor performing a range of image and language tasks using the same federated\nnetwork architecture - all of which benefit from Transformer personalization.\nExtensive experiments verify that FedTP with the learn-to-personalize mechanism\nyields state-of-the-art performance in non-IID scenarios. Our code is available\nonline.",
    "descriptor": "",
    "authors": [
      "Hongxia Li",
      "Zhongyi Cai",
      "Jingya Wang",
      "Jiangnan Tang",
      "Weiping Ding",
      "Chin-Teng Lin",
      "Ye Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01572"
  },
  {
    "id": "arXiv:2211.01573",
    "title": "Resource Allocation in MIMO setup",
    "abstract": "In a multi-input multi-output (MIMO) setup, where one side of the link\ncomprises a linear antenna array, data can be transmitted over the direction of\nincident rays. Channel capacity for this setup is studied in this paper. We\ndefine two different setups; one when the energy is constant and equal over all\nrays, and one when available energy is evenly distributed over rays. For the\nlatter, we show that there is an upper bound for channel capacity, regardless\nof the number of rays and antennas. Also, we have compared this setup with the\nlegacy single-input single-output (SISO) AWGN channel.",
    "descriptor": "",
    "authors": [
      "Felix Ma Yun",
      "Jordan Nabi",
      "Mitra Hassani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01573"
  },
  {
    "id": "arXiv:2211.01576",
    "title": "Sequence-Based Plan Feasibility Prediction for Efficient Task and Motion  Planning",
    "abstract": "Robots planning long-horizon behavior in complex environments must be able to\nquickly reason about the impact of the environment's geometry on what plans are\nfeasible, i.e., whether there exist action parameter values that satisfy all\nconstraints on a candidate plan. In tasks involving articulated and movable\nobstacles, typical Task and Motion Planning (TAMP) algorithms spend most of\ntheir runtime attempting to solve unsolvable constraint satisfaction problems\nimposed by infeasible plan skeletons. We developed a novel Transformer-based\narchitecture, PIGINet, that predicts plan feasibility based on the initial\nstate, goal, and candidate plans, fusing image and text embeddings with state\nfeatures. The model sorts the plan skeletons produced by a TAMP planner\naccording to the predicted satisfiability likelihoods. We evaluate the runtime\nof our learning-enabled TAMP algorithm on several distributions of kitchen\nrearrangement problems, comparing its performance to that of non-learning\nbaselines and algorithm ablations. Our experiments show that PIGINet\nsubstantially improves planning efficiency, cutting down runtime by 80% on\naverage on pick-and-place problems with articulated obstacles. It also achieves\nzero-shot generalization to problems with unseen object categories thanks to\nits visual encoding of objects.",
    "descriptor": "",
    "authors": [
      "Zhutian Yang",
      "Caelan Reed Garrett",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01576"
  },
  {
    "id": "arXiv:2211.01577",
    "title": "Open-Vocabulary Argument Role Prediction for Event Extraction",
    "abstract": "The argument role in event extraction refers to the relation between an event\nand an argument participating in it. Despite the great progress in event\nextraction, existing studies still depend on roles pre-defined by domain\nexperts. These studies expose obvious weakness when extending to emerging event\ntypes or new domains without available roles. Therefore, more attention and\neffort needs to be devoted to automatically customizing argument roles. In this\npaper, we define this essential but under-explored task: open-vocabulary\nargument role prediction. The goal of this task is to infer a set of argument\nroles for a given event type. We propose a novel unsupervised framework,\nRolePred for this task. Specifically, we formulate the role prediction problem\nas an in-filling task and construct prompts for a pre-trained language model to\ngenerate candidate roles. By extracting and analyzing the candidate arguments,\nthe event-specific roles are further merged and selected. To standardize the\nresearch of this task, we collect a new event extraction dataset from\nWikiPpedia including 142 customized argument roles with rich semantics. On this\ndataset, RolePred outperforms the existing methods by a large margin. Source\ncode and dataset are available on our GitHub repository:\nhttps://github.com/yzjiao/RolePred",
    "descriptor": "\nComments: EMNLP 2022 Findings\n",
    "authors": [
      "Yizhu Jiao",
      "Sha Li",
      "Yiqing Xie",
      "Ming Zhong",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01577"
  },
  {
    "id": "arXiv:2211.01579",
    "title": "Data-free Defense of Black Box Models Against Adversarial Attacks",
    "abstract": "Several companies often safeguard their trained deep models (i.e. details of\narchitecture, learnt weights, training details etc.) from third-party users by\nexposing them only as black boxes through APIs. Moreover, they may not even\nprovide access to the training data due to proprietary reasons or sensitivity\nconcerns. We make the first attempt to provide adversarial robustness to the\nblack box models in a data-free set up. We construct synthetic data via\ngenerative model and train surrogate network using model stealing techniques.\nTo minimize adversarial contamination on perturbed samples, we propose `wavelet\nnoise remover' (WNR) that performs discrete wavelet decomposition on input\nimages and carefully select only a few important coefficients determined by our\n`wavelet coefficient selection module' (WCSM). To recover the high-frequency\ncontent of the image after noise removal via WNR, we further train a\n`regenerator' network with an objective to retrieve the coefficients such that\nthe reconstructed image yields similar to original predictions on the surrogate\nmodel. At test time, WNR combined with trained regenerator network is prepended\nto the black box network, resulting in a high boost in adversarial accuracy.\nOur method improves the adversarial accuracy on CIFAR-10 by 38.98% and 32.01%\non state-of-the-art Auto Attack compared to baseline, even when the attacker\nuses surrogate architecture (Alexnet-half and Alexnet) similar to the black box\narchitecture (Alexnet) with same model stealing strategy as defender. The code\nis available at https://github.com/vcl-iisc/data-free-black-box-defense",
    "descriptor": "\nComments: TIFS Submission (Under Review)\n",
    "authors": [
      "Gaurav Kumar Nayak",
      "Inder Khatri",
      "Shubham Randive",
      "Ruchit Rawal",
      "Anirban Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01579"
  },
  {
    "id": "arXiv:2211.01580",
    "title": "AdaChain: A Learned Adaptive Blockchain",
    "abstract": "This paper presents AdaChain, a learning-based blockchain framework that\nadaptively chooses the best permissioned blockchain architecture in order to\noptimize effective throughput for dynamic transaction workloads. AdaChain\naddresses the challenge in the Blockchain-as-a-Service (BaaS) environments,\nwhere a large variety of possible smart contracts are deployed with different\nworkload characteristics. AdaChain supports automatically adapting to an\nunderlying, dynamically changing workload through the use of reinforcement\nlearning. When a promising architecture is identified, AdaChain switches from\nthe current architecture to the promising one at runtime in a way that respects\ncorrectness and security concerns. Experimentally, we show that AdaChain can\nconverge quickly to optimal architectures under changing workloads,\nsignificantly outperform fixed architectures in terms of the number of\nsuccessfully committed transactions, all while incurring low additional\noverhead.",
    "descriptor": "",
    "authors": [
      "Chenyuan Wu",
      "Bhavana Mehta",
      "Mohammad Javad Amiri",
      "Ryan Marcus",
      "Boon Thau Loo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.01580"
  },
  {
    "id": "arXiv:2211.01585",
    "title": "The ISCSLP 2022 Intelligent Cockpit Speech Recognition Challenge  (ICSRC): Dataset, Tracks, Baseline and Results",
    "abstract": "This paper summarizes the outcomes from the ISCSLP 2022 Intelligent Cockpit\nSpeech Recognition Challenge (ICSRC). We first address the necessity of the\nchallenge and then introduce the associated dataset collected from a new-energy\nvehicle (NEV) covering a variety of cockpit acoustic conditions and linguistic\ncontents. We then describe the track arrangement and the baseline system.\nSpecifically, we set up two tracks in terms of allowed model/system size to\ninvestigate resource-constrained and -unconstrained setups, targeting to\nvehicle embedded as well as cloud ASR systems respectively. Finally we\nsummarize the challenge results and provide the major observations from the\nsubmitted systems.",
    "descriptor": "\nComments: Accepted by ISCSLP2022\n",
    "authors": [
      "Ao Zhang",
      "Fan Yu",
      "Kaixun Huang",
      "Lei Xie",
      "Longbiao Wang",
      "Eng Siong Chng",
      "Hui Bu",
      "Binbin Zhang",
      "Wei Chen",
      "Xin Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01585"
  },
  {
    "id": "arXiv:2211.01587",
    "title": "Eliciting Knowledge from Large Pre-Trained Models for Unsupervised  Knowledge-Grounded Conversation",
    "abstract": "Recent advances in large-scale pre-training provide large models with the\npotential to learn knowledge from the raw text. It is thus natural to ask\nwhether it is possible to leverage these large models as knowledge bases for\ndownstream tasks. In this work, we answer the aforementioned question in\nunsupervised knowledge-grounded conversation. We explore various methods that\nbest elicit knowledge from large models. Our human study indicates that, though\nhallucinations exist, large models post the unique advantage of being able to\noutput common sense and summarize facts that cannot be directly retrieved from\nthe search engine. To better exploit such generated knowledge in dialogue\ngeneration, we treat the generated knowledge as a noisy knowledge source and\npropose the posterior-based reweighing as well as the noisy training strategy.\nEmpirical results on two benchmarks show advantages over the state-of-the-art\nmethods.",
    "descriptor": "\nComments: EMNLP2022 Main Conference\n",
    "authors": [
      "Yanyang Li",
      "Jianqiao Zhao",
      "Michael R. Lyu",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01587"
  },
  {
    "id": "arXiv:2211.01588",
    "title": "A Convergence Theory for Federated Average: Beyond Smoothness",
    "abstract": "Federated learning enables a large amount of edge computing devices to learn\na model without data sharing jointly. As a leading algorithm in this setting,\nFederated Average FedAvg, which runs Stochastic Gradient Descent (SGD) in\nparallel on local devices and averages the sequences only once in a while, have\nbeen widely used due to their simplicity and low communication cost. However,\ndespite recent research efforts, it lacks theoretical analysis under\nassumptions beyond smoothness. In this paper, we analyze the convergence of\nFedAvg. Different from the existing work, we relax the assumption of strong\nsmoothness. More specifically, we assume the semi-smoothness and semi-Lipschitz\nproperties for the loss function, which have an additional first-order term in\nassumption definitions. In addition, we also assume bound on the gradient,\nwhich is weaker than the commonly used bounded gradient assumption in the\nconvergence analysis scheme. As a solution, this paper provides a theoretical\nconvergence study on Federated Learning.",
    "descriptor": "\nComments: BigData 2022\n",
    "authors": [
      "Xiaoxiao Li",
      "Zhao Song",
      "Runzhou Tao",
      "Guangyi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01588"
  },
  {
    "id": "arXiv:2211.01589",
    "title": "PolyBuilding: Polygon Transformer for End-to-End Building Extraction",
    "abstract": "We present PolyBuilding, a fully end-to-end polygon Transformer for building\nextraction. PolyBuilding direct predicts vector representation of buildings\nfrom remote sensing images. It builds upon an encoder-decoder transformer\narchitecture and simultaneously outputs building bounding boxes and polygons.\nGiven a set of polygon queries, the model learns the relations among them and\nencodes context information from the image to predict the final set of building\npolygons with fixed vertex numbers. Corner classification is performed to\ndistinguish the building corners from the sampled points, which can be used to\nremove redundant vertices along the building walls during inference. A 1-d\nnon-maximum suppression (NMS) is further applied to reduce vertex redundancy\nnear the building corners. With the refinement operations, polygons with\nregular shapes and low complexity can be effectively obtained. Comprehensive\nexperiments are conducted on the CrowdAI dataset. Quantitative and qualitative\nresults show that our approach outperforms prior polygonal building extraction\nmethods by a large margin. It also achieves a new state-of-the-art in terms of\npixel-level coverage, instance-level precision and recall, and geometry-level\nproperties (including contour regularity and polygon complexity).",
    "descriptor": "",
    "authors": [
      "Yuan Hu",
      "Zhibin Wang",
      "Zhou Huang",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01589"
  },
  {
    "id": "arXiv:2211.01592",
    "title": "Try to Avoid Attacks: A Federated Data Sanitization Defense for  Healthcare IoMT Systems",
    "abstract": "Healthcare IoMT systems are becoming intelligent, miniaturized, and more\nintegrated into daily life. As for the distributed devices in the IoMT,\nfederated learning has become a topical area with cloud-based training\nprocedures when meeting data security. However, the distribution of IoMT has\nthe risk of protection from data poisoning attacks. Poisoned data can be\nfabricated by falsifying medical data, which urges a security defense to IoMT\nsystems. Due to the lack of specific labels, the filtering of malicious data is\na unique unsupervised scenario. One of the main challenges is finding robust\ndata filtering methods for various poisoning attacks. This paper introduces a\nFederated Data Sanitization Defense, a novel approach to protect the system\nfrom data poisoning attacks. To solve this unsupervised problem, we first use\nfederated learning to project all the data to the subspace domain, allowing\nunified feature mapping to be established since the data is stored locally.\nThen we adopt the federated clustering to re-group their features to clarify\nthe poisoned data. The clustering is based on the consistent association of\ndata and its semantics. After we get the clustering of the private data, we do\nthe data sanitization with a simple yet efficient strategy. In the end, each\ndevice of distributed ImOT is enabled to filter malicious data according to\nfederated data sanitization. Extensive experiments are conducted to evaluate\nthe efficacy of the proposed defense method against data poisoning attacks.\nFurther, we consider our approach in the different poisoning ratios and achieve\na high Accuracy and a low attack success rate.",
    "descriptor": "",
    "authors": [
      "Chong Chen",
      "Ying Gao",
      "Leyu Shi",
      "Siquan Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01592"
  },
  {
    "id": "arXiv:2211.01595",
    "title": "Reinforcement Learning in Non-Markovian Environments",
    "abstract": "Following the novel paradigm developed by Van Roy and coauthors for\nreinforcement learning in arbitrary non-Markovian environments, we propose a\nrelated formulation inspired by classical stochastic control that reduces the\nproblem to recursive computation of approximate sufficient statistics.",
    "descriptor": "\nComments: 15 pages, submitted to Systems and Control Letters\n",
    "authors": [
      "Siddharth Chandak",
      "Vivek S Borkar",
      "Parth Dodhia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01595"
  },
  {
    "id": "arXiv:2211.01598",
    "title": "Robust Few-shot Learning Without Using any Adversarial Samples",
    "abstract": "The high cost of acquiring and annotating samples has made the `few-shot'\nlearning problem of prime importance. Existing works mainly focus on improving\nperformance on clean data and overlook robustness concerns on the data\nperturbed with adversarial noise. Recently, a few efforts have been made to\ncombine the few-shot problem with the robustness objective using sophisticated\nMeta-Learning techniques. These methods rely on the generation of adversarial\nsamples in every episode of training, which further adds a computational\nburden. To avoid such time-consuming and complicated procedures, we propose a\nsimple but effective alternative that does not require any adversarial samples.\nInspired by the cognitive decision-making process in humans, we enforce\nhigh-level feature matching between the base class data and their corresponding\nlow-frequency samples in the pretraining stage via self distillation. The model\nis then fine-tuned on the samples of novel classes where we additionally\nimprove the discriminability of low-frequency query set features via cosine\nsimilarity. On a 1-shot setting of the CIFAR-FS dataset, our method yields a\nmassive improvement of $60.55\\%$ & $62.05\\%$ in adversarial accuracy on the PGD\nand state-of-the-art Auto Attack, respectively, with a minor drop in clean\naccuracy compared to the baseline. Moreover, our method only takes $1.69\\times$\nof the standard training time while being $\\approx$ $5\\times$ faster than\nstate-of-the-art adversarial meta-learning methods. The code is available at\nhttps://github.com/vcl-iisc/robust-few-shot-learning.",
    "descriptor": "\nComments: TNNLS Submission (Under Review)\n",
    "authors": [
      "Gaurav Kumar Nayak",
      "Ruchit Rawal",
      "Inder Khatri",
      "Anirban Chakraborty"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01598"
  },
  {
    "id": "arXiv:2211.01600",
    "title": "nerf2nerf: Pairwise Registration of Neural Radiance Fields",
    "abstract": "We introduce a technique for pairwise registration of neural fields that\nextends classical optimization-based local registration (i.e. ICP) to operate\non Neural Radiance Fields (NeRF) -- neural 3D scene representations trained\nfrom collections of calibrated images. NeRF does not decompose illumination and\ncolor, so to make registration invariant to illumination, we introduce the\nconcept of a ''surface field'' -- a field distilled from a pre-trained NeRF\nmodel that measures the likelihood of a point being on the surface of an\nobject. We then cast nerf2nerf registration as a robust optimization that\niteratively seeks a rigid transformation that aligns the surface fields of the\ntwo scenes. We evaluate the effectiveness of our technique by introducing a\ndataset of pre-trained NeRF scenes -- our synthetic scenes enable quantitative\nevaluations and comparisons to classical registration techniques, while our\nreal scenes demonstrate the validity of our technique in real-world scenarios.\nAdditional results available at: https://nerf2nerf.github.io",
    "descriptor": "",
    "authors": [
      "Lily Goli",
      "Daniel Rebain",
      "Sara Sabour",
      "Animesh Garg",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01600"
  },
  {
    "id": "arXiv:2211.01602",
    "title": "Optimal Behavior Prior: Data-Efficient Human Models for Improved  Human-AI Collaboration",
    "abstract": "AI agents designed to collaborate with people benefit from models that enable\nthem to anticipate human behavior. However, realistic models tend to require\nvast amounts of human data, which is often hard to collect. A good prior or\ninitialization could make for more data-efficient training, but what makes for\na good prior on human behavior? Our work leverages a very simple assumption:\npeople generally act closer to optimal than to random chance. We show that\nusing optimal behavior as a prior for human models makes these models vastly\nmore data-efficient and able to generalize to new environments. Our intuition\nis that such a prior enables the training to focus one's precious real-world\ndata on capturing the subtle nuances of human suboptimality, instead of on the\nbasics of how to do the task in the first place. We also show that using these\nimproved human models often leads to better human-AI collaboration performance\ncompared to using models based on real human data alone.",
    "descriptor": "\nComments: Presented at the NeurIPS 2022 Human in the Loop Learning (HiLL) Workshop\n",
    "authors": [
      "Mesut Yang",
      "Micah Carroll",
      "Anca Dragan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.01602"
  },
  {
    "id": "arXiv:2211.01604",
    "title": "Meta-PDE: Learning to Solve PDEs Quickly Without a Mesh",
    "abstract": "Partial differential equations (PDEs) are often computationally challenging\nto solve, and in many settings many related PDEs must be be solved either at\nevery timestep or for a variety of candidate boundary conditions, parameters,\nor geometric domains. We present a meta-learning based method which learns to\nrapidly solve problems from a distribution of related PDEs. We use\nmeta-learning (MAML and LEAP) to identify initializations for a neural network\nrepresentation of the PDE solution such that a residual of the PDE can be\nquickly minimized on a novel task. We apply our meta-solving approach to a\nnonlinear Poisson's equation, 1D Burgers' equation, and hyperelasticity\nequations with varying parameters, geometries, and boundary conditions. The\nresulting Meta-PDE method finds qualitatively accurate solutions to most\nproblems within a few gradient steps; for the nonlinear Poisson and\nhyper-elasticity equation this results in an intermediate accuracy\napproximation up to an order of magnitude faster than a baseline finite element\nanalysis (FEA) solver with equivalent accuracy. In comparison to other learned\nsolvers and surrogate models, this meta-learning approach can be trained\nwithout supervision from expensive ground-truth data, does not require a mesh,\nand can even be used when the geometry and topology varies between tasks.",
    "descriptor": "",
    "authors": [
      "Tian Qin",
      "Alex Beatson",
      "Deniz Oktay",
      "Nick McGreivy",
      "Ryan P. Adams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01604"
  },
  {
    "id": "arXiv:2211.01612",
    "title": "Computing a many-to-many matching with demands and capacities between  two sets using the Hungarian algorithm",
    "abstract": "Given two sets A={a_1,a_2,...,a_s} and {b_1,b_2,...,b_t}, a many-to-many\nmatching with demands and capacities (MMDC) between A and B matches each\nelement a_i in A to at least \\alpha_i and at most \\alpha'_i elements in B, and\neach element b_j in B to at least \\beta_j and at most \\beta'_j elements in A\nfor all 1=<i<=s and 1=<j<=t. In this paper, we present an algorithm for finding\na minimum-cost MMDC between A and B using the well-known Hungarian algorithm.",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Fatemeh Rajabi-Alni",
      "Alireza Bagheri"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.01612"
  },
  {
    "id": "arXiv:2211.01625",
    "title": "From Spelling to Grammar: A New Framework for Chinese Grammatical Error  Correction",
    "abstract": "Chinese Grammatical Error Correction (CGEC) aims to generate a correct\nsentence from an erroneous sequence, where different kinds of errors are mixed.\nThis paper divides the CGEC task into two steps, namely spelling error\ncorrection and grammatical error correction. Specifically, we propose a novel\nzero-shot approach for spelling error correction, which is simple but\neffective, obtaining a high precision to avoid error accumulation of the\npipeline structure. To handle grammatical error correction, we design\npart-of-speech (POS) features and semantic class features to enhance the neural\nnetwork model, and propose an auxiliary task to predict the POS sequence of the\ntarget sentence. Our proposed framework achieves a 42.11 F0.5 score on CGEC\ndataset without using any synthetic data or data augmentation methods, which\noutperforms the previous state-of-the-art by a wide margin of 1.30 points.\nMoreover, our model produces meaningful POS representations that capture\ndifferent POS words and convey reasonable POS transition rules.",
    "descriptor": "",
    "authors": [
      "Xiuyu Wu",
      "Yunfang Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01625"
  },
  {
    "id": "arXiv:2211.01628",
    "title": "Private Semi-supervised Knowledge Transfer for Deep Learning from Noisy  Labels",
    "abstract": "Deep learning models trained on large-scale data have achieved encouraging\nperformance in many real-world tasks. Meanwhile, publishing those models\ntrained on sensitive datasets, such as medical records, could pose serious\nprivacy concerns. To counter these issues, one of the current state-of-the-art\napproaches is the Private Aggregation of Teacher Ensembles, or PATE, which\nachieved promising results in preserving the utility of the model while\nproviding a strong privacy guarantee. PATE combines an ensemble of \"teacher\nmodels\" trained on sensitive data and transfers the knowledge to a \"student\"\nmodel through the noisy aggregation of teachers' votes for labeling unlabeled\npublic data which the student model will be trained on. However, the knowledge\nor voted labels learned by the student are noisy due to private aggregation.\nLearning directly from noisy labels can significantly impact the accuracy of\nthe student model.\nIn this paper, we propose the PATE++ mechanism, which combines the current\nadvanced noisy label training mechanisms with the original PATE framework to\nenhance its accuracy. A novel structure of Generative Adversarial Nets (GANs)\nis developed in order to integrate them effectively. In addition, we develop a\nnovel noisy label detection mechanism for semi-supervised model training to\nfurther improve student model performance when training with noisy labels. We\nevaluate our method on Fashion-MNIST and SVHN to show the improvements on the\noriginal PATE on all measures.",
    "descriptor": "",
    "authors": [
      "Qiuchen Zhang",
      "Jing Ma",
      "Jian Lou",
      "Li Xiong",
      "Xiaoqian Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01628"
  },
  {
    "id": "arXiv:2211.01629",
    "title": "Image-based Early Detection System for Wildfires",
    "abstract": "Wildfires are a disastrous phenomenon which cause damage to land, loss of\nproperty, air pollution, and even loss of human life. Due to the warmer and\ndrier conditions created by climate change, more severe and uncontrollable\nwildfires are expected to occur in the coming years. This could lead to a\nglobal wildfire crisis and have dire consequences on our planet. Hence, it has\nbecome imperative to use technology to help prevent the spread of wildfires.\nOne way to prevent the spread of wildfires before they become too large is to\nperform early detection i.e, detecting the smoke before the actual fire starts.\nIn this paper, we present our Wildfire Detection and Alert System which use\nmachine learning to detect wildfire smoke with a high degree of accuracy and\ncan send immediate alerts to users. Our technology is currently being used in\nthe USA to monitor data coming in from hundreds of cameras daily. We show that\nour system has a high true detection rate and a low false detection rate. Our\nperformance evaluation study also shows that on an average our system detects\nwildfire smoke faster than an actual person.",
    "descriptor": "\nComments: Published in Tackling Climate Change with Machine Learning workshop, Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Omkar Ranadive",
      "Jisu Kim",
      "Serin Lee",
      "Youngseo Cha",
      "Heechan Park",
      "Minkook Cho",
      "Young K. Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01629"
  },
  {
    "id": "arXiv:2211.01631",
    "title": "$\\mathcal{X}$-Metric: An N-Dimensional Information-Theoretic Framework  for Groupwise Registration and Deep Combined Computing",
    "abstract": "This paper presents a generic probabilistic framework for estimating the\nstatistical dependency and finding the anatomical correspondences among an\narbitrary number of medical images. The method builds on a novel formulation of\nthe $N$-dimensional joint intensity distribution by representing the common\nanatomy as latent variables and estimating the appearance model with\nnonparametric estimators. Through connection to maximum likelihood and the\nexpectation-maximization algorithm, an information\\hyp{}theoretic metric called\n$\\mathcal{X}$-metric and a co-registration algorithm named $\\mathcal{X}$-CoReg\nare induced, allowing groupwise registration of the $N$ observed images with\ncomputational complexity of $\\mathcal{O}(N)$. Moreover, the method naturally\nextends for a weakly-supervised scenario where anatomical labels of certain\nimages are provided. This leads to a combined\\hyp{}computing framework\nimplemented with deep learning, which performs registration and segmentation\nsimultaneously and collaboratively in an end-to-end fashion. Extensive\nexperiments were conducted to demonstrate the versatility and applicability of\nour model, including multimodal groupwise registration, motion correction for\ndynamic contrast enhanced magnetic resonance images, and deep combined\ncomputing for multimodal medical images. Results show the superiority of our\nmethod in various applications in terms of both accuracy and efficiency,\nhighlighting the advantage of the proposed representation of the imaging\nprocess.",
    "descriptor": "",
    "authors": [
      "Xinzhe Luo",
      "Xiahai Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01631"
  },
  {
    "id": "arXiv:2211.01633",
    "title": "Cooperative Maneuvers of Highly Automated Vehicles at Urban  Intersections: A Game-theoretic Approach",
    "abstract": "In this paper, we propose an approach how connected and highly automated\nvehicles can perform cooperative maneuvers such as lane changes and left-turns\nat urban intersections where they have to deal with human-operated vehicles and\nvulnerable road users such as cyclists and pedestrians in so-called mixed\ntraffic. In order to support cooperative maneuvers the urban intersection is\nequipped with an intelligent controller which has access to different sensors\nalong the intersection to detect and predict the behavior of the traffic\nparticipants involved. Since the intersection controller cannot directly\ncontrol all road users and - not least due to the legal situation - driving\ndecisions must always be made by the vehicle controller itself, we focus on a\ndecentralized control paradigm. In this context, connected and highly automated\nvehicles use some carefully selected game theory concepts to make the best\npossible and clear decisions about cooperative maneuvers. The aim is to improve\ntraffic efficiency while maintaining road safety at the same time. Our first\nresults obtained with a prototypical implementation of the approach in a\ntraffic simulation are promising.",
    "descriptor": "",
    "authors": [
      "Bj\u00f6rn Koopmann",
      "Stefan Puch",
      "G\u00fcnter Ehmen",
      "Martin Fr\u00e4nzle"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.01633"
  },
  {
    "id": "arXiv:2211.01634",
    "title": "P4P: Conflict-Aware Motion Prediction for Planning in Autonomous Driving",
    "abstract": "Motion prediction is crucial in enabling safe motion planning for autonomous\nvehicles in interactive scenarios. It allows the planner to identify potential\nconflicts with other traffic agents and generate safe plans. Existing motion\npredictors often focus on reducing prediction errors, yet it remains an open\nquestion on how well they help identify the conflicts for the planner. In this\npaper, we evaluate state-of-the-art predictors through novel conflict-related\nmetrics, such as the success rate of identifying conflicts. Surprisingly, the\npredictors suffer from a low success rate and thus lead to a large percentage\nof collisions when we test the prediction-planning system in an interactive\nsimulator. To fill the gap, we propose a simple but effective alternative that\ncombines a physics-based trajectory generator and a learning-based relation\npredictor to identify conflicts and infer conflict relations. We demonstrate\nthat our predictor, P4P, achieves superior performance over existing\nlearning-based predictors in realistic interactive driving scenarios from Waymo\nOpen Motion Dataset.",
    "descriptor": "\nComments: 7 pages, 4 figures, 3 tables\n",
    "authors": [
      "Qiao Sun",
      "Xin Huang",
      "Brian C. Williams",
      "Hang Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01634"
  },
  {
    "id": "arXiv:2211.01635",
    "title": "Revisiting Grammatical Error Correction Evaluation and Beyond",
    "abstract": "Pretraining-based (PT-based) automatic evaluation metrics (e.g., BERTScore\nand BARTScore) have been widely used in several sentence generation tasks\n(e.g., machine translation and text summarization) due to their better\ncorrelation with human judgments over traditional overlap-based methods.\nAlthough PT-based methods have become the de facto standard for training\ngrammatical error correction (GEC) systems, GEC evaluation still does not\nbenefit from pretrained knowledge. This paper takes the first step towards\nunderstanding and improving GEC evaluation with pretraining. We first find that\narbitrarily applying PT-based metrics to GEC evaluation brings unsatisfactory\ncorrelation results because of the excessive attention to inessential systems\noutputs (e.g., unchanged parts). To alleviate the limitation, we propose a\nnovel GEC evaluation metric to achieve the best of both worlds, namely PT-M2\nwhich only uses PT-based metrics to score those corrected parts. Experimental\nresults on the CoNLL14 evaluation task show that PT-M2 significantly\noutperforms existing methods, achieving a new state-of-the-art result of 0.949\nPearson correlation. Further analysis reveals that PT-M2 is robust to evaluate\ncompetitive GEC systems. Source code and scripts are freely available at\nhttps://github.com/pygongnlp/PT-M2.",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Peiyuan Gong",
      "Xuebo Liu",
      "Heyan Huang",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01635"
  },
  {
    "id": "arXiv:2211.01638",
    "title": "Joint Chinese Word Segmentation and Span-based Constituency Parsing",
    "abstract": "In constituency parsing, span-based decoding is an important direction.\nHowever, for Chinese sentences, because of their linguistic characteristics, it\nis necessary to utilize other models to perform word segmentation first, which\nintroduces a series of uncertainties and generally leads to errors in the\ncomputation of the constituency tree afterward. This work proposes a method for\njoint Chinese word segmentation and Span-based Constituency Parsing by adding\nextra labels to individual Chinese characters on the parse trees. Through\nexperiments, the proposed algorithm outperforms the recent models for joint\nsegmentation and constituency parsing on CTB 5.1.",
    "descriptor": "",
    "authors": [
      "Zhicheng Wang",
      "Tianyu Shi",
      "Cong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01638"
  },
  {
    "id": "arXiv:2211.01639",
    "title": "Temporal Consistency Learning of inter-frames for Video Super-Resolution",
    "abstract": "Video super-resolution (VSR) is a task that aims to reconstruct\nhigh-resolution (HR) frames from the low-resolution (LR) reference frame and\nmultiple neighboring frames. The vital operation is to utilize the relative\nmisaligned frames for the current frame reconstruction and preserve the\nconsistency of the results. Existing methods generally explore information\npropagation and frame alignment to improve the performance of VSR. However, few\nstudies focus on the temporal consistency of inter-frames. In this paper, we\npropose a Temporal Consistency learning Network (TCNet) for VSR in an\nend-to-end manner, to enhance the consistency of the reconstructed videos. A\nspatio-temporal stability module is designed to learn the self-alignment from\ninter-frames. Especially, the correlative matching is employed to exploit the\nspatial dependency from each frame to maintain structural stability. Moreover,\na self-attention mechanism is utilized to learn the temporal correspondence to\nimplement an adaptive warping operation for temporal consistency among\nmulti-frames. Besides, a hybrid recurrent architecture is designed to leverage\nshort-term and long-term information. We further present a progressive fusion\nmodule to perform a multistage fusion of spatio-temporal features. And the\nfinal reconstructed frames are refined by these fused features. Objective and\nsubjective results of various experiments demonstrate that TCNet has superior\nperformance on different benchmark datasets, compared to several\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted by IEEE Trans. Circuits Syst. Video Technol\n",
    "authors": [
      "Meiqin Liu",
      "Shuo Jin",
      "Chao Yao",
      "Chunyu Lin",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01639"
  },
  {
    "id": "arXiv:2211.01642",
    "title": "Fine-Tuning Pre-Trained Language Models Effectively by Optimizing  Subnetworks Adaptively",
    "abstract": "Large-scale pre-trained language models have achieved impressive results on a\nwide range of downstream tasks recently. However, fine-tuning an extremely\nlarge-scale pre-trained language model on limited target datasets is often\nplagued by overfitting and representation degradation. In this paper, we\npropose a Dynamic Parameter Selection (DPS) algorithm for the large-scale\npre-trained models during fine-tuning, which adaptively selects a more\npromising subnetwork to perform staging updates based on gradients of\nback-propagation. Experiments on the GLUE benchmark show that DPS outperforms\nprevious fine-tuning methods in terms of overall performance and stability, and\nconsistently achieves better results with variable pre-trained language models.\nIn addition, DPS brings a large magnitude of improvement in out-of-domain\ntransferring experiments and low-resource scenarios, which shows that it can\nmaintain stable general contextual features and reduce the representation\ncollapse. We release our code at https://github.com/ZhangHaojie077/DPS",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Haojie Zhang",
      "Ge Li",
      "Jia Li",
      "Zhongjin Zhang",
      "Yuqi Zhu",
      "Zhi Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01642"
  },
  {
    "id": "arXiv:2211.01644",
    "title": "StereoPose: Category-Level 6D Transparent Object Pose Estimation from  Stereo Images via Back-View NOCS",
    "abstract": "Most existing methods for category-level pose estimation rely on object point\nclouds. However, when considering transparent objects, depth cameras are\nusually not able to capture meaningful data, resulting in point clouds with\nsevere artifacts. Without a high-quality point cloud, existing methods are not\napplicable to challenging transparent objects. To tackle this problem, we\npresent StereoPose, a novel stereo image framework for category-level object\npose estimation, ideally suited for transparent objects. For a robust\nestimation from pure stereo images, we develop a pipeline that decouples\ncategory-level pose estimation into object size estimation, initial pose\nestimation, and pose refinement. StereoPose then estimates object pose based on\nrepresentation in the normalized object coordinate space~(NOCS). To address the\nissue of image content aliasing, we further define a back-view NOCS map for the\ntransparent object. The back-view NOCS aims to reduce the network learning\nambiguity caused by content aliasing, and leverage informative cues on the back\nof the transparent object for more accurate pose estimation. To further improve\nthe performance of the stereo framework, StereoPose is equipped with a parallax\nattention module for stereo feature fusion and an epipolar loss for improving\nthe stereo-view consistency of network predictions. Extensive experiments on\nthe public TOD dataset demonstrate the superiority of the proposed StereoPose\nframework for category-level 6D transparent object pose estimation.",
    "descriptor": "\nComments: 7 pages, 6 figures, Project homepage: this https URL\n",
    "authors": [
      "Kai Chen",
      "Stephen James",
      "Congying Sui",
      "Yun-Hui Liu",
      "Pieter Abbeel",
      "Qi Dou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01644"
  },
  {
    "id": "arXiv:2211.01648",
    "title": "A Scharfetter-Gummerl stabilization scheme for HDG approximations of  convection-diffusion problems",
    "abstract": "We present a Scharfetter-Gummel (SG) stabilization scheme for high-order\nHybrid Discontinuous Galerkin (HDG) approximations of convection-diffusion\nproblems. The scheme is based on a careful choice of the stabilization\nparameters used to define the numerical flux in the HDG method. We show that,\nin one dimension, the SG-HDG scheme is equivalent to the Finite Volume method\nstabilized with the Scharfetter--Gummel on the dual grid, for all orders of HDG\nschemes.",
    "descriptor": "\nComments: 17 pages, 7 figures, 1 table\n",
    "authors": [
      "Stefano Piani",
      "Luca Heltai",
      "Wenyu Lei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.01648"
  },
  {
    "id": "arXiv:2211.01656",
    "title": "GRAIMATTER Green Paper: Recommendations for disclosure control of  trained Machine Learning (ML) models from Trusted Research Environments  (TREs)",
    "abstract": "TREs are widely, and increasingly used to support statistical analysis of\nsensitive data across a range of sectors (e.g., health, police, tax and\neducation) as they enable secure and transparent research whilst protecting\ndata confidentiality. There is an increasing desire from academia and industry\nto train AI models in TREs. The field of AI is developing quickly with\napplications including spotting human errors, streamlining processes, task\nautomation and decision support. These complex AI models require more\ninformation to describe and reproduce, increasing the possibility that\nsensitive personal data can be inferred from such descriptions. TREs do not\nhave mature processes and controls against these risks. This is a complex\ntopic, and it is unreasonable to expect all TREs to be aware of all risks or\nthat TRE researchers have addressed these risks in AI-specific training.\nGRAIMATTER has developed a draft set of usable recommendations for TREs to\nguard against the additional risks when disclosing trained AI models from TREs.\nThe development of these recommendations has been funded by the GRAIMATTER UKRI\nDARE UK sprint research project. This version of our recommendations was\npublished at the end of the project in September 2022. During the course of the\nproject, we have identified many areas for future investigations to expand and\ntest these recommendations in practice. Therefore, we expect that this document\nwill evolve over time.",
    "descriptor": "",
    "authors": [
      "Emily Jefferson",
      "James Liley",
      "Maeve Malone",
      "Smarti Reel",
      "Alba Crespi-Boixader",
      "Xaroula Kerasidou",
      "Francesco Tava",
      "Andrew McCarthy",
      "Richard Preen",
      "Alberto Blanco-Justicia",
      "Esma Mansouri-Benssassi",
      "Josep Domingo-Ferrer",
      "Jillian Beggs",
      "Antony Chuter",
      "Christian Cole",
      "Felix Ritchie",
      "Angela Daly",
      "Simon Rogers",
      "Jim Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01656"
  },
  {
    "id": "arXiv:2211.01658",
    "title": "Secret Sharing for Generic Theoretic Cryptography",
    "abstract": "Sharing a secret efficiently amongst a group of participants is not easy\nsince there is always an adversary / eavesdropper trying to retrieve the\nsecret. In secret sharing schemes, every participant is given a unique share.\nWhen the desired group of participants come together and provide their shares,\nthe secret is obtained. For other combinations of shares, a garbage value is\nreturned. A threshold secret sharing scheme was proposed by Shamir and Blakley\nindependently. In this (n,t) threshold secret sharing scheme, the secret can be\nobtained when at least t out of n participants contribute their shares. This\npaper proposes a novel algorithm to reveal the secret only to the subsets of\nparticipants belonging to the access structure. This scheme implements totally\ngeneralized ideal secret sharing. Unlike threshold secret sharing schemes, this\nscheme reveals the secret only to the authorized sets of participants, not any\narbitrary set of users with cardinality more than or equal to t. Since any\naccess structure can be realized with this scheme, this scheme can be exploited\nto implement various access priorities and access control mechanisms. A major\nadvantage of this scheme over the existing ones is that the shares being\ndistributed to the participants is totally independent of the secret being\nshared. Hence, no restrictions are imposed on the scheme and it finds a wider\nuse in real world applications.",
    "descriptor": "",
    "authors": [
      "James Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.01658"
  },
  {
    "id": "arXiv:2211.01659",
    "title": "An Open Platform for Simulating the Physical Layer of 6G Communication  Systems with Multiple Intelligent Surfaces",
    "abstract": "Reconfigurable Intelligent Surfaces (RIS) constitute a promising technology\nthat could fulfill the extreme performance and capacity needs of the upcoming\n6G wireless networks, by offering software-defined control over wireless\npropagation phenomena. Despite the existence of many theoretical models\ndescribing various aspects of RIS from the signal processing perspective (e.g.,\nchannel fading models), there is no open platform to simulate and study their\nactual physical-layer behavior, especially in the multi-RIS case. In this\npaper, we develop an open simulation platform, aimed at modeling the\nphysical-layer electromagnetic coupling and propagation between RIS pairs. We\npresent the platform by initially designing a basic unit cell, and then\nproceeding to progressively model and simulate multiple and larger RISs. The\nplatform can be used for producing verifiable stochastic models for wireless\ncommunication in multi-RIS deployments, such as vehicle-to-everything (V2X)\ncommunications in autonomous vehicles and cybersecurity schemes, while its code\nis freely available to the public.",
    "descriptor": "",
    "authors": [
      "Alexandros Papadopoulos",
      "Antonios Lalas",
      "Konstantinos Votis",
      "Dimitrios Tyrovolas",
      "George K. Karagiannidis",
      "Sotiris Ioannidis",
      "Christos Liaskos"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01659"
  },
  {
    "id": "arXiv:2211.01661",
    "title": "Pairing optimization via statistics: Algebraic structure in pairing  problems and its application to performance enhancement",
    "abstract": "Fully pairing all elements of a set while attempting to maximize the total\nbenefit is a combinatorically difficult problem. Such pairing problems\nnaturally appear in various situations in science, technology, economics, and\nother fields. In our previous study, we proposed an efficient method to infer\nthe underlying compatibilities among the entities, under the constraint that\nonly the total compatibility is observable. Furthermore, by transforming the\npairing problem into a traveling salesman problem with a multi-layer\narchitecture, a pairing optimization algorithm was successfully demonstrated to\nderive a high-total-compatibility pairing. However, there is substantial room\nfor further performance enhancement by further exploiting the underlying\nmathematical properties. In this study, we prove the existence of algebraic\nstructures in the pairing problem. We transform the initially estimated\ncompatibility information into an equivalent form where the variance of the\nindividual compatibilities is minimized. We then demonstrate that the total\ncompatibility obtained when using the heuristic pairing algorithm on the\ntransformed problem is significantly higher compared to the previous method.\nWith this improved perspective on the pairing problem using fundamental\nmathematical properties, we can contribute to practical applications such as\nwireless communications beyond 5G, where efficient pairing is of critical\nimportance.",
    "descriptor": "",
    "authors": [
      "Naoki Fujita",
      "Andr\u00e9 R\u00f6hm",
      "Takatomo Mihana",
      "Ryoichi Horisaki",
      "Aohan Li",
      "Mikio Hasegawa",
      "Makoto Naruse"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.01661"
  },
  {
    "id": "arXiv:2211.01664",
    "title": "PointSee: Image Enhances Point Cloud",
    "abstract": "There is a trend to fuse multi-modal information for 3D object detection\n(3OD). However, the challenging problems of low lightweightness, poor\nflexibility of plug-and-play, and inaccurate alignment of features are still\nnot well-solved, when designing multi-modal fusion newtorks. We propose\nPointSee, a lightweight, flexible and effective multi-modal fusion solution to\nfacilitate various 3OD networks by semantic feature enhancement of LiDAR point\nclouds assembled with scene images. Beyond the existing wisdom of 3OD, PointSee\nconsists of a hidden module (HM) and a seen module (SM): HM decorates LiDAR\npoint clouds using 2D image information in an offline fusion manner, leading to\nminimal or even no adaptations of existing 3OD networks; SM further enriches\nthe LiDAR point clouds by acquiring point-wise representative semantic\nfeatures, leading to enhanced performance of existing 3OD networks. Besides the\nnew architecture of PointSee, we propose a simple yet efficient training\nstrategy, to ease the potential inaccurate regressions of 2D object detection\nnetworks. Extensive experiments on the popular outdoor/indoor benchmarks show\nnumerical improvements of our PointSee over twenty-two state-of-the-arts.",
    "descriptor": "",
    "authors": [
      "Lipeng Gu",
      "Xuefeng Yan",
      "Peng Cui",
      "Lina Gong",
      "Haoran Xie",
      "Fu Lee Wang",
      "Jin Qin",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01664"
  },
  {
    "id": "arXiv:2211.01671",
    "title": "Physically Adversarial Attacks and Defenses in Computer Vision: A Survey",
    "abstract": "Although Deep Neural Networks (DNNs) have been widely applied in various\nreal-world scenarios, they are vulnerable to adversarial examples. The current\nadversarial attacks in computer vision can be divided into digital attacks and\nphysical attacks according to their different attack forms. Compared with\ndigital attacks, which generate perturbations in the digital pixels, physical\nattacks are more practical in the real world. Owing to the serious security\nproblem caused by physically adversarial examples, many works have been\nproposed to evaluate the physically adversarial robustness of DNNs in the past\nyears. In this paper, we summarize a survey versus the current physically\nadversarial attacks and physically adversarial defenses in computer vision. To\nestablish a taxonomy, we organize the current physical attacks from attack\ntasks, attack forms, and attack methods, respectively. Thus, readers can have a\nsystematic knowledge about this topic from different aspects. For the physical\ndefenses, we establish the taxonomy from pre-processing, in-processing, and\npost-processing for the DNN models to achieve a full coverage of the\nadversarial defenses. Based on the above survey, we finally discuss the\nchallenges of this research field and further outlook the future direction.",
    "descriptor": "",
    "authors": [
      "Xingxing Wei",
      "Bangzheng Pu",
      "Jiefan Lu",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01671"
  },
  {
    "id": "arXiv:2211.01675",
    "title": "Spam Review Detection Using Deep Learning",
    "abstract": "A robust and reliable system of detecting spam reviews is a crying need in\ntodays world in order to purchase products without being cheated from online\nsites. In many online sites, there are options for posting reviews, and thus\ncreating scopes for fake paid reviews or untruthful reviews. These concocted\nreviews can mislead the general public and put them in a perplexity whether to\nbelieve the review or not. Prominent machine learning techniques have been\nintroduced to solve the problem of spam review detection. The majority of\ncurrent research has concentrated on supervised learning methods, which require\nlabeled data - an inadequacy when it comes to online review. Our focus in this\narticle is to detect any deceptive text reviews. In order to achieve that we\nhave worked with both labeled and unlabeled data and proposed deep learning\nmethods for spam review detection which includes Multi-Layer Perceptron (MLP),\nConvolutional Neural Network (CNN) and a variant of Recurrent Neural Network\n(RNN) that is Long Short-Term Memory (LSTM). We have also applied some\ntraditional machine learning classifiers such as Nave Bayes (NB), K Nearest\nNeighbor (KNN) and Support Vector Machine (SVM) to detect spam reviews and\nfinally, we have shown the performance comparison for both traditional and deep\nlearning classifiers.",
    "descriptor": "",
    "authors": [
      "G. M. Shahariar",
      "Swapnil Biswas",
      "Faiza Omar",
      "Faisal Muhammad Shah",
      "Samiha Binte Hassan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01675"
  },
  {
    "id": "arXiv:2211.01676",
    "title": "Repeatable random permutation set",
    "abstract": "Based on Dempster-Shafer evidence theory (DST), random permutation set (RPS)\nis proposed by replacing combinatorial number with permutation number and\ntherefore incorporating order information. Besides, RPS could take DST as a\nspecial case when all items occur in the same order. However, the repetition of\nitems is not allowed in RPS. To address this issue, we propose repeatable\nrandom permutation set (R2PS) which takes the repetition of items into\nconsideration. The right and left junctional sum combination rules are proposed\nand their properties including consistency, pseudo-Matthew effect and\nassociativity are researched. Based on these properties, a decision support\nsystem application is simulated to show the effectiveness of R2PS.",
    "descriptor": "",
    "authors": [
      "Wenran Yang",
      "Yong Deng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01676"
  },
  {
    "id": "arXiv:2211.01677",
    "title": "Little Tricky Logic: Misconceptions in the Understanding of LTL",
    "abstract": "Context: Linear Temporal Logic (LTL) has been used widely in verification.\nIts importance and popularity have only grown with the revival of temporal\nlogic synthesis, and with new uses of LTL in robotics and planning activities.\nAll these uses demand that the user have a clear understanding of what an LTL\nspecification means.\nInquiry: Despite the growing use of LTL, no studies have investigated the\nmisconceptions users actually have in understanding LTL formulas. This paper\naddresses the gap with a first study of LTL misconceptions. Approach: We study\nresearchers' and learners' understanding of LTL in four rounds (three written\nsurveys, one talk-aloud) spread across a two-year timeframe. Concretely, we\ndecompose \"understanding LTL\" into three questions. A person reading a spec\nneeds to understand what it is saying, so we study the mapping from LTL to\nEnglish. A person writing a spec needs to go in the other direction, so we\nstudy English to LTL. However, misconceptions could arise from two sources: a\nmisunderstanding of LTL's syntax or of its underlying semantics. Therefore, we\nalso study the relationship between formulas and specific traces.\nKnowledge: We find several misconceptions that have consequences for\nlearners, tool builders, and designers of new property languages. These\nfindings are already resulting in changes to the Alloy modeling language. We\nalso find that the English to LTL direction was the most common source of\nerrors; unfortunately, this is the critical \"authoring\" direction in which a\nsubtle mistake can lead to a faulty system. We contribute study instruments\nthat are useful for training learners (whether academic or industrial) who are\ngetting acquainted with LTL, and we provide a code book to assist in the\nanalysis of responses to similar-style questions.\nGrounding: Our findings are grounded in the responses to our survey rounds.\nRound 1 used Quizius to identify misconceptions among learners in a way that\nreduces the threat of expert blind spots. Rounds 2 and 3 confirm that both\nadditional learners and researchers (who work in formal methods, robotics, and\nrelated fields) make similar errors. Round 4 adds deep support for our\nmisconceptions via talk-aloud surveys.\nImportance This work provides useful answers to two critical but unexplored\nquestions: in what ways is LTL tricky and what can be done about it? Our survey\ninstruments can serve as a starting point for other studies.",
    "descriptor": "",
    "authors": [
      "Ben Greenman",
      "Sam Saarinen",
      "Tim Nelson",
      "Shriram Krishnamurthi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.01677"
  },
  {
    "id": "arXiv:2211.01678",
    "title": "Revisiting Language Support for Generic Programming: When Genericity Is  a Core Design Goal",
    "abstract": "Context: Generic programming, as defined by Stepanov, is a methodology for\nwriting efficient and reusable algorithms by considering only the required\nproperties of their underlying data types and operations. Generic programming\nhas proven to be an effective means of constructing libraries of reusable\nsoftware components in languages that support it. Generics-related language\ndesign choices play a major role in how conducive generic programming is in\npractice.\nInquiry: Several mainstream programming languages (e.g. Java and C++) were\nfirst created without generics; features to support generic programming were\nadded later, gradually. Much of the existing literature on supporting generic\nprogramming focuses thus on retrofitting generic programming into existing\nlanguages and identifying related implementation challenges. Is the programming\nexperience significantly better, or different when programming with a language\ndesigned for generic programming without limitations from prior language design\nchoices?\nApproach: We examine Magnolia, a language designed to embody generic\nprogramming. Magnolia is representative of an approach to language design\nrooted in algebraic specifications. We repeat a well-known experiment, where we\nput Magnolia's generic programming facilities under scrutiny by implementing a\nsubset of the Boost Graph Library, and reflect on our development experience.\nKnowledge: We discover that the idioms identified as key features for\nsupporting Stepanov-style generic programming in the previous studies and work\non the topic do not tell a full story. We clarify which of them are more of a\nmeans to an end, rather than fundamental features for supporting generic\nprogramming. Based on the development experience with Magnolia, we identify\nvariadics as an additional key feature for generic programming and point out\nlimitations and challenges of genericity by property.\nGrounding: Our work uses a well-known framework for evaluating the generic\nprogramming facilities of a language from the literature to evaluate the\nalgebraic approach through Magnolia, and we draw comparisons with well-known\nprogramming languages.\nImportance: This work gives a fresh perspective on generic programming, and\nclarifies what are fundamental language properties and their trade-offs when\nconsidering supporting Stepanov-style generic programming. The understanding of\nhow to set the ground for generic programming will inform future language\ndesign.",
    "descriptor": "",
    "authors": [
      "Benjamin Chetioui",
      "Jaakko J\u00e4rvi",
      "Magne Haveraaen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.01678"
  },
  {
    "id": "arXiv:2211.01679",
    "title": "Out-of-Things Debugging: A Live Debugging Approach for Internet of  Things",
    "abstract": "Context: Internet of Things (IoT) has become an important kind of distributed\nsystems thanks to the wide-spread of cheap embedded devices equipped with\ndifferent networking technologies. Although ubiquitous, developing IoT systems\nremains challenging.\nInquiry: A recent field study with 194 IoT developers identifies debugging as\none of the main challenges faced when developing IoT systems. This comes from\nthe lack of debugging tools taking into account the unique properties of IoT\nsystems such as non-deterministic data, and hardware restricted devices. On the\none hand, offline debuggers allow developers to analyse post-failure recorded\nprogram information, but impose too much overhead on the devices while\ngenerating such information.\nFurthermore, the analysis process is also time-consuming and might miss\ncontextual information relevant to find the root cause of bugs. On the other\nhand, online debuggers do allow debugging a program upon a failure while\nproviding contextual information (e.g., stack trace). In particular, remote\nonline debuggers enable debugging of devices without physical access to them.\nHowever, they experience debugging interference due to network delays which\ncomplicates bug reproducibility, and have limited support for dynamic software\nupdates on remote devices.\nApproach: This paper proposes out-of-things debugging, an online debugging\napproach especially designed for IoT systems. The debugger is always-on as it\nensures constant availability to for instance debug post-deployment situations.\nUpon a failure or breakpoint, out-of-things debugging moves the state of a\ndeployed application to the developer's machine. Developers can then debug the\napplication locally by applying operations (e.g., step commands) to the\nretrieved state. Once debugging is finished, developers can commit bug fixes to\nthe device through live update capabilities. Finally, by means of a\nfine-grained flexible interface for accessing remote resources, developers have\nfull control over the debugging overhead imposed on the device, and the access\nto device hardware resources (e.g., sensors) needed during local debugging.\nKnowledge: Out-of-things debugging maintains good properties of remote\ndebugging as it does not require physical access to the device to debug it,\nwhile reducing debugging interference since there are no network delays on\noperations (e.g., stepping) issued on the debugger since those happen locally.\nFurthermore, device resources are only accessed when requested by the user\nwhich further mitigates overhead and opens avenues for mocking or simulation of\nnon-accessed resources.\nGrounding: We implemented an out-of-things debugger as an extension to a\nWebAssembly Virtual Machine and benchmarked its suitability for IoT. In\nparticular, we compared our solution to remote debugging alternatives based on\nmetrics such as network overhead, memory usage, scalability, and usability in\nproduction settings. From the benchmarks, we conclude that our debugger\nexhibits competitive performance in addition to confining overhead without\nsacrificing debugging convenience and flexibility.\nImportance: Out-of-things debugging enables debugging of IoT systems by means\nof classical online operations (e.g., stepwise execution) while addressing\nIoT-specific concerns (e.g., hardware limitations). We show that having the\ndebugger always-on does not have to come at cost of performance loss or\nincreased overhead but instead can enforce a smooth-going and flexible\ndebugging experience of IoT systems.",
    "descriptor": "",
    "authors": [
      "Carlos Rojas Castillo",
      "Matteo Marra",
      "Jim Bauwens",
      "Elisa Gonzalez Boix"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.01679"
  },
  {
    "id": "arXiv:2211.01681",
    "title": "Matrix Multiplicative Weights Updates in Quantum Zero-Sum Games:  Conservation Laws & Recurrence",
    "abstract": "Recent advances in quantum computing and in particular, the introduction of\nquantum GANs, have led to increased interest in quantum zero-sum game theory,\nextending the scope of learning algorithms for classical games into the quantum\nrealm. In this paper, we focus on learning in quantum zero-sum games under\nMatrix Multiplicative Weights Update (a generalization of the multiplicative\nweights update method) and its continuous analogue, Quantum Replicator\nDynamics. When each player selects their state according to quantum replicator\ndynamics, we show that the system exhibits conservation laws in a\nquantum-information theoretic sense. Moreover, we show that the system exhibits\nPoincare recurrence, meaning that almost all orbits return arbitrarily close to\ntheir initial conditions infinitely often. Our analysis generalizes previous\nresults in the case of classical games.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Rahul Jain",
      "Georgios Piliouras",
      "Ryann Sim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.01681"
  },
  {
    "id": "arXiv:2211.01692",
    "title": "Data-efficient End-to-end Information Extraction for Statistical Legal  Analysis",
    "abstract": "Legal practitioners often face a vast amount of documents. Lawyers, for\ninstance, search for appropriate precedents favorable to their clients, while\nthe number of legal precedents is ever-growing. Although legal search engines\ncan assist finding individual target documents and narrowing down the number of\ncandidates, retrieved information is often presented as unstructured text and\nusers have to examine each document thoroughly which could lead to information\noverloading. This also makes their statistical analysis challenging. Here, we\npresent an end-to-end information extraction (IE) system for legal documents.\nBy formulating IE as a generation task, our system can be easily applied to\nvarious tasks without domain-specific engineering effort. The experimental\nresults of four IE tasks on Korean precedents shows that our IE system can\nachieve competent scores (-2.3 on average) compared to the rule-based baseline\nwith as few as 50 training examples per task and higher score (+5.4 on average)\nwith 200 examples. Finally, our statistical analysis on two case\ncategories--drunk driving and fraud--with 35k precedents reveals the resulting\nstructured information from our IE system faithfully reflects the macroscopic\nfeatures of Korean legal system.",
    "descriptor": "\nComments: NLLP workshop @ EMNLP 2022\n",
    "authors": [
      "Wonseok Hwang",
      "Saehee Eom",
      "Hanuhl Lee",
      "Hai Jin Park",
      "Minjoon Seo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01692"
  },
  {
    "id": "arXiv:2211.01696",
    "title": "An Empirical Bayes Analysis of Vehicle Trajectory Models",
    "abstract": "We present an in-depth empirical analysis of the trade-off between model\ncomplexity and representation error in modelling vehicle trajectories.\nAnalyzing several large public datasets, we show that simple linear models do\nrepresent realworld trajectories with high fidelity over relevant time scales\nat very moderate model complexity. This finding allows the formulation of\ntrajectory tracking and prediction as a Bayesian filtering problem. Using an\nEmpirical Bayes approach, we estimate prior distributions over model parameters\nfrom the data that inform the motion models necessary in the trajectory\ntracking problem and that can help regularize prediction models. We argue for\nthe use of linear models in trajectory prediction tasks as their representation\nerror is much smaller than the typical epistemic uncertainty in this task.",
    "descriptor": "",
    "authors": [
      "Yue Yao",
      "Daniel Goehring",
      "Joerg Reichardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01696"
  },
  {
    "id": "arXiv:2211.01699",
    "title": "A Round and Bipartize Approximation Algorithm for Vertex Cover",
    "abstract": "The vertex cover problem is a fundamental and widely studied combinatorial\noptimization problem. It is known that its standard linear programming\nrelaxation is integral for bipartite graphs and half-integral for general\ngraphs. As a consequence, the natural rounding algorithm based on this\nrelaxation computes an optimal solution for bipartite graphs and a\n$2$-approximation for general graphs. This raises the question of whether one\ncan obtain improved bounds on the approximation ratio, depending on how close\nthe graph is to being bipartite.\nIn this paper, we consider a round-and-bipartize algorithm that exploits the\nknowledge of an induced bipartite subgraph to attain improved approximation\nratios. Equivalently, we suppose that we have access to a subset of vertices\n$S$ whose removal bipartizes the graph.\nIf $S$ is an independent set, we prove an approximation ratio of $1 +\n1/\\rho$, where $2\\rho -1$ denotes the odd girth of the contracted graph\n$\\tilde{\\mathcal{G}} := \\mathcal{G} /S$ and thus satisfies $\\rho \\geq 2$. We\nshow that this is tight for any graph and independent set by providing a family\nof weight functions for which this bound is attained. In addition, we give\ntight upper bounds for the fractional chromatic number and the integrality gap\nof such graphs, both of which also depend on the odd girth.\nIf $S$ is an arbitrary set, we prove a tight approximation ratio of\n$\\left(1+1/\\rho \\right) (1 - \\alpha) + 2 \\alpha$, where $\\alpha \\in [0,1]$\ndenotes the total normalized dual sum of the edges lying inside of the set $S$.\nAs an algorithmic application, we show that for any efficiently $k$-colorable\ngraph with $k \\geq 4$ we can find a bipartizing set satisfying $\\alpha \\leq 1 -\n4/k$. This provides an approximation algorithm recovering the bound of $2 -\n2/k$ in the worst case (i.e., when $\\rho = 2$), which is best possible for this\nsetting when using the standard relaxation.",
    "descriptor": "\nComments: 26 pages, 9 figures\n",
    "authors": [
      "Danish Kashaev",
      "Guido Sch\u00e4fer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.01699"
  },
  {
    "id": "arXiv:2211.01700",
    "title": "Semantic 3D Maps for Autonomous Driving",
    "abstract": "Maps play a key role in rapidly developing area of autonomous driving. We\nsurvey the literature for different map representations and find that while the\nworld is three-dimensional, it is common to rely on 2D map representations in\norder to meet real-time constraints. We believe that high levels of situation\nawareness require a 3D representation as well as the inclusion of semantic\ninformation. We demonstrate that our recently presented hierarchical 3D grid\nmapping framework UFOMap meets the real-time constraints. Furthermore, we show\nhow it can be used to efficiently support more complex functions such as\ncalculating the occluded parts of space and accumulating the output from a\nsemantic segmentation network.",
    "descriptor": "\nComments: Submitted, accepted and presented at the 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022)\n",
    "authors": [
      "Ajinkya Khoche",
      "Maciej K Wozniak",
      "Daniel Duberg",
      "Patric Jensfelt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01700"
  },
  {
    "id": "arXiv:2211.01701",
    "title": "Efficient Branch-and-Bound Algorithms for Finding Triangle-Constrained  2-Clubs",
    "abstract": "In the Vertex Triangle 2-Club problem, we are given an undirected graph $G$\nand aim to find a maximum-vertex subgraph of $G$ that has diameter at most 2\nand in which every vertex is contained in at least $\\ell$ triangles in the\nsubgraph. So far, the only algorithm for solving Vertex Triangle 2-Club relies\non an ILP formulation [Almeida and Br\\'as, Comput. Oper. Res. 2019]. In this\nwork, we develop a combinatorial branch-and-bound algorithm that, coupled with\na set of data reduction rules, outperforms the existing implementation and is\nable to find optimal solutions on sparse real-world graphs with more than\n100,000 vertices in a few minutes. We also extend our algorithm to the Edge\nTriangle 2-Club problem where the triangle constraint is imposed on all edges\nof the subgraph.",
    "descriptor": "",
    "authors": [
      "Niels Gr\u00fcttemeier",
      "Christian Komusiewicz",
      "Philipp Heinrich Ke\u00dfler",
      "Frank Sommer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.01701"
  },
  {
    "id": "arXiv:2211.01703",
    "title": "Zero-Sum Games with Noisy Observations",
    "abstract": "In this paper, $2 \\times 2$ zero-sum games (ZSGs) are studied under the\nfollowing assumptions: (1) One of the players (the leader) publicly and\nirrevocably commits to choose its actions by sampling a given probability\nmeasure (strategy);(2) The leader announces its action, which is observed by\nits opponent (the follower) through a binary channel; and (3) the follower\nchooses its strategy based on the knowledge of the leader's strategy and the\nnoisy observation of the leader's action. Under these conditions, the\nequilibrium is shown to always exist and be often different from the Nash and\nStackelberg equilibria. Even subject to noise, observing the actions of the\nleader is either beneficial or immaterial to the follower for all possible\ncommitments. When the commitment is observed subject to a distortion, the\nequilibrium does not necessarily exist. Nonetheless, the leader might still\nobtain some benefit in some specific cases subject to equilibrium refinements.\nFor instance, $\\epsilon$-equilibria might exist in which the leader commits to\nsuboptimal strategies that allow unequivocally predicting the best response of\nits opponent.",
    "descriptor": "",
    "authors": [
      "Ke Sun",
      "Samir M. Perlaza",
      "Alain Jean-Marie"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01703"
  },
  {
    "id": "arXiv:2211.01705",
    "title": "A speech corpus for chronic kidney disease",
    "abstract": "In this study, we present a speech corpus of patients with chronic kidney\ndisease (CKD) that will be used for research on pathological voice analysis,\nautomatic illness identification, and severity prediction. This paper\nintroduces the steps involved in creating this corpus, including the choice of\nspeech-related parameters and speech lists as well as the recording technique.\nThe speakers in this corpus, 289 CKD patients with varying degrees of severity\nwho were categorized based on estimated glomerular filtration rate (eGFR),\ndelivered sustained vowels, sentence, and paragraph stimuli. This study\ncompared and analyzed the voice characteristics of CKD patients with those of\nthe control group; the results revealed differences in voice quality,\nphoneme-level pronunciation, prosody, glottal source, and aerodynamic\nparameters.",
    "descriptor": "",
    "authors": [
      "Jihyun Mun",
      "Sunhee Kim",
      "Myeong Ju Kim",
      "Jiwon Ryu",
      "Sejoong Kim",
      "Minhwa Chung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01705"
  },
  {
    "id": "arXiv:2211.01706",
    "title": "Minimum-Time Escape from a Circular Region for a Dubins Car",
    "abstract": "We investigate the problem of finding paths that enable a robot modeled as a\nDubins car (i.e., a constant-speed finite-turn-rate unicycle) to escape from a\ncircular region of space in minimum time. This minimum-time escape problem\narises in marine, aerial, and ground robotics in situations where a safety\nregion has been violated and must be exited before a potential negative\nconsequence occurs (e.g., a collision). Using the tools of nonlinear optimal\ncontrol theory, we show that a surprisingly simple closed-form feedback control\nlaw solves this minimum-time escape problem, and that the minimum-time paths\nhave an elegant geometric interpretation.",
    "descriptor": "\nComments: 7 pages, 5 figures, accepted for 12th IFAC Symposium on Nonlinear Control Systems (NOLCOS)\n",
    "authors": [
      "Timothy L. Molloy",
      "Iman Shames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01706"
  },
  {
    "id": "arXiv:2211.01712",
    "title": "Trust Management for Internet of Things: A Systematic Literature Review",
    "abstract": "Internet of Things (IoT) is a network of devices that communicate with each\nother through the internet and provides intelligence to industry and people.\nThese devices are running in potentially hostile environments, so the need for\nsecurity is critical. Trust Management aims to ensure the reliability of the\nnetwork by assigning a trust value in every node indicating its trust level.\nThis paper presents an exhaustive survey of the current Trust Management\ntechniques for IoT, a classification based on the methods used in every work\nand a discussion of the open challenges and future research directions.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Alyzia Maria Konsta",
      "Alberto Lluch Lafuente",
      "Nicola Dragoni"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.01712"
  },
  {
    "id": "arXiv:2211.01713",
    "title": "iGniter: Interference-Aware GPU Resource Provisioning for Predictable  DNN Inference in the Cloud",
    "abstract": "GPUs are essential to accelerating the latency-sensitive deep neural network\n(DNN) inference workloads in cloud datacenters. To fully utilize GPU resources,\nspatial sharing of GPUs among co-located DNN inference workloads becomes\nincreasingly compelling. However, GPU sharing inevitably brings severe\nperformance interference among co-located inference workloads, as motivated by\nan empirical measurement study of DNN inference on EC2 GPU instances. While\nexisting works on guaranteeing inference performance service level objectives\n(SLOs) focus on either temporal sharing of GPUs or reactive GPU resource\nscaling and inference migration techniques, how to proactively mitigate such\nsevere performance interference has received comparatively little attention. In\nthis paper, we propose iGniter, an interference-aware GPU resource provisioning\nframework for cost-efficiently achieving predictable DNN inference in the\ncloud. iGniter is comprised of two key components: (1) a lightweight DNN\ninference performance model, which leverages the system and workload metrics\nthat are practically accessible to capture the performance interference; (2) A\ncost-efficient GPU resource provisioning strategy that jointly optimizes the\nGPU resource allocation and adaptive batching based on our inference\nperformance model, with the aim of achieving predictable performance of DNN\ninference workloads. We implement a prototype of iGniter based on the NVIDIA\nTriton inference server hosted on EC2 GPU instances. Extensive prototype\nexperiments on four representative DNN models and datasets demonstrate that\niGniter can guarantee the performance SLOs of DNN inference workloads with\npractically acceptable runtime overhead, while saving the monetary cost by up\nto 25% in comparison to the state-of-the-art GPU resource provisioning\nstrategies.",
    "descriptor": "\nComments: 16 pages, 21 figures, submitted to IEEE Transactions on Parallel and Distributed Systems\n",
    "authors": [
      "Fei Xu",
      "Jianian Xu",
      "Jiabin Chen",
      "Li Chen",
      "Ruitao Shang",
      "Zhi Zhou",
      "Fangming Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01713"
  },
  {
    "id": "arXiv:2211.01717",
    "title": "Learning Hypergraphs From Signals With Dual Smoothness Prior",
    "abstract": "The construction of a meaningful hypergraph topology is the key to processing\nsignals with high-order relationships that involve more than two entities.\nLearning the hypergraph structure from the observed signals to capture the\nintrinsic relationships among the entities becomes crucial when a hypergraph\ntopology is not readily available in the datasets. There are two challenges\nthat lie at the heart of this problem: 1) how to handle the huge search space\nof potential hyperedges, and 2) how to define meaningful criteria to measure\nthe relationship between the signals observed on nodes and the hypergraph\nstructure. In this paper, to address the first challenge, we adopt the\nassumption that the ideal hypergraph structure can be derived from a learnable\ngraph structure that captures the pairwise relations within signals. Further,\nwe propose a hypergraph learning framework with a novel dual smoothness prior\nthat reveals a mapping between the observed node signals and the hypergraph\nstructure, whereby each hyperedge corresponds to a subgraph with both node\nsignal smoothness and edge signal smoothness in the learnable graph structure.\nFinally, we conduct extensive experiments to evaluate the proposed framework on\nboth synthetic and real world datasets. Experiments show that our proposed\nframework can efficiently infer meaningful hypergraph topologies from observed\nsignals.",
    "descriptor": "",
    "authors": [
      "Bohan Tang",
      "Siheng Chen",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01717"
  },
  {
    "id": "arXiv:2211.01720",
    "title": "Response Times Parametric Estimation of Real-Time Systems",
    "abstract": "Real-time systems are a set of programs, a scheduling policy and a system\narchitecture, constrained by timing requirements. Most of daily embedded\ndevices are real-time systems, e.g. airplanes, cars, trains, spatial probes,\netc. The time required by a program for its end-to-end execution is called its\nresponse time. Usually, upper-bounds of response times are computed in order to\nprovide safe deadline miss probabilities. In this paper, we propose a suited\nre-parametrization of the inverse Gaussian mixture distribution adapted to\nresponse times of real-time systems and the estimation of deadline miss\nprobabilities. The parameters and their associated deadline miss probabilities\nare estimated with an adapted Expectation-Maximization algorithm.",
    "descriptor": "\nComments: 21 pages, 6 figures, 2 tables\n",
    "authors": [
      "Kevin Zagalo",
      "Olena Verbytska",
      "Liliana Cucu-Grosjean",
      "Avner Bar-Hen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.01720"
  },
  {
    "id": "arXiv:2211.01722",
    "title": "Hybrid-SD ($\\text{H}_{\\text{SD}}$) : A new hybrid evaluation metric for  automatic speech recognition tasks",
    "abstract": "Many studies have examined the shortcomings of word error rate (WER) as an\nevaluation metric for automatic speech recognition (ASR) systems, particularly\nwhen used for spoken language understanding tasks such as intent recognition\nand dialogue systems. In this paper, we propose Hybrid-SD\n($\\text{H}_{\\text{SD}}$), a new hybrid evaluation metric for ASR systems that\ntakes into account both semantic correctness and error rate. To generate\nsentence dissimilarity scores (SD), we built a fast and lightweight SNanoBERT\nmodel using distillation techniques. Our experiments show that the SNanoBERT\nmodel is 25.9x smaller and 38.8x faster than SRoBERTa while achieving\ncomparable results on well-known benchmarks. Hence, making it suitable for\ndeploying with ASR models on edge devices. We also show that\n$\\text{H}_{\\text{SD}}$ correlates more strongly with downstream tasks such as\nintent recognition and named-entity recognition (NER).",
    "descriptor": "",
    "authors": [
      "Zitha Sasindran",
      "Harsha Yelchuri",
      "Supreeth Rao",
      "T. V. Prabhakar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01722"
  },
  {
    "id": "arXiv:2211.01723",
    "title": "Model-Checking for First-Order Logic with Disjoint Paths Predicates in  Proper Minor-Closed Graph Classes",
    "abstract": "The disjoint paths logic, FOL+DP, is an extension of First-Order Logic (FOL)\nwith the extra atomic predicate ${\\sf dp}_k(x_1,y_1,\\ldots,x_k,y_k),$\nexpressing the existence of internally vertex-disjoint paths between $x_i$ and\n$y_i,$ for $i\\in\\{1,\\ldots, k\\}$. This logic can express a wide variety of\nproblems that escape the expressibility potential of FOL. We prove that for\nevery proper minor-closed graph class, model-checking for FOL+DP can be done in\nquadratic time. We also introduce an extension of FOL+DP, namely the scattered\ndisjoint paths logic, FOL+SDP, where we further consider the atomic predicate\n$s{\\sf -sdp}_k(x_1,y_1,\\ldots,x_k,y_k),$ demanding that the disjoint paths are\nwithin distance bigger than some fixed value $s$. Using the same technique we\nprove that model-checking for FOL+SDP can be done in quadratic time on classes\nof graphs with bounded Euler genus.",
    "descriptor": "\nComments: An extended abstract of this paper will appear in the Proceedings of the 34th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2023)\n",
    "authors": [
      "Petr A. Golovach",
      "Giannos Stamoulis",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.01723"
  },
  {
    "id": "arXiv:2211.01724",
    "title": "Learning Control by Iterative Inversion",
    "abstract": "We formulate learning for control as an $\\textit{inverse problem}$ --\ninverting a dynamical system to give the actions which yield desired behavior.\nThe key challenge in this formulation is a $\\textit{distribution shift}$ -- the\nlearning agent only observes the forward mapping (its actions' consequences) on\ntrajectories that it can execute, yet must learn the inverse mapping for\ninputs-outputs that correspond to a different, desired behavior. We propose a\ngeneral recipe for inverse problems with a distribution shift that we term\n$\\textit{iterative inversion}$ -- learn the inverse mapping under the current\ninput distribution (policy), then use it on the desired output samples to\nobtain new inputs, and repeat. As we show, iterative inversion can converge to\nthe desired inverse mapping, but under rather strict conditions on the mapping\nitself.\nWe next apply iterative inversion to learn control. Our input is a set of\ndemonstrations of desired behavior, given as video embeddings of trajectories,\nand our method iteratively learns to imitate trajectories generated by the\ncurrent policy, perturbed by random exploration noise. We find that constantly\nadding the demonstrated trajectory embeddings $\\textit{as input}$ to the policy\nwhen generating trajectories to imitate, a-la iterative inversion, steers the\nlearning towards the desired trajectory distribution. To the best of our\nknowledge, this is the first exploration of learning control from the viewpoint\nof inverse problems, and our main advantage is simplicity -- we do not require\nrewards, and only employ supervised learning, which easily scales to\nstate-of-the-art trajectory embedding techniques and policy representations.\nWith a VQ-VAE embedding, and a transformer-based policy, we demonstrate\nnon-trivial continuous control on several tasks. We also report improved\nperformance on imitating diverse behaviors compared to reward based methods.",
    "descriptor": "\nComments: Videos available at this https URL\n",
    "authors": [
      "Gal Leibovich",
      "Guy Jacob",
      "Or Avner",
      "Gal Novik",
      "Aviv Tamar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01724"
  },
  {
    "id": "arXiv:2211.01725",
    "title": "Distributed Reconfiguration of Spanning Trees",
    "abstract": "In a reconfiguration problem, given a problem and two feasible solutions of\nthe problem, the task is to find a sequence of transformations to reach from\none solution to the other such that every intermediate state is also a feasible\nsolution to the problem. In this paper, we study the distributed spanning tree\nreconfiguration problem and we define a new reconfiguration step, called\n$k$-simultaneous add and delete, in which every node is allowed to add at most\n$k$ edges and delete at most $k$ edges such that multiple nodes do not add or\ndelete the same edge.\nWe first observe that, if the two input spanning trees are rooted, then we\ncan do the reconfiguration using a single $1$-simultaneous add and delete step\nin one round in the CONGEST model. Therefore, we focus our attention towards\nunrooted spanning trees and show that transforming an unrooted spanning tree\ninto another using a single $1$-simultaneous add and delete step requires\n$\\Omega(n)$ rounds in the LOCAL model. We additionally show that transforming\nan unrooted spanning tree into another using a single $2$-simultaneous add and\ndelete step can be done in $O(\\log n)$ rounds in the CONGEST model.",
    "descriptor": "",
    "authors": [
      "Siddharth Gupta",
      "Manish Kumar",
      "Shreyas Pai"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.01725"
  },
  {
    "id": "arXiv:2211.01726",
    "title": "SQUID: Faster Analytics via Sampled Quantiles Data-structure",
    "abstract": "Measurement is a fundamental enabler of network applications such as load\nbalancing, attack detection and mitigation, and traffic engineering. A key\nbuilding block in many critical measurement tasks is \\emph{q-MAX}, where we\nwish to find the largest $q$ values in a number stream. A standard approach of\nmaintaining a heap of the largest $q$ values ordered results in logarithmic\nruntime, which is too slow for large measurements. Modern approaches attain a\nconstant runtime by removing small items in bulk and retaining the largest $q$\nitems at all times. Yet, these approaches are bottlenecked by an expensive\nquantile calculation method.\nWe propose SQUID, a method that redesigns q-MAX to allow the use of\n\\emph{approximate quantiles}, which we can compute efficiently, thereby\naccelerating the solution and, subsequently, many measurement tasks. We\ndemonstrate the benefit of our approach by designing a novel weighted heavy\nhitters data structure that is faster and more accurate than the existing\nalternatives. Here, we combine our previous techniques with a lazy deletion of\nsmall entries, which expiates the maintenance process and increases the\naccuracy. We also demonstrate the applicability of our algorithmic approach in\na general algorithmic scope by implementing the LRFU cache policy with a\nconstant update time. Furthermore, we also show the practicality of SQUID for\nimproving real-world networked systems, by implementing a P4 prototype of SQUID\nfor in-network caching and demonstrating how SQUID enables a wide spectrum of\nscore-based caching policies directly on a P4 switch.",
    "descriptor": "",
    "authors": [
      "Ran Ben-Basat",
      "Gil Einziger",
      "Wenchen Han",
      "Bilal Tayh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.01726"
  },
  {
    "id": "arXiv:2211.01730",
    "title": "Feedback is Good, Active Feedback is Better: Block Attention Active  Feedback Codes",
    "abstract": "Deep neural network (DNN)-assisted channel coding designs, such as\nlow-complexity neural decoders for existing codes, or end-to-end\nneural-network-based auto-encoder designs are gaining interest recently due to\ntheir improved performance and flexibility; particularly for communication\nscenarios in which high-performing structured code designs do not exist.\nCommunication in the presence of feedback is one such communication scenario,\nand practical code design for feedback channels has remained an open challenge\nin coding theory for many decades. Recently, DNN-based designs have shown\nimpressive results in exploiting feedback. In particular, generalized block\nattention feedback (GBAF) codes, which utilizes the popular transformer\narchitecture, achieved significant improvement in terms of the block error rate\n(BLER) performance. However, previous works have focused mainly on passive\nfeedback, where the transmitter observes a noisy version of the signal at the\nreceiver. In this work, we show that GBAF codes can also be used for channels\nwith active feedback. We implement a pair of transformer architectures, at the\ntransmitter and the receiver, which interact with each other sequentially, and\nachieve a new state-of-the-art BLER performance, especially in the low SNR\nregime.",
    "descriptor": "",
    "authors": [
      "Emre Ozfatura",
      "Yulin Shao",
      "Amin Ghazanfari",
      "Alberto Perotti",
      "Branislav Popovic",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01730"
  },
  {
    "id": "arXiv:2211.01736",
    "title": "Exploring the State-of-the-Art Language Modeling Methods and Data  Augmentation Techniques for Multilingual Clause-Level Morphology",
    "abstract": "This paper describes the KUIS-AI NLP team's submission for the 1$^{st}$\nShared Task on Multilingual Clause-level Morphology (MRL2022). We present our\nwork on all three parts of the shared task: inflection, reinflection, and\nanalysis. We mainly explore two approaches: Transformer models in combination\nwith data augmentation, and exploiting the state-of-the-art language modeling\ntechniques for morphological analysis. Data augmentation leads a remarkable\nperformance improvement for most of the languages in the inflection task.\nPrefix-tuning on pretrained mGPT model helps us to adapt reinflection and\nanalysis tasks in a low-data setting. Additionally, we used pipeline\narchitectures using publicly available open source lemmatization tools and\nmonolingual BERT-based morphological feature classifiers for reinflection and\nanalysis tasks, respectively. While Transformer architectures with data\naugmentation and pipeline architectures achieved the best results for\ninflection and reinflection tasks, pipelines and prefix-tuning on mGPT received\nthe highest results for the analysis task. Our methods achieved first place in\neach of the three tasks and outperforms mT5-baseline with ~89\\% for inflection,\n~80\\% for reinflection and ~12\\% for analysis. Our code\nhttps://github.com/emrecanacikgoz/mrl2022 is publicly available.",
    "descriptor": "",
    "authors": [
      "Emre Can Acikgoz",
      "Tilek Chubakov",
      "M\u00fcge Kural",
      "G\u00f6zde G\u00fcl \u015eahin",
      "Deniz Yuret"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01736"
  },
  {
    "id": "arXiv:2211.01743",
    "title": "Beyond the Best: Estimating Distribution Functionals in Infinite-Armed  Bandits",
    "abstract": "In the infinite-armed bandit problem, each arm's average reward is sampled\nfrom an unknown distribution, and each arm can be sampled further to obtain\nnoisy estimates of the average reward of that arm. Prior work focuses on\nidentifying the best arm, i.e., estimating the maximum of the average reward\ndistribution. We consider a general class of distribution functionals beyond\nthe maximum, and propose unified meta algorithms for both the offline and\nonline settings, achieving optimal sample complexities. We show that online\nestimation, where the learner can sequentially choose whether to sample a new\nor existing arm, offers no advantage over the offline setting for estimating\nthe mean functional, but significantly reduces the sample complexity for other\nfunctionals such as the median, maximum, and trimmed mean. The matching lower\nbounds utilize several different Wasserstein distances. For the special case of\nmedian estimation, we identify a curious thresholding phenomenon on the\nindistinguishability between Gaussian convolutions with respect to the noise\nlevel, which may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Yifei Wang",
      "Tavor Baharav",
      "Yanjun Han",
      "Jiantao Jiao",
      "David Tse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01743"
  },
  {
    "id": "arXiv:2211.01745",
    "title": "Task Tree Retrieval for Robotic Cooking",
    "abstract": "Robotics is used to foster creativity. Humans can perform jobs in their\nunique manner, depending on the circumstances. This situation applies to food\ncooking. Robotic technology in the kitchen can speed up the process and reduce\nits workload. However, the potential of robotics in the kitchen is still\nunrealized. In this essay, the idea of FOON, a structural knowledge\nrepresentation built on insights from human manipulations, is introduced. To\nreduce the failure rate and ensure that the task is effectively completed,\nthree different algorithms have been implemented where weighted values have\nbeen assigned to the manipulations depending on the success rates of motion.\nThis knowledge representation was created using videos of open-sourced recipes",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Sandeep Bondalapati"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01745"
  },
  {
    "id": "arXiv:2211.01747",
    "title": "Comparison of Algorithms for Distributed Mutual Exclusion through  Simulations",
    "abstract": "In this paper, we show how different types of distributed mutual algorithms\ncan be compared in terms of performance through simulations. A simulation\napproach is presented, together with an overview of the relevant evaluation\nmetrics and statistical processing of the results. The presented simulations\ncan be used to learn students of a course on distributed software the basics of\nalgorithms for distributed mutual exclusion, together with a detailed\ncomparison study. Finally, a related work section is provided with relevant\nreferences which contain use cases where distributed mutual exclusion algorithm\ncan be beneficial.",
    "descriptor": "",
    "authors": [
      "Filip De Turck"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01747"
  },
  {
    "id": "arXiv:2211.01749",
    "title": "Enhanced Visual Feedback with Decoupled Viewpoint Control in Immersive  Humanoid Robot Teleoperation using SLAM",
    "abstract": "In immersive humanoid robot teleoperation, there are three main shortcomings\nthat can alter the transparency of the visual feedback: the lag between the\nmotion of the operator's and robot's head due to network communication delays\nor slow robot joint motion. This latency could cause a noticeable delay in the\nvisual feedback, which jeopardizes the embodiment quality, can cause dizziness,\nand affects the interactivity resulting in operator frequent motion pauses for\nthe visual feedback to settle; (ii) the mismatch between the camera's and the\nheadset's field-of-views (FOV), the former having generally a lower FOV; and\n(iii) a mismatch between human's and robot's range of motions of the neck, the\nlatter being also generally lower. In order to leverage these drawbacks, we\ndeveloped a decoupled viewpoint control solution for a humanoid platform which\nallows visual feedback with low-latency and artificially increases the camera's\nFOV range to match that of the operator's headset. Our novel solution uses SLAM\ntechnology to enhance the visual feedback from a reconstructed mesh,\ncomplementing the areas that are not covered by the visual feedback from the\nrobot. The visual feedback is presented as a point cloud in real-time to the\noperator. As a result, the operator is fed with real-time vision from the\nrobot's head orientation by observing the pose of the point cloud. Balancing\nthis kind of awareness and immersion is important in virtual reality based\nteleoperation, considering the safety and robustness of the control system. An\nexperiment shows the effectiveness of our solution.",
    "descriptor": "\nComments: IEEE-RAS International Conference on Humanoid Robots (Humanoids 2022)\n",
    "authors": [
      "Yang Chen",
      "Leyuan Sun",
      "Mehdi Benallegue",
      "Rafael Cisneros",
      "Rohan P. Singh",
      "Kenji Kaneko",
      "Arnaud Tanguy",
      "Guillaume Caron",
      "Kenji Suzuki",
      "Abderrahmane Kheddar",
      "Fumio Kanehiro"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01749"
  },
  {
    "id": "arXiv:2211.01751",
    "title": "Iterative autoregression: a novel trick to improve your low-latency  speech enhancement model",
    "abstract": "Streaming models are an essential component of real-time speech enhancement\ntools. The streaming regime constrains speech enhancement models to use only a\ntiny context of future information, thus, the low-latency streaming setup is\ngenerally assumed to be challenging and has a significant negative effect on\nthe model quality. However, due to the sequential nature of streaming\ngeneration, it provides a natural possibility for autoregression, i.e., using\nprevious predictions when making current ones. In this paper, we present a\nsimple, yet effective trick for training of autoregressive low-latency speech\nenhancement models. We demonstrate that the proposed technique leads to stable\nimprovement across different architectures and training scenarios.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Pavel Andreev",
      "Nicholas Babaev",
      "Azat Saginbaev",
      "Ivan Shchekotov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01751"
  },
  {
    "id": "arXiv:2211.01752",
    "title": "A Comparative Study of Smartphone and Smart TV Apps",
    "abstract": "Context: Smart TVs have become one of the most popular television types. Many\napp developers and service providers have designed TV versions for their\nsmartphone applications. Despite the extensive studies on mobile app analysis,\nits TV equivalents receive far too little attention. The relationship between\nphone and TV has not been the subject of research works. Objective: In this\npaper, we aim to characterize the relationship between smartphone and smart TV\napps. To fill this gap, we conduct a comparative study on smartphone and smart\nTV apps in this work, which is the starting and fundamental step to uncover the\ndomain-specific challenges. Method: We gather a large-scale phone/TV app pairs\nfrom Google Play Store. We then analyzed the app pairs quantitatively and\nqualitatively from a variety of perspectives, including non-code (e.g.,\nmetadata, resources, permissions, etc.), code (e.g., components, methods, user\ninteractions, etc.), security and privacy (e.g., reports of AndroBugs and\nFlowDroid). Results: Our experimental results indicate that (1) the code of the\nsmartphone and TV apps can be released in the same app package or in separate\napp packages with the same package name; (2) 43% of resource files and 50% of\ncode methods are reused between phone/TV app pairs; (3) TV and phone versions\nof the same app often encounter different kinds of security vulnerabilities;\nand (4) TV apps encounter fewer user interactions than their phone versions,\nbut the type of user interaction events, surprisingly, are similar between\nphone/TV apps. Conclution: Our findings are valuable for developers and\nacademics in comprehending the TV app ecosystem by providing additional insight\ninto the migration of phone apps to TVs and the design mechanism of analysis\ntools for TV apps.",
    "descriptor": "",
    "authors": [
      "Yonghui Liu",
      "Xiao Chen",
      "Yue Liu",
      "Pingfan Kong",
      "Tegawend\u00e9 F. Bissyande",
      "Jacques Klein",
      "Xiaoyu Sun",
      "Chunyang Chen",
      "John Grundy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.01752"
  },
  {
    "id": "arXiv:2211.01753",
    "title": "Looking Beyond IoCs: Automatically Extracting Attack Patterns from  External CTI",
    "abstract": "Public and commercial companies extensively share cyber threat intelligence\n(CTI) to prepare systems to defend against emerging cyberattacks. Most used\nintelligence thus far has been limited to tracking known threat indicators such\nas IP addresses and domain names as they are easier to extract using regular\nexpressions. Due to the limited long-term usage and difficulty of performing a\nlong-term analysis on indicators, we propose using significantly more robust\nthreat intelligence signals called attack patterns. However, extracting attack\npatterns at scale is a challenging task. In this paper, we present LADDER, a\nknowledge extraction framework that can extract text-based attack patterns from\nCTI reports at scale. The model characterizes attack patterns by capturing\nphases of an attack in android and enterprise networks. It then systematically\nmaps them to the MITRE ATT\\&CK pattern framework. We present several use cases\nto demonstrate the application of LADDER for SOC analysts in determining the\npresence of attack vectors belonging to emerging attacks in preparation for\ndefenses in advance.",
    "descriptor": "",
    "authors": [
      "Md Tanvirul Alam",
      "Dipkamal Bhusal",
      "Youngja Park",
      "Nidhi Rastogi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01753"
  },
  {
    "id": "arXiv:2211.01757",
    "title": "Learning Decentralized Strategies for a Perimeter Defense Game with  Graph Neural Networks",
    "abstract": "We consider the problem of finding decentralized strategies for multi-agent\nperimeter defense games. In this work, we design a graph neural network-based\nlearning framework to learn a mapping from defenders' local perceptions and the\ncommunication graph to defenders' actions such that the learned actions are\nclose to that generated by a centralized expert algorithm. We demonstrate that\nour proposed networks stay closer to the expert policy and are superior to\nother baseline algorithms by capturing more intruders. Our GNN-based networks\nare trained at a small scale and can generalize to large scales. To validate\nour results, we run perimeter defense games in scenarios with different team\nsizes and initial configurations to evaluate the performance of the learned\nnetworks.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Elijah S. Lee",
      "Lifeng Zhou",
      "Alejandro Ribeiro",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01757"
  },
  {
    "id": "arXiv:2211.01758",
    "title": "Optimal Algorithms for Stochastic Complementary Composite Minimization",
    "abstract": "Inspired by regularization techniques in statistics and machine learning, we\nstudy complementary composite minimization in the stochastic setting. This\nproblem corresponds to the minimization of the sum of a (weakly) smooth\nfunction endowed with a stochastic first-order oracle, and a structured\nuniformly convex (possibly nonsmooth and non-Lipschitz) regularization term.\nDespite intensive work on closely related settings, prior to our work no\ncomplexity bounds for this problem were known. We close this gap by providing\nnovel excess risk bounds, both in expectation and with high probability. Our\nalgorithms are nearly optimal, which we prove via novel lower complexity bounds\nfor this class of problems. We conclude by providing numerical results\ncomparing our methods to the state of the art.",
    "descriptor": "",
    "authors": [
      "Alexandre d'Aspremont",
      "Crist\u00f3bal Guzm\u00e1n",
      "Cl\u00e9ment Lezane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.01758"
  },
  {
    "id": "arXiv:2211.01759",
    "title": "Resource-aware Deep Learning for Wireless Fingerprinting Localization",
    "abstract": "Location based services, already popular with end users, are now inevitably\nbecoming part of new wireless infrastructures and emerging business processes.\nThe increasingly popular Deep Learning (DL) artificial intelligence methods\nperform very well in wireless fingerprinting localization based on extensive\nindoor radio measurement data. However, with the increasing complexity these\nmethods become computationally very intensive and energy hungry, both for their\ntraining and subsequent operation. Considering only mobile users, estimated to\nexceed 7.4 billion by the end of 2025, and assuming that the networks serving\nthese users will need to perform only one localization per user per hour on\naverage, the machine learning models used for the calculation would need to\nperform $65 \\times 10^{12}$ predictions per year. Add to this equation tens of\nbillions of other connected devices and applications that rely heavily on more\nfrequent location updates, and it becomes apparent that localization will\ncontribute significantly to carbon emissions unless more energy-efficient\nmodels are developed and used. In this Chapter, we discuss the latest results\nand trends in wireless localization and look at paths towards achieving more\nsustainable AI. We then elaborate on a methodology for computing DL model\ncomplexity, energy consumption and carbon footprint and show on a concrete\nexample how to develop a more resource-aware model for fingerprinting. We\nfinally compare relevant works in terms of complexity and training CO$_2$\nfootprint.",
    "descriptor": "\nComments: 20 pages, 7 figures, book chapter\n",
    "authors": [
      "Gregor Cerar",
      "Bla\u017e Bertalani\u010d",
      "Carolina Fortuna"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01759"
  },
  {
    "id": "arXiv:2211.01761",
    "title": "PromptEHR: Conditional Electronic Healthcare Records Generation with  Prompt Learning",
    "abstract": "Accessing longitudinal multimodal Electronic Healthcare Records (EHRs) is\nchallenging due to privacy concerns, which hinders the use of ML for healthcare\napplications. Synthetic EHRs generation bypasses the need to share sensitive\nreal patient records. However, existing methods generate single-modal EHRs by\nunconditional generation or by longitudinal inference, which falls short of low\nflexibility and makes unrealistic EHRs. In this work, we propose to formulate\nEHRs generation as a text-to-text translation task by language models (LMs),\nwhich suffices to highly flexible event imputation during generation. We also\ndesign prompt learning to control the generation conditioned by numerical and\ncategorical demographic features. We evaluate synthetic EHRs quality by two\nperplexity measures accounting for their longitudinal pattern (longitudinal\nimputation perplexity, lpl) and the connections cross modalities\n(cross-modality imputation perplexity, mpl). Moreover, we utilize two\nadversaries: membership and attribute inference attacks for privacy-preserving\nevaluation. Experiments on MIMIC-III data demonstrate the superiority of our\nmethods on realistic EHRs generation (53.1\\% decrease of lpl and 45.3\\%\ndecrease of mpl on average compared to the best baselines) with low privacy\nrisks. Software is available at https://github.com/RyanWangZf/PromptEHR.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zifeng Wang",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01761"
  },
  {
    "id": "arXiv:2211.01763",
    "title": "Implementation of the Digital QS-SVM-based Beamformer on an FPGA  Platform",
    "abstract": "To address practical challenges in establishing and maintaining robust\nwireless connectivity such as multi-path effects, low latency, size reduction,\nand high data rate, the digital beamformer is performed by the hybrid antenna\narray at the frequency of operation of 10 GHz. The proposed digital beamformer,\nas a spatial filter, is capable of performing Direction of Arrival (DOA)\nestimation and beamforming. The most well-established machine learning\ntechnique of support vector machine (SVM) for the DoA estimation is limited to\nproblems with linearly-separable datasets.\nTo overcome the aforementioned constraint, in the proposed beamformer, the\nQS-SVM classifier with a small regularizer has been used for the DoA estimation\nin addition to the two beamforming techniques of LCMV and MVDR. The\nQS-SVM-based beamformer has been deployed in an FPGA board, as demonstrated in\ndetail in this work. The implementation results have verified the strong\nperformance of the QS-SVM-based beamformer in suppressing undesired signals,\ndeep nulls with powers less than -10 dB in undesired signals, and transferring\ndesired signals. Furthermore, we have demonstrated that the performance of the\nQS-SVM-based beamformer consists of other advantages of average latency time in\nthe order of milliseconds, performance efficiency of more than 90\\%, and\nthroughput of about 100\\%.",
    "descriptor": "",
    "authors": [
      "Somayeh Komeylian",
      "Christopher Paolini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01763"
  },
  {
    "id": "arXiv:2211.01768",
    "title": "Embedding Knowledge Graph of Patent Metadata to Measure Knowledge  Proximity",
    "abstract": "Knowledge proximity refers to the strength of association between any two\nentities in a structural form that embodies certain aspects of a knowledge\nbase. In this work, we operationalize knowledge proximity within the context of\nthe US Patent Database (knowledge base) using a knowledge graph (structural\nform) named PatNet built using patent metadata, including citations, inventors,\nassignees, and domain classifications. Using several graph embedding models\n(e.g., TransE, RESCAL), we obtain the embeddings of entities and relations that\nconstitute PatNet. The cosine similarity between the corresponding (or\ntransformed) embeddings entities denotes the knowledge proximity between these.\nWe evaluate the plausibility of these embeddings across different models in\npredicting target entities. We also evaluate the meaningfulness of knowledge\nproximity to explain the domain expansion profiles of inventors and assignees.\nWe then apply the embeddings of the best-preferred model to associate\nhomogeneous (e.g., patent-patent) and heterogeneous (e.g., inventor-assignee)\npairs of entities.",
    "descriptor": "",
    "authors": [
      "Guangtong Li",
      "L Siddharth",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.01768"
  },
  {
    "id": "arXiv:2211.01770",
    "title": "Exploring Explainability Methods for Graph Neural Networks",
    "abstract": "With the growing use of deep learning methods, particularly graph neural\nnetworks, which encode intricate interconnectedness information, for a variety\nof real tasks, there is a necessity for explainability in such settings. In\nthis paper, we demonstrate the applicability of popular explainability\napproaches on Graph Attention Networks (GAT) for a graph-based super-pixel\nimage classification task. We assess the qualitative and quantitative\nperformance of these techniques on three different datasets and describe our\nfindings. The results shed a fresh light on the notion of explainability in\nGNNs, particularly GATs.",
    "descriptor": "",
    "authors": [
      "Harsh Patel",
      "Shivam Sahni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01770"
  },
  {
    "id": "arXiv:2211.01772",
    "title": "Collaborative Honeypot Defense in UAV Networks: A Learning-Based Game  Approach",
    "abstract": "The proliferation of unmanned aerial vehicles (UAVs) opens up new\nopportunities for on-demand service provisioning anywhere and anytime, but also\nexposes UAVs to a variety of cyber threats. Low/medium interaction honeypots\noffer a promising lightweight defense for actively protecting mobile Internet\nof things, particularly UAV networks. While previous research has primarily\nfocused on honeypot system design and attack pattern recognition, the incentive\nissue for motivating UAV's participation (e.g., sharing trapped attack data in\nhoneypots) to collaboratively resist distributed and sophisticated attacks\nremains unexplored. This paper proposes a novel game-theoretical collaborative\ndefense approach to address optimal, fair, and feasible incentive design, in\nthe presence of network dynamics and UAVs' multi-dimensional private\ninformation (e.g., valid defense data (VDD) volume, communication delay, and\nUAV cost). Specifically, we first develop a honeypot game between UAVs and the\nnetwork operator under both partial and complete information asymmetry\nscenarios. The optimal VDD-reward contract design problem with partial\ninformation asymmetry is then solved using a contract-theoretic approach that\nensures budget feasibility, truthfulness, fairness, and computational\nefficiency. In addition, under complete information asymmetry, we devise a\ndistributed reinforcement learning algorithm to dynamically design optimal\ncontracts for distinct types of UAVs in the time-varying UAV network. Extensive\nsimulations demonstrate that the proposed scheme can motivate UAV's cooperation\nin VDD sharing and improve defensive effectiveness, compared with conventional\nschemes.",
    "descriptor": "\nComments: 15 pages, 11 figures, under review. arXiv admin note: substantial text overlap with arXiv:2209.13815\n",
    "authors": [
      "Yuntao Wang",
      "Zhou Su",
      "Abderrahim Benslimane",
      "Qichao Xu",
      "Minghui Dai",
      "Ruidong Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.01772"
  },
  {
    "id": "arXiv:2211.01776",
    "title": "Complexity of Simon's problem in classical sense",
    "abstract": "Simon's problem is a standard example of a problem that is exponential in\nclassical sense, while it admits a polynomial solution in quantum computing. It\nis about a function $f$ for which it is given that a unique non-zero vector $s$\nexists for which $f(x) = f(x \\oplus s)$ for all $x$, where $\\oplus$ is the\nexclusive or operator. The goal is to find $s$. The exponential lower bound for\nthe classical sense assumes that $f$ only admits black box access. In this\npaper we investigate classical complexity when $f$ is given by a standard\nrepresentation like a circuit. We focus on finding the vector space of all\nvectors $s$ for which $f(x) = f(x \\oplus s)$ for all $x$, for any given $f$.\nTwo main results are: (1) if $f$ is given by any circuit, then checking whether\nthis vector space contains a non-zero element is NP-hard, and (2) if $f$ is\ngiven by any ordered BDD, then a basis of this vector space can be computed in\npolynomial time.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Hans Zantema"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.01776"
  },
  {
    "id": "arXiv:2211.01777",
    "title": "Evaluating a Synthetic Image Dataset Generated with Stable Diffusion",
    "abstract": "We generate synthetic images with the \"Stable Diffusion\" image generation\nmodel using the Wordnet taxonomy and the definitions of concepts it contains.\nThis synthetic image database can be used as training data for data\naugmentation in machine learning applications, and it is used to investigate\nthe capabilities of the Stable Diffusion model.\nAnalyses show that Stable Diffusion can produce correct images for a large\nnumber of concepts, but also a large variety of different representations. The\nresults show differences depending on the test concepts considered and problems\nwith very specific concepts. These evaluations were performed using a vision\ntransformer model for image classification.",
    "descriptor": "",
    "authors": [
      "Andreas St\u00f6ckl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01777"
  },
  {
    "id": "arXiv:2211.01778",
    "title": "Progressive Transformation Learning For Leveraging Virtual Images in  Training",
    "abstract": "To effectively interrogate UAV-based images for detecting objects of\ninterest, such as humans, it is essential to acquire large-scale UAV-based\ndatasets that include human instances with various poses captured from widely\nvarying viewing angles. As a viable alternative to laborious and costly data\ncuration, we introduce Progressive Transformation Learning (PTL), which\ngradually augments a training dataset by adding transformed virtual images with\nenhanced realism. Generally, a virtual2real transformation generator in the\nconditional GAN framework suffers from quality degradation when a large domain\ngap exists between real and virtual images. To deal with the domain gap, PTL\ntakes a novel approach that progressively iterates the following three steps:\n1) select a subset from a pool of virtual images according to the domain gap,\n2) transform the selected virtual images to enhance realism, and 3) add the\ntransformed virtual images to the training set while removing them from the\npool. In PTL, accurately quantifying the domain gap is critical. To do that, we\ntheoretically demonstrate that the feature representation space of a given\nobject detector can be modeled as a multivariate Gaussian distribution from\nwhich the Mahalanobis distance between a virtual object and the Gaussian\ndistribution of each object category in the representation space can be readily\ncomputed. Experiments show that PTL results in a substantial performance\nincrease over the baseline, especially in the small data and the cross-domain\nregime.",
    "descriptor": "",
    "authors": [
      "Yi-Ting Shen",
      "Hyungtae Lee",
      "Heesung Kwon",
      "Shuvra Shikhar Bhattacharyya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01778"
  },
  {
    "id": "arXiv:2211.01779",
    "title": "Exploring explicit coarse-grainend structure in artificial neural  networks",
    "abstract": "We propose to employ the hierarchical coarse-grained structure in the\nartificial neural networks explicitly to improve the interpretability without\ndegrading performance. The idea has been applied in two situations. One is a\nneural network called TaylorNet, which aims to approximate the general mapping\nfrom input data to output result in terms of Taylor series directly, without\nresorting to any magic nonlinear activations. The other is a new setup for data\ndistillation, which can perform multi-level abstraction of the input dataset\nand generate new data that possesses the relevant features of the original\ndataset and can be used as references for classification. In both cases, the\ncoarse-grained structure plays an important role in simplifying the network and\nimproving both the interpretability and efficiency. The validity has been\ndomonstrated on MNIST and CIFAR-10 datasets. Further improvement and some open\nquestions related are also discussed.",
    "descriptor": "",
    "authors": [
      "Xi-Ci Yang",
      "Z. Y. Xie",
      "Xiao-Tao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01779"
  },
  {
    "id": "arXiv:2211.01781",
    "title": "Video Event Extraction via Tracking Visual States of Arguments",
    "abstract": "Video event extraction aims to detect salient events from a video and\nidentify the arguments for each event as well as their semantic roles. Existing\nmethods focus on capturing the overall visual scene of each frame, ignoring\nfine-grained argument-level information. Inspired by the definition of events\nas changes of states, we propose a novel framework to detect video events by\ntracking the changes in the visual states of all involved arguments, which are\nexpected to provide the most informative evidence for the extraction of video\nevents. In order to capture the visual state changes of arguments, we decompose\nthem into changes in pixels within objects, displacements of objects, and\ninteractions among multiple arguments. We further propose Object State\nEmbedding, Object Motion-aware Embedding and Argument Interaction Embedding to\nencode and track these changes respectively. Experiments on various video event\nextraction tasks demonstrate significant improvements compared to\nstate-of-the-art models. In particular, on verb classification, we achieve\n3.49% absolute gains (19.53% relative gains) in F1@5 on Video Situation\nRecognition.",
    "descriptor": "",
    "authors": [
      "Guang Yang",
      "Manling Li",
      "Xudong Lin",
      "Jiajie Zhang",
      "Shih-Fu Chang",
      "Heng Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01781"
  },
  {
    "id": "arXiv:2211.01783",
    "title": "Quantifying and Learning Static vs. Dynamic Information in Deep  Spatiotemporal Networks",
    "abstract": "There is limited understanding of the information captured by deep\nspatiotemporal models in their intermediate representations. For example, while\nevidence suggests that action recognition algorithms are heavily influenced by\nvisual appearance in single frames, no quantitative methodology exists for\nevaluating such static bias in the latent representation compared to bias\ntoward dynamics. We tackle this challenge by proposing an approach for\nquantifying the static and dynamic biases of any spatiotemporal model, and\napply our approach to three tasks, action recognition, automatic video object\nsegmentation (AVOS) and video instance segmentation (VIS). Our key findings\nare: (i) Most examined models are biased toward static information. (ii) Some\ndatasets that are assumed to be biased toward dynamics are actually biased\ntoward static information. (iii) Individual channels in an architecture can be\nbiased toward static, dynamic or a combination of the two. (iv) Most models\nconverge to their culminating biases in the first half of training. We then\nexplore how these biases affect performance on dynamically biased datasets. For\naction recognition, we propose StaticDropout, a semantically guided dropout\nthat debiases a model from static information toward dynamics. For AVOS, we\ndesign a better combination of fusion and cross connection layers compared with\nprevious architectures.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2206.02846\n",
    "authors": [
      "Matthew Kowal",
      "Mennatullah Siam",
      "Md Amirul Islam",
      "Neil D. B. Bruce",
      "Richard P. Wildes",
      "Konstantinos G. Derpanis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01783"
  },
  {
    "id": "arXiv:2211.01785",
    "title": "Rethinking Hierarchicies in Pre-trained Plain Vision Transformer",
    "abstract": "Self-supervised pre-training vision transformer (ViT) via masked image\nmodeling (MIM) has been proven very effective. However, customized algorithms\nshould be carefully designed for the hierarchical ViTs, e.g., GreenMIM, instead\nof using the vanilla and simple MAE for the plain ViT. More importantly, since\nthese hierarchical ViTs cannot reuse the off-the-shelf pre-trained weights of\nthe plain ViTs, the requirement of pre-training them leads to a massive amount\nof computational cost, thereby incurring both algorithmic and computational\ncomplexity. In this paper, we address this problem by proposing a novel idea of\ndisentangling the hierarchical architecture design from the self-supervised\npre-training. We transform the plain ViT into a hierarchical one with minimal\nchanges. Technically, we change the stride of linear embedding layer from 16 to\n4 and add convolution (or simple average) pooling layers between the\ntransformer blocks, thereby reducing the feature size from 1/4 to 1/32\nsequentially. Despite its simplicity, it outperforms the plain ViT baseline in\nclassification, detection, and segmentation tasks on ImageNet, MS COCO,\nCityscapes, and ADE20K benchmarks, respectively. We hope this preliminary study\ncould draw more attention from the community on developing effective\n(hierarchical) ViTs while avoiding the pre-training cost by leveraging the\noff-the-shelf checkpoints. The code and models will be released at\nhttps://github.com/ViTAE-Transformer/HPViT.",
    "descriptor": "\nComments: Tech report, work in progress\n",
    "authors": [
      "Yufei Xu",
      "Jing Zhang",
      "Qiming Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01785"
  },
  {
    "id": "arXiv:2211.01786",
    "title": "Crosslingual Generalization through Multitask Finetuning",
    "abstract": "Multitask prompted finetuning (MTF) has been shown to help large language\nmodels generalize to new tasks in a zero-shot setting, but so far explorations\nof MTF have focused on English data and models. We apply MTF to the pretrained\nmultilingual BLOOM and mT5 model families to produce finetuned variants called\nBLOOMZ and mT0. We find finetuning large multilingual language models on\nEnglish tasks with English prompts allows for task generalization to\nnon-English languages that appear only in the pretraining corpus. Finetuning on\nmultilingual tasks with English prompts further improves performance on English\nand non-English tasks leading to various state-of-the-art zero-shot results. We\nalso investigate finetuning on multilingual tasks with prompts that have been\nmachine-translated from English to match the language of each dataset. We find\ntraining on these machine-translated prompts leads to better performance on\nhuman-written prompts in the respective languages. Surprisingly, we find models\nare capable of zero-shot generalization to tasks in languages they have never\nintentionally seen. We conjecture that the models are learning higher-level\ncapabilities that are both task- and language-agnostic. In addition, we\nintroduce xP3, a composite of supervised datasets in 46 languages with English\nand machine-translated prompts. Our code, datasets and models are publicly\navailable at https://github.com/bigscience-workshop/xmtf.",
    "descriptor": "\nComments: 8 main pages (114 with appendix), 16 figures and 7 tables\n",
    "authors": [
      "Niklas Muennighoff",
      "Thomas Wang",
      "Lintang Sutawika",
      "Adam Roberts",
      "Stella Biderman",
      "Teven Le Scao",
      "M Saiful Bari",
      "Sheng Shen",
      "Zheng-Xin Yong",
      "Hailey Schoelkopf",
      "Xiangru Tang",
      "Dragomir Radev",
      "Alham Fikri Aji",
      "Khalid Almubarak",
      "Samuel Albanie",
      "Zaid Alyafeai",
      "Albert Webson",
      "Edward Raff",
      "Colin Raffel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01786"
  },
  {
    "id": "arXiv:2211.01788",
    "title": "Common Information, Noise Stability, and Their Extensions",
    "abstract": "Common information (CI) is ubiquitous in information theory and related areas\nsuch as theoretical computer science and discrete probability. However, because\nthere are multiple notions of CI, a unified understanding of the deep\ninterconnections between them is lacking. This monograph seeks to fill this gap\nby leveraging a small set of mathematical techniques that are applicable across\nseemingly disparate problems.\nIn Part I, we review the operational tasks and properties associated with\nWyner's and G\\'acs-K\\\"orner-Witsenhausen's (GKW's) CI. In PartII, we discuss\nextensions of the former from the perspective of distributed source simulation.\nThis includes the R\\'enyi CI which forms a bridge between Wyner's CI and the\nexact CI. Via a surprising equivalence between the R\\'enyi CI of order~$\\infty$\nand the exact CI, we demonstrate the existence of a joint source in which the\nexact CI strictly exceeds Wyner's CI. Other closely related topics discussed in\nPart II include the channel synthesis problem and the connection of Wyner's and\nexact CI to the nonnegative rank of matrices.\nIn Part III, we examine GKW's CI with a more refined lens via the noise\nstability or NICD problem in which we quantify the agreement probability of\nextracted bits from a bivariate source. We then extend this to the $k$-user\nNICD and $q$-stability problems, and discuss various conjectures in information\ntheory and discrete probability, such as the Courtade-Kumar, Li-M\\'edard and\nMossell-O'Donnell conjectures. Finally, we consider hypercontractivity and\nBrascamp-Lieb inequalities, which further generalize noise stability via\nreplacing the Boolean functions therein by nonnnegative functions. The key\nideas behind the proofs in Part III can be presented in a pedagogically\ncoherent manner and unified via information-theoretic and Fourier-analytic\nmethods.",
    "descriptor": "\nComments: Lei Yu and Vincent Y. F. Tan (2022), \"Common Information, Noise Stability, and Their Extensions'', Foundations and Trends in Communications and Information Theory: Vol. 19, No. 3, pp 264--546. DOI: 10.1561/0100000122\n",
    "authors": [
      "Lei Yu",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.01788"
  },
  {
    "id": "arXiv:2211.01793",
    "title": "Data-driven Abstractions for Verification of Deterministic Systems",
    "abstract": "A common technique to verify complex logic specifications for dynamical\nsystems is the construction of symbolic abstractions: simpler, finite-state\nmodels whose behaviour mimics the one of the systems of interest. Typically,\nabstractions are constructed exploiting an accurate knowledge of the underlying\nmodel: in real-life applications, this may be a costly assumption. By sampling\nrandom $\\ell$-step trajectories of an unknown system, we build an abstraction\nbased on the notion of $\\ell$-completeness. We newly define the notion of\nprobabilistic behavioural inclusion, and provide probably approximately correct\n(PAC) guarantees that this abstraction includes all behaviours of the concrete\nsystem, for finite and infinite time horizon, leveraging the scenario theory\nfor non convex problems. Our method is then tested on several numerical\nbenchmarks.",
    "descriptor": "",
    "authors": [
      "Rudi Coppola",
      "Andrea Peruffo",
      "Manuel Mazo Jr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01793"
  },
  {
    "id": "arXiv:2211.01796",
    "title": "Beyond Instance Discrimination: Relation-aware Contrastive  Self-supervised Learning",
    "abstract": "Contrastive self-supervised learning (CSL) based on instance discrimination\ntypically attracts positive samples while repelling negatives to learn\nrepresentations with pre-defined binary self-supervision. However, vanilla CSL\nis inadequate in modeling sophisticated instance relations, limiting the\nlearned model to retain fine semantic structure. On the one hand, samples with\nthe same semantic category are inevitably pushed away as negatives. On the\nother hand, differences among samples cannot be captured. In this paper, we\npresent relation-aware contrastive self-supervised learning (ReCo) to integrate\ninstance relations, i.e., global distribution relation and local interpolation\nrelation, into the CSL framework in a plug-and-play fashion. Specifically, we\nalign similarity distributions calculated between the positive anchor views and\nthe negatives at the global level to exploit diverse similarity relations among\ninstances. Local-level interpolation consistency between the pixel space and\nthe feature space is applied to quantitatively model the feature differences of\nsamples with distinct apparent similarities. Through explicitly instance\nrelation modeling, our ReCo avoids irrationally pushing away semantically\nidentical samples and carves a well-structured feature space. Extensive\nexperiments conducted on commonly used benchmarks justify that our ReCo\nconsistently gains remarkable performance improvements.",
    "descriptor": "\nComments: The first two authors contributed equally to this work. (under review)\n",
    "authors": [
      "Yifei Zhang",
      "Chang Liu",
      "Yu Zhou",
      "Weiping Wang",
      "Qixiang Ye",
      "Xiangyang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01796"
  },
  {
    "id": "arXiv:2211.01797",
    "title": "Query-based Instance Discrimination Network for Relational Triple  Extraction",
    "abstract": "Joint entity and relation extraction has been a core task in the field of\ninformation extraction. Recent approaches usually consider the extraction of\nrelational triples from a stereoscopic perspective, either learning a\nrelation-specific tagger or separate classifiers for each relation type.\nHowever, they still suffer from error propagation, relation redundancy and lack\nof high-level connections between triples. To address these issues, we propose\na novel query-based approach to construct instance-level representations for\nrelational triples. By metric-based comparison between query embeddings and\ntoken embeddings, we can extract all types of triples in one step, thus\neliminating the error propagation problem. In addition, we learn the\ninstance-level representation of relational triples via contrastive learning.\nIn this way, relational triples can not only enclose rich class-level semantics\nbut also access to high-order global connections. Experimental results show\nthat our proposed method achieves the state of the art on five widely used\nbenchmarks.",
    "descriptor": "\nComments: Accepted to EMNLP 2022, submission version\n",
    "authors": [
      "Zeqi Tan",
      "Yongliang Shen",
      "Xuming Hu",
      "Wenqi Zhang",
      "Xiaoxia Cheng",
      "Weiming Lu",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01797"
  },
  {
    "id": "arXiv:2211.01801",
    "title": "DECISIVE Test Methods Handbook: Test Methods for Evaluating sUAS in  Subterranean and Constrained Indoor Environments, Version 1.1",
    "abstract": "This handbook outlines all test methods developed under the Development and\nExecution of Comprehensive and Integrated Subterranean Intelligent Vehicle\nEvaluations (DECISIVE) project by the University of Massachusetts Lowell for\nevaluating small unmanned aerial systems (sUAS) performance in subterranean and\nconstrained indoor environments, spanning communications, field readiness,\ninterface, obstacle avoidance, navigation, mapping, autonomy, trust, and\nsituation awareness. For sUAS deployment in subterranean and constrained indoor\nenvironments, this puts forth two assumptions about applicable sUAS to be\nevaluated using these test methods: (1) able to operate without access to GPS\nsignal, and (2) width from prop top to prop tip does not exceed 91 cm (36 in)\nwide (i.e., can physically fit through a typical doorway, although successful\nnavigation through is not guaranteed). All test methods are specified using a\ncommon format: Purpose, Summary of Test Method, Apparatus and Artifacts,\nEquipment, Metrics, Procedure, and Example Data. All test methods are designed\nto be run in real-world environments (e.g., MOUT sites) or using fabricated\napparatuses (e.g., test bays built from wood, or contained inside of one or\nmore shipping containers).",
    "descriptor": "\nComments: Approved for public release: PAO #PR2022_47058\n",
    "authors": [
      "Adam Norton",
      "Reza Ahmadzadeh",
      "Kshitij Jerath",
      "Paul Robinette",
      "Jay Weitzen",
      "Thanuka Wickramarathne",
      "Holly Yanco",
      "Minseop Choi",
      "Ryan Donald",
      "Brendan Donoghue",
      "Christian Dumas",
      "Peter Gavriel",
      "Alden Giedraitis",
      "Brendan Hertel",
      "Jack Houle",
      "Nathan Letteri",
      "Edwin Meriaux",
      "Zahra Rezaei",
      "Rakshith Singh",
      "Gregg Willcox",
      "Naye Yoni"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01801"
  },
  {
    "id": "arXiv:2211.01805",
    "title": "FedMint: Intelligent Bilateral Client Selection in Federated Learning  with Newcomer IoT Devices",
    "abstract": "Federated Learning (FL) is a novel distributed privacy-preserving learning\nparadigm, which enables the collaboration among several participants (e.g.,\nInternet of Things devices) for the training of machine learning models.\nHowever, selecting the participants that would contribute to this collaborative\ntraining is highly challenging. Adopting a random selection strategy would\nentail substantial problems due to the heterogeneity in terms of data quality,\nand computational and communication resources across the participants. Although\nseveral approaches have been proposed in the literature to overcome the problem\nof random selection, most of these approaches follow a unilateral selection\nstrategy. In fact, they base their selection strategy on only the federated\nserver's side, while overlooking the interests of the client devices in the\nprocess. To overcome this problem, we present in this paper FedMint, an\nintelligent client selection approach for federated learning on IoT devices\nusing game theory and bootstrapping mechanism. Our solution involves the design\nof: (1) preference functions for the client IoT devices and federated servers\nto allow them to rank each other according to several factors such as accuracy\nand price, (2) intelligent matching algorithms that take into account the\npreferences of both parties in their design, and (3) bootstrapping technique\nthat capitalizes on the collaboration of multiple federated servers in order to\nassign initial accuracy value for the newly connected IoT devices. Based on our\nsimulation findings, our strategy surpasses the VanillaFL selection approach in\nterms of maximizing both the revenues of the client devices and accuracy of the\nglobal federated learning model.",
    "descriptor": "",
    "authors": [
      "Osama Wehbi",
      "Sarhad Arisdakessian",
      "Omar Abdel Wahab",
      "Hadi Otrok",
      "Safa Otoum",
      "Azzam Mourad",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.01805"
  },
  {
    "id": "arXiv:2211.01806",
    "title": "BATT: Backdoor Attack with Transformation-based Triggers",
    "abstract": "Deep neural networks (DNNs) are vulnerable to backdoor attacks. The backdoor\nadversaries intend to maliciously control the predictions of attacked DNNs by\ninjecting hidden backdoors that can be activated by adversary-specified trigger\npatterns during the training process. One recent research revealed that most of\nthe existing attacks failed in the real physical world since the trigger\ncontained in the digitized test samples may be different from that of the one\nused for training. Accordingly, users can adopt spatial transformations as the\nimage pre-processing to deactivate hidden backdoors. In this paper, we explore\nthe previous findings from another side. We exploit classical spatial\ntransformations (i.e. rotation and translation) with the specific parameter as\ntrigger patterns to design a simple yet effective poisoning-based backdoor\nattack. For example, only images rotated to a particular angle can activate the\nembedded backdoor of attacked DNNs. Extensive experiments are conducted,\nverifying the effectiveness of our attack under both digital and physical\nsettings and its resistance to existing backdoor defenses.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Tong Xu",
      "Yiming Li",
      "Yong Jiang",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01806"
  },
  {
    "id": "arXiv:2211.01808",
    "title": "Dormant Neural Trojans",
    "abstract": "We present a novel methodology for neural network backdoor attacks. Unlike\nexisting training-time attacks where the Trojaned network would respond to the\nTrojan trigger after training, our approach inserts a Trojan that will remain\ndormant until it is activated. The activation is realized through a specific\nperturbation to the network's weight parameters only known to the attacker. Our\nanalysis and the experimental results demonstrate that dormant Trojaned\nnetworks can effectively evade detection by state-of-the-art backdoor detection\nmethods.",
    "descriptor": "",
    "authors": [
      "Feisi Fu",
      "Panagiota Kiourti",
      "Wenchao Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01808"
  },
  {
    "id": "arXiv:2211.01809",
    "title": "Manipulation of individual judgments in the quantitative pairwise  comparisons method",
    "abstract": "Decision-making methods very often use the technique of comparing\nalternatives in pairs. In this approach, experts are asked to compare different\noptions, and then a quantitative ranking is created from the results obtained.\nIt is commonly believed that experts (decision-makers) are honest in their\njudgments. In our work, we consider a scenario in which experts are vulnerable\nto bribery. For this purpose, we define a framework that allows us to determine\nthe intended manipulation and present three algorithms for achieving the\nintended goal. Analyzing these algorithms may provide clues to help defend\nagainst such attacks.",
    "descriptor": "\nComments: 23 pages, 6 compound figures\n",
    "authors": [
      "M. Strada",
      "K. Ku\u0142akowski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.01809"
  },
  {
    "id": "arXiv:2211.01811",
    "title": "Photonic Elementary Cellular Automata for Simulation of Complex  Phenomena",
    "abstract": "Cellular automata are a class of computational models based on simple rules\nand algorithms that can simulate a wide range of complex phenomena. However,\nwhen using conventional computers, these 'simple' rules are only encapsulated\nat the level of software. This can be taken one step further by simplifying the\nunderlying physical hardware. Here, we propose and implement a simple photonic\nhardware platform for simulating complex phenomena based on cellular automata.\nUsing this special-purpose computer, we experimentally demonstrate complex\nphenomena including fractals, chaos, and solitons, which are typically\nassociated with much more complex physical systems. The flexibility and\nprogrammability of our photonic computer presents new opportunities to simulate\nand harness complexity for efficient, robust, and decentralized information\nprocessing schemes using light.",
    "descriptor": "",
    "authors": [
      "Gordon H. Y. Li",
      "Christian R. Leefmans",
      "James Williams",
      "Alireza Marandi"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Cellular Automata and Lattice Gases (nlin.CG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.01811"
  },
  {
    "id": "arXiv:2211.01812",
    "title": "Benchmarking local motion planners for navigation of mobile manipulators",
    "abstract": "There are various trajectory planners for mobile manipulators. It is often\nchallenging to compare their performance under similar circumstances due to\ndifferences in hardware, dissimilarity of tasks and objectives, as well as\nuncertainties in measurements and operating environments. In this paper, we\npropose a simulation framework to evaluate the performance of the local\ntrajectory planners to generate smooth, and dynamically and kinematically\nfeasible trajectories for mobile manipulators in the same environment. We focus\non local planners as they are key components that provide smooth trajectories\nwhile carrying a load, react to dynamic obstacles, and avoid collisions. We\nevaluate two prominent local trajectory planners, Dynamic-Window Approach (DWA)\nand Time Elastic Band (TEB) using the metrics that we introduce. Moreover, our\nsoftware solution is applicable to any other local planners used in the Robot\nOperating System (ROS) framework, without additional programming effort.",
    "descriptor": "\nComments: Accepted to be presented at 2023 IEEE/SICE International Symposium on System Integration\n",
    "authors": [
      "Sevag Tafnakaji",
      "Hadi Hajieghrary",
      "Quentin Teixeira",
      "Yasemin Bekiroglu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01812"
  },
  {
    "id": "arXiv:2211.01813",
    "title": "Developing Modular Autonomous Capabilities for sUAS Operations",
    "abstract": "Small teams in the field can benefit from the capabilities provided by small\nUncrewed Aerial Systems (sUAS) for missions such as reconnaissance, hostile\nattribution, remote emplacement, and search and rescue. The mobility,\ncommunications, and flexible payload capacity of sUAS can offer teams new\nlevels of situational awareness and enable more highly coordinated missions\nthan previously possible. However, piloting such aircraft for specific missions\ndraws personnel away from other mission-critical tasks, increasing the load on\nremaining personnel while also increasing complexity of operations. For wider\nadoption and use of sUAS for security and humanitarian missions, safe and\nrobust autonomy must be employed to reduce this burden on small teams. In this\npaper, we present the development of the Collaborative-UAS for Hostile\nAttribution, Surveillance, Emplacement, and Reconnaissance (CHASER) testbed,\nfor rapidly prototyping capabilities that will reduce strain on small teams\nthrough sensor-guided autonomous control. We attempt to address autonomy needs\nunfilled by commercial sUAS platforms by creating and testing a series of\ncomposable modules that can be configured to support multiple missions. Methods\nimplemented and presented here include radar track correlation, on-board\ncomputer vision target detection, target position estimation, closed-loop\nrelative position control, and efficient search of a 3D volume for target\nacquisition. We configure and test a series of these modules in an example\nmission, executing a fully autonomous chase of an intruding sUAS in live\nflight, and demonstrating the success of the modularized autonomy approach. We\npresent performance results from simulation or live flight tests for each\nmodule. Lastly, we describe the software architecture that we have developed\nfor flexible controls and comment on how the capabilities presented may enable\nadditional missions.",
    "descriptor": "\nComments: Submitted to IEEE Aerospace Conference (AeroConf) 2023. Under Review\n",
    "authors": [
      "Keegan Quigley",
      "Virginia Goodwin",
      "Luis Alvarez",
      "Justin Yao",
      "Yousef Salaman Maclara"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01813"
  },
  {
    "id": "arXiv:2211.01814",
    "title": "Self Similarity Matrix based CNN Filter Pruning",
    "abstract": "In recent years, most of the deep learning solutions are targeted to be\ndeployed in mobile devices. This makes the need for development of lightweight\nmodels all the more imminent. Another solution is to optimize and prune regular\ndeep learning models. In this paper, we tackle the problem of CNN model pruning\nwith the help of Self-Similarity Matrix (SSM) computed from the 2D CNN filters.\nWe propose two novel algorithms to rank and prune redundant filters which\ncontribute similar activation maps to the output. One of the key features of\nour method is that there is no need of finetuning after training the model.\nBoth the training and pruning process is completed simultaneously. We benchmark\nour method on two of the most popular CNN models - ResNet and VGG and record\ntheir performance on the CIFAR-10 dataset.",
    "descriptor": "\nComments: Paper accepted in the 7th International Conference on Computer Vision & Image Processing (2022)\n",
    "authors": [
      "S Rakshith",
      "Jayesh Rajkumar Vachhani",
      "Sourabh Vasant Gothe",
      "Rishabh Khurana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01814"
  },
  {
    "id": "arXiv:2211.01817",
    "title": "Liability regimes in the age of AI: a use-case driven analysis of the  burden of proof",
    "abstract": "New emerging technologies powered by Artificial Intelligence (AI) have the\npotential to disruptively transform our societies for the better. In\nparticular, data-driven learning approaches (i.e., Machine Learning (ML)) have\nbeen a true revolution in the advancement of multiple technologies in various\napplication domains. But at the same time there is growing concerns about\ncertain intrinsic characteristics of these methodologies that carry potential\nrisks to both safety and fundamental rights. Although there are mechanisms in\nthe adoption process to minimize these risks (e.g., safety regulations), these\ndo not exclude the possibility of harm occurring, and if this happens, victims\nshould be able to seek compensation. Liability regimes will therefore play a\nkey role in ensuring basic protection for victims using or interacting with\nthese systems. However, the same characteristics that make AI systems\ninherently risky, such as lack of causality, opacity, unpredictability or their\nself and continuous learning capabilities, lead to considerable difficulties\nwhen it comes to proving causation. This paper presents three case studies, as\nwell as the methodology to reach them, that illustrate these difficulties.\nSpecifically, we address the cases of cleaning robots, delivery drones and\nrobots in education. The outcome of the proposed analysis suggests the need to\nrevise liability regimes to alleviate the burden of proof on victims in cases\ninvolving AI technologies.",
    "descriptor": "\nComments: Paper submitted to the Journal of Artificial Intelligence Research\n",
    "authors": [
      "David Fern\u00e1ndez Llorca",
      "Vicky Charisi",
      "Ronan Hamon",
      "Ignacio S\u00e1nchez",
      "Emilia G\u00f3mez"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01817"
  },
  {
    "id": "arXiv:2211.01822",
    "title": "Dead-zone compensation via passivity-based control for a class of  mechanical systems",
    "abstract": "This manuscript introduces a passivity-based control methodology for\nfully-actuated mechanical systems with symmetric or asymmetric dead-zones. To\nthis end, we find a smooth approximation of the inverse of the function that\ndescribes such a nonlinearity. Then, we propose an energy and damping injection\napproach - based on the PI-PBC technique - that compensates for the dead-zone.\nMoreover, we provide an analysis of the performance of the proposed controller\nnear the equilibrium. We conclude this paper by experimentally validating the\nresults on a two degrees-of-freedom planar manipulator.",
    "descriptor": "\nComments: Accepted in NOLCOS 2022\n",
    "authors": [
      "Carmen Chan-Zheng",
      "Pablo Borja",
      "Jacquelien M.A Scherpen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01822"
  },
  {
    "id": "arXiv:2211.01824",
    "title": "Human in the loop approaches in multi-modal conversational task guidance  system development",
    "abstract": "Development of task guidance systems for aiding humans in a situated task\nremains a challenging problem. The role of search (information retrieval) and\nconversational systems for task guidance has immense potential to help the task\nperformers achieve various goals. However, there are several technical\nchallenges that need to be addressed to deliver such conversational systems,\nwhere common supervised approaches fail to deliver the expected results in\nterms of overall performance, user experience and adaptation to realistic\nconditions. In this preliminary work we first highlight some of the challenges\ninvolved during the development of such systems. We then provide an overview of\nexisting datasets available and highlight their limitations. We finally develop\na model-in-the-loop wizard-of-oz based data collection tool and perform a pilot\nexperiment.",
    "descriptor": "\nComments: SCAI @ SIGIR\n",
    "authors": [
      "Ramesh Manuvinakurike",
      "Sovan Biswas",
      "Giuseppe Raffa",
      "Richard Beckwith",
      "Anthony Rhodes",
      "Meng Shi",
      "Gesem Gudino Mejia",
      "Saurav Sahay",
      "Lama Nachman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01824"
  },
  {
    "id": "arXiv:2211.01825",
    "title": "Fast Noise Removal in Hyperspectral Images via Representative  Coefficient Total Variation",
    "abstract": "Mining structural priors in data is a widely recognized technique for\nhyperspectral image (HSI) denoising tasks, whose typical ways include\nmodel-based methods and data-based methods. The model-based methods have good\ngeneralization ability, while the runtime cannot meet the fast processing\nrequirements of the practical situations due to the large size of an HSI data $\n\\mathbf{X} \\in \\mathbb{R}^{MN\\times B}$. For the data-based methods, they\nperform very fast on new test data once they have been trained. However, their\ngeneralization ability is always insufficient. In this paper, we propose a fast\nmodel-based HSI denoising approach. Specifically, we propose a novel\nregularizer named Representative Coefficient Total Variation (RCTV) to\nsimultaneously characterize the low rank and local smooth properties. The RCTV\nregularizer is proposed based on the observation that the representative\ncoefficient matrix $\\mathbf{U}\\in\\mathbb{R}^{MN\\times R} (R\\ll B)$ obtained by\northogonally transforming the original HSI $\\mathbf{X}$ can inherit the strong\nlocal-smooth prior of $\\mathbf{X}$. Since $R/B$ is very small, the HSI\ndenoising model based on the RCTV regularizer has lower time complexity.\nAdditionally, we find that the representative coefficient matrix $\\mathbf{U}$\nis robust to noise, and thus the RCTV regularizer can somewhat promote the\nrobustness of the HSI denoising model. Extensive experiments on mixed noise\nremoval demonstrate the superiority of the proposed method both in denoising\nperformance and denoising speed compared with other state-of-the-art methods.\nRemarkably, the denoising speed of our proposed method outperforms all the\nmodel-based techniques and is comparable with the deep learning-based\napproaches.",
    "descriptor": "\nComments: 16 pages, 18 figures, 5 tables, 1 theorem\n",
    "authors": [
      "Jiangjun Peng",
      "Hailin Wang",
      "Xiangyong Cao",
      "Xinlin Liu",
      "Xiangyu Rui",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.01825"
  },
  {
    "id": "arXiv:2211.01827",
    "title": "Demo: LE3D: A Privacy-preserving Lightweight Data Drift Detection  Framework",
    "abstract": "This paper presents LE3D; a novel data drift detection framework for\npreserving data integrity and confidentiality. LE3D is a generalisable platform\nfor evaluating novel drift detection mechanisms within the Internet of Things\n(IoT) sensor deployments. Our framework operates in a distributed manner,\npreserving data privacy while still being adaptable to new sensors with minimal\nonline reconfiguration. Our framework currently supports multiple drift\nestimators for time-series IoT data and can easily be extended to accommodate\nnew data types and drift detection mechanisms. This demo will illustrate the\nfunctionality of LE3D under a real-world-like scenario.",
    "descriptor": "\nComments: IEEE CCNC 2023, Las Vegas, USA\n",
    "authors": [
      "Ioannis Mavromatis",
      "Aftab Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.01827"
  },
  {
    "id": "arXiv:2211.01829",
    "title": "DriveFuzz: Discovering Autonomous Driving Bugs through Driving  Quality-Guided Fuzzing",
    "abstract": "Autonomous driving has become real; semi-autonomous driving vehicles in an\naffordable price range are already on the streets, and major automotive vendors\nare actively developing full self-driving systems to deploy them in this\ndecade. Before rolling the products out to the end-users, it is critical to\ntest and ensure the safety of the autonomous driving systems, consisting of\nmultiple layers intertwined in a complicated way. However, while\nsafety-critical bugs may exist in any layer and even across layers, relatively\nlittle attention has been given to testing the entire driving system across all\nthe layers. Prior work mainly focuses on white-box testing of individual layers\nand preventing attacks on each layer.\nIn this paper, we aim at holistic testing of autonomous driving systems that\nhave a whole stack of layers integrated in their entirety. Instead of looking\ninto the individual layers, we focus on the vehicle states that the system\ncontinuously changes in the driving environment. This allows us to design\nDriveFuzz, a new systematic fuzzing framework that can uncover potential\nvulnerabilities regardless of their locations. DriveFuzz automatically\ngenerates and mutates driving scenarios based on diverse factors leveraging a\nhigh-fidelity driving simulator. We build novel driving test oracles based on\nthe real-world traffic rules to detect safety-critical misbehaviors, and guide\nthe fuzzer towards such misbehaviors through driving quality metrics referring\nto the physical states of the vehicle.\nDriveFuzz has discovered 30 new bugs in various layers of two autonomous\ndriving systems (Autoware and CARLA Behavior Agent) and three additional bugs\nin the CARLA simulator. We further analyze the impact of these bugs and how an\nadversary may exploit them as security vulnerabilities to cause critical\naccidents in the real world.",
    "descriptor": "\nComments: This is the full version of the paper published at ACM CCS 2022. This version includes the appendices (pages 14 and 15)\n",
    "authors": [
      "Seulbae Kim",
      "Major Liu",
      "Junghwan \"John\" Rhee",
      "Yuseok Jeon",
      "Yonghwi Kwon",
      "Chung Hwan Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01829"
  },
  {
    "id": "arXiv:2211.01830",
    "title": "Ranking-based Group Identification via Factorized Attention on Social  Tripartite Graph",
    "abstract": "Due to the proliferation of social media, a growing number of users search\nfor and join group activities in their daily life. This develops a need for the\nstudy on the ranking-based group identification (RGI) task, i.e., recommending\ngroups to users. The major challenge in this task is how to effectively and\nefficiently leverage both the item interaction and group participation of\nusers' online behaviors. Though recent developments of Graph Neural Networks\n(GNNs) succeed in simultaneously aggregating both social and user-item\ninteraction, they however fail to comprehensively resolve this RGI task. In\nthis paper, we propose a novel GNN-based framework named Contextualized\nFactorized Attention for Group identification (CFAG). We devise tripartite\ngraph convolution layers to aggregate information from different types of\nneighborhoods among users, groups, and items. To cope with the data sparsity\nissue, we devise a novel propagation augmentation (PA) layer, which is based on\nour proposed factorized attention mechanism. PA layers efficiently learn the\nrelatedness of non-neighbor nodes to improve the information propagation to\nusers. Experimental results on three benchmark datasets verify the superiority\nof CFAG. Additional detailed investigations are conducted to demonstrate the\neffectiveness of the proposed framework.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Mingdai Yang",
      "Zhiwei Liu",
      "Liangwei Yang",
      "Xiaolong Liu",
      "Chen Wang",
      "Hao Peng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01830"
  },
  {
    "id": "arXiv:2211.01833",
    "title": "Basis Function feedforward for Position-Dependent Systems",
    "abstract": "Feedforward for motion systems is getting increasingly more important to\nachieve performance requirements. This leads to a situation where\nposition-dependent effects cannot be neglected anymore.",
    "descriptor": "\nComments: 3 page abstract; to appear in euspen Special Interest Group Meeting on Precision Motion Systems & Control\n",
    "authors": [
      "Max van Haren",
      "Lennart Blanken",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01833"
  },
  {
    "id": "arXiv:2211.01834",
    "title": "Toward Unsupervised Outlier Model Selection",
    "abstract": "Today there exists no shortage of outlier detection algorithms in the\nliterature, yet the complementary and critical problem of unsupervised outlier\nmodel selection (UOMS) is vastly understudied. In this work we propose ELECT, a\nnew approach to select an effective candidate model, i.e. an outlier detection\nalgorithm and its hyperparameter(s), to employ on a new dataset without any\nlabels. At its core, ELECT is based on meta-learning; transferring prior\nknowledge (e.g. model performance) on historical datasets that are similar to\nthe new one to facilitate UOMS. Uniquely, it employs a dataset similarity\nmeasure that is performance-based, which is more direct and goal-driven than\nother measures used in the past. ELECT adaptively searches for similar\nhistorical datasets, as such, it can serve an output on-demand, being able to\naccommodate varying time budgets. Extensive experiments show that ELECT\nsignificantly outperforms a wide range of basic UOMS baselines, including no\nmodel selection (always using the same popular model such as iForest) as well\nas more recent selection strategies based on meta-features.",
    "descriptor": "\nComments: ICDM 2022. Code available at this https URL\n",
    "authors": [
      "Yue Zhao",
      "Sean Zhang",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01834"
  },
  {
    "id": "arXiv:2211.01835",
    "title": "Jacobians and Gradients for Cartesian Differential Categories",
    "abstract": "Cartesian differential categories come equipped with a differential\ncombinator that formalizes the directional derivative from multivariable\ncalculus. Cartesian differential categories provide a categorical semantics of\nthe differential lambda-calculus and have also found applications in causal\ncomputation, incremental computation, game theory, differentiable programming,\nand machine learning. There has recently been a desire to provide a\n(coordinate-free) characterization of Jacobians and gradients in Cartesian\ndifferential categories. One's first attempt might be to consider Cartesian\ndifferential categories which are Cartesian closed, such as models of the\ndifferential lambda-calculus, and then take the curry of the derivative.\nUnfortunately, this approach excludes numerous important examples of Cartesian\ndifferential categories such as the category of real smooth functions. In this\npaper, we introduce linearly closed Cartesian differential categories, which\nare Cartesian differential categories that have an internal hom of linear maps,\na bilinear evaluation map, and the ability to curry maps which are linear in\ntheir second argument. As such, the Jacobian of a map is defined as the curry\nof its derivative. Many well-known examples of Cartesian differential\ncategories are linearly closed, such as, in particular, the category of real\nsmooth functions. We also explain how a Cartesian closed differential category\nis linearly closed if and only if a certain linear idempotent on the internal\nhom splits. To define the gradient of a map, one must be able to define the\ntranspose of the Jacobian, which can be done in a Cartesian reverse\ndifferential category. Thus, we define the gradient of a map to be the curry of\nits reverse derivative and show this equals the transpose of its Jacobian. We\nalso explain how a linearly closed Cartesian reverse differential category is\nprecisely a linearly closed Cartesian differential category with an appropriate\nnotion of transpose.",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Jean-Simon Pacaud Lemay"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.01835"
  },
  {
    "id": "arXiv:2211.01837",
    "title": "Latent Prompt Tuning for Text Summarization",
    "abstract": "Prompts with different control signals (e.g., length, keywords, etc.) can be\nused to control text summarization. When control signals are available, they\ncan control the properties of generated summaries and potentially improve\nsummarization quality (since more information are given). Unfortunately,\ncontrol signals are not already available during inference time. In this paper,\nwe propose Lotus (shorthand for Latent Prompt Tuning for Summarization), which\nis a single model that can be applied in both controlled and uncontrolled\n(without control signals) modes. During training, Lotus learns latent prompt\nrepresentations from prompts with gold control signals using a contrastive\nlearning objective. Experiments show Lotus in uncontrolled mode consistently\nimproves upon strong (uncontrollable) summarization models across four\ndifferent summarization datasets. We also demonstrate generated summaries can\nbe controlled using prompts with user specified control tokens.",
    "descriptor": "",
    "authors": [
      "Yubo Zhang",
      "Xingxing Zhang",
      "Xun Wang",
      "Si-qing Chen",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01837"
  },
  {
    "id": "arXiv:2211.01839",
    "title": "HyperSound: Generating Implicit Neural Representations of Audio Signals  with Hypernetworks",
    "abstract": "Implicit neural representations (INRs) are a rapidly growing research field,\nwhich provides alternative ways to represent multimedia signals. Recent\napplications of INRs include image super-resolution, compression of\nhigh-dimensional signals, or 3D rendering. However, these solutions usually\nfocus on visual data, and adapting them to the audio domain is not trivial.\nMoreover, it requires a separately trained model for every data sample. To\naddress this limitation, we propose HyperSound, a meta-learning method\nleveraging hypernetworks to produce INRs for audio signals unseen at training\ntime. We show that our approach can reconstruct sound waves with quality\ncomparable to other state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Filip Szatkowski",
      "Karol J. Piczak",
      "Przemys\u0142aw Spurek",
      "Jacek Tabor",
      "Tomasz Trzci\u0144ski"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01839"
  },
  {
    "id": "arXiv:2211.01840",
    "title": "LE3D: A Lightweight Ensemble Framework of Data Drift Detectors for  Resource-Constrained Devices",
    "abstract": "Data integrity becomes paramount as the number of Internet of Things (IoT)\nsensor deployments increases. Sensor data can be altered by benign causes or\nmalicious actions. Mechanisms that detect drifts and irregularities can prevent\ndisruptions and data bias in the state of an IoT application. This paper\npresents LE3D, an ensemble framework of data drift estimators capable of\ndetecting abnormal sensor behaviours. Working collaboratively with surrounding\nIoT devices, the type of drift (natural/abnormal) can also be identified and\nreported to the end-user. The proposed framework is a lightweight and\nunsupervised implementation able to run on resource-constrained IoT devices.\nOur framework is also generalisable, adapting to new sensor streams and\nenvironments with minimal online reconfiguration. We compare our method against\nstate-of-the-art ensemble data drift detection frameworks, evaluating both the\nreal-world detection accuracy as well as the resource utilisation of the\nimplementation. Experimenting with real-world data and emulated drifts, we show\nthe effectiveness of our method, which achieves up to 97% of detection accuracy\nwhile requiring minimal resources to run.",
    "descriptor": "\nComments: IEEE CCNC 2023, Las Vegas, USA\n",
    "authors": [
      "Ioannis Mavromatis",
      "Adrian Sanchez-Mompo",
      "Francesco Raimondo",
      "James Pope",
      "Marcello Bullo",
      "Ingram Weeks",
      "Vijay Kumar",
      "Pietro Carnelli",
      "George Oikonomou",
      "Theodoros Spyridopoulos",
      "Aftab Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01840"
  },
  {
    "id": "arXiv:2211.01841",
    "title": "Grounding Game Semantics in Categorical Algebra",
    "abstract": "I present a formal connection between algebraic effects and game semantics,\ntwo important lines of work in programming languages semantics with\napplications in compositional software verification.\nSpecifically, the algebraic signature enumerating the possible side-effects\nof a computation can be read as a game, and strategies for this game constitute\nthe free algebra for the signature in a category of complete partial orders\n(cpos). Hence, strategies provide a convenient model of computations with\nuninterpreted side-effects. In particular, the operational flavor of game\nsemantics carries over to the algebraic context, in the form of the coincidence\nbetween the initial algebras and the terminal coalgebras of cpo endofunctors.\nConversely, the algebraic point of view sheds new light on the strategy\nconstructions underlying game semantics. Strategy models can be reformulated as\nideal completions of partial strategy trees (free dcpos on the term algebra).\nExtending the framework to multi-sorted signatures would make this construction\navailable for a large class of games.",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "J\u00e9r\u00e9mie Koenig"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.01841"
  },
  {
    "id": "arXiv:2211.01842",
    "title": "Towards Discovering Neural Architectures from Scratch",
    "abstract": "The discovery of neural architectures from scratch is the long-standing goal\nof Neural Architecture Search (NAS). Searching over a wide spectrum of neural\narchitectures can facilitate the discovery of previously unconsidered but\nwell-performing architectures. In this work, we take a large step towards\ndiscovering neural architectures from scratch by expressing architectures\nalgebraically. This algebraic view leads to a more general method for designing\nsearch spaces, which allows us to compactly represent search spaces that are\n100s of orders of magnitude larger than common spaces from the literature.\nFurther, we propose a Bayesian Optimization strategy to efficiently search over\nsuch huge spaces, and demonstrate empirically that both our search space design\nand our search strategy can be superior to existing baselines. We open source\nour algebraic NAS approach and provide APIs for PyTorch and TensorFlow.",
    "descriptor": "",
    "authors": [
      "Simon Schrodi",
      "Danny Stoll",
      "Binxin Ru",
      "Rhea Sukthanker",
      "Thomas Brox",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01842"
  },
  {
    "id": "arXiv:2211.01845",
    "title": "Reinforcement Learning based Cyberattack Model for Adaptive Traffic  Signal Controller in Connected Transportation Systems",
    "abstract": "In a connected transportation system, adaptive traffic signal controllers\n(ATSC) utilize real-time vehicle trajectory data received from vehicles through\nwireless connectivity (i.e., connected vehicles) to regulate green time.\nHowever, this wirelessly connected ATSC increases cyber-attack surfaces and\nincreases their vulnerability to various cyber-attack modes, which can be\nleveraged to induce significant congestion in a roadway network. An attacker\nmay receive financial benefits to create such a congestion for a specific\nroadway. One such mode is a 'sybil' attack in which an attacker creates fake\nvehicles in the network by generating fake Basic Safety Messages (BSMs)\nimitating actual connected vehicles following roadway traffic rules. The\nultimate goal of an attacker will be to block a route(s) by generating fake or\n'sybil' vehicles at a rate such that the signal timing and phasing changes\noccur without flagging any abrupt change in number of vehicles. Because of the\nhighly non-linear and unpredictable nature of vehicle arrival rates and the\nATSC algorithm, it is difficult to find an optimal rate of sybil vehicles,\nwhich will be injected from different approaches of an intersection. Thus, it\nis necessary to develop an intelligent cyber-attack model to prove the\nexistence of such attacks. In this study, a reinforcement learning based\ncyber-attack model is developed for a waiting time-based ATSC. Specifically, an\nRL agent is trained to learn an optimal rate of sybil vehicle injection to\ncreate congestion for an approach(s). Our analyses revealed that the RL agent\ncan learn an optimal policy for creating an intelligent attack.",
    "descriptor": "\nComments: 18 pages, 12 figures, submitted to the Transportation Research Board 102nd Annual Meeting\n",
    "authors": [
      "Muhammad Sami Irfan",
      "Mizanur Rahman",
      "Travis Atkison",
      "Sagar Dasgupta",
      "Alexander Hainen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01845"
  },
  {
    "id": "arXiv:2211.01847",
    "title": "Seeing the Unseen: Errors and Bias in Visual Datasets",
    "abstract": "From face recognition in smartphones to automatic routing on self-driving\ncars, machine vision algorithms lie in the core of these features. These\nsystems solve image based tasks by identifying and understanding objects,\nsubsequently making decisions from these information. However, errors in\ndatasets are usually induced or even magnified in algorithms, at times\nresulting in issues such as recognising black people as gorillas and\nmisrepresenting ethnicities in search results. This paper tracks the errors in\ndatasets and their impacts, revealing that a flawed dataset could be a result\nof limited categories, incomprehensive sourcing and poor classification.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Hongrui Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01847"
  },
  {
    "id": "arXiv:2211.01848",
    "title": "Circling Back to Recurrent Models of Language",
    "abstract": "Just because some purely recurrent models suffer from being hard to optimize\nand inefficient on today's hardware, they are not necessarily bad models of\nlanguage. We demonstrate this by the extent to which these models can still be\nimproved by a combination of a slightly better recurrent cell, architecture,\nobjective, as well as optimization. In the process, we establish a new state of\nthe art for language modelling on small datasets and on enwik8 with dynamic\nevaluation.",
    "descriptor": "",
    "authors": [
      "G\u00e1bor Melis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01848"
  },
  {
    "id": "arXiv:2211.01852",
    "title": "Revisiting Hyperparameter Tuning with Differential Privacy",
    "abstract": "Hyperparameter tuning is a common practice in the application of machine\nlearning but is a typically ignored aspect in the literature on\nprivacy-preserving machine learning due to its negative effect on the overall\nprivacy parameter. In this paper, we aim to tackle this fundamental yet\nchallenging problem by providing an effective hyperparameter tuning framework\nwith differential privacy. The proposed method allows us to adopt a broader\nhyperparameter search space and even to perform a grid search over the whole\nspace, since its privacy loss parameter is independent of the number of\nhyperparameter candidates. Interestingly, it instead correlates with the\nutility gained from hyperparameter searching, revealing an explicit and\nmandatory trade-off between privacy and utility. Theoretically, we show that\nits additional privacy loss bound incurred by hyperparameter tuning is\nupper-bounded by the squared root of the gained utility. However, we note that\nthe additional privacy loss bound would empirically scale like a squared root\nof the logarithm of the utility term, benefiting from the design of doubling\nstep.",
    "descriptor": "\nComments: ML Safety Workshop of NeurIPS'22 Accepted Paper\n",
    "authors": [
      "Youlong Ding",
      "Xueyang Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01852"
  },
  {
    "id": "arXiv:2211.01856",
    "title": "Human Biophysics as Network Weights: Conditional Generative Models for  Ultra-fast Simulation",
    "abstract": "Simulations of biophysical systems have provided a huge contribution to our\nfundamental understanding of human physiology and remain a central pillar for\ndevelopments in medical devices and human machine interfaces. However, despite\ntheir successes, such simulations usually rely on highly computationally\nexpensive numerical modelling, which is often inefficient to adapt to new\nsimulation parameters. This limits their use in dynamic models of human\nbehavior, for example in modelling the electric fields generated by muscles in\na moving arm. We propose the alternative approach to use conditional generative\nmodels, which can learn complex relationships between the underlying generative\nconditions whilst remaining inexpensive to sample from. As a demonstration of\nthis concept, we present BioMime, a hybrid architecture that combines elements\nof deep latent variable models and conditional adversarial training to\nconstruct a generative model that can both transform existing data samples to\nreflect new modelling assumptions and sample new data from a conditioned\ndistribution. We demonstrate that BioMime can learn to accurately mimic a\ncomplex numerical model of human muscle biophysics and then use this knowledge\nto continuously sample from a dynamically changing system in real-time. We\nargue that transfer learning approaches with conditional generative models are\na viable solution for dynamic simulation with any numerical model.",
    "descriptor": "",
    "authors": [
      "Shihan Ma",
      "Alexander Kenneth Clarke",
      "Kostiantyn Maksymenko",
      "Samuel Deslauriers-Gauthier",
      "Xinjun Sheng",
      "Xiangyang Zhu",
      "Dario Farina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Signal Processing (eess.SP)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.01856"
  },
  {
    "id": "arXiv:2211.01858",
    "title": "Relating graph auto-encoders to linear models",
    "abstract": "Graph auto-encoders are widely used to construct graph representations in\nEuclidean vector spaces. However, it has already been pointed out empirically\nthat linear models on many tasks can outperform graph auto-encoders. In our\nwork, we prove that the solution space induced by graph auto-encoders is a\nsubset of the solution space of a linear map. This demonstrates that linear\nembedding models have at least the representational power of graph\nauto-encoders based on graph convolutional networks. So why are we still using\nnonlinear graph auto-encoders? One reason could be that actively restricting\nthe linear solution space might introduce an inductive bias that helps improve\nlearning and generalization. While many researchers believe that the\nnonlinearity of the encoder is the critical ingredient towards this end, we\ninstead identify the node features of the graph as a more powerful inductive\nbias. We give theoretical insights by introducing a corresponding bias in a\nlinear model and analyzing the change in the solution space. Our experiments\nshow that the linear encoder can outperform the nonlinear encoder when using\nfeature information.",
    "descriptor": "",
    "authors": [
      "Solveig Klepper",
      "Ulrike von Luxburg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01858"
  },
  {
    "id": "arXiv:2211.01859",
    "title": "Computed tomography coronary angiogram images, annotations and  associated data of normal and diseased arteries",
    "abstract": "Computed Tomography Coronary Angiography (CTCA) is a non-invasive method to\nevaluate coronary artery anatomy and disease. CTCA is ideal for geometry\nreconstruction to create virtual models of coronary arteries. To our knowledge\nthere is no public dataset that includes centrelines and segmentation of the\nfull coronary tree.\nWe provide anonymized CTCA images, voxel-wise annotations and associated data\nin the form of centrelines, calcification scores and meshes of the coronary\nlumen in 20 normal and 20 diseased cases. Images were obtained along with\npatient information with informed, written consent as part of Coronary Atlas\n(https://www.coronaryatlas.org/). Cases were classified as normal (zero calcium\nscore with no signs of stenosis) or diseased (confirmed coronary artery\ndisease). Manual voxel-wise segmentations by three experts were combined using\nmajority voting to generate the final annotations.\nProvided data can be used for a variety of research purposes, such as 3D\nprinting patient-specific models, development and validation of segmentation\nalgorithms, education and training of medical personnel and in-silico analyses\nsuch as testing of medical devices.",
    "descriptor": "\nComments: 10 pages, 3 figures. Submitted to the journal Scientific Data. For associated challenge, see this https URL\n",
    "authors": [
      "Ramtin Gharleghi",
      "Dona Adikari",
      "Katy Ellenberger",
      "Mark Webster",
      "Chris Ellis",
      "Arcot Sowmya",
      "Sze-Yuan Ooi",
      "Susann Beier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01859"
  },
  {
    "id": "arXiv:2211.01860",
    "title": "Learning safety in model-based Reinforcement Learning using MPC and  Gaussian Processes",
    "abstract": "In this work, we propose a method to encourage safety in a Model Predictive\nControl (MPC)-based Reinforcement Learning (RL) agent via Gaussian Process (GP)\nregression. This framework consists of 1) a parametric MPC scheme that is\nemployed as model-based controller with approximate knowledge on the real\nsystem's dynamics, 2) an episodic RL algorithm tasked with adjusting the MPC\nparametrization in order to increase its performance, and lastly, 3) GP\nregressors used to estimate, directly from data, constraints on the MPC\nparameters capable of predicting, up to some probability, whether the\nparametrization is likely to yield a safe or unsafe policy. These constraints\nare then enforced onto the RL updates in an effort to enhance the learning\nmethod with a probabilistic safety mechanism. Compared to other recent\npublications combining safe RL with MPC, our method does not require further\nassumptions on, e.g., the prediction model in order to retain computational\ntractability. We illustrate the results of our method in a numerical example on\nthe control of a quadrotor drone in a safety-critical environment.",
    "descriptor": "\nComments: 8 pages, 3 figures, submitted to IFAC World Congress 2023\n",
    "authors": [
      "Filippo Airaldi",
      "Bart De Schutter",
      "Azita Dabiri"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01860"
  },
  {
    "id": "arXiv:2211.01863",
    "title": "Edge, Fog, and Cloud Computing : An Overview on Challenges and  Applications",
    "abstract": "With the rapid growth of the Internet of Things (IoT) and a wide range of\nmobile devices, the conventional cloud computing paradigm faces significant\nchallenges (high latency, bandwidth cost, etc.). Motivated by those constraints\nand concerns for the future of the IoT, modern architectures are gearing toward\ndistributing the cloud computational resources to remote locations where most\nend-devices are located. Edge and fog computing are considered as the key\nenablers for applications where centralized cloud-based solutions are not\nsuitable. In this paper, we review the high-level definition of edge, fog,\ncloud computing, and their configurations in various IoT scenarios. We further\ndiscuss their interactions and collaborations in many applications such as\ncloud offloading, smart cities, health care, and smart agriculture. Though\nthere are still challenges in the development of such distributed systems,\nearly research to tackle those limitations have also surfaced.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Thong Vo",
      "Pranjal Dave",
      "Gaurav Bajpai",
      "Rasha Kashef"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01863"
  },
  {
    "id": "arXiv:2211.01866",
    "title": "ImageNet-X: Understanding Model Mistakes with Factor of Variation  Annotations",
    "abstract": "Deep learning vision systems are widely deployed across applications where\nreliability is critical. However, even today's best models can fail to\nrecognize an object when its pose, lighting, or background varies. While\nexisting benchmarks surface examples challenging for models, they do not\nexplain why such mistakes arise. To address this need, we introduce ImageNet-X,\na set of sixteen human annotations of factors such as pose, background, or\nlighting the entire ImageNet-1k validation set as well as a random subset of\n12k training images. Equipped with ImageNet-X, we investigate 2,200 current\nrecognition models and study the types of mistakes as a function of model's (1)\narchitecture, e.g. transformer vs. convolutional, (2) learning paradigm, e.g.\nsupervised vs. self-supervised, and (3) training procedures, e.g., data\naugmentation. Regardless of these choices, we find models have consistent\nfailure modes across ImageNet-X categories. We also find that while data\naugmentation can improve robustness to certain factors, they induce spill-over\neffects to other factors. For example, strong random cropping hurts robustness\non smaller objects. Together, these insights suggest to advance the robustness\nof modern vision models, future research should focus on collecting additional\ndata and understanding data augmentation schemes. Along with these insights, we\nrelease a toolkit based on ImageNet-X to spur further study into the mistakes\nimage recognition systems make.",
    "descriptor": "",
    "authors": [
      "Badr Youbi Idrissi",
      "Diane Bouchacourt",
      "Randall Balestriero",
      "Ivan Evtimov",
      "Caner Hazirbas",
      "Nicolas Ballas",
      "Pascal Vincent",
      "Michal Drozdzal",
      "David Lopez-Paz",
      "Mark Ibrahim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01866"
  },
  {
    "id": "arXiv:2211.01871",
    "title": "Spatiotemporal Calibration of 3D mm-Wavelength Radar-Camera Pairs",
    "abstract": "Autonomous vehicles (AVs) often depend on multiple sensors and sensing\nmodalities to mitigate data degradation and provide a measure of robustness\nwhen operating in adverse conditions. Radars and cameras are a popular sensor\ncombination - although radar measurements are sparse in comparison to camera\nimages, radar scans are able to penetrate fog, rain, and snow. Data from both\nsensors are typically fused in a common reference frame prior to use in\ndownstream perception tasks. However, accurate sensor fusion depends upon\nknowledge of the spatial transform between the sensors and any temporal\nmisalignment that exists in their measurement times. During the life cycle of\nan AV, these calibration parameters may change. The ability to perform in-situ\nspatiotemporal calibration is essential to ensure reliable long-term operation.\nState-of-the-art 3D radar-camera spatiotemporal calibration algorithms require\nbespoke calibration targets, which are not readily available in the field. In\nthis paper, we describe an algorithm for targetless spatiotemporal calibration\nthat is able to operate without specialized infrastructure. Our approach\nleverages the ability of the radar unit to measure its own ego-velocity\nrelative to a fixed external reference frame. We analyze the identifiability of\nthe spatiotemporal calibration problem and determine the motions necessary for\ncalibration. Through a series of simulation studies, we characterize the\nsensitivity of our algorithm to measurement noise. Finally, we demonstrate\naccurate calibration for three real-world systems, including a handheld sensor\nrig and a vehicle-mounted sensor array. Our results show that we are able to\nmatch the performance of an existing, target-based method, while calibrating in\narbitrary (infrastructure-free) environments.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Robotics, Oct. 2022\n",
    "authors": [
      "Emmett Wise",
      "Qilong Cheng",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01871"
  },
  {
    "id": "arXiv:2211.01873",
    "title": "Port-metriplectic neural networks: thermodynamics-informed machine  learning of complex physical systems",
    "abstract": "We develop inductive biases for the machine learning of complex physical\nsystems based on the port-Hamiltonian formalism. To satisfy by construction the\nprinciples of thermodynamics in the learned physics (conservation of energy,\nnon-negative entropy production), we modify accordingly the port-Hamiltonian\nformalism so as to achieve a port-metriplectic one. We show that the\nconstructed networks are able to learn the physics of complex systems by parts,\nthus alleviating the burden associated to the experimental characterization and\nposterior learning process of this kind of systems. Predictions can be done,\nhowever, at the scale of the complete system. Examples are shown on the\nperformance of the proposed technique.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Quercus Hern\u00e1ndez",
      "Alberto Bad\u00edas",
      "Francisco Chinesta",
      "El\u00edas Cueto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01873"
  },
  {
    "id": "arXiv:2211.01874",
    "title": "Contextual information integration for stance detection via  cross-attention",
    "abstract": "Stance detection deals with the identification of an author's stance towards\na target and is applied on various text domains like social media and news. In\nmany cases, inferring the stance is challenging due to insufficient access to\ncontextual information. Complementary context can be found in knowledge bases\nbut integrating the context into pretrained language models is non-trivial due\nto their graph structure. In contrast, we explore an approach to integrate\ncontextual information as text which aligns better with transformer\narchitectures. Specifically, we train a model consisting of dual encoders which\nexchange information via cross-attention. This architecture allows for\nintegrating contextual information from heterogeneous sources. We evaluate\ncontext extracted from structured knowledge sources and from prompting large\nlanguage models. Our approach is able to outperform competitive baselines\n(1.9pp on average) on a large and diverse stance detection benchmark, both (1)\nin-domain, i.e. for seen targets, and (2) out-of-domain, i.e. for targets\nunseen during training. Our analysis shows that it is able to regularize for\nspurious label correlations with target-specific cue words.",
    "descriptor": "\nComments: Data and code at this https URL\n",
    "authors": [
      "Tilman Beck",
      "Andreas Waldis",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01874"
  },
  {
    "id": "arXiv:2211.01875",
    "title": "M-to-N Backdoor Paradigm: A Stealthy and Fuzzy Attack to Deep Learning  Models",
    "abstract": "Recent studies show that deep neural networks (DNNs) are vulnerable to\nbackdoor attacks. A backdoor DNN model behaves normally with clean inputs,\nwhereas outputs attacker's expected behaviors when the inputs contain a\npre-defined pattern called a trigger. However, in some tasks, the attacker\ncannot know the exact target that shows his/her expected behavior, because the\ntask may contain a large number of classes and the attacker does not have full\naccess to know the semantic details of these classes. Thus, the attacker is\nwilling to attack multiple suspected targets to achieve his/her purpose. In\nlight of this, in this paper, we propose the M-to-N backdoor attack, a new\nattack paradigm that allows an attacker to launch a fuzzy attack by\nsimultaneously attacking N suspected targets, and each of the N targets can be\nactivated by any one of its M triggers. To achieve a better stealthiness, we\nrandomly select M clean images from the training dataset as our triggers for\neach target. Since the triggers used in our attack have the same distribution\nas the clean images, the inputs poisoned by the triggers are difficult to be\ndetected by the input-based defenses, and the backdoor models trained on the\npoisoned training dataset are also difficult to be detected by the model-based\ndefenses. Thus, our attack is stealthier and has a higher probability of\nachieving the attack purpose by attacking multiple suspected targets\nsimultaneously in contrast to prior backdoor attacks. Extensive experiments\nshow that our attack is effective against different datasets with various\nmodels and achieves high attack success rates (e.g., 99.43% for attacking 2\ntargets and 98.23% for attacking 4 targets on the CIFAR-10 dataset) when\npoisoning only an extremely small portion of the training dataset (e.g., less\nthan 2%). Besides, it is robust to pre-processing operations and can resist\nstate-of-the-art defenses.",
    "descriptor": "",
    "authors": [
      "Linshan Hou",
      "Zhongyun Hua",
      "Yuhong Li",
      "Leo Yu Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01875"
  },
  {
    "id": "arXiv:2211.01883",
    "title": "Faster Adaptive Momentum-Based Federated Methods for Distributed  Composition Optimization",
    "abstract": "Composition optimization recently appears in many machine learning\napplications such as meta learning and reinforcement learning. Recently many\ncomposition optimization algorithms have been proposed and studied, however,\nfew adaptive algorithm considers the composition optimization under the\ndistributed setting. Meanwhile, the existing distributed composition\noptimization methods still suffer from high sample and communication\ncomplexities. In the paper, thus, we develop a class of faster momentum-based\nfederated compositional gradient descent algorithms (i.e., MFCGD and AdaMFCGD)\nto solve the nonconvex distributed composition problems, which builds on the\nmomentum-based variance reduced and local-SGD techniques. In particular, our\nadaptive algorithm (i.e., AdaMFCGD) uses a unified adaptive matrix to flexibly\nincorporate various adaptive learning rates. Moreover, we provide a solid\ntheoretical analysis for our algorithms under non-i.i.d. setting, and prove our\nalgorithms obtain a lower sample and communication complexities simultaneously\nthan the existing federated compositional algorithms. Specifically, our\nalgorithms obtain lower sample complexity of $\\tilde{O}(\\epsilon^{-3})$ with\nlower communication complexity of $\\tilde{O}(\\epsilon^{-2})$ in finding an\n$\\epsilon$-stationary point. We conduct the experiments on robust federated\nlearning and distributed meta learning tasks to demonstrate efficiency of our\nalgorithms.",
    "descriptor": "\nComments: 39 pages. arXiv admin note: text overlap with arXiv:2211.01122\n",
    "authors": [
      "Feihu Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.01883"
  },
  {
    "id": "arXiv:2211.01886",
    "title": "Analysing the effectiveness of a generative model for semi-supervised  medical image segmentation",
    "abstract": "Image segmentation is important in medical imaging, providing valuable,\nquantitative information for clinical decision-making in diagnosis, therapy,\nand intervention. The state-of-the-art in automated segmentation remains\nsupervised learning, employing discriminative models such as U-Net. However,\ntraining these models requires access to large amounts of manually labelled\ndata which is often difficult to obtain in real medical applications. In such\nsettings, semi-supervised learning (SSL) attempts to leverage the abundance of\nunlabelled data to obtain more robust and reliable models. Recently, generative\nmodels have been proposed for semantic segmentation, as they make an attractive\nchoice for SSL. Their ability to capture the joint distribution over input\nimages and output label maps provides a natural way to incorporate information\nfrom unlabelled images. This paper analyses whether deep generative models such\nas the SemanticGAN are truly viable alternatives to tackle challenging medical\nimage segmentation problems. To that end, we thoroughly evaluate the\nsegmentation performance, robustness, and potential subgroup disparities of\ndiscriminative and generative segmentation methods when applied to large-scale,\npublicly available chest X-ray datasets.",
    "descriptor": "\nComments: Accepted at ML4H 2022\n",
    "authors": [
      "Margherita Rosnati",
      "Fabio De Sousa Ribeiro",
      "Miguel Monteiro",
      "Daniel Coelho de Castro",
      "Ben Glocker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01886"
  },
  {
    "id": "arXiv:2211.01889",
    "title": "When to Laugh and How Hard? A Multimodal Approach to Detecting Humor and  its Intensity",
    "abstract": "Prerecorded laughter accompanying dialog in comedy TV shows encourages the\naudience to laugh by clearly marking humorous moments in the show. We present\nan approach for automatically detecting humor in the Friends TV show using\nmultimodal data. Our model is capable of recognizing whether an utterance is\nhumorous or not and assess the intensity of it. We use the prerecorded laughter\nin the show as annotation as it marks humor and the length of the audience's\nlaughter tells us how funny a given joke is. We evaluate the model on episodes\nthe model has not been exposed to during the training phase. Our results show\nthat the model is capable of correctly detecting whether an utterance is\nhumorous 78% of the time and how long the audience's laughter reaction should\nlast with a mean absolute error of 600 milliseconds.",
    "descriptor": "\nComments: Outstanding paper award in COLING 2022\n",
    "authors": [
      "Khalid Alnajjar",
      "Mika H\u00e4m\u00e4l\u00e4inen",
      "J\u00f6rg Tiedemann",
      "Jorma Laaksonen",
      "Mikko Kurimo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01889"
  },
  {
    "id": "arXiv:2211.01905",
    "title": "The Complexity of Pattern Counting in Directed Graphs, Parameterised by  the Outdegree",
    "abstract": "We study the fixed-parameter tractability of the following fundamental\nproblem: given two directed graphs $\\vec H$ and $\\vec G$, count the number of\ncopies of $\\vec H$ in $\\vec G$. The standard setting, where the tractability is\nwell understood, uses only $|\\vec H|$ as a parameter. In this paper we take a\nstep forward, and adopt as a parameter $|\\vec H|+d(\\vec G)$, where $d(\\vec G)$\nis the maximum outdegree of $|\\vec G|$. Under this parameterization, we\ncompletely characterize the fixed-parameter tractability of the problem in both\nits non-induced and induced versions through two novel structural parameters,\nthe fractional cover number $\\rho^*$ and the source number $\\alpha_s$. On the\none hand we give algorithms with running time $f(|\\vec H|,d(\\vec G)) \\cdot\n|\\vec G|^{\\rho^*\\!(\\vec H)+O(1)}$ and $f(|\\vec H|,d(\\vec G)) \\cdot |\\vec\nG|^{\\alpha_s(\\vec H)+O(1)}$ for counting respectively the copies and induced\ncopies of $\\vec H$ in $\\vec G$; on the other hand we show that, unless the\nExponential Time Hypothesis fails, for any class $\\vec C$ of directed graphs\nthe (induced) counting problem is fixed-parameter tractable if and only if\n$\\rho^*(\\vec C)$ ($\\alpha_s(\\vec C)$) is bounded. These results explain how the\norientation of the pattern can make counting easy or hard, and prove that a\nclassic algorithm by Chiba and Nishizeki and its extensions (Chiba, Nishizeki\nSICOMP 85; Bressan Algorithmica 21) are optimal unless ETH fails.",
    "descriptor": "\nComments: 47 pages, 1 figure, abstract shortened due to arXiv requirements\n",
    "authors": [
      "Marco Bressan",
      "Matthias Lanzinger",
      "Marc Roth"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.01905"
  },
  {
    "id": "arXiv:2211.01907",
    "title": "The Polyhedral Geometry of Truthful Auctions",
    "abstract": "The difference set of an outcome in an auction is the set of types that the\nauction mechanism maps to the outcome. We give a complete characterization of\nthe geometry of the difference sets that can appear for a dominant strategy\nincentive compatible multi-unit auction showing that they correspond to regular\nsubdivisions of the unit cube. This observation is then used to construct\nmechanisms that are robust in the sense that the set of items allocated to a\nplayer does change only slightly when the player's reported type is changed\nslightly.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Michael Joswig",
      "Max Klimm",
      "Sylvain Spitz"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2211.01907"
  },
  {
    "id": "arXiv:2211.01910",
    "title": "Large Language Models Are Human-Level Prompt Engineers",
    "abstract": "By conditioning on natural language instructions, large language models\n(LLMs) have displayed impressive capabilities as general-purpose computers.\nHowever, task performance depends significantly on the quality of the prompt\nused to steer the model, and most effective prompts have been handcrafted by\nhumans. Inspired by classical program synthesis and the human approach to\nprompt engineering, we propose Automatic Prompt Engineer (APE) for automatic\ninstruction generation and selection. In our method, we treat the instruction\nas the \"program,\" optimized by searching over a pool of instruction candidates\nproposed by an LLM in order to maximize a chosen score function. To evaluate\nthe quality of the selected instruction, we evaluate the zero-shot performance\nof another LLM following the selected instruction. Experiments on 24 NLP tasks\nshow that our automatically generated instructions outperform the prior LLM\nbaseline by a large margin and achieve better or comparable performance to the\ninstructions generated by human annotators on 19/24 tasks. We conduct extensive\nqualitative and quantitative analyses to explore the performance of APE. We\nshow that APE-engineered prompts can be applied to steer models toward\ntruthfulness and/or informativeness, as well as to improve few-shot learning\nperformance by simply prepending them to standard in-context learning prompts.\nPlease check out our webpage at\nhttps://sites.google.com/view/automatic-prompt-engineer.",
    "descriptor": "",
    "authors": [
      "Yongchao Zhou",
      "Andrei Ioan Muresanu",
      "Ziwen Han",
      "Keiran Paster",
      "Silviu Pitis",
      "Harris Chan",
      "Jimmy Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01910"
  },
  {
    "id": "arXiv:2211.01912",
    "title": "Matching Augmentation via Simultaneous Contractions",
    "abstract": "We consider the matching augmentation problem (MAP), where a matching of a\ngraph needs to be extended into a $2$-edge-connected spanning subgraph by\nadding the minimum number of edges to it. We present a polynomial-time\nalgorithm with an approximation ratio of $13/8 = 1.625$ improving upon an\nearlier $5/3$-approximation. The improvement builds on a new\n$\\alpha$-approximation preserving reduction for any $\\alpha\\geq 3/2$ from\narbitrary MAP instances to well-structured instances that do not contain\ncertain forbidden structures like parallel edges, small separators, and\ncontractible subgraphs. We further introduce, as key ingredients, the technique\nof repeated simultaneous contractions and provide improved lower bounds for\ninstances that cannot be contracted.",
    "descriptor": "\nComments: 59 pages, 16 figures\n",
    "authors": [
      "Mohit Garg",
      "Felix Hommelsheim",
      "Nicole Megow"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.01912"
  },
  {
    "id": "arXiv:2211.01914",
    "title": "FedGen: Generalizable Federated Learning",
    "abstract": "Existing federated learning models that follow the standard risk minimization\nparadigm of machine learning often fail to generalize in the presence of\nspurious correlations in the training data. In many real-world distributed\nsettings, spurious correlations exist due to biases and data sampling issues on\ndistributed devices or clients that can erroneously influence models. Current\ngeneralization approaches are designed for centralized training and attempt to\nidentify features that have an invariant causal relationship with the target,\nthereby reducing the effect of spurious features. However, such invariant risk\nminimization approaches rely on apriori knowledge of training data\ndistributions which is hard to obtain in many applications. In this work, we\npresent a generalizable federated learning framework called FedGen, which\nallows clients to identify and distinguish between spurious and invariant\nfeatures in a collaborative manner without prior knowledge of training\ndistributions. We evaluate our approach on real-world datasets from different\ndomains and show that FedGen results in models that achieve significantly\nbetter generalization than current federated learning approaches.",
    "descriptor": "",
    "authors": [
      "Praveen Venkateswaran",
      "Vatche Isahagian",
      "Vinod Muthusamy",
      "Nalini Venkatasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01914"
  },
  {
    "id": "arXiv:2211.01915",
    "title": "Uncertainty Quantification for Rule-Based Models",
    "abstract": "Rule-based classification models described in the language of logic directly\npredict boolean values, rather than modeling a probability and translating it\ninto a prediction as done in statistical models. The vast majority of existing\nuncertainty quantification approaches rely on models providing continuous\noutput not available to rule-based models. In this work, we propose an\nuncertainty quantification framework in the form of a meta-model that takes any\nbinary classifier with binary output as a black box and estimates the\nprediction accuracy of that base model at a given input along with a level of\nconfidence on that estimation. The confidence is based on how well that input\nregion is explored and is designed to work in any OOD scenario. We demonstrate\nthe usefulness of this uncertainty model by building an abstaining classifier\npowered by it and observing its performance in various scenarios.",
    "descriptor": "",
    "authors": [
      "Yusik Kim"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01915"
  },
  {
    "id": "arXiv:2211.01916",
    "title": "Improved Analysis of Score-based Generative Modeling: User-Friendly  Bounds under Minimal Smoothness Assumptions",
    "abstract": "In this paper, we focus on the theoretical analysis of diffusion-based\ngenerative modeling. Under an $L^2$-accurate score estimator, we provide\nconvergence guarantees with polynomial complexity for any data distribution\nwith second-order moment, by either employing an early stopping technique or\nassuming smoothness condition on the score function of the data distribution.\nOur result does not rely on any log-concavity or functional inequality\nassumption and has a logarithmic dependence on the smoothness. In particular,\nwe show that under only a finite second moment condition, approximating the\nfollowing in KL divergence in $\\epsilon$-accuracy can be done in $\\tilde\nO\\left(\\frac{d^2 \\log^2 (1/\\delta)}{\\epsilon^2}\\right)$ steps: 1) the\nvariance-$\\delta$ Gaussian perturbation of any data distribution; 2) data\ndistributions with $1/\\delta$-smooth score functions. Our theoretical analysis\nalso provides quantitative comparison between different discrete approximations\nand may guide the choice of discretization points in practice.",
    "descriptor": "",
    "authors": [
      "Hongrui Chen",
      "Holden Lee",
      "Jianfeng Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01916"
  },
  {
    "id": "arXiv:2211.01917",
    "title": "Expanding Accurate Person Recognition to New Altitudes and Ranges: The  BRIAR Dataset",
    "abstract": "Face recognition technology has advanced significantly in recent years due\nlargely to the availability of large and increasingly complex training datasets\nfor use in deep learning models. These datasets, however, typically comprise\nimages scraped from news sites or social media platforms and, therefore, have\nlimited utility in more advanced security, forensics, and military\napplications. These applications require lower resolution, longer ranges, and\nelevated viewpoints. To meet these critical needs, we collected and curated the\nfirst and second subsets of a large multi-modal biometric dataset designed for\nuse in the research and development (R&D) of biometric recognition technologies\nunder extremely challenging conditions. Thus far, the dataset includes more\nthan 350,000 still images and over 1,300 hours of video footage of\napproximately 1,000 subjects. To collect this data, we used Nikon DSLR cameras,\na variety of commercial surveillance cameras, specialized long-rage R&D\ncameras, and Group 1 and Group 2 UAV platforms. The goal is to support the\ndevelopment of algorithms capable of accurately recognizing people at ranges up\nto 1,000 m and from high angles of elevation. These advances will include\nimprovements to the state of the art in face recognition and will support new\nresearch in the area of whole-body recognition using methods based on gait and\nanthropometry. This paper describes methods used to collect and curate the\ndataset, and the dataset's characteristics at the current stage.",
    "descriptor": "",
    "authors": [
      "David Cornett III",
      "Joel Brogan",
      "Nell Barber",
      "Deniz Aykac",
      "Seth Baird",
      "Nick Burchfield",
      "Carl Dukes",
      "Andrew Duncan",
      "Regina Ferrell",
      "Jim Goddard",
      "Gavin Jager",
      "Matt Larson",
      "Bart Murphy",
      "Christi Johnson",
      "Ian Shelley",
      "Nisha Srinivas",
      "Brandon Stockwell",
      "Leanne Thompson",
      "Matt Yohe",
      "Robert Zhang",
      "Scott Dolvin",
      "Hector J. Santos-Villalobos",
      "David S. Bolme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01917"
  },
  {
    "id": "arXiv:2211.01924",
    "title": "A New Agent-Based Intelligent Network Architecture",
    "abstract": "The advent of 5G and the design of its architecture has become possible\nbecause of the previous individual scientific works and standardization efforts\non cloud computing and network softwarization. Software-defined Networking and\nNetwork Function Virtualization started separately to find their convolution\ninto 5G network architecture. Then, the ongoing design of the future beyond 5G\n(B5G) and 6G network architecture cannot overlook the pivotal inputs of\ndifferent independent standardization efforts about autonomic networking,\nservice-based communication systems, and multi-access edge computing. This\narticle provides the design and the characteristics of an agent-based,\nsoftwarized, and intelligent architecture, which coherently condenses and\nmerges the independent proposed architectural works by different\nstandardization working groups and bodies. This novel work is a helpful means\nfor the design and standardization process of the futureB5G and 6G network\narchitecture.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Sisay Tadesse Arzo",
      "Domenico Scotece",
      "Riccardo Bassoli",
      "Fabrizio Granelli",
      "Luca Foschini",
      "Frank H.P. Fitzek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.01924"
  },
  {
    "id": "arXiv:2211.01926",
    "title": "Swelling-induced pattern transformations of periodic hydrogels -- from  the wrinkling of internal surfaces to the buckling of thin films",
    "abstract": "We investigate pattern transformations of periodic hydrogel systems that are\ntriggered by swelling-induced structural instabilities. The types of\nmicrostructures considered in the present work include single-phase and\ntwo-phase voided hydrogel structures as well as reinforced hydrogel thin films.\nWhile the observed transformations of the single-phase structures show good\nagreement with experimental findings, the two-phase materials provide novel\npatterns associated with wrinkling of internal surfaces. Furthermore, an\nextensive parametric study on the reinforced hydrogel thin films reveals new\nopportunities for the design of complex out-of-plane surface modes caused by\nswelling-induced instabilities. Next to the mentioned buckling-type\ninstabilities, we encountered the development of micro-creases at the internal\nsurfaces of periodic media before the loss of strong ellipticity of effective\nmoduli.",
    "descriptor": "",
    "authors": [
      "Elten Polukhov",
      "Laura Pytel",
      "Marc-Andre Keip"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.01926"
  },
  {
    "id": "arXiv:2211.01928",
    "title": "MPI-based Evaluation of Coordinator Election Algorithms",
    "abstract": "In this paper, we detail how two types of distributed coordinator election\nalgorithms can be compared in terms of performance based on an evaluation on\nthe High Performance Computing (HPC) infrastructure. An experimental approach\nbased on an MPI (Message Passing Interface) implementation is presented, with\nthe goal to characterize the relevant evaluation metrics based on statistical\nprocessing of the results. The presented approach can be used to learn master\nstudents of a course on distributed software the basics of algorithms for\ncoordinator election, and how to conduct an experimental performance evaluation\nstudy. Finally, use cases where distributed coordinator election algorithms are\nuseful are presented.",
    "descriptor": "",
    "authors": [
      "Filip De Turck"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01928"
  },
  {
    "id": "arXiv:2211.01930",
    "title": "Photorealistic Facial Wrinkles Removal",
    "abstract": "Editing and retouching facial attributes is a complex task that usually\nrequires human artists to obtain photo-realistic results. Its applications are\nnumerous and can be found in several contexts such as cosmetics or digital\nmedia retouching, to name a few. Recently, advancements in conditional\ngenerative modeling have shown astonishing results at modifying facial\nattributes in a realistic manner. However, current methods are still prone to\nartifacts, and focus on modifying global attributes like age and gender, or\nlocal mid-sized attributes like glasses or moustaches. In this work, we revisit\na two-stage approach for retouching facial wrinkles and obtain results with\nunprecedented realism. First, a state of the art wrinkle segmentation network\nis used to detect the wrinkles within the facial region. Then, an inpainting\nmodule is used to remove the detected wrinkles, filling them in with a texture\nthat is statistically consistent with the surrounding skin. To achieve this, we\nintroduce a novel loss term that reuses the wrinkle segmentation network to\npenalize those regions that still contain wrinkles after the inpainting. We\nevaluate our method qualitatively and quantitatively, showing state of the art\nresults for the task of wrinkle removal. Moreover, we introduce the first\nhigh-resolution dataset, named FFHQ-Wrinkles, to evaluate wrinkle detection\nmethods.",
    "descriptor": "",
    "authors": [
      "Marcelo Sanchez",
      "Gil Triginer",
      "Coloma Ballester",
      "Lara Raad",
      "Eduard Ramon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01930"
  },
  {
    "id": "arXiv:2211.01939",
    "title": "Empirical Analysis of Model Selection for Heterogenous Causal Effect  Estimation",
    "abstract": "We study the problem of model selection in causal inference, specifically for\nthe case of conditional average treatment effect (CATE) estimation under binary\ntreatments. Unlike model selection in machine learning, we cannot use the\ntechnique of cross-validation here as we do not observe the counterfactual\npotential outcome for any data point. Hence, we need to design model selection\ntechniques that do not explicitly rely on counterfactual data. As an\nalternative to cross-validation, there have been a variety of proxy metrics\nproposed in the literature, that depend on auxiliary nuisance models also\nestimated from the data (propensity score model, outcome regression model).\nHowever, the effectiveness of these metrics has only been studied on synthetic\ndatasets as we can observe the counterfactual data for them. We conduct an\nextensive empirical analysis to judge the performance of these metrics, where\nwe utilize the latest advances in generative modeling to incorporate multiple\nrealistic datasets. We evaluate 9 metrics on 144 datasets for selecting between\n415 estimators per dataset, including datasets that closely mimic real-world\ndatasets. Further, we use the latest techniques from AutoML to ensure\nconsistent hyperparameter selection for nuisance models for a fair comparison\nacross metrics.",
    "descriptor": "\nComments: Preprint. Under Review\n",
    "authors": [
      "Divyat Mahajan",
      "Ioannis Mitliagkas",
      "Brady Neal",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.01939"
  },
  {
    "id": "arXiv:2211.01941",
    "title": "DyOb-SLAM : Dynamic Object Tracking SLAM System",
    "abstract": "Simultaneous Localization & Mapping (SLAM) is the process of building a\nmutual relationship between localization and mapping of the subject in its\nsurrounding environment. With the help of different sensors, various types of\nSLAM systems have developed to deal with the problem of building the\nrelationship between localization and mapping. A limitation in the SLAM process\nis the lack of consideration of dynamic objects in the mapping of the\nenvironment. We propose the Dynamic Object Tracking SLAM (DyOb-SLAM), which is\na Visual SLAM system that can localize and map the surrounding dynamic objects\nin the environment as well as track the dynamic objects in each frame. With the\nhelp of a neural network and a dense optical flow algorithm, dynamic objects\nand static objects in an environment can be differentiated. DyOb-SLAM creates\ntwo separate maps for both static and dynamic contents. For the static\nfeatures, a sparse map is obtained. For the dynamic contents, a trajectory\nglobal map is created as output. As a result, a frame to frame real-time based\ndynamic object tracking system is obtained. With the pose calculation of the\ndynamic objects and camera, DyOb-SLAM can estimate the speed of the dynamic\nobjects with time. The performance of DyOb-SLAM is observed by comparing it\nwith a similar Visual SLAM system, VDO-SLAM and the performance is measured by\ncalculating the camera and object pose errors as well as the object speed\nerror.",
    "descriptor": "",
    "authors": [
      "Rushmian Annoy Wadud",
      "Wei Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01941"
  },
  {
    "id": "arXiv:2211.01945",
    "title": "Distributed Maximal Matching and Maximal Independent Set on Hypergraphs",
    "abstract": "We investigate the distributed complexity of maximal matching and maximal\nindependent set (MIS) in hypergraphs in the LOCAL model. A maximal matching of\na hypergraph $H=(V_H,E_H)$ is a maximal disjoint set $M\\subseteq E_H$ of\nhyperedges and an MIS $S\\subseteq V_H$ is a maximal set of nodes such that no\nhyperedge is fully contained in $S$. Both problems can be solved by a simple\nsequential greedy algorithm, which can be implemented naively in $O(\\Delta r +\n\\log^* n)$ rounds, where $\\Delta$ is the maximum degree, $r$ is the rank, and\n$n$ is the number of nodes.\nWe show that for maximal matching, this naive algorithm is optimal in the\nfollowing sense. Any deterministic algorithm for solving the problem requires\n$\\Omega(\\min\\{\\Delta r, \\log_{\\Delta r} n\\})$ rounds, and any randomized one\nrequires $\\Omega(\\min\\{\\Delta r, \\log_{\\Delta r} \\log n\\})$ rounds. Hence, for\nany algorithm with a complexity of the form $O(f(\\Delta, r) + g(n))$, we have\n$f(\\Delta, r) \\in \\Omega(\\Delta r)$ if $g(n)$ is not too large, and in\nparticular if $g(n) = \\log^* n$ (which is the optimal asymptotic dependency on\n$n$ due to Linial's lower bound [FOCS'87]). Our lower bound proof is based on\nthe round elimination framework, and its structure is inspired by a new round\nelimination fixed point that we give for the $\\Delta$-vertex coloring problem\nin hypergraphs.\nFor the MIS problem on hypergraphs, we show that for $\\Delta\\ll r$, there are\nsignificant improvements over the naive $O(\\Delta r + \\log^* n)$-round\nalgorithm. We give two deterministic algorithms for the problem. We show that a\nhypergraph MIS can be computed in $O(\\Delta^2\\cdot\\log r + \\Delta\\cdot\\log\nr\\cdot \\log^* r + \\log^* n)$ rounds. We further show that at the cost of a\nworse dependency on $\\Delta$, the dependency on $r$ can be removed almost\nentirely, by giving an algorithm with complexity $\\Delta^{O(\\Delta)}\\cdot\\log^*\nr + O(\\log^* n)$.",
    "descriptor": "",
    "authors": [
      "Alkida Balliu",
      "Sebastian Brandt",
      "Fabian Kuhn",
      "Dennis Olivetti"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01945"
  },
  {
    "id": "arXiv:2211.01946",
    "title": "Revisiting and Optimising a CNN Colour Constancy Method for  Multi-Illuminant Estimation",
    "abstract": "The aim of colour constancy is to discount the effect of the scene\nillumination from the image colours and restore the colours of the objects as\ncaptured under a 'white' illuminant. For the majority of colour constancy\nmethods, the first step is to estimate the scene illuminant colour. Generally,\nit is assumed that the illumination is uniform in the scene. However, real\nworld scenes have multiple illuminants, like sunlight and spot lights all\ntogether in one scene. We present in this paper a simple yet very effective\nframework using a deep CNN-based method to estimate and use multiple\nilluminants for colour constancy. Our approach works well in both the multi and\nsingle illuminant cases. The output of the CNN method is a region-wise estimate\nmap of the scene which is smoothed and divided out from the image to perform\ncolour constancy. The method that we propose outperforms other recent and state\nof the art methods and has promising visual results.",
    "descriptor": "",
    "authors": [
      "Ghalia Hemrit",
      "Joseph Meehan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01946"
  },
  {
    "id": "arXiv:2211.01948",
    "title": "Efficiently Trained Mongolian Text-to-Speech System Based On FullConv",
    "abstract": "Recurrent Neural Networks (RNNs) have become the standard modeling technique\nfor sequence data, and are used in a number of novel text-to-speech models.\nHowever, training a TTS model including RNN components has certain requirements\nfor GPU performance and takes a long time. In contrast, studies have shown that\nCNN-based sequence synthesis technology can greatly reduce training time in\ntext-to-speech models while ensuring a certain performance due to its high\nparallelism. We propose a new text-to-speech system based on deep convolutional\nneural networks that does not employ any RNN components (recurrent units). At\nthe same time, we improve the generality and robustness of our model through a\nseries of data augmentation methods such as Time Warping, Frequency Mask, and\nTime Mask. The final experimental results show that the TTS model using only\nthe CNN component can reduce the training time compared to the classic TTS\nmodels such as Tacotron while ensuring the quality of the synthesized speech.",
    "descriptor": "",
    "authors": [
      "ZiQi Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01948"
  },
  {
    "id": "arXiv:2211.01950",
    "title": "Unlocking the potential of two-point cells for energy-efficient training  of deep nets",
    "abstract": "Context-sensitive two-point layer 5 pyramidal cells (L5PC) were discovered as\nlong ago as 1999. However, the potential of this discovery to provide useful\nneural computation has yet to be demonstrated. Here we show for the first time\nhow a transformative L5PC-driven deep neural network (DNN), termed the\nmultisensory cooperative computing (MCC) architecture, can effectively process\nlarge amounts of heterogeneous real-world audio-visual (AV) data, using far\nless energy compared to best available `point' neuron-driven DNNs. A novel\nhighly-distributed parallel implementation on a Xilinx UltraScale+ MPSoC device\nestimates energy savings up to $245759 \\times 50000$ $\\mu$J (i.e., $62\\%$ less\nthan the baseline model in a semi-supervised learning setup) where a single\nsynapse consumes $8e^{-5}\\mu$J. In a supervised learning setup, the\nenergy-saving can potentially reach up to 1250x less (per feedforward\ntransmission) than the baseline model. This remarkable performance in pilot\nexperiments demonstrates the embodied neuromorphic intelligence of our proposed\nL5PC based MCC architecture that contextually selects the most salient and\nrelevant information for onward transmission, from overwhelmingly large\nmultimodal information utilised at the early stages of on-chip training. Our\nproposed approach opens new cross-disciplinary avenues for future on-chip DNN\ntraining implementations and posits a radical shift in current neuromorphic\ncomputing paradigms.",
    "descriptor": "",
    "authors": [
      "Ahsan Adeel",
      "Adewale Adetomi",
      "Khubaib Ahmed",
      "Amir Hussain",
      "Tughrul Arslan",
      "W.A. Phillips"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01950"
  },
  {
    "id": "arXiv:2211.01952",
    "title": "Spiking Variational Graph Auto-Encoders for Efficient Graph  Representation Learning",
    "abstract": "Graph representation learning is a fundamental research issue and benefits a\nwide range of applications on graph-structured data. Conventional artificial\nneural network-based methods such as graph neural networks (GNNs) and\nvariational graph auto-encoders (VGAEs) have achieved promising results in\nlearning on graphs, but they suffer from extremely high energy consumption\nduring training and inference stages. Inspired by the bio-fidelity and\nenergy-efficiency of spiking neural networks (SNNs), recent methods attempt to\nadapt GNNs to the SNN framework by substituting spiking neurons for the\nactivation functions. However, existing SNN-based GNN methods cannot be applied\nto the more general multi-node representation learning problem represented by\nlink prediction. Moreover, these methods did not fully exploit the bio-fidelity\nof SNNs, as they still require costly multiply-accumulate (MAC) operations,\nwhich severely harm the energy efficiency. To address the above issues and\nimprove energy efficiency, in this paper, we propose an SNN-based deep\ngenerative method, namely the Spiking Variational Graph Auto-Encoders (S-VGAE)\nfor efficient graph representation learning. To deal with the multi-node\nproblem, we propose a probabilistic decoder that generates binary latent\nvariables as spiking node representations and reconstructs graphs via the\nweighted inner product. To avoid the MAC operations for energy efficiency, we\nfurther decouple the propagation and transformation layers of conventional GNN\naggregators. We conduct link prediction experiments on multiple benchmark graph\ndatasets, and the results demonstrate that our model consumes significantly\nlower energy with the performances superior or comparable to other ANN- and\nSNN-based methods for graph representation learning.",
    "descriptor": "",
    "authors": [
      "Hanxuan Yang",
      "Ruike Zhang",
      "Qingchao Kong",
      "Wenji Mao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01952"
  },
  {
    "id": "arXiv:2211.01954",
    "title": "A BERT-based Deep Learning Approach for Reputation Analysis in Social  Media",
    "abstract": "Social media has become an essential part of the modern lifestyle, with its\nusage being highly prevalent. This has resulted in unprecedented amounts of\ndata generated from users in social media, such as users' attitudes, opinions,\ninterests, purchases, and activities across various aspects of their lives.\nTherefore, in a world of social media, where its power has shifted to users,\nactions taken by companies and public figures are subject to constantly being\nunder scrutiny by influential global audiences. As a result, reputation\nmanagement in social media has become essential as companies and public figures\nneed to maintain their reputation to preserve their reputation capital.\nHowever, domain experts still face the challenge of lacking appropriate\nsolutions to automate reliable online reputation analysis. To tackle this\nchallenge, we proposed a novel reputation analysis approach based on the\npopular language model BERT (Bidirectional Encoder Representations from\nTransformers). The proposed approach was evaluated on the reputational polarity\ntask using RepLab 2013 dataset. Compared to previous works, we achieved 5.8%\nimprovement in accuracy, 26.9% improvement in balanced accuracy, and 21.8%\nimprovement in terms of F-score.",
    "descriptor": "\nComments: Accepted to the 19th IEEE/ACS International Conference on Computer Systems and Applications\n",
    "authors": [
      "Mohammad Wali Ur Rahman",
      "Sicong Shao",
      "Pratik Satam",
      "Salim Hariri",
      "Chris Padilla",
      "Zoe Taylor",
      "Carlos Nevarez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.01954"
  },
  {
    "id": "arXiv:2211.01957",
    "title": "Sub-network Multi-objective Evolutionary Algorithm for Filter Pruning",
    "abstract": "Filter pruning is a common method to achieve model compression and\nacceleration in deep neural networks (DNNs).Some research regarded filter\npruning as a combinatorial optimization problem and thus used evolutionary\nalgorithms (EA) to prune filters of DNNs. However, it is difficult to find a\nsatisfactory compromise solution in a reasonable time due to the complexity of\nsolution space searching. To solve this problem, we first formulate a\nmulti-objective optimization problem based on a sub-network of the full model\nand propose a Sub-network Multiobjective Evolutionary Algorithm (SMOEA) for\nfilter pruning. By progressively pruning the convolutional layers in groups,\nSMOEA can obtain a lightweight pruned result with better\nperformance.Experiments on VGG-14 model for CIFAR-10 verify the effectiveness\nof the proposed SMOEA. Specifically, the accuracy of the pruned model with\n16.56% parameters decreases by 0.28% only, which is better than the widely used\npopular filter pruning criteria.",
    "descriptor": "",
    "authors": [
      "Xuhua Li",
      "Weize Sun",
      "Lei Huang",
      "Shaowu Chen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01957"
  },
  {
    "id": "arXiv:2211.01958",
    "title": "An Efficient Approach with Dynamic Multi-Swarm of UAVs for Forest  Firefighting",
    "abstract": "In this paper, the Multi-Swarm Cooperative Information-driven search and\nDivide and Conquer mitigation control (MSCIDC) approach is proposed for faster\ndetection and mitigation of forest fire by reducing the loss of biodiversity,\nnutrients, soil moisture, and other intangible benefits. A swarm is a\ncooperative group of Unmanned Aerial Vehicles (UAVs) that fly together to\nsearch and quench the fire effectively. The multi-swarm cooperative\ninformation-driven search uses a multi-level search comprising cooperative\ninformation-driven exploration and exploitation for quick/accurate detection of\nfire location. The search level is selected based on the thermal sensor\ninformation about the potential fire area. The dynamicity of swarms, aided by\nglobal regulative repulsion and merging between swarms, reduces the detection\nand mitigation time compared to the existing methods. The local attraction\namong the members of the swarm helps the non-detector members to reach the fire\nlocation faster, and divide-and-conquer mitigation control ensures a\nnon-overlapping fire sector allocation for all members quenching the fire. The\nperformance of MSCIDC has been compared with different multi-UAV methods using\na simulated environment of pine forest. The performance clearly shows that\nMSCIDC mitigates fire much faster than the multi-UAV methods. The Monte-Carlo\nsimulation results indicate that the proposed method reduces the average forest\narea burnt by $65\\%$ and mission time by $60\\%$ compared to the best result\ncase of the multi-UAV approaches, guaranteeing a faster and successful mission.",
    "descriptor": "",
    "authors": [
      "Josy John",
      "K. Harikumar",
      "J. Senthilnath",
      "Suresh Sundaram"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01958"
  },
  {
    "id": "arXiv:2211.01959",
    "title": "An agent-based approach to procedural city generation incorporating Land  Use and Transport Interaction models",
    "abstract": "We apply the knowledge of urban settings established with the study of Land\nUse and Transport Interaction (LUTI) models to develop reward functions for an\nagent-based system capable of planning realistic artificial cities. The system\naims to replicate in the micro scale the main components of real settlements,\nsuch as zoning and accessibility in a road network. Moreover, we propose a\nnovel representation for the agent's environment that efficiently combines the\nroad graph with a discrete model for the land. Our system starts from an empty\nmap consisting only of the road network graph, and the agent incrementally\nexpands it by building new sites while distinguishing land uses between\nresidential, commercial, industrial, and recreational.",
    "descriptor": "\nComments: 12 pages, 6 figures, XIX Encontro Nacional de Intelig\\^encia Artificial e Computacional (ENIAC 2022)\n",
    "authors": [
      "Luiz Fernando Silva Eug\u00eanio dos Santos",
      "Claus Aranha",
      "Andr\u00e9 Ponce de Leon F de Carvalho"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01959"
  },
  {
    "id": "arXiv:2211.01962",
    "title": "A Posterior Sampling Framework for Interactive Decision Making",
    "abstract": "We study sample efficient reinforcement learning (RL) under the general\nframework of interactive decision making, which includes Markov decision\nprocess (MDP), partially observable Markov decision process (POMDP), and\npredictive state representation (PSR) as special cases. Toward finding the\nminimum assumption that empowers sample efficient learning, we propose a novel\ncomplexity measure, generalized eluder coefficient (GEC), which characterizes\nthe fundamental tradeoff between exploration and exploitation in online\ninteractive decision making. In specific, GEC captures the hardness of\nexploration by comparing the error of predicting the performance of the updated\npolicy with the in-sample training error evaluated on the historical data. We\nshow that RL problems with low GEC form a remarkably rich class, which subsumes\nlow Bellman eluder dimension problems, bilinear class, low witness rank\nproblems, PO-bilinear class, and generalized regular PSR, where generalized\nregular PSR, a new tractable PSR class identified by us, includes nearly all\nknown tractable POMDPs. Furthermore, in terms of algorithm design, we propose a\ngeneric posterior sampling algorithm, which can be implemented in both\nmodel-free and model-based fashion, under both fully observable and partially\nobservable settings. The proposed algorithm modifies the standard posterior\nsampling algorithm in two aspects: (i) we use an optimistic prior distribution\nthat biases towards hypotheses with higher values and (ii) a loglikelihood\nfunction is set to be the empirical loss evaluated on the historical data,\nwhere the choice of loss function supports both model-free and model-based\nlearning. We prove that the proposed algorithm is sample efficient by\nestablishing a sublinear regret upper bound in terms of GEC. In summary, we\nprovide a new and unified understanding of both fully observable and partially\nobservable RL.",
    "descriptor": "",
    "authors": [
      "Han Zhong",
      "Wei Xiong",
      "Sirui Zheng",
      "Liwei Wang",
      "Zhaoran Wang",
      "Zhuoran Yang",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01962"
  },
  {
    "id": "arXiv:2211.01963",
    "title": "Machine Learning Methods for Device Identification Using Wireless  Fingerprinting",
    "abstract": "Industrial Internet of Things (IoT) systems increasingly rely on wireless\ncommunication standards. In a common industrial scenario, indoor wireless IoT\ndevices communicate with access points to deliver data collected from\nindustrial sensors, robots and factory machines. Due to static or quasi-static\nlocations of IoT devices and access points, historical observations of IoT\ndevice channel conditions provide a possibility to precisely identify the\ndevice without observing its traditional identifiers (e.g., MAC or IP address).\nSuch device identification methods based on wireless fingerprinting gained\nincreased attention lately as an additional cyber-security mechanism for\ncritical IoT infrastructures. In this paper, we perform a systematic study of a\nlarge class of machine learning algorithms for device identification using\nwireless fingerprints for the most popular cellular and Wi-Fi IoT technologies.\nWe design, implement, deploy, collect relevant data sets, train and test a\nmultitude of machine learning algorithms, as a part of the complete end-to-end\nsolution design for device identification via wireless fingerprinting. The\nproposed solution is currently being deployed in a real-world industrial IoT\nenvironment as part of H2020 project COLLABS.",
    "descriptor": "\nComments: 7 pages, 9 figures, 2 tables, preprint\n",
    "authors": [
      "Sr\u0111an \u0160obot",
      "Vukan Ninkovi\u0107",
      "Dejan Vukobratovi\u0107",
      "Milan Pavlovi\u0107",
      "Milo\u0161 Radovanovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.01963"
  },
  {
    "id": "arXiv:2211.01964",
    "title": "Combining Contrastive and Non-Contrastive Losses for Fine-Tuning  Pretrained Models in Speech Analysis",
    "abstract": "Embedding paralinguistic properties is a challenging task as there are only a\nfew hours of training data available for domains such as emotional speech. One\nsolution to this problem is to pretrain a general self-supervised speech\nrepresentation model on large amounts of unlabeled speech. This pretrained\nmodel is then finetuned to a specific task. Paralinguistic properties however\nhave notoriously high class variance, making the finetuning ineffective. In\nthis work, we propose a two step approach to this. First we improve the\nembedding space, then we train an adapter to bridge the gap from the embedding\nspace to a classification task. In order to improve the class invariance we use\na combination of contrastive and non-contrastive losses to explicitly optimize\nfor class invariant, yet discriminative features. Our approach consistently\noutperforms baselines that are finetuned end-to-end on multiple tasks and\nsurpasses a benchmark on state-of-the-art emotion classification.",
    "descriptor": "\nComments: Accepted to IEEE SLT 2022\n",
    "authors": [
      "Florian Lux",
      "Ching-Yi Chen",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01964"
  },
  {
    "id": "arXiv:2211.01966",
    "title": "MarginNCE: Robust Sound Localization with a Negative Margin",
    "abstract": "The goal of this work is to localize sound sources in visual scenes with a\nself-supervised approach. Contrastive learning in the context of sound source\nlocalization leverages the natural correspondence between audio and visual\nsignals where the audio-visual pairs from the same source are assumed as\npositive, while randomly selected pairs are negatives. However, this approach\nbrings in noisy correspondences; for example, positive audio and visual pair\nsignals that may be unrelated to each other, or negative pairs that may contain\nsemantically similar samples to the positive one. Our key contribution in this\nwork is to show that using a less strict decision boundary in contrastive\nlearning can alleviate the effect of noisy correspondences in sound source\nlocalization. We propose a simple yet effective approach by slightly modifying\nthe contrastive loss with a negative margin. Extensive experimental results\nshow that our approach gives on-par or better performance than the\nstate-of-the-art methods. Furthermore, we demonstrate that the introduction of\na negative margin to existing methods results in a consistent improvement in\nperformance.",
    "descriptor": "\nComments: Submitted to ICASSP 2023. SOTA performance in Audio-Visual Sound Localization. 5 Pages\n",
    "authors": [
      "Sooyoung Park",
      "Arda Senocak",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.01966"
  },
  {
    "id": "arXiv:2211.01967",
    "title": "On a Calder\u00f3n preconditioner for the symmetric formulation of the  electroencephalography forward problem without barycentric refinements",
    "abstract": "We present a Calder\\'on preconditioning scheme for the symmetric formulation\nof the forward electroencephalographic (EEG) problem that cures both the dense\ndiscretization and the high-contrast breakdown. Unlike existing Calder\\'on\nschemes presented for the EEG problem, it is refinement-free, that is, the\nelectrostatic integral operators are not discretized with basis functions\ndefined on the barycentrically-refined dual mesh. In fact, in the\npreconditioner, we reuse the original system matrix thus reducing computational\nburden. Moreover, the proposed formulation gives rise to a symmetric,\npositive-definite system of linear equations, which allows the application of\nthe conjugate gradient method, an iterative method that exhibits a smaller\ncomputational cost compared to other Krylov subspace methods applicable to\nnon-symmetric problems. Numerical results corroborate the theoretical analysis\nand attest of the efficacy of the proposed preconditioning technique on both\ncanonical and realistic scenarios.",
    "descriptor": "",
    "authors": [
      "Viviana Giunzioni",
      "John E. Ortiz G.",
      "Adrien Merlini",
      "Simon B. Adrian",
      "Francesco P. Andriulli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.01967"
  },
  {
    "id": "arXiv:2211.01969",
    "title": "Grounding Scene Graphs on Natural Images via Visio-Lingual Message  Passing",
    "abstract": "This paper presents a framework for jointly grounding objects that follow\ncertain semantic relationship constraints given in a scene graph. A typical\nnatural scene contains several objects, often exhibiting visual relationships\nof varied complexities between them. These inter-object relationships provide\nstrong contextual cues toward improving grounding performance compared to a\ntraditional object query-only-based localization task. A scene graph is an\nefficient and structured way to represent all the objects and their semantic\nrelationships in the image. In an attempt towards bridging these two modalities\nrepresenting scenes and utilizing contextual information for improving object\nlocalization, we rigorously study the problem of grounding scene graphs on\nnatural images. To this end, we propose a novel graph neural network-based\napproach referred to as Visio-Lingual Message PAssing Graph Neural Network\n(VL-MPAG Net). In VL-MPAG Net, we first construct a directed graph with object\nproposals as nodes and an edge between a pair of nodes representing a plausible\nrelation between them. Then a three-step inter-graph and intra-graph message\npassing is performed to learn the context-dependent representation of the\nproposals and query objects. These object representations are used to score the\nproposals to generate object localization. The proposed method significantly\noutperforms the baselines on four public datasets.",
    "descriptor": "",
    "authors": [
      "Aditay Tripathi",
      "Anand Mishra",
      "Anirban Chakraborty"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01969"
  },
  {
    "id": "arXiv:2211.01970",
    "title": "AI enhanced finite element multiscale modelling and structural  uncertainty analysis of a functionally graded porous beam",
    "abstract": "The local geometrical randomness of metal foams brings complexities to the\nperformance prediction of porous structures. Although the relative density is\ncommonly deemed as the key factor, the stochasticity of internal cell sizes and\nshapes has an apparent effect on the porous structural behaviour but the\ncorresponding measurement is challenging. To address this issue, we are aimed\nto develop an assessment strategy for efficiently examining the foam properties\nby combining multiscale modelling and deep learning. The multiscale modelling\nis based on the finite element (FE) simulation employing representative volume\nelements (RVEs) with random cellular morphologies, mimicking the typical\nfeatures of closed-cell Aluminium foams. A deep learning database is\nconstructed for training the designed convolutional neural networks (CNNs) to\nestablish a direct link between the mesoscopic porosity characteristics and the\neffective Youngs modulus of foams. The error range of CNN models leads to an\nuncertain mechanical performance, which is further evaluated in a structural\nuncertainty analysis on the FG porous three-layer beam consisting of two thin\nhigh-density layers and a thick low-density one, where the imprecise CNN\npredicted moduli are represented as triangular fuzzy numbers in double\nparametric form. The uncertain beam bending deflections under a mid-span point\nload are calculated with the aid of Timoshenko beam theory and the Ritz method.\nOur findings suggest the success in training CNN models to estimate RVE modulus\nusing images with an average error of 5.92%. The evaluation of FG porous\nstructures can be significantly simplified with the proposed method and\nconnects to the mesoscopic cellular morphologies without establishing the\nmechanics model for local foams.",
    "descriptor": "\nComments: Book chapter in MACHINE LEARNING AIDED ANALYSIS, DESIGN, AND ADDITIVE MANUFACTURING OF FUNCTIONALLY GRADED POROUS COMPOSITE STRUCTURES, 20 pages, 10 figures\n",
    "authors": [
      "Da Chen",
      "Nima Emami",
      "Shahed Rezaei",
      "Philipp L. Rosendahl",
      "Bai-Xiang Xu",
      "Jens Schneider",
      "Kang Gao",
      "Jie Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01970"
  },
  {
    "id": "arXiv:2211.01972",
    "title": "The role of prior information and computational power in Machine  Learning",
    "abstract": "Science consists on conceiving hypotheses, confronting them with empirical\nevidence, and keeping only hypotheses which have not yet been falsified. Under\ndeductive reasoning they are conceived in view of a theory and confronted with\nempirical evidence in an attempt to falsify it, and under inductive reasoning\nthey are conceived based on observation, confronted with empirical evidence and\na theory is established based on the not falsified hypotheses. When the\nhypotheses testing can be performed with quantitative data, the confrontation\ncan be achieved with Machine Learning methods, whose quality is highly\ndependent on the hypotheses' complexity, hence on the proper insertion of prior\ninformation into the set of hypotheses seeking to decrease its complexity\nwithout loosing good hypotheses. However, Machine Learning tools have been\napplied under the pragmatic view of instrumentalism, which is concerned only\nwith the performance of the methods and not with the understanding of their\nbehavior, leading to methods which are not fully understood. In this context,\nwe discuss how prior information and computational power can be employed to\nsolve a learning problem, but while prior information and a careful design of\nthe hypotheses space has as advantage the interpretability of the results,\nemploying high computational power has the advantage of a higher performance.\nWe discuss why learning methods which combine both should work better from an\nunderstanding and performance perspective, arguing in favor of basic\ntheoretical research on Machine Learning, in special about how properties of\nclassifiers may be identified in parameters of modern learning models.",
    "descriptor": "",
    "authors": [
      "Diego Marcondes",
      "Adilson Simonis",
      "Junior Barrera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01972"
  },
  {
    "id": "arXiv:2211.01976",
    "title": "Enhancing Patent Retrieval using Text and Knowledge Graph Embeddings: A  Technical Note",
    "abstract": "Patent retrieval influences several applications within engineering design\nresearch, education, and practice as well as applications that concern\ninnovation, intellectual property, and knowledge management etc. In this\narticle, we propose a method to retrieve patents relevant to an initial set of\npatents, by synthesizing state-of-the-art techniques among natural language\nprocessing and knowledge graph embedding. Our method involves a patent\nembedding that captures text, citation, and inventor information, which\nindividually represent different facets of knowledge communicated through a\npatent document. We obtain text embeddings using Sentence-BERT applied to\ntitles and abstracts. We obtain citation and inventor embeddings through TransE\nthat is trained using the corresponding knowledge graphs. We identify using a\nclassification task that the concatenation of text, citation, and inventor\nembeddings offers a plausible representation of a patent. While the proposed\npatent embedding could be used to associate a pair of patents, we observe using\na recall task that multiple initial patents could be associated with a target\npatent using mean cosine similarity, which could then be utilized to rank all\ntarget patents and retrieve the most relevant ones. We apply the proposed\npatent retrieval method to a set of patents corresponding to a product family\nand an inventor's portfolio.",
    "descriptor": "",
    "authors": [
      "L Siddharth",
      "Guangtong Li",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.01976"
  },
  {
    "id": "arXiv:2211.01979",
    "title": "Tiny-Attention Adapter: Contexts Are More Important Than the Number of  Parameters",
    "abstract": "Adapter-tuning is a paradigm that transfers a pretrained language model to\ndownstream tasks by adding and tuning a small number of new parameters.\nPreviously proposed adapter architectures are all feed-forward neural networks.\nIn this paper, we investigate the effectiveness of using tiny-attention --\ni.e., attention with extremely small per-head dimensionality -- as adapters.\nOur tiny-attention adapter learns to modify the hidden states at each position\ndirectly conditioned on the hidden states at all the other positions, which is\nmissed by the previously proposed adapters. Moreover, we view its multiple\nattention heads as a mixture of experts and propose to average their weights\nduring deployment, which further reduces its inference computation cost. On the\nGLUE benchmark, our tiny-attention adapter outperforms the other\nparameter-efficient transfer learning methods as well as full fine-tuning while\nonly updating 0.05% of the parameters. On the FewGLUE benchmark, its\nperformance is comparable to that of GPT-3 and PET.",
    "descriptor": "\nComments: EMNLP 2022 camera-ready\n",
    "authors": [
      "Hongyu Zhao",
      "Hao Tan",
      "Hongyuan Mei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01979"
  },
  {
    "id": "arXiv:2211.01980",
    "title": "Learning to Configure Computer Networks with Neural Algorithmic  Reasoning",
    "abstract": "We present a new method for scaling automatic configuration of computer\nnetworks. The key idea is to relax the computationally hard search problem of\nfinding a configuration that satisfies a given specification into an\napproximate objective amenable to learning-based techniques. Based on this\nidea, we train a neural algorithmic model which learns to generate\nconfigurations likely to (fully or partially) satisfy a given specification\nunder existing routing protocols. By relaxing the rigid satisfaction\nguarantees, our approach (i) enables greater flexibility: it is\nprotocol-agnostic, enables cross-protocol reasoning, and does not depend on\nhardcoded rules; and (ii) finds configurations for much larger computer\nnetworks than previously possible. Our learned synthesizer is up to 490x faster\nthan state-of-the-art SMT-based methods, while producing configurations which\non average satisfy more than 93% of the provided requirements.",
    "descriptor": "",
    "authors": [
      "Luca Beurer-Kellner",
      "Martin Vechev",
      "Laurent Vanbever",
      "Petar Veli\u010dkovi\u0107"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01980"
  },
  {
    "id": "arXiv:2211.01981",
    "title": "Topic Taxonomy Expansion via Hierarchy-Aware Topic Phrase Generation",
    "abstract": "Topic taxonomies display hierarchical topic structures of a text corpus and\nprovide topical knowledge to enhance various NLP applications. To dynamically\nincorporate new topic information, several recent studies have tried to expand\n(or complete) a topic taxonomy by inserting emerging topics identified in a set\nof new documents. However, existing methods focus only on frequent terms in\ndocuments and the local topic-subtopic relations in a taxonomy, which leads to\nlimited topic term coverage and fails to model the global topic hierarchy. In\nthis work, we propose a novel framework for topic taxonomy expansion, named\nTopicExpan, which directly generates topic-related terms belonging to new\ntopics. Specifically, TopicExpan leverages the hierarchical relation structure\nsurrounding a new topic and the textual content of an input document for topic\nterm generation. This approach encourages newly-inserted topics to further\ncover important but less frequent terms as well as to keep their relation\nconsistency within the taxonomy. Experimental results on two real-world text\ncorpora show that TopicExpan significantly outperforms other baseline methods\nin terms of the quality of output taxonomies.",
    "descriptor": "\nComments: 14 pages, 7 figures, Findings of EMNLP 2022 (Long paper)\n",
    "authors": [
      "Dongha Lee",
      "Jiaming Shen",
      "Seonghyeon Lee",
      "Susik Yoon",
      "Hwanjo Yu",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01981"
  },
  {
    "id": "arXiv:2211.01984",
    "title": "Sybil-Proof Diffusion Auction in Social Networks",
    "abstract": "A diffusion auction is a market to sell commodities over a social network,\nwhere the challenge is to incentivize existing buyers to invite their neighbors\nin the network to join the market. Existing mechanisms have been designed to\nsolve the challenge in various settings, aiming at desirable properties such as\nnon-deficiency, incentive compatibility and social welfare maximization. Since\nthe mechanisms are employed in dynamic networks with ever-changing structures,\nbuyers could easily generate fake nodes in the network to manipulate the\nmechanisms for their own benefits, which is commonly known as the Sybil attack.\nWe observe that strategic agents may gain an unfair advantage in existing\nmechanisms through such attacks. To resist this potential attack, we propose\ntwo diffusion auction mechanisms, the Sybil tax mechanism (STM) and the Sybil\ncluster mechanism (SCM), to achieve both Sybil-proofness and incentive\ncompatibility in the single-item setting. Our proposal provides the first\nmechanisms to protect the interests of buyers against Sybil attacks with a mild\nsacrifice of social welfare and revenue.",
    "descriptor": "",
    "authors": [
      "Hongyin Chen",
      "Xiaotie Deng",
      "Ying Wang",
      "Yue Wu",
      "Dengji Zhao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01984"
  },
  {
    "id": "arXiv:2211.01987",
    "title": "Exact calculation of quantizer constants for arbitrary lattices",
    "abstract": "We present an algorithm for the computer-aided analytical construction of the\nVoronoi cells of lattices with known symmetry group. This algorithm is applied\nto the Coxeter-Todd lattice $K_{12}$ as well as to a family of lattices\nobtained from laminating $K_{12}$. This way, we obtain a locally optimal\nlattice quantizer in 13 dimensions representing a new best quantizer among the\nlattices with published exact quantizer constants.",
    "descriptor": "\nComments: 36 pages, 6 figures\n",
    "authors": [
      "Daniel Pook-Kolb",
      "Bruce Allen",
      "Erik Agrell"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2211.01987"
  },
  {
    "id": "arXiv:2211.01991",
    "title": "Leveraging Fully Observable Policies for Learning under Partial  Observability",
    "abstract": "Reinforcement learning in partially observable domains is challenging due to\nthe lack of observable state information. Thankfully, learning offline in a\nsimulator with such state information is often possible. In particular, we\npropose a method for partially observable reinforcement learning that uses a\nfully observable policy (which we call a state expert) during offline training\nto improve online performance. Based on Soft Actor-Critic (SAC), our agent\nbalances performing actions similar to the state expert and getting high\nreturns under partial observability. Our approach can leverage the\nfully-observable policy for exploration and parts of the domain that are fully\nobservable while still being able to learn under partial observability. On six\nrobotics domains, our method outperforms pure imitation, pure reinforcement\nlearning, the sequential or parallel combination of both types, and a recent\nstate-of-the-art method in the same setting. A successful policy transfer to a\nphysical robot in a manipulation task from pixels shows our approach's\npracticality in learning interesting policies under partial observability.",
    "descriptor": "\nComments: Accepted at the 2022 Conference on Robot Learning (CoRL), Auckland, New Zealand\n",
    "authors": [
      "Hai Nguyen",
      "Andrea Baisero",
      "Dian Wang",
      "Christopher Amato",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01991"
  },
  {
    "id": "arXiv:2211.01992",
    "title": "Characterizing Virtual Reality Software Testing",
    "abstract": "Virtual Reality (VR) is an emerging technique that provides a unique\nreal-time experience for users. VR technologies have provided revolutionary\nuser experiences in various scenarios (e.g., training, education,\nproduct/architecture design, gaming, remote conference/tour, etc.). However,\ntesting VR applications is challenging due to their nature which necessitates\nphysical interactivity, and their reliance on hardware systems. Despite the\nrecent advancements in VR technology and its usage scenarios, we still know\nlittle about VR application testing. To fill up this knowledge gap, we\nperformed an empirical study on 97 open-source VR applications including 28\nindustrial projects. Our analysis identified that 74.2% of the VR projects\nevaluated did not have any tests, and for the VR projects that did, the median\nfunctional-method to test-method ratio was low in comparison to other project\ncategories. Moreover, we uncovered tool support issues concerning the\nmeasurement of VR code coverage, and the code coverage and assertion density\nresults we were able to generate were also relatively low, as they respectively\nhad averages of 15.63% and 17.69%. Finally, through manual analysis of 220 test\ncases from four VR applications and 281 test cases from four non-VR\napplications, we identified that VR applications require specific categories of\ntest cases to ensure VR application quality attributes. We believe that our\nfindings constitute a call to action for the VR development community to\nimprove testing aspects and provide directions for software engineering\nresearchers to develop advanced techniques for automatic test case generation\nand test quality analysis for VR applications.",
    "descriptor": "",
    "authors": [
      "Dhia Elhaq Rzig",
      "Nafees Iqbal",
      "Isabella Attisano",
      "Xue Qin",
      "Foyzul Hassan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.01992"
  },
  {
    "id": "arXiv:2211.01993",
    "title": "Probing Statistical Representations For End-To-End ASR",
    "abstract": "End-to-End automatic speech recognition (ASR) models aim to learn a\ngeneralised speech representation to perform recognition. In this domain there\nis little research to analyse internal representation dependencies and their\nrelationship to modelling approaches. This paper investigates cross-domain\nlanguage model dependencies within transformer architectures using SVCCA and\nuses these insights to exploit modelling approaches. It was found that specific\nneural representations within the transformer layers exhibit correlated\nbehaviour which impacts recognition performance.\nAltogether, this work provides analysis of the modelling approaches affecting\ncontextual dependencies and ASR performance, and can be used to create or adapt\nbetter performing End-to-End ASR models and also for downstream tasks.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Anna Ollerenshaw",
      "Md Asif Jalal",
      "Thomas Hain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01993"
  },
  {
    "id": "arXiv:2211.01994",
    "title": "lilGym: Natural Language Visual Reasoning with Reinforcement Learning",
    "abstract": "We present lilGym, a new benchmark for language-conditioned reinforcement\nlearning in visual environments. lilGym is based on 2,661 highly-compositional\nhuman-written natural language statements grounded in an interactive visual\nenvironment. We annotate all statements with executable Python programs\nrepresenting their meaning to enable exact reward computation in every possible\nworld state. Each statement is paired with multiple start states and reward\nfunctions to form thousands of distinct Markov Decision Processes of varying\ndifficulty. We experiment with lilGym with different models and learning\nregimes. Our results and analysis show that while existing methods are able to\nachieve non-trivial performance, lilGym forms a challenging open problem.\nlilGym is available at https://lil.nlp.cornell.edu/lilgym/.",
    "descriptor": "",
    "authors": [
      "Anne Wu",
      "Kiant\u00e9 Brantley",
      "Noriyuki Kojima",
      "Yoav Artzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01994"
  },
  {
    "id": "arXiv:2211.01998",
    "title": "Driving innovation through project based learning: A pre-university  STEAM for Social Good initiative",
    "abstract": "The Covid pandemic is a clarion call for increased sensitivity to the\ninterconnected nature of social problems facing our world today. A\nfuture-oriented education on critical issues, such as those outlined in the\nUnited Nations Sustainable Development Goals (UN SDGs) and designing potential\nsolutions for such problems is an imperative skill that must be imparted to\nchildren to help them navigate their future in today's unpredictable world.\nTowards this goal, we have been conducting 3.5 month-long mentoring programs\nfor pre-university students in India to participate in a STEAM for Social Good\ninnovation challenge conducted annually by the Government of India. Using\ndigital and physical computing skills, we helped children explore creative\nsolutions for social problems through a constructionist approach to learning,\nwherein they ideated and reflected upon the problems in their communities. The\nchildren learnt the Engineering Design Thinking process and worked in online\ngroups of two or three, from concept to completion. Despite the constraints\nposed by the pandemic, they explored creative ways to think about design and\ninnovation. They completed a variety of tasks by making, tinkering,\nengineering, assembling, and programming to grasp the intricate relationship\nbetween software and hardware. Subsequently, the children showcased their\ncreative abilities through video storytelling to a panel of domain experts. In\nthis paper, we present the children's perspective of their experiences through\nthis journey, the evaluation metrics based on IEEE design principles, and our\nlearnings from conducting this initiative as a university-school partnership\nmodel for 84 middle and high school students. The aspirational intent of this\ninitiative is to make the children better social problem solvers and help them\nperceive social problems as opportunities to enhance life for themselves and\ntheir communities.",
    "descriptor": "\nComments: IEEE Frontier in Education 2022\n",
    "authors": [
      "Gayathri Manikutty",
      "Sreejith Sasidharan",
      "Bhavani Rao"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.01998"
  },
  {
    "id": "arXiv:2211.01999",
    "title": "Quantifying Model Uncertainty for Semantic Segmentation using Operators  in the RKHS",
    "abstract": "Deep learning models for semantic segmentation are prone to poor performance\nin real-world applications due to the highly challenging nature of the task.\nModel uncertainty quantification (UQ) is one way to address this issue of lack\nof model trustworthiness by enabling the practitioner to know how much to trust\na segmentation output. Current UQ methods in this application domain are mainly\nrestricted to Bayesian based methods which are computationally expensive and\nare only able to extract central moments of uncertainty thereby limiting the\nquality of their uncertainty estimates. We present a simple framework for\nhigh-resolution predictive uncertainty quantification of semantic segmentation\nmodels that leverages a multi-moment functional definition of uncertainty\nassociated with the model's feature space in the reproducing kernel Hilbert\nspace (RKHS). The multiple uncertainty functionals extracted from this\nframework are defined by the local density dynamics of the model's feature\nspace and hence automatically align themselves at the tail-regions of the\nintrinsic probability density function of the feature space (where uncertainty\nis the highest) in such a way that the successively higher order moments\nquantify the more uncertain regions. This leads to a significantly more\naccurate view of model uncertainty than conventional Bayesian methods.\nMoreover, the extraction of such moments is done in a single-shot computation\nmaking it much faster than Bayesian and ensemble approaches (that involve a\nhigh number of forward stochastic passes of the model to quantify its\nuncertainty). We demonstrate these advantages through experimental evaluations\nof our framework implemented over four different state-of-the-art model\narchitectures that are trained and evaluated on two benchmark road-scene\nsegmentation datasets (Camvid and Cityscapes).",
    "descriptor": "",
    "authors": [
      "Rishabh Singh",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.01999"
  },
  {
    "id": "arXiv:2211.02000",
    "title": "Dynamic Kernels and Channel Attention with Multi-Layer Embedding  Aggregation for Speaker Verification",
    "abstract": "State-of-the-art speaker verification frameworks have typically focused on\nspeech enhancement techniques with increasingly deeper (more layers) and wider\n(number of channels) models to improve their verification performance. Instead,\nthis paper proposes an approach to increase the model resolution capability\nusing attention-based dynamic kernels in a convolutional neural network to\nadapt the model parameters to be feature-conditioned. The attention weights on\nthe kernels are further distilled by channel attention and multi-layer feature\naggregation to learn global features from speech. This approach provides an\nefficient solution to improving representation capacity with lower data\nresources. This is due to the self-adaptation to inputs of the structures of\nthe model parameters. The proposed dynamic convolutional model achieved 1.62\\%\nEER and 0.18 miniDCF on the VoxCeleb1 test set and has a 17\\% relative\nimprovement compared to the ECAPA-TDNN.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Anna Ollerenshaw",
      "Md Asif Jalal",
      "Thomas Hain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02000"
  },
  {
    "id": "arXiv:2211.02001",
    "title": "Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language  Model",
    "abstract": "Progress in machine learning (ML) comes with a cost to the environment, given\nthat training ML models requires significant computational resources, energy\nand materials. In the present article, we aim to quantify the carbon footprint\nof BLOOM, a 176-billion parameter language model, across its life cycle. We\nestimate that BLOOM's final training emitted approximately 24.7 tonnes\nof~\\carboneq~if we consider only the dynamic power consumption, and 50.5 tonnes\nif we account for all processes ranging from equipment manufacturing to\nenergy-based operational consumption. We also study the energy requirements and\ncarbon emissions of its deployment for inference via an API endpoint receiving\nuser queries in real-time. We conclude with a discussion regarding the\ndifficulty of precisely estimating the carbon footprint of ML models and future\nresearch directions that can contribute towards improving carbon emissions\nreporting.",
    "descriptor": "",
    "authors": [
      "Alexandra Sasha Luccioni",
      "Sylvain Viguier",
      "Anne-Laure Ligozat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02001"
  },
  {
    "id": "arXiv:2211.02003",
    "title": "Single SMPC Invocation DPHelmet: Differentially Private Distributed  Learning on a Large Scale",
    "abstract": "Distributing machine learning predictors enables the collection of\nlarge-scale datasets while leaving sensitive raw data at trustworthy sites. We\nshow that locally training support vector machines (SVMs) and computing their\naverages leads to a learning technique that is scalable to a large number of\nusers, satisfies differential privacy, and is applicable to non-trivial tasks,\nsuch as CIFAR-10. For a large number of participants, communication cost is one\nof the main challenges. We achieve a low communication cost by requiring only a\nsingle invocation of an efficient secure multiparty summation protocol. By\nrelying on state-of-the-art feature extractors (SimCLR), we are able to utilize\ndifferentially private convex learners for non-trivial tasks such as CIFAR-10.\nOur experimental results illustrate that for $1{,}000$ users with $50$ data\npoints each, our scheme outperforms state-of-the-art scalable distributed\nlearning methods (differentially private federated learning, short DP-FL) while\nrequiring around $500$ times fewer communication costs: For CIFAR-10, we\nachieve a classification accuracy of $79.7\\,\\%$ for an $\\varepsilon = 0.59$\nwhile DP-FL achieves $57.6\\,\\%$. More generally, we prove learnability\nproperties for the average of such locally trained models: convergence and\nuniform stability. By only requiring strongly convex, smooth, and\nLipschitz-continuous objective functions, locally trained via stochastic\ngradient descent (SGD), we achieve a strong utility-privacy tradeoff.",
    "descriptor": "",
    "authors": [
      "Moritz Kirschte",
      "Sebastian Meiser",
      "Saman Ardalan",
      "Esfandiar Mohammadi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.02003"
  },
  {
    "id": "arXiv:2211.02004",
    "title": "Truthful Matching with Online Items and Offline Agents",
    "abstract": "We study truthful mechanisms for welfare maximization in online bipartite\nmatching. In our (multi-parameter) setting, every buyer is associated with a\n(possibly private) desired set of items, and has a private value for being\nassigned an item in her desired set. Unlike most online matching settings,\nwhere agents arrive online, in our setting the items arrive online in an\nadversarial order while the buyers are present for the entire duration of the\nprocess. This poses a significant challenge to the design of truthful\nmechanisms, due to the ability of buyers to strategize over future rounds. We\nprovide an almost full picture of the competitive ratios in different\nscenarios, including myopic vs. non-myopic agents, tardy vs. prompt payments,\nand private vs. public desired sets. Among other results, we identify the\nfrontier for which the celebrated $e/(e-1)$ competitive ratio for the\nvertex-weighted online matching of Karp, Vazirani and Vazirani extends to\ntruthful agents and online items.",
    "descriptor": "",
    "authors": [
      "Michal Feldman",
      "Federico Fusco",
      "Stefano Leonardi",
      "Simon Mauras",
      "Rebecca Reiffenh\u00e4user"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.02004"
  },
  {
    "id": "arXiv:2211.02006",
    "title": "SAP-DETR: Bridging the Gap Between Salient Points and Queries-Based  Transformer Detector for Fast Model Convergency",
    "abstract": "Recently, the dominant DETR-based approaches apply central-concept spatial\nprior to accelerate Transformer detector convergency. These methods gradually\nrefine the reference points to the center of target objects and imbue object\nqueries with the updated central reference information for spatially\nconditional attention. However, centralizing reference points may severely\ndeteriorate queries' saliency and confuse detectors due to the indiscriminative\nspatial prior. To bridge the gap between the reference points of salient\nqueries and Transformer detectors, we propose SAlient Point-based DETR\n(SAP-DETR) by treating object detection as a transformation from salient points\nto instance objects. In SAP-DETR, we explicitly initialize a query-specific\nreference point for each object query, gradually aggregate them into an\ninstance object, and then predict the distance from each side of the bounding\nbox to these points. By rapidly attending to query-specific reference region\nand other conditional extreme regions from the image features, SAP-DETR can\neffectively bridge the gap between the salient point and the query-based\nTransformer detector with a significant convergency speed. Our extensive\nexperiments have demonstrated that SAP-DETR achieves 1.4 times convergency\nspeed with competitive performance. Under the standard training scheme,\nSAP-DETR stably promotes the SOTA approaches by 1.0 AP. Based on ResNet-DC-101,\nSAP-DETR achieves 46.9 AP.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Yang Liu",
      "Yao Zhang",
      "Yixin Wang",
      "Yang Zhang",
      "Jiang Tian",
      "Zhongchao Shi",
      "Jianping Fan",
      "Zhiqiang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02006"
  },
  {
    "id": "arXiv:2211.02011",
    "title": "Inverse scaling can become U-shaped",
    "abstract": "Although scaling language models improves performance on a range of tasks,\nthere are apparently some scenarios where scaling hurts performance. For\ninstance, the Inverse Scaling Prize Round 1 identified four ''inverse scaling''\ntasks, for which performance gets worse for larger models. These tasks were\nevaluated on models of up to 280B parameters, trained up to 500 zettaFLOPs of\ncompute.\nThis paper takes a closer look at these four tasks. We evaluate models of up\nto 540B parameters, trained on five times more compute than those evaluated in\nthe Inverse Scaling Prize. With this increased range of model sizes and\ntraining compute, three out of the four tasks exhibit what we call ''U-shaped\nscaling'' -- performance decreases up to a certain model size, and then\nincreases again up to the largest model evaluated. One hypothesis is that\nU-shaped scaling occurs when a task comprises a ''true task'' and a\n''distractor task''. Medium-size models can do the distractor task, which hurts\nperformance, while only large-enough models can ignore the distractor task and\ndo the true task. The existence of U-shaped scaling implies that inverse\nscaling may not hold for larger models.\nSecond, we evaluate the inverse scaling tasks using chain-of-thought (CoT)\nprompting, in addition to basic prompting without CoT. With CoT prompting, all\nfour tasks show either U-shaped scaling or positive scaling, achieving perfect\nsolve rates on two tasks and several sub-tasks. This suggests that the term\n\"inverse scaling task\" is under-specified -- a given task may be inverse\nscaling for one prompt but positive or U-shaped scaling for a different prompt.",
    "descriptor": "",
    "authors": [
      "Jason Wei",
      "Yi Tay",
      "Quoc V. Le"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.02011"
  },
  {
    "id": "arXiv:2211.02013",
    "title": "Analyzing Performance Issues of Virtual Reality Applications",
    "abstract": "Extended Reality (XR) includes Virtual Reality (VR), Augmented Reality (AR)\nand Mixed Reality (MR). XR is an emerging technology that simulates a realistic\nenvironment for users. XR techniques have provided revolutionary user\nexperiences in various application scenarios (e.g., training, education,\nproduct/architecture design, gaming, remote conference/tour, etc.). Due to the\nhigh computational cost of rendering real-time animation in limited-resource\ndevices and constant interaction with user activity, XR applications often face\nperformance bottlenecks, and these bottlenecks create a negative impact on the\nuser experience of XR software. Thus, performance optimization plays an\nessential role in many industry-standard XR applications. Even though\nidentifying performance bottlenecks in traditional software (e.g., desktop\napplications) is a widely explored topic, those approaches cannot be directly\napplied within XR software due to the different nature of XR applications.\nMoreover, XR applications developed in different frameworks such as Unity and\nUnreal Engine show different performance bottleneck patterns and thus,\nbottleneck patterns of Unity projects can't be applied for Unreal Engine\n(UE)-based XR projects. To fill the knowledge gap for XR performance\noptimizations of Unreal Engine-based XR projects, we present the first\nempirical study on performance optimizations from seven UE XR projects, 78 UE\nXR discussion issues and three sources of UE documentation. Our analysis\nidentified 14 types of performance bugs, including 12 types of bugs related to\nUE settings issues and two types of CPP source code-related issues. To further\nassist developers in detecting performance bugs based on the identified bug\npatterns, we also developed a static analyzer, UEPerfAnalyzer, that can detect\nperformance bugs in both configuration files and source code.",
    "descriptor": "",
    "authors": [
      "Jason Hogan",
      "Aaron Salo",
      "Dhia Elhaq Rzig",
      "Foyzul Hassan",
      "Bruce Maxim"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.02013"
  },
  {
    "id": "arXiv:2211.02016",
    "title": "Oracle Inequalities for Model Selection in Offline Reinforcement  Learning",
    "abstract": "In offline reinforcement learning (RL), a learner leverages prior logged data\nto learn a good policy without interacting with the environment. A major\nchallenge in applying such methods in practice is the lack of both\ntheoretically principled and practical tools for model selection and\nevaluation. To address this, we study the problem of model selection in offline\nRL with value function approximation. The learner is given a nested sequence of\nmodel classes to minimize squared Bellman error and must select among these to\nachieve a balance between approximation and estimation error of the classes. We\npropose the first model selection algorithm for offline RL that achieves\nminimax rate-optimal oracle inequalities up to logarithmic factors. The\nalgorithm, ModBE, takes as input a collection of candidate model classes and a\ngeneric base offline RL algorithm. By successively eliminating model classes\nusing a novel one-sided generalization test, ModBE returns a policy with regret\nscaling with the complexity of the minimally complete model class. In addition\nto its theoretical guarantees, it is conceptually simple and computationally\nefficient, amounting to solving a series of square loss regression problems and\nthen comparing relative square loss between classes. We conclude with several\nnumerical simulations showing it is capable of reliably selecting a good model\nclass.",
    "descriptor": "",
    "authors": [
      "Jonathan N. Lee",
      "George Tucker",
      "Ofir Nachum",
      "Bo Dai",
      "Emma Brunskill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02016"
  },
  {
    "id": "arXiv:2211.02018",
    "title": "A unconditionally energy dissipative, adaptive IMEX BDF2 scheme and its  error estimates for Cahn-Hilliard equation on generalized SAV approach",
    "abstract": "An adaptive implicit-explicit (IMEX) BDF2 scheme is investigated on\ngeneralized SAV approach for the Cahn-Hilliard equation by combining with\nFourier spectral method in space. It is proved that the modified energy\ndissipation law is unconditionally preserved at discrete levels. Under a mild\nratio restriction, i.e., \\Ass{1}: $0<r_k:=\\tau_k/\\tau_{k-1}< r_{\\max}\\approx\n4.8645$, we establish a rigorous error estimate in $H^1$-norm and achieve\noptimal second-order accuracy in time. The proof involves the tools of discrete\northogonal convolution (DOC) kernels and inequality zoom. It is worth noting\nthat the presented adaptive time-step scheme only requires solving one linear\nsystem with constant coefficients at each time step. In our analysis, the\nfirst-consistent BDF1 for the first step does not bring the order reduction in\n$H^1$-norm. The $H^1$ bound of the numerical solution under periodic boundary\nconditions can be derived without any restriction (such as zero mean of the\ninitial data). Finally, numerical examples are provided to verify our\ntheoretical analysis and the algorithm efficiency.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Yifan Wei",
      "Jiwei Zhang",
      "Chengchao Zhao",
      "Yanmin Zhao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.02018"
  },
  {
    "id": "arXiv:2211.02043",
    "title": "Could Giant Pretrained Image Models Extract Universal Representations?",
    "abstract": "Frozen pretrained models have become a viable alternative to the\npretraining-then-finetuning paradigm for transfer learning. However, with\nfrozen models there are relatively few parameters available for adapting to\ndownstream tasks, which is problematic in computer vision where tasks vary\nsignificantly in input/output format and the type of information that is of\nvalue. In this paper, we present a study of frozen pretrained models when\napplied to diverse and representative computer vision tasks, including object\ndetection, semantic segmentation and video action recognition. From this\nempirical analysis, our work answers the questions of what pretraining task\nfits best with this frozen setting, how to make the frozen setting more\nflexible to various downstream tasks, and the effect of larger model sizes. We\nadditionally examine the upper bound of performance using a giant frozen\npretrained model with 3 billion parameters (SwinV2-G) and find that it reaches\ncompetitive performance on a varied set of major benchmarks with only one\nshared frozen base network: 60.0 box mAP and 52.2 mask mAP on COCO object\ndetection test-dev, 57.6 val mIoU on ADE20K semantic segmentation, and 81.7\ntop-1 accuracy on Kinetics-400 action recognition. With this work, we hope to\nbring greater attention to this promising path of freezing pretrained image\nmodels.",
    "descriptor": "\nComments: To be published in NeurIPS2022\n",
    "authors": [
      "Yutong Lin",
      "Ze Liu",
      "Zheng Zhang",
      "Han Hu",
      "Nanning Zheng",
      "Stephen Lin",
      "Yue Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02043"
  },
  {
    "id": "arXiv:2211.02044",
    "title": "Competitive Kill-and-Restart Strategies for Non-Clairvoyant Scheduling",
    "abstract": "We consider the fundamental scheduling problem of minimizing the sum of\nweighted completion times on a single machine in the non-clairvoyant setting.\nWhile no non-preemptive algorithm is constant competitive, Motwani, Phillips,\nand Torng (SODA '93) proved that the simple preemptive round robin procedure is\n$2$-competitive and that no better competitive ratio is possible, initiating a\nlong line of research focused on preemptive algorithms for generalized variants\nof the problem. As an alternative model, Shmoys, Wein, and Williamson (FOCS\n'91) introduced kill-and-restart schedules, where running jobs may be killed\nand restarted from scratch later, and analyzed then for the makespan objective.\nHowever, to the best of our knowledge, this concept has never been considered\nfor the total completion time objective in the non-clairvoyant model.\nWe contribute to both models: First we give for any $b > 1$ a tight analysis\nfor the natural $b$-scaling kill-and-restart strategy for scheduling jobs\nwithout release dates, as well as for a randomized variant of it. This implies\na performance guarantee of $(1+3\\sqrt{3})\\approx 6.197$ for the deterministic\nalgorithm and of $\\approx 3.032$ for the randomized version. Second, we show\nthat the preemptive Weighted Shortest Elapsed Time First (WSETF) rule is\n$2$-competitive for jobs released in an online fashion over time, matching the\nlower bound by Motwani et al. Using this result as well as the competitiveness\nof round robin for multiple machines, we prove performance guarantees of\nadaptions of the $b$-scaling algorithm to online release dates and unweighted\njobs on identical parallel machines.",
    "descriptor": "",
    "authors": [
      "Sven J\u00e4ger",
      "Guillaume Sagnol",
      "Daniel Schmidt genannt Waldschmidt",
      "Philipp Warode"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.02044"
  },
  {
    "id": "arXiv:2211.02047",
    "title": "Along Similar Lines: Local Obstacle Avoidance for Long-term Autonomous  Path Following",
    "abstract": "Visual Teach and Repeat 3 (VT&R3), a generalization of stereo VT&R, achieves\nlong-term autonomous path-following using topometric mapping and localization\nfrom a single rich sensor stream. In this paper, we improve the capabilities of\na LiDAR implementation of VT&R3 to reliably detect and avoid obstacles in\nchanging environments. Our architecture simplifies the obstacle-perception\nproblem to that of place-dependent change detection. We then extend the\nbehaviour of generic sample-based motion planners to better suit the\nteach-and-repeat problem structure by introducing a new edge-cost metric paired\nwith a curvilinear planning space. The resulting planner generates naturally\nsmooth paths that avoid local obstacles while minimizing lateral path deviation\nto best exploit prior terrain knowledge. While we use the method with VT&R, it\ncan be generalized to suit arbitrary path-following applications. Experimental\nresults from online run-time analysis, unit testing, and qualitative\nexperiments on a differential drive robot show the promise of the technique for\nreliable long-term autonomous operation in complex unstructured environments.",
    "descriptor": "\nComments: 7 Pages, 8 Figures, Submitted to The International Conference on Robotics and Automation (ICRA) 2023\n",
    "authors": [
      "Jordy Sehn",
      "Yuchen Wu",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02047"
  },
  {
    "id": "arXiv:2211.02048",
    "title": "Efficient Spatially Sparse Inference for Conditional GANs and Diffusion  Models",
    "abstract": "During image editing, existing deep generative models tend to re-synthesize\nthe entire output from scratch, including the unedited regions. This leads to a\nsignificant waste of computation, especially for minor editing operations. In\nthis work, we present Spatially Sparse Inference (SSI), a general-purpose\ntechnique that selectively performs computation for edited regions and\naccelerates various generative models, including both conditional GANs and\ndiffusion models. Our key observation is that users tend to make gradual\nchanges to the input image. This motivates us to cache and reuse the feature\nmaps of the original image. Given an edited image, we sparsely apply the\nconvolutional filters to the edited regions while reusing the cached features\nfor the unedited regions. Based on our algorithm, we further propose Sparse\nIncremental Generative Engine (SIGE) to convert the computation reduction to\nlatency reduction on off-the-shelf hardware. With 1.2%-area edited regions, our\nmethod reduces the computation of DDIM by 7.5$\\times$ and GauGAN by 18$\\times$\nwhile preserving the visual fidelity. With SIGE, we accelerate the speed of\nDDIM by 3.0x on RTX 3090 and 6.6$\\times$ on Apple M1 Pro CPU, and GauGAN by\n4.2$\\times$ on RTX 3090 and 14$\\times$ on Apple M1 Pro CPU.",
    "descriptor": "\nComments: NeurIPS 2022 Website: this https URL Code: this https URL\n",
    "authors": [
      "Muyang Li",
      "Ji Lin",
      "Chenlin Meng",
      "Stefano Ermon",
      "Song Han",
      "Jun-Yan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02048"
  },
  {
    "id": "arXiv:2103.05191",
    "title": "Exponential Modalities and Complementarity (extended abstract)",
    "abstract": "The exponential modalities of linear logic have been used by various authors\nto model infinite-dimensional quantum systems. This paper explains how these\nmodalities can also give rise to the complementarity principle of quantum\nmechanics.\nThe paper uses a formulation of quantum systems based on dagger-linear logic,\nwhose categorical semantics lies in mixed unitary categories, and a formulation\nof measurement therein. The main result exhibits a complementary system as the\nresult of measurements on free exponential modalities. Recalling that, in\nlinear logic, exponential modalities have two distinct but dual components, !\nand ?, this shows how these components under measurement become \"compacted\"\ninto the usual notion of complementary Frobenius algebras from categorical\nquantum mechanics.",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102. A full version of this paper, containing all proofs, appears at arXiv:2103:05191\n",
    "authors": [
      "Robin Cockett",
      "Priyaa Varshinee Srinivasan"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.05191"
  },
  {
    "id": "arXiv:2210.17145",
    "title": "Probability-Dependent Gradient Decay in Large Margin Softmax",
    "abstract": "In the past few years, Softmax has become a common component in neural\nnetwork frameworks. In this paper, a gradient decay hyperparameter is\nintroduced in Softmax to control the probability-dependent gradient decay rate\nduring training. By following the theoretical analysis and empirical results of\na variety of model architectures trained on MNIST, CIFAR-10/100 and SVHN, we\nfind that the generalization performance depends significantly on the gradient\ndecay rate as the confidence probability rises, i.e., the gradient decreases\nconvexly or concavely as the sample probability increases. Moreover,\noptimization with the small gradient decay shows a similar curriculum learning\nsequence where hard samples are in the spotlight only after easy samples are\nconvinced sufficiently, and well-separated samples gain a higher gradient to\nreduce intra-class distance. Based on the analysis results, we can provide\nevidence that the large margin Softmax will affect the local Lipschitz\nconstraint of the loss function by regulating the probability-dependent\ngradient decay rate. This paper provides a new perspective and understanding of\nthe relationship among concepts of large margin Softmax, local Lipschitz\nconstraint and curriculum learning by analyzing the gradient decay rate.\nBesides, we propose a warm-up strategy to dynamically adjust Softmax loss in\ntraining, where the gradient decay rate increases from over-small to speed up\nthe convergence rate.",
    "descriptor": "",
    "authors": [
      "Siyuan Zhang",
      "Linbo Xie",
      "Ying Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.17145"
  },
  {
    "id": "arXiv:2211.01372",
    "title": "Investigating the robustness of a learning-based method for quantitative  phase retrieval from propagation-based x-ray phase contrast measurements  under laboratory conditions",
    "abstract": "Quantitative phase retrieval (QPR) in propagation-based x-ray phase contrast\nimaging of heterogeneous and structurally complicated objects is challenging\nunder laboratory conditions due to partial spatial coherence and\npolychromaticity. A learning-based method (LBM) provides a non-linear approach\nto this problem while not being constrained by restrictive assumptions about\nobject properties and beam coherence. In this work, a LBM was assessed for its\napplicability under practical scenarios by evaluating its robustness and\ngeneralizability under typical experimental variations. Towards this end, an\nend-to-end LBM was employed for QPR under laboratory conditions and its\nrobustness was investigated across various system and object conditions. The\nrobustness of the method was tested via varying propagation distances and its\ngeneralizability with respect to object structure and experimental data was\nalso tested. Although the LBM was stable under the studied variations, its\nsuccessful deployment was found to be affected by choices pertaining to data\npre-processing, network training considerations and system modeling. To our\nknowledge, we demonstrated for the first time, the potential applicability of\nan end-to-end learning-based quantitative phase retrieval method, trained on\nsimulated data, to experimental propagation-based x-ray phase contrast\nmeasurements acquired under laboratory conditions. We considered conditions of\npolychromaticity, partial spatial coherence, and high noise levels, typical to\nlaboratory conditions. This work further explored the robustness of this method\nto practical variations in propagation distances and object structure with the\ngoal of assessing its potential for experimental use. Such an exploration of\nany LBM (irrespective of its network architecture) before practical deployment\nprovides an understanding of its potential behavior under experimental\nsettings.",
    "descriptor": "\nComments: Under review as a journal submission. Early version with partial results has been accepted for poster presentation at SPIE-MI 2023\n",
    "authors": [
      "Rucha Deshpande",
      "Ashish Avachat",
      "Frank J. Brooks",
      "Mark A. Anastasio"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.01372"
  },
  {
    "id": "arXiv:2211.01373",
    "title": "Interpretable Modeling and Reduction of Unknown Errors in Mechanistic  Operators",
    "abstract": "Prior knowledge about the imaging physics provides a mechanistic forward\noperator that plays an important role in image reconstruction, although myriad\nsources of possible errors in the operator could negatively impact the\nreconstruction solutions. In this work, we propose to embed the traditional\nmechanistic forward operator inside a neural function, and focus on modeling\nand correcting its unknown errors in an interpretable manner. This is achieved\nby a conditional generative model that transforms a given mechanistic operator\nwith unknown errors, arising from a latent space of self-organizing clusters of\npotential sources of error generation. Once learned, the generative model can\nbe used in place of a fixed forward operator in any traditional\noptimization-based reconstruction process where, together with the inverse\nsolution, the error in prior mechanistic forward operator can be minimized and\nthe potential source of error uncovered. We apply the presented method to the\nreconstruction of heart electrical potential from body surface potential. In\ncontrolled simulation experiments and in-vivo real data experiments, we\ndemonstrate that the presented method allowed reduction of errors in the\nphysics-based forward operator and thereby delivered inverse reconstruction of\nheart-surface potential with increased accuracy.",
    "descriptor": "\nComments: 11 pages, Conference: Medical Image Computing and Computer Assisted Intervention\n",
    "authors": [
      "Maryam Toloubidokhti",
      "Nilesh Kumar",
      "Zhiyuan Li",
      "Prashnna K. Gyawali",
      "Brian Zenger",
      "Wilson W. Good",
      "Rob S. MacLeod",
      "Linwei Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01373"
  },
  {
    "id": "arXiv:2211.01374",
    "title": "End-to-end deep multi-score model for No-reference stereoscopic image  quality assessment",
    "abstract": "Deep learning-based quality metrics have recently given significant\nimprovement in Image Quality Assessment (IQA). In the field of stereoscopic\nvision, information is evenly distributed with slight disparity to the left and\nright eyes. However, due to asymmetric distortion, the objective quality\nratings for the left and right images would differ, necessitating the learning\nof unique quality indicators for each view. Unlike existing stereoscopic IQA\nmeasures which focus mainly on estimating a global human score, we suggest\nincorporating left, right, and stereoscopic objective scores to extract the\ncorresponding properties of each view, and so forth estimating stereoscopic\nimage quality without reference. Therefore, we use a deep multi-score\nConvolutional Neural Network (CNN). Our model has been trained to perform four\ntasks: First, predict the left view's quality. Second, predict the quality of\nthe left view. Third and fourth, predict the quality of the stereo view and\nglobal quality, respectively, with the global score serving as the ultimate\nquality. Experiments are conducted on Waterloo IVC 3D Phase 1 and Phase 2\ndatabases. The results obtained show the superiority of our method when\ncomparing with those of the state-of-the-art. The implementation code can be\nfound at: https://github.com/o-messai/multi-score-SIQA",
    "descriptor": "",
    "authors": [
      "Oussama Messai",
      "Aladine Chetouani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.01374"
  },
  {
    "id": "arXiv:2211.01406",
    "title": "Incorporating High-Frequency Weather Data into Consumption Expenditure  Predictions",
    "abstract": "Recent efforts have been very successful in accurately mapping welfare in\ndatasparse regions of the world using satellite imagery and other\nnon-traditional data sources. However, the literature to date has focused on\npredicting a particular class of welfare measures, asset indices, which are\nrelatively insensitive to short term fluctuations in well-being. We suggest\nthat predicting more volatile welfare measures, such as consumption\nexpenditure, substantially benefits from the incorporation of data sources with\nhigh temporal resolution. By incorporating daily weather data into training and\nprediction, we improve consumption prediction accuracy significantly compared\nto models that only utilize satellite imagery.",
    "descriptor": "",
    "authors": [
      "Anders Christensen",
      "Joel Ferguson",
      "Sim\u00f3n Ram\u00edrez Amaya"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01406"
  },
  {
    "id": "arXiv:2211.01438",
    "title": "Variable Attention Masking for Configurable Transformer Transducer  Speech Recognition",
    "abstract": "This work studies the use of attention masking in transformer transducer\nbased speech recognition for building a single configurable model for different\ndeployment scenarios. We present a comprehensive set of experiments comparing\nfixed masking, where the same attention mask is applied at every frame, with\nchunked masking, where the attention mask for each frame is determined by chunk\nboundaries, in terms of recognition accuracy and latency. We then explore the\nuse of variable masking, where the attention masks are sampled from a target\ndistribution at training time, to build models that can work in different\nconfigurations. Finally, we investigate how a single configurable model can be\nused to perform both first pass streaming recognition and second pass acoustic\nrescoring. Experiments show that chunked masking achieves a better accuracy vs\nlatency trade-off compared to fixed masking, both with and without FastEmit. We\nalso show that variable masking improves the accuracy by up to 8% relative in\nthe acoustic re-scoring scenario.",
    "descriptor": "\nComments: 5 pages, 4 figures, 2 Tables\n",
    "authors": [
      "Pawel Swietojanski",
      "Stefan Braun",
      "Dogan Can",
      "Thiago Fraga da Silva",
      "Arnab Ghoshal",
      "Takaaki Hori",
      "Roger Hsiao",
      "Henry Mason",
      "Erik McDermott",
      "Honza Silovsky",
      "Ruchir Travadi",
      "Xiaodan Zhuang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01438"
  },
  {
    "id": "arXiv:2211.01441",
    "title": "eXplainable AI for Quantum Machine Learning",
    "abstract": "Parametrized Quantum Circuits (PQCs) enable a novel method for machine\nlearning (ML). However, from a computational point of view they present a\nchallenge to existing eXplainable AI (xAI) methods. On the one hand,\nmeasurements on quantum circuits introduce probabilistic errors which impact\nthe convergence of these methods. On the other hand, the phase space of a\nquantum circuit expands exponentially with the number of qubits, complicating\nefforts to execute xAI methods in polynomial time. In this paper we will\ndiscuss the performance of established xAI methods, such as Baseline SHAP and\nIntegrated Gradients. Using the internal mechanics of PQCs we study ways to\nspeed up their computation.",
    "descriptor": "",
    "authors": [
      "Patrick Steinm\u00fcller",
      "Tobias Schulz",
      "Ferdinand Graf",
      "Daniel Herr"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.01441"
  },
  {
    "id": "arXiv:2211.01444",
    "title": "Pseudorandom (Function-Like) Quantum State Generators: New Definitions  and Applications",
    "abstract": "Pseudorandom quantum states (PRS) are efficiently constructible states that\nare computationally indistinguishable from being Haar-random, and have recently\nfound cryptographic applications. We explore new definitions, new properties\nand applications of pseudorandom states, and present the following\ncontributions:\n1. New Definitions: We study variants of pseudorandom function-like state\n(PRFS) generators, introduced by Ananth, Qian, and Yuen (CRYPTO'22), where the\npseudorandomness property holds even when the generator can be queried\nadaptively or in superposition. We show feasibility of these variants assuming\nthe existence of post-quantum one-way functions.\n2. Classical Communication: We show that PRS generators with logarithmic\noutput length imply commitment and encryption schemes with classical\ncommunication. Previous constructions of such schemes from PRS generators\nrequired quantum communication.\n3. Simplified Proof: We give a simpler proof of the Brakerski--Shmueli\n(TCC'19) result that polynomially-many copies of uniform superposition states\nwith random binary phases are indistinguishable from Haar-random states.\n4. Necessity of Computational Assumptions: We also show that a secure PRS\nwith output length logarithmic, or larger, in the key length necessarily\nrequires computational assumptions.",
    "descriptor": "",
    "authors": [
      "Prabhanjan Ananth",
      "Aditya Gulati",
      "Lower Qian",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01444"
  },
  {
    "id": "arXiv:2211.01450",
    "title": "An analog of the Edwards model for Jacobians of genus 2 curves",
    "abstract": "We give the explicit equations for a P^3 x P^3 embedding of the Jacobian of a\ncurve of genus 2, which gives a natural analog for abelian surfaces of the\nEdwards curve model of elliptic curves. This gives a much more succinct\ndescription of the Jacobian variety than the standard version in P^{15}. We\nalso give a condition under which, as for the Edwards curve, the abelian\nsurfaces have a universal group law, with no exceptions.",
    "descriptor": "\nComments: 33 pages, with supplemental maple file\n",
    "authors": [
      "E. Victor Flynn",
      "Kamal Khuri-Makdisi"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Symbolic Computation (cs.SC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2211.01450"
  },
  {
    "id": "arXiv:2211.01461",
    "title": "Phoneme Segmentation Using Self-Supervised Speech Models",
    "abstract": "We apply transfer learning to the task of phoneme segmentation and\ndemonstrate the utility of representations learned in self-supervised\npre-training for the task. Our model extends transformer-style encoders with\nstrategically placed convolutions that manipulate features learned in\npre-training. Using the TIMIT and Buckeye corpora we train and test the model\nin the supervised and unsupervised settings. The latter case is accomplished by\nfurnishing a noisy label-set with the predictions of a separate model, it\nhaving been trained in an unsupervised fashion. Results indicate our model\neclipses previous state-of-the-art performance in both settings and on both\ndatasets. Finally, following observations during published code review and\nattempts to reproduce past segmentation results, we find a need to disambiguate\nthe definition and implementation of widely-used evaluation metrics. We resolve\nthis ambiguity by delineating two distinct evaluation schemes and describing\ntheir nuances.",
    "descriptor": "\nComments: Accepted to SLT 2022\n",
    "authors": [
      "Luke Strgar",
      "David Harwath"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01461"
  },
  {
    "id": "arXiv:2211.01472",
    "title": "The Need for Medically Aware Video Compression in Gastroenterology",
    "abstract": "Compression is essential to storing and transmitting medical videos, but the\neffect of compression on downstream medical tasks is often ignored.\nFurthermore, systems in practice rely on standard video codecs, which naively\nallocate bits between medically relevant frames or parts of frames. In this\nwork, we present an empirical study of some deficiencies of classical codecs on\ngastroenterology videos, and motivate our ongoing work to train a learned\ncompression model for colonoscopy videos. We show that two of the most common\nclassical codecs, H264 and HEVC, compress medically relevant frames\nstatistically significantly worse than medically nonrelevant ones, and that\npolyp detector performance degrades rapidly as compression increases. We\nexplain how a learned compressor could allocate bits to important regions and\nallow detection performance to degrade more gracefully. Many of our proposed\ntechniques generalize to medical video domains beyond gastroenterology",
    "descriptor": "\nComments: Medical Imaging Meets NeurIPS Workshop 2022, NeurIPS 2022\n",
    "authors": [
      "Joel Shor",
      "Nick Johnston"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01472"
  },
  {
    "id": "arXiv:2211.01505",
    "title": "Implicit Neural Representation as a Differentiable Surrogate for Photon  Propagation in a Monolithic Neutrino Detector",
    "abstract": "Optical photons are used as signal in a wide variety of particle detectors.\nModern neutrino experiments employ hundreds to tens of thousands of photon\ndetectors to observe signal from millions to billions of scintillation photons\nproduced from energy deposition of charged particles. These neutrino detectors\nare typically large, containing kilotons of target volume, with different\noptical properties. Modeling individual photon propagation in form of look-up\ntable requires huge computational resources. As the size of a table increases\nwith detector volume for a fixed resolution, this method scales poorly for\nfuture larger detectors. Alternative approaches such as fitting a polynomial to\nthe model could address the memory issue, but results in poorer performance.\nBoth look-up table and fitting approaches are prone to discrepancies between\nthe detector simulation and the data collected. We propose a new approach using\nSIREN, an implicit neural representation with periodic activation functions, to\nmodel the look-up table as a 3D scene and reproduces the acceptance map with\nhigh accuracy. The number of parameters in our SIREN model is orders of\nmagnitude smaller than the number of voxels in the look-up table. As it models\nan underlying functional shape, SIREN is scalable to a larger detector.\nFurthermore, SIREN can successfully learn the spatial gradients of the photon\nlibrary, providing additional information for downstream applications. Finally,\nas SIREN is a neural network representation, it is differentiable with respect\nto its parameters, and therefore tunable via gradient descent. We demonstrate\nthe potential of optimizing SIREN directly on real data, which mitigates the\nconcern of data vs. simulation discrepancies. We further present an application\nfor data reconstruction where SIREN is used to form a likelihood function for\nphoton statistics.",
    "descriptor": "",
    "authors": [
      "Minjie Lei",
      "Ka Vang Tsang",
      "Sean Gasiorowski",
      "Chuan Li",
      "Youssef Nashed",
      "Gianluca Petrillo",
      "Olivia Piazza",
      "Daniel Ratner",
      "Kazuhiro Terao"
    ],
    "subjectives": [
      "Instrumentation and Detectors (physics.ins-det)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01505"
  },
  {
    "id": "arXiv:2211.01515",
    "title": "MAST: Multiscale Audio Spectrogram Transformers",
    "abstract": "We present Multiscale Audio Spectrogram Transformer (MAST) for audio\nclassification, which brings the concept of multiscale feature hierarchies to\nthe Audio Spectrogram Transformer (AST). Given an input audio spectrogram we\nfirst patchify and project it into an initial temporal resolution and embedding\ndimension, post which the multiple stages in MAST progressively expand the\nembedding dimension while reducing the temporal resolution of the input. We use\na pyramid structure that allows early layers of MAST operating at a high\ntemporal resolution but low embedding space to model simple low-level acoustic\ninformation and deeper temporally coarse layers to model high-level acoustic\ninformation with high-dimensional embeddings. We also extend our approach to\npresent a new Self-Supervised Learning (SSL) method called SS-MAST, which\ncalculates a symmetric contrastive loss between latent representations from a\nstudent and a teacher encoder. In practice, MAST significantly outperforms AST\nby an average accuracy of 3.4% across 8 speech and non-speech tasks from the\nLAPE Benchmark. Moreover, SS-MAST achieves an absolute average improvement of\n2.6% over SSAST for both AST and MAST encoders. We make all our codes available\non GitHub at the time of publication.",
    "descriptor": "\nComments: Submitted ICASSP 2023\n",
    "authors": [
      "Sreyan Ghosh",
      "Ashish Seth",
      "S. Umesh",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01515"
  },
  {
    "id": "arXiv:2211.01518",
    "title": "Bayesian Counterfactual Mean Embeddings and Off-Policy Evaluation",
    "abstract": "The counterfactual distribution models the effect of the treatment in the\nuntreated group. While most of the work focuses on the expected values of the\ntreatment effect, one may be interested in the whole counterfactual\ndistribution or other quantities associated to it. Building on the framework of\nBayesian conditional mean embeddings, we propose a Bayesian approach for\nmodeling the counterfactual distribution, which leads to quantifying the\nepistemic uncertainty about the distribution. The framework naturally extends\nto the setting where one observes multiple treatment effects (e.g. an\nintermediate effect after an interim period, and an ultimate treatment effect\nwhich is of main interest) and allows for additionally modelling uncertainty\nabout the relationship of these effects. For such goal, we present three novel\nBayesian methods to estimate the expectation of the ultimate treatment effect,\nwhen only noisy samples of the dependence between intermediate and ultimate\neffects are provided. These methods differ on the source of uncertainty\nconsidered and allow for combining two sources of data. Moreover, we generalize\nthese ideas to the off-policy evaluation framework, which can be seen as an\nextension of the counterfactual estimation problem. We empirically explore the\ncalibration of the algorithms in two different experimental settings which\nrequire data fusion, and illustrate the value of considering the uncertainty\nstemming from the two sources of data.",
    "descriptor": "",
    "authors": [
      "Diego Martinez-Taboada",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01518"
  },
  {
    "id": "arXiv:2211.01519",
    "title": "SLICER: Learning universal audio representations using low-resource  self-supervised pre-training",
    "abstract": "We present a new Self-Supervised Learning (SSL) approach to pre-train\nencoders on unlabeled audio data that reduces the need for large amounts of\nlabeled data for audio and speech classification. Our primary aim is to learn\naudio representations that can generalize across a large variety of speech and\nnon-speech tasks in a low-resource un-labeled audio pre-training setting.\nInspired by the recent success of clustering and contrasting learning paradigms\nfor SSL-based speech representation learning, we propose SLICER (Symmetrical\nLearning of Instance and Cluster-level Efficient Representations), which brings\ntogether the best of both clustering and contrasting learning paradigms. We use\na symmetric loss between latent representations from student and teacher\nencoders and simultaneously solve instance and cluster-level contrastive\nlearning tasks. We obtain cluster representations online by just projecting the\ninput spectrogram into an output subspace with dimensions equal to the number\nof clusters. In addition, we propose a novel mel-spectrogram augmentation\nprocedure, k-mix, based on mixup, which does not require labels and aids\nunsupervised representation learning for audio. Overall, SLICER achieves\nstate-of-the-art results on the LAPE Benchmark \\cite{9868132}, significantly\noutperforming DeLoRes-M and other prior approaches, which are pre-trained on\n$10\\times$ larger of unsupervised data. We will make all our codes available on\nGitHub.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Ashish Seth",
      "Sreyan Ghosh",
      "S. Umesh",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01519"
  },
  {
    "id": "arXiv:2211.01545",
    "title": "Extracting Spatial Interaction Patterns between Urban Road Networks and  Mixed Functions",
    "abstract": "In the field of urban planning, road network system planning is often the\nfirst step and the main purpose of urban planning is to create a spatial\nconfiguration of different functions such as residence, education, business,\netc. Generally speaking, the more mixed the functions of an area has, the more\npossible its vitality may be. Therefore, in this article, we propose a new\nframework to study the specific spatial influence patterns of the overall\nstructure and different sub-structures of road networks on the mixed functions.\nTaking road segment as the basic unit, we characterize mixed functions\naggregation of road networks with the number of POIs categories within 100\nmeters around every road segment. At the same time, on the basis of centrality\nmeasurement in graph theory, we use 4 indexes to reflect the characteristics of\nthe urban road network structure, including degree, closeness, betweenness, and\nlength. We conduct our methods and experiments using the road networks and POI\ndata within the 5th ring road of Beijing. The results demonstrate that urban\nroad networks inherently influence the aggregation of urban mixed functions in\nvarious patterns and the patterns of road network sub-structures is also quite\ndifferent. Our study shows that the higher the degree of the road network\nstructure has, the more likely it will attract functions' aggregation. It also\nreveals that diversified local degree will help gather urban functions. In\naddition to those, the analysis as well validates the importance of small-grids\ntypology of urban road networks and the closeness to the center of cities.",
    "descriptor": "",
    "authors": [
      "Huidan Xiao",
      "Tao Yang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.01545"
  },
  {
    "id": "arXiv:2211.01547",
    "title": "A Systematic Paradigm for Detecting, Surfacing, and Characterizing  Heterogeneous Treatment Effects (HTE)",
    "abstract": "To effectively optimize and personalize treatments, it is necessary to\ninvestigate the heterogeneity of treatment effects. With the wide range of\nusers being treated over many online controlled experiments, the typical\napproach of manually investigating each dimension of heterogeneity becomes\noverly cumbersome and prone to subjective human biases. We need an efficient\nway to search through thousands of experiments with hundreds of target\ncovariates and hundreds of breakdown dimensions. In this paper, we propose a\nsystematic paradigm for detecting, surfacing and characterizing heterogeneous\ntreatment effects. First, we detect if treatment effect variation is present in\nan experiment, prior to specifying any breakdowns. Second, we surface the most\nrelevant dimensions for heterogeneity. Finally, we characterize the\nheterogeneity beyond just the conditional average treatment effects (CATE) by\nstudying the conditional distributions of the estimated individual treatment\neffects. We show the effectiveness of our methods using simulated data and\nempirical studies.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "John Cai",
      "Weinan Wang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Mathematical Software (cs.MS)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2211.01547"
  },
  {
    "id": "arXiv:2211.01561",
    "title": "Benefits of Monotonicity in Safe Exploration with Gaussian Processes",
    "abstract": "We consider the problem of sequentially maximising an unknown function over a\nset of actions while ensuring that every sampled point has a function value\nbelow a given safety threshold. We model the function using kernel-based and\nGaussian process methods, while differing from previous works in our assumption\nthat the function is monotonically increasing with respect to a safety\nvariable. This assumption is motivated by various practical applications such\nas adaptive clinical trial design and robotics. Taking inspiration from the\nGP-UCB and SafeOpt algorithms, we propose an algorithm, monotone safe UCB\n(M-SafeUCB) for this task. We show that M-SafeUCB enjoys theoretical guarantees\nin terms of safety, a suitably-defined regret notion, and approximately finding\nthe entire safe boundary. In addition, we illustrate that the monotonicity\nassumption yields significant benefits in terms of both the guarantees obtained\nand the algorithmic simplicity. We support our theoretical findings by\nperforming empirical evaluations on a variety of functions.",
    "descriptor": "",
    "authors": [
      "Arpan Losalka",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01561"
  },
  {
    "id": "arXiv:2211.01567",
    "title": "Galaxy Image Deconvolution for Weak Gravitational Lensing with  Physics-informed Deep Learning",
    "abstract": "Removing optical and atmospheric blur from galaxy images significantly\nimproves galaxy shape measurements for weak gravitational lensing and galaxy\nevolution studies. This ill-posed linear inverse problem is usually solved with\ndeconvolution algorithms enhanced by regularisation priors or deep learning. We\nintroduce a so-called \"physics-based deep learning\" approach to the Point\nSpread Function (PSF) deconvolution problem in galaxy surveys. We apply\nalgorithm unrolling and the Plug-and-Play technique to the Alternating\nDirection Method of Multipliers (ADMM) with a Poisson noise model and use a\nneural network to learn appropriate priors from simulated galaxy images. We\ncharacterise the time-performance trade-off of several methods for galaxies of\ndiffering brightness levels, showing an improvement of 26% (SNR=20)/48%\n(SNR=100) compared to standard methods and 14% (SNR=20) compared to modern\nmethods.",
    "descriptor": "",
    "authors": [
      "Tianao Li",
      "Emma Alexander"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01567"
  },
  {
    "id": "arXiv:2211.01571",
    "title": "Phonetic-assisted Multi-Target Units Modeling for Improving  Conformer-Transducer ASR system",
    "abstract": "Exploiting effective target modeling units is very important and has always\nbeen a concern in end-to-end automatic speech recognition (ASR). In this work,\nwe propose a phonetic-assisted multi-target units (PMU) modeling approach, to\nenhance the Conformer-Transducer ASR system in a progressive representation\nlearning manner. Specifically, PMU first uses the pronunciation-assisted\nsubword modeling (PASM) and byte pair encoding (BPE) to produce\nphonetic-induced and text-induced target units separately; Then, three new\nframeworks are investigated to enhance the acoustic encoder, including a basic\nPMU, a paraCTC and a pcaCTC, they integrate the PASM and BPE units at different\nlevels for CTC and transducer multi-task training. Experiments on both\nLibriSpeech and accented ASR tasks show that, the proposed PMU significantly\noutperforms the conventional BPE, it reduces the WER of LibriSpeech clean,\nother, and six accented ASR testsets by relative 12.7%, 6.0% and 7.7%,\nrespectively.",
    "descriptor": "\nComments: 5 pages, 1 figures, submitted to ICASSP 2023\n",
    "authors": [
      "Li Li",
      "Dongxing Xu",
      "Haoran Wei",
      "Yanhua Long"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01571"
  },
  {
    "id": "arXiv:2211.01575",
    "title": "Are Synthetic Control Weights Balancing Score?",
    "abstract": "In this short note, I outline conditions under which conditioning on\nSynthetic Control (SC) weights emulates a randomized control trial where the\ntreatment status is independent of potential outcomes. Specifically, I\ndemonstrate that if there exist SC weights such that (i) the treatment effects\nare exactly identified and (ii) these weights are uniformly and cumulatively\nbounded, then SC weights are balancing scores.",
    "descriptor": "\nComments: 2 pages, 2 figures\n",
    "authors": [
      "Harsh Parikh"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2211.01575"
  },
  {
    "id": "arXiv:2211.01583",
    "title": "Data-based Polymer-Unit Fingerprint (PUFp): A Newly Accessible  Expression of Polymer Organic Semiconductors for Machine Learning",
    "abstract": "In the process of finding high-performance organic semiconductors (OSCs), it\nis of paramount importance in material development to identify important\nfunctional units that play key roles in material performance and subsequently\nestablish substructure-property relationships. Herein, we describe a\npolymer-unit fingerprint (PUFp) generation framework. Machine learning (ML)\nmodels can be used to determine structure-mobility relationships by using PUFp\ninformation as structural input with 678 pieces of collected OSC data. A\npolymer-unit library consisting of 445 units is constructed, and the key\npolymer units for the mobility of OSCs are identified. By investigating the\ncombinations of polymer units with mobility performance, a scheme for designing\npolymer OSC materials by combining ML approaches and PUFp information is\nproposed to not only passively predict OSC mobility but also actively provide\nstructural guidance for new high-mobility OSC material design. The proposed\nscheme demonstrates the ability to screen new materials through pre-evaluation\nand classification ML steps and is an alternative methodology for applying ML\nin new high-mobility OSC discovery.",
    "descriptor": "\nComments: 42 pages, 13 figures\n",
    "authors": [
      "Xinyue Zhang",
      "Genwang Wei",
      "Ye Sheng",
      "Jiong Yang",
      "Caichao Ye",
      "Wenqing Zhang"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01583"
  },
  {
    "id": "arXiv:2211.01599",
    "title": "Convolution channel separation and frequency sub-bands aggregation for  music genre classification",
    "abstract": "In music, short-term features such as pitch and tempo constitute long-term\nsemantic features such as melody and narrative. A music genre classification\n(MGC) system should be able to analyze these features. In this research, we\npropose a novel framework that can extract and aggregate both short- and\nlong-term features hierarchically. Our framework is based on ECAPA-TDNN, where\nall the layers that extract short-term features are affected by the layers that\nextract long-term features because of the back-propagation training. To prevent\nthe distortion of short-term features, we devised the convolution channel\nseparation technique that separates short-term features from long-term feature\nextraction paths. To extract more diverse features from our framework, we\nincorporated the frequency sub-bands aggregation method, which divides the\ninput spectrogram along frequency bandwidths and processes each segment. We\nevaluated our framework using the Melon Playlist dataset which is a large-scale\ndataset containing 600 times more data than GTZAN which is a widely used\ndataset in MGC studies. As the result, our framework achieved 70.4% accuracy,\nwhich was improved by 16.9% compared to a conventional framework.",
    "descriptor": "",
    "authors": [
      "Jungwoo Heo",
      "Hyun-seo Shin",
      "Ju-ho Kim",
      "Chan-yeong Lim",
      "Ha-Jin Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01599"
  },
  {
    "id": "arXiv:2211.01601",
    "title": "A Fast Solution Method for Large-scale Unit Commitment Based on  Lagrangian Relaxation and Dynamic Programming",
    "abstract": "The unit commitment problem (UC) is crucial for the operation and market\nmechanism of power systems. With the development of modern electricity, the\nscale of power systems is expanding, and solving the UC problem is also\nbecoming more and more difficult. To this end, this paper proposes a new fast\nsolution method based on Lagrangian relaxation and dynamic program-ming.\nFirstly, the UC solution is estimated to be an initial trial UC solution by a\nfast method based on Lagrangian relaxation. This initial trial UC solution\nfully considers the system-wide con-straints. Secondly, a dynamic programming\nmodule is introduced to adjust the trial UC solution to make it satisfy the\nunit-wise constraints. Thirdly, a method for constructing a feasible UC\nsolution is proposed based on the adjusted trial UC solution. Specifically, a\nfeasibility-testing model and an updating strategy for the trial UC solution\nare established in this part. Numerical tests are implemented on IEEE 24-bus,\nIEEE 118-bus, Polish 2383-bus, and French 6468-bus systems, which verify the\neffec-tiveness and efficiency of the proposed method.",
    "descriptor": "\nComments: 10 pages, journal paper, transactions\n",
    "authors": [
      "Jiangwei Hou",
      "Qiaozhu Zhai",
      "Yuzhou Zhou",
      "Xiaohong Guan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01601"
  },
  {
    "id": "arXiv:2211.01603",
    "title": "Using Signal Processing in Tandem With Adapted Mixture Models for  Classifying Genomic Signals",
    "abstract": "Genomic signal processing has been used successfully in bioinformatics to\nanalyze biomolecular sequences and gain varied insights into DNA structure,\ngene organization, protein binding, sequence evolution, etc. But challenges\nremain in finding the appropriate spectral representation of a biomolecular\nsequence, especially when multiple variable-length sequences need to be handled\nconsistently. In this study, we address this challenge in the context of the\nwell-studied problem of classifying genomic sequences into different taxonomic\nunits (strain, phyla, order, etc.). We propose a novel technique that employs\nsignal processing in tandem with Gaussian mixture models to improve the\nspectral representation of a sequence and subsequently the taxonomic\nclassification accuracies. The sequences are first transformed into spectra,\nand projected to a subspace, where sequences belonging to different taxons are\nbetter distinguishable. Our method outperforms a similar state-of-the-art\nmethod on established benchmark datasets by an absolute margin of 6.06%\naccuracy.",
    "descriptor": "",
    "authors": [
      "Saish Jaiswal",
      "Shreya Nema",
      "Hema A Murthy",
      "Manikandan Narayanan"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01603"
  },
  {
    "id": "arXiv:2211.01607",
    "title": "ImageCAS: A Large-Scale Dataset and Benchmark for Coronary Artery  Segmentation based on Computed Tomography Angiography Images",
    "abstract": "Cardiovascular disease (CVD) accounts for about half of non-communicable\ndiseases. Vessel stenosis in the coronary artery is considered to be the major\nrisk of CVD. Computed tomography angiography (CTA) is one of the widely used\nnoninvasive imaging modalities in coronary artery diagnosis due to its superior\nimage resolution. Clinically, segmentation of coronary arteries is essential\nfor the diagnosis and quantification of coronary artery disease. Recently, a\nvariety of works have been proposed to address this problem. However, on one\nhand, most works rely on in-house datasets, and only a few works published\ntheir datasets to the public which only contain tens of images. On the other\nhand, their source code have not been published, and most follow-up works have\nnot made comparison with existing works, which makes it difficult to judge the\neffectiveness of the methods and hinders the further exploration of this\nchallenging yet critical problem in the community. In this paper, we propose a\nlarge-scale dataset for coronary artery segmentation on CTA images. In\naddition, we have implemented a benchmark in which we have tried our best to\nimplement several typical existing methods. Furthermore, we propose a strong\nbaseline method which combines multi-scale patch fusion and two-stage\nprocessing to extract the details of vessels. Comprehensive experiments show\nthat the proposed method achieves better performance than existing works on the\nproposed large-scale dataset. The benchmark and the dataset are published at\nhttps://github.com/XiaoweiXu/ImageCAS-A-Large-Scale-Dataset-and-Benchmark-for-Coronary-Artery-Segmentation-based-on-CT.",
    "descriptor": "\nComments: 17 pages, 12 figures, 4 tables\n",
    "authors": [
      "An Zeng",
      "Chunbiao Wu",
      "Meiping Huang",
      "Jian Zhuang",
      "Shanshan Bi",
      "Dan Pan",
      "Najeeb Ullah",
      "Kaleem Nawaz Khan",
      "Tianchen Wang",
      "Yiyu Shi",
      "Xiaomeng Li",
      "Guisen Lin",
      "Xiaowei Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01607"
  },
  {
    "id": "arXiv:2211.01610",
    "title": "Proximal Subgradient Norm Minimization of ISTA and FISTA",
    "abstract": "For first-order smooth optimization, the research on the acceleration\nphenomenon has a long-time history. Until recently, the mechanism leading to\nacceleration was not successfully uncovered by the gradient correction term and\nits equivalent implicit-velocity form. Furthermore, based on the\nhigh-resolution differential equation framework with the corresponding emerging\ntechniques, phase-space representation and Lyapunov function, the squared\ngradient norm of Nesterov's accelerated gradient descent (\\texttt{NAG}) method\nat an inverse cubic rate is discovered. However, this result cannot be directly\ngeneralized to composite optimization widely used in practice, e.g., the linear\ninverse problem with sparse representation. In this paper, we meticulously\nobserve a pivotal inequality used in composite optimization about the step size\n$s$ and the Lipschitz constant $L$ and find that it can be improved tighter. We\napply the tighter inequality discovered in the well-constructed Lyapunov\nfunction and then obtain the proximal subgradient norm minimization by the\nphase-space representation, regardless of gradient-correction or\nimplicit-velocity. Furthermore, we demonstrate that the squared proximal\nsubgradient norm for the class of iterative shrinkage-thresholding algorithms\n(ISTA) converges at an inverse square rate, and the squared proximal\nsubgradient norm for the class of faster iterative shrinkage-thresholding\nalgorithms (FISTA) is accelerated to convergence at an inverse cubic rate.",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Bowen Li",
      "Bin Shi",
      "Ya-xiang Yuan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01610"
  },
  {
    "id": "arXiv:2211.01618",
    "title": "Self Supervised Low Dose Computed Tomography Image Denoising Using  Invertible Network Exploiting Inter Slice Congruence",
    "abstract": "The resurgence of deep neural networks has created an alternative pathway for\nlow-dose computed tomography denoising by learning a nonlinear transformation\nfunction between low-dose CT (LDCT) and normal-dose CT (NDCT) image pairs.\nHowever, those paired LDCT and NDCT images are rarely available in the clinical\nenvironment, making deep neural network deployment infeasible. This study\nproposes a novel method for self-supervised low-dose CT denoising to alleviate\nthe requirement of paired LDCT and NDCT images. Specifically, we have trained\nan invertible neural network to minimize the pixel-based mean square distance\nbetween a noisy slice and the average of its two immediate adjacent noisy\nslices. We have shown the aforementioned is similar to training a neural\nnetwork to minimize the distance between clean NDCT and noisy LDCT image pairs.\nAgain, during the reverse mapping of the invertible network, the output image\nis mapped to the original input image, similar to cycle consistency loss.\nFinally, the trained invertible network's forward mapping is used for denoising\nLDCT images. Extensive experiments on two publicly available datasets showed\nthat our method performs favourably against other existing unsupervised\nmethods.",
    "descriptor": "\nComments: 10 pages, Accepted in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Sutanu Bera",
      "Prabir Kumar Biswas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01618"
  },
  {
    "id": "arXiv:2211.01621",
    "title": "Leveraging Domain Features for Detecting Adversarial Attacks Against  Deep Speech Recognition in Noise",
    "abstract": "In recent years, significant progress has been made in deep model-based\nautomatic speech recognition (ASR), leading to its widespread deployment in the\nreal world. At the same time, adversarial attacks against deep ASR systems are\nhighly successful. Various methods have been proposed to defend ASR systems\nfrom these attacks. However, existing classification based methods focus on the\ndesign of deep learning models while lacking exploration of domain specific\nfeatures. This work leverages filter bank-based features to better capture the\ncharacteristics of attacks for improved detection. Furthermore, the paper\nanalyses the potentials of using speech and non-speech parts separately in\ndetecting adversarial attacks. In the end, considering adverse environments\nwhere ASR systems may be deployed, we study the impact of acoustic noise of\nvarious types and signal-to-noise ratios. Extensive experiments show that the\ninverse filter bank features generally perform better in both clean and noisy\nenvironments, the detection is effective using either speech or non-speech\npart, and the acoustic noise can largely degrade the detection performance.",
    "descriptor": "",
    "authors": [
      "Christian Heider Nielsen",
      "Zheng-Hua Tan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01621"
  },
  {
    "id": "arXiv:2211.01645",
    "title": "Towards federated multivariate statistical process control (FedMSPC)",
    "abstract": "The ongoing transition from a linear (produce-use-dispose) to a circular\neconomy poses significant challenges to current state-of-the-art information\nand communication technologies. In particular, the derivation of integrated,\nhigh-level views on material, process, and product streams from (real-time)\ndata produced along value chains is challenging for several reasons. Most\nimportantly, sufficiently rich data is often available yet not shared across\ncompany borders because of privacy concerns which make it impossible to build\nintegrated process models that capture the interrelations between input\nmaterials, process parameters, and key performance indicators along value\nchains. In the current contribution, we propose a privacy-preserving, federated\nmultivariate statistical process control (FedMSPC) framework based on Federated\nPrincipal Component Analysis (PCA) and Secure Multiparty Computation to foster\nthe incentive for closer collaboration of stakeholders along value chains. We\ntested our approach on two industrial benchmark data sets - SECOM and ST-AWFD.\nOur empirical results demonstrate the superior fault detection capability of\nthe proposed approach compared to standard, single-party (multiway) PCA.\nFurthermore, we showcase the possibility of our framework to provide\nprivacy-preserving fault diagnosis to each data holder in the value chain to\nunderpin the benefits of secure data sharing and federated process modeling.",
    "descriptor": "",
    "authors": [
      "Du Nguyen Duy",
      "David Gabauer",
      "Ramin Nikzad-Langerodi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.01645"
  },
  {
    "id": "arXiv:2211.01646",
    "title": "Adversarial Data Augmentation Using VAE-GAN for Disordered Speech  Recognition",
    "abstract": "Automatic recognition of disordered speech remains a highly challenging task\nto date. The underlying neuro-motor conditions, often compounded with\nco-occurring physical disabilities, lead to the difficulty in collecting large\nquantities of impaired speech required for ASR system development. This paper\npresents novel variational auto-encoder generative adversarial network\n(VAE-GAN) based personalized disordered speech augmentation approaches that\nsimultaneously learn to encode, generate and discriminate synthesized impaired\nspeech. Separate latent features are derived to learn dysarthric speech\ncharacteristics and phoneme context representations. Self-supervised\npre-trained Wav2vec 2.0 embedding features are also incorporated. Experiments\nconducted on the UASpeech corpus suggest the proposed adversarial data\naugmentation approach consistently outperformed the baseline speed perturbation\nand non-VAE GAN augmentation methods with trained hybrid TDNN and End-to-end\nConformer systems. After LHUC speaker adaptation, the best system using VAE-GAN\nbased augmentation produced an overall WER of 27.78% on the UASpeech test set\nof 16 dysarthric speakers, and the lowest published WER of 57.31% on the subset\nof speakers with \"Very Low\" intelligibility.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Zengrui Jin",
      "Xurong Xie",
      "Mengzhe Geng",
      "Tianzi Wang",
      "Shujie Hu",
      "Jiajun Deng",
      "Guinan Li",
      "Xunying Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01646"
  },
  {
    "id": "arXiv:2211.01665",
    "title": "From Auditable Quantum Authentication to Best-of-Both-Worlds Multiparty  Quantum Computation with Public Verifiable Identifiable Abort",
    "abstract": "We construct the first secure multiparty quantum computation with public\nverifiable identifiable abort (MPQC-PVIA) protocol, where PVIA security enables\noutside observers with only classical computational power to agree on the\nidentity of a malicious party in case of an abort. Moreover, our MPQC is the\nfirst quantum setting to provide Best-of-Both-Worlds (BoBW) security, which\nattains full security with an honest majority and is secure with abort if the\nmajority is dishonest. At the heart of our construction is a generic\ntransformation called Auditable Quantum Authentication (AQA) that publicly\nidentifies the malicious sender with overwhelming probability. Our approach\ncomes with several advantages over the traditional way of building MPQC\nprotocols. First, instead of following the Clifford code paradigm, our protocol\ncan be based on a variety of authentication codes. Second, the online phase of\nour MPQC requires only classical communications. Third, our construction can\nachieve distributed computation via a carefully crafted protocol design, which\ncan be adjusted to an MPQC that conditionally guarantees output delivery.",
    "descriptor": "",
    "authors": [
      "Mi-Ying",
      "Huang",
      "Er-Cheng Tang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01665"
  },
  {
    "id": "arXiv:2211.01668",
    "title": "A Data-Driven Approach to Quantum Cross-Platform Verification",
    "abstract": "The task of testing whether two uncharacterized devices behave in the same\nway, known as cross-platform verification, is crucial for benchmarking quantum\nsimulators and near-term quantum computers. Cross-platform verification becomes\nincreasingly challenging as the system's dimensionality increases, and has so\nfar remained intractable for continuous variable quantum systems. In this\nLetter, we develop a data-driven approach, working with limited noisy data and\nsuitable for continuous variable quantum states. Our approach is based on a\nconvolutional neural network that assesses the similarity of quantum states\nbased on a lower-dimensional state representation built from measurement data.\nThe network can be trained offline with classically simulated data, and is\ndemonstrated here on non-Gaussian quantum states for which cross-platform\nverification could not be achieved with previous techniques. It can also be\napplied to cross-platform verification of quantum dynamics and to the problem\nof experimentally testing whether two quantum states are equivalent up to\nGaussian unitary transformations.",
    "descriptor": "",
    "authors": [
      "Ya-Dong Wu",
      "Yan Zhu",
      "Ge Bai",
      "Yuexuan Wang",
      "Giulio Chiribella"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01668"
  },
  {
    "id": "arXiv:2211.01669",
    "title": "Channel-Aware Pretraining of Joint Encoder-Decoder Self-Supervised Model  for Telephonic-Speech ASR",
    "abstract": "This paper proposes a novel technique to obtain better downstream ASR\nperformance from a joint encoder-decoder self-supervised model when trained\nwith speech pooled from two different channels (narrow and wide band). The\njoint encoder-decoder self-supervised model extends the HuBERT model with a\nTransformer decoder. HuBERT performs clustering of features and predicts the\nclass of every input frame. In simple pooling, which is our baseline, there is\nno way to identify the channel information. To incorporate channel information,\nwe have proposed non-overlapping cluster IDs for speech from different\nchannels. Our method gives a relative improvement of ~ 5% over the joint\nencoder-decoder self-supervised model built with simple pooling of data, which\nserves as our baseline.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Vrunda N. Sukhadia",
      "A. Arunkumar",
      "S. Umesh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01669"
  },
  {
    "id": "arXiv:2211.01670",
    "title": "Active CT Reconstruction with a Learned Sampling Policy",
    "abstract": "Computed tomography (CT) is a widely-used imaging technology that assists\nclinical decision-making with high-quality human body representations. To\nreduce the radiation dose posed by CT, sparse-view and limited-angle CT are\ndeveloped with preserved image quality. However, these methods are still stuck\nwith a fixed or uniform sampling strategy, which inhibits the possibility of\nacquiring a better image with an even reduced dose. In this paper, we explore\nthis possibility via learning an active sampling policy that optimizes the\nsampling positions for patient-specific, high-quality reconstruction. To this\nend, we design an \\textit{intelligent agent} for active recommendation of\nsampling positions based on on-the-fly reconstruction with obtained sinograms\nin a progressive fashion. With such a design, we achieve better performances on\nthe NIH-AAPM dataset over popular uniform sampling, especially when the number\nof views is small. Finally, such a design also enables RoI-aware reconstruction\nwith improved reconstruction quality within regions of interest (RoI's) that\nare clinically important. Experiments on the VerSe dataset demonstrate this\nability of our sampling policy, which is difficult to achieve based on uniform\nsampling.",
    "descriptor": "",
    "authors": [
      "Ce Wang",
      "Kun Shang",
      "Haimiao Zhang",
      "Shang Zhao",
      "Dong Liang",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01670"
  },
  {
    "id": "arXiv:2211.01689",
    "title": "Isotropic Gaussian Processes on Finite Spaces of Graphs",
    "abstract": "We propose a principled way to define Gaussian process priors on various sets\nof unweighted graphs: directed or undirected, with or without loops. We endow\neach of these sets with a geometric structure, inducing the notions of\ncloseness and symmetries, by turning them into a vertex set of an appropriate\nmetagraph. Building on this, we describe the class of priors that respect this\nstructure and are analogous to the Euclidean isotropic processes, like squared\nexponential or Mat\\'ern. We propose an efficient computational technique for\nthe ostensibly intractable problem of evaluating these priors' kernels, making\nsuch Gaussian processes usable within the usual toolboxes and downstream\napplications. We go further to consider sets of equivalence classes of\nunweighted graphs and define the appropriate versions of priors thereon. We\nprove a hardness result, showing that in this case, exact kernel computation\ncannot be performed efficiently. However, we propose a simple Monte Carlo\napproximation for handling moderately sized cases. Inspired by applications in\nchemistry, we illustrate the proposed techniques on a real molecular property\nprediction task in the small data regime.",
    "descriptor": "",
    "authors": [
      "Viacheslav Borovitskiy",
      "Mohammad Reza Karimi",
      "Vignesh Ram Somnath",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01689"
  },
  {
    "id": "arXiv:2211.01698",
    "title": "Scaling up the self-optimization model by means of on-the-fly  computation of weights",
    "abstract": "The Self-Optimization (SO) model is a useful computational model for\ninvestigating self-organization in \"soft\" Artificial life (ALife) as it has\nbeen shown to be general enough to model various complex adaptive systems. So\nfar, existing work has been done on relatively small network sizes, precluding\nthe investigation of novel phenomena that might emerge from the complexity\narising from large numbers of nodes interacting in interconnected networks.\nThis work introduces a novel implementation of the SO model that scales as\n$\\mathcal{O}\\left(N^{2}\\right)$ with respect to the number of nodes $N$, and\ndemonstrates the applicability of the SO model to networks with system sizes\nseveral orders of magnitude higher than previously was investigated. Removing\nthe prohibitive computational cost of the naive $\\mathcal{O}\\left(N^{3}\\right)$\nalgorithm, our on-the-fly computation paves the way for investigating\nsubstantially larger system sizes, allowing for more variety and complexity in\nfuture studies.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Natalya Weber",
      "Werner Koch",
      "Tom Froese"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.01698"
  },
  {
    "id": "arXiv:2211.01704",
    "title": "Cutting Through the Noise: An Empirical Comparison of Psychoacoustic and  Envelope-based Features for Machinery Fault Detection",
    "abstract": "Acoustic-based fault detection has a high potential to monitor the health\ncondition of mechanical parts. However, the background noise of an industrial\nenvironment may negatively influence the performance of fault detection.\nLimited attention has been paid to improving the robustness of fault detection\nagainst industrial environmental noise. Therefore, we present the Lenze\nproduction background-noise (LPBN) real-world dataset and an automated and\nnoise-robust auditory inspection (ARAI) system for the end-of-line inspection\nof geared motors. An acoustic array is used to acquire data from motors with a\nminor fault, major fault, or which are healthy. A benchmark is provided to\ncompare the psychoacoustic features with different types of envelope features\nbased on expert knowledge of the gearbox. To the best of our knowledge, we are\nthe first to apply time-varying psychoacoustic features for fault detection. We\ntrain a state-of-the-art one-class-classifier, on samples from healthy motors\nand separate the faulty ones for fault detection using a threshold. The\nbest-performing approaches achieve an area under curve of 0.87 (logarithm\nenvelope), 0.86 (time-varying psychoacoustics), and 0.91 (combination of both).",
    "descriptor": "",
    "authors": [
      "Peter Wi\u00dfbrock",
      "Yvonne Richter",
      "David Pelkmann",
      "Zhao Ren",
      "Gregory Palmer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01704"
  },
  {
    "id": "arXiv:2211.01716",
    "title": "Discussion of Features for Acoustic Anomaly Detection under Industrial  Disturbing Noise in an End-of-Line Test of Geared Motors",
    "abstract": "In the end-of-line test of geared motors, the evaluation of product qual-ity\nis important. Due to time constraints and the high diversity of variants,\nacous-tic measurements are more economical than vibration measurements.\nHowever, the acoustic data is affected by industrial disturbing noise.\nTherefore, the aim of this study is to investigate the robustness of features\nused for anomaly detection in geared motor end-of-line testing. A real-world\ndataset with typical faults and acoustic disturbances is recorded by an\nacoustic array. This includes industrial noise from the production and\nsystematically produced disturbances, used to compare the robustness. Overall,\nit is proposed to apply features extracted from a log-envelope spectrum\ntogether with psychoacoustic features. The anomaly de-tection is done by using\nthe isolation forest or the more universal bagging random miner. Most\ndisturbances can be circumvented, while the use of a hammer or air pressure\noften causes problems. In general, these results are important for condi-tion\nmonitoring tasks that are based on acoustic or vibration measurements.\nFur-thermore, a real-world problem description is presented to improve common\nsig-nal processing and machine learning tasks.",
    "descriptor": "",
    "authors": [
      "Peter Wissbrock",
      "David Pelkmann",
      "Yvonne Richter"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01716"
  },
  {
    "id": "arXiv:2211.01738",
    "title": "Analysis of a Deep Learning Model for 12-Lead ECG Classification Reveals  Learned Features Similar to Diagnostic Criteria",
    "abstract": "Despite their remarkable performance, deep neural networks remain unadopted\nin clinical practice, which is considered to be partially due to their lack in\nexplainability. In this work, we apply attribution methods to a pre-trained\ndeep neural network (DNN) for 12-lead electrocardiography classification to\nopen this \"black box\" and understand the relationship between model prediction\nand learned features. We classify data from a public data set and the\nattribution methods assign a \"relevance score\" to each sample of the classified\nsignals. This allows analyzing what the network learned during training, for\nwhich we propose quantitative methods: average relevance scores over a)\nclasses, b) leads, and c) average beats. The analyses of relevance scores for\natrial fibrillation (AF) and left bundle branch block (LBBB) compared to\nhealthy controls show that their mean values a) increase with higher\nclassification probability and correspond to false classifications when around\nzero, and b) correspond to clinical recommendations regarding which lead to\nconsider. Furthermore, c) visible P-waves and concordant T-waves result in\nclearly negative relevance scores in AF and LBBB classification, respectively.\nIn summary, our analysis suggests that the DNN learned features similar to\ncardiology textbook knowledge.",
    "descriptor": "",
    "authors": [
      "Theresa Bender",
      "Jacqueline Michelle Beinecke",
      "Dagmar Krefting",
      "Carolin M\u00fcller",
      "Henning Dathe",
      "Tim Seidler",
      "Nicolai Spicher",
      "Anne-Christin Hauschild"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01738"
  },
  {
    "id": "arXiv:2211.01756",
    "title": "Speech-based emotion recognition with self-supervised models using  attentive channel-wise correlations and label smoothing",
    "abstract": "When recognizing emotions from speech, we encounter two common problems: how\nto optimally capture emotion-relevant information from the speech signal and\nhow to best quantify or categorize the noisy subjective emotion labels.\nSelf-supervised pre-trained representations can robustly capture information\nfrom speech enabling state-of-the-art results in many downstream tasks\nincluding emotion recognition. However, better ways of aggregating the\ninformation across time need to be considered as the relevant emotion\ninformation is likely to appear piecewise and not uniformly across the signal.\nFor the labels, we need to take into account that there is a substantial degree\nof noise that comes from the subjective human annotations. In this paper, we\npropose a novel approach to attentive pooling based on correlations between the\nrepresentations' coefficients combined with label smoothing, a method aiming to\nreduce the confidence of the classifier on the training labels. We evaluate our\nproposed approach on the benchmark dataset IEMOCAP, and demonstrate high\nperformance surpassing that in the literature. The code to reproduce the\nresults is available at github.com/skakouros/s3prl_attentive_correlation.",
    "descriptor": "\nComments: Submitted to IEEE-ICASSP 2023\n",
    "authors": [
      "Sofoklis Kakouros",
      "Themos Stafylakis",
      "Ladislav Mosner",
      "Lukas Burget"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01756"
  },
  {
    "id": "arXiv:2211.01762",
    "title": "Stock Trading Volume Prediction with Dual-Process Meta-Learning",
    "abstract": "Volume prediction is one of the fundamental objectives in the Fintech area,\nwhich is helpful for many downstream tasks, e.g., algorithmic trading. Previous\nmethods mostly learn a universal model for different stocks. However, this kind\nof practice omits the specific characteristics of individual stocks by applying\nthe same set of parameters for different stocks. On the other hand, learning\ndifferent models for each stock would face data sparsity or cold start problems\nfor many stocks with small capitalization. To take advantage of the data scale\nand the various characteristics of individual stocks, we propose a dual-process\nmeta-learning method that treats the prediction of each stock as one task under\nthe meta-learning framework. Our method can model the common pattern behind\ndifferent stocks with a meta-learner, while modeling the specific pattern for\neach stock across time spans with stock-dependent parameters. Furthermore, we\npropose to mine the pattern of each stock in the form of a latent variable\nwhich is then used for learning the parameters for the prediction module. This\nmakes the prediction procedure aware of the data pattern. Extensive experiments\non volume predictions show that our method can improve the performance of\nvarious baseline models. Further analyses testify the effectiveness of our\nproposed meta-learning framework.",
    "descriptor": "\nComments: 16 pages, 3 figures, 5 tables. Published in ECML-PKDD 2022\n",
    "authors": [
      "Ruibo Chen",
      "Wei Li",
      "Zhiyuan Zhang",
      "Ruihan Bao",
      "Keiko Harimoto",
      "Xu Sun"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01762"
  },
  {
    "id": "arXiv:2211.01784",
    "title": "MALUNet: A Multi-Attention and Light-weight UNet for Skin Lesion  Segmentation",
    "abstract": "Recently, some pioneering works have preferred applying more complex modules\nto improve segmentation performances. However, it is not friendly for actual\nclinical environments due to limited computing resources. To address this\nchallenge, we propose a light-weight model to achieve competitive performances\nfor skin lesion segmentation at the lowest cost of parameters and computational\ncomplexity so far. Briefly, we propose four modules: (1) DGA consists of\ndilated convolution and gated attention mechanisms to extract global and local\nfeature information; (2) IEA, which is based on external attention to\ncharacterize the overall datasets and enhance the connection between samples;\n(3) CAB is composed of 1D convolution and fully connected layers to perform a\nglobal and local fusion of multi-stage features to generate attention maps at\nchannel axis; (4) SAB, which operates on multi-stage features by a shared 2D\nconvolution to generate attention maps at spatial axis. We combine four modules\nwith our U-shape architecture and obtain a light-weight medical image\nsegmentation model dubbed as MALUNet. Compared with UNet, our model improves\nthe mIoU and DSC metrics by 2.39% and 1.49%, respectively, with a 44x and 166x\nreduction in the number of parameters and computational complexity. In\naddition, we conduct comparison experiments on two skin lesion segmentation\ndatasets (ISIC2017 and ISIC2018). Experimental results show that our model\nachieves state-of-the-art in balancing the number of parameters, computational\ncomplexity and segmentation performances. Code is available at\nhttps://github.com/JCruan519/MALUNet.",
    "descriptor": "\nComments: 7 pages, 7 figures, 5 tables; This work has been accepted as a regular paper in IEEE BIBM 2022\n",
    "authors": [
      "Jiacheng Ruan",
      "Suncheng Xiang",
      "Mingye Xie",
      "Ting Liu",
      "Yuzhuo Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01784"
  },
  {
    "id": "arXiv:2211.01798",
    "title": "Phase Transitions in Learning and Earning under Price Protection  Guarantee",
    "abstract": "Motivated by the prevalence of ``price protection guarantee\", which allows a\ncustomer who purchased a product in the past to receive a refund from the\nseller during the so-called price protection period (typically defined as a\ncertain time window after the purchase date) in case the seller decides to\nlower the price, we study the impact of such policy on the design of online\nlearning algorithm for data-driven dynamic pricing with initially unknown\ncustomer demand. We consider a setting where a firm sells a product over a\nhorizon of $T$ time steps. For this setting, we characterize how the value of\n$M$, the length of price protection period, can affect the optimal regret of\nthe learning process. We show that the optimal regret is\n$\\tilde{\\Theta}(\\sqrt{T}+\\min\\{M,\\,T^{2/3}\\})$ by first establishing a\nfundamental impossible regime with novel regret lower bound instances. Then, we\npropose LEAP, a phased exploration type algorithm for \\underline{L}earning and\n\\underline{EA}rning under \\underline{P}rice Protection to match this lower\nbound up to logarithmic factors or even doubly logarithmic factors (when there\nare only two prices available to the seller). Our results reveal the surprising\nphase transitions of the optimal regret with respect to $M$. Specifically, when\n$M$ is not too large, the optimal regret has no major difference when compared\nto that of the classic setting with no price protection guarantee. We also show\nthat there exists an upper limit on how much the optimal regret can deteriorate\nwhen $M$ grows large. Finally, we conduct extensive numerical experiments to\nshow the benefit of LEAP over other heuristic methods for this problem.",
    "descriptor": "",
    "authors": [
      "Qing Feng",
      "Ruihao Zhu",
      "Stefanus Jasin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01798"
  },
  {
    "id": "arXiv:2211.01804",
    "title": "Wasserstein Steepest Descent Flows of Discrepancies with Riesz Kernels",
    "abstract": "The aim of this paper is twofold. Based on the geometric Wasserstein tangent\nspace, we first introduce Wasserstein steepest descent flows. These are locally\nabsolutely continuous curves in the Wasserstein space whose tangent vectors\npoint into a steepest descent direction of a given functional. This allows the\nuse of Euler forward schemes instead of the minimizing movement scheme (MMS)\nintroduced by Jordan, Kinderlehrer, and Otto. The MMS finds Wasserstein\ngradient flows by successively computing Wasserstein proxies. For locally\nLipschitz continuous functionals which are $\\lambda$-convex along generalized\ngeodesics, we show that there exists a unique Wasserstein steepest descent flow\ncoinciding with the Wasserstein gradient flow.\nThe second aim is to study Wasserstein flows of the (maximum mean)\ndiscrepancy with respect to Riesz kernels. The crucial part is hereby the\ntreatment of the interaction energy. Although it is not $\\lambda$-convex along\ngeneralized geodesics, we give analytic expressions for Wasserstein steepest\ndescent flows of the interaction energy starting at Dirac measures. In contrast\nto smooth kernels, the particle may explode, i.e., the particle goes over to\nnon-Dirac measures. The computation of steepest descent flows amounts to\nfinding equilibrium measures with external fields, which nicely links\nWasserstein flows of interaction energies with potential theory. Furthermore,\nwe prove convergence of MMS to our Wasserstein steepest descent flows. Finally,\nwe provide analytic Wasserstein steepest descent flows of discrepancies in one\ndimension and numerical simulations in two and three dimensions showing\nrelations to interaction energy flows.",
    "descriptor": "",
    "authors": [
      "Johannes Hertrich",
      "Manuel Gr\u00e4f",
      "Robert Beinert",
      "Gabriele Steidl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.01804"
  },
  {
    "id": "arXiv:2211.01831",
    "title": "Polynomial Life: the Structure of Adaptive Systems",
    "abstract": "We extend our earlier work on the compositional structure of cybernetic\nsystems in order to account for the embodiment of such systems. All their\ninteractions proceed through their bodies' boundaries: sensations impinge on\ntheir surfaces, and actions correspond to changes in their configurations. We\nformalize this morphological perspective using polynomial functors. The\n'internal universes' of systems are shown to constitute an indexed category of\nstatistical games over polynomials; their dynamics form an indexed category of\nbehaviours. We characterize 'active inference doctrines' as indexed functors\nbetween such categories, resolving a number of open problems in our earlier\nwork, and pointing to a formalization of the 'free energy principle' as adjoint\nto such doctrines. We illustrate our framework through fundamental examples\nfrom biology, including homeostasis, morphogenesis, and autopoiesis, and\nsuggest a formal connection between spatial navigation and the process of\nproof.",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102. Summary of work in progress; comments welcome\n",
    "authors": [
      "Toby St Clere Smithe"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Computer Science and Game Theory (cs.GT)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2211.01831"
  },
  {
    "id": "arXiv:2211.01832",
    "title": "Extra-Newton: A First Approach to Noise-Adaptive Accelerated  Second-Order Methods",
    "abstract": "This work proposes a universal and adaptive second-order method for\nminimizing second-order smooth, convex functions. Our algorithm achieves\n$O(\\sigma / \\sqrt{T})$ convergence when the oracle feedback is stochastic with\nvariance $\\sigma^2$, and improves its convergence to $O( 1 / T^3)$ with\ndeterministic oracles, where $T$ is the number of iterations. Our method also\ninterpolates these rates without knowing the nature of the oracle apriori,\nwhich is enabled by a parameter-free adaptive step-size that is oblivious to\nthe knowledge of smoothness modulus, variance bounds and the diameter of the\nconstrained set. To our knowledge, this is the first universal algorithm with\nsuch global guarantees within the second-order optimization literature.",
    "descriptor": "\nComments: 32 pages, 4 figures, accepted at NeurIPS 2022\n",
    "authors": [
      "Kimon Antonakopoulos",
      "Ali Kavis",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01832"
  },
  {
    "id": "arXiv:2211.01851",
    "title": "Adaptive Stochastic Variance Reduction for Non-convex Finite-Sum  Minimization",
    "abstract": "We propose an adaptive variance-reduction method, called AdaSpider, for\nminimization of $L$-smooth, non-convex functions with a finite-sum structure.\nIn essence, AdaSpider combines an AdaGrad-inspired [Duchi et al., 2011, McMahan\n& Streeter, 2010], but a fairly distinct, adaptive step-size schedule with the\nrecursive stochastic path integrated estimator proposed in [Fang et al., 2018].\nTo our knowledge, Adaspider is the first parameter-free non-convex\nvariance-reduction method in the sense that it does not require the knowledge\nof problem-dependent parameters, such as smoothness constant $L$, target\naccuracy $\\epsilon$ or any bound on gradient norms. In doing so, we are able to\ncompute an $\\epsilon$-stationary point with $\\tilde{O}\\left(n +\n\\sqrt{n}/\\epsilon^2\\right)$ oracle-calls, which matches the respective lower\nbound up to logarithmic factors.",
    "descriptor": "\nComments: 23 pages, 2 figures, accepted at NeurIPS 2022\n",
    "authors": [
      "Ali Kavis",
      "Stratis Skoulakis",
      "Kimon Antonakopoulos",
      "Leello Tadesse Dadi",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01851"
  },
  {
    "id": "arXiv:2211.01877",
    "title": "Convex Clustering through MM: An Efficient Algorithm to Perform  Hierarchical Clustering",
    "abstract": "Convex clustering is a modern method with both hierarchical and $k$-means\nclustering characteristics. Although convex clustering can capture the complex\nclustering structure hidden in data, the existing convex clustering algorithms\nare not scalable to large data sets with sample sizes greater than ten\nthousand. Moreover, it is known that convex clustering sometimes fails to\nproduce hierarchical clustering structures. This undesirable phenomenon is\ncalled cluster split and makes it difficult to interpret clustering results. In\nthis paper, we propose convex clustering through majorization-minimization\n(CCMM) -- an iterative algorithm that uses cluster fusions and sparsity to\nenforce a complete cluster hierarchy with reduced memory usage. In the CCMM\nalgorithm, the diagonal majorization technique makes a highly efficient update\nfor each iteration. With a current desktop computer, the CCMM algorithm can\nsolve a single clustering problem featuring over one million objects in\nseven-dimensional space within 70 seconds.",
    "descriptor": "\nComments: 23 pages, 15 figures\n",
    "authors": [
      "Daniel J. W. Touw",
      "Patrick J. F. Groenen",
      "Yoshikazu Terada"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01877"
  },
  {
    "id": "arXiv:2211.01885",
    "title": "Using U-Net Network for Efficient Brain Tumor Segmentation in MRI Images",
    "abstract": "Magnetic Resonance Imaging (MRI) is the most commonly used non-intrusive\ntechnique for medical image acquisition. Brain tumor segmentation is the\nprocess of algorithmically identifying tumors in brain MRI scans. While many\napproaches have been proposed in the literature for brain tumor segmentation,\nthis paper proposes a lightweight implementation of U-Net. Apart from providing\nreal-time segmentation of MRI scans, the proposed architecture does not need\nlarge amount of data to train the proposed lightweight U-Net. Moreover, no\nadditional data augmentation step is required. The lightweight U-Net shows very\npromising results on BITE dataset and it achieves a mean\nintersection-over-union (IoU) of 89% while outperforming the standard benchmark\nalgorithms. Additionally, this work demonstrates an effective use of the three\nperspective planes, instead of the original three-dimensional volumetric\nimages, for simplified brain tumor segmentation.",
    "descriptor": "\nComments: Published in Healthcare Analytics, 2022\n",
    "authors": [
      "Jason Walsh",
      "Alice Othmani",
      "Mayank Jain",
      "Soumyabrata Dev"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.01885"
  },
  {
    "id": "arXiv:2211.01892",
    "title": "Deep meta-learning for the selection of accurate ultrasound based breast  mass classifier",
    "abstract": "Standard classification methods based on handcrafted morphological and\ntexture features have achieved good performance in breast mass differentiation\nin ultrasound (US). In comparison to deep neural networks, commonly perceived\nas \"black-box\" models, classical techniques are based on features that have\nwell-understood medical and physical interpretation. However, classifiers based\non morphological features commonly underperform in the presence of the\nshadowing artifact and ill-defined mass borders, while texture based\nclassifiers may fail when the US image is too noisy. Therefore, in practice it\nwould be beneficial to select the classification method based on the appearance\nof the particular US image. In this work, we develop a deep meta-network that\ncan automatically process input breast mass US images and recommend whether to\napply the shape or texture based classifier for the breast mass\ndifferentiation. Our preliminary results demonstrate that meta-learning\ntechniques can be used to improve the performance of the standard classifiers\nbased on handcrafted features. With the proposed meta-learning based approach,\nwe achieved the area under the receiver operating characteristic curve of 0.95\nand accuracy of 0.91.",
    "descriptor": "\nComments: Work presented at the 2022 IEEE International Ultrasonics Symposium, submission #2078\n",
    "authors": [
      "Michal Byra",
      "Piotr Karwat",
      "Ivan Ryzhankow",
      "Piotr Komorowski",
      "Ziemowit Klimonda",
      "Lukasz Fura",
      "Anna Pawlowska",
      "Norbert Zolek",
      "Jerzy Litniewski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.01892"
  },
  {
    "id": "arXiv:2211.01902",
    "title": "Martian Ionosphere Electron Density Prediction Using Bagged Trees",
    "abstract": "The availability of Martian atmospheric data provided by several Martian\nmissions broadened the opportunity to investigate and study the conditions of\nthe Martian ionosphere. As such, ionospheric models play a crucial part in\nimproving our understanding of ionospheric behavior in response to different\nspatial, temporal, and space weather conditions. This work represents an\ninitial attempt to construct an electron density prediction model of the\nMartian ionosphere using machine learning. The model targets the ionosphere at\nsolar zenith ranging from 70 to 90 degrees, and as such only utilizes\nobservations from the Mars Global Surveyor mission. The performance of\ndifferent machine learning methods was compared in terms of root mean square\nerror, coefficient of determination, and mean absolute error. The bagged\nregression trees method performed best out of all the evaluated methods.\nFurthermore, the optimized bagged regression trees model outperformed other\nMartian ionosphere models from the literature (MIRI and NeMars) in finding the\npeak electron density value, and the peak density height in terms of\nroot-mean-square error and mean absolute error.",
    "descriptor": "\nComments: Accepted for presentation by the ICECTA 2022 conference\n",
    "authors": [
      "Abdollah Masoud Darya",
      "Noora Alameri",
      "Muhammad Mubasshir Shaikh",
      "Ilias Fernini"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01902"
  },
  {
    "id": "arXiv:2211.01903",
    "title": "A Consistent Estimator for Confounding Strength",
    "abstract": "Regression on observational data can fail to capture a causal relationship in\nthe presence of unobserved confounding. Confounding strength measures this\nmismatch, but estimating it requires itself additional assumptions. A common\nassumption is the independence of causal mechanisms, which relies on\nconcentration phenomena in high dimensions. While high dimensions enable the\nestimation of confounding strength, they also necessitate adapted estimators.\nIn this paper, we derive the asymptotic behavior of the confounding strength\nestimator by Janzing and Sch\\\"olkopf (2018) and show that it is generally not\nconsistent. We then use tools from random matrix theory to derive an adapted,\nconsistent estimator.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Luca Rendsburg",
      "Leena Chennuru Vankadara",
      "Debarghya Ghoshdastidar",
      "Ulrike von Luxburg"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01903"
  },
  {
    "id": "arXiv:2211.01933",
    "title": "Automatic Crater Shape Retrieval using Unsupervised and Semi-Supervised  Systems",
    "abstract": "Impact craters are formed due to continuous impacts on the surface of\nplanetary bodies. Most recent deep learning-based crater detection methods\ntreat craters as circular shapes, and less attention is paid to extracting the\nexact shapes of craters. Extracting precise shapes of the craters can be\nhelpful for many advanced analyses, such as crater formation. This paper\nproposes a combination of unsupervised non-deep learning and semi-supervised\ndeep learning approach to accurately extract shapes of the craters and detect\nmissing craters from the existing catalog. In unsupervised non-deep learning,\nwe have proposed an adaptive rim extraction algorithm to extract craters'\nshapes. In this adaptive rim extraction algorithm, we utilized the elevation\nprofiles of DEMs and applied morphological operation on DEM-derived slopes to\nextract craters' shapes. The extracted shapes of the craters are used in\nsemi-supervised deep learning to get the locations, size, and refined shapes.\nFurther, the extracted shapes of the craters are utilized to improve the\nestimate of the craters' diameter, depth, and other morphological factors. The\ncraters' shape, estimated diameter, and depth with other morphological factors\nwill be publicly available.",
    "descriptor": "",
    "authors": [
      "Atal Tewari",
      "Vikrant Jain",
      "Nitin Khanna"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01933"
  },
  {
    "id": "arXiv:2211.01936",
    "title": "Differences in collaboration structures and impact among prominent  researchers in Europe and North America",
    "abstract": "Scientists collaborate through intricate networks, which impact the quality\nand scope of their research. At the same time, funding and institutional\narrangements, as well as scientific and political cultures, affect the\nstructure of collaboration networks. Since such arrangements and cultures\ndiffer across regions in the world in systematic ways, we surmise that\ncollaboration networks and impact should also differ systematically across\nregions. To test this, we compare the structure of collaboration networks among\nprominent researchers in North America and Europe. We find that prominent\nresearchers in Europe establish denser collaboration networks, whereas those in\nNorth-America establish more decentralized networks. We also find that the\nimpact of the publications of prominent researchers in North America is\nsignificantly higher than for those in Europe, both when they collaborate with\nother prominent researchers and when they do not. Although Europeans\ncollaborate with other prominent researchers more often, which increases their\nimpact, we also find that repeated collaboration among prominent researchers\ndecreases the synergistic effect of collaborating.",
    "descriptor": "",
    "authors": [
      "Lluis Danus",
      "Carles Muntaner",
      "Alexander Krauss",
      "Marta Sales-Pardo",
      "Roger Guimera"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.01936"
  },
  {
    "id": "arXiv:2211.01943",
    "title": "Quantized Precoding and RIS-Assisted Modulation for Integrated Sensing  and Communications Systems",
    "abstract": "In this paper, we present a novel reconfigurable intelligent surface\n(RIS)-assisted integrated sensing and communication (ISAC) system with 1-bit\nquantization at the ISAC base station. An RIS is introduced in the ISAC system\nto mitigate the effects of coarse quantization and to enable the co-existence\nbetween sensing and communication functionalities. Specifically, we design\ntransmit precoder to obtain 1-bit sensing waveforms having a desired radiation\npattern. The RIS phase shifts are then designed to modulate the 1-bit sensing\nwaveform to transmit M-ary phase shift keying symbols to users. Through\nnumerical simulations, we show that the proposed method offers significantly\nimproved symbol error probabilities when compared to MIMO communication systems\nhaving quantized linear precoders, while still offering comparable sensing\nperformance as that of unquantized sensing systems.",
    "descriptor": "",
    "authors": [
      "R.S. Prasobh Sankar",
      "Sundeep Prabhakar Chepuri"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.01943"
  },
  {
    "id": "arXiv:2211.01960",
    "title": "FingerFlex: Inferring Finger Trajectories from ECoG signals",
    "abstract": "Motor brain-computer interface (BCI) development relies critically on neural\ntime series decoding algorithms. Recent advances in deep learning architectures\nallow for automatic feature selection to approximate higher-order dependencies\nin data. This article presents the FingerFlex model - a convolutional\nencoder-decoder architecture adapted for finger movement regression on\nelectrocorticographic (ECoG) brain data. State-of-the-art performance was\nachieved on a publicly available BCI competition IV dataset 4 with a\ncorrelation coefficient between true and predicted trajectories up to 0.74. The\npresented method provides the opportunity for developing fully-functional\nhigh-precision cortical motor brain-computer interfaces.",
    "descriptor": "\nComments: 6 pages, 3 figures, 4 tables. Preprint. Under review\n",
    "authors": [
      "Vladislav Lomtev",
      "Alexander Kovalev",
      "Alexey Timchenko"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01960"
  },
  {
    "id": "arXiv:2211.01973",
    "title": "On the invariant region for compressible Euler equations with a general  equation of state",
    "abstract": "The state space for solutions of the compressible Euler equations with a\ngeneral equation of state is examined. An arbitrary equation of state is\nallowed, subject only to the physical requirements of thermodynamics. An\ninvariant region of the resulting Euler system is identified and the convexity\nproperty of this region is justified by using only very minimal thermodynamical\nassumptions. Finally, we show how an invariant-region-preserving (IRP) limiter\ncan be constructed for use in high order finite-volume type schemes to solve\nthe compressible Euler equations with a general constitutive relation.",
    "descriptor": "",
    "authors": [
      "Hailiang Liu",
      "Ferdinand Thein"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.01973"
  },
  {
    "id": "arXiv:2211.01974",
    "title": "Discrete approximations to Dirichlet and Neumann Laplacians on a  half-space and norm resolvent convergence",
    "abstract": "We extend recent results on discrete approximations of the Laplacian in\n$\\mathbf{R}^d$ with norm resolvent convergence to the corresponding results for\nDirichlet and Neumann Laplacians on a half-space. The resolvents of the\ndiscrete Dirichlet/Neumann Laplacians are embedded into the continuum using\nnatural discretization and embedding operators. Norm resolvent convergence to\ntheir continuous counterparts is proven with a quadratic rate in the mesh size.\nThese results generalize with a limited rate to also include operators with a\nreal, bounded, and H\\\"older continuous potential, as well as certain functions\nof the Dirichlet/Neumann Laplacians, including any positive real power.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Horia Cornean",
      "Henrik Garde",
      "Arne Jensen"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01974"
  },
  {
    "id": "arXiv:2211.01977",
    "title": "Galois Groups of Linear Difference-Differential Equations",
    "abstract": "We study the relation between the Galois group $G$ of a linear\ndifference-differential system and two classes $\\mathcal{C}_1$ and\n$\\mathcal{C}_2$ of groups that are the Galois groups of the specializations of\nthe linear difference equation and the linear differential equation in this\nsystem respectively. We show that almost all groups in $\\mathcal{C}_1\\cup\n\\mathcal{C}_2$ are algebraic subgroups of $G$, and there is a nonempty subset\nof $\\mathcal{C}_1$ and a nonempty subset of $\\mathcal{C}_2$ such that $G$ is\nthe product of any pair of groups from these two subsets. These results have\npotential application to the computation of the Galois group of a linear\ndifference-differential system. We also give a criterion for testing linear\ndependence of elements in a simple difference-differential ring, which\ngeneralizes Kolchin's criterion for partial differential fields.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Ruyong Feng",
      "Wei Lu"
    ],
    "subjectives": [
      "Rings and Algebras (math.RA)",
      "Symbolic Computation (cs.SC)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2211.01977"
  },
  {
    "id": "arXiv:2211.01978",
    "title": "PEMP: Leveraging Physics Properties to Enhance Molecular Property  Prediction",
    "abstract": "Molecular property prediction is essential for drug discovery. In recent\nyears, deep learning methods have been introduced to this area and achieved\nstate-of-the-art performances. However, most of existing methods ignore the\nintrinsic relations between molecular properties which can be utilized to\nimprove the performances of corresponding prediction tasks. In this paper, we\npropose a new approach, namely Physics properties Enhanced Molecular Property\nprediction (PEMP), to utilize relations between molecular properties revealed\nby previous physics theory and physical chemistry studies. Specifically, we\nenhance the training of the chemical and physiological property predictors with\nrelated physics property prediction tasks. We design two different methods for\nPEMP, respectively based on multi-task learning and transfer learning. Both\nmethods include a model-agnostic molecule representation module and a property\nprediction module. In our implementation, we adopt both the state-of-the-art\nmolecule embedding models under the supervised learning paradigm and the\npretraining paradigm as the molecule representation module of PEMP,\nrespectively. Experimental results on public benchmark MoleculeNet show that\nthe proposed methods have the ability to outperform corresponding\nstate-of-the-art models.",
    "descriptor": "\nComments: 9 pages. Published in CIKM 2022\n",
    "authors": [
      "Yuancheng Sun",
      "Yimeng Chen",
      "Weizhi Ma",
      "Wenhao Huang",
      "Kang Liu",
      "Zhiming Ma",
      "Wei-Ying Ma",
      "Yanyan Lan"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01978"
  },
  {
    "id": "arXiv:2211.01990",
    "title": "Membership in moment cones, quiver semi-invariants, and generic  semi-stability for bipartite quivers",
    "abstract": "Let $Q$ be a bipartite quiver with vertex set $Q_0$ such that the number of\narrows between any two source and sink vertices is constant. Let\n$\\beta=(\\beta(x))_{x \\in Q_0}$ be a dimension vector of $Q$ with positive\ninteger coordinates, and let $\\Delta(Q, \\beta)$ be the moment cone associated\nto $(Q, \\beta)$. We show that the membership problem for $\\Delta(Q, \\beta)$ can\nbe solved in strongly polynomial time.\nAs a key step in our approach, we first solve the polytopal problem for\nsemi-invariants of $Q$ and its flag-extensions. Specifically, let $Q_{\\beta}$\nbe the flag-extension of $Q$ obtained by attaching a flag $\\mathcal{F}(x)$ of\nlength $\\beta(x)-1$ at every vertex $x$ of $Q$, and let $\\widetilde{\\beta}$ be\nthe extension of $\\beta$ to $Q_{\\beta}$ that takes values $1, \\ldots, \\beta(x)$\nalong the vertices of the flag $\\mathcal{F}(x)$ for every vertex $x$ of $Q$.\nFor an integral weight $\\widetilde{\\sigma}$ of $Q_{\\beta}$, let\n$K_{\\widetilde{\\sigma}}$ be the dimension of the space of semi-invariants of\nweight $\\widetilde{\\sigma}$ on the representation space of\n$\\widetilde{\\beta}$-dimensional complex representations of $Q_{\\beta}$.\nWe show that $K_{\\widetilde{\\sigma}}$ can be expressed as the number of\nlattice points of a certain hive-type polytope. This polytopal description\ntogether with Derksen-Weyman's Saturation Theorem for quiver semi-invariants\nallows us to use Tardos's algorithm to solve the membership problem for\n$\\Delta(Q,\\beta)$ in strongly polynomial time. In particular, this yields a\nstrongly polynomial time algorithm for solving the generic semi-stability\nproblem for representations of $Q$ and $Q_\\beta$.",
    "descriptor": "",
    "authors": [
      "Calin Chindris",
      "Brett Collins",
      "Daniel Kline"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2211.01990"
  },
  {
    "id": "arXiv:2211.02005",
    "title": "Robust Dependence Measure using RKHS based Uncertainty Moments and  Optimal Transport",
    "abstract": "Reliable measurement of dependence between variables is essential in many\napplications of statistics and machine learning. Current approaches for\ndependence estimation, especially density-based approaches, lack in precision,\nrobustness and/or interpretability (in terms of the type of dependence being\nestimated). We propose a two-step approach for dependence quantification\nbetween random variables: 1) We first decompose the probability density\nfunctions (PDF) of the variables involved in terms of multiple local moments of\nuncertainty that systematically and precisely identify the different regions of\nthe PDF (with special emphasis on the tail-regions). 2) We then compute an\noptimal transport map to measure the geometric similarity between the\ncorresponding sets of decomposed local uncertainty moments of the variables.\nDependence is then determined by the degree of one-to-one correspondence\nbetween the respective uncertainty moments of the variables in the optimal\ntransport map. We utilize a recently introduced Gaussian reproducing kernel\nHilbert space (RKHS) based framework for multi-moment uncertainty decomposition\nof the variables. Being based on the Gaussian RKHS, our approach is robust\ntowards outliers and monotone transformations of data, while the multiple\nmoments of uncertainty provide high resolution and interpretability of the type\nof dependence being quantified. We support these claims through some\npreliminary results using simulated data.",
    "descriptor": "",
    "authors": [
      "Rishabh Singh",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.02005"
  },
  {
    "id": "arXiv:2211.02012",
    "title": "Optimal Compression for Minimizing Classification Error Probability: an  Information-Theoretic Approach",
    "abstract": "We formulate the problem of performing optimal data compression under the\nconstraints that compressed data can be used for accurate classification in\nmachine learning. We show that this translates to a problem of minimizing the\nmutual information between data and its compressed version under the constraint\non error probability of classification is small when using the compressed data\nfor machine learning. We then provide analytical and computational methods to\ncharacterize the optimal trade-off between data compression and classification\nerror probability. First, we provide an analytical characterization for the\noptimal compression strategy for data with binary labels. Second, for data with\nmultiple labels, we formulate a set of convex optimization problems to\ncharacterize the optimal tradeoff, from which the optimal trade-off between the\nclassification error and compression efficiency can be obtained by numerically\nsolving the formulated optimization problems. We further show the improvements\nof our formulations over the information-bottleneck methods in classification\nperformance.",
    "descriptor": "\nComments: This work was done in Summer 2021\n",
    "authors": [
      "Jingchao Gao",
      "Ao Tang",
      "Weiyu Xu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.02012"
  },
  {
    "id": "arXiv:2211.02024",
    "title": "fMRI from EEG is only Deep Learning away: the use of interpretable DL to  unravel EEG-fMRI relationships",
    "abstract": "The access to activity of subcortical structures offers unique opportunity\nfor building intention dependent brain-computer interfaces, renders abundant\noptions for exploring a broad range of cognitive phenomena in the realm of\naffective neuroscience including complex decision making processes and the\neternal free-will dilemma and facilitates diagnostics of a range of\nneurological deceases. So far this was possible only using bulky, expensive and\nimmobile fMRI equipment. Here we present an interpretable domain grounded\nsolution to recover the activity of several subcortical regions from the\nmultichannel EEG data and demonstrate up to 60% correlation between the actual\nsubcortical blood oxygenation level dependent sBOLD signal and its EEG-derived\ntwin. Then, using the novel and theoretically justified weight interpretation\nmethodology we recover individual spatial and time-frequency patterns of scalp\nEEG predictive of the hemodynamic signal in the subcortical nuclei. The\ndescribed results not only pave the road towards wearable subcortical activity\nscanners but also showcase an automatic knowledge discovery process facilitated\nby deep learning technology in combination with an interpretable domain\nconstrained architecture and the appropriate downstream task.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Alexander Kovalev",
      "Ilia Mikheev",
      "Alexei Ossadtchi"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.02024"
  },
  {
    "id": "arXiv:2211.02032",
    "title": "To spike or not to spike: the whims of the Wonham filter in the strong  noise regime",
    "abstract": "We study the celebrated Shiryaev-Wonham filter in its historical setup of\nWonham (1964) where the hidden Markov jump process has two states. We are\ninterested in the weak noise regime for the observation equation.\nInterestingly, this becomes a strong noise regime for the filtering equations.\nEarlier results of the authors show the appearance of spikes in the filtered\nprocess, akin to a metastability phenomenon. This paper is aimed at\nunderstanding the smoothed optimal filter, which is relevant for any system\nwith feedback. In particular, we demonstrate that there is a sharp phase\ntransition between a spiking regime and a regime with perfect smoothing.",
    "descriptor": "\nComments: v1: Preliminary version\n",
    "authors": [
      "Bernardin C\u00e9dric",
      "Chhaibi Reda",
      "Najnudel Joseph",
      "Pellegrini Cl\u00e9ment"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.02032"
  },
  {
    "id": "arXiv:1804.02128",
    "title": "The Numerical Invariant Measure of Stochastic Differential Equations  With Markovian Switching",
    "abstract": "Comments: 23 pages, 4 figures",
    "descriptor": "\nComments: 23 pages, 4 figures\n",
    "authors": [
      "Xiaoyue Li",
      "Qianlin Ma",
      "Hongfu Yang",
      "Chenggui Yuan"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1804.02128"
  },
  {
    "id": "arXiv:1812.05948",
    "title": "Characterizing the Global Crowd Workforce: A Cross-Country Comparison of  Crowdworker Demographics",
    "abstract": "Comments: 36 pages, 20 figures, final version as published in Human Computation",
    "descriptor": "\nComments: 36 pages, 20 figures, final version as published in Human Computation\n",
    "authors": [
      "Lisa Posch",
      "Arnim Bleier",
      "Fabian Fl\u00f6ck",
      "Clemens M. Lechner",
      "Katharina Kinder-Kurlanda",
      "Denis Helic",
      "Markus Strohmaier"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/1812.05948"
  },
  {
    "id": "arXiv:1903.04923",
    "title": "Network Identification for Diffusively-Coupled Systems with Minimal Time  Complexity",
    "abstract": "Comments: 12 pages, 3 figures",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Miel Sharf",
      "Daniel Zelazo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1903.04923"
  },
  {
    "id": "arXiv:1909.03819",
    "title": "A Rewriting Logic Approach to Stochastic and Spatial Constraint System  Specification and Verification",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1805.07434",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1805.07434\n",
    "authors": [
      "Miguel Romero",
      "Sergio Ram\u00edrez",
      "Camilo Rocha",
      "Frank Valencia"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1909.03819"
  },
  {
    "id": "arXiv:1909.08191",
    "title": "Exploring Scholarly Data by Semantic Query on Knowledge Graph Embedding  Space",
    "abstract": "Comments: TPDL 2019; add appendix for the KG20C scholarly knowledge graph benchmark dataset",
    "descriptor": "\nComments: TPDL 2019; add appendix for the KG20C scholarly knowledge graph benchmark dataset\n",
    "authors": [
      "Hung Nghiep Tran",
      "Atsuhiro Takasu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/1909.08191"
  },
  {
    "id": "arXiv:1910.09143",
    "title": "Subgoal-based Exploration via Bayesian Optimization",
    "abstract": "Comments: Presented at TARL, ICLR 2019 workshop",
    "descriptor": "\nComments: Presented at TARL, ICLR 2019 workshop\n",
    "authors": [
      "Yijia Wang",
      "Matthias Poloczek",
      "Daniel R. Jiang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.09143"
  },
  {
    "id": "arXiv:1912.10069",
    "title": "Learning Reserve Prices in Second-Price Auctions",
    "abstract": "Comments: To appear in ITCS'23",
    "descriptor": "\nComments: To appear in ITCS'23\n",
    "authors": [
      "Yaonan Jin",
      "Pinyan Lu",
      "Tao Xiao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1912.10069"
  },
  {
    "id": "arXiv:2001.01075",
    "title": "Finite Difference/Galerkin Finite Element Simulation of the Semi-Linear  Wave Equation with Scale-Invariant Damping and Mass and Power Non-Linearity",
    "abstract": "Comments: I will use this study in a book project",
    "descriptor": "\nComments: I will use this study in a book project\n",
    "authors": [
      "Harun Selvitopi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2001.01075"
  },
  {
    "id": "arXiv:2003.07545",
    "title": "Interpretable Personalization via Policy Learning with Linear Decision  Boundaries",
    "abstract": "Interpretable Personalization via Policy Learning with Linear Decision  Boundaries",
    "descriptor": "",
    "authors": [
      "Zhaonan Qu",
      "Isabella Qian",
      "Zhengyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2003.07545"
  },
  {
    "id": "arXiv:2004.08380",
    "title": "Completeness of Nominal PROPs",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1904.07534",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1904.07534\n",
    "authors": [
      "Samuel Balco",
      "Alexander Kurz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2004.08380"
  },
  {
    "id": "arXiv:2006.05551",
    "title": "Recursive moment computation in Filon methods and application to  high-frequency wave scattering in two dimensions",
    "abstract": "Recursive moment computation in Filon methods and application to  high-frequency wave scattering in two dimensions",
    "descriptor": "",
    "authors": [
      "G. Maierhofer",
      "A. Iserles",
      "N. Peake"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.05551"
  },
  {
    "id": "arXiv:2007.05630",
    "title": "Computing Dense and Sparse Subgraphs of Weakly Closed Graphs",
    "abstract": "Comments: Appeared in ISAAC '20",
    "descriptor": "\nComments: Appeared in ISAAC '20\n",
    "authors": [
      "Tomohiro Koana",
      "Christian Komusiewicz",
      "Frank Sommer"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2007.05630"
  },
  {
    "id": "arXiv:2007.11831",
    "title": "DBS: Dynamic Batch Size For Distributed Deep Neural Network Training",
    "abstract": "Comments: The latest version of this article has been accepted by IEEE TETCI",
    "descriptor": "\nComments: The latest version of this article has been accepted by IEEE TETCI\n",
    "authors": [
      "Qing Ye",
      "Yuhao Zhou",
      "Mingjia Shi",
      "Yanan Sun",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.11831"
  },
  {
    "id": "arXiv:2007.15390",
    "title": "Sampling-based 3-D Line-of-Sight PWA Model Predictive Control for  Autonomous Rendezvous and Docking with a Tumbling Target",
    "abstract": "Comments: none",
    "descriptor": "\nComments: none\n",
    "authors": [
      "Dongting Li",
      "Rui-Qi Dong",
      "Yanning Guo",
      "Guangtao Ran",
      "Dongyu Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2007.15390"
  },
  {
    "id": "arXiv:2008.08844",
    "title": "Complete the Missing Half: Augmenting Aggregation Filtering with  Diversification for Graph Convolutional Networks",
    "abstract": "Comments: New Frontiers in Graph Learning (GLFrontiers) Workshop (Oral), NeurIPS 2022",
    "descriptor": "\nComments: New Frontiers in Graph Learning (GLFrontiers) Workshop (Oral), NeurIPS 2022\n",
    "authors": [
      "Sitao Luan",
      "Mingde Zhao",
      "Chenqing Hua",
      "Xiao-Wen Chang",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.08844"
  },
  {
    "id": "arXiv:2008.11753",
    "title": "Countdown games, and simulation on (succinct) one-counter nets",
    "abstract": "Comments: Some presentation improvements w.r.t. the previous version",
    "descriptor": "\nComments: Some presentation improvements w.r.t. the previous version\n",
    "authors": [
      "Petr Jancar",
      "Petr Osicka",
      "Zdenek Sawa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2008.11753"
  },
  {
    "id": "arXiv:2010.14860",
    "title": "The Evidence Lower Bound of Variational Autoencoders Converges to a Sum  of Three Entropies",
    "abstract": "The Evidence Lower Bound of Variational Autoencoders Converges to a Sum  of Three Entropies",
    "descriptor": "",
    "authors": [
      "Simon Damm",
      "Dennis Forster",
      "Dmytro Velychko",
      "Zhenwen Dai",
      "Asja Fischer",
      "J\u00f6rg L\u00fccke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.14860"
  },
  {
    "id": "arXiv:2011.04102",
    "title": "Reliable Off-policy Evaluation for Reinforcement Learning",
    "abstract": "Comments: 46 pages, 7 figures",
    "descriptor": "\nComments: 46 pages, 7 figures\n",
    "authors": [
      "Jie Wang",
      "Rui Gao",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.04102"
  },
  {
    "id": "arXiv:2101.09100",
    "title": "A Categorical Semantics for Bounded Petri Nets",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Fabrizio Romano Genovese",
      "Fosco Loregian",
      "Daniele Palombi"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.09100"
  },
  {
    "id": "arXiv:2101.10443",
    "title": "Towards glass-box CNNs",
    "abstract": "Towards glass-box CNNs",
    "descriptor": "",
    "authors": [
      "Piduguralla Manaswini",
      "Jignesh S. Bhatt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.10443"
  },
  {
    "id": "arXiv:2102.02649",
    "title": "A step towards a reinforcement learning de novo genome assembler",
    "abstract": "A step towards a reinforcement learning de novo genome assembler",
    "descriptor": "",
    "authors": [
      "Kleber Padovani",
      "Roberto Xavier",
      "Andre Carvalho",
      "Anna Reali",
      "Annie Chateau",
      "Ronnie Alves"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02649"
  },
  {
    "id": "arXiv:2102.04672",
    "title": "Native Type Theory",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Christian Williams",
      "Michael Stay"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2102.04672"
  },
  {
    "id": "arXiv:2102.08773",
    "title": "Predicting Lexical Complexity in English Texts: The Complex 2.0 Dataset",
    "abstract": "Predicting Lexical Complexity in English Texts: The Complex 2.0 Dataset",
    "descriptor": "",
    "authors": [
      "Matthew Shardlow",
      "Richard Evans",
      "Marcos Zampieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.08773"
  },
  {
    "id": "arXiv:2103.01189",
    "title": "Learners' Languages",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "David I. Spivak"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01189"
  },
  {
    "id": "arXiv:2103.11909",
    "title": "Identifying Machine-Paraphrased Plagiarism",
    "abstract": "Identifying Machine-Paraphrased Plagiarism",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Tom\u00e1\u0161 Folt\u00fdnek",
      "Norman Meuschke",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2103.11909"
  },
  {
    "id": "arXiv:2103.12450",
    "title": "Are Neural Language Models Good Plagiarists? A Benchmark for Neural  Paraphrase Detection",
    "abstract": "Are Neural Language Models Good Plagiarists? A Benchmark for Neural  Paraphrase Detection",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Norman Meuschke",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2103.12450"
  },
  {
    "id": "arXiv:2103.14027",
    "title": "USB: Universal-Scale Object Detection Benchmark",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Yosuke Shinya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14027"
  },
  {
    "id": "arXiv:2103.15670",
    "title": "On the Adversarial Robustness of Vision Transformers",
    "abstract": "Comments: Published in Transactions on Machine Learning Research (TMLR). Codes available at this https URL",
    "descriptor": "\nComments: Published in Transactions on Machine Learning Research (TMLR). Codes available at this https URL\n",
    "authors": [
      "Rulin Shao",
      "Zhouxing Shi",
      "Jinfeng Yi",
      "Pin-Yu Chen",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.15670"
  },
  {
    "id": "arXiv:2104.03814",
    "title": "Algorithmic Obfuscation for LDPC Decoders",
    "abstract": "Algorithmic Obfuscation for LDPC Decoders",
    "descriptor": "",
    "authors": [
      "Jingbo Zhou",
      "Xinmiao Zhang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.03814"
  },
  {
    "id": "arXiv:2105.03252",
    "title": "Constructing Initial Algebras Using Inflationary Iteration",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Andrew M. Pitts",
      "S. C. Steenkamp"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2105.03252"
  },
  {
    "id": "arXiv:2105.04355",
    "title": "Situated Transition Systems",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Chad Nester"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.04355"
  },
  {
    "id": "arXiv:2105.06186",
    "title": "Tracelet Hopf Algebras and Decomposition Spaces (Extended Abstract)",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Nicolas Behr",
      "Joachim Kock"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2105.06186"
  },
  {
    "id": "arXiv:2105.06244",
    "title": "A Graphical Calculus for Lagrangian Relations",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Cole Comfort",
      "Aleks Kissinger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Mathematical Physics (math-ph)",
      "Category Theory (math.CT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.06244"
  },
  {
    "id": "arXiv:2105.06763",
    "title": "Translating Extensive Form Games to Open Games with Agency",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Matteo Capucci",
      "Neil Ghani",
      "J\u00e9r\u00e9my Ledent",
      "Fredrik Nordvall Forsberg"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2105.06763"
  },
  {
    "id": "arXiv:2105.08013",
    "title": "What makes you unique?",
    "abstract": "What makes you unique?",
    "descriptor": "",
    "authors": [
      "Benjamin B. Seiler",
      "Masayoshi Mase",
      "Art B. Owen"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.08013"
  },
  {
    "id": "arXiv:2105.09257",
    "title": "The Cost of Compositionality: A High-Performance Implementation of  String Diagram Composition",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Paul Wilson",
      "Fabio Zanasi"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.09257"
  },
  {
    "id": "arXiv:2105.14261",
    "title": "Computing with Infinite Objects: the Gray Code Case",
    "abstract": "Computing with Infinite Objects: the Gray Code Case",
    "descriptor": "",
    "authors": [
      "Dieter Spreen",
      "Ulrich Berger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14261"
  },
  {
    "id": "arXiv:2106.03149",
    "title": "Large-scale Unsupervised Semantic Segmentation",
    "abstract": "Comments: Benchmark and Source Code: this https URL",
    "descriptor": "\nComments: Benchmark and Source Code: this https URL\n",
    "authors": [
      "Shanghua Gao",
      "Zhong-Yu Li",
      "Ming-Hsuan Yang",
      "Ming-Ming Cheng",
      "Junwei Han",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03149"
  },
  {
    "id": "arXiv:2106.07763",
    "title": "String Diagrammatic Electrical Circuit Theory",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Guillaume Boisseau",
      "Pawe\u0142 Soboci\u0144ski"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.07763"
  },
  {
    "id": "arXiv:2106.12142",
    "title": "IQ-Learn: Inverse soft-Q Learning for Imitation",
    "abstract": "Comments: Spotlight in NeurIPS 2021. Winner of '21 MineRL BASALT Challenge. Website: this https URL",
    "descriptor": "\nComments: Spotlight in NeurIPS 2021. Winner of '21 MineRL BASALT Challenge. Website: this https URL\n",
    "authors": [
      "Divyansh Garg",
      "Shuvam Chakraborty",
      "Chris Cundy",
      "Jiaming Song",
      "Matthieu Geist",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.12142"
  },
  {
    "id": "arXiv:2107.01778",
    "title": "Quantaloidal Approach to Constraint Satisfaction",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Soichiro Fujii",
      "Yuni Iwamasa",
      "Kei Kimura"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.01778"
  },
  {
    "id": "arXiv:2107.06820",
    "title": "Composing Conversational Negation",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Razin A. Shaikh",
      "Lia Yeh",
      "Benjamin Rodatz",
      "Bob Coecke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2107.06820"
  },
  {
    "id": "arXiv:2108.02003",
    "title": "Robust direct acoustic impedance control using two microphones for mixed  feedforward-feedback controller",
    "abstract": "Robust direct acoustic impedance control using two microphones for mixed  feedforward-feedback controller",
    "descriptor": "",
    "authors": [
      "Maxime Volery",
      "Xinxin Guo",
      "Herv\u00e9 Lissek"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.02003"
  },
  {
    "id": "arXiv:2108.02465",
    "title": "On Regularization via Frame Decompositions with Applications in  Tomography",
    "abstract": "Comments: 30 pages, 6 figures",
    "descriptor": "\nComments: 30 pages, 6 figures\n",
    "authors": [
      "Simon Hubmer",
      "Ronny Ramlau",
      "Lukas Weissinger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.02465"
  },
  {
    "id": "arXiv:2108.11873",
    "title": "When Do Contrastive Learning Signals Help Spatio-Temporal Graph  Forecasting?",
    "abstract": "Comments: Accepted by SIGSPATIAL 2022",
    "descriptor": "\nComments: Accepted by SIGSPATIAL 2022\n",
    "authors": [
      "Xu Liu",
      "Yuxuan Liang",
      "Chao Huang",
      "Yu Zheng",
      "Bryan Hooi",
      "Roger Zimmermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.11873"
  },
  {
    "id": "arXiv:2108.12515",
    "title": "Convergence Rates for Learning Linear Operators from Noisy Data",
    "abstract": "Comments: To appear in SIAM/ASA Journal on Uncertainty Quantification (JUQ); 34 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: To appear in SIAM/ASA Journal on Uncertainty Quantification (JUQ); 34 pages, 5 figures, 2 tables\n",
    "authors": [
      "Maarten V. de Hoop",
      "Nikola B. Kovachki",
      "Nicholas H. Nelsen",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.12515"
  },
  {
    "id": "arXiv:2109.01718",
    "title": "Communication Efficient Generalized Tensor Factorization for  Decentralized Healthcare Networks",
    "abstract": "Comments: Short version accepted to IEEE ICDM 2021",
    "descriptor": "\nComments: Short version accepted to IEEE ICDM 2021\n",
    "authors": [
      "Jing Ma",
      "Qiuchen Zhang",
      "Jian Lou",
      "Li Xiong",
      "Sivasubramanium Bhavani",
      "Joyce C. Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.01718"
  },
  {
    "id": "arXiv:2109.04083",
    "title": "User Tampering in Reinforcement Learning Recommender Systems",
    "abstract": "Comments: Accepted for presentation at the 4th FAccTRec Workshop on Responsible Recommendation (FAccTRec '21)",
    "descriptor": "\nComments: Accepted for presentation at the 4th FAccTRec Workshop on Responsible Recommendation (FAccTRec '21)\n",
    "authors": [
      "Charles Evans",
      "Atoosa Kasirzadeh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04083"
  },
  {
    "id": "arXiv:2109.05765",
    "title": "DHA: End-to-End Joint Optimization of Data Augmentation Policy,  Hyper-parameter and Architecture",
    "abstract": "DHA: End-to-End Joint Optimization of Data Augmentation Policy,  Hyper-parameter and Architecture",
    "descriptor": "",
    "authors": [
      "Kaichen Zhou",
      "Lanqing Hong",
      "Shoukang Hu",
      "Fengwei Zhou",
      "Binxin Ru",
      "Jiashi Feng",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05765"
  },
  {
    "id": "arXiv:2109.08868",
    "title": "Clean-label Backdoor Attack against Deep Hashing based Retrieval",
    "abstract": "Clean-label Backdoor Attack against Deep Hashing based Retrieval",
    "descriptor": "",
    "authors": [
      "Kuofeng Gao",
      "Jiawang Bai",
      "Bin Chen",
      "Dongxian Wu",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.08868"
  },
  {
    "id": "arXiv:2109.13751",
    "title": "StereoSpike: Depth Learning with a Spiking Neural Network",
    "abstract": "StereoSpike: Depth Learning with a Spiking Neural Network",
    "descriptor": "",
    "authors": [
      "Ulysse Ran\u00e7on",
      "Javier Cuadrado-Anibarro",
      "Benoit R. Cottereau",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.13751"
  },
  {
    "id": "arXiv:2110.00242",
    "title": "3rd Place Scheme on Instance Segmentation Track of ICCV 2021 VIPriors  Challenges",
    "abstract": "Comments: Some authors are concerned that the results are biased",
    "descriptor": "\nComments: Some authors are concerned that the results are biased\n",
    "authors": [
      "Pengyu Chen",
      "Wanhua Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00242"
  },
  {
    "id": "arXiv:2110.03067",
    "title": "On Neurons Invariant to Sentence Structural Changes in Neural Machine  Translation",
    "abstract": "On Neurons Invariant to Sentence Structural Changes in Neural Machine  Translation",
    "descriptor": "",
    "authors": [
      "Gal Patel",
      "Leshem Choshen",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03067"
  },
  {
    "id": "arXiv:2110.03380",
    "title": "Advancing the dimensionality reduction of speaker embeddings for speaker  diarisation: disentangling noise and informing speech activity",
    "abstract": "Comments: This paper was submitted to ICASSP 2023",
    "descriptor": "\nComments: This paper was submitted to ICASSP 2023\n",
    "authors": [
      "You Jin Kim",
      "Hee-Soo Heo",
      "Jee-weon Jung",
      "Youngki Kwon",
      "Bong-Jin Lee",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.03380"
  },
  {
    "id": "arXiv:2110.05985",
    "title": "A Categorical Semantics of Fuzzy Concepts in Conceptual Spaces",
    "abstract": "Comments: In Proceedings ACT 2021, arXiv:2211.01102",
    "descriptor": "\nComments: In Proceedings ACT 2021, arXiv:2211.01102\n",
    "authors": [
      "Sean Tull"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.05985"
  },
  {
    "id": "arXiv:2110.09854",
    "title": "A New Extension of Chubanov's Method to Symmetric Cones",
    "abstract": "Comments: 44 pages; Department of Policy and Planning Sciences Discussion Paper Series No. 1378, University of Tsukuba",
    "descriptor": "\nComments: 44 pages; Department of Policy and Planning Sciences Discussion Paper Series No. 1378, University of Tsukuba\n",
    "authors": [
      "Shin-ichi Kanoh",
      "Akiko Yoshise"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.09854"
  },
  {
    "id": "arXiv:2110.14074",
    "title": "Fault-Tolerant Federated Reinforcement Learning with Theoretical  Guarantee",
    "abstract": "Comments: Published at NeurIPS 2021. Extended version with proofs and additional experimental details and results. New version changes: reduced file size of figures; added a diagram illustrating the problem setting; added link to code on GitHub; modified proof for Theorem 6 (highlighted in red)",
    "descriptor": "\nComments: Published at NeurIPS 2021. Extended version with proofs and additional experimental details and results. New version changes: reduced file size of figures; added a diagram illustrating the problem setting; added link to code on GitHub; modified proof for Theorem 6 (highlighted in red)\n",
    "authors": [
      "Flint Xiaofeng Fan",
      "Yining Ma",
      "Zhongxiang Dai",
      "Wei Jing",
      "Cheston Tan",
      "Bryan Kian Hsiang Low"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14074"
  },
  {
    "id": "arXiv:2110.14904",
    "title": "MERCURY: Accelerating DNN Training By Exploiting Input Similarity",
    "abstract": "Comments: 13 pages, 18 figures, 4 tables",
    "descriptor": "\nComments: 13 pages, 18 figures, 4 tables\n",
    "authors": [
      "Vahid Janfaza",
      "Kevin Weston",
      "Moein Razavi",
      "Shantanu Mandal",
      "Farabi Mahmud",
      "Alex Hilty",
      "Abdullah Muzahid"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.14904"
  },
  {
    "id": "arXiv:2110.14985",
    "title": "A machine learning approach for fighting the curse of dimensionality in  global optimization",
    "abstract": "Comments: Main text 36 pages, 6 figures, currently submitted to science advances",
    "descriptor": "\nComments: Main text 36 pages, 6 figures, currently submitted to science advances\n",
    "authors": [
      "Julian F. Schumann",
      "Alejandro M. Arag\u00f3n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.14985"
  },
  {
    "id": "arXiv:2110.15829",
    "title": "Holistic Deep Learning",
    "abstract": "Comments: In preparation for Machine Learning",
    "descriptor": "\nComments: In preparation for Machine Learning\n",
    "authors": [
      "Dimitris Bertsimas",
      "L\u00e9onard Boussioux",
      "Kimberly Villalobos Carballo",
      "Michael Lingzhi Li",
      "Alex Paskov",
      "Ivan Paskov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15829"
  },
  {
    "id": "arXiv:2111.02208",
    "title": "On role extraction for digraphs via neighbourhood pattern similarity",
    "abstract": "On role extraction for digraphs via neighbourhood pattern similarity",
    "descriptor": "",
    "authors": [
      "Giovanni Barbarino",
      "Vanni Noferini",
      "Paul Van Dooren"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.02208"
  },
  {
    "id": "arXiv:2111.02229",
    "title": "Cram\u00e9r-Rao Bounds for Holographic Positioning",
    "abstract": "Comments: 15 pages, 9 figures, IEEE Transactions on Signal Processing",
    "descriptor": "\nComments: 15 pages, 9 figures, IEEE Transactions on Signal Processing\n",
    "authors": [
      "Antonio A. D'Amico",
      "Andrea de Jesus Torres",
      "Luca Sanguinetti",
      "Moe Win"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.02229"
  },
  {
    "id": "arXiv:2111.03699",
    "title": "A space of goals: the cognitive geometry of informationally bounded  agents",
    "abstract": "Comments: Includes supplementary material, 6 figures in the main document, 5 figures in the supplementary material. Replacing preprint with author accepted manuscript",
    "descriptor": "\nComments: Includes supplementary material, 6 figures in the main document, 5 figures in the supplementary material. Replacing preprint with author accepted manuscript\n",
    "authors": [
      "Karen Archer",
      "Nicola Catenacci Volpi",
      "Franziska Br\u00f6ker",
      "Daniel Polani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.03699"
  },
  {
    "id": "arXiv:2111.05841",
    "title": "Physics-enhanced deep surrogates for PDEs",
    "abstract": "Physics-enhanced deep surrogates for PDEs",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Pestourie",
      "Youssef Mroueh",
      "Chris Rackauckas",
      "Payel Das",
      "Steven G. Johnson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.05841"
  },
  {
    "id": "arXiv:2111.07819",
    "title": "Testing the Generalization of Neural Language Models for COVID-19  Misinformation Detection",
    "abstract": "Testing the Generalization of Neural Language Models for COVID-19  Misinformation Detection",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Nischal Ashok",
      "Terry Ruas",
      "Norman Meuschke",
      "Tirthankar Ghosal",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.07819"
  },
  {
    "id": "arXiv:2112.02285",
    "title": "Configuring Intelligent Reflecting Surface with Performance Guarantees:  Blind Beamforming",
    "abstract": "Comments: 16 pages, 15 figures",
    "descriptor": "\nComments: 16 pages, 15 figures\n",
    "authors": [
      "Shuyi Ren",
      "Kaiming Shen",
      "Yaowen Zhang",
      "Xin Li",
      "Xin Chen",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.02285"
  },
  {
    "id": "arXiv:2112.02399",
    "title": "VT-CLIP: Enhancing Vision-Language Models with Visual-guided Texts",
    "abstract": "VT-CLIP: Enhancing Vision-Language Models with Visual-guided Texts",
    "descriptor": "",
    "authors": [
      "Longtian Qiu",
      "Renrui Zhang",
      "Ziyu Guo",
      "Ziyao Zeng",
      "Yafeng Li",
      "Guangnan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.02399"
  },
  {
    "id": "arXiv:2112.08766",
    "title": "CODER: An efficient framework for improving retrieval through COntextual  Document Embedding Reranking",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "George Zerveas",
      "Navid Rekabsaz",
      "Daniel Cohen",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08766"
  },
  {
    "id": "arXiv:2112.09802",
    "title": "Automated Domain Discovery from Multiple Sources to Improve Zero-Shot  Generalization",
    "abstract": "Automated Domain Discovery from Multiple Sources to Improve Zero-Shot  Generalization",
    "descriptor": "",
    "authors": [
      "Kowshik Thopalli",
      "Sameeksha Katoch",
      "Pavan Turaga",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09802"
  },
  {
    "id": "arXiv:2201.00292",
    "title": "Fair Data Representation for Machine Learning at the Pareto Frontier",
    "abstract": "Comments: 57 pages, 9 figures",
    "descriptor": "\nComments: 57 pages, 9 figures\n",
    "authors": [
      "Shizhou Xu",
      "Thomas Strohmer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2201.00292"
  },
  {
    "id": "arXiv:2201.01537",
    "title": "Few-shot Domain Adaptation for IMU Denoising",
    "abstract": "Few-shot Domain Adaptation for IMU Denoising",
    "descriptor": "",
    "authors": [
      "Feiyu Yao",
      "Zongkai Wu",
      "Zhenyu Wei",
      "Donglin Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.01537"
  },
  {
    "id": "arXiv:2201.03236",
    "title": "Projection based semi--implicit partitioned Reduced Basis Method for non  parametrized and parametrized Fluid--Structure Interaction problems",
    "abstract": "Projection based semi--implicit partitioned Reduced Basis Method for non  parametrized and parametrized Fluid--Structure Interaction problems",
    "descriptor": "",
    "authors": [
      "Monica Nonino",
      "Francesco Ballarin",
      "Gianluigi Rozza",
      "Yvon Maday"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.03236"
  },
  {
    "id": "arXiv:2201.09130",
    "title": "Artificial Intelligence for Suicide Assessment using Audiovisual Cues: A  Review",
    "abstract": "Comments: Manuscript submitted to Arificial Intelligence Reviews (2022)",
    "descriptor": "\nComments: Manuscript submitted to Arificial Intelligence Reviews (2022)\n",
    "authors": [
      "Sahraoui Dhelim",
      "Liming Chen",
      "Huansheng Ning",
      "Chris Nugent"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.09130"
  },
  {
    "id": "arXiv:2201.12433",
    "title": "FedGCN: Convergence and Communication Tradeoffs in Federated Training of  Graph Convolutional Networks",
    "abstract": "FedGCN: Convergence and Communication Tradeoffs in Federated Training of  Graph Convolutional Networks",
    "descriptor": "",
    "authors": [
      "Yuhang Yao",
      "Weizhao Jin",
      "Srivatsan Ravi",
      "Carlee Joe-Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.12433"
  },
  {
    "id": "arXiv:2202.05652",
    "title": "Numerical schemes for a multi-species BGK model with velocity-dependent  collision frequency",
    "abstract": "Numerical schemes for a multi-species BGK model with velocity-dependent  collision frequency",
    "descriptor": "",
    "authors": [
      "Jeffrey Haack",
      "Cory Hauck",
      "Christian Klingenberg",
      "Marlies Pirner",
      "Sandra Warnecke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.05652"
  },
  {
    "id": "arXiv:2202.06633",
    "title": "FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment  Act Flows",
    "abstract": "Comments: EMNLP 2022 camera-ready version",
    "descriptor": "\nComments: EMNLP 2022 camera-ready version\n",
    "authors": [
      "Jianqiao Zhao",
      "Yanyang Li",
      "Wanyu Du",
      "Yangfeng Ji",
      "Dong Yu",
      "Michael R. Lyu",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.06633"
  },
  {
    "id": "arXiv:2202.06898",
    "title": "The Complexity of Matching Games: A Survey",
    "abstract": "The Complexity of Matching Games: A Survey",
    "descriptor": "",
    "authors": [
      "M\u00e1rton Benedek",
      "P\u00e9ter Bir\u00f3",
      "Matthew Johnson",
      "Dani\u00ebl Paulusma",
      "Xin Ye"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.06898"
  },
  {
    "id": "arXiv:2202.07552",
    "title": "A Theory of PAC Learnability under Transformation Invariances",
    "abstract": "A Theory of PAC Learnability under Transformation Invariances",
    "descriptor": "",
    "authors": [
      "Han Shao",
      "Omar Montasser",
      "Avrim Blum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07552"
  },
  {
    "id": "arXiv:2202.08176",
    "title": "Bias and unfairness in machine learning models: a systematic literature  review",
    "abstract": "Bias and unfairness in machine learning models: a systematic literature  review",
    "descriptor": "",
    "authors": [
      "Tiago Palma Pagano",
      "Rafael Bessa Loureiro",
      "Fernanda Vit\u00f3ria Nascimento Lisboa",
      "Gustavo Oliveira Ramos Cruz",
      "Rodrigo Matos Peixoto",
      "Guilherme Arag\u00e3o de Sousa Guimar\u00e3es",
      "Lucas Lisboa dos Santos",
      "Maira Matos Araujo",
      "Marco Cruz",
      "Ewerton Lopes Silva de Oliveira",
      "Ingrid Winkler",
      "Erick Giovani Sperandio Nascimento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08176"
  },
  {
    "id": "arXiv:2202.13526",
    "title": "Sparse Graph Learning with Spectrum Prior for Deep Graph Convolutional  Networks",
    "abstract": "Sparse Graph Learning with Spectrum Prior for Deep Graph Convolutional  Networks",
    "descriptor": "",
    "authors": [
      "Jin Zeng",
      "Yang Liu",
      "Gene Cheung",
      "Wei Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.13526"
  },
  {
    "id": "arXiv:2203.02846",
    "title": "Region Proposal Rectification Towards Robust Instance Segmentation of  Biological Images",
    "abstract": "Region Proposal Rectification Towards Robust Instance Segmentation of  Biological Images",
    "descriptor": "",
    "authors": [
      "Qilong Zhangli",
      "Jingru Yi",
      "Di Liu",
      "Xiaoxiao He",
      "Zhaoyang Xia",
      "Qi Chang",
      "Ligong Han",
      "Yunhe Gao",
      "Song Wen",
      "Haiming Tang",
      "He Wang",
      "Mu Zhou",
      "Dimitris Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02846"
  },
  {
    "id": "arXiv:2203.09155",
    "title": "AdaSplats: Adaptive Splatting of Point Clouds for Accurate 3D Modeling  and Real-time High-Fidelity LiDAR Simulation",
    "abstract": "Comments: 28 pages, 11 figures, 6 tables",
    "descriptor": "\nComments: 28 pages, 11 figures, 6 tables\n",
    "authors": [
      "Jean Pierre Richa",
      "Jean-Emmanuel Deschaud",
      "Fran\u00e7ois Goulette",
      "Nicolas Dalmasso"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09155"
  },
  {
    "id": "arXiv:2203.09303",
    "title": "MSPred: Video Prediction at Multiple Spatio-Temporal Scales with  Hierarchical Recurrent Networks",
    "abstract": "MSPred: Video Prediction at Multiple Spatio-Temporal Scales with  Hierarchical Recurrent Networks",
    "descriptor": "",
    "authors": [
      "Angel Villar-Corrales",
      "Ani Karapetyan",
      "Andreas Boltres",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09303"
  },
  {
    "id": "arXiv:2203.10476",
    "title": "Revisiting the Design Patterns of Composite Visualizations",
    "abstract": "Revisiting the Design Patterns of Composite Visualizations",
    "descriptor": "",
    "authors": [
      "Dazhen Deng",
      "Weiwei Cui",
      "Xiyu Meng",
      "Mengye Xu",
      "Yu Liao",
      "Haidong Zhang",
      "Yingcai Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.10476"
  },
  {
    "id": "arXiv:2203.13479",
    "title": "Enhancing Transferability of Adversarial Examples with Spatial Momentum",
    "abstract": "Comments: Accepted as Oral by 5-th Chinese Conference on Pattern Recognition and Computer Vision, PRCV 2022",
    "descriptor": "\nComments: Accepted as Oral by 5-th Chinese Conference on Pattern Recognition and Computer Vision, PRCV 2022\n",
    "authors": [
      "Guoqiu Wang",
      "Huanqian Yan",
      "Xingxing Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13479"
  },
  {
    "id": "arXiv:2203.14184",
    "title": "All the codeword symbols in polar codes have the same SER under the SC  decoder",
    "abstract": "Comments: We extend the results in the previous version to polar codes over finite fields. Previously, we only proved the results for binary polar codes",
    "descriptor": "\nComments: We extend the results in the previous version to polar codes over finite fields. Previously, we only proved the results for binary polar codes\n",
    "authors": [
      "Guodong Li",
      "Min Ye",
      "Sihuang Hu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.14184"
  },
  {
    "id": "arXiv:2203.17232",
    "title": "Performative Power",
    "abstract": "Comments: to appear at NeurIPS 2022",
    "descriptor": "\nComments: to appear at NeurIPS 2022\n",
    "authors": [
      "Moritz Hardt",
      "Meena Jagadeesan",
      "Celestine Mendler-D\u00fcnner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2203.17232"
  },
  {
    "id": "arXiv:2204.02637",
    "title": "Global HRTF Interpolation via Learned Affine Transformation of  Hyper-conditioned Features",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Jin Woo Lee",
      "Sungho Lee",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.02637"
  },
  {
    "id": "arXiv:2204.03383",
    "title": "Overlay journals: a study of the current landscape",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Antti Mikael Rousi",
      "Mikael Laakso"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2204.03383"
  },
  {
    "id": "arXiv:2204.03421",
    "title": "Self-supervised learning for robust voice cloning",
    "abstract": "Comments: Accepted to INTERSPEECH 2022",
    "descriptor": "\nComments: Accepted to INTERSPEECH 2022\n",
    "authors": [
      "Konstantinos Klapsas",
      "Nikolaos Ellinas",
      "Karolos Nikitaras",
      "Georgios Vamvoukakis",
      "Panos Kakoulidis",
      "Konstantinos Markopoulos",
      "Spyros Raptis",
      "June Sig Sung",
      "Gunu Jho",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03421"
  },
  {
    "id": "arXiv:2204.03471",
    "title": "DynLight: Realize dynamic phase duration with multi-level traffic signal  control",
    "abstract": "Comments: We would like to withdraw this article for the following reasons: 1 this article is not satisfactory for limited language and theoretical description; 2 we have enriched and revised this article with the help of other authors; 3 we must update the author contribution information. PLease see: arXiv:2211.01025",
    "descriptor": "\nComments: We would like to withdraw this article for the following reasons: 1 this article is not satisfactory for limited language and theoretical description; 2 we have enriched and revised this article with the help of other authors; 3 we must update the author contribution information. PLease see: arXiv:2211.01025\n",
    "authors": [
      "Liang Zhang",
      "Shubin Xie",
      "Jianming Deng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03471"
  },
  {
    "id": "arXiv:2204.04944",
    "title": "Semantic Segmentation for Point Cloud Scenes via Dilated Graph Feature  Aggregation and Pyramid Decoders",
    "abstract": "Comments: AAAI Workshop 2022",
    "descriptor": "\nComments: AAAI Workshop 2022\n",
    "authors": [
      "Yongqiang Mao",
      "Xian Sun",
      "Kaiqiang Chen",
      "Wenhui Diao",
      "Zonghao Guo",
      "Xiaonan Lu",
      "Kun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04944"
  },
  {
    "id": "arXiv:2204.08031",
    "title": "Limit theorems of Chatterjee's rank correlation",
    "abstract": "Comments: Consistent variance estimators of Chatterjee's rank correlation and Azadkia-Chatterjee's graph-based correlation coefficient (applicable to any fixed and continuous distributions) were added to this version",
    "descriptor": "\nComments: Consistent variance estimators of Chatterjee's rank correlation and Azadkia-Chatterjee's graph-based correlation coefficient (applicable to any fixed and continuous distributions) were added to this version\n",
    "authors": [
      "Zhexiao Lin",
      "Fang Han"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2204.08031"
  },
  {
    "id": "arXiv:2204.08185",
    "title": "Completion Delay of Random Linear Network Coding in Full-Duplex Relay  Networks",
    "abstract": "Completion Delay of Random Linear Network Coding in Full-Duplex Relay  Networks",
    "descriptor": "",
    "authors": [
      "Rina Su",
      "Qifu Tyler Sun",
      "Zhongshan Zhang",
      "Zongpeng Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.08185"
  },
  {
    "id": "arXiv:2204.10189",
    "title": "Neural Topic Modeling of Psychotherapy Sessions",
    "abstract": "Comments: This work extends our research series in computational linguistics for psychiatry (e.g. working alliance analysis in arXiv:2204.05522) with a systematic investigation of neural topic modeling approaches to provide interpretable insights in psychotherapy",
    "descriptor": "\nComments: This work extends our research series in computational linguistics for psychiatry (e.g. working alliance analysis in arXiv:2204.05522) with a systematic investigation of neural topic modeling approaches to provide interpretable insights in psychotherapy\n",
    "authors": [
      "Baihan Lin",
      "Djallel Bouneffouf",
      "Guillermo Cecchi",
      "Ravi Tejwani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2204.10189"
  },
  {
    "id": "arXiv:2204.11235",
    "title": "Continuous rational functions are deterministic regular",
    "abstract": "Comments: 41 pages",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Olivier Carton",
      "Ga\u00ebtan Dou\u00e9neau-Tabot"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2204.11235"
  },
  {
    "id": "arXiv:2204.13384",
    "title": "D3: A Massive Dataset of Scholarly Metadata for Analyzing the State of  Computer Science Research",
    "abstract": "D3: A Massive Dataset of Scholarly Metadata for Analyzing the State of  Computer Science Research",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Saif M. Mohammad",
      "Bela Gipp"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.13384"
  },
  {
    "id": "arXiv:2205.01289",
    "title": "On Ranking Consistency of Pre-ranking Stage",
    "abstract": "Comments: 9 pagees, 5 figures",
    "descriptor": "\nComments: 9 pagees, 5 figures\n",
    "authors": [
      "Siyu Gu",
      "Xiangrong Sheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2205.01289"
  },
  {
    "id": "arXiv:2205.02161",
    "title": "Is the Algorithmic Kadison-Singer Problem Hard?",
    "abstract": "Is the Algorithmic Kadison-Singer Problem Hard?",
    "descriptor": "",
    "authors": [
      "Ben Jourdan",
      "Peter Macgregor",
      "He Sun"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.02161"
  },
  {
    "id": "arXiv:2205.02645",
    "title": "PyDaddy: A Python package for discovering stochastic dynamical equations  from timeseries data",
    "abstract": "PyDaddy: A Python package for discovering stochastic dynamical equations  from timeseries data",
    "descriptor": "",
    "authors": [
      "Arshed Nabeel",
      "Ashwin Karichannavar",
      "Shuaib Palathingal",
      "Jitesh Jhawar",
      "Danny Raj M",
      "Vishwesha Guttal"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.02645"
  },
  {
    "id": "arXiv:2205.03770",
    "title": "Transformer-Empowered 6G Intelligent Networks: From Massive MIMO  Processing to Semantic Communication",
    "abstract": "Comments: 9 pages, 6 figures. The current version has been accepted by IEEE Wireless Communications Magzine",
    "descriptor": "\nComments: 9 pages, 6 figures. The current version has been accepted by IEEE Wireless Communications Magzine\n",
    "authors": [
      "Yang Wang",
      "Zhen Gao",
      "Dezhi Zheng",
      "Sheng Chen",
      "Deniz G\u00fcnd\u00fcz",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.03770"
  },
  {
    "id": "arXiv:2205.03832",
    "title": "Blockchain Application on the Internet of Vehicles (IoV)",
    "abstract": "Blockchain Application on the Internet of Vehicles (IoV)",
    "descriptor": "",
    "authors": [
      "Nyothiri Aung",
      "Tahar Kechadi",
      "Tao Zhu",
      "Saber Zerdoumi",
      "Tahar Guerbouz",
      "Sahraoui Dhelim"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.03832"
  },
  {
    "id": "arXiv:2205.10770",
    "title": "Memorization Without Overfitting: Analyzing the Training Dynamics of  Large Language Models",
    "abstract": "Memorization Without Overfitting: Analyzing the Training Dynamics of  Large Language Models",
    "descriptor": "",
    "authors": [
      "Kushal Tirumala",
      "Aram H. Markosyan",
      "Luke Zettlemoyer",
      "Armen Aghajanyan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10770"
  },
  {
    "id": "arXiv:2205.11930",
    "title": "The Authenticity Gap in Human Evaluation",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Kawin Ethayarajh",
      "Dan Jurafsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.11930"
  },
  {
    "id": "arXiv:2205.13255",
    "title": "Active Labeling: Streaming Stochastic Gradients",
    "abstract": "Comments: 38 pages (9 main pages), 9 figures",
    "descriptor": "\nComments: 38 pages (9 main pages), 9 figures\n",
    "authors": [
      "Vivien Cabannes",
      "Francis Bach",
      "Vianney Perchet",
      "Alessandro Rudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.13255"
  },
  {
    "id": "arXiv:2205.13286",
    "title": "Ergodic Achievable Rate Maximization of RIS-assisted Millimeter-Wave  MIMO-OFDM Communication Systems",
    "abstract": "Comments: submitted for possible publication",
    "descriptor": "\nComments: submitted for possible publication\n",
    "authors": [
      "Renwang Li",
      "Shu Sun",
      "Meixia Tao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.13286"
  },
  {
    "id": "arXiv:2205.13561",
    "title": "Physics-Guided Hierarchical Reward Mechanism for Learning-Based Object  Grasping",
    "abstract": "Physics-Guided Hierarchical Reward Mechanism for Learning-Based Object  Grasping",
    "descriptor": "",
    "authors": [
      "Yunsik Jung",
      "Lingfeng Tao",
      "Michael Bowman",
      "Jiucai Zhang",
      "Xiaoli Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13561"
  },
  {
    "id": "arXiv:2205.15856",
    "title": "coVariance Neural Networks",
    "abstract": "coVariance Neural Networks",
    "descriptor": "",
    "authors": [
      "Saurabh Sihag",
      "Gonzalo Mateos",
      "Corey McMillan",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.15856"
  },
  {
    "id": "arXiv:2206.00447",
    "title": "CD$^2$: Fine-grained 3D Mesh Reconstruction with Twice Chamfer Distance",
    "abstract": "Comments: under major review in TOMM",
    "descriptor": "\nComments: under major review in TOMM\n",
    "authors": [
      "Rongfei Zeng",
      "Mai Su",
      "Ruiyun Yu",
      "Xingwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00447"
  },
  {
    "id": "arXiv:2206.00529",
    "title": "Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker  Assumptions and Communication Compression as a Cherry on the Top",
    "abstract": "Comments: 41 pages, 6 figures. Changes in v2: few typos and inaccuracies were fixed, more clarifications were added. Code: this https URL",
    "descriptor": "\nComments: 41 pages, 6 figures. Changes in v2: few typos and inaccuracies were fixed, more clarifications were added. Code: this https URL\n",
    "authors": [
      "Eduard Gorbunov",
      "Samuel Horv\u00e1th",
      "Peter Richt\u00e1rik",
      "Gauthier Gidel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.00529"
  },
  {
    "id": "arXiv:2206.03216",
    "title": "Data Governance in the Age of Large-Scale Data-Driven Language  Technology",
    "abstract": "Comments: 32 pages: Full paper and Appendices; Association for Computing Machinery, New York, NY, USA, 2206-2222",
    "descriptor": "\nComments: 32 pages: Full paper and Appendices; Association for Computing Machinery, New York, NY, USA, 2206-2222\n",
    "authors": [
      "Yacine Jernite",
      "Huu Nguyen",
      "Stella Biderman",
      "Anna Rogers",
      "Maraim Masoud",
      "Valentin Danchev",
      "Samson Tan",
      "Alexandra Sasha Luccioni",
      "Nishant Subramani",
      "G\u00e9rard Dupont",
      "Jesse Dodge",
      "Kyle Lo",
      "Zeerak Talat",
      "Isaac Johnson",
      "Dragomir Radev",
      "Somaieh Nikpoor",
      "J\u00f6rg Frohberg",
      "Aaron Gokaslan",
      "Peter Henderson",
      "Rishi Bommasani",
      "Margaret Mitchell"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.03216"
  },
  {
    "id": "arXiv:2206.04740",
    "title": "A Learning-Theoretic Framework for Certified Auditing with Explanations",
    "abstract": "A Learning-Theoretic Framework for Certified Auditing with Explanations",
    "descriptor": "",
    "authors": [
      "Chhavi Yadav",
      "Michal Moshkovitz",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04740"
  },
  {
    "id": "arXiv:2206.05086",
    "title": "Finite Model Theory and Proof Complexity revisited: Distinguishing  graphs in Choiceless Polynomial Time and the Extended Polynomial Calculus",
    "abstract": "Comments: Full version of a paper to appear at CSL 2023",
    "descriptor": "\nComments: Full version of a paper to appear at CSL 2023\n",
    "authors": [
      "Benedikt Pago"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.05086"
  },
  {
    "id": "arXiv:2206.06190",
    "title": "TransRec: Learning Transferable Recommendation from Mixture-of-Modality  Feedback",
    "abstract": "TransRec: Learning Transferable Recommendation from Mixture-of-Modality  Feedback",
    "descriptor": "",
    "authors": [
      "Jie Wang",
      "Fajie Yuan",
      "Mingyue Cheng",
      "Joemon M. Jose",
      "Chenyun Yu",
      "Beibei Kong",
      "Xiangnan He",
      "Zhijin Wang",
      "Bo Hu",
      "Zang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2206.06190"
  },
  {
    "id": "arXiv:2206.07021",
    "title": "Federated Optimization Algorithms with Random Reshuffling and Gradient  Compression",
    "abstract": "Comments: 66 pages, 6 figures. Changes in V2: the presentation of the results was changed, extra experiments were added. Code: this https URL",
    "descriptor": "\nComments: 66 pages, 6 figures. Changes in V2: the presentation of the results was changed, extra experiments were added. Code: this https URL\n",
    "authors": [
      "Abdurakhmon Sadiev",
      "Grigory Malinovsky",
      "Eduard Gorbunov",
      "Igor Sokolov",
      "Ahmed Khaled",
      "Konstantin Burlachenko",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.07021"
  },
  {
    "id": "arXiv:2206.07811",
    "title": "Safety Guarantees for Neural Network Dynamic Systems via Stochastic  Barrier Functions",
    "abstract": "Safety Guarantees for Neural Network Dynamic Systems via Stochastic  Barrier Functions",
    "descriptor": "",
    "authors": [
      "Rayan Mazouz",
      "Karan Muvvala",
      "Akash Ratheesh",
      "Luca Laurenti",
      "Morteza Lahijanian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.07811"
  },
  {
    "id": "arXiv:2206.11443",
    "title": "Image-based Stability Quantification",
    "abstract": "Image-based Stability Quantification",
    "descriptor": "",
    "authors": [
      "Jesse Scott",
      "John Challis",
      "Robert T. Collins",
      "Yanxi Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11443"
  },
  {
    "id": "arXiv:2206.13606",
    "title": "Online Resource Allocation under Horizon Uncertainty",
    "abstract": "Online Resource Allocation under Horizon Uncertainty",
    "descriptor": "",
    "authors": [
      "Santiago Balseiro",
      "Christian Kroer",
      "Rachitesh Kumar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.13606"
  },
  {
    "id": "arXiv:2206.14928",
    "title": "Manifold Interpolating Optimal-Transport Flows for Trajectory Inference",
    "abstract": "Comments: Presented at NeurIPS 2022, 24 pages, 7 tables, 14 figures",
    "descriptor": "\nComments: Presented at NeurIPS 2022, 24 pages, 7 tables, 14 figures\n",
    "authors": [
      "Guillaume Huguet",
      "D.S. Magruder",
      "Alexander Tong",
      "Oluwadamilola Fasina",
      "Manik Kuchroo",
      "Guy Wolf",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14928"
  },
  {
    "id": "arXiv:2207.00225",
    "title": "Keeping Less is More: Point Sparsification for Visual SLAM",
    "abstract": "Comments: The IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2022",
    "descriptor": "\nComments: The IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2022\n",
    "authors": [
      "Yeonsoo Park",
      "Soohyun Bae"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.00225"
  },
  {
    "id": "arXiv:2207.01780",
    "title": "CodeRL: Mastering Code Generation through Pretrained Models and Deep  Reinforcement Learning",
    "abstract": "Comments: An earlier version of the work was accepted to NeurIPS 2022",
    "descriptor": "\nComments: An earlier version of the work was accepted to NeurIPS 2022\n",
    "authors": [
      "Hung Le",
      "Yue Wang",
      "Akhilesh Deepak Gotmare",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2207.01780"
  },
  {
    "id": "arXiv:2207.05800",
    "title": "Long-Horizon Manipulation Planning with Functional Object-Oriented  Networks",
    "abstract": "Comments: Preliminary Draft, 8 pages, IEEE Conference Format",
    "descriptor": "\nComments: Preliminary Draft, 8 pages, IEEE Conference Format\n",
    "authors": [
      "David Paulius",
      "Alejandro Agostini",
      "Dongheui Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.05800"
  },
  {
    "id": "arXiv:2207.05876",
    "title": "Adaptive Diffusion Priors for Accelerated MRI Reconstruction",
    "abstract": "Adaptive Diffusion Priors for Accelerated MRI Reconstruction",
    "descriptor": "",
    "authors": [
      "Alper G\u00fcng\u00f6r",
      "Salman UH Dar",
      "\u015eaban \u00d6zt\u00fcrk",
      "Yilmaz Korkmaz",
      "Gokberk Elmas",
      "Muzaffer \u00d6zbey",
      "Tolga \u00c7ukur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.05876"
  },
  {
    "id": "arXiv:2207.08581",
    "title": "Study of the performance and scalability of federated learning for  medical imaging with intermittent clients",
    "abstract": "Study of the performance and scalability of federated learning for  medical imaging with intermittent clients",
    "descriptor": "",
    "authors": [
      "Judith S\u00e1inz-Pardo D\u00edaz",
      "\u00c1lvaro L\u00f3pez Garc\u00eda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.08581"
  },
  {
    "id": "arXiv:2207.09340",
    "title": "A coherence parameter characterizing generative compressed sensing with  Fourier measurements",
    "abstract": "A coherence parameter characterizing generative compressed sensing with  Fourier measurements",
    "descriptor": "",
    "authors": [
      "Aaron Berk",
      "Simone Brugiapaglia",
      "Babhru Joshi",
      "Yaniv Plan",
      "Matthew Scott",
      "\u00d6zg\u00fcr Yilmaz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.09340"
  },
  {
    "id": "arXiv:2207.10936",
    "title": "Long-tailed Instance Segmentation using Gumbel Optimized Loss",
    "abstract": "Comments: ECCV2022",
    "descriptor": "\nComments: ECCV2022\n",
    "authors": [
      "Konstantinos Panagiotis Alexandridis",
      "Jiankang Deng",
      "Anh Nguyen",
      "Shan Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10936"
  },
  {
    "id": "arXiv:2207.12678",
    "title": "Analyzing Sharpness along GD Trajectory: Progressive Sharpening and Edge  of Stability",
    "abstract": "Analyzing Sharpness along GD Trajectory: Progressive Sharpening and Edge  of Stability",
    "descriptor": "",
    "authors": [
      "Zhouzi Li",
      "Zixuan Wang",
      "Jian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.12678"
  },
  {
    "id": "arXiv:2208.00843",
    "title": "Relay Hindsight Experience Replay: Self-Guided Continual Reinforcement  Learning for Sequential Object Manipulation Tasks with Sparse Rewards",
    "abstract": "Comments: 10 pages, 15 figures. this https URL",
    "descriptor": "\nComments: 10 pages, 15 figures. this https URL\n",
    "authors": [
      "Yongle Luo",
      "Yuxin Wang",
      "Kun Dong",
      "Qiang Zhang",
      "Erkang Cheng",
      "Zhiyong Sun",
      "Bo Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.00843"
  },
  {
    "id": "arXiv:2208.03409",
    "title": "DP$^2$-VAE: Differentially Private Pre-trained Variational Autoencoders",
    "abstract": "Comments: The privacy analysis in the first version is incorrect",
    "descriptor": "\nComments: The privacy analysis in the first version is incorrect\n",
    "authors": [
      "Dihong Jiang",
      "Guojun Zhang",
      "Mahdi Karami",
      "Xi Chen",
      "Yunfeng Shao",
      "Yaoliang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.03409"
  },
  {
    "id": "arXiv:2208.03886",
    "title": "What can we know about that which we cannot even imagine?",
    "abstract": "Comments: 30 pages, 9 pages of references",
    "descriptor": "\nComments: 30 pages, 9 pages of references\n",
    "authors": [
      "David H. Wolpert"
    ],
    "subjectives": [
      "History and Philosophy of Physics (physics.hist-ph)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.03886"
  },
  {
    "id": "arXiv:2208.07628",
    "title": "FALCON: Sound and Complete Neural Semantic Entailment over ALC  Ontologies",
    "abstract": "FALCON: Sound and Complete Neural Semantic Entailment over ALC  Ontologies",
    "descriptor": "",
    "authors": [
      "Zhenwei Tang",
      "Tilman Hinnerichs",
      "Xi Peng",
      "Xiangliang Zhang",
      "Robert Hoehndorf"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2208.07628"
  },
  {
    "id": "arXiv:2208.07919",
    "title": "Dynamic Pricing for Non-fungible Resources: Designing Multidimensional  Blockchain Fee Markets",
    "abstract": "Dynamic Pricing for Non-fungible Resources: Designing Multidimensional  Blockchain Fee Markets",
    "descriptor": "",
    "authors": [
      "Theo Diamandis",
      "Alex Evans",
      "Tarun Chitra",
      "Guillermo Angeris"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2208.07919"
  },
  {
    "id": "arXiv:2208.09416",
    "title": "Kernel Memory Networks: A Unifying Framework for Memory Modeling",
    "abstract": "Comments: 24 pages, 5 figures. Camera-ready version for NeurIPS 2022",
    "descriptor": "\nComments: 24 pages, 5 figures. Camera-ready version for NeurIPS 2022\n",
    "authors": [
      "Georgios Iatropoulos",
      "Johanni Brea",
      "Wulfram Gerstner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2208.09416"
  },
  {
    "id": "arXiv:2208.09929",
    "title": "A Survey of Augmented Piano Prototypes: Has Augmentation Improved  Learning Experiences?",
    "abstract": "Comments: 28 pages, 5 figures, 3 tables, Proceedings of ISS'22",
    "descriptor": "\nComments: 28 pages, 5 figures, 3 tables, Proceedings of ISS'22\n",
    "authors": [
      "Jordan Aiko Deja",
      "Sven Mayer",
      "Klen \u010copi\u010d Pucihar",
      "Matja\u017e Kljun"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.09929"
  },
  {
    "id": "arXiv:2208.10933",
    "title": "Large-Scale Integrated Flexible Tactile Sensor Array for Sensitive Smart  Robotic Touch",
    "abstract": "Comments: Correction in Methods: The weight ratio of TPU:DMF was set to be 1:5",
    "descriptor": "\nComments: Correction in Methods: The weight ratio of TPU:DMF was set to be 1:5\n",
    "authors": [
      "Zhenxuan Zhao",
      "Jianshi Tang",
      "Jian Yuan",
      "Yijun Li",
      "Yuan Dai",
      "Jian Yao",
      "Qingtian Zhang",
      "Sanchuan Ding",
      "Tingyu Li",
      "Ruirui Zhang",
      "Yu Zheng",
      "Zhengyou Zhang",
      "Song Qiu",
      "Qingwen Li",
      "Bin Gao",
      "Ning Deng",
      "He Qian",
      "Fei Xing",
      "Zheng You",
      "Huaqiang Wu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.10933"
  },
  {
    "id": "arXiv:2208.13772",
    "title": "Computing committors via Mahalanobis diffusion maps with enhanced  sampling data",
    "abstract": "Comments: Restructured introduction, improved explanation of key algorithms and formulas (Section II.C and III.B,C). Streamlined presentation and proof of Theorem 1",
    "descriptor": "\nComments: Restructured introduction, improved explanation of key algorithms and formulas (Section II.C and III.B,C). Streamlined presentation and proof of Theorem 1\n",
    "authors": [
      "Luke Evans",
      "Maria K. Cameron",
      "Pratyush Tiwary"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.13772"
  },
  {
    "id": "arXiv:2209.00307",
    "title": "Memory Tagging: A Memory Efficient Design",
    "abstract": "Comments: 16 Pages, 7 Figures. This version of the paper extends a shorter version submitted to IEEE Euro S&P'23",
    "descriptor": "\nComments: 16 Pages, 7 Figures. This version of the paper extends a shorter version submitted to IEEE Euro S&P'23\n",
    "authors": [
      "Aditi Partap",
      "Dan Boneh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.00307"
  },
  {
    "id": "arXiv:2209.03917",
    "title": "Exploring Target Representations for Masked Autoencoders",
    "abstract": "Comments: The first two authors contributed equally",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "Xingbin Liu",
      "Jinghao Zhou",
      "Tao Kong",
      "Xianming Lin",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.03917"
  },
  {
    "id": "arXiv:2209.05279",
    "title": "Data assimilation: A dynamic homotopy-based coupling approach",
    "abstract": "Data assimilation: A dynamic homotopy-based coupling approach",
    "descriptor": "",
    "authors": [
      "Sebastian Reich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.05279"
  },
  {
    "id": "arXiv:2209.05735",
    "title": "Learning ASR pathways: A sparse multilingual ASR model",
    "abstract": "Comments: submitted to ICASSP 2023",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Mu Yang",
      "Andros Tjandra",
      "Chunxi Liu",
      "David Zhang",
      "Duc Le",
      "Ozlem Kalinli"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.05735"
  },
  {
    "id": "arXiv:2209.07064",
    "title": "SecSkyline: Fast Privacy-Preserving Skyline Queries over Encrypted Cloud  Databases",
    "abstract": "Comments: Accepted in IEEE Transacctions on Knowledge and Data Engineering (TKDE)",
    "descriptor": "\nComments: Accepted in IEEE Transacctions on Knowledge and Data Engineering (TKDE)\n",
    "authors": [
      "Yifeng Zheng",
      "Weibo Wang",
      "Songlei Wang",
      "Xiaohua Jia",
      "Hejiao Huang",
      "Cong Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2209.07064"
  },
  {
    "id": "arXiv:2209.07330",
    "title": "Semiparametric Best Arm Identification with Contextual Information",
    "abstract": "Semiparametric Best Arm Identification with Contextual Information",
    "descriptor": "",
    "authors": [
      "Masahiro Kato",
      "Masaaki Imaizumi",
      "Takuya Ishihara",
      "Toru Kitagawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.07330"
  },
  {
    "id": "arXiv:2209.07370",
    "title": "A Geometric Perspective on Variational Autoencoders",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Cl\u00e9ment Chadebec",
      "St\u00e9phanie Allassonni\u00e8re"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07370"
  },
  {
    "id": "arXiv:2209.08860",
    "title": "A Survey of Deep Causal Models",
    "abstract": "A Survey of Deep Causal Models",
    "descriptor": "",
    "authors": [
      "Zongyu Li",
      "Zhenfeng Zhu",
      "Zhenyu Guo",
      "Shuai Zheng",
      "Yao Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.08860"
  },
  {
    "id": "arXiv:2209.09775",
    "title": "FedToken: Tokenized Incentives for Data Contribution in Federated  Learning",
    "abstract": "Comments: Accepted at Workshop on Federated Learning: Recent Advances and New Challenges, in Conjunction with NeurIPS 2022 (FL-NeurIPS'22). 9 Pages, 5 Figures",
    "descriptor": "\nComments: Accepted at Workshop on Federated Learning: Recent Advances and New Challenges, in Conjunction with NeurIPS 2022 (FL-NeurIPS'22). 9 Pages, 5 Figures\n",
    "authors": [
      "Shashi Raj Pandey",
      "Lam Duc Nguyen",
      "Petar Popovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.09775"
  },
  {
    "id": "arXiv:2209.11350",
    "title": "Oracle Analysis of Representations for Deep Open Set Detection",
    "abstract": "Oracle Analysis of Representations for Deep Open Set Detection",
    "descriptor": "",
    "authors": [
      "Risheek Garrepalli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11350"
  },
  {
    "id": "arXiv:2209.11764",
    "title": "Taking the Intentional Stance Seriously: A Guide to Progress in  Artificial Intelligence",
    "abstract": "Comments: 13 pages, 1 figure, 2 tables",
    "descriptor": "\nComments: 13 pages, 1 figure, 2 tables\n",
    "authors": [
      "Will Bridewell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11764"
  },
  {
    "id": "arXiv:2209.12054",
    "title": "From Local to Global: Spectral-Inspired Graph Neural Networks",
    "abstract": "From Local to Global: Spectral-Inspired Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Ningyuan Huang",
      "Soledad Villar",
      "Carey E. Priebe",
      "Da Zheng",
      "Chengyue Huang",
      "Lin Yang",
      "Vladimir Braverman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.12054"
  },
  {
    "id": "arXiv:2209.13260",
    "title": "Multilingual analysis of intelligibility classification using English,  Korean, and Tamil dysarthric speech datasets",
    "abstract": "Comments: 6 pages, 1 figure, O-COCOSDA 2022",
    "descriptor": "\nComments: 6 pages, 1 figure, O-COCOSDA 2022\n",
    "authors": [
      "Eun Jung Yeo",
      "Sunhee Kim",
      "Minhwa Chung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.13260"
  },
  {
    "id": "arXiv:2209.13511",
    "title": "Phy-Taylor: Physics-Model-Based Deep Neural Networks",
    "abstract": "Comments: Working Paper",
    "descriptor": "\nComments: Working Paper\n",
    "authors": [
      "Yanbing Mao",
      "Lui Sha",
      "Huajie Shao",
      "Yuliang Gu",
      "Qixin Wang",
      "Tarek Abdelzaher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.13511"
  },
  {
    "id": "arXiv:2209.14610",
    "title": "Dynamic Prompt Learning via Policy Gradient for Semi-structured  Mathematical Reasoning",
    "abstract": "Comments: 24 pages, 18 figures, 8 tables. The data and code will be available at this https URL",
    "descriptor": "\nComments: 24 pages, 18 figures, 8 tables. The data and code will be available at this https URL\n",
    "authors": [
      "Pan Lu",
      "Liang Qiu",
      "Kai-Wei Chang",
      "Ying Nian Wu",
      "Song-Chun Zhu",
      "Tanmay Rajpurohit",
      "Peter Clark",
      "Ashwin Kalyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.14610"
  },
  {
    "id": "arXiv:2210.00166",
    "title": "Automated segmentation of microvessels in intravascular OCT images using  deep learning",
    "abstract": "Comments: 21 pages, 9 figures, 3 tables",
    "descriptor": "\nComments: 21 pages, 9 figures, 3 tables\n",
    "authors": [
      "Juhwan Lee",
      "Justin N. Kim",
      "Lia Gomez-Perez",
      "Yazan Gharaibeh",
      "Issam Motairek",
      "Ga-briel T. R. Pereira",
      "Vladislav N. Zimin",
      "Luis A. P. Dallan",
      "Ammar Hoori",
      "Sadeer Al-Kindi",
      "Giulio Guagliumi",
      "Hiram G. Bezerra",
      "David L. Wilson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00166"
  },
  {
    "id": "arXiv:2210.00340",
    "title": "Speed Up the Cold-Start Learning in Two-Sided Bandits with Many Arms",
    "abstract": "Speed Up the Cold-Start Learning in Two-Sided Bandits with Many Arms",
    "descriptor": "",
    "authors": [
      "Mohsen Bayati",
      "Junyu Cao",
      "Wanning Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00340"
  },
  {
    "id": "arXiv:2210.00421",
    "title": "Order-optimal Joint Transmission and Identification in Massive  Multi-User MIMO via Group Testing",
    "abstract": "Comments: 11 pages, 6 figures",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "George Vershinin",
      "Asaf Cohen",
      "Omer Gurewitz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00421"
  },
  {
    "id": "arXiv:2210.01123",
    "title": "Towards Learned Simulators for Cell Migration",
    "abstract": "Comments: Accepted at NeurIPS 2022 AI for Science workshop",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 AI for Science workshop\n",
    "authors": [
      "Koen Minartz",
      "Yoeri Poels",
      "Vlado Menkovski"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.01123"
  },
  {
    "id": "arXiv:2210.02631",
    "title": "Data-driven Approaches to Surrogate Machine Learning Model Development",
    "abstract": "Comments: 16 pages, 13 figures",
    "descriptor": "\nComments: 16 pages, 13 figures\n",
    "authors": [
      "H. Rhys Jones",
      "Tingting Mu",
      "Andrei C. Popescu",
      "Yusuf Sulehman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.02631"
  },
  {
    "id": "arXiv:2210.02890",
    "title": "Multiview Contextual Commonsense Inference: A New Dataset and Task",
    "abstract": "Multiview Contextual Commonsense Inference: A New Dataset and Task",
    "descriptor": "",
    "authors": [
      "Siqi Shen",
      "Deepanway Ghosal",
      "Navonil Majumder",
      "Henry Lim",
      "Rada Mihalcea",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02890"
  },
  {
    "id": "arXiv:2210.03209",
    "title": "Self-Adaptive Driving in Nonstationary Environments through Conjectural  Online Lookahead Adaptation",
    "abstract": "Comments: 10 pages with appendices; Nov 2 update: fixed minor typos in the appendices",
    "descriptor": "\nComments: 10 pages with appendices; Nov 2 update: fixed minor typos in the appendices\n",
    "authors": [
      "Tao Li",
      "Haozhe Lei",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.03209"
  },
  {
    "id": "arXiv:2210.03454",
    "title": "DABERT: Dual Attention Enhanced BERT for Semantic Matching",
    "abstract": "Comments: Accepted by COLING 2022",
    "descriptor": "\nComments: Accepted by COLING 2022\n",
    "authors": [
      "Sirui Wang",
      "Di Liang",
      "Jian Song",
      "Yuntao Li",
      "Wei Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03454"
  },
  {
    "id": "arXiv:2210.03568",
    "title": "How Large Language Models are Transforming Machine-Paraphrased  Plagiarism",
    "abstract": "How Large Language Models are Transforming Machine-Paraphrased  Plagiarism",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Frederic Kirstein",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03568"
  },
  {
    "id": "arXiv:2210.04590",
    "title": "The Small Solution Hypothesis for MAPF on Strongly Connected Directed  Graphs Is True",
    "abstract": "Comments: In this version, the proof for simple moves as been greatly simplified, which gave room to handle also the case of synchronous rotations",
    "descriptor": "\nComments: In this version, the proof for simple moves as been greatly simplified, which gave room to handle also the case of synchronous rotations\n",
    "authors": [
      "Bernhard Nebel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.04590"
  },
  {
    "id": "arXiv:2210.05164",
    "title": "Tight Error Bounds for Nonnegative Orthogonality Constraints and Exact  Penalties",
    "abstract": "Tight Error Bounds for Nonnegative Orthogonality Constraints and Exact  Penalties",
    "descriptor": "",
    "authors": [
      "Xiaojun Chen",
      "Yifan He",
      "Zaikun Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.05164"
  },
  {
    "id": "arXiv:2210.05361",
    "title": "Uncertainty-Aware Unsupervised Image Deblurring with Deep Residual Prior",
    "abstract": "Uncertainty-Aware Unsupervised Image Deblurring with Deep Residual Prior",
    "descriptor": "",
    "authors": [
      "Xiaole Tang",
      "Xile Zhao",
      "Jun Liu",
      "Jianli Wang",
      "Yuchun Miao",
      "Tieyong Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05361"
  },
  {
    "id": "arXiv:2210.07729",
    "title": "Model-Based Imitation Learning for Urban Driving",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Anthony Hu",
      "Gianluca Corrado",
      "Nicolas Griffiths",
      "Zak Murez",
      "Corina Gurau",
      "Hudson Yeo",
      "Alex Kendall",
      "Roberto Cipolla",
      "Jamie Shotton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07729"
  },
  {
    "id": "arXiv:2210.08342",
    "title": "Well-definedness of Physical Law Learning: The Uniqueness Problem",
    "abstract": "Well-definedness of Physical Law Learning: The Uniqueness Problem",
    "descriptor": "",
    "authors": [
      "Philipp Scholl",
      "Aras Bacho",
      "Holger Boche",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.08342"
  },
  {
    "id": "arXiv:2210.08471",
    "title": "Improving Semantic Matching through Dependency-Enhanced Pre-trained  Model with Adaptive Fusion",
    "abstract": "Comments: Accepted by Findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Jian Song",
      "Di Liang",
      "Rumei Li",
      "Yuntao Li",
      "Sirui Wang",
      "Minlong Peng",
      "Wei Wu",
      "Yongxin Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08471"
  },
  {
    "id": "arXiv:2210.09521",
    "title": "A Practical, Progressively-Expressive GNN",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Lingxiao Zhao",
      "Louis H\u00e4rtel",
      "Neil Shah",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09521"
  },
  {
    "id": "arXiv:2210.09887",
    "title": "MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving  Camera Videos",
    "abstract": "MotionDeltaCNN: Sparse CNN Inference of Frame Differences in Moving  Camera Videos",
    "descriptor": "",
    "authors": [
      "Mathias Parger",
      "Chengcheng Tang",
      "Thomas Neff",
      "Christopher D. Twigg",
      "Cem Keskin",
      "Robert Wang",
      "Markus Steinberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.09887"
  },
  {
    "id": "arXiv:2210.10678",
    "title": "Towards Realistic Low-resource Relation Extraction: A Benchmark with  Empirical Baseline Study",
    "abstract": "Comments: Accepted to EMNLP 2022 (Findings) and the project website is this https URL",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (Findings) and the project website is this https URL\n",
    "authors": [
      "Xin Xu",
      "Xiang Chen",
      "Ningyu Zhang",
      "Xin Xie",
      "Xi Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10678"
  },
  {
    "id": "arXiv:2210.11277",
    "title": "TANGO: Text-driven Photorealistic and Robust 3D Stylization via Lighting  Decomposition",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yongwei Chen",
      "Rui Chen",
      "Jiabao Lei",
      "Yabin Zhang",
      "Kui Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11277"
  },
  {
    "id": "arXiv:2210.11703",
    "title": "SCL: A Secure Concurrency Layer For Paranoid Stateful Lambdas",
    "abstract": "Comments: updated with acknowledgement; 14 pages, 11 figures, 2 tables",
    "descriptor": "\nComments: updated with acknowledgement; 14 pages, 11 figures, 2 tables\n",
    "authors": [
      "Kaiyuan Chen",
      "Alexander Thomas",
      "Hanming Lu",
      "William Mullen",
      "Jeffery Ichnowski",
      "Rahul Arya",
      "Nivedha Krishnakumar",
      "Ryan Teoh",
      "Willis Wang",
      "Anthony Joseph",
      "John Kubiatowicz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.11703"
  },
  {
    "id": "arXiv:2210.11947",
    "title": "Generalizing over Long Tail Concepts for Medical Term Normalization",
    "abstract": "Generalizing over Long Tail Concepts for Medical Term Normalization",
    "descriptor": "",
    "authors": [
      "Beatrice Portelli",
      "Simone Scaboro",
      "Enrico Santus",
      "Hooman Sedghamiz",
      "Emmanuele Chersoni",
      "Giuseppe Serra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.11947"
  },
  {
    "id": "arXiv:2210.12859",
    "title": "A Stack-Free Traversal Algorithm for Left-Balanced k-d Trees",
    "abstract": "A Stack-Free Traversal Algorithm for Left-Balanced k-d Trees",
    "descriptor": "",
    "authors": [
      "Ingo Wald"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.12859"
  },
  {
    "id": "arXiv:2210.12924",
    "title": "OLLA: Optimizing the Lifetime and Location of Arrays to Reduce the  Memory Usage of Neural Networks",
    "abstract": "OLLA: Optimizing the Lifetime and Location of Arrays to Reduce the  Memory Usage of Neural Networks",
    "descriptor": "",
    "authors": [
      "Benoit Steiner",
      "Mostafa Elhoushi",
      "Jacob Kahn",
      "James Hegarty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12924"
  },
  {
    "id": "arXiv:2210.13121",
    "title": "The Entropy Method in Large Deviation Theory",
    "abstract": "Comments: 32 pages. For this version, more results and references are added",
    "descriptor": "\nComments: 32 pages. For this version, more results and references are added\n",
    "authors": [
      "Lei Yu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.13121"
  },
  {
    "id": "arXiv:2210.13768",
    "title": "GLIF: A Unified Gated Leaky Integrate-and-Fire Neuron for Spiking Neural  Networks",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Xingting Yao",
      "Fanrong Li",
      "Zitao Mo",
      "Jian Cheng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.13768"
  },
  {
    "id": "arXiv:2210.13944",
    "title": "A Survey on Artificial Intelligence for Music Generation: Agents,  Domains and Perspectives",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Carlos Hernandez-Olivan",
      "Javier Hernandez-Olivan",
      "Jose R. Beltran"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.13944"
  },
  {
    "id": "arXiv:2210.14012",
    "title": "Gradient-based Weight Density Balancing for Robust Dynamic Sparse  Training",
    "abstract": "Gradient-based Weight Density Balancing for Robust Dynamic Sparse  Training",
    "descriptor": "",
    "authors": [
      "Mathias Parger",
      "Alexander Ertl",
      "Paul Eibensteiner",
      "Joerg H. Mueller",
      "Martin Winter",
      "Markus Steinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14012"
  },
  {
    "id": "arXiv:2210.14431",
    "title": "$N$-gram Is Back: Residual Learning of Neural Text Generation with  $n$-gram Language Model",
    "abstract": "Comments: Accepted to findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted to findings of EMNLP 2022\n",
    "authors": [
      "Huayang Li",
      "Deng Cai",
      "Jin Xu",
      "Taro Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14431"
  },
  {
    "id": "arXiv:2210.15137",
    "title": "ScoreMix: A Scalable Augmentation Strategy for Training GANs with  Limited Data",
    "abstract": "ScoreMix: A Scalable Augmentation Strategy for Training GANs with  Limited Data",
    "descriptor": "",
    "authors": [
      "Jie Cao",
      "Mandi Luo",
      "Junchi Yu",
      "Ming-Hsuan Yang",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15137"
  },
  {
    "id": "arXiv:2210.16031",
    "title": "UPainting: Unified Text-to-Image Diffusion Generation with Cross-modal  Guidance",
    "abstract": "Comments: First Version, 16 pages",
    "descriptor": "\nComments: First Version, 16 pages\n",
    "authors": [
      "Wei Li",
      "Xue Xu",
      "Xinyan Xiao",
      "Jiachen Liu",
      "Hu Yang",
      "Guohao Li",
      "Zhanpeng Wang",
      "Zhifan Feng",
      "Qiaoqiao She",
      "Yajuan Lyu",
      "Hua Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16031"
  },
  {
    "id": "arXiv:2210.16127",
    "title": "Target-Speaker Voice Activity Detection via Sequence-to-Sequence  Prediction",
    "abstract": "Comments: submitted to ICASSP2023",
    "descriptor": "\nComments: submitted to ICASSP2023\n",
    "authors": [
      "Ming Cheng",
      "Weiqing Wang",
      "Yucong Zhang",
      "Xiaoyi Qin",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.16127"
  },
  {
    "id": "arXiv:2210.16314",
    "title": "Hierarchical Automatic Power Plane Generation with Genetic Optimization  and Multilayer Perceptron",
    "abstract": "Hierarchical Automatic Power Plane Generation with Genetic Optimization  and Multilayer Perceptron",
    "descriptor": "",
    "authors": [
      "Haiguang Liao",
      "Vinay Patil",
      "Xuliang Dong",
      "Devika Shanbhag",
      "Elias Fallon",
      "Taylor Hogan",
      "Mirko Spasojevic",
      "Levent Burak Kara"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16314"
  },
  {
    "id": "arXiv:2210.16508",
    "title": "Clenshaw Graph Neural Networks",
    "abstract": "Comments: 10 pages, 2 figures",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Yuhe Guo",
      "Zhewei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.16508"
  },
  {
    "id": "arXiv:2210.16695",
    "title": "Impact of Reconfigurable Intelligent Surface Geometry on Communication  Performance",
    "abstract": "Impact of Reconfigurable Intelligent Surface Geometry on Communication  Performance",
    "descriptor": "",
    "authors": [
      "Zhuangzhuang Cui",
      "Sofie Pollin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.16695"
  },
  {
    "id": "arXiv:2210.16810",
    "title": "SL3D: Self-supervised-Self-labeled 3D Recognition",
    "abstract": "Comments: Accepted at Neural Information Processing Systems (NeurIPS 2022) Workshop on Self-Supervised Learning: Theory and Practice",
    "descriptor": "\nComments: Accepted at Neural Information Processing Systems (NeurIPS 2022) Workshop on Self-Supervised Learning: Theory and Practice\n",
    "authors": [
      "Fernando Julio Cendra",
      "Lan Ma",
      "Jiajun Shen",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16810"
  },
  {
    "id": "arXiv:2210.16993",
    "title": "STN: a new tensor network method to identify stimulus category from  brain activity pattern",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Chunyu Liu",
      "Jiacai Zhang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16993"
  },
  {
    "id": "arXiv:2210.17168",
    "title": "SDCL: Self-Distillation Contrastive Learning for Chinese Spell Checking",
    "abstract": "SDCL: Self-Distillation Contrastive Learning for Chinese Spell Checking",
    "descriptor": "",
    "authors": [
      "Xiaotian Zhang",
      "Hang Yan",
      "Sun Yu",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.17168"
  },
  {
    "id": "arXiv:2210.17177",
    "title": "Variational Inference Aided Estimation of Time Varying Channels",
    "abstract": "Variational Inference Aided Estimation of Time Varying Channels",
    "descriptor": "",
    "authors": [
      "Benedikt B\u00f6ck",
      "Michael Baur",
      "Valentina Rizzello",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.17177"
  },
  {
    "id": "arXiv:2210.17406",
    "title": "Emergent Linguistic Structures in Neural Networks are Fragile",
    "abstract": "Emergent Linguistic Structures in Neural Networks are Fragile",
    "descriptor": "",
    "authors": [
      "Emanuele La Malfa",
      "Matthew Wicker",
      "Marta Kiatkowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.17406"
  },
  {
    "id": "arXiv:2211.00119",
    "title": "Active Learning of Non-semantic Speech Tasks with Pretrained Models",
    "abstract": "Active Learning of Non-semantic Speech Tasks with Pretrained Models",
    "descriptor": "",
    "authors": [
      "Harlin Lee",
      "Aaqib Saeed",
      "Andrea L. Bertozzi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00119"
  },
  {
    "id": "arXiv:2211.00230",
    "title": "Survey on Source-coding technique",
    "abstract": "Survey on Source-coding technique",
    "descriptor": "",
    "authors": [
      "Weida Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00230"
  },
  {
    "id": "arXiv:2211.00384",
    "title": "The future is different: Large pre-trained language models fail in  prediction tasks",
    "abstract": "The future is different: Large pre-trained language models fail in  prediction tasks",
    "descriptor": "",
    "authors": [
      "Kostadin Cvejoski",
      "Rams\u00e9s J. S\u00e1nchez",
      "C\u00e9sar Ojeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00384"
  },
  {
    "id": "arXiv:2211.00577",
    "title": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "abstract": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "descriptor": "",
    "authors": [
      "Alireza Aghelan",
      "Modjtaba Rouhani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00577"
  },
  {
    "id": "arXiv:2211.00732",
    "title": "Kuaipedia: a Large-scale Multi-modal Short-video Encyclopedia",
    "abstract": "Kuaipedia: a Large-scale Multi-modal Short-video Encyclopedia",
    "descriptor": "",
    "authors": [
      "Haojie Pan",
      "Yuzhou Zhang",
      "Zepeng Zhai",
      "Ruiji Fu",
      "Ming Liu",
      "Yangqiu Song",
      "Zhongyuan Wang",
      "Bing Qin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00732"
  },
  {
    "id": "arXiv:2211.00915",
    "title": "Passage-Mask: A Learnable Regularization Strategy for Retriever-Reader  Models",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Shujian Zhang",
      "Chengyue Gong",
      "Xingchao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00915"
  },
  {
    "id": "arXiv:2211.00924",
    "title": "SyncTalkFace: Talking Face Generation with Precise Lip-Syncing via  Audio-Lip Memory",
    "abstract": "Comments: Accepted at AAAI 2022 (Oral)",
    "descriptor": "\nComments: Accepted at AAAI 2022 (Oral)\n",
    "authors": [
      "Se Jin Park",
      "Minsu Kim",
      "Joanna Hong",
      "Jeongsoo Choi",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.00924"
  },
  {
    "id": "arXiv:2211.01016",
    "title": "Holographic-Type Communication for Digital Twin: A Learning-based  Auction Approach",
    "abstract": "Comments: 6 pages",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "XiuYu Zhang",
      "Minrui Xu",
      "Rui Tan",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.01016"
  },
  {
    "id": "arXiv:2211.01058",
    "title": "A Note on the Ramanujan Machine",
    "abstract": "A Note on the Ramanujan Machine",
    "descriptor": "",
    "authors": [
      "Eric Brier",
      "David Naccache",
      "Ofer Yifrach-Stav"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2211.01058"
  },
  {
    "id": "arXiv:2211.01109",
    "title": "The Impostor Among US(B): Off-Path Injection Attacks on USB  Communications",
    "abstract": "Comments: To appear in USENIX Security 2023",
    "descriptor": "\nComments: To appear in USENIX Security 2023\n",
    "authors": [
      "Robert Dumitru",
      "Daniel Genkin",
      "Andrew Wabnitz",
      "Yuval Yarom"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01109"
  },
  {
    "id": "arXiv:2211.01111",
    "title": "On the Benefit of Dual-domain Denoising in a Self-supervised Low-dose CT  Setting",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Fabian Wagner",
      "Mareike Thies",
      "Laura Pfaff",
      "Oliver Aust",
      "Sabrina Pechmann",
      "Daniela Weidner",
      "Noah Maul",
      "Maximilian Rohleder",
      "Mingxuan Gu",
      "Jonas Utz",
      "Felix Denzinger",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01111"
  },
  {
    "id": "arXiv:2211.01122",
    "title": "Fast Adaptive Federated Bilevel Optimization",
    "abstract": "Comments: 45 pages. arXiv admin note: text overlap with arXiv:2106.11396",
    "descriptor": "\nComments: 45 pages. arXiv admin note: text overlap with arXiv:2106.11396\n",
    "authors": [
      "Feihu Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.01122"
  },
  {
    "id": "arXiv:2211.01214",
    "title": "Time-aware Random Walk Diffusion to Improve Dynamic Graph Learning",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jong-whi Lee",
      "Jinhong Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01214"
  },
  {
    "id": "arXiv:2211.01226",
    "title": "DEArt: Dataset of European Art",
    "abstract": "Comments: VISART VI. Workshop at the European Conference of Computer Vision (ECCV)",
    "descriptor": "\nComments: VISART VI. Workshop at the European Conference of Computer Vision (ECCV)\n",
    "authors": [
      "Artem Reshetnikov",
      "Maria-Cristina Marinescu",
      "Joaquim More Lopez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01226"
  },
  {
    "id": "arXiv:2211.01311",
    "title": "Distill and Collect for Semi-Supervised Temporal Action Segmentation",
    "abstract": "Distill and Collect for Semi-Supervised Temporal Action Segmentation",
    "descriptor": "",
    "authors": [
      "Sovan Biswas",
      "Anthony Rhodes",
      "Ramesh Manuvinakurike",
      "Giuseppe Raffa",
      "Richard Beckwith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01311"
  },
  {
    "id": "arXiv:2211.01334",
    "title": "MemoNet:Memorizing Representations of All Cross Features Efficiently via  Multi-Hash Codebook Network for CTR Prediction",
    "abstract": "MemoNet:Memorizing Representations of All Cross Features Efficiently via  Multi-Hash Codebook Network for CTR Prediction",
    "descriptor": "",
    "authors": [
      "Pengtao Zhang",
      "Junlin Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01334"
  },
  {
    "id": "arXiv:2211.01335",
    "title": "Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese",
    "abstract": "Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese",
    "descriptor": "",
    "authors": [
      "An Yang",
      "Junshu Pan",
      "Junyang Lin",
      "Rui Men",
      "Yichang Zhang",
      "Jingren Zhou",
      "Chang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01335"
  }
]
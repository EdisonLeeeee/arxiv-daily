[
  {
    "id": "arXiv:2211.00640",
    "title": "CascadeXML: Rethinking Transformers for End-to-end Multi-resolution  Training in Extreme Multi-label Classification",
    "abstract": "Extreme Multi-label Text Classification (XMC) involves learning a classifier\nthat can assign an input with a subset of most relevant labels from millions of\nlabel choices. Recent approaches, such as XR-Transformer and LightXML, leverage\na transformer instance to achieve state-of-the-art performance. However, in\nthis process, these approaches need to make various trade-offs between\nperformance and computational requirements. A major shortcoming, as compared to\nthe Bi-LSTM based AttentionXML, is that they fail to keep separate feature\nrepresentations for each resolution in a label tree. We thus propose\nCascadeXML, an end-to-end multi-resolution learning pipeline, which can harness\nthe multi-layered architecture of a transformer model for attending to\ndifferent label resolutions with separate feature representations. CascadeXML\nsignificantly outperforms all existing approaches with non-trivial gains\nobtained on benchmark datasets consisting of up to three million labels. Code\nfor CascadeXML will be made publicly available at\n\\url{https://github.com/xmc-aalto/cascadexml}.",
    "descriptor": "",
    "authors": [
      "Siddhant Kharbanda",
      "Atmadeep Banerjee",
      "Erik Schultheis",
      "Rohit Babbar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.00640"
  },
  {
    "id": "arXiv:2211.00641",
    "title": "Transposed Variational Auto-encoder with Intrinsic Feature Learning for  Traffic Forecasting",
    "abstract": "In this technical report, we present our solutions to the Traffic4cast 2022\ncore challenge and extended challenge. In this competition, the participants\nare required to predict the traffic states for the future 15-minute based on\nthe vehicle counter data in the previous hour. Compared to other competitions\nin the same series, this year focuses on the prediction of different data\nsources and sparse vertex-to-edge generalization. To address these issues, we\nintroduce the Transposed Variational Auto-encoder (TVAE) model to reconstruct\nthe missing data and Graph Attention Networks (GAT) to strengthen the\ncorrelations between learned representations. We further apply feature\nselection to learn traffic patterns from diverse but easily available data. Our\nsolutions have ranked first in both challenges on the final leaderboard. The\nsource code is available at \\url{https://github.com/Daftstone/Traffic4cast}",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Leyan Deng",
      "Chenwang Wu",
      "Defu Lian",
      "Min Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00641"
  },
  {
    "id": "arXiv:2211.00642",
    "title": "Farm-wide virtual load monitoring for offshore wind structures via  Bayesian neural networks",
    "abstract": "Offshore wind structures are subject to deterioration mechanisms throughout\ntheir operational lifetime. Even if the deterioration evolution of structural\nelements can be estimated through physics-based deterioration models, the\nuncertainties involved in the process hurdle the selection of lifecycle\nmanagement decisions. In this scenario, the collection of relevant information\nthrough an efficient monitoring system enables the reduction of uncertainties,\nultimately driving more optimal lifecycle decisions. However, a full monitoring\ninstrumentation implemented on all wind turbines in a farm might become\nunfeasible due to practical and economical constraints. Besides, certain load\nmonitoring systems often become defective after a few years of marine\nenvironment exposure. Addressing the aforementioned concerns, a farm-wide\nvirtual load monitoring scheme directed by a fleet-leader wind turbine offers\nan attractive solution. Fetched with data retrieved from a fully-instrumented\nwind turbine, a model can be trained and then deployed, thus yielding load\npredictions of non-fully monitored wind turbines, from which only standard data\nremains available. In this paper, we propose a virtual load monitoring\nframework formulated via Bayesian neural networks (BNNs) and we provide\nrelevant implementation details needed for the construction, training, and\ndeployment of BNN data-based virtual monitoring models. As opposed to their\ndeterministic counterparts, BNNs intrinsically announce the uncertainties\nassociated with generated load predictions and allow to detect inaccurate load\nestimations generated for non-fully monitored wind turbines. The proposed\nvirtual load monitoring is thoroughly tested through an experimental campaign\nin an operational offshore wind farm and the results demonstrate the\neffectiveness of BNN models for fleet-leader-based farm-wide virtual\nmonitoring.",
    "descriptor": "",
    "authors": [
      "N. Hlaing",
      "Pablo G. Morato",
      "F. d. N. Santos",
      "W. Weijtjens",
      "C. Devriendt",
      "P. Rigo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.00642"
  },
  {
    "id": "arXiv:2211.00676",
    "title": "Towards Inter-character Relationship-driven Story Generation",
    "abstract": "In this paper, we introduce the task of modeling interpersonal relationships\nfor story generation. For addressing this task, we propose Relationships as\nLatent Variables for Story Generation, (ReLiSt). ReLiSt generates stories\nsentence by sentence and has two major components - a relationship selector and\na story continuer. The relationship selector specifies a latent variable to\npick the relationship to exhibit in the next sentence and the story continuer\ngenerates the next sentence while expressing the selected relationship in a\ncoherent way. Our automatic and human evaluations demonstrate that ReLiSt is\nable to generate stories with relationships that are more faithful to desired\nrelationships while maintaining the content quality. The relationship\nassignments to sentences during inference bring interpretability to ReLiSt.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Anvesh Rao Vijjini",
      "Faeze Brahman",
      "Snigdha Chaturvedi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00676"
  },
  {
    "id": "arXiv:2211.00680",
    "title": "On the detection of synthetic images generated by diffusion models",
    "abstract": "Over the past decade, there has been tremendous progress in creating\nsynthetic media, mainly thanks to the development of powerful methods based on\ngenerative adversarial networks (GAN). Very recently, methods based on\ndiffusion models (DM) have been gaining the spotlight. In addition to providing\nan impressive level of photorealism, they enable the creation of text-based\nvisual content, opening up new and exciting opportunities in many different\napplication fields, from arts to video games. On the other hand, this property\nis an additional asset in the hands of malicious users, who can generate and\ndistribute fake media perfectly adapted to their attacks, posing new challenges\nto the media forensic community. With this work, we seek to understand how\ndifficult it is to distinguish synthetic images generated by diffusion models\nfrom pristine ones and whether current state-of-the-art detectors are suitable\nfor the task. To this end, first we expose the forensics traces left by\ndiffusion models, then study how current detectors, developed for GAN-generated\nimages, perform on these new synthetic images, especially in challenging\nsocial-networks scenarios involving image compression and resizing. Datasets\nand code are available at github.com/grip-unina/DMimageDetection.",
    "descriptor": "",
    "authors": [
      "Riccardo Corvi",
      "Davide Cozzolino",
      "Giada Zingarini",
      "Giovanni Poggi",
      "Koki Nagano",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00680"
  },
  {
    "id": "arXiv:2211.00683",
    "title": "Reduce, Reuse, Recycle: Improving Training Efficiency with Distillation",
    "abstract": "Methods for improving the efficiency of deep network training (i.e. the\nresources required to achieve a given level of model quality) are of immediate\nbenefit to deep learning practitioners. Distillation is typically used to\ncompress models or improve model quality, but it's unclear if distillation\nactually improves training efficiency. Can the quality improvements of\ndistillation be converted into training speed-ups, or do they simply increase\nfinal model quality with no resource savings? We conducted a series of\nexperiments to investigate whether and how distillation can be used to\naccelerate training using ResNet-50 trained on ImageNet and BERT trained on C4\nwith a masked language modeling objective and evaluated on GLUE, using common\nenterprise hardware (8x NVIDIA A100). We found that distillation can speed up\ntraining by up to 1.96x in ResNet-50 trained on ImageNet and up to 1.42x on\nBERT when evaluated on GLUE. Furthermore, distillation for BERT yields optimal\nresults when it is only performed for the first 20-50% of training. We also\nobserved that training with distillation is almost always more efficient than\ntraining without distillation, even when using the poorest-quality model as a\nteacher, in both ResNet-50 and BERT. Finally, we found that it's possible to\ngain the benefit of distilling from an ensemble of teacher models, which has\nO(n) runtime cost, by randomly sampling a single teacher from the pool of\nteacher models on each step, which only has a O(1) runtime cost. Taken\ntogether, these results show that distillation can substantially improve\ntraining efficiency in both image classification and language modeling, and\nthat a few simple optimizations to distillation protocols can further enhance\nthese efficiency improvements.",
    "descriptor": "",
    "authors": [
      "Cody Blakeney",
      "Jessica Zosa Forde",
      "Jonathan Frankle",
      "Ziliang Zong",
      "Matthew L. Leavitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00683"
  },
  {
    "id": "arXiv:2211.00684",
    "title": "TOE: A Grid-Tagging Discontinuous NER Model Enhanced by Embedding  Tag/Word Relations and More Fine-Grained Tags",
    "abstract": "So far, discontinuous named entity recognition (NER) has received increasing\nresearch attention and many related methods have surged such as\nhypergraph-based methods, span-based methods, and sequence-to-sequence\n(Seq2Seq) methods, etc. However, these methods more or less suffer from some\nproblems such as decoding ambiguity and efficiency, which limit their\nperformance. Recently, grid-tagging methods, which benefit from the flexible\ndesign of tagging systems and model architectures, have shown superiority to\nadapt for various information extraction tasks. In this paper, we follow the\nline of such methods and propose a competitive grid-tagging model for\ndiscontinuous NER. We call our model TOE because we incorporate two kinds of\nTag-Oriented Enhancement mechanisms into a state-of-the-art (SOTA) grid-tagging\nmodel that casts the NER problem into word-word relationship prediction. First,\nwe design a Tag Representation Embedding Module (TREM) to force our model to\nconsider not only word-word relationships but also word-tag and tag-tag\nrelationships. Concretely, we construct tag representations and embed them into\nTREM, so that TREM can treat tag and word representations as\nqueries/keys/values and utilize self-attention to model their relationships. On\nthe other hand, motivated by the Next-Neighboring-Word (NNW) and Tail-Head-Word\n(THW) tags in the SOTA model, we add two new symmetric tags, namely\nPrevious-Neighboring-Word (PNW) and Head-Tail-Word (HTW), to model more\nfine-grained word-word relationships and alleviate error propagation from tag\nprediction. In the experiments of three benchmark datasets, namely CADEC,\nShARe13 and ShARe14, our TOE model pushes the SOTA results by about 0.83%,\n0.05% and 0.66% in F1, demonstrating its effectiveness.",
    "descriptor": "",
    "authors": [
      "Jiang Liu",
      "Donghong Ji",
      "Jingye Li",
      "Dongdong Xie",
      "Chong Teng",
      "Liang Zhao",
      "Fei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00684"
  },
  {
    "id": "arXiv:2211.00688",
    "title": "Learning to Solve Voxel Building Embodied Tasks from Pixels and Natural  Language Instructions",
    "abstract": "The adoption of pre-trained language models to generate action plans for\nembodied agents is a promising research strategy. However, execution of\ninstructions in real or simulated environments requires verification of the\nfeasibility of actions as well as their relevance to the completion of a goal.\nWe propose a new method that combines a language model and reinforcement\nlearning for the task of building objects in a Minecraft-like environment\naccording to the natural language instructions. Our method first generates a\nset of consistently achievable sub-goals from the instructions and then\ncompletes associated sub-tasks with a pre-trained RL policy. The proposed\nmethod formed the RL baseline at the IGLU 2022 competition.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Alexey Skrynnik",
      "Zoya Volovikova",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Anton Voronov",
      "Artem Zholus",
      "Negar Arabzadeh",
      "Shrestha Mohanty",
      "Milagro Teruel",
      "Ahmed Awadallah",
      "Aleksandr Panov",
      "Mikhail Burtsev",
      "Julia Kiseleva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00688"
  },
  {
    "id": "arXiv:2211.00689",
    "title": "A control-oriented wind turbine dynamic simulation framework which  resolves local atmospheric conditions",
    "abstract": "Wind turbines may experience local weather perturbation, which is not taken\ninto account by the commonly-used wind turbine simulation packages. Without\nthis information, it is extremely challenging to evaluate the controller\nperformance with regard to the effect of the variation of local atmospheric\nconditions. On the other side, it is too late and costly to wait until field\ntest time. To fill this gap, in this paper, we develop a control-oriented\nturbine dynamic simulation framework to evaluate the controller performance\nconsidering the perturbation of local atmospheric conditions. This goal is\nachieved by integrating an internal wind turbine (IWT) model in the Weather\nResearch and Forecasting (WRF) simulation tool. The proposed framework is\nimplemented on a 5MW reference wind turbine, where the effects of the local\natmospheric conditions are illustrated. The controller performance results are\ncompared with those derived from the Fatigue, Aerodynamics, Structures,and\nTurbulence (FAST) simulator as a validation. Simulation results show that the\nproposed WRF-IWT model is able to capture the turbine dynamics and controller\nperformance regarding the perturbation of the complex local atmospheric\nconditions. The proposed framework can be leveraged to assist in designing\ncontrollers, which is more applicable to real-world wind conditions.",
    "descriptor": "\nComments: 8 pages, 9 figures, RENEW CONFERENCE 2022\n",
    "authors": [
      "Z. Feng",
      "Y. Liu",
      "R. Ferrari",
      "J.W. van.Wingerden"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00689"
  },
  {
    "id": "arXiv:2211.00692",
    "title": "Towards Better Out-of-Distribution Generalization of Neural Algorithmic  Reasoning Tasks",
    "abstract": "In this paper, we study the OOD generalization of neural algorithmic\nreasoning tasks, where the goal is to learn an algorithm (e.g., sorting,\nbreadth-first search, and depth-first search) from input-output pairs using\ndeep neural networks. First, we argue that OOD generalization in this setting\nis significantly different than common OOD settings. For example, some\nphenomena in OOD generalization of image classifications such as \\emph{accuracy\non the line} are not observed here, and techniques such as data augmentation\nmethods do not help as assumptions underlying many augmentation techniques are\noften violated. Second, we analyze the main challenges (e.g., input\ndistribution shift, non-representative data generation, and uninformative\nvalidation metrics) of the current leading benchmark, i.e., CLRS\n\\citep{deepmind2021clrs}, which contains 30 algorithmic reasoning tasks. We\npropose several solutions, including a simple-yet-effective fix to the input\ndistribution shift and improved data generation. Finally, we propose an\nattention-based 2WL-graph neural network (GNN) processor which complements\nmessage-passing GNNs so their combination outperforms the state-of-the-art\nmodel by a 3% margin averaged over all algorithms. Our code is available at:\n\\url{https://github.com/smahdavi4/clrs}.",
    "descriptor": "",
    "authors": [
      "Sadegh Mahdavi",
      "Kevin Swersky",
      "Thomas Kipf",
      "Milad Hashemi",
      "Christos Thrampoulidis",
      "Renjie Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00692"
  },
  {
    "id": "arXiv:2211.00696",
    "title": "Exploiting Kronecker structure in exponential integrators: fast  approximation of the action of $\\varphi$-functions of matrices via quadrature",
    "abstract": "In this article, we propose an algorithm for approximating the action of\n$\\varphi-$functions of matrices against vectors, which is a key operation in\nexponential time integrators. In particular, we consider matrices with\nKronecker sum structure, which arise from problems admitting a tensor product\nrepresentation. The method is based on quadrature approximations of the\nintegral form of the $\\varphi-$functions combined with a scaling and modified\nsquaring method. Owing to the Kronecker sum representation, only actions of 1D\nmatrix exponentials are needed at each quadrature node and assembly of the full\nmatrix can be avoided. Additionally, we derive \\emph{a priori} bounds for the\nquadrature error, which show that, as expected by classical theory, the rate of\nconvergence of our method is supergeometric. Guided by our analysis, we\nconstruct a fast and robust method for estimating the optimal scaling factor\nand number of quadrature nodes that minimizes the total cost for a prescribed\nerror tolerance. We investigate the performance of our algorithm by solving\nseveral linear and semilinear time-dependent problems in 2D and 3D. The results\nshow that our method is accurate and orders of magnitude faster than the\ncurrent state-of-the-art.",
    "descriptor": "\nComments: 20 pages, 3 figures, 7 tables\n",
    "authors": [
      "Matteo Croci",
      "Judit Mu\u00f1oz-Matute"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2211.00696"
  },
  {
    "id": "arXiv:2211.00705",
    "title": "Explicit-Implicit Domain Splitting for Two Phase Flows with Phase  Transition",
    "abstract": "Two phase flows that include phase transition, especially phase creation,\nwith a sharp interface remain a challenging task for numerics. We consider the\nisothermal Euler equations with phase transition between a liquid and a vapor\nphase. The phase interface is modeled as a sharp interface and the mass\ntransfer across the phase boundary is modeled by a kinetic relation. Existence\nand uniqueness results were proven in Ref. \\cite{Hantke2019a}. Using sharp\ninterfaces for simulating nucleation and cavitation results in the grid\ncontaining tiny cells that are several orders of magnitude smaller than the\nremaining grid cells. This forces explicit time stepping schemes to take tiny\ntime steps on these cells. As a remedy we suggest an explicit implicit domain\nsplitting where the majority of the grid cells is treated explicitly and only\nthe neighborhood of the tiny cells is treated implicitly. We use dual time\nstepping to solve the resulting small implicit systems. Our numerical results\nindicate that the new scheme is robust and provides significant speed-up\ncompared to a fully explicit treatment.",
    "descriptor": "",
    "authors": [
      "Sandra May",
      "Ferdinand Thein"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.00705"
  },
  {
    "id": "arXiv:2211.00707",
    "title": "Simplified Prophet Inequalities for Combinatorial Auctions",
    "abstract": "We consider prophet inequalities for XOS and MPH-$k$ combinatorial auctions\nand give a simplified proof for the existence of static and anonymous item\nprices which recover the state-of-the-art competitive ratios.\nOur proofs make use of a linear programming formulation which has a\nnon-negative objective value if there are prices which admit a given\ncompetitive ratio $\\alpha \\geq 1$. Changing our perspective to dual space by an\napplication of strong LP duality, we use an interpretation of the dual\nvariables as probabilities to directly obtain our result. In contrast to\nprevious work, our proofs do not require to argue about specific values of\nbuyers for bundles, but only about the presence or absence of items.\nAs a side remark, for any $k \\geq 2$, this simplification also leads to a\ntiny improvement in the best competitive ratio for MPH-$k$ combinatorial\nauctions from $4k-2$ to $2k + 2 \\sqrt{k(k-1)} -1$.",
    "descriptor": "",
    "authors": [
      "Alexander Braun",
      "Thomas Kesselheim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.00707"
  },
  {
    "id": "arXiv:2211.00708",
    "title": "Inferring school district learning modalities during the COVID-19  pandemic with a hidden Markov model",
    "abstract": "In this study, learning modalities offered by public schools across the\nUnited States were investigated to track changes in the proportion of schools\noffering fully in-person, hybrid and fully remote learning over time. Learning\nmodalities from 14,688 unique school districts from September 2020 to June 2021\nwere reported by Burbio, MCH Strategic Data, the American Enterprise\nInstitute's Return to Learn Tracker and individual state dashboards. A model\nwas needed to combine and deconflict these data to provide a more complete\ndescription of modalities nationwide.\nA hidden Markov model (HMM) was used to infer the most likely learning\nmodality for each district on a weekly basis. This method yielded higher\nspatiotemporal coverage than any individual data source and higher agreement\nwith three of the four data sources than any other single source. The model\noutput revealed that the percentage of districts offering fully in-person\nlearning rose from 40.3% in September 2020 to 54.7% in June of 2021 with\nincreases across 45 states and in both urban and rural districts. This type of\nprobabilistic model can serve as a tool for fusion of incomplete and\ncontradictory data sources in support of public health surveillance and\nresearch efforts.",
    "descriptor": "\nComments: 25 pages, 4 figures\n",
    "authors": [
      "Mark J. Panaggio",
      "Mike Fang",
      "Hyunseung Bang",
      "Paige A. Armstrong",
      "Alison M. Binder",
      "Julian E. Grass",
      "Jake Magid",
      "Marc Papazian",
      "Carrie K Shapiro-Mendoza",
      "Sharyn E. Parks"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00708"
  },
  {
    "id": "arXiv:2211.00709",
    "title": "Semantic Pivoting Model for Effective Event Detection",
    "abstract": "Event Detection, which aims to identify and classify mentions of event\ninstances from unstructured articles, is an important task in Natural Language\nProcessing (NLP). Existing techniques for event detection only use homogeneous\none-hot vectors to represent the event type classes, ignoring the fact that the\nsemantic meaning of the types is important to the task. Such an approach is\ninefficient and prone to overfitting. In this paper, we propose a Semantic\nPivoting Model for Effective Event Detection (SPEED), which explicitly\nincorporates prior information during training and captures semantically\nmeaningful correlations between input and events. Experimental results show\nthat our proposed model achieves state-of-the-art performance and outperforms\nthe baselines in multiple settings without using any external resources.",
    "descriptor": "\nComments: 11 pages, 4 figures; Accepted to ACIIDS 2022\n",
    "authors": [
      "Anran Hao",
      "Siu Cheung Hui",
      "Jian Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00709"
  },
  {
    "id": "arXiv:2211.00711",
    "title": "Alternative polynomial-time algorithm for Bipartite Matching",
    "abstract": "If $G$ is a bipartite graph, Hall's theorem \\cite{H35} gives a condition for\nthe existence of a matching of $G$ covering one side of the bipartition. This\ntheorem admits a well-known algorithmic proof involving the repeated search of\naugmenting paths. We present here an alternative algorithm, using a\ngame-theoretic formulation of the problem. We also show how to extend this\nformulation to the setting of balanced hypergraphs.",
    "descriptor": "",
    "authors": [
      "Sylvain Guillemot"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.00711"
  },
  {
    "id": "arXiv:2211.00713",
    "title": "MAgNET: A Graph U-Net Architecture for Mesh-Based Simulations",
    "abstract": "Mesh-based approaches are fundamental to solving physics-based simulations,\nhowever, they require significant computational efforts, especially for highly\nnon-linear problems. Deep learning techniques accelerate physics-based\nsimulations, however, they fail to perform efficiently as the size and\ncomplexity of the problem increases. Hence in this work, we propose MAgNET:\nMulti-channel Aggregation Network, a novel geometric deep learning framework\nfor performing supervised learning on mesh-based graph data. MAgNET is based on\nthe proposed MAg (Multichannel Aggregation) operation which generalises the\nconcept of multi-channel local operations in convolutional neural networks to\narbitrary non-grid inputs. MAg can efficiently perform non-linear regression\nmapping for graph-structured data. MAg layers are interleaved with the proposed\nnovel graph pooling operations to constitute a graph U-Net architecture that is\nrobust, handles arbitrary complex meshes and scales efficiently with the size\nof the problem. Although not limited to the type of discretisation, we showcase\nthe predictive capabilities of MAgNET for several non-linear finite element\nsimulations.",
    "descriptor": "",
    "authors": [
      "Saurabh Deshpande",
      "Jakub Lengiewicz",
      "St\u00e9phane P.A. Bordas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.00713"
  },
  {
    "id": "arXiv:2211.00715",
    "title": "Tunable Dynamic Walking via Soft Twisted Beam Vibration",
    "abstract": "We propose a novel mechanism that propagates vibration through soft twisted\nbeams, taking advantage of dynamically-coupled anisotropic stiffness to\nsimplify the actuation of walking robots. Using dynamic simulation and\nexperimental approaches, we show that the coupled stiffness of twisted beams\nwith terrain contact can be controlled to generate a variety of complex\ntrajectories by changing the frequency of the input signal. This work reveals\nhow ground contact influences the system's dynamic behavior, supporting the\ndesign of walking robots inspired by this phenomenon. We also show that the\nproposed twisted beam produces a tunable walking gait from a single vibrational\ninput.",
    "descriptor": "\nComments: 8 pages, 5 figure, this paper has been submitted to IEEE Robotics and Automation Letters, copyright may be transferred without notice, after which this version may no longer be accessible, the supplemental video is available at: this https URL\n",
    "authors": [
      "Yuhao Jiang",
      "Fuchen Chen",
      "Daniel M. Aukes"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00715"
  },
  {
    "id": "arXiv:2211.00716",
    "title": "Optimal Conservative Offline RL with General Function Approximation via  Augmented Lagrangian",
    "abstract": "Offline reinforcement learning (RL), which refers to decision-making from a\npreviously-collected dataset of interactions, has received significant\nattention over the past years. Much effort has focused on improving offline RL\npracticality by addressing the prevalent issue of partial data coverage through\nvarious forms of conservative policy learning. While the majority of algorithms\ndo not have finite-sample guarantees, several provable conservative offline RL\nalgorithms are designed and analyzed within the single-policy concentrability\nframework that handles partial coverage. Yet, in the nonlinear function\napproximation setting where confidence intervals are difficult to obtain,\nexisting provable algorithms suffer from computational intractability,\nprohibitively strong assumptions, and suboptimal statistical rates. In this\npaper, we leverage the marginalized importance sampling (MIS) formulation of RL\nand present the first set of offline RL algorithms that are statistically\noptimal and practical under general function approximation and single-policy\nconcentrability, bypassing the need for uncertainty quantification. We identify\nthat the key to successfully solving the sample-based approximation of the MIS\nproblem is ensuring that certain occupancy validity constraints are nearly\nsatisfied. We enforce these constraints by a novel application of the augmented\nLagrangian method and prove the following result: with the MIS formulation,\naugmented Lagrangian is enough for statistically optimal offline RL. In stark\ncontrast to prior algorithms that induce additional conservatism through\nmethods such as behavior regularization, our approach provably eliminates this\nneed and reinterprets regularizers as \"enforcers of occupancy validity\" than\n\"promoters of conservatism.\"",
    "descriptor": "\nComments: 49 pages, 1 figure\n",
    "authors": [
      "Paria Rashidinejad",
      "Hanlin Zhu",
      "Kunhe Yang",
      "Stuart Russell",
      "Jiantao Jiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.00716"
  },
  {
    "id": "arXiv:2211.00717",
    "title": "Using Unused: Non-Invasive Dynamic FaaS Infrastructure with HPC-Whisk",
    "abstract": "Modern HPC workload managers and their careful tuning contribute to the high\nutilization of HPC clusters. However, due to inevitable uncertainty it is\nimpossible to completely avoid node idleness. Although such idle slots are\nusually too short for any HPC job, they are too long to ignore them.\nFunction-as-a-Service (FaaS) paradigm promisingly fills this gap, and can be a\ngood match, as typical FaaS functions last seconds, not hours. Here we show how\nto build a FaaS infrastructure on idle nodes in an HPC cluster in such a way\nthat it does not affect the performance of the HPC jobs significantly. We\ndynamically adapt to a changing set of idle physical machines, by integrating\nopen-source software Slurm and OpenWhisk.\nWe designed and implemented a prototype solution that allowed us to cover up\nto 90\\% of the idle time slots on a 50k-core cluster that runs production\nworkloads.",
    "descriptor": "",
    "authors": [
      "Bart\u0142omiej Przybylski",
      "Maciej Pawlik",
      "Pawe\u0142 \u017buk",
      "Bart\u0142omiej \u0141agosz",
      "Maciej Malawski",
      "Krzysztof Rzadca"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00717"
  },
  {
    "id": "arXiv:2211.00718",
    "title": "SleepyWheels: An Ensemble Model for Drowsiness Detection leading to  Accident Prevention",
    "abstract": "Around 40 percent of accidents related to driving on highways in India occur\ndue to the driver falling asleep behind the steering wheel. Several types of\nresearch are ongoing to detect driver drowsiness but they suffer from the\ncomplexity and cost of the models. In this paper, SleepyWheels a revolutionary\nmethod that uses a lightweight neural network in conjunction with facial\nlandmark identification is proposed to identify driver fatigue in real time.\nSleepyWheels is successful in a wide range of test scenarios, including the\nlack of facial characteristics while covering the eye or mouth, the drivers\nvarying skin tones, camera placements, and observational angles. It can work\nwell when emulated to real time systems. SleepyWheels utilized EfficientNetV2\nand a facial landmark detector for identifying drowsiness detection. The model\nis trained on a specially created dataset on driver sleepiness and it achieves\nan accuracy of 97 percent. The model is lightweight hence it can be further\ndeployed as a mobile application for various platforms.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Jomin Jose",
      "Andrew J",
      "Kumudha Raimond",
      "Shweta Vincent"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00718"
  },
  {
    "id": "arXiv:2211.00720",
    "title": "Apple Silicon Performance in Scientific Computing",
    "abstract": "With the release of the Apple Silicon System-on-a-Chip processors, and the\nimpressive performance shown in general use by both the M1 and M1 Ultra, the\npotential use for Apple Silicon processors in scientific computing is explored.\nBoth the M1 and M1 Ultra are compared to current state-of-the-art data-center\nGPUs, including an NVIDIA V100 with PCIe, an NVIDIA V100 with NVLink, and an\nNVIDIA A100 with PCIe. The scientific performance is measured using the\nScalable Heterogeneous Computing (SHOC) benchmark suite using OpenCL\nbenchmarks. We find that both M1 processors outperform the GPUs in all\nbenchmarks.",
    "descriptor": "\nComments: 10 pages, 3 figures, IEEE HPEC\n",
    "authors": [
      "Connor Kenyon",
      "Collin Capano"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.00720"
  },
  {
    "id": "arXiv:2211.00722",
    "title": "VIINTER: View Interpolation with Implicit Neural Representations of  Images",
    "abstract": "We present VIINTER, a method for view interpolation by interpolating the\nimplicit neural representation (INR) of the captured images. We leverage the\nlearned code vector associated with each image and interpolate between these\ncodes to achieve viewpoint transitions. We propose several techniques that\nsignificantly enhance the interpolation quality. VIINTER signifies a new way to\nachieve view interpolation without constructing 3D structure, estimating camera\nposes, or computing pixel correspondence. We validate the effectiveness of\nVIINTER on several multi-view scenes with different types of camera layout and\nscene composition. As the development of INR of images (as opposed to surface\nor volume) has centered around tasks like image fitting and super-resolution,\nwith VIINTER, we show its capability for view interpolation and offer a\npromising outlook on using INR for image manipulation tasks.",
    "descriptor": "\nComments: SIGGRAPH Asia 2022\n",
    "authors": [
      "Brandon Yushan Feng",
      "Susmija Jabbireddy",
      "Amitabh Varshney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00722"
  },
  {
    "id": "arXiv:2211.00730",
    "title": "Tactile interaction with a robot leads to increased risk-taking",
    "abstract": "Tactile interaction plays a crucial role in interactions between people.\nTouch can, for example, help people calm down and lower physiological stress\nresponses. Consequently, it is believed that tactile and haptic interaction\nmatter also in human-robot interaction. We study if the intensity of the\ntactile interaction has an impact on people, and do so by studying whether\ndifferent intensities of tactile interaction modulate physiological measures\nand task performance. We use a paradigm in which a small humanoid robot is used\nto encourage risk-taking behaviour, relying on peer encouragement to take more\nrisks which might lead to a higher pay-off, but potentially also to higher\nlosses. For this, the Balloon Analogue Risk Task (BART) is used as a proxy for\nthe propensity to take risks. We study four conditions, one control condition\nin which the task is completed without a robot, and three experimental\nconditions in which a robot is present that encourages risk-taking behaviour\nwith different degrees of tactile interaction. The results show that both\nlow-intensity and high-intensity tactile interaction increase people's\nrisk-taking behaviour. However, low-intensity tactile interaction increases\ncomfort and lowers stress, whereas high-intensity touch does not.",
    "descriptor": "\nComments: 10 pages, 5 figures, conference\n",
    "authors": [
      "Qiaoqiao Ren",
      "Tony Belpaeme"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00730"
  },
  {
    "id": "arXiv:2211.00731",
    "title": "Comparision Of Adversarial And Non-Adversarial LSTM Music Generative  Models",
    "abstract": "Algorithmic music composition is a way of composing musical pieces with\nminimal to no human intervention. While recurrent neural networks are\ntraditionally applied to many sequence-to-sequence prediction tasks, including\nsuccessful implementations of music composition, their standard supervised\nlearning approach based on input-to-output mapping leads to a lack of note\nvariety. These models can therefore be seen as potentially unsuitable for tasks\nsuch as music generation. Generative adversarial networks learn the generative\ndistribution of data and lead to varied samples. This work implements and\ncompares adversarial and non-adversarial training of recurrent neural network\nmusic composers on MIDI data. The resulting music samples are evaluated by\nhuman listeners, their preferences recorded. The evaluation indicates that\nadversarial training produces more aesthetically pleasing music.",
    "descriptor": "\nComments: Submitted to a 2023 conference, 20 pages, 13 figures\n",
    "authors": [
      "Moseli Mots'oehli",
      "Anna Sergeevna Bosman",
      "Johan Pieter De Villiers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00731"
  },
  {
    "id": "arXiv:2211.00732",
    "title": "Kuaipedia: a Large-scale Multi-modal Short-video Encyclopedia",
    "abstract": "Online encyclopedias, such as Wikipedia, have been well-developed and\nresearched in the last two decades. One can find any attributes or other\ninformation of a wiki item on a wiki page edited by a community of volunteers.\nHowever, the traditional text along with images can hardly express some other\naspects of an item. For example, when we talk about \"Shiba Inu\", one may care\nmore about \"How to feed it\" or \"How to train it to not protect its food\".\nCurrently, short-video platforms have become a hallmark in the online world.\nWhether you're on TikTok, Instagram, Kuaishou, or YouTube Shorts, short-video\napps have changed how we consume and create content today. Except for\nentertainment short videos, we can find more and more authors sharing\ninsightful knowledge widely across all walks of life. These short videos, which\nwe call knowledge videos, can easily express any aspects (E.g. hair or\nhow-to-feed) consumers want to know about an item (E.g. Shiba Inu), and they\ncan be systematically analyzed and organized like an online encyclopedia. In\nthis paper, we propose Kuaipedia, a massive multi-modal encyclopedia consisting\nof items, aspects, and short videos linking to them, which is extracted from\nbillions of videos of Kuaishou, a well-known short-video platform in China. We\nfirst collected items from multiple sources and mined user-centered aspects\nfrom millions of users' queries to build an item-aspect tree. Then we propose a\nnew task called \"multi-modal item-aspect linking\" as an expansion of \"entity\nlinking\" to link short videos into item-aspect pairs and build the whole short\nvideo encyclopedia. Intrinsic evaluations show that our encyclopedia is of\nlarge scale and highly accurate.",
    "descriptor": "",
    "authors": [
      "Haojie Pan",
      "Yuzhou Zhang",
      "Zepeng Zhai",
      "Ruiji Fu",
      "Ming Liu",
      "Yangqiu Song",
      "Zhongyuan Wang",
      "Bing Qin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00732"
  },
  {
    "id": "arXiv:2211.00733",
    "title": "State-of-the-art Models for Object Detection in Various Fields of  Application",
    "abstract": "We present a list of datasets and their best models with the goal of\nadvancing the state-of-the-art in object detection by placing the question of\nobject recognition in the context of the two types of state-of-the-art methods:\none-stage methods and two stage-methods. We provided an in-depth statistical\nanalysis of the five top datasets in the light of recent developments in\ngranulated Deep Learning models - COCO minival, COCO test, Pascal VOC 2007,\nADE20K, and ImageNet. The datasets are handpicked after closely comparing them\nwith the rest in terms of diversity, quality of data, minimal bias, labeling\nquality etc. More importantly, our work extends to provide the best combination\nof these datasets with the emerging models in the last two years. It lists the\ntop models and their optimal use cases for each of the respective datasets. We\nhave provided a comprehensive overview of a variety of both generic and\nspecific object detection models, enlisting comparative results like inference\ntime and average precision of box (AP) fixed at different Intersection Over\nUnion (IoUs) and for different sized objects. The qualitative and quantitative\nanalysis will allow experts to achieve new performance records using the best\ncombination of datasets and models.",
    "descriptor": "\nComments: 4 pages, 5 tables\n",
    "authors": [
      "Syed Ali John Naqvi",
      "Syed Bazil Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00733"
  },
  {
    "id": "arXiv:2211.00734",
    "title": "On the Interaction Between Differential Privacy and Gradient Compression  in Deep Learning",
    "abstract": "While differential privacy and gradient compression are separately\nwell-researched topics in machine learning, the study of interaction between\nthese two topics is still relatively new. We perform a detailed empirical study\non how the Gaussian mechanism for differential privacy and gradient compression\njointly impact test accuracy in deep learning. The existing literature in\ngradient compression mostly evaluates compression in the absence of\ndifferential privacy guarantees, and demonstrate that sufficiently high\ncompression rates reduce accuracy. Similarly, existing literature in\ndifferential privacy evaluates privacy mechanisms in the absence of\ncompression, and demonstrates that sufficiently strong privacy guarantees\nreduce accuracy. In this work, we observe while gradient compression generally\nhas a negative impact on test accuracy in non-private training, it can\nsometimes improve test accuracy in differentially private training.\nSpecifically, we observe that when employing aggressive sparsification or rank\nreduction to the gradients, test accuracy is less affected by the Gaussian\nnoise added for differential privacy. These observations are explained through\nan analysis how differential privacy and compression effects the bias and\nvariance in estimating the average gradient. We follow this study with a\nrecommendation on how to improve test accuracy under the context of\ndifferentially private deep learning and gradient compression. We evaluate this\nproposal and find that it can reduce the negative impact of noise added by\ndifferential privacy mechanisms on test accuracy by up to 24.6%, and reduce the\nnegative impact of gradient sparsification on test accuracy by up to 15.1%.",
    "descriptor": "",
    "authors": [
      "Jimmy Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.00734"
  },
  {
    "id": "arXiv:2211.00735",
    "title": "TorchFL: A Performant Library for Bootstrapping Federated Learning  Experiments",
    "abstract": "With the increased legislation around data privacy, federated learning (FL)\nhas emerged as a promising technique that allows the clients (end-user) to\ncollaboratively train deep learning (DL) models without transferring and\nstoring the data in a centralized, third-party server. Despite the theoretical\nsuccess, FL is yet to be adopted in real-world systems due to the hardware,\ncomputing, and various infrastructure constraints presented by the edge and\nmobile devices of the clients. As a result, simulated datasets, models, and\nexperiments are heavily used by the FL research community to validate their\ntheories and findings. We introduce TorchFL, a performant library for (i)\nbootstrapping the FL experiments, (ii) executing them using various hardware\naccelerators, (iii) profiling the performance, and (iv) logging the overall and\nagent-specific results on the go. Being built on a bottom-up design using\nPyTorch and Lightning, TorchFL provides ready-to-use abstractions for models,\ndatasets, and FL algorithms, while allowing the developers to customize them as\nand when required.",
    "descriptor": "\nComments: 20 pages, 15 figures, 4 tables\n",
    "authors": [
      "Vivek Khimani",
      "Shahin Jabbari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00735"
  },
  {
    "id": "arXiv:2211.00739",
    "title": "Forecasting Patient Flows with Pandemic Induced Concept Drift using  Explainable Machine Learning",
    "abstract": "Accurately forecasting patient arrivals at Urgent Care Clinics (UCCs) and\nEmergency Departments (EDs) is important for effective resourcing and patient\ncare. However, correctly estimating patient flows is not straightforward since\nit depends on many drivers. The predictability of patient arrivals has recently\nbeen further complicated by the COVID-19 pandemic conditions and the resulting\nlockdowns. This study investigates how a suite of novel quasi-real-time\nvariables like Google search terms, pedestrian traffic, the prevailing\nincidence levels of influenza, as well as the COVID-19 Alert Level indicators\ncan both generally improve the forecasting models of patient flows and\neffectively adapt the models to the unfolding disruptions of pandemic\nconditions. This research also uniquely contributes to the body of work in this\ndomain by employing tools from the eXplainable AI field to investigate more\ndeeply the internal mechanics of the models than has previously been done. The\nVoting ensemble-based method combining machine learning and statistical\ntechniques was the most reliable in our experiments. Our study showed that the\nprevailing COVID-19 Alert Level feature together with Google search terms and\npedestrian traffic were effective at producing generalisable forecasts. The\nimplications of this study are that proxy variables can effectively augment\nstandard autoregressive features to ensure accurate forecasting of patient\nflows. The experiments showed that the proposed features are potentially\neffective model inputs for preserving forecast accuracies in the event of\nfuture pandemic outbreaks.",
    "descriptor": "",
    "authors": [
      "Teo Susnjak",
      "Paula Maddigan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.00739"
  },
  {
    "id": "arXiv:2211.00741",
    "title": "Benchmarking Hashing Algorithms for Load Balancing in a Distributed  Database Environment",
    "abstract": "Modern high load applications store data using multiple database instances.\nSuch an architecture requires data consistency, and it is important to ensure\neven distribution of data among nodes. Load balancing is used to achieve these\ngoals.\nHashing is the backbone of virtually all load balancing systems. Since the\nintroduction of classic Consistent Hashing, many algorithms have been devised\nfor this purpose.\nOne of the purposes of the load balancer is to ensure storage cluster\nscalability. It is crucial for the performance of the whole system to transfer\nas few data records as possible during node addition or removal. The load\nbalancer hashing algorithm has the greatest impact on this process.\nIn this paper we experimentally evaluate several hashing algorithms used for\nload balancing, conducting both simulated and real system experiments. To\nevaluate algorithm performance, we have developed a benchmark suite based on\nUnidata MDM~ -- a scalable toolkit for various Master Data Management (MDM)\napplications. For assessment, we have employed three criteria~ -- uniformity of\nthe produced distribution, the number of moved records, and computation speed.\nFollowing the results of our experiments, we have created a table, in which\neach algorithm is given an assessment according to the abovementioned criteria.",
    "descriptor": "",
    "authors": [
      "Alexander Slesarev",
      "Mikhail Mikhailov",
      "George Chernishev"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.00741"
  },
  {
    "id": "arXiv:2211.00746",
    "title": "3DMODT: Attention-Guided Affinities for Joint Detection & Tracking in 3D  Point Clouds",
    "abstract": "We propose a method for joint detection and tracking of multiple objects in\n3D point clouds, a task conventionally treated as a two-step process comprising\nobject detection followed by data association. Our method embeds both steps\ninto a single end-to-end trainable network eliminating the dependency on\nexternal object detectors. Our model exploits temporal information employing\nmultiple frames to detect objects and track them in a single network, thereby\nmaking it a utilitarian formulation for real-world scenarios. Computing\naffinity matrix by employing features similarity across consecutive point cloud\nscans forms an integral part of visual tracking. We propose an attention-based\nrefinement module to refine the affinity matrix by suppressing erroneous\ncorrespondences. The module is designed to capture the global context in\naffinity matrix by employing self-attention within each affinity matrix and\ncross-attention across a pair of affinity matrices. Unlike competing\napproaches, our network does not require complex post-processing algorithms,\nand processes raw LiDAR frames to directly output tracking results. We\ndemonstrate the effectiveness of our method on the three tracking benchmarks:\nJRDB, Waymo, and KITTI. Experimental evaluations indicate the ability of our\nmodel to generalize well across datasets.",
    "descriptor": "",
    "authors": [
      "Jyoti Kini",
      "Ajmal Mian",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00746"
  },
  {
    "id": "arXiv:2211.00748",
    "title": "Maximum Likelihood Distillation for Robust Modulation Classification",
    "abstract": "Deep Neural Networks are being extensively used in communication systems and\nAutomatic Modulation Classification (AMC) in particular. However, they are very\nsusceptible to small adversarial perturbations that are carefully crafted to\nchange the network decision. In this work, we build on knowledge distillation\nideas and adversarial training in order to build more robust AMC systems. We\nfirst outline the importance of the quality of the training data in terms of\naccuracy and robustness of the model. We then propose to use the Maximum\nLikelihood function, which could solve the AMC problem in offline settings, to\ngenerate better training labels. Those labels teach the model to be uncertain\nin challenging conditions, which permits to increase the accuracy, as well as\nthe robustness of the model when combined with adversarial training.\nInterestingly, we observe that this increase in performance transfers to online\nsettings, where the Maximum Likelihood function cannot be used in practice.\nOverall, this work highlights the potential of learning to be uncertain in\ndifficult scenarios, compared to directly removing label noise.",
    "descriptor": "",
    "authors": [
      "Javier Maroto",
      "G\u00e9r\u00f4me Bovet",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00748"
  },
  {
    "id": "arXiv:2211.00752",
    "title": "DeltaFinger: a 3-DoF Wearable Haptic Display Enabling High-Fidelity  Force Vector Presentation at a User Finger",
    "abstract": "This paper presents a novel haptic device DeltaFinger designed to deliver the\nforce of interaction with virtual objects by guiding user's finger with\nwearable delta mechanism. The developed interface is capable to deliver 3D\nforce vector to the fingertip of the index finger of the user, allowing complex\nrendering of virtual reality (VR) environment. The developed device is able to\nproduce the kinesthetic feedback up to 1.8 N in vertical projection and 0.9 N\nin horizontal projection without restricting the motion freedom of of the\nremaining fingers. The experimental results showed a sufficient precision in\nperception of force vector with DeltaFinger (mean force vector error of 0.6\nrad). The proposed device potentially can be applied to VR communications,\nmedicine, and navigation of the people with vision problems.",
    "descriptor": "\nComments: 13 pages, 8 figures, accepted version to AsiaHaptics 2022\n",
    "authors": [
      "Artem Lykov",
      "Aleksey Fedoseev",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00752"
  },
  {
    "id": "arXiv:2211.00755",
    "title": "Neuromorphic Twins for Networked Control and Decision-Making",
    "abstract": "We consider the problem of remotely tracking the state of and unstable linear\ntime-invariant plant by means of data transmitted through a noisy communication\nchannel from an algorithmic point of view. Assuming the dynamics of the plant\nare known, does there exist an algorithm that accepts a description of the\nchannel's characteristics as input, and returns 'Yes' if the transmission\ncapabilities permit the remote tracking of the plant's state, 'No' otherwise?\nDoes there exist an algorithm that, in case of a positive answer, computes a\nsuitable encoder/decoder-pair for the channel? Questions of this kind are\nbecoming increasingly important with regards to future communication\ntechnologies that aim to solve control engineering tasks in a distributed\nmanner. In particular, they play an essential role in digital twinning, an\nemerging information processing approach originally considered in the context\nof Industry 4.0. Yet, the abovementioned questions have been answered in the\nnegative with respect to algorithms that can be implemented on idealized\ndigital hardware, i.e., Turing machines. In this article, we investigate the\nremote state estimation problem in view of the Blum-Shub-Smale computability\nframework. In the broadest sense, the latter can be interpreted as a model for\nidealized analog computation. Especially in the context of neuromorphic\ncomputing, analog hardware has experienced a revival in the past view years.\nHence, the contribution of this work may serve as a motivation for a theory of\nneuromorphic twins as a counterpart to digital twins for analog hardware.",
    "descriptor": "",
    "authors": [
      "Holger Boche",
      "Yannik N. B\u00f6ck",
      "Christian Deppe",
      "Frank H. P. Fitzek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.00755"
  },
  {
    "id": "arXiv:2211.00758",
    "title": "Counterfactual Causality in Networks",
    "abstract": "In this abstract we propose a framework for explaining violations of safety\nproperties in Software Defined Networks, using counterfactual causal reasoning.",
    "descriptor": "",
    "authors": [
      "Georgiana Caltais",
      "Can Olmezoglu"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.00758"
  },
  {
    "id": "arXiv:2211.00759",
    "title": "Operator Selection in Adaptive Large Neighborhood Search using Deep  Reinforcement Learning",
    "abstract": "Large Neighborhood Search (LNS) is a popular heuristic for solving\ncombinatorial optimization problems. LNS iteratively explores the neighborhoods\nin solution spaces using destroy and repair operators. Determining the best\noperators for LNS to solve a problem at hand is a labor-intensive process.\nHence, Adaptive Large Neighborhood Search (ALNS) has been proposed to\nadaptively select operators during the search process based on operator\nperformances of the previous search iterations. Such an operator selection\nprocedure is a heuristic, based on domain knowledge, which is ineffective with\ncomplex, large solution spaces. In this paper, we address the problem of\nselecting operators for each search iteration of ALNS as a sequential decision\nproblem and propose a Deep Reinforcement Learning based method called Deep\nReinforced Adaptive Large Neighborhood Search. As such, the proposed method\naims to learn based on the state of the search which operation to select to\nobtain a high long-term reward, i.e., a good solution to the underlying\noptimization problem. The proposed method is evaluated on a time-dependent\norienteering problem with stochastic weights and time windows. Results show\nthat our approach effectively learns a strategy that adaptively selects\noperators for large neighborhood search, obtaining competitive results compared\nto a state-of-the-art machine learning approach while trained with much fewer\nobservations on small-sized problem instances.",
    "descriptor": "",
    "authors": [
      "Robbert Reijnen",
      "Yingqian Zhang",
      "Hoong Chuin Lau",
      "Zaharah Bukhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00759"
  },
  {
    "id": "arXiv:2211.00767",
    "title": "Over-the-Air Computation for Distributed Systems: Something Old and  Something New",
    "abstract": "Facing the upcoming era of Internet-of-Things and connected intelligence,\nefficient information processing, computation and communication design becomes\na key challenge in large-scale intelligent systems. Recently, Over-the-Air\n(OtA) computation has been proposed for data aggregation and distributed\nfunction computation over a large set of network nodes. Theoretical foundations\nfor this concept exist for a long time, but it was mainly investigated within\nthe context of wireless sensor networks. There are still many open questions\nwhen applying OtA computation in different types of distributed systems where\nmodern wireless communication technology is applied. In this article, we\nprovide a comprehensive overview of the OtA computation principle and its\napplications in distributed learning, control, and inference systems, for both\nserver-coordinated and fully decentralized architectures. Particularly, we\nhighlight the importance of the statistical heterogeneity of data and wireless\nchannels, the temporal evolution of model updates, and the choice of\nperformance metrics, for the communication design in OtA federated learning\n(FL) systems. Several key challenges in privacy, security and robustness\naspects of OtA FL are also identified for further investigation.",
    "descriptor": "\nComments: 7 pages, 3 figures, submitted for possible publication\n",
    "authors": [
      "Zheng Chen",
      "Erik G. Larsson",
      "Carlo Fischione",
      "Mikael Johansson",
      "Yura Malitsky"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00767"
  },
  {
    "id": "arXiv:2211.00768",
    "title": "Why is Winoground Hard? Investigating Failures in Visuolinguistic  Compositionality",
    "abstract": "Recent visuolinguistic pre-trained models show promising progress on various\nend tasks such as image retrieval and video captioning. Yet, they fail\nmiserably on the recently proposed Winoground dataset, which challenges models\nto match paired images and English captions, with items constructed to overlap\nlexically but differ in meaning (e.g., \"there is a mug in some grass\" vs.\n\"there is some grass in a mug\"). By annotating the dataset using new\nfine-grained tags, we show that solving the Winoground task requires not just\ncompositional language understanding, but a host of other abilities like\ncommonsense reasoning or locating small, out-of-focus objects in low-resolution\nimages. In this paper, we identify the dataset's main challenges through a\nsuite of experiments on related tasks (probing task, image retrieval task),\ndata augmentation, and manual inspection of the dataset. Our analysis suggests\nthat a main challenge in visuolinguistic models may lie in fusing visual and\ntextual representations, rather than in compositional language understanding.\nWe release our annotation and code at\nhttps://github.com/ajd12342/why-winoground-hard .",
    "descriptor": "\nComments: Accepted at EMNLP 2022. We release our annotation and code at this https URL . 15 pages, 3 figures\n",
    "authors": [
      "Anuj Diwan",
      "Layne Berry",
      "Eunsol Choi",
      "David Harwath",
      "Kyle Mahowald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00768"
  },
  {
    "id": "arXiv:2211.00778",
    "title": "Monte Carlo Tree Descent for Black-Box Optimization",
    "abstract": "The key to Black-Box Optimization is to efficiently search through input\nregions with potentially widely-varying numerical properties, to achieve\nlow-regret descent and fast progress toward the optima. Monte Carlo Tree Search\n(MCTS) methods have recently been introduced to improve Bayesian optimization\nby computing better partitioning of the search space that balances exploration\nand exploitation. Extending this promising framework, we study how to further\nintegrate sample-based descent for faster optimization. We design novel ways of\nexpanding Monte Carlo search trees, with new descent methods at vertices that\nincorporate stochastic search and Gaussian Processes. We propose the\ncorresponding rules for balancing progress and uncertainty, branch selection,\ntree expansion, and backpropagation. The designed search process puts more\nemphasis on sampling for faster descent and uses localized Gaussian Processes\nas auxiliary metrics for both exploitation and exploration. We show empirically\nthat the proposed algorithms can outperform state-of-the-art methods on many\nchallenging benchmark problems.",
    "descriptor": "\nComments: 17 pages, published in NeurIPS 2022\n",
    "authors": [
      "Yaoguang Zhai",
      "Sicun Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00778"
  },
  {
    "id": "arXiv:2211.00779",
    "title": "Reinforcement Learning in Education: A Multi-Armed Bandit Approach",
    "abstract": "Advances in reinforcement learning research have demonstrated the ways in\nwhich different agent-based models can learn how to optimally perform a task\nwithin a given environment. Reinforcement leaning solves unsupervised problems\nwhere agents move through a state-action-reward loop to maximize the overall\nreward for the agent, which in turn optimizes the solving of a specific problem\nin a given environment. However, these algorithms are designed based on our\nunderstanding of actions that should be taken in a real-world environment to\nsolve a specific problem. One such problem is the ability to identify,\nrecommend and execute an action within a system where the users are the\nsubject, such as in education. In recent years, the use of blended learning\napproaches integrating face-to-face learning with online learning in the\neducation context, has in-creased. Additionally, online platforms used for\neducation require the automation of certain functions such as the\nidentification, recommendation or execution of actions that can benefit the\nuser, in this sense, the student or learner. As promising as these scientific\nadvances are, there is still a need to conduct research in a variety of\ndifferent areas to ensure the successful deployment of these agents within\neducation systems. Therefore, the aim of this study was to contextualise and\nsimulate the cumulative reward within an environment for an intervention\nrecommendation problem in the education context.",
    "descriptor": "\nComments: 17 pages, 6 figures, 1 table, EAI AFRICATEK 2022 Conference\n",
    "authors": [
      "Herkulaas Combrink",
      "Vukosi Marivate",
      "Benjamin Rosman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.00779"
  },
  {
    "id": "arXiv:2211.00780",
    "title": "Measuring Air Quality via Multimodal AI and Satellite Imagery",
    "abstract": "Climate change may be classified as the most important environmental problem\nthat the Earth is currently facing, and affects all living species on Earth.\nGiven that air-quality monitoring stations are typically ground-based their\nabilities to detect pollutant distributions are often restricted to wide areas.\nSatellites however have the potential for studying the atmosphere at large; the\nEuropean Space Agency (ESA) Copernicus project satellite, \"Sentinel-5P\" is a\nnewly launched satellite capable of measuring a variety of pollutant\ninformation with publicly available data outputs. This paper seeks to create a\nmulti-modal machine learning model for predicting air-quality metrics where\nmonitoring stations do not exist. The inputs of this model will include a\nfusion of ground measurements and satellite data with the goal of highlighting\npollutant distribution and motivating change in societal and industrial\nbehaviors. A new dataset of European pollution monitoring station measurements\nis created with features including $\\textit{altitude, population, etc.}$ from\nthe ESA Copernicus project. This dataset is used to train a multi-modal ML\nmodel, Air Quality Network (AQNet) capable of fusing these various types of\ndata sources to output predictions of various pollutants. These predictions are\nthen aggregated to create an \"air-quality index\" that could be used to compare\nair quality over different regions. Three pollutants, NO$_2$, O$_3$, and\nPM$_{10}$, are predicted successfully by AQNet and the network was found to be\nuseful compared to a model only using satellite imagery. It was also found that\nthe addition of supporting data improves predictions. When testing the\ndeveloped AQNet on out-of-sample data of the UK and Ireland, we obtain\nsatisfactory estimates though on average pollution metrics were roughly\noverestimated by around 20\\%.",
    "descriptor": "\nComments: 14 pages, 9 figures, 4 tables\n",
    "authors": [
      "Andrew Rowley",
      "Oktay Karaku\u015f"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.00780"
  },
  {
    "id": "arXiv:2211.00781",
    "title": "Counting and Computing Join-Endomorphisms in Lattices (Revisited)",
    "abstract": "Structures involving a lattice and join-endomorphisms on it are ubiquitous in\ncomputer science. We study the cardinality of the set $\\mathcal{E}(L)$ of all\njoin-endomorphisms of a given finite lattice $L$. In particular, we show for\n$\\mathbf{M}_n$, the discrete order of $n$ elements extended with top and\nbottom, $| \\mathcal{E}(\\mathbf{M}_n) | =n!\\mathcal{L}_n(-1)+(n+1)^2$ where\n$\\mathcal{L}_n(x)$ is the Laguerre polynomial of degree $n$. We also study the\nfollowing problem: Given a lattice $L$ of size $n$ and a set $S\\subseteq\n\\mathcal{E}(L)$ of size $m$, find the greatest lower bound\n${\\large\\sqcap}_{\\mathcal{E}(L)} S$. The join-endomorphism\n${\\large\\sqcap}_{\\mathcal{E}(L)} S$ has meaningful interpretations in epistemic\nlogic, distributed systems, and Aumann structures. We show that this problem\ncan be solved with worst-case time complexity in $O(mn)$ for distributive\nlattices and $O(mn + n^3)$ for arbitrary lattices. In the particular case of\nmodular lattices, we present an adaptation of the latter algorithm that reduces\nits average time complexity. We provide theoretical and experimental results to\nsupport this enhancement. The complexity is expressed in terms of the basic\nbinary lattice operations performed by the algorithm.",
    "descriptor": "",
    "authors": [
      "Carlos Pinz\u00f3n",
      "Santiago Quintero",
      "Sergio Ram\u00edrez",
      "Camilo Rueda",
      "Frank Valencia"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2211.00781"
  },
  {
    "id": "arXiv:2211.00783",
    "title": "Impact Of Missing Data Imputation On The Fairness And Accuracy Of Graph  Node Classifiers",
    "abstract": "Analysis of the fairness of machine learning (ML) algorithms recently\nattracted many researchers' interest. Most ML methods show bias toward\nprotected groups, which limits the applicability of ML models in many\napplications like crime rate prediction etc. Since the data may have missing\nvalues which, if not appropriately handled, are known to further harmfully\naffect fairness. Many imputation methods are proposed to deal with missing\ndata. However, the effect of missing data imputation on fairness is not studied\nwell. In this paper, we analyze the effect on fairness in the context of graph\ndata (node attributes) imputation using different embedding and neural network\nmethods. Extensive experiments on six datasets demonstrate severe fairness\nissues in missing data imputation under graph node classification. We also find\nthat the choice of the imputation method affects both fairness and accuracy.\nOur results provide valuable insights into graph data fairness and how to\nhandle missingness in graphs efficiently. This work also provides directions\nregarding theoretical studies on fairness in graph data.",
    "descriptor": "\nComments: Accepted at IEEE International Conference on Big Data (IEEE Big Data)\n",
    "authors": [
      "Haris Mansoor",
      "Sarwan Ali",
      "Shafiq Alam",
      "Muhammad Asad Khan",
      "Umair ul Hassan",
      "Imdadullah Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00783"
  },
  {
    "id": "arXiv:2211.00786",
    "title": "Unified End-to-End Speech Recognition and Endpointing for Fast and  Efficient Speech Systems",
    "abstract": "Automatic speech recognition (ASR) systems typically rely on an external\nendpointer (EP) model to identify speech boundaries. In this work, we propose a\nmethod to jointly train the ASR and EP tasks in a single end-to-end (E2E)\nmultitask model, improving EP quality by optionally leveraging information from\nthe ASR audio encoder. We introduce a \"switch\" connection, which trains the EP\nto consume either the audio frames directly or low-level latent representations\nfrom the ASR model. This results in a single E2E model that can be used during\ninference to perform frame filtering at low cost, and also make high quality\nend-of-query (EOQ) predictions based on ongoing ASR computation. We present\nresults on a voice search test set showing that, compared to separate\nsingle-task models, this approach reduces median endpoint latency by 120 ms\n(30.8% reduction), and 90th percentile latency by 170 ms (23.0% reduction),\nwithout regressing word error rate. For continuous recognition, WER improves by\n10.6% (relative).",
    "descriptor": "\nComments: To be published in Spoken Language Technology Workshop (SLT) 2022\n",
    "authors": [
      "Shaan Bijwadia",
      "Shuo-yiin Chang",
      "Bo Li",
      "Tara Sainath",
      "Chao Zhang",
      "Yanzhang He"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00786"
  },
  {
    "id": "arXiv:2211.00789",
    "title": "Beyond Not-Forgetting: Continual Learning with Backward Knowledge  Transfer",
    "abstract": "By learning a sequence of tasks continually, an agent in continual learning\n(CL) can improve the learning performance of both a new task and `old' tasks by\nleveraging the forward knowledge transfer and the backward knowledge transfer,\nrespectively. However, most existing CL methods focus on addressing\ncatastrophic forgetting in neural networks by minimizing the modification of\nthe learnt model for old tasks. This inevitably limits the backward knowledge\ntransfer from the new task to the old tasks, because judicious model updates\ncould possibly improve the learning performance of the old tasks as well. To\ntackle this problem, we first theoretically analyze the conditions under which\nupdating the learnt model of old tasks could be beneficial for CL and also lead\nto backward knowledge transfer, based on the gradient projection onto the input\nsubspaces of old tasks. Building on the theoretical analysis, we next develop a\nContinUal learning method with Backward knowlEdge tRansfer (CUBER), for a fixed\ncapacity neural network without data replay. In particular, CUBER first\ncharacterizes the task correlation to identify the positively correlated old\ntasks in a layer-wise manner, and then selectively modifies the learnt model of\nthe old tasks when learning the new task. Experimental studies show that CUBER\ncan even achieve positive backward knowledge transfer on several existing CL\nbenchmarks for the first time without data replay, where the related baselines\nstill suffer from catastrophic forgetting (negative backward knowledge\ntransfer). The superior performance of CUBER on the backward knowledge transfer\nalso leads to higher accuracy accordingly.",
    "descriptor": "\nComments: Published as a conference paper at NeurIPS 2022\n",
    "authors": [
      "Sen Lin",
      "Li Yang",
      "Deliang Fan",
      "Junshan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00789"
  },
  {
    "id": "arXiv:2211.00794",
    "title": "Impact of annotation modality on label quality and model performance in  the automatic assessment of laughter in-the-wild",
    "abstract": "Laughter is considered one of the most overt signals of joy. Laughter is\nwell-recognized as a multimodal phenomenon but is most commonly detected by\nsensing the sound of laughter. It is unclear how perception and annotation of\nlaughter differ when annotated from other modalities like video, via the body\nmovements of laughter. In this paper we take a first step in this direction by\nasking if and how well laughter can be annotated when only audio, only video\n(containing full body movement information) or audiovisual modalities are\navailable to annotators. We ask whether annotations of laughter are congruent\nacross modalities, and compare the effect that labeling modality has on machine\nlearning model performance. We compare annotations and models for laughter\ndetection, intensity estimation, and segmentation, three tasks common in\nprevious studies of laughter. Our analysis of more than 4000 annotations\nacquired from 48 annotators revealed evidence for incongruity in the perception\nof laughter, and its intensity between modalities. Further analysis of\nannotations against consolidated audiovisual reference annotations revealed\nthat recall was lower on average for video when compared to the audio\ncondition, but tended to increase with the intensity of the laughter samples.\nOur machine learning experiments compared the performance of state-of-the-art\nunimodal (audio-based, video-based and acceleration-based) and multi-modal\nmodels for different combinations of input modalities, training label modality,\nand testing label modality. Models with video and acceleration inputs had\nsimilar performance regardless of training label modality, suggesting that it\nmay be entirely appropriate to train models for laughter detection from body\nmovements using video-acquired labels, despite their lower inter-rater\nagreement.",
    "descriptor": "",
    "authors": [
      "Jose Vargas-Quiros",
      "Laura Cabrera-Quiros",
      "Catharine Oertel",
      "Hayley Hung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00794"
  },
  {
    "id": "arXiv:2211.00797",
    "title": "Node repair on connected graphs, Part II",
    "abstract": "We continue our study of regenerating codes in distributed storage systems\nwhere connections between the nodes are constrained by a graph. In this\nproblem, the failed node downloads the information stored at a subset of\nvertices of the graph for the purpose of recovering the lost data. This\ninformation is moved across the network, and the cost of node repair is\ndetermined by the graphical distance from the helper nodes to the failed node.\nThis problem was formulated in our recent work (IEEE IT Transactions, May 2022)\nwhere we showed that processing of the information at the intermediate nodes\ncan yield savings in repair bandwidth over the direct forwarding of the data.\nWhile the previous paper was limited to the MSR case, here we extend our\nstudy to the case of general regenerating codes. We derive a lower bound on the\nrepair bandwidth and formulate repair procedures with intermediate processing\nfor several families of regenerating codes, with an emphasis on the recent\nconstructions from multilinear algebra. We also consider the task of data\nretrieval for codes on graphs, deriving a lower bound on the communication\nbandwidth and showing that it can be attained at the MBR point of the\nstorage-bandwidth tradeoff curve.",
    "descriptor": "",
    "authors": [
      "Adway Patra",
      "Alexander Barg"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.00797"
  },
  {
    "id": "arXiv:2211.00799",
    "title": "Practical Phase Retrieval Using Double Deep Image Priors",
    "abstract": "Phase retrieval (PR) concerns the recovery of complex phases from complex\nmagnitudes. We identify the connection between the difficulty level and the\nnumber and variety of symmetries in PR problems. We focus on the most difficult\nfar-field PR (FFPR), and propose a novel method using double deep image priors.\nIn realistic evaluation, our method outperforms all competing methods by large\nmargins. As a single-instance method, our method requires no training data and\nminimal hyperparameter tuning, and hence enjoys good practicality.",
    "descriptor": "",
    "authors": [
      "Zhong Zhuang",
      "David Yang",
      "Felix Hofmann",
      "David Barmherzig",
      "Ju Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.00799"
  },
  {
    "id": "arXiv:2211.00801",
    "title": "Multi-Agent Reinforcement Learning for Adaptive Mesh Refinement",
    "abstract": "Adaptive mesh refinement (AMR) is necessary for efficient finite element\nsimulations of complex physical phenomenon, as it allocates limited\ncomputational budget based on the need for higher or lower resolution, which\nvaries over space and time. We present a novel formulation of AMR as a\nfully-cooperative Markov game, in which each element is an independent agent\nwho makes refinement and de-refinement choices based on local information. We\ndesign a novel deep multi-agent reinforcement learning (MARL) algorithm called\nValue Decomposition Graph Network (VDGN), which solves the two core challenges\nthat AMR poses for MARL: posthumous credit assignment due to agent creation and\ndeletion, and unstructured observations due to the diversity of mesh\ngeometries. For the first time, we show that MARL enables anticipatory\nrefinement of regions that will encounter complex features at future times,\nthereby unlocking entirely new regions of the error-cost objective landscape\nthat are inaccessible by traditional methods based on local error estimators.\nComprehensive experiments show that VDGN policies significantly outperform\nerror threshold-based policies in global error and cost metrics. We show that\nlearned policies generalize to test problems with physical features, mesh\ngeometries, and longer simulation times that were not seen in training. We also\nextend VDGN with multi-objective optimization capabilities to find the Pareto\nfront of the tradeoff between cost and error.",
    "descriptor": "\nComments: 24 pages, 18 figures\n",
    "authors": [
      "Jiachen Yang",
      "Ketan Mittal",
      "Tarik Dzanic",
      "Socratis Petrides",
      "Brendan Keith",
      "Brenden Petersen",
      "Daniel Faissol",
      "Robert Anderson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00801"
  },
  {
    "id": "arXiv:2211.00802",
    "title": "Concrete Score Matching: Generalized Score Matching for Discrete Data",
    "abstract": "Representing probability distributions by the gradient of their density\nfunctions has proven effective in modeling a wide range of continuous data\nmodalities. However, this representation is not applicable in discrete domains\nwhere the gradient is undefined. To this end, we propose an analogous score\nfunction called the \"Concrete score\", a generalization of the (Stein) score for\ndiscrete settings. Given a predefined neighborhood structure, the Concrete\nscore of any input is defined by the rate of change of the probabilities with\nrespect to local directional changes of the input. This formulation allows us\nto recover the (Stein) score in continuous domains when measuring such changes\nby the Euclidean distance, while using the Manhattan distance leads to our\nnovel score function in discrete domains. Finally, we introduce a new framework\nto learn such scores from samples called Concrete Score Matching (CSM), and\npropose an efficient training objective to scale our approach to high\ndimensions. Empirically, we demonstrate the efficacy of CSM on density\nestimation tasks on a mixture of synthetic, tabular, and high-dimensional image\ndatasets, and demonstrate that it performs favorably relative to existing\nbaselines for modeling discrete data.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Chenlin Meng",
      "Kristy Choi",
      "Jiaming Song",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00802"
  },
  {
    "id": "arXiv:2211.00804",
    "title": "Analysis and object oriented implementation of the Kovacic algorithm",
    "abstract": "This paper gives a detailed overview and a number of worked out examples\nillustrating the Kovacic \\cite{Kovacic86} algorithm for solving second order\nlinear differential equation ${A(x) y\"+ B(x) y' + C(x) y=0}$ where $A,B,C$ are\nrational functions with complex coefficients in the independent variable $x$.\nAll three cases of the algorithm were implemented in a software package based\non an object oriented design and complete source code listing given in the\nappendix with usage examples. Implementation used the Maple computer algebra\nlanguage. The complete Kovacic package in one mpl file accompany the arXiv\nversion of this paper. This package was then used to analyze the distribution\nof Kovacic algorithm cases on $3000$ differential equations",
    "descriptor": "\nComments: 74 pages, 5 figures. Software package\n",
    "authors": [
      "Nasser M. Abbasi"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2211.00804"
  },
  {
    "id": "arXiv:2211.00805",
    "title": "Geodesic Sinkhorn: optimal transport for high-dimensional datasets",
    "abstract": "Understanding the dynamics and reactions of cells from population snapshots\nis a major challenge in single-cell transcriptomics. Here, we present Geodesic\nSinkhorn, a method for interpolating populations along a data manifold that\nleverages existing kernels developed for single-cell dimensionality reduction\nand visualization methods. Our Geodesic Sinkhorn method uses a heat-geodesic\nground distance that, as compared to Euclidean ground distances, is more\naccurate for interpolating single-cell dynamics on a wide variety of datasets\nand significantly speeds up the computation for sparse kernels. We first apply\nGeodesic Sinkhorn to 10 single-cell transcriptomics time series interpolation\ndatasets as a drop-in replacement for existing interpolation methods where it\noutperforms on all datasets, showing its effectiveness in modeling cell\ndynamics. Second, we show how to efficiently approximate the operator with\npolynomial kernels allowing us to improve scaling to large datasets. Finally,\nwe define the conditional Wasserstein-average treatment effect and show how it\ncan elucidate the treatment effect on single-cell populations on a drug screen.",
    "descriptor": "\nComments: 15 pages, 5 tables, 5 figures, submitted to RECOMB 2023\n",
    "authors": [
      "Guillaume Huguet",
      "Alexander Tong",
      "Mar\u00eda Ramos Zapatero",
      "Guy Wolf",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.00805"
  },
  {
    "id": "arXiv:2211.00806",
    "title": "Optical Channel Impulse Response-Based Localization Using An Artificial  Neural Network",
    "abstract": "Visible light positioning has the potential to yield sub-centimeter accuracy\nin indoor environments, yet conventional received signal strength (RSS)-based\nlocalization algorithms cannot achieve this because their performance degrades\nfrom optical multipath reflection. However, this part of the optical received\nsignal is deterministic due to the often static and predictable nature of the\noptical wireless channel. In this paper, the performance of optical channel\nimpulse response (OCIR)-based localization is studied using an artificial\nneural network (ANN) to map embedded features of the OCIR to the user\nequipment's location. Numerical results show that OCIR-based localization\noutperforms conventional RSS techniques by two orders of magnitude using only\ntwo photodetectors as anchor points. The ANN technique can take advantage of\nmultipath features in a wide range of scenarios, from using only the DC value\nto relying on high-resolution time sampling that can result in sub-centimeter\naccuracy.",
    "descriptor": "",
    "authors": [
      "Hamid Hosseinianfar",
      "Hami Rabbani",
      "Maite Bradnt-Pearce"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.00806"
  },
  {
    "id": "arXiv:2211.00807",
    "title": "Unsupervised Model Adaptation for Source-free Segmentation of Medical  Images",
    "abstract": "The recent prevalence of deep neural networks has lead semantic segmentation\nnetworks to achieve human-level performance in the medical field when\nsufficient training data is provided. Such networks however fail to generalize\nwhen tasked with predicting semantic maps for out-of-distribution images,\nrequiring model re-training on the new distributions. This expensive process\nnecessitates expert knowledge in order to generate training labels.\nDistribution shifts can arise naturally in the medical field via the choice of\nimaging device, i.e. MRI or CT scanners. To combat the need for labeling images\nin a target domain after a model is successfully trained in a fully annotated\n\\textit{source domain} with a different data distribution, unsupervised domain\nadaptation (UDA) can be used. Most UDA approaches ensure target generalization\nby creating a shared source/target latent feature space. This allows a source\ntrained classifier to maintain performance on the target domain. However most\nUDA approaches require joint source and target data access, which may create\nprivacy leaks with respect to patient information. We propose an UDA algorithm\nfor medical image segmentation that does not require access to source data\nduring adaptation, and is thus capable in maintaining patient data privacy. We\nrely on an approximation of the source latent features at adaptation time, and\ncreate a joint source/target embedding space by minimizing a distributional\ndistance metric based on optimal transport. We demonstrate our approach is\ncompetitive to recent UDA medical segmentation works even with the added\nprivacy requisite.",
    "descriptor": "",
    "authors": [
      "Serban Stan",
      "Mohammad Rostami"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00807"
  },
  {
    "id": "arXiv:2211.00815",
    "title": "Build a SRE Challenge System: Lessons from VoxSRC 2022 and CNSRC 2022",
    "abstract": "Different speaker recognition challenges have been held to assess the speaker\nverification system in the wild and probe the performance limit. Voxceleb\nSpeaker Recognition Challenge (VoxSRC), based on the voxceleb, is the most\npopular. Besides, another challenge called CN-Celeb Speaker Recognition\nChallenge (CNSRC) is also held this year, which is based on the Chinese\ncelebrity multi-genre dataset CN-Celeb. This year, our team participated in\nboth speaker verification closed tracks in CNSRC 2022 and VoxSRC 2022, and\nachieved the 1st place and 3rd place respectively. In most system reports, the\nauthors usually only provide a description of their systems but lack an\neffective analysis of their methods. In this paper, we will outline how to\nbuild a strong speaker verification challenge system and give a detailed\nanalysis of each method compared with some other popular technical means.",
    "descriptor": "",
    "authors": [
      "Zhengyang Chen",
      "Bing Han",
      "Xu Xiang",
      "Houjun Huang",
      "Bei Liu",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00815"
  },
  {
    "id": "arXiv:2211.00817",
    "title": "An Information-Theoretic Approach for Estimating Scenario Generalization  in Crowd Motion Prediction",
    "abstract": "Learning-based approaches to modeling crowd motion have become increasingly\nsuccessful but require training and evaluation on large datasets, coupled with\ncomplex model selection and parameter tuning. To circumvent this tremendously\ntime-consuming process, we propose a novel scoring method, which characterizes\ngeneralization of models trained on source crowd scenarios and applied to\ntarget crowd scenarios using a training-free, model-agnostic Interaction +\nDiversity Quantification score, ISDQ. The Interaction component aims to\ncharacterize the difficulty of scenario domains, while the diversity of a\nscenario domain is captured in the Diversity score. Both scores can be computed\nin a computation tractable manner. Our experimental results validate the\nefficacy of the proposed method on several simulated and real-world\n(source,target) generalization tasks, demonstrating its potential to select\noptimal domain pairs before training and testing a model.",
    "descriptor": "",
    "authors": [
      "Gang Qiao",
      "Kaidong Hu",
      "Seonghyeon Moon",
      "Samuel S. Sohn",
      "Sejong Yoon",
      "Mubbasir Kapadia",
      "Vladimir Pavlovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.00817"
  },
  {
    "id": "arXiv:2211.00818",
    "title": "CODEP: Grammatical Seq2Seq Model for General-Purpose Code Generation",
    "abstract": "General-purpose code generation aims to automatically convert the natural\nlanguage (NL) description to code snippets in a general-purpose programming\nlanguage (GPL) like Python. Intrinsically, code generation is a special type of\ntext generation that generates well-formed text, i.e., code. However, existing\nsequence-to-sequence (Seq2Seq) approaches generate the GPL code neglecting the\ngrammar rules. To this end, in this paper, we make the first attempt to\nconsider grammatical Seq2Seq models for general-purpose code generation and\npropose CODEP, a grammatical Seq2Seq code generation framework equipped with a\nPushdown automaton (PDA) module. In the training stage, CODEP additionally\nincorporates the state representation and the state prediction task, which\nleverages PDA states to help CODEP comprehend the parsing process of the PDA\nmodule. In the inference stage, CODEP generates well-formed code with the PDA\nmodule and the joint prediction of PDA states. Furthermore, the PDA module can\nbe directly applied to Seq2Seq models without training to ensure the\ngrammatical correctness of the generated code. To evaluate the effectiveness of\nour proposed method, we construct the DPA for the most popular GPL Python and\nconduct extensive experiments on four benchmark datasets. The experimental\nresults demonstrate the superiority of CODEP compared to the state-of-the-art\napproaches without pre-training, and the DPA module also achieves significant\nimprovements on the pre-trained models.",
    "descriptor": "",
    "authors": [
      "Yihong Dong",
      "Ge Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00818"
  },
  {
    "id": "arXiv:2211.00819",
    "title": "Interpretable estimation of the risk of heart failure hospitalization  from a 30-second electrocardiogram",
    "abstract": "Survival modeling in healthcare relies on explainable statistical models;\nyet, their underlying assumptions are often simplistic and, thus, unrealistic.\nMachine learning models can estimate more complex relationships and lead to\nmore accurate predictions, but are non-interpretable. This study shows it is\npossible to estimate hospitalization for congestive heart failure by a 30\nseconds single-lead electrocardiogram signal. Using a machine learning approach\nnot only results in greater predictive power but also provides clinically\nmeaningful interpretations. We train an eXtreme Gradient Boosting accelerated\nfailure time model and exploit SHapley Additive exPlanations values to explain\nthe effect of each feature on predictions. Our model achieved a concordance\nindex of 0.828 and an area under the curve of 0.853 at one year and 0.858 at\ntwo years on a held-out test set of 6,573 patients. These results show that a\nrapid test based on an electrocardiogram could be crucial in targeting and\ntreating high-risk individuals.",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Sergio Gonz\u00e1lez",
      "Wan-Ting Hsieh",
      "Davide Burba",
      "Trista Pei-Chun Chen",
      "Chun-Li Wang",
      "Victor Chien-Chia Wu",
      "Shang-Hung Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.00819"
  },
  {
    "id": "arXiv:2211.00824",
    "title": "Adversarial Auto-Augment with Label Preservation: A Representation  Learning Principle Guided Approach",
    "abstract": "Data augmentation is a critical contributing factor to the success of deep\nlearning but heavily relies on prior domain knowledge which is not always\navailable. Recent works on automatic data augmentation learn a policy to form a\nsequence of augmentation operations, which are still pre-defined and restricted\nto limited options. In this paper, we show that a prior-free autonomous data\naugmentation's objective can be derived from a representation learning\nprinciple that aims to preserve the minimum sufficient information of the\nlabels. Given an example, the objective aims at creating a distant \"hard\npositive example\" as the augmentation, while still preserving the original\nlabel. We then propose a practical surrogate to the objective that can be\noptimized efficiently and integrated seamlessly into existing methods for a\nbroad class of machine learning tasks, e.g., supervised, semi-supervised, and\nnoisy-label learning. Unlike previous works, our method does not require\ntraining an extra generative model but instead leverages the intermediate layer\nrepresentations of the end-task model for generating data augmentations. In\nexperiments, we show that our method consistently brings non-trivial\nimprovements to the three aforementioned learning tasks from both efficiency\nand final performance, either or not combined with strong pre-defined\naugmentations, e.g., on medical images when domain knowledge is unavailable and\nthe existing augmentation techniques perform poorly. Code is available at:\nhttps://github.com/kai-wen-yang/LPA3}{https://github.com/kai-wen-yang/LPA3.",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Kaiwen Yang",
      "Yanchao Sun",
      "Jiahao Su",
      "Fengxiang He",
      "Xinmei Tian",
      "Furong Huang",
      "Tianyi Zhou",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00824"
  },
  {
    "id": "arXiv:2211.00826",
    "title": "TSAA: A Two-Stage Anchor Assignment Method towards Anchor Drift in  Crowded Object Detection",
    "abstract": "Among current anchor-based detectors, a positive anchor box will be\nintuitively assigned to the object that overlaps it the most. The assigned\nlabel to each anchor will directly determine the optimization direction of the\ncorresponding prediction box, including the direction of box regression and\ncategory prediction. In our practice of crowded object detection, however, the\nresults show that a positive anchor does not always regress toward the object\nthat overlaps it the most when multiple objects overlap. We name it anchor\ndrift. The anchor drift reflects that the anchor-object matching relation,\nwhich is determined by the degree of overlap between anchors and objects, is\nnot always optimal. Conflicts between the fixed matching relation and learned\nexperience in the past training process may cause ambiguous predictions and\nthus raise the false-positive rate. In this paper, a simple but efficient\nadaptive two-stage anchor assignment (TSAA) method is proposed. It utilizes the\nfinal prediction boxes rather than the fixed anchors to calculate the overlap\ndegree with objects to determine which object to regress for each anchor. The\nparticipation of the prediction box makes the anchor-object assignment\nmechanism adaptive. Extensive experiments are conducted on three classic\ndetectors RetinaNet, Faster-RCNN and YOLOv3 on CrowdHuman and COCO to evaluate\nthe effectiveness of TSAA. The results show that TSAA can significantly improve\nthe detectors' performance without additional computational costs or network\nstructure changes.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Li Xiang",
      "He Miao",
      "Luo Haibo",
      "Yang Huiyuan",
      "Xiao Jiajie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00826"
  },
  {
    "id": "arXiv:2211.00828",
    "title": "Synthesizing Programs with Continuous Optimization",
    "abstract": "Automatic software generation based on some specification is known as program\nsynthesis. Most existing approaches formulate program synthesis as a search\nproblem with discrete parameters. In this paper, we present a novel formulation\nof program synthesis as a continuous optimization problem and use a\nstate-of-the-art evolutionary approach, known as Covariance Matrix Adaptation\nEvolution Strategy to solve the problem. We then propose a mapping scheme to\nconvert the continuous formulation into actual programs. We compare our system,\ncalled GENESYS, with several recent program synthesis techniques (in both\ndiscrete and continuous domains) and show that GENESYS synthesizes more\nprograms within a fixed time budget than those existing schemes. For example,\nfor programs of length 10, GENESYS synthesizes 28% more programs than those\nexisting schemes within the same time budget.",
    "descriptor": "",
    "authors": [
      "Shantanu Mandal",
      "Todd A. Anderson",
      "Javier Turek",
      "Justin Gottschlich",
      "Abdullah Muzahid"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.00828"
  },
  {
    "id": "arXiv:2211.00829",
    "title": "Exploiting Spatial-temporal Correlations for Video Anomaly Detection",
    "abstract": "Video anomaly detection (VAD) remains a challenging task in the pattern\nrecognition community due to the ambiguity and diversity of abnormal events.\nExisting deep learning-based VAD methods usually leverage proxy tasks to learn\nthe normal patterns and discriminate the instances that deviate from such\npatterns as abnormal. However, most of them do not take full advantage of\nspatial-temporal correlations among video frames, which is critical for\nunderstanding normal patterns. In this paper, we address unsupervised VAD by\nlearning the evolution regularity of appearance and motion in the long and\nshort-term and exploit the spatial-temporal correlations among consecutive\nframes in normal videos more adequately. Specifically, we proposed to utilize\nthe spatiotemporal long short-term memory (ST-LSTM) to extract and memorize\nspatial appearances and temporal variations in a unified memory cell. In\naddition, inspired by the generative adversarial network, we introduce a\ndiscriminator to perform adversarial learning with the ST-LSTM to enhance the\nlearning capability. Experimental results on standard benchmarks demonstrate\nthe effectiveness of spatial-temporal correlations for unsupervised VAD. Our\nmethod achieves competitive performance compared to the state-of-the-art\nmethods with AUCs of 96.7%, 87.8%, and 73.1% on the UCSD Ped2, CUHK Avenue, and\nShanghaiTech, respectively.",
    "descriptor": "\nComments: This paper is accepted at IEEE 26TH International Conference on Pattern Recognition (ICPR) 2022\n",
    "authors": [
      "Mengyang Zhao",
      "Yang Liu",
      "Jing Li",
      "Xinhua Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00829"
  },
  {
    "id": "arXiv:2211.00830",
    "title": "Internet Of Rights(IOR) In Role Based Block Chain",
    "abstract": "A large amount of data has been accumulated. with the development of the\nInternet industry. Many problems have been exposed with data explosion: 1. The\ncontradiction between data privacy and data collaborations; 2. The\ncontradiction between data ownership and the right of data usage; 3. The\nlegality of data collection and data usage; 4. The relationship between the\ngovernance of data and the governance of rules; 5. Traceability of evidence\nchain. In order to face such a complicated situation, many algorithms were\nproposed and developed. This article tries to build a model from the\nperspective of blockchain to make some breakthroughs.Internet Of Rights(IOR)\nmodel uses multi-chain technology to logically break down the consensus\nmechanism into layers, including storage consensus, permission consensus, role\nconsensus, transaction consensus etc. thus to build a new infrastructure, which\nenables data sources with complex organizational structures and interactions to\ncollaborate smoothly on the premise of protecting data privacy. With\nblockchain's nature of decentralization, openness, autonomy, immutability, and\ncontrollable anonymity, Internet Of Rights(IOR) model registers the ownership\nof data, enables applications to build ecosystem based on responsibilities and\nrights. It also provides cross-domain processing with privacy protection, as\nwell as the separation of data governance and rule governance. With the\nprocessing capabilities of artificial intelligence and big data technology, as\nwell as the ubiquitous data collection capabilities of the Internet of Things,\nInternet Of Rights(IOR) model may provide a new infrastructure concept for\nrealizing swarm intelligence and building a new paradigm of the Internet, i.e.\nintelligent governance.",
    "descriptor": "",
    "authors": [
      "Yunling Shi",
      "Jie Guan",
      "Junfeng Xiao",
      "Huai Zhang",
      "Qiang Guo",
      "Yu Yuan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.00830"
  },
  {
    "id": "arXiv:2211.00832",
    "title": "Distributed Massive MIMO for LEO Satellite Networks",
    "abstract": "The ultra-dense deployment of interconnected satellites will characterize\nfuture low Earth orbit (LEO) mega-constellations. Exploiting this towards a\nmore efficient satellite network (SatNet), this paper proposes a novel LEO\nSatNet architecture based on distributed massive multiple-input multiple-output\n(DM-MIMO) technology allowing ground user terminals to be connected to a\ncluster of satellites. To this end, we investigate various aspects of\nDM-MIMO-based satellite network design, the benefits of using this\narchitecture, the associated challenges, and the potential solutions. In\naddition, we propose a distributed joint power allocation and handover\nmanagement (D-JPAHM) technique that jointly optimizes the power allocation and\nhandover management processes in a cross-layer manner. This framework aims to\nmaximize the network throughput and minimize the handover rate while\nconsidering the quality-of-service (QoS) demands of user terminals and the\npower capabilities of the satellites. Moreover, we devise an artificial\nintelligence (AI)-based solution to efficiently implement the proposed D-JPAHM\nframework in a manner suitable for real-time operation and the dynamic SatNet\nenvironment. To the best of our knowledge, this is the first work to introduce\nand study DM-MIMO technology in LEO SatNets. Extensive simulation results\nreveal the superiority of the proposed architecture and solutions compared to\nconventional approaches in the literature.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.09837\n",
    "authors": [
      "Mohammed Y. Abdelsadek",
      "Gunes Karabulut Kurt",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00832"
  },
  {
    "id": "arXiv:2211.00833",
    "title": "Learning a Condensed Frame for Memory-Efficient Video Class-Incremental  Learning",
    "abstract": "Recent incremental learning for action recognition usually stores\nrepresentative videos to mitigate catastrophic forgetting. However, only a few\nbulky videos can be stored due to the limited memory. To address this problem,\nwe propose FrameMaker, a memory-efficient video class-incremental learning\napproach that learns to produce a condensed frame for each selected video.\nSpecifically, FrameMaker is mainly composed of two crucial components: Frame\nCondensing and Instance-Specific Prompt. The former is to reduce the memory\ncost by preserving only one condensed frame instead of the whole video, while\nthe latter aims to compensate the lost spatio-temporal details in the Frame\nCondensing stage. By this means, FrameMaker enables a remarkable reduction in\nmemory but keep enough information that can be applied to following incremental\ntasks. Experimental results on multiple challenging benchmarks, i.e., HMDB51,\nUCF101 and Something-Something V2, demonstrate that FrameMaker can achieve\nbetter performance to recent advanced methods while consuming only 20% memory.\nAdditionally, under the same memory consumption conditions, FrameMaker\nsignificantly outperforms existing state-of-the-arts by a convincing margin.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Yixuan Pei",
      "Zhiwu Qing",
      "Jun Cen",
      "Xiang Wang",
      "Shiwei Zhang",
      "Yaxiong Wang",
      "Mingqian Tang",
      "Nong Sang",
      "Xueming Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00833"
  },
  {
    "id": "arXiv:2211.00837",
    "title": "Unsupervised Deraining: Where Asymmetric Contrastive Learning Meets  Self-similarity",
    "abstract": "Most of the existing learning-based deraining methods are supervisedly\ntrained on synthetic rainy-clean pairs. The domain gap between the synthetic\nand real rain makes them less generalized to complex real rainy scenes.\nMoreover, the existing methods mainly utilize the property of the image or rain\nlayers independently, while few of them have considered their mutually\nexclusive relationship. To solve above dilemma, we explore the intrinsic\nintra-similarity within each layer and inter-exclusiveness between two layers\nand propose an unsupervised non-local contrastive learning (NLCL) deraining\nmethod. The non-local self-similarity image patches as the positives are\ntightly pulled together, rain patches as the negatives are remarkably pushed\naway, and vice versa. On one hand, the intrinsic self-similarity knowledge\nwithin positive/negative samples of each layer benefits us to discover more\ncompact representation; on the other hand, the mutually exclusive property\nbetween the two layers enriches the discriminative decomposition. Thus, the\ninternal self-similarity within each layer (similarity) and the external\nexclusive relationship of the two layers (dissimilarity) serving as a generic\nimage prior jointly facilitate us to unsupervisedly differentiate the rain from\nclean image. We further discover that the intrinsic dimension of the non-local\nimage patches is generally higher than that of the rain patches. This motivates\nus to design an asymmetric contrastive loss to precisely model the compactness\ndiscrepancy of the two layers for better discriminative decomposition. In\naddition, considering that the existing real rain datasets are of low quality,\neither small scale or downloaded from the internet, we collect a real\nlarge-scale dataset under various rainy kinds of weather that contains\nhigh-resolution rainy images.",
    "descriptor": "\nComments: 16 pages, 15 figures. arXiv admin note: substantial text overlap with arXiv:2203.11509\n",
    "authors": [
      "Yi Chang",
      "Yun Guo",
      "Yuntong Ye",
      "Changfeng Yu",
      "Lin Zhu",
      "Xile Zhao",
      "Luxin Yan",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00837"
  },
  {
    "id": "arXiv:2211.00838",
    "title": "Distributed Work Stealing in a Task-Based Dataflow Runtime",
    "abstract": "The task-based dataflow programming model has emerged as an alternative to\nthe process-centric programming model for extreme-scale applications. However,\nload balancing is still a challenge in task-based dataflow runtimes. In this\npaper, we present extensions to the PaR-SEC runtime to demonstrate that\ndistributed work stealing is an effective load-balancing method for task-based\ndataflow runtimes. In contrast to shared-memory work stealing, we find that\neach process should consider future tasks and the expected waiting time for\nexecution when determining whether to steal. We demonstrate the effectiveness\nof the proposed work-stealing policies for a sparse Cholesky factorization,\nwhich shows a speedup of up to 35% compared to a static division of work.",
    "descriptor": "",
    "authors": [
      "Joseph John",
      "Josh Milthorpe",
      "Peter Strazdins"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00838"
  },
  {
    "id": "arXiv:2211.00839",
    "title": "RCD-SGD: Resource-Constrained Distributed SGD in Heterogeneous  Environment via Submodular Partitioning",
    "abstract": "The convergence of SGD based distributed training algorithms is tied to the\ndata distribution across workers. Standard partitioning techniques try to\nachieve equal-sized partitions with per-class population distribution in\nproportion to the total dataset. Partitions having the same overall population\nsize or even the same number of samples per class may still have Non-IID\ndistribution in the feature space. In heterogeneous computing environments,\nwhen devices have different computing capabilities, even-sized partitions\nacross devices can lead to the straggler problem in distributed SGD. We develop\na framework for distributed SGD in heterogeneous environments based on a novel\ndata partitioning algorithm involving submodular optimization. Our data\npartitioning algorithm explicitly accounts for resource heterogeneity across\nworkers while achieving similar class-level feature distribution and\nmaintaining class balance. Based on this algorithm, we develop a distributed\nSGD framework that can accelerate existing SOTA distributed training algorithms\nby up to 32%.",
    "descriptor": "\nComments: 6 pages and 3 figures\n",
    "authors": [
      "Haoze He",
      "Parijat Dube"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00839"
  },
  {
    "id": "arXiv:2211.00848",
    "title": "Heterogeneous Trajectory Forecasting via Risk and Scene Graph Learning",
    "abstract": "Heterogeneous trajectory forecasting is critical for intelligent\ntransportation systems, while it is challenging because of the difficulty for\nmodeling the complex interaction relations among the heterogeneous road agents\nas well as their agent-environment constraint. In this work, we propose a risk\nand scene graph learning method for trajectory forecasting of heterogeneous\nroad agents, which consists of a Heterogeneous Risk Graph (HRG) and a\nHierarchical Scene Graph (HSG) from the aspects of agent category and their\nmovable semantic regions. HRG groups each kind of road agents and calculates\ntheir interaction adjacency matrix based on an effective collision risk metric.\nHSG of driving scene is modeled by inferring the relationship between road\nagents and road semantic layout aligned by the road scene grammar. Based on\nthis formulation, we can obtain an effective trajectory forecasting in driving\nsituations, and superior performance to other state-of-the-art approaches is\ndemonstrated by exhaustive experiments on the nuScenes, ApolloScape, and\nArgoverse datasets.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Intelligent Transportation Systems, 2022\n",
    "authors": [
      "Jianwu Fang",
      "Chen Zhu",
      "Pu Zhang",
      "Hongkai Yu",
      "Jianru Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00848"
  },
  {
    "id": "arXiv:2211.00849",
    "title": "P$^3$OVD: Fine-grained Visual-Text Prompt-Driven Self-Training for  Open-Vocabulary Object Detection",
    "abstract": "Inspired by the success of visual-language methods (VLMs) in zero-shot\nclassification, recent works attempt to extend this line of work into object\ndetection by leveraging the localization ability of pre-trained VLMs and\ngenerating pseudo labels for unseen classes in a self-training manner. However,\nsince the current VLMs are usually pre-trained with aligning sentence embedding\nwith global image embedding, the direct use of them lacks fine-grained\nalignment for object instances, which is the core of detection. In this paper,\nwe propose a simple but effective Pretrain-adaPt-Pseudo labeling paradigm for\nOpen-Vocabulary Detection (P$^3$OVD) that introduces a fine-grained visual-text\nprompt adapting stage to enhance the current self-training paradigm with a more\npowerful fine-grained alignment. During the adapting stage, we enable VLM to\nobtain fine-grained alignment by using learnable text prompts to resolve an\nauxiliary dense pixel-wise prediction task. Furthermore, we propose a visual\nprompt module to provide the prior task information (i.e., the categories need\nto be predicted) for the vision branch to better adapt the pretrained VLM to\nthe downstream tasks. Experiments show that our method achieves the\nstate-of-the-art performance for open-vocabulary object detection, e.g., 31.5%\nmAP on unseen classes of COCO.",
    "descriptor": "",
    "authors": [
      "Yanxin Long",
      "Jianhua Han",
      "Runhui Huang",
      "Xu Hang",
      "Yi Zhu",
      "Chunjing Xu",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00849"
  },
  {
    "id": "arXiv:2211.00852",
    "title": "A linear second-order maximum bound principle-preserving BDF scheme for  the Allen-Cahn equation with general mobility",
    "abstract": "In this paper, we propose and analyze a linear second-order numerical method\nfor solving the Allen-Cahn equation with general mobility. The proposed\nfully-discrete scheme is carefully constructed based on the combination of\nfirst and second-order backward differentiation formulas with nonuniform time\nsteps for temporal approximation and the central finite difference for spatial\ndiscretization. The discrete maximum bound principle is proved of the proposed\nscheme by using the kernel recombination technique under certain mild\nconstraints on the time steps and the ratios of adjacent time step sizes.\nFurthermore, we rigorously derive the discrete $H^{1}$ error estimate and\nenergy stability for the classic constant mobility case and the $L^{\\infty}$\nerror estimate for the general mobility case. Various numerical experiments are\nalso presented to validate the theoretical results and demonstrate the\nperformance of the proposed method with a time adaptive strategy.",
    "descriptor": "\nComments: 25pages, 5 figures\n",
    "authors": [
      "Dianming Hou",
      "Lili Ju",
      "Zhonghua Qiao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00852"
  },
  {
    "id": "arXiv:2211.00854",
    "title": "More Speaking or More Speakers?",
    "abstract": "Self-training (ST) and self-supervised learning (SSL) methods have\ndemonstrated strong improvements in automatic speech recognition (ASR). In\nspite of these advances, to the best of our knowledge, there is no analysis of\nhow the composition of the labelled and unlabelled datasets used in these\nmethods affects the results. In this work we aim to analyse the effect of\nnumbers of speakers in the training data on a recent SSL algorithm (wav2vec\n2.0), and a recent ST algorithm (slimIPL). We perform a systematic analysis on\nboth labeled and unlabeled data by varying the number of speakers while keeping\nthe number of hours fixed and vice versa. Our findings suggest that SSL\nrequires a large amount of unlabeled data to produce high accuracy results,\nwhile ST requires a sufficient number of speakers in the labelled data,\nespecially in the low-regime setting. In this manner these two approaches\nimprove supervised learning in different regimes of dataset composition.",
    "descriptor": "",
    "authors": [
      "Dan Berrebbi",
      "Ronan Collobert",
      "Navdeep Jaitly",
      "Tatiana Likhomanenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00854"
  },
  {
    "id": "arXiv:2211.00856",
    "title": "Deep Virtual-to-Real Distillation for Pedestrian Crossing Prediction",
    "abstract": "Pedestrian crossing is one of the most typical behavior which conflicts with\nnatural driving behavior of vehicles. Consequently, pedestrian crossing\nprediction is one of the primary task that influences the vehicle planning for\nsafe driving. However, current methods that rely on the practically collected\ndata in real driving scenes cannot depict and cover all kinds of scene\ncondition in real traffic world. To this end, we formulate a deep virtual to\nreal distillation framework by introducing the synthetic data that can be\ngenerated conveniently, and borrow the abundant information of pedestrian\nmovement in synthetic videos for the pedestrian crossing prediction in real\ndata with a simple and lightweight implementation. In order to verify this\nframework, we construct a benchmark with 4667 virtual videos owning about 745k\nframes (called Virtual-PedCross-4667), and evaluate the proposed method on two\nchallenging datasets collected in real driving situations, i.e., JAAD and PIE\ndatasets. State-of-the-art performance of this framework is demonstrated by\nexhaustive experiment analysis. The dataset and code can be downloaded from the\nwebsite \\url{this http URL}.",
    "descriptor": "\nComments: Accepted by ITSC 2022\n",
    "authors": [
      "Jie Bai",
      "Xin Fang",
      "Jianwu Fang",
      "Jianru Xue",
      "Changwei Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00856"
  },
  {
    "id": "arXiv:2211.00858",
    "title": "Conversation-oriented ASR with multi-look-ahead CBS architecture",
    "abstract": "During conversations, humans are capable of inferring the intention of the\nspeaker at any point of the speech to prepare the following action promptly.\nSuch ability is also the key for conversational systems to achieve rhythmic and\nnatural conversation. To perform this, the automatic speech recognition (ASR)\nused for transcribing the speech in real-time must achieve high accuracy\nwithout delay. In streaming ASR, high accuracy is assured by attending to\nlook-ahead frames, which leads to delay increments. To tackle this trade-off\nissue, we propose a multiple latency streaming ASR to achieve high accuracy\nwith zero look-ahead. The proposed system contains two encoders that operate in\nparallel, where a primary encoder generates accurate outputs utilizing\nlook-ahead frames, and the auxiliary encoder recognizes the look-ahead portion\nof the primary encoder without look-ahead. The proposed system is constructed\nbased on contextual block streaming (CBS) architecture, which leverages block\nprocessing and has a high affinity for the multiple latency architecture.\nVarious methods are also studied for architecting the system, including\nshifting the network to perform as different encoders; as well as generating\nboth encoders' outputs in one encoding pass.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Huaibo Zhao",
      "Shinya Fujie",
      "Tetsuji Ogawa",
      "Jin Sakuma",
      "Yusuke Kida",
      "Tetsunori Kobayashi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00858"
  },
  {
    "id": "arXiv:2211.00859",
    "title": "SufrinNet: Toward Sufficient Cross-View Interaction for Stereo Image  Enhancement in The Dark",
    "abstract": "Low-light stereo image enhancement (LLSIE) is a relatively new task to\nenhance the quality of visually unpleasant stereo images captured in dark\nconditions. So far, very few studies on deep LLSIE have been explored due to\ncertain challenging issues, i.e., the task has not been well addressed, and\ncurrent methods clearly suffer from two shortages: 1) insufficient cross-view\ninteraction; 2) lacking long-range dependency for intra-view learning. In this\npaper, we therefore propose a novel LLSIE model, termed \\underline{Suf}ficient\nC\\underline{r}oss-View \\underline{In}teraction Network (SufrinNet). To be\nspecific, we present sufficient inter-view interaction module (SIIM) to enhance\nthe information exchange across views. SIIM not only discovers the cross-view\ncorrelations at different scales, but also explores the cross-scale information\ninteraction. Besides, we present a spatial-channel information mining block\n(SIMB) for intra-view feature extraction, and the benefits are twofold. One is\nthe long-range dependency capture to build spatial long-range relationship, and\nthe other is expanded channel information refinement that enhances information\nflow in channel dimension. Extensive experiments on Flickr1024, KITTI 2012,\nKITTI 2015 and Middlebury datasets show that our method obtains better\nillumination adjustment and detail recovery, and achieves SOTA performance\ncompared to other related methods. Our codes, datasets and models will be\npublicly available.",
    "descriptor": "",
    "authors": [
      "Huan Zheng",
      "Zhao Zhang",
      "Jicong Fan",
      "Richang Hong",
      "Yi Yang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00859"
  },
  {
    "id": "arXiv:2211.00863",
    "title": "Behavior Prior Representation learning for Offline Reinforcement  Learning",
    "abstract": "Offline reinforcement learning (RL) struggles in environments with rich and\nnoisy inputs, where the agent only has access to a fixed dataset without\nenvironment interactions. Past works have proposed common workarounds based on\nthe pre-training of state representations, followed by policy training. In this\nwork, we introduce a simple, yet effective approach for learning state\nrepresentations. Our method, Behavior Prior Representation (BPR), learns state\nrepresentations with an easy-to-integrate objective based on behavior cloning\nof the dataset: we first learn a state representation by mimicking actions from\nthe dataset, and then train a policy on top of the fixed representation, using\nany off-the-shelf Offline RL algorithm. Theoretically, we prove that BPR\ncarries out performance guarantees when integrated into algorithms that have\neither policy improvement guarantees (conservative algorithms) or produce lower\nbounds of the policy values (pessimistic algorithms). Empirically, we show that\nBPR combined with existing state-of-the-art Offline RL algorithms leads to\nsignificant improvements across several offline control benchmarks.",
    "descriptor": "",
    "authors": [
      "Hongyu Zang",
      "Xin Li",
      "Jie Yu",
      "Chen Liu",
      "Riashat Islam",
      "Remi Tachet Des Combes",
      "Romain Laroche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00863"
  },
  {
    "id": "arXiv:2211.00864",
    "title": "Multi-task Learning for Source Attribution and Field Reconstruction for  Methane Monitoring",
    "abstract": "Inferring the source information of greenhouse gases, such as methane, from\nspatially sparse sensor observations is an essential element in mitigating\nclimate change. While it is well understood that the complex behavior of the\natmospheric dispersion of such pollutants is governed by the\nAdvection-Diffusion equation, it is difficult to directly apply the governing\nequations to identify the source location and magnitude (inverse problem)\nbecause of the spatially sparse and noisy observations, i.e., the pollution\nconcentration is known only at the sensor locations and sensors sensitivity is\nlimited. Here, we develop a multi-task learning framework that can provide\nhigh-fidelity reconstruction of the concentration field and identify emission\ncharacteristics of the pollution sources such as their location, emission\nstrength, etc. from sparse sensor observations. We demonstrate that our\nproposed framework is able to achieve accurate reconstruction of the methane\nconcentrations from sparse sensor measurements as well as precisely pin-point\nthe location and emission strength of these pollution sources.",
    "descriptor": "\nComments: 7 pages, 8 figures, 1 table\n",
    "authors": [
      "Arka Daw",
      "Kyongmin Yeo",
      "Anuj Karpatne",
      "Levente Klein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00864"
  },
  {
    "id": "arXiv:2211.00868",
    "title": "tSF: Transformer-based Semantic Filter for Few-Shot Learning",
    "abstract": "Few-Shot Learning (FSL) alleviates the data shortage challenge via embedding\ndiscriminative target-aware features among plenty seen (base) and few unseen\n(novel) labeled samples. Most feature embedding modules in recent FSL methods\nare specially designed for corresponding learning tasks (e.g., classification,\nsegmentation, and object detection), which limits the utility of embedding\nfeatures. To this end, we propose a light and universal module named\ntransformer-based Semantic Filter (tSF), which can be applied for different FSL\ntasks. The proposed tSF redesigns the inputs of a transformer-based structure\nby a semantic filter, which not only embeds the knowledge from whole base set\nto novel set but also filters semantic features for target category.\nFurthermore, the parameters of tSF is equal to half of a standard transformer\nblock (less than 1M). In the experiments, our tSF is able to boost the\nperformances in different classic few-shot learning tasks (about 2%\nimprovement), especially outperforms the state-of-the-arts on multiple\nbenchmark datasets in few-shot classification task.",
    "descriptor": "",
    "authors": [
      "Jinxiang Lai",
      "Siqian Yang",
      "Wenlong Liu",
      "Yi Zeng",
      "Zhongyi Huang",
      "Wenlong Wu",
      "Jun Liu",
      "Bin-Bin Gao",
      "Chengjie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00868"
  },
  {
    "id": "arXiv:2211.00869",
    "title": "Title2Event: Benchmarking Open Event Extraction with a Large-scale  Chinese Title Dataset",
    "abstract": "Event extraction (EE) is crucial to downstream tasks such as new aggregation\nand event knowledge graph construction. Most existing EE datasets manually\ndefine fixed event types and design specific schema for each of them, failing\nto cover diverse events emerging from the online text. Moreover, news titles,\nan important source of event mentions, have not gained enough attention in\ncurrent EE research. In this paper, We present Title2Event, a large-scale\nsentence-level dataset benchmarking Open Event Extraction without restricting\nevent types. Title2Event contains more than 42,000 news titles in 34 topics\ncollected from Chinese web pages. To the best of our knowledge, it is currently\nthe largest manually-annotated Chinese dataset for open event extraction. We\nfurther conduct experiments on Title2Event with different models and show that\nthe characteristics of titles make it challenging for event extraction,\naddressing the significance of advanced study on this problem. The dataset and\nbaseline codes are available at https://open-event-hub.github.io/title2event.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Haolin Deng",
      "Yanan Zhang",
      "Yangfan Zhang",
      "Wangyang Ying",
      "Changlong Yu",
      "Jun Gao",
      "Wei Wang",
      "Xiaoling Bai",
      "Nan Yang",
      "Jin Ma",
      "Xiang Chen",
      "Tianhua Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00869"
  },
  {
    "id": "arXiv:2211.00872",
    "title": "ADPTriage: Approximate Dynamic Programming for Bug Triage",
    "abstract": "Bug triaging is a critical task in any software development project. It\nentails triagers going over a list of open bugs, deciding whether each is\nrequired to be addressed, and, if so, which developer should fix it. However,\nthe manual bug assignment in issue tracking systems (ITS) offers only a limited\nsolution and might easily fail when triagers must handle a large number of bug\nreports. During the automated assignment, there are multiple sources of\nuncertainties in the ITS, which should be addressed meticulously. In this\nstudy, we develop a Markov decision process (MDP) model for an online bug\ntriage task. In addition to an optimization-based myopic technique, we provide\nan ADP-based bug triage solution, called ADPTriage, which has the ability to\nreflect the downstream uncertainty in the bug arrivals and developers'\ntimetables. Specifically, without placing any limits on the underlying\nstochastic process, this technique enables real-time decision-making on bug\nassignments while taking into consideration developers' expertise, bug type,\nand bug fixing time. Our result shows a significant improvement over the myopic\napproach in terms of assignment accuracy and fixing time. We also demonstrate\nthe empirical convergence of the model and conduct sensitivity analysis with\nvarious model parameters. Accordingly, this work constitutes a significant step\nforward in addressing the uncertainty in bug triage solutions",
    "descriptor": "",
    "authors": [
      "Hadi Jahanshahi",
      "Mucahit Cevik",
      "Kianoush Mousavi",
      "Ay\u015fe Ba\u015far"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00872"
  },
  {
    "id": "arXiv:2211.00874",
    "title": "Age of Information of Multi-user Mobile Edge Computing Systems",
    "abstract": "In this paper, we analyze the average age of information (AoI) and the\naverage peak AoI (PAoI) of a multiuser mobile edge computing (MEC) system where\na base station (BS) generates and transmits computation-intensive packets to\nuser equipments (UEs). In this MEC system, we focus on three computing schemes:\n(i) The local computing scheme where all computational tasks are computed by\nthe local server at the UE, (ii) The edge computing scheme where all\ncomputational tasks are computed by the edge server at the BS, and (iii) The\npartial computing scheme where computational tasks are partially allocated at\nthe edge server and the rest are computed by the local server. Considering\nexponentially distributed transmission time and computation time and adopting\nthe first come first serve (FCFS) queuing policy, we derive closed-form\nexpressions for the average AoI and average PAoI. To address the complexity of\nthe average AoI expression, we derive simple upper and lower bounds on the\naverage AoI, which allow us to explicitly examine the dependence of the optimal\noffloading decision on the MEC system parameters. Aided by simulation results,\nwe verify our analysis and illustrate the impact of system parameters on the\nAoI performance.",
    "descriptor": "",
    "authors": [
      "Zhifeng Tang",
      "Zhuo Sun",
      "Nan Yang",
      "Xiangyun Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.00874"
  },
  {
    "id": "arXiv:2211.00879",
    "title": "Fair Allocation of Two Types of Chores",
    "abstract": "We consider the problem of fair allocation of indivisible chores under\nadditive valuations. We assume that the chores are divided into two types and\nunder this scenario, we present several results. Our first result is a new\ncharacterization of Pareto optimal allocations in our setting, and a\npolynomial-time algorithm to compute an envy-free up to one item (EF1) and\nPareto optimal allocation. We then turn to the question of whether we can\nachieve a stronger fairness concept called envy-free up any item (EFX). We\npresent a polynomial-time algorithm that returns an EFX allocation. Finally, we\nshow that for our setting, it can be checked in polynomial time whether an\nenvy-free allocation exists or not.",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Jeremy Lindsay",
      "Angus Ritossa",
      "Mashbat Suzuki"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.00879"
  },
  {
    "id": "arXiv:2211.00880",
    "title": "DeepTrace: Learning to Optimize Contact Tracing in Epidemic Networks  with Graph Neural Networks",
    "abstract": "The goal of digital contact tracing is to diminish the spread of an epidemic\nor pandemic by detecting and mitigating public health emergencies using digital\ntechnologies. Since the start of the COVID-$19$ pandemic, a wide variety of\nmobile digital apps have been deployed to identify people exposed to the\nSARS-CoV-2 coronavirus and to stop onward transmission. Tracing sources of\nspreading (i.e., backward contact tracing), as has been used in Japan and\nAustralia, has proven crucial as going backwards can pick up infections that\nmight otherwise be missed at superspreading events. How should robust backward\ncontact tracing automated by mobile computing and network analytics be\ndesigned? In this paper, we formulate the forward and backward contact tracing\nproblem for epidemic source inference as maximum-likelihood (ML) estimation\nsubject to subgraph sampling. Besides its restricted case (inspired by the\nseminal work of Zaman and Shah in 2011) when the full infection topology is\nknown, the general problem is more challenging due to its sheer combinatorial\ncomplexity, problem scale and the fact that the full infection topology is\nrarely accurately known. We propose a Graph Neural Network (GNN) framework,\nnamed DeepTrace, to compute the ML estimator by leveraging the likelihood\nstructure to configure the training set with topological features of smaller\nepidemic networks as training sets. We demonstrate that the performance of our\nGNN approach improves over prior heuristics in the literature and serves as a\nbasis to design robust contact tracing analytics to combat pandemics.",
    "descriptor": "",
    "authors": [
      "Siya Chen",
      "Pei-Duo Yu",
      "Chee Wei Tan",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.00880"
  },
  {
    "id": "arXiv:2211.00881",
    "title": "Unsupervised Syntactically Controlled Paraphrase Generation with  Abstract Meaning Representations",
    "abstract": "Syntactically controlled paraphrase generation has become an emerging\nresearch direction in recent years. Most existing approaches require annotated\nparaphrase pairs for training and are thus costly to extend to new domains.\nUnsupervised approaches, on the other hand, do not need paraphrase pairs but\nsuffer from relatively poor performance in terms of syntactic control and\nquality of generated paraphrases. In this paper, we demonstrate that leveraging\nAbstract Meaning Representations (AMR) can greatly improve the performance of\nunsupervised syntactically controlled paraphrase generation. Our proposed\nmodel, AMR-enhanced Paraphrase Generator (AMRPG), separately encodes the AMR\ngraph and the constituency parse of the input sentence into two disentangled\nsemantic and syntactic embeddings. A decoder is then learned to reconstruct the\ninput sentence from the semantic and syntactic embeddings. Our experiments show\nthat AMRPG generates more accurate syntactically controlled paraphrases, both\nquantitatively and qualitatively, compared to the existing unsupervised\napproaches. We also demonstrate that the paraphrases generated by AMRPG can be\nused for data augmentation to improve the robustness of NLP models.",
    "descriptor": "\nComments: Paper accepted by EMNLP 2022 Findings. The first two authors contribute equally\n",
    "authors": [
      "Kuan-Hao Huang",
      "Varun Iyer",
      "Anoop Kumar",
      "Sriram Venkatapathy",
      "Kai-Wei Chang",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00881"
  },
  {
    "id": "arXiv:2211.00882",
    "title": "DyAnNet: A Scene Dynamicity Guided Self-Trained Video Anomaly Detection  Network",
    "abstract": "Unsupervised approaches for video anomaly detection may not perform as good\nas supervised approaches. However, learning unknown types of anomalies using an\nunsupervised approach is more practical than a supervised approach as\nannotation is an extra burden. In this paper, we use isolation tree-based\nunsupervised clustering to partition the deep feature space of the video\nsegments. The RGB- stream generates a pseudo anomaly score and the flow stream\ngenerates a pseudo dynamicity score of a video segment. These scores are then\nfused using a majority voting scheme to generate preliminary bags of positive\nand negative segments. However, these bags may not be accurate as the scores\nare generated only using the current segment which does not represent the\nglobal behavior of a typical anomalous event. We then use a refinement strategy\nbased on a cross-branch feed-forward network designed using a popular I3D\nnetwork to refine both scores. The bags are then refined through a segment\nre-mapping strategy. The intuition of adding the dynamicity score of a segment\nwith the anomaly score is to enhance the quality of the evidence. The method\nhas been evaluated on three popular video anomaly datasets, i.e., UCF-Crime,\nCCTV-Fights, and UBI-Fights. Experimental results reveal that the proposed\nframework achieves competitive accuracy as compared to the state-of-the-art\nvideo anomaly detection methods.",
    "descriptor": "\nComments: 10 pages, 8 figures, and 4 tables. (ACCEPTED AT WACV 2023)\n",
    "authors": [
      "Kamalakar Thakare",
      "Yash Raghuwanshi",
      "Debi Prosad Dogra",
      "Heeseung Choi",
      "Ig-Jae Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00882"
  },
  {
    "id": "arXiv:2211.00884",
    "title": "Alternating Phase Langevin Sampling with Implicit Denoiser Priors for  Phase Retrieval",
    "abstract": "Phase retrieval is the nonlinear inverse problem of recovering a true signal\nfrom its Fourier magnitude measurements. It arises in many applications such as\nastronomical imaging, X-Ray crystallography, microscopy, and more. The problem\nis highly ill-posed due to the phase-induced ambiguities and the large number\nof possible images that can fit to the given measurements. Thus, there's a rich\nhistory of enforcing structural priors to improve solutions including sparsity\npriors and deep-learning-based generative models. However, such priors are\noften limited in their representational capacity or generalizability to\nslightly different distributions. Recent advancements in using denoisers as\nregularizers for non-convex optimization algorithms have shown promising\nperformance and generalization. We present a way of leveraging the prior\nimplicitly learned by a denoiser to solve phase retrieval problems by\nincorporating it in a classical alternating minimization framework. Compared to\nperformant denoising-based algorithms for phase retrieval, we showcase\ncompetitive performance with Fourier measurements on in-distribution images and\nnotable improvement on out-of-distribution images.",
    "descriptor": "",
    "authors": [
      "Rohun Agrawal",
      "Oscar Leong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00884"
  },
  {
    "id": "arXiv:2211.00889",
    "title": "Accelerating Parallel Stochastic Gradient Descent via Non-blocking  Mini-batches",
    "abstract": "SOTA decentralized SGD algorithms can overcome the bandwidth bottleneck at\nthe parameter server by using communication collectives like Ring All-Reduce\nfor synchronization. While the parameter updates in distributed SGD may happen\nasynchronously there is still a synchronization barrier to make sure that the\nlocal training epoch at every learner is complete before the learners can\nadvance to the next epoch. The delays in waiting for the slowest\nlearners(stragglers) remain to be a problem in the synchronization steps of\nthese state-of-the-art decentralized frameworks. In this paper, we propose the\n(de)centralized Non-blocking SGD (Non-blocking SGD) which can address the\nstraggler problem in a heterogeneous environment. The main idea of Non-blocking\nSGD is to split the original batch into mini-batches, then accumulate the\ngradients and update the model based on finished mini-batches. The Non-blocking\nidea can be implemented using decentralized algorithms including Ring\nAll-reduce, D-PSGD, and MATCHA to solve the straggler problem. Moreover, using\ngradient accumulation to update the model also guarantees convergence and\navoids gradient staleness. Run-time analysis with random straggler delays and\ncomputational efficiency/throughput of devices is also presented to show the\nadvantage of Non-blocking SGD. Experiments on a suite of datasets and deep\nlearning networks validate the theoretical analyses and demonstrate that\nNon-blocking SGD speeds up the training and fastens the convergence. Compared\nwith the state-of-the-art decentralized asynchronous algorithms like D-PSGD and\nMACHA, Non-blocking SGD takes up to 2x fewer time to reach the same training\nloss in a heterogeneous environment.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Haoze He",
      "Parijat Dube"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00889"
  },
  {
    "id": "arXiv:2211.00890",
    "title": "Rethinking the Metric in Few-shot Learning: From an Adaptive  Multi-Distance Perspective",
    "abstract": "Few-shot learning problem focuses on recognizing unseen classes given a few\nlabeled images. In recent effort, more attention is paid to fine-grained\nfeature embedding, ignoring the relationship among different distance metrics.\nIn this paper, for the first time, we investigate the contributions of\ndifferent distance metrics, and propose an adaptive fusion scheme, bringing\nsignificant improvements in few-shot classification. We start from a naive\nbaseline of confidence summation and demonstrate the necessity of exploiting\nthe complementary property of different distance metrics. By finding the\ncompetition problem among them, built upon the baseline, we propose an Adaptive\nMetrics Module (AMM) to decouple metrics fusion into metric-prediction fusion\nand metric-losses fusion. The former encourages mutual complementary, while the\nlatter alleviates metric competition via multi-task collaborative learning.\nBased on AMM, we design a few-shot classification framework AMTNet, including\nthe AMM and the Global Adaptive Loss (GAL), to jointly optimize the few-shot\ntask and auxiliary self-supervised task, making the embedding features more\nrobust. In the experiment, the proposed AMM achieves 2% higher performance than\nthe naive metrics fusion module, and our AMTNet outperforms the\nstate-of-the-arts on multiple benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Jinxiang Lai",
      "Siqian Yang",
      "Guannan Jiang",
      "Xi Wang",
      "Yuxi Li",
      "Zihui Jia",
      "Xiaochen Chen",
      "Jun Liu",
      "Bin-Bin Gao",
      "Wei Zhang",
      "Yuan Xie",
      "Chengjie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00890"
  },
  {
    "id": "arXiv:2211.00891",
    "title": "New quantum codes from self-dual codes over F_4",
    "abstract": "We present new constructions of binary quantum codes from quaternary linear\nHermitian self-dual codes. Our main ingredients for these constructions are\nnearly self-orthogonal cyclic or duadic codes over F_4. An infinite family of\n$0$-dimensional binary quantum codes is provided. We give minimum distance\nlower bounds for our quantum codes in terms of the minimum distance of their\ningredient linear codes. We also present new results on the minimum distance of\nlinear cyclic codes using their fixed subcodes. Finally, we list many new\nrecord-breaking quantum codes obtained from our constructions.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Reza Dastbasteh",
      "Petr Lisonek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2211.00891"
  },
  {
    "id": "arXiv:2211.00892",
    "title": "A highly accurate perfectly-matched-layer boundary integral equation  solver for acoustic layered-medium problems",
    "abstract": "Based on the perfectly matched layer (PML) technique, this paper develops a\nhigh-accuracy boundary integral equation (BIE) solver for acoustic scattering\nproblems in locally defected layered media in both two and three dimensions.\nThe original scattering problem is truncated onto a bounded domain by the PML.\nAssuming the vanishing of the scattered field on the PML boundary, we derive\nBIEs on local defects only in terms of using PML-transformed free-space Green's\nfunction, and the four standard integral operators: single-layer, double-layer,\ntranspose of double-layer, and hyper-singular boundary integral operators. The\nhyper-singular integral operator is transformed into a combination of\nweakly-singular integral operators and tangential derivatives. We develop a\nhigh-order Chebyshev-based rectangular-polar singular-integration solver to\ndiscretize all weakly-singular integrals. Numerical experiments for both two-\nand three-dimensional problems are carried out to demonstrate the accuracy and\nefficiency of the proposed solver.",
    "descriptor": "\nComments: 19 pages, 16 figures\n",
    "authors": [
      "Wangtao Lu",
      "Liwei Xu",
      "Tao Yin",
      "Lu Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00892"
  },
  {
    "id": "arXiv:2211.00894",
    "title": "Community detection in overlapping weighted networks",
    "abstract": "Community detection in overlapping unweighted networks in which nodes can\nbelong to multiple communities is one of the most popular topics in modern\nnetwork science during the last decade. However, community detection in\noverlapping weighted networks in which elements of adjacency matrices can be\nany finite real values remains a challenge. In this article, we propose a\ndegree-corrected mixed membership distribution-free (DCMMDF) model which\nextends the degree-corrected mixed membership model from overlapping unweighted\nnetworks to overlapping weighted networks. We address the community membership\nestimation of the DCMMDF by an application of a spectral algorithm and\nestablish a theoretical guarantee of estimation consistency. The proposed model\nis applied to simulated data and real-world data.",
    "descriptor": "",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.00894"
  },
  {
    "id": "arXiv:2211.00895",
    "title": "Pop2Piano : Pop Audio-based Piano Cover Generation",
    "abstract": "The piano cover of pop music is widely enjoyed by people. However, the\ngeneration task of the pop piano cover is still understudied. This is partly\ndue to the lack of synchronized {Pop, Piano Cover} data pairs, which made it\nchallenging to apply the latest data-intensive deep learning-based methods. To\nleverage the power of the data-driven approach, we make a large amount of\npaired and synchronized {pop, piano cover} data using an automated pipeline. In\nthis paper, we present Pop2Piano, a Transformer network that generates piano\ncovers given waveforms of pop music. To the best of our knowledge, this is the\nfirst model to directly generate a piano cover from pop audio without melody\nand chord extraction modules. We show that Pop2Piano trained with our dataset\ncan generate plausible piano covers.",
    "descriptor": "",
    "authors": [
      "Jongho Choi",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00895"
  },
  {
    "id": "arXiv:2211.00897",
    "title": "On the equivalence of linear cyclic and constacyclic codes",
    "abstract": "We introduce new sufficient conditions for permutation and monomial\nequivalence of linear cyclic codes over various finite fields. We recall that\nmonomial equivalence and isometric equivalence are the same relation for linear\ncodes over finite fields. A necessary and sufficient condition for the monomial\nequivalence of linear cyclic codes through a shift map on their defining set is\nalso given. Moreover, we provide new algebraic criteria for the monomial\nequivalence of constacyclic codes over $\\mathbb{F}_4$. Finally, we prove that\nif $\\gcd(3n,\\phi(3n))=1$, then all permutation equivalent constacyclic codes of\nlength $n$ over $\\mathbb{F}_4$ are given by the action of multipliers. The\nresults of this work allow us to prune the search algorithm for new linear\ncodes and discover record-breaking linear and quantum codes.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Reza Dastbasteh",
      "Petr Lisonek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2211.00897"
  },
  {
    "id": "arXiv:2211.00898",
    "title": "SIMD-size aware weight regularization for fast neural vocoding on CPU",
    "abstract": "This paper proposes weight regularization for a faster neural vocoder.\nPruning time-consuming DNN modules is a promising way to realize a real-time\nvocoder on a CPU (e.g. WaveRNN, LPCNet). Regularization that encourages\nsparsity is also effective in avoiding the quality degradation created by\npruning. However, the orders of weight matrices must be contiguous in SIMD size\nfor fast vocoding. To ensure this order, we propose explicit SIMD size aware\nregularization. Our proposed method reshapes a weight matrix into a tensor so\nthat the weights are aligned by group size in advance, and then computes the\ngroup Lasso-like regularization loss. Experiments on 70% sparse subband WaveRNN\nshow that pruning in conventional Lasso and column-wise group Lasso degrades\nthe synthetic speech's naturalness. The vocoder with proposed regularization 1)\nachieves comparable naturalness to that without pruning and 2) performs\nmeaningfully faster than other conventional vocoders using regularization.",
    "descriptor": "\nComments: Accepted to SLT 2022\n",
    "authors": [
      "Hiroki Kanagawa",
      "Yusuke Ijima"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00898"
  },
  {
    "id": "arXiv:2211.00901",
    "title": "A survey on the development status and application prospects of  knowledge graph in smart grids",
    "abstract": "With the advent of the electric power big data era, semantic interoperability\nand interconnection of power data have received extensive attention. Knowledge\ngraph technology is a new method describing the complex relationships between\nconcepts and entities in the objective world, which is widely concerned because\nof its robust knowledge inference ability. Especially with the proliferation of\nmeasurement devices and exponential growth of electric power data empowers,\nelectric power knowledge graph provides new opportunities to solve the\ncontradictions between the massive power resources and the continuously\nincreasing demands for intelligent applications. In an attempt to fulfil the\npotential of knowledge graph and deal with the various challenges faced, as\nwell as to obtain insights to achieve business applications of smart grids,\nthis work first presents a holistic study of knowledge-driven intelligent\napplication integration. Specifically, a detailed overview of electric power\nknowledge mining is provided. Then, the overview of the knowledge graph in\nsmart grids is introduced. Moreover, the architecture of the big knowledge\ngraph platform for smart grids and critical technologies are described.\nFurthermore, this paper comprehensively elaborates on the application prospects\nleveraged by knowledge graph oriented to smart grids, power consumer service,\ndecision-making in dispatching, and operation and maintenance of power\nequipment. Finally, issues and challenges are summarised.",
    "descriptor": "\nComments: IET Generation, Transmission & Distribution\n",
    "authors": [
      "Jian Wang",
      "Xi Wang",
      "Chaoqun Ma",
      "Lei Kou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00901"
  },
  {
    "id": "arXiv:2211.00910",
    "title": "PLATO-K: Internal and External Knowledge Enhanced Dialogue Generation",
    "abstract": "Recently, the practical deployment of open-domain dialogue systems has been\nplagued by the knowledge issue of information deficiency and factual\ninaccuracy. To this end, we introduce PLATO-K based on two-stage dialogic\nlearning to strengthen internal knowledge memorization and external knowledge\nexploitation. In the first stage, PLATO-K learns through massive dialogue\ncorpora and memorizes essential knowledge into model parameters. In the second\nstage, PLATO-K mimics human beings to search for external information and to\nleverage the knowledge in response generation. Extensive experiments reveal\nthat the knowledge issue is alleviated significantly in PLATO-K with such\ncomprehensive internal and external knowledge enhancement. Compared to the\nexisting state-of-the-art Chinese dialogue model, the overall engagingness of\nPLATO-K is improved remarkably by 36.2% and 49.2% on chit-chat and\nknowledge-intensive conversations.",
    "descriptor": "\nComments: First four authors contributed equally to this work\n",
    "authors": [
      "Siqi Bao",
      "Huang He",
      "Jun Xu",
      "Hua Lu",
      "Fan Wang",
      "Hua Wu",
      "Han Zhou",
      "Wenquan Wu",
      "Zheng-Yu Niu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00910"
  },
  {
    "id": "arXiv:2211.00912",
    "title": "Bipartite Mixed Membership Distribution-Free Model. A novel model for  community detection in overlapping bipartite weighted networks",
    "abstract": "Modeling and estimating mixed memberships for un-directed un-weighted\nnetworks in which nodes can belong to multiple communities has been well\nstudied in recent years. However, for a more general case, the bipartite\nweighted networks in which nodes can belong to multiple communities, row nodes\ncan be different from column nodes, and all elements of adjacency matrices can\nbe any finite real values, to our knowledge, there is no model for such\nbipartite weighted networks. To close this gap, this paper introduces a novel\nmodel, the Bipartite Mixed Membership Distribution-Free (BiMMDF) model. As a\nspecial case, bipartite signed networks with mixed memberships can also be\ngenerated from BiMMDF. Our model enjoys its advantage by allowing all elements\nof an adjacency matrix to be generated from any distribution as long as the\nexpectation adjacency matrix has a block structure related to node memberships\nunder BiMMDF. The proposed model can be viewed as an extension of many previous\nmodels, including the popular mixed membership stochastic blcokmodels. An\nefficient algorithm with a theoretical guarantee of consistent estimation is\napplied to fit BiMMDF. In particular, for a standard bipartite weighted network\nwith two row (and column) communities, to make the algorithm's error rates\nsmall with high probability, separation conditions are obtained when adjacency\nmatrices are generated from different distributions under BiMMDF. The behavior\ndifferences of different distributions on separation conditions are verified by\nextensive synthetic bipartite weighted networks generated under BiMMDF.\nExperiments on real-world directed weighted networks illustrate the advantage\nof the algorithm in studying highly mixed nodes and asymmetry between row and\ncolumn communities.",
    "descriptor": "\nComments: 33 pages, 12 figures, 4 tables\n",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.00912"
  },
  {
    "id": "arXiv:2211.00914",
    "title": "Discover Important Paths in the Knowledge Graph Based on Dynamic  Relation Confidence",
    "abstract": "Most of the existing knowledge graphs are not usually complete and can be\ncomplemented by some reasoning algorithms. The reasoning method based on path\nfeatures is widely used in the field of knowledge graph reasoning and\ncompletion on account of that its have strong interpretability. However,\nreasoning methods based on path features still have several problems in the\nfollowing aspects: Path search isinefficient, insufficient paths for sparse\ntasks and some paths are not helpful for reasoning tasks. In order to solve the\nabove problems, this paper proposes a method called DC-Path that combines\ndynamic relation confidence and other indicators to evaluate path features, and\nthen guide path search, finally conduct relation reasoning. Experimental result\nshow that compared with the existing relation reasoning algorithm, this method\ncan select the most representative features in the current reasoning task from\nthe knowledge graph and achieve better performance on the current relation\nreasoning task.",
    "descriptor": "\nComments: accepted by the 7th China National Conference on Big Data & Social Computing\n",
    "authors": [
      "Shanqing Yu",
      "Yijun Wu",
      "Ran Gan",
      "Jiajun Zhou",
      "Ziwan Zheng",
      "Qi Xuan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00914"
  },
  {
    "id": "arXiv:2211.00915",
    "title": "Passage-Mask: A Learnable Regularization Strategy for Retriever-Reader  Models",
    "abstract": "Retriever-reader models achieve competitive performance across many different\nNLP tasks such as open question answering and dialogue conversations. In this\nwork, we notice these models easily overfit the top-rank retrieval passages and\nstandard training fails to reason over the entire retrieval passages. We\nintroduce a learnable passage mask mechanism which desensitizes the impact from\nthe top-rank retrieval passages and prevents the model from overfitting.\nControlling the gradient variance with fewer mask candidates and selecting the\nmask candidates with one-shot bi-level optimization, our learnable\nregularization strategy enforces the answer generation to focus on the entire\nretrieval passages. Experiments on different tasks across open question\nanswering, dialogue conversation, and fact verification show that our method\nconsistently outperforms its baselines. Extensive experiments and ablation\nstudies demonstrate that our method can be general, effective, and beneficial\nfor many NLP tasks.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Shujian Zhang",
      "Chengyue Gong",
      "Xingchao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00915"
  },
  {
    "id": "arXiv:2211.00917",
    "title": "A Novel Autonomous Mobile Platform for Monitoring Fish Habitat",
    "abstract": "Implementing fully automatic unmanned surface vehicles (USVs) monitoring\nwater quality is challenging since effectively collecting environmental data\nwhile keeping the platform stable and environmental-friendly is hard to\napproach. To address this problem, we construct a USV that can automatically\nnavigate an efficient path to sample water quality parameters in order to\nmonitor the aquatic environment. The detection device needs to be stable enough\nto resist a hostile environment or climates while enormous volumes will disturb\nthe aquaculture environment. Meanwhile, planning an efficient path for\ninformation collecting needs to deal with the contradiction between the\nrestriction of energy and the amount of information in the coverage region. To\ntackle with mentioned challenges, we provide a USV platform that can perfectly\nbalance mobility, stability, and portability attributed to its special\nround-shape structure and redundancy motion design. For informative planning,\nwe combined the TSP and CPP algorithms to construct an optimistic plan for\ncollecting more data within a certain range and limiting energy restrictions.We\ndesigned a fish existence prediction scenario to verify the novel system in\nboth simulation experiments and field experiments. The novel aquaculture\nenvironment monitoring system significantly reduces the burden of manual\noperation in the fishery inspection field. Additionally, the simplicity of the\nsensor setup and the minimal cost of the platform enables its other possible\napplications in aquatic exploration and commercial utilization.",
    "descriptor": "",
    "authors": [
      "Tianqi Zhang",
      "Tong Shen",
      "Kai Yuan",
      "Kaiwen Xue",
      "Huihuan Qian"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00917"
  },
  {
    "id": "arXiv:2211.00919",
    "title": "Hydra -- A Federated Data Repository over NDN",
    "abstract": "Today's big data science communities manage their data publication and\nreplication at the application layer. These communities utilize myriad\nmechanisms to publish, discover, and retrieve datasets - the result is an\necosystem of either centralized, or otherwise a collection of ad-hoc data\nrepositories. Publishing datasets to centralized repositories can be\nprocess-intensive, and those repositories do not accept all datasets. The\nad-hoc repositories are difficult to find and utilize due to differences in\ndata names, metadata standards, and access methods. To address the problem of\nscientific data publication and storage, we have designed Hydra, a secure,\ndistributed, and decentralized data repository made of a loose federation of\nstorage servers (nodes) provided by user communities. Hydra runs over Named\nData Networking (NDN) and utilizes the State Vector Sync (SVS) protocol that\nlets individual nodes maintain a \"global view\" of the system. Hydra provides a\nscalable and resilient data retrieval service, with data distribution\nscalability achieved via NDN's built-in data anycast and in-network caching and\nresiliency against individual server failures through automated failure\ndetection and maintaining a specific degree of replication. Hydra utilizes\n\"Favor\", a locally calculated numerical value to decide which nodes will\nreplicate a file. Finally, Hydra utilizes data-centric security for data\npublication and node authentication. Hydra uses a Network Operation Center\n(NOC) to bootstrap trust in Hydra nodes and data publishers. The NOC\ndistributes user and node certificates and performs the proof-of-possession\nchallenges.\nThis technical report serves as the reference for Hydra. It outlines the\ndesign decisions, the rationale behind them, the functional modules, and the\nprotocol specifications.",
    "descriptor": "",
    "authors": [
      "Justin Presley",
      "Xi Wang",
      "Tym Brandel",
      "Xusheng Ai",
      "Proyash Podder",
      "Tianyuan Yu",
      "Varun Patil",
      "Lixia Zhang",
      "Alex Afanasyev",
      "F. Alex Feltus",
      "Susmit Shannigrahi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.00919"
  },
  {
    "id": "arXiv:2211.00922",
    "title": "Dialect-robust Evaluation of Generated Text",
    "abstract": "Evaluation metrics that are not robust to dialect variation make it\nimpossible to tell how well systems perform for many groups of users, and can\neven penalize systems for producing text in lower-resource dialects. However,\ncurrently, there exists no way to quantify how metrics respond to change in the\ndialect of a generated utterance. We thus formalize dialect robustness and\ndialect awareness as goals for NLG evaluation metrics. We introduce a suite of\nmethods and corresponding statistical tests one can use to assess metrics in\nlight of the two goals. Applying the suite to current state-of-the-art metrics,\nwe demonstrate that they are not dialect-robust and that semantic perturbations\nfrequently lead to smaller decreases in a metric than the introduction of\ndialect features. As a first step to overcome this limitation, we propose a\ntraining schema, NANO, which introduces regional and language information to\nthe pretraining process of a metric. We demonstrate that NANO provides a\nsize-efficient way for models to improve the dialect robustness while\nsimultaneously improving their performance on the standard metric benchmark.",
    "descriptor": "",
    "authors": [
      "Jiao Sun",
      "Thibault Sellam",
      "Elizabeth Clark",
      "Tu Vu",
      "Timothy Dozat",
      "Dan Garrette",
      "Aditya Siddhant",
      "Jacob Eisenstein",
      "Sebastian Gehrmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00922"
  },
  {
    "id": "arXiv:2211.00923",
    "title": "SpeechBlender: Speech Augmentation Framework for Mispronunciation Data  Generation",
    "abstract": "One of the biggest challenges in designing mispronunciation detection models\nis the unavailability of labeled L2 speech data. To overcome such data\nscarcity, we introduce SpeechBlender -- a fine-grained data augmentation\npipeline for generating mispronunciation errors. The SpeechBlender utilizes\nvarieties of masks to target different regions of a phonetic unit, and use the\nmixing factors to linearly interpolate raw speech signals while generating\nerroneous pronunciation instances. The masks facilitate smooth blending of the\nsignals, thus generating more effective samples than the `Cut/Paste' method. We\nshow the effectiveness of our augmentation technique in a phoneme-level\npronunciation quality assessment task, leveraging only a good pronunciation\ndataset. With SpeechBlender augmentation, we observed a 3% and 2% increase in\nPearson correlation coefficient (PCC) compared to no-augmentation and goodness\nof pronunciation augmentation scenarios respectively for Speechocean762\ntestset. Moreover, a 2% rise in PCC is observed when comparing our single-task\nphoneme-level mispronunciation detection model with a multi-task learning model\nusing multiple-granularity information.",
    "descriptor": "\nComments: 5 pages, submitted to ICASSP 2023\n",
    "authors": [
      "Yassine El Kheir",
      "Shammur Absar Chowdhury",
      "Hamdy Mubarak",
      "Shazia Afzal",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00923"
  },
  {
    "id": "arXiv:2211.00924",
    "title": "SyncTalkFace: Talking Face Generation with Precise Lip-Syncing via  Audio-Lip Memory",
    "abstract": "The challenge of talking face generation from speech lies in aligning two\ndifferent modal information, audio and video, such that the mouth region\ncorresponds to input audio. Previous methods either exploit audio-visual\nrepresentation learning or leverage intermediate structural information such as\nlandmarks and 3D models. However, they struggle to synthesize fine details of\nthe lips varying at the phoneme level as they do not sufficiently provide\nvisual information of the lips at the video synthesis step. To overcome this\nlimitation, our work proposes Audio-Lip Memory that brings in visual\ninformation of the mouth region corresponding to input audio and enforces\nfine-grained audio-visual coherence. It stores lip motion features from\nsequential ground truth images in the value memory and aligns them with\ncorresponding audio features so that they can be retrieved using audio input at\ninference time. Therefore, using the retrieved lip motion features as visual\nhints, it can easily correlate audio with visual dynamics in the synthesis\nstep. By analyzing the memory, we demonstrate that unique lip features are\nstored in each memory slot at the phoneme level, capturing subtle lip motion\nbased on memory addressing. In addition, we introduce visual-visual\nsynchronization loss which can enhance lip-syncing performance when used along\nwith audio-visual synchronization loss in our model. Extensive experiments are\nperformed to verify that our method generates high-quality video with mouth\nshapes that best align with the input audio, outperforming previous\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted at AAAI 2022\n",
    "authors": [
      "Se Jin Park",
      "Minsu Kim",
      "Joanna Hong",
      "Jeongsoo Choi",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.00924"
  },
  {
    "id": "arXiv:2211.00928",
    "title": "Neural Active Learning on Heteroskedastic Distributions",
    "abstract": "Models that can actively seek out the best quality training data hold the\npromise of more accurate, adaptable, and efficient machine learning.\nState-of-the-art active learning techniques tend to prefer examples that are\nthe most difficult to classify. While this works well on homogeneous datasets,\nwe find that it can lead to catastrophic failures when performed on multiple\ndistributions with different degrees of label noise or heteroskedasticity.\nThese active learning algorithms strongly prefer to draw from the distribution\nwith more noise, even if their examples have no informative structure (such as\nsolid color images with random labels). To this end, we demonstrate the\ncatastrophic failure of these active learning algorithms on heteroskedastic\ndistributions and propose a fine-tuning-based approach to mitigate these\nfailures. Further, we propose a new algorithm that incorporates a model\ndifference scoring function for each data point to filter out the noisy\nexamples and sample clean examples that maximize accuracy, outperforming the\nexisting active learning techniques on the heteroskedastic datasets. We hope\nthese observations and techniques are immediately helpful to practitioners and\ncan help to challenge common assumptions in the design of active learning\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Savya Khosla",
      "Chew Kin Whye",
      "Jordan T. Ash",
      "Cyril Zhang",
      "Kenji Kawaguchi",
      "Alex Lamb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00928"
  },
  {
    "id": "arXiv:2211.00930",
    "title": "Nonverbal Social Behavior Generation for Social Robots Using End-to-End  Learning",
    "abstract": "To provide effective and enjoyable human-robot interaction, it is important\nfor social robots to exhibit nonverbal behaviors, such as a handshake or a hug.\nHowever, the traditional approach of reproducing pre-coded motions allows users\nto easily predict the reaction of the robot, giving the impression that the\nrobot is a machine rather than a real agent. Therefore, we propose a neural\nnetwork architecture based on the Seq2Seq model that learns social behaviors\nfrom human-human interactions in an end-to-end manner. We adopted a generative\nadversarial network to prevent invalid pose sequences from occurring when\ngenerating long-term behavior. To verify the proposed method, experiments were\nperformed using the humanoid robot Pepper in a simulated environment. Because\nit is difficult to determine success or failure in social behavior generation,\nwe propose new metrics to calculate the difference between the generated\nbehavior and the ground-truth behavior. We used these metrics to show how\ndifferent network architectural choices affect the performance of behavior\ngeneration, and we compared the performance of learning multiple behaviors and\nthat of learning a single behavior. We expect that our proposed method can be\nused not only with home service robots, but also for guide robots, delivery\nrobots, educational robots, and virtual robots, enabling the users to enjoy and\neffectively interact with the robots.",
    "descriptor": "\nComments: 10 pages, 7 figures, 3 tables, submitted to the International Journal of Robotics Research (IJRR)\n",
    "authors": [
      "Woo-Ri Ko",
      "Minsu Jang",
      "Jaeyeon Lee",
      "Jaehong Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00930"
  },
  {
    "id": "arXiv:2211.00933",
    "title": "Deep Multimodal Fusion for Generalizable Person Re-identification",
    "abstract": "Person re-identification plays a significant role in realistic scenarios due\nto its various applications in public security and video surveillance.\nRecently, leveraging the supervised or semi-unsupervised learning paradigms,\nwhich benefits from the large-scale datasets and strong computing performance,\nhas achieved a competitive performance on a specific target domain. However,\nwhen Re-ID models are directly deployed in a new domain without target samples,\nthey always suffer from considerable performance degradation and poor domain\ngeneralization. To address this challenge, in this paper, we propose DMF, a\nDeep Multimodal Fusion network for the general scenarios on person\nre-identification task, where rich semantic knowledge is introduced to assist\nin feature representation learning during the pre-training stage. On top of it,\na multimodal fusion strategy is introduced to translate the data of different\nmodalities into the same feature space, which can significantly boost\ngeneralization capability of Re-ID model. In the fine-tuning stage, a realistic\ndataset is adopted to fine-tine the pre-trained model for distribution\nalignment with real-world. Comprehensive experiments on benchmarks demonstrate\nthat our proposed method can significantly outperform previous domain\ngeneralization or meta-learning methods. Our source code will also be publicly\navailable at https://github.com/JeremyXSC/DMF.",
    "descriptor": "",
    "authors": [
      "Suncheng Xiang",
      "Hao Chen",
      "Jingsheng Gao",
      "Sijia Du",
      "Jiawang Mou",
      "Ting Liu",
      "Dahong Qian",
      "Yuzhuo Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00933"
  },
  {
    "id": "arXiv:2211.00937",
    "title": "WITT: A Wireless Image Transmission Transformer for Semantic  Communications",
    "abstract": "In this paper, we aim to redesign the vision Transformer (ViT) as a new\nbackbone to realize semantic image transmission, termed wireless image\ntransmission transformer (WITT). Previous works build upon convolutional neural\nnetworks (CNNs), which are inefficient in capturing global dependencies,\nresulting in degraded end-to-end transmission performance especially for\nhigh-resolution images. To tackle this, the proposed WITT employs Swin\nTransformers as a more capable backbone to extract long-range information.\nDifferent from ViTs in image classification tasks, WITT is highly optimized for\nimage transmission while considering the effect of the wireless channel.\nSpecifically, we propose a spatial modulation module to scale the latent\nrepresentations according to channel state information, which enhances the\nability of a single model to deal with various channel conditions. As a result,\nextensive experiments verify that our WITT attains better performance for\ndifferent image resolutions, distortion metrics, and channel conditions. The\ncode is available at https://github.com/KeYang8/WITT.",
    "descriptor": "",
    "authors": [
      "Ke Yang",
      "Sixian Wang",
      "Jincheng Dai",
      "Kailin Tan",
      "Kai Niu",
      "Ping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.00937"
  },
  {
    "id": "arXiv:2211.00941",
    "title": "Fast-U2++: Fast and Accurate End-to-End Speech Recognition in Joint  CTC/Attention Frames",
    "abstract": "Recently, the unified streaming and non-streaming two-pass (U2/U2++)\nend-to-end model for speech recognition has shown great performance in terms of\nstreaming capability, accuracy and latency. In this paper, we present\nfast-U2++, an enhanced version of U2++ to further reduce partial latency. The\ncore idea of fast-U2++ is to output partial results of the bottom layers in its\nencoder with a small chunk, while using a large chunk in the top layers of its\nencoder to compensate the performance degradation caused by the small chunk.\nMoreover, we use knowledge distillation method to reduce the token emission\nlatency. We present extensive experiments on Aishell-1 dataset. Experiments and\nablation studies show that compared to U2++, fast-U2++ reduces model latency\nfrom 320ms to 80ms, and achieves a character error rate (CER) of 5.06% with a\nstreaming setup.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Chengdong Liang",
      "Xiao-Lei Zhang",
      "BinBin Zhang",
      "Di Wu",
      "Shengqiang Li",
      "Xingchen Song",
      "Zhendong Peng",
      "Fuping Pan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00941"
  },
  {
    "id": "arXiv:2211.00942",
    "title": "Model-based Reinforcement Learning with a Hamiltonian Canonical ODE  Network",
    "abstract": "Model-based reinforcement learning usually suffers from a high sample\ncomplexity in training the world model, especially for the environments with\ncomplex dynamics. To make the training for general physical environments more\nefficient, we introduce Hamiltonian canonical ordinary differential equations\ninto the learning process, which inspires a novel model of neural ordinary\ndifferential auto-encoder (NODA). NODA can model the physical world by nature\nand is flexible to impose Hamiltonian mechanics (e.g., the dimension of the\nphysical equations) which can further accelerate training of the environment\nmodels. It can consequentially empower an RL agent with the robust\nextrapolation using a small amount of samples as well as the guarantee on the\nphysical plausibility. Theoretically, we prove that NODA has uniform bounds for\nmulti-step transition errors and value errors under certain conditions.\nExtensive experiments show that NODA can learn the environment dynamics\neffectively with a high sample efficiency, making it possible to facilitate\nreinforcement learning agents at the early stage.",
    "descriptor": "",
    "authors": [
      "Yao Feng",
      "Yuhong Jiang",
      "Hang Su",
      "Dong Yan",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00942"
  },
  {
    "id": "arXiv:2211.00945",
    "title": "CarDD: A New Dataset for Vision-based Car Damage Detection",
    "abstract": "Automatic car damage detection has attracted significant attention in the car\ninsurance business. However, due to the lack of high-quality and publicly\navailable datasets, we can hardly learn a feasible model for car damage\ndetection. To this end, we contribute with the Car Damage Detection (CarDD),\nthe first public large-scale dataset designed for vision-based car damage\ndetection and segmentation. Our CarDD contains 4,000 high-resolution car damage\nimages with over 9,000 wellannotated instances of six damage categories\n(examples are shown in Fig. 1). We detail the image collection, selection, and\nannotation processes, and present a statistical dataset analysis. Furthermore,\nwe conduct extensive experiments on CarDD with state-of-theart deep methods for\ndifferent tasks and provide comprehensive analysis to highlight the specialty\nof car damage detection.",
    "descriptor": "",
    "authors": [
      "Xinkuang Wang",
      "Wenjing Li",
      "Zhongcheng Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00945"
  },
  {
    "id": "arXiv:2211.00953",
    "title": "70 years of Krylov subspace methods: The journey continues",
    "abstract": "Using computed examples for the Conjugate Gradient method and GMRES, we\nrecall important building blocks in the understanding of Krylov subspace\nmethods over the last 70 years. Each example consists of a description of the\nsetup and the numerical observations, followed by an explanation of the\nobserved phenomena, where we keep technical details as small as possible. Our\ngoal is to show the mathematical beauty and hidden intricacies of the methods,\nand to point out some persistent misunderstandings as well as important open\nproblems. We hope that this work initiates further investigations of Krylov\nsubspace methods, which are efficient computational tools and exciting\nmathematical objects that are far from being fully understood.",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Erin Carson",
      "J\u00f6rg Liesen",
      "Zden\u011bk Strako\u0161"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00953"
  },
  {
    "id": "arXiv:2211.00960",
    "title": "Ambiguity-Aware Multi-Object Pose Optimization for Visually-Assisted  Robot Manipulation",
    "abstract": "6D object pose estimation aims to infer the relative pose between the object\nand the camera using a single image or multiple images. Most works have focused\non predicting the object pose without associated uncertainty under occlusion\nand structural ambiguity (symmetricity). However, these works demand prior\ninformation about shape attributes, and this condition is hardly satisfied in\nreality; even asymmetric objects may be symmetric under the viewpoint change.\nIn addition, acquiring and fusing diverse sensor data is challenging when\nextending them to robotics applications. Tackling these limitations, we present\nan ambiguity-aware 6D object pose estimation network, PrimA6D++, as a generic\nuncertainty prediction method. The major challenges in pose estimation, such as\nocclusion and symmetry, can be handled in a generic manner based on the\nmeasured ambiguity of the prediction. Specifically, we devise a network to\nreconstruct the three rotation axis primitive images of a target object and\npredict the underlying uncertainty along each primitive axis. Leveraging the\nestimated uncertainty, we then optimize multi-object poses using visual\nmeasurements and camera poses by treating it as an object SLAM problem. The\nproposed method shows a significant performance improvement in T-LESS and\nYCB-Video datasets. We further demonstrate real-time scene recognition\ncapability for visually-assisted robot manipulation. Our code and supplementary\nmaterials are available at https://github.com/rpmsnu/PrimA6D.",
    "descriptor": "\nComments: IEEE Robotics and Automation Letters\n",
    "authors": [
      "Myung-Hwan Jeon",
      "Jeongyun Kim",
      "Jee-Hwan Ryu",
      "Ayoung Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00960"
  },
  {
    "id": "arXiv:2211.00967",
    "title": "Multi-Speaker Multi-Style Speech Synthesis with Timbre and Style  Disentanglement",
    "abstract": "Disentanglement of a speaker's timbre and style is very important for style\ntransfer in multi-speaker multi-style text-to-speech (TTS) scenarios. With the\ndisentanglement of timbres and styles, TTS systems could synthesize expressive\nspeech for a given speaker with any style which has been seen in the training\ncorpus. However, there are still some shortcomings with the current research on\ntimbre and style disentanglement. The current method either requires\nsingle-speaker multi-style recordings, which are difficult and expensive to\ncollect, or uses a complex network and complicated training method, which is\ndifficult to reproduce and control the style transfer behavior. To improve the\ndisentanglement effectiveness of timbres and styles, and to remove the reliance\non single-speaker multi-style corpus, a simple but effective timbre and style\ndisentanglement method is proposed in this paper. The FastSpeech2 network is\nemployed as the backbone network, with explicit duration, pitch, and energy\ntrajectory to represent the style. Each speaker's data is considered as a\nseparate and isolated style, then a speaker embedding and a style embedding are\nadded to the FastSpeech2 network to learn disentangled representations.\nUtterance level pitch and energy normalization are utilized to improve the\ndecoupling effect. Experimental results demonstrate that the proposed model\ncould synthesize speech with any style seen during training with high style\nsimilarity while maintaining very high speaker similarity.",
    "descriptor": "",
    "authors": [
      "Wei Song",
      "Yanghao Yue",
      "Ya-jie Zhang",
      "Zhengchen Zhang",
      "Youzheng Wu",
      "Xiaodong He"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00967"
  },
  {
    "id": "arXiv:2211.00968",
    "title": "Internal Language Model Estimation based Adaptive Language Model Fusion  for Domain Adaptation",
    "abstract": "ASR model deployment environment is ever-changing, and the incoming speech\ncan be switched across different domains during a session. This brings a\nchallenge for effective domain adaptation when only target domain text data is\navailable, and our objective is to obtain obviously improved performance on the\ntarget domain while the performance on the general domain is less undermined.\nIn this paper, we propose an adaptive LM fusion approach called internal\nlanguage model estimation based adaptive domain adaptation (ILME-ADA). To\nrealize such an ILME-ADA, an interpolated log-likelihood score is calculated\nbased on the maximum of the scores from the internal LM and the external LM\n(ELM) respectively. We demonstrate the efficacy of the proposed ILME-ADA method\nwith both RNN-T and LAS modeling frameworks employing neural network and n-gram\nLMs as ELMs respectively on two domain specific (target) test sets. The\nproposed method can achieve significantly better performance on the target test\nsets while it gets minimal performance degradation on the general test set,\ncompared with both shallow and ILME-based LM fusion methods.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Rao Ma",
      "Xiaobo Wu",
      "Jin Qiu",
      "Yanan Qin",
      "Haihua Xu",
      "Peihao Wu",
      "Zejun Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00968"
  },
  {
    "id": "arXiv:2211.00969",
    "title": "Large deviations rates for stochastic gradient descent with strongly  convex functions",
    "abstract": "Recent works have shown that high probability metrics with stochastic\ngradient descent (SGD) exhibit informativeness and in some cases advantage over\nthe commonly adopted mean-square error-based ones. In this work we provide a\nformal framework for the study of general high probability bounds with SGD,\nbased on the theory of large deviations. The framework allows for a generic\n(not-necessarily bounded) gradient noise satisfying mild technical assumptions,\nallowing for the dependence of the noise distribution on the current iterate.\nUnder the preceding assumptions, we find an upper large deviations bound for\nSGD with strongly convex functions. The corresponding rate function captures\nanalytical dependence on the noise distribution and other problem parameters.\nThis is in contrast with conventional mean-square error analysis that captures\nonly the noise dependence through the variance and does not capture the effect\nof higher order moments nor interplay between the noise geometry and the shape\nof the cost function. We also derive exact large deviation rates for the case\nwhen the objective function is quadratic and show that the obtained function\nmatches the one from the general upper bound hence showing the tightness of the\ngeneral upper bound. Numerical examples illustrate and corroborate theoretical\nfindings.",
    "descriptor": "\nComments: 32 pages, 2 figures\n",
    "authors": [
      "Dragana Bajovic",
      "Dusan Jakovetic",
      "Soummya Kar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.00969"
  },
  {
    "id": "arXiv:2211.00973",
    "title": "BAXMC: a CEGAR approach to Max\\#SAT",
    "abstract": "Max\\#SAT is an important problem with multiple applications in security and\nprogram synthesis that is proven hard to solve. It is defined as: given a\nparameterized quantifier-free propositional formula compute parameters such\nthat the number of models of the formula is maximal. As an extension, the\nformula can include an existential prefix. We propose a CEGAR-based algorithm\nand refinements thereof, based on either exact or approximate model counting,\nand prove its correctness in both cases. Our experiments show that this\nalgorithm has much better effective complexity than the state of the art.",
    "descriptor": "\nComments: FMCAD 2022, Oct 2022, Trente, Italy\n",
    "authors": [
      "Thomas Vigouroux",
      "Cristian Ene",
      "David Monniaux",
      "Laurent Mounier",
      "Marie-Laure Potet"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.00973"
  },
  {
    "id": "arXiv:2211.00974",
    "title": "Processing Long Legal Documents with Pre-trained Transformers: Modding  LegalBERT and Longformer",
    "abstract": "Pre-trained Transformers currently dominate most NLP tasks. They impose,\nhowever, limits on the maximum input length (512 sub-words in BERT), which are\ntoo restrictive in the legal domain. Even sparse-attention models, such as\nLongformer and BigBird, which increase the maximum input length to 4,096\nsub-words, severely truncate texts in three of the six datasets of LexGLUE.\nSimpler linear classifiers with TF-IDF features can handle texts of any length,\nrequire far less resources to train and deploy, but are usually outperformed by\npre-trained Transformers. We explore two directions to cope with long legal\ntexts: (i) modifying a Longformer warm-started from LegalBERT to handle even\nlonger texts (up to 8,192 sub-words), and (ii) modifying LegalBERT to use\nTF-IDF representations. The first approach is the best in terms of performance,\nsurpassing a hierarchical version of LegalBERT, which was the previous state of\nthe art in LexGLUE. The second approach leads to computationally more efficient\nmodels at the expense of lower performance, but the resulting models still\noutperform overall a linear SVM with TF-IDF features in long legal document\nclassification.",
    "descriptor": "\nComments: 9 pages, long paper at NLLP Workshop 2022 proceedings\n",
    "authors": [
      "Dimitris Mamakas",
      "Petros Tsotsi",
      "Ion Androutsopoulos",
      "Ilias Chalkidis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00974"
  },
  {
    "id": "arXiv:2211.00980",
    "title": "Balancing Utility and Fairness in Submodular Maximization (Technical  Report)",
    "abstract": "Submodular function maximization is central in numerous data science\napplications, including data summarization, influence maximization, and\nrecommendation. In many of these problems, our goal is to find a solution that\nmaximizes the \\emph{average} of the utilities for all users, each measured by a\nmonotone submodular function. When the population of users is composed of\nseveral demographic groups, another critical problem is whether the utility is\nfairly distributed across groups. In the context of submodular optimization, we\nseek to improve the welfare of the \\emph{least well-off} group, i.e., to\nmaximize the minimum utility for any group, to ensure fairness. Although the\n\\emph{utility} and \\emph{fairness} objectives are both desirable, they might\ncontradict each other, and, to our knowledge, little attention has been paid to\noptimizing them jointly. In this paper, we propose a novel problem called\n\\emph{Bicriteria Submodular Maximization} (BSM) to strike a balance between\nutility and fairness. Specifically, it requires finding a fixed-size solution\nto maximize the utility function, subject to the value of the fairness function\nnot being below a threshold. Since BSM is inapproximable within any constant\nfactor in general, we propose efficient data-dependent approximation algorithms\nfor BSM by converting it into other submodular optimization problems and\nutilizing existing algorithms for the converted problems to obtain solutions to\nBSM. Using real-world and synthetic datasets, we showcase applications of our\nframework in three submodular maximization problems, namely maximum coverage,\ninfluence maximization, and facility location.",
    "descriptor": "\nComments: 13 pages, 7 figures, under review\n",
    "authors": [
      "Yanhao Wang",
      "Yuchen Li",
      "Francesco Bonchi",
      "Ying Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00980"
  },
  {
    "id": "arXiv:2211.00981",
    "title": "Relevance Assessments for Web Search Evaluation: Should We Randomise or  Prioritise the Pooled Documents? (CORRECTED VERSION)",
    "abstract": "In the context of depth-$k$ pooling for constructing web search test\ncollections, we compare two approaches to ordering pooled documents for\nrelevance assessors: the prioritisation strategy (PRI) used widely at NTCIR,\nand the simple randomisation strategy (RND). In order to address research\nquestions regarding PRI and RND, we have constructed and released the WWW3E8\ndata set, which contains eight independent relevance labels for 32,375\ntopic-document pairs, i.e., a total of 259,000 labels. Four of the eight\nrelevance labels were obtained from PRI-based pools; the other four were\nobtained from RND-based pools. Using WWW3E8, we compare PRI and RND in terms of\ninter-assessor agreement, system ranking agreement, and robustness to new\nsystems that did not contribute to the pools. We also utilise an assessor\nactivity log we obtained as a byproduct of WWW3E8 to compare the two strategies\nin terms of assessment efficiency.",
    "descriptor": "\nComments: 30 pages. This is a corrected version of an open-access TOIS paper ( this https URL )\n",
    "authors": [
      "Tetsuya Sakai",
      "Sijie Tao",
      "Zhaohao Zeng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.00981"
  },
  {
    "id": "arXiv:2211.00982",
    "title": "SpectroMap: Peak detection algorithm for audio fingerprinting",
    "abstract": "We present SpectroMap, an open source GitHub repository for audio\nfingerprinting written in Python programming language. It is composed of a peak\nsearch algorithm that extracts topological prominences from a spectrogram via\ntime-frequency bands. In this paper, we introduce the algorithm functioning\nwith two experimental applications in a high-quality urban sound dataset and\nenvironmental audio recordings to describe how it works and how effective it is\nin handling the input data.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Aar\u00f3n L\u00f3pez-Garc\u00eda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00982"
  },
  {
    "id": "arXiv:2211.00983",
    "title": "A scale-coupled numerical method for transient close-contact melting",
    "abstract": "We introduce a numerical workflow to model and simulate transient\nclose-contact melting processes based on the space-time finite element method.\nThat is, we aim at computing the velocity at which a forced heat source melts\nthrough a phase-change material. Existing approaches found in the literature\nconsider a thermo-mechanical equilibrium in the contact melt film, which\nresults in a constant melting velocity of the heat source. This classical\napproach, however, cannot account for transient effects in which the melting\nvelocity adjusts itself to equilibrium conditions. With our contribution, we\nderive a model for the transient melting process of a planar heat source. We\niteratively cycle between solving for the heat equation in the solid material\nand updating the melting velocity. The latter is computed based on the heat\nflux in the vicinity of the heat source. The motion of the heated body is\nsimulated via the moving mesh strategy referred to as the Virtual Region\nShear-Slip Mesh Update Method, which avoids remeshing and is particularly\nefficient in representing unidirectional movement. We show numerical examples\nto validate our methodology and present two application scenarios, a 2D planar\nthermal melting probe and a 2D hot-wire cutting machine.",
    "descriptor": "",
    "authors": [
      "Leonardo Boledi",
      "Fabian Key",
      "Benjamin Terschanski",
      "Stefanie Elgeti",
      "Julia Kowalski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.00983"
  },
  {
    "id": "arXiv:2211.00985",
    "title": "Distributed Robotic Systems in the Edge-Cloud Continuum with ROS 2: a  Review on Novel Architectures and Technology Readiness",
    "abstract": "Robotic systems are more connected, networked, and distributed than ever. New\narchitectures that comply with the \\textit{de facto} robotics middleware\nstandard, ROS\\,2, have recently emerged to fill the gap in terms of hybrid\nsystems deployed from edge to cloud. This paper reviews new architectures and\ntechnologies that enable containerized robotic applications to seamlessly run\nat the edge or in the cloud. We also overview systems that include solutions\nfrom extension to ROS\\,2 tooling to the integration of Kubernetes and ROS\\,2.\nAnother important trend is robot learning, and how new simulators and cloud\nsimulations are enabling, e.g., large-scale reinforcement learning or\ndistributed federated learning solutions. This has also enabled deeper\nintegration of continuous interaction and continuous deployment (CI/CD)\npipelines for robotic systems development, going beyond standard software unit\ntests with simulated tests to build and validate code automatically. We discuss\nthe current technology readiness and list the potential new application\nscenarios that are becoming available. Finally, we discuss the current\nchallenges in distributed robotic systems and list open research questions in\nthe field.",
    "descriptor": "",
    "authors": [
      "Jiaqiang Zhang",
      "Farhad Keramat",
      "Xianjia Yu",
      "Daniel Montero Hern",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00985"
  },
  {
    "id": "arXiv:2211.00987",
    "title": "Autoregressive GAN for Semantic Unconditional Head Motion Generation",
    "abstract": "We address the task of unconditional head motion generation to animate still\nhuman faces in a low-dimensional semantic space.Deviating from talking head\ngeneration conditioned on audio that seldom puts emphasis on realistic head\nmotions, we devise a GAN-based architecture that allows obtaining rich head\nmotion sequences while avoiding known caveats associated with GANs.Namely, the\nautoregressive generation of incremental outputs ensures smooth trajectories,\nwhile a multi-scale discriminator on input pairs drives generation toward\nbetter handling of high and low frequency signals and less mode collapse.We\ndemonstrate experimentally the relevance of the proposed architecture and\ncompare with models that showed state-of-the-art performances on similar tasks.",
    "descriptor": "",
    "authors": [
      "Louis Airale",
      "Xavier Alameda-Pineda",
      "St\u00e9phane Lathuili\u00e8re",
      "Dominique Vaufreydaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00987"
  },
  {
    "id": "arXiv:2211.00988",
    "title": "Audio-visual speech enhancement with a deep Kalman filter generative  model",
    "abstract": "Deep latent variable generative models based on variational autoencoder (VAE)\nhave shown promising performance for audiovisual speech enhancement (AVSE). The\nunderlying idea is to learn a VAEbased audiovisual prior distribution for clean\nspeech data, and then combine it with a statistical noise model to recover a\nspeech signal from a noisy audio recording and video (lip images) of the target\nspeaker. Existing generative models developed for AVSE do not take into account\nthe sequential nature of speech data, which prevents them from fully\nincorporating the power of visual data. In this paper, we present an\naudiovisual deep Kalman filter (AV-DKF) generative model which assumes a\nfirst-order Markov chain model for the latent variables and effectively fuses\naudiovisual data. Moreover, we develop an efficient inference methodology to\nestimate speech signals at test time. We conduct a set of experiments to\ncompare different variants of generative models for speech enhancement. The\nresults demonstrate the superiority of the AV-DKF model compared with both its\naudio-only version and the non-sequential audio-only and audiovisual VAE-based\nmodels.",
    "descriptor": "",
    "authors": [
      "Ali Golmakani",
      "Mostafa Sadeghi",
      "Romain Serizel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00988"
  },
  {
    "id": "arXiv:2211.00989",
    "title": "How Stable is Knowledge Base Knowledge?",
    "abstract": "Knowledge Bases (KBs) provide structured representation of the real-world in\nthe form of extensive collections of facts about real-world entities, their\nproperties and relationships. They are ubiquitous in large-scale intelligent\nsystems that exploit structured information such as in tasks like structured\nsearch, question answering and reasoning, and hence their data quality becomes\nparamount. The inevitability of change in the real-world, brings us to a\ncentral property of KBs -- they are highly dynamic in that the information they\ncontain are constantly subject to change. In other words, KBs are unstable.\nIn this paper, we investigate the notion of KB stability, specifically, the\nproblem of KBs changing due to real-world change. Some entity-property-pairs do\nnot undergo change in reality anymore (e.g., Einstein-children or\nTesla-founders), while others might well change in the future (e.g.,\nTesla-board member or Ronaldo-occupation as of 2022). This notion of real-world\ngrounded change is different from other changes that affect the data only,\nnotably correction and delayed insertion, which have received attention in data\ncleaning, vandalism detection, and completeness estimation already. To analyze\nKB stability, we proceed in three steps. (1) We present heuristics to delineate\nchanges due to world evolution from delayed completions and corrections, and\nuse these to study the real-world evolution behaviour of diverse Wikidata\ndomains, finding a high skew in terms of properties. (2) We evaluate heuristics\nto identify entities and properties likely to not change due to real-world\nchange, and filter inherently stable entities and properties. (3) We evaluate\nthe possibility of predicting stability post-hoc, specifically predicting\nchange in a property of an entity, finding that this is possible with up to 83%\nF1 score, on a balanced binary stability prediction task.",
    "descriptor": "\nComments: Incomplete draft. 12 pages\n",
    "authors": [
      "Suhas Shrinivasan",
      "Simon Razniewski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.00989"
  },
  {
    "id": "arXiv:2211.00990",
    "title": "Weighted variance variational autoencoder for speech enhancement",
    "abstract": "We address speech enhancement based on variational autoencoders, which\ninvolves learning a speech prior distribution in the time-frequency (TF)\ndomain. A zero-mean complexvalued Gaussian distribution is usually assumed for\nthe generative model, where the speech information is encoded in the variance\nas a function of a latent variable. While this is the commonly used approach,\nin this paper we propose a weighted variance generative model, where the\ncontribution of each TF point in parameter learning is weighted. We impose a\nGamma prior distribution on the weights, which would effectively lead to a\nStudent's t-distribution instead of Gaussian for speech modeling. We develop\nefficient training and speech enhancement algorithms based on the proposed\ngenerative model. Our experimental results on spectrogram modeling and speech\nenhancement demonstrate the effectiveness and robustness of the proposed\napproach compared to the standard unweighted variance model.",
    "descriptor": "",
    "authors": [
      "Ali Golmakani",
      "Mostafa Sadeghi",
      "Xavier Alameda-Pineda",
      "Romain Serizel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00990"
  },
  {
    "id": "arXiv:2211.00992",
    "title": "Low-Cost Traffic Sensing System Based on LoRaWAN for Urban Areas",
    "abstract": "The advent of Low Power Wide Area Networks (LPWAN) has enabled the\nfeasibility of wireless sensor networks for environmental traffic sensing\nacross urban areas. In this study, we explore the usage of LoRaWAN end nodes as\ntraffic sensing sensors to offer a practical traffic management solution. The\nmonitored Received Signal Strength Indicator (RSSI) factor is reported and used\nin the gateways to assess the traffic of the environment. Our technique\nutilizes LoRaWAN as a long-range communication technology to provide a\nlargescale system. In this work, we present a method of using LoRaWAN devices\nto estimate traffic flows. LoRaWAN end devices then transmit their packets to\ndifferent gateways. Their RSSI will be affected by the number of cars present\non the roadway. We used SVM and clustering methods to classify the approximate\nnumber of cars present. This paper details our experiences with the design and\nreal implementation of this system across an area that stretches for miles in\nurban scenarios. We continuously measured and reported RSSI at different\ngateways for weeks. Results have shown that if a LoRaWAN end node is placed in\nan optimal position, up to 96% of correct environment traffic level detection\ncan be obtained. Additionally, we share the l",
    "descriptor": "\nComments: 7 pages, accepted to Emerging Topics in Wireless (EmergingWireless) in CoNEXT 2022\n",
    "authors": [
      "Hannaneh Barahouei Pasandi",
      "Asma Haghighat",
      "Azin Moradbeikie",
      "Ahmad Keshavarz",
      "Habib Rostami",
      "Sara Paiva",
      "Sergio Ivan Lopes"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.00992"
  },
  {
    "id": "arXiv:2211.00995",
    "title": "The Collaborative Business Intelligence Ontology (CBIOnt)",
    "abstract": "In the current era, many disciplines are seen devoted towards ontology\ndevelopment for their domains with the intention of creating, disseminating and\nmanaging resource descriptions of their domain knowledge into machine\nunderstandable and processable manner. Ontology construction is a difficult\ngroup activity that involves many people with the different expertise.\nGenerally, domain experts are not familiar with the ontology implementation\nenvironments and implementation experts do not have all the domain knowledge.\nWe have designed Collaborative Business Intelligence Ontology (CBIOnt) for\nBI4People project. In this paper, we present CBIOnt that is OWL 2 DL ontology\nfor the description of collaborative session between different collaborators\nworking together on the business intelligent platform. As the collaborative\nsession between various collaborators belongs to some collaborative form, phase\nand research aspect, therefore CBIOnt captures this knowledge along with the\ncollaborative session content (comments, questions, answers, etc.) so that one\ncan inference various types of information stored on ontologies when required.\nIn addition, it stores the location and temporal-spatial information about the\ncollaboration held between collaborators. We believe CBIOnt serves as a formal\nframework for dealing with the collaborative session taken place among\ncollaborators on the semantic Web.",
    "descriptor": "",
    "authors": [
      "Muhammad Fahad",
      "J\u00e9r\u00f4me Darmont",
      "C\u00e9cile Favre"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.00995"
  },
  {
    "id": "arXiv:2211.00996",
    "title": "Singing Voice Synthesis with Vibrato Modeling and Latent Energy  Representation",
    "abstract": "This paper proposes an expressive singing voice synthesis system by\nintroducing explicit vibrato modeling and latent energy representation. Vibrato\nis essential to the naturalness of synthesized sound, due to the inherent\ncharacteristics of human singing. Hence, a deep learning-based vibrato model is\nintroduced in this paper to control the vibrato's likeliness, rate, depth and\nphase in singing, where the vibrato likeliness represents the existence\nprobability of vibrato and it would help improve the singing voice's\nnaturalness. Actually, there is no annotated label about vibrato likeliness in\nexisting singing corpus. We adopt a novel vibrato likeliness labeling method to\nlabel the vibrato likeliness automatically. Meanwhile, the power spectrogram of\naudio contains rich information that can improve the expressiveness of singing.\nAn autoencoder-based latent energy bottleneck feature is proposed for\nexpressive singing voice synthesis. Experimental results on the open dataset\nNUS48E show that both the vibrato modeling and the latent energy representation\ncould significantly improve the expressiveness of singing voice. The audio\nsamples are shown in the demo website.",
    "descriptor": "",
    "authors": [
      "Yingjie Song",
      "Wei Song",
      "Wei Zhang",
      "Zhengchen Zhang",
      "Dan Zeng",
      "Zhi Liu",
      "Yang Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00996"
  },
  {
    "id": "arXiv:2211.01000",
    "title": "SoK: Play-to-Earn Projects",
    "abstract": "Play-to-earn is one of the prospective categories of decentralized\napplications. The play-to-earn projects combine blockchain technology with\nentertaining games and finance, attracting various participants. While huge\namounts of capital have been poured into these projects, the new crypto niche\nis considered controversial, and the traditional gaming industry is hesitant to\nembrace blockchain technology. In addition, there is little systematic research\non these projects. In this paper, we delineate play-to-earn projects in terms\nof economic & governance models and implementation and analyze how blockchain\ntechnology can benefit these projects by providing system robustness,\ntransparency, composability, and decentralized governance. We begin by\nidentifying the participants and characterizing the tokens, which are products\nof composability. We then summarize the roadmap and governance model to exposit\nthere is a transition from centralized governance to decentralized governance.\nWe also classify the implementation of the play-to-earn projects with different\nextents of robustness and transparency. Finally, we discuss the security &\nsocietal challenges for future research in terms of possible attacks, the\neconomics of tokens, and governance.",
    "descriptor": "",
    "authors": [
      "Jingfan Yu",
      "Mengqian Zhang",
      "Xi Chen",
      "Zhixuan Fang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01000"
  },
  {
    "id": "arXiv:2211.01004",
    "title": "Spatial-temporal recurrent reinforcement learning for autonomous ships",
    "abstract": "The paper proposes a spatial-temporal recurrent neural network architecture\nfor Deep $Q$-Networks to steer an autonomous ship. The network design allows\nhandling an arbitrary number of surrounding target ships while offering\nrobustness to partial observability. Further, a state-of-the-art collision risk\nmetric is proposed to enable an easier assessment of different situations by\nthe agent. The COLREG rules of maritime traffic are explicitly considered in\nthe design of the reward function. The final policy is validated on a custom\nset of newly created single-ship encounters called \"Around the Clock\" problems\nand the commonly chosen Imazu (1987) problems, which include 18 multi-ship\nscenarios. Additionally, the framework shows robustness when deployed\nsimultaneously in multi-agent scenarios. The proposed network architecture is\ncompatible with other deep reinforcement learning algorithms, including\nactor-critic frameworks.",
    "descriptor": "",
    "authors": [
      "Martin Waltz",
      "Ostap Okhrin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01004"
  },
  {
    "id": "arXiv:2211.01009",
    "title": "Cluster-Based Autoencoders for Volumetric Point Clouds",
    "abstract": "Autoencoders allow to reconstruct a given input from a small set of\nparameters. However, the input size is often limited due to computational\ncosts. We therefore propose a clustering and reassembling method for volumetric\npoint clouds, in order to allow high resolution data as input. We furthermore\npresent an autoencoder based on the well-known FoldingNet for volumetric point\nclouds and discuss how our approach can be utilized for blending between high\nresolution point clouds as well as for transferring a volumetric design/style\nonto a pointcloud while maintaining its shape.",
    "descriptor": "",
    "authors": [
      "Stephan Antholzer",
      "Martin Berger",
      "Tobias Hell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01009"
  },
  {
    "id": "arXiv:2211.01015",
    "title": "Self-assess Momentary Mood in Mobile Devices: a Case Study with Mature  Female Participants",
    "abstract": "Starting from the assumption that mood has a central role in domain-specific\npersuasion systems for well-being, the main goal of this study was to\ninvestigate the feasibility and acceptability of single-input methods to assess\nmomentary mood as a medium for further interventions in health-related mobile\napps destined for mature women. To this aim, we designed a very simple android\nApp providing four user interfaces, each one showing one interactive widget to\nself-assess mood. Two widgets report a hint about the momentary mood they\nrepresent; the last two do not have the hints but were previously refined\nthrough questionnaires administered to 63 women (age 45-65) in order to reduce\ntheir expressive ambiguity. Next, fifteen women (age 45-65 years) were\nrecruited to use the app for 15 days. Participants were polled about their mood\nfour times a day and data were saved in a remote database. Moreover, users were\nasked to fill out a preliminary questionnaire, at the first access to the app,\nand a feedback questionnaire at the end of the testing period. Results appear\nto prove the feasibility and acceptability of this approach to self-assess\nmomentary mood in the target population and provides some potential input\nmethods to be used in this context.",
    "descriptor": "\nComments: 6 pages, 4 figures, 1 table\n",
    "authors": [
      "Caterina Senette",
      "Maria Claudia Buzzi",
      "Maria Teresa Paratore"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.01015"
  },
  {
    "id": "arXiv:2211.01016",
    "title": "Holographic-Type Communication for Digital Twin: A Learning-based  Auction Approach",
    "abstract": "Digital Twin (DT) technologies, which aim to build digital replicas of\nphysical entities, are the key to providing efficient, concurrent simulation\nand analysis of real-world objects. In displaying DTs, Holographic-Type\nCommunication (HTC), which supports the transmission of holographic data such\nas Light Field (LF), can provide an immersive way for users to interact with\nHolographic DTs (HDT). However, it is challenging to effectively allocate\ninteractive and resource-intensive HDT services among HDT users and providers.\nThis paper integrates the paradigms of HTC and DT to form a HTC for DT system,\ndesigns a marketplace for HDT services where HDT users' and providers' prices\nare evaluated by their valuation functions, and proposes an auction-based\nmechanism to match HDT services using a learning-based Double Dutch Auction\n(DDA). Specifically, we apply DDA and train an agent acting as the auctioneer\nto adjust the auction clock dynamically using Deep Reinforcement Learning\n(DRL), aiming to achieve the best market efficiency. Simulation results\ndemonstrate that the proposed learning-based auctioneer can achieve\nnear-optimal social welfare at halved auction information exchange cost of the\nbaseline method.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "XiuYu Zhang",
      "Minrui Xu",
      "Rui Tan",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.01016"
  },
  {
    "id": "arXiv:2211.01022",
    "title": "Verifying And Interpreting Neural Networks using Finite Automata",
    "abstract": "Verifying properties and interpreting the behaviour of deep neural networks\n(DNN) is an important task given their ubiquitous use in applications,\nincluding safety-critical ones, and their blackbox nature. We propose an\nautomata-theoric approach to tackling problems arising in DNN analysis. We show\nthat the input-output behaviour of a DNN can be captured precisely by a\n(special) weak B\\\"uchi automaton of exponential size. We show how these can be\nused to address common verification and interpretation tasks like adversarial\nrobustness, minimum sufficient reasons etc. We report on a proof-of-concept\nimplementation translating DNN to automata on finite words for better\nefficiency at the cost of losing precision in analysis.",
    "descriptor": "",
    "authors": [
      "Marco S\u00e4lzer",
      "Eric Alsmann",
      "Florian Bruse",
      "Martin Lange"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01022"
  },
  {
    "id": "arXiv:2211.01025",
    "title": "DynamicLight: Dynamically Tuning Traffic Signal Duration with DRL",
    "abstract": "Deep reinforcement learning (DRL) is becoming increasingly popular in\nimplementing traffic signal control (TSC). However, most existing DRL methods\nemploy fixed control strategies, making traffic signal phase duration less\nflexible. Additionally, the trend of using more complex DRL models makes\nreal-life deployment more challenging. To address these two challenges, we\nfirstly propose a two-stage DRL framework, named DynamicLight, which uses Max\nQueue-Length to select the proper phase and employs a deep Q-learning network\nto determine the duration of the corresponding phase. Based on the design of\nDynamicLight, we also introduce two variants: (1) DynamicLight-Lite, which\naddresses the first challenge by using only 19 parameters to achieve dynamic\nphase duration settings; and (2) DynamicLight-Cycle, which tackles the second\nchallenge by actuating a set of phases in a fixed cyclical order to implement\nflexible phase duration in the respective cyclical phase structure. Numerical\nexperiments are conducted using both real-world and synthetic datasets,\ncovering four most commonly adopted traffic signal intersections in real life.\nExperimental results show that: (1) DynamicLight can learn satisfactorily on\ndetermining the phase duration and achieve a new state-of-the-art, with\nimprovement up to 6% compared to the baselines in terms of adjusted average\ntravel time; (2) DynamicLight-Lite matches or outperforms most baseline methods\nwith only 19 parameters; and (3) DynamicLight-Cycle demonstrates high\nperformance for current TSC systems without remarkable modification in an\nactual deployment. Our code is released at Github.",
    "descriptor": "\nComments: 9 pages, 5figures\n",
    "authors": [
      "Liang Zhang",
      "Qiang Wu",
      "Jun Shen",
      "Linyuan L\u00fc",
      "Bo Du",
      "Akbar Telikani",
      "Jianqing Wu",
      "Shubin Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01025"
  },
  {
    "id": "arXiv:2211.01031",
    "title": "There Are Fewer Facts Than Words: Communication With A Growing  Complexity",
    "abstract": "We present an impossibility result, called a theorem about facts and words,\nwhich pertains to a general communication system. The theorem states that the\nnumber of distinct words used in a finite text is roughly greater than the\nnumber of independent elementary persistent facts described in the same text.\nIn particular, this theorem can be related to Zipf's law, power-law scaling of\nmutual information, and power-law-tailed learning curves. The assumptions of\nthe theorem are: a finite alphabet, linear sequence of symbols, complexity that\ndoes not decrease in time, entropy rate that can be estimated, and finiteness\nof the inverse complexity rate.",
    "descriptor": "\nComments: 8 pages; accepted as a poster at InfoCog@NeurIPS2022\n",
    "authors": [
      "\u0141ukasz D\u0119bowski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.01031"
  },
  {
    "id": "arXiv:2211.01036",
    "title": "Explainable AI over the Internet of Things: Overview, State-of-the-Art  and Future Directions",
    "abstract": "Explainable Artificial Intelligence (XAI) is transforming the field of\nArtificial Intelligence (AI) by enhancing the trust of end-users in machines.\nAs the number of connected devices keeps on growing, the Internet of Things\n(IoT) market needs to be trustworthy for the end-users. However, existing\nliterature still lacks a systematic and comprehensive survey work on the use of\nXAI for IoT. To bridge this lacking, in this paper, we address the XAI\nframeworks with a focus on their characteristics and support for IoT. We\nillustrate the widely-used XAI services for IoT applications, such as security\nenhancement, Internet of Medical Things (IoMT), Industrial IoT (IIoT), and\nInternet of City Things (IoCT). We also suggest the implementation choice of\nXAI models over IoT systems in these applications with appropriate examples and\nsummarize the key inferences for future works. Moreover, we present the\ncutting-edge development in edge XAI structures and the support of\nsixth-generation (6G) communication services for IoT applications, along with\nkey inferences. In a nutshell, this paper constitutes the first holistic\ncompilation on the development of XAI-based frameworks tailored for the demands\nof future IoT use cases.",
    "descriptor": "\nComments: 29 pages, 7 figures, 2 tables. IEEE Open Journal of the Communications Society (2022)\n",
    "authors": [
      "Senthil Kumar Jagatheesaperumal",
      "Quoc-Viet Pham",
      "Rukhsana Ruby",
      "Zhaohui Yang",
      "Chunmei Xu",
      "Zhaoyang Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01036"
  },
  {
    "id": "arXiv:2211.01037",
    "title": "Deep Learning Computer Vision Algorithms for Real-time UAVs On-board  Camera Image Processing",
    "abstract": "This paper describes how advanced deep learning based computer vision\nalgorithms are applied to enable real-time on-board sensor processing for small\nUAVs. Four use cases are considered: target detection, classification and\nlocalization, road segmentation for autonomous navigation in GNSS-denied zones,\nhuman body segmentation, and human action recognition. All algorithms have been\ndeveloped using state-of-the-art image processing methods based on deep neural\nnetworks. Acquisition campaigns have been carried out to collect custom\ndatasets reflecting typical operational scenarios, where the peculiar point of\nview of a multi-rotor UAV is replicated. Algorithms architectures and trained\nmodels performances are reported, showing high levels of both accuracy and\ninference speed. Output examples and on-field videos are presented,\ndemonstrating models operation when deployed on a GPU-powered commercial\nembedded device (NVIDIA Jetson Xavier) mounted on board of a custom quad-rotor,\npaving the way to enabling high level autonomy.",
    "descriptor": "\nComments: 10 pages, 12 figures, NATO AVT-353 Research Workshop \"Artificial Intelligence in Cockpits for UAVs\", Turin, Italy, 26 April 2022\n",
    "authors": [
      "Alessandro Palmas",
      "Pietro Andronico"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01037"
  },
  {
    "id": "arXiv:2211.01048",
    "title": "Sim2Real Grasp Pose Estimation for Adaptive Robotic Applications",
    "abstract": "Adaptive robotics plays an essential role in achieving truly co-creative\ncyber physical systems. In robotic manipulation tasks, one of the biggest\nchallenges is to estimate the pose of given workpieces. Even though the recent\ndeep-learning-based models show promising results, they require an immense\ndataset for training. In this paper, we propose two vision-based, multiobject\ngrasp-pose estimation models, the MOGPE Real-Time (RT) and the MOGPE\nHigh-Precision (HP). Furthermore, a sim2real method based on domain\nrandomization to diminish the reality gap and overcome the data shortage. We\nyielded an 80% and a 96.67% success rate in a real-world robotic pick-and-place\nexperiment, with the MOGPE RT and the MOGPE HP model respectively. Our\nframework provides an industrial tool for fast data generation and model\ntraining and requires minimal domain-specific data.",
    "descriptor": "\nComments: Submitted to the 22nd World Congress of the International Federation of Automatic Control (IFAC 2023)\n",
    "authors": [
      "D\u00e1niel Horv\u00e1th",
      "Krist\u00f3f Bocsi",
      "G\u00e1bor Erd\u0151s",
      "Zolt\u00e1n Istenes"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01048"
  },
  {
    "id": "arXiv:2211.01052",
    "title": "Offline RL With Realistic Datasets: Heteroskedasticity and Support  Constraints",
    "abstract": "Offline reinforcement learning (RL) learns policies entirely from static\ndatasets, thereby avoiding the challenges associated with online data\ncollection. Practical applications of offline RL will inevitably require\nlearning from datasets where the variability of demonstrated behaviors changes\nnon-uniformly across the state space. For example, at a red light, nearly all\nhuman drivers behave similarly by stopping, but when merging onto a highway,\nsome drivers merge quickly, efficiently, and safely, while many hesitate or\nmerge dangerously. Both theoretically and empirically, we show that typical\noffline RL methods, which are based on distribution constraints fail to learn\nfrom data with such non-uniform variability, due to the requirement to stay\nclose to the behavior policy to the same extent across the state space.\nIdeally, the learned policy should be free to choose per state how closely to\nfollow the behavior policy to maximize long-term return, as long as the learned\npolicy stays within the support of the behavior policy. To instantiate this\nprinciple, we reweight the data distribution in conservative Q-learning (CQL)\nto obtain an approximate support constraint formulation. The reweighted\ndistribution is a mixture of the current policy and an additional policy\ntrained to mine poor actions that are likely under the behavior policy. Our\nmethod, CQL (ReDS), is simple, theoretically motivated, and improves\nperformance across a wide range of offline RL problems in Atari games,\nnavigation, and pixel-based manipulation.",
    "descriptor": "",
    "authors": [
      "Anikait Singh",
      "Aviral Kumar",
      "Quan Vuong",
      "Yevgen Chebotar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01052"
  },
  {
    "id": "arXiv:2211.01053",
    "title": "Fantasizing with Dual GPs in Bayesian Optimization and Active Learning",
    "abstract": "Gaussian processes (GPs) are the main surrogate functions used for sequential\nmodelling such as Bayesian Optimization and Active Learning. Their drawbacks\nare poor scaling with data and the need to run an optimization loop when using\na non-Gaussian likelihood. In this paper, we focus on `fantasizing' batch\nacquisition functions that need the ability to condition on new fantasized data\ncomputationally efficiently. By using a sparse Dual GP parameterization, we\ngain linear scaling with batch size as well as one-step updates for\nnon-Gaussian likelihoods, thus extending sparse models to greedy batch\nfantasizing acquisition functions.",
    "descriptor": "\nComments: In the 2022 NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems\n",
    "authors": [
      "Paul E. Chang",
      "Prakhar Verma",
      "ST John",
      "Victor Picheny",
      "Henry Moss",
      "Arno Solin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01053"
  },
  {
    "id": "arXiv:2211.01062",
    "title": "Polynomial Identity Testing via Evaluation of Rational Functions",
    "abstract": "We introduce a hitting set generator for Polynomial Identity Testing based on\nevaluations of low-degree univariate rational functions at abscissas associated\nwith the variables. Despite the univariate nature, we establish an equivalence\nup to rescaling with a generator introduced by Shpilka and Volkovich, which has\na similar structure but uses multivariate polynomials in the abscissas.\nWe study the power of the generator by characterizing its vanishing ideal,\ni.e., the set of polynomials that it fails to hit. Capitalizing on the\nunivariate nature, we develop a small collection of polynomials that jointly\nproduce the vanishing ideal. As corollaries, we obtain tight bounds on the\nminimum degree, sparseness, and partition class size of set-multilinearity in\nthe vanishing ideal. Inspired by an alternating algebra representation, we\ndevelop a structured deterministic membership test for the vanishing ideal. As\na proof of concept, we rederive known derandomization results based on the\ngenerator by Shpilka and Volkovich and present a new application for read-once\noblivious algebraic branching programs.",
    "descriptor": "\nComments: Appeared at ITCS 2022\n",
    "authors": [
      "Dieter van Melkebeek",
      "Andrew Morgan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.01062"
  },
  {
    "id": "arXiv:2211.01069",
    "title": "Joint Correlation Detection and Alignment of Gaussian Databases",
    "abstract": "In this work, we propose an efficient two-stage algorithm solving a joint\nproblem of correlation detection and permutation recovery between two Gaussian\ndatabases. Correlation detection is an hypothesis testing problem; under the\nnull hypothesis, the databases are independent, and under the alternate\nhypothesis, they are correlated, under an unknown row permutation. We develop\nrelatively tight bounds on the type-I and type-II error probabilities, and show\nthat the analyzed detector performs better than a recently proposed detector,\nat least for some specific parameter choices. Since the proposed detector\nrelies on a statistic, which is a sum of dependent indicator random variables,\nthen in order to bound the type-I probability of error, we develop a novel\ngraph-theoretic technique for bounding the $k$-th order moments of such\nstatistics. When the databases are accepted as correlated, the algorithm also\noutputs an estimation for the underlying row permutation. By comparing to known\nconverse results for this problem, we prove that the alignment error\nprobability converges to zero under the asymptotically lowest possible\ncorrelation coefficient.",
    "descriptor": "\nComments: 41 pages, 7 figures\n",
    "authors": [
      "Ran Tamir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.01069"
  },
  {
    "id": "arXiv:2211.01070",
    "title": "CobotTouch: AR-based Interface with Fingertip-worn Tactile Display for  Immersive Operation/Control of Collaborative Robots",
    "abstract": "Complex robotic tasks require human collaboration to benefit from their high\ndexterity. Frequent human-robot interaction is mentally demanding and\ntime-consuming. Intuitive and easy-to-use robot control interfaces reduce the\nnegative influence on workers, especially inexperienced users. In this paper,\nwe present CobotTouch, a novel intuitive robot control interface with fingertip\nhaptic feedback. The proposed interface consists of a projected Graphical User\nInterface on the robotic arm to control the position of the robot end-effector\nbased on gesture recognition, and a wearable haptic interface to deliver\ntactile feedback on the user's fingertips. We evaluated the user's perception\nof the designed tactile patterns presented by the haptic interface and the\nintuitiveness of the proposed system for robot control in a use case. The\nresults revealed a high average recognition rate of 75.25\\% for the tactile\npatterns. An average NASA Task Load Index (TLX) indicated small mental and\ntemporal demands proving a high level of the intuitiveness of CobotTouch for\ninteraction with collaborative robots.",
    "descriptor": "\nComments: 12 pages, 11 figures, Accepted paper in AsiaHaptics 2022\n",
    "authors": [
      "Sautenkov Oleg",
      "Altamirano Cabrera Miguel",
      "Rakhmatulin Viktor",
      "Tsetserukou Dzmitry"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.01070"
  },
  {
    "id": "arXiv:2211.01071",
    "title": "Gradient Knowledge Distillation for Pre-trained Language Models",
    "abstract": "Knowledge distillation (KD) is an effective framework to transfer knowledge\nfrom a large-scale teacher to a compact yet well-performing student. Previous\nKD practices for pre-trained language models mainly transfer knowledge by\naligning instance-wise outputs between the teacher and student, while\nneglecting an important knowledge source, i.e., the gradient of the teacher.\nThe gradient characterizes how the teacher responds to changes in inputs, which\nwe assume is beneficial for the student to better approximate the underlying\nmapping function of the teacher. Therefore, we propose Gradient Knowledge\nDistillation (GKD) to incorporate the gradient alignment objective into the\ndistillation process. Experimental results show that GKD outperforms previous\nKD methods regarding student performance. Further analysis shows that\nincorporating gradient knowledge makes the student behave more consistently\nwith the teacher, improving the interpretability greatly.",
    "descriptor": "\nComments: Accepted by NeurIPS ENLSP 2022 workshop(spotlight)\n",
    "authors": [
      "Lean Wang",
      "Lei Li",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01071"
  },
  {
    "id": "arXiv:2211.01077",
    "title": "Dominance of Smartphone Exposure in 5G Mobile Networks",
    "abstract": "The deployment of 5G networks is sometimes questioned due to the impact of\nElectroMagnetic Field (EMF) generated by Radio Base Station (RBS) on users. The\ngoal of this work is to analyze such issue from a novel perspective, by\ncomparing RBS EMF against exposure generated by 5G smartphones in commercial\ndeployments. The measurement of exposure from 5G is hampered by several\nimplementation aspects, such as dual connectivity between 4G and 5G, spectrum\nfragmentation, and carrier aggregation. To face such issues, we deploy a novel\nframework, called 5G-EA, tailored to the assessment of smartphone and RBS\nexposure through an innovative measurement algorithm, able to remotely control\na programmable spectrum analyzer. Results, obtained in both outdoor and indoor\nlocations, reveal that smartphone exposure (upon generation of uplink traffic)\ndominates over the RBS one. Moreover, Line-of-Sight locations experience a\nreduction of around one order of magnitude on the overall exposure compared to\nNon-Line-of-Sight ones. In addition, 5G exposure always represents a small\nshare (up to 28%) compared to 4G EMF.",
    "descriptor": "",
    "authors": [
      "Luca Chiaraviglio",
      "Chiara Lodovisi",
      "Stefania Bartoletti",
      "Ahmed Elzanaty",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01077"
  },
  {
    "id": "arXiv:2211.01079",
    "title": "Intermediate Fine-Tuning Using Imperfect Synthetic Speech for Improving  Electrolaryngeal Speech Recognition",
    "abstract": "Research on automatic speech recognition (ASR) systems for electrolaryngeal\nspeakers has been relatively unexplored due to small datasets. When training\ndata is lacking in ASR, a large-scale pretraining and fine tuning framework is\noften sufficient to achieve high recognition rates; however, in\nelectrolaryngeal speech, the domain shift between the pretraining and\nfine-tuning data is too large to overcome, limiting the maximum improvement of\nrecognition rates. To resolve this, we propose an intermediate fine-tuning step\nthat uses imperfect synthetic speech to close the domain shift gap between the\npretraining and target data. Despite the imperfect synthetic data, we show the\neffectiveness of this on electrolaryngeal speech datasets, with improvements of\n6.1% over the baseline that did not use imperfect synthetic speech. Results\nshow how the intermediate fine-tuning stage focuses on learning the high-level\ninherent features of the imperfect synthetic data rather than the low-level\nfeatures such as intelligibility.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Lester Phillip Violeta",
      "Ding Ma",
      "Wen-Chin Huang",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01079"
  },
  {
    "id": "arXiv:2211.01080",
    "title": "Spatial Reasoning for Few-Shot Object Detection",
    "abstract": "Although modern object detectors rely heavily on a significant amount of\ntraining data, humans can easily detect novel objects using a few training\nexamples. The mechanism of the human visual system is to interpret spatial\nrelationships among various objects and this process enables us to exploit\ncontextual information by considering the co-occurrence of objects. Thus, we\npropose a spatial reasoning framework that detects novel objects with only a\nfew training examples in a context. We infer geometric relatedness between\nnovel and base RoIs (Region-of-Interests) to enhance the feature representation\nof novel categories using an object detector well trained on base categories.\nWe employ a graph convolutional network as the RoIs and their relatedness are\ndefined as nodes and edges, respectively. Furthermore, we present spatial data\naugmentation to overcome the few-shot environment where all objects and\nbounding boxes in an image are resized randomly. Using the PASCAL VOC and MS\nCOCO datasets, we demonstrate that the proposed method significantly\noutperforms the state-of-the-art methods and verify its efficacy through\nextensive ablation studies.",
    "descriptor": "\nComments: Pattern Recognition, Vol.120, 2021\n",
    "authors": [
      "Geonuk Kim",
      "Hong-Gyu Jung",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01080"
  },
  {
    "id": "arXiv:2211.01085",
    "title": "Coordinated Transmit Beamforming for Multi-antenna Network Integrated  Sensing and Communication",
    "abstract": "This paper studies a multi-antenna network integrated sensing and\ncommunication (ISAC) system, in which a set of multi-antenna base stations\n(BSs) employ the coordinated transmit beamforming to serve their respectively\nassociated single-antenna communication users (CUs), and at the same time reuse\nthe reflected information signals to perform joint target detection. In\nparticular, we consider two target detection scenarios depending on the time\nsynchronization among BSs. In Scenario \\uppercase\\expandafter{\\romannumeral1},\nthese BSs are synchronized and can exploit the target-reflected signals over\nboth the direct links (from each BS to target to itself) and the cross links\n(from each BS to target to other BSs) for joint detection. In Scenario\n\\uppercase\\expandafter{\\romannumeral2}, these BSs are not synchronized and can\nonly utilize target-reflected signals over the direct links for joint\ndetection. For each scenario, we derive the detection probability under a\nspecific false alarm probability at any given target location. Based on the\nderivation, we optimize the coordinated transmit beamforming at the BSs to\nmaximize the minimum detection probability over a particular target area, while\nensuring the minimum signal-to-interference-plus-noise ratio (SINR) constraints\nat the CUs, subject to the maximum transmit power constraints at the BSs. We\nuse the semi-definite relaxation (SDR) technique to obtain highly-quality\nsolutions to the formulated problems. Numerical results show that for each\nscenario, the proposed design achieves higher detection probability than the\nbenchmark scheme based on communication design. It is also shown that the time\nsynchronization among BSs is beneficial in enhancing the detection performance\nas more reflected signal paths are exploited.",
    "descriptor": "",
    "authors": [
      "Gaoyuan Cheng",
      "Jie Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01085"
  },
  {
    "id": "arXiv:2211.01086",
    "title": "Generative Poisoning Using Random Discriminators",
    "abstract": "We introduce ShortcutGen, a new data poisoning attack that generates\nsample-dependent, error-minimizing perturbations by learning a generator. The\nkey novelty of ShortcutGen is the use of a randomly-initialized discriminator,\nwhich provides spurious shortcuts needed for generating poisons. Different from\nrecent, iterative methods, our ShortcutGen can generate perturbations with only\none forward pass in a label-free manner, and compared to the only existing\ngenerative method, DeepConfuse, our ShortcutGen is faster and simpler to train\nwhile remaining competitive. We also demonstrate that integrating a simple\naugmentation strategy can further boost the robustness of ShortcutGen against\nearly stopping, and combining augmentation and non-augmentation leads to new\nstate-of-the-art results in terms of final validation accuracy, especially in\nthe challenging, transfer scenario. Lastly, we speculate, through uncovering\nits working mechanism, that learning a more general representation space could\nallow ShortcutGen to work for unseen data.",
    "descriptor": "\nComments: 6 pages, 2 figures, 4 tables, accepted as an oral presentation at RCV (ECCV 2022 Workshop)\n",
    "authors": [
      "Dirren van Vlijmen",
      "Alex Kolmus",
      "Zhuoran Liu",
      "Zhengyu Zhao",
      "Martha Larson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01086"
  },
  {
    "id": "arXiv:2211.01087",
    "title": "DSPGAN: a GAN-based universal vocoder for high-fidelity TTS by  time-frequency domain supervision from DSP",
    "abstract": "Recent development of neural vocoders based on the generative adversarial\nneural network (GAN) has shown their advantages of generating raw waveform\nconditioned on mel-spectrogram with fast inference speed and lightweight\nnetworks. Whereas, it is still challenging to train a universal neural vocoder\nthat can synthesize high-fidelity speech from various scenarios with unseen\nspeakers, languages, and speaking styles. In this paper, we propose DSPGAN, a\nGAN-based universal vocoder for high-fidelity speech synthesis by applying the\ntime-frequency domain supervision from digital signal processing (DSP). To\neliminate the mismatch problem caused by the ground-truth spectrograms in\ntraining phase and the predicted spectrograms in inference phase, we leverage\nthe mel-spectrogram extracted from the waveform generated by a DSP module,\nrather than the predicted mel-spectrogram from the Text-to-Speech (TTS)\nacoustic model, as the time-frequency domain supervision to the GAN-based\nvocoder. We also utilize sine excitation as the time-domain supervision to\nimprove the harmonic modeling and eliminate various artifacts of the GAN-based\nvocoder. Experimental results show that DSPGAN significantly outperforms the\ncompared approaches and can generate high-fidelity speech based on diverse data\nin TTS.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Kun Song",
      "Yongmao Zhang",
      "Yi Lei",
      "Jian Cong",
      "Hanzhao Li",
      "Lei Xie",
      "Gang He",
      "Jinfeng Bai"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01087"
  },
  {
    "id": "arXiv:2211.01089",
    "title": "Transformer-based encoder-encoder architecture for Spoken Term Detection",
    "abstract": "The paper presents a method for spoken term detection based on the\nTransformer architecture. We propose the encoder-encoder architecture employing\ntwo BERT-like encoders with additional modifications, including convolutional\nand upsampling layers, attention masking, and shared parameters. The encoders\nproject a recognized hypothesis and a searched term into a shared embedding\nspace, where the score of the putative hit is computed using the calibrated dot\nproduct. In the experiments, we used the Wav2Vec 2.0 speech recognizer, and the\nproposed system outperformed a baseline method based on deep LSTMs on the\nEnglish and Czech STD datasets based on USC Shoah Foundation Visual History\nArchive (MALACH).",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Jan \u0160vec",
      "Lubo\u0161 \u0160m\u00eddl",
      "Jan Lehe\u010dka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01089"
  },
  {
    "id": "arXiv:2211.01093",
    "title": "Improving transferability of 3D adversarial attacks with scale and shear  transformations",
    "abstract": "Previous work has shown that 3D point cloud classifiers can be vulnerable to\nadversarial examples. However, most of the existing methods are aimed at\nwhite-box attacks, where the parameters and other information of the\nclassifiers are known in the attack, which is unrealistic for real-world\napplications. In order to improve the attack performance of the black-box\nclassifiers, the research community generally uses the transfer-based black-box\nattack. However, the transferability of current 3D attacks is still relatively\nlow. To this end, this paper proposes Scale and Shear (SS) Attack to generate\n3D adversarial examples with strong transferability. Specifically, we randomly\nscale or shear the input point cloud, so that the attack will not overfit the\nwhite-box model, thereby improving the transferability of the attack. Extensive\nexperiments show that the SS attack proposed in this paper can be seamlessly\ncombined with the existing state-of-the-art (SOTA) 3D point cloud attack\nmethods to form more powerful attack methods, and the SS attack improves the\ntransferability over 3.6 times compare to the baseline. Moreover, while\nsubstantially outperforming the baseline methods, the SS attack achieves SOTA\ntransferability under various defenses. Our code will be available online at\nhttps://github.com/cuge1995/SS-attack",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Jinali Zhang",
      "Yinpeng Dong",
      "Jun Zhu",
      "Jihong Zhu",
      "Minchi Kuang",
      "Xiaming Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.01093"
  },
  {
    "id": "arXiv:2211.01095",
    "title": "DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic  Models",
    "abstract": "Diffusion probabilistic models (DPMs) have achieved impressive success in\nhigh-resolution image synthesis, especially in recent large-scale text-to-image\ngeneration applications. An essential technique for improving the sample\nquality of DPMs is guided sampling, which usually needs a large guidance scale\nto obtain the best sample quality. The commonly-used fast sampler for guided\nsampling is DDIM, a first-order diffusion ODE solver that generally needs 100\nto 250 steps for high-quality samples. Although recent works propose dedicated\nhigh-order solvers and achieve a further speedup for sampling without guidance,\ntheir effectiveness for guided sampling has not been well-tested before. In\nthis work, we demonstrate that previous high-order fast samplers suffer from\ninstability issues, and they even become slower than DDIM when the guidance\nscale grows large. To further speed up guided sampling, we propose\nDPM-Solver++, a high-order solver for the guided sampling of DPMs. DPM-Solver++\nsolves the diffusion ODE with the data prediction model and adopts thresholding\nmethods to keep the solution matches training data distribution. We further\npropose a multistep variant of DPM-Solver++ to address the instability issue by\nreducing the effective step size. Experiments show that DPM-Solver++ can\ngenerate high-quality samples within only 15 to 20 steps for guided sampling by\npixel-space and latent-space DPMs.",
    "descriptor": "",
    "authors": [
      "Cheng Lu",
      "Yuhao Zhou",
      "Fan Bao",
      "Jianfei Chen",
      "Chongxuan Li",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01095"
  },
  {
    "id": "arXiv:2211.01096",
    "title": "Recovering Sign Bits of DCT Coefficients in Digital Images as an  Optimization Problem",
    "abstract": "Recovering unknown, missing, damaged, distorted or lost information in DCT\ncoefficients is a common task in multiple applications of digital image\nprocessing, including image compression, selective image encryption, and image\ncommunications. This paper investigates recovery of a special type of\ninformation in DCT coefficients of digital images: sign bits. This problem can\nbe modelled as a mixed integer linear programming (MILP) problem, which is\nNP-hard in general. To efficiently solve the problem, we propose two\napproximation methods: 1) a relaxation-based method that convert the MILP\nproblem to a linear programming (LP) problem; 2) a divide-and-conquer method\nwhich splits the target image into sufficiently small regions, each of which\ncan be more efficiently solved as an MILP problem, and then conducts a global\noptimization phase as a smaller MILP problem or an LP problem to maximize\nsmoothness across different regions. To the best of our knowledge, we are the\nfirst who considered how to use global optimization to recover sign bits of DCT\ncoefficients. We considered how the proposed methods can be applied to\nJPEG-encoded images and conducted extensive experiments to validate the\nperformances of our proposed methods. The experimental results showed that the\nproposed methods worked well, especially when the number of unknown sign bits\nper DCT block is not too large. Compared with other existing methods, which are\nall based on simple error-concealment strategies, our proposed methods\noutperformed them with a substantial margin, both according to objective\nquality metrics (PSNR and SSIM) and also our subjective evaluation. Our work\nhas a number of profound implications, e.g., more sign bits can be discarded to\ndevelop more efficient image compression methods, and image encryption methods\nbased on sign bit encryption can be less secure than we previously understood.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Ruiyuan Lin",
      "Sheng Liu",
      "Jun Jiang",
      "Shujun Li",
      "Chengqing Li",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.01096"
  },
  {
    "id": "arXiv:2211.01097",
    "title": "Set Selection under Explorable Stochastic Uncertainty via Covering  Techniques",
    "abstract": "Given subsets of uncertain values, we study the problem of identifying the\nsubset of minimum total value (sum of the uncertain values) by querying as few\nvalues as possible. This set selection problem falls into the field of\nexplorable uncertainty and is of intrinsic importance therein as it implies\nstrong adversarial lower bounds for a wide range of interesting combinatorial\nproblems such as knapsack and matchings. We consider a stochastic problem\nvariant and give algorithms that, in expectation, improve upon these\nadversarial lower bounds. The key to our results is to prove a strong\nstructural connection to a seemingly unrelated covering problem with\nuncertainty in the constraints via a linear programming formulation. We exploit\nthis connection to derive an algorithmic framework that can be used to solve\nboth problems under uncertainty, obtaining nearly tight bounds on the\ncompetitive ratio. This is the first non-trivial stochastic result concerning\nthe sum of unknown values without further structure known for the set. Further,\nwe handle for the first time uncertainty in the constraints in a value-query\nmodel. With our novel methods, we lay the foundations for solving more general\nproblems in the area of explorable uncertainty.",
    "descriptor": "",
    "authors": [
      "Nicole Megow",
      "Jens Schl\u00f6ter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.01097"
  },
  {
    "id": "arXiv:2211.01098",
    "title": "Semantic SuperPoint: A Deep Semantic Descriptor",
    "abstract": "Several SLAM methods benefit from the use of semantic information. Most\nintegrate photometric methods with high-level semantics such as object\ndetection and semantic segmentation. We propose that adding a semantic\nsegmentation decoder in a shared encoder architecture would help the descriptor\ndecoder learn semantic information, improving the feature extractor. This would\nbe a more robust approach than only using high-level semantic information since\nit would be intrinsically learned in the descriptor and would not depend on the\nfinal quality of the semantic prediction. To add this information, we take\nadvantage of multi-task learning methods to improve accuracy and balance the\nperformance of each task. The proposed models are evaluated according to\ndetection and matching metrics on the HPatches dataset. The results show that\nthe Semantic SuperPoint model performs better than the baseline one.",
    "descriptor": "\nComments: Paper accepted at the 19th IEEE Latin American Robotics Symposium - LARS 2022\n",
    "authors": [
      "Gabriel S. Gama",
      "N\u00edcolas S. Rosa",
      "Valdir Grassi Jr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01098"
  },
  {
    "id": "arXiv:2211.01100",
    "title": "Nonparametric Involutive Markov Chain Monte Carlo",
    "abstract": "A challenging problem in probabilistic programming is to develop inference\nalgorithms that work for arbitrary programs in a universal probabilistic\nprogramming language (PPL). We present the nonparametric involutive Markov\nchain Monte Carlo (NP-iMCMC) algorithm as a method for constructing MCMC\ninference algorithms for nonparametric models expressible in universal PPLs.\nBuilding on the unifying involutive MCMC framework, and by providing a general\nprocedure for driving state movement between dimensions, we show that NP-iMCMC\ncan generalise numerous existing iMCMC algorithms to work on nonparametric\nmodels. We prove the correctness of the NP-iMCMC sampler. Our empirical study\nshows that the existing strengths of several iMCMC algorithms carry over to\ntheir nonparametric extensions. Applying our method to the recently proposed\nNonparametric HMC, an instance of (Multiple Step) NP-iMCMC, we have constructed\nseveral nonparametric extensions (all of which new) that exhibit significant\nperformance improvements.",
    "descriptor": "\nComments: Updated plots (after fixing minor bugs in the implementation) compared to the published version in Proceedings of the 39th International Conference on Machine Learning, PMLR 162:14802-14859, 2022. The conclusions of the version published at ICML 2022 are not affected\n",
    "authors": [
      "Carol Mak",
      "Fabian Zaiser",
      "Luke Ong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01100"
  },
  {
    "id": "arXiv:2211.01102",
    "title": "Proceedings of the Fourth International Conference on Applied Category  Theory",
    "abstract": "The Fourth International Conference on Applied Category Theory took place at\nthe Computer Laboratory of the University of Cambridge on 12--16 July 2021. It\nwas a hybrid event, with physical attendees present in Cambridge and other\nparticipants taking part online. All the talks were recorded and the videos\nhave been posted online, links to which can be found on the conference website\n(https://www.cl.cam.ac.uk/events/act2021/).\nContinuing the trend in the previous meetings of ACT, the contributions to\nACT 2021 ranged from pure to applied and represented a great variety of\ncategorical techniques and application topics, including: graphical calculi;\nlenses; differential categories; categorical probability theory; machine\nlearning; game theory; cybernetics; natural language semantics and processing;\ncryptography; and finite model theory.\nThis proceedings volume contains about half of the papers that were presented\nas talks at ACT 2021. This selection is a reflection of the authors' choice as\nto whether to publish their papers in this volume or elsewhere.",
    "descriptor": "",
    "authors": [
      "Kohei Kishida"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.01102"
  },
  {
    "id": "arXiv:2211.01104",
    "title": "A digital business ecosystem maturity model for personal service firms",
    "abstract": "Personal services can be found in sectors such as education, retail,\nhospitality, and craftsmanship. As of today, personal service firms lack the\nknow-how and experience on how to implement processes and practices to\neffectively build digital business ecosystems. This becomes an obstacle for\nthese kinds of firms to overcome the challenges of todays digital age. Based on\nthe guidelines of Design Science Research (DSR), we address this gap by\nproposing a maturity model, which offers specific guidance for this sector to\nbe able to achieve the transition from analog to digital. The design of the\nmodel is grounded in a systematic literature review, semi-structured\ninterviews, and a validation test involving company representatives from the\nfield of personal services, business ecosystems, and digitalization. Results\nrevealed a series of dimensions, capabilities, and maturity stages indicating\nan evolutionary path towards digital maturity for personal service firms. Thus,\nleading them to achieve a digital business ecosystem.",
    "descriptor": "\nComments: This is a draft chapter. The final version is available in Handbook on Digital Business Ecosystems edited by Sabine Baumann, published in 2022, Edward Elgar Publishing Ltd this https URL\n",
    "authors": [
      "Ricardo Guerrero",
      "Christoph Lattemann",
      "Simon Michalke",
      "Dominik Siemon"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.01104"
  },
  {
    "id": "arXiv:2211.01105",
    "title": "Road Markings Segmentation from LIDAR Point Clouds using Reflectivity  Information",
    "abstract": "Lane detection algorithms are crucial for the development of autonomous\nvehicles technologies. The more extended approach is to use cameras as sensors.\nHowever, LIDAR sensors can cope with weather and light conditions that cameras\ncan not. In this paper, we introduce a method to extract road markings from the\nreflectivity data of a 64-layers LIDAR sensor. First, a plane segmentation\nmethod along with region grow clustering was used to extract the road plane.\nThen we applied an adaptive thresholding based on Otsu s method and finally, we\nfitted line models to filter out the remaining outliers. The algorithm was\ntested on a test track at 60km/h and a highway at 100km/h. Results showed the\nalgorithm was reliable and precise. There was a clear improvement when using\nreflectivity data in comparison to the use of the raw intensity data both of\nthem provided by the LIDAR sensor.",
    "descriptor": "",
    "authors": [
      "Novel Certad",
      "Walter Morales-Alvarez",
      "Cristina Olaverri-Monreal"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01105"
  },
  {
    "id": "arXiv:2211.01107",
    "title": "Deep Reinforcement Learning for Power Control in Next-Generation WiFi  Network Systems",
    "abstract": "This paper presents a deep reinforcement learning (DRL) solution for power\ncontrol in wireless communications, describes its embedded implementation with\nWiFi transceivers for a WiFi network system, and evaluates the performance with\nhigh-fidelity emulation tests. In a multi-hop wireless network, each mobile\nnode measures its link quality and signal strength, and controls its transmit\npower. As a model-free solution, reinforcement learning allows nodes to adapt\ntheir actions by observing the states and maximize their cumulative rewards\nover time. For each node, the state consists of transmit power, link quality\nand signal strength; the action adjusts the transmit power; and the reward\ncombines energy efficiency (throughput normalized by energy consumption) and\npenalty of changing the transmit power. As the state space is large, Q-learning\nis hard to implement on embedded platforms with limited memory and processing\npower. By approximating the Q-values with a DQN, DRL is implemented for the\nembedded platform of each node combining an ARM processor and a WiFi\ntransceiver for 802.11n. Controllable and repeatable emulation tests are\nperformed by inducing realistic channel effects on RF signals. Performance\ncomparison with benchmark schemes of fixed and myopic power allocations shows\nthat power control with DRL provides major improvements to energy efficiency\nand throughput in WiFi network systems.",
    "descriptor": "\nComments: 5 pages, 6 figures, 1 table\n",
    "authors": [
      "Ziad El Jamous",
      "Kemal Davaslioglu",
      "Yalin E. Sagduyu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01107"
  },
  {
    "id": "arXiv:2211.01109",
    "title": "The Impostor Among US(B): Off-Path Injection Attacks on USB  Communications",
    "abstract": "USB is the most prevalent peripheral interface in modern computer systems and\nits inherent insecurities make it an appealing attack vector. A well-known\nlimitation of USB is that traffic is not encrypted. This allows on-path\nadversaries to trivially perform man-in-the-middle attacks. Off-path attacks\nthat compromise the confidentiality of communications have also been shown to\nbe possible. However, so far no off-path attacks that breach USB communications\nintegrity have been demonstrated.\nIn this work we show that the integrity of USB communications is not\nguaranteed even against off-path attackers.Specifically, we design and build\nmalicious devices that, even when placed outside of the path between a victim\ndevice and the host, can inject data to that path. Using our developed\ninjectors we can falsify the provenance of data input as interpreted by a host\ncomputer system. By injecting on behalf of trusted victim devices we can\ncircumvent any software-based authorisation policy defences that computer\nsystems employ against common USB attacks. We demonstrate two concrete attacks.\nThe first injects keystrokes allowing an attacker to execute commands. The\nsecond demonstrates file-contents replacement including during system install\nfrom a USB disk. We test the attacks on 29 USB 2.0 and USB 3.x hubs and find 14\nof them to be vulnerable.",
    "descriptor": "",
    "authors": [
      "Robert Dumitru",
      "Andrew Wabnitz",
      "Daniel Genkin",
      "Yuval Yarom"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01109"
  },
  {
    "id": "arXiv:2211.01110",
    "title": "AU-PD: An Arbitrary-size and Uniform Downsampling Framework for Point  Clouds",
    "abstract": "Point cloud downsampling is a crucial pre-processing operation to downsample\nthe points in the point cloud in order to reduce computational cost, and\ncommunication load, to name a few. Recent research on point cloud downsampling\nhas achieved great success which concentrates on learning to sample in a\ntask-aware way. However, existing learnable samplers can not perform\narbitrary-size sampling directly. Moreover, their sampled results always\ncomprise many overlapping points. In this paper, we introduce the AU-PD, a\nnovel task-aware sampling framework that directly downsamples point cloud to\nany smaller size based on a sample-to-refine strategy. Given a specified\narbitrary size, we first perform task-agnostic pre-sampling to sample the input\npoint cloud. Then, we refine the pre-sampled set to make it task-aware, driven\nby downstream task losses. The refinement is realized by adding each\npre-sampled point with a small offset predicted by point-wise multi-layer\nperceptrons (MLPs). In this way, the sampled set remains almost unchanged from\nthe original in distribution, and therefore contains fewer overlapping cases.\nWith the attention mechanism and proper training scheme, the framework learns\nto adaptively refine the pre-sampled set of different sizes. We evaluate\nsampled results for classification and registration tasks, respectively. The\nproposed AU-PD gets competitive downstream performance with the\nstate-of-the-art method while being more flexible and containing fewer\noverlapping points in the sampled set. The source code will be publicly\navailable at https://zhiyongsu.github.io/Project/AUPD.html.",
    "descriptor": "",
    "authors": [
      "Peng Zhang",
      "Ruoyin Xie",
      "Jinsheng Sun",
      "Weiqing Li",
      "Zhiyong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.01110"
  },
  {
    "id": "arXiv:2211.01112",
    "title": "a-RNA: Adversarial Radio Noise Attack to Fool Radar-based Environment  Perception Systems",
    "abstract": "Due to their robustness to degraded capturing conditions, radars are widely\nused for environment perception, which is a critical task in applications like\nautonomous vehicles. More specifically, Ultra-Wide Band (UWB) radars are\nparticularly efficient for short range settings as they carry rich information\non the environment. Recent UWB-based systems rely on Machine Learning (ML) to\nexploit the rich signature of these sensors. However, ML classifiers are\nsusceptible to adversarial examples, which are created from raw data to fool\nthe classifier such that it assigns the input to the wrong class. These attacks\nrepresent a serious threat to systems integrity, especially for safety-critical\napplications. In this work, we present a new adversarial attack on UWB radars\nin which an adversary injects adversarial radio noise in the wireless channel\nto cause an obstacle recognition failure. First, based on signals collected in\nreal-life environment, we show that conventional attacks fail to generate\nrobust noise under realistic conditions. We propose a-RNA, i.e., Adversarial\nRadio Noise Attack to overcome these issues. Specifically, a-RNA generates an\nadversarial noise that is efficient without synchronization between the input\nsignal and the noise. Moreover, a-RNA generated noise is, by-design, robust\nagainst pre-processing countermeasures such as filtering-based defenses.\nMoreover, in addition to the undetectability objective by limiting the noise\nmagnitude budget, a-RNA is also efficient in the presence of sophisticated\ndefenses in the spectral domain by introducing a frequency budget. We believe\nthis work should alert about potentially critical implementations of\nadversarial attacks on radar systems that should be taken seriously.",
    "descriptor": "",
    "authors": [
      "Amira Guesmi",
      "Ihsen Alouani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01112"
  },
  {
    "id": "arXiv:2211.01113",
    "title": "Implementation of Road Safety Perception in Autonomous Vehicles in a  Lane Change Scenario",
    "abstract": "Understanding human driving behavior is crucial to develop autonomous\nvehicles' algorithms. However, most low level automation, such as the one in\nadvanced driving assistance systems (ADAS), is based on objective safety\nmeasures, which are not always aligned with what the drivers perceive as safe\nand their correspondent driving behavior. Finding the bridge between the\nsubjective perception and objective safety measures has been analyzed in this\npaper focusing specifically on lane-change scenarios. Results showed\nstatistically significant differences between what is perceived as safe by\ndrivers and objective metrics depending on the specific maneuver and location\nof drivers.",
    "descriptor": "",
    "authors": [
      "Enrico Del Re",
      "Cristina Olaverri-Monreal"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01113"
  },
  {
    "id": "arXiv:2211.01120",
    "title": "Variational Hierarchical Mixtures for Learning Probabilistic Inverse  Dynamics",
    "abstract": "Well-calibrated probabilistic regression models are a crucial learning\ncomponent in robotics applications as datasets grow rapidly and tasks become\nmore complex. Classical regression models are usually either probabilistic\nkernel machines with a flexible structure that does not scale gracefully with\ndata or deterministic and vastly scalable automata, albeit with a restrictive\nparametric form and poor regularization. In this paper, we consider a\nprobabilistic hierarchical modeling paradigm that combines the benefits of both\nworlds to deliver computationally efficient representations with inherent\ncomplexity regularization. The presented approaches are probabilistic\ninterpretations of local regression techniques that approximate nonlinear\nfunctions through a set of local linear or polynomial units. Importantly, we\nrely on principles from Bayesian nonparametrics to formulate flexible models\nthat adapt their complexity to the data and can potentially encompass an\ninfinite number of components. We derive two efficient variational inference\ntechniques to learn these representations and highlight the advantages of\nhierarchical infinite local regression models, such as dealing with non-smooth\nfunctions, mitigating catastrophic forgetting, and enabling parameter sharing\nand fast predictions. Finally, we validate this approach on a set of large\ninverse dynamics datasets and test the learned models in real-world control\nscenarios.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2011.05217\n",
    "authors": [
      "Hany Abdulsamad",
      "Peter Nickl",
      "Pascal Klink",
      "Jan Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01120"
  },
  {
    "id": "arXiv:2211.01122",
    "title": "Fast Adaptive Federated Bilevel Optimization",
    "abstract": "Bilevel optimization has been widely applied to many machine learning tasks\nsuch as meta learning, hyperparameter learning and policy optimization.\nAlthough many optimization algorithms recently have been developed, few\nadaptive algorithm focuses on the bilevel problems under the distributed\nsetting. It is well known that the adaptive gradient methods show superior\nperformances on both distributed and non-distributed optimization. In the\npaper, thus, we propose an efficient adaptive federated bilevel optimization\nalgorithm (i.e.,AdaFBiO) to solve the distributed bilevel optimization\nproblems, where the objective function of Upper-Level (UL) problem is possibly\nnonconvex, and that of Lower-Level (LL) problem is strongly convex.\nSpecifically, our AdaFBiO algorithm builds on the momentum-based variance\nreduced technique and local-SGD to obtain the best known sample and\ncommunication complexities simultaneously. In particular, our AdaFBiO algorithm\nuses the unified adaptive matrices to flexibly incorporate various adaptive\nlearning rates to update variables in both UL and LL problems. Moreover, we\nprovide a convergence analysis framework for our AdaFBiO algorithm, and prove\nthat it reaches the sample complexity of $\\tilde{O}(\\epsilon^{-3})$ with\ncommunication complexity of $\\tilde{O}(\\epsilon^{-2})$ to find\n$\\epsilon$-stationary point. Experimental results on federated\nhyper-representation learning and federated data hyper-cleaning tasks verify\nefficiency of our algorithm.",
    "descriptor": "\nComments: 44 pages. arXiv admin note: text overlap with arXiv:2106.11396\n",
    "authors": [
      "Feihu Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.01122"
  },
  {
    "id": "arXiv:2211.01138",
    "title": "Local Differentially Private Frequency Estimation based on Learned  Sketches",
    "abstract": "Sketches are widely used for frequency estimation of data with a large\ndomain. However, sketches-based frequency estimation faces more challenges when\nconsidering privacy. Local differential privacy (LDP) is a solution to\nfrequency estimation on sensitive data while preserving the privacy. LDP\nenables each user to perturb its data on the client-side to protect the\nprivacy, but it also introduces errors to the frequency estimations. The hash\ncollisions in the sketches make the estimations for low-frequent items even\nworse. In this paper, we propose a two-phase frequency estimation framework for\ndata with a large domain based on an LDP learned sketch, which separates the\nhigh-frequent and low-frequent items to avoid the errors caused by hash\ncollisions. We theoretically proved that the proposed method satisfies LDP and\nit is more accurate than the state-of-the-art frequency estimation methods\nincluding Apple-CMS, Apple-HCMS and FLH. The experimental results verify the\nperformance of our method.",
    "descriptor": "",
    "authors": [
      "Meifan Zhang",
      "Sixin Lin",
      "Lihua Yin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.01138"
  },
  {
    "id": "arXiv:2211.01141",
    "title": "User-Entity Differential Privacy in Learning Natural Language Models",
    "abstract": "In this paper, we introduce a novel concept of user-entity differential\nprivacy (UeDP) to provide formal privacy protection simultaneously to both\nsensitive entities in textual data and data owners in learning natural language\nmodels (NLMs). To preserve UeDP, we developed a novel algorithm, called\nUeDP-Alg, optimizing the trade-off between privacy loss and model utility with\na tight sensitivity bound derived from seamlessly combining user and sensitive\nentity sampling processes. An extensive theoretical analysis and evaluation\nshow that our UeDP-Alg outperforms baseline approaches in model utility under\nthe same privacy budget consumption on several NLM tasks, using benchmark\ndatasets.",
    "descriptor": "\nComments: Accepted at IEEE BigData 2022\n",
    "authors": [
      "Phung Lai",
      "NhatHai Phan",
      "Tong Sun",
      "Rajiv Jain",
      "Franck Dernoncourt",
      "Jiuxiang Gu",
      "Nikolaos Barmpalios"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01141"
  },
  {
    "id": "arXiv:2211.01142",
    "title": "OPA-3D: Occlusion-Aware Pixel-Wise Aggregation for Monocular 3D Object  Detection",
    "abstract": "Despite monocular 3D object detection having recently made a significant leap\nforward thanks to the use of pre-trained depth estimators for pseudo-LiDAR\nrecovery, such two-stage methods typically suffer from overfitting and are\nincapable of explicitly encapsulating the geometric relation between depth and\nobject bounding box. To overcome this limitation, we instead propose OPA-3D, a\nsingle-stage, end-to-end, Occlusion-Aware Pixel-Wise Aggregation network that\nto jointly estimate dense scene depth with depth-bounding box residuals and\nobject bounding boxes, allowing a two-stream detection of 3D objects, leading\nto significantly more robust detections. Thereby, the geometry stream denoted\nas the Geometry Stream, combines visible depth and depth-bounding box residuals\nto recover the object bounding box via explicit occlusion-aware optimization.\nIn addition, a bounding box based geometry projection scheme is employed in an\neffort to enhance distance perception. The second stream, named as the Context\nStream, directly regresses 3D object location and size. This novel two-stream\nrepresentation further enables us to enforce cross-stream consistency terms\nwhich aligns the outputs of both streams, improving the overall performance.\nExtensive experiments on the public benchmark demonstrate that OPA-3D\noutperforms state-of-the-art methods on the main Car category, whilst keeping a\nreal-time inference speed. We plan to release all codes and trained models\nsoon.",
    "descriptor": "",
    "authors": [
      "Yongzhi Su",
      "Yan Di",
      "Fabian Manhardt",
      "Guangyao Zhai",
      "Jason Rambach",
      "Benjamin Busam",
      "Didier Stricker",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01142"
  },
  {
    "id": "arXiv:2211.01143",
    "title": "Proof of User Similarity: the Spatial Measurer of Blockchain",
    "abstract": "Although proof of work (PoW) consensus dominates the current blockchain-based\nsystems mostly, it has always been criticized for the uneconomic brute-force\ncalculation. As alternatives, energy-conservation and energy-recycling\nmechanisms heaved in sight. In this paper, we propose proof of user similarity\n(PoUS), a distinct energy-recycling consensus mechanism, harnessing the\nvaluable computing power to calculate the similarities of users, and enact the\ncalculation results into the packing rule. However, the expensive calculation\nrequired in PoUS challenges miners in participating, and may induce plagiarism\nand lying risks. To resolve these issues, PoUS embraces the best-effort schema\nby allowing miners to compute partially. Besides, a voting mechanism based on\nthe two-parties computation and Bayesian truth serum is proposed to guarantee\nprivacy-preserved voting and truthful reports. Noticeably, PoUS distinguishes\nitself in recycling the computing power back to blockchain since it turns the\nresource wastage to facilitate refined cohort analysis of users, serving as the\nspatial measurer and enabling a searchable blockchain. We build a prototype of\nPoUS and compare its performance with PoW. The results show that PoUS\noutperforms PoW in achieving an average TPS improvement of 24.01% and an\naverage confirmation latency reduction of 43.64%. Besides, PoUS functions well\nin mirroring the spatial information of users, with negligible computation time\nand communication cost.",
    "descriptor": "\nComments: 12 pages,10 figures\n",
    "authors": [
      "Shengling Wang",
      "Lina Shi",
      "Hongwei Shi",
      "Yifang Zhang",
      "Qin Hu",
      "Xiuzhen Cheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01143"
  },
  {
    "id": "arXiv:2211.01144",
    "title": "UniASM: Binary Code Similarity Detection without Fine-tuning",
    "abstract": "Binary code similarity detection (BCSD) is widely used in various binary\nanalysis tasks such as vulnerability search, malware detection, clone\ndetection, and patch analysis. Recent studies have shown that the\nlearning-based binary code embedding models perform better than the traditional\nfeature-based approaches. In this paper, we proposed a novel transformer-based\nbinary code embedding model, named UniASM, to learn representations of the\nbinary functions. We designed two new training tasks to make the spatial\ndistribution of the generated vectors more uniform, which can be used directly\nin BCSD without any fine-tuning. In addition, we proposed a new tokenization\napproach for binary functions, increasing the token's semantic information\nwhile mitigating the out-of-vocabulary (OOV) problem. The experimental results\nshow that UniASM outperforms state-of-the-art (SOTA) approaches on the\nevaluation dataset. We achieved the average scores of recall@1 on\ncross-compilers, cross-optimization-levels and cross-obfuscations are 0.72,\n0.63, and 0.77, which is higher than existing SOTA baselines. In a real-world\ntask of known vulnerability searching, UniASM outperforms all the current\nbaselines.",
    "descriptor": "",
    "authors": [
      "Yeming Gu",
      "Hui Shu",
      "Fan Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.01144"
  },
  {
    "id": "arXiv:2211.01145",
    "title": "Safety-centric and Smart Outdoor Workplace: A New Research Direction and  Its Technical Challenges",
    "abstract": "Despite the fact that outside is becoming the frontier of indoor workplaces,\na large amount of real-world work like road construction has to be done by\noutdoor human activities in open areas. Given the promise of the smart\nworkplace in various aspects including productivity and safety, we decided to\nemploy smart workplace technologies for a collaborative outdoor project both to\nimprove the work efficiency and to reduce the worker injuries. Nevertheless,\nour trials on smart workplace implementation have encountered a few problems\nranging from the theoretical confusion among different stakeholders, to the\ntechnical difficulties in extending underground devices' lifespan. This\ntriggers our rethinking of and discussions about \"smart workplace\". Eventually,\nconsidering the unique characteristics of outdoor work (e.g., more\nsophisticated workflows and more safety-related situations than office work),\nwe argue that \"safety-centric and smart outdoor workplace\" deserves dedicated\nresearch attentions and efforts under the umbrella discipline of smart\nenvironment. In addition, the identified technical challenges can in turn drive\ndifferent research dimensions of such a distinguishing topic.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Zheng Li",
      "Mauricio Pradena Miquel",
      "Pedro Pinacho-Davidson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01145"
  },
  {
    "id": "arXiv:2211.01146",
    "title": "DynamicISP: Dynamically Controlled Image Signal Processor for Image  Recognition",
    "abstract": "Image signal processor (ISP) plays an important role not only for human\nperceptual quality but also for computer vision. In most cases, experts resort\nto manual tuning of many parameters in the ISPs for perceptual quality. It\nfailed in sub-optimal, especially for computer vision. Aiming to improve ISPs,\ntwo approaches have been actively proposed; tuning the parameters with machine\nlearning, or constructing an ISP with DNN. The former is lightweight but lacks\nexpressive powers. The latter has expressive powers but it was too heavy to\ncalculate on edge devices. To this end, we propose DynamicISP, which consists\nof traditional simple ISP functions but their parameters are controlled\ndynamically per image according to what the downstream image recognition model\nfelt to the previous frame. Our proposed method successfully controlled\nparameters of multiple ISP functions and got state-of-the-art accuracy with a\nsmall computational cost.",
    "descriptor": "",
    "authors": [
      "Masakazu Yoshimura",
      "Junji Otsuka",
      "Atsushi Irie",
      "Takeshi Ohashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01146"
  },
  {
    "id": "arXiv:2211.01147",
    "title": "An Easy-to-use and Robust Approach for the Differentially Private  De-Identification of Clinical Textual Documents",
    "abstract": "Unstructured textual data is at the heart of healthcare systems. For obvious\nprivacy reasons, these documents are not accessible to researchers as long as\nthey contain personally identifiable information. One way to share this data\nwhile respecting the legislative framework (notably GDPR or HIPAA) is, within\nthe medical structures, to de-identify it, i.e. to detect the personal\ninformation of a person through a Named Entity Recognition (NER) system and\nthen replacing it to make it very difficult to associate the document with the\nperson. The challenge is having reliable NER and substitution tools without\ncompromising confidentiality and consistency in the document. Most of the\nconducted research focuses on English medical documents with coarse\nsubstitutions by not benefiting from advances in privacy. This paper shows how\nan efficient and differentially private de-identification approach can be\nachieved by strengthening the less robust de-identification method and by\nadapting state-of-the-art differentially private mechanisms for substitution\npurposes. The result is an approach for de-identifying clinical documents in\nFrench language, but also generalizable to other languages and whose robustness\nis mathematically proven.",
    "descriptor": "",
    "authors": [
      "Yakini Tchouka",
      "Jean-Fran\u00e7ois Couchot",
      "David Laiymani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01147"
  },
  {
    "id": "arXiv:2211.01152",
    "title": "New Tradeoffs for Decremental Approximate All-Pairs Shortest Paths",
    "abstract": "We provide new tradeoffs between approximation and running time for the\ndecremental all-pairs shortest paths (APSP) problem. For undirected graphs with\n$m$ edges and $n$ nodes undergoing edge deletions, we provide two new\napproximate decremental APSP algorithms, one for weighted and one for\nunweighted graphs. Our first result is an algorithm that supports $(2+\n\\epsilon)$-approximate all-pairs constant-time distance queries with total\nupdate time $\\tilde{O}(m^{1/2}n^{3/2})$ when $m= O(n^{5/3})$ (and $m= n^{1+c}$\nfor any constant $c >0$), or $\\tilde{O}(mn^{2/3})$ when $m = \\Omega(n^{5/3})$.\nPrior to our work the fastest algorithm for weighted graphs with approximation\nat most $3$ had total $\\tilde O(mn)$ update time providing a\n$(1+\\epsilon)$-approximation [Bernstein, SICOMP 2016]. Our technique also\nyields a decremental algorithm with total update time $\\tilde{O}(nm^{3/4})$\nsupporting $(2+\\epsilon, W_{u,v})$-approximate queries where the second term is\nan additional additive term and $W_{u,v}$ is the maximum weight on the shortest\npath from $u$ to $v$.\nOur second result is a decremental algorithm that given an unweighted graph\nand a constant integer $k \\geq 2 $, supports $(1+\\epsilon, 2(k-1))$-approximate\nqueries and has $\\tilde{O}(n^{2-1/k}m^{1/k})$ total update time (when\n$m=n^{1+c}$ for any constant $c >0$). For comparison, in the special case of\n$(1+\\epsilon, 2)$-approximation, this improves over the state-of-the-art\nalgorithm by [Henzinger, Krinninger, Nanongkai, SICOMP 2016] with total update\ntime of $\\tilde{O}(n^{2.5})$. All of our results are randomized and work\nagainst an oblivious adversary.",
    "descriptor": "",
    "authors": [
      "Michal Dory",
      "Sebastian Forster",
      "Yasamin Nazari",
      "Tijn de Vos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.01152"
  },
  {
    "id": "arXiv:2211.01153",
    "title": "A Two Step Approach to Weighted Bipartite Link Recommendations",
    "abstract": "Many real world person-person or person-product relationships can be modeled\ngraphically. More specifically, bipartite graphs can be especially useful when\nmodeling scenarios that involve two disjoint groups. As a result, many existing\npapers have utilized bipartite graphs for the classical link recommendation\nproblem. In this paper, using the principle of bipartite graphs, we present\nanother approach to this problem with a two step algorithm that takes into\naccount frequency and similarity between common edges to make recommendations.\nWe test this approach with bipartite data gathered from the Epinions and\nMovielens data sources, and find it to perform with roughly 14 percent error,\nwhich improves upon baseline results. This is a promising result, and can be\nrefined to generate even more accurate recommendations.",
    "descriptor": "",
    "authors": [
      "Nathan Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01153"
  },
  {
    "id": "arXiv:2211.01154",
    "title": "Mitigating Popularity Bias in Recommendation with Unbalanced  Interactions: A Gradient Perspective",
    "abstract": "Recommender systems learn from historical user-item interactions to identify\npreferred items for target users. These observed interactions are usually\nunbalanced following a long-tailed distribution. Such long-tailed data lead to\npopularity bias to recommend popular but not personalized items to users. We\npresent a gradient perspective to understand two negative impacts of popularity\nbias in recommendation model optimization: (i) the gradient direction of\npopular item embeddings is closer to that of positive interactions, and (ii)\nthe magnitude of positive gradient for popular items are much greater than that\nof unpopular items. To address these issues, we propose a simple yet efficient\nframework to mitigate popularity bias from a gradient perspective.\nSpecifically, we first normalize each user embedding and record accumulated\ngradients of users and items via popularity bias measures in model training. To\naddress the popularity bias issues, we develop a gradient-based embedding\nadjustment approach used in model testing. This strategy is generic,\nmodel-agnostic, and can be seamlessly integrated into most existing recommender\nsystems. Our extensive experiments on two classic recommendation models and\nfour real-world datasets demonstrate the effectiveness of our method over\nstate-of-the-art debiasing baselines.",
    "descriptor": "\nComments: Recommendation System, Popularity Bias\n",
    "authors": [
      "Weijieying Ren",
      "Lei Wang",
      "Kunpeng Liu",
      "Ruocheng Guo",
      "Lim Ee Peng",
      "Yanjie Fu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.01154"
  },
  {
    "id": "arXiv:2211.01155",
    "title": "Recommendation with User Active Disclosing Willingness",
    "abstract": "Recommender system has been deployed in a large amount of real-world\napplications, profoundly influencing people's daily life and\nproduction.Traditional recommender models mostly collect as comprehensive as\npossible user behaviors for accurate preference estimation. However,\nconsidering the privacy, preference shaping and other issues, the users may not\nwant to disclose all their behaviors for training the model. In this paper, we\nstudy a novel recommendation paradigm, where the users are allowed to indicate\ntheir \"willingness\" on disclosing different behaviors, and the models are\noptimized by trading-off the recommendation quality as well as the violation of\nthe user \"willingness\". More specifically, we formulate the recommendation\nproblem as a multiplayer game, where the action is a selection vector\nrepresenting whether the items are involved into the model training. For\nefficiently solving this game, we design a tailored algorithm based on\ninfluence function to lower the time cost for recommendation quality\nexploration, and also extend it with multiple anchor selection vectors.We\nconduct extensive experiments to demonstrate the effectiveness of our model on\nbalancing the recommendation quality and user disclosing willingness.",
    "descriptor": "",
    "authors": [
      "Lei Wang",
      "Xu Chen",
      "Quanyu Dai",
      "Zhenhua Dong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01155"
  },
  {
    "id": "arXiv:2211.01156",
    "title": "Entropic Neural Optimal Transport via Diffusion Processes",
    "abstract": "We propose a novel neural algorithm for the fundamental problem of computing\nthe entropic optimal transport (EOT) plan between probability distributions\nwhich are accessible by samples. Our algorithm is based on the saddle point\nreformulation of the dynamic version of EOT which is known as the Schr\\\"odinger\nBridge problem. In contrast to the prior methods for large-scale EOT, our\nalgorithm is end-to-end and consists of a single learning step, has fast\ninference procedure, and allows handling small values of the entropy\nregularization coefficient which is of particular importance in some applied\nproblems. Empirically, we show the performance of the method on several\nlarge-scale EOT tasks.",
    "descriptor": "",
    "authors": [
      "Nikita Gushchin",
      "Alexander Kolesov",
      "Alexander Korotin",
      "Dmitry Vetrov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01156"
  },
  {
    "id": "arXiv:2211.01160",
    "title": "Advertising strategy for profit-maximization: a novel practice on  Tmall's online ads manager platforms",
    "abstract": "Ads manager platform gains popularity among numerous e-commercial\nvendors/advertisers. It helps advertisers to facilitate the process of\ndisplaying their ads to target customers. One of the main challenges faced by\nadvertisers, especially small and medium-sized enterprises, is to configure\ntheir advertising strategy properly. An ineffective advertising strategy will\nbring too many ``just looking'' clicks and, eventually, generate high\nadvertising expenditure unproportionally to the growth of sales. In this paper,\nwe present a novel profit-maximization model for online advertising\noptimization. The optimization problem is constructed to find optimal set of\nfeatures to maximize the probability that target customers buy advertising\nproducts. We further reformulate the optimization problem to a knapsack problem\nwith changeable parameters, and introduce a self-adjusted algorithm for finding\nthe solution to the problem. Numerical experiment based on statistical data\nfrom Tmall show that our proposed method can optimize the advertising strategy\ngiven expenditure budget effectively.",
    "descriptor": "\nComments: Online advertising campaigns\n",
    "authors": [
      "Lianghai Xiao",
      "Yixing Zhao",
      "Jiwei Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.01160"
  },
  {
    "id": "arXiv:2211.01163",
    "title": "On-Device Model Fine-Tuning with Label Correction in Recommender Systems",
    "abstract": "To meet the practical requirements of low latency, low cost, and good privacy\nin online intelligent services, more and more deep learning models are\noffloaded from the cloud to mobile devices. To further deal with cross-device\ndata heterogeneity, the offloaded models normally need to be fine-tuned with\neach individual user's local samples before being put into real-time inference.\nIn this work, we focus on the fundamental click-through rate (CTR) prediction\ntask in recommender systems and study how to effectively and efficiently\nperform on-device fine-tuning. We first identify the bottleneck issue that each\nindividual user's local CTR (i.e., the ratio of positive samples in the local\ndataset for fine-tuning) tends to deviate from the global CTR (i.e., the ratio\nof positive samples in all the users' mixed datasets on the cloud for training\nout the initial model). We further demonstrate that such a CTR drift problem\nmakes on-device fine-tuning even harmful to item ranking. We thus propose a\nnovel label correction method, which requires each user only to change the\nlabels of the local samples ahead of on-device fine-tuning and can well align\nthe locally prior CTR with the global CTR. The offline evaluation results over\nthree datasets and five CTR prediction models as well as the online A/B testing\nresults in Mobile Taobao demonstrate the necessity of label correction in\non-device fine-tuning and also reveal the improvement over cloud-based learning\nwithout fine-tuning.",
    "descriptor": "",
    "authors": [
      "Yucheng Ding",
      "Chaoyue Niu",
      "Fan Wu",
      "Shaojie Tang",
      "Chengfei Lyu",
      "Guihai Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01163"
  },
  {
    "id": "arXiv:2211.01164",
    "title": "Lifted Inference with Linear Order Axiom",
    "abstract": "We consider the task of weighted first-order model counting (WFOMC) used for\nprobabilistic inference in the area of statistical relational learning. Given a\nformula $\\phi$, domain size $n$ and a pair of weight functions, what is the\nweighted sum of all models of $\\phi$ over a domain of size $n$? It was shown\nthat computing WFOMC of any logical sentence with at most two logical variables\ncan be done in time polynomial in $n$. However, it was also shown that the task\nis $\\texttt{#}P_1$-complete once we add the third variable, which inspired the\nsearch for extensions of the two-variable fragment that would still permit a\nrunning time polynomial in $n$. One of such extension is the two-variable\nfragment with counting quantifiers. In this paper, we prove that adding a\nlinear order axiom (which forces one of the predicates in $\\phi$ to introduce a\nlinear ordering of the domain elements in each model of $\\phi$) on top of the\ncounting quantifiers still permits a computation time polynomial in the domain\nsize. We present a new dynamic programming-based algorithm which can compute\nWFOMC with linear order in time polynomial in $n$, thus proving our primary\nclaim.",
    "descriptor": "",
    "authors": [
      "Jan T\u00f3th",
      "Ond\u0159ej Ku\u017eelka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.01164"
  },
  {
    "id": "arXiv:2211.01165",
    "title": "RegCLR: A Self-Supervised Framework for Tabular Representation Learning  in the Wild",
    "abstract": "Recent advances in self-supervised learning (SSL) using large models to learn\nvisual representations from natural images are rapidly closing the gap between\nthe results produced by fully supervised learning and those produced by SSL on\ndownstream vision tasks. Inspired by this advancement and primarily motivated\nby the emergence of tabular and structured document image applications, we\ninvestigate which self-supervised pretraining objectives, architectures, and\nfine-tuning strategies are most effective. To address these questions, we\nintroduce RegCLR, a new self-supervised framework that combines contrastive and\nregularized methods and is compatible with the standard Vision Transformer\narchitecture. Then, RegCLR is instantiated by integrating masked autoencoders\nas a representative example of a contrastive method and enhanced Barlow Twins\nas a representative example of a regularized method with configurable input\nimage augmentations in both branches. Several real-world table recognition\nscenarios (e.g., extracting tables from document images), ranging from standard\nWord and Latex documents to even more challenging electronic health records\n(EHR) computer screen images, have been shown to benefit greatly from the\nrepresentations learned from this new framework, with detection\naverage-precision (AP) improving relatively by 4.8% for Table, 11.8% for\nColumn, and 11.1% for GUI objects over a previous fully supervised baseline on\nreal-world EHR screen images.",
    "descriptor": "\nComments: To be presented at the 36th Conference on Neural Information Processing Systems, New Orleans, USA, on December 2, 2022, at the First Table Representation Learning (TRL) Workshop\n",
    "authors": [
      "Weiyao Wang",
      "Byung-Hak Kim",
      "Varun Ganapathi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01165"
  },
  {
    "id": "arXiv:2211.01169",
    "title": "Multicast Beamformer Design for MIMO Coded Caching Systems",
    "abstract": "Coded caching (CC) techniques have been shown to be conveniently applicable\nin multi-input multi-output (MIMO) systems. In a $K$-user network with spatial\nmultiplexing gains of $L$ at the transmitter and $G$ at every receiver, if each\nuser can cache a fraction $\\gamma$ of the file library, a total number of\n$GK\\gamma + L$ data streams can be served in parallel. In this paper, we focus\non improving the finite-SNR performance of MIMO-CC systems. We first consider a\nMIMO-CC scheme that relies only on unicasting individual data streams, and\nthen, introduce a decomposition strategy to design a new scheme that delivers\nthe same data streams through multicasting of $G$ parallel codewords. We\ndiscuss how optimized beamformers could be designed for each scheme and use\nnumerical simulations to compare their finite-SNR performance. It is shown that\nwhile both schemes serve the same number of streams, multicasting provides\nnotable performance improvements. This is because, with multicasting,\ntransmission vectors are built with fewer beamformers, leading to more\nefficient usage of available power resources.",
    "descriptor": "",
    "authors": [
      "MohammadJavad Salehi",
      "Mohammad NaseriTehrani",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.01169"
  },
  {
    "id": "arXiv:2211.01171",
    "title": "Entropy conservative high-order fluxes in the presence of boundaries",
    "abstract": "In this paper, we propose a novel development in the context of entropy\nstable finite-volume/finite-difference schemes. In the first part, we focus on\nthe construction of high-order entropy conservative fluxes. Already in\n[LMR2002], the authors have generalized the second order accurate entropy\nconservative numerical fluxes proposed by Tadmor to high-order ($2p$) by a\nsimple centered linear combination. We generalize this result additionally to\nnon-centered flux combinations which is in particular favorable if non-periodic\nboundary conditions are needed. In the second part, a Lax-Wendroff theorem for\nthe combination of these fluxes and the entropy dissipation steering from\n[Klein2022] is proven. In numerical simulations, we verify all of our\ntheoretical findings.",
    "descriptor": "",
    "authors": [
      "Simon-Christian Klein",
      "Philipp \u00d6ffner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.01171"
  },
  {
    "id": "arXiv:2211.01173",
    "title": "ModMag: A Modular Magnetic Micro-Robotic Manipulation Device",
    "abstract": "Electromagnetic systems have been used extensively for the control\nmagnetically actuated objects, such as in microrheology and microrobotics\nresearch. Therefore, optimizing the design of such systems is highly desired.\nSome of the features that are lacking in most current designs are compactness,\nportability, and versatility. Portability is especially relevant for biomedical\napplications in which in vivo or in vitro testing may be conducted in locations\naway from the laboratory microscope. This document describes the design,\nfabrication and implementation of a compact, low cost, versatile, and user\nfriendly device (the ModMag) capable of controlling multiple electromagnetic\nsetups, including a two-dimensional 4-coil traditional configuration, a\n3-dimensional Helmholtz configuration, and a 3-dimensional magnetic tweezer\nconfiguration. All electronics and circuitry for powering the systems is\ncontained in a compact 10\"x6\"x3\" system which includes a 10\" touchscreen. A\ngraphical user interface provides additional ease of use. The system can also\nbe controlled remotely, allowing for more flexibility and the ability to\ninterface with other software running on the remote computer such as propriety\ncamera software. Aside from the software and circuitry, we also describe the\ndesign of the electromagnetic coil setups and provide examples of the use of\nthe ModMag in experiments.",
    "descriptor": "",
    "authors": [
      "Max Sokolich",
      "Max Sokolich",
      "David Rivas",
      "Markos Duey",
      "Daniel Borsykowsky",
      "Sambeeta Das"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01173"
  },
  {
    "id": "arXiv:2211.01174",
    "title": "Hypergraph Convolutional Network based Weakly Supervised Point Cloud  Semantic Segmentation with Scene-Level Annotations",
    "abstract": "Point cloud segmentation with scene-level annotations is a promising but\nchallenging task. Currently, the most popular way is to employ the class\nactivation map (CAM) to locate discriminative regions and then generate\npoint-level pseudo labels from scene-level annotations. However, these methods\nalways suffer from the point imbalance among categories, as well as the sparse\nand incomplete supervision from CAM. In this paper, we propose a novel weighted\nhypergraph convolutional network-based method, called WHCN, to confront the\nchallenges of learning point-wise labels from scene-level annotations. Firstly,\nin order to simultaneously overcome the point imbalance among different\ncategories and reduce the model complexity, superpoints of a training point\ncloud are generated by exploiting the geometrically homogeneous partition.\nThen, a hypergraph is constructed based on the high-confidence superpoint-level\nseeds which are converted from scene-level annotations. Secondly, the WHCN\ntakes the hypergraph as input and learns to predict high-precision point-level\npseudo labels by label propagation. Besides the backbone network consisting of\nspectral hypergraph convolution blocks, a hyperedge attention module is learned\nto adjust the weights of hyperedges in the WHCN. Finally, a segmentation\nnetwork is trained by these pseudo point cloud labels. We comprehensively\nconduct experiments on the ScanNet and S3DIS segmentation datasets.\nExperimental results demonstrate that the proposed WHCN is effective to predict\nthe point labels with scene annotations, and yields state-of-the-art results in\nthe community. The source code is available at\nthis http URL",
    "descriptor": "",
    "authors": [
      "Zhuheng Lu",
      "Peng Zhang",
      "Yuewei Dai",
      "Weiqing Li",
      "Zhiyong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.01174"
  },
  {
    "id": "arXiv:2211.01177",
    "title": "Neural Block-Slot Representations",
    "abstract": "In this paper, we propose a novel object-centric representation, called\nBlock-Slot Representation. Unlike the conventional slot representation, the\nBlock-Slot Representation provides concept-level disentanglement within a slot.\nA block-slot is constructed by composing a set of modular concept\nrepresentations, called blocks, generated from a learned memory of abstract\nconcept prototypes. We call this block-slot construction process Block-Slot\nAttention. Block-Slot Attention facilitates the emergence of abstract concept\nblocks within a slot such as color, position, and texture, without any\nsupervision. This brings the benefits of disentanglement into slots and the\nrepresentation becomes more interpretable. Similar to Slot Attention, this\nmechanism can be used as a drop-in module in any arbitrary neural architecture.\nIn experiments, we show that our model disentangles object properties\nsignificantly better than the previous methods, including complex textured\nscenes. We also demonstrate the ability to compose novel scenes by composing\nslots at the block-level.",
    "descriptor": "",
    "authors": [
      "Gautam Singh",
      "Yeongbin Kim",
      "Sungjin Ahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01177"
  },
  {
    "id": "arXiv:2211.01178",
    "title": "AmiGo: Computational Design of Amigurumi Crochet Patterns",
    "abstract": "We propose an approach for generating crochet instructions (patterns) from an\ninput 3D model. We focus on Amigurumi, which are knitted stuffed toys. Given a\nclosed triangle mesh, and a single point specified by the user, we generate\ncrochet instructions, which when knitted and stuffed result in a toy similar to\nthe input geometry. Our approach relies on constructing the geometry and\nconnectivity of a Crochet Graph, which is then translated into a crochet\npattern. We segment the shape automatically into chrochetable components, which\nare connected using the join-as-you-go method, requiring no additional sewing.\nWe demonstrate that our method is applicable to a large variety of shapes and\ngeometries, and yields easily crochetable patterns.",
    "descriptor": "\nComments: 11 pages, 10 figures, SCF 2022\n",
    "authors": [
      "Michal Edelstein",
      "Hila Peleg",
      "Shachar Itzhaky",
      "Mirela Ben-Chen"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.01178"
  },
  {
    "id": "arXiv:2211.01179",
    "title": "Tournesol: Permissionless Collaborative Algorithmic Governance with  Security Guarantees",
    "abstract": "Recommendation algorithms play an increasingly central role in our societies.\nHowever, thus far, these algorithms are mostly designed and parameterized\nunilaterally by private groups or governmental authorities. In this paper, we\npresent an end-to-end permissionless collaborative algorithmic governance\nmethod with security guarantees. Our proposed method is deployed as part of an\nopen-source content recommendation platform https://tournesol.app, whose\nrecommender is collaboratively parameterized by a community of (non-technical)\ncontributors. This algorithmic governance is achieved through three main steps.\nFirst, the platform contains a mechanism to assign voting rights to the\ncontributors. Second, the platform uses a comparison-based model to evaluate\nthe individual preferences of contributors. Third, the platform aggregates the\njudgements of all contributors into collective scores for content\nrecommendations. We stress that the first and third steps are vulnerable to\nattacks from malicious contributors. To guarantee the resilience against fake\naccounts, the first step combines email authentication, a vouching mechanism, a\nnovel variant of the reputation-based EigenTrust algorithm and an adaptive\nvoting rights assignment for alternatives that are scored by too many untrusted\naccounts. To provide resilience against malicious authenticated contributors,\nwe adapt Mehestan, an algorithm previously proposed for robust sparse voting.\nWe believe that these algorithms provide an appealing foundation for a\ncollaborative, effective, scalable, fair, contributor-friendly, interpretable\nand secure governance. We conclude by highlighting key challenges to make our\nsolution applicable to larger-scale settings.",
    "descriptor": "\nComments: 31 pages, 5 figures\n",
    "authors": [
      "Romain Beylerian",
      "B\u00e9rang\u00e8re Colbois",
      "Louis Faucon",
      "L\u00ea Nguy\u00ean Hoang",
      "Aidan Jungo",
      "Alain Le Noac'h",
      "Adrien Matissart"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.01179"
  },
  {
    "id": "arXiv:2211.01180",
    "title": "M-SpeechCLIP: Leveraging Large-Scale, Pre-Trained Models for  Multilingual Speech to Image Retrieval",
    "abstract": "This work investigates the use of large-scale, pre-trained models (CLIP and\nHuBERT) for multilingual speech-image retrieval. For non-English speech-image\nretrieval, we outperform the current state-of-the-art performance by a wide\nmargin when training separate models for each language, and show that a single\nmodel which processes speech in all three languages still achieves retrieval\nscores comparable with the prior state-of-the-art. We identify key differences\nin model behavior and performance between English and non-English settings,\npresumably attributable to the English-only pre-training of CLIP and HuBERT.\nFinally, we show that our models can be used for mono- and cross-lingual\nspeech-text retrieval and cross-lingual speech-speech retrieval, despite never\nhaving seen any parallel speech-text or speech-speech data during training.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Layne Berry",
      "Yi-Jen Shih",
      "Hsuan-Fu Wang",
      "Heng-Jui Chang",
      "Hung-yi Lee",
      "David Harwath"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01180"
  },
  {
    "id": "arXiv:2211.01182",
    "title": "Defending with Errors: Approximate Computing for Robustness of Deep  Neural Networks",
    "abstract": "Machine-learning architectures, such as Convolutional Neural Networks (CNNs)\nare vulnerable to adversarial attacks: inputs crafted carefully to force the\nsystem output to a wrong label. Since machine-learning is being deployed in\nsafety-critical and security-sensitive domains, such attacks may have\ncatastrophic security and safety consequences. In this paper, we propose for\nthe first time to use hardware-supported approximate computing to improve the\nrobustness of machine-learning classifiers. We show that successful adversarial\nattacks against the exact classifier have poor transferability to the\napproximate implementation. Surprisingly, the robustness advantages also apply\nto white-box attacks where the attacker has unrestricted access to the\napproximate classifier implementation: in this case, we show that substantially\nhigher levels of adversarial noise are needed to produce adversarial examples.\nFurthermore, our approximate computing model maintains the same level in terms\nof classification accuracy, does not require retraining, and reduces resource\nutilization and energy consumption of the CNN. We conducted extensive\nexperiments on a set of strong adversarial attacks; We empirically show that\nthe proposed implementation increases the robustness of a LeNet-5, Alexnet and\nVGG-11 CNNs considerably with up to 50% by-product saving in energy consumption\ndue to the simpler nature of the approximate logic.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2006.07700\n",
    "authors": [
      "Amira Guesmi",
      "Ihsen Alouani",
      "Khaled N. Khasawneh",
      "Mouna Baklouti",
      "Tarek Frikha",
      "Mohamed Abid",
      "Nael Abu-Ghazaleh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01182"
  },
  {
    "id": "arXiv:2211.01184",
    "title": "Joint Data and Feature Augmentation for Self-Supervised Representation  Learning on Point Clouds",
    "abstract": "To deal with the exhausting annotations, self-supervised representation\nlearning from unlabeled point clouds has drawn much attention, especially\ncentered on augmentation-based contrastive methods. However, specific\naugmentations hardly produce sufficient transferability to high-level tasks on\ndifferent datasets. Besides, augmentations on point clouds may also change\nunderlying semantics. To address the issues, we propose a simple but efficient\naugmentation fusion contrastive learning framework to combine data\naugmentations in Euclidean space and feature augmentations in feature space. In\nparticular, we propose a data augmentation method based on sampling and graph\ngeneration. Meanwhile, we design a data augmentation network to enable a\ncorrespondence of representations by maximizing consistency between augmented\ngraph pairs. We further design a feature augmentation network that encourages\nthe model to learn representations invariant to the perturbations using an\nencoder perturbation. We comprehensively conduct extensive object\nclassification experiments and object part segmentation experiments to validate\nthe transferability of the proposed framework. Experimental results demonstrate\nthat the proposed framework is effective to learn the point cloud\nrepresentation in a self-supervised manner, and yields state-of-the-art results\nin the community. The source code is publicly available at:\nhttps://zhiyongsu.github.io/Project/AFSRL.html.",
    "descriptor": "",
    "authors": [
      "Zhuheng Lu",
      "Yuewei Dai",
      "Weiqing Li",
      "Zhiyong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.01184"
  },
  {
    "id": "arXiv:2211.01200",
    "title": "Multi-level Distillation of Semantic Knowledge for Pre-training  Multilingual Language Model",
    "abstract": "Pre-trained multilingual language models play an important role in\ncross-lingual natural language understanding tasks. However, existing methods\ndid not focus on learning the semantic structure of representation, and thus\ncould not optimize their performance. In this paper, we propose Multi-level\nMultilingual Knowledge Distillation (MMKD), a novel method for improving\nmultilingual language models. Specifically, we employ a teacher-student\nframework to adopt rich semantic representation knowledge in English BERT. We\npropose token-, word-, sentence-, and structure-level alignment objectives to\nencourage multiple levels of consistency between source-target pairs and\ncorrelation similarity between teacher and student models. We conduct\nexperiments on cross-lingual evaluation benchmarks including XNLI, PAWS-X, and\nXQuAD. Experimental results show that MMKD outperforms other baseline models of\nsimilar size on XNLI and XQuAD and obtains comparable performance on PAWS-X.\nEspecially, MMKD obtains significant performance gains on low-resource\nlanguages.",
    "descriptor": "\nComments: accepted at EMNLP 2022\n",
    "authors": [
      "Mingqi Li",
      "Fei Ding",
      "Dan Zhang",
      "Long Cheng",
      "Hongxin Hu",
      "Feng Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01200"
  },
  {
    "id": "arXiv:2211.01201",
    "title": "Human alignment of neural network representations",
    "abstract": "Today's computer vision models achieve human or near-human level performance\nacross a wide variety of vision tasks. However, their architectures, data, and\nlearning algorithms differ in numerous ways from those that give rise to human\nvision. In this paper, we investigate the factors that affect alignment between\nthe representations learned by neural networks and human concept\nrepresentations. Human representations are inferred from behavioral responses\nin an odd-one-out triplet task, where humans were presented with three images\nand had to select the odd-one-out. We find that model scale and architecture\nhave essentially no effect on alignment with human behavioral responses,\nwhereas the training dataset and objective function have a much larger impact.\nUsing a sparse Bayesian model of human conceptual representations, we partition\ntriplets by the concept that distinguishes the two similar images from the\nodd-one-out, finding that some concepts such as food and animals are\nwell-represented in neural network representations whereas others such as royal\nor sports-related objects are not. Overall, although models trained on larger,\nmore diverse datasets achieve better alignment with humans than models trained\non ImageNet alone, our results indicate that scaling alone is unlikely to be\nsufficient to train neural networks with conceptual representations that match\nthose used by humans.",
    "descriptor": "",
    "authors": [
      "Lukas Muttenthaler",
      "Jonas Dippel",
      "Lorenz Linhardt",
      "Robert A. Vandermeulen",
      "Simon Kornblith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.01201"
  },
  {
    "id": "arXiv:2211.01202",
    "title": "Web-based Elicitation of Human Perception on mixup Data",
    "abstract": "Synthetic data is proliferating on the web and powering many advances in\nmachine learning. However, it is not always clear if synthetic labels are\nperceptually sensible to humans. The web provides us with a platform to take a\nstep towards addressing this question through online elicitation. We design a\nseries of elicitation interfaces, which we release as \\texttt{HILL MixE Suite},\nand recruit 159 participants, to provide perceptual judgments over the kinds of\nsynthetic data constructed during \\textit{mixup} training: a powerful\nregularizer shown to improve model robustness, generalization, and calibration.\nWe find that human perception does not consistently align with the labels\ntraditionally used for synthetic points and begin to demonstrate the\napplicability of these findings to potentially increase the reliability of\ndownstream models. We release all elicited judgments in a new data hub we call\n\\texttt{H-Mix}.",
    "descriptor": "",
    "authors": [
      "Katherine M. Collins",
      "Umang Bhatt",
      "Weiyang Liu",
      "Vihari Piratla",
      "Bradley Love",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.01202"
  },
  {
    "id": "arXiv:2211.01204",
    "title": "Semi-Deterministic Subspace Selection for Sparse Recursive  Projection-Aggregation Decoding of Reed-Muller Codes",
    "abstract": "Recursive projection aggregation (RPA) decoding as introduced in [1] is a\nnovel decoding algorithm which performs close to the maximum likelihood decoder\nfor short-length Reed-Muller codes. Recently, an extension to RPA decoding,\ncalled sparse multi-decoder RPA (SRPA), has been proposed [2]. The SRPA\napproach makes use of multiple pruned RPA decoders to lower the amount of\ncomputations while keeping the performance loss small compared to RPA decoding.\nHowever, the use of multiple sparse decoders again increases the computational\nburden. Therefore, the focus is on the optimization of sparse single-decoder\nRPA decoding to keep the complexity small. In this paper, a novel method is\nproposed, to select subsets of subspaces used in the projection and aggregation\nstep of SRPA decoding in order to decrease the decoding error probability on\nAWGN channels. The proposed method replaces the random selection of subspace\nsubsets with a semi-deterministic selection method based on a figure of merit\nthat evaluates the performance of each subspace. Our simulation results show\nthat the semi-deterministic subspace selection improves the decoding\nperformance up to $0.2\\,\\text{dB}$ compared to SRPA. At the same time, the\ncomplexity of SRPA decoding for RM codes of order $r\\geq 3$ is reduced by up to\n81% compared to SRPA.",
    "descriptor": "",
    "authors": [
      "Johannes Voigt",
      "Holger J\u00e4kel",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.01204"
  },
  {
    "id": "arXiv:2211.01205",
    "title": "No-reference Point Cloud Geometry Quality Assessment Based on Pairwise  Rank Learning",
    "abstract": "Objective geometry quality assessment of point clouds is essential to\nevaluate the performance of a wide range of point cloud-based solutions, such\nas denoising, simplification, reconstruction, and watermarking. Existing point\ncloud quality assessment (PCQA) methods dedicate to assigning absolute quality\nscores to distorted point clouds. Their performance is strongly reliant on the\nquality and quantity of subjective ground-truth scores for training, which are\nchallenging to gather and have been shown to be imprecise, biased, and\ninconsistent. Furthermore, the majority of existing objective geometry quality\nassessment approaches are carried out by full-reference traditional metrics. So\nfar, point-based no-reference geometry-only quality assessment techniques have\nnot yet been investigated. This paper presents PRL-GQA, the first pairwise\nlearning framework for no-reference geometry-only quality assessment of point\nclouds, to the best of our knowledge. The proposed PRL-GQA framework employs a\nsiamese deep architecture, which takes as input a pair of point clouds and\noutputs their rank order. Each siamese architecture branch is a geometry\nquality assessment network (GQANet), which is designed to extract multi-scale\nquality-aware geometric features and output a quality index for the input point\ncloud. Then, based on the predicted quality indexes, a pairwise rank learning\nmodule is introduced to rank the relative quality of a pair of degraded point\nclouds.Extensive experiments demonstrate the effectiveness of the proposed\nPRL-GQA framework. Furthermore, the results also show that the fine-tuned\nno-reference GQANet performs competitively when compared to existing\nfull-reference geometry quality assessment metrics.",
    "descriptor": "",
    "authors": [
      "Zhiyong Su",
      "Chao Chu",
      "Long Chen",
      "Yong Li",
      "Weiqing Li"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.01205"
  },
  {
    "id": "arXiv:2211.01207",
    "title": "Bias-Aware Face Mask Detection Dataset",
    "abstract": "In December 2019, a novel coronavirus (COVID-19) spread so quickly around the\nworld that many countries had to set mandatory face mask rules in public areas\nto reduce the transmission of the virus. To monitor public adherence,\nresearchers aimed to rapidly develop efficient systems that can detect faces\nwith masks automatically. However, the lack of representative and novel\ndatasets proved to be the biggest challenge. Early attempts to collect face\nmask datasets did not account for potential race, gender, and age biases.\nTherefore, the resulting models show inherent biases toward specific race\ngroups, such as Asian or Caucasian. In this work, we present a novel face mask\ndetection dataset that contains images posted on Twitter during the pandemic\nfrom around the world. Unlike previous datasets, the proposed Bias-Aware Face\nMask Detection (BAFMD) dataset contains more images from underrepresented race\nand age groups to mitigate the problem for the face mask detection task. We\nperform experiments to investigate potential biases in widely used face mask\ndetection datasets and illustrate that the BAFMD dataset yields models with\nbetter performance and generalization ability. The dataset is publicly\navailable at https://github.com/Alpkant/BAFMD.",
    "descriptor": "\nComments: submitted to Pattern Recognition Letters, 7 pages, 3 figures\n",
    "authors": [
      "Alperen Kantarc\u0131",
      "Ferda Ofli",
      "Muhammad Imran",
      "Haz\u0131m Kemal Ekenel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.01207"
  },
  {
    "id": "arXiv:2211.01213",
    "title": "FiFo: Fishbone Forwarding in Massive IoT Networks",
    "abstract": "Massive Internet of Things (IoT) networks have a wide range of applications,\nincluding but not limited to the rapid delivery of emergency and disaster\nmessages. Although various benchmark algorithms have been developed to date for\nmessage delivery in such applications, they pose several practical challenges\nsuch as insufficient network coverage and/or highly redundant transmissions to\nexpand the coverage area, resulting in considerable energy consumption for each\nIoT device. To overcome this problem, we first characterize a new performance\nmetric, forwarding efficiency, which is defined as the ratio of the coverage\nprobability to the average number of transmissions per device, to evaluate the\ndata dissemination performance more appropriately. Then, we propose a novel and\neffective forwarding method, fishbone forwarding (FiFo), which aims to improve\nthe forwarding efficiency with acceptable computational complexity. Our FiFo\nmethod completes two tasks: 1) it clusters devices based on the unweighted pair\ngroup method with the arithmetic average; and 2) it creates the main axis and\nsub axes of each cluster using both the expectation-maximization algorithm for\nthe Gaussian mixture model and principal component analysis. We demonstrate the\nsuperiority of FiFo by using a real-world dataset. Through intensive and\ncomprehensive simulations, we show that the proposed FiFo method outperforms\nbenchmark algorithms in terms of the forwarding efficiency.",
    "descriptor": "\nComments: 13 pages, 16 figures, 5 tables; to appear in the IEEE Internet of Things Journal (Please cite our journal version that will appear in an upcoming issue.)\n",
    "authors": [
      "Hayoung Seong",
      "Junseon Kim",
      "Won-Yong Shin",
      "Howon Lee"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.01213"
  },
  {
    "id": "arXiv:2211.01214",
    "title": "Time-aware Random Walk Diffusion to Improve Dynamic Graph Learning",
    "abstract": "How can we augment a dynamic graph for improving the performance of dynamic\ngraph neural networks? Graph augmentation has been widely utilized to boost the\nlearning performance of GNN-based models. However, most existing approaches\nonly enhance spatial structure within an input static graph by transforming the\ngraph, and do not consider dynamics caused by time such as temporal locality,\ni.e., recent edges are more influential than earlier ones, which remains\nchallenging for dynamic graph augmentation. In this work, we propose TiaRa\n(Time-aware Random Walk Diffusion), a novel diffusion-based method for\naugmenting a dynamic graph represented as a discrete-time sequence of graph\nsnapshots. For this purpose, we first design a time-aware random walk proximity\nso that a surfer can walk along the time dimension as well as edges, resulting\nin spatially and temporally localized scores. We then derive our diffusion\nmatrices based on the time-aware random walk, and show they become enhanced\nadjacency matrices that both spatial and temporal localities are augmented.\nThroughout extensive experiments, we demonstrate that TiaRaeffectively augments\na given dynamic graph, and leads to significant improvements in dynamic GNN\nmodels for various graph datasets and tasks.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jong-whi Lee",
      "Jinhong Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01214"
  },
  {
    "id": "arXiv:2211.01217",
    "title": "Design and implementation of a Framework for remote experiments in  education",
    "abstract": "Remote Controlled laboratories is a teaching and learning tool that\nincreasingly becomes fundamental in the teaching and learning processes at all\nthe levels. A study of available systems highlights a series of limitations on\nthe used programming languages, overall architecture and network communication\npatterns that, that hinder these systems to be further adopted. Current\ntechnologies and modern WEB architectures allow the resolution of such\nlimitations.\nHere we present the FREE (Framework for Remote Experiments in Education)\nplatform, a novel system, that, using modern technologies, architectures, and\nprogramming practices, will be easier to integrate with external tool and\nservices and new experiments.\nFREE was developed in Python, Django programming framework, HTML, JavaScript,\nand web services to easy the development of new functionalities. The designed\narchitecture provides a louse coupling between the infrastructure and the\nremote experiments facilitating further developments and allow new experiment\nintegrations.\nCurrently FREE is already running in various countries providing access to\nabout five types of experiments in the area of physics), integration with\nvarious Learning Management Systems and external Authentication mechanisms.\nUsing FREE the development and integration of new experiments (independently of\nthe supporting Hardware and programming language) is now easier to be made\navailable to remote users.",
    "descriptor": "\nComments: Accepted for publication and presentation on 2022 VIII International Engineering, Science and Technology Conference, Panama City, October 19-21, 2022\n",
    "authors": [
      "Pavel Kuri\u0161\u010d\u00e1k",
      "Pedro Rossa",
      "Hor\u00e1cio Fernandes",
      "Jo\u00e3o Nuno Silva"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.01217"
  },
  {
    "id": "arXiv:2211.01220",
    "title": "MDS Variable Generation and Secure Summation with User Selection",
    "abstract": "A collection of $K$ random variables are called $(K,n)$-MDS if any $n$ of the\n$K$ variables are independent and determine all remaining variables. In the MDS\nvariable generation problem, $K$ users wish to generate variables that are\n$(K,n)$-MDS using a randomness variable owned by each user. We show that to\ngenerate $1$ bit of $(K,n)$-MDS variables for each $n \\in \\{1,2,\\cdots, K\\}$,\nthe minimum size of the randomness variable at each user is $1 + 1/2 + \\cdots +\n1/K$ bits.\nAn intimately related problem is secure summation with user selection, where\na server may select an arbitrary subset of $K$ users and securely compute the\nsum of the inputs of the selected users. We show that to compute $1$ bit of an\narbitrarily chosen sum securely, the minimum size of the key held by each user\nis $1 + 1/2 + \\cdots + 1/(K-1)$ bits, whose achievability uses the generation\nof $(K,n)$-MDS variables for $n \\in \\{1,2,\\cdots,K-1\\}$.",
    "descriptor": "",
    "authors": [
      "Yizhou Zhao",
      "Hua Sun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.01220"
  },
  {
    "id": "arXiv:2211.01222",
    "title": "Higher order convergence of perfectly matched layers in 3D bi-periodic  surface scattering problems",
    "abstract": "The perfectly matched layer (PML) is a very popular tool in the truncation of\nwave scattering in unbounded domains. In Chandler-Wilde & Monk et al. 2009, the\nauthor proposed a conjecture that for scattering problems with rough surfaces,\nthe PML converges exponentially with respect to the PML parameter in any\ncompact subset. In the author's previous paper (Zhang et al. 2022), this result\nhas been proved for periodic surfaces in two dimensional spaces, when the wave\nnumber is not a half integer. In this paper, we prove that the method has a\nhigh order convergence rate in the 3D bi-periodic surface scattering problems.\nWe extend the 2D results and prove that the exponential convergence still holds\nwhen the wavenumber is smaller than $0.5$. For lareger wavenumbers, although\nexponential convergence is no longer proved, we are able to prove that a higher\norder convergence for the PML method.",
    "descriptor": "",
    "authors": [
      "Ruming Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.01222"
  },
  {
    "id": "arXiv:2211.01223",
    "title": "Audio Language Modeling using Perceptually-Guided Discrete  Representations",
    "abstract": "In this work, we study the task of Audio Language Modeling, in which we aim\nat learning probabilistic models for audio that can be used for generation and\ncompletion. We use a state-of-the-art perceptually-guided audio compression\nmodel, to encode audio to discrete representations. Next, we train a\ntransformer-based causal language model using these representations. At\ninference time, we perform audio auto-completion by encoding an audio prompt as\na discrete sequence, feeding it to the audio language model, sampling from the\nmodel, and synthesizing the corresponding time-domain signal. We evaluate the\nquality of samples generated by our method on Audioset, the largest dataset for\ngeneral audio to date, and show that it is superior to the evaluated baseline\naudio encoders. We additionally provide an extensive analysis to better\nunderstand the trade-off between audio-quality and language-modeling\ncapabilities. Samples:link.",
    "descriptor": "",
    "authors": [
      "Felix Kreuk",
      "Yaniv Taigman",
      "Adam Polyak",
      "Jade Copet",
      "Gabriel Synnaeve",
      "Alexandre D\u00e9fossez",
      "Yossi Adi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01223"
  },
  {
    "id": "arXiv:2211.01224",
    "title": "Stack graphs: Name resolution at scale",
    "abstract": "We present stack graphs, an extension of Visser et al.'s scope graphs\nframework. Stack graphs power Precise Code Navigation at GitHub, allowing users\nto navigate name binding references both within and across repositories. Like\nscope graphs, stack graphs encode the name binding information about a program\nin a graph structure, in which paths represent valid name bindings. Resolving a\nreference to its definition is then implemented with a simple path-finding\nsearch.\nGitHub hosts millions of repositories, containing petabytes of total code,\nimplemented in hundreds of different programming languages, and receiving\nthousands of pushes per minute. To support this scale, we update the graph\nconstruction and path-finding judgments to be file-incremental. For each source\nfile, we create an isolated subgraph without any knowledge of, or visibility\ninto, any other file in the program. This lets us eliminate the storage and\ncompute costs of reanalyzing file versions that we have already seen. Since\nmost commits change a small fraction of the files in a repository, this greatly\namortizes the operational costs of indexing large, frequently changed\nrepositories over time. To handle type-directed name lookups (which require\n\"pausing\" the current lookup to resolve another name), our path-finding\nalgorithm maintains a stack of the currently paused (but still pending)\nlookups. Stack graphs can be constructed via a purely syntactic analysis of the\nprogram's source code, using a new declarative graph construction language.\nThis means that we can extract name binding information for every repository\nwithout any per-package configuration, and without having to invoke an\narbitrary, untrusted, package-specific build process.",
    "descriptor": "\nComments: 8 pages, submitted to Eelco Visser Commemorative Symposium 2022\n",
    "authors": [
      "Douglas A. Creager",
      "Hendrik van Antwerpen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.01224"
  },
  {
    "id": "arXiv:2211.01226",
    "title": "DEArt: Dataset of European Art",
    "abstract": "Large datasets that were made publicly available to the research community\nover the last 20 years have been a key enabling factor for the advances in deep\nlearning algorithms for NLP or computer vision. These datasets are generally\npairs of aligned image / manually annotated metadata, where images are\nphotographs of everyday life. Scholarly and historical content, on the other\nhand, treat subjects that are not necessarily popular to a general audience,\nthey may not always contain a large number of data points, and new data may be\ndifficult or impossible to collect. Some exceptions do exist, for instance,\nscientific or health data, but this is not the case for cultural heritage (CH).\nThe poor performance of the best models in computer vision - when tested over\nartworks - coupled with the lack of extensively annotated datasets for CH, and\nthe fact that artwork images depict objects and actions not captured by\nphotographs, indicate that a CH-specific dataset would be highly valuable for\nthis community. We propose DEArt, at this point primarily an object detection\nand pose classification dataset meant to be a reference for paintings between\nthe XIIth and the XVIIIth centuries. It contains more than 15000 images, about\n80% non-iconic, aligned with manual annotations for the bounding boxes\nidentifying all instances of 69 classes as well as 12 possible poses for boxes\nidentifying human-like objects. Of these, more than 50 classes are CH-specific\nand thus do not appear in other datasets; these reflect imaginary beings,\nsymbolic entities and other categories related to art. Additionally, existing\ndatasets do not include pose annotations. Our results show that object\ndetectors for the cultural heritage domain can achieve a level of precision\ncomparable to state-of-art models for generic images via transfer learning.",
    "descriptor": "\nComments: VISART VI. Workshop at the European Conference of Computer Vision (ECCV)\n",
    "authors": [
      "Artem Reshetnikov",
      "Maria-Cristina Marinescu",
      "Joaquim More Lopez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01226"
  },
  {
    "id": "arXiv:2211.01229",
    "title": "Fast convergence for of perfectly matched layers for scattering with  periodic surfaces: the exceptional case",
    "abstract": "In the author's previous paper (Zhang et al. 2022), exponential convergence\nwas proved for the perfectly matched layers (PML) approximation of scattering\nproblems with periodic surfaces in 2D. However, due to the overlapping of\nsingularities, an exceptional case, i.e., when the wave number is a half\ninteger, has to be excluded in the proof. However, numerical results for these\ncases still have fast convergence rate and this motivates us to go deeper into\nthese cases. In this paper, we focus on these cases and prove that the fast\nconvergence result for the discretized form. Numerical examples are also\npresented to support our theoretical results.",
    "descriptor": "",
    "authors": [
      "Ruming Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.01229"
  },
  {
    "id": "arXiv:2211.01231",
    "title": "Interval Markov Decision Processes with Continuous Action-Spaces",
    "abstract": "Interval Markov Decision Processes (IMDPs) are uncertain Markov models, where\nthe transition probabilities belong to intervals. Recently, there has been a\nsurge of research on employing IMDPs as abstractions of stochastic systems for\ncontrol synthesis. However, due to the absence of algorithms for synthesis over\nIMDPs with continuous action-spaces, the action-space is assumed discrete\na-priori, which is a restrictive assumption for many applications. Motivated by\nthis, we introduce continuous-action IMDPs (caIMDPs), where the bounds on\ntransition probabilities are functions of the action variables, and study value\niteration for maximizing expected cumulative rewards. Specifically, we show\nthat solving the max-min problem associated to value iteration is equivalent to\nsolving $|\\mathcal{Q}|$ max problems, where $|\\mathcal{Q}|$ is the number of\nstates of the caIMDP. Then, exploiting the simple form of these max problems,\nwe identify cases where value iteration over caIMDPs can be solved efficiently\n(e.g., with linear or convex programming). We also gain other interesting\ninsights: e.g., in the case where the action set $\\mathcal{A}$ is a polytope\nand the transition bounds are linear, synthesizing over a discrete-action IMDP,\nwhere the actions are the vertices of $\\mathcal{A}$, is sufficient for\noptimality. We demonstrate our results on a numerical example. Finally, we\ninclude a short discussion on employing caIMDPs as abstractions for control\nsynthesis.",
    "descriptor": "",
    "authors": [
      "Giannis Delimpaltadakis",
      "Morteza Lahijanian",
      "Manuel Mazo Jr.",
      "Luca Laurenti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01231"
  },
  {
    "id": "arXiv:2211.01233",
    "title": "Attention-based Neural Cellular Automata",
    "abstract": "Recent extensions of Cellular Automata (CA) have incorporated key ideas from\nmodern deep learning, dramatically extending their capabilities and catalyzing\na new family of Neural Cellular Automata (NCA) techniques. Inspired by\nTransformer-based architectures, our work presents a new class of\n$\\textit{attention-based}$ NCAs formed using a spatially\nlocalized$\\unicode{x2014}$yet globally organized$\\unicode{x2014}$self-attention\nscheme. We introduce an instance of this class named $\\textit{Vision\nTransformer Cellular Automata}$ (ViTCA). We present quantitative and\nqualitative results on denoising autoencoding across six benchmark datasets,\ncomparing ViTCA to a U-Net, a U-Net-based CA baseline (UNetCA), and a Vision\nTransformer (ViT). When comparing across architectures configured to similar\nparameter complexity, ViTCA architectures yield superior performance across all\nbenchmarks and for nearly every evaluation metric. We present an ablation study\non various architectural configurations of ViTCA, an analysis of its effect on\ncell states, and an investigation on its inductive biases. Finally, we examine\nits learned representations via linear probes on its converged cell state\nhidden representations, yielding, on average, superior results when compared to\nour U-Net, ViT, and UNetCA baselines.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Mattie Tesfaldet",
      "Derek Nowrouzezahrai",
      "Christopher Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01233"
  },
  {
    "id": "arXiv:2211.01234",
    "title": "A comparison of uncertainty estimation approaches for DNN-based camera  localization",
    "abstract": "Camera localization, i.e., camera pose regression, represents a very\nimportant task in computer vision, since it has many practical applications,\nsuch as autonomous driving. A reliable estimation of the uncertainties in\ncamera localization is also important, as it would allow to intercept\nlocalization failures, which would be dangerous. Even though the literature\npresents some uncertainty estimation methods, to the best of our knowledge\ntheir effectiveness has not been thoroughly examined. This work compares the\nperformances of three consolidated epistemic uncertainty estimation methods:\nMonte Carlo Dropout (MCD), Deep Ensemble (DE), and Deep Evidential Regression\n(DER), in the specific context of camera localization. We exploited CMRNet, a\nDNN approach for multi-modal image to LiDAR map registration, by modifying its\ninternal configuration to allow for an extensive experimental activity with the\nthree methods on the KITTI dataset. Particularly significant has been the\napplication of DER. We achieve accurate camera localization and a calibrated\nuncertainty, to the point that some method can be used for detecting\nlocalization failures.",
    "descriptor": "",
    "authors": [
      "Matteo Vaghi",
      "Augusto Luis Ballardini",
      "Simone Fontana",
      "Domenico Giorgio Sorrenti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01234"
  },
  {
    "id": "arXiv:2211.01236",
    "title": "Isometric Representations in Neural Networks Improve Robustness",
    "abstract": "Artificial and biological agents cannon learn given completely random and\nunstructured data. The structure of data is encoded in the metric relationships\nbetween data points. In the context of neural networks, neuronal activity\nwithin a layer forms a representation reflecting the transformation that the\nlayer implements on its inputs. In order to utilize the structure in the data\nin a truthful manner, such representations should reflect the input distances\nand thus be continuous and isometric. Supporting this statement, recent\nfindings in neuroscience propose that generalization and robustness are tied to\nneural representations being continuously differentiable. In machine learning,\nmost algorithms lack robustness and are generally thought to rely on aspects of\nthe data that differ from those that humans use, as is commonly seen in\nadversarial attacks. During cross-entropy classification, the metric and\nstructural properties of network representations are usually broken both\nbetween and within classes. This side effect from training can lead to\ninstabilities under perturbations near locations where such structure is not\npreserved. One of the standard solutions to obtain robustness is to add ad hoc\nregularization terms, but to our knowledge, forcing representations to preserve\nthe metric structure of the input data as a stabilising mechanism has not yet\nbeen studied. In this work, we train neural networks to perform classification\nwhile simultaneously maintaining within-class metric structure, leading to\nisometric within-class representations. Such network representations turn out\nto be beneficial for accurate and robust inference. By stacking layers with\nthis property we create a network architecture that facilitates hierarchical\nmanipulation of internal neural representations. Finally, we verify that\nisometric regularization improves the robustness to adversarial attacks on\nMNIST.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Kosio Beshkov",
      "Jonas Verhellen",
      "Mikkel Elle Lepper\u00f8d"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.01236"
  },
  {
    "id": "arXiv:2211.01244",
    "title": "EquiMod: An Equivariance Module to Improve Self-Supervised Learning",
    "abstract": "Self-supervised visual representation methods are closing the gap with\nsupervised learning performance. These methods rely on maximizing the\nsimilarity between embeddings of related synthetic inputs created through data\naugmentations. This can be seen as a task that encourages embeddings to leave\nout factors modified by these augmentations, i.e. to be invariant to them.\nHowever, this only considers one side of the trade-off in the choice of the\naugmentations: they need to strongly modify the images to avoid simple solution\nshortcut learning (e.g. using only color histograms), but on the other hand,\naugmentations-related information may be lacking in the representations for\nsome downstream tasks (e.g. color is important for birds and flower\nclassification). Few recent works proposed to mitigate the problem of using\nonly an invariance task by exploring some form of equivariance to\naugmentations. This has been performed by learning additional embeddings\nspace(s), where some augmentation(s) cause embeddings to differ, yet in a\nnon-controlled way. In this work, we introduce EquiMod a generic equivariance\nmodule that structures the learned latent space, in the sense that our module\nlearns to predict the displacement in the embedding space caused by the\naugmentations. We show that applying that module to state-of-the-art invariance\nmodels, such as SimCLR and BYOL, increases the performances on CIFAR10 and\nImageNet datasets. Moreover, while our model could collapse to a trivial\nequivariance, i.e. invariance, we observe that it instead automatically learns\nto keep some augmentations-related information beneficial to the\nrepresentations.",
    "descriptor": "",
    "authors": [
      "Alexandre Devillers",
      "Mathieu Lefort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01244"
  },
  {
    "id": "arXiv:2211.01248",
    "title": "Exact Completeness of LP Hierarchies for Linear Codes",
    "abstract": "Determining the maximum size $A_2(n,d)$ of a binary code of blocklength $n$\nand distance $d$ remains an elusive open question even when restricted to the\nimportant class of linear codes. Recently, two linear programming hierarchies\nextending Delsarte's LP were independently proposed to upper bound\n$A_2^{\\text{Lin}}(n,d)$ (the analogue of $A_2(n,d)$ for linear codes). One of\nthese hierarchies, by the authors, was shown to be approximately complete in\nthe sense that the hierarchy converges to $A_2^{\\text{Lin}}(n,d)$ as the level\ngrows beyond $n^2$. Despite some structural similarities, not even approximate\ncompleteness was known for the other hierarchy by Loyfer and Linial.\nIn this work, we prove that both hierarchies recover the exact value of\n$A_2^{\\text{Lin}}(n,d)$ at level $n$. We also prove that at this level the\npolytope of Loyfer and Linial is integral.Even though these hierarchies seem\nless powerful than general hierarchies such as Sum-of-Squares, we show that\nthey have enough structure to yield exact completeness via pseudoprobabilities.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Leonardo Nagami Coregliano",
      "Fernando Granha Jeronimo",
      "Chris Jones"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.01248"
  },
  {
    "id": "arXiv:2211.01253",
    "title": "Fair Visual Recognition via Intervention with Proxy Features",
    "abstract": "Deep learning models often learn to make predictions that rely on sensitive\nsocial attributes like gender and race, which poses significant fairness risks,\nespecially in societal applications, e.g., hiring, banking, and criminal\njustice. Existing work tackles this issue by minimizing information about\nsocial attributes in models for debiasing. However, the high correlation\nbetween target task and social attributes makes bias mitigation incompatible\nwith target task accuracy. Recalling that model bias arises because the\nlearning of features in regard to bias attributes (i.e., bias features) helps\ntarget task optimization, we explore the following research question: \\emph{Can\nwe leverage proxy features to replace the role of bias feature in target task\noptimization for debiasing?} To this end, we propose \\emph{Proxy Debiasing}, to\nfirst transfer the target task's learning of bias information from bias\nfeatures to artificial proxy features, and then employ causal intervention to\neliminate proxy features in inference. The key idea of \\emph{Proxy Debiasing}\nis to design controllable proxy features to on one hand replace bias features\nin contributing to target task during the training stage, and on the other hand\neasily to be removed by intervention during the inference stage. This\nguarantees the elimination of bias features without affecting the target\ninformation, thus addressing the fairness-accuracy paradox in previous\ndebiasing solutions. We apply \\emph{Proxy Debiasing} to several benchmark\ndatasets, and achieve significant improvements over the state-of-the-art\ndebiasing methods in both of accuracy and fairness.",
    "descriptor": "",
    "authors": [
      "Yi Zhang",
      "Jitao Sang",
      "Junyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.01253"
  },
  {
    "id": "arXiv:2211.01254",
    "title": "CircleSnake: Instance Segmentation with Circle Representation",
    "abstract": "Circle representation has recently been introduced as a medical imaging\noptimized representation for more effective instance object detection on\nball-shaped medical objects. With its superior performance on instance\ndetection, it is appealing to extend the circle representation to instance\nmedical object segmentation. In this work, we propose CircleSnake, a simple\nend-to-end circle contour deformation-based segmentation method for ball-shaped\nmedical objects. Compared to the prevalent DeepSnake method, our contribution\nis three-fold: (1) We replace the complicated bounding box to octagon contour\ntransformation with a computation-free and consistent bounding circle to circle\ncontour adaption for segmenting ball-shaped medical objects; (2) Circle\nrepresentation has fewer degrees of freedom (DoF=2) as compared with the\noctagon representation (DoF=8), thus yielding a more robust segmentation\nperformance and better rotation consistency; (3) To the best of our knowledge,\nthe proposed CircleSnake method is the first end-to-end circle representation\ndeep segmentation pipeline method with consistent circle detection, circle\ncontour proposal, and circular convolution. The key innovation is to integrate\nthe circular graph convolution with circle detection into an end-to-end\ninstance segmentation framework, enabled by the proposed simple and consistent\ncircle contour representation. Glomeruli are used to evaluate the performance\nof the benchmarks. From the results, CircleSnake increases the average\nprecision of glomerular detection from 0.559 to 0.614. The Dice score increased\nfrom 0.804 to 0.849. The code has been released:\nhttps://github.com/hrlblab/CircleSnake",
    "descriptor": "\nComments: Machine Learning in Medical Imaging Workshop for 2022 MICCAI\n",
    "authors": [
      "Ethan H. Nguyen",
      "Haichun Yang",
      "Zuhayr Asad",
      "Ruining Deng",
      "Agnes B. Fogo",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01254"
  },
  {
    "id": "arXiv:2211.01255",
    "title": "Task-Oriented Over-the-Air Computation for Multi-Device Edge AI",
    "abstract": "Departing from the classic paradigm of data-centric designs, the 6G networks\nfor supporting edge AI features task-oriented techniques that focus on\neffective and efficient execution of AI task. Targeting end-to-end system\nperformance, such techniques are sophisticated as they aim to seamlessly\nintegrate sensing (data acquisition), communication (data transmission), and\ncomputation (data processing). Aligned with the paradigm shift, a task-oriented\nover-the-air computation (AirComp) scheme is proposed in this paper for\nmulti-device split-inference system. In the considered system, local feature\nvectors, which are extracted from the real-time noisy sensory data on devices,\nare aggregated over-the-air by exploiting the waveform superposition in a\nmultiuser channel. Then the aggregated features as received at a server are fed\ninto an inference model with the result used for decision making or control of\nactuators. To design inference-oriented AirComp, the transmit precoders at edge\ndevices and receive beamforming at edge server are jointly optimized to rein in\nthe aggregation error and maximize the inference accuracy. The problem is made\ntractable by measuring the inference accuracy using a surrogate metric called\ndiscriminant gain, which measures the discernibility of two object classes in\nthe application of object/event classification. It is discovered that the\nconventional AirComp beamforming design for minimizing the mean square error in\ngeneric AirComp with respect to the noiseless case may not lead to the optimal\nclassification accuracy. The reason is due to the overlooking of the fact that\nfeature dimensions have different sensitivity towards aggregation errors and\nare thus of different importance levels for classification. This issue is\naddressed in this work via a new task-oriented AirComp scheme designed by\ndirectly maximizing the derived discriminant gain.",
    "descriptor": "",
    "authors": [
      "Dingzhu Wen",
      "Xiang Jiao",
      "Peixi Liu",
      "Guangxu Zhu",
      "Yuanming Shi",
      "Kaibin Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01255"
  },
  {
    "id": "arXiv:2211.01256",
    "title": "An Aggregation of Aggregation Methods in Computational Pathology",
    "abstract": "Image analysis and machine learning algorithms operating on multi-gigapixel\nwhole-slide images (WSIs) often process a large number of tiles (sub-images)\nand require aggregating predictions from the tiles in order to predict\nWSI-level labels. In this paper, we present a review of existing literature on\nvarious types of aggregation methods with a view to help guide future research\nin the area of computational pathology (CPath). We propose a general CPath\nworkflow with three pathways that consider multiple levels and types of data\nand the nature of computation to analyse WSIs for predictive modelling. We\ncategorize aggregation methods according to the context and representation of\nthe data, features of computational modules and CPath use cases. We compare and\ncontrast different methods based on the principle of multiple instance\nlearning, perhaps the most commonly used aggregation method, covering a wide\nrange of CPath literature. To provide a fair comparison, we consider a specific\nWSI-level prediction task and compare various aggregation methods for that\ntask. Finally, we conclude with a list of objectives and desirable attributes\nof aggregation methods in general, pros and cons of the various approaches,\nsome recommendations and possible future directions.",
    "descriptor": "\nComments: 32 pages, 4 figures\n",
    "authors": [
      "Mohsin Bilal",
      "Robert Jewsbury",
      "Ruoyu Wang",
      "Hammam M. AlGhamdi",
      "Amina Asif",
      "Mark Eastwood",
      "Nasir Rajpoot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01256"
  },
  {
    "id": "arXiv:2211.01260",
    "title": "Executable Models and Instance Tracking for Decentralized Applications  -- Towards an Architecture Based on Blockchains and Cloud Platforms",
    "abstract": "The execution of decentralized applications on blockchains is limited today\nby technical and organizational barriers, including scalability and the high\ncomplexity to specify execution correctly for developers as well as for domain\nexperts in organizations. Overcoming these limitations could allow for\ndecentralized coordination beyond data, where distributed parties rely on\nhigher-level abstractions for coordinating their actions using decentralized\napplications, not limited to organizations. Towards this goal, the paper at\nhand proposes executable models as high-level abstraction that can be observed\nand tracked by distributed parties. In particular, it is investigated how\nexecutable models on cloud platforms can be coupled with smart contracts for\ntracking their execution, concluding with an architecture as exploratory\nresearch result towards supporting scalability and decentralized coordination.",
    "descriptor": "\nComments: Submission for BES2022: 3rd International Workshop on Blockchain and Enterprise Systems, 23-11, 2022, London, UK\n",
    "authors": [
      "Felix H\u00e4rer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.01260"
  },
  {
    "id": "arXiv:2211.01261",
    "title": "Where Do We Go From Here? Guidelines For Offline Recommender Evaluation",
    "abstract": "Various studies in recent years have pointed out large issues in the offline\nevaluation of recommender systems, making it difficult to assess whether true\nprogress has been made. However, there has been little research into what set\nof practices should serve as a starting point during experimentation. In this\npaper, we examine four larger issues in recommender system research regarding\nuncertainty estimation, generalization, hyperparameter optimization and dataset\npre-processing in more detail to arrive at a set of guidelines. We present a\nTrainRec, a lightweight and flexible toolkit for offline training and\nevaluation of recommender systems that implements these guidelines. Different\nfrom other frameworks, TrainRec is a toolkit that focuses on experimentation\nalone, offering flexible modules that can be can be used together or in\nisolation.\nFinally, we demonstrate TrainRec's usefulness by evaluating a diverse set of\ntwelve baselines across ten datasets. Our results show that (i) many results on\nsmaller datasets are likely not statistically significant, (ii) there are at\nleast three baselines that perform well on most datasets and should be\nconsidered in future experiments, and (iii) improved uncertainty quantification\n(via nested CV and statistical testing) rules out some reported differences\nbetween linear and neural methods. Given these results, we advocate that future\nresearch should standardize evaluation using our suggested guidelines.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Tobias Schnabel"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01261"
  },
  {
    "id": "arXiv:2211.01263",
    "title": "A Quantum Kernel Learning Approach to Acoustic Modeling for Spoken  Command Recognition",
    "abstract": "We propose a quantum kernel learning (QKL) framework to address the inherent\ndata sparsity issues often encountered in training large-scare acoustic models\nin low-resource scenarios. We project acoustic features based on\nclassical-to-quantum feature encoding. Different from existing quantum\nconvolution techniques, we utilize QKL with features in the quantum space to\ndesign kernel-based classifiers. Experimental results on challenging spoken\ncommand recognition tasks for a few low-resource languages, such as Arabic,\nGeorgian, Chuvash, and Lithuanian, show that the proposed QKL-based hybrid\napproach attains good improvements over existing classical and quantum\nsolutions.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Chao-Han Huck Yang",
      "Bo Li",
      "Yu Zhang",
      "Nanxin Chen",
      "Tara N. Sainath",
      "Sabato Marco Siniscalchi",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.01263"
  },
  {
    "id": "arXiv:2211.01266",
    "title": "Knowing the Past to Predict the Future: Reinforcement Virtual Learning",
    "abstract": "Reinforcement Learning (RL)-based control system has received considerable\nattention in recent decades. However, in many real-world problems, such as\nBatch Process Control, the environment is uncertain, which requires expensive\ninteraction to acquire the state and reward values. In this paper, we present a\ncost-efficient framework, such that the RL model can evolve for itself in a\nVirtual Space using the predictive models with only historical data. The\nproposed framework enables a step-by-step RL model to predict the future state\nand select optimal actions for long-sight decisions. The main focuses are\nsummarized as: 1) how to balance the long-sight and short-sight rewards with an\noptimal strategy; 2) how to make the virtual model interacting with real\nenvironment to converge to a final learning policy. Under the experimental\nsettings of Fed-Batch Process, our method consistently outperforms the existing\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Peng Zhang",
      "Yawen Huang",
      "Bingzhang Hu",
      "Shizheng Wang",
      "Haoran Duan",
      "Noura Al Moubayed",
      "Yefeng Zheng",
      "Yang Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01266"
  },
  {
    "id": "arXiv:2211.01267",
    "title": "Multi-Vector Retrieval as Sparse Alignment",
    "abstract": "Multi-vector retrieval models improve over single-vector dual encoders on\nmany information retrieval tasks. In this paper, we cast the multi-vector\nretrieval problem as sparse alignment between query and document tokens. We\npropose AligneR, a novel multi-vector retrieval model that learns sparsified\npairwise alignments between query and document tokens (e.g. `dog' vs. `puppy')\nand per-token unary saliences reflecting their relative importance for\nretrieval. We show that controlling the sparsity of pairwise token alignments\noften brings significant performance gains. While most factoid questions\nfocusing on a specific part of a document require a smaller number of\nalignments, others requiring a broader understanding of a document favor a\nlarger number of alignments. Unary saliences, on the other hand, decide whether\na token ever needs to be aligned with others for retrieval (e.g. `kind' from\n`kind of currency is used in new zealand}'). With sparsified unary saliences,\nwe are able to prune a large number of query and document token vectors and\nimprove the efficiency of multi-vector retrieval. We learn the sparse unary\nsaliences with entropy-regularized linear programming, which outperforms other\nmethods to achieve sparsity. In a zero-shot setting, AligneR scores 51.1 points\nnDCG@10, achieving a new retriever-only state-of-the-art on 13 tasks in the\nBEIR benchmark. In addition, adapting pairwise alignments with a few examples\n(<= 8) further improves the performance up to 15.7 points nDCG@10 for argument\nretrieval tasks. The unary saliences of AligneR helps us to keep only 20% of\nthe document token representations with minimal performance loss. We further\nshow that our model often produces interpretable alignments and significantly\nimproves its performance when initialized from larger language models.",
    "descriptor": "",
    "authors": [
      "Yujie Qian",
      "Jinhyuk Lee",
      "Sai Meher Karthik Duddu",
      "Zhuyun Dai",
      "Siddhartha Brahma",
      "Iftekhar Naim",
      "Tao Lei",
      "Vincent Y. Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.01267"
  },
  {
    "id": "arXiv:2211.01270",
    "title": "Secure and Efficient Privacy-preserving Authentication Scheme using  Cuckoo Filter in Remote Patient Monitoring Network",
    "abstract": "With the ubiquitous advancement in smart medical devices and systems, the\npotential of Remote Patient Monitoring (RPM) network is evolving in modern\nhealthcare systems. The medical professionals (doctors, nurses, or medical\nexperts) can access vitals and sensitive physiological information about the\npatients and provide proper treatment to improve the quality of life through\nthe RPM network. However, the wireless nature of communication in the RPM\nnetwork makes it challenging to design an efficient mechanism for secure\ncommunication. Many authentication schemes have been proposed in recent years\nto ensure the security of the RPM network. Pseudonym, digital signature, and\nAuthenticated Key Exchange (AKE) protocols are used for the Internet of Medical\nThings (IoMT) to develop secure authorization and privacy-preserving\ncommunication. However, traditional authentication protocols face overhead\nchallenges due to maintaining a large set of key-pairs or pseudonyms results on\nthe hospital cloud server. In this research work, we identify this research gap\nand propose a novel secure and efficient privacy-preserving authentication\nscheme using cuckoo filters for the RPM network. The use of cuckoo filters in\nour proposed scheme provides an efficient way for mutual anonymous\nauthentication and a secret shared key establishment process between medical\nprofessionals and patients. Moreover, we identify the misbehaving sensor nodes\nusing a correlation-based anomaly detection model to establish secure\ncommunication. The security analysis and formal security validation using SPAN\nand AVISPA tools show the robustness of our proposed scheme against message\nmodification attacks, replay attacks, and man-in-the-middle attacks.",
    "descriptor": "",
    "authors": [
      "Shafika Showkat Moni",
      "Deepti Gupta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01270"
  },
  {
    "id": "arXiv:2211.01282",
    "title": "Numerical integration of Schr\u00f6dinger maps via the Hasimoto transform",
    "abstract": "We introduce a numerical approach to computing the Schr\\\"odinger map (SM)\nbased on the Hasimoto transform which relates the SM flow to a cubic nonlinear\nSchr\\\"odinger (NLS) equation. In exploiting this nonlinear transform we are\nable to introduce the first fully explicit unconditionally stable symmetric\nintegrators for the SM equation. Our approach consists of two parts: an\nintegration of the NLS equation followed by the numerical evaluation of the\nHasimoto transform. Motivated by the desire to study rough solutions to the SM\nequation, we also introduce a new symmetric low-regularity integrator for the\nNLS equation. This is combined with our novel fast low-regularity Hasimoto\n(FLowRH) transform, based on a tailored analysis of the resonance structures in\nthe Magnus expansion and a fast realisation based on block-Toeplitz partitions,\nto yield an efficient low-regularity integrator for the SM equation. This\nscheme in particular allows us to obtain approximations to the SM in a more\ngeneral regime (i.e. under lower regularity assumptions) than previously\nproposed methods. The favorable properties of our methods are exhibited both in\ntheoretical convergence analysis and in numerical experiments.",
    "descriptor": "",
    "authors": [
      "Valeria Banica",
      "Georg Maierhofer",
      "Katharina Schratz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.01282"
  },
  {
    "id": "arXiv:2211.01288",
    "title": "Characterizing Intrinsic Compositionality In Transformers With Tree  Projections",
    "abstract": "When trained on language data, do transformers learn some arbitrary\ncomputation that utilizes the full capacity of the architecture or do they\nlearn a simpler, tree-like computation, hypothesized to underlie compositional\nmeaning systems like human languages? There is an apparent tension between\ncompositional accounts of human language understanding, which are based on a\nrestricted bottom-up computational process, and the enormous success of neural\nmodels like transformers, which can route information arbitrarily between\ndifferent parts of their input. One possibility is that these models, while\nextremely flexible in principle, in practice learn to interpret language\nhierarchically, ultimately building sentence representations close to those\npredictable by a bottom-up, tree-structured model. To evaluate this\npossibility, we describe an unsupervised and parameter-free method to\n\\emph{functionally project} the behavior of any transformer into the space of\ntree-structured networks. Given an input sentence, we produce a binary tree\nthat approximates the transformer's representation-building process and a score\nthat captures how \"tree-like\" the transformer's behavior is on the input. While\ncalculation of this score does not require training any additional models, it\nprovably upper-bounds the fit between a transformer and any tree-structured\napproximation. Using this method, we show that transformers for three different\ntasks become more tree-like over the course of training, in some cases\nunsupervisedly recovering the same trees as supervised parsers. These trees, in\nturn, are predictive of model behavior, with more tree-like models generalizing\nbetter on tests of compositional generalization.",
    "descriptor": "\nComments: Preprint. Under Review\n",
    "authors": [
      "Shikhar Murty",
      "Pratyusha Sharma",
      "Jacob Andreas",
      "Christopher D. Manning"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01288"
  },
  {
    "id": "arXiv:2211.01289",
    "title": "Boosting word frequencies in authorship attribution",
    "abstract": "In this paper, I introduce a simple method of computing relative word\nfrequencies for authorship attribution and similar stylometric tasks. Rather\nthan computing relative frequencies as the number of occurrences of a given\nword divided by the total number of tokens in a text, I argue that a more\nefficient normalization factor is the total number of relevant tokens only. The\nnotion of relevant words includes synonyms and, usually, a few dozen other\nwords in some ways semantically similar to a word in question. To determine\nsuch a semantic background, one of word embedding models can be used. The\nproposed method outperforms classical most-frequent-word approaches\nsubstantially, usually by a few percentage points depending on the input\nsettings.",
    "descriptor": "",
    "authors": [
      "Maciej Eder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01289"
  },
  {
    "id": "arXiv:2211.01290",
    "title": "An Algebraic Framework for Stock & Flow Diagrams and Dynamical Systems  Using Category Theory",
    "abstract": "Mathematical modeling of infectious disease at scale is important, but\nchallenging. Some of these difficulties can be alleviated by an approach that\ntakes diagrams seriously as mathematical formalisms in their own right. Stock &\nflow diagrams are widely used as broadly accessible building blocks for\ninfectious disease modeling. In this chapter, rather than focusing on the\nunderlying mathematics, we informally use communicable disease examples created\nby the implemented software of StockFlow.jl to explain the basics,\ncharacteristics, and benefits of the categorical framework. We first\ncharacterize categorical stock & flow diagrams, and note the clear separation\nbetween the syntax of stock & flow diagrams and their semantics, demonstrating\nthree examples of semantics already implemented in the software: ODEs, causal\nloop diagrams, and system structure diagrams. We then establish composition and\nstratification frameworks and examples for stock & flow diagrams. Applying\ncategory theory, these frameworks can build large diagrams from smaller ones in\na modular fashion. Finally, we introduce the open-source ModelCollab software\nfor diagram-centric real-time collaborative modeling. Using the graphical user\ninterface, this web-based software allows the user to undertake the types of\ncategorically-rooted operations discussed above, but without any knowledge of\ntheir categorical foundations.",
    "descriptor": "",
    "authors": [
      "Xiaoyan Li",
      "John Baez",
      "Sophie Libkind",
      "Eric Redekopp",
      "Long Pham",
      "Nathaniel D Osgood"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01290"
  },
  {
    "id": "arXiv:2211.01291",
    "title": "SoK: A Stratified Approach to Blockchain Decentralization",
    "abstract": "Decentralization has been touted as the principal security advantage which\npropelled blockchain systems at the forefront of developments in the financial\ntechnology space. Its exact semantics nevertheless remain highly contested and\nambiguous, with proponents and critics disagreeing widely on the level of\ndecentralization offered. To address this, we put forth a systematization of\nthe current landscape with respect to decentralization and we derive a\nmethodology that can help direct future research towards defining and measuring\ndecentralization. Our approach dissects blockchain systems into multiple\nlayers, or strata, each possibly encapsulating multiple categories, and enables\na unified method for measuring decentralization in each one. Our layers are (1)\nhardware, (2) software, (3) network, (4) consensus, (5) economics\n(\"tokenomics\"), (6) API, (7) governance, and (8) geography. Armed with this\nstratification, we examine for each layer which pertinent properties of\ndistributed ledgers (safety, liveness, privacy, stability) can be at risk due\nto centralization and in what way. Our work highlights the challenges in\nmeasuring and achieving decentralization, points to the degree of\n(de)centralization of various existing systems, where such assessment can be\nmade from presently available public information, and suggests potential\nmetrics and directions where future research is needed. We also introduce the\n\"Minimum Decentralization Test\", as a way to assess the decentralization state\nof a blockchain system and, as an exemplary case, we showcase how it can be\napplied to Bitcoin.",
    "descriptor": "",
    "authors": [
      "Dimitris Karakostas",
      "Aggelos Kiayias",
      "Christina Ovezik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01291"
  },
  {
    "id": "arXiv:2211.01292",
    "title": "Learning an Artificial Language for Knowledge-Sharing in Multilingual  Translation",
    "abstract": "The cornerstone of multilingual neural translation is shared representations\nacross languages. Given the theoretically infinite representation power of\nneural networks, semantically identical sentences are likely represented\ndifferently. While representing sentences in the continuous latent space\nensures expressiveness, it introduces the risk of capturing of irrelevant\nfeatures which hinders the learning of a common representation. In this work,\nwe discretize the encoder output latent space of multilingual models by\nassigning encoder states to entries in a codebook, which in effect represents\nsource sentences in a new artificial language. This discretization process not\nonly offers a new way to interpret the otherwise black-box model\nrepresentations, but, more importantly, gives potential for increasing\nrobustness in unseen testing conditions. We validate our approach on\nlarge-scale experiments with realistic data volumes and domains. When tested in\nzero-shot conditions, our approach is competitive with two strong alternatives\nfrom the literature. We also use the learned artificial language to analyze\nmodel behavior, and discover that using a similar bridge language increases\nknowledge-sharing among the remaining languages.",
    "descriptor": "\nComments: WMT 2022\n",
    "authors": [
      "Danni Liu",
      "Jan Niehues"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01292"
  },
  {
    "id": "arXiv:2211.01294",
    "title": "Driver Digital Twin for Online Prediction of Personalized Lane Change  Behavior",
    "abstract": "Connected and automated vehicles (CAVs) are supposed to share the road with\nhuman-driven vehicles (HDVs) in a foreseeable future. Therefore, considering\nthe mixed traffic environment is more pragmatic, as the well-planned operation\nof CAVs may be interrupted by HDVs. In the circumstance that human behaviors\nhave significant impacts, CAVs need to understand HDV behaviors to make safe\nactions. In this study, we develop a Driver Digital Twin (DDT) for the online\nprediction of personalized lane change behavior, allowing CAVs to predict\nsurrounding vehicles' behaviors with the help of the digital twin technology.\nDDT is deployed on a vehicle-edge-cloud architecture, where the cloud server\nmodels the driver behavior for each HDV based on the historical naturalistic\ndriving data, while the edge server processes the real-time data from each\ndriver with his/her digital twin on the cloud to predict the lane change\nmaneuver. The proposed system is first evaluated on a human-in-the-loop\nco-simulation platform, and then in a field implementation with three passenger\nvehicles connected through the 4G/LTE cellular network. The lane change\nintention can be recognized in 6 seconds on average before the vehicle crosses\nthe lane separation line, and the Mean Euclidean Distance between the predicted\ntrajectory and GPS ground truth is 1.03 meters within a 4-second prediction\nwindow. Compared to the general model, using a personalized model can improve\nprediction accuracy by 27.8%. The demonstration video of the proposed system\ncan be watched at https://youtu.be/5cbsabgIOdM.",
    "descriptor": "",
    "authors": [
      "Xishun Liao",
      "Xuanpeng Zhao",
      "Ziran Wang",
      "Zhouqiao Zhao",
      "Kyungtae Han",
      "Rohit Gupta",
      "Matthew J. Barth",
      "Guoyuan Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01294"
  },
  {
    "id": "arXiv:2211.01297",
    "title": "C3SASR: Cheap Causal Convolutions for Self-Attentive Sequential  Recommendation",
    "abstract": "Sequential Recommendation is a prominent topic in current research, which\nuses user behavior sequence as an input to predict future behavior. By\nassessing the correlation strength of historical behavior through the dot\nproduct, the model based on the self-attention mechanism can capture the\nlong-term preference of the sequence. However, it has two limitations. On the\none hand, it does not effectively utilize the items' local context information\nwhen determining the attention and creating the sequence representation. On the\nother hand, the convolution and linear layers often contain redundant\ninformation, which limits the ability to encode sequences. In this paper, we\npropose a self-attentive sequential recommendation model based on cheap causal\nconvolution. It utilizes causal convolutions to capture items' local\ninformation for calculating attention and generating sequence embedding. It\nalso uses cheap convolutions to improve the representations by lightweight\nstructure. We evaluate the effectiveness of the proposed model in terms of both\naccurate and calibrated sequential recommendation. Experiments on benchmark\ndatasets show that the proposed model can perform better in single- and\nmulti-objective recommendation scenarios.",
    "descriptor": "",
    "authors": [
      "Jiayi Chen",
      "Wen Wu",
      "Liang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.01297"
  },
  {
    "id": "arXiv:2211.01298",
    "title": "Contract Composition for Dynamical Control Systems: Definition and  Verification using Linear Programming",
    "abstract": "Designing large-scale control systems to satisfy complex specifications is\nhard in practice, as most formal methods are limited to systems of modest size.\nContract theory has been proposed as a modular alternative to formal methods in\ncontrol, in which specifications are defined by assumptions on the input to a\ncomponent and guarantees on its output. However, current contract-based methods\nfor control systems either prescribe guarantees on the state of the system,\ngoing against the spirit of contract theory, or can only support rudimentary\ncompositions.\nIn this paper, we present a contract-based modular framework for\ndiscrete-time dynamical control systems. We extend the definition of contracts\nby allowing the assumption on the input at a time $k$ to depend on outputs up\nto time $k-1$, which is essential when considering the feedback connection of\nan unregulated dynamical system and a controller. We also define contract\ncomposition for arbitrary interconnection topologies, under the pretence of\nwell-posedness, and prove that this notion supports modular design, analysis\nand verification. This is done using graph theory methods, and specifically\nusing the notions of topological ordering and backward-reachable nodes. Lastly,\nwe use $k$-induction to present an algorithm for verifying vertical contracts,\nwhich are claims of the form \"the conjugation of given component-level\ncontracts is a stronger specification than a given contract on the integrated\nsystem\". These algorithms are based on linear programming, and scale linearly\nwith the number of components in the interconnected network. A numerical\nexample is provided to demonstrate the scalability of the presented approach,\nas well as the modularity achieved by using it.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Miel Sharf",
      "Bart Besselink",
      "Karl Henrik Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.01298"
  },
  {
    "id": "arXiv:2211.01301",
    "title": "Computational Desire Line Analysis of Cyclists on the Dybb\u00f8lsbro  Intersection in Copenhagen",
    "abstract": "Contemporary street design prioritizes vehicular traffic flow and assumes\ncompliant road users. However, actual human behavior is typically neglected,\nespecially of cyclists, leading to streets with inadequate wayfinding and\nprotection from vehicular traffic. To improve planning, here we develop a\ncomputational method to detect cyclist trajectories from video recordings and\napply it to the Dybb{\\o}lsbro intersection in Copenhagen, Denmark. In one hour\nof footage we find hundreds of trajectories that contradict the design,\nexplainable by the desire for straightforward, uninterrupted travel largely not\nprovided by the intersection. This neglect and the prioritization of vehicular\ntraffic highlight opportunities for improving Danish intersection design.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Simon Martin Breum",
      "Bojan Kostic",
      "Michael Szell"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.01301"
  },
  {
    "id": "arXiv:2211.01303",
    "title": "A Bayesian Learning, Greedy agglomerative clustering approach and  evaluation techniques for Author Name Disambiguation Problem",
    "abstract": "Author names often suffer from ambiguity owing to the same author appearing\nunder different names and multiple authors possessing similar names. It creates\ndifficulty in associating a scholarly work with the person who wrote it,\nthereby introducing inaccuracy in credit attribution, bibliometric analysis,\nsearch-by-author in a digital library, and expert discovery. A plethora of\ntechniques for disambiguation of author names has been proposed in the\nliterature. I try to focus on the research efforts targeted to disambiguate\nauthor names. I first go through the conventional methods, then I discuss\nevaluation techniques and the clustering model which finally leads to the\nBayesian learning and Greedy agglomerative approach. I believe this\nconcentrated review will be useful for the research community because it\ndiscusses techniques applied to a very large real database that is actively\nused worldwide. The Bayesian and the greedy agglomerative approach used will\nhelp to tackle AND problems in a better way. Finally, I try to outline a few\ndirections for future work",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Shashwat Sourav"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01303"
  },
  {
    "id": "arXiv:2211.01310",
    "title": "A Joint Framework Towards Class-aware and Class-agnostic Alignment for  Few-shot Segmentation",
    "abstract": "Few-shot segmentation (FSS) aims to segment objects of unseen classes given\nonly a few annotated support images. Most existing methods simply stitch query\nfeatures with independent support prototypes and segment the query image by\nfeeding the mixed features to a decoder. Although significant improvements have\nbeen achieved, existing methods are still face class biases due to class\nvariants and background confusion. In this paper, we propose a joint framework\nthat combines more valuable class-aware and class-agnostic alignment guidance\nto facilitate the segmentation. Specifically, we design a hybrid alignment\nmodule which establishes multi-scale query-support correspondences to mine the\nmost relevant class-aware information for each query image from the\ncorresponding support features. In addition, we explore utilizing base-classes\nknowledge to generate class-agnostic prior mask which makes a distinction\nbetween real background and foreground by highlighting all object regions,\nespecially those of unseen classes. By jointly aggregating class-aware and\nclass-agnostic alignment guidance, better segmentation performances are\nobtained on query images. Extensive experiments on PASCAL-$5^i$ and COCO-$20^i$\ndatasets demonstrate that our proposed joint framework performs better,\nespecially on the 1-shot setting.",
    "descriptor": "",
    "authors": [
      "Kai Huang",
      "Mingfei Cheng",
      "Yang Wang",
      "Bochen Wang",
      "Ye Xi",
      "Feigege Wang",
      "Peng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01310"
  },
  {
    "id": "arXiv:2211.01311",
    "title": "Distill and Collect for Semi-Supervised Temporal Action Segmentation",
    "abstract": "Recent temporal action segmentation approaches have been very effective.\nHowever, most of these approaches need frame annotations to train. These\nannotations are very expensive and time-consuming to obtain. This limits their\nperformances when only limited annotated data is available. In contrast, we can\neasily collect a large corpus of in-domain unannotated videos by scavenging\nthrough the internet. Thus, this paper proposes an approach for the temporal\naction segmentation task that can simultaneously leverage knowledge from\nannotated and unannotated video sequences. Our approach uses multi-stream\ndistillation that repeatedly refines and finally combines their frame\npredictions. Our model also predicts the action order, which is later used as a\ntemporal constraint while estimating frames labels to counter the lack of\nsupervision for unannotated videos. In the end, our evaluation of the proposed\napproach on two different datasets demonstrates its capability to achieve\ncomparable performance to the full supervision despite limited annotation.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.06669 by other authors\n",
    "authors": [
      "Sovan Biswas",
      "Anthony Rhodes",
      "Ramesh Manuvinakurike",
      "Giuseppe Raffa",
      "Richard Beckwith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01311"
  },
  {
    "id": "arXiv:2211.01315",
    "title": "Continual Conscious Active Fine-Tuning to Robustify Online Machine  Learning Models Against Data Distribution Shifts",
    "abstract": "Unlike their offline traditional counterpart, online machine learning models\nare capable of handling data distribution shifts while serving at the test\ntime. However, they have limitations in addressing this phenomenon. They are\neither expensive or unreliable. We propose augmenting an online learning\napproach called test-time adaptation with a continual conscious active\nfine-tuning layer to develop an enhanced variation that can handle drastic data\ndistribution shifts reliably and cost-effectively. The proposed augmentation\nincorporates the following aspects: a continual aspect to confront the\never-ending data distribution shifts, a conscious aspect to imply that\nfine-tuning is a distribution-shift-aware process that occurs at the\nappropriate time to address the recently detected data distribution shifts, and\nan active aspect to indicate employing human-machine collaboration for the\nrelabeling to be cost-effective and practical for diverse applications. Our\nempirical results show that the enhanced test-time adaptation variation\noutperforms the traditional variation by a factor of two.",
    "descriptor": "",
    "authors": [
      "Shawqi Al-Maliki",
      "Faissal El Bouanani",
      "Mohamed Abdallah",
      "Junaid Qadir",
      "Ala Al-Fuqaha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01315"
  },
  {
    "id": "arXiv:2211.01316",
    "title": "Cluster Assignment in Multi-Agent Systems : Sparsity Bounds and Fault  Tolerance",
    "abstract": "We study cluster assignment in homogeneous diffusive multi-agent networks.\nGiven the number of clusters and agents within each cluster, we design the\nnetwork graph ensuring the system will converge to the prescribed cluster\nconfiguration. Using recent results linking clustering and symmetries, we show\nthat it is possible to design an oriented graph for which the action of the\nautomorphism group of the graph has orbits of predetermined sizes, guaranteeing\nthe network will converge to the prescribed cluster configuration. We provide\nbounds on the number of edges needed to construct these graphs along with a\nconstructive approach for their generation. We also consider the robustness of\nthe clustering process under agent malfunction.",
    "descriptor": "\nComments: 12 pages, 6 figures. arXiv admin note: text overlap with arXiv:2203.06642\n",
    "authors": [
      "Miel Sharf",
      "Daniel Zelazo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.01316"
  },
  {
    "id": "arXiv:2211.01317",
    "title": "Low-Resource Music Genre Classification with Advanced Neural Model  Reprogramming",
    "abstract": "Transfer learning (TL) approaches have shown promising results when handling\ntasks with limited training data. However, considerable memory and\ncomputational resources are often required for fine-tuning pre-trained neural\nnetworks with target domain data. In this work, we introduce a novel method for\nleveraging pre-trained models for low-resource (music) classification based on\nthe concept of Neural Model Reprogramming (NMR). NMR aims at re-purposing a\npre-trained model from a source domain to a target domain by modifying the\ninput of a frozen pre-trained model. In addition to the known,\ninput-independent, reprogramming method, we propose an advanced reprogramming\nparadigm: Input-dependent NMR, to increase adaptability to complex input data\nsuch as musical audio. Experimental results suggest that a neural model\npre-trained on large-scale datasets can successfully perform music genre\nclassification by using this reprogramming method. The two proposed\nInput-dependent NMR TL methods outperform fine-tuning-based TL methods on a\nsmall genre classification dataset.",
    "descriptor": "\nComments: Submitted to ICASSP 2023. Some experimental results were reduced due to the space limit. The implementation will be available at this https URL\n",
    "authors": [
      "Yun-Ning Hung",
      "Chao-Han Huck Yang",
      "Pin-Yu Chen",
      "Alexander Lerch"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01317"
  },
  {
    "id": "arXiv:2211.01324",
    "title": "eDiffi: Text-to-Image Diffusion Models with an Ensemble of Expert  Denoisers",
    "abstract": "Large-scale diffusion-based generative models have led to breakthroughs in\ntext-conditioned high-resolution image synthesis. Starting from random noise,\nsuch text-to-image diffusion models gradually synthesize images in an iterative\nfashion while conditioning on text prompts. We find that their synthesis\nbehavior qualitatively changes throughout this process: Early in sampling,\ngeneration strongly relies on the text prompt to generate text-aligned content,\nwhile later, the text conditioning is almost entirely ignored. This suggests\nthat sharing model parameters throughout the entire generation process may not\nbe ideal. Therefore, in contrast to existing works, we propose to train an\nensemble of text-to-image diffusion models specialized for different synthesis\nstages. To maintain training efficiency, we initially train a single model,\nwhich is then split into specialized models that are trained for the specific\nstages of the iterative generation process. Our ensemble of diffusion models,\ncalled eDiffi, results in improved text alignment while maintaining the same\ninference computation cost and preserving high visual quality, outperforming\nprevious large-scale text-to-image diffusion models on the standard benchmark.\nIn addition, we train our model to exploit a variety of embeddings for\nconditioning, including the T5 text, CLIP text, and CLIP image embeddings. We\nshow that these different embeddings lead to different behaviors. Notably, the\nCLIP image embedding allows an intuitive way of transferring the style of a\nreference image to the target text-to-image output. Lastly, we show a technique\nthat enables eDiffi's \"paint-with-words\" capability. A user can select the word\nin the input text and paint it in a canvas to control the output, which is very\nhandy for crafting the desired image in mind. The project page is available at\nhttps://deepimagination.cc/eDiffi/",
    "descriptor": "",
    "authors": [
      "Yogesh Balaji",
      "Seungjun Nah",
      "Xun Huang",
      "Arash Vahdat",
      "Jiaming Song",
      "Karsten Kreis",
      "Miika Aittala",
      "Timo Aila",
      "Samuli Laine",
      "Bryan Catanzaro",
      "Tero Karras",
      "Ming-Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01324"
  },
  {
    "id": "arXiv:2211.01327",
    "title": "Predicting phoneme-level prosody latents using AR and flow-based Prior  Networks for expressive speech synthesis",
    "abstract": "A large part of the expressive speech synthesis literature focuses on\nlearning prosodic representations of the speech signal which are then modeled\nby a prior distribution during inference. In this paper, we compare different\nprior architectures at the task of predicting phoneme level prosodic\nrepresentations extracted with an unsupervised FVAE model. We use both\nsubjective and objective metrics to show that normalizing flow based prior\nnetworks can result in more expressive speech at the cost of a slight drop in\nquality. Furthermore, we show that the synthesized speech has higher\nvariability, for a given text, due to the nature of normalizing flows. We also\npropose a Dynamical VAE model, that can generate higher quality speech although\nwith decreased expressiveness and variability compared to the flow based\nmodels.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Konstantinos Klapsas",
      "Karolos Nikitaras",
      "Nikolaos Ellinas",
      "June Sig Sung",
      "Inchul Hwang",
      "Spyros Raptis",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01327"
  },
  {
    "id": "arXiv:2211.01328",
    "title": "Diversely Regularized Matrix Factorization for Accurate and Aggregately  Diversified Recommendation",
    "abstract": "When recommending personalized top-$k$ items to users, how can we recommend\nthe items diversely to them while satisfying their needs? Aggregately\ndiversified recommender systems aim to recommend a variety of items across\nwhole users without sacrificing the recommendation accuracy. They increase the\nexposure opportunities of various items, which in turn increase potential\nrevenue of sellers as well as user satisfaction. However, it is challenging to\ntackle aggregate-level diversity with a matrix factorization (MF), one of the\nmost common recommendation model, since skewed real world data lead to skewed\nrecommendation results of MF. In this work, we propose DivMF (Diversely\nRegularized Matrix Factorization), a novel matrix factorization method for\naggregately diversified recommendation. DivMF regularizes a score matrix of an\nMF model to maximize coverage and entropy of top-$k$ recommendation lists to\naggregately diversify the recommendation results. We also propose an unmasking\nmechanism and carefully designed mi i-batch learning technique for accurate and\nefficient training. Extensive experiments on real-world datasets show that\nDivMF achieves the state-of-the-art performance in aggregately diversified\nrecommendation.",
    "descriptor": "\nComments: 9 pages, 7 figures, 2 tables\n",
    "authors": [
      "Jongjin Kim",
      "Hyunsik Jeon",
      "Jaeri Lee",
      "U Kang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01328"
  },
  {
    "id": "arXiv:2211.01329",
    "title": "A Hybrid Adaptive Velocity Aided Navigation Filter with Application to  INS/DVL Fusion",
    "abstract": "Autonomous underwater vehicles (AUV) are commonly used in many underwater\napplications. Usually, inertial sensors and Doppler velocity log readings are\nused in a nonlinear filter to estimate the AUV navigation solution. The process\nnoise covariance matrix is tuned according to the inertial sensors'\ncharacteristics. This matrix greatly influences filter accuracy, robustness,\nand performance. A common practice is to assume that this matrix is fixed\nduring the AUV operation. However, it varies over time as the amount of\nuncertainty is unknown. Therefore, adaptive tuning of this matrix can lead to a\nsignificant improvement in the filter performance. In this work, we propose a\nlearning-based adaptive velocity-aided navigation filter. To that end,\nhandcrafted features are generated and used to tune the momentary system noise\ncovariance matrix. Once the process noise covariance is learned, it is fed into\nthe model-based navigation filter. Simulation results show the benefits of our\napproach compared to other adaptive approaches.",
    "descriptor": "\nComments: 5 pages. arXiv admin note: substantial text overlap with arXiv:2207.12082\n",
    "authors": [
      "Barak Or",
      "Itzik Klein"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.01329"
  },
  {
    "id": "arXiv:2211.01332",
    "title": "A Health Focused Text Classification Tool (HFTCT)",
    "abstract": "Due to the high number of users on social media and the massive amounts of\nqueries requested every second to share a new video, picture, or message,\nsocial platforms struggle to manage this humungous amount of data that is\nendlessly coming in. HFTCT relies on wordlists to classify opinions. It can\ncarry out its tasks reasonably well; however, sometimes, the wordlists\nthemselves fail to be reliable as they are a limited source of positive and\nnegative words.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Baadr Suleman M Alwheepy",
      "Leandros Maglaras",
      "Nick Ayres"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.01332"
  },
  {
    "id": "arXiv:2211.01333",
    "title": "Item-based Variational Auto-encoder for Fair Music Recommendation",
    "abstract": "We present our solution for the EvalRS DataChallenge. The EvalRS\nDataChallenge aims to build a more realistic recommender system considering\naccuracy, fairness, and diversity in evaluation. Our proposed system is based\non an ensemble between an item-based variational auto-encoder (VAE) and a\nBayesian personalized ranking matrix factorization (BPRMF). To mitigate the\nbias in popularity, we use an item-based VAE for each popularity group with an\nadditional fairness regularization. To make a reasonable recommendation even\nthe predictions are inaccurate, we combine the recommended list of BPRMF and\nthat of item-based VAE. Through the experiments, we demonstrate that the\nitem-based VAE with fairness regularization significantly reduces popularity\nbias compared to the user-based VAE. The ensemble between the item-based VAE\nand BPRMF makes the top-1 item similar to the ground truth even the predictions\nare inaccurate. Finally, we propose a `Coefficient Variance based Fairness' as\na novel evaluation metric based on our reflections from the extensive\nexperiments.",
    "descriptor": "\nComments: 6pages, CIKM 2022 Data challenge\n",
    "authors": [
      "Jinhyeok Park",
      "Dain Kim",
      "Dongwoo Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01333"
  },
  {
    "id": "arXiv:2211.01334",
    "title": "MemoNet:Memorizing Representations of All Cross Features Efficiently via  Multi-Hash Codebook Network for CTR Prediction",
    "abstract": "New findings in natural language processing(NLP) demonstrate that the strong\nmemorization capability contributes a lot to the success of large language\nmodels.This inspires us to explicitly bring an independent memory mechanism\ninto CTR ranking model to learn and memorize all cross features'\nrepresentations.In this paper,we propose multi-Hash Codebook NETwork(HCNet) as\nthe memory mechanism for efficiently learning and memorizing representations of\nall cross features in CTR tasks.HCNet uses multi-hash codebook as the main\nmemory place and the whole memory procedure consists of three phases:\nmulti-hash addressing,memory restoring and feature shrinking.HCNet can be\nregarded as a general module and can be incorporated into any current deep CTR\nmodel.We also propose a new CTR model named MemoNet which combines HCNet with a\nDNN backbone.Extensive experimental results on three public datasets show that\nMemoNet reaches superior performance over state-of-the-art approaches and\nvalidate the effectiveness of HCNet as a strong memory module.Besides, MemoNet\nshows the prominent feature of big models in NLP,which means we can enlarge the\nsize of codebook in HCNet to sustainably obtain performance gains.Our work\ndemonstrates the importance and feasibility of learning and memorizing\nrepresentations of all cross features ,which sheds light on a new promising\nresearch direction.",
    "descriptor": "",
    "authors": [
      "Pengtao Zhang",
      "Junlin Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01334"
  },
  {
    "id": "arXiv:2211.01335",
    "title": "Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese",
    "abstract": "The tremendous success of CLIP (Radford et al., 2021) has promoted the\nresearch and application of contrastive learning for vision-language\npretraining. However, while the publicly available CLIP models are mostly\npretrained on English data, it is hard to search for a CLIP pretrained on\nChinese data. We assume that pretraining a Chinese CLIP is essential to\nresearch and industry for the following reasons. First, it can benefit the\nvision-language retrieval in Chinese and thus promote the language-specific\nmultimodal representation learning. Second, the distribution of images in\nChinese websites should be different from that of images in English websites.\nIn this work, we construct a large-scale dataset of image-text pairs in\nChinese, where most data are retrieved from publicly available datasets, and we\npretrain Chinese CLIP models on the new dataset. We develop 5 Chinese CLIP\nmodels of multiple sizes, spanning from 77 to 958 million parameters.\nFurthermore, we propose a two-stage pretraining method, where the model is\nfirst trained with the image encoder frozen and then trained with all\nparameters being optimized, to achieve enhanced model performance. Our\ncomprehensive experiments demonstrate that Chinese CLIP can achieve the\nstate-of-the-art performance on MUGE, Flickr30K-CN, and COCO-CN in the setups\nof zero-shot learning and finetuning, and it is able to achieve competitive\nperformance in zero-shot image classification based on the evaluation on the\nELEVATER benchmark (Li et al., 2022). Furthermore, through the ablation study\nwe show that the two-stage pretraining method is the most effective compared\nwith the other options. We release our code in\nhttps://github.com/OFA-Sys/Chinese-CLIP",
    "descriptor": "",
    "authors": [
      "An Yang",
      "Junshu Pan",
      "Junyang Lin",
      "Rui Men",
      "Yichang Zhang",
      "Jingren Zhou",
      "Chang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01335"
  },
  {
    "id": "arXiv:2211.01336",
    "title": "A Transformer-based Framework for POI-level Social Post Geolocation",
    "abstract": "POI-level geo-information of social posts is critical to many location-based\napplications and services. However, the multi-modality, complexity and diverse\nnature of social media data and their platforms limit the performance of\ninferring such fine-grained locations and their subsequent applications. To\naddress this issue, we present a transformer-based general framework, which\nbuilds upon pre-trained language models and considers non-textual data, for\nsocial post geolocation at the POI level. To this end, inputs are categorized\nto handle different social data, and an optimal combination strategy is\nprovided for feature representations. Moreover, a uniform representation of\nhierarchy is proposed to learn temporal information, and a concatenated version\nof encodings is employed to capture feature-wise positions better. Experimental\nresults on various social datasets demonstrate that three variants of our\nproposed framework outperform multiple state-of-art baselines by a large margin\nin terms of accuracy and distance error metrics.",
    "descriptor": "\nComments: Full papers are 12 pages in length plus additional 4 pages for references (turns to 18 pages in total after submitting to arxiv). One figure and 5 tables are contained. This paper was submitted to ECIR 2023 for review\n",
    "authors": [
      "Menglin Li",
      "Kwan Hui Lim",
      "Teng Guo",
      "Junhua Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01336"
  },
  {
    "id": "arXiv:2211.01340",
    "title": "POLICE: Provably Optimal Linear Constraint Enforcement for Deep Neural  Networks",
    "abstract": "Deep Neural Networks (DNNs) outshine alternative function approximators in\nmany settings thanks to their modularity in composing any desired\ndifferentiable operator. The formed parametrized functional is then tuned to\nsolve a task at hand from simple gradient descent. This modularity comes at the\ncost of making strict enforcement of constraints on DNNs, e.g. from a priori\nknowledge of the task, or from desired physical properties, an open challenge.\nIn this paper we propose the first provable affine constraint enforcement\nmethod for DNNs that requires minimal changes into a given DNN's forward-pass,\nthat is computationally friendly, and that leaves the optimization of the DNN's\nparameter to be unconstrained i.e. standard gradient-based method can be\nemployed. Our method does not require any sampling and provably ensures that\nthe DNN fulfills the affine constraint on a given input space's region at any\npoint during training, and testing. We coin this method POLICE, standing for\nProvably Optimal LInear Constraint Enforcement.",
    "descriptor": "",
    "authors": [
      "Randall Balestriero",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01340"
  },
  {
    "id": "arXiv:2211.01341",
    "title": "A logical framework to model software development by multiple agents  following a common specification",
    "abstract": "In this paper, we address program development by multiple different\nprogrammers (or programming teams), each working in different settings\n(programming languages or reasoning frameworks), but following a common\nspecification; in particular, we examine at an abstract level the problem of\ntranslatability between their produced programs. To this end, after\nconsideration of some philosophical issues regarding program development,\nincluding its similarities and dissimilarities with scientific theorising, we\nextend a logical framework built to describe scientific theorising in\nrelativist settings: our extensions add the ability of reasoning about\nprograms, the iterative process of their generation, and their specifications.\nWe are thus able to define a notion of translation between the outputs of\nprogram generators and prove that there is a (trivial) such translation when\ntwo program generators follow the same specification reliably (in a specific\nsense of reliability).",
    "descriptor": "\nComments: 15 pages (including bibliography). To be submitted to Logical Methods in Computer Science\n",
    "authors": [
      "Georgios V. Pitsiladis",
      "Petros S. Stefaneas"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.01341"
  },
  {
    "id": "arXiv:2211.01342",
    "title": "Fine-grained Human Activity Recognition Using Virtual On-body  Acceleration Data",
    "abstract": "Previous work has demonstrated that virtual accelerometry data, extracted\nfrom videos using cross-modality transfer approaches like IMUTube, is\nbeneficial for training complex and effective human activity recognition (HAR)\nmodels. Systems like IMUTube were originally designed to cover activities that\nare based on substantial body (part) movements. Yet, life is complex, and a\nrange of activities of daily living is based on only rather subtle movements,\nwhich bears the question to what extent systems like IMUTube are of value also\nfor fine-grained HAR, i.e., When does IMUTube break? In this work we first\nintroduce a measure to quantitatively assess the subtlety of human movements\nthat are underlying activities of interest--the motion subtlety index\n(MSI)--which captures local pixel movements and pose changes in the vicinity of\ntarget virtual sensor locations, and correlate it to the eventual activity\nrecognition accuracy. We then perform a \"stress-test\" on IMUTube and explore\nfor which activities with underlying subtle movements a cross-modality transfer\napproach works, and for which not. As such, the work presented in this paper\nallows us to map out the landscape for IMUTube applications in practical\nscenarios.",
    "descriptor": "",
    "authors": [
      "Zikang Leng",
      "Yash Jain",
      "Hyeokhyen Kwon",
      "Thomas Pl\u00f6tz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01342"
  },
  {
    "id": "arXiv:2211.01343",
    "title": "Are Turn-by-Turn Navigation Systems of Regular Vehicles Ready for  Edge-Assisted Autonomous Vehicles?",
    "abstract": "Future private and public transportation will be dominated by Autonomous\nVehicles (AV), which are potentially safer than regular vehicles. However,\nensuring good performance for the autonomous features requires fast processing\nof heavy computational tasks. Providing each AV with powerful enough computing\nresources is certainly a practical solution but may result in increased AV cost\nand decreased driving range. An alternative solution being explored in research\nis to install low-power computing hardware on each AV and offload the heavy\ntasks to powerful nearby edge servers. In this case, the AV's reaction time\ndepends on how quickly the navigation tasks are completed in the edge server.\nTo reduce task completion latency, the edge servers must be equipped with\nenough network and computing resources to handle the vehicle demands. However,\nthis demand shows large spatio-temporal variations. Thus, deploying the same\namount of resources in different locations may lead to unnecessary resource\nover-provisioning.\nTaking these challenges into consideration, in this paper, we discuss the\nimplications of deploying different amounts of resources in different city\nareas based on real traffic data to sustain peak versus average demand. Because\ndeploying edge resources to handle the average demand leads to lower deployment\ncosts and better system utilization, we then investigate how peak-hour demand\naffect the safe travel time of AVs and whether current turn-by-turn navigation\napps would still provide the fastest travel route. The insights and findings of\nthis paper will inspire new research that can considerably speed up the\ndeployment of edge-assisted AVs in our society.",
    "descriptor": "",
    "authors": [
      "Syeda Tanjila Atik",
      "Marco Brocanelli",
      "Daniel Grosu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.01343"
  },
  {
    "id": "arXiv:2211.01348",
    "title": "Detecting Emerging Technologies in Artificial Intelligence Scientific  Ecosystem Using an Indicator-based Model",
    "abstract": "Early identification of emergent topics is of eminent importance due to their\npotential impacts on society. There are many methods for detecting emerging\nterms and topics, all with advantages and drawbacks. However, there is no\nconsensus about the attributes and indicators of emergence. In this study, we\nevaluate emerging topic detection in the field of artificial intelligence using\na new method to evaluate emergence. We also introduce two new attributes of\ncollaboration and technological impact which can help us use both paper and\npatent information simultaneously. Our results confirm that the proposed new\nmethod can successfully identify the emerging topics in the period of the\nstudy. Moreover, this new method can provide us with the score of each\nattribute and a final emergence score, which enable us to rank the emerging\ntopics with their emergence scores and each attribute score.",
    "descriptor": "",
    "authors": [
      "Ali Ghaemmaghami",
      "Andrea Schiffauerova",
      "Ashkan Ebadi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.01348"
  },
  {
    "id": "arXiv:2211.01354",
    "title": "Improving Named Entity Recognition in Telephone Conversations via  Effective Active Learning with Human in the Loop",
    "abstract": "Telephone transcription data can be very noisy due to speech recognition\nerrors, disfluencies, etc. Not only that annotating such data is very\nchallenging for the annotators, but also such data may have lots of annotation\nerrors even after the annotation job is completed, resulting in a very poor\nmodel performance. In this paper, we present an active learning framework that\nleverages human in the loop learning to identify data samples from the\nannotated dataset for re-annotation that are more likely to contain annotation\nerrors. In this way, we largely reduce the need for data re-annotation for the\nwhole dataset. We conduct extensive experiments with our proposed approach for\nNamed Entity Recognition and observe that by re-annotating only about 6%\ntraining instances out of the whole dataset, the F1 score for a certain entity\ntype can be significantly improved by about 25%.",
    "descriptor": "\nComments: The final version of this paper will be published in the Proceedings of the DaSH Workshop @ EMNLP 2022. This paper is accepted for presentation in both DaSH@EMNLP 2022 and HiLL@NIPS 2022\n",
    "authors": [
      "Md Tahmid Rahman Laskar",
      "Cheng Chen",
      "Xue-Yong Fu",
      "Shashi Bhushan TN"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01354"
  },
  {
    "id": "arXiv:2211.01355",
    "title": "MT-GenEval: A Counterfactual and Contextual Dataset for Evaluating  Gender Accuracy in Machine Translation",
    "abstract": "As generic machine translation (MT) quality has improved, the need for\ntargeted benchmarks that explore fine-grained aspects of quality has increased.\nIn particular, gender accuracy in translation can have implications in terms of\noutput fluency, translation accuracy, and ethics. In this paper, we introduce\nMT-GenEval, a benchmark for evaluating gender accuracy in translation from\nEnglish into eight widely-spoken languages. MT-GenEval complements existing\nbenchmarks by providing realistic, gender-balanced, counterfactual data in\neight language pairs where the gender of individuals is unambiguous in the\ninput segment, including multi-sentence segments requiring inter-sentential\ngender agreement. Our data and code is publicly available under a CC BY SA 3.0\nlicense.",
    "descriptor": "\nComments: Accepted at EMNLP 2022. Data and code: this https URL\n",
    "authors": [
      "Anna Currey",
      "Maria N\u0103dejde",
      "Raghavendra Pappagari",
      "Mia Mayer",
      "Stanislas Lauly",
      "Xing Niu",
      "Benjamin Hsu",
      "Georgiana Dinu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01355"
  },
  {
    "id": "arXiv:2211.01359",
    "title": "Partitioning a Polygon Into Small Pieces",
    "abstract": "We study the problem of partitioning a given simple polygon $P$ into a\nminimum number of polygonal pieces, each of which has bounded size. We give\nalgorithms for seven notions of `bounded size,' namely that each piece has\nbounded area, perimeter, straight-line diameter, geodesic diameter, or that\neach piece must be contained in a unit disk, an axis-aligned unit square or an\narbitrarily rotated unit square.\nA more general version of the area problem has already been studied. Here we\nare, in addition to $P$, given positive real values $a_1,\\ldots,a_k$ such that\nthe sum $\\sum_{i=1}^k a_i$ equals the area of $P$. The goal is to partition $P$\ninto exactly $k$ pieces $Q_1,\\ldots,Q_k$ such that the area of $Q_i$ is $a_i$.\nSuch a partition always exists, and an algorithm with running time $O(nk)$ has\npreviously been described, where $n$ is the number of corners of $P$. We give\nan algorithm with optimal running time $O(n+k)$. For polygons with holes, we\nget running time $O(n\\log n+k)$.\nFor the other problems, it seems out of reach to compute optimal partitions\nfor simple polygons; for most of them, even in extremely restricted cases such\nas when $P$ is a square. We therefore develop $O(1)$-approximation algorithms\nfor these problems, which means that the number of pieces in the produced\npartition is at most a constant factor larger than the cardinality of a minimum\npartition. Existing algorithms do not allow Steiner points, which means that\nall corners of the produced pieces must also be corners of $P$. This has the\ndisappointing consequence that a partition does often not exist, whereas our\nalgorithms always produce useful partitions. Furthermore, an optimal partition\nwithout Steiner points may require $\\Omega(n)$ pieces for polygons where a\npartition consisting of just $2$ pieces exists when Steiner points are allowed.",
    "descriptor": "\nComments: 32 pages, 24 figures\n",
    "authors": [
      "Mikkel Abrahamsen",
      "Nichlas Langhoff Rasmussen"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.01359"
  },
  {
    "id": "arXiv:2211.01361",
    "title": "My Face My Choice: Privacy Enhancing Deepfakes for Social Media  Anonymization",
    "abstract": "Recently, productization of face recognition and identification algorithms\nhave become the most controversial topic about ethical AI. As new policies\naround digital identities are formed, we introduce three face access models in\na hypothetical social network, where the user has the power to only appear in\nphotos they approve. Our approach eclipses current tagging systems and replaces\nunapproved faces with quantitatively dissimilar deepfakes. In addition, we\npropose new metrics specific for this task, where the deepfake is generated at\nrandom with a guaranteed dissimilarity. We explain access models based on\nstrictness of the data flow, and discuss impact of each model on privacy,\nusability, and performance. We evaluate our system on Facial Descriptor Dataset\nas the real dataset, and two synthetic datasets with random and equal class\ndistributions. Running seven SOTA face recognizers on our results, MFMC reduces\nthe average accuracy by 61%. Lastly, we extensively analyze similarity metrics,\ndeepfake generators, and datasets in structural, visual, and generative spaces;\nsupporting the design choices and verifying the quality.",
    "descriptor": "\nComments: 2023 IEEE Winter Conference on Applications of Computer Vision (WACV)\n",
    "authors": [
      "Umur A. Ciftci",
      "Gokturk Yuksek",
      "Ilke Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01361"
  },
  {
    "id": "arXiv:2211.01364",
    "title": "An optimal control perspective on diffusion-based generative modeling",
    "abstract": "We establish a connection between stochastic optimal control and generative\nmodels based on stochastic differential equations (SDEs) such as recently\ndeveloped diffusion probabilistic models. In particular, we derive a\nHamilton-Jacobi-Bellman equation that governs the evolution of the\nlog-densities of the underlying SDE marginals. This perspective allows to\ntransfer methods from optimal control theory to generative modeling. First, we\nshow that the evidence lower bound is a direct consequence of the well-known\nverification theorem from control theory. Further, we develop a novel\ndiffusion-based method for sampling from unnormalized densities -- a problem\nfrequently occurring in statistics and computational sciences.",
    "descriptor": "\nComments: Accepted for oral presentation at NeurIPS 2022 Workshop on Score-Based Methods\n",
    "authors": [
      "Julius Berner",
      "Lorenz Richter",
      "Karen Ullrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01364"
  },
  {
    "id": "arXiv:2211.01367",
    "title": "Two-Stream Network for Sign Language Recognition and Translation",
    "abstract": "Sign languages are visual languages using manual articulations and non-manual\nelements to convey information. For sign language recognition and translation,\nthe majority of existing approaches directly encode RGB videos into hidden\nrepresentations. RGB videos, however, are raw signals with substantial visual\nredundancy, leading the encoder to overlook the key information for sign\nlanguage understanding. To mitigate this problem and better incorporate domain\nknowledge, such as handshape and body movement, we introduce a dual visual\nencoder containing two separate streams to model both the raw videos and the\nkeypoint sequences generated by an off-the-shelf keypoint estimator. To make\nthe two streams interact with each other, we explore a variety of techniques,\nincluding bidirectional lateral connection, sign pyramid network with auxiliary\nsupervision, and frame-level self-distillation. The resulting model is called\nTwoStream-SLR, which is competent for sign language recognition (SLR).\nTwoStream-SLR is extended to a sign language translation (SLT) model,\nTwoStream-SLT, by simply attaching an extra translation network.\nExperimentally, our TwoStream-SLR and TwoStream-SLT achieve state-of-the-art\nperformance on SLR and SLT tasks across a series of datasets including\nPhoenix-2014, Phoenix-2014T, and CSL-Daily.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yutong Chen",
      "Ronglai Zuo",
      "Fangyun Wei",
      "Yu Wu",
      "Shujie Liu",
      "Brian Mak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01367"
  },
  {
    "id": "arXiv:1904.01095",
    "title": "Fast, accurate, and transferable many-body interatomic potentials by  symbolic regression",
    "abstract": "The length and time scales of atomistic simulations are limited by the\ncomputational cost of the methods used to predict material properties. In\nrecent years there has been great progress in the use of machine learning\nalgorithms to develop fast and accurate interatomic potential models, but it\nremains a challenge to develop models that generalize well and are fast enough\nto be used at extreme time and length scales. To address this challenge, we\nhave developed a machine learning algorithm based on symbolic regression in the\nform of genetic programming that is capable of discovering accurate,\ncomputationally efficient manybody potential models. The key to our approach is\nto explore a hypothesis space of models based on fundamental physical\nprinciples and select models within this hypothesis space based on their\naccuracy, speed, and simplicity. The focus on simplicity reduces the risk of\noverfitting the training data and increases the chances of discovering a model\nthat generalizes well. Our algorithm was validated by rediscovering an exact\nLennard-Jones potential and a Sutton Chen embedded atom method potential from\ntraining data generated using these models. By using training data generated\nfrom density functional theory calculations, we found potential models for\nelemental copper that are simple, as fast as embedded atom models, and capable\nof accurately predicting properties outside of their training set. Our approach\nrequires relatively small sets of training data, making it possible to generate\ntraining data using highly accurate methods at a reasonable computational cost.\nWe present our approach, the forms of the discovered models, and assessments of\ntheir transferability, accuracy and speed.",
    "descriptor": "",
    "authors": [
      "Alberto Hernandez",
      "Adarsh Balasubramanian",
      "Fenglin Yuan",
      "Simon Mason",
      "Tim Mueller"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/1904.01095"
  },
  {
    "id": "arXiv:2210.15124",
    "title": "Generalizability of Functional Forms for Interatomic Potential Models  Discovered by Symbolic Regression",
    "abstract": "In recent years there has been great progress in the use of machine learning\nalgorithms to develop interatomic potential models. Machine-learned potential\nmodels are typically orders of magnitude faster than density functional theory\nbut also orders of magnitude slower than physics-derived models such as the\nembedded atom method. In our previous work, we used symbolic regression to\ndevelop fast, accurate and transferrable interatomic potential models for\ncopper with novel functional forms that resemble those of the embedded atom\nmethod. To determine the extent to which the success of these forms was\nspecific to copper, here we explore the generalizability of these models to\nother elements and analyze their out-of-sample performance on several material\nproperties. We found that these forms work particularly well on elements that\nare chemically similar to copper. When compared to optimized Sutton-Chen\nmodels, which have similar complexity, the functional forms discovered using\nsymbolic regression perform better across all elements considered except gold\nwhere they have a similar performance. They perform similarly to a moderately\nmore complex embedded atom form on properties on which they were trained, and\nthey are more accurate on average on other properties. We attribute this\nimproved generalized accuracy to the relative simplicity of the models\ndiscovered using symbolic regression. The genetic programming models are found\nto outperform other models from the literature about 50% of the time, with\nabout 1/10th the model complexity on average. We discuss the implications of\nthese results to the broader application of symbolic regression to the\ndevelopment of new potentials and highlight how models discovered for one\nelement can be used to seed new searches for different elements.",
    "descriptor": "",
    "authors": [
      "Alberto Hernandez",
      "Tim Mueller"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.15124"
  },
  {
    "id": "arXiv:2211.00643",
    "title": "A Federated Learning Scheme for Neuro-developmental Disorders:  Multi-Aspect ASD Detection",
    "abstract": "Autism Spectrum Disorder (ASD) is a neuro-developmental syndrome resulting\nfrom alterations in the embryological brain before birth. This disorder\ndistinguishes its patients by special socially restricted and repetitive\nbehavior in addition to specific behavioral traits. Hence, this would possibly\ndeteriorate their social behavior among other individuals, as well as their\noverall interaction within their community. Moreover, medical research has\nproved that ASD also affects the facial characteristics of its patients, making\nthe syndrome recognizable from distinctive signs within an individual's face.\nGiven that as a motivation behind our work, we propose a novel\nprivacy-preserving federated learning scheme to predict ASD in a certain\nindividual based on their behavioral and facial features, embedding a merging\nprocess of both data features through facial feature extraction while\nrespecting patient data privacy. After training behavioral and facial image\ndata on federated machine learning models, promising results are achieved, with\n70\\% accuracy for the prediction of ASD according to behavioral traits in a\nfederated learning environment, and a 62\\% accuracy is reached for the\nprediction of ASD given an image of the patient's face. Then, we test the\nbehavior of regular as well as federated ML on our merged data, behavioral and\nfacial, where a 65\\% accuracy is achieved with the regular logistic regression\nmodel and 63\\% accuracy with the federated learning model.",
    "descriptor": "",
    "authors": [
      "Hala Shamseddine",
      "Safa Otoum",
      "Azzam Mourad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00643"
  },
  {
    "id": "arXiv:2211.00644",
    "title": "minoHealth.ai: A Clinical Evaluation Of Deep Learning Systems For the  Diagnosis of Pleural Effusion and Cardiomegaly In Ghana, Vietnam and the  United States of America",
    "abstract": "A rapid and accurate diagnosis of cardiomegaly and pleural effusion is of the\nutmost importance to reduce mortality and medical costs. Artificial\nIntelligence has shown promise in diagnosing medical conditions. With this\nstudy, we seek to evaluate how well Artificial Intelligence (AI) systems,\ndeveloped my minoHealth AI Labs, will perform at diagnosing cardiomegaly and\npleural effusion, using chest x-rays from Ghana, Vietnam and the USA, and how\nwell AI systems will perform when compared with radiologists working in Ghana.\nThe evaluation dataset used in this study contained 100 images randomly\nselected from three datasets. The Deep Learning models were further tested on a\nlarger Ghanaian dataset containing five hundred and sixty one (561) samples.\nTwo AI systems were then evaluated on the evaluation dataset, whilst we also\ngave the same chest x-ray images within the evaluation dataset to 4\nradiologists, with 5 - 20 years experience, to diagnose independently. For\ncardiomegaly, minoHealth.ai systems scored Area under the Receiver operating\ncharacteristic Curve (AUC-ROC) of 0.9 and 0.97 while the AUC-ROC of individual\nradiologists ranged from 0.77 to 0.87. For pleural effusion, the minoHealth.ai\nsystems scored 0.97 and 0.91 whereas individual radiologists scored between\n0.75 and 0.86. On both conditions, the best performing AI model outperforms the\nbest performing radiologist by about 10%. We also evaluate the specificity,\nsensitivity, negative predictive value (NPV), and positive predictive value\n(PPV) between the minoHealth.ai systems and radiologists.",
    "descriptor": "",
    "authors": [
      "Darlington Akogo",
      "Issah Abubakari Samori",
      "Bashiru Babatunde Jimah",
      "Dorothea Akosua Anim",
      "Yaw Boateng Mensah",
      "Benjamin Dabo Sarkodie"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00644"
  },
  {
    "id": "arXiv:2211.00646",
    "title": "Learning Melanocytic Cell Masks from Adjacent Stained Tissue",
    "abstract": "Melanoma is one of the most aggressive forms of skin cancer, causing a large\nproportion of skin cancer deaths. However, melanoma diagnoses by pathologists\nshows low interrater reliability. As melanoma is a cancer of the melanocyte,\nthere is a clear need to develop a melanocytic cell segmentation tool that is\nagnostic to pathologist variability and automates pixel-level annotation.\nGigapixel-level pathologist labeling, however, is impractical. Herein, we\npropose a means to train deep neural networks for melanocytic cell segmentation\nfrom hematoxylin and eosin (H&E) stained slides using paired\nimmunohistochemical (IHC) slides of adjacent tissue sections, achieving a mean\nIOU of 0.64 despite imperfect ground-truth labels.",
    "descriptor": "\nComments: {Medical Image Learning with Limited & Noisy Data Workshop at MICCAI 2022\n",
    "authors": [
      "Mikio Tada",
      "Maria L. Wei",
      "Michael J. Keiser"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.00646"
  },
  {
    "id": "arXiv:2211.00652",
    "title": "Persistent Tensors and Multiqudit Entanglement Transformation",
    "abstract": "We construct a lower bound of the tensor rank for a new class of tensors,\nwhich we call persistent tensors. We present three specific families of\npersistent tensors, of which the lower bound is tight. We show that there is a\nchain of degenerations between these three families of minimal-rank persistent\ntensors that can be used to study the entanglement transformation between them.\nIn addition, we show that these three families of persistent tensors are indeed\ndifferent generalizations of multiqubit $\\rm{W}$ states within multiqudit\nsystems and are geometrically in the orbit closure of multiqudit $\\rm{GHZ}$\nstates. Consequently, we show that one can obtain every one of the\ngeneralizations of $\\rm{W}$ state from a multiqudit $\\rm{GHZ}$ state via\nasymptotic Stochastic Local Operations and Classical Communication (SLOCC) with\nrate one. Finally, we extend the obtained lower bound of the tensor rank to\ndirect sums with persistent summands and to even more general combinations of\ntensors, which we call block pyramidal tensors. As a result, we show that the\ntensor rank is multiplicative under the Kronecker and tensor products of\nminimal-rank persistent tensors with the $\\rm{GHZ}$ tensor.",
    "descriptor": "\nComments: 15 pages. Your comments are more than welcome\n",
    "authors": [
      "Masoud Gharahi",
      "Vladimir Lysikov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Mathematical Physics (math-ph)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2211.00652"
  },
  {
    "id": "arXiv:2211.00677",
    "title": "Semi-Supervised Domain Adaptation for Cross-Survey Galaxy Morphology  Classification and Anomaly Detection",
    "abstract": "In the era of big astronomical surveys, our ability to leverage artificial\nintelligence algorithms simultaneously for multiple datasets will open new\navenues for scientific discovery. Unfortunately, simply training a deep neural\nnetwork on images from one data domain often leads to very poor performance on\nany other dataset. Here we develop a Universal Domain Adaptation method\nDeepAstroUDA, capable of performing semi-supervised domain alignment that can\nbe applied to datasets with different types of class overlap. Extra classes can\nbe present in any of the two datasets, and the method can even be used in the\npresence of unknown classes. For the first time, we demonstrate the successful\nuse of domain adaptation on two very different observational datasets (from\nSDSS and DECaLS). We show that our method is capable of bridging the gap\nbetween two astronomical surveys, and also performs well for anomaly detection\nand clustering of unknown data in the unlabeled dataset. We apply our model to\ntwo examples of galaxy morphology classification tasks with anomaly detection:\n1) classifying spiral and elliptical galaxies with detection of merging\ngalaxies (three classes including one unknown anomaly class); 2) a more\ngranular problem where the classes describe more detailed morphological\nproperties of galaxies, with the detection of gravitational lenses (ten classes\nincluding one unknown anomaly class).",
    "descriptor": "\nComments: 3 figures, 1 table; accepted to Machine Learning and the Physical Sciences - Workshop at the 36th conference on Neural Information Processing Systems (NeurIPS)\n",
    "authors": [
      "Aleksandra \u0106iprijanovi\u0107",
      "Ashia Lewis",
      "Kevin Pedro",
      "Sandeep Madireddy",
      "Brian Nord",
      "Gabriel N. Perdue",
      "Stefan Wild"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00677"
  },
  {
    "id": "arXiv:2211.00697",
    "title": "A Converse for Fault-tolerant Quantum Computation",
    "abstract": "With improvements in achievable redundancy for fault-tolerant quantum\ncomputing, it is natural to ask: what is the minimum required redundancy? In\nthis paper, we obtain a lower bound on the minimum redundancy required for\n$\\epsilon$-accurate implementation of a large class of operations, which\nincludes unitary operators. For the practically relevant case of\nsub-exponential (in input size) depth and sub-linear gate size, our bound on\nredundancy is tighter than the best known lower bound in \\cite{FawziMS2022}. We\nobtain this bound by connecting fault-tolerant computation with a set of finite\nblocklength quantum communication problems whose accuracy requirements satisfy\na joint constraint. This bound gives a strictly lower noise threshold for\nnon-degradable noise and captures its dependence on gate size. This bound\ndirectly extends to the case where noise at the outputs of a gate are\ncorrelated but noise across gates are independent.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Uthirakalyani G",
      "Anuj K. Nayak",
      "Avhishek Chatterjee"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.00697"
  },
  {
    "id": "arXiv:2211.00724",
    "title": "Privacy Induces Robustness: Information-Computation Gaps and Sparse Mean  Estimation",
    "abstract": "We establish a simple connection between robust and differentially-private\nalgorithms: private mechanisms which perform well with very high probability\nare automatically robust in the sense that they retain accuracy even if a\nconstant fraction of the samples they receive are adversarially corrupted.\nSince optimal mechanisms typically achieve these high success probabilities,\nour results imply that optimal private mechanisms for many basic statistics\nproblems are robust.\nWe investigate the consequences of this observation for both algorithms and\ncomputational complexity across different statistical problems. Assuming the\nBrennan-Bresler secret-leakage planted clique conjecture, we demonstrate a\nfundamental tradeoff between computational efficiency, privacy leakage, and\nsuccess probability for sparse mean estimation. Private algorithms which match\nthis tradeoff are not yet known -- we achieve that (up to polylogarithmic\nfactors) in a polynomially-large range of parameters via the Sum-of-Squares\nmethod.\nTo establish an information-computation gap for private sparse mean\nestimation, we also design new (exponential-time) mechanisms using fewer\nsamples than efficient algorithms must use. Finally, we give evidence for\nprivacy-induced information-computation gaps for several other statistics and\nlearning problems, including PAC learning parity functions and estimation of\nthe mean of a multivariate Gaussian.",
    "descriptor": "\nComments: 39 pages, 2 figures\n",
    "authors": [
      "Kristian Georgiev",
      "Samuel B. Hopkins"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00724"
  },
  {
    "id": "arXiv:2211.00725",
    "title": "LARO: Learned Acquisition and Reconstruction Optimization to accelerate  Quantitative Susceptibility Mapping",
    "abstract": "Quantitative susceptibility mapping (QSM) involves acquisition and\nreconstruction of a series of images at multi-echo time points to estimate\ntissue field, which prolongs scan time and requires specific reconstruction\ntechnique. In this paper, we present our new framework, called Learned\nAcquisition and Reconstruction Optimization (LARO), which aims to accelerate\nthe multi-echo gradient echo (mGRE) pulse sequence for QSM. Our approach\ninvolves optimizing a Cartesian multi-echo k-space sampling pattern with a deep\nreconstruction network. Next, this optimized sampling pattern was implemented\nin an mGRE sequence using Cartesian fan-beam k-space segmenting and ordering\nfor prospective scans. Furthermore, we propose to insert a recurrent temporal\nfeature fusion module into the reconstruction network to capture signal\nredundancies along echo time. Our ablation studies show that both the optimized\nsampling pattern and proposed reconstruction strategy help improve the quality\nof the multi-echo image reconstructions. Generalization experiments show that\nLARO is robust on the test data with new pathologies and different sequence\nparameters. Our code is available at https://github.com/Jinwei1209/LARO.git.",
    "descriptor": "",
    "authors": [
      "Jinwei Zhang",
      "Pascal Spincemaille",
      "Hang Zhang",
      "Thanh D. Nguyen",
      "Chao Li",
      "Jiahao Li",
      "Ilhami Kovanlikaya",
      "Mert R. Sabuncu",
      "Yi Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00725"
  },
  {
    "id": "arXiv:2211.00727",
    "title": "Quantum Natural Language Generation on Near-Term Devices",
    "abstract": "The emergence of noisy medium-scale quantum devices has led to\nproof-of-concept applications for quantum computing in various domains.\nExamples include Natural Language Processing (NLP) where sentence\nclassification experiments have been carried out, as well as procedural\ngeneration, where tasks such as geopolitical map creation, and image\nmanipulation have been performed. We explore applications at the intersection\nof these two areas by designing a hybrid quantum-classical algorithm for\nsentence generation.\nOur algorithm is based on the well-known simulated annealing technique for\ncombinatorial optimisation. An implementation is provided and used to\ndemonstrate successful sentence generation on both simulated and real quantum\nhardware. A variant of our algorithm can also be used for music generation.\nThis paper aims to be self-contained, introducing all the necessary\nbackground on NLP and quantum computing along the way.",
    "descriptor": "\nComments: To appear in proceedings of International Natural Language Generation Conference (INLG) 2022\n",
    "authors": [
      "Amin Karamlou",
      "Marcel Pfaffhauser",
      "James Wootton"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00727"
  },
  {
    "id": "arXiv:2211.00728",
    "title": "Multifractality in time series is due to temporal correlations",
    "abstract": "Based on the rigorous mathematical arguments formulated within the\nMultifractal Detrended Fluctuation Analysis (MFDFA) approach it is shown that\nin the uncorrelated time series the effects resembling multifractality\nasymptotically disappear when the length of time series increases. The related\neffects are also illustrated by numerical simulations. This documents that the\ngenuine multifractality in time series may only result from the long-range\ntemporal correlations and the fatter distribution tails of fluctuations may\nbroaden the width of singularity spectrum only when such correlations are\npresent. The frequently asked question of what makes multifractality in time\nseries - temporal correlations or broad distribution tails - is thus ill posed.",
    "descriptor": "",
    "authors": [
      "Jaros\u0142aw Kwapie\u0144",
      "Pawel Blasiak",
      "Stanis\u0142aw Dro\u017cd\u017c",
      "Pawe\u0142 O\u015bwi\u0119cimka"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Numerical Analysis (math.NA)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.00728"
  },
  {
    "id": "arXiv:2211.00729",
    "title": "A Bayesian Framework on Asymmetric Mixture of Factor Analyser",
    "abstract": "Mixture of factor analyzer (MFA) model is an efficient model for the analysis\nof high dimensional data through which the factor-analyzer technique based on\nthe covariance matrices reducing the number of free parameters. The model also\nprovides an important methodology to determine latent groups in data. There are\nseveral pieces of research to extend the model based on the asymmetrical and/or\nwith outlier datasets with some known computational limitations that have been\nexamined in frequentist cases. In this paper, an MFA model with a rich and\nflexible class of skew normal (unrestricted) generalized hyperbolic (called\nSUNGH) distributions along with a Bayesian structure with several computational\nbenefits have been introduced. The SUNGH family provides considerable\nflexibility to model skewness in different directions as well as allowing for\nheavy tailed data. There are several desirable properties in the structure of\nthe SUNGH family, including, an analytically flexible density which leads to\neasing up the computation applied for the estimation of parameters. Considering\nfactor analysis models, the SUNGH family also allows for skewness and heavy\ntails for both the error component and factor scores. In the present study, the\nadvantages of using this family of distributions have been discussed and the\nsuitable efficiency of the introduced MFA model using real data examples and\nsimulation has been demonstrated.",
    "descriptor": "\nComments: 21 pages, 3 tables, 2 figures\n",
    "authors": [
      "Hamid Reza Safaeyan",
      "Karim Zare",
      "Mohamad R. Mahmoudi",
      "Amir Mosavi"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00729"
  },
  {
    "id": "arXiv:2211.00745",
    "title": "Self-supervised Physics-based Denoising for Computed Tomography",
    "abstract": "Computed Tomography (CT) imposes risk on the patients due to its inherent\nX-ray radiation, stimulating the development of low-dose CT (LDCT) imaging\nmethods. Lowering the radiation dose reduces the health risks but leads to\nnoisier measurements, which decreases the tissue contrast and causes artifacts\nin CT images. Ultimately, these issues could affect the perception of medical\npersonnel and could cause misdiagnosis. Modern deep learning noise suppression\nmethods alleviate the challenge but require low-noise-high-noise CT image pairs\nfor training, rarely collected in regular clinical workflows. In this work, we\nintroduce a new self-supervised approach for CT denoising Noise2NoiseTD-ANM\nthat can be trained without the high-dose CT projection ground truth images.\nUnlike previously proposed self-supervised techniques, the introduced method\nexploits the connections between the adjacent projections and the actual model\nof CT noise distribution. Such a combination allows for interpretable\nno-reference denoising using nothing but the original noisy LDCT projections.\nOur experiments with LDCT data demonstrate that the proposed method reaches the\nlevel of the fully supervised models, sometimes superseding them, easily\ngeneralizes to various noise levels, and outperforms state-of-the-art\nself-supervised denoising algorithms.",
    "descriptor": "\nComments: 13 pages, 12 figures. Under review\n",
    "authors": [
      "Elvira Zainulina",
      "Alexey Chernyavskiy",
      "Dmitry V. Dylov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00745"
  },
  {
    "id": "arXiv:2211.00747",
    "title": "Quantum Pseudoentanglement",
    "abstract": "Quantum pseudorandom states are efficiently constructable states which\nnevertheless masquerade as Haar-random states to poly-time observers. First\ndefined by Ji, Liu and Song, such states have found a number of applications\nranging from cryptography to the AdS/CFT correspondence. A fundamental question\nis exactly how much entanglement is required to create such states. Haar-random\nstates, as well as $t$-designs for $t\\geq 2$, exhibit near-maximal\nentanglement. Here we provide the first construction of pseudorandom states\nwith only polylogarithmic entanglement entropy across an equipartition of the\nqubits, which is the minimum possible. Our construction can be based on any\none-way function secure against quantum attack. We additionally show that the\nentanglement in our construction is fully \"tunable\", in the sense that one can\nhave pseudorandom states with entanglement $\\Theta(f(n))$ for any desired\nfunction $\\omega(\\log n) \\leq f(n) \\leq O(n)$.\nMore fundamentally, our work calls into question to what extent entanglement\nis a \"feelable\" quantity of quantum systems. Inspired by recent work of\nGheorghiu and Hoban, we define a new notion which we call \"pseudoentanglement\",\nwhich are ensembles of efficiently constructable quantum states which hide\ntheir entanglement entropy. We show such states exist in the strongest form\npossible while simultaneously being pseudorandom states. We also describe\ndiverse applications of our result from entanglement distillation to property\ntesting to quantum gravity.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Adam Bouland",
      "Bill Fefferman",
      "Soumik Ghosh",
      "Umesh Vazirani",
      "Zixin Zhou"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.00747"
  },
  {
    "id": "arXiv:2211.00749",
    "title": "ViT-DeiT: An Ensemble Model for Breast Cancer Histopathological Images  Classification",
    "abstract": "Breast cancer is the most common cancer in the world and the second most\ncommon type of cancer that causes death in women. The timely and accurate\ndiagnosis of breast cancer using histopathological images is crucial for\npatient care and treatment. Pathologists can make more accurate diagnoses with\nthe help of a novel approach based on image processing. This approach is an\nensemble model of two types of pre-trained vision transformer models, namely,\nVision Transformer and Data-Efficient Image Transformer. The proposed ensemble\nmodel classifies breast cancer histopathology images into eight classes, four\nof which are categorized as benign, whereas the others are categorized as\nmalignant. A public dataset was used to evaluate the proposed model. The\nexperimental results showed 98.17% accuracy, 98.18% precision, 98.08% recall,\nand a 98.12% F1 score.",
    "descriptor": "\nComments: 7 pages, 10 figures, 7 tables\n",
    "authors": [
      "Amira Alotaibi",
      "Tarik Alafif",
      "Faris Alkhilaiwi",
      "Yasser Alatawi",
      "Hassan Althobaiti",
      "Abdulmajeed Alrefaei",
      "Yousef M Hawsawi",
      "Tin Nguyen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00749"
  },
  {
    "id": "arXiv:2211.00750",
    "title": "Automatic Quantitative Analysis of Brain Organoids via Deep Learning",
    "abstract": "Recent advances in brain organoid technology are exciting new ways, which\nhave the potential to change the way how doctors and researchers understand and\ntreat cerebral diseases. Despite the remarkable use of brain organoids derived\nfrom human stem cells in new drug testing, disease modeling, and scientific\nresearch, it is still heavily time-consuming work to observe and analyze the\ninternal structure, cells, and neural inside the organoid by humans,\nspecifically no standard quantitative analysis method combined growing AI\ntechnology for brain organoid. In this paper, an automated computer-assisted\nanalysis method is proposed for brain organoid slice channels tagged with\ndifferent fluorescent. We applied the method on two channels of two group\nmicroscopy images and the experiment result shows an obvious difference between\nWild Type and Mutant Type cerebral organoids.",
    "descriptor": "",
    "authors": [
      "Jingli Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.00750"
  },
  {
    "id": "arXiv:2211.00761",
    "title": "Linear optimization over homogeneous matrix cones",
    "abstract": "A convex cone is homogeneous if its automorphism group acts transitively on\nthe interior of the cone, i.e., for every pair of points in the interior of the\ncone, there exists a cone automorphism that maps one point to the other. Cones\nthat are homogeneous and self-dual are called symmetric. The symmetric cones\ninclude the positive semidefinite matrix cone and the second order cone as\nimportant practical examples. In this paper, we consider the less well-studied\nconic optimization problems over cones that are homogeneous but not necessarily\nself-dual. We start with cones of positive semidefinite symmetric matrices with\na given sparsity pattern. Homogeneous cones in this class are characterized by\nnested block-arrow sparsity patterns, a subset of the chordal sparsity\npatterns. We describe transitive subsets of the automorphism groups of the\ncones and their duals, and important properties of the composition of log-det\nbarrier functions with the automorphisms in this set. Next, we consider\nextensions to linear slices of the positive semidefinite cone, i.e.,\nintersection of the positive semidefinite cone with a linear subspace, and\nreview conditions that make the cone homogeneous. In the third part of the\npaper we give a high-level overview of the classical algebraic theory of\nhomogeneous cones due to Vinberg and Rothaus. A fundamental consequence of this\ntheory is that every homogeneous cone admits a spectrahedral (linear matrix\ninequality) representation. We conclude by discussing the role of homogeneous\ncone structure in primal-dual symmetric interior-point methods.",
    "descriptor": "\nComments: 59 pages, 10 figures, to appear in Acta Numerica\n",
    "authors": [
      "Levent Tun\u00e7el",
      "Lieven Vandenberghe"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00761"
  },
  {
    "id": "arXiv:2211.00792",
    "title": "BECTRA: Transducer-based End-to-End ASR with BERT-Enhanced Encoder",
    "abstract": "We present BERT-CTC-Transducer (BECTRA), a novel end-to-end automatic speech\nrecognition (E2E-ASR) model formulated by the transducer with a BERT-enhanced\nencoder. Integrating a large-scale pre-trained language model (LM) into E2E-ASR\nhas been actively studied, aiming to utilize versatile linguistic knowledge for\ngenerating accurate text. One crucial factor that makes this integration\nchallenging lies in the vocabulary mismatch; the vocabulary constructed for a\npre-trained LM is generally too large for E2E-ASR training and is likely to\nhave a mismatch against a target ASR domain. To overcome such an issue, we\npropose BECTRA, an extended version of our previous BERT-CTC, that realizes\nBERT-based E2E-ASR using a vocabulary of interest. BECTRA is a transducer-based\nmodel, which adopts BERT-CTC for its encoder and trains an ASR-specific decoder\nusing a vocabulary suitable for a target task. With the combination of the\ntransducer and BERT-CTC, we also propose a novel inference algorithm for taking\nadvantage of both autoregressive and non-autoregressive decoding. Experimental\nresults on several ASR tasks, varying in amounts of data, speaking styles, and\nlanguages, demonstrate that BECTRA outperforms BERT-CTC by effectively dealing\nwith the vocabulary mismatch while exploiting BERT knowledge.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Yosuke Higuchi",
      "Tetsuji Ogawa",
      "Tetsunori Kobayashi",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00792"
  },
  {
    "id": "arXiv:2211.00795",
    "title": "InterMPL: Momentum Pseudo-Labeling with Intermediate CTC Loss",
    "abstract": "This paper presents InterMPL, a semi-supervised learning method of end-to-end\nautomatic speech recognition (ASR) that performs pseudo-labeling (PL) with\nintermediate supervision. Momentum PL (MPL) trains a connectionist temporal\nclassification (CTC)-based model on unlabeled data by continuously generating\npseudo-labels on the fly and improving their quality. In contrast to\nautoregressive formulations, such as the attention-based encoder-decoder and\ntransducer, CTC is well suited for MPL, or PL-based semi-supervised ASR in\ngeneral, owing to its simple/fast inference algorithm and robustness against\ngenerating collapsed labels. However, CTC generally yields inferior performance\nthan the autoregressive models due to the conditional independence assumption,\nthereby limiting the performance of MPL. We propose to enhance MPL by\nintroducing intermediate loss, inspired by the recent advances in CTC-based\nmodeling. Specifically, we focus on self-conditional and hierarchical\nconditional CTC, that apply auxiliary CTC losses to intermediate layers such\nthat the conditional independence assumption is explicitly relaxed. We also\nexplore how pseudo-labels should be generated and used as supervision for\nintermediate losses. Experimental results in different semi-supervised settings\ndemonstrate that the proposed approach outperforms MPL and improves an ASR\nmodel by up to a 12.1% absolute performance gain. In addition, our detailed\nanalysis validates the importance of the intermediate loss.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Yosuke Higuchi",
      "Tetsuji Ogawa",
      "Tetsunori Kobayashi",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00795"
  },
  {
    "id": "arXiv:2211.00820",
    "title": "A new method for determining Wasserstein 1 optimal transport maps from  Kantorovich potentials, with deep learning applications",
    "abstract": "Wasserstein 1 optimal transport maps provide a natural correspondence between\npoints from two probability distributions, $\\mu$ and $\\nu$, which is useful in\nmany applications. Available algorithms for computing these maps do not appear\nto scale well to high dimensions. In deep learning applications, efficient\nalgorithms have been developed for approximating solutions of the dual problem,\nknown as Kantorovich potentials, using neural networks (e.g. [Gulrajani et al.,\n2017]). Importantly, such algorithms work well in high dimensions. In this\npaper we present an approach towards computing Wasserstein 1 optimal transport\nmaps that relies only on Kantorovich potentials. In general, a Wasserstein 1\noptimal transport map is not unique and is not computable from a potential\nalone. Our main result is to prove that if $\\mu$ has a density and $\\nu$ is\nsupported on a submanifold of codimension at least 2, an optimal transport map\nis unique and can be written explicitly in terms of a potential. These\nassumptions are natural in many image processing contexts and other\napplications. When the Kantorovich potential is only known approximately, our\nresult motivates an iterative procedure wherein data is moved in optimal\ndirections and with the correct average displacement. Since this provides an\napproach for transforming one distribution to another, it can be used as a\nmultipurpose algorithm for various transport problems; we demonstrate through\nseveral proof of concept experiments that this algorithm successfully performs\nvarious imaging tasks, such as denoising, generation, translation and\ndeblurring, which normally require specialized techniques.",
    "descriptor": "\nComments: 25 pages, 12 figures. The TTC algorithm detailed here is a simplified and improved version of that of arXiv:2111.15099\n",
    "authors": [
      "Tristan Milne",
      "\u00c9tienne Bilocq",
      "Adrian Nachman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.00820"
  },
  {
    "id": "arXiv:2211.00825",
    "title": "LMD: A Learnable Mask Network to Detect Adversarial Examples for Speaker  Verification",
    "abstract": "Although the security of automatic speaker verification (ASV) is seriously\nthreatened by recently emerged adversarial attacks, there have been some\ncountermeasures to alleviate the threat. However, many defense approaches not\nonly require the prior knowledge of the attackers but also possess weak\ninterpretability. To address this issue, in this paper, we propose an\nattacker-independent and interpretable method, named learnable mask detector\n(LMD), to separate adversarial examples from the genuine ones. It utilizes\nscore variation as an indicator to detect adversarial examples, where the score\nvariation is the absolute discrepancy between the ASV scores of an original\naudio recording and its transformed audio synthesized from its masked complex\nspectrogram. A core component of the score variation detector is to generate\nthe masked spectrogram by a neural network. The neural network needs only\ngenuine examples for training, which makes it an attacker-independent approach.\nIts interpretability lies that the neural network is trained to minimize the\nscore variation of the targeted ASV, and maximize the number of the masked\nspectrogram bins of the genuine training examples. Its foundation is based on\nthe observation that, masking out the vast majority of the spectrogram bins\nwith little speaker information will inevitably introduce a large score\nvariation to the adversarial example, and a small score variation to the\ngenuine example. Experimental results with 12 attackers and two representative\nASV systems show that our proposed method outperforms five state-of-the-art\nbaselines. The extensive experimental results can also be a benchmark for the\ndetection-based ASV defenses.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Xing Chen",
      "Jie Wang",
      "Xiao-Lei Zhang",
      "Wei-Qiang Zhang",
      "Kunde Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00825"
  },
  {
    "id": "arXiv:2211.00835",
    "title": "The degree-restricted random process is far from uniform",
    "abstract": "The degree-restricted random process is a natural algorithmic model for\ngenerating graphs with degree sequence D_n=(d_1, \\ldots, d_n): starting with an\nempty n-vertex graph, it sequentially adds new random edges so that the degree\nof each vertex v_i remains at most d_i. Wormald conjectured in 1999 that, for\nd-regular degree sequences D_n, the final graph of this process is similar to a\nuniform random d-regular graph.\nIn this paper we show that, for degree sequences D_n that are not nearly\nregular, the final graph of the degree-restricted random process differs\nsubstantially from a uniform random graph with degree sequence D_n. The\ncombinatorial proof technique is our main conceptual contribution: we adapt the\nswitching method to the degree-restricted process, demonstrating that this\nenumeration technique can also be used to analyze stochastic processes (rather\nthan just uniform random models, as before).",
    "descriptor": "\nComments: 32 pages, 3 figures\n",
    "authors": [
      "Michael Molloy",
      "Erlang Surya",
      "Lutz Warnke"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.00835"
  },
  {
    "id": "arXiv:2211.00842",
    "title": "Delivery by Drones with Arbitrary Energy Consumption Models: A New  Formulation Approach",
    "abstract": "This paper presents a new approach for formulating the delivery problem by\ndrones with general energy consumption models where the drones visit a set of\nplaces to deliver parcels to customers. Drones can perform multiple trips that\nstart and end at a central depot while visiting several customers along their\npaths. The problem determines the routing and scheduling decisions of the\ndrones in order to minimize the total transportation cost of serving customers.\nFor the first time, the new formulation approach enables us to use the best\navailable energy consumption model without the need of any extra\napproximations. Though the approach works in a very general setting including\nnon-convex energy consumption models, it is also computationally efficient as\nthe resulting optimization model has a linear relaxation. A numerical study on\n255 benchmark instances with up to 50 customers and a specific energy function\nindicate that all the instances can be solved 20 times faster on average using\nthe new formulation when compared to the best existing branch-and-cut\nalgorithm. All the 15 benchmark instances with 50 customers are solved exactly,\nwhereas none of them has been solved optimally before. Moreover, new instances\nwith up to 150 customers are solved with small error bounds within a few hours.\nThe new approach can be simply applied to consider the extra energy required\nwhen a drone needs to continue hovering until opening the delivery time window.\nIt can also be applied to the case where the flight time is dependent on the\ndrone's payload weight. Owing to the flexibility of the new approach, these\nchallenging extensions are formulated as linear optimization models for the\nfirst time.",
    "descriptor": "",
    "authors": [
      "Amir Ahmadi-Javid",
      "Mahla Meskar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.00842"
  },
  {
    "id": "arXiv:2211.00844",
    "title": "Introducing the Quantum Research Kernels: Lessons from Classical  Parallel Computing",
    "abstract": "Quantum computing represents a paradigm shift for computation requiring an\nentirely new computer architecture. However, there is much that can be learned\nfrom traditional classical computer engineering. In this paper, we describe the\nParallel Research Kernels (PRK), a tool that was very useful for designing\nclassical parallel computing systems. The PRK are simple kernels written to\nexpose bottlenecks that limit classical parallel computing performance. We\nhypothesize that an analogous tool for quantum computing, Quantum Research\nKernels (QRK), may similarly aid the co-design of software and hardware for\nquantum computing systems, and we give a few examples of representative QRKs.",
    "descriptor": "\nComments: 2 pages\n",
    "authors": [
      "A.Y. Matsuura",
      "Timothy G. Mattson"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00844"
  },
  {
    "id": "arXiv:2211.00860",
    "title": "Insight into cloud processes from unsupervised classification with a  rotationally invariant autoencoder",
    "abstract": "Clouds play a critical role in the Earth's energy budget and their potential\nchanges are one of the largest uncertainties in future climate projections.\nHowever, the use of satellite observations to understand cloud feedbacks in a\nwarming climate has been hampered by the simplicity of existing cloud\nclassification schemes, which are based on single-pixel cloud properties and\ncannot consider spatial structures and textures. Recent advances in computer\nvision enable the grouping of different patterns of images without using human\npredefined labels, providing a novel means of automated cloud classification.\nThis unsupervised learning approach allows discovery of unknown\nclimate-relevant cloud patterns, and the automated processing of large\ndatasets. We describe here the use of such methods to generate a new AI-driven\nCloud Classification Atlas (AICCA), which leverages 22 years and 800 terabytes\nof MODIS satellite observations over the global ocean. We use a rotationally\ninvariant cloud clustering (RICC) method to classify those observations into 42\nAI-generated cloud class labels at ~100 km spatial resolution. As a case study,\nwe use AICCA to examine a recent finding of decreasing cloudiness in a critical\npart of the subtropical stratocumulus deck, and show that the change is\naccompanied by strong trends in cloud classes.",
    "descriptor": "\nComments: 5 pages, 3 figures, the 36th conference on Neural Information Processing Systems (NeurIPS) Machine Learning and the Physical Sciences workshop\n",
    "authors": [
      "Takuya Kurihana",
      "James Franke",
      "Ian Foster",
      "Ziwei Wang",
      "Elisabeth Moyer"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00860"
  },
  {
    "id": "arXiv:2211.00866",
    "title": "Gradient Descent and the Power Method: Exploiting their connection to  find the leftmost eigen-pair and escape saddle points",
    "abstract": "This work shows that applying Gradient Descent (GD) with a fixed step size to\nminimize a (possibly nonconvex) quadratic function is equivalent to running the\nPower Method (PM) on the gradients. The connection between GD with a fixed step\nsize and the PM, both with and without fixed momentum, is thus established.\nConsequently, valuable eigen-information is available via GD.\nRecent examples show that GD with a fixed step size, applied to locally\nquadratic nonconvex functions, can take exponential time to escape saddle\npoints (Simon S. Du, Chi Jin, Jason D. Lee, Michael I. Jordan, Aarti Singh, and\nBarnabas Poczos: \"Gradient descent can take exponential time to escape saddle\npoints\"; S. Paternain, A. Mokhtari, and A. Ribeiro: \"A newton-based method for\nnonconvex optimization with fast evasion of saddle points\"). Here, those\nexamples are revisited and it is shown that eigenvalue information was missing,\nso that the examples may not provide a complete picture of the potential\npractical behaviour of GD. Thus, ongoing investigation of the behaviour of GD\non nonconvex functions, possibly with an \\emph{adaptive} or \\emph{variable}\nstep size, is warranted.\nIt is shown that, in the special case of a quadratic in $R^2$, if an\neigenvalue is known, then GD with a fixed step size will converge in two\niterations, and a complete eigen-decomposition is available.\nBy considering the dynamics of the gradients and iterates, new step size\nstrategies are proposed to improve the practical performance of GD. Several\nnumerical examples are presented, which demonstrate the advantages of\nexploiting the GD--PM connection.",
    "descriptor": "",
    "authors": [
      "Rachael Tappenden",
      "Martin Tak\u00e1\u010d"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00866"
  },
  {
    "id": "arXiv:2211.00878",
    "title": "Neural Fourier Shift for Binaural Speech Rendering",
    "abstract": "We present a neural network for rendering binaural speech from given monaural\naudio, position, and orientation of the source. Most of the previous works have\nfocused on synthesizing binaural speeches by conditioning the positions and\norientations in the feature space of convolutional neural networks. These\nsynthesis approaches are powerful in estimating the target binaural speeches\neven for in-the-wild data but are difficult to generalize for rendering the\naudio from out-of-distribution domains. To alleviate this, we propose Neural\nFourier Shift (NFS), a novel network architecture that enables binaural speech\nrendering in the Fourier space. Specifically, utilizing a geometric time delay\nbased on the distance between the source and the receiver, NFS is trained to\npredict the delays and scales of various early reflections. NFS is efficient in\nboth memory and computational cost, is interpretable, and operates\nindependently of the source domain by its design. With up to 25 times lighter\nmemory and 6 times fewer calculations, the experimental results show that NFS\noutperforms the previous studies on the benchmark dataset.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Jin Woo Lee",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00878"
  },
  {
    "id": "arXiv:2211.00887",
    "title": "Certified Robustness of Quantum Classifiers against Adversarial Examples  through Quantum Noise",
    "abstract": "Recently, quantum classifiers have been known to be vulnerable to adversarial\nattacks, where quantum classifiers are fooled by imperceptible noises to have\nmisclassification. In this paper, we propose one first theoretical study that\nutilizing the added quantum random rotation noise can improve the robustness of\nquantum classifiers against adversarial attacks. We connect the definition of\ndifferential privacy and demonstrate the quantum classifier trained with the\nnatural presence of additive noise is differentially private. Lastly, we derive\na certified robustness bound to enable quantum classifiers to defend against\nadversarial examples supported by experimental results.",
    "descriptor": "\nComments: Submitted to IEEE ICASSP 2023\n",
    "authors": [
      "Jhih-Cing Huang",
      "Yu-Lin Tsai",
      "Chao-Han Huck Yang",
      "Cheng-Fang Su",
      "Chia-Mu Yu",
      "Pin-Yu Chen",
      "Sy-Yen Kuo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00887"
  },
  {
    "id": "arXiv:2211.00896",
    "title": "Factorized Blank Thresholding for Improved Runtime Efficiency of Neural  Transducers",
    "abstract": "We show how factoring the RNN-T's output distribution can significantly\nreduce the computation cost and power consumption for on-device ASR inference\nwith no loss in accuracy. With the rise in popularity of neural-transducer type\nmodels like the RNN-T for on-device ASR, optimizing RNN-T's runtime efficiency\nis of great interest. While previous work has primarily focused on the\noptimization of RNN-T's acoustic encoder and predictor, this paper focuses the\nattention on the joiner. We show that despite being only a small part of RNN-T,\nthe joiner has a large impact on the overall model's runtime efficiency. We\npropose to factorize the joiner into blank and non-blank portions for the\npurpose of skipping the more expensive non-blank computation when the blank\nprobability exceeds a certain threshold. Since the blank probability can be\ncomputed very efficiently and the RNN-T output is dominated by blanks, our\nproposed method leads to a 26-30% decoding speed-up and 43-53% reduction in\non-device power consumption, all the while incurring no accuracy degradation\nand being relatively simple to implement.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Duc Le",
      "Frank Seide",
      "Yuhao Wang",
      "Yang Li",
      "Kjell Schubert",
      "Ozlem Kalinli",
      "Michael L. Seltzer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00896"
  },
  {
    "id": "arXiv:2211.00899",
    "title": "LightVessel: Exploring Lightweight Coronary Artery Vessel Segmentation  via Similarity Knowledge Distillation",
    "abstract": "In recent years, deep convolution neural networks (DCNNs) have achieved great\nprospects in coronary artery vessel segmentation. However, it is difficult to\ndeploy complicated models in clinical scenarios since high-performance\napproaches have excessive parameters and high computation costs. To tackle this\nproblem, we propose \\textbf{LightVessel}, a Similarity Knowledge Distillation\nFramework, for lightweight coronary artery vessel segmentation. Primarily, we\npropose a Feature-wise Similarity Distillation (FSD) module for semantic-shift\nmodeling. Specifically, we calculate the feature similarity between the\nsymmetric layers from the encoder and decoder. Then the similarity is\ntransferred as knowledge from a cumbersome teacher network to a non-trained\nlightweight student network. Meanwhile, for encouraging the student model to\nlearn more pixel-wise semantic information, we introduce the Adversarial\nSimilarity Distillation (ASD) module. Concretely, the ASD module aims to\nconstruct the spatial adversarial correlation between the annotation and\nprediction from the teacher and student models, respectively. Through the ASD\nmodule, the student model obtains fined-grained subtle edge segmented results\nof the coronary artery vessel. Extensive experiments conducted on Clinical\nCoronary Artery Vessel Dataset demonstrate that LightVessel outperforms various\nknowledge distillation counterparts.",
    "descriptor": "\nComments: 5 pages, 7 figures, conference\n",
    "authors": [
      "Hao Dang",
      "Yuekai Zhang",
      "Xingqun Qi",
      "Wanting Zhou",
      "Muyi Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00899"
  },
  {
    "id": "arXiv:2211.00902",
    "title": "Spot the fake lungs: Generating Synthetic Medical Images using Neural  Diffusion Models",
    "abstract": "Generative models are becoming popular for the synthesis of medical images.\nRecently, neural diffusion models have demonstrated the potential to generate\nphoto-realistic images of objects. However, their potential to generate medical\nimages is not explored yet. In this work, we explore the possibilities of\nsynthesis of medical images using neural diffusion models. First, we use a\npre-trained DALLE2 model to generate lungs X-Ray and CT images from an input\ntext prompt. Second, we train a stable diffusion model with 3165 X-Ray images\nand generate synthetic images. We evaluate the synthetic image data through a\nqualitative analysis where two independent radiologists label randomly chosen\nsamples from the generated data as real, fake, or unsure. Results demonstrate\nthat images generated with the diffusion model can translate characteristics\nthat are otherwise very specific to certain medical conditions in chest X-Ray\nor CT images. Careful tuning of the model can be very promising. To the best of\nour knowledge, this is the first attempt to generate lungs X-Ray and CT images\nusing neural diffusion models. This work aims to introduce a new dimension in\nartificial intelligence for medical imaging. Given that this is a new topic,\nthe paper will serve as an introduction and motivation for the research\ncommunity to explore the potential of diffusion models for medical image\nsynthesis. We have released the synthetic images on\nhttps://www.kaggle.com/datasets/hazrat/awesomelungs.",
    "descriptor": "\nComments: 8 pages. Submitted to AICS 2022 conference\n",
    "authors": [
      "Hazrat Ali",
      "Shafaq Murad",
      "Zubair Shah"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00902"
  },
  {
    "id": "arXiv:2211.00918",
    "title": "Universal Deep Image Compression via Content-Adaptive Optimization with  Adapters",
    "abstract": "Deep image compression performs better than conventional codecs, such as\nJPEG, on natural images. However, deep image compression is learning-based and\nencounters a problem: the compression performance deteriorates significantly\nfor out-of-domain images. In this study, we highlight this problem and address\na novel task: universal deep image compression. This task aims to compress\nimages belonging to arbitrary domains, such as natural images, line drawings,\nand comics. To address this problem, we propose a content-adaptive optimization\nframework; this framework uses a pre-trained compression model and adapts the\nmodel to a target image during compression. Adapters are inserted into the\ndecoder of the model. For each input image, our framework optimizes the latent\nrepresentation extracted by the encoder and the adapter parameters in terms of\nrate-distortion. The adapter parameters are additionally transmitted per image.\nFor the experiments, a benchmark dataset containing uncompressed images of four\ndomains (natural images, line drawings, comics, and vector arts) is constructed\nand the proposed universal deep compression is evaluated. Finally, the proposed\nmodel is compared with non-adaptive and existing adaptive compression models.\nThe comparison reveals that the proposed model outperforms these. The code and\ndataset are publicly available at https://github.com/kktsubota/universal-dic.",
    "descriptor": "\nComments: Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Koki Tsubota",
      "Hiroaki Akutsu",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00918"
  },
  {
    "id": "arXiv:2211.00921",
    "title": "A Data-driven Case-based Reasoning in Bankruptcy Prediction",
    "abstract": "There has been intensive research regarding machine learning models for\npredicting bankruptcy in recent years. However, the lack of interpretability\nlimits their growth and practical implementation. This study proposes a\ndata-driven explainable case-based reasoning (CBR) system for bankruptcy\nprediction. Empirical results from a comparative study show that the proposed\napproach performs superior to existing, alternative CBR systems and is\ncompetitive with state-of-the-art machine learning models. We also demonstrate\nthat the asymmetrical feature similarity comparison mechanism in the proposed\nCBR system can effectively capture the asymmetrically distributed nature of\nfinancial attributes, such as a few companies controlling more cash than the\nmajority, hence improving both the accuracy and explainability of predictions.\nIn addition, we delicately examine the explainability of the CBR system in the\ndecision-making process of bankruptcy prediction. While much research suggests\na trade-off between improving prediction accuracy and explainability, our\nfindings show a prospective research avenue in which an explainable model that\nthoroughly incorporates data attributes by design can reconcile the dilemma.",
    "descriptor": "",
    "authors": [
      "Wei Li",
      "Wolfgang Karl H\u00e4rdle",
      "Stefan Lessmann"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00921"
  },
  {
    "id": "arXiv:2211.00943",
    "title": "Adversarial Guitar Amplifier Modelling With Unpaired Data",
    "abstract": "We propose an audio effects processing framework that learns to emulate a\ntarget electric guitar tone from a recording. We train a deep neural network\nusing an adversarial approach, with the goal of transforming the timbre of a\nguitar, into the timbre of another guitar after audio effects processing has\nbeen applied, for example, by a guitar amplifier. The model training requires\nno paired data, and the resulting model emulates the target timbre well whilst\nbeing capable of real-time processing on a modern personal computer. To verify\nour approach we present two experiments, one which carries out unpaired\ntraining using paired data, allowing us to monitor training via objective\nmetrics, and another that uses fully unpaired data, corresponding to a\nrealistic scenario where a user wants to emulate a guitar timbre only using\naudio data from a recording. Our listening test results confirm that the models\nare perceptually convincing.",
    "descriptor": "",
    "authors": [
      "Alec Wright",
      "Vesa V\u00e4lim\u00e4ki",
      "Lauri Juvela"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00943"
  },
  {
    "id": "arXiv:2211.00947",
    "title": "Linear Embedding-based High-dimensional Batch Bayesian Optimization  without Reconstruction Mappings",
    "abstract": "The optimization of high-dimensional black-box functions is a challenging\nproblem. When a low-dimensional linear embedding structure can be assumed,\nexisting Bayesian optimization (BO) methods often transform the original\nproblem into optimization in a low-dimensional space. They exploit the\nlow-dimensional structure and reduce the computational burden. However, we\nreveal that this approach could be limited or inefficient in exploring the\nhigh-dimensional space mainly due to the biased reconstruction of the\nhigh-dimensional queries from the low-dimensional queries. In this paper, we\ninvestigate a simple alternative approach: tackling the problem in the original\nhigh-dimensional space using the information from the learned low-dimensional\nstructure. We provide a theoretical analysis of the exploration ability.\nFurthermore, we show that our method is applicable to batch optimization\nproblems with thousands of dimensions without any computational difficulty. We\ndemonstrate the effectiveness of our method on high-dimensional benchmarks and\na real-world function.",
    "descriptor": "",
    "authors": [
      "Shuhei A. Horiguchi",
      "Tomoharu Iwata",
      "Taku Tsuzuki",
      "Yosuke Ozawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00947"
  },
  {
    "id": "arXiv:2211.00948",
    "title": "Deep Learning for Inflexible Multi-Asset Hedging of incomplete market",
    "abstract": "Models trained under assumptions in the complete market usually don't take\neffect in the incomplete market. This paper solves the hedging problem in\nincomplete market with three sources of incompleteness: risk factor,\nilliquidity, and discrete transaction dates. A new jump-diffusion model is\nproposed to describe stochastic asset prices. Three neutral networks, including\nRNN, LSTM, Mogrifier-LSTM are used to attain hedging strategies with MSE Loss\nand Huber Loss implemented and compared.As a result, Mogrifier-LSTM is the\nfastest model with the best results under MSE and Huber Loss.",
    "descriptor": "",
    "authors": [
      "Ruochen Xiao",
      "Qiaochu Feng",
      "Ruxin Deng"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00948"
  },
  {
    "id": "arXiv:2211.00962",
    "title": "Oblivious Quantum Computation and Delegated Multiparty Quantum  Computation",
    "abstract": "We propose a new concept, oblivious quantum computation, which requires\nperform oblivious transfer to send the computation outcome of the quantum\ncomputation, where the secrecy of the input qubits and the program to identify\nthe quantum gates is required. We propose a two-server protocol for this task,\nwhich realizes an exponential improvement for the communication complexity over\nthe simple application of two-server (quantum) oblivious transfer to the\nsending of the computation result. Also, we propose another new concept,\ndelegated multiparty quantum computation, in which, several users ask\nmultiparty quantum computation to server(s) only using classical\ncommunications. We propose a two-server protocol for this task.",
    "descriptor": "",
    "authors": [
      "Masahito Hayashi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.00962"
  },
  {
    "id": "arXiv:2211.00986",
    "title": "Matrix Denoising with Partial Noise Statistics: Optimal Singular Value  Shrinkage of Spiked F-Matrices",
    "abstract": "We study the problem of estimating a large, low-rank matrix corrupted by\nadditive noise of unknown covariance, assuming one has access to additional\nside information in the form of noise-only measurements. We study the\nWhiten-Shrink-reColor (WSC) workflow, where a \"noise covariance whitening\"\ntransformation is applied to the observations, followed by appropriate singular\nvalue shrinkage and a \"noise covariance re-coloring\" transformation. We show\nthat under the mean square error loss, a unique, asymptotically optimal\nshrinkage nonlinearity exists for the WSC denoising workflow, and calculate it\nin closed form. To this end, we calculate the asymptotic eigenvector rotation\nof the random spiked F-matrix ensemble, a result which may be of independent\ninterest. With sufficiently many pure-noise measurements, our optimally-tuned\nWSC denoising workflow outperforms, in mean square error, matrix denoising\nalgorithms based on optimal singular value shrinkage which do not make similar\nuse of noise-only side information; numerical experiments show that our\nprocedure's relative performance is particularly strong in challenging\nstatistical settings with high dimensionality and large degree of\nheteroscedasticity.",
    "descriptor": "",
    "authors": [
      "Matan Gavish",
      "William Leeb",
      "Elad Romanov"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00986"
  },
  {
    "id": "arXiv:2211.01001",
    "title": "Thunderstorm nowcasting with deep learning: a multi-hazard data fusion  model",
    "abstract": "Predictions of thunderstorm-related hazards are needed in several sectors,\nincluding first responders, infrastructure management and aviation. To address\nthis need, we present a deep learning model that can be adapted to different\nhazard types. The model can utilize multiple data sources; we use data from\nweather radar, lightning detection, satellite visible/infrared imagery,\nnumerical weather prediction and digital elevation models. It can be trained to\noperate with any combination of these sources, such that predictions can still\nbe provided if one or more of the sources become unavailable. We demonstrate\nthe ability of the model to predict lightning, hail and heavy precipitation\nprobabilistically on a 1 km resolution grid, with a time resolution of 5 min\nand lead times up to 60 min. Shapley values quantify the importance of the\ndifferent data sources, showing that the weather radar products are the most\nimportant predictors for all three hazard types.",
    "descriptor": "\nComments: 15 pages, 3 figures. Submitted to Geophysical Research Letters\n",
    "authors": [
      "Jussi Leinonen",
      "Ulrich Hamann",
      "Ioannis V. Sideris",
      "Urs Germann"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01001"
  },
  {
    "id": "arXiv:2211.01021",
    "title": "Data-Driven Modeling of Landau Damping by Physics-Informed Neural  Networks",
    "abstract": "Kinetic approaches are generally accurate in dealing with microscale plasma\nphysics problems but are computationally expensive for large-scale or\nmultiscale systems. One of the long-standing problems in plasma physics is the\nintegration of kinetic physics into fluid models, which is often achieved\nthrough sophisticated analytical closure terms. In this study, we successfully\nconstruct a multi-moment fluid model with an implicit fluid closure included in\nthe neural network using machine learning. The multi-moment fluid model is\ntrained with a small fraction of sparsely sampled data from kinetic simulations\nof Landau damping, using the physics-informed neural network (PINN) and the\ngradient-enhanced physics-informed neural network (gPINN). The multi-moment\nfluid model constructed using either PINN or gPINN reproduces the time\nevolution of the electric field energy, including its damping rate, and the\nplasma dynamics from the kinetic simulations. For the first time, we introduce\na new variant of the gPINN architecture, namely, gPINN$p$ to capture the Landau\ndamping process. Instead of including the gradients of all the equation\nresiduals, gPINN$p$ only adds the gradient of the pressure equation residual as\none additional constraint. Among the three approaches, the gPINN$p$-constructed\nmulti-moment fluid model offers the most accurate results. This work sheds new\nlight on the accurate and efficient modeling of large-scale systems, which can\nbe extended to complex multiscale laboratory, space, and astrophysical plasma\nphysics problems.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Yilan Qin",
      "Jiayu Ma",
      "Mingle Jiang",
      "Chuanfei Dong",
      "Haiyang Fu",
      "Liang Wang",
      "Wenjie Cheng",
      "Yaqiu Jin"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Space Physics (physics.space-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.01021"
  },
  {
    "id": "arXiv:2211.01032",
    "title": "Random Embeddings of Graphs: The Expected Number of Faces in Most Graphs  is Logarithmic",
    "abstract": "A random 2-cell embedding of a connected graph $G$ in some orientable surface\nis obtained by choosing a random local rotation around each vertex. Under this\nsetup, the number of faces or the genus of the corresponding 2-cell embedding\nbecomes a random variable. Random embeddings of two particular graph classes --\nthose of a bouquet of $n$ loops and those of $n$ parallel edges connecting two\nvertices -- have been extensively studied and are well-understood. However,\nlittle is known about more general graphs despite their important connections\nwith central problems in mainstream mathematics and in theoretical physics (see\n[Lando & Zvonkin, Springer 2004]). There are also tight connections with\nproblems in computing (random generation, approximation algorithms). The\nresults of this paper, in particular, explain why Monte Carlo methods (see,\ne.g., [Gross & Tucker, Ann. NY Acad. Sci 1979] and [Gross & Rieper, JGT 1991])\ncannot work for approximating the minimum genus of graphs.\nIn his breakthrough work ([Stahl, JCTB 1991] and a series of other papers),\nStahl developed the foundation of \"random topological graph theory\". Most of\nhis results have been unsurpassed until today. In our work, we analyze the\nexpected number of faces of random embeddings (equivalently, the average genus)\nof a graph $G$. It was very recently shown [Campion Loth & Mohar, arXiv 2022]\nthat for any graph $G$, the expected number of faces is at most linear. We show\nthat the actual expected number of faces is usually much smaller. In\nparticular, we prove the following results:\n1) $\\frac{1}{2}\\ln n - 2 < \\mathbb{E}[F(K_n)] \\le 3.65\\ln n$, for $n$\nsufficiently large. This greatly improves Stahl's $n+\\ln n$ upper bound for\nthis case.\n2) For random models $B(n,\\Delta)$ containing only graphs, whose maximum\ndegree is at most $\\Delta$, we show that the expected number of faces is\n$\\Theta(\\ln n)$.",
    "descriptor": "\nComments: 44 pages, 6 figures\n",
    "authors": [
      "Jesse Campion Loth",
      "Kevin Halasz",
      "Tom\u00e1\u0161 Masa\u0159\u00edk",
      "Bojan Mohar",
      "Robert \u0160\u00e1mal"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.01032"
  },
  {
    "id": "arXiv:2211.01046",
    "title": "Monolingual Recognizers Fusion for Code-switching Speech Recognition",
    "abstract": "The bi-encoder structure has been intensively investigated in code-switching\n(CS) automatic speech recognition (ASR). However, most existing methods require\nthe structures of two monolingual ASR models (MAMs) should be the same and only\nuse the encoder of MAMs. This leads to the problem that pre-trained MAMs cannot\nbe timely and fully used for CS ASR. In this paper, we propose a monolingual\nrecognizers fusion method for CS ASR. It has two stages: the speech awareness\n(SA) stage and the language fusion (LF) stage. In the SA stage, acoustic\nfeatures are mapped to two language-specific predictions by two independent\nMAMs. To keep the MAMs focused on their own language, we further extend the\nlanguage-aware training strategy for the MAMs. In the LF stage, the BELM fuses\ntwo language-specific predictions to get the final prediction. Moreover, we\npropose a text simulation strategy to simplify the training process of the BELM\nand reduce reliance on CS data. Experiments on a Mandarin-English corpus show\nthe efficiency of the proposed method. The mix error rate is significantly\nreduced on the test set after using open-source pre-trained MAMs.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Tongtong Song",
      "Qiang Xu",
      "Haoyu Lu",
      "Longbiao Wang",
      "Hao Shi",
      "Yuqin Lin",
      "Yanbing Yang",
      "Jianwu Dang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01046"
  },
  {
    "id": "arXiv:2211.01058",
    "title": "A Note on the Ramanujan Machine",
    "abstract": "The Ramanujan Machine project detects new expressions related to constants of\ninterest, such as $\\zeta$ function values, $\\gamma$ and algebraic numbers (to\nname a few). In particular the project lists a number of conjectures involving\neven and odd $\\zeta$ function values, logarithms etc. We show that many\nrelations detected by the Ramanujan Machine Project stem from a specific\nalgebraic observation and show how to generate infinitely many. This provides\nan automated proof of many of the relations listed as conjectures by the\nproject (although not all of them).",
    "descriptor": "",
    "authors": [
      "Eric Brier",
      "David Naccache",
      "Ofer Yifrach-Stav"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2211.01058"
  },
  {
    "id": "arXiv:2211.01091",
    "title": "I4U System Description for NIST SRE'20 CTS Challenge",
    "abstract": "This manuscript describes the I4U submission to the 2020 NIST Speaker\nRecognition Evaluation (SRE'20) Conversational Telephone Speech (CTS)\nChallenge. The I4U's submission was resulted from active collaboration among\nresearchers across eight research teams - I$^2$R (Singapore), UEF (Finland),\nVALPT (Italy, Spain), NEC (Japan), THUEE (China), LIA (France), NUS\n(Singapore), INRIA (France) and TJU (China). The submission was based on the\nfusion of top performing sub-systems and sub-fusion systems contributed by\nindividual teams. Efforts have been spent on the use of common development and\nvalidation sets, submission schedule and milestone, minimizing inconsistency in\ntrial list and score file format across sites.",
    "descriptor": "\nComments: SRE 2021, NIST Speaker Recognition Evaluation Workshop, CTS Speaker Recognition Challenge, 14-12 December 2021\n",
    "authors": [
      "Kong Aik Lee",
      "Tomi Kinnunen",
      "Daniele Colibro",
      "Claudio Vair",
      "Andreas Nautsch",
      "Hanwu Sun",
      "Liang He",
      "Tianyu Liang",
      "Qiongqiong Wang",
      "Mickael Rouvier",
      "Pierre-Michel Bousquet",
      "Rohan Kumar Das",
      "Ignacio Vi\u00f1als Bailo",
      "Meng Liu",
      "H\u00e9ctor Deldago",
      "Xuechen Liu",
      "Md Sahidullah",
      "Sandro Cumani",
      "Boning Zhang",
      "Koji Okabe",
      "Hitoshi Yamamoto",
      "Ruijie Tao",
      "Haizhou Li",
      "Alfonso Ortega Gim\u00e9nez",
      "Longbiao Wang",
      "Luis Buera"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01091"
  },
  {
    "id": "arXiv:2211.01111",
    "title": "On the Benefit of Dual-domain Denoising in a Self-supervised Low-dose CT  Setting",
    "abstract": "Computed tomography (CT) is routinely used for three-dimensional non-invasive\nimaging. Numerous data-driven image denoising algorithms were proposed to\nrestore image quality in low-dose acquisitions. However, considerably less\nresearch investigates methods already intervening in the raw detector data due\nto limited access to suitable projection data or correct reconstruction\nalgorithms. In this work, we present an end-to-end trainable CT reconstruction\npipeline that contains denoising operators in both the projection and the image\ndomain and that are optimized simultaneously without requiring ground-truth\nhigh-dose CT data. Our experiments demonstrate that including an additional\nprojection denoising operator improved the overall denoising performance by\n82.4-94.1%/12.5-41.7% (PSNR/SSIM) on abdomen CT and 1.5-2.9%/0.4-0.5%\n(PSNR/SSIM) on XRM data relative to the low-dose baseline. We make our entire\nhelical CT reconstruction framework publicly available that contains a raw\nprojection rebinning step to render helical projection data suitable for\ndifferentiable fan-beam reconstruction operators and end-to-end learning.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Fabian Wagner",
      "Mareike Thies",
      "Laura Pfaff",
      "Oliver Aust",
      "Sabrina Pechmann",
      "Daniela Weidner",
      "Noah Maul",
      "Maximilian Rohleder",
      "Mingxuan Gu",
      "Jonas Utz",
      "Felix Denzinger",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01111"
  },
  {
    "id": "arXiv:2211.01125",
    "title": "Style Augmentation improves Medical Image Segmentation",
    "abstract": "Due to the limitation of available labeled data, medical image segmentation\nis a challenging task for deep learning. Traditional data augmentation\ntechniques have been shown to improve segmentation network performances by\noptimizing the usage of few training examples. However, current augmentation\napproaches for segmentation do not tackle the strong texture bias of\nconvolutional neural networks, observed in several studies. This work shows on\nthe MoNuSeg dataset that style augmentation, which is already used in\nclassification tasks, helps reducing texture over-fitting and improves\nsegmentation performance.",
    "descriptor": "",
    "authors": [
      "Kevin Ginsburger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01125"
  },
  {
    "id": "arXiv:2211.01126",
    "title": "Likelihood-free hypothesis testing",
    "abstract": "Consider the problem of testing $Z \\sim \\mathbb P^{\\otimes m}$ vs $Z \\sim\n\\mathbb Q^{\\otimes m}$ from $m$ samples. Generally, to achieve a small error\nrate it is necessary and sufficient to have $m \\asymp 1/\\epsilon^2$, where\n$\\epsilon$ measures the separation between $\\mathbb P$ and $\\mathbb Q$ in total\nvariation ($\\mathsf{TV}$). Achieving this, however, requires complete knowledge\nof the distributions $\\mathbb P$ and $\\mathbb Q$ and can be done, for example,\nusing the Neyman-Pearson test. In this paper we consider a variation of the\nproblem, which we call likelihood-free (or simulation-based) hypothesis\ntesting, where access to $\\mathbb P$ and $\\mathbb Q$ (which are a priori only\nknown to belong to a large non-parametric family $\\mathcal P$) is given through\n$n$ iid samples from each. We demostrate existence of a fundamental trade-off\nbetween $n$ and $m$ given by $nm \\asymp n^2_\\mathsf{GoF}(\\epsilon,\\mathcal P)$,\nwhere $n_\\mathsf{GoF}$ is the minimax sample complexity of testing between the\nhypotheses $H_0: \\mathbb P= \\mathbb Q$ vs $H_1: \\mathsf{TV}(\\mathbb P,\\mathbb\nQ) \\ge \\epsilon$. We show this for three non-parametric families $\\cal P$:\n$\\beta$-smooth densities over $[0,1]^d$, the Gaussian sequence model over a\nSobolev ellipsoid, and the collection of distributions $\\mathcal P$ on a large\nalphabet $[k]$ with pmfs bounded by $c/k$ for fixed $c$. The test that we\npropose (based on the $L^2$-distance statistic of Ingster) simultaneously\nachieves all points on the tradeoff curve for these families. In particular,\nwhen $m\\gg 1/\\epsilon^2$ our test requires the number of simulation samples $n$\nto be orders of magnitude smaller than what is needed for density estimation\nwith accuracy $\\asymp \\epsilon$ (under $\\mathsf{TV}$). This demonstrates the\npossibility of testing without fully estimating the distributions.",
    "descriptor": "\nComments: 48 pages, 1 figure\n",
    "authors": [
      "Patrik R\u00f3bert Gerber",
      "Yury Polyanskiy"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.01126"
  },
  {
    "id": "arXiv:2211.01131",
    "title": "RF signal classification in hardware with an RF spintronic neural  network",
    "abstract": "Extracting information from radiofrequency (RF) signals using artificial\nneural networks at low energy cost is a critical need for a wide range of\napplications. Here we show how to leverage the intrinsic dynamics of spintronic\nnanodevices called magnetic tunnel junctions to process multiple analogue RF\ninputs in parallel and perform synaptic operations. Furthermore, we achieve\nclassification of RF signals with experimental data from magnetic tunnel\njunctions as neurons and synapses, with the same accuracy as an equivalent\nsoftware neural network. These results are a key step for embedded\nradiofrequency artificial intelligence.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Nathan Leroux",
      "Danijela Markovi\u0107",
      "D\u00e9dalo Sanz-Hern\u00e1ndez",
      "Juan Trastoy",
      "Paolo Bortolotti",
      "Alejandro Schulman",
      "Luana Benetti",
      "Alex Jenkins",
      "Ricardo Ferreira",
      "Julie Grollier",
      "Alice Mizrahi"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.01131"
  },
  {
    "id": "arXiv:2211.01134",
    "title": "Faster variational quantum algorithms with quantum kernel-based  surrogate models",
    "abstract": "We present a new optimization method for small-to-intermediate scale\nvariational algorithms on noisy near-term quantum processors which uses a\nGaussian process surrogate model equipped with a classically-evaluated quantum\nkernel. Variational algorithms are typically optimized using gradient-based\napproaches however these are difficult to implement on current noisy devices,\nrequiring large numbers of objective function evaluations. Our scheme shifts\nthis computational burden onto the classical optimizer component of these\nhybrid algorithms, greatly reducing the number of queries to the quantum\nprocessor. We focus on the variational quantum eigensolver (VQE) algorithm and\ndemonstrate numerically that such surrogate models are particularly well suited\nto the algorithm's objective function. Next, we apply these models to both\nnoiseless and noisy VQE simulations and show that they exhibit better\nperformance than widely-used classical kernels in terms of final accuracy and\nconvergence speed. Compared to the typically-used stochastic gradient-descent\napproach for VQAs, our quantum kernel-based approach is found to consistently\nachieve significantly higher accuracy while requiring less than an order of\nmagnitude fewer quantum circuit evaluations. We analyse the performance of the\nquantum kernel-based models in terms of the kernels' induced feature spaces and\nexplicitly construct their feature maps. Finally, we describe a scheme for\napproximating the best-performing quantum kernel using a classically-efficient\ntensor network representation of its input state and so provide a pathway for\nscaling these methods to larger systems.",
    "descriptor": "",
    "authors": [
      "Alistair W. R. Smith",
      "A. J. Paige",
      "M. S. Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01134"
  },
  {
    "id": "arXiv:2211.01159",
    "title": "Unsupervised denoising for sparse multi-spectral computed tomography",
    "abstract": "Multi-energy computed tomography (CT) with photon counting detectors (PCDs)\nenables spectral imaging as PCDs can assign the incoming photons to specific\nenergy channels. However, PCDs with many spectral channels drastically increase\nthe computational complexity of the CT reconstruction, and bespoke\nreconstruction algorithms need fine-tuning to varying noise statistics.\n\\rev{Especially if many projections are taken, a large amount of data has to be\ncollected and stored. Sparse view CT is one solution for data reduction.\nHowever, these issues are especially exacerbated when sparse imaging scenarios\nare encountered due to a significant reduction in photon counts.} In this work,\nwe investigate the suitability of learning-based improvements to the\nchallenging task of obtaining high-quality reconstructions from sparse\nmeasurements for a 64-channel PCD-CT. In particular, to overcome missing\nreference data for the training procedure, we propose an unsupervised denoising\nand artefact removal approach by exploiting different filter functions in the\nreconstruction and an explicit coupling of spectral channels with the nuclear\nnorm. Performance is assessed on both simulated synthetic data and the openly\navailable experimental Multi-Spectral Imaging via Computed Tomography (MUSIC)\ndataset. We compared the quality of our unsupervised method to iterative total\nnuclear variation regularized reconstructions and a supervised denoiser trained\nwith reference data. We show that improved reconstruction quality can be\nachieved with flexibility on noise statistics and effective suppression of\nstreaking artefacts when using unsupervised denoising with spectral coupling.",
    "descriptor": "",
    "authors": [
      "Satu I. Inkinen",
      "Mikael A. K. Brix",
      "Miika T. Nieminen",
      "Simon Arridge",
      "Andreas Hauptmann"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2211.01159"
  },
  {
    "id": "arXiv:2211.01189",
    "title": "Inference and Denoise: Causal Inference-based Neural Speech Enhancement",
    "abstract": "This study addresses the speech enhancement (SE) task within the causal\ninference paradigm by modeling the noise presence as an intervention. Based on\nthe potential outcome framework, the proposed causal inference-based speech\nenhancement (CISE) separates clean and noisy frames in an intervened noisy\nspeech using a noise detector and assigns both sets of frames to two mask-based\nenhancement modules (EMs) to perform noise-conditional SE. Specifically, we use\nthe presence of noise as guidance for EM selection during training, and the\nnoise detector selects the enhancement module according to the prediction of\nthe presence of noise for each frame. Moreover, we derived a SE-specific\naverage treatment effect to quantify the causal effect adequately. Experimental\nevidence demonstrates that CISE outperforms a non-causal mask-based SE approach\nin the studied settings and has better performance and efficiency than more\ncomplex SE models.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Tsun-An Hsieh",
      "Chao-Han Huck Yang",
      "Pin-Yu Chen",
      "Sabato Marco Siniscalchi",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01189"
  },
  {
    "id": "arXiv:2211.01198",
    "title": "Analysis of Noisy-target Training for DNN-based speech enhancement",
    "abstract": "Deep neural network (DNN)-based speech enhancement usually uses a clean\nspeech as a training target. However, it is hard to collect large amounts of\nclean speech because the recording is very costly. In other words, the\nperformance of current speech enhancement has been limited by the amount of\ntraining data. To relax this limitation, Noisy-target Training (NyTT) that\nutilizes noisy speech as a training target has been proposed. Although it has\nbeen experimentally shown that NyTT can train a DNN without clean speech, a\ndetailed analysis has not been conducted and its behavior has not been\nunderstood well. In this paper, we conduct various analyses to deepen our\nunderstanding of NyTT. In addition, based on the property of NyTT, we propose a\nrefined method that is comparable to the method using clean speech.\nFurthermore, we show that we can improve the performance by using a huge amount\nof noisy speech with clean speech.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Takuya Fujimura",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01198"
  },
  {
    "id": "arXiv:2211.01209",
    "title": "An Asymptotically Optimal Bound for Covering Arrays of Higher Index",
    "abstract": "A \\emph{covering array} is an $N \\times k$ array ($N$ rows, $k$ columns) with\neach entry from a $v$-ary alphabet, and for every $N\\times t$ subarray, all\n$v^t$ tuples of size $t$ appear at least $\\lambda$ times. The \\emph{covering\narray number} is the smallest number $N$ for which such an array exists. For\n$\\lambda = 1$, the covering array number is asymptotically logarithmic in $k$,\nwhen $v, t$ are fixed. Godbole, Skipper, and Sunley proved a bound of the form\n$\\log k + \\lambda \\log \\log k$ for the covering array number for arbitrary\n$\\lambda$ and $v,t$ constant. The author proved a similar bound via a different\ntechnique, and conjectured that the $\\log \\log k$ term can be removed. In this\nshort note we answer the conjecture in the affirmative with an asymptotically\ntight upper bound. In particular, we employ the probabilistic method in\nconjunction with the Lambert $W$ function.",
    "descriptor": "",
    "authors": [
      "Ryan E. Dougherty"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.01209"
  },
  {
    "id": "arXiv:2211.01241",
    "title": "WiserVR: Semantic Communication Enabled Wireless Virtual Reality  Delivery",
    "abstract": "Virtual reality (VR) over wireless is expected to be one of the killer\napplications in next-generation communication networks. Nevertheless, the huge\ndata volume along with stringent requirements on latency and reliability under\nlimited bandwidth resources makes untethered wireless VR delivery increasingly\nchallenging. Such bottlenecks, therefore, motivate this work to seek the\npotential of using semantic communication, a new paradigm that promises to\nsignificantly ease the resource pressure, for efficient VR delivery. To this\nend, we propose a novel framework, namely WIreless SEmantic deliveRy for VR\n(WiserVR), for delivering consecutive 360{\\deg} video frames to VR users.\nSpecifically, deep learning-based multiple modules are well-devised for the\ntransceiver in WiserVR to realize high-performance feature extraction and\nsemantic recovery. Among them, we dedicatedly develop a concept of semantic\nlocation graph and leverage the joint-semantic-channel-coding method with\nknowledge sharing to not only substantially reduce communication latency, but\nalso to guarantee adequate transmission reliability and resilience under\nvarious channel states. Moreover, implementation of WiserVR is presented,\nfollowed by corresponding initial simulations for performance evaluation\ncompared with benchmarks. Finally, we discuss several open issues and offer\nfeasible solutions to unlock the full potential of WiserVR.",
    "descriptor": "\nComments: This article has been submitted to IEEE Wireless Communications Magazine (after major revisions) for possible publication\n",
    "authors": [
      "Le Xia",
      "Yao Sun",
      "Chengsi Liang",
      "Daquan Feng",
      "Runze Cheng",
      "Yang Yang",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.01241"
  },
  {
    "id": "arXiv:2211.01245",
    "title": "An efficient algorithm for the $\\ell_{p}$ norm based metric nearness  problem",
    "abstract": "Given a dissimilarity matrix, the metric nearness problem is to find the\nnearest matrix of distances that satisfy the triangle inequalities. This\nproblem has wide applications, such as sensor networks, image processing, and\nso on. But it is of great challenge even to obtain a moderately accurate\nsolution due to the $O(n^{3})$ metric constraints and the nonsmooth objective\nfunction which is usually a weighted $\\ell_{p}$ norm based distance. In this\npaper, we propose a delayed constraint generation method with each subproblem\nsolved by the semismooth Newton based proximal augmented Lagrangian method\n(PALM) for the metric nearness problem. Due to the high memory requirement for\nthe storage of the matrix related to the metric constraints, we take advantage\nof the special structure of the matrix and do not need to store the\ncorresponding constraint matrix. A pleasing aspect of our algorithm is that we\ncan solve these problems involving up to $10^{8}$ variables and $10^{13}$\nconstraints. Numerical experiments demonstrate the efficiency of our algorithm.\nIn theory, firstly, under a mild condition, we establish a primal-dual error\nbound condition which is very essential for the analysis of local convergence\nrate of PALM. Secondly, we prove the equivalence between the dual nondegeneracy\ncondition and nonsingularity of the generalized Jacobian for the inner\nsubproblem of PALM. Thirdly, when $q(\\cdot)=\\|\\cdot\\|_{1}$ or\n$\\|\\cdot\\|_{\\infty}$, without the strict complementarity condition, we also\nprove the equivalence between the the dual nondegeneracy condition and the\nuniqueness of the primal solution.",
    "descriptor": "",
    "authors": [
      "Peipei Tang",
      "Bo Jiang",
      "Chengjing Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01245"
  },
  {
    "id": "arXiv:2211.01246",
    "title": "data2vec-aqc: Search for the right Teaching Assistant in the  Teacher-Student training setup",
    "abstract": "In this paper, we propose a new Self-Supervised Learning (SSL) algorithm\ncalled data2vec-aqc, for speech representation learning from unlabeled speech\ndata. Our goal is to improve SSL for speech in domains where both unlabeled and\nlabeled data are limited. Building on the recently introduced data2vec, we\nintroduce additional modules to the data2vec framework that leverage the\nbenefit of data augmentations, quantized representations, and clustering. The\ninteraction between these modules helps solve the cross-contrastive loss as an\nadditional self-supervised objective. data2vec-aqc achieves up to 14.1% and\n20.9% relative WER improvement over the existing state-of-the-art data2vec\nsystem on the test-clean and test-other sets, respectively, of LibriSpeech,\nwithout the use of any language model. Our proposed model also achieves up to\n17.8% relative WER improvement over the baseline data2vec when fine-tuned on\nSwitchboard data.",
    "descriptor": "\nComments: Submitted to ICASSP 2023. arXiv admin note: text overlap with arXiv:2210.02592\n",
    "authors": [
      "Vasista Sai Lodagala",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01246"
  },
  {
    "id": "arXiv:2211.01258",
    "title": "Instance-Dependent Generalization Bounds via Optimal Transport",
    "abstract": "Existing generalization bounds fail to explain crucial factors that drive\ngeneralization of modern neural networks. Since such bounds often hold\nuniformly over all parameters, they suffer from over-parametrization, and fail\nto account for the fact that the set of parameters, considered during\ninitialization and training, is much more restricted than the entire parameter\nspace. As an alternative, we propose a novel optimal transport interpretation\nof the generalization problem. This allows us to derive instance-dependent\ngeneralization bounds that depend on the local Lipschitz regularity of the\nlearned prediction function} in the data space. Therefore, our bounds are\nagnostic to the parametrization of the model and work well when the number of\ntraining samples is much smaller than the number of parameters. With small\nmodifications, our approach yields accelerated rates for data on\nlow-dimensional manifolds, and guarantees under distribution shifts. We\nempirically analyze our generalization bounds for neural networks, showing that\nthe bound values are meaningful and capture the effect of popular\nregularization methods during training.",
    "descriptor": "\nComments: 50 pages, 7 figures\n",
    "authors": [
      "Songyan Hou",
      "Parnian Kassraie",
      "Anastasis Kratsios",
      "Jonas Rothfuss",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01258"
  },
  {
    "id": "arXiv:2211.01280",
    "title": "An Exponentially Converging Particle Method for the Mixed Nash  Equilibrium of Continuous Games",
    "abstract": "We consider the problem of computing mixed Nash equilibria of two-player\nzero-sum games with continuous sets of pure strategies and with first-order\naccess to the payoff function. This problem arises for example in\ngame-theory-inspired machine learning applications, such as\ndistributionally-robust learning. In those applications, the strategy sets are\nhigh-dimensional and thus methods based on discretisation cannot tractably\nreturn high-accuracy solutions.\nIn this paper, we introduce and analyze a particle-based method that enjoys\nguaranteed local convergence for this problem. This method consists in\nparametrizing the mixed strategies as atomic measures and applying proximal\npoint updates to both the atoms' weights and positions. It can be interpreted\nas a time-implicit discretization of the \"interacting\" Wasserstein-Fisher-Rao\ngradient flow.\nWe prove that, under non-degeneracy assumptions, this method converges at an\nexponential rate to the exact mixed Nash equilibrium from any initialization\nsatisfying a natural notion of closeness to optimality. We illustrate our\nresults with numerical experiments and discuss applications to max-margin and\ndistributionally-robust classification using two-layer neural networks, where\nour method has a natural interpretation as a simultaneous training of the\nnetwork's weights and of the adversarial distribution.",
    "descriptor": "\nComments: 77 pages, 6 figures\n",
    "authors": [
      "Guillaume Wang",
      "L\u00e9na\u00efc Chizat"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01280"
  },
  {
    "id": "arXiv:2211.01287",
    "title": "Evaluating Impact of Social Media Posts by Executives on Stock Prices",
    "abstract": "Predicting stock market movements has always been of great interest to\ninvestors and an active area of research. Research has proven that popularity\nof products is highly influenced by what people talk about. Social media like\nTwitter, Reddit have become hotspots of such influences. This paper\ninvestigates the impact of social media posts on close price prediction of\nstocks using Twitter and Reddit posts. Our objective is to integrate sentiment\nof social media data with historical stock data and study its effect on closing\nprices using time series models. We carried out rigorous experiments and deep\nanalysis using multiple deep learning based models on different datasets to\nstudy the influence of posts by executives and general people on the close\nprice. Experimental results on multiple stocks (Apple and Tesla) and\ndecentralised currencies (Bitcoin and Ethereum) consistently show improvements\nin prediction on including social media data and greater improvements on\nincluding executive posts.",
    "descriptor": "\nComments: Accepted at the 14th meeting of Forum for Information Retrieval Evaluation (FIRE-2022)\n",
    "authors": [
      "Anubhav Sarkar",
      "Swagata Chakraborty",
      "Sohom Ghosh",
      "Sudip Kumar Naskar"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.01287"
  },
  {
    "id": "arXiv:2211.01293",
    "title": "DC-cycleGAN: Bidirectional CT-to-MR Synthesis from Unpaired Data",
    "abstract": "Magnetic resonance (MR) and computer tomography (CT) images are two typical\ntypes of medical images that provide mutually-complementary information for\naccurate clinical diagnosis and treatment. However, obtaining both images may\nbe limited due to some considerations such as cost, radiation dose and modality\nmissing. Recently, medical image synthesis has aroused gaining research\ninterest to cope with this limitation. In this paper, we propose a\nbidirectional learning model, denoted as dual contrast cycleGAN (DC-cycleGAN),\nto synthesis medical images from unpaired data. Specifically, a dual contrast\nloss is introduced into the discriminators to indirectly build constraints\nbetween MR and CT images by taking the advantage of samples from the source\ndomain as negative sample and enforce the synthetic images fall far away from\nthe source domain. In addition, cross entropy and structural similarity index\n(SSIM) are integrated into the cycleGAN in order to consider both luminance and\nstructure of samples when synthesizing images. The experimental results\nindicates that DC-cycleGAN is able to produce promising results as compared\nwith other cycleGAN-based medical image synthesis methods such as cycleGAN,\nRegGAN, DualGAN and NiceGAN. The code will be available at\nhttps://github.com/JiayuanWang-JW/DC-cycleGAN.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Jiayuan Wang",
      "Q. M. Jonathan Wu",
      "Farhad Pourpanah"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01293"
  },
  {
    "id": "arXiv:2211.01299",
    "title": "Towards End-to-end Speaker Diarization in the Wild",
    "abstract": "Speaker diarization algorithms address the \"who spoke when\" problem in audio\nrecordings. Algorithms trained end-to-end have proven superior to classical\nmodular-cascaded systems in constrained scenarios with a small number of\nspeakers. However, their performance for in-the-wild recordings containing more\nspeakers with shorter utterance lengths remains to be investigated. In this\npaper, we address this gap, showing that an attractor-based end-to-end system\ncan also perform remarkably well in the latter scenario when first pre-trained\non a carefully-designed simulated dataset that matches the distribution of\nin-the-wild recordings. We also propose to use an attention mechanism to\nincrease the network capacity in decoding more speaker attractors, and to\njointly train the attractors on a speaker recognition task to improve the\nspeaker attractor representation. Even though the model we propose is\naudio-only, we find it significantly outperforms both audio-only and\naudio-visual baselines on the AVA-AVD benchmark dataset, achieving\nstate-of-the-art results with an absolute reduction in diarization error of\n23.3%.",
    "descriptor": "\nComments: 5 pages, 2 figures, 2 tables. Submitted to ICASSP 2023\n",
    "authors": [
      "Zexu Pan",
      "Gordon Wichern",
      "Fran\u00e7ois G. Germain",
      "Aswin Subramanian",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.01299"
  },
  {
    "id": "arXiv:2211.01323",
    "title": "Generation of Anonymous Chest Radiographs Using Latent Diffusion Models  for Training Thoracic Abnormality Classification Systems",
    "abstract": "The availability of large-scale chest X-ray datasets is a requirement for\ndeveloping well-performing deep learning-based algorithms in thoracic\nabnormality detection and classification. However, biometric identifiers in\nchest radiographs hinder the public sharing of such data for research purposes\ndue to the risk of patient re-identification. To counteract this issue,\nsynthetic data generation offers a solution for anonymizing medical images.\nThis work employs a latent diffusion model to synthesize an anonymous chest\nX-ray dataset of high-quality class-conditional images. We propose a\nprivacy-enhancing sampling strategy to ensure the non-transference of biometric\ninformation during the image generation process. The quality of the generated\nimages and the feasibility of serving as exclusive training data are evaluated\non a thoracic abnormality classification task. Compared to a real classifier,\nwe achieve competitive results with a performance gap of only 3.5% in the area\nunder the receiver operating characteristic curve.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kai Packh\u00e4user",
      "Lukas Folle",
      "Florian Thamm",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01323"
  },
  {
    "id": "arXiv:2211.01330",
    "title": "Bayesian Nonlocal Operator Regression (BNOR): A Data-Driven Learning  Framework of Nonlocal Models with Uncertainty Quantification",
    "abstract": "We consider the problem of modeling heterogeneous materials where micro-scale\ndynamics and interactions affect global behavior. In the presence of\nheterogeneities in material microstructure it is often impractical, if not\nimpossible, to provide quantitative characterization of material response. The\ngoal of this work is to develop a Bayesian framework for uncertainty\nquantification (UQ) in material response prediction when using nonlocal models.\nOur approach combines the nonlocal operator regression (NOR) technique and\nBayesian inference. Specifically, we use a Markov chain Monte Carlo (MCMC)\nmethod to sample the posterior probability distribution on parameters involved\nin the nonlocal constitutive law, and associated modeling discrepancies\nrelative to higher fidelity computations. As an application, we consider the\npropagation of stress waves through a one-dimensional heterogeneous bar with\nrandomly generated microstructure. Several numerical tests illustrate the\nconstruction, enabling UQ in nonlocal model predictions. Although nonlocal\nmodels have become popular means for homogenization, their statistical\ncalibration with respect to high-fidelity models has not been presented before.\nThis work is a first step towards statistical characterization of nonlocal\nmodel discrepancy in the context of homogenization.",
    "descriptor": "",
    "authors": [
      "Yiming Fan",
      "Marta D'Elia",
      "Yue Yu",
      "Habib N. Najm",
      "Stewart Silling"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01330"
  },
  {
    "id": "arXiv:2211.01338",
    "title": "Technology Pipeline for Large Scale Cross-Lingual Dubbing of Lecture  Videos into Multiple Indian Languages",
    "abstract": "Cross-lingual dubbing of lecture videos requires the transcription of the\noriginal audio, correction and removal of disfluencies, domain term discovery,\ntext-to-text translation into the target language, chunking of text using\ntarget language rhythm, text-to-speech synthesis followed by isochronous\nlipsyncing to the original video. This task becomes challenging when the source\nand target languages belong to different language families, resulting in\ndifferences in generated audio duration. This is further compounded by the\noriginal speaker's rhythm, especially for extempore speech. This paper\ndescribes the challenges in regenerating English lecture videos in Indian\nlanguages semi-automatically. A prototype is developed for dubbing lectures\ninto 9 Indian languages. A mean-opinion-score (MOS) is obtained for two\nlanguages, Hindi and Tamil, on two different courses. The output video is\ncompared with the original video in terms of MOS (1-5) and lip synchronisation\nwith scores of 4.09 and 3.74, respectively. The human effort also reduces by\n75%.",
    "descriptor": "",
    "authors": [
      "Anusha Prakash",
      "Arun Kumar",
      "Ashish Seth",
      "Bhagyashree Mukherjee",
      "Ishika Gupta",
      "Jom Kuriakose",
      "Jordan Fernandes",
      "K V Vikram",
      "Mano Ranjith Kumar M",
      "Metilda Sagaya Mary",
      "Mohammad Wajahat",
      "Mohana N",
      "Mudit Batra",
      "Navina K",
      "Nihal John George",
      "Nithya Ravi",
      "Pruthwik Mishra",
      "Sudhanshu Srivastava",
      "Vasista Sai Lodagala",
      "Vandan Mujadia",
      "Kada Sai Venkata Vineeth",
      "Vrunda Sukhadia",
      "Dipti Sharma",
      "Hema Murthy",
      "Pushpak Bhattacharya",
      "S Umesh",
      "Rajeev Sangal"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.01338"
  },
  {
    "id": "arXiv:2211.01345",
    "title": "Generative machine learning methods for multivariate ensemble  post-processing",
    "abstract": "Ensemble weather forecasts based on multiple runs of numerical weather\nprediction models typically show systematic errors and require post-processing\nto obtain reliable forecasts. Accurately modeling multivariate dependencies is\ncrucial in many practical applications, and various approaches to multivariate\npost-processing have been proposed where ensemble predictions are first\npost-processed separately in each margin and multivariate dependencies are then\nrestored via copulas. These two-step methods share common key limitations, in\nparticular the difficulty to include additional predictors in modeling the\ndependencies. We propose a novel multivariate post-processing method based on\ngenerative machine learning to address these challenges. In this new class of\nnonparametric data-driven distributional regression models, samples from the\nmultivariate forecast distribution are directly obtained as output of a\ngenerative neural network. The generative model is trained by optimizing a\nproper scoring rule which measures the discrepancy between the generated and\nobserved data, conditional on exogenous input variables. Our method does not\nrequire parametric assumptions on univariate distributions or multivariate\ndependencies and allows for incorporating arbitrary predictors. In two case\nstudies on multivariate temperature and wind speed forecasting at weather\nstations over Germany, our generative model shows significant improvements over\nstate-of-the-art methods and particularly improves the representation of\nspatial dependencies.",
    "descriptor": "",
    "authors": [
      "Jieyu Chen",
      "Tim Janke",
      "Florian Steinke",
      "Sebastian Lerch"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.01345"
  },
  {
    "id": "arXiv:2211.01346",
    "title": "Predictive Crypto-Asset Automated Market Making Architecture for  Decentralized Finance using Deep Reinforcement Learning",
    "abstract": "The study proposes a quote-driven predictive automated market maker (AMM)\nplatform with on-chain custody and settlement functions, alongside off-chain\npredictive reinforcement learning capabilities to improve liquidity provision\nof real-world AMMs. The proposed AMM architecture is an augmentation to the\nUniswap V3, a cryptocurrency AMM protocol, by utilizing a novel market\nequilibrium pricing for reduced divergence and slippage loss. Further, the\nproposed architecture involves a predictive AMM capability, utilizing a deep\nhybrid Long Short-Term Memory (LSTM) and Q-learning reinforcement learning\nframework that looks to improve market efficiency through better forecasts of\nliquidity concentration ranges, so liquidity starts moving to expected\nconcentration ranges, prior to asset price movement, so that liquidity\nutilization is improved. The augmented protocol framework is expected have\npractical real-world implications, by (i) reducing divergence loss for\nliquidity providers, (ii) reducing slippage for crypto-asset traders, while\n(iii) improving capital efficiency for liquidity provision for the AMM\nprotocol. To our best knowledge, there are no known protocol or literature that\nare proposing similar deep learning-augmented AMM that achieves similar capital\nefficiency and loss minimization objectives for practical real-world\napplications.",
    "descriptor": "\nComments: 20 pages, 6 figures, 1 algorithm\n",
    "authors": [
      "Tristan Lim"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2211.01346"
  },
  {
    "id": "arXiv:2211.01353",
    "title": "Fourier Disentangled Multimodal Prior Knowledge Fusion for Red Nucleus  Segmentation in Brain MRI",
    "abstract": "Early and accurate diagnosis of parkinsonian syndromes is critical to provide\nappropriate care to patients and for inclusion in therapeutic trials. The red\nnucleus is a structure of the midbrain that plays an important role in these\ndisorders. It can be visualized using iron-sensitive magnetic resonance imaging\n(MRI) sequences. Different iron-sensitive contrasts can be produced with MRI.\nCombining such multimodal data has the potential to improve segmentation of the\nred nucleus. Current multimodal segmentation algorithms are computationally\nconsuming, cannot deal with missing modalities and need annotations for all\nmodalities. In this paper, we propose a new model that integrates prior\nknowledge from different contrasts for red nucleus segmentation. The method\nconsists of three main stages. First, it disentangles the image into high-level\ninformation representing the brain structure, and low-frequency information\nrepresenting the contrast. The high-frequency information is then fed into a\nnetwork to learn anatomical features, while the list of multimodal\nlow-frequency information is processed by another module. Finally, feature\nfusion is performed to complete the segmentation task. The proposed method was\nused with several iron-sensitive contrasts (iMag, QSM, R2*, SWI). Experiments\ndemonstrate that our proposed model substantially outperforms a baseline UNet\nmodel when the training set size is very small.",
    "descriptor": "",
    "authors": [
      "Guanghui Fu",
      "Gabriel Jimenez",
      "Sophie Loizillon",
      "Rosana El Jurdi",
      "Lydia Chougar",
      "Didier Dormont",
      "Romain Valabregue",
      "Ninon Burgos",
      "St\u00e9phane Leh\u00e9ricy",
      "Daniel Racoceanu",
      "Olivier Colliot",
      "ICEBERG Study Group"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01353"
  },
  {
    "id": "arXiv:2211.01357",
    "title": "Quasi-Newton Steps for Efficient Online Exp-Concave Optimization",
    "abstract": "The aim of this paper is to design computationally-efficient and optimal\nalgorithms for the online and stochastic exp-concave optimization settings.\nTypical algorithms for these settings, such as the Online Newton Step (ONS),\ncan guarantee a $O(d\\ln T)$ bound on their regret after $T$ rounds, where $d$\nis the dimension of the feasible set. However, such algorithms perform\nso-called generalized projections whenever their iterates step outside the\nfeasible set. Such generalized projections require $\\Omega(d^3)$ arithmetic\noperations even for simple sets such a Euclidean ball, making the total runtime\nof ONS of order $d^3 T$ after $T$ rounds, in the worst-case. In this paper, we\nside-step generalized projections by using a self-concordant barrier as a\nregularizer to compute the Newton steps. This ensures that the iterates are\nalways within the feasible set without requiring projections. This approach\nstill requires the computation of the inverse of the Hessian of the barrier at\nevery step. However, using the stability properties of the Newton steps, we\nshow that the inverse of the Hessians can be efficiently approximated via\nTaylor expansions for most rounds, resulting in a $O(d^2 T +d^\\omega \\sqrt{T})$\ntotal computational complexity, where $\\omega$ is the exponent of matrix\nmultiplication. In the stochastic setting, we show that this translates into a\n$O(d^3/\\epsilon)$ computational complexity for finding an $\\epsilon$-suboptimal\npoint, answering an open question by Koren 2013. We first show these new\nresults for the simple case where the feasible set is a Euclidean ball. Then,\nto move to general convex set, we use a reduction to Online Convex Optimization\nover the Euclidean ball. Our final algorithm can be viewed as a more efficient\nversion of ONS.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Zakaria Mhammedi",
      "Khashayar Gatmiry"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01357"
  },
  {
    "id": "arXiv:2211.01365",
    "title": "Koopman Operator learning for Accelerating Quantum Optimization and  Machine Learning",
    "abstract": "Finding efficient optimization methods plays an important role for quantum\noptimization and quantum machine learning on near-term quantum computers. While\nbackpropagation on classical computers is computationally efficient, obtaining\ngradients on quantum computers is not, because the computational complexity\nusually scales with the number of parameters and measurements. In this paper,\nwe connect Koopman operator theory, which has been successful in predicting\nnonlinear dynamics, with natural gradient methods in quantum optimization. We\npropose a data-driven approach using Koopman operator learning to accelerate\nquantum optimization and quantum machine learning. We develop two new families\nof methods: the sliding window dynamic mode decomposition (DMD) and the neural\nDMD for efficiently updating parameters on quantum computers. We show that our\nmethods can predict gradient dynamics on quantum computers and accelerate the\nvariational quantum eigensolver used in quantum optimization, as well as\nquantum machine learning. We further implement our Koopman operator learning\nalgorithm on a real IBM quantum computer and demonstrate their practical\neffectiveness.",
    "descriptor": "",
    "authors": [
      "Di Luo",
      "Jiayu Shen",
      "Rumen Dangovski",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.01365"
  },
  {
    "id": "arXiv:1612.00276",
    "title": "Ebert's asymmetric Hat Game",
    "abstract": "Comments: 33 pages",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Theo van Uem"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1612.00276"
  },
  {
    "id": "arXiv:1705.00211",
    "title": "Two Algorithms for Deciding Coincidence In Double Temporal Recurrence of  Eventuality Sequences",
    "abstract": "Two Algorithms for Deciding Coincidence In Double Temporal Recurrence of  Eventuality Sequences",
    "descriptor": "",
    "authors": [
      "Babatunde Opeoluwa Akinkunmi",
      "Adesoji A. Adegbola"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1705.00211"
  },
  {
    "id": "arXiv:2002.01924",
    "title": "Explicit Wiretap Channel Codes via Source Coding, Universal Hashing, and  Distribution Approximation, When the Channels' Statistics are Uncertain",
    "abstract": "Comments: 16 pages, two-column, 3 figures, accepted to IEEE Transactions on Information Forensics and Security",
    "descriptor": "\nComments: 16 pages, two-column, 3 figures, accepted to IEEE Transactions on Information Forensics and Security\n",
    "authors": [
      "Remi A. Chou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2002.01924"
  },
  {
    "id": "arXiv:2008.10547",
    "title": "Approximate Cross-Validation with Low-Rank Data in High Dimensions",
    "abstract": "Comments: Published in NeurIPS 2020",
    "descriptor": "\nComments: Published in NeurIPS 2020\n",
    "authors": [
      "William T. Stephenson",
      "Madeleine Udell",
      "Tamara Broderick"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2008.10547"
  },
  {
    "id": "arXiv:2009.09756",
    "title": "Demand Prediction Using Machine Learning Methods and Stacked  Generalization",
    "abstract": "Comments: Proceedings of the 6th International Conference on Data Science, Technology and Applications",
    "descriptor": "\nComments: Proceedings of the 6th International Conference on Data Science, Technology and Applications\n",
    "authors": [
      "Resul Tugay",
      "Sule Gunduz Oguducu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.09756"
  },
  {
    "id": "arXiv:2010.09694",
    "title": "Data Assimilation Networks",
    "abstract": "Data Assimilation Networks",
    "descriptor": "",
    "authors": [
      "Pierre Boudier",
      "Anthony Fillion",
      "Serge Gratton",
      "Selime G\u00fcrol",
      "Sixin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.09694"
  },
  {
    "id": "arXiv:2011.03396",
    "title": "The Bayes Security Measure",
    "abstract": "The Bayes Security Measure",
    "descriptor": "",
    "authors": [
      "Konstantinos Chatzikokolakis",
      "Giovanni Cherubin",
      "Catuscia Palamidessi",
      "Carmela Troncoso"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2011.03396"
  },
  {
    "id": "arXiv:2011.12771",
    "title": "Learning to Expand: Reinforced Pseudo-relevance Feedback Selection for  Information-seeking Conversations",
    "abstract": "Learning to Expand: Reinforced Pseudo-relevance Feedback Selection for  Information-seeking Conversations",
    "descriptor": "",
    "authors": [
      "Haojie Pan",
      "Cen Chen",
      "Chengyu Wang",
      "Minghui Qiu",
      "Liu Yang",
      "Feng Ji",
      "Jun Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2011.12771"
  },
  {
    "id": "arXiv:2012.01266",
    "title": "Meta-KD: A Meta Knowledge Distillation Framework for Language Model  Compression across Domains",
    "abstract": "Meta-KD: A Meta Knowledge Distillation Framework for Language Model  Compression across Domains",
    "descriptor": "",
    "authors": [
      "Haojie Pan",
      "Chengyu Wang",
      "Minghui Qiu",
      "Yichang Zhang",
      "Yaliang Li",
      "Jun Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.01266"
  },
  {
    "id": "arXiv:2012.04087",
    "title": "Invertibility Conditions for the Admittance Matrices of Balanced Power  Systems",
    "abstract": "Comments: 12 pages, 4 figures, 1 table, published in IEEE Transactions on Power Systems",
    "descriptor": "\nComments: 12 pages, 4 figures, 1 table, published in IEEE Transactions on Power Systems\n",
    "authors": [
      "Daniel Turizo",
      "Daniel K. Molzahn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.04087"
  },
  {
    "id": "arXiv:2101.10723",
    "title": "No-harm principle, rationality, and Pareto optimality in games",
    "abstract": "No-harm principle, rationality, and Pareto optimality in games",
    "descriptor": "",
    "authors": [
      "Shaun Hargreaves Heap",
      "Mehmet S. Ismail"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2101.10723"
  },
  {
    "id": "arXiv:2103.08109",
    "title": "Boundary Proposal Network for Two-Stage Natural Language Video  Localization",
    "abstract": "Comments: AAAI 2021",
    "descriptor": "\nComments: AAAI 2021\n",
    "authors": [
      "Shaoning Xiao",
      "Long Chen",
      "Songyang Zhang",
      "Wei Ji",
      "Jian Shao",
      "Lu Ye",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.08109"
  },
  {
    "id": "arXiv:2104.01392",
    "title": "Place Bisimilarity is Decidable, Indeed!",
    "abstract": "Place Bisimilarity is Decidable, Indeed!",
    "descriptor": "",
    "authors": [
      "Roberto Gorrieri"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.01392"
  },
  {
    "id": "arXiv:2104.06176",
    "title": "COVID-19 detection using chest X-rays: is lung segmentation important  for generalization?",
    "abstract": "Comments: Text and figure improvements. Results did not change. Included DOI and reference to the published article (Research on Biomedical Engineering, Springer). Link for the published paper: this https URL",
    "descriptor": "\nComments: Text and figure improvements. Results did not change. Included DOI and reference to the published article (Research on Biomedical Engineering, Springer). Link for the published paper: this https URL\n",
    "authors": [
      "Pedro R. A. S. Bassi",
      "Romis Attux"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.06176"
  },
  {
    "id": "arXiv:2104.14859",
    "title": "A Decidable Equivalence for a Turing-complete, Distributed Model of  Computation",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2104.01392",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.01392\n",
    "authors": [
      "Arnaldo Cesco",
      "Roberto Gorrieri"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.14859"
  },
  {
    "id": "arXiv:2106.10238",
    "title": "Nonparametric Hamiltonian Monte Carlo",
    "abstract": "Comments: Updated plots (after fixing minor bugs in the implementation) compared to the published version in Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. The conclusions of the version published at ICML 2021 are not affected",
    "descriptor": "\nComments: Updated plots (after fixing minor bugs in the implementation) compared to the published version in Proceedings of the 38th International Conference on Machine Learning, PMLR 139, 2021. The conclusions of the version published at ICML 2021 are not affected\n",
    "authors": [
      "Carol Mak",
      "Fabian Zaiser",
      "Luke Ong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10238"
  },
  {
    "id": "arXiv:2107.01776",
    "title": "Continual Contrastive Learning for Image Classification",
    "abstract": "Comments: Accepted in ICME2022",
    "descriptor": "\nComments: Accepted in ICME2022\n",
    "authors": [
      "Zhiwei Lin",
      "Yongtao Wang",
      "Hongxiang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.01776"
  },
  {
    "id": "arXiv:2107.09194",
    "title": "Can we globally optimize cross-validation loss? Quasiconvexity in ridge  regression",
    "abstract": "Comments: Published in NeurIPS 2021",
    "descriptor": "\nComments: Published in NeurIPS 2021\n",
    "authors": [
      "William T. Stephenson",
      "Zachary Frangella",
      "Madeleine Udell",
      "Tamara Broderick"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.09194"
  },
  {
    "id": "arXiv:2108.07014",
    "title": "Robust Beamforming Design for Rate Splitting Multiple Access-Aided MISO  Visible Light Communications",
    "abstract": "Robust Beamforming Design for Rate Splitting Multiple Access-Aided MISO  Visible Light Communications",
    "descriptor": "",
    "authors": [
      "Shuai Ma",
      "Guanjie Zhang",
      "Zhi Zhang",
      "Rongyan Gu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.07014"
  },
  {
    "id": "arXiv:2109.06308",
    "title": "Improving Scheduled Sampling with Elastic Weight Consolidation for  Neural Machine Translation",
    "abstract": "Improving Scheduled Sampling with Elastic Weight Consolidation for  Neural Machine Translation",
    "descriptor": "",
    "authors": [
      "Michalis Korakakis",
      "Andreas Vlachos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06308"
  },
  {
    "id": "arXiv:2109.07983",
    "title": "Let the CAT out of the bag: Contrastive Attributed explanations for Text",
    "abstract": "Let the CAT out of the bag: Contrastive Attributed explanations for Text",
    "descriptor": "",
    "authors": [
      "Saneem Chemmengath",
      "Amar Prakash Azad",
      "Ronny Luss",
      "Amit Dhurandhar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07983"
  },
  {
    "id": "arXiv:2110.00077",
    "title": "Discrete-Value Group and Fully Connected Architectures for Beyond  Diagonal Reconfigurable Intelligent Surfaces",
    "abstract": "Comments: Submitted to IEEE for publication",
    "descriptor": "\nComments: Submitted to IEEE for publication\n",
    "authors": [
      "Matteo Nerini",
      "Shanpu Shen",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.00077"
  },
  {
    "id": "arXiv:2110.04629",
    "title": "The Neural Testbed: Evaluating Joint Predictions",
    "abstract": "The Neural Testbed: Evaluating Joint Predictions",
    "descriptor": "",
    "authors": [
      "Ian Osband",
      "Zheng Wen",
      "Seyed Mohammad Asghari",
      "Vikranth Dwaracherla",
      "Botao Hao",
      "Morteza Ibrahimi",
      "Dieterich Lawson",
      "Xiuyuan Lu",
      "Brendan O'Donoghue",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04629"
  },
  {
    "id": "arXiv:2110.04795",
    "title": "Isogeny-based Group Signatures and Accountable Ring Signatures in QROM",
    "abstract": "Isogeny-based Group Signatures and Accountable Ring Signatures in QROM",
    "descriptor": "",
    "authors": [
      "Kai-Min Chung",
      "Yao-Ching Hsieh",
      "Mi-Ying Huang",
      "Yu-Hsuan Huang",
      "Tanja Lange",
      "Bo-Yin Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.04795"
  },
  {
    "id": "arXiv:2110.12674",
    "title": "mlr3spatiotempcv: Spatiotemporal resampling methods for machine learning  in R",
    "abstract": "Comments: 35 pages, 15 Figures, 1 Table",
    "descriptor": "\nComments: 35 pages, 15 Figures, 1 Table\n",
    "authors": [
      "Patrick Schratz",
      "Marc Becker",
      "Michel Lang",
      "Alexander Brenning"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.12674"
  },
  {
    "id": "arXiv:2110.15221",
    "title": "rustworkx: A High-Performance Graph Library for Python",
    "abstract": "rustworkx: A High-Performance Graph Library for Python",
    "descriptor": "",
    "authors": [
      "Matthew Treinish",
      "Ivan Carvalho",
      "Georgios Tsilimigkounakis",
      "Nahum S\u00e1"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.15221"
  },
  {
    "id": "arXiv:2111.00088",
    "title": "Stitching Dynamic Movement Primitives and Image-based Visual Servo  Control",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ghananeel Rotithor",
      "Iman Salehi",
      "Edward Tunstel",
      "Ashwin P. Dani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00088"
  },
  {
    "id": "arXiv:2111.02276",
    "title": "Origami-inspired soft twisting actuator",
    "abstract": "Comments: 9 figures. Soft Robotics (2022)",
    "descriptor": "\nComments: 9 figures. Soft Robotics (2022)\n",
    "authors": [
      "Diancheng Li",
      "Dongliang Fan",
      "Renjie Zhu",
      "Qiaozhi Lei",
      "Yuxuan Liao",
      "Xin Yang",
      "Yang Pan",
      "Zheng Wang",
      "Yang Wu",
      "Sicong Liu",
      "Hongqiang Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02276"
  },
  {
    "id": "arXiv:2111.02673",
    "title": "Recurrent Neural Network Training with Convex Loss and Regularization  Functions by Extended Kalman Filtering",
    "abstract": "Comments: 21 pages, 3 figures, submitted for publication",
    "descriptor": "\nComments: 21 pages, 3 figures, submitted for publication\n",
    "authors": [
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.02673"
  },
  {
    "id": "arXiv:2111.06211",
    "title": "Model-Based Reinforcement Learning for Stochastic Hybrid Systems",
    "abstract": "Model-Based Reinforcement Learning for Stochastic Hybrid Systems",
    "descriptor": "",
    "authors": [
      "Hany Abdulsamad",
      "Jan Peters"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.06211"
  },
  {
    "id": "arXiv:2111.08945",
    "title": "On the coalition number of trees",
    "abstract": "On the coalition number of trees",
    "descriptor": "",
    "authors": [
      "Davood Bakhshesh",
      "Michael A. Henning",
      "Dinabandhu Pradhan"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.08945"
  },
  {
    "id": "arXiv:2111.09902",
    "title": "A transformer-based model for default prediction in mid-cap corporate  markets",
    "abstract": "Comments: to be published in the European Journal of Operational Research",
    "descriptor": "\nComments: to be published in the European Journal of Operational Research\n",
    "authors": [
      "Kamesh Korangi",
      "Christophe Mues",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09902"
  },
  {
    "id": "arXiv:2112.10552",
    "title": "Relational hyperevent models for polyadic interaction networks",
    "abstract": "Relational hyperevent models for polyadic interaction networks",
    "descriptor": "",
    "authors": [
      "J\u00fcrgen Lerner",
      "Alessandro Lomi"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.10552"
  },
  {
    "id": "arXiv:2112.10961",
    "title": "Nonlinear Transform Source-Channel Coding for Semantic Communications",
    "abstract": "Comments: published in IEEE JSAC",
    "descriptor": "\nComments: published in IEEE JSAC\n",
    "authors": [
      "Jincheng Dai",
      "Sixian Wang",
      "Kailin Tan",
      "Zhongwei Si",
      "Xiaoqi Qin",
      "Kai Niu",
      "Ping Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.10961"
  },
  {
    "id": "arXiv:2201.00570",
    "title": "3DPG: Distributed Deep Deterministic Policy Gradient Algorithms for  Networked Multi-Agent Systems",
    "abstract": "3DPG: Distributed Deep Deterministic Policy Gradient Algorithms for  Networked Multi-Agent Systems",
    "descriptor": "",
    "authors": [
      "Adrian Redder",
      "Arunselvan Ramaswamy",
      "Holger Karl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.00570"
  },
  {
    "id": "arXiv:2201.01134",
    "title": "Network Collaborator: Knowledge Transfer Between Network Reconstruction  and Community Detection",
    "abstract": "Comments: This work has been submitted to the IEEE Transactions on Emerging Topics in Computational Intelligence for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE Transactions on Emerging Topics in Computational Intelligence for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kai Wu",
      "Chao Wang",
      "Junyuan Chen",
      "Jing Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.01134"
  },
  {
    "id": "arXiv:2201.06487",
    "title": "Minimax risk classifiers with 0-1 loss",
    "abstract": "Minimax risk classifiers with 0-1 loss",
    "descriptor": "",
    "authors": [
      "Santiago Mazuelas",
      "Mauricio Romero",
      "Peter Gr\u00fcnwald"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06487"
  },
  {
    "id": "arXiv:2201.07083",
    "title": "A Short Tutorial on The Weisfeiler-Lehman Test And Its Variants",
    "abstract": "A Short Tutorial on The Weisfeiler-Lehman Test And Its Variants",
    "descriptor": "",
    "authors": [
      "Ningyuan Huang",
      "Soledad Villar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07083"
  },
  {
    "id": "arXiv:2201.11627",
    "title": "Internal Language Model Estimation Through Explicit Context Vector  Learning for Attention-based Encoder-decoder ASR",
    "abstract": "Comments: Proceedings of INTERSPEECH",
    "descriptor": "\nComments: Proceedings of INTERSPEECH\n",
    "authors": [
      "Yufei Liu",
      "Rao Ma",
      "Haihua Xu",
      "Yi He",
      "Zejun Ma",
      "Weibin Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2201.11627"
  },
  {
    "id": "arXiv:2201.12947",
    "title": "Fair Wrapping for Black-box Predictions",
    "abstract": "Comments: Published in Advances in Neural Information Processing Systems 35 (NeurIPS 2022)",
    "descriptor": "\nComments: Published in Advances in Neural Information Processing Systems 35 (NeurIPS 2022)\n",
    "authors": [
      "Alexander Soen",
      "Ibrahim Alabdulmohsin",
      "Sanmi Koyejo",
      "Yishay Mansour",
      "Nyalleng Moorosi",
      "Richard Nock",
      "Ke Sun",
      "Lexing Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12947"
  },
  {
    "id": "arXiv:2202.01354",
    "title": "Dissecting BFT Consensus: In Trusted Components we Trust!",
    "abstract": "Dissecting BFT Consensus: In Trusted Components we Trust!",
    "descriptor": "",
    "authors": [
      "Suyash Gupta",
      "Sajjad Rahnama",
      "Shubham Pandey",
      "Natacha Crooks",
      "Mohammad Sadoghi"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01354"
  },
  {
    "id": "arXiv:2202.04816",
    "title": "Scale Estimation with Dual Quadrics for Monocular Object SLAM",
    "abstract": "Comments: 8 pages, 6 figures, accepted by IROS2022",
    "descriptor": "\nComments: 8 pages, 6 figures, accepted by IROS2022\n",
    "authors": [
      "Shuangfu Song",
      "Junqiao Zhao",
      "Tiantian Feng",
      "Chen Ye",
      "Lu Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04816"
  },
  {
    "id": "arXiv:2202.10471",
    "title": "Classical versus Quantum: comparing Tensor Network-based Quantum  Circuits on LHC data",
    "abstract": "Comments: 18 pages, 15 figures, 1 table. Accepted version for publication in PRA",
    "descriptor": "\nComments: 18 pages, 15 figures, 1 table. Accepted version for publication in PRA\n",
    "authors": [
      "Jack Y. Araz",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.10471"
  },
  {
    "id": "arXiv:2202.12059",
    "title": "AFFDEX 2.0: A Real-Time Facial Expression Analysis Toolkit",
    "abstract": "Comments: Accepted at the FG2023 conference",
    "descriptor": "\nComments: Accepted at the FG2023 conference\n",
    "authors": [
      "Mina Bishay",
      "Kenneth Preston",
      "Matthew Strafuss",
      "Graham Page",
      "Jay Turcot",
      "Mohammad Mavadati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12059"
  },
  {
    "id": "arXiv:2202.12498",
    "title": "Diffeomorphic Image Registration with Neural Velocity Field",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Kun Han",
      "Shanlin sun",
      "Xiangyi Yan",
      "Chenyu You",
      "Hao Tang",
      "Junayed Naushad",
      "Haoyu Ma",
      "Deying Kong",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12498"
  },
  {
    "id": "arXiv:2202.12993",
    "title": "Projective Ranking-based GNN Evasion Attacks",
    "abstract": "Comments: Accepted by IEEE Transactions on Knowledge and Data Engineering",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Knowledge and Data Engineering\n",
    "authors": [
      "He Zhang",
      "Xingliang Yuan",
      "Chuan Zhou",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.12993"
  },
  {
    "id": "arXiv:2203.00281",
    "title": "Fast-R2D2: A Pretrained Recursive Neural Network based on Pruned CKY for  Grammar Induction and Text Representation",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Xiang Hu",
      "Haitao Mi",
      "Liang Li",
      "Gerard de Melo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.00281"
  },
  {
    "id": "arXiv:2203.01225",
    "title": "Video Question Answering: Datasets, Algorithms and Challenges",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Yaoyao Zhong",
      "Junbin Xiao",
      "Wei Ji",
      "Yicong Li",
      "Weihong Deng",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01225"
  },
  {
    "id": "arXiv:2203.01978",
    "title": "Region-of-Interest Based Neural Video Compression",
    "abstract": "Comments: Updated arxiv version to the camera-ready version after acceptance at British Machine Vision Conference (BMVC) 2022",
    "descriptor": "\nComments: Updated arxiv version to the camera-ready version after acceptance at British Machine Vision Conference (BMVC) 2022\n",
    "authors": [
      "Yura Perugachi-Diaz",
      "Guillaume Sauti\u00e8re",
      "Davide Abati",
      "Yang Yang",
      "Amirhossein Habibian",
      "Taco S Cohen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01978"
  },
  {
    "id": "arXiv:2203.02861",
    "title": "Optimally Scheduling Public Safety Power Shutoffs",
    "abstract": "Optimally Scheduling Public Safety Power Shutoffs",
    "descriptor": "",
    "authors": [
      "Antoine Lesage-Landry",
      "F\u00e9lix Pellerin",
      "Joshua A. Taylor",
      "Duncan S. Callaway"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.02861"
  },
  {
    "id": "arXiv:2203.03342",
    "title": "High-Resolution Peak Demand Estimation Using Generalized Additive Models  and Deep Neural Networks",
    "abstract": "High-Resolution Peak Demand Estimation Using Generalized Additive Models  and Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Jonathan Berrisch",
      "Micha\u0142 Narajewski",
      "Florian Ziel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.03342"
  },
  {
    "id": "arXiv:2203.04774",
    "title": "Tailored vertex ordering for faster triangle listing in large graphs",
    "abstract": "Comments: 11 pages, 4 figures. Open-source C++ code available at: this https URL",
    "descriptor": "\nComments: 11 pages, 4 figures. Open-source C++ code available at: this https URL\n",
    "authors": [
      "Fabrice L\u00e9cuyer",
      "Louis Jachiet",
      "Cl\u00e9mence Magnien",
      "Lionel Tabourier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.04774"
  },
  {
    "id": "arXiv:2203.07852",
    "title": "Block-Recurrent Transformers",
    "abstract": "Comments: Update to NeurIPS camera-ready version",
    "descriptor": "\nComments: Update to NeurIPS camera-ready version\n",
    "authors": [
      "DeLesley Hutchins",
      "Imanol Schlag",
      "Yuhuai Wu",
      "Ethan Dyer",
      "Behnam Neyshabur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.07852"
  },
  {
    "id": "arXiv:2203.08445",
    "title": "Structurally Diverse Sampling for Sample-Efficient Training and  Comprehensive Evaluation",
    "abstract": "Comments: Accepted at Findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted at Findings of EMNLP 2022\n",
    "authors": [
      "Shivanshu Gupta",
      "Sameer Singh",
      "Matt Gardner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08445"
  },
  {
    "id": "arXiv:2203.16965",
    "title": "PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech  Representations",
    "abstract": "Comments: IEEE SLT 2022",
    "descriptor": "\nComments: IEEE SLT 2022\n",
    "authors": [
      "Lodagala V S V Durga Prasad",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16965"
  },
  {
    "id": "arXiv:2203.17159",
    "title": "Preventing Over-Smoothing for Hypergraph Neural Networks",
    "abstract": "Preventing Over-Smoothing for Hypergraph Neural Networks",
    "descriptor": "",
    "authors": [
      "Guanzi Chen",
      "Jiying Zhang",
      "Xi Xiao",
      "Yang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17159"
  },
  {
    "id": "arXiv:2204.02550",
    "title": "Continuous LWE is as Hard as LWE & Applications to Learning Gaussian  Mixtures",
    "abstract": "Comments: Fixed bugs in Lemma 9 and Section 6",
    "descriptor": "\nComments: Fixed bugs in Lemma 9 and Section 6\n",
    "authors": [
      "Aparna Gupte",
      "Neekon Vafa",
      "Vinod Vaikuntanathan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02550"
  },
  {
    "id": "arXiv:2204.03297",
    "title": "A Multi-Transformation Evolutionary Framework for Influence Maximization  in Social Networks",
    "abstract": "Comments: This work has been submitted to the IEEE Computational Intelligence Magazine for publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE Computational Intelligence Magazine for publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Chao Wang",
      "Jiaxuan Zhao",
      "Lingling Li",
      "Licheng Jiao",
      "Jing Liu",
      "Kai Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.03297"
  },
  {
    "id": "arXiv:2204.03656",
    "title": "Automatic Parameter Optimization Using Genetic Algorithm in Deep  Reinforcement Learning for Robotic Manipulation Tasks",
    "abstract": "Comments: I want to replace previous submission by this new submission with same title",
    "descriptor": "\nComments: I want to replace previous submission by this new submission with same title\n",
    "authors": [
      "Adarsh Sehgal",
      "Nicholas Ward",
      "Hung La",
      "Sushil Louis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03656"
  },
  {
    "id": "arXiv:2204.03895",
    "title": "SoundBeam: Target sound extraction conditioned on sound-class labels and  enrollment clues for increased performance and continuous learning",
    "abstract": "Comments: Submitted to IEEE/ACM Trans. Audio, Speech, and Language Processing on Feb. 10th, 2022, and accepted on Oct. 20, 2022",
    "descriptor": "\nComments: Submitted to IEEE/ACM Trans. Audio, Speech, and Language Processing on Feb. 10th, 2022, and accepted on Oct. 20, 2022\n",
    "authors": [
      "Marc Delcroix",
      "Jorge Bennasar V\u00e1zquez",
      "Tsubasa Ochiai",
      "Keisuke Kinoshita",
      "Yasunori Ohishi",
      "Shoko Araki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.03895"
  },
  {
    "id": "arXiv:2204.05486",
    "title": "Neural Graph Matching for Modification Similarity Applied to Electronic  Document Comparison",
    "abstract": "Neural Graph Matching for Modification Similarity Applied to Electronic  Document Comparison",
    "descriptor": "",
    "authors": [
      "Po-Fang Hsu",
      "Chiching Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05486"
  },
  {
    "id": "arXiv:2204.05628",
    "title": "Linearly ordered colourings of hypergraphs",
    "abstract": "Comments: Full version (with stronger both tractability and intractability results) of an ICALP 2022 paper",
    "descriptor": "\nComments: Full version (with stronger both tractability and intractability results) of an ICALP 2022 paper\n",
    "authors": [
      "Tamio-Vesa Nakajima",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2204.05628"
  },
  {
    "id": "arXiv:2204.06543",
    "title": "Sharing the Load: Considering Fairness in De-energization Scheduling to  Mitigate Wildfire Ignition Risk using Rolling Optimization",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Alyssa Kody",
      "Amanda West",
      "Daniel K. Molzahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.06543"
  },
  {
    "id": "arXiv:2204.11544",
    "title": "Rethinking Multi-Modal Alignment in Video Question Answering from  Feature and Sample Perspectives",
    "abstract": "Rethinking Multi-Modal Alignment in Video Question Answering from  Feature and Sample Perspectives",
    "descriptor": "",
    "authors": [
      "Shaoning Xiao",
      "Long Chen",
      "Kaifeng Gao",
      "Zhao Wang",
      "Yi Yang",
      "Zhimeng Zhang",
      "Jun Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.11544"
  },
  {
    "id": "arXiv:2204.11641",
    "title": "Cryptography Is Not Enough: Relay Attacks on Authenticated GNSS Signals",
    "abstract": "Cryptography Is Not Enough: Relay Attacks on Authenticated GNSS Signals",
    "descriptor": "",
    "authors": [
      "Maryam Motallebighomi",
      "Harshad Sathaye",
      "Mridula Singh",
      "Aanjhan Ranganathan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.11641"
  },
  {
    "id": "arXiv:2204.12663",
    "title": "Understanding A Class of Decentralized and Federated Optimization  Algorithms: A Multi-Rate Feedback Control Perspective",
    "abstract": "Understanding A Class of Decentralized and Federated Optimization  Algorithms: A Multi-Rate Feedback Control Perspective",
    "descriptor": "",
    "authors": [
      "Xinwei Zhang",
      "Mingyi Hong",
      "Nicola Elia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.12663"
  },
  {
    "id": "arXiv:2204.12993",
    "title": "Counterfactual harm",
    "abstract": "Comments: Accepted at NeurIPS 2022. Included appendix comparing to Beckers et. al. arXiv:2210.05327. Typos corrected",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. Included appendix comparing to Beckers et. al. arXiv:2210.05327. Typos corrected\n",
    "authors": [
      "Jonathan G. Richens",
      "Rory Beard",
      "Daniel H. Thompson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.12993"
  },
  {
    "id": "arXiv:2204.13361",
    "title": "It's DONE: Direct ONE-shot learning with quantile weight imprinting",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Kazufumi Hosoda",
      "Keigo Nishida",
      "Shigeto Seno",
      "Tomohiro Mashita",
      "Hideki Kashioka",
      "Izumi Ohzawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.13361"
  },
  {
    "id": "arXiv:2204.13825",
    "title": "A node-based uniform strain virtual element method for compressible and  nearly incompressible elasticity",
    "abstract": "A node-based uniform strain virtual element method for compressible and  nearly incompressible elasticity",
    "descriptor": "",
    "authors": [
      "A. Ortiz-Bernardin",
      "R. Silva-Valenzuela",
      "S. Salinas-Fern\u00e1ndez",
      "N. Hitschfeld-Kahler",
      "S. Luza",
      "B. Rebolledo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.13825"
  },
  {
    "id": "arXiv:2205.03931",
    "title": "Write It Like You See It: Detectable Differences in Clinical Notes By  Race Lead To Differential Model Recommendations",
    "abstract": "Write It Like You See It: Detectable Differences in Clinical Notes By  Race Lead To Differential Model Recommendations",
    "descriptor": "",
    "authors": [
      "Hammaad Adam",
      "Ming Ying Yang",
      "Kenrick Cato",
      "Ioana Baldini",
      "Charles Senteio",
      "Leo Anthony Celi",
      "Jiaming Zeng",
      "Moninder Singh",
      "Marzyeh Ghassemi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.03931"
  },
  {
    "id": "arXiv:2205.03981",
    "title": "A construction of a $\u03bb$- Poisson generic sequence",
    "abstract": "Comments: 14 pages. Accepted in Mathematics of Computation",
    "descriptor": "\nComments: 14 pages. Accepted in Mathematics of Computation\n",
    "authors": [
      "Ver\u00f3nica Becher",
      "Gabriel Sac Himelfarb"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.03981"
  },
  {
    "id": "arXiv:2205.10012",
    "title": "Descartes: Generating Short Descriptions of Wikipedia Articles",
    "abstract": "Descartes: Generating Short Descriptions of Wikipedia Articles",
    "descriptor": "",
    "authors": [
      "Marija Sakota",
      "Maxime Peyrard",
      "Robert West"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10012"
  },
  {
    "id": "arXiv:2205.10129",
    "title": "Topology-aware Graph Neural Networks for Learning Feasible and Adaptive  ac-OPF Solutions",
    "abstract": "Topology-aware Graph Neural Networks for Learning Feasible and Adaptive  ac-OPF Solutions",
    "descriptor": "",
    "authors": [
      "Shaohui Liu",
      "Chengyang Wu",
      "Hao Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.10129"
  },
  {
    "id": "arXiv:2205.11052",
    "title": "Scaling and performance portability of the particle-in-cell scheme for  plasma physics applications through mini-apps targeting exascale  architectures",
    "abstract": "Scaling and performance portability of the particle-in-cell scheme for  plasma physics applications through mini-apps targeting exascale  architectures",
    "descriptor": "",
    "authors": [
      "Sriramkrishnan Muralikrishnan",
      "Matthias Frey",
      "Alessandro Vinciguerra",
      "Michael Ligotino",
      "Antoine J. Cerfon",
      "Miroslav Stoyanov",
      "Rahulkumar Gayatri",
      "Andreas Adelmann"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.11052"
  },
  {
    "id": "arXiv:2205.13129",
    "title": "Wireless Deep Video Semantic Transmission",
    "abstract": "Comments: published in IEEE JSAC",
    "descriptor": "\nComments: published in IEEE JSAC\n",
    "authors": [
      "Sixian Wang",
      "Jincheng Dai",
      "Zijian Liang",
      "Kai Niu",
      "Zhongwei Si",
      "Chao Dong",
      "Xiaoqi Qin",
      "Ping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.13129"
  },
  {
    "id": "arXiv:2205.13790",
    "title": "BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework",
    "abstract": "Comments: NerIPS 2022 camera ready",
    "descriptor": "\nComments: NerIPS 2022 camera ready\n",
    "authors": [
      "Tingting Liang",
      "Hongwei Xie",
      "Kaicheng Yu",
      "Zhongyu Xia",
      "Zhiwei Lin",
      "Yongtao Wang",
      "Tao Tang",
      "Bing Wang",
      "Zhi Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13790"
  },
  {
    "id": "arXiv:2205.13792",
    "title": "kNN-Prompt: Nearest Neighbor Zero-Shot Inference",
    "abstract": "kNN-Prompt: Nearest Neighbor Zero-Shot Inference",
    "descriptor": "",
    "authors": [
      "Weijia Shi",
      "Julian Michael",
      "Suchin Gururangan",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.13792"
  },
  {
    "id": "arXiv:2206.00006",
    "title": "COIN: Co-Cluster Infomax for Bipartite Graphs",
    "abstract": "Comments: NeurIPS 2022 GLFrontiers Workshop",
    "descriptor": "\nComments: NeurIPS 2022 GLFrontiers Workshop\n",
    "authors": [
      "Baoyu Jing",
      "Yuchen Yan",
      "Yada Zhu",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00006"
  },
  {
    "id": "arXiv:2206.00050",
    "title": "FiLM-Ensemble: Probabilistic Deep Learning via Feature-wise Linear  Modulation",
    "abstract": "Comments: accepted at NeurIPS 2022",
    "descriptor": "\nComments: accepted at NeurIPS 2022\n",
    "authors": [
      "Mehmet Ozgur Turkoglu",
      "Alexander Becker",
      "H\u00fcseyin Anil G\u00fcnd\u00fcz",
      "Mina Rezaei",
      "Bernd Bischl",
      "Rodrigo Caye Daudt",
      "Stefano D'Aronco",
      "Jan Dirk Wegner",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.00050"
  },
  {
    "id": "arXiv:2206.00208",
    "title": "AdaVITS: Tiny VITS for Low Computing Resource Speaker Adaptation",
    "abstract": "Comments: Accepted by ISCSLP 2022",
    "descriptor": "\nComments: Accepted by ISCSLP 2022\n",
    "authors": [
      "Kun Song",
      "Heyang Xue",
      "Xinsheng Wang",
      "Jian Cong",
      "Yongmao Zhang",
      "Lei Xie",
      "Bing Yang",
      "Xiong Zhang",
      "Dan Su"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.00208"
  },
  {
    "id": "arXiv:2206.00373",
    "title": "A Flexible and Robust Vision Trap for Automated Part Feeder Design",
    "abstract": "Comments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)",
    "descriptor": "\nComments: IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Rasmus Laurvig Haugaard",
      "Thorbj\u00f8rn Mosekj\u00e6r Iversen",
      "Anders Glent Buch",
      "Aljaz Kramberger",
      "Simon Faarvang Mathiesen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.00373"
  },
  {
    "id": "arXiv:2206.01163",
    "title": "Invertible Neural Networks for Graph Prediction",
    "abstract": "Invertible Neural Networks for Graph Prediction",
    "descriptor": "",
    "authors": [
      "Chen Xu",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01163"
  },
  {
    "id": "arXiv:2206.01178",
    "title": "Approximate Discretization Invariance for Deep Learning on Neural Fields",
    "abstract": "Comments: Presented at NeurIPS 2022 Symmetry and Geometry in Neural Representations (NeurReps) Workshop",
    "descriptor": "\nComments: Presented at NeurIPS 2022 Symmetry and Geometry in Neural Representations (NeurReps) Workshop\n",
    "authors": [
      "Clinton J. Wang",
      "Polina Golland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.01178"
  },
  {
    "id": "arXiv:2206.02660",
    "title": "Port-Hamiltonian Neural Networks with State-Dependent Ports",
    "abstract": "Comments: 21 pages, 12 figures; v3: restructured the paper for more clarity, major changes to the text, updated plots",
    "descriptor": "\nComments: 21 pages, 12 figures; v3: restructured the paper for more clarity, major changes to the text, updated plots\n",
    "authors": [
      "S\u00f8lve Eidnes",
      "Alexander J. Stasik",
      "Camilla Sterud",
      "Eivind B\u00f8hn",
      "Signe Riemer-S\u00f8rensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02660"
  },
  {
    "id": "arXiv:2206.02969",
    "title": "A Simple and Optimal Policy Design with Safety against Heavy-tailed Risk  for Stochastic Bandits",
    "abstract": "Comments: Preliminary version appeared in NeurIPS 2022",
    "descriptor": "\nComments: Preliminary version appeared in NeurIPS 2022\n",
    "authors": [
      "David Simchi-Levi",
      "Zeyu Zheng",
      "Feng Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.02969"
  },
  {
    "id": "arXiv:2206.03098",
    "title": "Better Best of Both Worlds Bounds for Bandits with Switching Costs",
    "abstract": "Better Best of Both Worlds Bounds for Bandits with Switching Costs",
    "descriptor": "",
    "authors": [
      "Idan Amir",
      "Guy Azov",
      "Tomer Koren",
      "Roi Livni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03098"
  },
  {
    "id": "arXiv:2206.03572",
    "title": "Compressive Sensing with Wigner $D$-functions on Subsets of the Sphere",
    "abstract": "Compressive Sensing with Wigner $D$-functions on Subsets of the Sphere",
    "descriptor": "",
    "authors": [
      "Marc Andrew Valdez",
      "Alex J. Yuffa",
      "Michael B. Wakin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.03572"
  },
  {
    "id": "arXiv:2206.03925",
    "title": "A projected Nesterov-Kaczmarz approach to stellar population-kinematic  distribution reconstruction in Extragalactic Archaeology",
    "abstract": "Comments: 34 pages, 8 figures",
    "descriptor": "\nComments: 34 pages, 8 figures\n",
    "authors": [
      "Fabian Hinterer",
      "Simon Hubmer",
      "Prashin Jethwa",
      "Kirk M. Soodhalter",
      "Glenn van de Ven",
      "Ronny Ramlau"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2206.03925"
  },
  {
    "id": "arXiv:2206.04079",
    "title": "Computational advantage of quantum random sampling",
    "abstract": "Comments: 82 pages, 13 figures, 2 tables. Sections II-V build on previously unpublished chapters of arXiv:2012.07905. v2: added some references. v3: small corrections",
    "descriptor": "\nComments: 82 pages, 13 figures, 2 tables. Sections II-V build on previously unpublished chapters of arXiv:2012.07905. v2: added some references. v3: small corrections\n",
    "authors": [
      "Dominik Hangleiter",
      "Jens Eisert"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Quantum Gases (cond-mat.quant-gas)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.04079"
  },
  {
    "id": "arXiv:2206.04186",
    "title": "Reinforced Inverse Scattering",
    "abstract": "Reinforced Inverse Scattering",
    "descriptor": "",
    "authors": [
      "Hanyang Jiang",
      "Yuehaw Khoo",
      "Haizhao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04186"
  },
  {
    "id": "arXiv:2206.08439",
    "title": "OpenSRH: optimizing brain tumor surgery using intraoperative stimulated  Raman histology",
    "abstract": "Comments: Neural Information Processing Systems (NeurIPS) 2022 Datasets and Benchmarks Track",
    "descriptor": "\nComments: Neural Information Processing Systems (NeurIPS) 2022 Datasets and Benchmarks Track\n",
    "authors": [
      "Cheng Jiang",
      "Asadur Chowdury",
      "Xinhai Hou",
      "Akhil Kondepudi",
      "Christian W. Freudiger",
      "Kyle Conway",
      "Sandra Camelo-Piragua",
      "Daniel A. Orringer",
      "Honglak Lee",
      "Todd C. Hollon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08439"
  },
  {
    "id": "arXiv:2206.08920",
    "title": "VectorMapNet: End-to-end Vectorized HD Map Learning",
    "abstract": "VectorMapNet: End-to-end Vectorized HD Map Learning",
    "descriptor": "",
    "authors": [
      "Yicheng Liu",
      "Yuantian Tuan",
      "Yue Wang",
      "Yilun Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.08920"
  },
  {
    "id": "arXiv:2206.09578",
    "title": "Performance-Oriented Design for Intelligent Reflecting Surface Assisted  Federated Learning",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Yapeng Zhao",
      "Qingqing Wu",
      "Wen Chen",
      "Celimuge Wu",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09578"
  },
  {
    "id": "arXiv:2206.10843",
    "title": "Learning Debiased Classifier with Biased Committee",
    "abstract": "Comments: Conference on Neural Information Processing Systems (NeurIPS), New Orleans, 2022",
    "descriptor": "\nComments: Conference on Neural Information Processing Systems (NeurIPS), New Orleans, 2022\n",
    "authors": [
      "Nayeong Kim",
      "Sehyun Hwang",
      "Sungsoo Ahn",
      "Jaesik Park",
      "Suha Kwak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.10843"
  },
  {
    "id": "arXiv:2206.15308",
    "title": "Fast sampling of satisfying assignments from random $k$-SAT",
    "abstract": "Comments: 47 pages",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Andreas Galanis",
      "Leslie Ann Goldberg",
      "Heng Guo",
      "Andr\u00e9s Herrera-Poyatos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.15308"
  },
  {
    "id": "arXiv:2207.01166",
    "title": "Target-absent Human Attention",
    "abstract": "Comments: Accepted to ECCV2022",
    "descriptor": "\nComments: Accepted to ECCV2022\n",
    "authors": [
      "Zhibo Yang",
      "Sounak Mondal",
      "Seoyoung Ahn",
      "Gregory Zelinsky",
      "Minh Hoai",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.01166"
  },
  {
    "id": "arXiv:2207.01387",
    "title": "Multi-granularity Item-based Contrastive Recommendation",
    "abstract": "Comments: 17 pages, under review",
    "descriptor": "\nComments: 17 pages, under review\n",
    "authors": [
      "Ruobing Xie",
      "Zhijie Qiu",
      "Bo Zhang",
      "Leyu Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.01387"
  },
  {
    "id": "arXiv:2207.04497",
    "title": "One-shot Neural Backdoor Erasing via Adversarial Weight Masking",
    "abstract": "Comments: Accepted by NeurIPS 2022 (19 pages, 6 figures, 10 tables)",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 (19 pages, 6 figures, 10 tables)\n",
    "authors": [
      "Shuwen Chai",
      "Jinghui Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.04497"
  },
  {
    "id": "arXiv:2207.06010",
    "title": "Does GNN Pretraining Help Molecular Representation?",
    "abstract": "Does GNN Pretraining Help Molecular Representation?",
    "descriptor": "",
    "authors": [
      "Ruoxi Sun",
      "Hanjun Dai",
      "Adams Wei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2207.06010"
  },
  {
    "id": "arXiv:2207.06874",
    "title": "Kernelization for Graph Packing Problems via Rainbow Matching",
    "abstract": "Comments: Accepted to SODA 2023",
    "descriptor": "\nComments: Accepted to SODA 2023\n",
    "authors": [
      "St\u00e9phane Bessy",
      "Marin Bougeret",
      "Dimitrios M. Thilikos",
      "Sebastian Wiederrecht"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.06874"
  },
  {
    "id": "arXiv:2207.11918",
    "title": "Analysis and Optimization of GNN-Based Recommender Systems on Persistent  Memory",
    "abstract": "Analysis and Optimization of GNN-Based Recommender Systems on Persistent  Memory",
    "descriptor": "",
    "authors": [
      "Yuwei Hu",
      "Jiajie Li",
      "Zhongming Yu",
      "Zhiru Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11918"
  },
  {
    "id": "arXiv:2207.14219",
    "title": "A general framework for multi-step ahead adaptive conformal  heteroscedastic time series forecasting",
    "abstract": "Comments: 13 pages, 8 figures",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Martim Sousa",
      "Ana Maria Tom\u00e9",
      "Jos\u00e9 Moreira"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14219"
  },
  {
    "id": "arXiv:2208.00627",
    "title": "A Rotation Meanout Network with Invariance for Dermoscopy Image  Classification and Retrieval",
    "abstract": "A Rotation Meanout Network with Invariance for Dermoscopy Image  Classification and Retrieval",
    "descriptor": "",
    "authors": [
      "Yilan Zhang",
      "Fengying Xie",
      "Xuedong Song",
      "Hangning Zhou",
      "Yiguang Yang",
      "Haopeng Zhang",
      "Jie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.00627"
  },
  {
    "id": "arXiv:2208.00671",
    "title": "RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in  Racket Sports",
    "abstract": "RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in  Racket Sports",
    "descriptor": "",
    "authors": [
      "Jiang Wu",
      "Dongyu Liu",
      "Ziyang Guo",
      "Yingcai Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.00671"
  },
  {
    "id": "arXiv:2208.04995",
    "title": "A Model-Constrained Tangent Slope Learning Approach for Dynamical  Systems",
    "abstract": "A Model-Constrained Tangent Slope Learning Approach for Dynamical  Systems",
    "descriptor": "",
    "authors": [
      "Hai V. Nguyen",
      "Tan Bui-Thanh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.04995"
  },
  {
    "id": "arXiv:2208.06570",
    "title": "Attention Mechanism Based Intelligent Channel Feedback for mmWave  Massive MIMO Systems",
    "abstract": "Attention Mechanism Based Intelligent Channel Feedback for mmWave  Massive MIMO Systems",
    "descriptor": "",
    "authors": [
      "Yibin Zhang",
      "Jinlong Sun",
      "Guan Gui",
      "Yun Lin",
      "Haris Gacanin",
      "Hikmet Sari",
      "Fumiyuki Adachi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.06570"
  },
  {
    "id": "arXiv:2208.06671",
    "title": "Bidirectional Feature Globalization for Few-shot Semantic Segmentation  of 3D Point Cloud Scenes",
    "abstract": "Comments: 3DV2022 Oral",
    "descriptor": "\nComments: 3DV2022 Oral\n",
    "authors": [
      "Yongqiang Mao",
      "Zonghao Guo",
      "Xiaonan Lu",
      "Zhiqiang Yuan",
      "Haowen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06671"
  },
  {
    "id": "arXiv:2208.07522",
    "title": "Reliable Decision from Multiple Subtasks through Threshold Optimization:  Content Moderation in the Wild",
    "abstract": "Comments: WSDM 2023",
    "descriptor": "\nComments: WSDM 2023\n",
    "authors": [
      "Donghyun Son",
      "Byounggyu Lew",
      "Kwanghee Choi",
      "Yongsu Baek",
      "Seungwoo Choi",
      "Beomjun Shin",
      "Sungjoo Ha",
      "Buru Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.07522"
  },
  {
    "id": "arXiv:2209.00721",
    "title": "Generalizing intrusion detection for heterogeneous networks: A  stacked-unsupervised federated learning approach",
    "abstract": "Comments: Preprint (Under revision), 32 pages. Added repository link, see this https URL",
    "descriptor": "\nComments: Preprint (Under revision), 32 pages. Added repository link, see this https URL\n",
    "authors": [
      "Gustavo de Carvalho Bertoli",
      "Louren\u00e7o Alves Pereira Junior",
      "Aldri Luiz dos Santos",
      "Osamu Saotome"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.00721"
  },
  {
    "id": "arXiv:2209.02577",
    "title": "Avgust: Automating Usage-Based Test Generation from Videos of App  Executions",
    "abstract": "Avgust: Automating Usage-Based Test Generation from Videos of App  Executions",
    "descriptor": "",
    "authors": [
      "Yixue Zhao",
      "Saghar Talebipour",
      "Kesina Baral",
      "Hyojae Park",
      "Leon Yee",
      "Safwat Ali Khan",
      "Yuriy Brun",
      "Nenad Medvidovic",
      "Kevin Moran"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.02577"
  },
  {
    "id": "arXiv:2209.02692",
    "title": "Deep Learning Assisted Optimization for 3D Reconstruction from Single 2D  Line Drawings",
    "abstract": "Comments: Project page is at this https URL",
    "descriptor": "\nComments: Project page is at this https URL\n",
    "authors": [
      "Jia Zheng",
      "Yifan Zhu",
      "Kehan Wang",
      "Qiang Zou",
      "Zihan Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.02692"
  },
  {
    "id": "arXiv:2209.02814",
    "title": "A Subexponential Quantum Algorithm for the Semidirect Discrete Logarithm  Problem",
    "abstract": "A Subexponential Quantum Algorithm for the Semidirect Discrete Logarithm  Problem",
    "descriptor": "",
    "authors": [
      "Christopher Battarbee",
      "Delaram Kahrobaei",
      "Ludovic Perret",
      "Siamak F. Shahandashti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Group Theory (math.GR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.02814"
  },
  {
    "id": "arXiv:2209.03100",
    "title": "Effects of Archive Size on Computation Time and Solution Quality for  Multi-Objective Optimization",
    "abstract": "Effects of Archive Size on Computation Time and Solution Quality for  Multi-Objective Optimization",
    "descriptor": "",
    "authors": [
      "Tianye Shu",
      "Ke Shang",
      "Hisao Ishibuchi",
      "Yang Nan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2209.03100"
  },
  {
    "id": "arXiv:2209.03138",
    "title": "Treating Motion as Option to Reduce Motion Dependency in Unsupervised  Video Object Segmentation",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Suhwan Cho",
      "Minhyeok Lee",
      "Seunghoon Lee",
      "Chaewon Park",
      "Donghyeong Kim",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.03138"
  },
  {
    "id": "arXiv:2209.03625",
    "title": "Application of image-to-image translation in improving pedestrian  detection",
    "abstract": "Comments: This is a working draft and not indented for publication",
    "descriptor": "\nComments: This is a working draft and not indented for publication\n",
    "authors": [
      "Devarsh Patel",
      "Sarthak Patel",
      "Megh Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.03625"
  },
  {
    "id": "arXiv:2209.06172",
    "title": "Comparative analysis of segmentation and generative models for  fingerprint retrieval task",
    "abstract": "Comments: This is a working draft and not indented for publication",
    "descriptor": "\nComments: This is a working draft and not indented for publication\n",
    "authors": [
      "Megh Patel",
      "Devarsh Patel",
      "Sarthak Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.06172"
  },
  {
    "id": "arXiv:2209.11280",
    "title": "Scalable Gaussian Process Hyperparameter Optimization via Coverage  Regularization",
    "abstract": "Comments: 4 pages content, 3 figures, 6 tables",
    "descriptor": "\nComments: 4 pages content, 3 figures, 6 tables\n",
    "authors": [
      "Killian Wood",
      "Alec M. Dunton",
      "Amanda Muyskens",
      "Benjamin W. Priest"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.11280"
  },
  {
    "id": "arXiv:2209.14156",
    "title": "TVLT: Textless Vision-Language Transformer",
    "abstract": "Comments: NeurIPS 2022 Oral (21 pages; the first three authors contributed equally)",
    "descriptor": "\nComments: NeurIPS 2022 Oral (21 pages; the first three authors contributed equally)\n",
    "authors": [
      "Zineng Tang",
      "Jaemin Cho",
      "Yixin Nie",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.14156"
  },
  {
    "id": "arXiv:2209.15007",
    "title": "Understanding Collapse in Non-Contrastive Siamese Representation  Learning",
    "abstract": "Comments: Published at ECCV 2022. Project page at this https URL",
    "descriptor": "\nComments: Published at ECCV 2022. Project page at this https URL\n",
    "authors": [
      "Alexander C. Li",
      "Alexei A. Efros",
      "Deepak Pathak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.15007"
  },
  {
    "id": "arXiv:2209.15096",
    "title": "AICCA: AI-driven Cloud Classification Atlas",
    "abstract": "Comments: 27 pages, 11 figures, under revision in MDPI Remote Sensing",
    "descriptor": "\nComments: 27 pages, 11 figures, under revision in MDPI Remote Sensing\n",
    "authors": [
      "Takuya Kurihana",
      "Elisabeth Moyer",
      "Ian Foster"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15096"
  },
  {
    "id": "arXiv:2210.00421",
    "title": "Order-optimal Joint Transmission and Identification in Massive  Multi-User MIMO via Group Testing",
    "abstract": "Comments: 11 pages, 6 figures",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "George Vershinin",
      "Asaf Cohen",
      "Omer Gurewitz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.00421"
  },
  {
    "id": "arXiv:2210.00508",
    "title": "The lexicographically least square-free word with a given prefix",
    "abstract": "The lexicographically least square-free word with a given prefix",
    "descriptor": "",
    "authors": [
      "Siddharth Berera",
      "Andr\u00e9s G\u00f3mez-Colunga",
      "Joey Lakerdas-Gayle",
      "John L\u00f3pez",
      "Mauditra Matin",
      "Daniel Roebuck",
      "Eric Rowland",
      "Noam Scully",
      "Juliet Whidden"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.00508"
  },
  {
    "id": "arXiv:2210.00747",
    "title": "Stochastic optimization of a mixed moving average process for  controlling non-Markovian streamflow environments",
    "abstract": "Stochastic optimization of a mixed moving average process for  controlling non-Markovian streamflow environments",
    "descriptor": "",
    "authors": [
      "Hidekazu Yoshioka",
      "Tomohiro Tanaka",
      "Yumi Yoshioka",
      "Ayumi Hashiguchi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00747"
  },
  {
    "id": "arXiv:2210.01477",
    "title": "OrderlessChain: Do Permissioned Blockchains Need Total Global Order of  Transactions?",
    "abstract": "OrderlessChain: Do Permissioned Blockchains Need Total Global Order of  Transactions?",
    "descriptor": "",
    "authors": [
      "Pezhman Nasirifard",
      "Ruben Mayer",
      "Hans-Arno Jacobsen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.01477"
  },
  {
    "id": "arXiv:2210.01790",
    "title": "Goal Misgeneralization: Why Correct Specifications Aren't Enough For  Correct Goals",
    "abstract": "Goal Misgeneralization: Why Correct Specifications Aren't Enough For  Correct Goals",
    "descriptor": "",
    "authors": [
      "Rohin Shah",
      "Vikrant Varma",
      "Ramana Kumar",
      "Mary Phuong",
      "Victoria Krakovna",
      "Jonathan Uesato",
      "Zac Kenton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01790"
  },
  {
    "id": "arXiv:2210.01860",
    "title": "ProtoBandit: Efficient Prototype Selection via Multi-Armed Bandits",
    "abstract": "Comments: Camera Ready version for ACML 2022",
    "descriptor": "\nComments: Camera Ready version for ACML 2022\n",
    "authors": [
      "Arghya Roy Chaudhuri",
      "Pratik Jawanpuria",
      "Bamdev Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01860"
  },
  {
    "id": "arXiv:2210.02168",
    "title": "An Active Learning Reliability Method for Systems with Partially Defined  Performance Functions",
    "abstract": "Comments: To appear in NeurIPS 2022 Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems (GPSMDMS). The code to generate these experiments is available as an open source repository, see this http URL",
    "descriptor": "\nComments: To appear in NeurIPS 2022 Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems (GPSMDMS). The code to generate these experiments is available as an open source repository, see this http URL\n",
    "authors": [
      "Jonathan Sadeghi",
      "Romain Mueller",
      "John Redford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02168"
  },
  {
    "id": "arXiv:2210.02592",
    "title": "CCC-wav2vec 2.0: Clustering aided Cross Contrastive Self-supervised  learning of speech representations",
    "abstract": "Comments: IEEE SLT 2022",
    "descriptor": "\nComments: IEEE SLT 2022\n",
    "authors": [
      "Vasista Sai Lodagala",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02592"
  },
  {
    "id": "arXiv:2210.03064",
    "title": "A Toolkit for Robust Thresholds",
    "abstract": "Comments: 38 pages",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Huy Tuan Pham",
      "Ashwin Sah",
      "Mehtaab Sawhney",
      "Michael Simkin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.03064"
  },
  {
    "id": "arXiv:2210.03739",
    "title": "Dual-Stage Deeply Supervised Attention-based Convolutional Neural  Networks for Mandibular Canal Segmentation in CBCT Scans",
    "abstract": "Comments: 7 Pages",
    "descriptor": "\nComments: 7 Pages\n",
    "authors": [
      "Azka Rehman",
      "Muhammad Usman",
      "Rabeea Jawaid",
      "Amal Muhammad Saleem",
      "Shi Sub Byon",
      "Sung Hyun Kim",
      "Byoung Dai Lee",
      "Byung il Lee",
      "Yeong Gil Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03739"
  },
  {
    "id": "arXiv:2210.05267",
    "title": "Simulating Structural Plasticity of the Brain more Scalable than  Expected",
    "abstract": "Simulating Structural Plasticity of the Brain more Scalable than  Expected",
    "descriptor": "",
    "authors": [
      "Fabian Czappa",
      "Alexander Gei\u00df",
      "Felix Wolf"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.05267"
  },
  {
    "id": "arXiv:2210.05663",
    "title": "CLIP-Fields: Weakly Supervised Semantic Fields for Robotic Memory",
    "abstract": "Comments: Code, video, and interactive demonstrations available at this https URL",
    "descriptor": "\nComments: Code, video, and interactive demonstrations available at this https URL\n",
    "authors": [
      "Nur Muhammad Mahi Shafiullah",
      "Chris Paxton",
      "Lerrel Pinto",
      "Soumith Chintala",
      "Arthur Szlam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05663"
  },
  {
    "id": "arXiv:2210.06036",
    "title": "Guaranteed Conservation of Momentum for Learning Particle-based Fluid  Dynamics",
    "abstract": "Guaranteed Conservation of Momentum for Learning Particle-based Fluid  Dynamics",
    "descriptor": "",
    "authors": [
      "Lukas Prantl",
      "Benjamin Ummenhofer",
      "Vladlen Koltun",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.06036"
  },
  {
    "id": "arXiv:2210.06143",
    "title": "On the Importance of Gradient Norm in PAC-Bayesian Bounds",
    "abstract": "Comments: NeurIPS 22. arXiv admin note: text overlap with arXiv:2002.09866",
    "descriptor": "\nComments: NeurIPS 22. arXiv admin note: text overlap with arXiv:2002.09866\n",
    "authors": [
      "Itai Gat",
      "Yossi Adi",
      "Alexander Schwing",
      "Tamir Hazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.06143"
  },
  {
    "id": "arXiv:2210.08964",
    "title": "PromptCast: A New Prompt-based Learning Paradigm for Time Series  Forecasting",
    "abstract": "PromptCast: A New Prompt-based Learning Paradigm for Time Series  Forecasting",
    "descriptor": "",
    "authors": [
      "Hao Xue",
      "Flora D.Salim"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.08964"
  },
  {
    "id": "arXiv:2210.10392",
    "title": "Spatio-channel Attention Blocks for Cross-modal Crowd Counting",
    "abstract": "Comments: Accepted to ACCV 2022 (Oral). Code is available at this https URL",
    "descriptor": "\nComments: Accepted to ACCV 2022 (Oral). Code is available at this https URL\n",
    "authors": [
      "Youjia Zhang",
      "Soyun Choi",
      "Sungeun Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.10392"
  },
  {
    "id": "arXiv:2210.10401",
    "title": "Asynchronous RIS-assisted Localization: A Comprehensive Analysis of  Fundamental Limits",
    "abstract": "Asynchronous RIS-assisted Localization: A Comprehensive Analysis of  Fundamental Limits",
    "descriptor": "",
    "authors": [
      "Ziyi Gong",
      "Liang Wu",
      "Zaichen Zhang",
      "Jian Dang",
      "Yongpeng Wu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.10401"
  },
  {
    "id": "arXiv:2210.10638",
    "title": "Digital Human Interactive Recommendation Decision-Making Based on  Reinforcement Learning",
    "abstract": "Comments: 9 pages, 1 figure, 1 table, the paper has been accepted and this is the camera-ready for NeurIPS 2022 Workshop on Human in the Loop Learning, this https URL",
    "descriptor": "\nComments: 9 pages, 1 figure, 1 table, the paper has been accepted and this is the camera-ready for NeurIPS 2022 Workshop on Human in the Loop Learning, this https URL\n",
    "authors": [
      "Xiong Junwu",
      "Xiaoyun Feng",
      "YunZhou Shi",
      "James Zhang",
      "Zhongzhou Zhao",
      "Wei Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10638"
  },
  {
    "id": "arXiv:2210.10729",
    "title": "Ruminations on Matrix Convexity and the Strong Subadditivity of Quantum  Entropy",
    "abstract": "Comments: 12 pages, no figures, fixing a typo of version 1, where \"self adjoint\" was omitted in the description of Q in Prop. 1.1",
    "descriptor": "\nComments: 12 pages, no figures, fixing a typo of version 1, where \"self adjoint\" was omitted in the description of Q in Prop. 1.1\n",
    "authors": [
      "Michael Aizenman",
      "Giorgio Cipolloni"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.10729"
  },
  {
    "id": "arXiv:2210.11350",
    "title": "A Survey on Over-the-Air Computation",
    "abstract": "Comments: 26 pages, 6 Figures; Comments are welcome! (IEEE Communications Surveys & Tutorials)",
    "descriptor": "\nComments: 26 pages, 6 Figures; Comments are welcome! (IEEE Communications Surveys & Tutorials)\n",
    "authors": [
      "Alphan Sahin",
      "Rui Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.11350"
  },
  {
    "id": "arXiv:2210.11639",
    "title": "HesScale: Scalable Computation of Hessian Diagonals",
    "abstract": "HesScale: Scalable Computation of Hessian Diagonals",
    "descriptor": "",
    "authors": [
      "Mohamed Elsayed",
      "A. Rupam Mahmood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.11639"
  },
  {
    "id": "arXiv:2210.13012",
    "title": "CMU-Net: A Strong ConvMixer-based Medical Ultrasound Image Segmentation  Network",
    "abstract": "Comments: 5 pages, 13 figures, conference",
    "descriptor": "\nComments: 5 pages, 13 figures, conference\n",
    "authors": [
      "Fenghe Tang",
      "Lingtao Wang",
      "Chunping Ning",
      "Min Xian",
      "Jianrui Ding"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.13012"
  },
  {
    "id": "arXiv:2210.13263",
    "title": "Driver Locations Harvesting Attack on pRide",
    "abstract": "Driver Locations Harvesting Attack on pRide",
    "descriptor": "",
    "authors": [
      "Shyam Murthy",
      "Srinivas Vivek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.13263"
  },
  {
    "id": "arXiv:2210.13856",
    "title": "A Framework for Collaborative Multi-Robot Mapping using Spectral Graph  Wavelets",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2203.00308",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.00308\n",
    "authors": [
      "Lukas Bernreiter",
      "Shehryar Khattak",
      "Lionel Ott",
      "Roland Siegwart",
      "Marco Hutter",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.13856"
  },
  {
    "id": "arXiv:2210.14044",
    "title": "SeismicNet: Physics-informed neural networks for seismic wave modeling  in semi-infinite domain",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Pu Ren",
      "Chengping Rao",
      "Su Chen",
      "Jian-Xun Wang",
      "Hao Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.14044"
  },
  {
    "id": "arXiv:2210.14169",
    "title": "Weakly Supervised Data Augmentation Through Prompting for Dialogue  Understanding",
    "abstract": "Comments: To appear in SyntheticData4ML @ NeurIPS 2022. 16 pages, 10 figures, 3 tables",
    "descriptor": "\nComments: To appear in SyntheticData4ML @ NeurIPS 2022. 16 pages, 10 figures, 3 tables\n",
    "authors": [
      "Maximillian Chen",
      "Alexandros Papangelis",
      "Chenyang Tao",
      "Andy Rosenbaum",
      "Seokhwan Kim",
      "Yang Liu",
      "Zhou Yu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14169"
  },
  {
    "id": "arXiv:2210.14295",
    "title": "Cross-View Image Sequence Geo-localization",
    "abstract": "Cross-View Image Sequence Geo-localization",
    "descriptor": "",
    "authors": [
      "Xiaohan Zhang",
      "Waqas Sultani",
      "Safwan Wshah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.14295"
  },
  {
    "id": "arXiv:2210.14383",
    "title": "CLIP-FLow: Contrastive Learning by semi-supervised Iterative Pseudo  labeling for Optical Flow Estimation",
    "abstract": "CLIP-FLow: Contrastive Learning by semi-supervised Iterative Pseudo  labeling for Optical Flow Estimation",
    "descriptor": "",
    "authors": [
      "Zhiqi Zhang",
      "Pan Ji",
      "Nitin Bansal",
      "Changjiang Cai",
      "Qingan Yan",
      "Xiangyu Xu",
      "Yi Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.14383"
  },
  {
    "id": "arXiv:2210.14431",
    "title": "$N$-gram is Back: Residual Learning of Neural Text Generation with  $n$-gram Language Model",
    "abstract": "Comments: Accepted to findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted to findings of EMNLP 2022\n",
    "authors": [
      "Huayang Li",
      "Deng Cai",
      "Jin Xu",
      "Taro Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14431"
  },
  {
    "id": "arXiv:2210.14612",
    "title": "Analyzing Deep Learning Representations of Point Clouds for Real-Time  In-Vehicle LiDAR Perception",
    "abstract": "Comments: Accepted at the NeurIPS 2022 Workshop on Machine Learning for Autonomous Driving (ML4AD)",
    "descriptor": "\nComments: Accepted at the NeurIPS 2022 Workshop on Machine Learning for Autonomous Driving (ML4AD)\n",
    "authors": [
      "Marc Uecker",
      "Tobias Fleck",
      "Marcel Pflugfelder",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.14612"
  },
  {
    "id": "arXiv:2210.14827",
    "title": "A Nonlinear Sum of Squares Search for CAZAC Sequences",
    "abstract": "Comments: 6 pages, 4 figures, submitted to IEEE Radar Conference 2023",
    "descriptor": "\nComments: 6 pages, 4 figures, submitted to IEEE Radar Conference 2023\n",
    "authors": [
      "Mark Magsino",
      "Yixin Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.14827"
  },
  {
    "id": "arXiv:2210.14880",
    "title": "Integrated Sensing and Communication in Distributed Antenna Networks",
    "abstract": "Comments: 18 pages, 5 figures",
    "descriptor": "\nComments: 18 pages, 5 figures\n",
    "authors": [
      "Dongfang Xu",
      "Ata Khalili",
      "Xianghao Yu",
      "Derrick Wing Kwan Ng",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.14880"
  },
  {
    "id": "arXiv:2210.15058",
    "title": "Tangent Bundle Filters and Neural Networks: from Manifolds to Cellular  Sheaves and Back",
    "abstract": "Tangent Bundle Filters and Neural Networks: from Manifolds to Cellular  Sheaves and Back",
    "descriptor": "",
    "authors": [
      "Claudio Battiloro",
      "Zhiyang Wang",
      "Hans Riess",
      "Paolo Di Lorenzo",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15058"
  },
  {
    "id": "arXiv:2210.15315",
    "title": "Noise in the Clouds: Influence of Network Performance Variability on  Application Scalability",
    "abstract": "Comments: To appear in SIGMETRICS 2023",
    "descriptor": "\nComments: To appear in SIGMETRICS 2023\n",
    "authors": [
      "Daniele De Sensi",
      "Tiziano De Matteis",
      "Konstantin Taranov",
      "Salvatore Di Girolamo",
      "Tobias Rahn",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.15315"
  },
  {
    "id": "arXiv:2210.15366",
    "title": "Multi-dimensional Edge-based Audio Event Relational Graph Representation  Learning for Acoustic Scene Classification",
    "abstract": "Multi-dimensional Edge-based Audio Event Relational Graph Representation  Learning for Acoustic Scene Classification",
    "descriptor": "",
    "authors": [
      "Yuanbo Hou",
      "Siyang Song",
      "Chuang Yu",
      "Yuxin Song",
      "Wenwu Wang",
      "Dick Botteldooren"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15366"
  },
  {
    "id": "arXiv:2210.15669",
    "title": "On Catalan Constant Continued Fractions",
    "abstract": "On Catalan Constant Continued Fractions",
    "descriptor": "",
    "authors": [
      "David Naccache",
      "Ofer Yifrach-Stav"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Discrete Mathematics (cs.DM)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2210.15669"
  },
  {
    "id": "arXiv:2210.16147",
    "title": "Modeling structure-building in the brain with CCG parsing and large  language models",
    "abstract": "Comments: removed errant To Do marker that was accidentally left in the manuscript",
    "descriptor": "\nComments: removed errant To Do marker that was accidentally left in the manuscript\n",
    "authors": [
      "Milo\u0161 Stanojevi\u0107",
      "Jonathan R. Brennan",
      "Donald Dunagan",
      "Mark Steedman",
      "John T. Hale"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16147"
  },
  {
    "id": "arXiv:2210.16173",
    "title": "Deep Learning Object Detection Approaches to Signal Identification",
    "abstract": "Deep Learning Object Detection Approaches to Signal Identification",
    "descriptor": "",
    "authors": [
      "Luke Wood",
      "Kevin Anderson",
      "Peter Gerstoft",
      "Richard Bell",
      "Raghab Subbaraman",
      "Dinesh Bharadia"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16173"
  },
  {
    "id": "arXiv:2210.16307",
    "title": "Investigation of chemical structure recognition by encoder-decoder  models in learning progress",
    "abstract": "Comments: 17 pages, 4 figures",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Shumpei Nemoto",
      "Tadahaya Mizuno",
      "Hiroyuki Kusuhara"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2210.16307"
  },
  {
    "id": "arXiv:2210.16371",
    "title": "Distributed Black-box Attack against Image Classification Cloud Services",
    "abstract": "Comments: 10 pages, 11 figures",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Han Wu",
      "Sareh Rowlands",
      "Johan Wahlstrom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16371"
  },
  {
    "id": "arXiv:2210.16414",
    "title": "Meta-Learning Biologically Plausible Plasticity Rules with Random  Feedback Pathways",
    "abstract": "Meta-Learning Biologically Plausible Plasticity Rules with Random  Feedback Pathways",
    "descriptor": "",
    "authors": [
      "Navid Shervani-Tabar",
      "Robert Rosenbaum"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.16414"
  },
  {
    "id": "arXiv:2210.16441",
    "title": "GowFed -- A novel Federated Network Intrusion Detection System",
    "abstract": "Comments: 16 pages, 12 figures, currently under review at Journal of Network and Computer Applications (JNCA). arXiv admin note: text overlap with arXiv:2204.12443",
    "descriptor": "\nComments: 16 pages, 12 figures, currently under review at Journal of Network and Computer Applications (JNCA). arXiv admin note: text overlap with arXiv:2204.12443\n",
    "authors": [
      "Aitor Belenguer",
      "Jose A. Pascual",
      "Javier Navaridas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.16441"
  },
  {
    "id": "arXiv:2210.16938",
    "title": "A view on model misspecification in uncertainty quantification",
    "abstract": "Comments: An initial version of the current work has been accepted to be presented at BNAIC/BeNeLearn 2022, to which it was submitted on August 27, 2022",
    "descriptor": "\nComments: An initial version of the current work has been accepted to be presented at BNAIC/BeNeLearn 2022, to which it was submitted on August 27, 2022\n",
    "authors": [
      "Yuko Kato",
      "David M.J. Tax",
      "Marco Loog"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.16938"
  },
  {
    "id": "arXiv:2210.17030",
    "title": "Uncertainty Aware Trader-Company Method: Interpretable Stock Price  Prediction Capturing Uncertainty",
    "abstract": "Comments: IEEE BIGDATA 2022 Accepted",
    "descriptor": "\nComments: IEEE BIGDATA 2022 Accepted\n",
    "authors": [
      "Yugo Fujimoto",
      "Kei Nakagawa",
      "Kentaro Imajo",
      "Kentaro Minami"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.17030"
  },
  {
    "id": "arXiv:2210.17174",
    "title": "uBFT: Microsecond-scale BFT using Disaggregated Memory [Extended  Version]",
    "abstract": "uBFT: Microsecond-scale BFT using Disaggregated Memory [Extended  Version]",
    "descriptor": "",
    "authors": [
      "Marcos K. Aguilera",
      "Naama Ben-David",
      "Rachid Guerraoui",
      "Antoine Murat",
      "Athanasios Xygkis",
      "Igor Zablotchi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.17174"
  },
  {
    "id": "arXiv:2210.17299",
    "title": "Bayesian Model Selection of Lithium-Ion Battery Models via Bayesian  Quadrature",
    "abstract": "Comments: 10 pages, 2 figures",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Masaki Adachi",
      "Yannick Kuhn",
      "Birger Horstmann",
      "Michael A. Osborne",
      "David A. Howey"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.17299"
  },
  {
    "id": "arXiv:2210.17302",
    "title": "Design, Field Evaluation, and Traffic Analysis of a Competitive  Autonomous Driving Model in the a Congested Environment",
    "abstract": "Design, Field Evaluation, and Traffic Analysis of a Competitive  Autonomous Driving Model in the a Congested Environment",
    "descriptor": "",
    "authors": [
      "Daegyu Lee",
      "Hyunki Seong",
      "Seungil Han",
      "Gyuree Kang",
      "D.Hyunchul Shim",
      "Yoonjin Yoon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.17302"
  },
  {
    "id": "arXiv:2210.17327",
    "title": "Diffusion-based Generative Speech Source Separation",
    "abstract": "Comments: 5 pages, 3 figures, 2 tables. Submitted to ICASSP 2023",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables. Submitted to ICASSP 2023\n",
    "authors": [
      "Robin Scheibler",
      "Youna Ji",
      "Soo-Whan Chung",
      "Jaeuk Byun",
      "Soyeon Choe",
      "Min-Seok Choi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.17327"
  },
  {
    "id": "arXiv:2210.17349",
    "title": "Robust MelGAN: A robust universal neural vocoder for high-fidelity TTS",
    "abstract": "Comments: Accepted by ISCSLP 2022",
    "descriptor": "\nComments: Accepted by ISCSLP 2022\n",
    "authors": [
      "Kun Song",
      "Jian Cong",
      "Xinsheng Wang",
      "Yongmao Zhang",
      "Lei Xie",
      "Ning Jiang",
      "Haiying Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.17349"
  },
  {
    "id": "arXiv:2210.17409",
    "title": "Deep Model Reassembly",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Xingyi Yang",
      "Daquan Zhou",
      "Songhua Liu",
      "Jingwen Ye",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.17409"
  },
  {
    "id": "arXiv:2210.17451",
    "title": "AdaMix: Mixture-of-Adaptations for Parameter-efficient Model Tuning",
    "abstract": "Comments: The paper is withdraw to avoid duplicate version of arXiv article 2205.12410. We will include new content as a updated version",
    "descriptor": "\nComments: The paper is withdraw to avoid duplicate version of arXiv article 2205.12410. We will include new content as a updated version\n",
    "authors": [
      "Yaqing Wang",
      "Sahaj Agarwal",
      "Subhabrata Mukherjee",
      "Xiaodong Liu",
      "Jing Gao",
      "Ahmed Hassan Awadallah",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.17451"
  },
  {
    "id": "arXiv:2211.00107",
    "title": "Where to start? Analyzing the potential value of intermediate models",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Leshem Choshen",
      "Elad Venezian",
      "Shachar Don-Yehia",
      "Noam Slonim",
      "Yoav Katz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00107"
  },
  {
    "id": "arXiv:2211.00120",
    "title": "GPU-friendly, Parallel, and (Almost-)In-Place Construction of  Left-Balanced k-d Trees",
    "abstract": "GPU-friendly, Parallel, and (Almost-)In-Place Construction of  Left-Balanced k-d Trees",
    "descriptor": "",
    "authors": [
      "Ingo Wald"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.00120"
  },
  {
    "id": "arXiv:2211.00222",
    "title": "SDMuse: Stochastic Differential Music Editing and Generation via Hybrid  Representation",
    "abstract": "SDMuse: Stochastic Differential Music Editing and Generation via Hybrid  Representation",
    "descriptor": "",
    "authors": [
      "Chen Zhang",
      "Yi Ren",
      "Kejun Zhang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00222"
  },
  {
    "id": "arXiv:2211.00277",
    "title": "HFN: Heterogeneous Feature Network for Multivariate Time Series Anomaly  Detection",
    "abstract": "HFN: Heterogeneous Feature Network for Multivariate Time Series Anomaly  Detection",
    "descriptor": "",
    "authors": [
      "Jun Zhan",
      "Chengkun Wu",
      "Canqun Yang",
      "Qiucheng Miao",
      "Xiandong Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.00277"
  },
  {
    "id": "arXiv:2211.00316",
    "title": "Hessian-inversion-free ray-born inversion for high-resolution  quantitative ultrasound tomography",
    "abstract": "Hessian-inversion-free ray-born inversion for high-resolution  quantitative ultrasound tomography",
    "descriptor": "",
    "authors": [
      "Ashkan Javaherian"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00316"
  },
  {
    "id": "arXiv:2211.00385",
    "title": "Behavioral Intention Prediction in Driving Scenes: A Survey",
    "abstract": "Comments: Submitted to IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Jianwu Fang",
      "Fan Wang",
      "Peining Shen",
      "Zhedong Zheng",
      "Jianru Xue",
      "Tat-seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00385"
  },
  {
    "id": "arXiv:2211.00471",
    "title": "Exploring Effects of Computational Parameter Changes to Image  Recognition Systems",
    "abstract": "Comments: 9 pages, 8 figures, 1 table",
    "descriptor": "\nComments: 9 pages, 8 figures, 1 table\n",
    "authors": [
      "Nikolaos Louloudakis",
      "Perry Gibson",
      "Jos\u00e9 Cano",
      "Ajitha Rajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00471"
  },
  {
    "id": "arXiv:2211.00529",
    "title": "DOLPH: Diffusion Models for Phase Retrieval",
    "abstract": "DOLPH: Diffusion Models for Phase Retrieval",
    "descriptor": "",
    "authors": [
      "Shirin Shoushtari",
      "Jiaming Liu",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00529"
  },
  {
    "id": "arXiv:2211.00565",
    "title": "Revisiting Heterophily in Graph Convolution Networks by Learning  Representations Across Topological and Feature Spaces",
    "abstract": "Comments: Under Review Project Page: this https URL",
    "descriptor": "\nComments: Under Review Project Page: this https URL\n",
    "authors": [
      "Ashish Tiwari",
      "Sresth Tosniwal",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00565"
  },
  {
    "id": "arXiv:2211.00568",
    "title": "Consistent Training via Energy-Based GFlowNets for Modeling Discrete  Joint Distributions",
    "abstract": "Comments: 9 Pages, 10 Figures",
    "descriptor": "\nComments: 9 Pages, 10 Figures\n",
    "authors": [
      "Chanakya Ekbote",
      "Moksh Jain",
      "Payel Das",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00568"
  }
]
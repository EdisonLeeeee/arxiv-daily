[
  {
    "id": "arXiv:2211.03790",
    "title": "Knowledge Retrieval using Foon",
    "abstract": "Flexible task planning is still a significant challenge for robots. The\ninability of robots to creatively adapt their task plans to new or unforeseen\nchallenges is largely attributable to their limited understanding of their\nactivities and the environment. Cooking, for example, requires a person to\noccasionally take risks that a robot would find extremely dangerous. We may\nobtain manipulation sequences by employing knowledge that is drawn from\nnumerous video sources thanks to knowledge retrieval through graph search.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1902.01537 by other authors. text overlap with arXiv:2211.02992\n",
    "authors": [
      "Vara Bhavya Sri Malli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.03790"
  },
  {
    "id": "arXiv:2211.03808",
    "title": "ToDD: Topological Compound Fingerprinting in Computer-Aided Drug  Discovery",
    "abstract": "In computer-aided drug discovery (CADD), virtual screening (VS) is used for\nidentifying the drug candidates that are most likely to bind to a molecular\ntarget in a large library of compounds. Most VS methods to date have focused on\nusing canonical compound representations (e.g., SMILES strings, Morgan\nfingerprints) or generating alternative fingerprints of the compounds by\ntraining progressively more complex variational autoencoders (VAEs) and graph\nneural networks (GNNs). Although VAEs and GNNs led to significant improvements\nin VS performance, these methods suffer from reduced performance when scaling\nto large virtual compound datasets. The performance of these methods has shown\nonly incremental improvements in the past few years. To address this problem,\nwe developed a novel method using multiparameter persistence (MP) homology that\nproduces topological fingerprints of the compounds as multidimensional vectors.\nOur primary contribution is framing the VS process as a new topology-based\ngraph ranking problem by partitioning a compound into chemical substructures\ninformed by the periodic properties of its atoms and extracting their\npersistent homology features at multiple resolution levels. We show that the\nmargin loss fine-tuning of pretrained Triplet networks attains highly\ncompetitive results in differentiating between compounds in the embedding space\nand ranking their likelihood of becoming effective drug candidates. We further\nestablish theoretical guarantees for the stability properties of our proposed\nMP signatures, and demonstrate that our models, enhanced by the MP signatures,\noutperform state-of-the-art methods on benchmark datasets by a wide and highly\nstatistically significant margin (e.g., 93% gain for Cleves-Jain and 54% gain\nfor DUD-E Diverse dataset).",
    "descriptor": "\nComments: NeurIPS, 2022 (36th Conference on Neural Information Processing Systems)\n",
    "authors": [
      "Andac Demir",
      "Baris Coskunuzer",
      "Ignacio Segovia-Dominguez",
      "Yuzhou Chen",
      "Yulia Gel",
      "Bulent Kiziltan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.03808"
  },
  {
    "id": "arXiv:2211.03817",
    "title": "A Property Specification Pattern Catalog for Real-Time System  Verification with UPPAAL",
    "abstract": "Context: The goal of specification pattern catalogs for real-time\nrequirements is to mask the complexity of specifying such requirements in a\ntimed temporal logic for verification. For this purpose, they provide frontends\nto express and translate pattern-based natural language requirements to\nformulae in a suitable logic. However, the widely used real-time model checking\ntool UPPAAL only supports a restricted subset of those formulae that focus only\non basic and non-nested reachability, safety, and liveness properties. This\nrestriction renders many specification patterns inapplicable. As a workaround,\ntimed observer automata need to be constructed manually to express\nsophisticated requirements envisioned by these patterns. Objective: In this\nwork, we fill these gaps by providing a comprehensive specification pattern\ncatalog for UPPAAL. The catalog supports qualitative and real-time requirements\nand covers all corresponding patterns of existing catalogs. Method: The catalog\nwe propose is integrated with UPPAAL. It supports the specification of\nqualitative and real-time requirements using patterns and provides an automated\ngenerator that translates these requirements to observer automata and TCTL\nformulae. The resulting artifacts are used for verifying systems in UPPAAL.\nThus, our catalog enables an automated end-to-end verification process for\nUPPAAL based on property specification patterns and observer automata. Results:\nWe evaluate our catalog on three UPPAAL system models reported in the\nliterature and mostly applied in an industrial setting. As a result, not only\nthe reproducibility of the related UPPAAL models was possible, but also the\nvalidation of an automated, seamless, and accurate pattern- and observer-based\nverification process. Conclusion: The proposed property specification pattern\ncatalog for UPPAAL enables practitioners to specify qualitative and real-time\nrequirements...",
    "descriptor": "\nComments: Accepted Manuscript\n",
    "authors": [
      "Thomas Vogel",
      "Marc Carwehl",
      "Gena\u00edna Nunes Rodrigues",
      "Lars Grunske"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.03817"
  },
  {
    "id": "arXiv:2211.03818",
    "title": "CELLS: A Parallel Corpus for Biomedical Lay Language Generation",
    "abstract": "Recent lay language generation systems have used Transformer models trained\non a parallel corpus to increase health information accessibility. However, the\napplicability of these models is constrained by the limited size and topical\nbreadth of available corpora. We introduce CELLS, the largest (63k pairs) and\nbroadest-ranging (12 journals) parallel corpus for lay language generation. The\nabstract and the corresponding lay language summary are written by domain\nexperts, assuring the quality of our dataset. Furthermore, qualitative\nevaluation of expert-authored plain language summaries has revealed background\nexplanation as a key strategy to increase accessibility. Such explanation is\nchallenging for neural models to generate because it goes beyond simplification\nby adding content absent from the source. We derive two specialized paired\ncorpora from CELLS to address key challenges in lay language generation:\ngenerating background explanations and simplifying the original abstract. We\nadopt retrieval-augmented models as an intuitive fit for the task of background\nexplanation generation, and show improvements in summary quality and simplicity\nwhile maintaining factual correctness. Taken together, this work presents the\nfirst comprehensive study of background explanation for lay language\ngeneration, paving the path for disseminating scientific knowledge to a broader\naudience. CELLS is publicly available at:\nhttps://github.com/LinguisticAnomalies/pls_retrieval.",
    "descriptor": "",
    "authors": [
      "Yue Guo",
      "Wei Qiu",
      "Gondy Leroy",
      "Sheng Wang",
      "Trevor Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.03818"
  },
  {
    "id": "arXiv:2211.03826",
    "title": "Network Diffusion Model Reveals Recovery Multipliers and Heterogeneous  Spatial Effects in Post-Disaster Community Recovery",
    "abstract": "Community recovery from hazards and crises occurs through various diffusion\nprocesses within social and spatial networks of communities. Existing knowledge\nregarding the diffusion of recovery in community socio-spatial networks,\nhowever, is rather limited. To bridge this gap, in this study, we created a\nnetwork diffusion model to characterize the unfolding of population activity\nrecovery in spatial networks of communities. Using data related to population\nactivity recovery durations calculated from location-based data in the context\nof 2017 Hurricane Harvey in the Houston area, we parameterized the\nthreshold-based network diffusion model and evaluated the extent of homogeneity\nin spatial effects. Then we implemented the network diffusion model along with\nthe genetic algorithm to simulate and identify recovery multipliers. The\nresults show that the spatial effects of recovery are rather heterogeneous\nacross spatial areas; some spatial areas demonstrate a greater spatial effect\n(spatial interdependence) in their recovery compared with others. Also, the\nresults show that low-income areas demonstrate a greater spatial effect in\ntheir recovery. The greater spatial effects in recovery of low-income areas\nimply more reliance on resources and facilities of neighboring areas and also\nexplain the existence of slow recovery hotspots in areas where socially\nvulnerable populations reside. Also, the results show that low-income and\nminority areas are community recovery multipliers; the faster the recovery of\nthese recovery multipliers; the faster the recovery of the entire community.\nHence, prioritizing these areas for recovery resource allocation could expedite\nthe recovery of the overall community and promote recovery equality and equity.",
    "descriptor": "\nComments: 20 pages, 9 figures, 2 tables\n",
    "authors": [
      "Chia-Fu Liu",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.03826"
  },
  {
    "id": "arXiv:2211.03827",
    "title": "Lower Bounds for the Convergence of Tensor Power Iteration on Random  Overcomplete Models",
    "abstract": "Tensor decomposition serves as a powerful primitive in statistics and machine\nlearning. In this paper, we focus on using power iteration to decompose an\novercomplete random tensor. Past work studying the properties of tensor power\niteration either requires a non-trivial data-independent initialization, or is\nrestricted to the undercomplete regime. Moreover, several papers implicitly\nsuggest that logarithmically many iterations (in terms of the input dimension)\nare sufficient for the power method to recover one of the tensor components. In\nthis paper, we analyze the dynamics of tensor power iteration from random\ninitialization in the overcomplete regime. Surprisingly, we show that\npolynomially many steps are necessary for convergence of tensor power iteration\nto any of the true component, which refutes the previous conjecture. On the\nother hand, our numerical experiments suggest that tensor power iteration\nsuccessfully recovers tensor components for a broad range of parameters,\ndespite that it takes at least polynomially many steps to converge. To further\ncomplement our empirical evidence, we prove that a popular objective function\nfor tensor decomposition is strictly increasing along the power iteration path.\nOur proof is based on the Gaussian conditioning technique, which has been\napplied to analyze the approximate message passing (AMP) algorithm. The major\ningredient of our argument is a conditioning lemma that allows us to generalize\nAMP-type analysis to non-proportional limit and polynomially many iterations of\nthe power method.",
    "descriptor": "\nComments: 40 pages, 3 figures\n",
    "authors": [
      "Yuchen Wu",
      "Kangjie Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.03827"
  },
  {
    "id": "arXiv:2211.03829",
    "title": "Optimal Merging Control of an Autonomous Vehicle in Mixed Traffic: an  Optimal Index Policy",
    "abstract": "We consider the problem of a single Autonomous Vehicle (AV) merging into\ntraffic consisting only of Human Driven Vehicles (HDVs) with the goal of\nminimizing both the travel time and energy consumption of the entire group of\nvehicles involved in the merging process. This is done by controlling only the\nAV and determining both the optimal merging sequence and the optimal AV\ntrajectory associated with it. We derive an optimal index policy which\nprescribes the merging position of the AV within the group of HDVs. We also\nspecify conditions under which the optimal index corresponds to the AV merging\nbefore all HDVs or after all HDVs, in which case no interaction of the AV with\nthe HDVs is required. Simulation results are included to validate the optimal\nindex policy and demonstrate cases where optimal merging can be achieved\nwithout requiring any explicit assumptions regarding human driving behavior.",
    "descriptor": "",
    "authors": [
      "Ehsan Sabouni",
      "Christos G. Cassandras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.03829"
  },
  {
    "id": "arXiv:2211.03830",
    "title": "Further Improvements on Approximating the Uniform Cost-Distance Steiner  Tree Problem",
    "abstract": "In this paper, we consider the Uniform Cost-Distance Steiner Tree Problem in\nmetric spaces, a generalization of the well-known Steiner tree problem.\nCost-distance Steiner trees minimize the sum of the total length and the\nweighted path lengths from a dedicated root to the other terminals, which have\na weight to penalize the path length. They are applied when the tree is\nintended for signal transmission, e.g. in chip design or telecommunication\nnetworks, and the signal speed through the tree has to be considered besides\nthe total length. Constant factor approximation algorithms for the uniform\ncost-distance Steiner tree problem have been known since the first mentioning\nof the problem by Meyerson, Munagala, and Plotkin. Recently, the approximation\nfactor was improved from 2.87 to 2.39 by Khazraei and Held. We refine their\napproach further and reduce the approximation factor down to 2.15.",
    "descriptor": "",
    "authors": [
      "Stephan Held",
      "Yannik Kyle Dustin Spitzley"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.03830"
  },
  {
    "id": "arXiv:2211.03831",
    "title": "Multi-Head Adapter Routing for Data-Efficient Fine-Tuning",
    "abstract": "Parameter-efficient fine-tuning (PEFT) methods can adapt large language\nmodels to downstream tasks by training a small amount of newly added\nparameters. In multi-task settings, PEFT adapters typically train on each task\nindependently, inhibiting transfer across tasks, or on the concatenation of all\ntasks, which can lead to negative interference. To address this, Polytropon\n(Ponti et al.) jointly learns an inventory of PEFT adapters and a routing\nfunction to share variable-size sets of adapters across tasks. Subsequently,\nadapters can be re-combined and fine-tuned on novel tasks even with limited\ndata. In this paper, we investigate to what extent the ability to control which\nadapters are active for each task leads to sample-efficient generalization.\nThus, we propose less expressive variants where we perform weighted averaging\nof the adapters before few-shot adaptation (Poly-mu) instead of learning a\nrouting function. Moreover, we introduce more expressive variants where\nfiner-grained task-adapter allocation is learned through a multi-head routing\nfunction (Poly-S). We test these variants on three separate benchmarks for\nmulti-task learning. We find that Poly-S achieves gains on all three (up to 5.3\npoints on average) over strong baselines, while incurring a negligible\nadditional cost in parameter count. In particular, we find that instruction\ntuning, where models are fully fine-tuned on natural language instructions for\neach task, is inferior to modular methods such as Polytropon and our proposed\nvariants.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Lucas Caccia",
      "Edoardo Ponti",
      "Lucas Liu",
      "Matheus Pereira",
      "Nicolas Le Roux",
      "Alessandro Sordoni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.03831"
  },
  {
    "id": "arXiv:2211.03837",
    "title": "AX-MABSA: A Framework for Extremely Weakly Supervised Multi-label Aspect  Based Sentiment Analysis",
    "abstract": "Aspect Based Sentiment Analysis is a dominant research area with potential\napplications in social media analytics, business, finance, and health. Prior\nworks in this area are primarily based on supervised methods, with a few\ntechniques using weak supervision limited to predicting a single aspect\ncategory per review sentence. In this paper, we present an extremely weakly\nsupervised multi-label Aspect Category Sentiment Analysis framework which does\nnot use any labelled data. We only rely on a single word per class as an\ninitial indicative information. We further propose an automatic word selection\ntechnique to choose these seed categories and sentiment words. We explore\nunsupervised language model post-training to improve the overall performance,\nand propose a multi-label generator model to generate multiple aspect\ncategory-sentiment pairs per review sentence. Experiments conducted on four\nbenchmark datasets showcase our method to outperform other weakly supervised\nbaselines by a significant margin.",
    "descriptor": "\nComments: to be published in EMNLP 2022\n",
    "authors": [
      "Sabyasachi Kamila",
      "Walid Magdy",
      "Sourav Dutta",
      "MingXue Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.03837"
  },
  {
    "id": "arXiv:2211.03846",
    "title": "FED-CD: Federated Causal Discovery from Interventional and Observational  Data",
    "abstract": "Causal discovery, the inference of causal relations from data, is a core task\nof fundamental importance in all scientific domains, and several new machine\nlearning methods for addressing the causal discovery problem have been proposed\nrecently. However, existing machine learning methods for causal discovery\ntypically require that the data used for inference is pooled and available in a\ncentralized location. In many domains of high practical importance, such as in\nhealthcare, data is only available at local data-generating entities (e.g.\nhospitals in the healthcare context), and cannot be shared across entities due\nto, among others, privacy and regulatory reasons. In this work, we address the\nproblem of inferring causal structure - in the form of a directed acyclic graph\n(DAG) - from a distributed data set that contains both observational and\ninterventional data in a privacy-preserving manner by exchanging updates\ninstead of samples. To this end, we introduce a new federated framework,\nFED-CD, that enables the discovery of global causal structures both when the\nset of intervened covariates is the same across decentralized entities, and\nwhen the set of intervened covariates are potentially disjoint. We perform a\ncomprehensive experimental evaluation on synthetic data that demonstrates that\nFED-CD enables effective aggregation of decentralized data for causal discovery\nwithout direct sample sharing, even when the contributing distributed data sets\ncover disjoint sets of interventions. Effective methods for causal discovery in\ndistributed data sets could significantly advance scientific discovery and\nknowledge sharing in important settings, for instance, healthcare, in which\nsharing of data across local sites is difficult or prohibited.",
    "descriptor": "",
    "authors": [
      "Amin Abyaneh",
      "Nino Scherrer",
      "Patrick Schwab",
      "Stefan Bauer",
      "Bernhard Sch\u00f6lkopf",
      "Arash Mehrjou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.03846"
  },
  {
    "id": "arXiv:2211.03850",
    "title": "Polite Teacher: Semi-Supervised Instance Segmentation with Mutual  Learning and Pseudo-Label Thresholding",
    "abstract": "We present Polite Teacher, a simple yet effective method for the task of\nsemi-supervised instance segmentation. The proposed architecture relies on the\nTeacher-Student mutual learning framework. To filter out noisy pseudo-labels,\nwe use confidence thresholding for bounding boxes and mask scoring for masks.\nThe approach has been tested with CenterMask, a single-stage anchor-free\ndetector. Tested on the COCO 2017 val dataset, our architecture significantly\n(approx. +8 pp. in mask AP) outperforms the baseline at different supervision\nregimes. To the best of our knowledge, this is one of the first works tackling\nthe problem of semi-supervised instance segmentation and the first one devoted\nto an anchor-free detector.",
    "descriptor": "",
    "authors": [
      "Dominik Filipiak",
      "Andrzej Zapa\u0142a",
      "Piotr Tempczyk",
      "Anna Fensel",
      "Marek Cygan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03850"
  },
  {
    "id": "arXiv:2211.03854",
    "title": "Exploration of Convolutional Neural Network Architectures for Large  Region Map Automation",
    "abstract": "Deep learning semantic segmentation algorithms have provided improved\nframeworks for the automated production of Land-Use and Land-Cover (LULC) maps,\nwhich significantly increases the frequency of map generation as well as\nconsistency of production quality. In this research, a total of 28 different\nmodel variations were examined to improve the accuracy of LULC maps. The\nexperiments were carried out using Landsat 5/7 or Landsat 8 satellite images\nwith the North American Land Change Monitoring System labels. The performance\nof various CNNs and extension combinations were assessed, where VGGNet with an\noutput stride of 4, and modified U-Net architecture provided the best results.\nAdditional expanded analysis of the generated LULC maps was also provided.\nUsing a deep neural network, this work achieved 92.4% accuracy for 13 LULC\nclasses within southern Manitoba representing a 15.8% improvement over\npublished results for the NALCMS. Based on the large regions of interest,\nhigher radiometric resolution of Landsat 8 data resulted in better overall\naccuracies (88.04%) compare to Landsat 5/7 (80.66%) for 16 LULC classes. This\nrepresents an 11.44% and 4.06% increase in overall accuracy compared to\npreviously published NALCMS results, including larger land area and higher\nnumber of LULC classes incorporated into the models compared to other published\nLULC map automation methods.",
    "descriptor": "",
    "authors": [
      "R. M. Tsenov",
      "C. J. Henry",
      "J. L. Storie",
      "C. D. Storie",
      "B. Murray",
      "M. Sokolov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03854"
  },
  {
    "id": "arXiv:2211.03856",
    "title": "User Engagement and the Toxicity of Tweets",
    "abstract": "Twitter is one of the most popular online micro-blogging and social\nnetworking platforms. This platform allows individuals to freely express\nopinions and interact with others regardless of geographic barriers. However,\nwith the good that online platforms offer, also comes the bad. Twitter and\nother social networking platforms have created new spaces for incivility. With\nthe growing interest on the consequences of uncivil behavior online,\nunderstanding how a toxic comment impacts online interactions is imperative. We\nanalyze a random sample of more than 85,300 Twitter conversations to examine\ndifferences between toxic and non-toxic conversations and the relationship\nbetween toxicity and user engagement. We find that toxic conversations, those\nwith at least one toxic tweet, are longer but have fewer individual users\ncontributing to the dialogue compared to the non-toxic conversations. However,\nwithin toxic conversations, toxicity is positively associated with more\nindividual Twitter users participating in conversations. This suggests that\noverall, more visible conversations are more likely to include toxic replies.\nAdditionally, we examine the sequencing of toxic tweets and its impact on\nconversations. Toxic tweets often occur as the main tweet or as the first\nreply, and lead to greater overall conversation toxicity. We also find a\nrelationship between the toxicity of the first reply to a toxic tweet and the\ntoxicity of the conversation, such that whether the first reply is toxic or\nnon-toxic sets the stage for the overall toxicity of the conversation,\nfollowing the idea that hate can beget hate.",
    "descriptor": "",
    "authors": [
      "Nazanin Salehabadi",
      "Anne Groggel",
      "Mohit Singhal",
      "Sayak Saha Roy",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.03856"
  },
  {
    "id": "arXiv:2211.03862",
    "title": "Looking at the Overlooked: An Analysis on the Word-Overlap Bias in  Natural Language Inference",
    "abstract": "It has been shown that NLI models are usually biased with respect to the\nword-overlap between premise and hypothesis; they take this feature as a\nprimary cue for predicting the entailment label. In this paper, we focus on an\noverlooked aspect of the overlap bias in NLI models: the reverse word-overlap\nbias. Our experimental results demonstrate that current NLI models are highly\nbiased towards the non-entailment label on instances with low overlap, and the\nexisting debiasing methods, which are reportedly successful on existing\nchallenge datasets, are generally ineffective in addressing this category of\nbias. We investigate the reasons for the emergence of the overlap bias and the\nrole of minority examples in its mitigation. For the former, we find that the\nword-overlap bias does not stem from pre-training, and for the latter, we\nobserve that in contrast to the accepted assumption, eliminating minority\nexamples does not affect the generalizability of debiasing methods with respect\nto the overlap bias.",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Sara Rajaee",
      "Yadollah Yaghoobzadeh",
      "Mohammad Taher Pilehvar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.03862"
  },
  {
    "id": "arXiv:2211.03872",
    "title": "Optimizing Wi-Fi Channel Selection in a Dense Neighborhood",
    "abstract": "In dense neighborhoods, there are often dozens of homes in close proximity.\nThis can either be a tight city-block with many single-family homes (SFHs), or\na multiple dwelling units (MDU) complex (such as a big apartment building or\ncondominium). Each home in such a neighborhood (either a SFH or a single unit\nin a MDU complex) has its own Wi-Fi access point (AP). Because there are few\n(typically 2 or 3) non-overlapping radio channels for Wi-Fi, neighboring homes\nmay find themselves sharing a channel and competing over airtime, which may\ncause bad experience of slow internet (long latency, buffering while streaming\nmovies, etc.). Wi-Fi optimization over all the APs in a dense neighborhood is\nhighly desired to provide the best user experience.\nWe present a method for Wi-Fi channel selection in a centralized way for all\nthe APs in a dense neighborhood. We describe how to use recent observations to\nestimate the potential-pain matrix - for each pair of APs, how much Wi-Fi-pain\nwould they cause each other if they were on the same channel. We formulate an\noptimization problem - finding a channel allocation (which channel each home\nshould use) that minimizes the total Wi-Fi-pain in the neighborhood. We design\nan optimization algorithm that uses gradient descent over a neural network to\nsolve the optimization problem. We describe initial results from offline\nexperiments comparing our optimization solver to an off-the-shelf\nmixed-integer-programming solver. In our experiments we show that the\noff-the-shelf solver manages to find a better (lower total pain) solution on\nthe train data (from the recent days), but our neural-network solver\ngeneralizes better - it finds a solution that achieves lower total pain for the\ntest data (tomorrow).",
    "descriptor": "\nComments: We discussed this work in the 2022 Fall Technical Forum as part of SCTE Cable-Tec Expo. This paper was published in SCTE Technical Journal. For citing this work, please cite the original publication\n",
    "authors": [
      "Yonatan Vaizman",
      "Hongcheng Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.03872"
  },
  {
    "id": "arXiv:2211.03874",
    "title": "Nearly optimal independence oracle algorithms for edge estimation in  hypergraphs",
    "abstract": "We study a query model of computation in which an n-vertex k-hypergraph can\nbe accessed only via its independence oracle or via its colourful independence\noracle, and each oracle query may incur a cost depending on the size of the\nquery. In each of these models, we obtain oracle algorithms to approximately\ncount the hypergraph's edges, and we unconditionally prove that no oracle\nalgorithm for this problem can have significantly smaller worst-case oracle\ncost than our algorithms.",
    "descriptor": "",
    "authors": [
      "Holger Dell",
      "John Lapinskas",
      "Kitty Meeks"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.03874"
  },
  {
    "id": "arXiv:2211.03876",
    "title": "CoNMix for Source-free Single and Multi-target Domain Adaptation",
    "abstract": "This work introduces the novel task of Source-free Multi-target Domain\nAdaptation and proposes adaptation framework comprising of \\textbf{Co}nsistency\nwith \\textbf{N}uclear-Norm Maximization and \\textbf{Mix}Up knowledge\ndistillation (\\textit{CoNMix}) as a solution to this problem.\nThe main motive of this work is to solve for Single and Multi target Domain\nAdaptation (SMTDA) for the source-free paradigm, which enforces a constraint\nwhere the labeled source data is not available during target adaptation due to\nvarious privacy-related restrictions on data sharing. The source-free approach\nleverages target pseudo labels, which can be noisy, to improve the target\nadaptation. We introduce consistency between label preserving augmentations and\nutilize pseudo label refinement methods to reduce noisy pseudo labels. Further,\nwe propose novel MixUp Knowledge Distillation (MKD) for better generalization\non multiple target domains using various source-free STDA models.\nWe also show that the Vision Transformer (VT) backbone gives better feature\nrepresentation with improved domain transferability and class discriminability.\nOur proposed framework achieves the state-of-the-art (SOTA) results in various\nparadigms of source-free STDA and MTDA settings on popular domain adaptation\ndatasets like Office-Home, Office-Caltech, and DomainNet. Project Page:\nhttps://sites.google.com/view/conmix-vcl",
    "descriptor": "\nComments: Accepted at WACV 2023\n",
    "authors": [
      "Vikash Kumar",
      "Rohit Lal",
      "Himanshu Patil",
      "Anirban Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03876"
  },
  {
    "id": "arXiv:2211.03877",
    "title": "The Need for Seed (in the abstract Tile Assembly Model)",
    "abstract": "In the abstract Tile Assembly Model (aTAM) square tiles self-assemble,\nautonomously binding via glues on their edges, to form structures. Algorithmic\naTAM systems can be designed in which the patterns of tile attachments are\nforced to follow the execution of targeted algorithms. Such systems have been\nproven to be computationally universal as well as intrinsically universal (IU),\na notion borrowed and adapted from cellular automata showing that a single tile\nset exists which is capable of simulating all aTAM systems (FOCS 2012). The\ninput to an algorithmic aTAM system can be provided in a variety of ways, with\na common method being via the ``seed'' assembly, which is a pre-formed assembly\nfrom which all growth propagates. In this paper we present a series of results\nwhich investigate the the trade-offs of using seeds consisting of a single\ntile, versus those containing multiple tiles. We show that arbitrary systems\nwith multi-tile seeds cannot be converted to functionally equivalent systems\nwith single-tile seeds without using a scale factor > 1. We prove tight bounds\non the scale factor required, and also present a construction which uses a\nlarge scale factor but an optimal number of unique tile types. That\nconstruction is then used to develop a construction that performs simultaneous\nsimulation of all aTAM systems in parallel, as well as to display a connection\nto other tile-based self-assembly models via the notion of intrinsic\nuniversality.",
    "descriptor": "\nComments: To appear in the SODA 2023 proceedings\n",
    "authors": [
      "Andrew Alseth",
      "Matthew J. Patitz"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.03877"
  },
  {
    "id": "arXiv:2211.03878",
    "title": "EEG-Fest: Few-shot based Attention Network for Driver's Vigilance  Estimation with EEG Signals",
    "abstract": "A lack of driver's vigilance is the main cause of most vehicle crashes.\nElectroencephalography(EEG) has been reliable and efficient tool for drivers'\ndrowsiness estimation. Even though previous studies have developed accurate and\nrobust driver's vigilance detection algorithms, these methods are still facing\nchallenges on following areas: (a) small sample size training, (b) anomaly\nsignal detection, and (c) subject-independent classification. In this paper, we\npropose a generalized few-shot model, namely EEG-Fest, to improve\naforementioned drawbacks. The EEG-Fest model can (a) classify the query\nsample's drowsiness with a few samples, (b) identify whether a query sample is\nanomaly signals or not, and (c) achieve subject independent classification. The\nproposed algorithm achieves state-of-the-art results on the SEED-VIG dataset\nand the SADT dataset. The accuracy of the drowsy class achieves 92% and 94% for\n1-shot and 5-shot support samples in the SEED-VIG dataset, and 62% and 78% for\n1-shot and 5-shot support samples in the SADT dataset.",
    "descriptor": "\nComments: Submitted to peer review journal for review\n",
    "authors": [
      "Ning Ding",
      "Ce Zhang",
      "Azim Eskandarian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.03878"
  },
  {
    "id": "arXiv:2211.03880",
    "title": "NSNet: A General Neural Probabilistic Framework for Satisfiability  Problems",
    "abstract": "We present the Neural Satisfiability Network (NSNet), a general neural\nframework that models satisfiability problems as probabilistic inference and\nmeanwhile exhibits proper explainability. Inspired by the Belief Propagation\n(BP), NSNet uses a novel graph neural network (GNN) to parameterize BP in the\nlatent space, where its hidden representations maintain the same probabilistic\ninterpretation as BP. NSNet can be flexibly configured to solve both SAT and\n#SAT problems by applying different learning objectives. For SAT, instead of\ndirectly predicting a satisfying assignment, NSNet performs marginal inference\namong all satisfying solutions, which we empirically find is more feasible for\nneural networks to learn. With the estimated marginals, a satisfying assignment\ncan be efficiently generated by rounding and executing a stochastic local\nsearch. For #SAT, NSNet performs approximate model counting by learning the\nBethe approximation of the partition function. Our evaluations show that NSNet\nachieves competitive results in terms of inference accuracy and time efficiency\non multiple SAT and #SAT datasets.",
    "descriptor": "",
    "authors": [
      "Zhaoyu Li",
      "Xujie Si"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03880"
  },
  {
    "id": "arXiv:2211.03882",
    "title": "Latent Neural ODE for Integrating Multi-timescale measurements in Smart  Distribution Grids",
    "abstract": "Under a smart grid paradigm, there has been an increase in sensor\ninstallations to enhance situational awareness. The measurements from these\nsensors can be leveraged for real-time monitoring, control, and protection.\nHowever, these measurements are typically irregularly sampled. These\nmeasurements may also be intermittent due to communication bandwidth\nlimitations. To tackle this problem, this paper proposes a novel latent neural\nordinary differential equations (LODE) approach to aggregate the unevenly\nsampled multivariate time-series measurements. The proposed approach is\nflexible in performing both imputations and predictions while being\ncomputationally efficient. Simulation results on IEEE 37 bus test systems\nillustrate the efficiency of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Shweta Dahale",
      "Sai Munikoti",
      "Balasubramaniam Natarajan",
      "Rui Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.03882"
  },
  {
    "id": "arXiv:2211.03883",
    "title": "Approximating Nash Social Welfare by Matching and Local Search",
    "abstract": "For any $\\varepsilon>0$, we give a simple, deterministic\n$(6+\\varepsilon)$-approximation algorithm for the Nash social welfare (NSW)\nproblem under submodular valuations. The previous best approximation factor was\n$380$ via a randomized algorithm. We also consider the asymmetric variant of\nthe problem, where the objective is to maximize the weighted geometric mean of\nagents' valuations, and give an $(\\omega + 2 +\\varepsilon) e$-approximation if\nthe ratio between the largest weight and the average weight is at most\n$\\omega$.\nWe also show that the $1/2$-EFX envy-freeness property can be attained\nsimultaneously with a constant-factor approximation. More precisely, we can\nfind an allocation in polynomial time which is both $1/2$-EFX and a\n$(12+\\varepsilon)$-approximation to the symmetric NSW problem under submodular\nvaluations. The previous best approximation factor under $1/2$-EFX was linear\nin the number of agents.",
    "descriptor": "\nComments: 28 pages, 1 figure\n",
    "authors": [
      "Jugal Garg",
      "Edin Husi\u0107",
      "Wenzheng Li",
      "L\u00e1szl\u00f3 A. V\u00e9gh",
      "Jan Vondr\u00e1k"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.03883"
  },
  {
    "id": "arXiv:2211.03885",
    "title": "Learned Smartphone ISP on Mobile GPUs with Deep Learning, Mobile AI &  AIM 2022 Challenge: Report",
    "abstract": "The role of mobile cameras increased dramatically over the past few years,\nleading to more and more research in automatic image quality enhancement and\nRAW photo processing. In this Mobile AI challenge, the target was to develop an\nefficient end-to-end AI-based image signal processing (ISP) pipeline replacing\nthe standard mobile ISPs that can run on modern smartphone GPUs using\nTensorFlow Lite. The participants were provided with a large-scale Fujifilm\nUltraISP dataset consisting of thousands of paired photos captured with a\nnormal mobile camera sensor and a professional 102MP medium-format FujiFilm\nGFX100 camera. The runtime of the resulting models was evaluated on the\nSnapdragon's 8 Gen 1 GPU that provides excellent acceleration results for the\nmajority of common deep learning ops. The proposed solutions are compatible\nwith all recent mobile GPUs, being able to process Full HD photos in less than\n20-50 milliseconds while achieving high fidelity results. A detailed\ndescription of all models developed in this challenge is provided in this\npaper.",
    "descriptor": "",
    "authors": [
      "Andrey Ignatov",
      "Radu Timofte",
      "Shuai Liu",
      "Chaoyu Feng",
      "Furui Bai",
      "Xiaotao Wang",
      "Lei Lei",
      "Ziyao Yi",
      "Yan Xiang",
      "Zibin Liu",
      "Shaoqing Li",
      "Keming Shi",
      "Dehui Kong",
      "Ke Xu",
      "Minsu Kwon",
      "Yaqi Wu",
      "Jiesi Zheng",
      "Zhihao Fan",
      "Xun Wu",
      "Feng Zhang",
      "Albert No",
      "Minhyeok Cho",
      "Zewen Chen",
      "Xiaze Zhang",
      "Ran Li",
      "Juan Wang",
      "Zhiming Wang",
      "Marcos V. Conde",
      "Ui-Jin Choi",
      "Georgy Perevozchikov",
      "Egor Ershov",
      "Zheng Hui",
      "Mengchuan Dong",
      "Xin Lou",
      "Wei Zhou",
      "Cong Pang",
      "Haina Qin",
      "Mingxuan Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03885"
  },
  {
    "id": "arXiv:2211.03888",
    "title": "Proceedings of Principle and practice of data and Knowledge Acquisition  Workshop 2022 (PKAW 2022)",
    "abstract": "Over the past two decades, PKAW has provided a forum for researchers and\npractitioners to discuss the state-of-the-arts in the area of knowledge\nacquisition and machine intelligence (MI, also Artificial Intelligence, AI).\nPKAW2022 will continue the above focus and welcome the contributions on the\nmulti-disciplinary approach of human and big data-driven knowledge acquisition,\nas well as AI techniques and applications.",
    "descriptor": "\nComments: Proceedings of Principle and practice of data and Knowledge Acquisition Workshop 2022 (PKAW 2022)\n",
    "authors": [
      "Qing Liu",
      "Wenli Yang",
      "Shiqing Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.03888"
  },
  {
    "id": "arXiv:2211.03889",
    "title": "Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable  Categories",
    "abstract": "Obtaining photorealistic reconstructions of objects from sparse views is\ninherently ambiguous and can only be achieved by learning suitable\nreconstruction priors. Earlier works on sparse rigid object reconstruction\nsuccessfully learned such priors from large datasets such as CO3D. In this\npaper, we extend this approach to dynamic objects. We use cats and dogs as a\nrepresentative example and introduce Common Pets in 3D (CoP3D), a collection of\ncrowd-sourced videos showing around 4,200 distinct pets. CoP3D is one of the\nfirst large-scale datasets for benchmarking non-rigid 3D reconstruction \"in the\nwild\". We also propose Tracker-NeRF, a method for learning 4D reconstruction\nfrom our dataset. At test time, given a small number of video frames of an\nunseen object, Tracker-NeRF predicts the trajectories of its 3D points and\ngenerates new views, interpolating viewpoint and time. Results on CoP3D reveal\nsignificantly better non-rigid new-view synthesis performance than existing\nbaselines.",
    "descriptor": "",
    "authors": [
      "Samarth Sinha",
      "Roman Shapovalov",
      "Jeremy Reizenstein",
      "Ignacio Rocco",
      "Natalia Neverova",
      "Andrea Vedaldi",
      "David Novotny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03889"
  },
  {
    "id": "arXiv:2211.03890",
    "title": "Humans decompose tasks by trading off utility and computational cost",
    "abstract": "Human behavior emerges from planning over elaborate decompositions of tasks\ninto goals, subgoals, and low-level actions. How are these decompositions\ncreated and used? Here, we propose and evaluate a normative framework for task\ndecomposition based on the simple idea that people decompose tasks to reduce\nthe overall cost of planning while maintaining task performance. Analyzing\n11,117 distinct graph-structured planning tasks, we find that our framework\njustifies several existing heuristics for task decomposition and makes\npredictions that can be distinguished from two alternative normative accounts.\nWe report a behavioral study of task decomposition ($N=806$) that uses 30\nrandomly sampled graphs, a larger and more diverse set than that of any\nprevious behavioral study on this topic. We find that human responses are more\nconsistent with our framework for task decomposition than alternative normative\naccounts and are most consistent with a heuristic -- betweenness centrality --\nthat is justified by our approach. Taken together, our results provide new\ntheoretical insight into the computational principles underlying the\nintelligent structuring of goal-directed behavior.",
    "descriptor": "",
    "authors": [
      "Carlos G. Correa",
      "Mark K. Ho",
      "Frederick Callaway",
      "Nathaniel D. Daw",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.03890"
  },
  {
    "id": "arXiv:2211.03891",
    "title": "A deterministic near-linear time approximation scheme for geometric  transportation",
    "abstract": "Given a set of points $P = (P^+ \\sqcup P^-) \\subset \\mathbb{R}^d$ for some\nconstant $d$ and a supply function $\\mu:P\\to \\mathbb{R}$ such that $\\mu(p) >\n0~\\forall p \\in P^+$, $\\mu(p) < 0~\\forall p \\in P^-$, and $\\sum_{p\\in\nP}{\\mu(p)} = 0$, the geometric transportation problem asks one to find a\ntransportation map $\\tau: P^+\\times P^-\\to \\mathbb{R}_{\\ge 0}$ such that\n$\\sum_{q\\in P^-}{\\tau(p, q)} = \\mu(p)~\\forall p \\in P^+$, $\\sum_{p\\in\nP^+}{\\tau(p, q)} = -\\mu(q)~ \\forall q \\in P^-$, and the weighted sum of\nEuclidean distances for the pairs $\\sum_{(p,q)\\in P^+\\times P^-}\\tau(p, q)\\cdot\n||q-p||_2$ is minimized. We present the first deterministic algorithm that\ncomputes, in near-linear time, a transportation map whose cost is within a $(1\n+ \\varepsilon)$ factor of optimal. More precisely, our algorithm runs in\n$O(n\\varepsilon^{-(d+2)}\\log^5{n}\\log{\\log{n}})$ time for any constant\n$\\varepsilon > 0$. While a randomized $n\\varepsilon^{-O(d)}\\log^{O(d)}{n}$ time\nalgorithm was discovered in the last few years, all previously known\ndeterministic $(1 + \\varepsilon)$-approximation algorithms run in\n$\\Omega(n^{3/2})$ time. A similar situation existed for geometric bipartite\nmatching, the special case of geometric transportation where all supplies are\nunit, until a deterministic $n\\varepsilon^{-O(d)}\\log^{O(d)}{n}$ time $(1 +\n\\varepsilon)$-approximation algorithm was presented at STOC 2022. Surprisingly,\nour result is not only a generalization of the bipartite matching one to\narbitrary instances of geometric transportation, but it also reduces the\nrunning time for all previously known $(1 + \\varepsilon)$-approximation\nalgorithms, randomized or deterministic, even for geometric bipartite matching,\nby removing the dependence on the dimension $d$ from the exponent in the\nrunning time's polylog.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Kyle Fox",
      "Jiashuai Lu"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.03891"
  },
  {
    "id": "arXiv:2211.03893",
    "title": "Query Complexity of the Metric Steiner Tree Problem",
    "abstract": "We study the query complexity of the metric Steiner Tree problem, where we\nare given an $n \\times n$ metric on a set $V$ of vertices along with a set $T\n\\subseteq V$ of $k$ terminals, and the goal is to find a tree of minimum cost\nthat contains all terminals in $T$. The query complexity for the related\nminimum spanning tree (MST) problem is well-understood: for any fixed\n$\\varepsilon > 0$, one can estimate the MST cost to within a\n$(1+\\varepsilon)$-factor using only $\\tilde{O}(n)$ queries, and this is known\nto be tight. This implies that a $(2 + \\varepsilon)$-approximate estimate of\nSteiner Tree cost can be obtained with $\\tilde{O}(k)$ queries by simply\napplying the MST cost estimation algorithm on the metric induced by the\nterminals.\nOur first result shows that any (randomized) algorithm that estimates the\nSteiner Tree cost to within a $(5/3 - \\varepsilon)$-factor requires\n$\\Omega(n^2)$ queries, even if $k$ is a constant. This lower bound is in sharp\ncontrast to an upper bound of $O(nk)$ queries for computing a\n$(5/3)$-approximate Steiner Tree, which follows from previous work by Du and\nZelikovsky.\nOur second main result, and the main technical contribution of this work, is\na sublinear query algorithm for estimating the Steiner Tree cost to within a\nstrictly better-than-$2$ factor, with query complexity $\\tilde{O}(n^{12/7} +\nn^{6/7}\\cdot k)=\\tilde{O}(n^{13/7})=o(n^2)$. We complement this result by\nshowing an $\\tilde{\\Omega}(n + k^{6/5})$ query lower bound for any algorithm\nthat estimates Steiner Tree cost to a strictly better than $2$ factor. Thus\n$\\tilde{\\Omega}(n^{6/5})$ queries are needed to just beat $2$-approximation\nwhen $k = \\Omega(n)$; a sharp contrast to MST cost estimation where a\n$(1+o(1))$-approximate estimate of cost is achievable with only $\\tilde{O}(n)$\nqueries.",
    "descriptor": "",
    "authors": [
      "Yu Chen",
      "Sanjeev Khanna",
      "Zihan Tan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.03893"
  },
  {
    "id": "arXiv:2211.03894",
    "title": "visClust: A visual clustering algorithm based on orthogonal projections",
    "abstract": "We present a novel clustering algorithm, visClust, that is based on lower\ndimensional data representations and visual interpretation. Thereto, we design\na transformation that allows the data to be represented by a binary integer\narray enabling the further use of image processing methods to select a\npartition. Qualitative and quantitative analyses show that the algorithm\nobtains high accuracy (measured with an adjusted one-sided Rand-Index) and\nrequires low runtime and RAM. We compare the results to 6 state-of-the-art\nalgorithms, confirming the quality of visClust by outperforming in most\nexperiments. Moreover, the algorithm asks for just one obligatory input\nparameter while allowing optimization via optional parameters. The code is made\navailable on GitHub.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Anna Breger",
      "Clemens Karner",
      "Martin Ehler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03894"
  },
  {
    "id": "arXiv:2211.03895",
    "title": "Facial Tic Detection in Untrimmed Videos of Tourette Syndrome Patients",
    "abstract": "Tourette Syndrome (TS) is a behavior disorder that onsets in childhood and is\ncharacterized by the expression of involuntary movements and sounds commonly\nreferred to as tics. Behavioral therapy is the first-line treatment for\npatients with TS, and it helps patients raise awareness about tic occurrence as\nwell as develop tic inhibition strategies. However, the limited availability of\ntherapists and the difficulties for in-home follow up work limits its\neffectiveness. An automatic tic detection system that is easy to deploy could\nalleviate the difficulties of home-therapy by providing feedback to the\npatients while exercising tic awareness. In this work, we propose a novel\narchitecture (T-Net) for automatic tic detection and classification from\nuntrimmed videos. T-Net combines temporal detection and segmentation and\noperates on features that are interpretable to a clinician. We compare T-Net to\nseveral state-of-the-art systems working on deep features extracted from the\nraw videos and T-Net achieves comparable performance in terms of average\nprecision while relying on interpretable features needed in clinical practice.",
    "descriptor": "",
    "authors": [
      "Yutao Tang",
      "Benjam\u00edn B\u00e9jar",
      "Joey K.-Y. Essoe",
      "Joseph F. McGuire",
      "Ren\u00e9 Vidal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03895"
  },
  {
    "id": "arXiv:2211.03898",
    "title": "Lessons Learned: Surveying the Practicality of Differential Privacy in  the Industry",
    "abstract": "Since its introduction in 2006, differential privacy has emerged as a\npredominant statistical tool for quantifying data privacy in academic works.\nYet despite the plethora of research and open-source utilities that have\naccompanied its rise, with limited exceptions, differential privacy has failed\nto achieve widespread adoption in the enterprise domain. Our study aims to shed\nlight on the fundamental causes underlying this academic-industrial utilization\ngap through detailed interviews of 24 privacy practitioners across 9 major\ncompanies. We analyze the results of our survey to provide key findings and\nsuggestions for companies striving to improve privacy protection in their data\nworkflows and highlight the necessary and missing requirements of existing\ndifferential privacy tools, with the goal of guiding researchers working\ntowards the broader adoption of differential privacy. Our findings indicate\nthat analysts suffer from lengthy bureaucratic processes for requesting access\nto sensitive data, yet once granted, only scarcely-enforced privacy policies\nstand between rogue practitioners and misuse of private information. We thus\nargue that differential privacy can significantly improve the processes of\nrequesting and conducting data exploration across silos, and conclude that with\na few of the improvements suggested herein, the practical use of differential\nprivacy across the enterprise is within striking distance.",
    "descriptor": "",
    "authors": [
      "Gonzalo Munilla Garrido",
      "Xiaoyuan Liu",
      "Florian Matthes",
      "Dawn Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.03898"
  },
  {
    "id": "arXiv:2211.03900",
    "title": "SLICT: Multi-input Multi-scale Surfel-Based Lidar-Inertial  Continuous-Time Odometry and Mapping",
    "abstract": "While feature association to a global map has significant benefits, to keep\nthe computations from growing exponentially, most lidar-based odometry and\nmapping methods opt to associate features with local maps at one voxel scale.\nTaking advantage of the fact that surfels (surface elements) at different voxel\nscales can be organized in a tree-like structure, we propose an octree-based\nglobal map of multi-scale surfels that can be updated incrementally. This\nalleviates the need for recalculating, for example, a k-d tree of the whole map\nrepeatedly. The system can also take input from a single or a number of\nsensors, reinforcing the robustness in degenerate cases. We also propose a\npoint-to-surfel (PTS) association scheme, continuous-time optimization on PTS\nand IMU preintegration factors, along with loop closure and bundle adjustment,\nmaking a complete framework for Lidar-Inertial continuous-time odometry and\nmapping. Experiments on public and in-house datasets demonstrate the advantages\nof our system compared to other state-of-the-art methods. To benefit the\ncommunity, we release the source code and dataset at\nhttps://github.com/brytsknguyen/slict.",
    "descriptor": "",
    "authors": [
      "Thien-Minh Nguyen",
      "Daniel Duberg",
      "Patric Jensfelt",
      "Shenghai Yuan",
      "Lihua Xie"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.03900"
  },
  {
    "id": "arXiv:2211.03905",
    "title": "Dynamics of Gender Bias in Computing",
    "abstract": "Gender bias in computing is a hard problem that has resisted decades of\nresearch. One obstacle has been the absence of systematic data that might\nindicate when gender bias emerged in computing and how it has changed. This\narticle presents a new dataset (N=50,000) focusing on formative years of\ncomputing as a profession (1950-1980) when U.S. government workforce statistics\nare thin or non-existent. This longitudinal dataset, based on archival records\nfrom six computer user groups (SHARE, USE, and others) and ACM conference\nattendees and membership rosters, revises commonly held conjectures that gender\nbias in computing emerged during professionalization of computer science in the\n1960s or 1970s and that there was a 'linear' one-time onset of gender bias to\nthe present. Such a linear view also lent support to the \"pipeline\" model of\ncomputing's \"losing\" women at successive career stages. Instead, this dataset\nreveals three distinct periods of gender bias in computing and so invites\ntemporally distinct explanations for these changing dynamics. It significantly\nrevises both scholarly assessment and popular understanding about gender bias\nin computing. It also draws attention to diversity within computing. One\nconsequence of this research for CS reform efforts today is data-driven\nrecognition that legacies of gender bias beginning in the mid-1980s (not in\nearlier decades) is the problem. A second consequence is correcting the public\nimage of computer science: this research shows that gender bias is a contingent\naspect of professional computing, not an intrinsic or permanent one.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Thomas J Misa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.03905"
  },
  {
    "id": "arXiv:2211.03911",
    "title": "Towards Extending the Range of Bugs That Automated Program Repair Can  Handle",
    "abstract": "Modern automated program repair (APR) is well-tuned to finding and repairing\nbugs that introduce observable erroneous behavior to a program. However, a\nsignificant class of bugs does not lead to such observable behavior (e.g.,\nliveness/termination bugs, non-functional bugs, and information flow bugs).\nSuch bugs can generally not be handled with current APR approaches, so, as a\ncommunity, we need to develop complementary techniques.\nTo stimulate the systematic study of alternative APR approaches and hybrid\nAPR combinations, we devise a novel bug classification system that enables\nmethodical analysis of their bug detection power and bug repair capabilities.\nTo demonstrate the benefits, we analyze the repair of termination bugs in\nsequential and concurrent programs. The study shows that integrating dynamic\nAPR with formal analysis techniques, such as termination provers and software\nmodel checkers, reduces complexity and improves the overall reliability of\nthese repairs.",
    "descriptor": "\nComments: Accepted for publication in the 22nd IEEE International Conference on Software Quality, Reliability and Security (QRS 2022)\n",
    "authors": [
      "Omar I. Al-Bataineh",
      "Leon Moonen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.03911"
  },
  {
    "id": "arXiv:2211.03916",
    "title": "Streaming beyond sketching for Maximum Directed Cut",
    "abstract": "We give an $\\widetilde{O}(\\sqrt{n})$-space single-pass $0.483$-approximation\nstreaming algorithm for estimating the maximum directed cut size\n($\\textsf{Max-DICUT}$) in a directed graph on $n$ vertices. This improves over\nan $O(\\log n)$-space $4/9 < 0.45$ approximation algorithm due to Chou,\nGolovnev, Velusamy (FOCS 2020), which was known to be optimal for\n$o(\\sqrt{n})$-space algorithms.\n$\\textsf{Max-DICUT}$ is a special case of a constraint satisfaction problem\n(CSP). In this broader context, our work gives the first CSP for which\nalgorithms with $\\widetilde{O}(\\sqrt{n})$ space can provably outperform\n$o(\\sqrt{n})$-space algorithms on general instances. Previously, this was shown\nin the restricted case of bounded-degree graphs in a previous work of the\nauthors (SODA 2023). Prior to that work, the only algorithms for any CSP were\nbased on generalizations of the $O(\\log n)$-space algorithm for\n$\\textsf{Max-DICUT}$, and were in particular so-called \"sketching\" algorithms.\nIn this work, we demonstrate that more sophisticated streaming algorithms can\noutperform these algorithms even on general instances.\nOur algorithm constructs a \"snapshot\" of the graph and then applies a result\nof Feige and Jozeph (Algorithmica, 2015) to approximately estimate the\n$\\textsf{Max-DICUT}$ value from this snapshot. Constructing this snapshot is\neasy for bounded-degree graphs and the main contribution of our work is to\nconstruct this snapshot in the general setting. This involves some delicate\nsampling methods as well as a host of \"continuity\" results on the\n$\\textsf{Max-DICUT}$ behaviour in graphs.",
    "descriptor": "\nComments: 57 pages, 2 figures\n",
    "authors": [
      "Raghuvansh R. Saxena",
      "Noah Singer",
      "Madhu Sudan",
      "Santhoshini Velusamy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.03916"
  },
  {
    "id": "arXiv:2211.03917",
    "title": "On the amortized complexity of approximate counting",
    "abstract": "Naively storing a counter up to value $n$ would require $\\Omega(\\log n)$ bits\nof memory. Nelson and Yu [NY22], following work of [Morris78], showed that if\nthe query answers need only be $(1+\\epsilon)$-approximate with probability at\nleast $1 - \\delta$, then $O(\\log\\log n + \\log\\log(1/\\delta) +\n\\log(1/\\epsilon))$ bits suffice, and in fact this bound is tight. Morris'\noriginal motivation for studying this problem though, as well as modern\napplications, require not only maintaining one counter, but rather $k$ counters\nfor $k$ large. This motivates the following question: for $k$ large, can $k$\ncounters be simultaneously maintained using asymptotically less memory than $k$\ntimes the cost of an individual counter? That is to say, does this problem\nbenefit from an improved {\\it amortized} space complexity bound?\nWe answer this question in the negative. Specifically, we prove a lower bound\nfor nearly the full range of parameters showing that, in terms of memory usage,\nthere is no asymptotic benefit possible via amortization when storing multiple\ncounters. Our main proof utilizes a certain notion of \"information cost\"\nrecently introduced by Braverman, Garg and Woodruff in FOCS 2020 to prove lower\nbounds for streaming algorithms.",
    "descriptor": "",
    "authors": [
      "Ishaq Aden-Ali",
      "Yanjun Han",
      "Jelani Nelson",
      "Huacheng Yu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.03917"
  },
  {
    "id": "arXiv:2211.03919",
    "title": "ShaSTA: Modeling Shape and Spatio-Temporal Affinities for 3D  Multi-Object Tracking",
    "abstract": "Multi-object tracking is a cornerstone capability of any robotic system. Most\napproaches follow a tracking-by-detection paradigm. However, within this\nframework, detectors function in a low precision-high recall regime, ensuring a\nlow number of false-negatives while producing a high rate of false-positives.\nThis can negatively affect the tracking component by making data association\nand track lifecycle management more challenging. Additionally, false-negative\ndetections due to difficult scenarios like occlusions can negatively affect\ntracking performance. Thus, we propose a method that learns shape and\nspatio-temporal affinities between consecutive frames to better distinguish\nbetween true-positive and false-positive detections and tracks, while\ncompensating for false-negative detections. Our method provides a probabilistic\nmatching of detections that leads to robust data association and track\nlifecycle management. We quantitatively evaluate our method through ablative\nexperiments and on the nuScenes tracking benchmark where we achieve\nstate-of-the-art results. Our method not only estimates accurate, high-quality\ntracks but also decreases the overall number of false-positive and\nfalse-negative tracks. Please see our project website for source code and demo\nvideos: sites.google.com/view/shasta-3d-mot/home.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Tara Sadjadpour",
      "Jie Li",
      "Rares Ambrus",
      "Jeannette Bohg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03919"
  },
  {
    "id": "arXiv:2211.03920",
    "title": "Distributed Computing for Scalable Optimal Power Flow in Large Radial  Electric Power Distribution Systems with Distributed Energy Resources",
    "abstract": "Solving the non-convex optimal power flow (OPF) problem for large-scale power\ndistribution systems is computationally expensive. An alternative is to solve\nthe relaxed convex problem or linear approximated problem, but these methods\nlead to sub-optimal or power flow infeasible solutions. In this paper, we\npropose a fast method to solve the OPF problem using distributed computing\nalgorithms combined with a decomposition technique. The full network-level OPF\nproblem is decomposed into multiple smaller sub-problems defined for each\ndecomposed area or node that can be easily solved using off-the-shelf nonlinear\nprogramming (NLP) solvers. Distributed computing approach is proposed via which\nsub-problems achieve consensus and converge to network-level optimal solutions.\nThe novelty lies in leveraging the nature of power flow equations in radial\nnetwork topologies to design effective decomposition techniques that reduce the\nnumber of iterations required to achieve consensus by an order of magnitude.",
    "descriptor": "",
    "authors": [
      "Rabayet Sadnan",
      "Anamika Dubey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.03920"
  },
  {
    "id": "arXiv:2211.03922",
    "title": "Strictly Breadth-First AMR Parsing",
    "abstract": "AMR parsing is the task that maps a sentence to an AMR semantic graph\nautomatically. We focus on the breadth-first strategy of this task, which was\nproposed recently and achieved better performance than other strategies.\nHowever, current models under this strategy only \\emph{encourage} the model to\nproduce the AMR graph in breadth-first order, but \\emph{cannot guarantee} this.\nTo solve this problem, we propose a new architecture that \\emph{guarantees}\nthat the parsing will strictly follow the breadth-first order. In each parsing\nstep, we introduce a \\textbf{focused parent} vertex and use this vertex to\nguide the generation. With the help of this new architecture and some other\nimprovements in the sentence and graph encoder, our model obtains better\nperformance on both the AMR 1.0 and 2.0 dataset.",
    "descriptor": "",
    "authors": [
      "Chen Yu",
      "Daniel Gildea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.03922"
  },
  {
    "id": "arXiv:2211.03923",
    "title": "Proactive Detractor Detection Framework Based on Message-Wise Sentiment  Analysis Over Customer Support Interactions",
    "abstract": "In this work, we propose a framework relying solely on chat-based customer\nsupport (CS) interactions for predicting the recommendation decision of\nindividual users. For our case study, we analyzed a total number of 16.4k users\nand 48.7k customer support conversations within the financial vertical of a\nlarge e-commerce company in Latin America. Consequently, our main contributions\nand objectives are to use Natural Language Processing (NLP) to assess and\npredict the recommendation behavior where, in addition to using static\nsentiment analysis, we exploit the predictive power of each user's sentiment\ndynamics. Our results show that, with respective feature interpretability, it\nis possible to predict the likelihood of a user to recommend a product or\nservice, based solely on the message-wise sentiment evolution of their CS\nconversations in a fully automated way.",
    "descriptor": "\nComments: 10 pages, 4 figures, 1 table. Already accepted at NeurIPS 2022, LatinX in AI Workshop\n",
    "authors": [
      "Juan Sebasti\u00e1n Salcedo Gallo",
      "Jes\u00fas Solano",
      "Javier Hern\u00e1n Garc\u00eda",
      "David Zarruk-Valencia",
      "Alejandro Correa-Bahnsen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03923"
  },
  {
    "id": "arXiv:2211.03925",
    "title": "AutoML-based Almond Yield Prediction and Projection in California",
    "abstract": "Almonds are one of the most lucrative products of California, but are also\namong the most sensitive to climate change. In order to better understand the\nrelationship between climatic factors and almond yield, an automated machine\nlearning framework is used to build a collection of machine learning models.\nThe prediction skill is assessed using historical records. Future projections\nare derived using 17 downscaled climate outputs. The ensemble mean projection\ndisplays almond yield changes under two different climate scenarios, along with\ntwo technology development scenarios, where the role of technology development\nis highlighted. The mean projections and distributions provide insightful\nresults to stakeholders and can be utilized by policymakers for climate\nadaptation.",
    "descriptor": "\nComments: Submitted to Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022\n",
    "authors": [
      "Shiheng Duan",
      "Shuaiqi Wu",
      "Erwan Monier",
      "Paul Ullrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.03925"
  },
  {
    "id": "arXiv:2211.03927",
    "title": "Automatic Error Detection in Integrated Circuits Image Segmentation: A  Data-driven Approach",
    "abstract": "Due to the complicated nanoscale structures of current integrated\ncircuits(IC) builds and low error tolerance of IC image segmentation tasks,\nmost existing automated IC image segmentation approaches require human experts\nfor visual inspection to ensure correctness, which is one of the major\nbottlenecks in large-scale industrial applications. In this paper, we present\nthe first data-driven automatic error detection approach targeting two types of\nIC segmentation errors: wire errors and via errors. On an IC image dataset\ncollected from real industry, we demonstrate that, by adapting existing\nCNN-based approaches of image classification and image translation with\nadditional pre-processing and post-processing techniques, we are able to\nachieve recall/precision of 0.92/0.93 in wire error detection and 0.96/0.90 in\nvia error detection, respectively.",
    "descriptor": "",
    "authors": [
      "Zhikang Zhang",
      "Bruno Machado Trindade",
      "Michael Green",
      "Zifan Yu",
      "Christopher Pawlowicz",
      "Fengbo Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03927"
  },
  {
    "id": "arXiv:2211.03928",
    "title": "Editable indoor lighting estimation",
    "abstract": "We present a method for estimating lighting from a single perspective image\nof an indoor scene. Previous methods for predicting indoor illumination usually\nfocus on either simple, parametric lighting that lack realism, or on richer\nrepresentations that are difficult or even impossible to understand or modify\nafter prediction. We propose a pipeline that estimates a parametric light that\nis easy to edit and allows renderings with strong shadows, alongside with a\nnon-parametric texture with high-frequency information necessary for realistic\nrendering of specular objects. Once estimated, the predictions obtained with\nour model are interpretable and can easily be modified by an artist/user with a\nfew mouse clicks. Quantitative and qualitative results show that our approach\nmakes indoor lighting estimation easier to handle by a casual user, while still\nproducing competitive results.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Henrique Weber",
      "Mathieu Garon",
      "Jean-Fran\u00e7ois Lalonde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03928"
  },
  {
    "id": "arXiv:2211.03929",
    "title": "Comparative layer-wise analysis of self-supervised speech models",
    "abstract": "Many self-supervised speech models, varying in their pre-training objective,\ninput modality, and pre-training data, have been proposed in the last few\nyears. Despite impressive empirical successes on downstream tasks, we still\nhave a limited understanding of the properties encoded by the models and the\ndifferences across models. In this work, we examine the intermediate\nrepresentations for a variety of recent models. Specifically, we measure\nacoustic, phonetic, and word-level properties encoded in individual layers,\nusing a lightweight analysis tool based on canonical correlation analysis\n(CCA). We find that these properties evolve across layers differently depending\non the model, and the variations relate to the choice of pre-training\nobjective. We further investigate the utility of our analyses for downstream\ntasks by comparing the property trends with performance on speech recognition\nand spoken language understanding tasks. We discover that CCA trends provide\nreliable guidance to choose layers of interest for downstream tasks and that\nsingle-layer performance often matches or improves upon using all layers,\nsuggesting implications for more efficient use of pre-trained models.",
    "descriptor": "\nComments: submitted to ICASSP 2022\n",
    "authors": [
      "Ankita Pasad",
      "Bowen Shi",
      "Karen Livescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.03929"
  },
  {
    "id": "arXiv:2211.03930",
    "title": "ReLoc: A Restoration-Assisted Framework for Robust Image Tampering  Localization",
    "abstract": "With the spread of tampered images, locating the tampered regions in digital\nimages has drawn increasing attention. The existing image tampering\nlocalization methods, however, suffer from severe performance degradation when\nthe tampered images are subjected to some post-processing, as the tampering\ntraces would be distorted by the post-processing operations. The poor\nrobustness against post-processing has become a bottleneck for the practical\napplications of image tampering localization techniques. In order to address\nthis issue, this paper proposes a novel restoration-assisted framework for\nimage tampering localization (ReLoc). The ReLoc framework mainly consists of an\nimage restoration module and a tampering localization module. The key idea of\nReLoc is to use the restoration module to recover a high-quality counterpart of\nthe distorted tampered image, such that the distorted tampering traces can be\nre-enhanced, facilitating the tampering localization module to identify the\ntampered regions. To achieve this, the restoration module is optimized not only\nwith the conventional constraints on image visual quality but also with a\nforensics-oriented objective function. Furthermore, the restoration module and\nthe localization module are trained alternately, which can stabilize the\ntraining process and is beneficial for improving the performance. The proposed\nframework is evaluated by fighting against JPEG compression, the most commonly\nused post-processing. Extensive experimental results show that ReLoc can\nsignificantly improve the robustness against JPEG compression. The restoration\nmodule in a well-trained ReLoc model is transferable. Namely, it is still\neffective when being directly deployed with another tampering localization\nmodule.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Peiyu Zhuang",
      "Haodong Li",
      "Rui Yang",
      "Jiwu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.03930"
  },
  {
    "id": "arXiv:2211.03932",
    "title": "Enhanced Low-resolution LiDAR-Camera Calibration Via Depth Interpolation  and Supervised Contrastive Learning",
    "abstract": "Motivated by the increasing application of low-resolution LiDAR recently, we\ntarget the problem of low-resolution LiDAR-camera calibration in this work. The\nmain challenges are two-fold: sparsity and noise in point clouds. To address\nthe problem, we propose to apply depth interpolation to increase the point\ndensity and supervised contrastive learning to learn noise-resistant features.\nThe experiments on RELLIS-3D demonstrate that our approach achieves an average\nmean absolute rotation/translation errors of 0.15cm/0.33\\textdegree on\n32-channel LiDAR point cloud data, which significantly outperforms all\nreference methods.",
    "descriptor": "",
    "authors": [
      "Zhikang Zhang",
      "Zifan Yu",
      "Suya You",
      "Raghuveer Rao",
      "Sanjeev Agarwal",
      "Fengbo Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.03932"
  },
  {
    "id": "arXiv:2211.03933",
    "title": "A Hypergraph-Based Machine Learning Ensemble Network Intrusion Detection  System",
    "abstract": "Network intrusion detection systems (NIDS) to detect malicious attacks\ncontinues to meet challenges. NIDS are vulnerable to auto-generated port scan\ninfiltration attempts and NIDS are often developed offline, resulting in a time\nlag to prevent the spread of infiltration to other parts of a network. To\naddress these challenges, we use hypergraphs to capture evolving patterns of\nport scan attacks via the set of internet protocol addresses and destination\nports, thereby deriving a set of hypergraph-based metrics to train a robust and\nresilient ensemble machine learning (ML) NIDS that effectively monitors and\ndetects port scanning activities and adversarial intrusions while evolving\nintelligently in real-time. Through the combination of (1) intrusion examples,\n(2) NIDS update rules, (3) attack threshold choices to trigger NIDS retraining\nrequests, and (4) production environment with no prior knowledge of the nature\nof network traffic 40 scenarios were auto-generated to evaluate the ML ensemble\nNIDS comprising three tree-based models. Results show that under the model\nsettings of an Update-ALL-NIDS rule (namely, retrain and update all the three\nmodels upon the same NIDS retraining request) the proposed ML ensemble NIDS\nproduced the best results with nearly 100% detection performance throughout the\nsimulation, exhibiting robustness in the complex dynamics of the simulated\ncyber-security scenario.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Zong-Zhi Lin",
      "Thomas D. Pike",
      "Mark M. Bailey",
      "Nathaniel D. Bastian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.03933"
  },
  {
    "id": "arXiv:2211.03934",
    "title": "Robust Manifold Nonnegative Tucker Factorization for Tensor Data  Representation",
    "abstract": "Nonnegative Tucker Factorization (NTF) minimizes the euclidean distance or\nKullback-Leibler divergence between the original data and its low-rank\napproximation which often suffers from grossly corruptions or outliers and the\nneglect of manifold structures of data. In particular, NTF suffers from\nrotational ambiguity, whose solutions with and without rotation transformations\nare equally in the sense of yielding the maximum likelihood. In this paper, we\npropose three Robust Manifold NTF algorithms to handle outliers by\nincorporating structural knowledge about the outliers. They first applies a\nhalf-quadratic optimization algorithm to transform the problem into a general\nweighted NTF where the weights are influenced by the outliers. Then, we\nintroduce the correntropy induced metric, Huber function and Cauchy function\nfor weights respectively, to handle the outliers. Finally, we introduce a\nmanifold regularization to overcome the rotational ambiguity of NTF. We have\ncompared the proposed method with a number of representative references\ncovering major branches of NTF on a variety of real-world image databases.\nExperimental results illustrate the effectiveness of the proposed method under\ntwo evaluation metrics (accuracy and nmi).",
    "descriptor": "",
    "authors": [
      "Jianyu Wang",
      "Linruize Tang",
      "Jie Chen",
      "Jingdong Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.03934"
  },
  {
    "id": "arXiv:2211.03936",
    "title": "Policy-Based Reinforcement Learning for Assortative Matching in Human  Behavior Modeling",
    "abstract": "Human behavior is the potential and expressive capacity (mental, physical,\nand social) of human individuals or groups to respond to internal and external\nstimuli. We explore assortative matching as a typical human behavior in virtual\nnetworked communities. We propose a modeling approach based on MAS(Multi-Agent\nSystem) and policy-based reinforcement learning to simulate human behavior\nthrough various environmental parameter settings and agent action strategies.\nIn our experiment, reinforcement learning serves specific agents who learn from\nthe environment status and competitor behaviors, then optimize strategy to\nachieve better results. This work simulates both the individual and group\nlevel, showing some possible paths for forming relative competitive advantages.\nThis modeling approach can help further analyze the evolutionary dynamics of\nhuman behavior, communities, and organizations on various socioeconomic topics.",
    "descriptor": "\nComments: 2 pages, 800 words, Extended abstract for DHM of HCI International 2023\n",
    "authors": [
      "Ou Deng",
      "Qun Jin"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.03936"
  },
  {
    "id": "arXiv:2211.03937",
    "title": "From fat droplets to floating forests: cross-domain transfer learning  using a PatchGAN-based segmentation model",
    "abstract": "Many scientific domains gather sufficient labels to train machine algorithms\nthrough human-in-the-loop techniques provided by the Zooniverse.org citizen\nscience platform. As the range of projects, task types and data rates increase,\nacceleration of model training is of paramount concern to focus volunteer\neffort where most needed. The application of Transfer Learning (TL) between\nZooniverse projects holds promise as a solution. However, understanding the\neffectiveness of TL approaches that pretrain on large-scale generic image sets\nvs. images with similar characteristics possibly from similar tasks is an open\nchallenge. We apply a generative segmentation model on two Zooniverse\nproject-based data sets: (1) to identify fat droplets in liver cells\n(FatChecker; FC) and (2) the identification of kelp beds in satellite images\n(Floating Forests; FF) through transfer learning from the first project. We\ncompare and contrast its performance with a TL model based on the COCO image\nset, and subsequently with baseline counterparts. We find that both the FC and\nCOCO TL models perform better than the baseline cases when using >75% of the\noriginal training sample size. The COCO-based TL model generally performs\nbetter than the FC-based one, likely due to its generalized features. Our\ninvestigations provide important insights into usage of TL approaches on\nmulti-domain data hosted across different Zooniverse projects, enabling future\nprojects to accelerate task completion.",
    "descriptor": "\nComments: 5 pages, 4 figures, accepted for publication at the Proceedings of the ACM/CIKM 2022 (Human-in-the-loop Data Curation Workshop)\n",
    "authors": [
      "Kameswara Bharadwaj Mantha",
      "Ramanakumar Sankar",
      "Yuping Zheng",
      "Lucy Fortson",
      "Thomas Pengo",
      "Douglas Mashek",
      "Mark Sanders",
      "Trace Christensen",
      "Jeffrey Salisbury",
      "Laura Trouille",
      "Jarrett E. K. Byrnes",
      "Isaac Rosenthal",
      "Henry Houskeeper",
      "Kyle Cavanaugh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03937"
  },
  {
    "id": "arXiv:2211.03940",
    "title": "Tell Your Story: Task-Oriented Dialogs for Interactive Content Creation",
    "abstract": "People capture photos and videos to relive and share memories of personal\nsignificance. Recently, media montages (stories) have become a popular mode of\nsharing these memories due to their intuitive and powerful storytelling\ncapabilities. However, creating such montages usually involves a lot of manual\nsearches, clicks, and selections that are time-consuming and cumbersome,\nadversely affecting user experiences.\nTo alleviate this, we propose task-oriented dialogs for montage creation as a\nnovel interactive tool to seamlessly search, compile, and edit montages from a\nmedia collection. To the best of our knowledge, our work is the first to\nleverage multi-turn conversations for such a challenging application, extending\nthe previous literature studying simple media retrieval tasks. We collect a new\ndataset C3 (Conversational Content Creation), comprising 10k dialogs\nconditioned on media montages simulated from a large media collection.\nWe take a simulate-and-paraphrase approach to collect these dialogs to be\nboth cost and time efficient, while drawing from natural language distribution.\nOur analysis and benchmarking of state-of-the-art language models showcase the\nmultimodal challenges present in the dataset. Lastly, we present a real-world\nmobile demo application that shows the feasibility of the proposed work in\nreal-world applications. Our code and data will be made publicly available.",
    "descriptor": "\nComments: 8 pages, 6 figures, 2 tables\n",
    "authors": [
      "Satwik Kottur",
      "Seungwhan Moon",
      "Aram H. Markosyan",
      "Hardik Shah",
      "Babak Damavandi",
      "Alborz Geramifard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.03940"
  },
  {
    "id": "arXiv:2211.03942",
    "title": "The Interpolated MVU Mechanism For Communication-efficient Private  Federated Learning",
    "abstract": "We consider private federated learning (FL), where a server aggregates\ndifferentially private gradient updates from a large number of clients in order\nto train a machine learning model. The main challenge is balancing privacy with\nboth classification accuracy of the learned model as well as the amount of\ncommunication between the clients and server. In this work, we build on a\nrecently proposed method for communication-efficient private FL -- the MVU\nmechanism -- by introducing a new interpolation mechanism that can accommodate\na more efficient privacy analysis. The result is the new Interpolated MVU\nmechanism that provides SOTA results on communication-efficient private FL on a\nvariety of datasets.",
    "descriptor": "",
    "authors": [
      "Chuan Guo",
      "Kamalika Chaudhuri",
      "Pierre Stock",
      "Mike Rabbat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.03942"
  },
  {
    "id": "arXiv:2211.03943",
    "title": "Final Report on MITRE Evaluations for the DARPA Big Mechanism Program",
    "abstract": "This report presents the evaluation approach developed for the DARPA Big\nMechanism program, which aimed at developing computer systems that will read\nresearch papers, integrate the information into a computer model of cancer\nmechanisms, and frame new hypotheses. We employed an iterative, incremental\napproach to the evaluation of the three phases of the program. In Phase I, we\nevaluated the ability of system and human teams ability to read-with-a-model to\ncapture mechanistic information from the biomedical literature, integrated with\ninformation from expert curated biological databases. In Phase II we evaluated\nthe ability of systems to assemble fragments of information into a mechanistic\nmodel. The Phase III evaluation focused on the ability of systems to provide\nexplanations of experimental observations based on models assembled (largely\nautomatically) by the Big Mechanism process. The evaluation for each phase\nbuilt on earlier evaluations and guided developers towards creating\ncapabilities for the new phase. The report describes our approach, including\ninnovations such as a reference set (a curated data set limited to major\nfindings of each paper) to assess the accuracy of systems in extracting\nmechanistic findings in the absence of a gold standard, and a method to\nevaluate model-based explanations of experimental data. Results of the\nevaluation and supporting materials are included in the appendices.",
    "descriptor": "\nComments: 46 pages, 8 figures\n",
    "authors": [
      "Matthew Peterson",
      "Tonia Korves",
      "Christopher Garay",
      "Robyn Kozierok",
      "Lynette Hirschman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.03943"
  },
  {
    "id": "arXiv:2211.03946",
    "title": "Understanding the Role of Mixup in Knowledge Distillation: \\\\An  Empirical Study",
    "abstract": "Mixup is a popular data augmentation technique based on creating new samples\nby linear interpolation between two given data samples, to improve both the\ngeneralization and robustness of the trained model. Knowledge distillation\n(KD), on the other hand, is widely used for model compression and transfer\nlearning, which involves using a larger network's implicit knowledge to guide\nthe learning of a smaller network. At first glance, these two techniques seem\nvery different, however, we found that ``smoothness\" is the connecting link\nbetween the two and is also a crucial attribute in understanding KD's interplay\nwith mixup. Although many mixup variants and distillation methods have been\nproposed, much remains to be understood regarding the role of a mixup in\nknowledge distillation. In this paper, we present a detailed empirical study on\nvarious important dimensions of compatibility between mixup and knowledge\ndistillation. We also scrutinize the behavior of the networks trained with a\nmixup in the light of knowledge distillation through extensive analysis,\nvisualizations, and comprehensive experiments on image classification. Finally,\nbased on our findings, we suggest improved strategies to guide the student\nnetwork to enhance its effectiveness. Additionally, the findings of this study\nprovide insightful suggestions to researchers and practitioners that commonly\nuse techniques from KD. Our code is available at\nhttps://github.com/hchoi71/MIX-KD.",
    "descriptor": "\nComments: To be presented at WACV 2023\n",
    "authors": [
      "Hongjun Choi",
      "Eun Som Jeon",
      "Ankita Shukla",
      "Pavan Turaga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03946"
  },
  {
    "id": "arXiv:2211.03950",
    "title": "Alleviating Sparsity of Open Knowledge Graphs with Ternary Contrastive  Learning",
    "abstract": "Sparsity of formal knowledge and roughness of non-ontological construction\nmake sparsity problem particularly prominent in Open Knowledge Graphs\n(OpenKGs). Due to sparse links, learning effective representation for few-shot\nentities becomes difficult. We hypothesize that by introducing negative\nsamples, a contrastive learning (CL) formulation could be beneficial in such\nscenarios. However, existing CL methods model KG triplets as binary objects of\nentities ignoring the relation-guided ternary propagation patterns and they are\ntoo generic, i.e., they ignore zero-shot, few-shot and synonymity problems that\nappear in OpenKGs. To address this, we propose TernaryCL, a CL framework based\non ternary propagation patterns among head, relation and tail. TernaryCL\ndesigns Contrastive Entity and Contrastive Relation to mine ternary\ndiscriminative features with both negative entities and relations, introduces\nContrastive Self to help zero- and few-shot entities learn discriminative\nfeatures, Contrastive Synonym to model synonymous entities, and Contrastive\nFusion to aggregate graph features from multiple paths. Extensive experiments\non benchmarks demonstrate the superiority of TernaryCL over state-of-the-art\nmodels.",
    "descriptor": "",
    "authors": [
      "Qian Li",
      "Shafiq Joty",
      "Daling Wang",
      "Shi Feng",
      "Yifei Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.03950"
  },
  {
    "id": "arXiv:2211.03952",
    "title": "Optimal design of large-scale nonlinear Bayesian inverse problems under  model uncertainty",
    "abstract": "We consider optimal experimental design (OED) for Bayesian nonlinear inverse\nproblems governed by partial differential equations (PDEs) under model\nuncertainty. Specifically, we consider inverse problems in which, in addition\nto the inversion parameters, the governing PDEs include secondary uncertain\nparameters. We focus on problems with infinite-dimensional inversion and\nsecondary parameters and present a scalable computational framework for optimal\ndesign of such problems. The proposed approach enables Bayesian inversion and\nOED under uncertainty within a unfied framework. We build on the Bayesian\napproximation error (BAE) framework, to incorporate modeling uncertainties in\nthe Bayesian inverse problem, and methods for A-optimal design of\ninfinite-dimensional Bayesian nonlinear inverse problems. Specifically, a\nGaussian approximation to the posterior at the maximum a posteriori probability\npoint is used to define an uncertainty aware OED objective that is tractable to\nevaluate and optimize. In particular, the OED objective can be computed at a\ncost, in the number of PDE solves, that does not grow with the dimension of the\ndiscretized inversion and secondary parameters. The OED problem is formulated\nas a binary bilevel PDE constrained optimization problem and a greedy\nalgorithm, which provides a pragmatic approach, is used to find optimal\ndesigns. We demonstrate the effectiveness of the proposed approach for a model\ninverse problem governed by an elliptic PDE on a three-dimensional domain. Our\ncomputational results also highlight the pitfalls of ignoring modeling\nuncertainties in the OED and/or inference stages.",
    "descriptor": "\nComments: 26 Pages\n",
    "authors": [
      "Alen Alexanderian",
      "Ruanui Nicholson",
      "Noemi Petra"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.03952"
  },
  {
    "id": "arXiv:2211.03956",
    "title": "Significance-Based Categorical Data Clustering",
    "abstract": "Although numerous algorithms have been proposed to solve the categorical data\nclustering problem, how to access the statistical significance of a set of\ncategorical clusters remains unaddressed. To fulfill this void, we employ the\nlikelihood ratio test to derive a test statistic that can serve as a\nsignificance-based objective function in categorical data clustering.\nConsequently, a new clustering algorithm is proposed in which the\nsignificance-based objective function is optimized via a Monte Carlo search\nprocedure. As a by-product, we can further calculate an empirical $p$-value to\nassess the statistical significance of a set of clusters and develop an\nimproved gap statistic for estimating the cluster number. Extensive\nexperimental studies suggest that our method is able to achieve comparable\nperformance to state-of-the-art categorical data clustering algorithms.\nMoreover, the effectiveness of such a significance-based formulation on\nstatistical cluster validation and cluster number estimation is demonstrated\nthrough comprehensive empirical results.",
    "descriptor": "\nComments: 36 pages, 6 figures\n",
    "authors": [
      "Lianyu Hu",
      "Mudi Jiang",
      "Yan Liu",
      "Zengyou He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.03956"
  },
  {
    "id": "arXiv:2211.03959",
    "title": "Pretraining in Deep Reinforcement Learning: A Survey",
    "abstract": "The past few years have seen rapid progress in combining reinforcement\nlearning (RL) with deep learning. Various breakthroughs ranging from games to\nrobotics have spurred the interest in designing sophisticated RL algorithms and\nsystems. However, the prevailing workflow in RL is to learn tabula rasa, which\nmay incur computational inefficiency. This precludes continuous deployment of\nRL algorithms and potentially excludes researchers without large-scale\ncomputing resources. In many other areas of machine learning, the pretraining\nparadigm has shown to be effective in acquiring transferable knowledge, which\ncan be utilized for a variety of downstream tasks. Recently, we saw a surge of\ninterest in Pretraining for Deep RL with promising results. However, much of\nthe research has been based on different experimental settings. Due to the\nnature of RL, pretraining in this field is faced with unique challenges and\nhence requires new design principles. In this survey, we seek to systematically\nreview existing works in pretraining for deep reinforcement learning, provide a\ntaxonomy of these methods, discuss each sub-field, and bring attention to open\nproblems and future directions.",
    "descriptor": "",
    "authors": [
      "Zhihui Xie",
      "Zichuan Lin",
      "Junyou Li",
      "Shuai Li",
      "Deheng Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.03959"
  },
  {
    "id": "arXiv:2211.03963",
    "title": "Fast Algorithms for $\\ell_p$-Regression",
    "abstract": "The $\\ell_p$-norm regression problem is a classic problem in optimization\nwith wide ranging applications in machine learning and theoretical computer\nscience. The goal is to compute $x^{\\star} =\\arg\\min_{Ax=b}\\|x\\|_p^p$, where\n$x^{\\star}\\in \\mathbb{R}^n, A\\in \\mathbb{R}^{d\\times n},b \\in \\mathbb{R}^d$ and\n$d\\leq n$. Efficient high-accuracy algorithms for the problem have been\nchallenging both in theory and practice and the state of the art algorithms\nrequire $poly(p)\\cdot n^{\\frac{1}{2}-\\frac{1}{p}}$ linear system solves for\n$p\\geq 2$. In this paper, we provide new algorithms for $\\ell_p$-regression\n(and a more general formulation of the problem) that obtain a high-accuracy\nsolution in $O(p n^{\\frac{(p-2)}{(3p-2)}})$ linear system solves. We further\npropose a new inverse maintenance procedure that speeds-up our algorithm to\n$\\widetilde{O}(n^{\\omega})$ total runtime, where $O(n^{\\omega})$ denotes the\nrunning time for multiplying $n \\times n$ matrices. Additionally, we give the\nfirst Iteratively Reweighted Least Squares (IRLS) algorithm that is guaranteed\nto converge to an optimum in a few iterations. Our IRLS algorithm has shown\nexceptional practical performance, beating the currently available\nimplementations in MATLAB/CVX by 10-50x.",
    "descriptor": "\nComments: This paper is a coherent algorithmic framework that combines and simplifies our previous works: 1. arXiv:1901.06764 2. arXiv:1907.07167 3. arXiv:1910.10571\n",
    "authors": [
      "Deeksha Adil",
      "Rasmus Kyng",
      "Richard Peng",
      "Sushant Sachdeva"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.03963"
  },
  {
    "id": "arXiv:2211.03966",
    "title": "Parameter and Data Efficient Continual Pre-training for Robustness to  Dialectal Variance in Arabic",
    "abstract": "The use of multilingual language models for tasks in low and high-resource\nlanguages has been a success story in deep learning. In recent times, Arabic\nhas been receiving widespread attention on account of its dialectal variance.\nWhile prior research studies have tried to adapt these multilingual models for\ndialectal variants of Arabic, it still remains a challenging problem owing to\nthe lack of sufficient monolingual dialectal data and parallel translation data\nof such dialectal variants. It remains an open problem on whether the limited\ndialectical data can be used to improve the models trained in Arabic on its\ndialectal variants. First, we show that multilingual-BERT (mBERT) incrementally\npretrained on Arabic monolingual data takes less training time and yields\ncomparable accuracy when compared to our custom monolingual Arabic model and\nbeat existing models (by an avg metric of +$6.41$). We then explore two\ncontinual pre-training methods-- (1) using small amounts of dialectical data\nfor continual finetuning and (2) parallel Arabic to English data and a\nTranslation Language Modeling loss function. We show that both approaches help\nimprove performance on dialectal classification tasks ($+4.64$ avg. gain) when\nused on monolingual models.",
    "descriptor": "",
    "authors": [
      "Soumajyoti Sarkar",
      "Kaixiang Lin",
      "Sailik Sengupta",
      "Leonard Lausen",
      "Sheng Zha",
      "Saab Mansour"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03966"
  },
  {
    "id": "arXiv:2211.03970",
    "title": "On the Algorithmic Stability and Generalization of Adaptive Optimization  Methods",
    "abstract": "Despite their popularity in deep learning and machine learning in general,\nthe theoretical properties of adaptive optimizers such as Adagrad, RMSProp,\nAdam or AdamW are not yet fully understood. In this paper, we develop a novel\nframework to study the stability and generalization of these optimization\nmethods. Based on this framework, we show provable guarantees about such\nproperties that depend heavily on a single parameter $\\beta_2$. Our empirical\nexperiments support our claims and provide practical insights into the\nstability and generalization properties of adaptive optimization methods.",
    "descriptor": "\nComments: 21 pages including appendix\n",
    "authors": [
      "Han Nguyen",
      "Hai Pham",
      "Sashank J. Reddi",
      "Barnab\u00e1s P\u00f3czos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.03970"
  },
  {
    "id": "arXiv:2211.03972",
    "title": "Quantization-Based Optimization: Alternative Stochastic Approximation of  Global Optimization",
    "abstract": "In this study, we propose a global optimization algorithm based on quantizing\nthe energy level of an objective function in an NP-hard problem. According to\nthe white noise hypothesis for a quantization error with a dense and uniform\ndistribution, we can regard the quantization error as i.i.d. white noise. From\nstochastic analysis, the proposed algorithm converges weakly only under\nconditions satisfying Lipschitz continuity, instead of local convergence\nproperties such as the Hessian constraint of the objective function. This shows\nthat the proposed algorithm ensures global optimization by Laplace's condition.\nNumerical experiments show that the proposed algorithm outperforms conventional\nlearning methods in solving NP-hard optimization problems such as the traveling\nsalesman problem.",
    "descriptor": "\nComments: 25 pages, 3 figures, NeurIPS 2022 workshop OPT 2022 (14th Annual Workshop on Optimization for Machine Learning)\n",
    "authors": [
      "Jinwuk Seok",
      "Chang Sik Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.03972"
  },
  {
    "id": "arXiv:2211.03977",
    "title": "Assemble Them All: Physics-Based Planning for Generalizable Assembly by  Disassembly",
    "abstract": "Assembly planning is the core of automating product assembly, maintenance,\nand recycling for modern industrial manufacturing. Despite its importance and\nlong history of research, planning for mechanical assemblies when given the\nfinal assembled state remains a challenging problem. This is due to the\ncomplexity of dealing with arbitrary 3D shapes and the highly constrained\nmotion required for real-world assemblies. In this work, we propose a novel\nmethod to efficiently plan physically plausible assembly motion and sequences\nfor real-world assemblies. Our method leverages the assembly-by-disassembly\nprinciple and physics-based simulation to efficiently explore a reduced search\nspace. To evaluate the generality of our method, we define a large-scale\ndataset consisting of thousands of physically valid industrial assemblies with\na variety of assembly motions required. Our experiments on this new benchmark\ndemonstrate we achieve a state-of-the-art success rate and the highest\ncomputational efficiency compared to other baseline algorithms. Our method also\ngeneralizes to rotational assemblies (e.g., screws and puzzles) and solves\n80-part assemblies within several minutes.",
    "descriptor": "\nComments: Accepted by SIGGRAPH Asia 2022. Project website: this http URL\n",
    "authors": [
      "Yunsheng Tian",
      "Jie Xu",
      "Yichen Li",
      "Jieliang Luo",
      "Shinjiro Sueda",
      "Hui Li",
      "Karl D.D. Willis",
      "Wojciech Matusik"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.03977"
  },
  {
    "id": "arXiv:2211.03979",
    "title": "AI Testing Framework for Next-G O-RAN Networks: Requirements, Design,  and Research Opportunities",
    "abstract": "Openness and intelligence are two enabling features to be introduced in next\ngeneration wireless networks, e.g. Beyond 5G and 6G, to support service\nheterogeneity, open hardware, optimal resource utilization, and on-demand\nservice deployment. The open radio access network (O-RAN) is a promising RAN\narchitecture to achieve both openness and intelligence through virtualized\nnetwork elements and well-defined interfaces. While deploying artificial\nintelligence (AI) models is becoming easier in O-RAN, one significant challenge\nthat has been long neglected is the comprehensive testing of their performance\nin realistic environments. This article presents a general automated,\ndistributed and AI-enabled testing framework to test AI models deployed in\nO-RAN in terms of their decision-making performance, vulnerability and\nsecurity. This framework adopts a master-actor architecture to manage a number\nof end devices for distributed testing. More importantly, it leverages AI to\nautomatically and intelligently explore the decision space of AI models in\nO-RAN. Both software simulation testing and software-defined radio hardware\ntesting are supported, enabling rapid proof of concept research and\nexperimental research on wireless research platforms.",
    "descriptor": "\nComments: To be published in IEEE Wireless Communications Magazine\n",
    "authors": [
      "Bo Tang",
      "Vijay K. Shah",
      "Vuk Marojevic",
      "Jeffrey H. Reed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.03979"
  },
  {
    "id": "arXiv:2211.03982",
    "title": "Low regularity integrators for semilinear parabolic equations with  maximum bound principles",
    "abstract": "This paper is concerned with conditionally structure-preserving, low\nregularity time integration methods for a class of semilinear parabolic\nequations of Allen-Cahn type. Important properties of such equations include\nmaximum bound principle (MBP) and energy dissipation law; for the former, that\nmeans the absolute value of the solution is pointwisely bounded for all the\ntime by some constant imposed by appropriate initial and boundary conditions.\nThe model equation is first discretized in space by the central finite\ndifference, then by iteratively using Duhamel's formula, first- and\nsecond-order low regularity integrators (LRIs) are constructed for time\ndiscretization of the semi-discrete system. The proposed LRI schemes are proved\nto preserve the MBP and the energy stability in the discrete sense.\nFurthermore, their temporal error estimates are also successfully derived under\na low regularity requirement that the exact solution of the semi-discrete\nproblem is only assumed to be continuous in time. Numerical results show that\nthe proposed LRI schemes are more accurate and have better convergence rates\nthan classic exponential time differencing schemes, especially when the\ninterfacial parameter approaches zero.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Cao-Kha Doan",
      "Thi-Thao-Phuong Hoang",
      "Lili Ju",
      "Katharina Schratz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.03982"
  },
  {
    "id": "arXiv:2211.03984",
    "title": "Causal Discovery in Linear Latent Variable Models Subject to Measurement  Error",
    "abstract": "We focus on causal discovery in the presence of measurement error in linear\nsystems where the mixing matrix, i.e., the matrix indicating the independent\nexogenous noise terms pertaining to the observed variables, is identified up to\npermutation and scaling of the columns. We demonstrate a somewhat surprising\nconnection between this problem and causal discovery in the presence of\nunobserved parentless causes, in the sense that there is a mapping, given by\nthe mixing matrix, between the underlying models to be inferred in these\nproblems. Consequently, any identifiability result based on the mixing matrix\nfor one model translates to an identifiability result for the other model. We\ncharacterize to what extent the causal models can be identified under a\ntwo-part faithfulness assumption. Under only the first part of the assumption\n(corresponding to the conventional definition of faithfulness), the structure\ncan be learned up to the causal ordering among an ordered grouping of the\nvariables but not all the edges across the groups can be identified. We further\nshow that if both parts of the faithfulness assumption are imposed, the\nstructure can be learned up to a more refined ordered grouping. As a result of\nthis refinement, for the latent variable model with unobserved parentless\ncauses, the structure can be identified. Based on our theoretical results, we\npropose causal structure learning methods for both models, and evaluate their\nperformance on synthetic data.",
    "descriptor": "\nComments: Accepted at 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Yuqin Yang",
      "AmirEmad Ghassami",
      "Mohamed Nafea",
      "Negar Kiyavash",
      "Kun Zhang",
      "Ilya Shpitser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.03984"
  },
  {
    "id": "arXiv:2211.03988",
    "title": "Unsupervised Domain Adaptation for Sparse Retrieval by Filling  Vocabulary and Word Frequency Gaps",
    "abstract": "IR models using a pretrained language model significantly outperform lexical\napproaches like BM25. In particular, SPLADE, which encodes texts to sparse\nvectors, is an effective model for practical use because it shows robustness to\nout-of-domain datasets. However, SPLADE still struggles with exact matching of\nlow-frequency words in training data. In addition, domain shifts in vocabulary\nand word frequencies deteriorate the IR performance of SPLADE. Because\nsupervision data are scarce in the target domain, addressing the domain shifts\nwithout supervision data is necessary. This paper proposes an unsupervised\ndomain adaptation method by filling vocabulary and word-frequency gaps. First,\nwe expand a vocabulary and execute continual pretraining with a masked language\nmodel on a corpus of the target domain. Then, we multiply SPLADE-encoded sparse\nvectors by inverse document frequency weights to consider the importance of\ndocuments with lowfrequency words. We conducted experiments using our method on\ndatasets with a large vocabulary gap from a source domain. We show that our\nmethod outperforms the present stateof-the-art domain adaptation method. In\naddition, our method achieves state-of-the-art results, combined with BM25.",
    "descriptor": "\nComments: AACL-IJCNLP2022 Camera Ready\n",
    "authors": [
      "Hiroki Iida",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.03988"
  },
  {
    "id": "arXiv:2211.03989",
    "title": "$BT^2$: Backward-compatible Training with Basis Transformation",
    "abstract": "Modern retrieval system often requires recomputing the representation of\nevery piece of data in the gallery when updating to a better representation\nmodel. This process is known as backfilling and can be especially costly in the\nreal world where the gallery often contains billions of samples. Recently,\nresearchers have proposed the idea of Backward Compatible Training (BCT) where\nthe new representation model can be trained with an auxiliary loss to make it\nbackward compatible with the old representation. In this way, the new\nrepresentation can be directly compared with the old representation, in\nprinciple avoiding the need for any backfilling. However, followup work shows\nthat there is an inherent tradeoff where a backward compatible representation\nmodel cannot simultaneously maintain the performance of the new model itself.\nThis paper reports our ``not-so-surprising'' finding that adding extra\ndimensions to the representation can help here. However, we also found that\nnaively increasing the dimension of the representation did not work. To deal\nwith this, we propose Backward-compatible Training with a novel Basis\nTransformation ($BT^2$). A basis transformation (BT) is basically a learnable\nset of parameters that applies an orthonormal transformation. Such a\ntransformation possesses an important property whereby the original information\ncontained in its input is retained in its output. We show in this paper how a\nBT can be utilized to add only the necessary amount of additional dimensions.\nWe empirically verify the advantage of $BT^2$ over other state-of-the-art\nmethods in a wide range of settings. We then further extend $BT^2$ to other\nchallenging yet more practical settings, including significant change in model\narchitecture (CNN to Transformers), modality change, and even a series of\nupdates in the model architecture mimicking the evolution of deep learning\nmodels.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Yifei Zhou",
      "Zilu Li",
      "Abhinav Shrivastava",
      "Hengshuang Zhao",
      "Antonio Torralba",
      "Taipeng Tian",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03989"
  },
  {
    "id": "arXiv:2211.03990",
    "title": "Robust Unstructured Knowledge Access in Conversational Dialogue with ASR  Errors",
    "abstract": "Performance of spoken language understanding (SLU) can be degraded with\nautomatic speech recognition (ASR) errors. We propose a novel approach to\nimprove SLU robustness by randomly corrupting clean training text with an ASR\nerror simulator, followed by self-correcting the errors and minimizing the\ntarget classification loss in a joint manner. In the proposed error simulator,\nwe leverage confusion networks generated from an ASR decoder without human\ntranscriptions to generate a variety of error patterns for model training. We\nevaluate our approach on the DSTC10 challenge targeted for knowledge-grounded\ntask-oriented conversational dialogues with ASR errors. Experimental results\nshow the effectiveness of our proposed approach, boosting the knowledge-seeking\nturn detection (KTD) F1 significantly from 0.9433 to 0.9904. Knowledge cluster\nclassification is boosted from 0.7924 to 0.9333 in Recall@1. After knowledge\ndocument re-ranking, our approach shows significant improvement in all\nknowledge selection metrics, from 0.7358 to 0.7806 in Recall@1, from 0.8301 to\n0.9333 in Recall@5, and from 0.7798 to 0.8460 in MRR@5 on the test set. In the\nrecent DSTC10 evaluation, our approach demonstrates significant improvement in\nknowledge selection, boosting Recall@1 from 0.495 to 0.7144 compared to the\nofficial baseline. Our source code is released in GitHub\nhttps://github.com/yctam/dstc10_track2_task2.git.",
    "descriptor": "\nComments: 7 pages, 2 figures. Accepted at ICASSP 2022\n",
    "authors": [
      "Yik-Cheung Tam",
      "Jiacheng Xu",
      "Jiakai Zou",
      "Zecheng Wang",
      "Tinglong Liao",
      "Shuhan Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.03990"
  },
  {
    "id": "arXiv:2211.03991",
    "title": "Time-Varying Correlation Networks for Interpretable Change Point  Detection",
    "abstract": "Change point detection (CPD) methods aim to detect abrupt changes in\ntime-series data. Recent CPD methods have demonstrated their potential in\nidentifying changes in underlying statistical distributions but often fail to\ncapture complex changes in the correlation structure in time-series data. These\nmethods also fail to generalize effectively, as even within the same\ntime-series, different kinds of change points (CPs) may arise that are best\ncharacterized by different types of time-series perturbations. To address this\nissue, we propose TiVaCPD, a CPD methodology that uses a time-varying graphical\nlasso based method to identify changes in correlation patterns between features\nover time, and combines that with an aggregate Kernel Maximum Mean Discrepancy\n(MMD) test to identify subtle changes in the underlying statistical\ndistributions of dynamically established time windows. We evaluate the\nperformance of TiVaCPD in identifying and characterizing various types of CPs\nin time-series and show that our method outperforms current state-of-the-art\nCPD methods for all categories of CPs.",
    "descriptor": "",
    "authors": [
      "Kopal Garg",
      "Sana Tonekaboni",
      "Anna Goldenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03991"
  },
  {
    "id": "arXiv:2211.03994",
    "title": "Reinforcement Learning with Stepwise Fairness Constraints",
    "abstract": "AI methods are used in societally important settings, ranging from credit to\nemployment to housing, and it is crucial to provide fairness in regard to\nalgorithmic decision making. Moreover, many settings are dynamic, with\npopulations responding to sequential decision policies. We introduce the study\nof reinforcement learning (RL) with stepwise fairness constraints, requiring\ngroup fairness at each time step. Our focus is on tabular episodic RL, and we\nprovide learning algorithms with strong theoretical guarantees in regard to\npolicy optimality and fairness violation. Our framework provides useful tools\nto study the impact of fairness constraints in sequential settings and brings\nup new challenges in RL.",
    "descriptor": "\nComments: Fairness, Reinforcement Learning\n",
    "authors": [
      "Zhun Deng",
      "He Sun",
      "Zhiwei Steven Wu",
      "Linjun Zhang",
      "David C. Parkes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.03994"
  },
  {
    "id": "arXiv:2211.03995",
    "title": "Computing palindromes on a trie in linear time",
    "abstract": "A trie $\\mathcal{T}$ is a rooted tree such that each edge is labeled by a\nsingle character from the alphabet, and the labels of out-going edges from the\nsame node are mutually distinct. Given a trie $\\mathcal{T}$ with $n$ edges, we\nshow how to compute all distinct palindromes and all maximal palindromes on\n$\\mathcal{T}$ in $O(n)$ time, in the case of integer alphabets of size\npolynomial in $n$.This improves the state-of-the-art $O(n \\log h)$-time\nalgorithms by Funakoshi et al. [PCS 2019], where $h$ is the height of\n$\\mathcal{T}$. Using our new algorithms, the eertree with suffix links for a\ngiven trie $\\mathcal{T}$ can readily be obtained in $O(n)$ time. Further, our\ntrie-based $O(n)$-space data structure allows us to report all distinct\npalindromes and maximal palindromes in a query string represented in the trie\n$\\mathcal{T}$, in output optimal time. This is an improvement over an existing\n(na\\\"ive) solution that precomputes and stores all distinct palindromes and\nmaximal palindromes for each and every string in the trie $\\mathcal{T}$\nseparately, using a total $O(n^2)$ preprocessing time and space, and reports\nthem in output optimal time upon query.",
    "descriptor": "\nComments: accepted to ISAAC 2022\n",
    "authors": [
      "Takuya Mieno",
      "Mitsuru Funakoshi",
      "Shunsuke Inenaga"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.03995"
  },
  {
    "id": "arXiv:2211.04000",
    "title": "When Less Is More: Consequence-Finding in a Weak Theory of Arithmetic",
    "abstract": "This paper presents a theory of non-linear integer/real arithmetic and\nalgorithms for reasoning about this theory. The theory can be conceived as an\nextension of linear integer/real arithmetic with a weakly-axiomatized\nmultiplication symbol, which retains many of the desirable algorithmic\nproperties of linear arithmetic. In particular, we show that the conjunctive\nfragment of the theory can be effectively manipulated (analogously to the usual\noperations on convex polyhedra, the conjunctive fragment of linear arithmetic).\nAs a result, we can solve the following consequence-finding problem: given a\nground formula F, find the strongest conjunctive formula that is entailed by F.\nAs an application of consequence-finding, we give a loop invariant generation\nalgorithm that is monotone with respect to the theory and (in a sense)\ncomplete. Experiments show that the invariants generated from the consequences\nare effective for proving safety properties of programs that require non-linear\nreasoning.",
    "descriptor": "",
    "authors": [
      "Zachary Kincaid",
      "Nicolas Koh",
      "Shaowei Zhu"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.04000"
  },
  {
    "id": "arXiv:2211.04001",
    "title": "Progress and summary of reinforcement learning on energy management of  MPS-EV",
    "abstract": "The high emission and low energy efficiency caused by internal combustion\nengines (ICE) have become unacceptable under environmental regulations and the\nenergy crisis. As a promising alternative solution, multi-power source electric\nvehicles (MPS-EVs) introduce different clean energy systems to improve\npowertrain efficiency. The energy management strategy (EMS) is a critical\ntechnology for MPS-EVs to maximize efficiency, fuel economy, and range.\nReinforcement learning (RL) has become an effective methodology for the\ndevelopment of EMS. RL has received continuous attention and research, but\nthere is still a lack of systematic analysis of the design elements of RL-based\nEMS. To this end, this paper presents an in-depth analysis of the current\nresearch on RL-based EMS (RL-EMS) and summarizes the design elements of\nRL-based EMS. This paper first summarizes the previous applications of RL in\nEMS from five aspects: algorithm, perception scheme, decision scheme, reward\nfunction, and innovative training method. The contribution of advanced\nalgorithms to the training effect is shown, the perception and control schemes\nin the literature are analyzed in detail, different reward function settings\nare classified, and innovative training methods with their roles are\nelaborated. Finally, by comparing the development routes of RL and RL-EMS, this\npaper identifies the gap between advanced RL solutions and existing RL-EMS.\nFinally, this paper suggests potential development directions for implementing\nadvanced artificial intelligence (AI) solutions in EMS.",
    "descriptor": "",
    "authors": [
      "Jincheng Hu",
      "Yang Lin",
      "Liang Chu",
      "Zhuoran Hou",
      "Jihan Li",
      "Jingjing Jiang",
      "Yuanjian Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.04001"
  },
  {
    "id": "arXiv:2211.04002",
    "title": "The free algebra in R",
    "abstract": "The free algebra is an interesting and useful algebraic object. Here I\nintroduce \"freealg\", an R package which furnishes computational support for\nfree algebras. The package uses the standard template library's \"map\" class for\nefficiency, which uses the fact that the order of the terms is algebraically\nimmaterial. The package follows \"disordR\" discipline. I demonstrate some\nproperties of free algebra using the package, and showcase package idiom. The\npackage is available on CRAN at https://CRAN.R-project.org/package=freealg.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Robin K. S. Hankin"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2211.04002"
  },
  {
    "id": "arXiv:2211.04005",
    "title": "ABC: Adversarial Behavioral Cloning for Offline Mode-Seeking Imitation  Learning",
    "abstract": "Given a dataset of expert agent interactions with an environment of interest,\na viable method to extract an effective agent policy is to estimate the maximum\nlikelihood policy indicated by this data. This approach is commonly referred to\nas behavioral cloning (BC). In this work, we describe a key disadvantage of BC\nthat arises due to the maximum likelihood objective function; namely that BC is\nmean-seeking with respect to the state-conditional expert action distribution\nwhen the learner's policy is represented with a Gaussian. To address this\nissue, we introduce a modified version of BC, Adversarial Behavioral Cloning\n(ABC), that exhibits mode-seeking behavior by incorporating elements of GAN\n(generative adversarial network) training. We evaluate ABC on toy domains and a\ndomain based on Hopper from the DeepMind Control suite, and show that it\noutperforms standard BC by being mode-seeking in nature.",
    "descriptor": "",
    "authors": [
      "Eddy Hudson",
      "Ishan Durugkar",
      "Garrett Warnell",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04005"
  },
  {
    "id": "arXiv:2211.04009",
    "title": "SOTIF Entropy: Online SOTIF Risk Quantification and Mitigation for  Autonomous Driving",
    "abstract": "Autonomous driving confronts great challenges in complex traffic scenarios,\nwhere the risk of Safety of the Intended Functionality (SOTIF) can be triggered\nby the dynamic operational environment and system insufficiencies. The SOTIF\nrisk is reflected not only intuitively in the collision risk with objects\noutside the autonomous vehicles (AVs), but also inherently in the performance\nlimitation risk of the implemented algorithms themselves. How to minimize the\nSOTIF risk for autonomous driving is currently a critical, difficult, and\nunresolved issue. Therefore, this paper proposes the \"Self-Surveillance and\nSelf-Adaption System\" as a systematic approach to online minimize the SOTIF\nrisk, which aims to provide a systematic solution for monitoring,\nquantification, and mitigation of inherent and external risks. The core of this\nsystem is the risk monitoring of the implemented artificial intelligence\nalgorithms within the AV. As a demonstration of the Self-Surveillance and\nSelf-Adaption System, the risk monitoring of the perception algorithm, i.e.,\nYOLOv5 is highlighted. Moreover, the inherent perception algorithm risk and\nexternal collision risk are jointly quantified via SOTIF entropy, which is then\npropagated downstream to the decision-making module and mitigated. Finally,\nseveral challenging scenarios are demonstrated, and the Hardware-in-the-Loop\nexperiments are conducted to verify the efficiency and effectiveness of the\nsystem. The results demonstrate that the Self-Surveillance and Self-Adaption\nSystem enables dependable online monitoring, quantification, and mitigation of\nSOTIF risk in real-time critical traffic environments.",
    "descriptor": "\nComments: 16 pages, 10 figures, 2 tables, submitted to IEEE TITS\n",
    "authors": [
      "Liang Peng",
      "Boqi Li",
      "Wenhao Yu",
      "Kai Yang",
      "Wenbo Shao",
      "Hong Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04009"
  },
  {
    "id": "arXiv:2211.04010",
    "title": "Numerical analysis of Givens rotation",
    "abstract": "Generating 2-by-2 unitary matrices in floating-precision arithmetic is a\ndelicate task. One way to reduce the accumulation error is to use less\nfloating-point operations to compute each of the entries in the 2-by-2 unitary\nmatrix. This paper shows an algorithm that reduces the number of operations to\ncompute the entries of a Givens rotation. Overall, the new algorithm has more\noperations in total when compared to algorithms in different releases of\nLAPACK, but less operations per entry. Numerical tests show that the new\nalgorithm is more accurate on average.",
    "descriptor": "",
    "authors": [
      "Weslley da Silva Pereira",
      "Ali Lotfi",
      "Julien Langou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04010"
  },
  {
    "id": "arXiv:2211.04011",
    "title": "An Incremental Phase Mapping Approach for X-ray Diffraction Patterns  using Binary Peak Representations",
    "abstract": "Despite the huge advancement in knowledge discovery and data mining\ntechniques, the X-ray diffraction (XRD) analysis process has mostly remained\nuntouched and still involves manual investigation, comparison, and\nverification. Due to the large volume of XRD samples from high-throughput XRD\nexperiments, it has become impossible for domain scientists to process them\nmanually. Recently, they have started leveraging standard clustering\ntechniques, to reduce the XRD pattern representations requiring manual efforts\nfor labeling and verification. Nevertheless, these standard clustering\ntechniques do not handle problem-specific aspects such as peak shifting,\nadjacent peaks, background noise, and mixed phases; hence, resulting in\nincorrect composition-phase diagrams that complicate further steps. Here, we\nleverage data mining techniques along with domain expertise to handle these\nissues. In this paper, we introduce an incremental phase mapping approach based\non binary peak representations using a new threshold based fuzzy dissimilarity\nmeasure. The proposed approach first applies an incremental phase computation\nalgorithm on discrete binary peak representation of XRD samples, followed by\nhierarchical clustering or manual merging of similar pure phases to obtain the\nfinal composition-phase diagram. We evaluate our method on the composition\nspace of two ternary alloy systems- Co-Ni-Ta and Co-Ti-Ta. Our results are\nverified by domain scientists and closely resembles the manually computed\nground-truth composition-phase diagrams. The proposed approach takes us closer\ntowards achieving the goal of complete end-to-end automated XRD analysis.",
    "descriptor": "\nComments: Accepted and presented at the International Workshop on Domain-Driven Data Mining (DDDM) as a part of the SIAM International Conference on Data Mining (SDM 2021). Contains 11 pages and 5 figures\n",
    "authors": [
      "Dipendra Jha",
      "K.V.L.V. Narayanachari",
      "Ruifeng Zhang",
      "Justin Liao",
      "Denis T. Keane",
      "Wei-keng Liao",
      "Alok Choudhary",
      "Yip-Wah Chung",
      "Michael Bedzyk",
      "Ankit Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04011"
  },
  {
    "id": "arXiv:2211.04013",
    "title": "COV19IR : COVID-19 Domain Literature Information Retrieval",
    "abstract": "Increasing number of COVID-19 research literatures cause new challenges in\neffective literature screening and COVID-19 domain knowledge aware Information\nRetrieval. To tackle the challenges, we demonstrate two tasks along\nwithsolutions, COVID-19 literature retrieval, and question answering. COVID-19\nliterature retrieval task screens matching COVID-19 literature documents for\ntextual user query, and COVID-19 question answering task predicts proper text\nfragments from text corpus as the answer of specific COVID-19 related\nquestions. Based on transformer neural network, we provided solutions to\nimplement the tasks on CORD-19 dataset, we display some examples to show the\neffectiveness of our proposed solutions.",
    "descriptor": "",
    "authors": [
      "Arusarka Bose",
      "Zili Zhou",
      "Guandong Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04013"
  },
  {
    "id": "arXiv:2211.04022",
    "title": "Integrated Sensing, Computation, and Communication: System Framework and  Performance Optimization",
    "abstract": "Integrated sensing, computation, and communication (ISCC) has been recently\nconsidered as a promising technique for beyond 5G systems. In ISCC systems, the\ncompetition for communication and computation resources between sensing tasks\nfor ambient intelligence and computation tasks from mobile devices becomes an\nincreasingly challenging issue. To address it, we first propose an efficient\nsensing framework with a novel action detection module. It can reduce the\noverhead of computation resource by detecting whether the sensing target is\nstatic. Subsequently, we analyze the sensing performance of the proposed\nframework and theoretically prove its effectiveness with the help of the\nsampling theorem. Then, we formulate a sensing accuracy maximization problem\nwhile guaranteeing the quality-of-service (QoS) requirements of tasks. To solve\nit, we propose an optimal resource allocation strategy, in which the minimal\nresource is allocated to computation tasks, and the rest is devoted to sensing\ntasks. Besides, a threshold selection policy is derived. Compared with the\nconventional schemes, the results further demonstrate the necessity of the\nproposed sensing framework. Finally, a real-world test of action recognition\ntasks based on USRP B210 is conducted to verify the sensing performance\nanalysis, and extensive experiments demonstrate the performance improvement of\nour proposal by comparing it with some benchmark schemes.",
    "descriptor": "",
    "authors": [
      "Yinghui He",
      "Guanding Yu",
      "Yunlong Cai",
      "Haiyan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04022"
  },
  {
    "id": "arXiv:2211.04023",
    "title": "A Dynamic Graph Interactive Framework with Label-Semantic Injection for  Spoken Language Understanding",
    "abstract": "Multi-intent detection and slot filling joint models are gaining increasing\ntraction since they are closer to complicated real-world scenarios. However,\nexisting approaches (1) focus on identifying implicit correlations between\nutterances and one-hot encoded labels in both tasks while ignoring explicit\nlabel characteristics; (2) directly incorporate multi-intent information for\neach token, which could lead to incorrect slot prediction due to the\nintroduction of irrelevant intent. In this paper, we propose a framework termed\nDGIF, which first leverages the semantic information of labels to give the\nmodel additional signals and enriched priors. Then, a multi-grain interactive\ngraph is constructed to model correlations between intents and slots.\nSpecifically, we propose a novel approach to construct the interactive graph\nbased on the injection of label semantics, which can automatically update the\ngraph to better alleviate error propagation. Experimental results show that our\nframework significantly outperforms existing approaches, obtaining a relative\nimprovement of 13.7% over the previous best model on the MixATIS dataset in\noverall accuracy.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Zhihong Zhu",
      "Weiyuan Xu",
      "Xuxin Cheng",
      "Tengtao Song",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04023"
  },
  {
    "id": "arXiv:2211.04024",
    "title": "Comparing Two Counting Methods for Estimating the Probabilities of  Strings",
    "abstract": "There are two methods for counting the number of occurrences of a string in\nanother large string. One is to count the number of places where the string is\nfound. The other is to determine how many pieces of string can be extracted\nwithout overlapping. The difference between the two becomes apparent when the\nstring is part of a periodic pattern. This research reports that the difference\nis significant in estimating the occurrence probability of a pattern.\nIn this study, the strings used in the experiments are approximated from\ntime-series data. The task involves classifying strings by estimating the\nprobability or computing the information quantity. First, the frequencies of\nall substrings of a string are computed. Each counting method may sometimes\nproduce different frequencies for an identical string. Second, the probability\nof the most probable segmentation is selected. The probability of the string is\nthe product of all probabilities of substrings in the selected segmentation.\nThe classification results demonstrate that the difference in counting methods\nis statistically significant, and that the method without overlapping is\nbetter.",
    "descriptor": "",
    "authors": [
      "Ayaka Takamoto",
      "Mitsuo Yoshida",
      "Kyoji Umemura"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04024"
  },
  {
    "id": "arXiv:2211.04026",
    "title": "Domain-decomposed Bayesian inversion based on local Karhunen-Lo\u00e8ve  expansions",
    "abstract": "In many Bayesian inverse problems the goal is to recover a spatially varying\nrandom field. Such problems are often computationally challenging especially\nwhen the forward model is governed by complex partial differential equations\n(PDEs). The challenge is particularly severe when the spatial domain is large\nand the unknown random field needs to be represented by a high-dimensional\nparameter. In this paper, we present a domain-decomposed method to attack the\ndimensionality issue and the method decomposes the spatial domain and the\nparameter domain simultaneously. On each subdomain, a local Karhunen-Lo`eve\n(KL) expansion is constructed, and a local inversion problem is solved\nindependently in a parallel manner, and more importantly, in a\nlower-dimensional space. After local posterior samples are generated through\nconducting Markov chain Monte Carlo (MCMC) simulations on subdomains, a novel\nprojection procedure is developed to effectively reconstruct the global field.\nIn addition, the domain decomposition interface conditions are dealt with an\nadaptive Gaussian process-based fitting strategy. Numerical examples are\nprovided to demonstrate the performance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Zhihang Xu",
      "Qifeng Liao",
      "Jinglai Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04026"
  },
  {
    "id": "arXiv:2211.04031",
    "title": "Hilbert Distillation for Cross-Dimensionality Networks",
    "abstract": "3D convolutional neural networks have revealed superior performance in\nprocessing volumetric data such as video and medical imaging. However, the\ncompetitive performance by leveraging 3D networks results in huge computational\ncosts, which are far beyond that of 2D networks. In this paper, we propose a\nnovel Hilbert curve-based cross-dimensionality distillation approach that\nfacilitates the knowledge of 3D networks to improve the performance of 2D\nnetworks. The proposed Hilbert Distillation (HD) method preserves the\nstructural information via the Hilbert curve, which maps high-dimensional (>=2)\nrepresentations to one-dimensional continuous space-filling curves. Since the\ndistilled 2D networks are supervised by the curves converted from dimensionally\nheterogeneous 3D features, the 2D networks are given an informative view in\nterms of learning structural information embedded in well-trained\nhigh-dimensional representations. We further propose a Variable-length Hilbert\nDistillation (VHD) method to dynamically shorten the walking stride of the\nHilbert curve in activation feature areas and lengthen the stride in context\nfeature areas, forcing the 2D networks to pay more attention to learning from\nactivation features. The proposed algorithm outperforms the current\nstate-of-the-art distillation techniques adapted to cross-dimensionality\ndistillation on two classification tasks. Moreover, the distilled 2D networks\nby the proposed method achieve competitive performance with the original 3D\nnetworks, indicating the lightweight distilled 2D networks could potentially be\nthe substitution of cumbersome 3D networks in the real-world scenario.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Dian Qin",
      "Haishuai Wang",
      "Zhe Liu",
      "Hongjia Xu",
      "Sheng Zhou",
      "Jiajun Bu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04031"
  },
  {
    "id": "arXiv:2211.04032",
    "title": "Non-existence of a short algorithm for multiplication of $3\\times3$  matrices with group $S_4\\times S_3$, II",
    "abstract": "It is proved that there is no an algorithm for multiplication of $3\\times3$\nmatrices of multiplicative length $\\leq23$ that is invariant under a certain\ngroup isomorphic to $S_4\\times S_3$. The proof makes use of description of the\norbits of this group on decomposable tensors in the tensor cube $(M_3({\\mathbb\nC}))^{\\otimes3}$ which was obtained earlier.",
    "descriptor": "\nComments: 13 pp. Accepted for publication in Proceedings of the Institute of Mathematics of Academy of Sciences of Belarus\n",
    "authors": [
      "Vladimir P. Burichenko"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.04032"
  },
  {
    "id": "arXiv:2211.04033",
    "title": "AEDNet: Adaptive Edge-Deleting Network For Subgraph Matching",
    "abstract": "Subgraph matching is to find all subgraphs in a data graph that are\nisomorphic to an existing query graph. Subgraph matching is an NP-hard problem,\nyet has found its applications in many areas. Many learning-based methods have\nbeen proposed for graph matching, whereas few have been designed for subgraph\nmatching. The subgraph matching problem is generally more challenging, mainly\ndue to the different sizes between the two graphs, resulting in considerable\nlarge space of solutions. Also the extra edges existing in the data graph\nconnecting to the matched nodes may lead to two matched nodes of two graphs\nhaving different adjacency structures and often being identified as distinct\nobjects. Due to the extra edges, the existing learning based methods often fail\nto generate sufficiently similar node-level embeddings for matched nodes. This\nstudy proposes a novel Adaptive Edge-Deleting Network (AEDNet) for subgraph\nmatching. The proposed method is trained in an end-to-end fashion. In AEDNet, a\nnovel sample-wise adaptive edge-deleting mechanism removes extra edges to\nensure consistency of adjacency structure of matched nodes, while a\nunidirectional cross-propagation mechanism ensures consistency of features of\nmatched nodes. We applied the proposed method on six datasets with graph sizes\nvarying from 20 to 2300. Our evaluations on six open datasets demonstrate that\nthe proposed AEDNet outperforms six state-of-the-arts and is much faster than\nthe exact methods on large graphs.",
    "descriptor": "",
    "authors": [
      "Zixun Lan",
      "Ye Ma",
      "Limin Yu",
      "LingLong Yuan",
      "Fei Ma"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.04033"
  },
  {
    "id": "arXiv:2211.04037",
    "title": "A $C^0$ Linear Finite Element Method for a Second Order Elliptic  Equation in Non-Divergence Form with Cordes Coefficients",
    "abstract": "In this paper, we develop a gradient recovery based linear (GRBL) finite\nelement method (FEM) and a Hessian recovery based linear (HRBL) FEM for second\norder elliptic equations in non-divergence form. The elliptic equation is\ncasted into a symmetric non-divergence weak formulation, in which second order\nderivatives of the unknown function are involved. We use gradient and Hessian\nrecovery operators to calculate the second order derivatives of linear finite\nelement approximations. Although, thanks to low degrees of freedom (DOF) of\nlinear elements, the implementation of the proposed schemes is easy and\nstraightforward, the performances of the methods are competitive. The unique\nsolvability and the $H^2$ seminorm error estimate of the GRBL scheme are\nrigorously proved. Optimal error estimates in both the $L^2$ norm and the $H^1$\nseminorm have been proved when the coefficient is diagonal, which have been\nconfirmed by numerical experiments. Superconvergence in errors has also been\nobserved. Moreover, our methods can handle computational domains with curved\nboundaries without loss of accuracy from approximation of boundaries. Finally,\nthe proposed numerical methods have been successfully applied to solve fully\nnonlinear Monge-Amp\\`{e}re equations.",
    "descriptor": "",
    "authors": [
      "Minqiang Xu",
      "Runchang Lin",
      "Qingsong Zou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04037"
  },
  {
    "id": "arXiv:2211.04039",
    "title": "Fine-grained Population Mapping from Coarse Census Counts and Open  Geodata",
    "abstract": "Fine-grained population maps are needed in several domains, like urban\nplanning, environmental monitoring, public health, and humanitarian operations.\nUnfortunately, in many countries only aggregate census counts over large\nspatial units are collected, moreover, these are not always up-to-date. We\npresent POMELO, a deep learning model that employs coarse census counts and\nopen geodata to estimate fine-grained population maps with 100m ground sampling\ndistance. Moreover, the model can also estimate population numbers when no\ncensus counts at all are available, by generalizing across countries. In a\nseries of experiments for several countries in sub-Saharan Africa, the maps\nproduced with POMELOare in good agreement with the most detailed available\nreference counts: disaggregation of coarse census counts reaches R2 values of\n85-89%; unconstrained prediction in the absence of any counts reaches 48-69%.",
    "descriptor": "",
    "authors": [
      "Nando Metzger",
      "John E. Vargas-Mu\u00f1oz",
      "Rodrigo C. Daudt",
      "Benjamin Kellenberger",
      "Thao Ton-That Whelan",
      "Ferda Ofli",
      "Muhammad Imran",
      "Konrad Schindler",
      "Devis Tuia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.04039"
  },
  {
    "id": "arXiv:2211.04041",
    "title": "ParticleNeRF: Particle Based Encoding for Online Neural Radiance Fields  in Dynamic Scenes",
    "abstract": "Neural Radiance Fields (NeRFs) are coordinate-based implicit representations\nof 3D scenes that use a differentiable rendering procedure to learn a\nrepresentation of an environment from images. This paper extends NeRFs to\nhandle dynamic scenes in an online fashion. We do so by introducing a\nparticle-based parametric encoding, which allows the intermediate NeRF features\n-- now coupled to particles in space -- to be moved with the dynamic geometry.\nWe backpropagate the NeRF's photometric reconstruction loss into the position\nof the particles in addition to the features they are associated with. The\nposition gradients are interpreted as particle velocities and integrated into\npositions using a position-based dynamics (PBS) physics system. Introducing PBS\ninto the NeRF formulation allows us to add collision constraints to the\nparticle motion and creates future opportunities to add other movement priors\ninto the system such as rigid and deformable body constraints. We show that by\nallowing the features to move in space, we incrementally adapt the NeRF to the\nchanging scene.",
    "descriptor": "",
    "authors": [
      "Jad Abou-Chakra",
      "Feras Dayoub",
      "Niko S\u00fcnderhauf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04041"
  },
  {
    "id": "arXiv:2211.04045",
    "title": "Fast GPU-Based Two-Way Continuous Collision Handling",
    "abstract": "Step-and-project is a popular way to simulate non-penetrated deformable\nbodies in physically-based animation. First integrating the system in time\nregardless of contacts and post resolving potential intersections practically\nstrike a good balance between plausibility and efficiency. However, existing\nmethods could be defective and unsafe when the time step is large, taking risks\nof failures or demands of repetitive collision testing and resolving that\nseverely degrade performance. In this paper, we propose a novel two-way method\nfor fast and reliable continuous collision handling. Our method launches the\noptimization at both ends of the intermediate time-integrated state and the\nprevious intersection-free state, progressively generating a piecewise-linear\npath and finally reaching a feasible solution for the next time step.\nTechnically, our method interleaves between a forward step and a backward step\nat a low cost, until the result is conditionally converged. Due to a set of\nunified volume-based contact constraints, our method can flexibly and reliably\nhandle a variety of codimensional deformable bodies, including volumetric\nbodies, cloth, hair and sand. The experiments show that our method is safe,\nrobust, physically faithful and numerically efficient, especially suitable for\nlarge deformations or large time steps.",
    "descriptor": "",
    "authors": [
      "Tianyu Wang",
      "Jiong Chen",
      "Dongping Li",
      "Xiaowei Liu",
      "Huamin Wang",
      "Kun Zhou"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.04045"
  },
  {
    "id": "arXiv:2211.04046",
    "title": "Many Destinations, Many Pathways: A Quantitative Analysis of Legitimate  Peripheral Participation in Scratch",
    "abstract": "Although informal online learning communities have proliferated over the last\ntwo decades, a fundamental question remains: What are the users of these\ncommunities expected to learn? Guided by the work of Etienne Wenger on\ncommunities of practice, we identify three distinct types of learning goals\ncommon to online informal learning communities: the development of domain\nskills, the development of identity as a community member, and the development\nof community-specific values and practices. Given these goals, what is the best\nway to support learning? Drawing from previous research in social computing, we\nask how different types of legitimate peripheral participation by\nnewcomers-contribution to core tasks, engagement with practice proxies, social\nbonding, and feedback exchange-may be associated with these three learning\ngoals. Using data from the Scratch online community, we conduct a quantitative\nanalysis to explore these questions. Our study contributes both theoretical\ninsights and empirical evidence on how different types of learning occur in\ninformal online environments.",
    "descriptor": "",
    "authors": [
      "Ruijia Cheng",
      "Benjamin Mako Hill"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.04046"
  },
  {
    "id": "arXiv:2211.04047",
    "title": "DNN Filter for Bias Reduction in Distribution-to-Distribution Scan  Matching",
    "abstract": "Distribution-to-distribution (D2D) point cloud registration techniques such\nas the Normal Distributions Transform (NDT) can align point clouds sampled from\nunstructured scenes and provide accurate bounds of their own solution error\ncovariance-- an important feature for safety-of life navigation tasks. D2D\nmethods rely on the assumption of a static scene and are therefore susceptible\nto bias from range-shadowing, self-occlusion, moving objects, and distortion\nartifacts as the recording device moves between frames. Deep Learning-based\napproaches can achieve higher accuracy in dynamic scenes by relaxing these\nconstraints, however, DNNs produce uninterpratable solutions which can be\nproblematic from a safety perspective. In this paper, we propose a method of\ndown-sampling LIDAR point clouds to exclude voxels that violate the assumption\nof a static scene and introduce error to the D2D scan matching process. Our\napproach uses a solution consistency filter, identifying and flagging voxels\nwhere D2D contributions disagree with local estimates from a PointNet-based\nregistration network.",
    "descriptor": "",
    "authors": [
      "Matthew McDermott",
      "Jason Rife"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04047"
  },
  {
    "id": "arXiv:2211.04049",
    "title": "Caching and Reproducibility: Making Data Science experiments faster and  FAIRer",
    "abstract": "Small to medium-scale data science experiments often rely on research\nsoftware developed ad-hoc by individual scientists or small teams. Often there\nis no time to make the research software fast, reusable, and open access. The\nconsequence is twofold. First, subsequent researchers must spend significant\nwork hours building upon the proposed hypotheses or experimental framework. In\nthe worst case, others cannot reproduce the experiment and reuse the findings\nfor subsequent research. Second, suppose the ad-hoc research software fails\nduring often long-running computationally expensive experiments. In that case,\nthe overall effort to iteratively improve the software and rerun the\nexperiments creates significant time pressure on the researchers. We suggest\nmaking caching an integral part of the research software development process,\neven before the first line of code is written. This article outlines caching\nrecommendations for developing research software in data science projects. Our\nrecommendations provide a perspective to circumvent common problems such as\npropriety dependence, speed, etc. At the same time, caching contributes to the\nreproducibility of experiments in the open science workflow. Concerning the\nfour guiding principles, i.e., Findability, Accessibility, Interoperability,\nand Reusability (FAIR), we foresee that including the proposed recommendation\nin a research software development will make the data related to that software\nFAIRer for both machines and humans. We exhibit the usefulness of some of the\nproposed recommendations on our recently completed research software project in\nmathematical information retrieval.",
    "descriptor": "\nComments: 8 pages, 1 table\n",
    "authors": [
      "Moritz Schubotz",
      "Ankit Satpute",
      "Andre Greiner-Petter",
      "Akiko Aizawa",
      "Bela Gipp"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04049"
  },
  {
    "id": "arXiv:2211.04050",
    "title": "Hyperbolic Graph Representation Learning: A Tutorial",
    "abstract": "Graph-structured data are widespread in real-world applications, such as\nsocial networks, recommender systems, knowledge graphs, chemical molecules etc.\nDespite the success of Euclidean space for graph-related learning tasks, its\nability to model complex patterns is essentially constrained by its\npolynomially growing capacity. Recently, hyperbolic spaces have emerged as a\npromising alternative for processing graph data with tree-like structure or\npower-law distribution, owing to the exponential growth property. Different\nfrom Euclidean space, which expands polynomially, the hyperbolic space grows\nexponentially which makes it gains natural advantages in abstracting tree-like\nor scale-free graphs with hierarchical organizations.\nIn this tutorial, we aim to give an introduction to this emerging field of\ngraph representation learning with the express purpose of being accessible to\nall audiences. We first give a brief introduction to graph representation\nlearning as well as some preliminary Riemannian and hyperbolic geometry. We\nthen comprehensively revisit the hyperbolic embedding techniques, including\nhyperbolic shallow models and hyperbolic neural networks. In addition, we\nintroduce the technical details of the current hyperbolic graph neural networks\nby unifying them into a general framework and summarizing the variants of each\ncomponent. Moreover, we further introduce a series of related applications in a\nvariety of fields. In the last part, we discuss several advanced topics about\nhyperbolic geometry for graph representation learning, which potentially serve\nas guidelines for further flourishing the non-Euclidean graph learning\ncommunity.",
    "descriptor": "\nComments: Accepted as ECML-PKDD 2022 Tutorial\n",
    "authors": [
      "Min Zhou",
      "Menglin Yang",
      "Lujia Pan",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04050"
  },
  {
    "id": "arXiv:2211.04052",
    "title": "What Knowledge Is Needed? Towards Explainable Memory for kNN-MT Domain  Adaptation",
    "abstract": "kNN-MT presents a new paradigm for domain adaptation by building an external\ndatastore, which usually saves all target language token occurrences in the\nparallel corpus. As a result, the constructed datastore is usually large and\npossibly redundant. In this paper, we investigate the interpretability issue of\nthis approach: what knowledge does the NMT model need? We propose the notion of\nlocal correctness (LAC) as a new angle, which describes the potential\ntranslation correctness for a single entry and for a given neighborhood.\nEmpirical study shows that our investigation successfully finds the conditions\nwhere the NMT model could easily fail and need related knowledge. Experiments\non six diverse target domains and two language-pairs show that pruning\naccording to local correctness brings a light and more explainable memory for\nkNN-MT domain adaptation.",
    "descriptor": "",
    "authors": [
      "Wenhao Zhu",
      "Shujian Huang",
      "Yunzhe Lv",
      "Xin Zheng",
      "Jiajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04052"
  },
  {
    "id": "arXiv:2211.04053",
    "title": "A study and comparison of COordinate Rotation DIgital Computer (CORDIC)  architectures",
    "abstract": "Most of the digital signal processing applications performs operations like\nmultiplication, addition, square-root calculation, solving linear equations\netc. The physical implementation of these operations consumes a lot of hardware\nand, software implementation consumes large memory. Even if they are\nimplemented in hardware, they do not provide high speed, and due to this\nreason, even today the software implementation dominates hardware. For\nrealizing operations from basic to very complex ones with less hardware, a\nCo-ordinate Rotation Digital Computer (CORDIC) proves beneficial. It is capable\nof performing mathematical operations right from addition to highly complex\nfunctions with the help of arithmetic unit and shifters only. This paper gives\na brief overview of various existing CORDIC architectures, their working\nprinciple, application domain and a comparison of these architectures.\nDifferent designs are available as per the target, i.e. high accuracy and\nprecision, low area, low latency, hardware efficient, low power,\nreconfigurability, etc. that can be used as per the application in which the\narchitecture needs to be employed.",
    "descriptor": "",
    "authors": [
      "Neha K Nawandar",
      "Vishal R Satpute"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.04053"
  },
  {
    "id": "arXiv:2211.04054",
    "title": "ATCO2 corpus: A Large-Scale Dataset for Research on Automatic Speech  Recognition and Natural Language Understanding of Air Traffic Control  Communications",
    "abstract": "Personal assistants, automatic speech recognizers and dialogue understanding\nsystems are becoming more critical in our interconnected digital world. A clear\nexample is air traffic control (ATC) communications. ATC aims at guiding\naircraft and controlling the airspace in a safe and optimal manner. These\nvoice-based dialogues are carried between an air traffic controller (ATCO) and\npilots via very-high frequency radio channels. In order to incorporate these\nnovel technologies into ATC (low-resource domain), large-scale annotated\ndatasets are required to develop the data-driven AI systems. Two examples are\nautomatic speech recognition (ASR) and natural language understanding (NLU). In\nthis paper, we introduce the ATCO2 corpus, a dataset that aims at fostering\nresearch on the challenging ATC field, which has lagged behind due to lack of\nannotated data. The ATCO2 corpus covers 1) data collection and pre-processing,\n2) pseudo-annotations of speech data, and 3) extraction of ATC-related named\nentities. The ATCO2 corpus is split into three subsets. 1) ATCO2-test-set\ncorpus contains 4 hours of ATC speech with manual transcripts and a subset with\ngold annotations for named-entity recognition (callsign, command, value). 2)\nThe ATCO2-PL-set corpus consists of 5281 hours of unlabeled ATC data enriched\nwith automatic transcripts from an in-domain speech recognizer, contextual\ninformation, speaker turn information, signal-to-noise ratio estimate and\nEnglish language detection score per sample. Both available for purchase\nthrough ELDA at this http URL 3)\nThe ATCO2-test-set-1h corpus is a one-hour subset from the original test set\ncorpus, that we are offering for free at https://www.atco2.org/data. We expect\nthe ATCO2 corpus will foster research on robust ASR and NLU not only in the\nfield of ATC communications but also in the general research community.",
    "descriptor": "\nComments: Manuscript under review; The code will be available at this https URL\n",
    "authors": [
      "Juan Zuluaga-Gomez",
      "Karel Vesel\u00fd",
      "Igor Sz\u00f6ke",
      "Petr Motlicek",
      "Martin Kocour",
      "Mickael Rigault",
      "Khalid Choukri",
      "Amrutha Prasad",
      "Seyyed Saeed Sarfjoo",
      "Iuliia Nigmatulina",
      "Claudia Cevenini",
      "Pavel Kol\u010d\u00e1rek",
      "Allan Tart",
      "Jan \u010cernock\u00fd"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04054"
  },
  {
    "id": "arXiv:2211.04056",
    "title": "Stress Propagation in Human-Robot Teams Based on Computational Logic  Model",
    "abstract": "Mission teams are exposed to the emotional toll of life and death decisions.\nThese are small groups of specially trained people supported by intelligent\nmachines for dealing with stressful environments and scenarios. We developed a\ncomposite model for stress monitoring in such teams of human and autonomous\nmachines. This modelling aims to identify the conditions that may contribute to\nmission failure. The proposed model is composed of three parts: 1) a\ncomputational logic part that statically describes the stress states of\nteammates; 2) a decision part that manifests the mission status at any time; 3)\na stress propagation part based on standard Susceptible-Infected-Susceptible\n(SIS) paradigm. In contrast to the approaches such as agent-based, random-walk\nand game models, the proposed model combines various mechanisms to satisfy the\nconditions of stress propagation in small groups. Our core approach involves\ndata structures such as decision tables and decision diagrams. These tools are\nadaptable to human-machine teaming as well.",
    "descriptor": "\nComments: Submitted to IEEE Aerospace 2023 conference\n",
    "authors": [
      "Peter Shmerko",
      "Yumi Iwashita",
      "Adrian Stoica",
      "Svetlana Yanushkevich"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.04056"
  },
  {
    "id": "arXiv:2211.04060",
    "title": "High-resolution embedding extractor for speaker diarisation",
    "abstract": "Speaker embedding extractors significantly influence the performance of\nclustering-based speaker diarisation systems. Conventionally, only one\nembedding is extracted from each speech segment. However, because of the\nsliding window approach, a segment easily includes two or more speakers owing\nto speaker change points. This study proposes a novel embedding extractor\narchitecture, referred to as a high-resolution embedding extractor (HEE), which\nextracts multiple high-resolution embeddings from each speech segment. Hee\nconsists of a feature-map extractor and an enhancer, where the enhancer with\nthe self-attention mechanism is the key to success. The enhancer of HEE\nreplaces the aggregation process; instead of a global pooling layer, the\nenhancer combines relative information to each frame via attention leveraging\nthe global context. Extracted dense frame-level embeddings can each represent a\nspeaker. Thus, multiple speakers can be represented by different frame-level\nfeatures in each segment. We also propose an artificially generating mixture\ndata training framework to train the proposed HEE. Through experiments on five\nevaluation sets, including four public datasets, the proposed HEE demonstrates\nat least 10% improvement on each evaluation set, except for one dataset, which\nwe analyse that rapid speaker changes less exist.",
    "descriptor": "\nComments: 5pages, 2 figure, 3 tables, submitted to ICASSP\n",
    "authors": [
      "Hee-Soo Heo",
      "Youngki Kwon",
      "Bong-Jin Lee",
      "You Jin Kim",
      "Jee-weon Jung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04060"
  },
  {
    "id": "arXiv:2211.04062",
    "title": "Concurrent Downlink and Uplink Joint Communication and Sensing for 6G  Networks",
    "abstract": "Joint communication and sensing (JCAS) is a promising technology for 6th\nGeneration (6G) mobile networks, such as intelligent vehicular networks,\nintelligent manufacturing, and so on. Equipped with two spatially separated\nantenna arrays, the base station (BS) can perform downlink active JCAS in a\nmono-static setup. This paper proposes a Concurrent Downlink and Uplink (CDU)\nJCAS system where the BS can use the echo of transmitted dedicated signals for\nsensing in the uplink timeslot, while performing reliable uplink communication.\nA novel successive interference cancellation-based CDU JCAS processing method\nis proposed to enable the estimation of uplink communication symbols and\ndownlink sensing parameters. Extensive simulation results verify the\nfeasibility of the CDU JCAS system, showing a performance improvement of more\nthan 10 dB compared to traditional JCAS methods while maintaining reliable\nuplink communication.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to IEEE transactions on vehicular technology correspondence\n",
    "authors": [
      "Xu Chen",
      "Zhiyong Feng",
      "Zhiqing Wei",
      "J. Andrew Zhang",
      "Xin Yuan",
      "Ping Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04062"
  },
  {
    "id": "arXiv:2211.04063",
    "title": "Sensing-aided Uplink Channel Estimation for Joint Communication and  Sensing",
    "abstract": "The joint communication and sensing (JCAS) technique has drawn great\nattention due to its high spectrum efficiency by using the same transmit signal\nfor both communication and sensing. Exploiting the correlation between the\nuplink (UL) channel and the sensing results, we propose a sensing-aided Kalman\nfilter (SAKF)-based channel state information (CSI) estimation method for UL\nJCAS, which exploits the angle-of-arrival (AoA) estimation to improve the CSI\nestimation accuracy. A Kalman filter (KF)-based CSI enhancement method is\nproposed to refine the least-square CSI estimation by exploiting the estimated\nAoA as the prior information. Simulation results show that the bit error rates\n(BER) of UL communication using the proposed SAKF-based CSI estimation method\napproach those using the minimum mean square error (MMSE) method, while at\nsignificantly reduced complexity.",
    "descriptor": "\nComments: 4 pages, 5 figures, IEEE letter\n",
    "authors": [
      "Xu Chen",
      "Zhiyong Feng",
      "J. Andrew Zhang",
      "Zhiqing Wei",
      "Xin Yuan",
      "Ping Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.04063"
  },
  {
    "id": "arXiv:2211.04064",
    "title": "Multiple Signal Classification Based Joint Communication and Sensing  System",
    "abstract": "Joint communication and sensing (JCS) has become a promising technology for\nmobile networks because of its higher spectrum and energy efficiency. Up to\nnow, the prevalent fast Fourier transform (FFT)-based sensing method for mobile\nJCS networks is on-grid based, and the grid interval determines the resolution.\nBecause the mobile network usually has limited consecutive OFDM symbols in a\ndownlink (DL) time slot, the sensing accuracy is restricted by the limited\nresolution, especially for velocity estimation. In this paper, we propose a\nmultiple signal classification (MUSIC)-based JCS system that can achieve higher\nsensing accuracy for the angle of arrival, range, and velocity estimation,\ncompared with the traditional FFT-based JCS method. We further propose a JCS\nchannel state information (CSI) enhancement method by leveraging the JCS\nsensing results. Finally, we derive a theoretical lower bound for sensing mean\nsquare error (MSE) by using perturbation analysis. Simulation results show that\nin terms of the sensing MSE performance, the proposed MUSIC-based JCS\noutperforms the FFT-based one by more than 20 dB. Moreover, the bit error rate\n(BER) of communication demodulation using the proposed JCS CSI enhancement\nmethod is significantly reduced compared with communication using the\noriginally estimated CSI.",
    "descriptor": "\nComments: 30 pages, 10 figures, major revision to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Xu Chen",
      "Zhiyong Feng",
      "Zhiqing Wei",
      "Xin Yuan",
      "Ping Zhang",
      "J. Andrew Zhang",
      "Heng Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04064"
  },
  {
    "id": "arXiv:2211.04065",
    "title": "Downlink and Uplink Cooperative Joint Communication and Sensing",
    "abstract": "Downlink (DL) and uplink (UL) joint communication and sensing (JCAS)\ntechnologies have been individually studied for realizing sensing using DL and\nUL communication signals, respectively. Since the spatial environment and JCAS\nchannels in the consecutive DL and UL JCAS time slots are generally unchanged,\nDL and UL JCAS may be jointly designed to achieve better sensing performance.\nIn this paper, we propose a novel DL and UL cooperative (DUC) JCAS scheme,\nincluding a unified multiple signal classification (MUSIC)-based JCAS sensing\nscheme for both DL and UL JCAS and a DUC JCAS fusion method. The unified MUSIC\nJCAS sensing scheme can accurately estimate AoA, range, and Doppler based on a\nunified MUSIC-based sensing module. The DUC JCAS fusion method can distinguish\nbetween the sensing results of the communication user and other dumb targets.\nMoreover, by exploiting the channel reciprocity, it can also improve the\nsensing and channel state information (CSI) estimation accuracy. Extensive\nsimulation results validate the proposed DUC JCAS scheme. It is shown that the\nminimum location and velocity estimation mean square errors of the proposed DUC\nJCAS scheme are about 20 dB lower than those of the state-of-the-art separated\nDL and UL JCAS schemes.",
    "descriptor": "\nComments: 14 pages, 10 figures, submitted to IEEE Transactions on Communications\n",
    "authors": [
      "Xu Chen",
      "Zhiyong Feng",
      "Zhiqing Wei",
      "J. Andrew Zhang",
      "Xin Yuan",
      "Ping Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04065"
  },
  {
    "id": "arXiv:2211.04067",
    "title": "Efficient Global Occupancy Mapping for Mobile Robots using OpenVDB",
    "abstract": "In this work we present a fast occupancy map building approach based on the\nVDB datastructure. Existing log-odds based occupancy mapping systems are often\nnot able to keep up with the high point densities and framerates of modern\nsensors. Therefore, we suggest a highly optimized approach based on a modern\ndatastructure coming from a computer graphic background. A multithreaded\ninsertion scheme allows occupancy map building at unprecedented speed. Multiple\noptimizations allow for a customizable tradeoff between runtime and map\nquality. We first demonstrate the effectiveness of the approach quantitatively\non a set of ablation studies and typical benchmark sets, before we practically\ndemonstrate the system using a legged robot and a UAV.",
    "descriptor": "\nComments: 6 pages, presented in Agile Robotics Workshop at IROS2022\n",
    "authors": [
      "Raphael Hagmanns",
      "Thomas Emter",
      "Marvin Grosse-Besselmann",
      "J\u00fcrgen Beyerer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04067"
  },
  {
    "id": "arXiv:2211.04071",
    "title": "Improving performance of real-time full-band blind packet-loss  concealment with predictive network",
    "abstract": "Packet loss concealment (PLC) is a tool for enhancing speech degradation\ncaused by poor network conditions or underflow/overflow in audio processing\npipelines. We propose a real-time recurrent method that leverages previous\noutputs to mitigate artefact of lost packets without the prior knowledge of\nloss mask. The proposed full-band recurrent network (FRN) model operates at\n48~kHz, which is suitable for high-quality telecommunication applications.\nExperiment results highlight the superiority of FRN over an offline non-causal\nbaseline and a top performer in a recent PLC challenge.",
    "descriptor": "\nComments: Submitted to ICASSP 2023, 5 pages, 1 figure, 4 tables\n",
    "authors": [
      "Viet-Anh Nguyen",
      "Anh H. T. Nguyen",
      "Andy W. H. Khong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04071"
  },
  {
    "id": "arXiv:2211.04076",
    "title": "Linear Self-Attention Approximation via Trainable Feedforward Kernel",
    "abstract": "In pursuit of faster computation, Efficient Transformers demonstrate an\nimpressive variety of approaches -- models attaining sub-quadratic attention\ncomplexity can utilize a notion of sparsity or a low-rank approximation of\ninputs to reduce the number of attended keys; other ways to reduce complexity\ninclude locality-sensitive hashing, key pooling, additional memory to store\ninformation in compacted or hybridization with other architectures, such as\nCNN. Often based on a strong mathematical basis, kernelized approaches allow\nfor the approximation of attention with linear complexity while retaining high\naccuracy. Therefore, in the present paper, we aim to expand the idea of\ntrainable kernel methods to approximate the self-attention mechanism of the\nTransformer architecture.",
    "descriptor": "",
    "authors": [
      "Uladzislau Yorsh",
      "Alexander Kovalenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04076"
  },
  {
    "id": "arXiv:2211.04079",
    "title": "COPEN: Probing Conceptual Knowledge in Pre-trained Language Models",
    "abstract": "Conceptual knowledge is fundamental to human cognition and knowledge bases.\nHowever, existing knowledge probing works only focus on evaluating factual\nknowledge of pre-trained language models (PLMs) and ignore conceptual\nknowledge. Since conceptual knowledge often appears as implicit commonsense\nbehind texts, designing probes for conceptual knowledge is hard. Inspired by\nknowledge representation schemata, we comprehensively evaluate conceptual\nknowledge of PLMs by designing three tasks to probe whether PLMs organize\nentities by conceptual similarities, learn conceptual properties, and\nconceptualize entities in contexts, respectively. For the tasks, we collect and\nannotate 24k data instances covering 393 concepts, which is COPEN, a COnceptual\nknowledge Probing bENchmark. Extensive experiments on different sizes and types\nof PLMs show that existing PLMs systematically lack conceptual knowledge and\nsuffer from various spurious correlations. We believe this is a critical\nbottleneck for realizing human-like cognition in PLMs. COPEN and our codes are\npublicly released at https://github.com/THU-KEG/COPEN.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Hao Peng",
      "Xiaozhi Wang",
      "Shengding Hu",
      "Hailong Jin",
      "Lei Hou",
      "Juanzi Li",
      "Zhiyuan Liu",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04079"
  },
  {
    "id": "arXiv:2211.04085",
    "title": "Detection and depth estimation for domestic waste in outdoor  environments by sensors fusion",
    "abstract": "In this work, we estimate the depth in which domestic waste are located in\nspace from a mobile robot in outdoor scenarios. As we are doing this calculus\non a broad range of space (0.3 - 6.0 m), we use RGB-D camera and LiDAR fusion.\nWith this aim and range, we compare several methods such as average, nearest,\nmedian and center point, applied to those which are inside a reduced or\nnon-reduced Bounding Box (BB). These BB are obtained from segmentation and\ndetection methods which are representative of these techniques like Yolact,\nSOLO, You Only Look Once (YOLO)v5, YOLOv6 and YOLOv7. Results shown that,\napplying a detection method with the average technique and a reduction of BB of\n40%, returns the same output as segmenting the object and applying the average\nmethod. Indeed, the detection method is faster and lighter in comparison with\nthe segmentation one. The committed median error in the conducted experiments\nwas 0.0298 ${\\pm}$ 0.0544 m.",
    "descriptor": "\nComments: This work has been submitted to IFAC WC 2023 for possible publication\n",
    "authors": [
      "Ignacio de L. P\u00e1ez-Ubieta",
      "Edison Velasco-S\u00e1nchez",
      "Santiago T. Puente",
      "Francisco A. Candelas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04085"
  },
  {
    "id": "arXiv:2211.04086",
    "title": "Does an ensemble of GANs lead to better performance when training  segmentation networks with synthetic images?",
    "abstract": "Large annotated datasets are required to train segmentation networks. In\nmedical imaging, it is often difficult, time consuming and expensive to create\nsuch datasets, and it may also be difficult to share these datasets with other\nresearchers. Different AI models can today generate very realistic synthetic\nimages, which can potentially be openly shared as they do not belong to\nspecific persons. However, recent work has shown that using synthetic images\nfor training deep networks often leads to worse performance compared to using\nreal images. Here we demonstrate that using synthetic images and annotations\nfrom an ensemble of 10 GANs, instead of from a single GAN, increases the Dice\nscore on real test images with 4.7 % to 14.0 % on specific classes.",
    "descriptor": "\nComments: 5 pages, submitted to ISBI 2023\n",
    "authors": [
      "M\u00e5ns Larsson",
      "Muhammad Usman Akbar",
      "Anders Eklund"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.04086"
  },
  {
    "id": "arXiv:2211.04088",
    "title": "A Penalty Based Method for Communication-Efficient Decentralized Bilevel  Programming",
    "abstract": "Bilevel programming has recently received attention in the literature, due to\na wide range of applications, including reinforcement learning and\nhyper-parameter optimization. However, it is widely assumed that the underlying\nbilevel optimization problem is solved either by a single machine or in the\ncase of multiple machines connected in a star-shaped network, i.e., federated\nlearning setting. The latter approach suffers from a high communication cost on\nthe central node (e.g., parameter server) and exhibits privacy vulnerabilities.\nHence, it is of interest to develop methods that solve bilevel optimization\nproblems in a communication-efficient decentralized manner. To that end, this\npaper introduces a penalty function based decentralized algorithm with\ntheoretical guarantees for this class of optimization problems. Specifically, a\ndistributed alternating gradient-type algorithm for solving consensus bilevel\nprogramming over a decentralized network is developed. A key feature of the\nproposed algorithm is to estimate the hyper-gradient of the penalty function\nvia decentralized computation of matrix-vector products and few vector\ncommunications, which is then integrated within our alternating algorithm to\ngive the finite-time convergence analysis under different convexity\nassumptions. Owing to the generality of this complexity analysis, our result\nyields convergence rates for a wide variety of consensus problems including\nminimax and compositional optimization. Empirical results on both synthetic and\nreal datasets demonstrate that the proposed method works well in practice.",
    "descriptor": "",
    "authors": [
      "Parvin Nazari",
      "Ahmad Mousavi",
      "Davoud Ataee Tarzanagh",
      "George Michailidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.04088"
  },
  {
    "id": "arXiv:2211.04094",
    "title": "The French National 3D Data Repository for Humanities: Features,  Feedback and Open Questions",
    "abstract": "We introduce the French National 3D Data Repository for Humanities designed\nfor the conservation and the publication of 3D research data in the field of\nHumanities and Social Sciences. We present the choices made for the data\norganization, metadata, standards and infrastructure towards a FAIR service.\nWith 437 references at the time of the writing, we have feedback on some\nchallenges to develop such a service and to make it widely used. This leads to\nopen questions and future developments.",
    "descriptor": "\nComments: CAA 2021 - \"Digital Crossroads\" full paper version (in review)\n",
    "authors": [
      "Sarah Tournon-Valiente",
      "Vincent Baillet",
      "Mehdi Chayani",
      "Bruno Dutailly",
      "Xavier Granier",
      "Valentin Grimaud"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.04094"
  },
  {
    "id": "arXiv:2211.04098",
    "title": "Abstraction-Based Verification of Approximate Pre-Opacity for Control  Systems",
    "abstract": "In this paper, we consider the problem of verifying pre-opacity for\ndiscrete-time control systems. Pre-opacity is an important information-flow\nsecurity property that secures the intention of a system to execute some secret\nbehaviors in the future. Existing works on pre-opacity only consider non-metric\ndiscrete systems, where it is assumed that intruders can distinguish different\noutput behaviors precisely. However, for continuous-space control systems whose\noutput sets are equipped with metrics (which is the case for most real-world\napplications), it is too restrictive to assume precise measurements from\noutside observers. In this paper, we first introduce a concept of approximate\npre-opacity by capturing the security level of control systems with respect to\nthe measurement precision of the intruder. Based on this new notion of\npre-opacity, we propose a verification approach for continuous-space control\nsystems by leveraging abstraction-based techniques. In particular, a new\nconcept of approximate pre-opacity preserving simulation relation is introduced\nto characterize the distance between two systems in terms of preserving\npre-opacity. This new system relation allows us to verify pre-opacity of\ncomplex continuous-space control systems using their finite abstractions. We\nalso present a method to construct pre-opacity preserving finite abstractions\nfor a class of discrete-time control systems under certain stability\nassumptions.",
    "descriptor": "\nComments: Discrete Event Systems, Opacity, Formal Abstractions\n",
    "authors": [
      "Junyao Hou",
      "Siyuan Liu",
      "Xiang Yin",
      "Majid Zamani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2211.04098"
  },
  {
    "id": "arXiv:2211.04100",
    "title": "GENIUS: A Novel Solution for Subteam Replacement with Clustering-based  Graph Neural Network",
    "abstract": "Subteam replacement is defined as finding the optimal candidate set of people\nwho can best function as an unavailable subset of members (i.e., subteam) for\ncertain reasons (e.g., conflicts of interests, employee churn), given a team of\npeople embedded in a social network working on the same task. Prior\ninvestigations on this problem incorporate graph kernel as the optimal criteria\nfor measuring the similarity between the new optimized team and the original\nteam. However, the increasingly abundant social networks reveal fundamental\nlimitations of existing methods, including (1) the graph kernel-based\napproaches are powerless to capture the key intrinsic correlations among node\nfeatures, (2) they generally search over the entire network for every member to\nbe replaced, making it extremely inefficient as the network grows, and (3) the\nrequirement of equal-sized replacement for the unavailable subteam can be\ninapplicable due to limited hiring budget. In this work, we address the\nlimitations in the state-of-the-art for subteam replacement by (1) proposing\nGENIUS, a novel clustering-based graph neural network (GNN) framework that can\ncapture team network knowledge for flexible subteam replacement, and (2)\nequipping the proposed GENIUS with self-supervised positive team contrasting\ntraining scheme to improve the team-level representation learning and\nunsupervised node clusters to prune candidates for fast computation. Through\nextensive empirical evaluations, we demonstrate the efficacy of the proposed\nmethod (1) effectiveness: being able to select better candidate members that\nsignificantly increase the similarity between the optimized and original teams,\nand (2) efficiency: achieving more than 600 times speed-up in average running\ntime.",
    "descriptor": "",
    "authors": [
      "Chuxuan Hu",
      "Qinghai Zhou",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.04100"
  },
  {
    "id": "arXiv:2211.04101",
    "title": "Factors that Contribute to the Success of a Software Organisation's  DevOps Environment: A Systematic Review",
    "abstract": "This research assesses the aspects of software organizations' DevOps\nenvironments and identifies the factors contributing to these environments'\nsuccess. DevOps is a recent concept, and many organizations are moving from\nold-style software development methods to agile approaches such as DevOps.\nHowever, there is no comprehensive information on what factors impact the\nsuccess of the DevOps environment once organizations adopt it. This research\nfocused on addressing this gap through a systematic literature review. The\nsystematic review consisted of 33 articles from five selected search systems\nand databases from 2015 to 2021. Based on the included articles, 15 factors\nwere identified and grouped into four categories: Collaborative Culture,\nOrganizational Aspects, Tooling and Technology, and Continuous Practices. In\naddition, this research proposes a DevOps environment success factors model to\npotentially contribute to DevOps research and practice. Recommendations are\nmade for additional research on the effectiveness of the proposed model and its\nsuccess factors.",
    "descriptor": "\nComments: 15 pages, 3 figures, 1 table\n",
    "authors": [
      "Ashley Gwangwadza",
      "Ridewaan Hanslo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.04101"
  },
  {
    "id": "arXiv:2211.04105",
    "title": "Horizontal collaboration in forestry: game theory models and algorithms  for trading demands",
    "abstract": "In this paper, we introduce a new cooperative game theory model that we call\nproduction-distribution game to address a major open problem for operations\nresearch in forestry, raised by R\\\"onnqvist et al. in 2015, namely, that of\nmodelling and proposing efficient sharing principles for practical\ncollaboration in transportation in this sector. The originality of our model\nlies in the fact that the value/strength of a player does not only depend on\nthe individual cost or benefit of the objects she owns but also depends on her\nmarket shares (customers demand). We show however that the\nproduction-distribution game is an interesting special case of a market game\nintroduced by Shapley and Shubik in 1969. As such it exhibits the nice property\nof having a non-empty core. We then prove that we can compute both the\nnucleolus and the Shapley value efficiently, in a nontrivial and interesting\nspecial case. We in particular provide two different algorithms to compute the\nnucleolus: a simple separation algorithm and a fast primal-dual algorithm. Our\nresults can be used to tackle more general versions of the problem and we\nbelieve that our contribution paves the way towards solving the challenging\nopen problem herein.",
    "descriptor": "",
    "authors": [
      "Mourad Ba\u00efou",
      "Gianpaolo Oriolo",
      "Gautier Stauffer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.04105"
  },
  {
    "id": "arXiv:2211.04107",
    "title": "Do Mutable Variables Have Reference Types?",
    "abstract": "Implicit heterogeneous metaprogramming (a.k.a. offshoring) is an attractive\napproach for generating C with some correctness guarantees: generate OCaml\ncode, where the correctness guarantees are easier to establish, and then map\nthat code to C. The key idea is that simple imperative OCaml code looks like a\nnon-standard notation for C. Regretfully, it is false, when it comes to mutable\nvariables. In the past, the approach was salvaged by imposing strong ad hoc\nrestrictions. The present paper for the first time investigates the problem\nsystematically and discovers general solutions needing no restrictions. In the\nprocess we explicate the subtleties of modeling mutable variables by values of\nreference types and arrive at an intuitively and formally clear correspondence.\nWe also explain C assignment without resorting to L-values.",
    "descriptor": "\nComments: Peer-reviewed, accepted for presentation and presented at the ACM SIGPLAN ML Family Workshop 2022\n",
    "authors": [
      "Oleg Kiselyov"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.04107"
  },
  {
    "id": "arXiv:2211.04108",
    "title": "Determining Accessible Sidewalk Width by Extracting Obstacle Information  from Point Clouds",
    "abstract": "Obstacles on the sidewalk often block the path, limiting passage and\nresulting in frustration and wasted time, especially for citizens and visitors\nwho use assistive devices (wheelchairs, walkers, strollers, canes, etc). To\nenable equal participation and use of the city, all citizens should be able to\nperform and complete their daily activities in a similar amount of time and\neffort. Therefore, we aim to offer accessibility information regarding\nsidewalks, so that citizens can better plan their routes, and to help city\nofficials identify the location of bottlenecks and act on them. In this paper\nwe propose a novel pipeline to estimate obstacle-free sidewalk widths based on\n3D point cloud data of the city of Amsterdam, as the first step to offer a more\ncomplete set of information regarding sidewalk accessibility.",
    "descriptor": "\nComments: 4 pages, 9 figures. Presented at the workshop on \"The Future of Urban Accessibility\" at ACM ASSETS'22. Code for this paper is available at this https URL\n",
    "authors": [
      "Cl\u00e1udia Fonseca Pinh\u00e3o",
      "Chris Eijgenstein",
      "Iva Gornishka",
      "Shayla Jansen",
      "Diederik M. Roijers",
      "Daan Bloembergen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04108"
  },
  {
    "id": "arXiv:2211.04110",
    "title": "Privacy Meets Explainability: A Comprehensive Impact Benchmark",
    "abstract": "Since the mid-10s, the era of Deep Learning (DL) has continued to this day,\nbringing forth new superlatives and innovations each year. Nevertheless, the\nspeed with which these innovations translate into real applications lags behind\nthis fast pace. Safety-critical applications, in particular, underlie strict\nregulatory and ethical requirements which need to be taken care of and are\nstill active areas of debate. eXplainable AI (XAI) and privacy-preserving\nmachine learning (PPML) are both crucial research fields, aiming at mitigating\nsome of the drawbacks of prevailing data-hungry black-box models in DL. Despite\nbrisk research activity in the respective fields, no attention has yet been\npaid to their interaction. This work is the first to investigate the impact of\nprivate learning techniques on generated explanations for DL-based models. In\nan extensive experimental analysis covering various image and time series\ndatasets from multiple domains, as well as varying privacy techniques, XAI\nmethods, and model architectures, the effects of private training on generated\nexplanations are studied. The findings suggest non-negligible changes in\nexplanations through the introduction of privacy. Apart from reporting\nindividual effects of PPML on XAI, the paper gives clear recommendations for\nthe choice of techniques in real applications. By unveiling the\ninterdependencies of these pivotal technologies, this work is a first step\ntowards overcoming the remaining hurdles for practically applicable AI in\nsafety-critical domains.",
    "descriptor": "\nComments: Under Submission\n",
    "authors": [
      "Saifullah Saifullah",
      "Dominique Mercier",
      "Adriano Lucieri",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04110"
  },
  {
    "id": "arXiv:2211.04112",
    "title": "Improved Pattern-Avoidance Bounds for Greedy BSTs via Matrix  Decomposition",
    "abstract": "Greedy BST (or simply Greedy) is an online self-adjusting binary search tree\ndefined in the geometric view ([Lucas, 1988; Munro, 2000; Demaine, Harmon,\nIacono, Kane, Patrascu, SODA 2009). Along with Splay trees (Sleator, Tarjan\n1985), Greedy is considered the most promising candidate for being dynamically\noptimal, i.e., starting with any initial tree, their access costs on any\nsequence is conjectured to be within $O(1)$ factor of the offline optimal.\nHowever, in the past four decades, the question has remained elusive even for\nhighly restricted input.\nIn this paper, we prove new bounds on the cost of Greedy in the ''pattern\navoidance'' regime. Our new results include:\nThe (preorder) traversal conjecture for Greedy holds up to a factor of\n$O(2^{\\alpha(n)})$, improving upon the bound of $2^{\\alpha(n)^{O(1)}}$ in\n(Chalermsook et al., FOCS 2015). This is the best known bound obtained by any\nonline BSTs.\nWe settle the postorder traversal conjecture for Greedy.\nThe deque conjecture for Greedy holds up to a factor of $O(\\alpha(n))$,\nimproving upon the bound $2^{O(\\alpha(n))}$ in (Chalermsook, et al., WADS\n2015).\nThe split conjecture holds for Greedy up to a factor of $O(2^{\\alpha(n)})$.\nKey to all these results is to partition (based on the input structures) the\nexecution log of Greedy into several simpler-to-analyze subsets for which\nclassical forbidden submatrix bounds can be leveraged. Finally, we show the\napplicability of this technique to handle a class of increasingly complex\npattern-avoiding input sequences, called $k$-increasing sequences.\nAs a bonus, we discover a new class of permutation matrices whose extremal\nbounds are polynomially bounded. This gives a partial progress on an open\nquestion by Jacob Fox (2013).",
    "descriptor": "\nComments: Accepted to SODA 2023\n",
    "authors": [
      "Parinya Chalermsook",
      "Manoj Gupta",
      "Wanchote Jiamjitrak",
      "Nidia Obscura Acosta",
      "Akash Pareek",
      "Sorrachai Yingchareonthawornchai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04112"
  },
  {
    "id": "arXiv:2211.04117",
    "title": "Computing better approximate pure Nash equilibria in cut games via  semidefinite programming",
    "abstract": "Cut games are among the most fundamental strategic games in algorithmic game\ntheory. It is well-known that computing an exact pure Nash equilibrium in these\ngames is PLS-hard, so research has focused on computing approximate equilibria.\nWe present a polynomial-time algorithm that computes $2.7371$-approximate pure\nNash equilibria in cut games. This is the first improvement to the previously\nbest-known bound of $3$, due to the work of Bhalgat, Chakraborty, and Khanna\nfrom EC 2010. Our algorithm is based on a general recipe proposed by\nCaragiannis, Fanelli, Gravin, and Skopalik from FOCS 2011 and applied on\nseveral potential games since then. The first novelty of our work is the\nintroduction of a phase that can identify subsets of players who can\nsimultaneously improve their utilities considerably. This is done via\nsemidefinite programming and randomized rounding. In particular, a negative\nobjective value to the semidefinite program guarantees that no such\nconsiderable improvement is possible for a given set of players. Otherwise,\nrandomized rounding of the SDP solution is used to identify a set of players\nwho can simultaneously improve their strategies considerably and allows the\nalgorithm to make progress. The way rounding is performed is another important\nnovelty of our work. Here, we exploit an idea that dates back to a paper by\nFeige and Goemans from 1995, but we take it to an extreme that has not been\nanalyzed before.",
    "descriptor": "",
    "authors": [
      "Ioannis Caragiannis",
      "Zhile Jiang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04117"
  },
  {
    "id": "arXiv:2211.04118",
    "title": "ConsPrompt: Easily Exploiting Contrastive Samples for Few-shot Prompt  Learning",
    "abstract": "Prompt learning recently become an effective linguistic tool to motivate the\nPLMs' knowledge on few-shot-setting tasks. However, studies have shown the lack\nof robustness still exists in prompt learning, since suitable initialization of\ncontinuous prompt and expert-first manual prompt are essential in fine-tuning\nprocess. What is more, human also utilize their comparative ability to motivate\ntheir existing knowledge for distinguishing different examples. Motivated by\nthis, we explore how to use contrastive samples to strengthen prompt learning.\nIn detail, we first propose our model ConsPrompt combining with prompt encoding\nnetwork, contrastive sampling module, and contrastive scoring module.\nSubsequently, two sampling strategies, similarity-based and label-based\nstrategies, are introduced to realize differential contrastive learning. The\neffectiveness of proposed ConsPrompt is demonstrated in five different few-shot\nlearning tasks and shown the similarity-based sampling strategy is more\neffective than label-based in combining contrastive learning. Our results also\nexhibits the state-of-the-art performance and robustness in different few-shot\nsettings, which proves that the ConsPrompt could be assumed as a better\nknowledge probe to motivate PLMs.",
    "descriptor": "",
    "authors": [
      "Jinta Weng",
      "Yue Hu",
      "Zhihong Tian",
      "Heyan Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04118"
  },
  {
    "id": "arXiv:2211.04119",
    "title": "Simulation-Based Parallel Training",
    "abstract": "Numerical simulations are ubiquitous in science and engineering. Machine\nlearning for science investigates how artificial neural architectures can learn\nfrom these simulations to speed up scientific discovery and engineering\nprocesses. Most of these architectures are trained in a supervised manner. They\nrequire tremendous amounts of data from simulations that are slow to generate\nand memory greedy. In this article, we present our ongoing work to design a\ntraining framework that alleviates those bottlenecks. It generates data in\nparallel with the training process. Such simultaneity induces a bias in the\ndata available during the training. We present a strategy to mitigate this bias\nwith a memory buffer. We test our framework on the multi-parametric Lorenz's\nattractor. We show the benefit of our framework compared to offline training\nand the success of our data bias mitigation strategy to capture the complex\nchaotic dynamics of the system.",
    "descriptor": "",
    "authors": [
      "Lucas Meyer",
      "Alejandro Rib\u00e9s",
      "Bruno Raffin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04119"
  },
  {
    "id": "arXiv:2211.04123",
    "title": "Cost-optimal adaptive iterative linearized FEM for semilinear elliptic  PDEs",
    "abstract": "We consider scalar semilinear elliptic PDEs where the nonlinearity is\nstrongly monotone, but only locally Lipschitz continuous. We formulate an\nadaptive iterative linearized finite element method (AILFEM) which steers the\nlocal mesh refinement as well as the iterative linearization of the arising\nnonlinear discrete equations. To this end, we employ a damped Zarantonello\niteration so that, in each step of the algorithm, only a linear Poisson-type\nequation has to be solved. We prove that the proposed AILFEM strategy\nguarantees convergence with optimal rates, where rates are understood with\nrespect to the overall computational complexity (i.e., the computational time).\nMoreover, we formulate and test an adaptive algorithm where also the damping\nparameter of the Zarantonello iteration is adaptively adjusted. Numerical\nexperiments underline the theoretical findings.",
    "descriptor": "",
    "authors": [
      "Roland Becker",
      "Maximilian Brunner",
      "Michael Innerberger",
      "Jens Markus Melenk",
      "Dirk Praetorius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04123"
  },
  {
    "id": "arXiv:2211.04125",
    "title": "Efficacy of MRI data harmonization in the age of machine learning. A  multicenter study across 36 datasets",
    "abstract": "Pooling publicly-available MRI data from multiple sites allows to assemble\nextensive groups of subjects, increase statistical power, and promote data\nreuse with machine learning techniques. The harmonization of multicenter data\nis necessary to reduce the confounding effect associated with non-biological\nsources of variability in the data. However, when applied to the entire dataset\nbefore machine learning, the harmonization leads to data leakage, because\ninformation outside the training set may affect model building, and potentially\nfalsely overestimate performance. We propose a 1) measurement of the efficacy\nof data harmonization; 2) harmonizer transformer, i.e., an implementation of\nthe ComBat harmonization allowing its encapsulation among the preprocessing\nsteps of a machine learning pipeline, avoiding data leakage. We tested these\ntools using brain T1-weighted MRI data from 1740 healthy subjects acquired at\n36 sites. After harmonization, the site effect was removed or reduced, and we\nmeasured the data leakage effect in predicting individual age from MRI data,\nhighlighting that introducing the harmonizer transformer into a machine\nlearning pipeline allows for avoiding data leakage.",
    "descriptor": "",
    "authors": [
      "Chiara Marzi",
      "Marco Giannelli",
      "Andrea Barucci",
      "Carlo Tessa",
      "Mario Mascalchi",
      "Stefano Diciotti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.04125"
  },
  {
    "id": "arXiv:2211.04126",
    "title": "Conciseness: An Overlooked Language Task",
    "abstract": "We report on novel investigations into training models that make sentences\nconcise. We define the task and show that it is different from related tasks\nsuch as summarization and simplification. For evaluation, we release two test\nsets, consisting of 2000 sentences each, that were annotated by two and five\nhuman annotators, respectively. We demonstrate that conciseness is a difficult\ntask for which zero-shot setups with large neural language models often do not\nperform well. Given the limitations of these approaches, we propose a synthetic\ndata generation method based on round-trip translations. Using this data to\neither train Transformers from scratch or fine-tune T5 models yields our\nstrongest baselines that can be further improved by fine-tuning on an\nartificial conciseness dataset that we derived from multi-annotator machine\ntranslation test sets.",
    "descriptor": "\nComments: EMNLP 2022 Workshop on Text Simplification, Accessibility, and Readability (TSAR)\n",
    "authors": [
      "Felix Stahlberg",
      "Aashish Kumar",
      "Chris Alberti",
      "Shankar Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04126"
  },
  {
    "id": "arXiv:2211.04128",
    "title": "Active Learning with Tabular Language Models",
    "abstract": "Despite recent advancements in tabular language model research, real-world\napplications are still challenging. In industry, there is an abundance of\ntables found in spreadsheets, but acquisition of substantial amounts of labels\nis expensive, since only experts can annotate the often highly technical and\ndomain-specific tables. Active learning could potentially reduce labeling\ncosts, however, so far there are no works related to active learning in\nconjunction with tabular language models. In this paper we investigate\ndifferent acquisition functions in a real-world industrial tabular language\nmodel use case for sub-cell named entity recognition. Our results show that\ncell-level acquisition functions with built-in diversity can significantly\nreduce the labeling effort, while enforced table diversity is detrimental. We\nfurther see open fundamental questions concerning computational efficiency and\nthe perspective of human annotators.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Martin Ringsquandl",
      "Aneta Koleva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04128"
  },
  {
    "id": "arXiv:2211.04132",
    "title": "Stochastic Coded Federated Learning: Theoretical Analysis and Incentive  Mechanism Design",
    "abstract": "Federated learning (FL) has achieved great success as a privacy-preserving\ndistributed training paradigm, where many edge devices collaboratively train a\nmachine learning model by sharing the model updates instead of the raw data\nwith a server. However, the heterogeneous computational and communication\nresources of edge devices give rise to stragglers that significantly decelerate\nthe training process. To mitigate this issue, we propose a novel FL framework\nnamed stochastic coded federated learning (SCFL) that leverages coded computing\ntechniques. In SCFL, before the training process starts, each edge device\nuploads a privacy-preserving coded dataset to the server, which is generated by\nadding Gaussian noise to the projected local dataset. During training, the\nserver computes gradients on the global coded dataset to compensate for the\nmissing model updates of the straggling devices. We design a gradient\naggregation scheme to ensure that the aggregated model update is an unbiased\nestimate of the desired global update. Moreover, this aggregation scheme\nenables periodical model averaging to improve the training efficiency. We\ncharacterize the tradeoff between the convergence performance and privacy\nguarantee of SCFL. In particular, a more noisy coded dataset provides stronger\nprivacy protection for edge devices but results in learning performance\ndegradation. We further develop a contract-based incentive mechanism to\ncoordinate such a conflict. The simulation results show that SCFL learns a\nbetter model within the given time and achieves a better privacy-performance\ntradeoff than the baseline methods. In addition, the proposed incentive\nmechanism grants better training performance than the conventional Stackelberg\ngame approach.",
    "descriptor": "",
    "authors": [
      "Yuchang Sun",
      "Jiawei Shao",
      "Yuyi Mao",
      "Songze Li",
      "Jun Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04132"
  },
  {
    "id": "arXiv:2211.04134",
    "title": "Consistent Query Answering for Primary Keys and Conjunctive Queries with  Counting",
    "abstract": "The problem of consistent query answering for primary keys and self-join-free\nconjunctive queries has been intensively studied in recent years and is by now\nwell understood. In this paper, we study an extension of this problem with\ncounting. The queries we consider count how many times each value occurs in a\ndesignated (possibly composite) column of an answer to a full conjunctive\nquery. In a setting of database repairs, we adopt the semantics of [Arenas et\nal., ICDT 2001] which computes tight lower and upper bounds on these counts,\nwhere the bounds are taken over all repairs. Ariel Fuxman defined in his PhD\nthesis a syntactic class of queries, called C_forest, for which this\ncomputation can be done by executing two first-order queries (one for lower\nbounds, and one for upper bounds) followed by simple counting steps. We use the\nterm \"parsimonious counting\" for this computation. A natural question is\nwhether C_forest contains all self-join-free conjunctive queries that admit\nparsimonious counting. We answer this question negatively. We define a new\nsyntactic class of queries, called C_parsimony, and prove that it contains all\n(and only) self-join-free conjunctive queries that admit parsimonious counting.",
    "descriptor": "\nComments: 27 pages, 2 figures\n",
    "authors": [
      "Aziz Amezian El Khalfioui",
      "Jef Wijsen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.04134"
  },
  {
    "id": "arXiv:2211.04141",
    "title": "Perspectives on neural proof nets",
    "abstract": "In this paper I will present a novel way of combining proof net proof search\nwith neural networks. It contrasts with the 'standard' approach which has been\napplied to proof search in type-logical grammars in various different forms. In\nthe standard approach, we first transform words to formulas (supertagging) then\nmatch atomic formulas to obtain a proof. I will introduce an alternative way to\nsplit the task into two: first, we generate the graph structure in a way which\nguarantees it corresponds to a lambda-term, then we obtain the detailed\nstructure using vertex labelling. Vertex labelling is a well-studied task in\ngraph neural networks, and different ways of implementing graph generation\nusing neural networks will be explored.",
    "descriptor": "\nComments: This is an extended version of an invited talk for the workshop End-to-End Compositional Models of Vector-Based Semantics\n",
    "authors": [
      "Richard Moot"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04141"
  },
  {
    "id": "arXiv:2211.04142",
    "title": "Query-Specific Knowledge Graphs for Complex Finance Topics",
    "abstract": "Across the financial domain, researchers answer complex questions by\nextensively \"searching\" for relevant information to generate long-form reports.\nThis workshop paper discusses automating the construction of query-specific\ndocument and entity knowledge graphs (KGs) for complex research topics. We\nfocus on the CODEC dataset, where domain experts (1) create challenging\nquestions, (2) construct long natural language narratives, and (3) iteratively\nsearch and assess the relevance of documents and entities. For the construction\nof query-specific KGs, we show that state-of-the-art ranking systems have\nheadroom for improvement, with specific failings due to a lack of context or\nexplicit knowledge representation. We demonstrate that entity and document\nrelevance are positively correlated, and that entity-based query feedback\nimproves document ranking effectiveness. Furthermore, we construct\nquery-specific KGs using retrieval and evaluate using CODEC's \"ground-truth\ngraphs\", showing the precision and recall trade-offs. Lastly, we point to\nfuture work, including adaptive KG retrieval algorithms and GNN-based weighting\nmethods, while highlighting key challenges such as high-quality data,\ninformation extraction recall, and the size and sparsity of complex topic\ngraphs.",
    "descriptor": "\nComments: AKBC 2022 Workshop, Knowledge Graphs in Finance and Economics\n",
    "authors": [
      "Iain Mackie",
      "Jeffrey Dalton"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04142"
  },
  {
    "id": "arXiv:2211.04145",
    "title": "Prophet Inequality: Order selection beats random order",
    "abstract": "In the prophet inequality problem, a gambler faces a sequence of items\narriving online with values drawn independently from known distributions. On\nseeing an item, the gambler must choose whether to accept its value as her\nreward and quit the game, or reject it and continue. The gambler's aim is to\nmaximize her expected reward relative to the expected maximum of the values of\nall items. Since the seminal work of Krengel and Sucheston (1977,1978), a tight\nbound of 1/2 has been known for this competitive ratio in the setting where the\nitems arrive in an adversarial order. However, the optimum ratio still remains\nunknown in the order selection setting, where the gambler selects the arrival\norder, as well as in prophet secretary, where the items arrive in a random\norder. Moreover, it is not even known whether a separation exists between the\ntwo settings.\nIn this paper, we show that the power of order selection allows the gambler\nto guarantee a strictly better competitive ratio than if the items arrive\nrandomly. For the order selection setting, we identify an instance for which\nPeng and Tang's (FOCS'22) state-of-the-art algorithm performs no better than\ntheir claimed competitive ratio of (approximately) 0.7251, thus illustrating\nthe need for an improved approach. We therefore extend their design and provide\na more general algorithm design framework which allows the use of a different\ntime-dependent threshold function for each item, as opposed to the common\nthreshold function employed by Peng and Tang's algorithm. We use this framework\nto show that Peng and Tang's ratio can be beaten, by designing a\n0.7258-competitive algorithm. For the random order setting, we improve upon\nCorrea, Saona and Ziliotto's (SODA'19) 0.732-hardness result to show a hardness\nof 0.7254 for general algorithms, thus establishing a separation between the\norder selection and random order settings.",
    "descriptor": "",
    "authors": [
      "Archit Bubna",
      "Ashish Chiplunkar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.04145"
  },
  {
    "id": "arXiv:2211.04146",
    "title": "Control-Flow-Based Querying of Process Executions from Partially Ordered  Event Data",
    "abstract": "Event logs, as viewed in process mining, contain event data describing the\nexecution of operational processes. Most process mining techniques take an\nevent log as input and generate insights about the underlying process by\nanalyzing the data provided. Consequently, handling large volumes of event data\nis essential to apply process mining successfully. Traditionally, individual\nprocess executions are considered sequentially ordered process activities.\nHowever, process executions are increasingly viewed as partially ordered\nactivities to more accurately reflect process behavior observed in reality,\nsuch as simultaneous execution of activities. Process executions comprising\npartially ordered activities may contain more complex activity patterns than\nsequence-based process executions. This paper presents a novel query language\nto call up process executions from event logs containing partially ordered\nactivities. The query language allows users to specify complex ordering\nrelations over activities, i.e., control flow constraints. Evaluating a query\nfor a given log returns process executions satisfying the specified\nconstraints. We demonstrate the implementation of the query language in a\nprocess mining tool and evaluate its performance on real-life event logs.",
    "descriptor": "",
    "authors": [
      "Daniel Schuster",
      "Michael Martini",
      "Sebastiaan J. van Zelst",
      "Wil M.P. van der Alast"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.04146"
  },
  {
    "id": "arXiv:2211.04148",
    "title": "The Technological Emergence of AutoML: A Survey of Performant Software  and Applications in the Context of Industry",
    "abstract": "With most technical fields, there exists a delay between fundamental academic\nresearch and practical industrial uptake. Whilst some sciences have robust and\nwell-established processes for commercialisation, such as the pharmaceutical\npractice of regimented drug trials, other fields face transitory periods in\nwhich fundamental academic advancements diffuse gradually into the space of\ncommerce and industry. For the still relatively young field of\nAutomated/Autonomous Machine Learning (AutoML/AutonoML), that transitory period\nis under way, spurred on by a burgeoning interest from broader society. Yet, to\ndate, little research has been undertaken to assess the current state of this\ndissemination and its uptake. Thus, this review makes two primary contributions\nto knowledge around this topic. Firstly, it provides the most up-to-date and\ncomprehensive survey of existing AutoML tools, both open-source and commercial.\nSecondly, it motivates and outlines a framework for assessing whether an AutoML\nsolution designed for real-world application is 'performant'; this framework\nextends beyond the limitations of typical academic criteria, considering a\nvariety of stakeholder needs and the human-computer interactions required to\nservice them. Thus, additionally supported by an extensive assessment and\ncomparison of academic and commercial case-studies, this review evaluates\nmainstream engagement with AutoML in the early 2020s, identifying obstacles and\nopportunities for accelerating future uptake.",
    "descriptor": "",
    "authors": [
      "Alexander Scriven",
      "David Jacob Kedziora",
      "Katarzyna Musial",
      "Bogdan Gabrys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04148"
  },
  {
    "id": "arXiv:2211.04149",
    "title": "Towards edible drones for rescue missions: design and flight of  nutritional wings",
    "abstract": "Drones have shown to be useful aerial vehicles for unmanned transport\nmissions such as food and medical supply delivery. This can be leveraged to\ndeliver life-saving nutrition and medicine for people in emergency situations.\nHowever, commercial drones can generally only carry 10 % - 30 % of their own\nmass as payload, which limits the amount of food delivery in a single flight.\nOne novel solution to noticeably increase the food-carrying ratio of a drone,\nis recreating some structures of a drone, such as the wings, with edible\nmaterials. We thus propose a drone, which is no longer only a food transporting\naircraft, but itself is partially edible, increasing its food-carrying mass\nratio to 50 %, owing to its edible wings. Furthermore, should the edible drone\nbe left behind in the environment after performing its task in an emergency\nsituation, it will be more biodegradable than its non-edible counterpart,\nleaving less waste in the environment. Here we describe the choice of materials\nand scalable design of edible wings, and validate the method in a\nflight-capable prototype that can provide 300 kcal and carry a payload of 80 g\nof water.",
    "descriptor": "",
    "authors": [
      "Bokeon Kwak",
      "Jun Shintake",
      "Lu Zhang",
      "Dario Floreano"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04149"
  },
  {
    "id": "arXiv:2211.04152",
    "title": "Federated Learning Using Three-Operator ADMM",
    "abstract": "Federated learning (FL) has emerged as an instance of distributed machine\nlearning paradigm that avoids the transmission of data generated on the users'\nside. Although data are not transmitted, edge devices have to deal with limited\ncommunication bandwidths, data heterogeneity, and straggler effects due to the\nlimited computational resources of users' devices. A prominent approach to\novercome such difficulties is FedADMM, which is based on the classical\ntwo-operator consensus alternating direction method of multipliers (ADMM). The\ncommon assumption of FL algorithms, including FedADMM, is that they learn a\nglobal model using data only on the users' side and not on the edge server.\nHowever, in edge learning, the server is expected to be near the base station\nand have direct access to rich datasets. In this paper, we argue that\nleveraging the rich data on the edge server is much more beneficial than\nutilizing only user datasets. Specifically, we show that the mere application\nof FL with an additional virtual user node representing the data on the edge\nserver is inefficient. We propose FedTOP-ADMM, which generalizes FedADMM and is\nbased on a three-operator ADMM-type technique that exploits a smooth cost\nfunction on the edge server to learn a global model parallel to the edge\ndevices. Our numerical experiments indicate that FedTOP-ADMM has substantial\ngain up to 33\\% in communication efficiency to reach a desired test accuracy\nwith respect to FedADMM, including a virtual user on the edge server.",
    "descriptor": "\nComments: accepted to IEEE Journal of Selected Topics in Signal Processing, 2022\n",
    "authors": [
      "Shashi Kant",
      "Jos\u00e9 Mairton B. da Silva Jr.",
      "Gabor Fodor",
      "Bo G\u00f6ransson",
      "Mats Bengtsson",
      "Carlo Fischione"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.04152"
  },
  {
    "id": "arXiv:2211.04154",
    "title": "Russian propaganda on social media during the 2022 invasion of Ukraine",
    "abstract": "The Russian invasion of Ukraine in February 2022 was accompanied by a\nlarge-scale propaganda campaign. Here, we analyze the spread of Russian\npropaganda on social media. For this, we collected N = 349,455 messages from\nTwitter with pro-Russian content. Our findings suggest that pro-Russian\nmessages were mainly disseminated through a systematic, coordinated propaganda\ncampaign. Overall, pro-Russian content received ~251,000 retweets and thereby\nreached around 14.4 million users, primarily in countries such as India, South\nAfrica, and the United States. We further provide evidence that bots played a\ndisproportionate role in the dissemination of propaganda and amplified its\nproliferation. Overall, 20.28% of the spreaders are classified as bots, most of\nwhich were created in the beginning of the invasion. Together, our results\nhighlight the new threats to society that originate from coordinated propaganda\ncampaigns on social media in modern warfare. Our results also suggest that\ncurbing bots may be an effective strategy to mitigate such campaigns.",
    "descriptor": "",
    "authors": [
      "Dominique Geissler",
      "Dominik B\u00e4r",
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.04154"
  },
  {
    "id": "arXiv:2211.04157",
    "title": "Inferring Class Label Distribution of Training Data from Classifiers: An  Accuracy-Augmented Meta-Classifier Attack",
    "abstract": "Property inference attacks against machine learning (ML) models aim to infer\nproperties of the training data that are unrelated to the primary task of the\nmodel, and have so far been formulated as binary decision problems, i.e.,\nwhether or not the training data have a certain property. However, in\nindustrial and healthcare applications, the proportion of labels in the\ntraining data is quite often also considered sensitive information. In this\npaper we introduce a new type of property inference attack that unlike binary\ndecision problems in literature, aim at inferring the class label distribution\nof the training data from parameters of ML classifier models. We propose a\nmethod based on \\emph{shadow training} and a \\emph{meta-classifier} trained on\nthe parameters of the shadow classifiers augmented with the accuracy of the\nclassifiers on auxiliary data. We evaluate the proposed approach for ML\nclassifiers with fully connected neural network architectures. We find that the\nproposed \\emph{meta-classifier} attack provides a maximum relative improvement\nof $52\\%$ over state of the art.",
    "descriptor": "\nComments: 12 pages, 2022 Trustworthy and Socially Responsible Machine Learning (TSRML 2022) co-located with NeurIPS 2022\n",
    "authors": [
      "Raksha Ramakrishna",
      "Gy\u00f6rgy D\u00e1n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.04157"
  },
  {
    "id": "arXiv:2211.04161",
    "title": "Theoretical analysis and experimental validation of volume bias of soft  Dice optimized segmentation maps in the context of inherent uncertainty",
    "abstract": "The clinical interest is often to measure the volume of a structure, which is\ntypically derived from a segmentation. In order to evaluate and compare\nsegmentation methods, the similarity between a segmentation and a predefined\nground truth is measured using popular discrete metrics, such as the Dice\nscore. Recent segmentation methods use a differentiable surrogate metric, such\nas soft Dice, as part of the loss function during the learning phase. In this\nwork, we first briefly describe how to derive volume estimates from a\nsegmentation that is, potentially, inherently uncertain or ambiguous. This is\nfollowed by a theoretical analysis and an experimental validation linking the\ninherent uncertainty to common loss functions for training CNNs, namely\ncross-entropy and soft Dice. We find that, even though soft Dice optimization\nleads to an improved performance with respect to the Dice score and other\nmeasures, it may introduce a volume bias for tasks with high inherent\nuncertainty. These findings indicate some of the method's clinical limitations\nand suggest doing a closer ad-hoc volume analysis with an optional\nre-calibration step.",
    "descriptor": "\nComments: 18 pages, 7 figures, 3 tables, published in Elsevier Medical Image Analysis (2021)\n",
    "authors": [
      "Jeroen Bertels",
      "David Robben",
      "Dirk Vandermeulen",
      "Paul Suetens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04161"
  },
  {
    "id": "arXiv:2211.04162",
    "title": "Convergent numerical approximation of the stochastic total variation  flow with linear multiplicative noise: the higher dimensional case",
    "abstract": "We consider fully discrete finite element approximation of the stochastic\ntotal variation flow equation (STVF) with linear multiplicative noise which was\npreviously proposed in \\cite{our_paper}. Due to lack of a discrete counterpart\nof stronger a priori estimates in higher spatial dimensions the original\nconvergence analysis of the numerical scheme was limited to one spatial\ndimension, cf. \\cite{stvf_erratum}. In this paper we generalize the convergence\nproof to higher dimensions.",
    "descriptor": "",
    "authors": [
      "\u013dubom\u00edr Ba\u0148as",
      "Michael R\u00f6ckner",
      "Andr\u00e9 Wilke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04162"
  },
  {
    "id": "arXiv:2211.04163",
    "title": "Designing robots with the context in mind -- One design does not fit all",
    "abstract": "Robots' visual qualities (VQs) impact people's perception of their\ncharacteristics and affect users' behaviors and attitudes toward the robot.\nRecent years point toward a growing need for Socially Assistive Robots (SARs)\nin various contexts and functions, interacting with various users. Since SAR\ntypes have functional differences, the user experience must vary by the context\nof use, functionality, user characteristics, and environmental conditions.\nStill, SAR manufacturers often design and deploy the same robotic embodiment\nfor diverse contexts. We argue that the visual design of SARs requires a more\nscientific approach considering their multiple evolving roles in future\nsociety. In this work, we define four contextual layers: the domain in which\nthe SAR exists, the physical environment, its intended users, and the robot's\nrole. Via an online questionnaire, we collected potential users' expectations\nregarding the desired characteristics and visual qualities of four different\nSARs: a service robot for an assisted living/retirement residence facility, a\nmedical assistant robot for a hospital environment, a COVID-19 officer robot,\nand a personal assistant robot for domestic use. Results indicated that users'\nexpectations differ regarding the robot's desired characteristics and the\nanticipated visual qualities for each context and use case.",
    "descriptor": "\nComments: Accepted to the 15th International Workshop on Human-Friendly Robotics\n",
    "authors": [
      "Ela Liberman-Pincu",
      "Elmer D. van Grondelle",
      "Tal Oron-Gilad"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04163"
  },
  {
    "id": "arXiv:2211.04165",
    "title": "Dynamic loss balancing and sequential enhancement for road-safety  assessment and traffic scene classification",
    "abstract": "Road-safety inspection is an indispensable instrument for reducing\nroad-accident fatalities contributed to road infrastructure. Recent work\nformalizes road-safety assessment in terms of carefully selected risk factors\nthat are also known as road-safety attributes. In current practice, these\nattributes are manually annotated in geo-referenced monocular video for each\nroad segment. We propose to reduce dependency on tedious human labor by\nautomating recognition with a two-stage neural architecture. The first stage\npredicts more than forty road-safety attributes by observing a local\nspatio-temporal context. Our design leverages an efficient convolutional\npipeline, which benefits from pre-training on semantic segmentation of street\nscenes. The second stage enhances predictions through sequential integration\nacross a larger temporal window. Our design leverages per-attribute instances\nof a lightweight bidirectional LSTM architecture. Both stages alleviate extreme\nclass imbalance by incorporating a multi-task variant of recall-based dynamic\nloss weighting. We perform experiments on the iRAP-BH dataset, which involves\nfully labeled geo-referenced video along 2,300 km of public roads in Bosnia and\nHerzegovina. We also validate our approach by comparing it with the related\nwork on two road-scene classification datasets from the literature: Honda\nScenes and FM3m. Experimental evaluation confirms the value of our\ncontributions on all three datasets.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Marin Ka\u010dan",
      "Marko \u0160evrovi\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04165"
  },
  {
    "id": "arXiv:2211.04166",
    "title": "Spiking sampling network for image sparse representation and dynamic  vision sensor data compression",
    "abstract": "Sparse representation has attracted great attention because it can greatly\nsave storage re- sources and find representative features of data in a\nlow-dimensional space. As a result, it may be widely applied in engineering\ndomains including feature extraction, compressed sensing, signal denoising,\npicture clustering, and dictionary learning, just to name a few. In this paper,\nwe propose a spiking sampling network. This network is composed of spiking\nneurons, and it can dynamically decide which pixel points should be retained\nand which ones need to be masked according to the input. Our experiments\ndemonstrate that this approach enables better sparse representation of the\noriginal image and facilitates image reconstruction compared to random\nsampling. We thus use this approach for compressing massive data from the\ndynamic vision sensor, which greatly reduces the storage requirements for event\ndata.",
    "descriptor": "",
    "authors": [
      "Chunming Jiang",
      "Yilei Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.04166"
  },
  {
    "id": "arXiv:2211.04169",
    "title": "Graph Summarization via Node Grouping: A Spectral Algorithm",
    "abstract": "Graph summarization via node grouping is a popular method to build concise\ngraph representations by grouping nodes from the original graph into supernodes\nand encoding edges into superedges such that the loss of adjacency information\nis minimized. Such summaries have immense applications in large-scale graph\nanalytics due to their small size and high query processing efficiency. In this\npaper, we reformulate the loss minimization problem for summarization into an\nequivalent integer maximization problem. By initially allowing relaxed\n(fractional) solutions for integer maximization, we analytically expose the\nunderlying connections to the spectral properties of the adjacency matrix.\nConsequently, we design an algorithm called SpecSumm that consists of two\nphases. In the first phase, motivated by spectral graph theory, we apply\nk-means clustering on the k largest (in magnitude) eigenvectors of the\nadjacency matrix to assign nodes to supernodes. In the second phase, we propose\na greedy heuristic that updates the initial assignment to further improve\nsummary quality. Finally, via extensive experiments on 11 datasets, we show\nthat SpecSumm efficiently produces high-quality summaries compared to\nstate-of-the-art summarization algorithms and scales to graphs with millions of\nnodes.",
    "descriptor": "\nComments: Full version of the paper published at WSDM 2023\n",
    "authors": [
      "Arpit Merchant",
      "Michael Mathioudakis",
      "Yanhao Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04169"
  },
  {
    "id": "arXiv:2211.04173",
    "title": "Active-IRS Aided Wireless Network: System Modeling and Performance  Analysis",
    "abstract": "Active intelligent reflecting surface (IRS) enables flexible signal\nreflection control with \\emph{power amplification}, thus effectively\ncompensating the product-distance path-loss in conventional passive-IRS aided\nsystems. In this letter, we characterize the communication performance of an\nactive-IRS aided single-cell wireless network. To this end, we first propose a\n\\emph{customized} IRS deployment strategy, where the active IRSs are uniformly\ndeployed within a ring concentric with the cell to serve the users far from the\nbase station. Next, given the Nakagami-$m$ fading channel, we characterize the\ncascaded active-IRS channel by using the \\emph{mixture Gamma distribution}\napproximation and derive a closed-form expression for the mean signal-to-noise\nratio (SNR) at the user averaged over channel fading. Moreover, we numerically\nshow that to maximize the system performance, it is necessary to choose a\nproper active-IRS density given a fixed number of total reflecting elements,\nwhich significantly differs from the passive-IRS case for which the centralized\nIRS deployment scheme is better. Furthermore, the active-IRS aided wireless\nnetwork achieves higher spatial throughput than the passive-IRS counterpart\nwhen the total number of reflecting elements is small.",
    "descriptor": "",
    "authors": [
      "Yunli Li",
      "Changsheng You",
      "Young Jin Chun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.04173"
  },
  {
    "id": "arXiv:2211.04175",
    "title": "Centaur: Federated Learning for Constrained Edge Devices",
    "abstract": "Federated learning (FL) on deep neural networks facilitates new applications\nat the edge, especially for wearable and Internet-of-Thing devices. Such\ndevices capture a large and diverse amount of data, but they have memory,\ncompute, power, and connectivity constraints which hinder their participation\nin FL. We propose Centaur, a multitier FL framework, enabling ultra-constrained\ndevices to efficiently participate in FL on large neural nets. Centaur combines\ntwo major ideas: (i) a data selection scheme to choose a portion of samples\nthat accelerates the learning, and (ii) a partition-based training algorithm\nthat integrates both constrained and powerful devices owned by the same user.\nEvaluations, on four benchmark neural nets and three datasets, show that\nCentaur gains ~10% higher accuracy than local training on constrained devices\nwith ~58% energy saving on average. Our experimental results also demonstrate\nthe superior efficiency of Centaur when dealing with imbalanced data, client\nparticipation heterogeneity, and various network connection probabilities.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Fan Mo",
      "Mohammad Malekzadeh",
      "Soumyajit Chatterjee",
      "Fahim Kawsar",
      "Akhil Mathur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04175"
  },
  {
    "id": "arXiv:2211.04177",
    "title": "Learning advisor networks for noisy image classification",
    "abstract": "In this paper, we introduced the novel concept of advisor network to address\nthe problem of noisy labels in image classification. Deep neural networks (DNN)\nare prone to performance reduction and overfitting problems on training data\nwith noisy annotations. Weighting loss methods aim to mitigate the influence of\nnoisy labels during the training, completely removing their contribution. This\ndiscarding process prevents DNNs from learning wrong associations between\nimages and their correct labels but reduces the amount of data used, especially\nwhen most of the samples have noisy labels. Differently, our method weighs the\nfeature extracted directly from the classifier without altering the loss value\nof each data. The advisor helps to focus only on some part of the information\npresent in mislabeled examples, allowing the classifier to leverage that data\nas well. We trained it with a meta-learning strategy so that it can adapt\nthroughout the training of the main model. We tested our method on CIFAR10 and\nCIFAR100 with synthetic noise, and on Clothing1M which contains real-world\nnoise, reporting state-of-the-art results.",
    "descriptor": "\nComments: Paper published as Poster at ICIAP21\n",
    "authors": [
      "Simone Ricci",
      "Tiberio Uricchio",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04177"
  },
  {
    "id": "arXiv:2211.04185",
    "title": "Coupled Modeling and Fusion Control for a Multi-modal Deformable  Land-air Robot",
    "abstract": "This paper introduces a structure-deformable land-air robot which possesses\nboth excellent ground driving and flying ability, with smooth switching\nmechanism between two modes. The elaborate coupled dynamics model of the\nproposed robot is established, including rotors, chassis, especially the\ndeformable structures. Furthermore, taking fusion locomotion and complex\nnear-ground situations into consideration, a model based controller is designed\nfor landing and mode switching under various harsh conditions, in which we\nrealise the cooperation between fused two motion modes. The entire system is\nimplemented in ADAMS/Simulink simulation and in practical. We conduct\nexperiments under various complex scenarios. The results show our robot can\naccomplish land-air switching swiftly and smoothly, and the designed controller\ncan effectively improve the landing flexibility and reliability.",
    "descriptor": "",
    "authors": [
      "Xinyu Zhang",
      "Yuanhao Huang",
      "Kangyao Huang",
      "Ziqi Zhao",
      "Jingwei Li",
      "Huaping Liu",
      "Jun Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04185"
  },
  {
    "id": "arXiv:2211.04188",
    "title": "DepthFormer: Multimodal Positional Encodings and Cross-Input Attention  for Transformer-Based Segmentation Networks",
    "abstract": "Most approaches for semantic segmentation use only information from color\ncameras to parse the scenes, yet recent advancements show that using depth data\nallows to further improve performances. In this work, we focus on\ntransformer-based deep learning architectures, that have achieved\nstate-of-the-art performances on the segmentation task, and we propose to\nemploy depth information by embedding it in the positional encoding.\nEffectively, we extend the network to multimodal data without adding any\nparameters and in a natural way that makes use of the strength of transformers'\nself-attention modules. We also investigate the idea of performing\ncross-modality operations inside the attention module, swapping the key inputs\nbetween the depth and color branches. Our approach consistently improves\nperformances on the Cityscapes benchmark.",
    "descriptor": "",
    "authors": [
      "Francesco Barbato",
      "Giulia Rizzoli",
      "Pietro Zanuttigh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04188"
  },
  {
    "id": "arXiv:2211.04192",
    "title": "Correction to: Convergent numerical approximation of the stochastic  total variation flow",
    "abstract": "We correct two errors in our paper [4]. First error concerns the definition\nof the SVI solution, where a boundary term which arises due to the Dirichlet\nboundary condition, was not included. The second error concerns the discrete\nestimate [4, Lemma 4.4], which involves the discrete Laplace operator. We\nprovide an alternative proof of the estimate in spatial dimension $d=1$ by\nusing a mass lumped version of the discrete Laplacian. Hence, after a minor\nmodification of the fully discrete numerical scheme the convergence in $d=1$\nfollows along the lines of the original proof. The convergence proof of the\ntime semi-discrete scheme, which relies on the continuous counterpart of the\nestimate [4, Lemma 4.4], remains valid in higher spatial dimension. The\nconvergence of the fully discrete finite element scheme from [4] in any spatial\ndimension is shown in [3] by using a different approach.",
    "descriptor": "",
    "authors": [
      "\u013dubom\u00edr Ba\u0148as",
      "Michael R\u00f6ckner",
      "Andr\u00e9 Wilke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04192"
  },
  {
    "id": "arXiv:2211.04193",
    "title": "A Systematic Review of Ethical Concerns with Voice Assistants",
    "abstract": "Siri's introduction in 2011 marked the beginning of a wave of domestic voice\nassistant releases, and this technology has since become commonplace in\nconsumer devices such as smartphones and TVs. But as their presence expands\nthere have also been a range of ethical concerns identified around the use of\nvoice assistants, such as the privacy implications of having devices that are\nalways recording and the ways that these devices are integrated into the\nexisting social order of the home. This has created a burgeoning area of\nresearch across a range of fields including computer science, social science,\nand psychology. This paper takes stock of the foundations and frontiers of this\nwork through a systematic literature review of 117 papers on ethical concerns\nwith voice assistants. In addition to analysis of nine specific areas of\nconcern, the review measures the distribution of methods and participant\ndemographics across the literature. We show how some concerns, such as privacy,\nare operationalized to a much greater extent than others like accessibility,\nand how study participants are overwhelmingly drawn from a small handful of\nWestern nations. In so doing we hope to provide an outline of the rich tapestry\nof work around these concerns and highlight areas where current research\nefforts are lacking.",
    "descriptor": "",
    "authors": [
      "William Seymour",
      "Xiao Zhan",
      "Mark Cote",
      "Jose Such"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.04193"
  },
  {
    "id": "arXiv:2211.04194",
    "title": "Submission-Aware Reviewer Profiling for Reviewer Recommender System",
    "abstract": "Assigning qualified, unbiased and interested reviewers to paper submissions\nis vital for maintaining the integrity and quality of the academic publishing\nsystem and providing valuable reviews to authors. However, matching thousands\nof submissions with thousands of potential reviewers within a limited time is a\ndaunting challenge for a conference program committee. Prior efforts based on\ntopic modeling have suffered from losing the specific context that help define\nthe topics in a publication or submission abstract. Moreover, in some cases,\ntopics identified are difficult to interpret. We propose an approach that\nlearns from each abstract published by a potential reviewer the topics studied\nand the explicit context in which the reviewer studied the topics. Furthermore,\nwe contribute a new dataset for evaluating reviewer matching systems. Our\nexperiments show a significant, consistent improvement in precision when\ncompared with the existing methods. We also use examples to demonstrate why our\nrecommendations are more explainable. The new approach has been deployed\nsuccessfully at top-tier conferences in the last two years.",
    "descriptor": "",
    "authors": [
      "Omer Anjum",
      "Alok Kamatar",
      "Toby Liang",
      "Jinjun Xiong",
      "Wen-mei Hwu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04194"
  },
  {
    "id": "arXiv:2211.04198",
    "title": "Third-Party Aligner for Neural Word Alignments",
    "abstract": "Word alignment is to find translationally equivalent words between source and\ntarget sentences. Previous work has demonstrated that self-training can achieve\ncompetitive word alignment results. In this paper, we propose to use word\nalignments generated by a third-party word aligner to supervise the neural word\nalignment training. Specifically, source word and target word of each word pair\naligned by the third-party aligner are trained to be close neighbors to each\nother in the contextualized embedding space when fine-tuning a pre-trained\ncross-lingual language model. Experiments on the benchmarks of various language\npairs show that our approach can surprisingly do self-correction over the\nthird-party supervision by finding more accurate word alignments and deleting\nwrong word alignments, leading to better performance than various third-party\nword aligners, including the currently best one. When we integrate all\nsupervisions from various third-party aligners, we achieve state-of-the-art\nword alignment performances, with averagely more than two points lower\nalignment error rates than the best third-party aligner. We released our code\nat https://github.com/sdongchuanqi/Third-Party-Supervised-Aligner.",
    "descriptor": "\nComments: 12 pages, 4 figures, findings of emnlp 2022\n",
    "authors": [
      "Jinpeng Zhang",
      "Chuanqi Dong",
      "Xiangyu Duan",
      "Yuqi Zhang",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04198"
  },
  {
    "id": "arXiv:2211.04200",
    "title": "Intelligent Surface Enabled Sensing-Assisted Communication",
    "abstract": "Vehicle-to-everything (V2X) communication is expected to support many\npromising applications in next-generation wireless networks. The recent\ndevelopment of integrated sensing and communications (ISAC) technology offers\nnew opportunities to meet the stringent sensing and communication (S&C)\nrequirements in V2X networks. However, considering the relatively small radar\ncross section (RCS) of the vehicles and the limited transmit power of the road\nsite units (RSUs), the power of echoes may be too weak to achieve effective\ntarget detection and tracking. To handle this issue, we propose a novel\nsensing-assisted communication scheme by employing an intelligent Omni-surface\n(IOS) on the surface of the vehicle. First, a two-phase ISAC protocol,\nincluding the S&C phase and the communication-only phase, was presented to\nmaximize the throughput by jointly optimizing the IOS phase shifts and the\nsensing duration. Then, we derive a closed-form expression of the achievable\nrate which achieves a good approximation. Furthermore, a sufficient and\nnecessary condition for the existence of the S&C phase is derived to provide\nuseful insights for practical system design. Simulation results demonstrate the\neffectiveness of the proposed sensing-assisted communication scheme in\nachieving high throughput with low transmit power requirements.",
    "descriptor": "\nComments: 8 pages, Submitted to IEEE for possible publication\n",
    "authors": [
      "Kaitao Meng",
      "Qingqing Wu",
      "Wen Chen",
      "Deshi Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04200"
  },
  {
    "id": "arXiv:2211.04203",
    "title": "RRSR:Reciprocal Reference-based Image Super-Resolution with Progressive  Feature Alignment and Selection",
    "abstract": "Reference-based image super-resolution (RefSR) is a promising SR branch and\nhas shown great potential in overcoming the limitations of single image\nsuper-resolution. While previous state-of-the-art RefSR methods mainly focus on\nimproving the efficacy and robustness of reference feature transfer, it is\ngenerally overlooked that a well reconstructed SR image should enable better SR\nreconstruction for its similar LR images when it is referred to as. Therefore,\nin this work, we propose a reciprocal learning framework that can appropriately\nleverage such a fact to reinforce the learning of a RefSR network. Besides, we\ndeliberately design a progressive feature alignment and selection module for\nfurther improving the RefSR task. The newly proposed module aligns\nreference-input images at multi-scale feature spaces and performs\nreference-aware feature selection in a progressive manner, thus more precise\nreference features can be transferred into the input features and the network\ncapability is enhanced. Our reciprocal learning paradigm is model-agnostic and\nit can be applied to arbitrary RefSR models. We empirically show that multiple\nrecent state-of-the-art RefSR models can be consistently improved with our\nreciprocal learning paradigm. Furthermore, our proposed model together with the\nreciprocal learning strategy sets new state-of-the-art performances on multiple\nbenchmarks.",
    "descriptor": "\nComments: 8 figures, 17 pages\n",
    "authors": [
      "Lin Zhang",
      "Xin Li",
      "Dongliang He",
      "Fu Li",
      "Yili Wang",
      "Zhaoxiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04203"
  },
  {
    "id": "arXiv:2211.04205",
    "title": "Preserving Semantics in Textual Adversarial Attacks",
    "abstract": "Adversarial attacks in NLP challenge the way we look at language models. The\ngoal of this kind of adversarial attack is to modify the input text to fool a\nclassifier while maintaining the original meaning of the text. Although most\nexisting adversarial attacks claim to fulfill the constraint of semantics\npreservation, careful scrutiny shows otherwise. We show that the problem lies\nin the text encoders used to determine the similarity of adversarial examples,\nspecifically in the way they are trained. Unsupervised training methods make\nthese encoders more susceptible to problems with antonym recognition. To\novercome this, we introduce a simple, fully supervised sentence embedding\ntechnique called Semantics-Preserving-Encoder (SPE). The results show that our\nsolution minimizes the variation in the meaning of the adversarial examples\ngenerated. It also significantly improves the overall quality of adversarial\nexamples, as confirmed by human evaluators. Furthermore, it can be used as a\ncomponent in any existing attack to speed up its execution while maintaining\nsimilar attack success.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "David Herel",
      "Hugo Cisneros",
      "Tomas Mikolov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04205"
  },
  {
    "id": "arXiv:2211.04208",
    "title": "GOOD-D: On Unsupervised Graph Out-Of-Distribution Detection",
    "abstract": "Most existing deep learning models are trained based on the closed-world\nassumption, where the test data is assumed to be drawn i.i.d. from the same\ndistribution as the training data, known as in-distribution (ID). However, when\nmodels are deployed in an open-world scenario, test samples can be\nout-of-distribution (OOD) and therefore should be handled with caution. To\ndetect such OOD samples drawn from unknown distribution, OOD detection has\nreceived increasing attention lately. However, current endeavors mostly focus\non grid-structured data and its application for graph-structured data remains\nunder-explored. Considering the fact that data labeling on graphs is commonly\ntime-expensive and labor-intensive, in this work we study the problem of\nunsupervised graph OOD detection, aiming at detecting OOD graphs solely based\non unlabeled ID data. To achieve this goal, we develop a new graph contrastive\nlearning framework GOOD-D for detecting OOD graphs without using any\nground-truth labels. By performing hierarchical contrastive learning on the\naugmented graphs generated by our perturbation-free graph data augmentation\nmethod, GOOD-D is able to capture the latent ID patterns and accurately detect\nOOD graphs based on the semantic inconsistency in different granularities\n(i.e., node-level, graph-level, and group-level). As a pioneering work in\nunsupervised graph-level OOD detection, we build a comprehensive benchmark to\ncompare our proposed approach with different state-of-the-art methods. The\nexperiment results demonstrate the superiority of our approach over different\nmethods on various datasets.",
    "descriptor": "\nComments: Accepted by WSDM 2023. 10 pages, 4 figures\n",
    "authors": [
      "Yixin Liu",
      "Kaize Ding",
      "Huan Liu",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04208"
  },
  {
    "id": "arXiv:2211.04211",
    "title": "Distribution Grid Monitoring Based on Widely Available Smart Plugs",
    "abstract": "During the last few years, smart home devices have become increasingly\npopular. Smart plugs, smart lights, and smart switches are now found in as many\nas 37 percent of German households, and the popularity of these devices is\nrising. Smart devices sometimes also integrate sensors for measuring voltage\nand current. The increase in renewable generation, e-mobility and heat pumps\nlead to scenarios for which the distribution grid was not originally designed.\nMoreover, parts of the distribution grid are only sparsely instrumented, which\nleaves the distribution grid operator unaware of possible bottlenecks resulting\nfrom the introduction of such loads and renewable generation. To overcome this\nlack of information, we propose a grid monitoring that is based on measurements\nof widely available smart home devices, such as smart plugs. In the present\npaper, we illustrate the collection and utilization of smart plug measurements\nfor distribution grid monitoring and examine the extent and effect of\nmeasurement inaccuracy. For this evaluation, we analyze the measurements of\nmultiple commercially available smart plugs and test the effect of measurement\nerrors on the monitoring when using a single smart plug.",
    "descriptor": "\nComments: 8 pages,\n",
    "authors": [
      "Simon Grafenhorst",
      "Kevin F\u00f6rderer",
      "Veit Hagenmeyer"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.04211"
  },
  {
    "id": "arXiv:2211.04214",
    "title": "Generative Adversarial Networks for anonymous Acneic face dataset  generation",
    "abstract": "It is well known that the performance of any classification model is\neffective if the dataset used for the training process and the test process\nsatisfy some specific requirements. In other words, the more the dataset size\nis large, balanced, and representative, the more one can trust the proposed\nmodel's effectiveness and, consequently, the obtained results. Unfortunately,\nlarge-size anonymous datasets are generally not publicly available in\nbiomedical applications, especially those dealing with pathological human face\nimages. This concern makes using deep-learning-based approaches challenging to\ndeploy and difficult to reproduce or verify some published results. In this\npaper, we suggest an efficient method to generate a realistic anonymous\nsynthetic dataset of human faces with the attributes of acne disorders\ncorresponding to three levels of severity (i.e. Mild, Moderate and Severe).\nTherefore, a specific hierarchy StyleGAN-based algorithm trained at distinct\nlevels is considered. To evaluate the performance of the proposed scheme, we\nconsider a CNN-based classification system, trained using the generated\nsynthetic acneic face images and tested using authentic face images.\nConsequently, we show that an accuracy of 97,6\\% is achieved using\nInceptionResNetv2. As a result, this work allows the scientific community to\nemploy the generated synthetic dataset for any data processing application\nwithout restrictions on legal or ethical concerns. Moreover, this approach can\nalso be extended to other applications requiring the generation of synthetic\nmedical images. We can make the code and the generated dataset accessible for\nthe scientific community.",
    "descriptor": "",
    "authors": [
      "Hazem Zein",
      "Samer Chantaf",
      "R\u00e9gis Fournier",
      "Amine Nait-Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04214"
  },
  {
    "id": "arXiv:2211.04215",
    "title": "Active Relation Discovery: Towards General and Label-aware Open Relation  Extraction",
    "abstract": "Open Relation Extraction (OpenRE) aims to discover novel relations from open\ndomains. Previous OpenRE methods mainly suffer from two problems: (1)\nInsufficient capacity to discriminate between known and novel relations. When\nextending conventional test settings to a more general setting where test data\nmight also come from seen classes, existing approaches have a significant\nperformance decline. (2) Secondary labeling must be performed before practical\napplication. Existing methods cannot label human-readable and meaningful types\nfor novel relations, which is urgently required by the downstream tasks. To\naddress these issues, we propose the Active Relation Discovery (ARD) framework,\nwhich utilizes relational outlier detection for discriminating known and novel\nrelations and involves active learning for labeling novel relations. Extensive\nexperiments on three real-world datasets show that ARD significantly\noutperforms previous state-of-the-art methods on both conventional and our\nproposed general OpenRE settings. The source code and datasets will be\navailable for reproducibility.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yangning Li",
      "Yinghui Li",
      "Xi Chen",
      "Hai-Tao Zheng",
      "Ying Shen",
      "Hong-Gee Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04215"
  },
  {
    "id": "arXiv:2211.04217",
    "title": "Deterministic Incremental APSP with Polylogarithmic Update Time and  Stretch",
    "abstract": "We provide the first deterministic data structure that given a weighted\nundirected graph undergoing edge insertions, processes each update with\npolylogarithmic amortized update time and answers queries for the distance\nbetween any pair of vertices in the current graph with a polylogarithmic\napproximation in $O(\\log \\log n)$ time.\nPrior to this work, no data structure was known for partially dynamic graphs,\ni.e., graphs undergoing either edge insertions or deletions, with less than\n$n^{o(1)}$ update time except for dense graphs, even when allowing\nrandomization against oblivious adversaries or considering only single-source\ndistances.",
    "descriptor": "",
    "authors": [
      "Sebastian Forster",
      "Yasamin Nazari",
      "Maximilian Probst Gutenberg"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04217"
  },
  {
    "id": "arXiv:2211.04218",
    "title": "Clustered Federated Learning based on Nonconvex Pairwise Fusion",
    "abstract": "This study investigates clustered federated learning (FL), one of the\nformulations of FL with non-i.i.d. data, where the devices are partitioned into\nclusters and each cluster optimally fits its data with a localized model. We\npropose a novel clustered FL framework, which applies a nonconvex penalty to\npairwise differences of parameters. This framework can automatically identify\nclusters without a priori knowledge of the number of clusters and the set of\ndevices in each cluster. To implement the proposed framework, we develop a\nnovel clustered FL method called FPFC. Advancing from the standard ADMM, our\nmethod is implemented in parallel, updates only a subset of devices at each\ncommunication round, and allows each participating device to perform a variable\namount of work. This greatly reduces the communication cost while\nsimultaneously preserving privacy, making it practical for FL. We also propose\na new warmup strategy for hyperparameter tuning under FL settings and consider\nthe asynchronous variant of FPFC (asyncFPFC). Theoretically, we provide\nconvergence guarantees of FPFC for general nonconvex losses and establish the\nstatistical convergence rate under a linear model with squared loss. Our\nextensive experiments demonstrate the advantages of FPFC over existing methods.",
    "descriptor": "\nComments: 46 pages, 9 figures\n",
    "authors": [
      "Xue Yu",
      "Ziyi Liu",
      "Yifan Sun",
      "Wu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.04218"
  },
  {
    "id": "arXiv:2211.04219",
    "title": "Nimbus: Toward Speed Up Function Signature Recovery via Input Resizing  and Multi-Task Learning",
    "abstract": "Function signature recovery is important for many binary analysis tasks such\nas control-flow integrity enforcement, clone detection, and bug finding.\nExisting works try to substitute learning-based methods with rule-based methods\nto reduce human effort.They made considerable efforts to enhance the system's\nperformance, which also bring the side effect of higher resource consumption.\nHowever, recovering the function signature is more about providing information\nfor subsequent tasks, and both efficiency and performance are significant.\nIn this paper, we first propose a method called Nimbus for efficient function\nsignature recovery that furthest reduces the whole-process resource consumption\nwithout performance loss. Thanks to information bias and task relation (i.e.,\nthe relation between parameter count and parameter type recovery), we utilize\nselective inputs and introduce multi-task learning (MTL) structure for function\nsignature recovery to reduce computational resource consumption, and fully\nleverage mutual information. Our experimental results show that, with only\nabout the one-eighth processing time of the state-of-the-art method, we even\nachieve about 1% more prediction accuracy over all function signature recovery\ntasks.",
    "descriptor": "",
    "authors": [
      "Yi Qian",
      "Ligeng Chen",
      "Yuyang Wang",
      "Bing Mao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.04219"
  },
  {
    "id": "arXiv:2211.04224",
    "title": "An $hp$ Weak Galerkin FEM for singularly perturbed problems",
    "abstract": "We present the analysis for an $hp$ weak Galerkin-FEM for singularly\nperturbed reaction-convection-diffusion problems in one-dimension. Under the\nanalyticity of the data assumption, we establish robust exponential\nconvergence, when the error is measured in the energy norm, as the degree $p$\nof the approximating polynomials is increased. The Spectral Boundary Layer mesh\nis used, which is the minimal (layer adapted) mesh for such problems. Numerical\nexamples illustrating the theory are also presented.",
    "descriptor": "",
    "authors": [
      "Torsten Lin\u00df",
      "Christos Xenophontos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04224"
  },
  {
    "id": "arXiv:2211.04226",
    "title": "Gradient-enhanced deep neural network approximations",
    "abstract": "We propose in this work the gradient-enhanced deep neural networks (DNNs)\napproach for function approximations and uncertainty quantification. More\nprecisely, the proposed approach adopts both the function evaluations and the\nassociated gradient information to yield enhanced approximation accuracy. In\nparticular, the gradient information is included as a regularization term in\nthe gradient-enhanced DNNs approach, for which we present similar posterior\nestimates (by the two-layer neural networks) as those in the path-norm\nregularized DNNs approximations. We also discuss the application of this\napproach to gradient-enhanced uncertainty quantification, and present several\nnumerical experiments to show that the proposed approach can outperform the\ntraditional DNNs approach in many cases of interests.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Xiaodong Feng",
      "Li Zeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04226"
  },
  {
    "id": "arXiv:2211.04227",
    "title": "Exponential Euler and backward Euler methods for nonlinear heat  conduction problems",
    "abstract": "In this paper a variant of nonlinear exponential Euler scheme is proposed for\nsolving nonlinear heat conduction problems. The method is based on nonlinear\niterations where at each iteration a linear initial-value problem has to be\nsolved. We compare this method to the backward Euler method combined with\nnonlinear iterations. For both methods we show monotonicity and boundedness of\nthe solutions and give sufficient conditions for convergence of the nonlinear\niterations. Numerical tests are presented to examine performance of the two\nschemes. The presented exponential Euler scheme is implemented based on\nrestarted Krylov subspace methods and, hence, is essentially explicit (involves\nonly matrix-vector products).",
    "descriptor": "\nComments: 11 pages, 2 figures. This is a preprint of the work accepted for publication in Lobachevskii Journal of Mathematics\n",
    "authors": [
      "M. A. Botchev",
      "V. T. Zhukov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.04227"
  },
  {
    "id": "arXiv:2211.04230",
    "title": "On Multi-Robot Path Planning Based on Petri Net Models and LTL  specifications",
    "abstract": "This work considers the path planning problem for a team of identical robots\nevolving in a known environment. The robots should satisfy a global\nspecification given as a Linear Temporal Logic (LTL) formula over a set of\nregions of interest. The proposed method exploits the advantages of Petri net\nmodels for the team of robots and B\\\"uchi automata modeling the specification.\nThe approach in this paper consists in combining the two models into one,\ndenoted Composed Petri net and use it to find a sequence of action movements\nfor the mobile robots, providing collision free trajectories to fulfill the\nspecification. The solution results from a set of Mixed Integer Linear\nProgramming (MILP) problems. The main advantage of the proposed solution is the\ncompleteness of the algorithm, meaning that a solution is found when exists,\nthis representing the key difference with our previous work in [1]. The\nsimulations illustrate comparison results between current and previous\napproaches, focusing on the computational complexity.",
    "descriptor": "\nComments: submitted to IEEE Transactions on Automatic Control, 2022\n",
    "authors": [
      "Sofia Hustiu",
      "Cristian Mahulea",
      "Marius Kloetzer",
      "Jean-Jacques Lesage"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04230"
  },
  {
    "id": "arXiv:2211.04234",
    "title": "Learning Spatio-Temporal Model of Disease Progression with NeuralODEs  from Longitudinal Volumetric Data",
    "abstract": "Robust forecasting of the future anatomical changes inflicted by an ongoing\ndisease is an extremely challenging task that is out of grasp even for\nexperienced healthcare professionals. Such a capability, however, is of great\nimportance since it can improve patient management by providing information on\nthe speed of disease progression already at the admission stage, or it can\nenrich the clinical trials with fast progressors and avoid the need for control\narms by the means of digital twins. In this work, we develop a deep learning\nmethod that models the evolution of age-related disease by processing a single\nmedical scan and providing a segmentation of the target anatomy at a requested\nfuture point in time. Our method represents a time-invariant physical process\nand solves a large-scale problem of modeling temporal pixel-level changes\nutilizing NeuralODEs. In addition, we demonstrate the approaches to incorporate\nthe prior domain-specific constraints into our method and define temporal Dice\nloss for learning temporal objectives. To evaluate the applicability of our\napproach across different age-related diseases and imaging modalities, we\ndeveloped and tested the proposed method on the datasets with 967 retinal OCT\nvolumes of 100 patients with Geographic Atrophy, and 2823 brain MRI volumes of\n633 patients with Alzheimer's Disease. For Geographic Atrophy, the proposed\nmethod outperformed the related baseline models in the atrophy growth\nprediction. For Alzheimer's Disease, the proposed method demonstrated\nremarkable performance in predicting the brain ventricle changes induced by the\ndisease, achieving the state-of-the-art result on TADPOLE challenge.",
    "descriptor": "",
    "authors": [
      "Dmitrii Lachinov",
      "Arunava Chakravarty",
      "Christoph Grechenig",
      "Ursula Schmidt-Erfurth",
      "Hrvoje Bogunovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04234"
  },
  {
    "id": "arXiv:2211.04236",
    "title": "Self-conditioned Embedding Diffusion for Text Generation",
    "abstract": "Can continuous diffusion models bring the same performance breakthrough on\nnatural language they did for image generation? To circumvent the discrete\nnature of text data, we can simply project tokens in a continuous space of\nembeddings, as is standard in language modeling. We propose Self-conditioned\nEmbedding Diffusion, a continuous diffusion mechanism that operates on token\nembeddings and allows to learn flexible and scalable diffusion models for both\nconditional and unconditional text generation. Through qualitative and\nquantitative evaluation, we show that our text diffusion models generate\nsamples comparable with those produced by standard autoregressive language\nmodels - while being in theory more efficient on accelerator hardware at\ninference time. Our work paves the way for scaling up diffusion models for\ntext, similarly to autoregressive models, and for improving performance with\nrecent refinements to continuous diffusion.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Robin Strudel",
      "Corentin Tallec",
      "Florent Altch\u00e9",
      "Yilun Du",
      "Yaroslav Ganin",
      "Arthur Mensch",
      "Will Grathwohl",
      "Nikolay Savinov",
      "Sander Dieleman",
      "Laurent Sifre",
      "R\u00e9mi Leblond"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04236"
  },
  {
    "id": "arXiv:2211.04240",
    "title": "Ruya: Memory-Aware Iterative Optimization of Cluster Configurations for  Big Data Processing",
    "abstract": "Selecting appropriate computational resources for data processing jobs on\nlarge clusters is difficult, even for expert users like data engineers.\nInadequate choices can result in vastly increased costs, without significantly\nimproving performance. One crucial aspect of selecting an efficient resource\nconfiguration is avoiding memory bottlenecks. By knowing the required memory of\na job in advance, the search space for an optimal resource configuration can be\ngreatly reduced.\nTherefore, we present Ruya, a method for memory-aware optimization of data\nprocessing cluster configurations based on iteratively exploring a\nnarrowed-down search space. First, we perform job profiling runs with small\nsamples of the dataset on just a single machine to model the job's memory usage\npatterns. Second, we prioritize cluster configurations with a suitable amount\nof total memory and within this reduced search space, we iteratively search for\nthe best cluster configuration with Bayesian optimization. This search process\nstops once it converges on a configuration that is believed to be optimal for\nthe given job. In our evaluation on a dataset with 1031 Spark and Hadoop jobs,\nwe see a reduction of search iterations to find an optimal configuration by\naround half, compared to the baseline.",
    "descriptor": "\nComments: 9 pages, 5 Figures, 3 Tables; IEEE BigData 2022. arXiv admin note: substantial text overlap with arXiv:2206.13852\n",
    "authors": [
      "Jonathan Will",
      "Lauritz Thamsen",
      "Jonathan Bader",
      "Dominik Scheinert",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.04240"
  },
  {
    "id": "arXiv:2211.04242",
    "title": "Impact of Virtual Inertia on DC Grid Stability with Constant Power Loads",
    "abstract": "Virtual inertia is an effective control approach to help prevent sudden\nvoltage changes during transient events in low inertia DC grids. While several\nmethods have been proposed to implement virtual inertia in DC grids, its impact\non the stability in presence of constant power loads (CPLs) remains unclear. In\nthis paper, we perform a rigorous stability analysis for DC grids with CPLs\npowered by virtual-inertia-enhanced converters. We give expressions relating\nvirtual inertia and the required DC bus capacitance to guarantee stability. We\nconclude that: 1. the DC grid stability can be improved if virtual inertia is\nproperly designed; 2. a large virtual inertia deteriorates the DC grid\nstability, and a correspondingly large DC bus capacitance is required to\nguarantee stability. Test results are presented to validate the analysis.",
    "descriptor": "",
    "authors": [
      "Hao Tu",
      "Hui Yu",
      "Srdjan Lukic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04242"
  },
  {
    "id": "arXiv:2211.04247",
    "title": "Containminated Images Recovery by Implementing Non-negative Matrix  Factorisation",
    "abstract": "Non-negative matrix factorisation (NMF) has been widely used to address the\nproblem of corrupted data in images. The standard NMF algorithm minimises the\nEuclidean distance between the data matrix and the factorised approximation.\nAlthough this method has demonstrated good results, because it employs the\nsquared error of each data point, the standard NMF algorithm is sensitive to\noutliers. In this paper, we theoretically analyse the robustness of the\nstandard NMF, HCNMF and L2,1-NMF algorithms, and implement sets of experiments\nto show the robustness on real datasets, namely ORL and Extended YaleB. Our\nwork demonstrates that different amounts of iterations are required for each\nalgorithm to converge. Given the high computational complexity of these\nalgorithms, our final models such as HCNMF and L2,1-NMF model do not\nsuccessfully converge within the iteration parameters of this paper.\nNevertheless, the experimental results still demonstrate the robustness of the\naforementioned algorithms to some extent.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Pengwei Yang",
      "Angel Teng",
      "Jack Mangos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04247"
  },
  {
    "id": "arXiv:2211.04248",
    "title": "Improving Graph Neural Networks at Scale: Combining Approximate PageRank  and CoreRank",
    "abstract": "Graph Neural Networks (GNNs) have achieved great successes in many learning\ntasks performed on graph structures. Nonetheless, to propagate information GNNs\nrely on a message passing scheme which can become prohibitively expensive when\nworking with industrial-scale graphs. Inspired by the PPRGo model, we propose\nthe CorePPR model, a scalable solution that utilises a learnable convex\ncombination of the approximate personalised PageRank and the CoreRank to\ndiffuse multi-hop neighbourhood information in GNNs. Additionally, we\nincorporate a dynamic mechanism to select the most influential neighbours for a\nparticular node which reduces training time while preserving the performance of\nthe model. Overall, we demonstrate that CorePPR outperforms PPRGo, particularly\non large graphs where selecting the most influential nodes is particularly\nrelevant for scalability. Our code is publicly available at:\nhttps://github.com/arielramos97/CorePPR.",
    "descriptor": "\nComments: Accepted at the \"NeurIPS 2022 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2022)\"\n",
    "authors": [
      "Ariel R. Ramos Vela",
      "Johannes F. Lutzeyer",
      "Anastasios Giovanidis",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.04248"
  },
  {
    "id": "arXiv:2211.04249",
    "title": "Numerical analysis of the SIMP model for the topology optimization of  minimizing compliance in linear elasticity",
    "abstract": "We study the finite element approximation of the solid isotropic material\nwith penalization (SIMP) model for the topology optimization of the compliance\nof a linearly elastic structure. To ensure the existence of a minimizer to the\ninfinite-dimensional problem, we consider two popular restriction methods:\n$W^{1,p}$-type regularization and density filtering. Previous results prove\nweak(-*) convergence in the solution space of the material distribution to an\nunspecified minimizer of the infinite-dimensional problem. In this work, we\nshow that, for every isolated minimizer, there exists a sequence of finite\nelement minimizers that strongly converges to the minimizer in the solution\nspace. As a by-product, this ensures that there exists a sequence of unfiltered\ndiscretized material distributions that does not exhibit checkerboarding.",
    "descriptor": "",
    "authors": [
      "Ioannis P. A. Papadopoulos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04249"
  },
  {
    "id": "arXiv:2211.04250",
    "title": "DetAIL : A Tool to Automatically Detect and Analyze Drift In Language",
    "abstract": "Machine learning and deep learning-based decision making has become part of\ntoday's software. The goal of this work is to ensure that machine learning and\ndeep learning-based systems are as trusted as traditional software. Traditional\nsoftware is made dependable by following rigorous practice like static\nanalysis, testing, debugging, verifying, and repairing throughout the\ndevelopment and maintenance life-cycle. Similarly for machine learning systems,\nwe need to keep these models up to date so that their performance is not\ncompromised. For this, current systems rely on scheduled re-training of these\nmodels as new data kicks in. In this work, we propose to measure the data drift\nthat takes place when new data kicks in so that one can adaptively re-train the\nmodels whenever re-training is actually required irrespective of schedules. In\naddition to that, we generate various explanations at sentence level and\ndataset level to capture why a given payload text has drifted.",
    "descriptor": "",
    "authors": [
      "Nishtha Madaan",
      "Adithya Manjunatha",
      "Hrithik Nambiar",
      "Aviral Kumar Goel",
      "Harivansh Kumar",
      "Diptikalyan Saha",
      "Srikanta Bedathur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04250"
  },
  {
    "id": "arXiv:2211.04253",
    "title": "Eat-Radar: Continuous Fine-Grained Eating Gesture Detection Using FMCW  Radar and 3D Temporal Convolutional Network",
    "abstract": "Unhealthy dietary habits are considered as the primary cause of multiple\nchronic diseases such as obesity and diabetes. The automatic food intake\nmonitoring system has the potential to improve the quality of life (QoF) of\npeople with dietary related diseases through dietary assessment. In this work,\nwe propose a novel contact-less radar-based food intake monitoring approach.\nSpecifically, a Frequency Modulated Continuous Wave (FMCW) radar sensor is\nemployed to recognize fine-grained eating and drinking gestures. The\nfine-grained eating/drinking gesture contains a series of movement from raising\nthe hand to the mouth until putting away the hand from the mouth. A 3D temporal\nconvolutional network (3D-TCN) is developed to detect and segment eating and\ndrinking gestures in meal sessions by processing the Range-Doppler Cube (RD\nCube). Unlike previous radar-based research, this work collects data in\ncontinuous meal sessions. We create a public dataset that contains 48 meal\nsessions (3121 eating gestures and 608 drinking gestures) from 48 participants\nwith a total duration of 783 minutes. Four eating styles (fork & knife,\nchopsticks, spoon, hand) are included in this dataset. To validate the\nperformance of the proposed approach, 8-fold cross validation method is\napplied. Experimental results show that our proposed 3D-TCN outperforms the\nmodel that combines a convolutional neural network and a long-short-term-memory\nnetwork (CNN-LSTM), and also the CNN-Bidirectional LSTM model (CNN-BiLSTM) in\neating and drinking gesture detection. The 3D-TCN model achieves a segmental\nF1-score of 0.887 and 0.844 for eating and drinking gestures, respectively. The\nresults of the proposed approach indicate the feasibility of using radar for\nfine-grained eating and drinking gesture detection and segmentation in meal\nsessions.",
    "descriptor": "",
    "authors": [
      "Chunzhuo Wang",
      "T. Sunil Kumar",
      "Walter De Raedt",
      "Guido Camps",
      "Hans Hallez",
      "Bart Vanrumste"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04253"
  },
  {
    "id": "arXiv:2211.04254",
    "title": "FedGrad: Optimisation in Decentralised Machine Learning",
    "abstract": "Federated Learning is a machine learning paradigm where we aim to train\nmachine learning models in a distributed fashion. Many clients/edge devices\ncollaborate with each other to train a single model on the central. Clients do\nnot share their own datasets with each other, decoupling computation and data\non the same device. In this paper, we propose yet another adaptive federated\noptimization method and some other ideas in the field of federated learning. We\nalso perform experiments using these methods and showcase the improvement in\nthe overall performance of federated learning.",
    "descriptor": "\nComments: 4 pages, 6 figures, FL-AAAI Workshop Proceeding\n",
    "authors": [
      "Mann Patel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04254"
  },
  {
    "id": "arXiv:2211.04255",
    "title": "Two-stream Multi-dimensional Convolutional Network for Real-time  Violence Detection",
    "abstract": "The increasing number of surveillance cameras and security concerns have made\nautomatic violent activity detection from surveillance footage an active area\nfor research. Modern deep learning methods have achieved good accuracy in\nviolence detection and proved to be successful because of their applicability\nin intelligent surveillance systems. However, the models are computationally\nexpensive and large in size because of their inefficient methods for feature\nextraction. This work presents a novel architecture for violence detection\ncalled Two-stream Multi-dimensional Convolutional Network (2s-MDCN), which uses\nRGB frames and optical flow to detect violence. Our proposed method extracts\ntemporal and spatial information independently by 1D, 2D, and 3D convolutions.\nDespite combining multi-dimensional convolutional networks, our models are\nlightweight and efficient due to reduced channel capacity, yet they learn to\nextract meaningful spatial and temporal information. Additionally, combining\nRGB frames and optical flow yields 2.2% more accuracy than a single RGB stream.\nRegardless of having less complexity, our models obtained state-of-the-art\naccuracy of 89.7% on the largest violence detection benchmark dataset.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Dipon Kumar Ghosh",
      "Amitabha Chakrabarty"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04255"
  },
  {
    "id": "arXiv:2211.04256",
    "title": "Bridging Fairness and Environmental Sustainability in Natural Language  Processing",
    "abstract": "Fairness and environmental impact are important research directions for the\nsustainable development of artificial intelligence. However, while each topic\nis an active research area in natural language processing (NLP), there is a\nsurprising lack of research on the interplay between the two fields. This\nlacuna is highly problematic, since there is increasing evidence that an\nexclusive focus on fairness can actually hinder environmental sustainability,\nand vice versa. In this work, we shed light on this crucial intersection in NLP\nby (1) investigating the efficiency of current fairness approaches through\nsurveying example methods for reducing unfair stereotypical bias from the\nliterature, and (2) evaluating a common technique to reduce energy consumption\n(and thus environmental impact) of English NLP models, knowledge distillation\n(KD), for its impact on fairness. In this case study, we evaluate the effect of\nimportant KD factors, including layer and dimensionality reduction, with\nrespect to: (a) performance on the distillation task (natural language\ninference and semantic similarity prediction), and (b) multiple measures and\ndimensions of stereotypical bias (e.g., gender bias measured via the Word\nEmbedding Association Test). Our results lead us to clarify current assumptions\nregarding the effect of KD on unfair bias: contrary to other findings, we show\nthat KD can actually decrease model fairness.",
    "descriptor": "\nComments: Accepted for publication at EMNLP 2022\n",
    "authors": [
      "Marius Hessenthaler",
      "Emma Strubell",
      "Dirk Hovy",
      "Anne Lauscher"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04256"
  },
  {
    "id": "arXiv:2211.04257",
    "title": "Toward Human-AI Co-creation to Accelerate Material Discovery",
    "abstract": "There is an increasing need in our society to achieve faster advances in\nScience to tackle urgent problems, such as climate changes, environmental\nhazards, sustainable energy systems, pandemics, among others. In certain\ndomains like chemistry, scientific discovery carries the extra burden of\nassessing risks of the proposed novel solutions before moving to the\nexperimental stage. Despite several recent advances in Machine Learning and AI\nto address some of these challenges, there is still a gap in technologies to\nsupport end-to-end discovery applications, integrating the myriad of available\ntechnologies into a coherent, orchestrated, yet flexible discovery process.\nSuch applications need to handle complex knowledge management at scale,\nenabling knowledge consumption and production in a timely and efficient way for\nsubject matter experts (SMEs). Furthermore, the discovery of novel functional\nmaterials strongly relies on the development of exploration strategies in the\nchemical space. For instance, generative models have gained attention within\nthe scientific community due to their ability to generate enormous volumes of\nnovel molecules across material domains. These models exhibit extreme\ncreativity that often translates in low viability of the generated candidates.\nIn this work, we propose a workbench framework that aims at enabling the\nhuman-AI co-creation to reduce the time until the first discovery and the\nopportunity costs involved. This framework relies on a knowledge base with\ndomain and process knowledge, and user-interaction components to acquire\nknowledge and advise the SMEs. Currently,the framework supports four main\nactivities: generative modeling, dataset triage, molecule adjudication, and\nrisk assessment.",
    "descriptor": "\nComments: 9 pages, 5 figures, NeurIPS 2022 WS: AI4Science\n",
    "authors": [
      "Dmitry Zubarev",
      "Carlos Raoni Mendes",
      "Emilio Vital Brazil",
      "Renato Cerqueira",
      "Kristin Schmidt",
      "Vinicius Segura",
      "Juliana Jansen Ferreira",
      "Dan Sanders"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.04257"
  },
  {
    "id": "arXiv:2211.04259",
    "title": "Towards Measuring The Fungibility and Anonymity of Cryptocurrencies",
    "abstract": "Cryptocurrencies aim to replicate physical cash in the digital realm while\nremoving centralized middlemen. Decentralization is achieved by the blockchain,\na permanent public ledger that contains a record of every transaction. The\npublic ledger ensures transparency, which enables public verifiability but\nharms fungibility and anonymity. Even though cryptocurrencies attracted\nmillions of users in the last decade with their total market cap reaching\napproximately one trillion USD, their anonymity guarantees are poorly\nunderstood. Indeed, previous notions of privacy, anonymity, and fungibility for\ncryptocurrencies are either non-quantitative or inapplicable, e.g.,\ncomputationally hard to measure. In this work, we put forward a formal\nframework to measure the fungibility and anonymity of cryptocurrencies,\nallowing us to quantitatively reason about the mixing characteristics of\ncryptocurrencies and the privacy-enhancing technologies built on top of them.\nOur methods apply absorbing Markov chains combined with Shannon entropy. To the\nbest of our knowledge, our work is the first to assess the fungibility of\ncryptocurrencies. Among other results, we find that in the studied one-week\ninterval, the Bitcoin network, on average, provided comparable but quantifiably\nmore fungibility than the Ethereum network.",
    "descriptor": "\nComments: Pre-print. 23 pages\n",
    "authors": [
      "Domokos Mikl\u00f3s Kelen",
      "Istv\u00e1n Andr\u00e1s Seres"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.04259"
  },
  {
    "id": "arXiv:2211.04261",
    "title": "Synchronization of Diverse Agents via Phase Analysis",
    "abstract": "In this paper, the synchronization of heterogeneous agents interacting over a\ndynamical network is studied. The edge dynamics can model the inter-agent\ncommunications which are often heterogeneous by nature. They can also model the\ncontrollers of the agents which may be different for each agent or uniform for\nall the agents. Novel synchronization conditions are obtained for both cases\nfrom a phase perspective by exploiting a recently developed small phase\ntheorem. The conditions scale well with the network and reveal the trade-off\nbetween the phases of node dynamics and edge dynamics. We also study the\nsynchronizability problem which aims to characterize the allowable diversity of\nthe agents for which controllers can be designed so as to achieve\nsynchronization. The allowable diversity is captured in terms of phase\nconditions engaging the residue matrices of the agents at their persistent\nmodes. Controller design algorithms are provided for the cases of\nagent-dependent and uniform controllers, respectively.",
    "descriptor": "",
    "authors": [
      "Dan Wang",
      "Wei Chen",
      "Li Qiu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04261"
  },
  {
    "id": "arXiv:2211.04264",
    "title": "Note on generalized group testing",
    "abstract": "In this note, we present a new adaptive algorithm for generalized group\ntesting, which is asymptotically optimal if $d=o(\\log_2|E|)$, $E$ is a set of\npotentially contaminated sets, $d$ is a maximal size of elements of $E$. Also,\nwe design a 3-stage algorithm, which is asymptotically optimal for $d=2$.",
    "descriptor": "",
    "authors": [
      "Ilya Vorobyev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.04264"
  },
  {
    "id": "arXiv:2211.04266",
    "title": "TimeKit: A Time-series Forecasting-based Upgrade Kit for Collaborative  Filtering",
    "abstract": "Recommender systems are a long-standing research problem in data mining and\nmachine learning. They are incremental in nature, as new user-item interaction\nlogs arrive. In real-world applications, we need to periodically train a\ncollaborative filtering algorithm to extract user/item embedding vectors and\ntherefore, a time-series of embedding vectors can be naturally defined. We\npresent a time-series forecasting-based upgrade kit (TimeKit), which works in\nthe following way: it i) first decides a base collaborative filtering\nalgorithm, ii) extracts user/item embedding vectors with the base algorithm\nfrom user-item interaction logs incrementally, e.g., every month, iii) trains\nour time-series forecasting model with the extracted time- series of embedding\nvectors, and then iv) forecasts the future embedding vectors and recommend with\ntheir dot-product scores owing to a recent breakthrough in processing\ncomplicated time- series data, i.e., neural controlled differential equations\n(NCDEs). Our experiments with four real-world benchmark datasets show that the\nproposed time-series forecasting-based upgrade kit can significantly enhance\nexisting popular collaborative filtering algorithms.",
    "descriptor": "\nComments: Accepted at IEEE BigData 2022\n",
    "authors": [
      "Seoyoung Hong",
      "Minju Jo",
      "Seungji Kook",
      "Jaeeun Jung",
      "Hyowon Wi",
      "Noseong Park",
      "Sung-Bae Cho"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04266"
  },
  {
    "id": "arXiv:2211.04269",
    "title": "Spoofing Attack Detection in the Physical Layer with Commutative Neural  Networks",
    "abstract": "In a spoofing attack, an attacker impersonates a legitimate user to access or\ntamper with data intended for or produced by the legitimate user. In wireless\ncommunication systems, these attacks may be detected by relying on features of\nthe channel and transmitter radios. In this context, a popular approach is to\nexploit the dependence of the received signal strength (RSS) at multiple\nreceivers or access points with respect to the spatial location of the\ntransmitter. Existing schemes rely on long-term estimates, which makes it\ndifficult to distinguish spoofing from movement of a legitimate user. This\nlimitation is here addressed by means of a deep neural network that implicitly\nlearns the distribution of pairs of short-term RSS vector estimates. The\nadopted network architecture imposes the invariance to permutations of the\ninput (commutativity) that the decision problem exhibits. The merits of the\nproposed algorithm are corroborated on a data set that we collected.",
    "descriptor": "",
    "authors": [
      "Daniel Romero",
      "Peter Gerstoft",
      "Hadi Givehchian",
      "Dinesh Bharadia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.04269"
  },
  {
    "id": "arXiv:2211.04274",
    "title": "A Semiparametric Efficient Approach To Label Shift Estimation and  Quantification",
    "abstract": "Transfer Learning is an area of statistics and machine learning research that\nseeks answers to the following question: how do we build successful learning\nalgorithms when the data available for training our model is qualitatively\ndifferent from the data we hope the model will perform well on? In this thesis,\nwe focus on a specific area of Transfer Learning called label shift, also known\nas quantification. In quantification, the aforementioned discrepancy is\nisolated to a shift in the distribution of the response variable. In such a\nsetting, accurately inferring the response variable's new distribution is both\nan important estimation task in its own right and a crucial step for ensuring\nthat the learning algorithm can adapt to the new data. We make two\ncontributions to this field. First, we present a new procedure called SELSE\nwhich estimates the shift in the response variable's distribution. Second, we\nprove that SELSE is semiparametric efficient among a large family of\nquantification algorithms, i.e., SELSE's normalized error has the smallest\npossible asymptotic variance matrix compared to any other algorithm in that\nfamily. This family includes nearly all existing algorithms, including ACC/PACC\nquantifiers and maximum likelihood based quantifiers such as EMQ and MLLS.\nEmpirical experiments reveal that SELSE is competitive with, and in many cases\noutperforms, existing state-of-the-art quantification methods, and that this\nimprovement is especially large when the number of test samples is far greater\nthan the number of train samples.",
    "descriptor": "",
    "authors": [
      "Brandon Tse Wei Chow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.04274"
  },
  {
    "id": "arXiv:2211.04275",
    "title": "Machine Learning-based Framework for Optimally Solving the Analytical  Inverse Kinematics for Redundant Manipulators",
    "abstract": "Solving the analytical inverse kinematics (IK) of redundant manipulators in\nreal time is a difficult problem in robotics since its solution for a given\ntarget pose is not unique. Moreover, choosing the optimal IK solution with\nrespect to application-specific demands helps to improve the robustness and to\nincrease the success rate when driving the manipulator from its current\nconfiguration towards a desired pose. This is necessary, especially in\nhigh-dynamic tasks like catching objects in mid-flights. To compute a suitable\ntarget configuration in the joint space for a given target pose in the\ntrajectory planning context, various factors such as travel time or\nmanipulability must be considered. However, these factors increase the\ncomplexity of the overall problem which impedes real-time implementation. In\nthis paper, a real-time framework to compute the analytical inverse kinematics\nof a redundant robot is presented. To this end, the analytical IK of the\nredundant manipulator is parameterized by so-called redundancy parameters,\nwhich are combined with a target pose to yield a unique IK solution. Most\nexisting works in the literature either try to approximate the direct mapping\nfrom the desired pose of the manipulator to the solution of the IK or cluster\nthe entire workspace to find IK solutions. In contrast, the proposed framework\ndirectly learns these redundancy parameters by using a neural network (NN) that\nprovides the optimal IK solution with respect to the manipulability and the\ncloseness to the current robot configuration. Monte Carlo simulations show the\neffectiveness of the proposed approach which is accurate and real-time capable\n($\\approx$ \\SI{32}{\\micro\\second}) on the KUKA LBR iiwa 14 R820.",
    "descriptor": "",
    "authors": [
      "Minh Nhat Vu",
      "Florian Beck",
      "Christian Hartl-Nesic",
      "Anh Nguyen",
      "Andreas Kugi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04275"
  },
  {
    "id": "arXiv:2211.04278",
    "title": "Tight Complexity Bounds for Counting Generalized Dominating Sets in  Bounded-Treewidth Graphs",
    "abstract": "We investigate how efficiently a well-studied family of domination-type\nproblems can be solved on bounded-treewidth graphs. For sets $\\sigma,\\rho$ of\nnon-negative integers, a $(\\sigma,\\rho)$-set of a graph $G$ is a set $S$ of\nvertices such that $|N(u)\\cap S|\\in \\sigma$ for every $u\\in S$, and $|N(v)\\cap\nS|\\in \\rho$ for every $v\\not\\in S$. The problem of finding a\n$(\\sigma,\\rho)$-set (of a certain size) unifies standard problems such as\nIndependent Set, Dominating Set, Independent Dominating Set, and many others.\nFor all pairs of finite or cofinite sets $(\\sigma,\\rho)$, we determine (under\nstandard complexity assumptions) the best possible value $c_{\\sigma,\\rho}$ such\nthat there is an algorithm that counts $(\\sigma,\\rho)$-sets in time\n$c_{\\sigma,\\rho}^{\\sf tw}\\cdot n^{O(1)}$ (if a tree decomposition of width\n${\\sf tw}$ is given in the input). For example, for the Exact Independent\nDominating Set problem (also known as Perfect Code) corresponding to\n$\\sigma=\\{0\\}$ and $\\rho=\\{1\\}$, we improve the $3^{\\sf tw}\\cdot n^{O(1)}$\nalgorithm of [van Rooij, 2020] to $2^{\\sf tw}\\cdot n^{O(1)}$.\nDespite the unusually delicate definition of $c_{\\sigma,\\rho}$, we show that\nour algorithms are most likely optimal, i.e., for any pair $(\\sigma, \\rho)$ of\nfinite or cofinite sets where the problem is non-trivial, and any\n$\\varepsilon>0$, a $(c_{\\sigma,\\rho}-\\varepsilon)^{\\sf tw}\\cdot\nn^{O(1)}$-algorithm counting the number of $(\\sigma,\\rho)$-sets would violate\nthe Counting Strong Exponential-Time Hypothesis (#SETH). For finite sets\n$\\sigma$ and $\\rho$, our lower bounds also extend to the decision version,\nshowing that our algorithms are optimal in this setting as well. In contrast,\nfor many cofinite sets, we show that further significant improvements for the\ndecision and optimization versions are possible using the technique of\nrepresentative sets.",
    "descriptor": "",
    "authors": [
      "Jacob Focke",
      "D\u00e1niel Marx",
      "Fionn Mc Inerney",
      "Daniel Neuen",
      "Govind S. Sankar",
      "Philipp Schepper",
      "Philip Wellnitz"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04278"
  },
  {
    "id": "arXiv:2211.04279",
    "title": "Detecting Shortcuts in Medical Images - A Case Study in Chest X-rays",
    "abstract": "The availability of large public datasets and the increased amount of\ncomputing power have shifted the interest of the medical community to\nhigh-performance algorithms. However, little attention is paid to the quality\nof the data and their annotations. High performance on benchmark datasets may\nbe reported without considering possible shortcuts or artifacts in the data,\nbesides, models are not tested on subpopulation groups. With this work, we aim\nto raise awareness about shortcuts problems. We validate previous findings, and\npresent a case study on chest X-rays using two publicly available datasets. We\nshare annotations for a subset of pneumothorax images with drains. We conclude\nwith general recommendations for medical image classification.",
    "descriptor": "\nComments: Submitted to ISBI 2023\n",
    "authors": [
      "Amelia Jim\u00e9nez-S\u00e1nchez",
      "Dovile Juodelye",
      "Bethany Chamberlain",
      "Veronika Cheplygina"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04279"
  },
  {
    "id": "arXiv:2211.04281",
    "title": "SocioProbe: What, When, and Where Language Models Learn about  Sociodemographics",
    "abstract": "Pre-trained language models (PLMs) have outperformed other NLP models on a\nwide range of tasks. Opting for a more thorough understanding of their\ncapabilities and inner workings, researchers have established the extend to\nwhich they capture lower-level knowledge like grammaticality, and mid-level\nsemantic knowledge like factual understanding. However, there is still little\nunderstanding of their knowledge of higher-level aspects of language. In\nparticular, despite the importance of sociodemographic aspects in shaping our\nlanguage, the questions of whether, where, and how PLMs encode these aspects,\ne.g., gender or age, is still unexplored. We address this research gap by\nprobing the sociodemographic knowledge of different single-GPU PLMs on multiple\nEnglish data sets via traditional classifier probing and information-theoretic\nminimum description length probing. Our results show that PLMs do encode these\nsociodemographics, and that this knowledge is sometimes spread across the\nlayers of some of the tested PLMs. We further conduct a multilingual analysis\nand investigate the effect of supplementary training to further explore to what\nextent, where, and with what amount of pre-training data the knowledge is\nencoded. Our overall results indicate that sociodemographic knowledge is still\na major challenge for NLP. PLMs require large amounts of pre-training data to\nacquire the knowledge and models that excel in general language understanding\ndo not seem to own more knowledge about these aspects.",
    "descriptor": "\nComments: Accepted for publication at EMNLP 2022\n",
    "authors": [
      "Anne Lauscher",
      "Federico Bianchi",
      "Samuel Bowman",
      "Dirk Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04281"
  },
  {
    "id": "arXiv:2211.04284",
    "title": "Efficient Compressed Ratio Estimation using Online Sequential Learning  for Edge Computing",
    "abstract": "Owing to the widespread adoption of the Internet of Things, a vast amount of\nsensor information is being acquired in real time. Accordingly, the\ncommunication cost of data from edge devices is increasing. Compressed sensing\n(CS), a data compression method that can be used on edge devices, has been\nattracting attention as a method to reduce communication costs. In CS,\nestimating the appropriate compression ratio is important. There is a method to\nadaptively estimate the compression ratio for the acquired data using\nreinforcement learning. However, the computational costs associated with\nexisting reinforcement learning methods that can be utilized on edges are\nexpensive. In this study, we developed an efficient reinforcement learning\nmethod for edge devices, referred to as the actor--critic online sequential\nextreme learning machine (AC-OSELM), and a system to compress data by\nestimating an appropriate compression ratio on the edge using AC-OSELM. The\nperformance of the proposed method in estimating the compression ratio is\nevaluated by comparing it with other reinforcement learning methods for edge\ndevices. The experimental results show that AC-OSELM achieved the same or\nbetter compression performance and faster compression ratio estimation than the\nexisting methods.",
    "descriptor": "\nComments: 7 pages, 7 figures, Submitted to IEEE ICC 2023\n",
    "authors": [
      "Hiroki Oikawa",
      "Hangli Ge",
      "Noboru Koshizuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04284"
  },
  {
    "id": "arXiv:2211.04289",
    "title": "Review and Analysis of Pain Research Literature through Keyword  Co-occurrence Networks",
    "abstract": "Pain is a significant public health problem as the number of individuals with\na history of pain globally keeps growing. In response, many synergistic\nresearch areas have been coming together to address pain-related issues. This\nwork conducts a review and analysis of a vast body of pain-related literature\nusing the keyword co-occurrence network (KCN) methodology. In this method, a\nset of KCNs is constructed by treating keywords as nodes and the co-occurrence\nof keywords as links between the nodes. Since keywords represent the knowledge\ncomponents of research articles, analysis of KCNs will reveal the knowledge\nstructure and research trends in the literature. This study extracted and\nanalyzed keywords from 264,560 pain-related research articles indexed in IEEE,\nPubMed, Engineering Village, and Web of Science published between 2002 and\n2021. We observed rapid growth in pain literature in the last two decades: the\nnumber of articles has grown nearly threefold, and the number of keywords has\ngrown by a factor of 7. We identified emerging and declining research trends in\nsensors/methods, biomedical, and treatment tracks. We also extracted the most\nfrequently co-occurring keyword pairs and clusters to help researchers\nrecognize the synergies among different pain-related topics.",
    "descriptor": "",
    "authors": [
      "Burcu Ozek",
      "Zhenyuan Lu",
      "Fatemeh Pouromran",
      "Sagar Kamarthi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.04289"
  },
  {
    "id": "arXiv:2211.04293",
    "title": "Evaluation of Color Anomaly Detection in Multispectral Images For  Synthetic Aperture Sensing",
    "abstract": "In this article, we evaluate unsupervised anomaly detection methods in\nmultispectral images obtained with a wavelength-independent synthetic aperture\nsensing technique, called Airborne Optical Sectioning (AOS). With a focus on\nsearch and rescue missions that apply drones to locate missing or injured\npersons in dense forest and require real-time operation, we evaluate runtime\nvs. quality of these methods. Furthermore, we show that color anomaly detection\nmethods that normally operate in the visual range always benefit from an\nadditional far infrared (thermal) channel. We also show that, even without\nadditional thermal bands, the choice of color space in the visual range already\nhas an impact on the detection results. Color spaces like HSV and HLS have the\npotential to outperform the widely used RGB color space, especially when color\nanomaly detection is used for forest-like environments.",
    "descriptor": "\nComments: 12 pages, 6 figures, 3 tables\n",
    "authors": [
      "Francis Seits",
      "Indrajit Kurmi",
      "Oliver Bimber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04293"
  },
  {
    "id": "arXiv:2211.04297",
    "title": "Heterogeneous Recurrent Spiking Neural Network for Spatio-Temporal  Classification",
    "abstract": "Spiking Neural Networks are often touted as brain-inspired learning models\nfor the third wave of Artificial Intelligence. Although recent SNNs trained\nwith supervised backpropagation show classification accuracy comparable to deep\nnetworks, the performance of unsupervised learning-based SNNs remains much\nlower. This paper presents a heterogeneous recurrent spiking neural network\n(HRSNN) with unsupervised learning for spatio-temporal classification of video\nactivity recognition tasks on RGB (KTH, UCF11, UCF101) and event-based datasets\n(DVS128 Gesture). The key novelty of the HRSNN is that the recurrent layer in\nHRSNN consists of heterogeneous neurons with varying firing/relaxation\ndynamics, and they are trained via heterogeneous\nspike-time-dependent-plasticity (STDP) with varying learning dynamics for each\nsynapse. We show that this novel combination of heterogeneity in architecture\nand learning method outperforms current homogeneous spiking neural networks. We\nfurther show that HRSNN can achieve similar performance to state-of-the-art\nbackpropagation trained supervised SNN, but with less computation (fewer\nneurons and sparse connection) and less training data.",
    "descriptor": "\nComments: 32 pages, 11 Figures, 4 Tables. arXiv admin note: text overlap with arXiv:1511.03198 by other authors\n",
    "authors": [
      "Biswadeep Chakraborty",
      "Saibal Mukhopadhyay"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.04297"
  },
  {
    "id": "arXiv:2211.04301",
    "title": "Model Checking Linear Dynamical Systems under Floating-point Rounding",
    "abstract": "We consider linear dynamical systems under floating-point rounding. In these\nsystems, a matrix is repeatedly applied to a vector, but the numbers are\nrounded into floating-point representation after each step (i.e., stored as a\nfixed-precision mantissa and an exponent). The approach more faithfully models\nrealistic implementations of linear loops, compared to the exact\narbitrary-precision setting often employed in the study of linear dynamical\nsystems.\nOur results are twofold: We show that for non-negative matrices there is a\nspecial structure to the sequence of vectors generated by the system: the\nmantissas are periodic and the exponents grow linearly. We leverage this to\nshow decidability of $\\omega$-regular temporal model checking against\nsemialgebraic predicates. This contrasts with the unrounded setting, where even\nthe non-negative case encompasses the long-standing open Skolem and positivity\nproblems.\nOn the other hand, when negative numbers are allowed in the matrix, we show\nthat the reachability problem is undecidable by encoding a two-counter machine.\nAgain, this is in contrast to the unrounded setting where point-to-point\nreachability is known to be decidable in polynomial time.",
    "descriptor": "",
    "authors": [
      "Engel Lefaucheux",
      "Jo\u00ebl Ouaknine",
      "David Purser",
      "Mohammadamin Sharifi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.04301"
  },
  {
    "id": "arXiv:2211.04304",
    "title": "BER: Balanced Error Rate For Speaker Diarization",
    "abstract": "DER is the primary metric to evaluate diarization performance while facing a\ndilemma: the errors in short utterances or segments tend to be overwhelmed by\nlonger ones. Short segments, e.g., `yes' or `no,' still have semantic\ninformation. Besides, DER overlooks errors in less-talked speakers. Although\nJER balances speaker errors, it still suffers from the same dilemma.\nConsidering all those aspects, duration error, segment error, and\nspeaker-weighted error constituting a complete diarization evaluation, we\npropose a Balanced Error Rate (BER) to evaluate speaker diarization. First, we\npropose a segment-level error rate (SER) via connected sub-graphs and adaptive\nIoU threshold to get accurate segment matching. Second, to evaluate diarization\nin a unified way, we adopt a speaker-specific harmonic mean between duration\nand segment, followed by a speaker-weighted average. Third, we analyze our\nmetric via the modularized system, EEND, and the multi-modal method on real\ndatasets. SER and BER are publicly available at https://github.com/X-LANCE/BER.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Tao Liu",
      "Kai Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04304"
  },
  {
    "id": "arXiv:2211.04305",
    "title": "Designing an Adaptive Application-Level Checkpoint Management System for  Malleable MPI Applications",
    "abstract": "Dynamic resource management opens up numerous opportunities in High\nPerformance Computing. It improves the system-level services as well as\napplication performance. Checkpointing can also be deemed as a system-level\nservice and can reap the benefits offered by dynamism. A checkpointing system\ncan have better resource availability by integrating with a malleable resource\nmanagement system. In addition to fault tolerance, the checkpointing system can\ncater to the data redistribution demand of malleable applications during\nresource change. Therefore, we propose iCheck, an adaptive application-level\ncheckpoint management system that can efficiently utilize the system and\napplication level dynamism to provide better checkpointing and data\nredistribution services to applications.",
    "descriptor": "\nComments: Third International Symposium on Checkpointing for Supercomputing (SuperCheck-SC22)\n",
    "authors": [
      "Jophin John",
      "Michael Gerndt"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.04305"
  },
  {
    "id": "arXiv:2211.04307",
    "title": "Stability and convergence analysis of high-order numerical schemes with  DtN-type absorbing boundary conditions for nonlocal wave equations",
    "abstract": "The stability and convergence analysis of high-order numerical approximations\nfor the one- and two-dimensional nonlocal wave equations on unbounded spatial\ndomains are considered. We first use the quadrature-based finite difference\nschemes to discretize the spatially nonlocal operator, and apply the explicit\ndifference scheme to approximate the temporal derivative to achieve a fully\ndiscrete infinity system. After that, we construct the Dirichlet-to-Neumann\n(DtN)-type absorbing boundary conditions (ABCs) to reduce the infinite discrete\nsystem into a finite discrete system. To do so, we first adopt the idea in [Du,\nZhang and Zheng, \\emph{Commun. Comput. Phys.}, 24(4):1049--1072, 2018 and Du,\nHan, Zhang and Zheng, \\emph{SIAM J. Sci. Comp.}, 40(3):A1430--A1445, 2018] to\nderive the Dirichlet-to-Dirichlet (DtD)-type mappings for one- and\ntwo-dimensional cases, respectively. We then use the discrete nonlocal Green's\nfirst identity to achieve the discrete DtN-type mappings from the DtD-type\nmappings. The resulting DtN-type mappings make it possible to perform the\nstability and convergence analysis of the reduced problem. Numerical\nexperiments are provided to demonstrate the accuracy and effectiveness of the\nproposed approach.",
    "descriptor": "\nComments: 26 pages, 4 figures\n",
    "authors": [
      "Jihong Wang",
      "Jerry Zhijian Yang",
      "Jiwei Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04307"
  },
  {
    "id": "arXiv:2211.04310",
    "title": "Safety-Critical Ergodic Exploration in Cluttered Environments via  Control Barrier Functions",
    "abstract": "In this paper, we address the problem of safe trajectory planning for\nautonomous search and exploration in constrained, cluttered environments.\nGuaranteeing safe navigation is a challenging problem that has garnered\nsignificant attention. This work contributes a method that generates guaranteed\nsafety-critical search trajectories in a cluttered environment. Our approach\nintegrates safety-critical constraints using discrete control barrier functions\n(DCBFs) with ergodic trajectory optimization to enable safe exploration.\nErgodic trajectory optimization plans continuous exploratory trajectories that\nguarantee full coverage of a space. We demonstrate through simulated and\nexperimental results on a drone that our approach is able to generate\ntrajectories that enable safe and effective exploration. Furthermore, we show\nthe efficacy of our approach for safe exploration of real-world single- and\nmulti- drone platforms.",
    "descriptor": "",
    "authors": [
      "Cameron Lerch",
      "Ethan Dong",
      "Ian Abraham"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04310"
  },
  {
    "id": "arXiv:2211.04311",
    "title": "Geometric Constellation Shaping for Fiber-Optic Channels via End-to-End  Learning",
    "abstract": "End-to-end learning has become a popular method to optimize a constellation\nshape of a communication system. When the channel model is differentiable,\nend-to-end learning can be applied with conventional backpropagation algorithm\nfor optimization of the shape. A variety of optimization algorithms have also\nbeen developed for end-to-end learning over a non-differentiable channel model.\nIn this paper, we compare gradient-free optimization method based on the\ncubature Kalman filter, model-free optimization and backpropagation for\nend-to-end learning on a fiber-optic channel modeled by the split-step Fourier\nmethod. The results indicate that the gradient-free optimization algorithms\nprovide a decent replacement to backpropagation in terms of performance at the\nexpense of computational complexity. Furthermore, the quantization problem of\nfinite bit resolution of the digital-to-analog and analog-to-digital converters\nis addressed and its impact on geometrically shaped constellations is analysed.\nHere, the results show that when optimizing a constellation with respect to\nmutual information, a minimum number of quantization levels is required to\nachieve shaping gain. For generalized mutual information, the gain is\nmaintained throughout all of the considered quantization levels. Also, the\nresults implied that the autoencoder can adapt the constellation size to the\ngiven channel conditions.",
    "descriptor": "",
    "authors": [
      "Ognjen Jovanovic",
      "Francesco Da Ros",
      "Darko Zibar",
      "Metodi P. Yankov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04311"
  },
  {
    "id": "arXiv:2211.04312",
    "title": "From Causal Pairs to Causal Graphs",
    "abstract": "Causal structure learning from observational data remains a non-trivial task\ndue to various factors such as finite sampling, unobserved confounding factors,\nand measurement errors. Constraint-based and score-based methods tend to suffer\nfrom high computational complexity due to the combinatorial nature of\nestimating the directed acyclic graph (DAG). Motivated by the `Cause-Effect\nPair' NIPS 2013 Workshop on Causality Challenge, in this paper, we take a\ndifferent approach and generate a probability distribution over all possible\ngraphs informed by the cause-effect pair features proposed in response to the\nworkshop challenge. The goal of the paper is to propose new methods based on\nthis probabilistic information and compare their performance with traditional\nand state-of-the-art approaches. Our experiments, on both synthetic and real\ndatasets, show that our proposed methods not only have statistically similar or\nbetter performances than some traditional approaches but also are\ncomputationally faster.",
    "descriptor": "\nComments: ICMLA 2022\n",
    "authors": [
      "Rezaur Rashid",
      "Jawad Chowdhury",
      "Gabriel Terejanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.04312"
  },
  {
    "id": "arXiv:2211.04313",
    "title": "An Ensemble-based approach for assigning text to correct Harmonized  system code",
    "abstract": "Industries must follow government rules and regulations around the world to\nclassify products when assessing duties and taxes for international shipment.\nHarmonized System (HS) is the most standardized numerical method of classifying\ntraded products among industry classification systems. A hierarchical ensemble\nmodel comprising of Bert- transformer, NER, distance-based approaches, and\nknowledge-graphs have been developed to address scalability, coverage, ability\nto capture nuances, automation and auditing requirements when classifying\nunknown text-descriptions as per HS method.",
    "descriptor": "",
    "authors": [
      "Shubham",
      "Avinash Arya",
      "Subarna Roy",
      "Sridhar Jonnala"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04313"
  },
  {
    "id": "arXiv:2211.04314",
    "title": "Scalable multi-class sampling via filtered sliced optimal transport",
    "abstract": "We propose a multi-class point optimization formulation based on continuous\nWasserstein barycenters. Our formulation is designed to handle hundreds to\nthousands of optimization objectives and comes with a practical optimization\nscheme. We demonstrate the effectiveness of our framework on various sampling\napplications like stippling, object placement, and Monte-Carlo integration. We\na derive multi-class error bound for perceptual rendering error which can be\nminimized using our optimization. We provide source code at\nhttps://github.com/iribis/filtered-sliced-optimal-transport.",
    "descriptor": "\nComments: 15 pages, 17 figures, ACM Trans. Graph., Vol. 41, No. 6, Article 261. Publication date: December 2022\n",
    "authors": [
      "Corentin Sala\u00fcn",
      "Iliyan Georgiev",
      "Hans-Peter Seidel",
      "Gurprit Singh"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.04314"
  },
  {
    "id": "arXiv:2211.04315",
    "title": "Finding twin smooth integers by solving Pell equations",
    "abstract": "Any pair of consecutive B-smooth integers for a given smoothness bound B\ncorresponds to a solution (x, y) of the equation x^2 - 2Dy^2 = 1 for a certain\nsquare-free, B-smooth integer D and a B-smooth integer y. This paper describes\nalgorithms to find such twin B-smooth integers that lie in a given interval by\nusing the structure of solutions of the above Pell equation. The problem of\nfinding such twin smooth integers is motivated by the quest for suitable\nparameters to efficiently instantiate recent isogeny-based cryptosystems. While\nthe Pell equation structure of twin B-smooth integers has previously been used\nto describe and compute the full set of such pairs for very small values of B,\nincreasing B to allow for cryptographically sized solutions makes this approach\nutterly infeasible. We start by revisiting the Pell solution structure of the\nset of twin smooth integers. Instead of using it to enumerate all twin smooth\npairs, we focus on identifying only those that lie in a given interval. This\nrestriction allows us to describe algorithms that navigate the vast set of Pell\nsolutions in a more targeted way. Experiments run with these algorithms have\nprovided examples of twin B-smooth pairs that are larger and have smaller\nsmoothness bound B than previously reported pairs. Unfortunately, those\nexamples do not yet provide better parameters for cryptography, but we hope\nthat our methods can be generalized or used as subroutines in future work to\nachieve that goal.",
    "descriptor": "",
    "authors": [
      "Jan Buzek",
      "Junaid Hasan",
      "Jason Liu",
      "Michael Naehrig",
      "Anthony Vigil"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2211.04315"
  },
  {
    "id": "arXiv:2211.04323",
    "title": "Sequential Transformer for End-to-End Person Search",
    "abstract": "Person Search aims to simultaneously localize and recognize a target person\nfrom realistic and uncropped gallery images. One major challenge of person\nsearch comes from the contradictory goals of the two sub-tasks, i.e., person\ndetection focuses on finding the commonness of all persons so as to distinguish\npersons from the background, while person re-identification (re-ID) focuses on\nthe differences among different persons. In this paper, we propose a novel\nSequential Transformer (SeqTR) for end-to-end person search to deal with this\nchallenge. Our SeqTR contains a detection transformer and a novel re-ID\ntransformer that sequentially addresses detection and re-ID tasks. The re-ID\ntransformer comprises the self-attention layer that utilizes contextual\ninformation and the cross-attention layer that learns local fine-grained\ndiscriminative features of the human body. Moreover, the re-ID transformer is\nshared and supervised by multi-scale features to improve the robustness of\nlearned person representations. Extensive experiments on two widely-used person\nsearch benchmarks, CUHK-SYSU and PRW, show that our proposed SeqTR not only\noutperforms all existing person search methods with a 59.3% mAP on PRW but also\nachieves comparable performance to the state-of-the-art results with an mAP of\n94.8% on CUHK-SYSU.",
    "descriptor": "",
    "authors": [
      "Long Chen",
      "Jinhua Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04323"
  },
  {
    "id": "arXiv:2211.04324",
    "title": "Machine Learning-Aided Operations and Communications of Unmanned Aerial  Vehicles: A Contemporary Survey",
    "abstract": "The ongoing amalgamation of UAV and ML techniques is creating a significant\nsynergy and empowering UAVs with unprecedented intelligence and autonomy. This\nsurvey aims to provide a timely and comprehensive overview of ML techniques\nused in UAV operations and communications and identify the potential growth\nareas and research gaps. We emphasise the four key components of UAV operations\nand communications to which ML can significantly contribute, namely, perception\nand feature extraction, feature interpretation and regeneration, trajectory and\nmission planning, and aerodynamic control and operation. We classify the latest\npopular ML tools based on their applications to the four components and conduct\ngap analyses. This survey also takes a step forward by pointing out significant\nchallenges in the upcoming realm of ML-aided automated UAV operations and\ncommunications. It is revealed that different ML techniques dominate the\napplications to the four key modules of UAV operations and communications.\nWhile there is an increasing trend of cross-module designs, little effort has\nbeen devoted to an end-to-end ML framework, from perception and feature\nextraction to aerodynamic control and operation. It is also unveiled that the\nreliability and trust of ML in UAV operations and applications require\nsignificant attention before full automation of UAVs and potential cooperation\nbetween UAVs and humans come to fruition.",
    "descriptor": "\nComments: 36 pages, 304 references, 19 Figures\n",
    "authors": [
      "Harrison Kurunathan",
      "Hailong Huang",
      "Kai Li",
      "Wei Ni",
      "Ekram Hossain"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04324"
  },
  {
    "id": "arXiv:2211.04325",
    "title": "Will we run out of data? An analysis of the limits of scaling datasets  in Machine Learning",
    "abstract": "We analyze the growth of dataset sizes used in machine learning for natural\nlanguage processing and computer vision, and extrapolate these using two\nmethods; using the historical growth rate and estimating the compute-optimal\ndataset size for future predicted compute budgets. We investigate the growth in\ndata usage by estimating the total stock of unlabeled data available on the\ninternet over the coming decades. Our analysis indicates that the stock of\nhigh-quality language data will be exhausted soon; likely before 2026. By\ncontrast, the stock of low-quality language data and image data will be\nexhausted only much later; between 2030 and 2050 (for low-quality language) and\nbetween 2030 and 2060 (for images). Our work suggests that the current trend of\never-growing ML models that rely on enormous datasets might slow down if data\nefficiency is not drastically improved or new sources of data become available.",
    "descriptor": "",
    "authors": [
      "Pablo Villalobos",
      "Jaime Sevilla",
      "Lennart Heim",
      "Tamay Besiroglu",
      "Marius Hobbhahn",
      "Anson Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.04325"
  },
  {
    "id": "arXiv:2211.04327",
    "title": "Synthesis of separation processes with reinforcement learning",
    "abstract": "This paper shows the implementation of reinforcement learning (RL) in\ncommercial flowsheet simulator software (Aspen Plus V12) for designing and\noptimising a distillation sequence. The aim of the SAC agent was to separate a\nhydrocarbon mixture in its individual components by utilising distillation.\nWhile doing so it tries to maximise the profit produced by the distillation\nsequence. All actions of the agent were set by the SAC agent in Python and\ncommunicated in Aspen Plus via an API. Here the distillation column was\nsimulated by use of the build-in RADFRAC column. With this a connection was\nestablished for data transfer between Python and Aspen and the agent succeeded\nto show learning behaviour, while increasing profit. Although results were\ngenerated, the use of Aspen was slow (190 hours) and Aspen was found unsuitable\nfor parallelisation. This makes that Aspen is incompatible for solving RL\nproblems. Code and thesis are available at https://github.com/lollcat/Aspen-RL",
    "descriptor": "",
    "authors": [
      "Stephan C.P.A. van Kalmthout",
      "Laurence I. Midgley",
      "Meik B. Franke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.04327"
  },
  {
    "id": "arXiv:2211.04331",
    "title": "Multi-Stage Based Feature Fusion of Multi-Modal Data for Human Activity  Recognition",
    "abstract": "To properly assist humans in their needs, human activity recognition (HAR)\nsystems need the ability to fuse information from multiple modalities. Our\nhypothesis is that multimodal sensors, visual and non-visual tend to provide\ncomplementary information, addressing the limitations of other modalities. In\nthis work, we propose a multi-modal framework that learns to effectively\ncombine features from RGB Video and IMU sensors, and show its robustness for\nMMAct and UTD-MHAD datasets. Our model is trained in two-stage, where in the\nfirst stage, each input encoder learns to effectively extract features, and in\nthe second stage, learns to combine these individual features. We show\nsignificant improvements of 22% and 11% compared to video only and IMU only\nsetup on UTD-MHAD dataset, and 20% and 12% on MMAct datasets. Through extensive\nexperimentation, we show the robustness of our model on zero shot setting, and\nlimited annotated data setting. We further compare with state-of-the-art\nmethods that use more input modalities and show that our method outperforms\nsignificantly on the more difficult MMact dataset, and performs comparably in\nUTD-MHAD dataset.",
    "descriptor": "",
    "authors": [
      "Hyeongju Choi",
      "Apoorva Beedu",
      "Harish Haresamudram",
      "Irfan Essa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04331"
  },
  {
    "id": "arXiv:2211.04337",
    "title": "Prompt-Based Metric Learning for Few-Shot NER",
    "abstract": "Few-shot named entity recognition (NER) targets generalizing to unseen labels\nand/or domains with few labeled examples. Existing metric learning methods\ncompute token-level similarities between query and support sets, but are not\nable to fully incorporate label semantics into modeling. To address this issue,\nwe propose a simple method to largely improve metric learning for NER: 1)\nmultiple prompt schemas are designed to enhance label semantics; 2) we propose\na novel architecture to effectively combine multiple prompt-based\nrepresentations. Empirically, our method achieves new state-of-the-art (SOTA)\nresults under 16 of the 18 considered settings, substantially outperforming the\nprevious SOTA by an average of 8.84% and a maximum of 34.51% in relative gains\nof micro F1. Our code is available at https://github.com/AChen-qaq/ProML.",
    "descriptor": "",
    "authors": [
      "Yanru Chen",
      "Yanan Zheng",
      "Zhilin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04337"
  },
  {
    "id": "arXiv:2211.04338",
    "title": "Extracting and Pre-Processing Event Logs",
    "abstract": "Event data is the basis for all process mining analysis. Most process mining\ntechniques assume their input to be an event log. However, event data is rarely\nrecorded in an event log format, but has to be extracted from raw data. Event\nlog extraction itself is an act of modeling as the analyst has to consciously\nchoose which features of the raw data are used for describing which behavior of\nwhich entities. Being aware of these choices and subtle but important\ndifferences in concepts such as trace, case, activity, event, table, and log is\ncrucial for mastering advanced process mining analyses.\nThis text provides fundamental concepts and formalizations and discusses\ndesign decisions in event log extraction from a raw event table and for event\nlog pre-processing. It is intended as study material for an advanced lecture in\na process mining course.",
    "descriptor": "\nComments: This text is intended as study material for an advanced lecture in a process mining course\n",
    "authors": [
      "Dirk Fahland"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.04338"
  },
  {
    "id": "arXiv:2211.04339",
    "title": "Adaptive Semantic Communications: Overfitting the Source and Channel for  Profit",
    "abstract": "Most semantic communication systems leverage deep learning models to provide\nend-to-end transmission performance surpassing the established source and\nchannel coding approaches. While, so far, research has mainly focused on\narchitecture and model improvements, but such a model trained over a full\ndataset and ergodic channel responses is unlikely to be optimal for every test\ninstance. Due to limitations on the model capacity and imperfect optimization\nand generalization, such learned models will be suboptimal especially when the\ntesting data distribution or channel response is different from that in the\ntraining phase, as is likely to be the case in practice. To tackle this, in\nthis paper, we propose a novel semantic communication paradigm by leveraging\nthe deep learning model's overfitting property. Our model can for instance be\nupdated after deployment, which can further lead to substantial gains in terms\nof the transmission rate-distortion (RD) performance. This new system is named\nadaptive semantic communication (ASC). In our ASC system, the ingredients of\nwireless transmitted stream include both the semantic representations of source\ndata and the adapted decoder model parameters. Specifically, we take the\noverfitting concept to the extreme, proposing a series of ingenious methods to\nadapt the semantic codec or representations to an individual data or channel\nstate instance. The whole ASC system design is formulated as an optimization\nproblem whose goal is to minimize the loss function that is a tripartite\ntradeoff among the data rate, model rate, and distortion terms. The experiments\n(including user study) verify the effectiveness and efficiency of our ASC\nsystem. Notably, the substantial gain of our overfitted coding paradigm can\ncatalyze semantic communication upgrading to a new era.",
    "descriptor": "",
    "authors": [
      "Jincheng Dai",
      "Sixian Wang",
      "Ke Yang",
      "Kailin Tan",
      "Xiaoqi Qin",
      "Zhongwei Si",
      "Kai Niu",
      "Ping Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04339"
  },
  {
    "id": "arXiv:2211.04340",
    "title": "Calibrated Perception Uncertainty Across Objects and Regions in  Bird's-Eye-View",
    "abstract": "In driving scenarios with poor visibility or occlusions, it is important that\nthe autonomous vehicle would take into account all the uncertainties when\nmaking driving decisions, including choice of a safe speed. The grid-based\nperception outputs, such as occupancy grids, and object-based outputs, such as\nlists of detected objects, must then be accompanied by well-calibrated\nuncertainty estimates. We highlight limitations in the state-of-the-art and\npropose a more complete set of uncertainties to be reported, particularly\nincluding undetected-object-ahead probabilities. We suggest a novel way to get\nthese probabilistic outputs from bird's-eye-view probabilistic semantic\nsegmentation, in the example of the FIERY model. We demonstrate that the\nobtained probabilities are not calibrated out-of-the-box and propose methods to\nachieve well-calibrated uncertainties.",
    "descriptor": "",
    "authors": [
      "Markus K\u00e4ngsepp",
      "Meelis Kull"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04340"
  },
  {
    "id": "arXiv:2211.04344",
    "title": "FLock: Defending Malicious Behaviors in Federated Learning with  Blockchain",
    "abstract": "Federated learning (FL) is a promising way to allow multiple data owners\n(clients) to collaboratively train machine learning models without compromising\ndata privacy. Yet, existing FL solutions usually rely on a centralized\naggregator for model weight aggregation, while assuming clients are honest.\nEven if data privacy can still be preserved, the problem of single-point\nfailure and data poisoning attack from malicious clients remains unresolved. To\ntackle this challenge, we propose to use distributed ledger technology (DLT) to\nachieve FLock, a secure and reliable decentralized Federated Learning system\nbuilt on blockchain. To guarantee model quality, we design a novel peer-to-peer\n(P2P) review and reward/slash mechanism to detect and deter malicious clients,\npowered by on-chain smart contracts. The reward/slash mechanism, in addition,\nserves as incentives for participants to honestly upload and review model\nparameters in the FLock system. FLock thus improves the performance and the\nrobustness of FL systems in a fully P2P manner.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 Workshop\n",
    "authors": [
      "Nanqing Dong",
      "Jiahao Sun",
      "Zhipeng Wang",
      "Shuoying Zhang",
      "Shuhao Zheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04344"
  },
  {
    "id": "arXiv:2211.04347",
    "title": "When & How to Transfer with Transfer Learning",
    "abstract": "In deep learning, transfer learning (TL) has become the de facto approach\nwhen dealing with image related tasks. Visual features learnt for one task have\nbeen shown to be reusable for other tasks, improving performance significantly.\nBy reusing deep representations, TL enables the use of deep models in domains\nwith limited data availability, limited computational resources and/or limited\naccess to human experts. Domains which include the vast majority of real-life\napplications. This paper conducts an experimental evaluation of TL, exploring\nits trade-offs with respect to performance, environmental footprint, human\nhours and computational requirements. Results highlight the cases were a cheap\nfeature extraction approach is preferable, and the situations where an\nexpensive fine-tuning effort may be worth the added cost. Finally, a set of\nguidelines on the use of TL are proposed.",
    "descriptor": "",
    "authors": [
      "Adrian Tormos",
      "Dario Garcia-Gasulla",
      "Victor Gimenez-Abalos",
      "Sergio Alvarez-Napagao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04347"
  },
  {
    "id": "arXiv:2211.04351",
    "title": "The ERA Theorem for Safe Memory Reclamation",
    "abstract": "Safe memory reclamation (SMR) schemes for concurrent data structures offer\ntrade-offs between three desirable properties: ease of integration, robustness,\nand applicability. In this paper we rigorously define SMR and these three\nproperties, and we present the ERA theorem, asserting that any SMR scheme can\nonly provide at most two of the three properties.",
    "descriptor": "",
    "authors": [
      "Gali Sheffi",
      "Erez Petrank"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.04351"
  },
  {
    "id": "arXiv:2211.04361",
    "title": "Iris: Automatic Generation of Efficient Data Layouts for High Bandwidth  Utilization",
    "abstract": "Optimizing data movements is becoming one of the biggest challenges in\nheterogeneous computing to cope with data deluge and, consequently, big data\napplications. When creating specialized accelerators, modern high-level\nsynthesis (HLS) tools are increasingly efficient in optimizing the\ncomputational aspects, but data transfers have not been adequately improved. To\ncombat this, novel architectures such as High-Bandwidth Memory with wider data\nbusses have been developed so that more data can be transferred in parallel.\nDesigners must tailor their hardware/software interfaces to fully exploit the\navailable bandwidth. HLS tools can automate this process, but the designer must\nfollow strict coding-style rules. If the bus width is not evenly divisible by\nthe data width (e.g., when using custom-precision data types) or if the arrays\nare not power-of-two length, the HLS-generated accelerator will likely not\nfully utilize the available bandwidth, demanding even more manual effort from\nthe designer. We propose a methodology to automatically find and implement a\ndata layout that, when streamed between memory and an accelerator, uses a\nhigher percentage of the available bandwidth than a naive or HLS-optimized\ndesign. We borrow concepts from multiprocessor scheduling to achieve such high\nefficiency.",
    "descriptor": "\nComments: Accepted for presentation at ASPDAC'23\n",
    "authors": [
      "Stephanie Soldavini",
      "Donatella Sciuto",
      "Christian Pilato"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.04361"
  },
  {
    "id": "arXiv:2211.04362",
    "title": "Hyperparameter optimization in deep multi-target prediction",
    "abstract": "As a result of the ever increasing complexity of configuring and fine-tuning\nmachine learning models, the field of automated machine learning (AutoML) has\nemerged over the past decade. However, software implementations like Auto-WEKA\nand Auto-sklearn typically focus on classical machine learning (ML) tasks such\nas classification and regression. Our work can be seen as the first attempt at\noffering a single AutoML framework for most problem settings that fall under\nthe umbrella of multi-target prediction, which includes popular ML settings\nsuch as multi-label classification, multivariate regression, multi-task\nlearning, dyadic prediction, matrix completion, and zero-shot learning.\nAutomated problem selection and model configuration are achieved by extending\nDeepMTP, a general deep learning framework for MTP problem settings, with\npopular hyperparameter optimization (HPO) methods. Our extensive benchmarking\nacross different datasets and MTP problem settings identifies cases where\nspecific HPO methods outperform others.",
    "descriptor": "\nComments: 17 pages, 4 figures, 1 table\n",
    "authors": [
      "Dimitrios Iliadis",
      "Marcel Wever",
      "Bernard De Baets",
      "Willem Waegeman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04362"
  },
  {
    "id": "arXiv:2211.04364",
    "title": "NaturalAdversaries: Can Naturalistic Adversaries Be as Effective as  Artificial Adversaries?",
    "abstract": "While a substantial body of prior work has explored adversarial example\ngeneration for natural language understanding tasks, these examples are often\nunrealistic and diverge from the real-world data distributions. In this work,\nwe introduce a two-stage adversarial example generation framework\n(NaturalAdversaries), for designing adversaries that are effective at fooling a\ngiven classifier and demonstrate natural-looking failure cases that could\nplausibly occur during in-the-wild deployment of the models.\nAt the first stage a token attribution method is used to summarize a given\nclassifier's behaviour as a function of the key tokens in the input. In the\nsecond stage a generative model is conditioned on the key tokens from the first\nstage. NaturalAdversaries is adaptable to both black-box and white-box\nadversarial attacks based on the level of access to the model parameters. Our\nresults indicate these adversaries generalize across domains, and offer\ninsights for future research on improving robustness of neural text\nclassification models.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Saadia Gabriel",
      "Hamid Palangi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04364"
  },
  {
    "id": "arXiv:2211.04367",
    "title": "Much Easier Said Than Done: Falsifying the Causal Relevance of Linear  Decoding Methods",
    "abstract": "Linear classifier probes are frequently utilized to better understand how\nneural networks function. Researchers have approached the problem of\ndetermining unit importance in neural networks by probing their learned,\ninternal representations. Linear classifier probes identify highly selective\nunits as the most important for network function. Whether or not a network\nactually relies on high selectivity units can be tested by removing them from\nthe network using ablation. Surprisingly, when highly selective units are\nablated they only produce small performance deficits, and even then only in\nsome cases. In spite of the absence of ablation effects for selective neurons,\nlinear decoding methods can be effectively used to interpret network function,\nleaving their effectiveness a mystery. To falsify the exclusive role of\nselectivity in network function and resolve this contradiction, we\nsystematically ablate groups of units in subregions of activation space. Here,\nwe find a weak relationship between neurons identified by probes and those\nidentified by ablation. More specifically, we find that an interaction between\nselectivity and the average activity of the unit better predicts ablation\nperformance deficits for groups of units in AlexNet, VGG16, MobileNetV2, and\nResNet101. Linear decoders are likely somewhat effective because they overlap\nwith those units that are causally important for network function.\nInterpretability methods could be improved by focusing on causally important\nunits.",
    "descriptor": "\nComments: 6 pages, 3 figures, to be published in I Can't Believe It's Note Better Workshop at NeurIPS 2022\n",
    "authors": [
      "Lucas Hayne",
      "Abhijit Suresh",
      "Hunar Jain",
      "Rahul Kumar",
      "R. McKell Carter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04367"
  },
  {
    "id": "arXiv:2211.04368",
    "title": "A Multimodal Approach for Dementia Detection from Spontaneous Speech  with Tensor Fusion Layer",
    "abstract": "Alzheimer's disease (AD) is a progressive neurological disorder, meaning that\nthe symptoms develop gradually throughout the years. It is also the main cause\nof dementia, which affects memory, thinking skills, and mental abilities.\nNowadays, researchers have moved their interest towards AD detection from\nspontaneous speech, since it constitutes a time-effective procedure. However,\nexisting state-of-the-art works proposing multimodal approaches do not take\ninto consideration the inter- and intra-modal interactions and propose early\nand late fusion approaches. To tackle these limitations, we propose deep neural\nnetworks, which can be trained in an end-to-end trainable way and capture the\ninter- and intra-modal interactions. Firstly, each audio file is converted to\nan image consisting of three channels, i.e., log-Mel spectrogram, delta, and\ndelta-delta. Next, each transcript is passed through a BERT model followed by a\ngated self-attention layer. Similarly, each image is passed through a Swin\nTransformer followed by an independent gated self-attention layer. Acoustic\nfeatures are extracted also from each audio file. Finally, the representation\nvectors from the different modalities are fed to a tensor fusion layer for\ncapturing the inter-modal interactions. Extensive experiments conducted on the\nADReSS Challenge dataset indicate that our introduced approaches obtain\nvaluable advantages over existing research initiatives reaching Accuracy and\nF1-score up to 86.25% and 85.48% respectively.",
    "descriptor": "\nComments: 2022 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI) - Oral Presentation\n",
    "authors": [
      "Loukas Ilias",
      "Dimitris Askounis",
      "John Psarras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04368"
  },
  {
    "id": "arXiv:2211.04369",
    "title": "Accelerating Time Series Analysis via Processing using Non-Volatile  Memories",
    "abstract": "Time Series Analysis (TSA) is a critical workload for consumer-facing\ndevices. Accelerating TSA is vital for many domains as it enables the\nextraction of valuable information and predict future events. The\nstate-of-the-art algorithm in TSA is the subsequence Dynamic Time Warping\n(sDTW) algorithm. However, sDTW's computation complexity increases\nquadratically with the time series' length, resulting in two performance\nimplications. First, the amount of data parallelism available is significantly\nhigher than the small number of processing units enabled by commodity systems\n(e.g., CPUs). Second, sDTW is bottlenecked by memory because it 1) has low\narithmetic intensity and 2) incurs a large memory footprint. To tackle these\ntwo challenges, we leverage Processing-using-Memory (PuM) by performing in-situ\ncomputation where data resides, using the memory cells. PuM provides a\npromising solution to alleviate data movement bottlenecks and exposes immense\nparallelism.\nIn this work, we present MATSA, the first MRAM-based Accelerator for Time\nSeries Analysis. The key idea is to exploit magneto-resistive memory crossbars\nto enable energy-efficient and fast time series computation in memory. MATSA\nprovides the following key benefits: 1) it leverages high levels of parallelism\nin the memory substrate by exploiting column-wise arithmetic operations, and 2)\nit significantly reduces the data movement costs performing computation using\nthe memory cells. We evaluate three versions of MATSA to match the requirements\nof different environments (e.g., embedded, desktop, or HPC computing) based on\nMRAM technology trends. We perform a design space exploration and demonstrate\nthat our HPC version of MATSA can improve performance by 7.35x/6.15x/6.31x and\nenergy efficiency by 11.29x/4.21x/2.65x over server CPU, GPU and PNM\narchitectures, respectively.",
    "descriptor": "",
    "authors": [
      "Ivan Fernandez",
      "Aditya Manglik",
      "Christina Giannoula",
      "Ricardo Quislant",
      "Nika Mansouri Ghiasi",
      "Juan G\u00f3mez-Luna",
      "Eladio Gutierrez",
      "Oscar Plata",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.04369"
  },
  {
    "id": "arXiv:2211.04370",
    "title": "Estimating Treatment Effects using Neurosymbolic Program Synthesis",
    "abstract": "Estimating treatment effects from observational data is a central problem in\ncausal inference. Methods to solve this problem exploit inductive biases and\nheuristics from causal inference to design multi-head neural network\narchitectures and regularizers. In this work, we propose to use neurosymbolic\nprogram synthesis, a data-efficient, and interpretable technique, to solve the\ntreatment effect estimation problem. We theoretically show that neurosymbolic\nprogramming can solve the treatment effect estimation problem. By designing a\nDomain Specific Language (DSL) for treatment effect estimation problem based on\nthe inductive biases used in literature, we argue that neurosymbolic\nprogramming is a better alternative to treatment effect estimation than\ntraditional methods. Our empirical study reveals that our method, which\nimplicitly encodes inductive biases in a DSL, achieves better performance on\nbenchmark datasets than the state-of-the-art methods.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Abbavaram Gowtham Reddy",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.04370"
  },
  {
    "id": "arXiv:2211.04385",
    "title": "Why we couldn't prove SETH hardness of the Closest Vector Problem for  even norms, and of the Subset Sum Problem!",
    "abstract": "Recent work [BGS17,ABGS19] has shown SETH hardness of some constant factor\napproximate CVP in the $\\ell_p$ norm for any $p$ that is not an even integer.\nThis result was shown by giving a Karp reduction from $k$-SAT on $n$ variables\nto approximate CVP on a lattice of rank $n$. In this work, we show a barrier\ntowards proving a similar result for CVP in the $\\ell_p$ norm where $p$ is an\neven integer. We show that for any $c, c'>0$, if for every $k > 0$, there\nexists an efficient reduction that maps a $k$-SAT instance on $n$ variables to\na $(1+exp(-n^c)))$-CVP instance for a lattice of rank at most $n^{c'}$ in the\nEuclidean norm, then $\\mathsf{coNP} \\subset \\mathsf{NP/Poly}$. We prove a\nsimilar result for $(1+exp(-n^c)))$-CVP for all even norms under a mild\nadditional promise that the ratio of the distance of the target from the\nlattice and the shortest non-zero vector in the lattice is bounded by\n$exp(n^{O(1)})$.\nFurthermore, we show that for any $c,c' > 0$, and any even integer $p$, if\nfor every $k > 0$, there exists an efficient reduction that maps a $k$-SAT\ninstance on $n$ variables to a $(1+exp(-n^c)))$-$SVP_p$ instance for a lattice\nof rank at most $n^{c'}$, then $\\mathsf{coNP} \\subset \\mathsf{NP/Poly}$. The\nresult for SVP does not require any additional promise.\nWhile prior results have indicated that lattice problems in the $\\ell_2$ norm\n(Euclidean norm) are easier than lattice problems in other norms, this is the\nfirst result that shows a separation between these problems.\nWe achieve this by using a result by Dell and van Melkebeek [JACM, 2014] on\nthe impossibility of the existence of a reduction that compresses an arbitrary\n$k$-SAT instance into a string of length $\\mathcal{O}(n^{k-\\epsilon})$ for any\n$\\epsilon>0$. In addition to CVP, we also show that the same result holds for\nthe Subset-Sum problem using similar techniques.",
    "descriptor": "\nComments: 32 pages, 3 figures\n",
    "authors": [
      "Divesh Aggarwal",
      "Rajendra Kumar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04385"
  },
  {
    "id": "arXiv:2211.04391",
    "title": "EVs and ERCOT: Future Adoption Scenarios and Grid Implications",
    "abstract": "Electric vehicles (EVs) are becoming more commonplace in Texas, mainly due to\ntheir increasing attractiveness to consumers and pushes from the state's\ngoverning bodies to incentivize further adoption. Meanwhile, service from\nTexas's electric grid, ERCOT, has been seeing increases in power demand due to\na growing population, increased air conditioning use, and pushes for\nelectrification across other industries. The electrification of vehicles will\nonly add to this demand increase. This paper focuses on evaluating different EV\nadoption, charging management, and policy scenarios, and how they will be\nexpected to impact ERCOT, particularly with respect to peak demand increases. A\nstrong increase in the peak demand can lead to challenges to keep the\nelectrical grid's reliability, making it an important consideration for\nelectrification in any sector. The anticipated impacts of EV adoption on peak\ndemand are quantified using ERCOT's data on past generation and planned\ninstallations, the approximated effectiveness of EV incentives, EV charging\nprofiles, and travel patterns. The results showcase the fact that the\nachievement of ambitious EV market share goals will be manageable on a\nstatewide level regarding electricity supply into 2030, but will eventually\nnecessitate ambitious charging management strategies in order to limit the EV\nfleet's potentially heavy impact on peak demand looking forward into 2050 and\nbeyond.",
    "descriptor": "\nComments: 5 pages, 2 figures, 3 tables, Submitted to IEEE for Power & Energy Society 2023 General Meeting,\n",
    "authors": [
      "Kelsey Nelson",
      "Javad Mohammadi",
      "Pedro Moura"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04391"
  },
  {
    "id": "arXiv:2211.04393",
    "title": "Normalization Perturbation: A Simple Domain Generalization Method for  Real-World Domain Shifts",
    "abstract": "Improving model's generalizability against domain shifts is crucial,\nespecially for safety-critical applications such as autonomous driving.\nReal-world domain styles can vary substantially due to environment changes and\nsensor noises, but deep models only know the training domain style. Such domain\nstyle gap impedes model generalization on diverse real-world domains. Our\nproposed Normalization Perturbation (NP) can effectively overcome this domain\nstyle overfitting problem. We observe that this problem is mainly caused by the\nbiased distribution of low-level features learned in shallow CNN layers. Thus,\nwe propose to perturb the channel statistics of source domain features to\nsynthesize various latent styles, so that the trained deep model can perceive\ndiverse potential domains and generalizes well even without observations of\ntarget domain data in training. We further explore the style-sensitive channels\nfor effective style synthesis. Normalization Perturbation only relies on a\nsingle source domain and is surprisingly effective and extremely easy to\nimplement. Extensive experiments verify the effectiveness of our method for\ngeneralizing models under real-world domain shifts.",
    "descriptor": "",
    "authors": [
      "Qi Fan",
      "Mattia Segu",
      "Yu-Wing Tai",
      "Fisher Yu",
      "Chi-Keung Tang",
      "Bernt Schiele",
      "Dengxin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04393"
  },
  {
    "id": "arXiv:2211.04395",
    "title": "Expressing linear equality constraints in feedforward neural networks",
    "abstract": "We seek to impose linear, equality constraints in feedforward neural\nnetworks. As top layer predictors are usually nonlinear, this is a difficult\ntask if we seek to deploy standard convex optimization methods and strong\nduality. To overcome this, we introduce a new saddle-point Lagrangian with\nauxiliary predictor variables on which constraints are imposed. Elimination of\nthe auxiliary variables leads to a dual minimization problem on the Lagrange\nmultipliers introduced to satisfy the linear constraints. This minimization\nproblem is combined with the standard learning problem on the weight matrices.\nFrom this theoretical line of development, we obtain the surprising\ninterpretation of Lagrange parameters as additional, penultimate layer hidden\nunits with fixed weights stemming from the constraints. Consequently, standard\nminimization approaches can be used despite the inclusion of Lagrange\nparameters -- a very satisfying, albeit unexpected, discovery. Examples ranging\nfrom multi-label classification to constrained autoencoders are envisaged in\nthe future.",
    "descriptor": "",
    "authors": [
      "Anand Rangarajan",
      "Pan He",
      "Jaemoon Lee",
      "Tania Banerjee",
      "Sanjay Ranka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.04395"
  },
  {
    "id": "arXiv:2211.04402",
    "title": "Summation Problem Revisited -- More Robust Computation",
    "abstract": "Numerical data processing is a key task across different fields of computer\ntechnology use. However, even simple summation of values is not precise due to\nthe floating point representation use. This paper presents a practical\nalgorithm for summation of values convenient for medium and large data sets.\nThe proposed algorithm is simple, easy to implement. Its computational\ncomplexity is O(N) in the contrary of the Exact Sign Summation Algorithm (ESSA)\napproach with O(N^2) run-time complexity. The proposed algorithm is especially\nconvenient for cases when exponent data differ significantly and many small\nvalues are summed with higher values",
    "descriptor": "\nComments: 9 pages, 3 Figs, 3 Tabs. Presented at Recent Advances in Computer Science Conf, 2013\n",
    "authors": [
      "Vaclav Skala"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04402"
  },
  {
    "id": "arXiv:2211.04404",
    "title": "An Energy-Based Lengthscale for Reduced Order Models of Turbulent Flows",
    "abstract": "In this paper, we propose a novel reduced order model (ROM) lengthscale that\nis constructed by using energy distribution arguments. The new energy-based ROM\nlengthscale is fundamentally different from the current ROM lengthscales, which\nare built by using dimensional arguments. To assess the novel, energy-based ROM\nlengthscale, we compare it with a standard, dimensionality-based ROM\nlengthscale in two fundamentally different types of models: (i) the\nmixing-length ROM (ML-ROM), which is a ROM closure model; and (ii) the\nevolve-filter-relax ROM (EFR-ROM), which is a regularized ROM. We test the four\ncombinations (i.e., ML-ROM and EFR-ROM equipped with the energy-based and\ndimensionality-based lengthscales) in the numerical simulation of the turbulent\nchannel flow at $Re_{\\tau} = 395$. The numerical investigation yields the\nfollowing conclusions: (i) The new energy-based ROM lengthscale is\nsignificantly (almost two orders of magnitude) larger than the standard\ndimensionality-based ROM lengthscale. As a result, the energy-based lengthscale\nyields more stable ML-ROMs and EFR-ROMs than the dimensionality-based\nlengthscale. (ii) The energy-based lengthscale displays the correct asymptotic\nbehavior with respect to the ROM dimension, whereas the dimensionality-based\nlengthscale does not. (iii) The energy-based lengthscale yields ML-ROMs and\n(when significant filtering is effected) EFR-ROMs whose parameters are less\nsensitive (i.e., more robust) than the parameters of the ML-ROMs and EFR-ROMs\nbased on the dimensionality-based lengthscale. The novel energy-based\nlengthscale could enable the development of better scale-aware ROM strategies\nfor flow-specific applications and is expected to have long term applications\nin nuclear reactor thermal-hydraulics.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.02254\n",
    "authors": [
      "Changhong Mou",
      "Elia Merzari",
      "Omer San",
      "Traian Iliescu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.04404"
  },
  {
    "id": "arXiv:2211.04411",
    "title": "Motif-guided Time Series Counterfactual Explanations",
    "abstract": "With the rising need of interpretable machine learning methods, there is a\nnecessity for a rise in human effort to provide diverse explanations of the\ninfluencing factors of the model decisions. To improve the trust and\ntransparency of AI-based systems, the EXplainable Artificial Intelligence (XAI)\nfield has emerged. The XAI paradigm is bifurcated into two main categories:\nfeature attribution and counterfactual explanation methods. While feature\nattribution methods are based on explaining the reason behind a model decision,\ncounterfactual explanation methods discover the smallest input changes that\nwill result in a different decision. In this paper, we aim at building trust\nand transparency in time series models by using motifs to generate\ncounterfactual explanations. We propose Motif-Guided Counterfactual Explanation\n(MG-CF), a novel model that generates intuitive post-hoc counterfactual\nexplanations that make full use of important motifs to provide interpretive\ninformation in decision-making processes. To the best of our knowledge, this is\nthe first effort that leverages motifs to guide the counterfactual explanation\ngeneration. We validated our model using five real-world time-series datasets\nfrom the UCR repository. Our experimental results show the superiority of MG-CF\nin balancing all the desirable counterfactual explanations properties in\ncomparison with other competing state-of-the-art baselines.",
    "descriptor": "\nComments: 13 pages, accepted at 2-nd Workshop on Explainable and Ethical AI - ICPR 2022\n",
    "authors": [
      "Peiyu Li",
      "Soukaina Filali Boubrahimi",
      "Shah Muhammad Hamd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04411"
  },
  {
    "id": "arXiv:2211.04417",
    "title": "nBIIG: A Neural BI Insights Generation System for Table Reporting",
    "abstract": "We present nBIIG, a neural Business Intelligence (BI) Insights Generation\nsystem. Given a table, our system applies various analyses to create\ncorresponding RDF representations, and then uses a neural model to generate\nfluent textual insights out of these representations. The generated insights\ncan be used by an analyst, via a human-in-the-loop paradigm, to enhance the\ntask of creating compelling table reports. The underlying generative neural\nmodel is trained over large and carefully distilled data, curated from multiple\nBI domains. Thus, the system can generate faithful and fluent insights over\nopen-domain tables, making it practical and useful.",
    "descriptor": "\nComments: Accepted to AAAI-23\n",
    "authors": [
      "Yotam Perlitz",
      "Dafna Sheinwald",
      "Noam Slonim",
      "Michal Shmueli-Scheuer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04417"
  },
  {
    "id": "arXiv:2211.04427",
    "title": "Word Order Matters when you Increase Masking",
    "abstract": "Word order, an essential property of natural languages, is injected in\nTransformer-based neural language models using position encoding. However,\nrecent experiments have shown that explicit position encoding is not always\nuseful, since some models without such feature managed to achieve state-of-the\nart performance on some tasks. To understand better this phenomenon, we examine\nthe effect of removing position encodings on the pre-training objective itself\n(i.e., masked language modelling), to test whether models can reconstruct\nposition information from co-occurrences alone. We do so by controlling the\namount of masked tokens in the input sentence, as a proxy to affect the\nimportance of position information for the task. We find that the necessity of\nposition information increases with the amount of masking, and that masked\nlanguage models without position encodings are not able to reconstruct this\ninformation on the task. These findings point towards a direct relationship\nbetween the amount of masking and the ability of Transformers to capture\norder-sensitive aspects of language using position encoding.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 (main conference)\n",
    "authors": [
      "Karim Lasri",
      "Alessandro Lenci",
      "Thierry Poibeau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.04427"
  },
  {
    "id": "arXiv:2211.04428",
    "title": "Review of coreference resolution in English and Persian",
    "abstract": "Coreference resolution (CR) is one of the most challenging areas of natural\nlanguage processing. This task seeks to identify all textual references to the\nsame real-world entity. Research in this field is divided into coreference\nresolution and anaphora resolution. Due to its application in textual\ncomprehension and its utility in other tasks such as information extraction\nsystems, document summarization, and machine translation, this field has\nattracted considerable interest. Consequently, it has a significant effect on\nthe quality of these systems. This article reviews the existing corpora and\nevaluation metrics in this field. Then, an overview of the coreference\nalgorithms, from rule-based methods to the latest deep learning techniques, is\nprovided. Finally, coreference resolution and pronoun resolution systems in\nPersian are investigated.",
    "descriptor": "\nComments: 44 pages, 11 figures, 5 tables\n",
    "authors": [
      "Hassan Haji Mohammadi",
      "Alireza Talebpour",
      "Ahmad Mahmoudi Aznaveh",
      "Samaneh Yazdani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04428"
  },
  {
    "id": "arXiv:2211.04429",
    "title": "A half-century of international research collaboration dynamism:  Congregate or disperse?",
    "abstract": "The past decades have witnessed a dramatic change in researchers'\ncollaboration mode across borders. In addition to purely academia-driven\ncollaborations, various state-led initiatives have also been developed and are\nunderway, reflecting the rapidly changing geopolitical situation of the\ncontemporary world. In such multilayered cooperative and competitive\nrelationships among countries, it is of great interest to leaders in academia\nand the policy arena to grasp the full scope of international research\ncollaboration and their country's place within it, along with its change over\ntime. However, evidence for such world-scale dynamism is scarce to date. This\npaper provides unique evidence of how international collaboration clusters have\nformed and evolved over the past half-century for a broad set of scientific\npublications. Our analyses are based on data retrieved from OpenAlex, a\nlarge-scale Open Bibliometrics platform launched in 2022. The science and\ntechnology areas of focus include Quantum Science, Artificial Intelligence,\nBiotechnology and others, totalling 15. We first review the top-tier countries'\nglobal presence change for each discipline, measured by publication volumes and\ninternational collaboration rates. Notably, the US and China are shown to have\nrapidly moved closer together for decades but have started moving apart after\n2019. Subsequently, we analyse and visualise the international collaboration\nclusters for each discipline and period based on a hierarchical clustering\nmethod. Finally, we provide global-scale quantitative evidence for a 'Shrinking\nWorld' of the past half-century's research collaboration. These results provide\nvaluable insights into the big picture of past, present and future\ninternational collaboration.",
    "descriptor": "\nComments: 2+19 pages (5 figures) for Main Text; 21 pages (7 figures, 1 table) for Supplementary Materials\n",
    "authors": [
      "Keisuke Okamura"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.04429"
  },
  {
    "id": "arXiv:2211.04430",
    "title": "Bounded Guaranteed Algorithms for Concave Impurity Minimization Via  Maximum Likelihood",
    "abstract": "Partitioning algorithms play a key role in many scientific and engineering\ndisciplines. A partitioning algorithm divides a set into a number of disjoint\nsubsets or partitions. Often, the quality of the resulted partitions is\nmeasured by the amount of impurity in each partition, the smaller impurity the\nhigher quality of the partitions. In general, for a given impurity measure\nspecified by a function of the partitions, finding the minimum impurity\npartitions is an NP-hard problem. Let $M$ be the number of $N$-dimensional\nelements in a set and $K$ be the number of desired partitions, then an\nexhaustive search over all the possible partitions to find a minimum partition\nhas the complexity of $O(K^M)$ which quickly becomes impractical for many\napplications with modest values of $K$ and $M$. Thus, many approximate\nalgorithms with polynomial time complexity have been proposed, but few provide\nbounded guarantee. In this paper, an upper bound and a lower bound for a class\nof impurity functions are constructed. Based on these bounds, we propose a\nlow-complexity partitioning algorithm with bounded guarantee based on the\nmaximum likelihood principle. The theoretical analyses on the bounded guarantee\nof the algorithms are given for two well-known impurity functions Gini index\nand entropy. When $K \\geq N$, the proposed algorithm achieves state-of-the-art\nresults in terms of lowest approximations and polynomial time complexity\n$O(NM)$. In addition, a heuristic greedy-merge algorithm having the time\ncomplexity of $O((N-K)N^2+NM)$ is proposed for $K<N$. Although the greedy-merge\nalgorithm does not provide a bounded guarantee, its performance is comparable\nto that of the state-of-the-art methods. Our results also generalize some\nwell-known information-theoretic bounds such as Fano's inequality and\nBoyd-Chiang's bound.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Thuan Nguyen",
      "Hoang Le",
      "Thinh Nguyen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04430"
  },
  {
    "id": "arXiv:2211.04433",
    "title": "A study on the ephemeral nature of knowledge shared within multiagent  systems",
    "abstract": "Achieving knowledge sharing within an artificial swarm system could lead to\nsignificant development in autonomous multiagent and robotic systems research\nand realize collective intelligence. However, this is difficult to achieve\nsince there is no generic framework to transfer skills between agents other\nthan a query-response-based approach. Moreover, natural living systems have a\n\"forgetfulness\" property for everything they learn. Analyzing such ephemeral\nnature (temporal memory properties of new knowledge gained) in artificial\nsystems has never been studied in the literature. We propose a behavior\ntree-based framework to realize a query-response mechanism for transferring\nskills encoded as the condition-action control sub-flow of that portion of the\nknowledge between agents to fill this gap. We simulate a multiagent group with\ndifferent initial knowledge on a foraging mission. While performing basic\noperations, each robot queries other robots to respond to an unknown condition.\nThe responding robot shares the control actions by sharing a portion of the\nbehavior tree that addresses the queries. Specifically, we investigate the\nephemeral nature of the new knowledge gained through such a framework, where\nthe knowledge gained by the agent is either limited due to memory or is\nforgotten over time. Our investigations show that knowledge grows\nproportionally with the duration of remembrance, which is trivial. However, we\nfound minimal impact on knowledge growth due to memory. We compare these cases\nagainst a baseline that involved full knowledge pre-coded on all agents. We\nfound that knowledge-sharing strived to match the baseline condition by sharing\nand achieving knowledge growth as a collective system.",
    "descriptor": "\nComments: In Proceedings of the Fifth International Symposium on Swarm Behavior and Bio-Inspired Robotics 2022 (SWARM 5th 2022)\n",
    "authors": [
      "Sanjay Sarma Oruganti Venkata",
      "Ramviyas Parasuraman",
      "Ramana Pidaparti"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04433"
  },
  {
    "id": "arXiv:2211.04439",
    "title": "Sampling from convex sets with a cold start using multiscale  decompositions",
    "abstract": "A standard approach to sample approximately uniformly from a convex body\n$K\\subseteq\\mathbb{R}^n$ is to run a random walk within $K$. The requirement is\nthat from a suitable initial distribution, the distribution of the walk comes\nclose to the uniform distribution $\\pi_K$ on $K$ after a number of steps\npolynomial in $n$ and the aspect ratio $R/r$ (here, $K$ is assumed to contain a\nball of radius $r$ and to be contained in a ball of radius $R$).\nProofs of rapid mixing of such walks often require the probability density\n$\\eta_0$ of the initial distribution with respect to $\\pi_K$ to be at most\n$\\mathrm{poly}(n)$: this is called a \"warm start\". Achieving a warm start often\nrequires non-trivial pre-processing before starting the random walk. This\nmotivates proving rapid mixing from a \"cold start\", wherein $\\eta_0$ can be as\nhigh as $\\exp(\\mathrm{poly}(n))$. Unlike warm starts, a cold start is usually\ntrivial to achieve. However, a random walks need not mix rapidly from a cold\nstart: an example being the well-known \"ball walk\". On the other hand, Lov\\'asz\nand Vempala proved that the \"hit-and-run\" random walk mixes rapidly from a cold\nstart. For the related coordinate hit-and-run (CHR) walk, which has been found\nto be promising in computational experiments, rapid mixing from a warm start\nwas proved only recently but the question of rapid mixing from a cold start\nremained open.\nWe construct a family of random walks inspired by classical decompositions of\nsubsets of $\\mathbb{R}^n$ into countably many axis-aligned dyadic cubes. We\nshow that even with a cold start, the mixing times of these walks are bounded\nby a polynomial in $n$ and the aspect ratio. Our main technical ingredient is\nan isoperimetric inequality for $K$ for a metric that magnifies distances\nbetween points close to the boundary of $K$. As a corollary, we show that the\nCHR walk also mixes rapidly from a cold start.",
    "descriptor": "",
    "authors": [
      "Hariharan Narayanan",
      "Amit Rajaraman",
      "Piyush Srivastava"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.04439"
  },
  {
    "id": "arXiv:2211.04442",
    "title": "Algorithmic Bias in Machine Learning Based Delirium Prediction",
    "abstract": "Although prediction models for delirium, a commonly occurring condition\nduring general hospitalization or post-surgery, have not gained huge\npopularity, their algorithmic bias evaluation is crucial due to the existing\nassociation between social determinants of health and delirium risk. In this\ncontext, using MIMIC-III and another academic hospital dataset, we present some\ninitial experimental evidence showing how sociodemographic features such as sex\nand race can impact the model performance across subgroups. With this work, our\nintent is to initiate a discussion about the intersectionality effects of old\nage, race and socioeconomic factors on the early-stage detection and prevention\nof delirium using ML.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 14 pages\n",
    "authors": [
      "Sandhya Tripathi",
      "Bradley A Fritz",
      "Michael S Avidan",
      "Yixin Chen",
      "Christopher R King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04442"
  },
  {
    "id": "arXiv:2211.04444",
    "title": "A Local Search-Based Approach for Set Covering",
    "abstract": "In the Set Cover problem, we are given a set system with each set having a\nweight, and we want to find a collection of sets that cover the universe,\nwhilst having low total weight. There are several approaches known (based on\ngreedy approaches, relax-and-round, and dual-fitting) that achieve a $H_k\n\\approx \\ln k + O(1)$ approximation for this problem, where the size of each\nset is bounded by $k$. Moreover, getting a $\\ln k - O(\\ln \\ln k)$ approximation\nis hard.\nWhere does the truth lie? Can we close the gap between the upper and lower\nbounds? An improvement would be particularly interesting for small values of\n$k$, which are often used in reductions between Set Cover and other\ncombinatorial optimization problems.\nWe consider a non-oblivious local-search approach: to the best of our\nknowledge this gives the first $H_k$-approximation for Set Cover using an\napproach based on local-search. Our proof fits in one page, and gives a\nintegrality gap result as well. Refining our approach by considering larger\nmoves and an optimized potential function gives an $(H_k - \\Omega(\\log^2\nk)/k)$-approximation, improving on the previous bound of $(H_k -\n\\Omega(1/k^8))$ (\\emph{R.\\ Hassin and A.\\ Levin, SICOMP '05}) based on a\nmodified greedy algorithm.",
    "descriptor": "\nComments: To appear in SOSA '23\n",
    "authors": [
      "Anupam Gupta",
      "Euiwoong Lee",
      "Jason Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04444"
  },
  {
    "id": "arXiv:2211.04445",
    "title": "Physics-Constrained Backdoor Attacks on Power System Fault Localization",
    "abstract": "The advances in deep learning (DL) techniques have the potential to deliver\ntransformative technological breakthroughs to numerous complex tasks in modern\npower systems that suffer from increasing uncertainty and nonlinearity.\nHowever, the vulnerability of DL has yet to be thoroughly explored in power\nsystem tasks under various physical constraints. This work, for the first time,\nproposes a novel physics-constrained backdoor poisoning attack, which embeds\nthe undetectable attack signal into the learned model and only performs the\nattack when it encounters the corresponding signal. The paper illustrates the\nproposed attack on the real-time fault line localization application.\nFurthermore, the simulation results on the 68-bus power system demonstrate that\nDL-based fault line localization methods are not robust to our proposed attack,\nindicating that backdoor poisoning attacks pose real threats to DL\nimplementations in power systems. The proposed attack pipeline can be easily\ngeneralized to other power system tasks.",
    "descriptor": "",
    "authors": [
      "Jianing Bai",
      "Ren Wang",
      "Zuyi Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04445"
  },
  {
    "id": "arXiv:2211.04446",
    "title": "Private Set Generation with Discriminative Information",
    "abstract": "Differentially private data generation techniques have become a promising\nsolution to the data privacy challenge -- it enables sharing of data while\ncomplying with rigorous privacy guarantees, which is essential for scientific\nprogress in sensitive domains. Unfortunately, restricted by the inherent\ncomplexity of modeling high-dimensional distributions, existing private\ngenerative models are struggling with the utility of synthetic samples.\nIn contrast to existing works that aim at fitting the complete data\ndistribution, we directly optimize for a small set of samples that are\nrepresentative of the distribution under the supervision of discriminative\ninformation from downstream tasks, which is generally an easier task and more\nsuitable for private training. Our work provides an alternative view for\ndifferentially private generation of high-dimensional data and introduces a\nsimple yet effective method that greatly improves the sample utility of\nstate-of-the-art approaches.",
    "descriptor": "\nComments: NeurIPS 2022, 19 pages\n",
    "authors": [
      "Dingfan Chen",
      "Raouf Kerkouche",
      "Mario Fritz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04446"
  },
  {
    "id": "arXiv:2211.04448",
    "title": "A review of TinyML",
    "abstract": "In this current technological world, the application of machine learning is\nbecoming ubiquitous. Incorporating machine learning algorithms on extremely\nlow-power and inexpensive embedded devices at the edge level is now possible\ndue to the combination of the Internet of Things (IoT) and edge computing. To\nestimate an outcome, traditional machine learning demands vast amounts of\nresources. The TinyML concept for embedded machine learning attempts to push\nsuch diversity from usual high-end approaches to low-end applications. TinyML\nis a rapidly expanding interdisciplinary topic at the convergence of machine\nlearning, software, and hardware centered on deploying deep neural network\nmodels on embedded (micro-controller-driven) systems. TinyML will pave the way\nfor novel edge-level services and applications that survive on distributed edge\ninferring and independent decision-making rather than server computation. In\nthis paper, we explore TinyML's methodology, how TinyML can benefit a few\nspecific industrial fields, its obstacles, and its future scope.",
    "descriptor": "",
    "authors": [
      "Harsha Yelchuri",
      "Rashmi R"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04448"
  },
  {
    "id": "arXiv:2211.04449",
    "title": "Fairness-aware Regression Robust to Adversarial Attacks",
    "abstract": "In this paper, we take a first step towards answering the question of how to\ndesign fair machine learning algorithms that are robust to adversarial attacks.\nUsing a minimax framework, we aim to design an adversarially robust fair\nregression model that achieves optimal performance in the presence of an\nattacker who is able to add a carefully designed adversarial data point to the\ndataset or perform a rank-one attack on the dataset. By solving the proposed\nnonsmooth nonconvex-nonconcave minimax problem, the optimal adversary as well\nas the robust fairness-aware regression model are obtained. For both synthetic\ndata and real-world datasets, numerical results illustrate that the proposed\nadversarially robust fair models have better performance on poisoned datasets\nthan other fair machine learning models in both prediction accuracy and\ngroup-based fairness measure.",
    "descriptor": "",
    "authors": [
      "Yulu Jin",
      "Lifeng Lai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04449"
  },
  {
    "id": "arXiv:2211.04454",
    "title": "SLATE: A Sequence Labeling Approach for Task Extraction from Free-form  Inked Content",
    "abstract": "We present SLATE, a sequence labeling approach for extracting tasks from\nfree-form content such as digitally handwritten (or \"inked\") notes on a virtual\nwhiteboard. Our approach allows us to create a single, low-latency model to\nsimultaneously perform sentence segmentation and classification of these\nsentences into task/non-task sentences. SLATE greatly outperforms a baseline\ntwo-model (sentence segmentation followed by classification model) approach,\nachieving a task F1 score of 84.4\\%, a sentence segmentation (boundary\nsimilarity) score of 88.4% and three times lower latency compared to the\nbaseline. Furthermore, we provide insights into tackling challenges of\nperforming NLP on the inking domain. We release both our code and dataset for\nthis novel task.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 as an Industry Track paper\n",
    "authors": [
      "Apurva Gandhi",
      "Ryan Serrao",
      "Biyi Fang",
      "Gilbert Antonius",
      "Jenna Hong",
      "Tra My Nguyen",
      "Sheng Yi",
      "Ehi Nosakhare",
      "Irene Shaffer",
      "Soundararajan Srinivasan",
      "Vivek Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04454"
  },
  {
    "id": "arXiv:2211.04455",
    "title": "Microprocessor Design with Dynamic Clock Source and Multi-Width  Instructions",
    "abstract": "This paper introduces a novel 32-bit microprocessor, based on the RISC-V\ninstruction set architecture, is designed,utilising a dynamic clock source to\nachieve high efficiency, overcoming the limitations of hardware delays. In\naddition, the microprocessor is also aimed to operate with both base (32-bit)\ninstructions and 16-bit compressed instructions. The testing of the design is\ncarried out using ModelSim with an ideal result.",
    "descriptor": "",
    "authors": [
      "Keyu Chen",
      "Xuyi Hu",
      "Robert Killey"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04455"
  },
  {
    "id": "arXiv:2211.04458",
    "title": "Computing Square Colorings on Bounded-Treewidth and Planar Graphs",
    "abstract": "A square coloring of a graph $G$ is a coloring of the square $G^2$ of $G$,\nthat is, a coloring of the vertices of $G$ such that any two vertices that are\nat distance at most $2$ in $G$ receive different colors. We investigate the\ncomplexity of finding a square coloring with a given number of $q$ colors. We\nshow that the problem is polynomial-time solvable on graphs of bounded\ntreewidth by presenting an algorithm with running time $n^{2^{\\operatorname{tw}\n+ 4}+O(1)}$ for graphs of treewidth at most $\\operatorname{tw}$. The somewhat\nunusual exponent $2^{\\operatorname{tw}}$ in the running time is essentially\noptimal: we show that for any $\\epsilon>0$, there is no algorithm with running\ntime $f(\\operatorname{tw})n^{(2-\\epsilon)^{\\operatorname{tw}}}$ unless the\nExponential-Time Hypothesis (ETH) fails.\nWe also show that the square coloring problem is NP-hard on planar graphs for\nany fixed number $q \\ge 4$ of colors. Our main algorithmic result is showing\nthat the problem (when the number of colors $q$ is part of the input) can be\nsolved in subexponential time $2^{O(n^{2/3}\\log n)}$ on planar graphs. The\nresult follows from the combination of two algorithms. If the number $q$ of\ncolors is small ($\\le n^{1/3}$), then we can exploit a treewidth bound on the\nsquare of the graph to solve the problem in time $2^{O(\\sqrt{qn}\\log n)}$. If\nthe number of colors is large ($\\ge n^{1/3}$), then an algorithm based on\nprotrusion decompositions and building on our result for the bounded-treewidth\ncase solves the problem in time $2^{O(n\\log n/q)}$.",
    "descriptor": "\nComments: 72 pages, 15 figures, full version of a paper accepted at SODA 2023\n",
    "authors": [
      "Akanksha Agrawal",
      "D\u00e1niel Marx",
      "Daniel Neuen",
      "Jasper Slusallek"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.04458"
  },
  {
    "id": "arXiv:2211.04462",
    "title": "Hyperbolic Centroid Calculations for Text Classification",
    "abstract": "A new development in NLP is the construction of hyperbolic word embeddings.\nAs opposed to their Euclidean counterparts, hyperbolic embeddings are\nrepresented not by vectors, but by points in hyperbolic space. This makes the\nmost common basic scheme for constructing document representations, namely the\naveraging of word vectors, meaningless in the hyperbolic setting. We\nreinterpret the vector mean as the centroid of the points represented by the\nvectors, and investigate various hyperbolic centroid schemes and their\neffectiveness at text classification.",
    "descriptor": "",
    "authors": [
      "Ayd\u0131n Gerek",
      "C\u00fcneyt Ferahlar",
      "Bilge \u015eipal Sert",
      "Mehmet Can Y\u00fcney",
      "Onur Ta\u015fdemir",
      "Zeynep Billur Kalafat",
      "Mert Kelkit",
      "Murat Can Ganiz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04462"
  },
  {
    "id": "arXiv:2210.13869",
    "title": "A jet tagging algorithm of graph network with HaarPooling message  passing",
    "abstract": "Recently methods of graph neural networks (GNNs) have been applied to solving\nthe problems in high energy physics (HEP) and have shown its great potential\nfor quark-gluon tagging with graph representation of jet events. In this paper,\nwe introduce an approach of GNNs combined with a HaarPooling operation to\nanalyze the events, called HaarPooling Message Passing neural network (HMPNet).\nIn HMPNet, HaarPooling not only extract the features of graph, but also embed\nadditional information obtained by clustering of k-means of different particle\nobservables. We construct Haarpooling from three different observables:\nabsolute energy $\\log E$, transverse momentum $\\log p_T$ , and relative\ncoordinates $(\\Delta\\eta,\\Delta\\phi)$, then discuss their impacts on the\ntagging and compare the results with those obtained via MPNN and ParticleNet\n(PN). The results show that an appropriate selection of information for\nHaarPooling enhance the accuracy of quark-gluon tagging, for adding extra\ninformation of $\\log P_T$ to the HMPNet outperforms all the others, meanwhile\nadding relative coordinates information $(\\Delta\\eta,\\Delta\\phi)$ is not very\nbeneficial.",
    "descriptor": "",
    "authors": [
      "Fei Ma",
      "Feiyi Liu",
      "Wei Li"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.13869"
  },
  {
    "id": "arXiv:2211.03787",
    "title": "Regimes of charged particle dynamics in current sheets: the machine  learning approach",
    "abstract": "Current sheets are spatially localized almost-1D structures with intense\nplasma currents. They play a key role in storing the magnetic field energy and\nthey separate different plasma populations in planetary magnetospheres, the\nsolar wind, and the solar corona. Current sheets are primary regions for the\nmagnetic field line reconnection responsible for plasma heating and charged\nparticle acceleration. One of the most interesting and widely observed type of\n1D current sheets is the rotational discontinuity, that can be force-free or\ninclude plasma compression. Theoretical models of such 1D current sheets are\nbased on the assumption of adiabatic motion of ions, i.e. ion adiabatic\ninvariants are conserved. We focus on three current sheet configurations,\nwidely observed in the Earth magnetopause and magnetotail and in the near-Earth\nsolar wind. Magnetic field in such current sheets is supported by currents\ncarried by transient ions, which exist only when there is a sufficient number\nof invariants. In this paper, we apply a novel machine learning approach, AI\nPoincar'e, to determine parametrical domains where adiabatic invariants are\nconserved. For all three current sheet configurations, these domains are quite\nnarrow and do not cover the entire parametrical range of observed current\nsheets. We discuss possible interpretation of obtained results indicating that\n1D current sheets are dynamical rather than static plasma equilibria.",
    "descriptor": "",
    "authors": [
      "Alexander Lukin",
      "Anton Artemyev",
      "Dmitri Vainchtein",
      "Anatoli Petrukovich"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Space Physics (physics.space-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.03787"
  },
  {
    "id": "arXiv:2211.03789",
    "title": "A Random Forest and Current Fault Texture Feature-Based Method for  Current Sensor Fault Diagnosis in Three-Phase PWM VSR",
    "abstract": "Three-phase PWM voltage-source rectifier (VSR) systems have been widely used\nin various energy conversion systems, where current sensors are the key\ncomponent for state monitoring and system control. The current sensor faults\nmay bring hidden danger or damage to the whole system; therefore, this paper\nproposed a random forest (RF) and current fault texture feature-based method\nfor current sensor fault diagnosis in three-phase PWM VSR systems. First, the\nthree-phase alternating currents (ACs) of the three-phase PWM VSR are collected\nto extract the current fault texture features, and no additional hardware\nsensors are needed to avoid causing additional unstable factors. Then, the\ncurrent fault texture features are adopted to train the random forest current\nsensor fault detection and diagnosis (CSFDD) classifier, which is a data-driven\nCSFDD classifier. Finally, the effectiveness of the proposed method is verified\nby simulation experiments. The result shows that the current sensor faults can\nbe detected and located successfully and that it can effectively provide fault\nlocations for maintenance personnel to keep the stable operation of the whole\nsystem.",
    "descriptor": "\nComments: Frontiers in Energy Research\n",
    "authors": [
      "Lei Kou",
      "Xiao-dong Gong",
      "Yi Zheng",
      "Xiu-hui Ni",
      "Yang Li",
      "Quan-de Yuan",
      "Ya-nan Dong"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.03789"
  },
  {
    "id": "arXiv:2211.03793",
    "title": "Uncertainty Quantification for Atlas-Level Cell Type Transfer",
    "abstract": "Single-cell reference atlases are large-scale, cell-level maps that capture\ncellular heterogeneity within an organ using single cell genomics. Given their\nsize and cellular diversity, these atlases serve as high-quality training data\nfor the transfer of cell type labels to new datasets. Such label transfer,\nhowever, must be robust to domain shifts in gene expression due to measurement\ntechnique, lab specifics and more general batch effects. This requires methods\nthat provide uncertainty estimates on the cell type predictions to ensure\ncorrect interpretation. Here, for the first time, we introduce uncertainty\nquantification methods for cell type classification on single-cell reference\natlases. We benchmark four model classes and show that currently used models\nlack calibration, robustness, and actionable uncertainty scores. Furthermore,\nwe demonstrate how models that quantify uncertainty are better suited to detect\nunseen cell types in the setting of atlas-level cell type transfer.",
    "descriptor": "\nComments: Workshop paper at the 2022 ICML Workshop on Computational Biology\n",
    "authors": [
      "Jan Engelmann",
      "Leon Hetzel",
      "Giovanni Palla",
      "Lisa Sikkema",
      "Malte Luecken",
      "Fabian Theis"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.03793"
  },
  {
    "id": "arXiv:2211.03796",
    "title": "Astronomia ex machina: a history, primer, and outlook on neural networks  in astronomy",
    "abstract": "In recent years, deep learning has infiltrated every field it has touched,\nreducing the need for specialist knowledge and automating the process of\nknowledge discovery from data. This review argues that astronomy is no\ndifferent, and that we are currently in the midst of a deep learning revolution\nthat is transforming the way we do astronomy. We trace the history of\nastronomical connectionism from the early days of multilayer perceptrons,\nthrough the second wave of convolutional and recurrent neural networks, to the\ncurrent third wave of self-supervised and unsupervised deep learning. We then\npredict that we will soon enter a fourth wave of astronomical connectionism, in\nwhich finetuned versions of an all-encompassing 'foundation' model will replace\nexpertly crafted deep learning models. We argue that such a model can only be\nbrought about through a symbiotic relationship between astronomy and\nconnectionism, whereby astronomy provides high quality multimodal data to train\nthe foundation model, and in turn the foundation model is used to advance\nastronomical research.",
    "descriptor": "\nComments: 60 pages, 269 references, 29 figures. Review submitted to Royal Society Open Science. Comments and feedback welcome\n",
    "authors": [
      "Michael J. Smith",
      "James E. Geach"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03796"
  },
  {
    "id": "arXiv:2211.03803",
    "title": "Quantum-probabilistic Hamiltonian learning for generative modelling &  anomaly detection",
    "abstract": "The Hamiltonian of an isolated quantum mechanical system determines its\ndynamics and physical behaviour. This study investigates the possibility of\nlearning and utilising a system's Hamiltonian and its variational thermal state\nestimation for data analysis techniques. For this purpose, we employ the method\nof Quantum Hamiltonian-Based Models for the generative modelling of simulated\nLarge Hadron Collider data and demonstrate the representability of such data as\na mixed state. In a further step, we use the learned Hamiltonian for anomaly\ndetection, showing that different sample types can form distinct dynamical\nbehaviours once treated as a quantum many-body system. We exploit these\ncharacteristics to quantify the difference between sample types. Our findings\nshow that the methodologies designed for field theory computations can be\nutilised in machine learning applications to employ theoretical approaches in\ndata analysis techniques.",
    "descriptor": "\nComments: 10 pages, 4 figures. Comments are welcome!\n",
    "authors": [
      "Jack Y. Araz",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.03803"
  },
  {
    "id": "arXiv:2211.03812",
    "title": "Posterior samples of source galaxies in strong gravitational lenses with  score-based priors",
    "abstract": "Inferring accurate posteriors for high-dimensional representations of the\nbrightness of gravitationally-lensed sources is a major challenge, in part due\nto the difficulties of accurately quantifying the priors. Here, we report the\nuse of a score-based model to encode the prior for the inference of undistorted\nimages of background galaxies. This model is trained on a set of\nhigh-resolution images of undistorted galaxies. By adding the likelihood score\nto the prior score and using a reverse-time stochastic differential equation\nsolver, we obtain samples from the posterior. Our method produces independent\nposterior samples and models the data almost down to the noise level. We show\nhow the balance between the likelihood and the prior meet our expectations in\nan experiment with out-of-distribution data.",
    "descriptor": "\nComments: 5+6 pages, 3 figures, Accepted (poster + contributed talk) for the Machine Learning and the Physical Sciences Workshop at the 36th conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Alexandre Adam",
      "Adam Coogan",
      "Nikolay Malkin",
      "Ronan Legin",
      "Laurence Perreault-Levasseur",
      "Yashar Hezaveh",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03812"
  },
  {
    "id": "arXiv:2211.03859",
    "title": "From approximate to exact integer programming",
    "abstract": "Approximate integer programming is the following: For a convex body $K\n\\subseteq \\mathbb{R}^n$, either determine whether $K \\cap \\mathbb{Z}^n$ is\nempty, or find an integer point in the convex body scaled by $2$ from its\ncenter of gravity $c$. Approximate integer programming can be solved in time\n$2^{O(n)}$ while the fastest known methods for exact integer programming run in\ntime $2^{O(n)} \\cdot n^n$. So far, there are no efficient methods for integer\nprogramming known that are based on approximate integer programming. Our main\ncontribution are two such methods, each yielding novel complexity results.\nFirst, we show that an integer point $x^* \\in (K \\cap \\mathbb{Z}^n)$ can be\nfound in time $2^{O(n)}$, provided that the remainders of each component $x_i^*\n\\mod{\\ell}$ for some arbitrarily fixed $\\ell \\geq 5(n+1)$ of $x^*$ are given.\nThe algorithm is based on a cutting-plane technique, iteratively halving the\nvolume of the feasible set. The cutting planes are determined via approximate\ninteger programming. Enumeration of the possible remainders gives a\n$2^{O(n)}n^n$ algorithm for general integer programming. This matches the\ncurrent best bound of an algorithm by Dadush (2012) that is considerably more\ninvolved. Our algorithm also relies on a new asymmetric approximate\nCarath\\'eodory theorem that might be of interest on its own.\nOur second method concerns integer programming problems in equation-standard\nform $Ax = b, 0 \\leq x \\leq u, \\, x \\in \\mathbb{Z}^n$ . Such a problem can be\nreduced to the solution of $\\prod_i O(\\log u_i +1)$ approximate integer\nprogramming problems. This implies, for example that knapsack or subset-sum\nproblems with polynomial variable range $0 \\leq x_i \\leq p(n)$ can be solved in\ntime $(\\log n)^{O(n)}$. For these problems, the best running time so far was\n$n^n \\cdot 2^{O(n)}$.",
    "descriptor": "",
    "authors": [
      "Daniel Dadush",
      "Friedrich Eisenbrand",
      "Thomas Rothvoss"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.03859"
  },
  {
    "id": "arXiv:2211.03860",
    "title": "Automatic Change-Point Detection in Time Series via Deep Learning",
    "abstract": "Detecting change-points in data is challenging because of the range of\npossible types of change and types of behaviour of data when there is no\nchange. Statistically efficient methods for detecting a change will depend on\nboth of these features, and it can be difficult for a practitioner to develop\nan appropriate detection method for their application of interest. We show how\nto automatically generate new detection methods based on training a neural\nnetwork. Our approach is motivated by many existing tests for the presence of a\nchange-point being able to be represented by a simple neural network, and thus\na neural network trained with sufficient data should have performance at least\nas good as these methods. We present theory that quantifies the error rate for\nsuch an approach, and how it depends on the amount of training data. Empirical\nresults show that, even with limited training data, its performance is\ncompetitive with the standard CUSUM test for detecting a change in mean when\nthe noise is independent and Gaussian, and can substantially outperform it in\nthe presence of auto-correlated or heavy-tailed noise. Our method also shows\nstrong results in detecting and localising changes in activity based on\naccelerometer data.",
    "descriptor": "\nComments: 16 pages, 5 figures and 1 table\n",
    "authors": [
      "Jie Li",
      "Paul Fearnhead",
      "Piotr Fryzlewicz",
      "Tengyao Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.03860"
  },
  {
    "id": "arXiv:2211.03899",
    "title": "Policy evaluation from a single path: Multi-step methods, mixing and  mis-specification",
    "abstract": "We study non-parametric estimation of the value function of an\ninfinite-horizon $\\gamma$-discounted Markov reward process (MRP) using\nobservations from a single trajectory. We provide non-asymptotic guarantees for\na general family of kernel-based multi-step temporal difference (TD) estimates,\nincluding canonical $K$-step look-ahead TD for $K = 1, 2, \\ldots$ and the\nTD$(\\lambda)$ family for $\\lambda \\in [0,1)$ as special cases. Our bounds\ncapture its dependence on Bellman fluctuations, mixing time of the Markov\nchain, any mis-specification in the model, as well as the choice of weight\nfunction defining the estimator itself, and reveal some delicate interactions\nbetween mixing time and model mis-specification. For a given TD method applied\nto a well-specified model, its statistical error under trajectory data is\nsimilar to that of i.i.d. sample transition pairs, whereas under\nmis-specification, temporal dependence in data inflates the statistical error.\nHowever, any such deterioration can be mitigated by increased look-ahead. We\ncomplement our upper bounds by proving minimax lower bounds that establish\noptimality of TD-based methods with appropriately chosen look-ahead and\nweighting, and reveal some fundamental differences between value function\nestimation and ordinary non-parametric regression.",
    "descriptor": "",
    "authors": [
      "Yaqi Duan",
      "Martin J. Wainwright"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.03899"
  },
  {
    "id": "arXiv:2211.03975",
    "title": "Optimal Smoothed Analysis and Quantitative Universality for the Smallest  Singular Value of Random Matrices",
    "abstract": "The smallest singular value and condition number play important roles in\nnumerical linear algebra and the analysis of algorithms. In numerical analysis\nwith randomness, many previous works make Gaussian assumptions, which are not\ngeneral enough to reflect the arbitrariness of the input. To overcome this\ndrawback, we prove the first quantitative universality for the smallest\nsingular value and condition number of random matrices.\nMoreover, motivated by the study of smoothed analysis that random\nperturbation makes deterministic matrices well-conditioned, we consider an\nanalog for random matrices. For a random matrix perturbed by independent\nGaussian noise, we show that this matrix quickly becomes approximately\nGaussian. In particular, we derive an optimal smoothed analysis for random\nmatrices in terms of a sharp Gaussian approximation.",
    "descriptor": "",
    "authors": [
      "Haoyu Wang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.03975"
  },
  {
    "id": "arXiv:2211.03983",
    "title": "Doubly Inhomogeneous Reinforcement Learning",
    "abstract": "This paper studies reinforcement learning (RL) in doubly inhomogeneous\nenvironments under temporal non-stationarity and subject heterogeneity. In a\nnumber of applications, it is commonplace to encounter datasets generated by\nsystem dynamics that may change over time and population, challenging\nhigh-quality sequential decision making. Nonetheless, most existing RL\nsolutions require either temporal stationarity or subject homogeneity, which\nwould result in sub-optimal policies if both assumptions were violated. To\naddress both challenges simultaneously, we propose an original algorithm to\ndetermine the ``best data chunks\" that display similar dynamics over time and\nacross individuals for policy learning, which alternates between most recent\nchange point detection and cluster identification. Our method is general, and\nworks with a wide range of clustering and change point detection algorithms. It\nis multiply robust in the sense that it takes multiple initial estimators as\ninput and only requires one of them to be consistent. Moreover, by borrowing\ninformation over time and population, it allows us to detect weaker signals and\nhas better convergence properties when compared to applying the clustering\nalgorithm per time or the change point detection algorithm per subject.\nEmpirically, we demonstrate the usefulness of our method through extensive\nsimulations and a real data application.",
    "descriptor": "",
    "authors": [
      "Liyuan Hu",
      "Mengbing Li",
      "Chengchun Shi",
      "Zhenke Wu",
      "Piotr Fryzlewicz"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03983"
  },
  {
    "id": "arXiv:2211.03985",
    "title": "Adaptive Data Depth via Multi-Armed Bandits",
    "abstract": "Data depth, introduced by Tukey (1975), is an important tool in data science,\nrobust statistics, and computational geometry. One chief barrier to its broader\npractical utility is that many common measures of depth are computationally\nintensive, requiring on the order of $n^d$ operations to exactly compute the\ndepth of a single point within a data set of $n$ points in $d$-dimensional\nspace. Often however, we are not directly interested in the absolute depths of\nthe points, but rather in their \\textit{relative ordering}. For example, we may\nwant to find the most central point in a data set (a generalized median), or to\nidentify and remove all outliers (points on the fringe of the data set with low\ndepth). With this observation, we develop a novel and instance-adaptive\nalgorithm for adaptive data depth computation by reducing the problem of\nexactly computing $n$ depths to an $n$-armed stochastic multi-armed bandit\nproblem which we can efficiently solve. We focus our exposition on simplicial\ndepth, developed by \\citet{liu1990notion}, which has emerged as a promising\nnotion of depth due to its interpretability and asymptotic properties. We\nprovide general instance-dependent theoretical guarantees for our proposed\nalgorithms, which readily extend to many other common measures of data depth\nincluding majority depth, Oja depth, and likelihood depth. When specialized to\nthe case where the gaps in the data follow a power law distribution with\nparameter $\\alpha<2$, we show that we can reduce the complexity of identifying\nthe deepest point in the data set (the simplicial median) from $O(n^d)$ to\n$\\tilde{O}(n^{d-(d-1)\\alpha/2})$, where $\\tilde{O}$ suppresses logarithmic\nfactors. We corroborate our theoretical results with numerical experiments on\nsynthetic data, showing the practical utility of our proposed methods.",
    "descriptor": "",
    "authors": [
      "Tavor Z. Baharav",
      "Tze Leung Lai"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03985"
  },
  {
    "id": "arXiv:2211.03997",
    "title": "A Simple Algorithm for Online Decision Making",
    "abstract": "Motivated by recent progress on online linear programming (OLP), we study the\nonline decision making problem (ODMP) as a natural generalization of OLP. In\nODMP, there exists a single decision maker who makes a series of decisions\nspread out over a total of $T$ time stages. At each time stage, the decision\nmaker makes a decision based on information obtained up to that point without\nseeing into the future. The task of the decision maker is to maximize the\naccumulated reward while overall meeting some predetermined $m$-dimensional\nlong-term goal (linking) constraints. ODMP significantly broadens the modeling\nframework of OLP by allowing more general feasible regions (for local and goal\nconstraints) potentially involving both discreteness and nonlinearity in each\nlocal decision making problem.\nWe propose a Fenchel dual-based online algorithm for ODMP. At each time\nstage, the proposed algorithm requires solving a potentially nonconvex\noptimization problem over the local feasible set and a convex optimization\nproblem over the goal set. Under the uniform random permutation model, we show\nthat our algorithm achieves $O(\\sqrt{mT})$ constraint violation\ndeterministically in meeting the long-term goals, and $O(\\sqrt{m\\log\nm}\\sqrt{T})$ competitive difference in expected reward with respect to the\noptimal offline decisions. We also extend our results to the grouped random\npermutation model.",
    "descriptor": "",
    "authors": [
      "Rui Chen",
      "Oktay Gunluk",
      "Andrea Lodi",
      "Guanyi Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.03997"
  },
  {
    "id": "arXiv:2211.04020",
    "title": "Generating counterfactual explanations of tumor spatial proteomes to  discover effective, combinatorial therapies that enhance cancer immunotherapy",
    "abstract": "Recent advances in spatial omics methods enable the molecular composition of\nhuman tumors to be imaged at micron-scale resolution across hundreds of\npatients and ten to thousands of molecular imaging channels. Large-scale\nmolecular imaging datasets offer a new opportunity to understand how the\nspatial organization of proteins and cell types within a tumor modulate the\nresponse of a patient to different therapeutic strategies and offer potential\ninsights into the design of novel therapies to increase patient response.\nHowever, spatial omics datasets require computational analysis methods that can\nscale to incorporate hundreds to thousands of imaging channels (ie colors)\nwhile enabling the extraction of molecular patterns that correlate with\ntreatment responses across large number of patients with potentially\nheterogeneous tumors presentations. Here, we have develop a machine learning\nstrategy for the identification and design of signaling molecule combinations\nthat predict the degree of immune system engagement with a specific patient\ntumors. We specifically train a classifier to predict T cell distribution in\npatient tumors using the images from 30-40 molecular imaging channels. Second,\nwe apply a gradient descent based counterfactual reasoning strategy to the\nclassifier and discover combinations of signaling molecules predicted to\nincrease T cell infiltration. Applied to spatial proteomics data of melanoma\ntumor, our model predicts that increasing the level of CXCL9, CXCL10, CXCL12,\nCCL19 and decreasing the level of CCL8 in melanoma tumor will increase T cell\ninfiltration by 10-fold across a cohort of 69 patients. The model predicts that\nthe combination is many fold more effective than single target perturbations.\nOur work provides a paradigm for machine learning based prediction and design\nof cancer therapeutics based on classification of immune system activity in\nspatial omics data.",
    "descriptor": "",
    "authors": [
      "Zitong Jerry Wang",
      "Matt Thomson"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2211.04020"
  },
  {
    "id": "arXiv:2211.04025",
    "title": "Complexity of directed Steiner path packing problem",
    "abstract": "For a digraph $D=(V(D), A(D))$, and a set $S\\subseteq V(D)$ with $r\\in S$ and\n$|S|\\geq 2$, a directed $(S, r)$-Steiner path or, simply, an $(S, r)$-path is a\ndirected path $P$ started at $r$ with $S\\subseteq V(P)$. Two $(S, r)$-paths are\nsaid to be arc-disjoint if they have no common arc. Two arc-disjoint $(S,\nr)$-paths are said to be internally disjoint if the set of common vertices of\nthem is exactly $S$. Let $\\kappa^p_{S,r}(D)$ (resp. $\\lambda^p_{S,r}(D)$) be\nthe maximum number of internally disjoint (resp. arc-disjoint) $(S, r)$-paths\nin $D$.\nIn this paper, we study the complexity for $\\kappa^p_{S,r}(D)$ and\n$\\lambda^p_{S,r}(D)$. When both $k\\geq 2, \\ell\\geq 1$ are fixed integers, we\nshow that the problem of deciding whether $\\kappa^p_{S,r}(D) \\geq \\ell$ for an\nEulerian digraph $D$ is NP-complete, where $r\\in S\\subseteq V(D)$ and $|S|=k$.\nHowever, when we consider the class of symmetric digraphs, the problem becomes\npolynomial-time solvable. We also show that the problem of deciding whether\n$\\lambda^p_{S,r}(D) \\geq \\ell$ for a given digraph $D$ is NP-complete, where\n$r\\in S\\subseteq V(D)$ and $|S|=k$.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2208.08618, arXiv:2206.12092\n",
    "authors": [
      "Yuefang Sun"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.04025"
  },
  {
    "id": "arXiv:2211.04051",
    "title": "Global Convergence of Policy Gradient Methods for Output Feedback Linear  Quadratic Control",
    "abstract": "While the optimization landscape of policy gradient methods has been recently\ninvestigated for partially observable linear systems in terms of both dynamical\ncontrollers and static output feedback, they can only provide convergence\nguarantees to stationary points. In this paper, we propose a new\nparameterization of the policy, which uses a past input-output trajectory of\nfinite length as the feedback. We show that the solution set to the\nparameterized optimization problem is a matrix space, which is invariant to\n\\textit{similarity transformation}. By proving a gradient dominance property,\nwe show the global convergence of policy gradient methods. Moreover, we observe\nthat the gradient is orthogonal to the solution set, revealing an explicit\nrelation between the resulting solution and the initial policy. Finally, we\nperform simulations to validate our theoretical results.",
    "descriptor": "\nComments: Submitted to IFAC World Congress 2023\n",
    "authors": [
      "Feiran Zhao",
      "Xingyun Fu",
      "Keyou You"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04051"
  },
  {
    "id": "arXiv:2211.04070",
    "title": "On Negative Sampling for Contrastive Audio-Text Retrieval",
    "abstract": "This paper investigates negative sampling for contrastive learning in the\ncontext of audio-text retrieval. The strategy for negative sampling refers to\nselecting negatives (either audio clips or textual descriptions) from a pool of\ncandidates for a positive audio-text pair. We explore sampling strategies via\nmodel-estimated within-modality and cross-modality relevance scores for audio\nand text samples. With a constant training setting on the retrieval system from\n[1], we study eight sampling strategies, including hard and semi-hard negative\nsampling. Experimental results show that retrieval performance varies\ndramatically among different strategies. Particularly, by selecting semi-hard\nnegatives with cross-modality scores, the retrieval system gains improved\nperformance in both text-to-audio and audio-to-text retrieval. Besides, we show\nthat feature collapse occurs while sampling hard negatives with cross-modality\nscores.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Huang Xie",
      "Okko R\u00e4s\u00e4nen",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.04070"
  },
  {
    "id": "arXiv:2211.04104",
    "title": "Selective compression learning of latent representations for  variable-rate image compression",
    "abstract": "Recently, many neural network-based image compression methods have shown\npromising results superior to the existing tool-based conventional codecs.\nHowever, most of them are often trained as separate models for different target\nbit rates, thus increasing the model complexity. Therefore, several studies\nhave been conducted for learned compression that supports variable rates with\nsingle models, but they require additional network modules, layers, or inputs\nthat often lead to complexity overhead, or do not provide sufficient coding\nefficiency. In this paper, we firstly propose a selective compression method\nthat partially encodes the latent representations in a fully generalized manner\nfor deep learning-based variable-rate image compression. The proposed method\nadaptively determines essential representation elements for compression of\ndifferent target quality levels. For this, we first generate a 3D importance\nmap as the nature of input content to represent the underlying importance of\nthe representation elements. The 3D importance map is then adjusted for\ndifferent target quality levels using importance adjustment curves. The\nadjusted 3D importance map is finally converted into a 3D binary mask to\ndetermine the essential representation elements for compression. The proposed\nmethod can be easily integrated with the existing compression models with a\nnegligible amount of overhead increase. Our method can also enable continuously\nvariable-rate compression via simple interpolation of the importance adjustment\ncurves among different quality levels. The extensive experimental results show\nthat the proposed method can achieve comparable compression efficiency as those\nof the separately trained reference compression models and can reduce decoding\ntime owing to the selective compression. The sample codes are publicly\navailable at https://github.com/JooyoungLeeETRI/SCR.",
    "descriptor": "\nComments: Accepted as a NeurIPS 2022 paper. [Github] this https URL\n",
    "authors": [
      "Jooyoung Lee",
      "Seyoon Jeong",
      "Munchurl Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04104"
  },
  {
    "id": "arXiv:2211.04124",
    "title": "Unsupervised vocal dereverberation with diffusion-based generative  models",
    "abstract": "Removing reverb from reverberant music is a necessary technique to clean up\naudio for downstream music manipulations. Reverberation of music contains two\ncategories, natural reverb, and artificial reverb. Artificial reverb has a\nwider diversity than natural reverb due to its various parameter setups and\nreverberation types. However, recent supervised dereverberation methods may\nfail because they rely on sufficiently diverse and numerous pairs of\nreverberant observations and retrieved data for training in order to be\ngeneralizable to unseen observations during inference. To resolve these\nproblems, we propose an unsupervised method that can remove a general kind of\nartificial reverb for music without requiring pairs of data for training. The\nproposed method is based on diffusion models, where it initializes the unknown\nreverberation operator with a conventional signal processing technique and\nsimultaneously refines the estimate with the help of diffusion models. We show\nthrough objective and perceptual evaluations that our method outperforms the\ncurrent leading vocal dereverberation benchmarks.",
    "descriptor": "\nComments: 6 pages, 2 figures, submitted to ICASSP 2023\n",
    "authors": [
      "Koichi Saito",
      "Naoki Murata",
      "Toshimitsu Uesaka",
      "Chieh-Hsin Lai",
      "Yuhta Takida",
      "Takao Fukui",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.04124"
  },
  {
    "id": "arXiv:2211.04153",
    "title": "Solution to a problem of Katona on counting cliques of weighted graphs",
    "abstract": "A subset $I$ of the vertex set $V(G)$ of a graph $G$ is called a $k$-clique\nindependent set of $G$ if no $k$ vertices in $I$ form a $k$-clique of $G$. An\nindependent set is a $2$-clique independent set. Let $\\pi_k(G)$ denote the\nnumber of $k$-cliques of $G$. For a function $w: V(G) \\rightarrow \\{0, 1, 2,\n\\dots\\}$, let $G(w)$ be the graph obtained from $G$ by replacing each vertex\n$v$ by a $w(v)$-clique $K^v$ and making each vertex of $K^u$ adjacent to each\nvertex of $K^v$ for each edge $\\{u,v\\}$ of $G$. For an integer $m \\geq 1$,\nconsider any $w$ with $\\sum_{v \\in V(G)} w(v) = m$. For $U \\subseteq V(G)$, we\nsay that $w$ is uniform on $U$ if $w(v) = 0$ for each $v \\in V(G) \\setminus U$\nand, for each $u \\in U$, $w(u) = \\left\\lfloor m/|U| \\right\\rfloor$ or $w(u) =\n\\left\\lceil m/|U| \\right\\rceil$. Katona asked if $\\pi_k(G(w))$ is smallest when\n$w$ is uniform on a largest $k$-clique independent set of $G$. He placed\nparticular emphasis on the Sperner graph $B_n$, given by $V(B_n) = \\{X \\colon X\n\\subseteq \\{1, \\dots, n\\}\\}$ and $E(B_n) = \\{\\{X,Y\\} \\colon X \\subsetneq Y \\in\nV(B_n)\\}$. He provided an affirmative answer for $k = 2$ (and any $G$). We\ndetermine graphs for which the answer is negative for every $k \\geq 3$. These\ninclude $B_n$ for $n \\geq 2$. Generalizing Sperner's Theorem and a recent\nresult of Qian, Engel and Xu, we show that $\\pi_k(B_n(w))$ is smallest when $w$\nis uniform on a largest independent set of $B_n$. We also show that the same\nholds for complete multipartite graphs and chordal graphs. We show that this is\nnot true of every graph, using a deep result of Bohman on triangle-free graphs.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Peter Borg",
      "Carl Feghali",
      "R\u00e9mi Pellerin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.04153"
  },
  {
    "id": "arXiv:2211.04160",
    "title": "A Neural Network Subgrid Model of the Early Stages of Planet Formation",
    "abstract": "Planet formation is a multi-scale process in which the coagulation of\n$\\mathrm{\\mu m}$-sized dust grains in protoplanetary disks is strongly\ninfluenced by the hydrodynamic processes on scales of astronomical units\n($\\approx 1.5\\times 10^8 \\,\\mathrm{km}$). Studies are therefore dependent on\nsubgrid models to emulate the micro physics of dust coagulation on top of a\nlarge scale hydrodynamic simulation. Numerical simulations which include the\nrelevant physical effects are complex and computationally expensive. Here, we\npresent a fast and accurate learned effective model for dust coagulation,\ntrained on data from high resolution numerical coagulation simulations. Our\nmodel captures details of the dust coagulation process that were so far not\ntractable with other dust coagulation prescriptions with similar computational\nefficiency.",
    "descriptor": "\nComments: 6 pages, 4 figures, accepted at the Machine Learning and the Physical Sciences workshop, NeurIPS 2022\n",
    "authors": [
      "Thomas Pfeil",
      "Miles Cranmer",
      "Shirley Ho",
      "Philip J. Armitage",
      "Tilman Birnstiel",
      "Hubert Klahr"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04160"
  },
  {
    "id": "arXiv:2211.04168",
    "title": "Pushing the limits of self-supervised speaker verification using  regularized distillation framework",
    "abstract": "Training robust speaker verification systems without speaker labels has long\nbeen a challenging task. Previous studies observed a large performance gap\nbetween self-supervised and fully supervised methods. In this paper, we apply a\nnon-contrastive self-supervised learning framework called DIstillation with NO\nlabels (DINO) and propose two regularization terms applied to embeddings in\nDINO. One regularization term guarantees the diversity of the embeddings, while\nthe other regularization term decorrelates the variables of each embedding. The\neffectiveness of various data augmentation techniques are explored, on both\ntime and frequency domain. A range of experiments conducted on the VoxCeleb\ndatasets demonstrate the superiority of the regularized DINO framework in\nspeaker verification. Our method achieves the state-of-the-art speaker\nverification performance under a single-stage self-supervised setting on\nVoxCeleb. The codes will be made publicly-available.",
    "descriptor": "",
    "authors": [
      "Yafeng Chen",
      "Siqi Zheng",
      "Hui Wang",
      "Luyao Cheng",
      "Qian Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.04168"
  },
  {
    "id": "arXiv:2211.04171",
    "title": "The Hypervolume Indicator Hessian Matrix: Analytical Expression,  Computational Time Complexity, and Sparsity",
    "abstract": "The problem of approximating the Pareto front of a multiobjective\noptimization problem can be reformulated as the problem of finding a set that\nmaximizes the hypervolume indicator. This paper establishes the analytical\nexpression of the Hessian matrix of the mapping from a (fixed size) collection\nof $n$ points in the $d$-dimensional decision space (or $m$ dimensional\nobjective space) to the scalar hypervolume indicator value. To define the\nHessian matrix, the input set is vectorized, and the matrix is derived by\nanalytical differentiation of the mapping from a vectorized set to the\nhypervolume indicator. The Hessian matrix plays a crucial role in second-order\nmethods, such as the Newton-Raphson optimization method, and it can be used for\nthe verification of local optimal sets. So far, the full analytical expression\nwas only established and analyzed for the relatively simple bi-objective case.\nThis paper will derive the full expression for arbitrary dimensions ($m\\geq2$\nobjective functions). For the practically important three-dimensional case, we\nalso provide an asymptotically efficient algorithm with time complexity in\n$O(n\\log n)$ for the exact computation of the Hessian Matrix' non-zero entries.\nWe establish a sharp bound of $12m-6$ for the number of non-zero entries. Also,\nfor the general $m$-dimensional case, a compact recursive analytical expression\nis established, and its algorithmic implementation is discussed. Also, for the\ngeneral case, some sparsity results can be established; these results are\nimplied by the recursive expression. To validate and illustrate the\nanalytically derived algorithms and results, we provide a few numerical\nexamples using Python and Mathematica implementations. Open-source\nimplementations of the algorithms and testing data are made available as a\nsupplement to this paper.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 H. Deutz",
      "Michael T.M. Emmerich",
      "Hao Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04171"
  },
  {
    "id": "arXiv:2211.04180",
    "title": "Exploiting segmentation labels and representation learning to forecast  therapy response of PDAC patients",
    "abstract": "The prediction of pancreatic ductal adenocarcinoma therapy response is a\nclinically challenging and important task in this high-mortality tumour entity.\nThe training of neural networks able to tackle this challenge is impeded by a\nlack of large datasets and the difficult anatomical localisation of the\npancreas. Here, we propose a hybrid deep neural network pipeline to predict\ntumour response to initial chemotherapy which is based on the Response\nEvaluation Criteria in Solid Tumors (RECIST) score, a standardised method for\ncancer response evaluation by clinicians as well as tumour markers, and\nclinical evaluation of the patients. We leverage a combination of\nrepresentation transfer from segmentation to classification, as well as\nlocalisation and representation learning. Our approach yields a remarkably\ndata-efficient method able to predict treatment response with a ROC-AUC of\n63.7% using only 477 datasets in total.",
    "descriptor": "",
    "authors": [
      "Alexander Ziller",
      "Ayhan Can Erdur",
      "Friederike Jungmann",
      "Daniel Rueckert",
      "Rickmer Braren",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04180"
  },
  {
    "id": "arXiv:2211.04183",
    "title": "Vanishing opinions in Latan\u00e9 model of opinion formation",
    "abstract": "In this paper, the results of the computer simulations based on\nNowak--Szamrej--Latan\\'e model with multiple (from two to five) opinions\navailable in the system are presented. We introduce the noise discrimination\nlevel as a quite useful quantity that allows qualitative characterization of\nthe system. We show that depending on the introduced noise discrimination\nlevel, the range of actors' interactions and the information noise level, the\nultimate number of the opinions (measured as the number of clusters of actors\nsharing the same opinion in clusters greater than the noise discrimination\nlevel) may be smaller than the number of opinions available in the system.\nThese are observed in small and large information noise limits but result in\neither unanimity, or polarization, or randomization of opinions. We also show\nthat the larger the range of interaction, the more influential the nearest\nneighbors are.",
    "descriptor": "\nComments: 22 pages, 20 figures, for this https URL\n",
    "authors": [
      "Maciej Dworak",
      "Krzysztof Malarz"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.04183"
  },
  {
    "id": "arXiv:2211.04258",
    "title": "MetaLoc: Learning to Learn Wireless Localization",
    "abstract": "The existing indoor fingerprinting localization methods are rather accurate\nafter intensive offline calibration for a specific environment, no matter based\non received signal strength (RSS) or channel state information (CSI), but the\nwell-calibrated localization model (can be a pure statistical one or a\ndata-driven one) will present poor generalization ability in the highly\nvariable environments, which results in big loss in knowledge and human effort.\nTo break the environment-specific localization bottleneck, we propose a\nnew-fashioned data-driven fingerprinting method for localization based on\nmodel-agnostic meta-learning (MAML), named by MetaLoc. Specifically, MetaLoc is\nchar acterized by rapldly adapting itself to a new, possibly unseen environment\nwith very little calibration. The underlying localization model is taken to be\na deep neural network, and we train an optimal set of environment-specific\nmeta-parameters by leveraging previous data collected from diverse\nwell-calibrated indoor environments and the maximum mean discrepancy criterion.\nWe further modify the loss function of vanilla MAML and propose a novel\nframework named as MAML-DG, which is able to achieve faster convergence and\nbetter adaptation abilities by forcing the loss on different training domains\nto decrease in similar directions. Experiments from simulation and site survey\nconfirm that the meta-parameters obtained for MetaLoc achieves very rapid\nadaptation to new environments, competitive localization accuracy, and high\nresistance to significantly reduced reference points (RPs), saving a lot of\ncalibration effort.",
    "descriptor": "",
    "authors": [
      "Jun Gao",
      "Dongze Wu",
      "Feng Yin",
      "Qinglei Kong",
      "Lexi Xu",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04258"
  },
  {
    "id": "arXiv:2211.04332",
    "title": "DiffPhase: Generative Diffusion-based STFT Phase Retrieval",
    "abstract": "Diffusion probabilistic models have been recently used in a variety of tasks,\nincluding speech enhancement and synthesis. As a generative approach, diffusion\nmodels have been shown to be especially suitable for imputation problems, where\nmissing data is generated based on existing data. Phase retrieval is inherently\nan imputation problem, where phase information has to be generated based on the\ngiven magnitude. In this work we build upon previous work in the speech domain,\nadapting a speech enhancement diffusion model specifically for STFT phase\nretrieval. Evaluation using speech quality and intelligibility metrics shows\nthe diffusion approach is well-suited to the phase retrieval task, with\nperformance surpassing both classical and modern methods.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Tal Peer",
      "Simon Welker",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04332"
  },
  {
    "id": "arXiv:2211.04343",
    "title": "Quantum Deep Dreaming: A Novel Approach for Quantum Circuit Design",
    "abstract": "One of the challenges currently facing the quantum computing community is the\ndesign of quantum circuits which can efficiently run on near-term quantum\ncomputers, known as the quantum compiling problem. Algorithms such as the\nVariational Quantum Eigensolver (VQE), Quantum Approximate Optimization\nAlgorithm (QAOA), and Quantum Architecture Search (QAS) have been shown to\ngenerate or find optimal near-term quantum circuits. However, these methods are\ncomputationally expensive and yield little insight into the circuit design\nprocess. In this paper, we propose Quantum Deep Dreaming (QDD), an algorithm\nthat generates optimal quantum circuit architectures for specified objectives,\nsuch as ground state preparation, while providing insight into the circuit\ndesign process. In QDD, we first train a neural network to predict some\nproperty of a quantum circuit (such as VQE energy). Then, we employ the Deep\nDreaming technique on the trained network to iteratively update an initial\ncircuit to achieve a target property value (such as ground state VQE energy).\nImportantly, this iterative updating allows us to analyze the intermediate\ncircuits of the dreaming process and gain insights into the circuit features\nthat the network is modifying during dreaming. We demonstrate that QDD\nsuccessfully generates, or 'dreams', circuits of six qubits close to ground\nstate energy (Transverse Field Ising Model VQE energy) and that dreaming\nanalysis yields circuit design insights. QDD is designed to optimize circuits\nwith any target property and can be applied to circuit design problems both\nwithin and outside of quantum chemistry. Hence, QDD lays the foundation for the\nfuture discovery of optimized quantum circuits and for increased\ninterpretability of automated quantum algorithm design.",
    "descriptor": "\nComments: Undergraduate Thesis. Defended 19th April 2022, McMaster University. Supervised by Dr. Alan Aspuru-Guzik. 40 Pages, 9 Figures, 1 Appendix\n",
    "authors": [
      "Romi Lifshitz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04343"
  },
  {
    "id": "arXiv:2211.04346",
    "title": "Cross-Attention is all you need: Real-Time Streaming Transformers for  Personalised Speech Enhancement",
    "abstract": "Personalised speech enhancement (PSE), which extracts only the speech of a\ntarget user and removes everything else from a recorded audio clip, can\npotentially improve users' experiences of audio AI modules deployed in the\nwild. To support a large variety of downstream audio tasks, such as real-time\nASR and audio-call enhancement, a PSE solution should operate in a streaming\nmode, i.e., input audio cleaning should happen in real-time with a small\nlatency and real-time factor. Personalisation is typically achieved by\nextracting a target speaker's voice profile from an enrolment audio, in the\nform of a static embedding vector, and then using it to condition the output of\na PSE model. However, a fixed target speaker embedding may not be optimal under\nall conditions. In this work, we present a streaming Transformer-based PSE\nmodel and propose a novel cross-attention approach that gives adaptive target\nspeaker representations. We present extensive experiments and show that our\nproposed cross-attention approach outperforms competitive baselines\nconsistently, even when our model is only approximately half the size.",
    "descriptor": "",
    "authors": [
      "Shucong Zhang",
      "Malcolm Chadwick",
      "Alberto Gil C. P. Ramos",
      "Sourav Bhattacharya"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.04346"
  },
  {
    "id": "arXiv:2211.04349",
    "title": "A deep solver for BSDEs with jumps",
    "abstract": "The aim of this work is to propose an extension of the Deep BSDE solver by\nHan, E, Jentzen (2017) to the case of FBSDEs with jumps. As in the\naforementioned solver, starting from a discretized version of the BSDE and\nparametrizing the (high dimensional) control processes by means of a family of\nANNs, the BSDE is viewed as model-based reinforcement learning problem and the\nANN parameters are fitted so as to minimize a prescribed loss function. We take\ninto account both finite and infinite jump activity by introducing, in the\nlatter case, an approximation with finitely many jumps of the forward process.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Alessandro Gnoatto",
      "Marco Patacca",
      "Athena Picarelli"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Computational Finance (q-fin.CP)",
      "Pricing of Securities (q-fin.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.04349"
  },
  {
    "id": "arXiv:2211.04350",
    "title": "Infant hip screening using multi-class ultrasound scan segmentation",
    "abstract": "Developmental dysplasia of the hip (DDH) is a condition in infants where the\nfemoral head is incorrectly located in the hip joint. We propose a deep\nlearning algorithm for segmenting key structures within ultrasound images,\nemploying this to calculate Femoral Head Coverage (FHC) and provide a screening\ndiagnosis for DDH. To our knowledge, this is the first study to automate FHC\ncalculation for DDH screening. Our algorithm outperforms the international\nstate of the art, agreeing with expert clinicians on 89.8% of our test images.",
    "descriptor": "\nComments: Four page paper\n",
    "authors": [
      "Andrew Stamper",
      "Abhinav Singh",
      "James McCouat",
      "Irina Voiculescu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04350"
  },
  {
    "id": "arXiv:2211.04352",
    "title": "Optimal shepherding and transport of a flock",
    "abstract": "We investigate how a shepherd should move in order to effectively herd and\nguide a flock of agents towards a target. Using a detailed agent-based model\n(ABM) for the members of the flock, we pose and solve an optimization problem\nfor the shepherd that has to simultaneously work to keep the flock cohesive\nwhile coercing it towards a prescribed project. We find that three distinct\nstrategies emerge as potential solutions as a function of just two parameters:\nthe ratio of herd size to shepherd repulsion length and the ratio of herd speed\nto shepherd speed. We term these as: (i) mustering, in which the shepherd\ncircles the herd to ensure compactness, (ii) droving, in which the shepherd\nchases the herd in a desired direction, and (iii) driving, a hitherto\nunreported strategy where the flock surrounds a shepherd that drives it from\nwithin. A minimal dynamical model for the size, shape and position of the herd\ncaptures the effective behavior of the ABM, and further allows us to\ncharacterize the different herding strategies in terms of the behavior of the\nshepherd that librates (mustering), oscillates (droving) or moves steadily\n(driving). All together, our study yields a simple and intuitive classification\nof herding strategies that ought to be of general interest in the context of\ncontrolling the collective behavior of active matter.",
    "descriptor": "",
    "authors": [
      "Aditya Ranganathan",
      "Alexander Heyde",
      "Anupam Gupta",
      "L.Mahadevan"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04352"
  },
  {
    "id": "arXiv:2211.04392",
    "title": "Reduced Order Probabilistic Emulation for Physics-Based Thermosphere  Models",
    "abstract": "The geospace environment is volatile and highly driven. Space weather has\neffects on Earth's magnetosphere that cause a dynamic and enigmatic response in\nthe thermosphere, particularly on the evolution of neutral mass density. Many\nmodels exist that use space weather drivers to produce a density response, but\nthese models are typically computationally expensive or inaccurate for certain\nspace weather conditions. In response, this work aims to employ a probabilistic\nmachine learning (ML) method to create an efficient surrogate for the\nThermosphere Ionosphere Electrodynamics General Circulation Model (TIE-GCM), a\nphysics-based thermosphere model. Our method leverages principal component\nanalysis to reduce the dimensionality of TIE-GCM and recurrent neural networks\nto model the dynamic behavior of the thermosphere much quicker than the\nnumerical model. The newly developed reduced order probabilistic emulator\n(ROPE) uses Long-Short Term Memory neural networks to perform time-series\nforecasting in the reduced state and provide distributions for future density.\nWe show that across the available data, TIE-GCM ROPE has similar error to\nprevious linear approaches while improving storm-time modeling. We also conduct\na satellite propagation study for the significant November 2003 storm which\nshows that TIE-GCM ROPE can capture the position resulting from TIE-GCM density\nwith < 5 km bias. Simultaneously, linear approaches provide point estimates\nthat can result in biases of 7 - 18 km.",
    "descriptor": "",
    "authors": [
      "Richard J. Licata",
      "Piyush M. Mehta"
    ],
    "subjectives": [
      "Space Physics (physics.space-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04392"
  },
  {
    "id": "arXiv:2211.04399",
    "title": "Stability estimates for the expected utility in Bayesian optimal  experimental design",
    "abstract": "We study stability properties of the expected utility function in Bayesian\noptimal experimental design. We provide a framework for this problem in a\nnon-parametric setting and prove a convergence rate of the expected utility\nwith respect to a likelihood perturbation. This rate is uniform over the design\nspace and its sharpness in the general setting is demonstrated by proving a\nlower bound in a special case. To make the problem more concrete we proceed by\nconsidering non-linear Bayesian inverse problems with Gaussian likelihood and\nprove that the assumptions set out for the general case are satisfied and\nregain the stability of the expected utility with respect to perturbations to\nthe observation map. Theoretical convergence rates are demonstrated numerically\nin three different examples.",
    "descriptor": "\nComments: 20 pages; 6 figures\n",
    "authors": [
      "Duc-Lam Duong",
      "Tapio Helin",
      "Jose Rodrigo Rojo-Garcia"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04399"
  },
  {
    "id": "arXiv:2211.04406",
    "title": "Multiple Packing: Lower and Upper Bounds",
    "abstract": "We study the problem of high-dimensional multiple packing in Euclidean space.\nMultiple packing is a natural generalization of sphere packing and is defined\nas follows. Let $ N>0 $ and $ L\\in\\mathbb{Z}_{\\ge2} $. A multiple packing is a\nset $\\mathcal{C}$ of points in $ \\mathbb{R}^n $ such that any point in $\n\\mathbb{R}^n $ lies in the intersection of at most $ L-1 $ balls of radius $\n\\sqrt{nN} $ around points in $ \\mathcal{C} $. We study the multiple packing\nproblem for both bounded point sets whose points have norm at most $\\sqrt{nP}$\nfor some constant $P>0$ and unbounded point sets whose points are allowed to be\nanywhere in $ \\mathbb{R}^n $. Given a well-known connection with coding theory,\nmultiple packings can be viewed as the Euclidean analog of list-decodable\ncodes, which are well-studied for finite fields. In this paper, we derive\nvarious bounds on the largest possible density of a multiple packing in both\nbounded and unbounded settings. A related notion called average-radius multiple\npacking is also studied. Some of our lower bounds exactly pin down the\nasymptotics of certain ensembles of average-radius list-decodable codes, e.g.,\n(expurgated) Gaussian codes and (expurgated) spherical codes. In particular,\nour lower bound obtained from spherical codes is the best known lower bound on\nthe optimal multiple packing density and is the first lower bound that\napproaches the known large $L$ limit under the average-radius notion of\nmultiple packing. To derive these results, we apply tools from high-dimensional\ngeometry and large deviation theory.",
    "descriptor": "\nComments: The paper arXiv:2107.05161 has been split into three parts with new results added and significant revision. This paper is one of the three parts\n",
    "authors": [
      "Yihan Zhang",
      "Shashank Vatedka"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04406"
  },
  {
    "id": "arXiv:2211.04407",
    "title": "Multiple Packing: Lower Bounds via Infinite Constellations",
    "abstract": "We study the problem of high-dimensional multiple packing in Euclidean space.\nMultiple packing is a natural generalization of sphere packing and is defined\nas follows. Let $ N>0 $ and $ L\\in\\mathbb{Z}_{\\ge2} $. A multiple packing is a\nset $\\mathcal{C}$ of points in $ \\mathbb{R}^n $ such that any point in $\n\\mathbb{R}^n $ lies in the intersection of at most $ L-1 $ balls of radius $\n\\sqrt{nN} $ around points in $ \\mathcal{C} $. Given a well-known connection\nwith coding theory, multiple packings can be viewed as the Euclidean analog of\nlist-decodable codes, which are well-studied for finite fields. In this paper,\nwe derive the best known lower bounds on the optimal density of list-decodable\ninfinite constellations for constant $L$ under a stronger notion called\naverage-radius multiple packing. To this end, we apply tools from\nhigh-dimensional geometry and large deviation theory.",
    "descriptor": "\nComments: The paper arXiv:2107.05161 has been split into three parts with new results added and significant revision. This paper is one of the three parts\n",
    "authors": [
      "Yihan Zhang",
      "Shashank Vatedka"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04407"
  },
  {
    "id": "arXiv:2211.04408",
    "title": "Multiple Packing: Lower Bounds via Error Exponents",
    "abstract": "We derive lower bounds on the maximal rates for multiple packings in\nhigh-dimensional Euclidean spaces. Multiple packing is a natural generalization\nof the sphere packing problem. For any $ N>0 $ and $ L\\in\\mathbb{Z}_{\\ge2} $, a\nmultiple packing is a set $\\mathcal{C}$ of points in $ \\mathbb{R}^n $ such that\nany point in $ \\mathbb{R}^n $ lies in the intersection of at most $ L-1 $ balls\nof radius $ \\sqrt{nN} $ around points in $ \\mathcal{C} $. We study this problem\nfor both bounded point sets whose points have norm at most $\\sqrt{nP}$ for some\nconstant $P>0$ and unbounded point sets whose points are allowed to be anywhere\nin $ \\mathbb{R}^n $. Given a well-known connection with coding theory, multiple\npackings can be viewed as the Euclidean analog of list-decodable codes, which\nare well-studied for finite fields. We derive the best known lower bounds on\nthe optimal multiple packing density. This is accomplished by establishing a\ncurious inequality which relates the list-decoding error exponent for additive\nwhite Gaussian noise channels, a quantity of average-case nature, to the\nlist-decoding radius, a quantity of worst-case nature. We also derive various\nbounds on the list-decoding error exponent in both bounded and unbounded\nsettings which are of independent interest beyond multiple packing.",
    "descriptor": "\nComments: The paper arXiv:2107.05161 has been split into three parts with new results added and significant revision. This paper is one of the three parts\n",
    "authors": [
      "Yihan Zhang",
      "Shashank Vatedka"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04408"
  },
  {
    "id": "arXiv:2211.04409",
    "title": "Individualized and Global Feature Attributions for Gradient Boosted  Trees in the Presence of $\\ell_2$ Regularization",
    "abstract": "While $\\ell_2$ regularization is widely used in training gradient boosted\ntrees, popular individualized feature attribution methods for trees such as\nSaabas and TreeSHAP overlook the training procedure. We propose Prediction\nDecomposition Attribution (PreDecomp), a novel individualized feature\nattribution for gradient boosted trees when they are trained with $\\ell_2$\nregularization. Theoretical analysis shows that the inner product between\nPreDecomp and labels on in-sample data is essentially the total gain of a tree,\nand that it can faithfully recover additive models in the population case when\nfeatures are independent. Inspired by the connection between PreDecomp and\ntotal gain, we also propose TreeInner, a family of debiased global feature\nattributions defined in terms of the inner product between any individualized\nfeature attribution and labels on out-sample data for each tree. Numerical\nexperiments on a simulated dataset and a genomic ChIP dataset show that\nTreeInner has state-of-the-art feature selection performance. Code reproducing\nexperiments is available at https://github.com/nalzok/TreeInner .",
    "descriptor": "\nComments: 43 pages, 29 figures\n",
    "authors": [
      "Qingyao Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04409"
  },
  {
    "id": "arXiv:2211.04420",
    "title": "Computational indistinguishability and boson sampling",
    "abstract": "We introduce a computational problem of distinguishing between the output of\nan ideal coarse-grained boson sampler and the output of a true random number\ngenerator, as a resource for cryptographic schemes, which are secure against\ncomputationally unbounded adversaries. Moreover, we define a cryptographic\nsetting for the implementation of such schemes, including message encryption\nand authentication, as well as entity authentication.",
    "descriptor": "",
    "authors": [
      "Georgios M. Nikolopoulos"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04420"
  },
  {
    "id": "arXiv:2211.04422",
    "title": "Black Box Lie Group Preconditioners for SGD",
    "abstract": "A matrix free and a low rank approximation preconditioner are proposed to\naccelerate the convergence of stochastic gradient descent (SGD) by exploiting\ncurvature information sampled from Hessian-vector products or finite\ndifferences of parameters and gradients similar to the BFGS algorithm. Both\npreconditioners are fitted with an online updating manner minimizing a\ncriterion that is free of line search and robust to stochastic gradient noise,\nand further constrained to be on certain connected Lie groups to preserve their\ncorresponding symmetry or invariance, e.g., orientation of coordinates by the\nconnected general linear group with positive determinants. The Lie group's\nequivariance property facilitates preconditioner fitting, and its invariance\nproperty saves any need of damping, which is common in second-order optimizers,\nbut difficult to tune. The learning rate for parameter updating and step size\nfor preconditioner fitting are naturally normalized, and their default values\nwork well in most situations.",
    "descriptor": "\nComments: HOOML 2022\n",
    "authors": [
      "Xilin Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04422"
  },
  {
    "id": "arXiv:2211.04453",
    "title": "Automated discovery of generalized standard material models with EUCLID",
    "abstract": "We extend the scope of our approach for unsupervised automated discovery of\nmaterial laws (EUCLID) to the case of a material belonging to an unknown class\nof behavior. To this end, we leverage the theory of generalized standard\nmaterials, which encompasses a plethora of important constitutive classes. We\nshow that, based only on full-field kinematic measurements and net reaction\nforces, EUCLID is able to automatically discover the two scalar thermodynamic\npotentials, namely, the Helmholtz free energy and the dissipation potential,\nwhich completely define the behavior of generalized standard materials. The a\npriori enforced constraint of convexity on these potentials guarantees by\nconstruction stability and thermodynamic consistency of the discovered model;\nbalance of linear momentum acts as a fundamental constraint to replace the\navailability of stress-strain labeled pairs; sparsity promoting regularization\nenables the automatic selection of a small subset from a possibly large number\nof candidate model features and thus leads to a parsimonious, i.e., simple and\ninterpretable, model. Importantly, since model features go hand in hand with\nthe correspondingly active internal variables, sparse regression automatically\ninduces a parsimonious selection of the few internal variables needed for an\naccurate but simple description of the material behavior. A fully automatic\nprocedure leads to the selection of the hyperparameter controlling the weight\nof the sparsity promoting regularization term, in order to strike a\nuser-defined balance between model accuracy and simplicity. By testing the\nmethod on synthetic data including artificial noise, we demonstrate that EUCLID\nis able to automatically discover the true hidden material model from a large\ncatalog of constitutive classes, including elasticity, viscoelasticity,\nelastoplasticity, viscoplasticity, isotropic and kinematic hardening.",
    "descriptor": "",
    "authors": [
      "Moritz Flaschel",
      "Siddhant Kumar",
      "Laura De Lorenzis"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.04453"
  },
  {
    "id": "arXiv:2211.04465",
    "title": "Quantum Persistent Homology for Time Series",
    "abstract": "Persistent homology, a powerful mathematical tool for data analysis,\nsummarizes the shape of data through tracking topological features across\nchanges in different scales. Classical algorithms for persistent homology are\noften constrained by running times and memory requirements that grow\nexponentially on the number of data points. To surpass this problem, two\nquantum algorithms of persistent homology have been developed based on two\ndifferent approaches. However, both of these quantum algorithms consider a data\nset in the form of a point cloud, which can be restrictive considering that\nmany data sets come in the form of time series. In this paper, we alleviate\nthis issue by establishing a quantum Takens's delay embedding algorithm, which\nturns a time series into a point cloud by considering a pertinent embedding\ninto a higher dimensional space. Having this quantum transformation of time\nseries to point clouds, then one may use a quantum persistent homology\nalgorithm to extract the topological features from the point cloud associated\nwith the original times series.",
    "descriptor": "\nComments: 11 pages, 6 figures, to be published in the ACM/IEEE International Workshop on Quantum Computing conference proceedings\n",
    "authors": [
      "Bernardo Ameneyro",
      "George Siopsis",
      "Vasileios Maroulas"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04465"
  },
  {
    "id": "arXiv:1907.04446",
    "title": "Let's Keep It Safe: Designing User Interfaces that Allow Everyone to  Contribute to AI Safety",
    "abstract": "Comments: The full journal version of this article (published in Proceedings of the ACM on Human-Computer Interaction 4, CSCW2) can be found at this https URL The article is public access",
    "descriptor": "\nComments: The full journal version of this article (published in Proceedings of the ACM on Human-Computer Interaction 4, CSCW2) can be found at this https URL The article is public access\n",
    "authors": [
      "Travis Mandel",
      "Jahnu Best",
      "Randall H. Tanaka",
      "Hiram Temple",
      "Chansen Haili",
      "Kayla Schlectinger",
      "Roy Szeto"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/1907.04446"
  },
  {
    "id": "arXiv:2001.11906",
    "title": "Zeta Functions and the (Linear) Logic of Markov Processes",
    "abstract": "Zeta Functions and the (Linear) Logic of Markov Processes",
    "descriptor": "",
    "authors": [
      "Thomas Seiller"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Dynamical Systems (math.DS)",
      "Logic (math.LO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2001.11906"
  },
  {
    "id": "arXiv:2002.03391",
    "title": "Message Type Identification of Binary Network Protocols using Continuous  Segment Similarity",
    "abstract": "Comments: 11 pages, 4 figures",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Stephan Kleber",
      "Rens Wouter van der Heijden",
      "Frank Kargl"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2002.03391"
  },
  {
    "id": "arXiv:2007.12823",
    "title": "Improved Analysis of RANKING for Online Vertex-Weighted Bipartite  Matching in the Random Order Model",
    "abstract": "Comments: 23 pages, 7 figures",
    "descriptor": "\nComments: 23 pages, 7 figures\n",
    "authors": [
      "Billy Jin",
      "David P. Williamson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2007.12823"
  },
  {
    "id": "arXiv:2008.09790",
    "title": "On the Hill relation and the mean reaction time for metastable processes",
    "abstract": "On the Hill relation and the mean reaction time for metastable processes",
    "descriptor": "",
    "authors": [
      "Manon Baudel",
      "Arnaud Guyader",
      "Tony Leli\u00e8vre"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.09790"
  },
  {
    "id": "arXiv:2011.11258",
    "title": "Approximation of a Multivariate Function of Bounded Variation from its  Scattered Data",
    "abstract": "Comments: 50 pages",
    "descriptor": "\nComments: 50 pages\n",
    "authors": [
      "Rajesh Dachiraju"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2011.11258"
  },
  {
    "id": "arXiv:2101.08879",
    "title": "Privacy-Preserving and Efficient Verification of the Outcome in  Genome-Wide Association Studies",
    "abstract": "Comments: Appeared in the Proceedings on Privacy Enhancing Technologies Symposium (PETS) 2022",
    "descriptor": "\nComments: Appeared in the Proceedings on Privacy Enhancing Technologies Symposium (PETS) 2022\n",
    "authors": [
      "Anisa Halimi",
      "Leonard Dervishi",
      "Erman Ayday",
      "Apostolos Pyrgelis",
      "Juan Ramon Troncoso-Pastoriza",
      "Jean-Pierre Hubaux",
      "Xiaoqian Jiang",
      "Jaideep Vaidya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2101.08879"
  },
  {
    "id": "arXiv:2102.00463",
    "title": "PV-RCNN++: Point-Voxel Feature Set Abstraction With Local Vector  Representation for 3D Object Detection",
    "abstract": "Comments: Accepted by International Journal of Computer Vision (IJCV), code is available at this https URL",
    "descriptor": "\nComments: Accepted by International Journal of Computer Vision (IJCV), code is available at this https URL\n",
    "authors": [
      "Shaoshuai Shi",
      "Li Jiang",
      "Jiajun Deng",
      "Zhe Wang",
      "Chaoxu Guo",
      "Jianping Shi",
      "Xiaogang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.00463"
  },
  {
    "id": "arXiv:2102.09029",
    "title": "Joint Continuous and Discrete Model Selection via Submodularity",
    "abstract": "Comments: 32 pages, 4 figures. Revised statement on polynomial-time solvability implications",
    "descriptor": "\nComments: 32 pages, 4 figures. Revised statement on polynomial-time solvability implications\n",
    "authors": [
      "Jonathan Bunton",
      "Paulo Tabuada"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.09029"
  },
  {
    "id": "arXiv:2103.16997",
    "title": "UA-GEC: Grammatical Error Correction and Fluency Corpus for the  Ukrainian Language",
    "abstract": "Comments: See this https URL for the dataset. Version 2 of the data is in progress",
    "descriptor": "\nComments: See this https URL for the dataset. Version 2 of the data is in progress\n",
    "authors": [
      "Oleksiy Syvokon",
      "Olena Nahorna"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.16997"
  },
  {
    "id": "arXiv:2104.05512",
    "title": "One-shot learning for solution operators of partial differential  equations",
    "abstract": "One-shot learning for solution operators of partial differential  equations",
    "descriptor": "",
    "authors": [
      "Anran Jiao",
      "Haiyang He",
      "Rishikesh Ranade",
      "Jay Pathak",
      "Lu Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.05512"
  },
  {
    "id": "arXiv:2104.10553",
    "title": "Rethinking Annotation Granularity for Overcoming Shortcuts in Deep  Learning-based Radiograph Diagnosis: A Multicenter Study",
    "abstract": "Comments: Radiology: Artificial Intelligence",
    "descriptor": "\nComments: Radiology: Artificial Intelligence\n",
    "authors": [
      "Luyang Luo",
      "Hao Chen",
      "Yongjie Xiao",
      "Yanning Zhou",
      "Xi Wang",
      "Varut Vardhanabhuti",
      "Mingxiang Wu",
      "Chu Han",
      "Zaiyi Liu",
      "Xin Hao Benjamin Fang",
      "Efstratios Tsougenis",
      "Huangjing Lin",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10553"
  },
  {
    "id": "arXiv:2106.04037",
    "title": "Online Algorithms for Network Robustness under Connectivity Constraints",
    "abstract": "Online Algorithms for Network Robustness under Connectivity Constraints",
    "descriptor": "",
    "authors": [
      "Deepan Muthirayan",
      "Pramod P. Khargonekar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.04037"
  },
  {
    "id": "arXiv:2106.15516",
    "title": "Geometry-aware Transformer for molecular property prediction",
    "abstract": "Comments: 14 pages, 5 figures",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Bumju Kwak",
      "Jeonghee Jo",
      "Byunghan Lee",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.15516"
  },
  {
    "id": "arXiv:2107.00281",
    "title": "Scientia Potentia Est -- On the Role of Knowledge in Computational  Argumentation",
    "abstract": "Comments: Accepted for publication in TACL",
    "descriptor": "\nComments: Accepted for publication in TACL\n",
    "authors": [
      "Anne Lauscher",
      "Henning Wachsmuth",
      "Iryna Gurevych",
      "Goran Glava\u0161"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.00281"
  },
  {
    "id": "arXiv:2107.10867",
    "title": "A local approach to parameter space reduction for regression and  classification tasks",
    "abstract": "A local approach to parameter space reduction for regression and  classification tasks",
    "descriptor": "",
    "authors": [
      "Francesco Romor",
      "Marco Tezzele",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.10867"
  },
  {
    "id": "arXiv:2108.02551",
    "title": "Ensemble Consensus-based Representation Deep Reinforcement Learning for  Hybrid FSO/RF Communication Systems",
    "abstract": "Comments: Number of pages 16 and number of figures 15, Unpublished work, accepted",
    "descriptor": "\nComments: Number of pages 16 and number of figures 15, Unpublished work, accepted\n",
    "authors": [
      "Shagufta Henna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02551"
  },
  {
    "id": "arXiv:2108.05857",
    "title": "How Optimal is Greedy Decoding for Extractive Question Answering?",
    "abstract": "Comments: AKBC 2022 12 pages, 3 figures",
    "descriptor": "\nComments: AKBC 2022 12 pages, 3 figures\n",
    "authors": [
      "Or Castel",
      "Ori Ram",
      "Avia Efrat",
      "Omer Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.05857"
  },
  {
    "id": "arXiv:2108.06688",
    "title": "Complex Knowledge Base Question Answering: A Survey",
    "abstract": "Comments: 20 pages, 4 tables, 7 figures. arXiv admin note: text overlap with arXiv:2105.11644",
    "descriptor": "\nComments: 20 pages, 4 tables, 7 figures. arXiv admin note: text overlap with arXiv:2105.11644\n",
    "authors": [
      "Yunshi Lan",
      "Gaole He",
      "Jinhao Jiang",
      "Jing Jiang",
      "Wayne Xin Zhao",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.06688"
  },
  {
    "id": "arXiv:2108.11580",
    "title": "Learning Partial Differential Equations in Reproducing Kernel Hilbert  Spaces",
    "abstract": "Comments: 72 pages, 10 figures",
    "descriptor": "\nComments: 72 pages, 10 figures\n",
    "authors": [
      "George Stepaniants"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.11580"
  },
  {
    "id": "arXiv:2109.12736",
    "title": "Hardness of Graph-Structured Algebraic and Symbolic Problems",
    "abstract": "Comments: 57 pages, submitted version to STOC23",
    "descriptor": "\nComments: 57 pages, submitted version to STOC23\n",
    "authors": [
      "Jingbang Chen",
      "Yu Gao",
      "Yufan Huang",
      "Richard Peng",
      "Runze Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.12736"
  },
  {
    "id": "arXiv:2109.14855",
    "title": "Sim2Real for Soft Robotic Fish via Differentiable Simulation",
    "abstract": "Comments: Published at IROS 2022. 8 pages, 9 figures",
    "descriptor": "\nComments: Published at IROS 2022. 8 pages, 9 figures\n",
    "authors": [
      "John Z. Zhang",
      "Yu Zhang",
      "Pingchuan Ma",
      "Elvis Nava",
      "Tao Du",
      "Philip Arm",
      "Wojciech Matusik",
      "Robert K. Katzschmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.14855"
  },
  {
    "id": "arXiv:2110.00976",
    "title": "LexGLUE: A Benchmark Dataset for Legal Language Understanding in English",
    "abstract": "Comments: 9 pages, long paper at ACL 2022 proceedings. LexGLUE benchmark is available at: this https URL Code is available at: this https URL Update TFIDF-SVM scores in the last version",
    "descriptor": "\nComments: 9 pages, long paper at ACL 2022 proceedings. LexGLUE benchmark is available at: this https URL Code is available at: this https URL Update TFIDF-SVM scores in the last version\n",
    "authors": [
      "Ilias Chalkidis",
      "Abhik Jana",
      "Dirk Hartung",
      "Michael Bommarito",
      "Ion Androutsopoulos",
      "Daniel Martin Katz",
      "Nikolaos Aletras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.00976"
  },
  {
    "id": "arXiv:2110.03877",
    "title": "Designing the Architecture of a Convolutional Neural Network  Automatically for Diabetic Retinopathy Diagnosis",
    "abstract": "Comments: 20 pages, 6 figures",
    "descriptor": "\nComments: 20 pages, 6 figures\n",
    "authors": [
      "Fahman Saeed",
      "Muhammad Hussain",
      "Hatim A Aboalsamh",
      "Fadwa Al Adel",
      "Adi Mohammed Al Owaifeer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03877"
  },
  {
    "id": "arXiv:2110.11851",
    "title": "Voting algorithms for unique games on complete graphs",
    "abstract": "Voting algorithms for unique games on complete graphs",
    "descriptor": "",
    "authors": [
      "Antoine M\u00e9ot",
      "Arnaud de Mesmay",
      "Moritz M\u00fchlenthaler",
      "Alantha Newman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.11851"
  },
  {
    "id": "arXiv:2111.00341",
    "title": "Causal Discovery in Linear Structural Causal Models with Deterministic  Relations",
    "abstract": "Comments: Accepted at 1st Conference on Causal Learning and Reasoning (CLeaR 2022)",
    "descriptor": "\nComments: Accepted at 1st Conference on Causal Learning and Reasoning (CLeaR 2022)\n",
    "authors": [
      "Yuqin Yang",
      "Mohamed Nafea",
      "AmirEmad Ghassami",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00341"
  },
  {
    "id": "arXiv:2111.02295",
    "title": "The Parameterized Complexity of the Survivable Network Design Problem",
    "abstract": "The Parameterized Complexity of the Survivable Network Design Problem",
    "descriptor": "",
    "authors": [
      "Andreas Emil Feldmann",
      "Anish Mukherjee",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.02295"
  },
  {
    "id": "arXiv:2111.02719",
    "title": "SPEEDEX: A Scalable, Parallelizable, and Economically Efficient Digital  EXchange",
    "abstract": "Comments: 22 pages, 5 figures",
    "descriptor": "\nComments: 22 pages, 5 figures\n",
    "authors": [
      "Geoffrey Ramseyer",
      "Ashish Goel",
      "David Mazi\u00e8res"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.02719"
  },
  {
    "id": "arXiv:2111.03559",
    "title": "Computability and Beltrami fields in Euclidean space",
    "abstract": "Comments: overall improvement of the article, proofs revised, 37 pages, 3 figures, final version to appear at J. Math. Pures Appl",
    "descriptor": "\nComments: overall improvement of the article, proofs revised, 37 pages, 3 figures, final version to appear at J. Math. Pures Appl\n",
    "authors": [
      "Robert Cardona",
      "Eva Miranda",
      "Daniel Peralta-Salas"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Computational Complexity (cs.CC)",
      "Mathematical Physics (math-ph)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.03559"
  },
  {
    "id": "arXiv:2111.08030",
    "title": "Fast and Credible Likelihood-Free Cosmology with Truncated Marginal  Neural Ratio Estimation",
    "abstract": "Comments: v2: accepted journal version. v1: 37 pages, 13 figures. \\texttt{swyft} is available at this https URL, and demonstration code for cosmological examples is available at this https URL",
    "descriptor": "\nComments: v2: accepted journal version. v1: 37 pages, 13 figures. \\texttt{swyft} is available at this https URL, and demonstration code for cosmological examples is available at this https URL\n",
    "authors": [
      "Alex Cole",
      "Benjamin Kurt Miller",
      "Samuel J. Witte",
      "Maxwell X. Cai",
      "Meiert W. Grootes",
      "Francesco Nattino",
      "Christoph Weniger"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08030"
  },
  {
    "id": "arXiv:2111.08712",
    "title": "Automatic Semantic Segmentation of the Lumbar Spine: Clinical  Applicability in a Multi-parametric and Multi-centre Study on Magnetic  Resonance Images",
    "abstract": "Comments: 19 pages, 9 Figures, 8 Tables; Supplementary Material: 6 pages, 8 Tables",
    "descriptor": "\nComments: 19 pages, 9 Figures, 8 Tables; Supplementary Material: 6 pages, 8 Tables\n",
    "authors": [
      "Jhon Jairo Saenz-Gamboa",
      "Julio Domenech",
      "Antonio Alonso-Manjarr\u00e9s",
      "Jon A. G\u00f3mez",
      "Maria de la Iglesia-Vay\u00e1"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08712"
  },
  {
    "id": "arXiv:2111.10491",
    "title": "Malicious Selling Strategies in E-Commerce Livestream: A Case Study of  Alibaba's Taobao and ByteDance's TikTok",
    "abstract": "Malicious Selling Strategies in E-Commerce Livestream: A Case Study of  Alibaba's Taobao and ByteDance's TikTok",
    "descriptor": "",
    "authors": [
      "Qunfang Wu",
      "Yisi Sang",
      "Dakuo Wang",
      "Zhicong Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.10491"
  },
  {
    "id": "arXiv:2112.01898",
    "title": "Linear algebra with transformers",
    "abstract": "Comments: Transactions in Machine Learning Research (TMLR), October 2022",
    "descriptor": "\nComments: Transactions in Machine Learning Research (TMLR), October 2022\n",
    "authors": [
      "Fran\u00e7ois Charton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.01898"
  },
  {
    "id": "arXiv:2112.08345",
    "title": "Reliable Multi-Object Tracking in the Presence of Unreliable Detections",
    "abstract": "Comments: The full journal version of this article (published in Pattern Recognition, Vol. 135) can be found at this https URL The article is open access. The source code and dataset can be found at this https URL",
    "descriptor": "\nComments: The full journal version of this article (published in Pattern Recognition, Vol. 135) can be found at this https URL The article is open access. The source code and dataset can be found at this https URL\n",
    "authors": [
      "Travis Mandel",
      "Mark Jimenez",
      "Emily Risley",
      "Taishi Nammoto",
      "Rebekka Williams",
      "Max Panoff",
      "Meynard Ballesteros",
      "Bobbie Suarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08345"
  },
  {
    "id": "arXiv:2202.02031",
    "title": "Complex-to-Real Random Features for Polynomial Kernels",
    "abstract": "Comments: 33 pages",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Jonas Wacker",
      "Ruben Ohana",
      "Maurizio Filippone"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.02031"
  },
  {
    "id": "arXiv:2202.04966",
    "title": "Real-Time Siamese Multiple Object Tracker with Enhanced Proposals",
    "abstract": "Comments: Accepted at Pattern Recognition. Code available at this https URL",
    "descriptor": "\nComments: Accepted at Pattern Recognition. Code available at this https URL\n",
    "authors": [
      "Lorenzo Vaquero",
      "V\u00edctor M. Brea",
      "Manuel Mucientes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04966"
  },
  {
    "id": "arXiv:2202.05691",
    "title": "A Tight $(1.5+\u03b5)$-Approximation for Unsplittable Capacitated  Vehicle Routing on Trees",
    "abstract": "A Tight $(1.5+\u03b5)$-Approximation for Unsplittable Capacitated  Vehicle Routing on Trees",
    "descriptor": "",
    "authors": [
      "Claire Mathieu",
      "Hang Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.05691"
  },
  {
    "id": "arXiv:2202.07228",
    "title": "Leveraging the Learnable Vertex-Vertex Relationship to Generalize Human  Pose and Mesh Reconstruction for In-the-Wild Scenes",
    "abstract": "Leveraging the Learnable Vertex-Vertex Relationship to Generalize Human  Pose and Mesh Reconstruction for In-the-Wild Scenes",
    "descriptor": "",
    "authors": [
      "Trung Tran-Quang",
      "Cuong Than-Cao",
      "Hai Nguyen-Thanh",
      "Hong Hoang Si"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07228"
  },
  {
    "id": "arXiv:2202.10517",
    "title": "Individualized PATE: Differentially Private Machine Learning with  Individual Privacy Guarantees",
    "abstract": "Comments: accepted for publication at PoPETs'23",
    "descriptor": "\nComments: accepted for publication at PoPETs'23\n",
    "authors": [
      "Franziska Boenisch",
      "Christopher M\u00fchl",
      "Roy Rinberg",
      "Jannis Ihrig",
      "Adam Dziedzic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.10517"
  },
  {
    "id": "arXiv:2203.00872",
    "title": "Centralized Fairness for Redistricting",
    "abstract": "Centralized Fairness for Redistricting",
    "descriptor": "",
    "authors": [
      "Seyed A. Esmaeili",
      "Darshan Chakrabarti",
      "Hayley Grape",
      "Brian Brubach"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.00872"
  },
  {
    "id": "arXiv:2203.01327",
    "title": "Hyperspectral Pixel Unmixing with Latent Dirichlet Variational  Autoencoder",
    "abstract": "Hyperspectral Pixel Unmixing with Latent Dirichlet Variational  Autoencoder",
    "descriptor": "",
    "authors": [
      "Kiran Mantripragada",
      "Faisal Z. Qureshi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01327"
  },
  {
    "id": "arXiv:2203.03907",
    "title": "On a Simple Connection Between $\u0394$-modular ILP and LP, and a New  Bound on the Number of Integer Vertices",
    "abstract": "On a Simple Connection Between $\u0394$-modular ILP and LP, and a New  Bound on the Number of Integer Vertices",
    "descriptor": "",
    "authors": [
      "D. V. Gribanov",
      "D. S. Malyshev",
      "I. A. Shumilov"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.03907"
  },
  {
    "id": "arXiv:2203.04895",
    "title": "Joint Learning of Salient Object Detection, Depth Estimation and Contour  Extraction",
    "abstract": "Comments: Accepted by IEEE TIP",
    "descriptor": "\nComments: Accepted by IEEE TIP\n",
    "authors": [
      "Xiaoqi Zhao",
      "Youwei Pang",
      "Lihe Zhang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04895"
  },
  {
    "id": "arXiv:2203.08161",
    "title": "Sensitivity Estimation for Dark Matter Subhalos in Synthetic Gaia DR2  using Deep Learning",
    "abstract": "Comments: 13 pages, 8 figures, 1 table. Accepted for publication in Astronomy and Computing",
    "descriptor": "\nComments: 13 pages, 8 figures, 1 table. Accepted for publication in Astronomy and Computing\n",
    "authors": [
      "Abdullah Bazarov",
      "Mar\u00eda Benito",
      "Gert H\u00fctsi",
      "Rain Kipper",
      "Joosep Pata",
      "Sven P\u00f5der"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.08161"
  },
  {
    "id": "arXiv:2203.10850",
    "title": "Automatic Creation of High-Bandwidth Memory Architectures from  Domain-Specific Languages: The Case of Computational Fluid Dynamics",
    "abstract": "Comments: Accepted for publication in ACM Transactions on Reconfigurable Technology and Systems (TRETS)",
    "descriptor": "\nComments: Accepted for publication in ACM Transactions on Reconfigurable Technology and Systems (TRETS)\n",
    "authors": [
      "Stephanie Soldavini",
      "Karl F. A. Friebel",
      "Mattia Tibaldi",
      "Gerald Hempel",
      "Jeronimo Castrillon",
      "Christian Pilato"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.10850"
  },
  {
    "id": "arXiv:2203.14889",
    "title": "LOCAT: Low-Overhead Online Configuration Auto-Tuning of Spark SQL  Applications",
    "abstract": "Comments: 16 pages, 21 figures, SIGMOD '22. This arxiv version is an extended version of the SIGMOD '22 paper with same title, allowed by conference chairs",
    "descriptor": "\nComments: 16 pages, 21 figures, SIGMOD '22. This arxiv version is an extended version of the SIGMOD '22 paper with same title, allowed by conference chairs\n",
    "authors": [
      "Jinhan Xin",
      "Kai Hwang",
      "Zhibin Yu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.14889"
  },
  {
    "id": "arXiv:2203.17006",
    "title": "Quantum simulation of real-space dynamics",
    "abstract": "Quantum simulation of real-space dynamics",
    "descriptor": "",
    "authors": [
      "Andrew M. Childs",
      "Jiaqi Leng",
      "Tongyang Li",
      "Jin-Peng Liu",
      "Chenyi Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.17006"
  },
  {
    "id": "arXiv:2204.00480",
    "title": "Simulator-based explanation and debugging of hazard-triggering events in  DNN-based safety-critical systems",
    "abstract": "Comments: 48 pages, 15 figures, 20 tables",
    "descriptor": "\nComments: 48 pages, 15 figures, 20 tables\n",
    "authors": [
      "Hazem Fahmy",
      "Fabrizio Pastore",
      "Lionel Briand",
      "Thomas Stifter"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.00480"
  },
  {
    "id": "arXiv:2204.01368",
    "title": "Training Fully Connected Neural Networks is $\\exists\\mathbb{R}$-Complete",
    "abstract": "Comments: 41 pages, 18 figures. Changes in version 2: Added algebraic universality result, improved interpretation of results",
    "descriptor": "\nComments: 41 pages, 18 figures. Changes in version 2: Added algebraic universality result, improved interpretation of results\n",
    "authors": [
      "Daniel Bertschinger",
      "Christoph Hertrich",
      "Paul Jungeblut",
      "Tillmann Miltzow",
      "Simon Weber"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.01368"
  },
  {
    "id": "arXiv:2204.07122",
    "title": "MIMO Channel Estimation using Score-Based Generative Models",
    "abstract": "MIMO Channel Estimation using Score-Based Generative Models",
    "descriptor": "",
    "authors": [
      "Marius Arvinte",
      "Jonathan I Tamir"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07122"
  },
  {
    "id": "arXiv:2204.07657",
    "title": "Accurate detection of sepsis at ED triage using machine learning with  clinical natural language processing",
    "abstract": "Comments: 38 pages, 2 figure, 6 tables, 7 supplementary tables",
    "descriptor": "\nComments: 38 pages, 2 figure, 6 tables, 7 supplementary tables\n",
    "authors": [
      "Oleksandr Ivanov",
      "Karin Molander",
      "Robert Dunne",
      "Stephen Liu",
      "Kevin Masek",
      "Erica Lewis",
      "Deena Brecher",
      "Lisa Wolf",
      "Debbie Travers",
      "Deb Delaney",
      "Kyla Montgomery",
      "Christian Reilly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07657"
  },
  {
    "id": "arXiv:2204.12451",
    "title": "Understanding The Robustness in Vision Transformers",
    "abstract": "Understanding The Robustness in Vision Transformers",
    "descriptor": "",
    "authors": [
      "Daquan Zhou",
      "Zhiding Yu",
      "Enze Xie",
      "Chaowei Xiao",
      "Anima Anandkumar",
      "Jiashi Feng",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.12451"
  },
  {
    "id": "arXiv:2204.12749",
    "title": "Control Globally, Understand Locally: A Global-to-Local Hierarchical  Graph Network for Emotional Support Conversation",
    "abstract": "Comments: Accepted by IJCAI,2022",
    "descriptor": "\nComments: Accepted by IJCAI,2022\n",
    "authors": [
      "Wei Peng",
      "Yue Hu",
      "Luxi Xing",
      "Yuqiang Xie",
      "Yajing Sun",
      "Yunpeng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.12749"
  },
  {
    "id": "arXiv:2204.13366",
    "title": "Semantic Information Retrieval in Wireless Networks",
    "abstract": "Comments: Submitted for peer review",
    "descriptor": "\nComments: Submitted for peer review\n",
    "authors": [
      "Edgar Beck",
      "Carsten Bockelmann",
      "Armin Dekorsy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.13366"
  },
  {
    "id": "arXiv:2204.13827",
    "title": "PRETRUST: A Framework for Fast Payments in Blockchain Systems",
    "abstract": "Comments: 10 pages, 1 figure,",
    "descriptor": "\nComments: 10 pages, 1 figure,\n",
    "authors": [
      "Huapeng Li",
      "Baocheng Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.13827"
  },
  {
    "id": "arXiv:2205.00158",
    "title": "AnimalTrack: A Benchmark for Multi-Animal Tracking in the Wild",
    "abstract": "Comments: Tech. report",
    "descriptor": "\nComments: Tech. report\n",
    "authors": [
      "Libo Zhang",
      "Junyuan Gao",
      "Zhen Xiao",
      "Heng Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.00158"
  },
  {
    "id": "arXiv:2205.02613",
    "title": "Exploiting Global and Local Hierarchies for Hierarchical Text  Classification",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Ting Jiang",
      "Deqing Wang",
      "Leilei Sun",
      "Zhongzhi Chen",
      "Fuzhen Zhuang",
      "Qinghong Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02613"
  },
  {
    "id": "arXiv:2205.03570",
    "title": "Iteration Complexity of an Infeasible Interior Point Methods for  Seconder-order Cone Programming and its Warmstarting",
    "abstract": "Iteration Complexity of an Infeasible Interior Point Methods for  Seconder-order Cone Programming and its Warmstarting",
    "descriptor": "",
    "authors": [
      "Yushu Chen",
      "Guangwen Yang",
      "Lu Wang",
      "Qingzhong Gan",
      "Haipeng Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2205.03570"
  },
  {
    "id": "arXiv:2205.04745",
    "title": "PaCHash: Packed and Compressed Hash Tables",
    "abstract": "PaCHash: Packed and Compressed Hash Tables",
    "descriptor": "",
    "authors": [
      "Florian Kurpicz",
      "Hans-Peter Lehmann",
      "Peter Sanders"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.04745"
  },
  {
    "id": "arXiv:2205.06764",
    "title": "What do we mean by \"data\"? A proposed classification of data types in  the arts and humanities",
    "abstract": "What do we mean by \"data\"? A proposed classification of data types in  the arts and humanities",
    "descriptor": "",
    "authors": [
      "Bianca Gualandi",
      "Luca Pareschi",
      "Silvio Peroni"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2205.06764"
  },
  {
    "id": "arXiv:2205.12113",
    "title": "The Curious Case of Control",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Elias Stengel-Eskin",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12113"
  },
  {
    "id": "arXiv:2205.12228",
    "title": "When More Data Hurts: A Troubling Quirk in Developing Broad-Coverage  Natural Language Understanding Systems",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Elias Stengel-Eskin",
      "Emmanouil Antonios Platanios",
      "Adam Pauls",
      "Sam Thomson",
      "Hao Fang",
      "Benjamin Van Durme",
      "Jason Eisner",
      "Yu Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12228"
  },
  {
    "id": "arXiv:2205.12558",
    "title": "Gradient-Based Constrained Sampling from Language Models",
    "abstract": "Gradient-Based Constrained Sampling from Language Models",
    "descriptor": "",
    "authors": [
      "Sachin Kumar",
      "Biswajit Paria",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12558"
  },
  {
    "id": "arXiv:2205.12598",
    "title": "RobustLR: Evaluating Robustness to Logical Perturbation in Deductive  Reasoning",
    "abstract": "Comments: Accpeted at EMNLP 2022, code available at this https URL",
    "descriptor": "\nComments: Accpeted at EMNLP 2022, code available at this https URL\n",
    "authors": [
      "Soumya Sanyal",
      "Zeyi Liao",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2205.12598"
  },
  {
    "id": "arXiv:2205.13492",
    "title": "Sparse Graph Learning from Spatiotemporal Time Series",
    "abstract": "Comments: updated and extended version",
    "descriptor": "\nComments: updated and extended version\n",
    "authors": [
      "Andrea Cini",
      "Daniele Zambon",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.13492"
  },
  {
    "id": "arXiv:2205.13662",
    "title": "Explaining Preferences with Shapley Values",
    "abstract": "Explaining Preferences with Shapley Values",
    "descriptor": "",
    "authors": [
      "Robert Hu",
      "Siu Lun Chau",
      "Jaime Ferrando Huertas",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2205.13662"
  },
  {
    "id": "arXiv:2205.15670",
    "title": "REF: A Rapid Exploration Framework for Deploying Autonomous MAVs in  Unknown Environments",
    "abstract": "REF: A Rapid Exploration Framework for Deploying Autonomous MAVs in  Unknown Environments",
    "descriptor": "",
    "authors": [
      "Akash Patel",
      "Bj\u00f6rn Lindqvist",
      "Christoforos Kanellakis",
      "Ali-akbar Agha-mohammadi",
      "George Nikolakopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15670"
  },
  {
    "id": "arXiv:2206.00897",
    "title": "xView3-SAR: Detecting Dark Fishing Activity Using Synthetic Aperture  Radar Imagery",
    "abstract": "Comments: Accepted to NeurIPS 2022. 10 pages (25 with references and supplement)",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. 10 pages (25 with references and supplement)\n",
    "authors": [
      "Fernando Paolo",
      "Tsu-ting Tim Lin",
      "Ritwik Gupta",
      "Bryce Goodman",
      "Nirav Patel",
      "Daniel Kuster",
      "David Kroodsma",
      "Jared Dunnmon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00897"
  },
  {
    "id": "arXiv:2206.01802",
    "title": "Do-Operation Guided Causal Representation Learning with Reduced  Supervision Strength",
    "abstract": "Comments: NeurIPS 2022 Workshop CML4Impact Workshop Camera Ready",
    "descriptor": "\nComments: NeurIPS 2022 Workshop CML4Impact Workshop Camera Ready\n",
    "authors": [
      "Jiageng Zhu",
      "Hanchen Xie",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.01802"
  },
  {
    "id": "arXiv:2206.02043",
    "title": "UAV-Aided Multi-Community Federated Learning",
    "abstract": "Comments: Accepted to be presented at GLOBECOM 2022, IEEE Global Communications Conference: Selected Areas in Communications: Aerial Communications (Globecom 2022 SAC AC)\", 4-8 December 2022, Rio de Janeiro, Brazil",
    "descriptor": "\nComments: Accepted to be presented at GLOBECOM 2022, IEEE Global Communications Conference: Selected Areas in Communications: Aerial Communications (Globecom 2022 SAC AC)\", 4-8 December 2022, Rio de Janeiro, Brazil\n",
    "authors": [
      "Mohamad Mestoukirdi",
      "Omid Esrafilian",
      "David Gesbert",
      "Qianrui Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02043"
  },
  {
    "id": "arXiv:2206.02768",
    "title": "The Neural Covariance SDE: Shaped Infinite Depth-and-Width Networks at  Initialization",
    "abstract": "Comments: 48 pages, 10 figures. To appear, Advances in Neural Information Processing Systems (2022)",
    "descriptor": "\nComments: 48 pages, 10 figures. To appear, Advances in Neural Information Processing Systems (2022)\n",
    "authors": [
      "Mufan Bill Li",
      "Mihai Nica",
      "Daniel M. Roy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02768"
  },
  {
    "id": "arXiv:2206.03093",
    "title": "Beyond spectral gap: The role of the topology in decentralized learning",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Thijs Vogels",
      "Hadrien Hendrikx",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03093"
  },
  {
    "id": "arXiv:2206.04046",
    "title": "Sparse Mixture-of-Experts are Domain Generalizable Learners",
    "abstract": "Comments: remake preprint version",
    "descriptor": "\nComments: remake preprint version\n",
    "authors": [
      "Bo Li",
      "Yifei Shen",
      "Jingkang Yang",
      "Yezhen Wang",
      "Jiawei Ren",
      "Tong Che",
      "Jun Zhang",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04046"
  },
  {
    "id": "arXiv:2206.06004",
    "title": "A Novel Multi-Layer Modular Approach for Real-Time Gravitational-Wave  Detection",
    "abstract": "A Novel Multi-Layer Modular Approach for Real-Time Gravitational-Wave  Detection",
    "descriptor": "",
    "authors": [
      "Francesco Pio Barone",
      "Daniele Dell'Aquila",
      "Marco Russo"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06004"
  },
  {
    "id": "arXiv:2206.06178",
    "title": "EGRU: Event-based GRU for activity-sparse inference and learning",
    "abstract": "EGRU: Event-based GRU for activity-sparse inference and learning",
    "descriptor": "",
    "authors": [
      "Anand Subramoney",
      "Khaleelulla Khan Nazeer",
      "Mark Sch\u00f6ne",
      "Christian Mayr",
      "David Kappel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06178"
  },
  {
    "id": "arXiv:2206.07348",
    "title": "Unsupervised multi-branch Capsule for Hyperspectral and LiDAR  classification",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Quanfeng Xu",
      "Yi Tang",
      "Yumei She"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07348"
  },
  {
    "id": "arXiv:2206.07922",
    "title": "Challenges and Opportunities in Deep Reinforcement Learning with Graph  Neural Networks: A Comprehensive review of Algorithms and Applications",
    "abstract": "Comments: 20 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 20 pages, 3 figures, 2 tables\n",
    "authors": [
      "Sai Munikoti",
      "Deepesh Agarwal",
      "Laya Das",
      "Mahantesh Halappanavar",
      "Balasubramaniam Natarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07922"
  },
  {
    "id": "arXiv:2206.10098",
    "title": "Reconstruct from BEV: A 3D Lane Detection Approach based on Geometry  Structure Prior",
    "abstract": "Reconstruct from BEV: A 3D Lane Detection Approach based on Geometry  Structure Prior",
    "descriptor": "",
    "authors": [
      "Chenguang Li",
      "Jia Shi",
      "Ya Wang",
      "Guangliang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10098"
  },
  {
    "id": "arXiv:2206.12063",
    "title": "Mutual Information-guided Knowledge Transfer for Novel Class Discovery",
    "abstract": "Comments: The derivation of Mutual Information in the manuscript is wrong",
    "descriptor": "\nComments: The derivation of Mutual Information in the manuscript is wrong\n",
    "authors": [
      "Chuyu Zhang",
      "Chuanyang Hu",
      "Ruijie Xu",
      "Zhitong Gao",
      "Qian He",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.12063"
  },
  {
    "id": "arXiv:2207.03333",
    "title": "FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments",
    "abstract": "FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments",
    "descriptor": "",
    "authors": [
      "Jishnu Jaykumar P",
      "Yu-Wei Chao",
      "Yu Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.03333"
  },
  {
    "id": "arXiv:2207.03361",
    "title": "Prophet Inequalities via the Expected Competitive Ratio",
    "abstract": "Prophet Inequalities via the Expected Competitive Ratio",
    "descriptor": "",
    "authors": [
      "Tomer Ezra",
      "Stefano Leonardi",
      "Rebecca Reiffenh\u00e4user",
      "Matteo Russo",
      "Alexandros Tsigonias-Dimitriadis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2207.03361"
  },
  {
    "id": "arXiv:2207.07809",
    "title": "Curve Simplification and Clustering under Fr\u00e9chet Distance",
    "abstract": "Comments: 30 pages; Corrected some wrong descriptions concerning related work; Add some figures for illustration",
    "descriptor": "\nComments: 30 pages; Corrected some wrong descriptions concerning related work; Add some figures for illustration\n",
    "authors": [
      "Siu-Wing Cheng",
      "Haoqiang Huang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.07809"
  },
  {
    "id": "arXiv:2207.07974",
    "title": "Online Prediction in Sub-linear Space",
    "abstract": "Online Prediction in Sub-linear Space",
    "descriptor": "",
    "authors": [
      "Binghui Peng",
      "Fred Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.07974"
  },
  {
    "id": "arXiv:2207.09102",
    "title": "Complexity of High-Dimensional Identity Testing with Coordinate  Conditional Sampling",
    "abstract": "Complexity of High-Dimensional Identity Testing with Coordinate  Conditional Sampling",
    "descriptor": "",
    "authors": [
      "Antonio Blanca",
      "Zongchen Chen",
      "Daniel \u0160tefankovi\u010d",
      "Eric Vigoda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.09102"
  },
  {
    "id": "arXiv:2207.10175",
    "title": "Optimization-Based Reference Generator for Nonlinear Model Predictive  Control of Legged Robots",
    "abstract": "Optimization-Based Reference Generator for Nonlinear Model Predictive  Control of Legged Robots",
    "descriptor": "",
    "authors": [
      "Angelo Bratta",
      "Michele Focchi",
      "Niraj Rathod",
      "Mario Zanon",
      "Alberto Bemporad",
      "Claudio Semini"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10175"
  },
  {
    "id": "arXiv:2207.11211",
    "title": "Improving Predictive Performance and Calibration by Weight Fusion in  Semantic Segmentation",
    "abstract": "Improving Predictive Performance and Calibration by Weight Fusion in  Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Timo S\u00e4mann",
      "Ahmed Mostafa Hammam",
      "Andrei Bursuc",
      "Christoph Stiller",
      "Horst-Michael Gro\u00df"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11211"
  },
  {
    "id": "arXiv:2207.12062",
    "title": "Adaptive Asynchronous Control using Meta-learned Neural Ordinary  Differential Equations",
    "abstract": "Comments: 19 pages, 8 figures, 4 algorithms, 3 tables",
    "descriptor": "\nComments: 19 pages, 8 figures, 4 algorithms, 3 tables\n",
    "authors": [
      "Achkan Salehi",
      "Steffen R\u00fchl",
      "Stephane Doncieux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.12062"
  },
  {
    "id": "arXiv:2207.12264",
    "title": "Dynamics of (mis)information flow and engaging power of narratives",
    "abstract": "Dynamics of (mis)information flow and engaging power of narratives",
    "descriptor": "",
    "authors": [
      "Emanuele Brugnoli",
      "Marco Delmastro"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.12264"
  },
  {
    "id": "arXiv:2207.13126",
    "title": "Sample Complexity of Forecast Aggregation",
    "abstract": "Comments: Add a new result about multi-outcome events. Revise proofs and proof sketches of the main theorems",
    "descriptor": "\nComments: Add a new result about multi-outcome events. Revise proofs and proof sketches of the main theorems\n",
    "authors": [
      "Yiling Chen",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2207.13126"
  },
  {
    "id": "arXiv:2208.01563",
    "title": "Deepening the (Parameterized) Complexity Analysis of Incremental Stable  Matching Problems",
    "abstract": "Comments: Accepted to MFCS'22",
    "descriptor": "\nComments: Accepted to MFCS'22\n",
    "authors": [
      "Niclas Boehmer",
      "Klaus Heeger",
      "Rolf Niedermeier"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.01563"
  },
  {
    "id": "arXiv:2208.02157",
    "title": "Integrated Sensing and Communication for 6G: Ten Key Machine Learning  Roles",
    "abstract": "Comments: Submitted to IEEE",
    "descriptor": "\nComments: Submitted to IEEE\n",
    "authors": [
      "Umut Demirhan",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.02157"
  },
  {
    "id": "arXiv:2208.05187",
    "title": "Leveraging Endo- and Exo-Temporal Regularization for Black-box Video  Domain Adaptation",
    "abstract": "Comments: 9 pages, 4 figures, and 4 tables",
    "descriptor": "\nComments: 9 pages, 4 figures, and 4 tables\n",
    "authors": [
      "Yuecong Xu",
      "Jianfei Yang",
      "Haozhi Cao",
      "Min Wu",
      "Xiaoli Li",
      "Lihua Xie",
      "Zhenghua Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.05187"
  },
  {
    "id": "arXiv:2208.07194",
    "title": "An Efficient and Reliable Asynchronous Federated Learning Scheme for  Smart Public Transportation",
    "abstract": "An Efficient and Reliable Asynchronous Federated Learning Scheme for  Smart Public Transportation",
    "descriptor": "",
    "authors": [
      "Chenhao Xu",
      "Youyang Qu",
      "Tom H. Luan",
      "Peter W. Eklund",
      "Yong Xiang",
      "Longxiang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.07194"
  },
  {
    "id": "arXiv:2208.08227",
    "title": "A Scalable and Extensible Approach to Benchmarking NL2Code for 18  Programming Languages",
    "abstract": "A Scalable and Extensible Approach to Benchmarking NL2Code for 18  Programming Languages",
    "descriptor": "",
    "authors": [
      "Federico Cassano",
      "John Gouwar",
      "Daniel Nguyen",
      "Sydney Nguyen",
      "Luna Phipps-Costin",
      "Donald Pinckney",
      "Ming-Ho Yee",
      "Yangtian Zi",
      "Carolyn Jane Anderson",
      "Molly Q Feldman",
      "Arjun Guha",
      "Michael Greenberg",
      "Abhinav Jangda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2208.08227"
  },
  {
    "id": "arXiv:2208.09577",
    "title": "Real-time Short Video Recommendation on Mobile Devices",
    "abstract": "Comments: Accepted by CIKM 2022, 10 pages",
    "descriptor": "\nComments: Accepted by CIKM 2022, 10 pages\n",
    "authors": [
      "Xudong Gong",
      "Qinlin Feng",
      "Yuan Zhang",
      "Jiangling Qin",
      "Weijie Ding",
      "Biao Li",
      "Peng Jiang",
      "Kun Gai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.09577"
  },
  {
    "id": "arXiv:2208.14227",
    "title": "CLUDA : Contrastive Learning in Unsupervised Domain Adaptation for  Semantic Segmentation",
    "abstract": "Comments: Contrastive learning",
    "descriptor": "\nComments: Contrastive learning\n",
    "authors": [
      "Midhun Vayyat",
      "Jaswin Kasi",
      "Anuraag Bhattacharya",
      "Shuaib Ahmed",
      "Rahul Tallamraju"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.14227"
  },
  {
    "id": "arXiv:2209.02160",
    "title": "Improving Assistive Robotics with Deep Reinforcement Learning",
    "abstract": "Comments: Accepted to the 2022 NeurIPS Deep RL Workshop",
    "descriptor": "\nComments: Accepted to the 2022 NeurIPS Deep RL Workshop\n",
    "authors": [
      "Yash Jakhotiya",
      "Iman Haque"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.02160"
  },
  {
    "id": "arXiv:2209.02263",
    "title": "The Twin-in-the-Loop approach for vehicle dynamics control",
    "abstract": "The Twin-in-the-Loop approach for vehicle dynamics control",
    "descriptor": "",
    "authors": [
      "Federico Dett\u00f9",
      "Simone Formentin",
      "Sergio Matteo Savaresi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.02263"
  },
  {
    "id": "arXiv:2209.06251",
    "title": "Data-Driven Gain Scheduling Control of Linear Parameter-Varying Systems  using Quadratic Matrix Inequalities",
    "abstract": "Comments: 13 pages, 2 figures",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Jared Miller",
      "Mario Sznaier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.06251"
  },
  {
    "id": "arXiv:2209.07521",
    "title": "On-Device Domain Generalization",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Kaiyang Zhou",
      "Yuanhan Zhang",
      "Yuhang Zang",
      "Jingkang Yang",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07521"
  },
  {
    "id": "arXiv:2209.07970",
    "title": "Causal Fourier Analysis on Directed Acyclic Graphs and Posets",
    "abstract": "Comments: 13 pages, 11 figures",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Bastian Seifert",
      "Chris Wendler",
      "Markus P\u00fcschel"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2209.07970"
  },
  {
    "id": "arXiv:2209.07988",
    "title": "Prophet Inequalities for Cost Minimization",
    "abstract": "Comments: 38 pages",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Vasilis Livanos",
      "Ruta Mehta"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.07988"
  },
  {
    "id": "arXiv:2209.09574",
    "title": "Sampling Agnostic Feature Representation for Long-Term Person  Re-identification",
    "abstract": "Comments: 11 pages, 7 figures, In IEEE Transactions on Image Processing 2022",
    "descriptor": "\nComments: 11 pages, 7 figures, In IEEE Transactions on Image Processing 2022\n",
    "authors": [
      "Seongyeop Yang",
      "Byeongkeun Kang",
      "Yeejin Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09574"
  },
  {
    "id": "arXiv:2209.10225",
    "title": "On the Rate-Memory Tradeoff of D2D Coded Caching with Three Users",
    "abstract": "Comments: To be submitted for possible journal publication",
    "descriptor": "\nComments: To be submitted for possible journal publication\n",
    "authors": [
      "Wuqu Wang",
      "Nan Liu",
      "Wei Kang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.10225"
  },
  {
    "id": "arXiv:2209.10320",
    "title": "Continual VQA for Disaster Response Systems",
    "abstract": "Comments: Accepted at Tackling Climate Change with Machine Learning workshop at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at Tackling Climate Change with Machine Learning workshop at NeurIPS 2022\n",
    "authors": [
      "Aditya Kane",
      "V Manushree",
      "Sahil Khose"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.10320"
  },
  {
    "id": "arXiv:2209.10464",
    "title": "Quantifying attention via dwell time and engagement in a social media  browsing environment",
    "abstract": "Comments: All Things Attention NeurIPS Workshop",
    "descriptor": "\nComments: All Things Attention NeurIPS Workshop\n",
    "authors": [
      "Ziv Epstein",
      "Hause Lin",
      "Gordon Pennycook",
      "David Rand"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.10464"
  },
  {
    "id": "arXiv:2209.10690",
    "title": "Spectral inequalities for elliptic pseudo-differential operators on  closed manifolds",
    "abstract": "Comments: 31 Pages",
    "descriptor": "\nComments: 31 Pages\n",
    "authors": [
      "Duv\u00e1n Cardona"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Classical Analysis and ODEs (math.CA)",
      "Differential Geometry (math.DG)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.10690"
  },
  {
    "id": "arXiv:2209.11764",
    "title": "Taking the Intentional Stance Seriously, or \"Intending\" to Improve  Cognitive Systems",
    "abstract": "Comments: 13 pages, 1 figure, 2 tables",
    "descriptor": "\nComments: 13 pages, 1 figure, 2 tables\n",
    "authors": [
      "Will Bridewell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.11764"
  },
  {
    "id": "arXiv:2209.12350",
    "title": "Unsupervised Reward Shaping for a Robotic Sequential Picking Task from  Visual Observations in a Logistics Scenario",
    "abstract": "Unsupervised Reward Shaping for a Robotic Sequential Picking Task from  Visual Observations in a Logistics Scenario",
    "descriptor": "",
    "authors": [
      "Vittorio Giammarino",
      "Andrew J Meyer",
      "Kai Biegun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.12350"
  },
  {
    "id": "arXiv:2210.00050",
    "title": "Distributionally Robust Covariance Steering with Optimal Risk Allocation",
    "abstract": "Distributionally Robust Covariance Steering with Optimal Risk Allocation",
    "descriptor": "",
    "authors": [
      "Venkatraman Renganathan",
      "Joshua Pilipovsky",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.00050"
  },
  {
    "id": "arXiv:2210.00552",
    "title": "Occlusion-Aware Crowd Navigation Using People as Sensors",
    "abstract": "Comments: 7 pages, 4 figures",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Ye-Ji Mun",
      "Masha Itkina",
      "Shuijing Liu",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00552"
  },
  {
    "id": "arXiv:2210.01533",
    "title": "Concise and interpretable multi-label rule sets",
    "abstract": "Concise and interpretable multi-label rule sets",
    "descriptor": "",
    "authors": [
      "Martino Ciaperoni",
      "Han Xiao",
      "Aristides Gionis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01533"
  },
  {
    "id": "arXiv:2210.01560",
    "title": "SicHash - Small Irregular Cuckoo Tables for Perfect Hashing",
    "abstract": "SicHash - Small Irregular Cuckoo Tables for Perfect Hashing",
    "descriptor": "",
    "authors": [
      "Hans-Peter Lehmann",
      "Peter Sanders",
      "Stefan Walzer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.01560"
  },
  {
    "id": "arXiv:2210.02286",
    "title": "Efficient probabilistic reconciliation of forecasts for real-valued and  count time series",
    "abstract": "Comments: 25 pages, 4 figures",
    "descriptor": "\nComments: 25 pages, 4 figures\n",
    "authors": [
      "Lorenzo Zambon",
      "Dario Azzimonti",
      "Giorgio Corani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02286"
  },
  {
    "id": "arXiv:2210.03235",
    "title": "Improving Large-scale Paraphrase Acquisition and Generation",
    "abstract": "Comments: The project webpage is at this http URL Accepted at EMNLP 2022",
    "descriptor": "\nComments: The project webpage is at this http URL Accepted at EMNLP 2022\n",
    "authors": [
      "Yao Dou",
      "Chao Jiang",
      "Wei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03235"
  },
  {
    "id": "arXiv:2210.04251",
    "title": "State Advantage Weighting for Offline RL",
    "abstract": "Comments: 3rd Offline RL workshop at NeurIPS 2022. arXiv admin note: text overlap with arXiv:2206.07989",
    "descriptor": "\nComments: 3rd Offline RL workshop at NeurIPS 2022. arXiv admin note: text overlap with arXiv:2206.07989\n",
    "authors": [
      "Jiafei Lyu",
      "Aicheng Gong",
      "Le Wan",
      "Zongqing Lu",
      "Xiu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04251"
  },
  {
    "id": "arXiv:2210.04535",
    "title": "Belief functions on ordered frames of discernment",
    "abstract": "Belief functions on ordered frames of discernment",
    "descriptor": "",
    "authors": [
      "Arnaud Martin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.04535"
  },
  {
    "id": "arXiv:2210.07410",
    "title": "Quantification of entanglement with Siamese convolutional neural  networks",
    "abstract": "Comments: 17 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 17 pages, 9 figures, 5 tables\n",
    "authors": [
      "Jaros\u0142aw Paw\u0142owski",
      "Mateusz Krawczyk"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07410"
  },
  {
    "id": "arXiv:2210.08006",
    "title": "Failure Analysis of Big Cloud Service Providers Prior to and During  Covid-19 Period",
    "abstract": "Comments: Undergraduate project report, advisors Alexandru Iosup and Sacheendra Talluri. In updated version typos corrected: Corrected Figures 3.6, 3.8 and 3.8 to Figures 3.6, 3.7 and 3.8. Corrected Figures 3.9, 3.11 and 3.11 to Figures 3.9, 3.10 and 3.11",
    "descriptor": "\nComments: Undergraduate project report, advisors Alexandru Iosup and Sacheendra Talluri. In updated version typos corrected: Corrected Figures 3.6, 3.8 and 3.8 to Figures 3.6, 3.7 and 3.8. Corrected Figures 3.9, 3.11 and 3.11 to Figures 3.9, 3.10 and 3.11\n",
    "authors": [
      "Muhammad Ahsan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.08006"
  },
  {
    "id": "arXiv:2210.08242",
    "title": "RAPS: A Novel Few-Shot Relation Extraction Pipeline with  Query-Information Guided Attention and Adaptive Prototype Fusion",
    "abstract": "Comments: 9 pages, 2 figures",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Yuzhe Zhang",
      "Min Cen",
      "Tongzhou Wu",
      "Hong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08242"
  },
  {
    "id": "arXiv:2210.08443",
    "title": "CLEAR: Generative Counterfactual Explanations on Graphs",
    "abstract": "Comments: 18 pages, 9 figures",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Jing Ma",
      "Ruocheng Guo",
      "Saumitra Mishra",
      "Aidong Zhang",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08443"
  },
  {
    "id": "arXiv:2210.08786",
    "title": "Characterizing and Detecting State-Sponsored Troll Activity on Social  Media",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Fatima Ezzeddine",
      "Luca Luceri",
      "Omran Ayoub",
      "Ihab Sbeity",
      "Gianluca Nogara",
      "Emilio Ferrara",
      "Silvia Giordano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08786"
  },
  {
    "id": "arXiv:2210.10173",
    "title": "Faster Matrix Multiplication via Asymmetric Hashing",
    "abstract": "Comments: 67 pages",
    "descriptor": "\nComments: 67 pages\n",
    "authors": [
      "Ran Duan",
      "Hongxun Wu",
      "Renfei Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.10173"
  },
  {
    "id": "arXiv:2210.10418",
    "title": "p$^3$VAE: a physics-integrated generative model. Application to the  semantic segmentation of optical remote sensing images",
    "abstract": "Comments: 21 pages, 11 figures, submitted to the International Journal of Computer Vision",
    "descriptor": "\nComments: 21 pages, 11 figures, submitted to the International Journal of Computer Vision\n",
    "authors": [
      "Romain Thoreau",
      "Laurent Risser",
      "V\u00e9ronique Achard",
      "B\u00e9atrice Berthelot",
      "Xavier Briottet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10418"
  },
  {
    "id": "arXiv:2210.11601",
    "title": "gSuite: A Flexible and Framework Independent Benchmark Suite for Graph  Neural Network Inference on GPUs",
    "abstract": "Comments: IEEE International Symposium on Workload Characterization (IISWC) 2022",
    "descriptor": "\nComments: IEEE International Symposium on Workload Characterization (IISWC) 2022\n",
    "authors": [
      "Taha Tekdo\u011fan",
      "Serkan G\u00f6kta\u015f",
      "Ayse Yilmazer-Metin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.11601"
  },
  {
    "id": "arXiv:2210.12298",
    "title": "VRContour: Bringing Contour Delineations of Medical Structures Into  Virtual Reality",
    "abstract": "Comments: C. Chen, M. Yarmand, V. Singh, M.V. Sherer, J.D. Murphy, Y. Zhang and N. Weibel, \"VRContour: Bringing Contour Delineations of Medical Structures Into Virtual Reality\", 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), 2022, pp. 1-10, doi: 10.1109/ISMAR55827.2022.00020",
    "descriptor": "\nComments: C. Chen, M. Yarmand, V. Singh, M.V. Sherer, J.D. Murphy, Y. Zhang and N. Weibel, \"VRContour: Bringing Contour Delineations of Medical Structures Into Virtual Reality\", 2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), 2022, pp. 1-10, doi: 10.1109/ISMAR55827.2022.00020\n",
    "authors": [
      "Chen Chen",
      "Matin Yarmand",
      "Varun Singh",
      "Michael V. Sherer",
      "James D. Murphy",
      "Yang Zhang",
      "Nadir Weibel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.12298"
  },
  {
    "id": "arXiv:2210.13458",
    "title": "OpenAUC: Towards AUC-Oriented Open-Set Recognition",
    "abstract": "OpenAUC: Towards AUC-Oriented Open-Set Recognition",
    "descriptor": "",
    "authors": [
      "Zitai Wang",
      "Qianqian Xu",
      "Zhiyong Yang",
      "Yuan He",
      "Xiaochun Cao",
      "Qingming Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.13458"
  },
  {
    "id": "arXiv:2210.13611",
    "title": "Understanding the Evolution of Linear Regions in Deep Reinforcement  Learning",
    "abstract": "Comments: NeurIPS 2022 camera ready",
    "descriptor": "\nComments: NeurIPS 2022 camera ready\n",
    "authors": [
      "Setareh Cohan",
      "Nam Hee Kim",
      "David Rolnick",
      "Michiel van de Panne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.13611"
  },
  {
    "id": "arXiv:2210.14958",
    "title": "Constrained Approximate Similarity Search on Proximity Graph",
    "abstract": "Constrained Approximate Similarity Search on Proximity Graph",
    "descriptor": "",
    "authors": [
      "Weijie Zhao",
      "Shulong Tan",
      "Ping Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.14958"
  },
  {
    "id": "arXiv:2210.15424",
    "title": "What Language Model to Train if You Have One Million GPU Hours?",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Teven Le Scao",
      "Thomas Wang",
      "Daniel Hesslow",
      "Lucile Saulnier",
      "Stas Bekman",
      "M Saiful Bari",
      "Stella Biderman",
      "Hady Elsahar",
      "Niklas Muennighoff",
      "Jason Phang",
      "Ofir Press",
      "Colin Raffel",
      "Victor Sanh",
      "Sheng Shen",
      "Lintang Sutawika",
      "Jaesung Tae",
      "Zheng Xin Yong",
      "Julien Launay",
      "Iz Beltagy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15424"
  },
  {
    "id": "arXiv:2210.15855",
    "title": "Optimal Policy for Task Migration to UAV in Discrete-Time Systems with  Firm Deadlines",
    "abstract": "Optimal Policy for Task Migration to UAV in Discrete-Time Systems with  Firm Deadlines",
    "descriptor": "",
    "authors": [
      "Khai Doan",
      "Wesley Araujo",
      "Evangelos Kranakis",
      "Ioannis Lambadaris",
      "Yannis Viniotis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.15855"
  },
  {
    "id": "arXiv:2210.16097",
    "title": "cRedAnno+: Annotation Exploitation in Self-Explanatory Lung Nodule  Diagnosis",
    "abstract": "Comments: 5 pages, 5 figures, 2 tables. arXiv admin note: text overlap with arXiv:2206.13608",
    "descriptor": "\nComments: 5 pages, 5 figures, 2 tables. arXiv admin note: text overlap with arXiv:2206.13608\n",
    "authors": [
      "Jiahao Lu",
      "Chong Yin",
      "Kenny Erleben",
      "Michael Bachmann Nielsen",
      "Sune Darkner"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16097"
  },
  {
    "id": "arXiv:2210.16719",
    "title": "Multi-view Multi-label Anomaly Network Traffic Classification based on  MLP-Mixer Neural Network",
    "abstract": "Comments: 15 pages,6 figures",
    "descriptor": "\nComments: 15 pages,6 figures\n",
    "authors": [
      "Yu Zheng",
      "Zhangxuan Dang",
      "Chunlei Peng",
      "Chao Yang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16719"
  },
  {
    "id": "arXiv:2210.17406",
    "title": "Emergent Linguistic Structures in Neural Networks are Fragile",
    "abstract": "Emergent Linguistic Structures in Neural Networks are Fragile",
    "descriptor": "",
    "authors": [
      "Emanuele La Malfa",
      "Matthew Wicker",
      "Marta Kiatkowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.17406"
  },
  {
    "id": "arXiv:2210.17417",
    "title": "Fashion-Specific Attributes Interpretation via Dual Gaussian  Visual-Semantic Embedding",
    "abstract": "Fashion-Specific Attributes Interpretation via Dual Gaussian  Visual-Semantic Embedding",
    "descriptor": "",
    "authors": [
      "Ryotaro Shimizu",
      "Masanari Kimura",
      "Masayuki Goto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.17417"
  },
  {
    "id": "arXiv:2210.17429",
    "title": "The power of the Binary Value Principle",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Yaroslav Alekseev",
      "Edward A. Hirsch"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.17429"
  },
  {
    "id": "arXiv:2210.17473",
    "title": "Chronic pain patient narratives allow for the estimation of current pain  intensity",
    "abstract": "Comments: 29 pages, 6 figures, 7 tables",
    "descriptor": "\nComments: 29 pages, 6 figures, 7 tables\n",
    "authors": [
      "Diogo A.P. Nunes",
      "Joana Ferreira-Gomes",
      "Carlos Vaz",
      "Daniela Oliveira",
      "Sofia Pimenta",
      "Fani Neto",
      "David Martins de Matos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.17473"
  },
  {
    "id": "arXiv:2211.00416",
    "title": "Higher-order mutual information reveals synergistic sub-networks for  multi-neuron importance",
    "abstract": "Comments: Paper presented at InfoCog @ NeurIPS 2022",
    "descriptor": "\nComments: Paper presented at InfoCog @ NeurIPS 2022\n",
    "authors": [
      "Kenzo Clauw",
      "Sebastiano Stramaglia",
      "Daniele Marinazzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.00416"
  },
  {
    "id": "arXiv:2211.00577",
    "title": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "abstract": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "descriptor": "",
    "authors": [
      "Alireza Aghelan",
      "Modjtaba Rouhani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00577"
  },
  {
    "id": "arXiv:2211.00917",
    "title": "A Novel Autonomous Robotics System for Aquaculture Environment  Monitoring",
    "abstract": "A Novel Autonomous Robotics System for Aquaculture Environment  Monitoring",
    "descriptor": "",
    "authors": [
      "Tianqi Zhang",
      "Tong Shen",
      "Kai Yuan",
      "Kaiwen Xue",
      "Huihuan Qian"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00917"
  },
  {
    "id": "arXiv:2211.00962",
    "title": "Oblivious Quantum Computation and Delegated Multiparty Quantum  Computation",
    "abstract": "Oblivious Quantum Computation and Delegated Multiparty Quantum  Computation",
    "descriptor": "",
    "authors": [
      "Masahito Hayashi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.00962"
  },
  {
    "id": "arXiv:2211.01270",
    "title": "Secure and Efficient Privacy-preserving Authentication Scheme using  Cuckoo Filter in Remote Patient Monitoring Network",
    "abstract": "Secure and Efficient Privacy-preserving Authentication Scheme using  Cuckoo Filter in Remote Patient Monitoring Network",
    "descriptor": "",
    "authors": [
      "Shafika Showkat Moni",
      "Deepti Gupta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01270"
  },
  {
    "id": "arXiv:2211.01324",
    "title": "eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert  Denoisers",
    "abstract": "eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert  Denoisers",
    "descriptor": "",
    "authors": [
      "Yogesh Balaji",
      "Seungjun Nah",
      "Xun Huang",
      "Arash Vahdat",
      "Jiaming Song",
      "Karsten Kreis",
      "Miika Aittala",
      "Timo Aila",
      "Samuli Laine",
      "Bryan Catanzaro",
      "Tero Karras",
      "Ming-Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01324"
  },
  {
    "id": "arXiv:2211.01535",
    "title": "Reliable Malware Analysis and Detection using Topology Data Analysis",
    "abstract": "Reliable Malware Analysis and Detection using Topology Data Analysis",
    "descriptor": "",
    "authors": [
      "Lionel Nganyewou Tidjon",
      "Foutse Khomh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01535"
  },
  {
    "id": "arXiv:2211.01587",
    "title": "Eliciting Knowledge from Large Pre-Trained Models for Unsupervised  Knowledge-Grounded Conversation",
    "abstract": "Comments: Accepted to EMNLP 2022 Main Conference. The code is publicly available at this https URL",
    "descriptor": "\nComments: Accepted to EMNLP 2022 Main Conference. The code is publicly available at this https URL\n",
    "authors": [
      "Yanyang Li",
      "Jianqiao Zhao",
      "Michael R. Lyu",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01587"
  },
  {
    "id": "arXiv:2211.01701",
    "title": "Efficient Branch-and-Bound Algorithms for Finding Triangle-Constrained  2-Clubs",
    "abstract": "Efficient Branch-and-Bound Algorithms for Finding Triangle-Constrained  2-Clubs",
    "descriptor": "",
    "authors": [
      "Niels Gr\u00fcttemeier",
      "Philipp Heinrich Ke\u00dfler",
      "Christian Komusiewicz",
      "Frank Sommer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.01701"
  },
  {
    "id": "arXiv:2211.01747",
    "title": "Comparison of Algorithms for Distributed Mutual Exclusion through  Simulations",
    "abstract": "Comments: Updated references - Corrected typos",
    "descriptor": "\nComments: Updated references - Corrected typos\n",
    "authors": [
      "Filip De Turck"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01747"
  },
  {
    "id": "arXiv:2211.01785",
    "title": "Rethinking Hierarchies in Pre-trained Plain Vision Transformer",
    "abstract": "Comments: Tech report, work in progress",
    "descriptor": "\nComments: Tech report, work in progress\n",
    "authors": [
      "Yufei Xu",
      "Jing Zhang",
      "Qiming Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01785"
  },
  {
    "id": "arXiv:2211.01928",
    "title": "MPI-based Evaluation of Coordinator Election Algorithms",
    "abstract": "Comments: Updated references - Corrected typos",
    "descriptor": "\nComments: Updated references - Corrected typos\n",
    "authors": [
      "Filip De Turck"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01928"
  },
  {
    "id": "arXiv:2211.02516",
    "title": "Singlularity Avoidance with Application to Online Trajectory  Optimization for Serial Manipulators",
    "abstract": "Comments: 8 pages, 2 figures",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Florian Beck",
      "Minh Nhat Vu",
      "Christian Hartl-Nesic",
      "Andreas Kugi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02516"
  },
  {
    "id": "arXiv:2211.02757",
    "title": "Higher order time discretization method for the stochastic Stokes  equations with multiplicative noise",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Liet Vo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.02757"
  },
  {
    "id": "arXiv:2211.02904",
    "title": "HAQJSK: Hierarchical-Aligned Quantum Jensen-Shannon Kernels for Graph  Classification",
    "abstract": "HAQJSK: Hierarchical-Aligned Quantum Jensen-Shannon Kernels for Graph  Classification",
    "descriptor": "",
    "authors": [
      "Lu Bai",
      "Lixin Cui",
      "Yue Wang",
      "Ming Li",
      "Edwin R. Hancock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02904"
  },
  {
    "id": "arXiv:2211.03051",
    "title": "Multilayer Perceptron Network Discriminates Larval Zebrafish Genotype  using Behaviour",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Christopher Fusco",
      "Angel Allen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03051"
  },
  {
    "id": "arXiv:2211.03148",
    "title": "UATTA-ENS: Uncertainty Aware Test Time Augmented Ensemble for PIRC  Diabetic Retinopathy Detection",
    "abstract": "Comments: To Appear at Medical Imaging meets NeurIPS Workshop 2022",
    "descriptor": "\nComments: To Appear at Medical Imaging meets NeurIPS Workshop 2022\n",
    "authors": [
      "Pratinav Seth",
      "Adil Khan",
      "Ananya Gupta",
      "Saurabh Kumar Mishra",
      "Akshat Bhandari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03148"
  },
  {
    "id": "arXiv:2211.03168",
    "title": "Approximate Graph Colouring and the Hollow Shadow",
    "abstract": "Comments: Generalises and subsumes results from Section 6 in arXiv:2203.02478; builds on and generalises results in arXiv:2210.08293",
    "descriptor": "\nComments: Generalises and subsumes results from Section 6 in arXiv:2203.02478; builds on and generalises results in arXiv:2210.08293\n",
    "authors": [
      "Lorenzo Ciardo",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.03168"
  },
  {
    "id": "arXiv:2211.03268",
    "title": "Newton Like Iterative Method without Derivative for Solving Nonlinear  Equations Based on Dynamical Systems",
    "abstract": "Comments: 7pages,under review",
    "descriptor": "\nComments: 7pages,under review\n",
    "authors": [
      "Yonglong Liao",
      "Limin Cui"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.03268"
  },
  {
    "id": "arXiv:2211.03286",
    "title": "Learning Task Requirements and Agent Capabilities for Multi-agent Task  Allocation",
    "abstract": "Comments: The video and open-source code are at this https URL",
    "descriptor": "\nComments: The video and open-source code are at this https URL\n",
    "authors": [
      "Bo Fu",
      "William Smith",
      "Denise Rizzo",
      "Matthew Castanier",
      "Maani Ghaffari",
      "Kira Barton"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.03286"
  },
  {
    "id": "arXiv:2211.03341",
    "title": "Parameterized Algorithm for the Disjoint Path Problem on Planar Graphs:  Exponential in $k^2$ and Linear in $n$",
    "abstract": "Comments: SODA 2023",
    "descriptor": "\nComments: SODA 2023\n",
    "authors": [
      "Kyungjin Cho",
      "Eunjin Oh",
      "Seunghyeok Oh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.03341"
  },
  {
    "id": "arXiv:2211.03363",
    "title": "Over-The-Air Clustered Wireless Federated Learning",
    "abstract": "Comments: Under review at ICASSP 2023",
    "descriptor": "\nComments: Under review at ICASSP 2023\n",
    "authors": [
      "Ayush Madhan-Sohini",
      "Divin Dominic",
      "Nazreen Shah",
      "Ranjitha Prasad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03363"
  },
  {
    "id": "arXiv:2211.03396",
    "title": "Certificate games",
    "abstract": "Comments: 43 pages, 1 figure, ITCS2023",
    "descriptor": "\nComments: 43 pages, 1 figure, ITCS2023\n",
    "authors": [
      "Sourav Chakraborty",
      "Anna G\u00e1l",
      "Sophie Laplante",
      "Rajat Mittal",
      "Anupa Sunny"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.03396"
  },
  {
    "id": "arXiv:2211.03449",
    "title": "How to Coordinate Edge Devices for Over-the-Air Federated Learning?",
    "abstract": "How to Coordinate Edge Devices for Over-the-Air Federated Learning?",
    "descriptor": "",
    "authors": [
      "Mohammad Ali Sedaghat",
      "Ali Bereyhi",
      "Saba Asaad",
      "Ralf R. Mueller"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.03449"
  },
  {
    "id": "arXiv:2211.03553",
    "title": "Learning Causal Representations of Single Cells via Sparse Mechanism  Shift Modeling",
    "abstract": "Learning Causal Representations of Single Cells via Sparse Mechanism  Shift Modeling",
    "descriptor": "",
    "authors": [
      "Romain Lopez",
      "Nata\u0161a Tagasovska",
      "Stephen Ra",
      "Kyunghyn Cho",
      "Jonathan K. Pritchard",
      "Aviv Regev"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03553"
  },
  {
    "id": "arXiv:2211.03663",
    "title": "Generalizable Re-Identification from Videos with Cycle Association",
    "abstract": "Generalizable Re-Identification from Videos with Cycle Association",
    "descriptor": "",
    "authors": [
      "Zhongdao Wang",
      "Zhaopeng Dou",
      "Jingwei Zhang",
      "Liang Zheng",
      "Yifan Sun",
      "Yali Li",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03663"
  }
]
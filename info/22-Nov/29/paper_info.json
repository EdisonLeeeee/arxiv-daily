[
  {
    "id": "arXiv:2211.14314",
    "title": "The applicability of transperceptual and deep learning approaches to the  study and mimicry of complex cartilaginous tissues",
    "abstract": "Complex soft tissues, for example the knee meniscus, play a crucial role in\nmobility and joint health, but when damaged are incredibly difficult to repair\nand replace. This is due to their highly hierarchical and porous nature which\nin turn leads to their unique mechanical properties. In order to design tissue\nsubstitutes, the internal architecture of the native tissue needs to be\nunderstood and replicated. Here we explore a combined audio-visual approach -\nso called transperceptual - to generate artificial architectures mimicking the\nnative ones. The proposed method uses both traditional imagery, and sound\ngenerated from each image as a method of rapidly comparing and contrasting the\nporosity and pore size within the samples. We have trained and tested a\ngenerative adversarial network (GAN) on the 2D image stacks. The impact of the\ntraining set of images on the similarity of the artificial to the original\ndataset was assessed by analyzing two samples. The first consisting of n=478\npairs of audio and image files for which the images were downsampled to 64\n$\\times$ 64 pixels, the second one consisting of n=7640 pairs of audio and\nimage files for which the full resolution 256 $\\times$ 256 pixels is retained\nbut each image is divided into 16 squares to maintain the limit of 64 $\\times$\n64 pixels required by the GAN. We reconstruct the 2D stacks of artificially\ngenerated datasets into 3D objects and run image analysis algorithms to\ncharacterize statistically the architectural parameters - pore size, tortuosity\nand pore connectivity - and compare them with the original dataset. Results\nshow that the artificially generated dataset that undergoes downsampling\nperforms better in terms of parameter matching. Our audiovisual approach has\nthe potential to be extended to larger data sets to explore both how\nsimilarities and differences can be audibly recognized across multiple samples.",
    "descriptor": "",
    "authors": [
      "J. Waghorne",
      "C. Howard",
      "H. Hu",
      "J. Pang",
      "W.J. Peveler",
      "L. Harris",
      "O. Barrera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.14314"
  },
  {
    "id": "arXiv:2211.14316",
    "title": "Identifying discreditable firms in a large-scale ownership network",
    "abstract": "Violations of laws and regulations about food safety, production safety,\nquality standard and environmental protection, or negative consequences from\nloan, guarantee and pledge contracts, may result in operating and credit risks\nof firms. The above illegal or trust-breaking activities are collectively\ncalled discreditable activities, and firms with discreditable activities are\nnamed as discreditable firms. Identification of discreditable firms is of great\nsignificance for investment attraction, bank lending, equity investment,\nsupplier selection, job seeking, and so on. In this paper, we collect\nregistration records of about 113 million Chinese firms and construct an\nownership network with about 6 million nodes, where each node is a firm who has\ninvested at least one firm or has been invested by at least one firm. Analysis\nof publicly available records of discreditable activities show strong network\neffect, namely the probability of a firm to be discreditable is remarkably\nhigher than the average probability given the fact that one of its investors or\ninvestees is discreditable. In comparison, for the risk of being a\ndiscreditable firm, an investee has higher impact than an investor in average.\nThe impact of a firm on surrounding firms decays along with the increasing\ntopological distance, analogous to the well-known \"three degrees of separation\"\nphenomenon. The uncovered correlation of discreditable activities can be\nconsidered as a representative example of network effect, in addition to the\npropagation of diseases, opinions and human behaviors. Lastly, we show that the\nutilization of the network effect largely improves the accuracy of the\nalgorithm to identify discreditable firms.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Tao Zhou",
      "Yan-Li Lee",
      "Qian Li",
      "Duanbing Chen",
      "Wenbo Xie",
      "Tong Wu",
      "Tu Zeng"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.14316"
  },
  {
    "id": "arXiv:2211.14317",
    "title": "Hard to Track Objects with Irregular Motions and Similar Appearances?  Make It Easier by Buffering the Matching Space",
    "abstract": "We propose a Cascaded Buffered IoU (C-BIoU) tracker to track multiple objects\nthat have irregular motions and indistinguishable appearances. When appearance\nfeatures are unreliable and geometric features are confused by irregular\nmotions, applying conventional Multiple Object Tracking (MOT) methods may\ngenerate unsatisfactory results. To address this issue, our C-BIoU tracker adds\nbuffers to expand the matching space of detections and tracks, which mitigates\nthe effect of irregular motions in two aspects: one is to directly match\nidentical but non-overlapping detections and tracks in adjacent frames, and the\nother is to compensate for the motion estimation bias in the matching space. In\naddition, to reduce the risk of overexpansion of the matching space, cascaded\nmatching is employed: first matching alive tracks and detections with a small\nbuffer, and then matching unmatched tracks and detections with a large buffer.\nDespite its simplicity, our C-BIoU tracker works surprisingly well and achieves\nstate-of-the-art results on MOT datasets that focus on irregular motions and\nindistinguishable appearances. Moreover, the C-BIoU tracker is the dominant\ncomponent for our 2-nd place solution in the CVPR'22 SoccerNet MOT and ECCV'22\nMOTComplex DanceTrack challenges. Finally, we analyze the limitation of our\nC-BIoU tracker in ablation studies and discuss its application scope.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2211.13509\n",
    "authors": [
      "Fan Yang",
      "Shigeyuki Odashima",
      "Shoichi Masui",
      "Shan Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.14317"
  },
  {
    "id": "arXiv:2211.14318",
    "title": "Multidimensional rank-one convexification of incremental damage models  at finite strains",
    "abstract": "This paper presents computationally feasible rank-one relaxation algorithms\nfor the efficient simulation of a time-incremental damage model with nonconvex\nincremental stress potentials in multiple spatial dimensions. While the\nstandard model suffers from numerical issues due to the lack of convexity, the\nrelaxation techniques circumvent the problem of non-existence of minimizers and\nprevent mesh dependency of the solutions of discretized boundary value problems\nusing finite elements. By the combination, modification and parallelization of\nthe underlying convexification algorithms the approach becomes computationally\nfeasible. A descent method and a Newton scheme enhanced by step size control\nstrategies prevents stability issues related to local minima in the energy\nlandscape and the computation of derivatives. Special techniques for the\nconstruction of continuous derivatives of the approximated rank-one convex\nenvelope are discussed. A series of numerical experiments demonstrates the\nability of the computationally relaxed model to capture softening effects and\nthe mesh independence of the computed approximations.",
    "descriptor": "",
    "authors": [
      "Daniel Balzani",
      "Maximilian K\u00f6hler",
      "Timo Neumeier",
      "Malte A. Peter",
      "Daniel Peterseim"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14318"
  },
  {
    "id": "arXiv:2211.14320",
    "title": "Bidirectional Representations for Low Resource Spoken Language  Understanding",
    "abstract": "Most spoken language understanding systems use a pipeline approach composed\nof an automatic speech recognition interface and a natural language\nunderstanding module. This approach forces hard decisions when converting\ncontinuous inputs into discrete language symbols. Instead, we propose a\nrepresentation model to encode speech in rich bidirectional encodings that can\nbe used for downstream tasks such as intent prediction. The approach uses a\nmasked language modelling objective to learn the representations, and thus\nbenefits from both the left and right contexts. We show that the performance of\nthe resulting encodings before fine-tuning is better than comparable models on\nmultiple datasets, and that fine-tuning the top layers of the representation\nmodel improves the current state of the art on the Fluent Speech Command\ndataset, also in a low-data regime, when a limited amount of labelled data is\nused for training. Furthermore, we propose class attention as a spoken language\nunderstanding module, efficient both in terms of speed and number of\nparameters. Class attention can be used to visually explain the predictions of\nour model, which goes a long way in understanding how the model makes\npredictions. We perform experiments in English and in Dutch.",
    "descriptor": "",
    "authors": [
      "Quentin Meeus",
      "Marie-Francine Moens",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14320"
  },
  {
    "id": "arXiv:2211.14321",
    "title": "A Machine Learning, Natural Language Processing Analysis of Youth  Perspectives: Key Trends and Focus Areas for Sustainable Youth Development  Policies",
    "abstract": "Investing in children and youth is a critical step towards inclusive,\nequitable, and sustainable development for current and future generations.\nSeveral international agendas for accomplishing common global goals emphasize\nthe need for active youth participation and engagement for sustainable\ndevelopment. The 2030 Agenda for Sustainable Development emphasizes the need\nfor youth engagement and the inclusion of youth perspectives as an important\nstep toward addressing each of the 17 Sustainable Development Goals. The aim of\nthis study is to analyze youth perspectives, values, and sentiments towards\nissues addressed by the 17 Sustainable Development Goals through social network\nanalysis using machine learning. Social network data collected during 7 major\nsustainability conferences aimed at engaging children and youth is analyzed\nusing natural language processing techniques for sentiment analysis. This data\ncategorized using a natural language processing text classifier trained on a\nsample dataset of social network data during the 7 youth sustainability\nconferences for deeper understanding of youth perspectives in relation to the\nSDGs. Machine learning identified demographic and location attributes and\nfeatures are utilized in order to identify bias and demographic differences\nbetween ages, gender, and race among youth. Using natural language processing,\nthe qualitative data collected from over 7 different countries in 3 languages\nare systematically translated, categorized, and analyzed, revealing key trends\nand focus areas for sustainable youth development policies. The obtained\nresults reveal the general youth's depth of knowledge on sustainable\ndevelopment and their attitudes towards each of the 17 SDGs. The findings of\nthis study serve as a guide toward better understanding the interests, roles,\nand perspectives of children and youth in achieving the goals of Agenda 2030.",
    "descriptor": "",
    "authors": [
      "Kushaagra Gupta"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14321"
  },
  {
    "id": "arXiv:2211.14343",
    "title": "Less Data, More Knowledge: Building Next Generation Semantic  Communication Networks",
    "abstract": "Semantic communication is viewed as a revolutionary paradigm that can\npotentially transform how we design and operate wireless communication systems.\nHowever, despite a recent surge of research activities in this area, the\nresearch landscape remains limited. In this tutorial, we present the first\nrigorous vision of a scalable end-to-end semantic communication network that is\nfounded on novel concepts from artificial intelligence (AI), causal reasoning,\nand communication theory. We first discuss how the design of semantic\ncommunication networks requires a move from data-driven networks towards\nknowledge-driven ones. Subsequently, we highlight the necessity of creating\nsemantic representations of data that satisfy the key properties of minimalism,\ngeneralizability, and efficiency so as to do more with less. We then explain\nhow those representations can form the basis a so-called semantic language. By\nusing semantic representation and languages, we show that the traditional\ntransmitter and receiver now become a teacher and apprentice. Then, we define\nthe concept of reasoning by investigating the fundamentals of causal\nrepresentation learning and their role in designing semantic communication\nnetworks. We demonstrate that reasoning faculties are majorly characterized by\nthe ability to capture causal and associational relationships in datastreams.\nFor such reasoning-driven networks, we propose novel and essential semantic\ncommunication metrics that include new \"reasoning capacity\" measures that could\ngo beyond Shannon's bound to capture the convergence of computing and\ncommunication. Finally, we explain how semantic communications can be scaled to\nlarge-scale networks (6G and beyond). In a nutshell, we expect this tutorial to\nprovide a comprehensive reference on how to properly build, analyze, and deploy\nfuture semantic communication networks.",
    "descriptor": "",
    "authors": [
      "Christina Chaccour",
      "Walid Saad",
      "Merouane Debbah",
      "Zhu Han",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.14343"
  },
  {
    "id": "arXiv:2211.14344",
    "title": "MavVStream: Extending Database Capabilities for Situation Monitoring  Using Extracted Video Contents",
    "abstract": "Query-based video situation detection (as opposed to manual or customized\nalgorithms) is critical for diverse applications such as traffic monitoring,\nsurveillance1 , and other types of environmental/infrastructure monitoring.\nVideo contents are complex in terms of disparate object types and background\ninformation. Therefore, in addition to extracting complex contents using the\nlatest vision technologies (including deep learning-based), their\nrepresentation as well as querying pose different kinds of challenges. Once we\nhave a representation to accommodate extracted contents, ad-hoc querying on\nthat will need new operators, along with their semantics and algorithms for\ntheir efficient computation. Extending database framework (representation and\nreal-time querying) for processing queries on video contents extracted only\nonce is critical and this effort is an initial step in that direction. In this\npaper, we extend the traditional relation to R++ (vector attributes) and\narrables to accommodate video contents and extend CQL (Continuous Query\nLanguage) with a few new operators to query situations on the extended\nrepresentation. Backward compatibility, ease-of-use, new operators (including\nspatial and temporal), and algorithms for efficient execution are discussed in\nthis paper. Classes of queries are identified based on their complexity to\nevaluate with respect to video content. A large number of small and large video\ndatasets have been used (some from the literature) to show how our work can be\nused on available datasets. Correctness of queries with manual ground truth,\nefficient evaluation as well as robustness of algorithms is demonstrated. Our\nmain contribution is couching a framework for a problem that is becoming very\nimportant as part of big data analytics based on a novel idea.",
    "descriptor": "",
    "authors": [
      "Hafsa Billah",
      "Mayur Arora",
      "Sharma Chakravarthy"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.14344"
  },
  {
    "id": "arXiv:2211.14347",
    "title": "The smooth output assumption, and why deep networks are better than wide  ones",
    "abstract": "When several models have similar training scores, classical model selection\nheuristics follow Occam's razor and advise choosing the ones with least\ncapacity. Yet, modern practice with large neural networks has often led to\nsituations where two networks with exactly the same number of parameters score\nsimilar on the training set, but the deeper one generalizes better to unseen\nexamples. With this in mind, it is well accepted that deep networks are\nsuperior to shallow wide ones. However, theoretically there is no difference\nbetween the two. In fact, they are both universal approximators.\nIn this work we propose a new unsupervised measure that predicts how well a\nmodel will generalize. We call it the output sharpness, and it is based on the\nfact that, in reality, boundaries between concepts are generally unsharp. We\ntest this new measure on several neural network settings, and architectures,\nand show how generally strong the correlation is between our metric, and test\nset performance.\nHaving established this measure, we give a mathematical probabilistic\nargument that predicts network depth to be correlated with our proposed\nmeasure. After verifying this in real data, we are able to formulate the key\nargument of the work: output sharpness hampers generalization; deep networks\nhave an in built bias against it; therefore, deep networks beat wide ones.\nAll in all the work not only provides a helpful predictor of overfitting that\ncan be used in practice for model selection (or even regularization), but also\nprovides a much needed theoretical grounding for the success of modern deep\nneural networks.",
    "descriptor": "",
    "authors": [
      "Luis Sa-Couto",
      "Jose Miguel Ramos",
      "Andreas Wichert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14347"
  },
  {
    "id": "arXiv:2211.14358",
    "title": "A Moral- and Event- Centric Inspection of Gender Bias in Fairy Tales at  A Large Scale",
    "abstract": "Fairy tales are a common resource for young children to learn a language or\nunderstand how a society works. However, gender bias, e.g., stereotypical\ngender roles, in this literature may cause harm and skew children's world view.\nInstead of decades of qualitative and manual analysis of gender bias in fairy\ntales, we computationally analyze gender bias in a fairy tale dataset\ncontaining 624 fairy tales from 7 different cultures. We specifically examine\ngender difference in terms of moral foundations, which are measures of human\nmorality, and events, which reveal human activities associated with each\ncharacter. We find that the number of male characters is two times that of\nfemale characters, showing a disproportionate gender representation. Our\nanalysis further reveal stereotypical portrayals of both male and female\ncharacters in terms of moral foundations and events. Female characters turn out\nmore associated with care-, loyalty- and sanctity- related moral words, while\nmale characters are more associated with fairness- and authority- related moral\nwords. Female characters' events are often about emotion (e.g., weep),\nappearance (e.g., comb), household (e.g., bake), etc.; while male characters'\nevents are more about profession (e.g., hunt), violence (e.g., destroy),\njustice (e.g., judge), etc. Gender bias in terms of moral foundations shows an\nobvious difference across cultures. For example, female characters are more\nassociated with care and sanctity in high uncertainty-avoidance cultures which\nare less open to changes and unpredictability. Based on the results, we propose\nimplications for children's literature and early literacy research.",
    "descriptor": "",
    "authors": [
      "Zhixuan Zhou",
      "Jiao Sun",
      "Jiaxin Pei",
      "Nanyun Peng",
      "Jinjun Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14358"
  },
  {
    "id": "arXiv:2211.14360",
    "title": "Finetuning BERT on Partially Annotated NER Corpora",
    "abstract": "Most Named Entity Recognition (NER) models operate under the assumption that\ntraining datasets are fully labelled. While it is valid for established\ndatasets like CoNLL 2003 and OntoNotes, sometimes it is not feasible to obtain\nthe complete dataset annotation. These situations may occur, for instance,\nafter selective annotation of entities for cost reduction. This work presents\nan approach to finetuning BERT on such partially labelled datasets using\nself-supervision and label preprocessing. Our approach outperforms the previous\nLSTM-based label preprocessing baseline, significantly improving the\nperformance on poorly labelled datasets. We demonstrate that following our\napproach while finetuning RoBERTa on CoNLL 2003 dataset with only 10% of total\nentities labelled is enough to reach the performance of the baseline trained on\nthe same dataset with 50% of the entities labelled.",
    "descriptor": "\nComments: 6 pages, to be published in Proceedings of ISP RAS Open Conference 2022\n",
    "authors": [
      "Viktor Scherbakov",
      "Vladimir Mayorov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14360"
  },
  {
    "id": "arXiv:2211.14361",
    "title": "Gatekeeper: Safety Critical Control of Nonlinear Systems with Limited  Perception in Unknown and Dynamic Environments",
    "abstract": "This paper presents the Gatekeeper algorithm, a real-time method to guarantee\nthe safety of a robotic system operating in environments that are unknown and\ndynamic. Given a nominal planner designed to meet mission objectives,\nGatekeeper extends the nominal trajectories using backup controllers, and\ndetermines a control policy that is certified safe for all future time using\nthe currently available information. We demonstrate the algorithm on a dynamic\naerial firefighting mission, and show reduced conservatism relative to existing\nmethods. The algorithm was also demonstrated onboard a quadrotor, where a map\nof the environment was built online, and the Gatekeeper algorithm prevented a\nhuman pilot from flying the quadrotor into obstacles and unknown regions.",
    "descriptor": "\nComments: submitted to ICRA 2023, 7 pages, 4 figures\n",
    "authors": [
      "Devansh Agrawal",
      "Ruichang Chen",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14361"
  },
  {
    "id": "arXiv:2211.14362",
    "title": "Chart-RCNN: Efficient Line Chart Data Extraction from Camera Images",
    "abstract": "Line Chart Data Extraction is a natural extension of Optical Character\nRecognition where the objective is to recover the underlying numerical\ninformation a chart image represents. Some recent works such as ChartOCR\napproach this problem using multi-stage networks combining OCR models with\nobject detection frameworks. However, most of the existing datasets and models\nare based on \"clean\" images such as screenshots that drastically differ from\ncamera photos. In addition, creating domain-specific new datasets requires\nextensive labeling which can be time-consuming. Our main contributions are as\nfollows: we propose a synthetic data generation framework and a one-stage model\nthat outputs text labels, mark coordinates, and perspective estimation\nsimultaneously. We collected two datasets consisting of real camera photos for\nevaluation. Results show that our model trained only on synthetic data can be\napplied to real photos without any fine-tuning and is feasible for real-world\napplication.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Shufan Li",
      "Congxi Lu",
      "Linkai Li",
      "Haoshuai Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14362"
  },
  {
    "id": "arXiv:2211.14363",
    "title": "Homology-constrained vector quantization entropy regularizer",
    "abstract": "This paper describes an entropy regularization term for vector quantization\n(VQ) based on the analysis of persistent homology of the VQ embeddings. Higher\nembedding entropy positively correlates with higher codebook utilization,\nmitigating overfit towards the identity and codebook collapse in VQ-based\nautoencoders [1]. We show that homology-constrained regularization is an\neffective way to increase entropy of the VQ process (approximated to input\nentropy) while preserving the approximated topology in the quantized latent\nspace, averaged over mini batches. This work further explores some patterns of\npersistent homology diagrams of latents formed by vector quantization. We\nimplement and test the proposed algorithm as a module integrated into a sample\nVQ-VAE. Linked code repository provides a functioning implementation of the\nproposed architecture, referred to as homology-constrained vector quantization\n(HC-VQ) further in this work.",
    "descriptor": "",
    "authors": [
      "Ivan Volkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14363"
  },
  {
    "id": "arXiv:2211.14364",
    "title": "Safe and Robust Observer-Controller Synthesis using Control Barrier  Functions",
    "abstract": "This paper addresses the synthesis of safety-critical controllers using\nestimate feedback. We propose an observer-controller interconnection to ensure\nthat the nonlinear system remains safe despite bounded disturbances on the\nsystem dynamics and measurements that correspond to partial state information.\nThe co-design of observers and controllers is critical, since even in\nundisturbed cases, observers and controllers designed independently may not\nrender the system safe. We propose two approaches to synthesize\nobserver-controller interconnections. The first approach utilizes\nInput-to-State Stable observers, and the second uses Bounded Error observers.\nUsing these stability and boundedness properties of the observation error, we\nconstruct novel Control Barrier Functions that impose inequality constraints on\nthe control inputs which, when satisfied, certifies safety. We propose\nquadratic program-based controllers to satisfy these constraints, and prove\nLipschitz continuity of the derived controllers. Simulations and experiments on\na quadrotor demonstrate the efficacy of the proposed methods.",
    "descriptor": "\nComments: 6 pages, 4 figures. Accepted at LCSS, CDC 2023\n",
    "authors": [
      "Devansh R. Agrawal",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14364"
  },
  {
    "id": "arXiv:2211.14366",
    "title": "Mixture Manifold Networks: A Computationally Efficient Baseline for  Inverse Modeling",
    "abstract": "We propose and show the efficacy of a new method to address generic inverse\nproblems. Inverse modeling is the task whereby one seeks to determine the\ncontrol parameters of a natural system that produce a given set of observed\nmeasurements. Recent work has shown impressive results using deep learning, but\nwe note that there is a trade-off between model performance and computational\ntime. For some applications, the computational time at inference for the best\nperforming inverse modeling method may be overly prohibitive to its use. We\npresent a new method that leverages multiple manifolds as a mixture of backward\n(e.g., inverse) models in a forward-backward model architecture. These multiple\nbackwards models all share a common forward model, and their training is\nmitigated by generating training examples from the forward model. The proposed\nmethod thus has two innovations: 1) the multiple Manifold Mixture Network (MMN)\narchitecture, and 2) the training procedure involving augmenting backward model\ntraining data using the forward model. We demonstrate the advantages of our\nmethod by comparing to several baselines on four benchmark inverse problems,\nand we furthermore provide analysis to motivate its design.",
    "descriptor": "\nComments: This paper has been accepted to AAAI 2023; this is not the final version\n",
    "authors": [
      "Gregory P. Spell",
      "Simiao Ren",
      "Leslie M. Collins",
      "Jordan M. Malof"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14366"
  },
  {
    "id": "arXiv:2211.14369",
    "title": "The Naughtyformer: A Transformer Understands Offensive Humor",
    "abstract": "Jokes are intentionally written to be funny, but not all jokes are created\nthe same. Some jokes may be fit for a classroom of kindergarteners, but others\nare best reserved for a more mature audience. While recent work has shown\nimpressive results on humor detection in text, here we instead investigate the\nmore nuanced task of detecting humor subtypes, especially of the less innocent\nvariety. To that end, we introduce a novel jokes dataset filtered from Reddit\nand solve the subtype classification task using a finetuned Transformer dubbed\nthe Naughtyformer. Moreover, we show that our model is significantly better at\ndetecting offensiveness in jokes compared to state-of-the-art methods.",
    "descriptor": "\nComments: AAAI-23 Student Abstract\n",
    "authors": [
      "Leonard Tang",
      "Alexander Cai",
      "Steve Li",
      "Jason Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14369"
  },
  {
    "id": "arXiv:2211.14375",
    "title": "Designing Neural Networks for Hyperbolic Conservation Laws",
    "abstract": "We propose a new data-driven method to learn the dynamics of an unknown\nhyperbolic system of conservation laws using deep neural networks. Inspired by\nclassical methods in numerical conservation laws, we develop a new conservative\nform network (CFN) in which the network learns the flux function of the unknown\nsystem. Our numerical examples demonstrate that the CFN yields significantly\nbetter prediction accuracy than what is obtained using a standard\nnon-conservative form network, even when it is enhanced with constraints to\npromote conservation. In particular, solutions obtained using the CFN\nconsistently capture the correct shock propagation speed without introducing\nnon-physical oscillations into the solution. They are furthermore robust to\nnoisy and sparse observation environments.",
    "descriptor": "",
    "authors": [
      "Zhen Chen",
      "Anne Gelb",
      "Yoonsang Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14375"
  },
  {
    "id": "arXiv:2211.14382",
    "title": "Parallel decoder for Low Density Parity Check Codes: A MPSoC study",
    "abstract": "The near channel performance of Low Density Parity Check Codes (LDPC) has\nmotivated its wide applications. Iterative decoding of LDPC codes provides\nsignificant implementation challenges as the complexity grows with the code\nsize. Recent trends in integrating Multiprocessor System on Chip (MPSoC) with\nNetwork on Chip (NoC) gives a modular platform for parallel implementation.\nThis paper presents an implementation platform for decoding LDPC codes based on\nHeMPS, an open source MPSoC framework based on NoC communication fabric.\nReduced minimum sum algorithm is used for decoding LDPC codes and simulations\nare performed using HeMPS tool. The data rate and speedup factor measured for\ndecoding a rate 1/2 LDPC code characterised by 252x504 parity matrix is\npresented",
    "descriptor": "\nComments: 2013 International Conference on High Performance Computing & Simulation (HPCS)\n",
    "authors": [
      "Sudeep Kanur",
      "Georgios Georgakarakos",
      "Antti Siiril\u00e4",
      "J\u00e9r\u00e9mie Lagravi\u00e8re",
      "Kristian Nybom",
      "S\u00e9bastien Lafond",
      "Johan Lilius"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.14382"
  },
  {
    "id": "arXiv:2211.14383",
    "title": "Interpreting Unfairness in Graph Neural Networks via Training Node  Attribution",
    "abstract": "Graph Neural Networks (GNNs) have emerged as the leading paradigm for solving\ngraph analytical problems in various real-world applications. Nevertheless,\nGNNs could potentially render biased predictions towards certain demographic\nsubgroups. Understanding how the bias in predictions arises is critical, as it\nguides the design of GNN debiasing mechanisms. However, most existing works\noverwhelmingly focus on GNN debiasing, but fall short on explaining how such\nbias is induced. In this paper, we study a novel problem of interpreting GNN\nunfairness through attributing it to the influence of training nodes.\nSpecifically, we propose a novel strategy named Probabilistic Distribution\nDisparity (PDD) to measure the bias exhibited in GNNs, and develop an algorithm\nto efficiently estimate the influence of each training node on such bias. We\nverify the validity of PDD and the effectiveness of influence estimation\nthrough experiments on real-world datasets. Finally, we also demonstrate how\nthe proposed framework could be used for debiasing GNNs. Open-source code can\nbe found at https://github.com/yushundong/BIND.",
    "descriptor": "\nComments: Published as a conference paper at AAAI 2023\n",
    "authors": [
      "Yushun Dong",
      "Song Wang",
      "Jing Ma",
      "Ninghao Liu",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.14383"
  },
  {
    "id": "arXiv:2211.14385",
    "title": "Pac-Man Pete: An extensible framework for building AI in VEX Robotics",
    "abstract": "This technical report details VEX Robotics team BLRSAI's development of a\nfully autonomous robot for VEX Robotics' Tipping Point AI Competition. We\nidentify and develop three separate critical components. This includes a Unity\nsimulation and reinforcement learning model training pipeline, a malleable\ncomputer vision pipeline, and a data transfer pipeline to offload large\ncomputations from the VEX V5 Brain/micro-controller to an external computer. We\ngive the community access to all of these components in hopes they can reuse\nand improve upon them in the future, and that it'll spark new ideas for\nautonomy as well as the necessary infrastructure and programs for AI in\neducational robotics.",
    "descriptor": "",
    "authors": [
      "Jacob Zietek",
      "Nicholas Wade",
      "Cole Roberts",
      "Aref Malek",
      "Manish Pylla",
      "Will Xu",
      "Sagar Patil"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14385"
  },
  {
    "id": "arXiv:2211.14387",
    "title": "Machine Learning Algorithms for Time Series Analysis and Forecasting",
    "abstract": "Time series data is being used everywhere, from sales records to patients'\nhealth evolution metrics. The ability to deal with this data has become a\nnecessity, and time series analysis and forecasting are used for the same.\nEvery Machine Learning enthusiast would consider these as very important tools,\nas they deepen the understanding of the characteristics of data. Forecasting is\nused to predict the value of a variable in the future, based on its past\noccurrences. A detailed survey of the various methods that are used for\nforecasting has been presented in this paper. The complete process of\nforecasting, from preprocessing to validation has also been explained\nthoroughly. Various statistical and deep learning models have been considered,\nnotably, ARIMA, Prophet and LSTMs. Hybrid versions of Machine Learning models\nhave also been explored and elucidated. Our work can be used by anyone to\ndevelop a good understanding of the forecasting process, and to identify\nvarious state of the art models which are being used today.",
    "descriptor": "\nComments: 9 Pages, 4 Figures, 9 Formulae, 1 Table, 6th International Conference on Microelectronics, Computing & Communication Systems (MCCS-2021), Paper ID: MCCS21084, Presented at MCCS-2021, Accepted, In Press\n",
    "authors": [
      "Rameshwar Garg",
      "Shriya Barpanda",
      "Girish Rao Salanke N S",
      "Ramya S"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2211.14387"
  },
  {
    "id": "arXiv:2211.14388",
    "title": "Non-Polar Opposites: Analyzing the Relationship Between Echo Chambers  and Hostile Intergroup Interactions on Reddit",
    "abstract": "Previous research has documented the existence of both online echo chambers\nand hostile intergroup interactions. In this paper, we explore the relationship\nbetween these two phenomena by studying the activity of 5.97M Reddit users and\n421M comments posted over 13 years. We examine whether users who are more\nengaged in echo chambers are more hostile when they comment on other\ncommunities. We then create a typology of relationships between political\ncommunities based on whether their users are toxic to each other, whether echo\nchamber-like engagement with these communities is associated with polarization,\nand on the communities' political leanings. We observe both the echo chamber\nand hostile intergroup interaction phenomena, but neither holds universally\nacross communities. Contrary to popular belief, we find that polarizing and\ntoxic speech is more dominant between communities on the same, rather than\nopposing, sides of the political spectrum, especially on the left; however,\nthis mainly points to the collective targeting of political outgroups.",
    "descriptor": "",
    "authors": [
      "Alexandros Efstratiou",
      "Jeremy Blackburn",
      "Tristan Caulfield",
      "Gianluca Stringhini",
      "Savvas Zannettou",
      "Emiliano De Cristofaro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14388"
  },
  {
    "id": "arXiv:2211.14390",
    "title": "Discontinuous Galerkin method for linear wave equations involving  derivatives of the Dirac delta distribution",
    "abstract": "Linear wave equations sourced by a Dirac delta distribution $\\delta(x)$ and\nits derivative(s) can serve as a model for many different phenomena. We\ndescribe a discontinuous Galerkin (DG) method to numerically solve such\nequations with source terms proportional to $\\partial^n \\delta /\\partial x^n$.\nDespite the presence of singular source terms, which imply discontinuous or\npotentially singular solutions, our DG method achieves global spectral accuracy\neven at the source's location. Our DG method is developed for the wave equation\nwritten in fully first-order form. The first-order reduction is carried out\nusing a distributional auxiliary variable that removes some of the source\nterm's singular behavior. While this is helpful numerically, it gives rise to a\ndistributional constraint. We show that a time-independent spurious solution\ncan develop if the initial constraint violation is proportional to $\\delta(x)$.\nNumerical experiments verify this behavior and our scheme's convergence\nproperties by comparing against exact solutions.",
    "descriptor": "\nComments: 15 pages; 4 figures. Accepted to Spectral and High Order Methods for Partial Differential Equations ICOSAHOM 2020+1 (Springer)\n",
    "authors": [
      "Scott E. Field",
      "Sigal Gottlieb",
      "Gaurav Khanna",
      "Ed McClain"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.14390"
  },
  {
    "id": "arXiv:2211.14391",
    "title": "MDA: Availability-Aware Federated Learning Client Selection",
    "abstract": "Recently, a new distributed learning scheme called Federated Learning (FL)\nhas been introduced. FL is designed so that server never collects user-owned\ndata meaning it is great at preserving privacy. FL's process starts with the\nserver sending a model to clients, then the clients train that model using\ntheir data and send the updated model back to the server. Afterward, the server\naggregates all the updates and modifies the global model. This process is\nrepeated until the model converges. This study focuses on an FL setting called\ncross-device FL, which trains based on a large number of clients. Since many\ndevices may be unavailable in cross-device FL, and communication between the\nserver and all clients is extremely costly, only a fraction of clients gets\nselected for training at each round. In vanilla FL, clients are selected\nrandomly, which results in an acceptable accuracy but is not ideal from the\noverall training time perspective, since some clients are slow and can cause\nsome training rounds to be slow. If only fast clients get selected the learning\nwould speed up, but it will be biased toward only the fast clients' data, and\nthe accuracy degrades. Consequently, new client selection techniques have been\nproposed to improve the training time by considering individual clients'\nresources and speed. This paper introduces the first availability-aware\nselection strategy called MDA. The results show that our approach makes\nlearning faster than vanilla FL by up to 6.5%. Moreover, we show that resource\nheterogeneity-aware techniques are effective but can become even better when\ncombined with our approach, making it faster than the state-of-the-art\nselectors by up to 16%. Lastly, our approach selects more unique clients for\ntraining compared to client selectors that only select fast clients, which\nreduces our technique's bias.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Reliability\n",
    "authors": [
      "Amin Eslami Abyane",
      "Steve Drew",
      "Hadi Hemmati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14391"
  },
  {
    "id": "arXiv:2211.14393",
    "title": "FedSysID: A Federated Approach to Sample-Efficient System Identification",
    "abstract": "We study the problem of learning a linear system model from the observations\nof $M$ clients. The catch: Each client is observing data from a different\ndynamical system. This work addresses the question of how multiple clients\ncollaboratively learn dynamical models in the presence of heterogeneity. We\npose this problem as a federated learning problem and characterize the tension\nbetween achievable performance and system heterogeneity. Furthermore, our\nfederated sample complexity result provides a constant factor improvement over\nthe single agent setting. Finally, we describe a meta federated learning\nalgorithm, FedSysID, that leverages existing federated algorithms at the client\nlevel.",
    "descriptor": "",
    "authors": [
      "Han Wang",
      "Leonardo F. Toso",
      "James Anderson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.14393"
  },
  {
    "id": "arXiv:2211.14394",
    "title": "Link Prediction with Non-Contrastive Learning",
    "abstract": "A recent focal area in the space of graph neural networks (GNNs) is graph\nself-supervised learning (SSL), which aims to derive useful node\nrepresentations without labeled data. Notably, many state-of-the-art graph SSL\nmethods are contrastive methods, which use a combination of positive and\nnegative samples to learn node representations. Owing to challenges in negative\nsampling (slowness and model sensitivity), recent literature introduced\nnon-contrastive methods, which instead only use positive samples. Though such\nmethods have shown promising performance in node-level tasks, their suitability\nfor link prediction tasks, which are concerned with predicting link existence\nbetween pairs of nodes (and have broad applicability to recommendation systems\ncontexts) is yet unexplored. In this work, we extensively evaluate the\nperformance of existing non-contrastive methods for link prediction in both\ntransductive and inductive settings. While most existing non-contrastive\nmethods perform poorly overall, we find that, surprisingly, BGRL generally\nperforms well in transductive settings. However, it performs poorly in the more\nrealistic inductive settings where the model has to generalize to links to/from\nunseen nodes. We find that non-contrastive models tend to overfit to the\ntraining graph and use this analysis to propose T-BGRL, a novel non-contrastive\nframework that incorporates cheap corruptions to improve the generalization\nability of the model. This simple modification strongly improves inductive\nperformance in 5/6 of our datasets, with up to a 120% improvement in\nHits@50--all with comparable speed to other non-contrastive baselines and up to\n14x faster than the best-performing contrastive baseline. Our work imparts\ninteresting findings about non-contrastive learning for link prediction and\npaves the way for future researchers to further expand upon this area.",
    "descriptor": "",
    "authors": [
      "William Shiao",
      "Zhichun Guo",
      "Tong Zhao",
      "Evangelos E. Papalexakis",
      "Yozen Liu",
      "Neil Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14394"
  },
  {
    "id": "arXiv:2211.14395",
    "title": "Deep Learning Training Procedure Augmentations",
    "abstract": "Recent advances in Deep Learning have greatly improved performance on various\ntasks such as object detection, image segmentation, sentiment analysis. The\nfocus of most research directions up until very recently has been on beating\nstate-of-the-art results. This has materialized in the utilization of bigger\nand bigger models and techniques which help the training procedure to extract\nmore predictive power out of a given dataset. While this has lead to great\nresults, many of which with real-world applications, other relevant aspects of\ndeep learning have remained neglected and unknown. In this work, we will\npresent several novel deep learning training techniques which, while capable of\noffering significant performance gains they also reveal several interesting\nanalysis results regarding convergence speed, optimization landscape\nsmoothness, and adversarial robustness. The methods presented in this work are\nthe following:\n$\\bullet$ Perfect Ordering Approximation; a generalized model agnostic\ncurriculum learning approach. The results show the effectiveness of the\ntechnique for improving training time as well as offer some new insight into\nthe training process of deep networks.\n$\\bullet$ Cascading Sum Augmentation; an extension of mixup capable of\nutilizing more data points for linear interpolation by leveraging a smoother\noptimization landscape. This can be used for computer vision tasks in order to\nimprove both prediction performance as well as improve passive model\nrobustness.",
    "descriptor": "",
    "authors": [
      "Cristian Simionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14395"
  },
  {
    "id": "arXiv:2211.14396",
    "title": "A Comprehensive Study of Radiomics-based Machine Learning for Fibrosis  Detection",
    "abstract": "Objectives: Early detection of liver fibrosis can help cure the disease or\nprevent disease progression. We perform a comprehensive study of machine\nlearning-based fibrosis detection in CT images using radiomic features to\ndevelop a non-invasive approach to fibrosis detection.\nMethods: Two sets of radiomic features were extracted from spherical ROIs in\nCT images of 182 patients who underwent simultaneous liver biopsy and CT\nexaminations, one set corresponding to biopsy locations and another distant\nfrom biopsy locations. Combinations of contrast, normalization, machine\nlearning model, feature selection method, bin width, and kernel radius were\ninvestigated, each of which were trained and evaluated 100 times with\nrandomized development and test cohorts. The best settings were evaluated based\non their mean test AUC and the best features were determined based on their\nfrequency among the best settings.\nResults: Logistic regression models with NC images normalized using Gamma\ncorrection with $\\gamma = 1.5$ performed best for fibrosis detection. Boruta\nwas the best for radiomic feature selection method. Training a model using\nthese optimal settings and features consisting of first order energy, first\norder kurtosis, and first order skewness, resulted in a model that achieved\nmean test AUCs of 0.7549 and 0.7166 on biopsy-based and non-biopsy ROIs\nrespectively, outperforming a baseline and best models found during the initial\nstudy.\nConclusions: Logistic regression models trained on radiomic features from NC\nimages normalized using Gamma correction with $\\gamma = 1.5$ that underwent\nBoruta feature selection are effective for liver fibrosis detection. Energy,\nkurtosis, and skewness are particularly effective features for fibrosis\ndetection.",
    "descriptor": "",
    "authors": [
      "Jay J. Yoo",
      "Khashayar Namdar",
      "Chris McIntosh",
      "Farzad Khalvati",
      "Patrik Rogalla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.14396"
  },
  {
    "id": "arXiv:2211.14402",
    "title": "An Analysis of Social Biases Present in BERT Variants Across Multiple  Languages",
    "abstract": "Although large pre-trained language models have achieved great success in\nmany NLP tasks, it has been shown that they reflect human biases from their\npre-training corpora. This bias may lead to undesirable outcomes when these\nmodels are applied in real-world settings. In this paper, we investigate the\nbias present in monolingual BERT models across a diverse set of languages\n(English, Greek, and Persian). While recent research has mostly focused on\ngender-related biases, we analyze religious and ethnic biases as well and\npropose a template-based method to measure any kind of bias, based on sentence\npseudo-likelihood, that can handle morphologically complex languages with\ngender-based adjective declensions. We analyze each monolingual model via this\nmethod and visualize cultural similarities and differences across different\ndimensions of bias. Ultimately, we conclude that current methods of probing for\nbias are highly language-dependent, necessitating cultural insights regarding\nthe unique ways bias is expressed in each language and culture (e.g. through\ncoded language, synecdoche, and other similar linguistic concepts). We also\nhypothesize that higher measured social biases in the non-English BERT models\ncorrelate with user-generated content in their training.",
    "descriptor": "\nComments: Accepted to 2022 Trustworthy and Socially Responsible Machine Learning (TSRML 2022) Workshop at NeurIPS 2022\n",
    "authors": [
      "Aristides Milios",
      "Parishad BehnamGhader"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14402"
  },
  {
    "id": "arXiv:2211.14403",
    "title": "Nonlinear Schwarz preconditioning for Quasi-Newton methods",
    "abstract": "We propose the nonlinear restricted additive Schwarz (RAS) preconditioning\nstrategy to improve the convergence speed of limited memory quasi-Newton (QN)\nmethods. We consider both \"left-preconditioning\" and \"right-preconditioning\"\nstrategies. As the application of the nonlinear preconditioning changes the\nstandard gradients and Hessians to their preconditioned counterparts, the\nstandard secant pairs cannot be used to approximate the preconditioned\nHessians. We discuss how to construct the secant pairs in the preconditioned QN\nframework. Finally, we demonstrate the robustness and efficiency of the\npreconditioned QN methods using numerical experiments.",
    "descriptor": "",
    "authors": [
      "Hardik Kothari"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14403"
  },
  {
    "id": "arXiv:2211.14405",
    "title": "Learning Branching Heuristics from Graph Neural Networks",
    "abstract": "Backtracking has been widely used for solving problems in artificial\nintelligence (AI), including constraint satisfaction problems and combinatorial\noptimization problems. Good branching heuristics can efficiently improve the\nperformance of backtracking by helping prune the search space and leading the\nsearch to the most promising direction. In this paper, we first propose a new\ngraph neural network (GNN) model designed using the probabilistic method. From\nthe GNN model, we introduce an approach to learn a branching heuristic for\ncombinatorial optimization problems. In particular, our GNN model learns\nappropriate probability distributions on vertices in given graphs from which\nthe branching heuristic is extracted and used in a backtracking search. Our\nexperimental results for the (minimum) dominating-clique problem show that this\nlearned branching heuristic performs better than the minimum-remaining-values\nheuristic in terms of the number of branches of the whole search tree. Our\napproach introduces a new way of applying GNNs towards enhancing the classical\nbacktracking algorithm used in AI.",
    "descriptor": "",
    "authors": [
      "Congsong Zhang",
      "Yong Gao",
      "James Nastos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14405"
  },
  {
    "id": "arXiv:2211.14406",
    "title": "Exploring Temporal Information Dynamics in Spiking Neural Networks",
    "abstract": "Most existing Spiking Neural Network (SNN) works state that SNNs may utilize\ntemporal information dynamics of spikes. However, an explicit analysis of\ntemporal information dynamics is still missing. In this paper, we ask several\nimportant questions for providing a fundamental understanding of SNNs: What are\ntemporal information dynamics inside SNNs? How can we measure the temporal\ninformation dynamics? How do the temporal information dynamics affect the\noverall learning performance? To answer these questions, we estimate the Fisher\nInformation of the weights to measure the distribution of temporal information\nduring training in an empirical manner. Surprisingly, as training goes on,\nFisher information starts to concentrate in the early timesteps. After\ntraining, we observe that information becomes highly concentrated in earlier\nfew timesteps, a phenomenon we refer to as temporal information concentration.\nWe observe that the temporal information concentration phenomenon is a common\nlearning feature of SNNs by conducting extensive experiments on various\nconfigurations such as architecture, dataset, optimization strategy, time\nconstant, and timesteps. Furthermore, to reveal how temporal information\nconcentration affects the performance of SNNs, we design a loss function to\nchange the trend of temporal information. We find that temporal information\nconcentration is crucial to building a robust SNN but has little effect on\nclassification accuracy. Finally, we propose an efficient iterative pruning\nmethod based on our observation on temporal information concentration. Code is\navailable at\nhttps://github.com/Intelligent-Computing-Lab-Yale/Exploring-Temporal-Information-Dynamics-in-Spiking-Neural-Networks.",
    "descriptor": "\nComments: Accepted to AAAI2023\n",
    "authors": [
      "Youngeun Kim",
      "Yuhang Li",
      "Hyoungseob Park",
      "Yeshwanth Venkatesha",
      "Anna Hambitzer",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.14406"
  },
  {
    "id": "arXiv:2211.14407",
    "title": "Faster Algorithm for Structured John Ellipsoid Computation",
    "abstract": "Computing John Ellipsoid is a fundamental problem in machine learning and\nconvex optimization, where the goal is to compute the ellipsoid with maximal\nvolume that lies in a given convex centrally symmetric polytope defined by a\nmatrix $A \\in \\mathbb{R}^{n \\times d}$. In this work, we show two faster\nalgorithms for approximating the John Ellipsoid.\n$\\bullet$ For sparse matrix $A$, we can achieve nearly input sparsity time\n$\\mathrm{nnz}(A) + d^{\\omega}$, where $\\omega$ is exponent of matrix\nmultiplication. Currently, $\\omega \\approx 2.373$.\n$\\bullet$ For the matrix $A$ which has small treewidth $\\tau$, we can achieve\n$n \\tau^2$ time.\nTherefore, we significantly improves the state-of-the-art results on\napproximating the John Ellipsoid for centrally symmetric polytope [Cohen,\nCousins, Lee, and Yang COLT 2019] which takes $nd^2$ time.",
    "descriptor": "",
    "authors": [
      "Zhao Song",
      "Xin Yang",
      "Yuanyuan Yang",
      "Tianyi Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.14407"
  },
  {
    "id": "arXiv:2211.14409",
    "title": "Domain-Independent Dynamic Programming: Generic State Space Search for  Combinatorial Optimization",
    "abstract": "For combinatorial optimization problems, model-based approaches such as\nmixed-integer programming (MIP) and constraint programming (CP) aim to decouple\nmodeling and solving a problem: the 'holy grail' of declarative problem\nsolving. We propose domain-independent dynamic programming (DIDP), a new\nmodel-based paradigm based on dynamic programming (DP). While DP is not new, it\nhas typically been implemented as a problem-specific method. We propose Dynamic\nProgramming Description Language (DyPDL), a formalism to define DP models, and\ndevelop Cost-Algebraic A* Solver for DyPDL (CAASDy), a generic solver for DyPDL\nusing state space search. We formalize existing problem-specific DP and state\nspace search methods for combinatorial optimization problems as DP models in\nDyPDL. Using CAASDy and commercial MIP and CP solvers, we experimentally\ncompare the DP models with existing MIP and CP models, showing that, despite\nits nascent nature, CAASDy outperforms MIP and CP on a number of common problem\nclasses.",
    "descriptor": "",
    "authors": [
      "Ryo Kuroiwa",
      "J. Christopher Beck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14409"
  },
  {
    "id": "arXiv:2211.14411",
    "title": "c-TPE: Generalizing Tree-structured Parzen Estimator with Inequality  Constraints for Continuous and Categorical Hyperparameter Optimization",
    "abstract": "Hyperparameter optimization (HPO) is crucial for strong performance of deep\nlearning algorithms. A widely-used versatile HPO method is a variant of\nBayesian optimization called tree-structured Parzen estimator (TPE), which\nsplits data into good and bad groups and uses the density ratio of those groups\nas an acquisition function (AF). However, real-world applications often have\nsome constraints, such as memory requirements, or latency. In this paper, we\npresent an extension of TPE to constrained optimization (c-TPE) via simple\nfactorization of AFs. The experiments demonstrate c-TPE is robust to various\nconstraint levels and exhibits the best average rank performance among existing\nmethods with statistical significance on search spaces with categorical\nparameters on 81 settings.",
    "descriptor": "",
    "authors": [
      "Shuhei Watanabe",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14411"
  },
  {
    "id": "arXiv:2211.14417",
    "title": "EasyMLServe: Easy Deployment of REST Machine Learning Services",
    "abstract": "Various research domains use machine learning approaches because they can\nsolve complex tasks by learning from data. Deploying machine learning models,\nhowever, is not trivial and developers have to implement complete solutions\nwhich are often installed locally and include Graphical User Interfaces (GUIs).\nDistributing software to various users on-site has several problems. Therefore,\nwe propose a concept to deploy software in the cloud. There are several\nframeworks available based on Representational State Transfer (REST) which can\nbe used to implement cloud-based machine learning services. However, machine\nlearning services for scientific users have special requirements that\nstate-of-the-art REST frameworks do not cover completely. We contribute an\nEasyMLServe software framework to deploy machine learning services in the cloud\nusing REST interfaces and generic local or web-based GUIs. Furthermore, we\napply our framework on two real-world applications, \\ie, energy time-series\nforecasting and cell instance segmentation. The EasyMLServe framework and the\nuse cases are available on GitHub.",
    "descriptor": "",
    "authors": [
      "Oliver Neumann",
      "Marcel Schilling",
      "Markus Reischl",
      "Ralf Mikut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.14417"
  },
  {
    "id": "arXiv:2211.14419",
    "title": "Panoramic Video Salient Object Detection with Ambisonic Audio Guidance",
    "abstract": "Video salient object detection (VSOD), as a fundamental computer vision\nproblem, has been extensively discussed in the last decade. However, all\nexisting works focus on addressing the VSOD problem in 2D scenarios. With the\nrapid development of VR devices, panoramic videos have been a promising\nalternative to 2D videos to provide immersive feelings of the real world. In\nthis paper, we aim to tackle the video salient object detection problem for\npanoramic videos, with their corresponding ambisonic audios. A multimodal\nfusion module equipped with two pseudo-siamese audio-visual context fusion\n(ACF) blocks is proposed to effectively conduct audio-visual interaction. The\nACF block equipped with spherical positional encoding enables the fusion in the\n3D context to capture the spatial correspondence between pixels and sound\nsources from the equirectangular frames and ambisonic audios. Experimental\nresults verify the effectiveness of our proposed components and demonstrate\nthat our method achieves state-of-the-art performance on the ASOD60K dataset.",
    "descriptor": "",
    "authors": [
      "Xiang Li",
      "Haoyuan Cao",
      "Shijie Zhao",
      "Junlin Li",
      "Li Zhang",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14419"
  },
  {
    "id": "arXiv:2211.14420",
    "title": "Photo Rater: Photographs Auto-Selector with Deep Learning",
    "abstract": "Photo Rater is a computer vision project that uses neural networks to help\nphotographers select the best photo among those that are taken based on the\nsame scene. This process is usually referred to as \"culling\" in photography,\nand it can be tedious and time-consuming if done manually. Photo Rater utilizes\nthree separate neural networks to complete such a task: one for general image\nquality assessment, one for classifying whether the photo is blurry (either due\nto unsteady hands or out-of-focusness), and one for assessing general\naesthetics (including the composition of the photo, among others). After\nfeeding the image through each neural network, Photo Rater outputs a final\nscore for each image, ranking them based on this score and presenting it to the\nuser.",
    "descriptor": "",
    "authors": [
      "Wentao Guo",
      "Charlie Ruan",
      "Claire Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14420"
  },
  {
    "id": "arXiv:2211.14422",
    "title": "Quantitative Method for Security Situation of the Power Information  Network Based on the Evolutionary Neural Network",
    "abstract": "Cybersecurity is the security cornerstone of digital transformation of the\npower grid and construction of new power systems. The traditional network\nsecurity situation quantification method only analyzes from the perspective of\nnetwork performance, ignoring the impact of various power application services\non the security situation, so the quantification results cannot fully reflect\nthe power information network risk state. This study proposes a method for\nquantifying security situation of the power information network based on the\nevolutionary neural network. First, the security posture system architecture is\ndesigned by analyzing the business characteristics of power information network\napplications. Second, combining the importance of power application business,\nthe spatial element index system of coupled interconnection is established from\nthree dimensions of network reliability, threat, and vulnerability. Then, the\nBP neural network optimized by the genetic evolutionary algorithm is\nincorporated into the element index calculation process, and the quantitative\nmodel of security posture of the power information network based on the\nevolutionary neural network is constructed. Finally, a simulation experiment\nenvironment is built according to a power sector network topology, and the\neffectiveness and robustness of the method proposed in the study are verified.",
    "descriptor": "\nComments: Frontiers in Energy Research\n",
    "authors": [
      "Quande Yuan",
      "Yuzhen Pi",
      "Lei Kou",
      "Fangfang Zhang",
      "Bo Ye"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14422"
  },
  {
    "id": "arXiv:2211.14424",
    "title": "Supervised Contrastive Prototype Learning: Augmentation Free Robust  Neural Network",
    "abstract": "Transformations in the input space of Deep Neural Networks (DNN) lead to\nunintended changes in the feature space. Almost perceptually identical inputs,\nsuch as adversarial examples, can have significantly distant feature\nrepresentations. On the contrary, Out-of-Distribution (OOD) samples can have\nhighly similar feature representations to training set samples. Our theoretical\nanalysis for DNNs trained with a categorical classification head suggests that\nthe inflexible logit space restricted by the classification problem size is one\nof the root causes for the lack of $\\textit{robustness}$. Our second\nobservation is that DNNs over-fit to the training augmentation technique and do\nnot learn $\\textit{nuance invariant}$ representations. Inspired by the recent\nsuccess of prototypical and contrastive learning frameworks for both improving\nrobustness and learning nuance invariant representations, we propose a training\nframework, $\\textbf{Supervised Contrastive Prototype Learning}$ (SCPL). We use\nN-pair contrastive loss with prototypes of the same and opposite classes and\nreplace a categorical classification head with a $\\textbf{Prototype\nClassification Head}$ (PCH). Our approach is $\\textit{sample efficient}$, does\nnot require $\\textit{sample mining}$, can be implemented on any existing DNN\nwithout modification to their architecture, and combined with other training\naugmentation techniques. We empirically evaluate the $\\textbf{clean}$\nrobustness of our method on out-of-distribution and adversarial samples. Our\nframework outperforms other state-of-the-art contrastive and prototype learning\napproaches in $\\textit{robustness}$.",
    "descriptor": "",
    "authors": [
      "Iordanis Fostiropoulos",
      "Laurent Itti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14424"
  },
  {
    "id": "arXiv:2211.14425",
    "title": "PatchGT: Transformer over Non-trainable Clusters for Learning Graph  Representations",
    "abstract": "Recently the Transformer structure has shown good performances in graph\nlearning tasks. However, these Transformer models directly work on graph nodes\nand may have difficulties learning high-level information. Inspired by the\nvision transformer, which applies to image patches, we propose a new\nTransformer-based graph neural network: Patch Graph Transformer (PatchGT).\nUnlike previous transformer-based models for learning graph representations,\nPatchGT learns from non-trainable graph patches, not from nodes directly. It\ncan help save computation and improve the model performance. The key idea is to\nsegment a graph into patches based on spectral clustering without any trainable\nparameters, with which the model can first use GNN layers to learn patch-level\nrepresentations and then use Transformer to obtain graph-level representations.\nThe architecture leverages the spectral information of graphs and combines the\nstrengths of GNNs and Transformers. Further, we show the limitations of\nprevious hierarchical trainable clusters theoretically and empirically. We also\nprove the proposed non-trainable spectral clustering method is permutation\ninvariant and can help address the information bottlenecks in the graph.\nPatchGT achieves higher expressiveness than 1-WL-type GNNs, and the empirical\nstudy shows that PatchGT achieves competitive performances on benchmark\ndatasets and provides interpretability to its predictions. The implementation\nof our algorithm is released at our Github repo:\nhttps://github.com/tufts-ml/PatchGT.",
    "descriptor": "\nComments: 25 pages, 10 figures\n",
    "authors": [
      "Han Gao",
      "Xu Han",
      "Jiaoyang Huang",
      "Jian-Xun Wang",
      "Li-Ping Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.14425"
  },
  {
    "id": "arXiv:2211.14426",
    "title": "A Critical Review of Traffic Signal Control and A Novel Unified View of  Reinforcement Learning and Model Predictive Control Approaches for Adaptive  Traffic Signal Control",
    "abstract": "Recent years have witnessed substantial growth in adaptive traffic signal\ncontrol (ATSC) methodologies that improve transportation network efficiency,\nespecially in branches leveraging artificial intelligence based optimization\nand control algorithms such as reinforcement learning as well as conventional\nmodel predictive control. However, lack of cross-domain analysis and comparison\nof the effectiveness of applied methods in ATSC research limits our\nunderstanding of existing challenges and research directions. This chapter\nproposes a novel unified view of modern ATSCs to identify common ground as well\nas differences and shortcomings of existing methodologies with the ultimate\ngoal to facilitate cross-fertilization and advance the state-of-the-art. The\nunified view applies the mathematical language of the Markov decision process,\ndescribes the process of controller design from both the world (problem) and\nsolution modeling perspectives. The unified view also analyses systematic\nissues commonly ignored in existing studies and suggests future potential\ndirections to resolve these issues.",
    "descriptor": "\nComments: 32 pages, 19 figures. This is a draft chapter/article. The final version is available in Handbook on Artificial Intelligence in Transport, edited by Hussein Dia, forthcoming 2023, Edward Elgar Publishing Ltd\n",
    "authors": [
      "Xiaoyu Wang",
      "Scott Sanner",
      "Baher Abdulhai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14426"
  },
  {
    "id": "arXiv:2211.14428",
    "title": "Utility Assessment of Synthetic Data Generation Methods",
    "abstract": "Big data analysis poses the dual problem of privacy preservation and utility,\ni.e., how accurate data analyses remain after transforming original data in\norder to protect the privacy of the individuals that the data is about - and\nwhether they are accurate enough to be meaningful. In this paper, we thus\ninvestigate across several datasets whether different methods of generating\nfully synthetic data vary in their utility a priori (when the specific analyses\nto be performed on the data are not known yet), how closely their results\nconform to analyses on original data a posteriori, and whether these two\neffects are correlated. We find some methods (decision-tree based) to perform\nbetter than others across the board, sizeable effects of some choices of\nimputation parameters (notably the number of released datasets), no correlation\nbetween broad utility metrics and analysis accuracy, and varying correlations\nfor narrow metrics. We did get promising findings for classification tasks when\nusing synthetic data for training machine learning models, which we consider\nworth exploring further also in terms of mitigating privacy attacks against ML\nmodels such as membership inference and model inversion.",
    "descriptor": "\nComments: Published in Privacy in Statistical Databases Conference 2022 USB Proceedings\n",
    "authors": [
      "Md Sakib Nizam Khan",
      "Niklas Reje",
      "Sonja Buchegger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.14428"
  },
  {
    "id": "arXiv:2211.14430",
    "title": "Effectiveness of an Online Course in Programming in a State University  in the Philippines",
    "abstract": "Online courses, as a pedagogical approach to teaching, boomed during this\nCoronavirus Disease 2019 pandemic era. Universities shifted from traditional\nface to face classes to online distance learning due to the cause of the\npandemic. This study aimed to determine how effective an online course is in\nlearning a programming course. The study utilized mixed method research applied\nthrough a validated survey questionnaire consisting of closed and open ended\nquestions. Python programming was the course selected to undergo the study and\nunderwent an evaluation to determine the students' responses. Student\nrespondents are from Bulacan State University, a state university in the\nPhilippines, under the Bachelor of Science in Information Technology program.\nBased on their responses, the students found that the online Python programming\nwas Very Effective, with an overall mean of 4.49. This result shows that\nstudents found the online course effective, provided the proper course design\nand content, allowed them to spend enough time finishing tasks, and provided\ncommunication and interaction with their instructor and fellow students.\nAdditionally, students gave overwhelmingly positive responses when asked what\ntheir instructors had done well on the course delivery and provided insightful\nand constructive comments for further enhancement and delivery of the course.\nThis study found that most students strongly agreed and believed in the\neffectiveness of delivering the Python Programming course asynchronously. With\nsuch positive results from the student's perspective and evaluation, the course\ncan be enhanced to continue providing quality education at Bulacan State\nUniversity.",
    "descriptor": "",
    "authors": [
      "Aaron Paul M. Dela Rosa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.14430"
  },
  {
    "id": "arXiv:2211.14432",
    "title": "A1 SLAM: Quadruped SLAM using the A1's Onboard Sensors",
    "abstract": "Quadrupeds are robots that have been of interest in the past few years due to\ntheir versatility in navigating across various terrain and utility in several\napplications. For quadrupeds to navigate without a predefined map a priori,\nthey must rely on SLAM approaches to localize and build the map of the\nenvironment. Despite the surge of interest and research development in SLAM and\nquadrupeds, there still has yet to be an open-source package that capitalizes\non the onboard sensors of an affordable quadruped. This motivates the A1 SLAM\npackage, which is an open-source ROS package that provides the Unitree A1\nquadruped with real-time, high performing SLAM capabilities using the default\nsensors shipped with the robot. A1 SLAM solves the PoseSLAM problem using the\nfactor graph paradigm to optimize for the poses throughout the trajectory. A\nmajor design feature of the algorithm is using a sliding window of fully\nconnected LiDAR odometry factors. A1 SLAM has been benchmarked against Google's\nCartographer and has showed superior performance especially with trajectories\nexperiencing aggressive motion.",
    "descriptor": "\nComments: 8 pages, 5 figures, 4 tables\n",
    "authors": [
      "Jerred Chen",
      "Frank Dellaert"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14432"
  },
  {
    "id": "arXiv:2211.14434",
    "title": "Multistep prediction for short-term wind speed based on the MLP and LSTM  method with rankpooling",
    "abstract": "The actual wind speed data suffers from the intermittent and fluctuating\nproperty, which implies that it is very difficult to forecast wind speed with\nhigh accuracy by applying single or shallow models. Hence, with the purpose of\nimproving the forecasting accuracy and obtain better forecasting results, in\nthis paper, a novel hybrid deep learning model is proposed for multistep\nforecasting of wind speed, which is intuitively abbreviated as LR-FFT-RP-LSTM\nand LR-FFT-RP-LSTM. Under these formulated model, the rankpooling method is\nfirstly presented to extract local features of the raw meteorological data, and\nthe Fast Fourier Transformation (FFT) is adopted to extract local and global\nfeatures of the raw meteorological data to obtain pre-processed data, and the\ndata obtained is then integrated with the original data using the two\nprocedures to produce two input datasets. Then, deep learning model named\nmulti-layer perceptron method (MLP) and long short-term memory (LSTM) are\nadopted to predict the wind speed dataset. The target prediction results are\nthen obtained by integrating the preliminary prediction findings using the\nlinear regression method.Practical wind speed data from 2010 to 2020 are\nexploited to evaluate the performance of the proposed model. Case study results\nindicate that the proposed model for wind speed has a superior forecasting\ncapability. Moreover, the proposed hybrid model is very competitive compared to\nthe state-of-the-art single model and other hybrid models involved in this\npaper.",
    "descriptor": "",
    "authors": [
      "Hailong Shu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.14434"
  },
  {
    "id": "arXiv:2211.14437",
    "title": "Unsupervised User-Based Insider Threat Detection Using Bayesian Gaussian  Mixture Models",
    "abstract": "Insider threats are a growing concern for organizations due to the amount of\ndamage that their members can inflict by combining their privileged access and\ndomain knowledge. Nonetheless, the detection of such threats is challenging,\nprecisely because of the ability of the authorized personnel to easily conduct\nmalicious actions and because of the immense size and diversity of audit data\nproduced by organizations in which the few malicious footprints are hidden. In\nthis paper, we propose an unsupervised insider threat detection system based on\naudit data using Bayesian Gaussian Mixture Models. The proposed approach\nleverages a user-based model to optimize specific behaviors modelization and an\nautomatic feature extraction system based on Word2Vec for ease of use in a\nreal-life scenario. The solution distinguishes itself by not requiring data\nbalancing nor to be trained only on normal instances, and by its little domain\nknowledge required to implement. Still, results indicate that the proposed\nmethod competes with state-of-the-art approaches, presenting a good recall of\n88\\%, accuracy and true negative rate of 93%, and a false positive rate of\n6.9%. For our experiments, we used the benchmark dataset CERT version 4.2.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Simon Bertrand",
      "Nadia Tawbi",
      "Jos\u00e9e Desharnais"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14437"
  },
  {
    "id": "arXiv:2211.14438",
    "title": "BERN-NN: Tight Bound Propagation For Neural Networks Using Bernstein  Polynomial Interval Arithmetic",
    "abstract": "In this paper, we present BERN-NN as an efficient tool to perform bound\npropagation of Neural Networks (NNs). Bound propagation is a critical step in\nwide range of NN model checkers and reachability analysis tools. Given a\nbounded input set, bound propagation algorithms aim to compute tight bounds on\nthe output of the NN. So far, linear and convex optimizations have been used to\nperform bound propagation. Since neural networks are highly non-convex,\nstate-of-the-art bound propagation techniques suffer from introducing large\nerrors. To circumvent such drawback, BERN-NN approximates the bounds of each\nneuron using a class of polynomials called Bernstein polynomials. Bernstein\npolynomials enjoy several interesting properties that allow BERN-NN to obtain\ntighter bounds compared to those relying on linear and convex approximations.\nBERN-NN is efficiently parallelized on graphic processing units (GPUs).\nExtensive numerical results show that bounds obtained by BERN-NN are orders of\nmagnitude tighter than those obtained by state-of-the-art verifiers such as\nlinear programming and linear interval arithmetic. Moreoveer, BERN-NN is both\nfaster and produces tighter outputs compared to convex programming approaches\nlike alpha-CROWN.",
    "descriptor": "",
    "authors": [
      "Wael Fatnassi",
      "Haitham Khedr",
      "Valen Yamamoto",
      "Yasser Shoukry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14438"
  },
  {
    "id": "arXiv:2211.14439",
    "title": "Incentive-boosted Federated Crowdsourcing",
    "abstract": "Crowdsourcing is a favorable computing paradigm for processing computer-hard\ntasks by harnessing human intelligence. However, generic crowdsourcing systems\nmay lead to privacy-leakage through the sharing of worker data. To tackle this\nproblem, we propose a novel approach, called iFedCrowd (incentive-boosted\nFederated Crowdsourcing), to manage the privacy and quality of crowdsourcing\nprojects. iFedCrowd allows participants to locally process sensitive data and\nonly upload encrypted training models, and then aggregates the model parameters\nto build a shared server model to protect data privacy. To motivate workers to\nbuild a high-quality global model in an efficacy way, we introduce an incentive\nmechanism that encourages workers to constantly collect fresh data to train\naccurate client models and boosts the global model training. We model the\nincentive-based interaction between the crowdsourcing platform and\nparticipating workers as a Stackelberg game, in which each side maximizes its\nown profit. We derive the Nash Equilibrium of the game to find the optimal\nsolutions for the two sides. Experimental results confirm that iFedCrowd can\ncomplete secure crowdsourcing projects with high quality and efficiency.",
    "descriptor": "\nComments: Accepted by the Thirty-Seventh AAAI Conference on Artificial Intelligence(AAAI2023)\n",
    "authors": [
      "Xiangping Kang",
      "Guoxian Yu",
      "Jun Wang",
      "Wei Guo",
      "Carlotta Domeniconi",
      "Jinglin Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.14439"
  },
  {
    "id": "arXiv:2211.14440",
    "title": "Don't Watch Me: A Spatio-Temporal Trojan Attack on  Deep-Reinforcement-Learning-Augment Autonomous Driving",
    "abstract": "Deep reinforcement learning (DRL) is one of the most popular algorithms to\nrealize an autonomous driving (AD) system. The key success factor of DRL is\nthat it embraces the perception capability of deep neural networks which,\nhowever, have been proven vulnerable to Trojan attacks. Trojan attacks have\nbeen widely explored in supervised learning (SL) tasks (e.g., image\nclassification), but rarely in sequential decision-making tasks solved by DRL.\nHence, in this paper, we explore Trojan attacks on DRL for AD tasks. First, we\npropose a spatio-temporal DRL algorithm based on the recurrent neural network\nand attention mechanism to prove that capturing spatio-temporal traffic\nfeatures is the key factor to the effectiveness and safety of a DRL-augment AD\nsystem. We then design a spatial-temporal Trojan attack on DRL policies, where\nthe trigger is hidden in a sequence of spatial and temporal traffic features,\nrather than a single instant state used in existing Trojan on SL and DRL tasks.\nWith our Trojan, the adversary acts as a surrounding normal vehicle and can\ntrigger attacks via specific spatial-temporal driving behaviors, rather than\nphysical or wireless access. Through extensive experiments, we show that while\ncapturing spatio-temporal traffic features can improve the performance of DRL\nfor different AD tasks, they suffer from Trojan attacks since our designed\nTrojan shows high stealthy (various spatio-temporal trigger patterns),\neffective (less than 3.1\\% performance variance rate and more than 98.5\\%\nattack success rate), and sustainable to existing advanced defenses.",
    "descriptor": "",
    "authors": [
      "Yinbo Yu",
      "Jiajia Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14440"
  },
  {
    "id": "arXiv:2211.14442",
    "title": "Contract-Backed Digital Cash",
    "abstract": "We characterize digital cash as the digital equivalent of physical cash:\nsecure, fungible, decentralized, directly controlled, privacy-preserving; but\nenhanced with qualitatively new functionality. It is extremely efficiently\ntransferable and, most importantly, transactional or, more generally,\ncontract-backed. This facilitates fully automated, guaranteed transactional\nexecution of atomic resource exchanges and more complex contracts, without a\nmultitude of intermediaries and expensive or slow semi-manual processes.\nA didactic objective is separating money characteristics from technology\naspects such as specific blockchain and distributed ledger systems to help\ndisentangle discussions of digital money design from implementation techniques.\nWe finally discuss the power and role of programmable (contract-backed)\ndigital money in case studies: tokenization of invoice debt using smart\ncontracts on Ethereum, with stablecoins serving as digital money; smart\ncontracts for disbursing payments transparently and reliably in accordance with\nsocial legislation; and a Danish e-krone for crowdfunding public and private\ncommunity projets.\nThese contributions are made in independent chapters by participants of the\nWorking Group on Digital Cash at Copenhagen FinTech in 2018 and 2019, which\nhave not been published before.\nCollectively, the contributions illustrate the design space and potential of\ndigital money when powered by smart digital contracts that effectively\neliminate both counterparty risk (somebody does not pay or does not deliver)\nand settlement risk (a trade fails and needs to be aborted) orders of magnitude\nfaster than in current financial practice.",
    "descriptor": "\nComments: Editor: Fritz Henglein. Authors: Fritz Henglein (Chapters 1, 2, 3, 5), Fritz Henglein and Christian Olesen (Chapter 4), Gert Sylvest (Chapter 6), S{\\o}ren Debois (Chapter 7), Morten C. Nielsen and Christian Olesen (Chapter 8)\n",
    "authors": [
      "S\u00f8ren Debois",
      "Fritz Henglein",
      "Morten C. Nielsen",
      "Christian Olesen",
      "Gert Sylvest"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.14442"
  },
  {
    "id": "arXiv:2211.14443",
    "title": "Siamese based Neural Network for Offline Writer Identification on word  level data",
    "abstract": "Handwriting recognition is one of the desirable attributes of document\ncomprehension and analysis. It is concerned with the documents writing style\nand characteristics that distinguish the authors. The diversity of text images,\nnotably in images with varying handwriting, makes the process of learning good\nfeatures difficult in cases where little data is available. In this paper, we\npropose a novel scheme to identify the author of a document based on the input\nword image. Our method is text independent and does not impose any constraint\non the size of the input image under examination. To begin with, we detect\ncrucial components in handwriting and extract regions surrounding them using\nScale Invariant Feature Transform (SIFT). These patches are designed to capture\nindividual writing features (including allographs, characters, or combinations\nof characters) that are likely to be unique for an individual writer. These\nfeatures are then passed through a deep Convolutional Neural Network (CNN) in\nwhich the weights are learned by applying the concept of Similarity learning\nusing Siamese network. Siamese network enhances the discrimination power of CNN\nby mapping similarity between different pairs of input image. Features learned\nat different scales of the extracted SIFT key-points are encoded using Sparse\nPCA, each components of the Sparse PCA is assigned a saliency score signifying\nits level of significance in discriminating different writers effectively.\nFinally, the weighted Sparse PCA corresponding to each SIFT key-points is\ncombined to arrive at a final classification score for each writer. The\nproposed algorithm was evaluated on two publicly available databases (namely\nIAM and CVL) and is able to achieve promising result, when compared with other\ndeep learning based algorithm.",
    "descriptor": "",
    "authors": [
      "Vineet Kumar",
      "Suresh Sundaram"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14443"
  },
  {
    "id": "arXiv:2211.14444",
    "title": "MiftyCoin (MFT): A Cryptocurrency Mined with Proof of Human Work",
    "abstract": "We present in this paper a cryptocurrency called Mobile Fungible Token (MFT)\nor \"MiftyCoin\", which is mined with Proof of Human Work (PoH). Blocks in MFT's\nblockchain are mined by users solving unique 24-tile puzzles autogenerated as a\nfunction of block hash values. Each tile in the puzzle is a 4-sided domino-like\nsquare, where the number of dots per square is a function of a subset of the\nbits of a corresponding byte in the block's hash value. The objective is to\nfind a set of tile moves that end up in an arrangement with an optimal score;\nwhere each matching tile side increases the score by one. The block with the\nhighest score gets a reward. More information about MiftyCoin is available at:\nhttps://www.miftycoin.com.",
    "descriptor": "",
    "authors": [
      "Javier A. Arroyo-Figueroa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.14444"
  },
  {
    "id": "arXiv:2211.14445",
    "title": "LAPTNet: LiDAR-Aided Perspective Transform Network",
    "abstract": "Semantic grids are a useful representation of the environment around a robot.\nThey can be used in autonomous vehicles to concisely represent the scene around\nthe car, capturing vital information for downstream tasks like navigation or\ncollision assessment. Information from different sensors can be used to\ngenerate these grids. Some methods rely only on RGB images, whereas others\nchoose to incorporate information from other sensors, such as radar or LiDAR.\nIn this paper, we present an architecture that fuses LiDAR and camera\ninformation to generate semantic grids. By using the 3D information from a\nLiDAR point cloud, the LiDAR-Aided Perspective Transform Network (LAPTNet) is\nable to associate features in the camera plane to the bird's eye view without\nhaving to predict any depth information about the scene. Compared to\nstate-of-theart camera-only methods, LAPTNet achieves an improvement of up to\n8.8 points (or 38.13%) over state-of-art competing approaches for the classes\nproposed in the NuScenes dataset validation split.",
    "descriptor": "\nComments: ICARCV 2022 - 17th International Conference on Control, Automation, Robotics and Vision, Dec 2022, Singapore, Singapore\n",
    "authors": [
      "Manuel Alejandro Diaz-Zapata",
      "\u00d6zg\u00fcr Erkent",
      "Christian Laugier",
      "Jilles Dibangoye",
      "David Sierra Gonz\u00e1lez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14445"
  },
  {
    "id": "arXiv:2211.14446",
    "title": "Sign Language to Text Conversion in Real Time using Transfer Learning",
    "abstract": "The people in the world who are hearing impaired face many obstacles in\ncommunication and require an interpreter to comprehend what a person is saying.\nThere has been constant scientific research and the existing models lack the\nability to make accurate predictions. So we propose a deep learning model\ntrained on the ASL i.e. American Sign Language which will take action in the\nform of American Sign Language as input and translate it into text. To achieve\nthe former a Convolution Neural Network based VGG16 architecture is used as\nwell as a TensorFlow model for image classification and we have improved the\naccuracy of the latter by over 4%. There has been an improvement in accuracy\nfrom 94% of CNN to 98.7% by Transfer Learning. An application with the deep\nlearning model integrated has also been built.",
    "descriptor": "\nComments: Will be published in IEEE Explore. Presented at the 3rd Global Conference for Advancement in Technology (GCAT), Bangalore, India\n",
    "authors": [
      "Shubham Thakar",
      "Samveg Shah",
      "Bhavya Shah",
      "Anant V. Nimkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14446"
  },
  {
    "id": "arXiv:2211.14447",
    "title": "Sentence-Level Sign Language Recognition Framework",
    "abstract": "We present two solutions to sentence-level SLR. Sentence-level SLR required\nmapping videos of sign language sentences to sequences of gloss labels.\nConnectionist Temporal Classification (CTC) has been used as the classifier\nlevel of both models. CTC is used to avoid pre-segmenting the sentences into\nindividual words. The first model is an LRCN-based model, and the second model\nis a Multi-Cue Network. LRCN is a model in which a CNN as a feature extractor\nis applied to each frame before feeding them into an LSTM. In the first\napproach, no prior knowledge has been leveraged. Raw frames are fed into an\n18-layer LRCN with a CTC on top. In the second approach, three main\ncharacteristics (hand shape, hand position, and hand movement information)\nassociated with each sign have been extracted using Mediapipe. 2D landmarks of\nhand shape have been used to create the skeleton of the hands and then are fed\nto a CONV-LSTM model. Hand locations and hand positions as relative distance to\nhead are fed to separate LSTMs. All three sources of information have been then\nintegrated into a Multi-Cue network with a CTC classification layer. We\nevaluated the performance of proposed models on RWTH-PHOENIX-Weather. After\nperforming an excessive search on model hyper-parameters such as the number of\nfeature maps, input size, batch size, sequence length, LSTM memory cell,\nregularization, and dropout, we were able to achieve 35 Word Error Rate (WER).",
    "descriptor": "",
    "authors": [
      "Atra Akandeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14447"
  },
  {
    "id": "arXiv:2211.14448",
    "title": "How to Backpropagate through Hungarian in Your DETR?",
    "abstract": "The DEtection TRansformer (DETR) approach, which uses a transformer\nencoder-decoder architecture and a set-based global loss, has become a building\nblock in many transformer based applications. However, as originally presented,\nthe assignment cost and the global loss are not aligned, i.e., reducing the\nformer is likely but not guaranteed to reduce the latter. And the issue of\ngradient is ignored when a combinatorial solver such as Hungarian is used. In\nthis paper we show that the global loss can be expressed as the sum of an\nassignment-independent term, and an assignment-dependent term which can be used\nto define the assignment cost matrix. Recent results on generalized gradients\nof optimal assignment cost with respect to parameters of an assignment problem\nare then used to define generalized gradients of the loss with respect to\nnetwork parameters, and backpropagation is carried out properly. Our\nexperiments using the same loss weights show interesting convergence properties\nand a potential for further performance improvements.",
    "descriptor": "",
    "authors": [
      "Lingji Chen",
      "Alok Sharma",
      "Chinmay Shirore",
      "Chengjie Zhang",
      "Balarama Raju Buddharaju"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.14448"
  },
  {
    "id": "arXiv:2211.14449",
    "title": "PatchBlender: A Motion Prior for Video Transformers",
    "abstract": "Transformers have become one of the dominant architectures in the field of\ncomputer vision. However, there are yet several challenges when applying such\narchitectures to video data. Most notably, these models struggle to model the\ntemporal patterns of video data effectively. Directly targeting this issue, we\nintroduce PatchBlender, a learnable blending function that operates over patch\nembeddings across the temporal dimension of the latent space. We show that our\nmethod is successful at enabling vision transformers to encode the temporal\ncomponent of video data. On Something-Something v2 and MOVi-A, we show that our\nmethod improves the performance of a ViT-B. PatchBlender has the advantage of\nbeing compatible with almost any Transformer architecture and since it is\nlearnable, the model can adaptively turn on or off the prior. It is also\nextremely lightweight compute-wise, 0.005% the GFLOPs of a ViT-B.",
    "descriptor": "",
    "authors": [
      "Gabriele Prato",
      "Yale Song",
      "Janarthanan Rajendran",
      "R Devon Hjelm",
      "Neel Joshi",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14449"
  },
  {
    "id": "arXiv:2211.14450",
    "title": "Text-Aware Dual Routing Network for Visual Question Answering",
    "abstract": "Visual question answering (VQA) is a challenging task to provide an accurate\nnatural language answer given an image and a natural language question about\nthe image. It involves multi-modal learning, i.e., computer vision (CV) and\nnatural language processing (NLP), as well as flexible answer prediction for\nfree-form and open-ended answers. Existing approaches often fail in cases that\nrequire reading and understanding text in images to answer questions. In\npractice, they cannot effectively handle the answer sequence derived from text\ntokens because the visual features are not text-oriented. To address the above\nissues, we propose a Text-Aware Dual Routing Network (TDR) which simultaneously\nhandles the VQA cases with and without understanding text information in the\ninput images. Specifically, we build a two-branch answer prediction network\nthat contains a specific branch for each case and further develop a dual\nrouting scheme to dynamically determine which branch should be chosen. In the\nbranch that involves text understanding, we incorporate the Optical Character\nRecognition (OCR) features into the model to help understand the text in the\nimages. Extensive experiments on the VQA v2.0 dataset demonstrate that our\nproposed TDR outperforms existing methods, especially on the ''number'' related\nVQA questions.",
    "descriptor": "",
    "authors": [
      "Luoqian Jiang",
      "Yifan He",
      "Jian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14450"
  },
  {
    "id": "arXiv:2211.14451",
    "title": "GLAMI-1M: A Multilingual Image-Text Fashion Dataset",
    "abstract": "We introduce GLAMI-1M: the largest multilingual image-text classification\ndataset and benchmark. The dataset contains images of fashion products with\nitem descriptions, each in 1 of 13 languages. Categorization into 191 classes\nhas high-quality annotations: all 100k images in the test set and 75% of the 1M\ntraining set were human-labeled. The paper presents baselines for image-text\nclassification showing that the dataset presents a challenging fine-grained\nclassification problem: The best scoring EmbraceNet model using both visual and\ntextual features achieves 69.7% accuracy. Experiments with a modified Imagen\nmodel show the dataset is also suitable for image generation conditioned on\ntext. The dataset, source code and model checkpoints are published at\nhttps://github.com/glami/glami-1m",
    "descriptor": "",
    "authors": [
      "Vaclav Kosar",
      "Anton\u00edn Hoskovec",
      "Milan \u0160ulc",
      "Radek Bartyzal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14451"
  },
  {
    "id": "arXiv:2211.14452",
    "title": "Web-based Management Information System of Cases Filed with the National  Labor Relations Commission",
    "abstract": "This study was developed to describe the daily operations and encountered\nproblems of the National Labor Relations Commission Regional Arbitration Branch\nNo. IV (NLRC RAB IV) through conducted observations and interviews. These\nproblems were addressed and analyzed to be the features of the developed\nweb-based management information system (MIS) for cases. The research\nmethodology utilized in this project was the descriptive developmental\napproach. The Agile Software Development methodology was followed to develop\nthe system. It was used to quickly produce the desired output while allowing\nthe user to go back through phases without finishing the whole cycle. The\nsystem covered managing filed complaints, Single-Entry Approach (SEnA), labor\ncases, and report generation. The findings, through the interview, of handling\nrecords were inconsistent and inaccurate. This study also focused on ensuring\nthe Data Privacy Act of 2012, protecting the database's information using the\nXOR Cipher Algorithm. This study was evaluated using standard web evaluation\ncriteria. Using the criteria, the study's overall mean was 4.27 and 4.43, with\nthe descriptive meaning of Very Good, which showed that the system was accepted\nas perceived by experts and end-users, respectively. Management of filed cases\nis a vital process for the Commission. With that said, developing a web-based\nmanagement information system could ease the internal operations of handling\nand managing filed labor cases. Moreover, respondents and complainants can\neasily determine their filed cases' status using the case status tracking\nsystem. For further improvements to the system, additional printable documents\nmay be added that could be found needed by the Commission. Lastly, further\nresearch about the effectiveness of the web-based system may be conducted for\nfurther enhancements of the system.",
    "descriptor": "",
    "authors": [
      "Aaron Paul M. Dela Rosa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.14452"
  },
  {
    "id": "arXiv:2211.14453",
    "title": "Transform Once: Efficient Operator Learning in Frequency Domain",
    "abstract": "Spectral analysis provides one of the most effective paradigms for\ninformation-preserving dimensionality reduction, as simple descriptions of\nnaturally occurring signals are often obtained via few terms of periodic basis\nfunctions. In this work, we study deep neural networks designed to harness the\nstructure in frequency domain for efficient learning of long-range correlations\nin space or time: frequency-domain models (FDMs). Existing FDMs are based on\ncomplex-valued transforms i.e. Fourier Transforms (FT), and layers that perform\ncomputation on the spectrum and input data separately. This design introduces\nconsiderable computational overhead: for each layer, a forward and inverse FT.\nInstead, this work introduces a blueprint for frequency domain learning through\na single transform: transform once (T1). To enable efficient, direct learning\nin the frequency domain we derive a variance-preserving weight initialization\nscheme and investigate methods for frequency selection in reduced-order FDMs.\nOur results noticeably streamline the design process of FDMs, pruning redundant\ntransforms, and leading to speedups of 3x to 10x that increase with data\nresolution and model size. We perform extensive experiments on learning the\nsolution operator of spatio-temporal dynamics, including incompressible\nNavier-Stokes, turbulent flows around airfoils and high-resolution video of\nsmoke. T1 models improve on the test performance of FDMs while requiring\nsignificantly less computation (5 hours instead of 32 for our large-scale\nexperiment), with over 20% reduction in average predictive error across tasks.",
    "descriptor": "\nComments: Published at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Michael Poli",
      "Stefano Massaroli",
      "Federico Berto",
      "Jinykoo Park",
      "Tri Dao",
      "Christopher R\u00e9",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14453"
  },
  {
    "id": "arXiv:2211.14454",
    "title": "Dual gradient method for ill-posed problems using multiple repeated  measurement data",
    "abstract": "We consider determining $\\R$-minimizing solutions of linear ill-posed\nproblems $A x = y$, where $A: {\\mathscr X} \\to {\\mathscr Y}$ is a bounded\nlinear operator from a Banach space ${\\mathscr X}$ to a Hilbert space\n${\\mathscr Y}$ and ${\\mathcal R}: {\\mathscr X} \\to [0, \\infty]$ is a proper\nstrongly convex penalty function. Assuming that multiple repeated independent\nidentically distributed unbiased data of $y$ are available, we consider a dual\ngradient method to reconstruct the ${\\mathcal R}$-minimizing solution using the\naverage of these data. By terminating the method by either an {\\it a priori}\nstopping rule or a statistical variant of the discrepancy principle, we provide\nthe convergence analysis and derive convergence rates when the sought solution\nsatisfies certain variational source conditions. Various numerical results are\nreported to test the performance of the method.",
    "descriptor": "",
    "authors": [
      "Qinian Jin",
      "Wei Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.14454"
  },
  {
    "id": "arXiv:2211.14455",
    "title": "Information Geometry of Dynamics on Graphs and Hypergraphs",
    "abstract": "We introduce a new information-geometric structure of dynamics on discrete\nobjects such as graphs and hypergraphs. The setup consists of two dually flat\nstructures built on the vertex and edge spaces, respectively. The former is the\nconventional duality between density and potential, e.g., the probability\ndensity and its logarithmic form induced by a convex thermodynamic function.\nThe latter is the duality between flux and force induced by a convex and\nsymmetric dissipation function, which drives the dynamics on the manifold.\nThese two are connected topologically by the homological algebraic relation\ninduced by the underlying discrete objects. The generalized gradient flow in\nthis doubly dual flat structure is an extension of the gradient flows on\nRiemannian manifolds, which include Markov jump processes and nonlinear\nchemical reaction dynamics as well as the natural gradient and mirror descent.\nThe information-geometric projections on this doubly dual flat structure lead\nto the information-geometric generalizations of Helmholtz-Hodge-Kodaira\ndecomposition and Otto structure in $L^{2}$ Wasserstein geometry. The structure\ncan be extended to non-gradient nonequilibrium flow, from which we also obtain\nthe induced dually flat structure on cycle spaces. This abstract but general\nframework can extend the applicability of information geometry to various\nproblems of linear and nonlinear dynamics.",
    "descriptor": "\nComments: 87 pages, 7 figures\n",
    "authors": [
      "Tetsuya J. Kobayashi",
      "Dimitri Loutchko",
      "Atsushi Kamimura",
      "Shuhei Horiguchi",
      "Yuki Sughiyama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Differential Geometry (math.DG)",
      "Statistics Theory (math.ST)",
      "Chemical Physics (physics.chem-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.14455"
  },
  {
    "id": "arXiv:2211.14456",
    "title": "TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud  Classification",
    "abstract": "Rotation invariance is an important requirement for the analysis of 3D point\nclouds. In this paper, we present TetraSphere -- a learnable descriptor for\nrotation- and reflection-invariant 3D point cloud classification based on\nrecently introduced steerable 3D spherical neurons and vector neurons, as well\nas the Gram matrix method. Taking 3D points as input, TetraSphere performs\nTetraTransform -- lifts the 3D input to 4D -- and extracts rotation-equivariant\nfeatures, subsequently computing pair-wise O(3)-invariant inner products of\nthese features. Remarkably, TetraSphere can be embedded into common point cloud\nprocessing models. We demonstrate its effectiveness and versatility by\nintegrating it into DGCNN and VN-DGCNN, performing the classification of\narbitrarily rotated ModelNet40 shapes. We show that using TetraSphere improves\nthe performance and reduces the computational complexity by about 10% of the\nrespective baseline methods.",
    "descriptor": "",
    "authors": [
      "Pavlo Melnyk",
      "Andreas Robinson",
      "M\u00e5rten Wadenb\u00e4ck",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14456"
  },
  {
    "id": "arXiv:2211.14459",
    "title": "Transformer-based Model for Word Level Language Identification in  Code-mixed Kannada-English Texts",
    "abstract": "Using code-mixed data in natural language processing (NLP) research currently\ngets a lot of attention. Language identification of social media code-mixed\ntext has been an interesting problem of study in recent years due to the\nadvancement and influences of social media in communication. This paper\npresents the Instituto Polit\\'ecnico Nacional, Centro de Investigaci\\'on en\nComputaci\\'on (CIC) team's system description paper for the CoLI-Kanglish\nshared task at ICON2022. In this paper, we propose the use of a Transformer\nbased model for word-level language identification in code-mixed Kannada\nEnglish texts. The proposed model on the CoLI-Kenglish dataset achieves a\nweighted F1-score of 0.84 and a macro F1-score of 0.61.",
    "descriptor": "",
    "authors": [
      "Atnafu Lambebo Tonja",
      "Mesay Gemeda Yigezu",
      "Olga Kolesnikova",
      "Moein Shahiki Tash",
      "Grigori Sidorov",
      "Alexander Gelbuk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14459"
  },
  {
    "id": "arXiv:2211.14461",
    "title": "CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition for  Multi-Modality Image Fusion",
    "abstract": "Multi-modality (MM) image fusion aims to render fused images that maintain\nthe merits of different modalities, e.g., functional highlight and detailed\ntextures. To tackle the challenge in modeling cross-modality features and\ndecomposing desirable modality-specific and modality-shared features, we\npropose a novel Correlation-Driven feature Decomposition Fusion (CDDFuse)\nnetwork for end-to-end MM feature decomposition and image fusion. In the first\nstage of the two-stage architectures, CDDFuse uses Restormer blocks to extract\ncross-modality shallow features. We then introduce a dual-branch\nTransformer-CNN feature extractor with Lite Transformer (LT) blocks leveraging\nlong-range attention to handle low-frequency global features and Invertible\nNeural Networks (INN) blocks focusing on extracting high-frequency local\ninformation. Upon the embedded semantic information, the low-frequency features\nshould be correlated while the high-frequency features should be uncorrelated.\nThus, we propose a correlation-driven loss for better feature decomposition. In\nthe second stage, the LT-based global fusion and INN-based local fusion layers\noutput the fused image. Extensive experiments demonstrate that our CDDFuse\nachieves promising results in multiple fusion tasks, including infrared-visible\nimage fusion and medical image fusion. We also show that CDDFuse can boost the\nperformance in downstream infrared-visible semantic segmentation and object\ndetection in a unified benchmark.",
    "descriptor": "",
    "authors": [
      "Zixiang Zhao",
      "Haowen Bai",
      "Jiangshe Zhang",
      "Yulun Zhang",
      "Shuang Xu",
      "Zudi Lin",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14461"
  },
  {
    "id": "arXiv:2211.14462",
    "title": "Meta Architecure for Point Cloud Analysis",
    "abstract": "Recent advances in 3D point cloud analysis bring a diverse set of network\narchitectures to the field. However, the lack of a unified framework to\ninterpret those networks makes any systematic comparison, contrast, or analysis\nchallenging, and practically limits healthy development of the field. In this\npaper, we take the initiative to explore and propose a unified framework called\nPointMeta, to which the popular 3D point cloud analysis approaches could fit.\nThis brings three benefits. First, it allows us to compare different approaches\nin a fair manner, and use quick experiments to verify any empirical\nobservations or assumptions summarized from the comparison. Second, the big\npicture brought by PointMeta enables us to think across different components,\nand revisit common beliefs and key design decisions made by the popular\napproaches. Third, based on the learnings from the previous two analyses, by\ndoing simple tweaks on the existing approaches, we are able to derive a basic\nbuilding block, termed PointMetaBase. It shows very strong performance in\nefficiency and effectiveness through extensive experiments on challenging\nbenchmarks, and thus verifies the necessity and benefits of high-level\ninterpretation, contrast, and comparison like PointMeta. In particular,\nPointMetaBase surpasses the previous state-of-the-art method by 0.7%/1.4/%2.1%\nmIoU with only 2%/11%/13% of the computation cost on the S3DIS datasets.",
    "descriptor": "",
    "authors": [
      "Haojia Lin",
      "Xiawu Zheng",
      "Lijiang Li",
      "Fei Chao",
      "Shanshan Wang",
      "Yan Wang",
      "Yonghong Tian",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14462"
  },
  {
    "id": "arXiv:2211.14466",
    "title": "SKDBERT: Compressing BERT via Stochastic Knowledge Distillation",
    "abstract": "In this paper, we propose Stochastic Knowledge Distillation (SKD) to obtain\ncompact BERT-style language model dubbed SKDBERT. In each iteration, SKD\nsamples a teacher model from a pre-defined teacher ensemble, which consists of\nmultiple teacher models with multi-level capacities, to transfer knowledge into\nstudent model in an one-to-one manner. Sampling distribution plays an important\nrole in SKD. We heuristically present three types of sampling distributions to\nassign appropriate probabilities for multi-level teacher models. SKD has two\nadvantages: 1) it can preserve the diversities of multi-level teacher models\nvia stochastically sampling single teacher model in each iteration, and 2) it\ncan also improve the efficacy of knowledge distillation via multi-level teacher\nmodels when large capacity gap exists between the teacher model and the student\nmodel. Experimental results on GLUE benchmark show that SKDBERT reduces the\nsize of a BERT$_{\\rm BASE}$ model by 40% while retaining 99.5% performances of\nlanguage understanding and being 100% faster.",
    "descriptor": "\nComments: 16 pages, 19 figures, 14 tables, has been accepted by AAAI2023\n",
    "authors": [
      "Zixiang Ding",
      "Guoqing Jiang",
      "Shuai Zhang",
      "Lin Guo",
      "Wei Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14466"
  },
  {
    "id": "arXiv:2211.14467",
    "title": "Self-Supervised Surgical Instrument 3D Reconstruction from a Single  Camera Image",
    "abstract": "Surgical instrument tracking is an active research area that can provide\nsurgeons feedback about the location of their tools relative to anatomy. Recent\ntracking methods are mainly divided into two parts: segmentation and object\ndetection. However, both can only predict 2D information, which is limiting for\napplication to real-world surgery. An accurate 3D surgical instrument model is\na prerequisite for precise predictions of the pose and depth of the instrument.\nRecent single-view 3D reconstruction methods are only used in natural object\nreconstruction and do not achieve satisfying reconstruction accuracy without 3D\nattribute-level supervision. Further, those methods are not suitable for the\nsurgical instruments because of their elongated shapes. In this paper, we\nfirstly propose an end-to-end surgical instrument reconstruction system --\nSelf-supervised Surgical Instrument Reconstruction (SSIR). With SSIR, we\npropose a multi-cycle-consistency strategy to help capture the texture\ninformation from a slim instrument while only requiring a binary instrument\nlabel map. Experiments demonstrate that our approach improves the\nreconstruction quality of surgical instruments compared to other\nself-supervised methods and achieves promising results.",
    "descriptor": "\nComments: Accepted by SPIE Medical Imaging 2023\n",
    "authors": [
      "Ange Lou",
      "Xing Yao",
      "Ziteng Liu",
      "Jintong Han",
      "Jack Noble"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.14467"
  },
  {
    "id": "arXiv:2211.14468",
    "title": "Similarity-based Cooperation",
    "abstract": "As machine learning agents act more autonomously in the world, they will\nincreasingly interact with each other. Unfortunately, in many social dilemmas\nlike the one-shot Prisoner's Dilemma, standard game theory predicts that ML\nagents will fail to cooperate with each other. Prior work has shown that one\nway to enable cooperative outcomes in the one-shot Prisoner's Dilemma is to\nmake the agents mutually transparent to each other, i.e., to allow them to\naccess one another's source code (Rubinstein 1998, Tennenholtz 2004) -- or\nweights in the case of ML agents. However, full transparency is often\nunrealistic, whereas partial transparency is commonplace. Moreover, it is\nchallenging for agents to learn their way to cooperation in the full\ntransparency setting. In this paper, we introduce a more realistic setting in\nwhich agents only observe a single number indicating how similar they are to\neach other. We prove that this allows for the same set of cooperative outcomes\nas the full transparency setting. We also demonstrate experimentally that\ncooperation can be learned using simple ML methods.",
    "descriptor": "\nComments: 35 pages, 9 figures\n",
    "authors": [
      "Caspar Oesterheld",
      "Johannes Treutlein",
      "Roger Grosse",
      "Vincent Conitzer",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.14468"
  },
  {
    "id": "arXiv:2211.14469",
    "title": "Transfer RL via the Undo Maps Formalism",
    "abstract": "Transferring knowledge across domains is one of the most fundamental problems\nin machine learning, but doing so effectively in the context of reinforcement\nlearning remains largely an open problem. Current methods make strong\nassumptions on the specifics of the task, often lack principled objectives, and\n-- crucially -- modify individual policies, which might be sub-optimal when the\ndomains differ due to a drift in the state space, i.e., it is intrinsic to the\nenvironment and therefore affects every agent interacting with it. To address\nthese drawbacks, we propose TvD: transfer via distribution matching, a\nframework to transfer knowledge across interactive domains. We approach the\nproblem from a data-centric perspective, characterizing the discrepancy in\nenvironments by means of (potentially complex) transformation between their\nstate spaces, and thus posing the problem of transfer as learning to undo this\ntransformation. To accomplish this, we introduce a novel optimization objective\nbased on an optimal transport distance between two distributions over\ntrajectories -- those generated by an already-learned policy in the source\ndomain and a learnable pushforward policy in the target domain. We show this\nobjective leads to a policy update scheme reminiscent of imitation learning,\nand derive an efficient algorithm to implement it. Our experiments in simple\ngridworlds show that this method yields successful transfer learning across a\nwide range of environment transformations.",
    "descriptor": "\nComments: 8 main pages, 3 appendix\n",
    "authors": [
      "Abhi Gupta",
      "Ted Moskovitz",
      "David Alvarez-Melis",
      "Aldo Pacchiano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14469"
  },
  {
    "id": "arXiv:2211.14470",
    "title": "Towards Better Document-level Relation Extraction via Iterative  Inference",
    "abstract": "Document-level relation extraction (RE) aims to extract the relations between\nentities from the input document that usually containing many\ndifficultly-predicted entity pairs whose relations can only be predicted\nthrough relational inference. Existing methods usually directly predict the\nrelations of all entity pairs of input document in a one-pass manner, ignoring\nthe fact that predictions of some entity pairs heavily depend on the predicted\nresults of other pairs. To deal with this issue, in this paper, we propose a\nnovel document-level RE model with iterative inference. Our model is mainly\ncomposed of two modules: 1) a base module expected to provide preliminary\nrelation predictions on entity pairs; 2) an inference module introduced to\nrefine these preliminary predictions by iteratively dealing with\ndifficultly-predicted entity pairs depending on other pairs in an easy-to-hard\nmanner. Unlike previous methods which only consider feature information of\nentity pairs, our inference module is equipped with two Extended Cross\nAttention units, allowing it to exploit both feature information and previous\npredictions of entity pairs during relational inference. Furthermore, we adopt\na two-stage strategy to train our model. At the first stage, we only train our\nbase module. During the second stage, we train the whole model, where\ncontrastive learning is introduced to enhance the training of inference module.\nExperimental results on three commonly-used datasets show that our model\nconsistently outperforms other competitive baselines.",
    "descriptor": "\nComments: Accepted by EMNLP 2022 (long paper)\n",
    "authors": [
      "Liang Zhang",
      "Jinsong Su",
      "Yidong Chen",
      "Zhongjian Miao",
      "Zijun Min",
      "Qingguo Hu",
      "Xiaodong Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14470"
  },
  {
    "id": "arXiv:2211.14475",
    "title": "SGCE-Font: Skeleton Guided Channel Expansion for Chinese Font Generation",
    "abstract": "The automatic generation of Chinese fonts is an important problem involved in\nmany applications. The predominated methods for the Chinese font generation are\nbased on the deep generative models, especially the generative adversarial\nnetworks (GANs). However, existing GAN-based methods (say, CycleGAN) for the\nChinese font generation usually suffer from the mode collapse issue, mainly due\nto the lack of effective guidance information. This paper proposes a novel\ninformation guidance module called the skeleton guided channel expansion (SGCE)\nmodule for the Chinese font generation through integrating the skeleton\ninformation into the generator with the channel expansion way, motivated by the\nobservation that the skeleton embodies both local and global structure\ninformation of Chinese characters. We conduct extensive experiments to show the\neffectiveness of the proposed module. Numerical results show that the mode\ncollapse issue suffered by the known CycleGAN can be effectively alleviated by\nequipping with the proposed SGCE module, and the CycleGAN equipped with SGCE\noutperforms the state-of-the-art models in terms of four important evaluation\nmetrics and visualization quality. Besides CycleGAN, we also show that the\nsuggested SGCE module can be adapted to other models for Chinese font\ngeneration as a plug-and-play module to further improve their performance.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Jie Zhou",
      "Yefei Wang",
      "Yiyang Yuan",
      "Qing Huang",
      "Jinshan Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14475"
  },
  {
    "id": "arXiv:2211.14477",
    "title": "PCRED: Zero-shot Relation Triplet Extraction with Potential Candidate  Relation Selection and Entity Boundary Detection",
    "abstract": "Zero-shot relation triplet extraction (ZeroRTE) aims to extract relation\ntriplets from unstructured texts, while the relation sets at the training and\ntesting stages are disjoint. Previous state-of-the-art method handles this\nchallenging task by leveraging pretrained language models to generate data as\nadditional training samples, which increases the training cost and severely\nconstrains the model performance. We tackle this task from a new perspective\nand propose a novel method named PCRED for ZeroRTE with Potential Candidate\nRelation selection and Entity boundary Detection. The model adopts a\nrelation-first paradigm, which firstly recognizes unseen relations through\ncandidate relation selection. By this approach, the semantics of relations are\nnaturally infused in the context. Entities are extracted based on the context\nand the semantics of relations subsequently. We evaluate our model on two\nZeroRTE datasets. The experiment result shows that our method consistently\noutperforms previous works. Besides, our model does not rely on any additional\ndata, which boasts the advantages of simplicity and effectiveness. Our code is\navailable at https://anonymous.4open.science/r/PCRED.",
    "descriptor": "",
    "authors": [
      "Yuquan Lan",
      "Dongxu Li",
      "Hui Zhao",
      "Gang Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14477"
  },
  {
    "id": "arXiv:2211.14478",
    "title": "DynaVIG: Monocular Vision/INS/GNSS Integrated Navigation and Object  Tracking for AGV in Dynamic Scenes",
    "abstract": "Visual-Inertial Odometry (VIO) usually suffers from drifting over long-time\nruns, the accuracy is easily affected by dynamic objects. We propose DynaVIG, a\nnavigation and object tracking system based on the integration of Monocular\nVision, Inertial Navigation System (INS), and Global Navigation Satellite\nSystem (GNSS). Our system aims to provide an accurate global estimation of the\nnavigation states and object poses for the automated ground vehicle (AGV) in\ndynamic scenes. Due to the scale ambiguity of the object, a prior height model\nis proposed to initialize the object pose, and the scale is continuously\nestimated with the aid of GNSS and INS. To precisely track the object with\ncomplex moving, we establish an accurate dynamics model according to its motion\nstate. Then the multi-sensor observations are optimized in a unified framework.\nExperiments on the KITTI dataset demonstrate that the multisensor fusion can\neffectively improve the accuracy of navigation and object tracking, compared to\nstate-of-the-art methods. In addition, the proposed system achieves good\nestimation of the objects that change speed or direction.",
    "descriptor": "",
    "authors": [
      "Ronghe Jin",
      "Yan Wang",
      "Zhi Gao",
      "Xiaoji Niu",
      "Li-Ta Hsu",
      "Jingnan Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14478"
  },
  {
    "id": "arXiv:2211.14481",
    "title": "End-to-End Learning for VCSEL-based Optical Interconnects:  State-of-the-Art, Challenges, and Opportunities",
    "abstract": "Optical interconnects (OIs) based on vertical-cavity surface-emitting lasers\n(VCSELs) are the main workhorse within data centers, supercomputers, and even\nvehicles, providing low-cost, high-rate connectivity. VCSELs must operate under\nextremely harsh and time-varying conditions, thus requiring adaptive and\nflexible designs of the communication chain. Such designs can be built based on\nmathematical models (model-based design) or learned from data (machine learning\n(ML) based design). Various ML techniques have recently come to the forefront,\nreplacing individual components in the transmitters and receivers with deep\nneural networks. Beyond such component-wise learning, end-to-end (E2E)\nautoencoder approaches can reach the ultimate performance through co-optimizing\nentire parameterized transmitters and receivers. This tutorial paper aims to\nprovide an overview of ML for VCSEL-based OIs, with a focus on E2E approaches,\ndealing specifically with the unique challenges facing VCSELs, such as the wide\ntemperature variations and complex models.",
    "descriptor": "",
    "authors": [
      "Muralikrishnan Srinivasan",
      "Jinxiang Song",
      "Alexander Grabowski",
      "Krzysztof Szczerba",
      "Holger K. Iversen",
      "Mikkel N. Schmidt",
      "Darko Zibar",
      "Jochen Schr\u00f6der",
      "Anders Larsson",
      "Christian H\u00e4ger",
      "Henk Wymeersch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.14481"
  },
  {
    "id": "arXiv:2211.14485",
    "title": "PatchShading: High-Quality Human Reconstruction by Patch Warping and  Shading Refinement",
    "abstract": "Human reconstruction from multi-view images plays an important role in many\napplications. Although neural rendering methods have achieved promising results\non synthesising realistic images, it is still difficult to handle the ambiguity\nbetween the geometry and appearance using only rendering loss. Moreover, it is\nvery computationally intensive to render a whole image as each pixel requires a\nforward network inference. To tackle these challenges, we propose a novel\napproach called \\emph{PatchShading} to reconstruct high-quality mesh of human\nbody from multi-view posed images. We first present a patch warping strategy to\nconstrain multi-view photometric consistency explicitly. Second, we adopt\nsphere harmonics (SH) illumination and shape from shading image formation to\nfurther refine the geometric details. By taking advantage of the oriented point\nclouds shape representation and SH shading, our proposed method significantly\nreduce the optimization and rendering time compared to those implicit methods.\nThe encouraging results on both synthetic and real-world datasets demonstrate\nthe efficacy of our proposed approach.",
    "descriptor": "",
    "authors": [
      "Lixiang Lin",
      "Songyou Peng",
      "Qijun Gan",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14485"
  },
  {
    "id": "arXiv:2211.14487",
    "title": "Receptive Field Refinement for Convolutional Neural Networks Reliably  Improves Predictive Performance",
    "abstract": "Minimal changes to neural architectures (e.g. changing a single\nhyperparameter in a key layer), can lead to significant gains in predictive\nperformance in Convolutional Neural Networks (CNNs). In this work, we present a\nnew approach to receptive field analysis that can yield these types of\ntheoretical and empirical performance gains across twenty well-known CNN\narchitectures examined in our experiments. By further developing and\nformalizing the analysis of receptive field expansion in convolutional neural\nnetworks, we can predict unproductive layers in an automated manner before ever\ntraining a model. This allows us to optimize the parameter-efficiency of a\ngiven architecture at low cost. Our method is computationally simple and can be\ndone in an automated manner or even manually with minimal effort for most\ncommon architectures. We demonstrate the effectiveness of this approach by\nincreasing parameter efficiency across past and current top-performing\nCNN-architectures. Specifically, our approach is able to improve ImageNet1K\nperformance across a wide range of well-known, state-of-the-art (SOTA) model\nclasses, including: VGG Nets, MobileNetV1, MobileNetV3, NASNet A (mobile),\nMnasNet, EfficientNet, and ConvNeXt - leading to a new SOTA result for each\nmodel class.",
    "descriptor": "",
    "authors": [
      "Mats L. Richter",
      "Christopher Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14487"
  },
  {
    "id": "arXiv:2211.14489",
    "title": "Mitigating Relational Bias on Knowledge Graphs",
    "abstract": "Knowledge graph data are prevalent in real-world applications, and knowledge\ngraph neural networks (KGNNs) are essential techniques for knowledge graph\nrepresentation learning. Although KGNN effectively models the structural\ninformation from knowledge graphs, these frameworks amplify the underlying data\nbias that leads to discrimination towards certain groups or individuals in\nresulting applications. Additionally, as existing debiasing approaches mainly\nfocus on the entity-wise bias, eliminating the multi-hop relational bias that\npervasively exists in knowledge graphs remains an open question. However, it is\nvery challenging to eliminate relational bias due to the sparsity of the paths\nthat generate the bias and the non-linear proximity structure of knowledge\ngraphs. To tackle the challenges, we propose Fair-KGNN, a KGNN framework that\nsimultaneously alleviates multi-hop bias and preserves the proximity\ninformation of entity-to-relation in knowledge graphs. The proposed framework\nis generalizable to mitigate the relational bias for all types of KGNN. We\ndevelop two instances of Fair-KGNN incorporating with two state-of-the-art KGNN\nmodels, RGCN and CompGCN, to mitigate gender-occupation and nationality-salary\nbias. The experiments carried out on three benchmark knowledge graph datasets\ndemonstrate that the Fair-KGNN can effectively mitigate unfair situations\nduring representation learning while preserving the predictive performance of\nKGNN models.",
    "descriptor": "",
    "authors": [
      "Yu-Neng Chuang",
      "Kwei-Herng Lai",
      "Ruixiang Tang",
      "Mengnan Du",
      "Chia-Yuan Chang",
      "Na Zou",
      "Xia Hu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14489"
  },
  {
    "id": "arXiv:2211.14490",
    "title": "Resampling community detection to maximize propagation in complex  network",
    "abstract": "Identifying important nodes in complex networks is essential in theoretical\nand applied fields. A small number of such nodes have deterministic power to\ndecide information spreading, so it is of importance to find a set of nodes\nthat maximize the propagation in networks. Based on baseline ranking methods,\nvarious improved methods were proposed, but there does not exist one enhanced\nmethod that covers all the base methods. In this paper, we propose a penalized\nmethod called RCD-Map, which is short for resampling community detection to\nmaximize propagation, on five baseline ranking methods(Degree centrality,\nCloseness centrality, Betweennees centrality, K-shell and PageRank) with nodes'\nlocal community information. We perturbed the original graph by resampling to\ndecrease the biases and randomness brought by community detection methods-both\noverlapping and non-overlapping methods. To assess the performance of our\nidentifying method, SIR(susceptible-infected-recovered) model is applied to\nsimulate the information propagation process. The result shows that methods\nwith penalties perform better with a vaster propagation range in general.",
    "descriptor": "",
    "authors": [
      "Xintong Zhai",
      "Zhonghao Xu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14490"
  },
  {
    "id": "arXiv:2211.14491",
    "title": "Human-machine Interactive Tissue Prototype Learning for Label-efficient  Histopathology Image Segmentation",
    "abstract": "Recently, deep neural networks have greatly advanced histopathology image\nsegmentation but usually require abundant annotated data. However, due to the\ngigapixel scale of whole slide images and pathologists' heavy daily workload,\nobtaining pixel-level labels for supervised learning in clinical practice is\noften infeasible. Alternatively, weakly-supervised segmentation methods have\nbeen explored with less laborious image-level labels, but their performance is\nunsatisfactory due to the lack of dense supervision. Inspired by the recent\nsuccess of self-supervised learning methods, we present a label-efficient\ntissue prototype dictionary building pipeline and propose to use the obtained\nprototypes to guide histopathology image segmentation. Particularly, taking\nadvantage of self-supervised contrastive learning, an encoder is trained to\nproject the unlabeled histopathology image patches into a discriminative\nembedding space where these patches are clustered to identify the tissue\nprototypes by efficient pathologists' visual examination. Then, the encoder is\nused to map the images into the embedding space and generate pixel-level pseudo\ntissue masks by querying the tissue prototype dictionary. Finally, the pseudo\nmasks are used to train a segmentation network with dense supervision for\nbetter performance. Experiments on two public datasets demonstrate that our\nhuman-machine interactive tissue prototype learning method can achieve\ncomparable segmentation performance as the fully-supervised baselines with less\nannotation burden and outperform other weakly-supervised methods. Codes will be\navailable upon publication.",
    "descriptor": "",
    "authors": [
      "Wentao Pan",
      "Jiangpeng Yan",
      "Hanbo Chen",
      "Jiawei Yang",
      "Zhe Xu",
      "Xiu Li",
      "Jianhua Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14491"
  },
  {
    "id": "arXiv:2211.14492",
    "title": "Enhancing Constraint Programming via Supervised Learning for Job Shop  Scheduling",
    "abstract": "Constraint programming (CP) is an effective technique for solving constraint\nsatisfaction and optimization problems. CP solvers typically use a variable\nordering strategy to select which variable to explore first in the solving\nprocess, which has a large impact on the efficacy of the solvers. In this\npaper, we propose a novel variable ordering strategy based on supervised\nlearning to solve job shop scheduling problems. We develop a classification\nmodel and a regression model to predict the optimal solution of a problem\ninstance, and use the predicted solution to order variables for CP solvers. We\nshow that training machine learning models is very efficient and can achieve a\nhigh accuracy. Our extensive experiments demonstrate that the learned variable\nordering methods perform competitively compared to four existing methods.\nFinally, we show that hybridising the machine learning-based variable ordering\nmethods with traditional domain-based methods is beneficial.",
    "descriptor": "",
    "authors": [
      "Yuan Sun",
      "Su Nguyen",
      "Dhananjay Thiruvady",
      "Xiaodong Li",
      "Andreas T. Ernst",
      "Uwe Aickelin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14492"
  },
  {
    "id": "arXiv:2211.14493",
    "title": "Multi-fidelity Gaussian Process for Biomanufacturing Process Modeling  with Small Data",
    "abstract": "In biomanufacturing, developing an accurate model to simulate the complex\ndynamics of bioprocesses is an important yet challenging task. This is\npartially due to the uncertainty associated with bioprocesses, high data\nacquisition cost, and lack of data availability to learn complex relations in\nbioprocesses. To deal with these challenges, we propose to use a statistical\nmachine learning approach, multi-fidelity Gaussian process, for process\nmodelling in biomanufacturing. Gaussian process regression is a\nwell-established technique based on probability theory which can naturally\nconsider uncertainty in a dataset via Gaussian noise, and multi-fidelity\ntechniques can make use of multiple sources of information with different\nlevels of fidelity, thus suitable for bioprocess modeling with small data. We\napply the multi-fidelity Gaussian process to solve two significant problems in\nbiomanufacturing, bioreactor scale-up and knowledge transfer across cell lines,\nand demonstrate its efficacy on real-world datasets.",
    "descriptor": "",
    "authors": [
      "Yuan Sun",
      "Winton Nathan-Roberts",
      "Tien Dung Pham",
      "Ellen Otte",
      "Uwe Aickelin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14493"
  },
  {
    "id": "arXiv:2211.14497",
    "title": "Extractors for Images of Varieties",
    "abstract": "We construct explicit deterministic extractors for polynomial images of\nvarieties, that is, distributions sampled by applying a low-degree polynomial\nmap $f : \\mathbb{F}_q^r \\to \\mathbb{F}_q^n$ to an element sampled uniformly at\nrandom from a $k$-dimensional variety $V \\subseteq \\mathbb{F}_q^r$. This class\nof sources generalizes both polynomial sources, studied by Dvir, Gabizon and\nWigderson (FOCS 2007, Comput. Complex. 2009), and variety sources, studied by\nDvir (CCC 2009, Comput. Complex. 2012).\nAssuming certain natural non-degeneracy conditions on the map $f$ and the\nvariety $V$, which in particular ensure that the source has enough min-entropy,\nwe extract almost all the min-entropy of the distribution. Unlike the\nDvir-Gabizon-Wigderson and Dvir results, our construction works over large\nenough finite fields of arbitrary characteristic. One key part of our\nconstruction is an improved deterministic rank extractor for varieties. As a\nby-product, we obtain explicit Noether normalization lemmas for affine\nvarieties and affine algebras.\nAdditionally, we generalize a construction of affine extractors with\nexponentially small error due to Bourgain, Dvir and Leeman (Comput. Complex.\n2016) by extending it to all finite prime fields of quasipolynomial size.",
    "descriptor": "",
    "authors": [
      "Zeyu Guo",
      "Ben Lee Volk",
      "Akhil Jalan",
      "David Zuckerman"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2211.14497"
  },
  {
    "id": "arXiv:2211.14498",
    "title": "The Impact of Racial Distribution in Training Data on Face Recognition  Bias: A Closer Look",
    "abstract": "Face recognition algorithms, when used in the real world, can be very useful,\nbut they can also be dangerous when biased toward certain demographics. So, it\nis essential to understand how these algorithms are trained and what factors\naffect their accuracy and fairness to build better ones. In this study, we shed\nsome light on the effect of racial distribution in the training data on the\nperformance of face recognition models. We conduct 16 different experiments\nwith varying racial distributions of faces in the training data. We analyze\nthese trained models using accuracy metrics, clustering metrics, UMAP\nprojections, face quality, and decision thresholds. We show that a uniform\ndistribution of races in the training datasets alone does not guarantee\nbias-free face recognition algorithms and how factors like face image quality\nplay a crucial role. We also study the correlation between the clustering\nmetrics and bias to understand whether clustering is a good indicator of bias.\nFinally, we introduce a metric called racial gradation to study the inter and\nintra race correlation in facial features and how they affect the learning\nability of the face recognition models. With this study, we try to bring more\nunderstanding to an essential element of face recognition training, the data. A\nbetter understanding of the impact of training data on the bias of face\nrecognition algorithms will aid in creating better datasets and, in turn,\nbetter face recognition systems.",
    "descriptor": "\nComments: 10 pages, 5 figures, Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW), 2023\n",
    "authors": [
      "Manideep Kolla",
      "Aravinth Savadamuthu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14498"
  },
  {
    "id": "arXiv:2211.14499",
    "title": "Deep neuroevolution for limited, heterogeneous data: proof-of-concept  application to Neuroblastoma brain metastasis using a small virtual pooled  image collection",
    "abstract": "Artificial intelligence (AI) in radiology has made great strides in recent\nyears, but many hurdles remain. Overfitting and lack of generalizability\nrepresent important ongoing challenges hindering accurate and dependable\nclinical deployment. If AI algorithms can avoid overfitting and achieve true\ngeneralizability, they can go from the research realm to the forefront of\nclinical work. Recently, small data AI approaches such as deep neuroevolution\n(DNE) have avoided overfitting small training sets. We seek to address both\noverfitting and generalizability by applying DNE to a virtually pooled data set\nconsisting of images from various institutions. Our use case is classifying\nneuroblastoma brain metastases on MRI. Neuroblastoma is well-suited for our\ngoals because it is a rare cancer. Hence, studying this pediatric disease\nrequires a small data approach. As a tertiary care center, the neuroblastoma\nimages in our local Picture Archiving and Communication System (PACS) are\nlargely from outside institutions. These multi-institutional images provide a\nheterogeneous data set that can simulate real world clinical deployment. As in\nprior DNE work, we used a small training set, consisting of 30 normal and 30\nmetastasis-containing post-contrast MRI brain scans, with 37% outside images.\nThe testing set was enriched with 83% outside images. DNE converged to a\ntesting set accuracy of 97%. Hence, the algorithm was able to predict image\nclass with near-perfect accuracy on a testing set that simulates real-world\ndata. Hence, the work described here represents a considerable contribution\ntoward clinically feasible AI.",
    "descriptor": "",
    "authors": [
      "Subhanik Purkayastha",
      "Hrithwik Shalu",
      "David Gutman",
      "Shakeel Modak",
      "Ellen Basu",
      "Brian Kushner",
      "Kim Kramer",
      "Sofia Haque",
      "Joseph Stember"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14499"
  },
  {
    "id": "arXiv:2211.14500",
    "title": "Deep neuroevolution to predict primary brain tumor grade from functional  MRI adjacency matrices",
    "abstract": "Whereas MRI produces anatomic information about the brain, functional MRI\n(fMRI) tells us about neural activity within the brain, including how various\nregions communicate with each other. The full chorus of conversations within\nthe brain is summarized elegantly in the adjacency matrix. Although\ninformation-rich, adjacency matrices typically provide little in the way of\nintuition. Whereas trained radiologists viewing anatomic MRI can readily\ndistinguish between different kinds of brain cancer, a similar determination\nusing adjacency matrices would exceed any expert's grasp. Artificial\nintelligence (AI) in radiology usually analyzes anatomic imaging, providing\nassistance to radiologists. For non-intuitive data types such as adjacency\nmatrices, AI moves beyond the role of helpful assistant, emerging as\nindispensible. We sought here to show that AI can learn to discern between two\nimportant brain tumor types, high-grade glioma (HGG) and low-grade glioma\n(LGG), based on adjacency matrices. We trained a convolutional neural networks\n(CNN) with the method of deep neuroevolution (DNE), because of the latter's\nrecent promising results; DNE has produced remarkably accurate CNNs even when\nrelying on small and noisy training sets, or performing nuanced tasks. After\ntraining on just 30 adjacency matrices, our CNN could tell HGG apart from LGG\nwith perfect testing set accuracy. Saliency maps revealed that the network\nlearned highly sophisticated and complex features to achieve its success.\nHence, we have shown that it is possible for AI to recognize brain tumor type\nfrom functional connectivity. In future work, we will apply DNE to other noisy\nand somewhat cryptic forms of medical data, including further explorations with\nfMRI.",
    "descriptor": "",
    "authors": [
      "Joseph Stember",
      "Mehrnaz Jenabi",
      "Luca Pasquini",
      "Kyung Peck",
      "Andrei Holodny",
      "Hrithwik Shalu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14500"
  },
  {
    "id": "arXiv:2211.14502",
    "title": "Learning Single Image Defocus Deblurring with Misaligned Training Pairs",
    "abstract": "By adopting popular pixel-wise loss, existing methods for defocus deblurring\nheavily rely on well aligned training image pairs. Although training pairs of\nground-truth and blurry images are carefully collected, e.g., DPDD dataset,\nmisalignment is inevitable between training pairs, making existing methods\npossibly suffer from deformation artifacts. In this paper, we propose a joint\ndeblurring and reblurring learning (JDRL) framework for single image defocus\ndeblurring with misaligned training pairs. Generally, JDRL consists of a\ndeblurring module and a spatially invariant reblurring module, by which\ndeblurred result can be adaptively supervised by ground-truth image to recover\nsharp textures while maintaining spatial consistency with the blurry image.\nFirst, in the deblurring module, a bi-directional optical flow-based\ndeformation is introduced to tolerate spatial misalignment between deblurred\nand ground-truth images. Second, in the reblurring module, deblurred result is\nreblurred to be spatially aligned with blurry image, by predicting a set of\nisotropic blur kernels and weighting maps. Moreover, we establish a new single\nimage defocus deblurring (SDD) dataset, further validating our JDRL and also\nbenefiting future research. Our JDRL can be applied to boost defocus deblurring\nnetworks in terms of both quantitative metrics and visual quality on DPDD,\nRealDOF and our SDD datasets.",
    "descriptor": "",
    "authors": [
      "Yu Li",
      "Dongwei Ren",
      "Xinya Shu",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14502"
  },
  {
    "id": "arXiv:2211.14503",
    "title": "Simple initialization and parametrization of sinusoidal networks via  their kernel bandwidth",
    "abstract": "Neural networks with sinusoidal activations have been proposed as an\nalternative to networks with traditional activation functions. Despite their\npromise, particularly for learning implicit models, their training behavior is\nnot yet fully understood, leading to a number of empirical design choices that\nare not well justified. In this work, we first propose a simplified version of\nsuch sinusoidal neural networks, which allows both for easier practical\nimplementation and simpler theoretical analysis. We then analyze the behavior\nof these networks from the neural tangent kernel perspective and demonstrate\nthat their kernel approximates a low-pass filter with an adjustable bandwidth.\nFinally, we utilize these insights to inform the sinusoidal network\ninitialization, optimizing their performance for each of a series of tasks,\nincluding learning implicit models and solving differential equations.",
    "descriptor": "",
    "authors": [
      "Filipe de Avila Belbute-Peres",
      "J. Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14503"
  },
  {
    "id": "arXiv:2211.14505",
    "title": "Predictive linguistic cues for fake news: a societal artificial  intelligence problem",
    "abstract": "Media news are making a large part of public opinion and, therefore, must not\nbe fake. News on web sites, blogs, and social media must be analyzed before\nbeing published. In this paper, we present linguistic characteristics of media\nnews items to differentiate between fake news and real news using machine\nlearning algorithms. Neural fake news generation, headlines created by\nmachines, semantic incongruities in text and image captions generated by\nmachine are other types of fake news problems. These problems use neural\nnetworks which mainly control distributional features rather than evidence. We\npropose applying correlation between features set and class, and correlation\namong the features to compute correlation attribute evaluation metric and\ncovariance metric to compute variance of attributes over the news items.\nFeatures unique, negative, positive, and cardinal numbers with high values on\nthe metrics are observed to provide a high area under the curve (AUC) and\nF1-score.",
    "descriptor": "",
    "authors": [
      "Sandhya Aneja",
      "Nagender Aneja",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14505"
  },
  {
    "id": "arXiv:2211.14506",
    "title": "Progressive Disentangled Representation Learning for Fine-Grained  Controllable Talking Head Synthesis",
    "abstract": "We present a novel one-shot talking head synthesis method that achieves\ndisentangled and fine-grained control over lip motion, eye gaze&blink, head\npose, and emotional expression. We represent different motions via disentangled\nlatent representations and leverage an image generator to synthesize talking\nheads from them. To effectively disentangle each motion factor, we propose a\nprogressive disentangled representation learning strategy by separating the\nfactors in a coarse-to-fine manner, where we first extract unified motion\nfeature from the driving signal, and then isolate each fine-grained motion from\nthe unified feature. We introduce motion-specific contrastive learning and\nregressing for non-emotional motions, and feature-level decorrelation and\nself-reconstruction for emotional expression, to fully utilize the inherent\nproperties of each motion factor in unstructured video data to achieve\ndisentanglement. Experiments show that our method provides high quality\nspeech&lip-motion synchronization along with precise and disentangled control\nover multiple extra facial motions, which can hardly be achieved by previous\nmethods.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Duomin Wang",
      "Yu Deng",
      "Zixin Yin",
      "Heung-Yeung Shum",
      "Baoyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14506"
  },
  {
    "id": "arXiv:2211.14508",
    "title": "Lexicon-injected Semantic Parsing for Task-Oriented Dialog",
    "abstract": "Recently, semantic parsing using hierarchical representations for dialog\nsystems has captured substantial attention. Task-Oriented Parse (TOP), a tree\nrepresentation with intents and slots as labels of nested tree nodes, has been\nproposed for parsing user utterances. Previous TOP parsing methods are limited\non tackling unseen dynamic slot values (e.g., new songs and locations added),\nwhich is an urgent matter for real dialog systems. To mitigate this issue, we\nfirst propose a novel span-splitting representation for span-based parser that\noutperforms existing methods. Then we present a novel lexicon-injected semantic\nparser, which collects slot labels of tree representation as a lexicon, and\ninjects lexical features to the span representation of parser. An additional\nslot disambiguation technique is involved to remove inappropriate span match\noccurrences from the lexicon. Our best parser produces a new state-of-the-art\nresult (87.62%) on the TOP dataset, and demonstrates its adaptability to\nfrequently updated slot lexicon entries in real task-oriented dialog, with no\nneed of retraining.",
    "descriptor": "",
    "authors": [
      "Xiaojun Meng",
      "Wenlin Dai",
      "Yasheng Wang",
      "Baojun Wang",
      "Zhiyong Wu",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14508"
  },
  {
    "id": "arXiv:2211.14509",
    "title": "Joint Design of Spectrally-Constrained OFDM Sequences and Mismatch  Filter With PAPR Constraint",
    "abstract": "The OFDM sequences with low correlation sidelobe level (SLCL) is desired in\nmany 5G wireless systems. In this letter, the OFDM sequences and mismatch\nfilter are jointly designed to achieve the SLCL under the constraints of\nspectra and peak to average power ratio (PAPR). Specifically, we formulate the\noptimization problem by maximizing the peak side lobe ratio (PSLR) of the\ncross-correlation between the OFDM sequences and mismatch filter, subject to\nseveral practice constraints. To solve the nonconvex problem, an efficient\nalternating optimization (AltOpt) algorithm is proposed. Numerical simulations\nare provided to demonstrate the effectiveness of the proposed algorithms.",
    "descriptor": "",
    "authors": [
      "Jinyang He",
      "Ziyang Cheng",
      "Zishu He"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.14509"
  },
  {
    "id": "arXiv:2211.14512",
    "title": "Residual Pattern Learning for Pixel-wise Out-of-Distribution Detection  in Semantic Segmentation",
    "abstract": "Semantic segmentation models classify pixels into a set of known\n(``in-distribution'') visual classes. When deployed in an open world, the\nreliability of these models depends on their ability not only to classify\nin-distribution pixels but also to detect out-of-distribution (OoD) pixels.\nHistorically, the poor OoD detection performance of these models has motivated\nthe design of methods based on model re-training using synthetic training\nimages that include OoD visual objects. Although successful, these re-trained\nmethods have two issues: 1) their in-distribution segmentation accuracy may\ndrop during re-training, and 2) their OoD detection accuracy does not\ngeneralise well to new contexts (e.g., country surroundings) outside the\ntraining set (e.g., city surroundings). In this paper, we mitigate these issues\nwith: (i) a new residual pattern learning (RPL) module that assists the\nsegmentation model to detect OoD pixels without affecting the inlier\nsegmentation performance; and (ii) a novel context-robust contrastive learning\n(CoroCL) that enforces RPL to robustly detect OoD pixels among various\ncontexts. Our approach improves by around 10\\% FPR and 7\\% AuPRC the previous\nstate-of-the-art in Fishyscapes, Segment-Me-If-You-Can, and RoadAnomaly\ndatasets. Our code is available at: https://github.com/yyliu01/RPL.",
    "descriptor": "\nComments: 16 pages, 11 figures and it is a preprint version\n",
    "authors": [
      "Yuyuan Liu",
      "Choubo Ding",
      "Yu Tian",
      "Guansong Pang",
      "Vasileios Belagiannis",
      "Ian Reid",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14512"
  },
  {
    "id": "arXiv:2211.14513",
    "title": "Rethinking Alignment and Uniformity in Unsupervised Image Semantic  Segmentation",
    "abstract": "Unsupervised image semantic segmentation(UISS) aims to match low-level visual\nfeatures with semantic-level representations without outer supervision. In this\npaper, we address the critical properties from the view of feature alignments\nand feature uniformity for UISS models. We also make a comparison between UISS\nand image-wise representation learning. Based on the analysis, we argue that\nthe existing MI-based methods in UISS suffer from representation collapse. By\nthis, we proposed a robust network called Semantic Attention Network(SAN), in\nwhich a new module Semantic Attention(SEAT) is proposed to generate pixel-wise\nand semantic features dynamically. Experimental results on multiple semantic\nsegmentation benchmarks show that our unsupervised segmentation framework\nspecializes in catching semantic representations, which outperforms all the\nunpretrained and even several pretrained methods.",
    "descriptor": "\nComments: AAAI23\n",
    "authors": [
      "Daoan Zhang",
      "Chenming Li",
      "Haoquan Li",
      "Wenjian Huang",
      "Lingyun Huang",
      "Jianguo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14513"
  },
  {
    "id": "arXiv:2211.14515",
    "title": "Instance-level Heterogeneous Domain Adaptation for Limited-labeled  Sketch-to-Photo Retrieval",
    "abstract": "Although sketch-to-photo retrieval has a wide range of applications, it is\ncostly to obtain paired and rich-labeled ground truth. Differently, photo\nretrieval data is easier to acquire. Therefore, previous works pre-train their\nmodels on rich-labeled photo retrieval data (i.e., source domain) and then\nfine-tune them on the limited-labeled sketch-to-photo retrieval data (i.e.,\ntarget domain). However, without co-training source and target data, source\ndomain knowledge might be forgotten during the fine-tuning process, while\nsimply co-training them may cause negative transfer due to domain gaps.\nMoreover, identity label spaces of source data and target data are generally\ndisjoint and therefore conventional category-level Domain Adaptation (DA) is\nnot directly applicable. To address these issues, we propose an Instance-level\nHeterogeneous Domain Adaptation (IHDA) framework. We apply the fine-tuning\nstrategy for identity label learning, aiming to transfer the instance-level\nknowledge in an inductive transfer manner. Meanwhile, labeled attributes from\nthe source data are selected to form a shared label space for source and target\ndomains. Guided by shared attributes, DA is utilized to bridge cross-dataset\ndomain gaps and heterogeneous domain gaps, which transfers instance-level\nknowledge in a transductive transfer manner. Experiments show that our method\nhas set a new state of the art on three sketch-to-photo image retrieval\nbenchmarks without extra annotations, which opens the door to train more\neffective models on limited-labeled heterogeneous image retrieval tasks.\nRelated codes are available at \\url{https://github.com/fandulu/IHDA.",
    "descriptor": "",
    "authors": [
      "Fan Yang",
      "Yang Wu",
      "Zheng Wang",
      "Xiang Li",
      "Sakriani Sakti",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14515"
  },
  {
    "id": "arXiv:2211.14516",
    "title": "A Unified Framework for Contrastive Learning from a Perspective of  Affinity Matrix",
    "abstract": "In recent years, a variety of contrastive learning based unsupervised visual\nrepresentation learning methods have been designed and achieved great success\nin many visual tasks. Generally, these methods can be roughly classified into\nfour categories: (1) standard contrastive methods with an InfoNCE like loss,\nsuch as MoCo and SimCLR; (2) non-contrastive methods with only positive pairs,\nsuch as BYOL and SimSiam; (3) whitening regularization based methods, such as\nW-MSE and VICReg; and (4) consistency regularization based methods, such as\nCO2. In this study, we present a new unified contrastive learning\nrepresentation framework (named UniCLR) suitable for all the above four kinds\nof methods from a novel perspective of basic affinity matrix. Moreover, three\nvariants, i.e., SimAffinity, SimWhitening and SimTrace, are presented based on\nUniCLR. In addition, a simple symmetric loss, as a new consistency\nregularization term, is proposed based on this framework. By symmetrizing the\naffinity matrix, we can effectively accelerate the convergence of the training\nprocess. Extensive experiments have been conducted to show that (1) the\nproposed UniCLR framework can achieve superior results on par with and even be\nbetter than the state of the art, (2) the proposed symmetric loss can\nsignificantly accelerate the convergence of models, and (3) SimTrace can avoid\nthe mode collapse problem by maximizing the trace of a whitened affinity matrix\nwithout relying on asymmetry designs or stop-gradients.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Wenbin Li",
      "Meihao Kong",
      "Xuesong Yang",
      "Lei Wang",
      "Jing Huo",
      "Yang Gao",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14516"
  },
  {
    "id": "arXiv:2211.14517",
    "title": "A Particle-based Sparse Gaussian Process Optimizer",
    "abstract": "Task learning in neural networks typically requires finding a globally\noptimal minimizer to a loss function objective. Conventional designs of swarm\nbased optimization methods apply a fixed update rule, with possibly an adaptive\nstep-size for gradient descent based optimization. While these methods gain\nhuge success in solving different optimization problems, there are some cases\nwhere these schemes are either inefficient or suffering from local-minimum. We\npresent a new particle-swarm-based framework utilizing Gaussian Process\nRegression to learn the underlying dynamical process of descent. The biggest\nadvantage of this approach is greater exploration around the current state\nbefore deciding a descent direction. Empirical results show our approach can\nescape from the local minima compare with the widely-used state-of-the-art\noptimizers when solving non-convex optimization problems. We also test our\napproach under high-dimensional parameter space case, namely, image\nclassification task.",
    "descriptor": "",
    "authors": [
      "Chandrajit Bajaj",
      "Omatharv Bharat Vaidya",
      "Yi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.14517"
  },
  {
    "id": "arXiv:2211.14521",
    "title": "Robust One-shot Segmentation of Brain Tissues via Image-aligned Style  Transformation",
    "abstract": "One-shot segmentation of brain tissues is typically a dual-model iterative\nlearning: a registration model (reg-model) warps a carefully-labeled atlas onto\nunlabeled images to initialize their pseudo masks for training a segmentation\nmodel (seg-model); the seg-model revises the pseudo masks to enhance the\nreg-model for a better warping in the next iteration. However, there is a key\nweakness in such dual-model iteration that the spatial misalignment inevitably\ncaused by the reg-model could misguide the seg-model, which makes it converge\non an inferior segmentation performance eventually. In this paper, we propose a\nnovel image-aligned style transformation to reinforce the dual-model iterative\nlearning for robust one-shot segmentation of brain tissues. Specifically, we\nfirst utilize the reg-model to warp the atlas onto an unlabeled image, and then\nemploy the Fourier-based amplitude exchange with perturbation to transplant the\nstyle of the unlabeled image into the aligned atlas. This allows the subsequent\nseg-model to learn on the aligned and style-transferred copies of the atlas\ninstead of unlabeled images, which naturally guarantees the correct spatial\ncorrespondence of an image-mask training pair, without sacrificing the\ndiversity of intensity patterns carried by the unlabeled images. Furthermore,\nwe introduce a feature-aware content consistency in addition to the image-level\nsimilarity to constrain the reg-model for a promising initialization, which\navoids the collapse of image-aligned style transformation in the first\niteration. Experimental results on two public datasets demonstrate 1) a\ncompetitive segmentation performance of our method compared to the\nfully-supervised method, and 2) a superior performance over other\nstate-of-the-arts with an increase of average Dice by up to 4.67%. The source\ncode is available.",
    "descriptor": "\nComments: Accepted by AAAI-2023\n",
    "authors": [
      "Jinxin Lv",
      "Xiaoyu Zeng",
      "Sheng Wang",
      "Ran Duan",
      "Zhiwei Wang",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14521"
  },
  {
    "id": "arXiv:2211.14522",
    "title": "Visual Fault Detection of Multi-scale Key Components in Freight Trains",
    "abstract": "Fault detection for key components in the braking system of freight trains is\ncritical for ensuring railway transportation safety. Despite the frequently\nemployed methods based on deep learning, these fault detectors are highly\nreliant on hardware resources and are complex to implement. In addition, no\ntrain fault detectors consider the drop in accuracy induced by scale variation\nof fault parts. This paper proposes a lightweight anchor-free framework to\nsolve the above problems. Specifically, to reduce the amount of computation and\nmodel size, we introduce a lightweight backbone and adopt an anchor-free method\nfor localization and regression. To improve detection accuracy for multi-scale\nparts, we design a feature pyramid network to generate rectangular layers of\ndifferent sizes to map parts with similar aspect ratios. Experiments on four\nfault datasets show that our framework achieves 98.44% accuracy while the model\nsize is only 22.5 MB, outperforming state-of-the-art detectors.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Yang Zhang",
      "Yang Zhou",
      "Huilin Pan",
      "Bo Wu",
      "Guodong Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.14522"
  },
  {
    "id": "arXiv:2211.14523",
    "title": "VR-GNN: Variational Relation Vector Graph Neural Network for Modeling  both Homophily and Heterophily",
    "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success in diverse\nreal-world applications. Traditional GNNs are designed based on homophily,\nwhich leads to poor performance under heterophily scenarios. Current solutions\ndeal with heterophily mainly by mixing high-order neighbors or passing signed\nmessages. However, mixing high-order neighbors destroys the original graph\nstructure and passing signed messages utilizes an inflexible message-passing\nmechanism, which is prone to producing unsatisfactory effects. To overcome the\nabove problems, we propose a novel GNN model based on relation vector\ntranslation named Variational Relation Vector Graph Neural Network (VR-GNN).\nVR-GNN models relation generation and graph aggregation into an end-to-end\nmodel based on Variational Auto-Encoder. The encoder utilizes the structure,\nfeature and label to generate a proper relation vector. The decoder achieves\nsuperior node representation by incorporating the relation translation into the\nmessage-passing framework. VR-GNN can fully capture the homophily and\nheterophily between nodes due to the great flexibility of relation translation\nin modeling neighbor relationships. We conduct extensive experiments on eight\nreal-world datasets with different homophily-heterophily properties to verify\nthe effectiveness of our model. The experimental results show that VR-GNN gains\nconsistent and significant improvements against state-of-the-art GNN methods\nunder heterophily, and competitive performance under homophily.",
    "descriptor": "",
    "authors": [
      "Fengzhao Shi",
      "Ren Li",
      "Yanan Cao",
      "Yanmin Shang",
      "Lanxue Zhang",
      "Chuan Zhou",
      "Jia Wu",
      "Shirui Pan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14523"
  },
  {
    "id": "arXiv:2211.14528",
    "title": "An optimisation-based domain-decomposition reduced order model for the  incompressible Navier-Stokes equations",
    "abstract": "The aim of this work is to present a model reduction technique in the\nframework of optimal control problems for partial differential equations. We\ncombine two approaches used for reducing the computational cost of the\nmathematical numerical models: domain-decomposition (DD) methods and\nreduced-order modelling (ROM). In particular, we consider an optimisation-based\ndomain-decomposition algorithm for the parameter-dependent stationary\nincompressible Navier-Stokes equations. Firstly, the problem is described on\nthe subdomains coupled at the interface and solved through an optimal control\nproblem, which leads to the complete separation of the subdomain problems in\nthe DD method. On top of that, a reduced model for the obtained optimal-control\nproblem is built; the procedure is based on the Proper Orthogonal Decomposition\ntechnique and a further Galerkin projection. The presented methodology is\ntested on two fluid dynamics benchmarks: the stationary backward-facing step\nand lid-driven cavity flow. The numerical tests show a significant reduction of\nthe computational costs in terms of both the problem dimensions and the number\nof optimisation iterations in the domain-decomposition algorithm.",
    "descriptor": "",
    "authors": [
      "Ivan Prusak",
      "Monica Nonino",
      "Davide Torlo",
      "Francesco Ballarin",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.14528"
  },
  {
    "id": "arXiv:2211.14530",
    "title": "On the Stability and Accuracy of Clenshaw-Curtis Collocation",
    "abstract": "We study the A-stability and accuracy characteristics of Clenshaw-Curtis\ncollocation. We present closed-form expressions to evaluate the Runge-Kutta\ncoefficients of these methods. From the A-stability study, Clenshaw-Curtis\nmethods are A-stable up to a high number of nodes. High accuracy is another\nbenefit of these methods; numerical experiments demonstrate that they can match\nthe accuracy of the Gauss-Legendre collocation, which has the optimal accuracy\norder of all Runge-Kutta methods.",
    "descriptor": "",
    "authors": [
      "Ahmed Atallah",
      "Ahmad Bani Younes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14530"
  },
  {
    "id": "arXiv:2211.14531",
    "title": "Equity Promotion in Public Transportation",
    "abstract": "There are many news articles reporting the obstacles confronting\npoverty-stricken households in access to public transits. These barriers create\na great deal of inconveniences for these impoverished families and more\nimportantly, they contribute a lot of social inequalities. A typical approach\naddressing the issue is to build more transport infrastructure to offer more\nopportunities to access the public transits especially for those deprived\ncommunities. Examples include adding more bus lines connecting needy residents\nto railways systems and extending existing bus lines to areas with low\nsocioeconomic status. Recently, a new strategy is proposed, which is to harness\nthe ubiquitous ride-hailing services to connect disadvantaged households with\nthe nearest public transportations. Compared with the former\ninfrastructure-based solution, the ride-hailing-based strategy enjoys a few\nexclusive benefits such as higher effectiveness and more flexibility.\nIn this paper, we propose an optimization model to study how to integrate the\ntwo approaches together for equity-promotion purposes. Specifically, we aim to\ndesign a strategy of allocating a given limited budget to different candidate\nprograms such that the overall social equity is maximized, which is defined as\nthe minimum covering ratio among all pre-specified protected groups of\nhouseholds (based on race, income, etc.). We have designed a linear-programming\n(LP) based rounding algorithm, which proves to achieve an optimal approximation\nratio of 1-1/e. Additionally, we test our algorithm against a few baselines on\nreal data assembled by outsourcing multiple public datasets collected in the\ncity of Chicago. Experimental results confirm our theoretical predictions and\ndemonstrate the effectiveness of our LP-based strategy in promoting social\nequity, especially when the budget is insufficient.",
    "descriptor": "\nComments: A preliminary version will appear in the 37th AAAI Conference on Artificial Intelligence (AAAI 23)\n",
    "authors": [
      "Anik Pramanik",
      "Pan Xu",
      "Yifan Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.14531"
  },
  {
    "id": "arXiv:2211.14533",
    "title": "Visual Place Recognition",
    "abstract": "Visual position recognition affects the safety and accuracy of automatic\ndriving. To accurately identify the location, this paper studies a visual place\nrecognition algorithm based on HMM filter and HMM smoother. Firstly, we\nconstructed the traffic situations in Canberra city. Then the mathematical\nmodels of the HMM filter and HMM smoother were performed. Finally, the vehicle\nposition was predicted based on the algorithms. Experiment results show that\nHMM smoother is better than HMM filter in terms of prediction accuracy.",
    "descriptor": "",
    "authors": [
      "Bailu Guo",
      "Boyu Zhao",
      "Zishun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14533"
  },
  {
    "id": "arXiv:2211.14537",
    "title": "An FMM Accelerated Poisson Solver for Complicated Geometries in the  Plane using Function Extension",
    "abstract": "We describe a new, adaptive solver for the two-dimensional Poisson equation\nin complicated geometries. Using classical potential theory, we represent the\nsolution as the sum of a volume potential and a double layer potential. Rather\nthan evaluating the volume potential over the given domain, we first extend the\nsource data to a geometrically simpler region with high order accuracy. This\nallows us to accelerate the evaluation of the volume potential using an\nefficient, geometry-unaware fast multipole-based algorithm. To impose the\ndesired boundary condition, it remains only to solve the Laplace equation with\nsuitably modified boundary data. This is accomplished with existing fast and\naccurate boundary integral methods. The novelty of our solver is the scheme\nused for creating the source extension, assuming it is provided on an adaptive\nquad-tree. For leaf boxes intersected by the boundary, we construct a universal\n\"stencil\" and require that the data be provided at the subset of those points\nthat lie within the domain interior. This universality permits us to precompute\nand store an interpolation matrix which is used to extrapolate the source data\nto an extended set of leaf nodes with full tensor-product grids on each. We\ndemonstrate the method's speed, robustness and high-order convergence with\nseveral examples, including domains with piecewise smooth boundaries.",
    "descriptor": "",
    "authors": [
      "Fredrik Fryklund",
      "Leslie Greengard"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14537"
  },
  {
    "id": "arXiv:2211.14539",
    "title": "An Automatic SOAP Classification System Using Weakly Supervision And  Transfer Learning",
    "abstract": "In this paper, we introduce a comprehensive framework for developing a\nmachine learning-based SOAP (Subjective, Objective, Assessment, and Plan)\nclassification system without manually SOAP annotated training data or with\nless manually SOAP annotated training data. The system is composed of the\nfollowing two parts: 1) Data construction, 2) A neural network-based SOAP\nclassifier, and 3) Transfer learning framework. In data construction, since a\nmanual construction of a large size training dataset is expensive, we propose a\nrule-based weak labeling method utilizing the structured information of an EHR\nnote. Then, we present a SOAP classifier composed of a pre-trained language\nmodel and bi-directional long-short term memory with conditional random field\n(Bi-LSTM-CRF). Finally, we propose a transfer learning framework that re-uses\nthe trained parameters of the SOAP classifier trained with the weakly labeled\ndataset for datasets collected from another hospital. The proposed weakly\nlabel-based learning model successfully performed SOAP classification (89.99\nF1-score) on the notes collected from the target hospital. Otherwise, in the\nnotes collected from other hospitals and departments, the performance\ndramatically decreased. Meanwhile, we verified that the transfer learning\nframework is advantageous for inter-hospital adaptation of the model increasing\nthe models' performance in every cases. In particular, the transfer learning\napproach was more efficient when the manually annotated data size was smaller.\nWe showed that SOAP classification models trained with our weakly labeling\nalgorithm can perform SOAP classification without manually annotated data on\nthe EHR notes from the same hospital. The transfer learning framework helps\nSOAP classification model's inter-hospital migration with a minimal size of the\nmanually annotated dataset.",
    "descriptor": "",
    "authors": [
      "Sunjae Kwon",
      "Zhichao Yang",
      "Hong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14539"
  },
  {
    "id": "arXiv:2211.14540",
    "title": "Lexical Complexity Controlled Sentence Generation",
    "abstract": "Text generation rarely considers the control of lexical complexity, which\nlimits its more comprehensive practical application. We introduce a novel task\nof lexical complexity controlled sentence generation, which aims at keywords to\nsentence generation with desired complexity levels. It has enormous potential\nin domains such as grade reading, language teaching and acquisition. The\nchallenge of this task is to generate fluent sentences only using the words of\ngiven complexity levels. We propose a simple but effective approach for this\ntask based on complexity embedding. Compared with potential solutions, our\napproach fuses the representations of the word complexity levels into the model\nto get better control of lexical complexity. And we demonstrate the feasibility\nof the approach for both training models from scratch and fine-tuning the\npre-trained models. To facilitate the research, we develop two datasets in\nEnglish and Chinese respectively, on which extensive experiments are conducted.\nResults show that our approach better controls lexical complexity and generates\nhigher quality sentences than baseline methods.",
    "descriptor": "",
    "authors": [
      "Jinran Nie",
      "Liner Yang",
      "Yun Chen",
      "Cunliang Kong",
      "Junhui Zhu",
      "Erhong Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14540"
  },
  {
    "id": "arXiv:2211.14541",
    "title": "RL-Based Guidance in Outpatient Hysteroscopy Training: A Feasibility  Study",
    "abstract": "This work presents an RL-based agent for outpatient hysteroscopy training.\nHysteroscopy is a gynecological procedure for examination of the uterine\ncavity. Recent advancements enabled performing this type of intervention in the\noutpatient setup without anaesthesia. While being beneficial to the patient,\nthis approach introduces new challenges for clinicians, who should take\nadditional measures to maintain the level of patient comfort and prevent tissue\ndamage. Our prior work has presented a platform for hysteroscopic training with\nthe focus on the passage of the cervical canal. With this work, we aim to\nextend the functionality of the platform by designing a subsystem that\nautonomously performs the task of the passage of the cervical canal. This\nfeature can later be used as a virtual instructor to provide educational cues\nfor trainees and assess their performance. The developed algorithm is based on\nthe soft actor critic approach to smooth the learning curve of the agent and\nensure uniform exploration of the workspace. The designed algorithm was tested\nagainst the performance of five clinicians. Overall, the algorithm demonstrated\nhigh efficiency and reliability, succeeding in 98% of trials and outperforming\nthe expert group in three out of four measured metrics.",
    "descriptor": "",
    "authors": [
      "Vladimir Poliakov",
      "Kenan Niu",
      "Emmanuel Vander Poorten",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14541"
  },
  {
    "id": "arXiv:2211.14542",
    "title": "The Information Ecosystem of Conspiracy Theory: Examining the QAnon  Narrative on Facebook",
    "abstract": "There has been concern about the proliferation of the \"QAnon\" conspiracy\ntheory on Facebook, but little is known about how its misleading narrative\npropagated on the world's largest social media platform. Thus, the present\nresearch analyzed content generated by 2,813 Facebook pages and groups that\ncontributed to promoting the conspiracy narrative between 2017 and 2020. The\nresult demonstrated that activities of QAnon pages and groups started a\nsignificant surge months before the 2020 U.S. Presidential Election. We found\nthat these pages and groups increasingly relied on internal sources, i.e.,\nFacebook accounts or their content on the platform, while their dependence on\nexternal information sources decreased continuously since 2017. It was also\nfound that QAnon posts based on the Facebook internal sources attracted\nsignificantly more shares and comments compared with other QAnon posts. These\nfindings suggest that QAnon pages and groups increasingly isolated themselves\nfrom sources outside Facebook while having more internal interactions within\nthe platform, and the endogenous creation and circulation of disinformation\nmight play a significant role in boosting the influence of the misleading\nnarrative within Facebook. The findings imply that the efforts to tackle down\ndisinformation on social media should target not only the cross-platform\ninfiltration of falsehood but also the intra-platform production and\npropagation of disinformation.",
    "descriptor": "\nComments: Accepted for publication at CSCW 2023. Forthcoming in the Proceedings of the ACM on Human-Computer Interaction\n",
    "authors": [
      "Soojong Kim",
      "Jisu Kim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.14542"
  },
  {
    "id": "arXiv:2211.14544",
    "title": "Target-Free Text-guided Image Manipulation",
    "abstract": "We tackle the problem of target-free text-guided image manipulation, which\nrequires one to modify the input reference image based on the given text\ninstruction, while no ground truth target image is observed during training. To\naddress this challenging task, we propose a Cyclic-Manipulation GAN (cManiGAN)\nin this paper, which is able to realize where and how to edit the image regions\nof interest. Specifically, the image editor in cManiGAN learns to identify and\ncomplete the input image, while cross-modal interpreter and reasoner are\ndeployed to verify the semantic correctness of the output image based on the\ninput instruction. While the former utilizes factual/counterfactual description\nlearning for authenticating the image semantics, the latter predicts the \"undo\"\ninstruction and provides pixel-level supervision for the training of cManiGAN.\nWith such operational cycle-consistency, our cManiGAN can be trained in the\nabove weakly supervised setting. We conduct extensive experiments on the\ndatasets of CLEVR and COCO, and the effectiveness and generalizability of our\nproposed method can be successfully verified. Project page:\nhttps://sites.google.com/view/wancyuanfan/projects/cmanigan.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Wan-Cyuan Fan",
      "Cheng-Fu Yang",
      "Chiao-An Yang",
      "Yu-Chiang Frank Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14544"
  },
  {
    "id": "arXiv:2211.14545",
    "title": "Ensemble Multi-Quantile: Adaptively Flexible Distribution Prediction for  Uncertainty Quantification",
    "abstract": "We propose a novel, succinct, and effective approach to quantify uncertainty\nin machine learning. It incorporates adaptively flexible distribution\nprediction for $\\mathbb{P}(\\mathbf{y}|\\mathbf{X}=x)$ in regression tasks. For\npredicting this conditional distribution, its quantiles of probability levels\nspreading the interval $(0,1)$ are boosted by additive models which are\ndesigned by us with intuitions and interpretability. We seek an adaptive\nbalance between the structural integrity and the flexibility for\n$\\mathbb{P}(\\mathbf{y}|\\mathbf{X}=x)$, while Gaussian assumption results in a\nlack of flexibility for real data and highly flexible approaches (e.g.,\nestimating the quantiles separately without a distribution structure)\ninevitably have drawbacks and may not lead to good generalization. This\nensemble multi-quantiles approach called EMQ proposed by us is totally\ndata-driven, and can gradually depart from Gaussian and discover the optimal\nconditional distribution in the boosting. On extensive regression tasks from\nUCI datasets, we show that EMQ achieves state-of-the-art performance comparing\nto many recent uncertainty quantification methods including Gaussian\nassumption-based, Bayesian methods, quantile regression-based, and traditional\ntree models, under the metrics of calibration, sharpness, and tail-side\ncalibration. Visualization results show what we actually learn from the real\ndata and how, illustrating the necessity and the merits of such an ensemble\nmodel.",
    "descriptor": "",
    "authors": [
      "Xing Yan",
      "Yonghua Su",
      "Wenxuan Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14545"
  },
  {
    "id": "arXiv:2211.14547",
    "title": "Profile-Guided Parallel Task Extraction and Execution for Domain  Specific Heterogeneous SoC",
    "abstract": "In this study, we introduce a methodology for automatically transforming user\napplications in the radar and communication domain written in C/C++ based on\ndynamic profiling to a parallel representation targeted for a heterogeneous\nSoC. We present our approach for instrumenting the user application binary\nduring the compilation process with barrier synchronization primitives that\nenable runtime system schedule and execute independent tasks concurrently over\nthe available compute resources. We demonstrate the capabilities of our\nintegrated compile time and runtime flow through task-level parallel and\nfunctionally correct execution of real-life applications. We perform validation\nof our integrated system by executing four distinct applications each carrying\nvarious degrees of task level parallelism over the Xeon-based multi-core\nhomogeneous processor. We use the proposed compilation and code transformation\nmethodology to re-target each application for execution on a heterogeneous SoC\ncomposed of three ARM cores and one FFT accelerator that is emulated on the\nXilinx Zynq UltraScale+ platform. We demonstrate our runtime's ability to\nprocess application binary, dispatch independent tasks over the available\ncompute resources of the emulated SoC on the Zynq FPGA based on three different\nscheduling heuristics. Finally we demonstrate execution of each application\nindividually with task level parallelism on the Zynq FPGA and execution of\nworkload scenarios composed of multiple instances of the same application as\nwell as mixture of two distinct applications to demonstrate ability to realize\nboth application and task level parallel execution. Our integrated approach\noffers a path forward for application developers to take full advantage of the\ntarget SoC without requiring users to become hardware and parallel programming\nexperts.",
    "descriptor": "\nComments: 8 pages, accepted by ISPA 2022\n",
    "authors": [
      "Liangliang Chang",
      "Joshua Mack",
      "Benjamin Willis",
      "Xing Chen",
      "John Brunhaver",
      "Ali Akoglu",
      "Chaitali Chakrabarti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.14547"
  },
  {
    "id": "arXiv:2211.14552",
    "title": "Cross-Field Transformer for Diabetic Retinopathy Grading on Two-feld  Fundus Images",
    "abstract": "Automatic diabetic retinopathy (DR) grading based on fundus photography has\nbeen widely explored to benefit the routine screening and early treatment.\nExisting researches generally focus on single-feld fundus images, which have\nlimited field of view for precise eye examinations. In clinical applications,\nophthalmologists adopt two-feld fundus photography as the dominating tool,\nwhere the information from each feld (i.e.,macula-centric and optic\ndisc-centric) is highly correlated and complementary, and benefits\ncomprehensive decisions. However, automatic DR grading based on two-feld fundus\nphotography remains a challenging task due to the lack of publicly available\ndatasets and effective fusion strategies. In this work, we first construct a\nnew benchmark dataset (DRTiD) for DR grading, consisting of 3,100 two-feld\nfundus images. To the best of our knowledge, it is the largest public DR\ndataset with diverse and high-quality two-feld images. Then, we propose a novel\nDR grading approach, namely Cross-Field Transformer (CrossFiT), to capture the\ncorrespondence between two felds as well as the long-range spatial correlations\nwithin each feld. Considering the inherent two-feld geometric constraints, we\nparticularly define aligned position embeddings to preserve relative consistent\nposition in fundus. Besides, we perform masked cross-field attention during\ninteraction to flter the noisy relations between fields. Extensive experiments\non our DRTiD dataset and a public DeepDRiD dataset demonstrate the\neffectiveness of our CrossFiT network. The new dataset and the source code of\nCrossFiT will be publicly available at https://github.com/FDU-VTS/DRTiD.",
    "descriptor": "\nComments: BIBM 2022\n",
    "authors": [
      "Junlin Hou",
      "Jilan Xu",
      "Fan Xiao",
      "Rui-Wei Zhao",
      "Yuejie Zhang",
      "Haidong Zou",
      "Lina Lu",
      "Wenwen Xue",
      "Rui Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14552"
  },
  {
    "id": "arXiv:2211.14553",
    "title": "A Remote Baby Surveillance System with RFID and GPS Tracking",
    "abstract": "In the 21st century, sending babies or children to daycare centres has become\nmore and more common among young guardians. The balance between full-time work\nand child care is increasingly challenging nowadays. In Malaysia, thousands of\nchild abuse cases have been reported from babysitting centres every year, which\nindeed triggers the anxiety and stress of the guardians. Hence, this paper\nproposes to construct a remote baby surveillance system with radio-frequency\nidentification (RFID) and global positioning system (GPS) tracking. With the\nincorporation of the Internet of Things (IoT), a sensor-based microcontroller\nis used to detect the conditions of the baby as well as the surrounding\nenvironment and then display the real-time data as well as notifications to\nalert the guardians via a mobile application. These conditions include the\ncrying and waking of the baby, as well as temperature, the mattress's wetness,\nand moving objects around the baby. In addition, RFID and GPS location tracking\nare implemented to ensure the safety of the baby, while white noise is used to\nincrease the comfort of the baby. In the end, a prototype has been successfully\ndeveloped for functionality and reliability testing. Several experiments have\nbeen conducted to measure the efficiency of the mattress's wetness detection,\nthe RFID transmission range, the frequency spectrum of white noise, and also\nthe output power of the solar panel. The proposed system is expected to assist\nguardians in ensuring the safety and comfort of their babies remotely, as well\nas prevent any occurrence of child abuse.",
    "descriptor": "\nComments: 12 pages, 13 figures Published with International Journal of Engineering Trends and Technology (IJETT)\n",
    "authors": [
      "Ruven A/L Sundarajoo",
      "Gwo Chin Chung",
      "Wai Leong Pang",
      "Soo Fun Tan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14553"
  },
  {
    "id": "arXiv:2211.14554",
    "title": "DynaGAN: Dynamic Few-shot Adaptation of GANs to Multiple Domains",
    "abstract": "Few-shot domain adaptation to multiple domains aims to learn a complex image\ndistribution across multiple domains from a few training images. A na\\\"ive\nsolution here is to train a separate model for each domain using few-shot\ndomain adaptation methods. Unfortunately, this approach mandates\nlinearly-scaled computational resources both in memory and computation time\nand, more importantly, such separate models cannot exploit the shared knowledge\nbetween target domains. In this paper, we propose DynaGAN, a novel few-shot\ndomain-adaptation method for multiple target domains. DynaGAN has an adaptation\nmodule, which is a hyper-network that dynamically adapts a pretrained GAN model\ninto the multiple target domains. Hence, we can fully exploit the shared\nknowledge across target domains and avoid the linearly-scaled computational\nrequirements. As it is still computationally challenging to adapt a large-size\nGAN model, we design our adaptation module light-weight using the rank-1 tensor\ndecomposition. Lastly, we propose a contrastive-adaptation loss suitable for\nmulti-domain few-shot adaptation. We validate the effectiveness of our method\nthrough extensive qualitative and quantitative evaluations.",
    "descriptor": "\nComments: Accepted to SIGGRAPH Asia 2022. For supplementary material, see this https URL\n",
    "authors": [
      "Seongtae Kim",
      "Kyoungkook Kang",
      "Geonung Kim",
      "Seung-Hwan Baek",
      "Sunghyun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14554"
  },
  {
    "id": "arXiv:2211.14558",
    "title": "Toward Universal Text-to-Music Retrieval",
    "abstract": "This paper introduces effective design choices for text-to-music retrieval\nsystems. An ideal text-based retrieval system would support various input\nqueries such as pre-defined tags, unseen tags, and sentence-level descriptions.\nIn reality, most previous works mainly focused on a single query type (tag or\nsentence) which may not generalize to another input type. Hence, we review\nrecent text-based music retrieval systems using our proposed benchmark in two\nmain aspects: input text representation and training objectives. Our findings\nenable a universal text-to-music retrieval system that achieves comparable\nretrieval performances in both tag- and sentence-level inputs. Furthermore, the\nproposed multimodal representation generalizes to 9 different downstream music\nclassification tasks. We present the code and demo online.",
    "descriptor": "",
    "authors": [
      "SeungHeon Doh",
      "Minz Won",
      "Keunwoo Choi",
      "Juhan Nam"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.14558"
  },
  {
    "id": "arXiv:2211.14563",
    "title": "Who are you referring to? Weakly supervised coreference resolution with  multimodal grounding",
    "abstract": "Coreference resolution aims at identifying words and phrases which refer to\nsame entity in a text, a core tool in natural language processing. In this\npaper, we propose a novel task, resolving coreferences in multimodal data,\nlong-form textual descriptions of visual scenes. Most existing image-text\ndatasets only contain short sentences without coreferent expressions, or\ncoreferences are not annotated. To this end, we first introduce a new dataset,\nFlickr30k-Coref in which coreference chains and bounding box localization of\nthese chains are annotated. We propose a new technique that learns to identify\ncoreference chains through weakly supervised grounding from image-text pairs\nand a regularization using prior linguistic knowledge. Our model yields large\nperformance gains over prior work in coreference resolution and weakly\nsupervised grounding of long-form text descriptions.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Arushi Goel",
      "Basura Fernando",
      "Frank Keller",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14563"
  },
  {
    "id": "arXiv:2211.14564",
    "title": "Siamese Object Tracking for Vision-Based UAM Approaching with Pairwise  Scale-Channel Attention",
    "abstract": "Although the manipulating of the unmanned aerial manipulator (UAM) has been\nwidely studied, vision-based UAM approaching, which is crucial to the\nsubsequent manipulating, generally lacks effective design. The key to the\nvisual UAM approaching lies in object tracking, while current UAM tracking\ntypically relies on costly model-based methods. Besides, UAM approaching often\nconfronts more severe object scale variation issues, which makes it\ninappropriate to directly employ state-of-the-art model-free Siamese-based\nmethods from the object tracking field. To address the above problems, this\nwork proposes a novel Siamese network with pairwise scale-channel attention\n(SiamSA) for vision-based UAM approaching. Specifically, SiamSA consists of a\npairwise scale-channel attention network (PSAN) and a scale-aware anchor\nproposal network (SA-APN). PSAN acquires valuable scale information for feature\nprocessing, while SA-APN mainly attaches scale awareness to anchor proposing.\nMoreover, a new tracking benchmark for UAM approaching, namely UAMT100, is\nrecorded with 35K frames on a flying UAM platform for evaluation. Exhaustive\nexperiments on the benchmarks and real-world tests validate the efficiency and\npracticality of SiamSA with a promising speed. Both the code and UAMT100\nbenchmark are now available at https://github.com/vision4robotics/SiamSA.",
    "descriptor": "\nComments: Accepted by IROS2022\n",
    "authors": [
      "Guangze Zheng",
      "Changhong Fu",
      "Junjie Ye",
      "Bowen Li",
      "Geng Lu",
      "Jia Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14564"
  },
  {
    "id": "arXiv:2211.14565",
    "title": "On the Joint Estimation of Phase Noise and Time-Varying Channels for  OFDM under High-Mobility Conditions",
    "abstract": "The combination of the effects of Doppler frequency shifts (due to mobility)\nand phase noise (due to the imperfections of oscillators operating at a high\ncarrier frequency) poses serious challenges to Orthogonal Frequency Division\nMultiplexing (OFDM) wireless transmissions in terms of channel estimation and\nphase noise tracking performance and the associated pilot overhead required for\nthat estimation and tracking. In this paper, we use separate sets of Basis\nExpansion Model (BEM) coefficients for modelling the time variation over\nintervals of several OFDM symbols of the channel paths and the phase noise\nprocess. Based on this model, an efficient solution approximating the\nmaximum-likelihood joint estimation of these BEM coefficients is derived and\nshown to outperform state-of-the-art phase noise compensation methods",
    "descriptor": "",
    "authors": [
      "Francesco Linsalata",
      "Nassar Ksairi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.14565"
  },
  {
    "id": "arXiv:2211.14568",
    "title": "BeGin: Extensive Benchmark Scenarios and An Easy-to-use Framework for  Graph Continual Learning",
    "abstract": "Continual Learning (CL) is the process of learning ceaselessly a sequence of\ntasks. Most existing CL methods deal with independent data (e.g., images and\ntext) for which many benchmark frameworks and results under standard\nexperimental settings are available. CL methods for graph data, however, are\nsurprisingly underexplored because of (a) the lack of standard experimental\nsettings, especially regarding how to deal with the dependency between\ninstances, (b) the lack of benchmark datasets and scenarios, and (c) high\ncomplexity in implementation and evaluation due to the dependency. In this\npaper, regarding (a), we define four standard incremental settings (task-,\nclass-, domain-, and time-incremental settings) for graph data, which are\nnaturally applied to many node-, link-, and graph-level problems. Regarding\n(b), we provide 23 benchmark scenarios based on 14 real-world graphs. Regarding\n(c), we develop BeGin, an easy and fool-proof framework for graph CL. BeGin is\neasily extended since it is modularized with reusable modules for data\nprocessing, algorithm design, and evaluation. Especially, the evaluation module\nis completely separated from user code to eliminate potential mistakes in\nevaluation. Using all above, we report extensive benchmark results of seven\ngraph CL methods. Compared to the latest benchmark for graph CL, using BeGin,\nwe cover three times more combinations of incremental settings and levels of\nproblems.",
    "descriptor": "",
    "authors": [
      "Jihoon Ko",
      "Shinhwan Kang",
      "Kijung Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14568"
  },
  {
    "id": "arXiv:2211.14570",
    "title": "The Role of In-House Procurement According to Finnish Municipalities'  Purchase Invoice Data",
    "abstract": "Public sector is a large consumer of ICT systems and services, used for\nvarious public services. Tendering for such systems is governed by laws aimed\nat eliminating unfair advantages and offering all possible parties equal\nopportunities to participate in the tendering process. In this article, we\nstudy in-house rpocurement, where the acquiring organization is an owner of the\nsubcontractor that delivers the system or the service. Municipalities' purchase\ninvoice data is used to determine how much municipalities in Finland depend on\nin-house procurement. In conclusion, the understanding if included\nmunicipalities have ICT service and development units within the organizations\nneeds closer examination, as in-house companies may offer municipalities with\nlimited resources divided costs in the public procurement process.",
    "descriptor": "\nComments: 8 pages, 1 figure, 2 tables\n",
    "authors": [
      "Reetta-Kaisa Ghezzi",
      "Minnamaria Korhonen",
      "Hannu Vilpponen",
      "Tommi Mikkonen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.14570"
  },
  {
    "id": "arXiv:2211.14572",
    "title": "Identifying a 3-vertex strongly biconnected directed subgraph with  minimum number of edges",
    "abstract": "A strongly connected graph is strongly biconnected if after ignoring the\ndirection of its edges we have an undirected graph with no articulation points.\nA 3-vertex strongly biconnected graph is a strongly biconnected digraph that\nhas the property that deleting any two vertices in this graph leaves a strongly\nbinconnected subgraph. Jaberi [11] presented approximation algorithms for\nminimum cardinality 2-vertex strongly biconnected directed subgraph problem. We\nwill focus in this paper on polynomial time algorithms which we have\nimplemented for producing spanning subgraphs that are 3-vertex strongly\nbiconnected.",
    "descriptor": "",
    "authors": [
      "Azzam Habib"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.14572"
  },
  {
    "id": "arXiv:2211.14573",
    "title": "Deep Curvilinear Editing: Commutative and Nonlinear Image Manipulation  for Pretrained Deep Generative Model",
    "abstract": "Semantic editing of images is the fundamental goal of computer vision.\nAlthough deep learning methods, such as generative adversarial networks (GANs),\nare capable of producing high-quality images, they often do not have an\ninherent way of editing generated images semantically. Recent studies have\ninvestigated a way of manipulating the latent variable to determine the images\nto be generated. However, methods that assume linear semantic arithmetic have\ncertain limitations in terms of the quality of image editing, whereas methods\nthat discover nonlinear semantic pathways provide non-commutative editing,\nwhich is inconsistent when applied in different orders. This study proposes a\nnovel method called deep curvilinear editing (DeCurvEd) to determine semantic\ncommuting vector fields on the latent space. We theoretically demonstrate that\nowing to commutativity, the editing of multiple attributes depends only on the\nquantities and not on the order. Furthermore, we experimentally demonstrate\nthat compared to previous methods, the nonlinear and commutative nature of\nDeCurvEd facilitates the disentanglement of image attributes and provides\nhigher-quality editing.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Takehiro Aoshima",
      "Takashi Matsubara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14573"
  },
  {
    "id": "arXiv:2211.14574",
    "title": "Very High-Order A-stable Stiffly Accurate Diagonally Implicit  Runge-Kutta Methods",
    "abstract": "A numerical search approach is used to design high-order diagonally implicit\nRunge-Kutta (DIRK) schemes suitable for stiff and oscillatory systems. We\npresent new A-stable schemes of orders six (the highest order of previously\ndesigned DIRK schemes) up to eight. For each order, we include one scheme that\nis only A-stable as well as one that is stiffly accurate and therefore\nL-stable. The stiffly accurate schemes require more stages but can be expected\nto give better results for highly stiff problems and differential-algebraic\nequations. The development of eighth-order schemes requires the highly accurate\nnumerical solution of a system of 200 equations in over 100 variables, which is\naccomplished via a combination of global and local optimization. The accuracy\nand stability of the schemes is analyzed and tested on diverse problems.",
    "descriptor": "",
    "authors": [
      "Yousef Alamri",
      "David I. Ketcheson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14574"
  },
  {
    "id": "arXiv:2211.14575",
    "title": "Randomized Conditional Flow Matching for Video Prediction",
    "abstract": "We introduce a novel generative model for video prediction based on latent\nflow matching, an efficient alternative to diffusion-based models. In contrast\nto prior work that either incurs a high training cost by modeling the past\nthrough a memory state, as in recurrent neural networks, or limits the\ncomputational load by conditioning only on a predefined window of past frames,\nwe efficiently and effectively take the past into account by conditioning at\ninference time only on a small random set of past frames at each integration\nstep of the learned flow. Moreover, to enable the generation of high-resolution\nvideos and speed up the training, we work in the latent space of a pretrained\nVQGAN. Furthermore, we propose to approximate the initial condition of the flow\nODE with the previous noisy frame. This allows to reduce the number of\nintegration steps and hence, speed up the sampling at inference time. We call\nour model Random frame conditional flow Integration for VidEo pRediction, or,\nin short, RIVER. We show that RIVER achieves superior or on par performance\ncompared to prior work on common video prediction benchmarks.",
    "descriptor": "",
    "authors": [
      "Aram Davtyan",
      "Sepehr Sameni",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14575"
  },
  {
    "id": "arXiv:2211.14577",
    "title": "Distribution estimation and change-point detection for time series via  DNN-based GANs",
    "abstract": "The generative adversarial networks (GANs) have recently been applied to\nestimating the distribution of independent and\nidentically distributed data, and got excellent performances. In this paper,\nwe use the blocking technique to demonstrate the effectiveness of GANs for\nestimating the distribution of stationary time series. Theoretically, we obtain\na non-asymptotic error bound for the Deep Neural Network (DNN)-based GANs\nestimator for the stationary distribution of the time series. Based on our\ntheoretical analysis, we put forward an algorithm for detecting the\nchange-point in time series. We simulate in our first experiment a stationary\ntime series by the multivariate autoregressive model to test our GAN estimator,\nwhile the second experiment is to use our proposed algorithm to detect the\nchange-point in a time series sequence. Both perform very well. The third\nexperiment is to use our GAN estimator to learn the distribution of a real\nfinancial time series data, which is not stationary, we can see from the\nexperiment results that our estimator cannot match the distribution of the time\nseries very well but give the right changing tendency.",
    "descriptor": "",
    "authors": [
      "Jianya Lu",
      "Yingjun Mo",
      "Zhijie Xiao",
      "Lihu Xu",
      "Qiuran Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.14577"
  },
  {
    "id": "arXiv:2211.14582",
    "title": "Demystifying Bitcoin Address Behavior via Graph Neural Networks",
    "abstract": "Bitcoin is one of the decentralized cryptocurrencies powered by a\npeer-to-peer blockchain network. Parties who trade in the bitcoin network are\nnot required to disclose any personal information. Such property of anonymity,\nhowever, precipitates potential malicious transactions to a certain extent.\nIndeed, various illegal activities such as money laundering, dark network\ntrading, and gambling in the bitcoin network are nothing new now. While a\nproliferation of work has been developed to identify malicious bitcoin\ntransactions, the behavior analysis and classification of bitcoin addresses are\nlargely overlooked by existing tools. In this paper, we propose BAClassifier, a\ntool that can automatically classify bitcoin addresses based on their\nbehaviors. Technically, we come up with the following three key designs. First,\nwe consider casting the transactions of the bitcoin address into an address\ngraph structure, of which we introduce a graph node compression technique and a\ngraph structure augmentation method to characterize a unified graph\nrepresentation. Furthermore, we leverage a graph feature network to learn the\ngraph representations of each address and generate the graph embeddings.\nFinally, we aggregate all graph embeddings of an address into the address-level\nrepresentation, and engage in a classification model to give the address\nbehavior classification. As a side contribution, we construct and release a\nlarge-scale annotated dataset that consists of over 2 million real-world\nbitcoin addresses and concerns 4 types of address behaviors. Experimental\nresults demonstrate that our proposed framework outperforms state-of-the-art\nbitcoin address classifiers and existing classification models, where the\nprecision and F1-score are 96% and 95%, respectively. Our implementation and\ndataset are released, hoping to inspire others.",
    "descriptor": "\nComments: This paper has been accepted by IEEE International Conference on Data Engineering 2023 (Second Research Round)\n",
    "authors": [
      "Zhengjie Huang",
      "Yunyang Huang",
      "Peng Qian",
      "Jianhai Chen",
      "Qinming He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14582"
  },
  {
    "id": "arXiv:2211.14585",
    "title": "Safety Verification of Declarative Smart Contracts",
    "abstract": "Smart contracts manage a large number of digital assets nowadays. Bugs in\nthese contracts have led to significant financial loss. Verifying the\ncorrectness of smart contracts is therefore an important task. This paper\npresents a safety verification tool DCV that targets declarative smart\ncontracts written in DeCon, a logic-based domain-specific language for smart\ncontract implementation and specification. DCV is sound and fully automatic. It\nproves safety properties by mathematical induction and can automatically infer\ninductive invariants without annotations from the developer. Our evaluation\nshows that DCV is effective in verifying smart contracts adapted from public\nrepositories, and can verify contracts not supported by other tools.\nFurthermore, DCV significantly outperforms baseline tools in verification time.",
    "descriptor": "\nComments: In submission to TACAS'23\n",
    "authors": [
      "Haoxian Chen",
      "Lan Lu",
      "Brendan Massey",
      "Yuepeng Wang",
      "Boon Thau Loo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.14585"
  },
  {
    "id": "arXiv:2211.14589",
    "title": "AvatarGen: A 3D Generative Model for Animatable Human Avatars",
    "abstract": "Unsupervised generation of 3D-aware clothed humans with various appearances\nand controllable geometries is important for creating virtual human avatars and\nother AR/VR applications. Existing methods are either limited to rigid object\nmodeling, or not generative and thus unable to generate high-quality virtual\nhumans and animate them. In this work, we propose AvatarGen, the first method\nthat enables not only geometry-aware clothed human synthesis with high-fidelity\nappearances but also disentangled human animation controllability, while only\nrequiring 2D images for training. Specifically, we decompose the generative 3D\nhuman synthesis into pose-guided mapping and canonical representation with\npredefined human pose and shape, such that the canonical representation can be\nexplicitly driven to different poses and shapes with the guidance of a 3D\nparametric human model SMPL. AvatarGen further introduces a deformation network\nto learn non-rigid deformations for modeling fine-grained geometric details and\npose-dependent dynamics. To improve the geometry quality of the generated human\navatars, it leverages the signed distance field as geometric proxy, which\nallows more direct regularization from the 3D geometric priors of SMPL.\nBenefiting from these designs, our method can generate animatable 3D human\navatars with high-quality appearance and geometry modeling, significantly\noutperforming previous 3D GANs. Furthermore, it is competent for many\napplications, e.g., single-view reconstruction, re-animation, and text-guided\nsynthesis/editing. Code and pre-trained model will be available at\nthis http URL",
    "descriptor": "\nComments: First two authors contributed equally. Our code and models will be available at this http URL arXiv admin note: substantial text overlap with arXiv:2208.00561\n",
    "authors": [
      "Jianfeng Zhang",
      "Zihang Jiang",
      "Dingdong Yang",
      "Hongyi Xu",
      "Yichun Shi",
      "Guoxian Song",
      "Zhongcong Xu",
      "Xinchao Wang",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14589"
  },
  {
    "id": "arXiv:2211.14591",
    "title": "A Survey of Text Representation Methods and Their Genealogy",
    "abstract": "In recent years, with the advent of highly scalable\nartificial-neural-network-based text representation methods the field of\nnatural language processing has seen unprecedented growth and sophistication.\nIt has become possible to distill complex linguistic information of text into\nmultidimensional dense numeric vectors with the use of the distributional\nhypothesis. As a consequence, text representation methods have been evolving at\nsuch a quick pace that the research community is struggling to retain knowledge\nof the methods and their interrelations. We contribute threefold to this lack\nof compilation, composition, and systematization by providing a survey of\ncurrent approaches, by arranging them in a genealogy, and by conceptualizing a\ntaxonomy of text representation methods to examine and explain the\nstate-of-the-art. Our research is a valuable guide and reference for artificial\nintelligence researchers and practitioners interested in natural language\nprocessing applications such as recommender systems, chatbots, and sentiment\nanalysis.",
    "descriptor": "\nComments: Published online in IEEE Access\n",
    "authors": [
      "Philipp Siebers",
      "Christian Janiesch",
      "Patrick Zschech"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14591"
  },
  {
    "id": "arXiv:2211.14592",
    "title": "An Efficient Black-Box Support of Advanced Coverage Criteria for Klee",
    "abstract": "Dynamic symbolic execution (DSE) is a powerful test generation approach based\non an exploration of the path space of the program under test. Well-adapted for\npath coverage, this approach is however less efficient for conditions,\ndecisions, advanced coverage criteria (such as multiple conditions, weak\nmutations, boundary testing) or user-provided test objectives. While\ntheoretical solutions to adapt DSE to a large set of criteria have been\nproposed, they have never been integrated into publicly available testing\ntools. This paper presents a first integration of an optimized test generation\nstrategy for advanced coverage criteria into a popular open-source testing tool\nbased on DSE, namely, Klee. The integration is performed in a fully black-box\nmanner, and can therefore inspire an easy integration into other similar tools.\nThe resulting version of the tool is publicly available. We present the design\nof the proposed technique and evaluate it on several benchmarks. Our results\nconfirm the benefits of the proposed tool for advanced coverage criteria.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Nicolas Berthier",
      "Steven De Oliveira",
      "Nikolai Kosmatov",
      "Delphine Longuet",
      "Romain Soulat"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.14592"
  },
  {
    "id": "arXiv:2211.14593",
    "title": "Fast method and convergence analysis of fractional magnetohydrodynamic  coupled flow and heat transfer model for generalized second-grade fluid",
    "abstract": "In this paper, we first establish a new fractional magnetohydrodynamic (MHD)\ncoupled flow and heat transfer model for a generalized second-grade fluid. This\ncoupled model consists of a fractional momentum equation and a heat conduction\nequation with a generalized form of Fourier law. The second-order fractional\nbackward difference formula is applied to the temporal discretization and the\nLegendre spectral method is used for the spatial discretization. The fully\ndiscrete scheme is proved to be stable and convergent with an accuracy of\n$O(\\tau^2+N^{-r})$, where $\\tau$ is the time step size and $N$ is the\npolynomial degree. To reduce the memory requirements and computational cost, a\nfast method is developed, which is based on a globally uniform approximation of\nthe trapezoidal rule for integrals on the real line. And the strict convergence\nof the numerical scheme with this fast method is proved. We present the results\nof several numerical experiments to verify the effectiveness of the proposed\nmethod. Finally, we simulate the unsteady fractional MHD flow and heat transfer\nof the generalized second-grade fluid through a porous medium. The effects of\nthe relevant parameters on the velocity and temperature are presented and\nanalyzed in detail.",
    "descriptor": "\nComments: This paper has been accepted for publication in SCIENCE CHINA Mathematics\n",
    "authors": [
      "Xiaoqing Chi",
      "Hui Zhang",
      "Xiaoyun Jiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14593"
  },
  {
    "id": "arXiv:2211.14594",
    "title": "Direct-Effect Risk Minimization for Domain Generalization",
    "abstract": "We study the problem of out-of-distribution (o.o.d.) generalization where\nspurious correlations of attributes vary across training and test domains. This\nis known as the problem of correlation shift and has posed concerns on the\nreliability of machine learning. In this work, we introduce the concepts of\ndirect and indirect effects from causal inference to the domain generalization\nproblem. We argue that models that learn direct effects minimize the worst-case\nrisk across correlation-shifted domains. To eliminate the indirect effects, our\nalgorithm consists of two stages: in the first stage, we learn an\nindirect-effect representation by minimizing the prediction error of domain\nlabels using the representation and the class label; in the second stage, we\nremove the indirect effects learned in the first stage by matching each data\nwith another data of similar indirect-effect representation but of different\nclass label. We also propose a new model selection method by matching the\nvalidation set in the same way, which is shown to improve the generalization\nperformance of existing models on correlation-shifted datasets. Experiments on\n5 correlation-shifted datasets and the DomainBed benchmark verify the\neffectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Yuhui Li",
      "Zejia Wu",
      "Chao Zhang",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14594"
  },
  {
    "id": "arXiv:2211.14595",
    "title": "Tube-based Distributionally Robust Model Predictive Control for  Nonlinear Process Systems via Linearization",
    "abstract": "Model predictive control (MPC) is an effective approach to control\nmultivariable dynamic systems with constraints. Most real dynamic models are\nhowever affected by plant-model mismatch and process uncertainties, which can\nlead to closed-loop performance deterioration and constraint violations.\nMethods such as stochastic MPC (SMPC) have been proposed to alleviate these\nproblems; however, the resulting closed-loop state trajectory might still\nsignificantly violate the prescribed constraints if the real system deviates\nfrom the assumed disturbance distributions made during the controller design.\nIn this work we propose a novel data-driven distributionally robust MPC scheme\nfor nonlinear systems. Unlike SMPC, which requires the exact knowledge of the\ndisturbance distribution, our scheme decides the control action with respect to\nthe worst distribution from a distribution ambiguity set. This ambiguity set is\ndefined as a Wasserstein ball centered at the empirical distribution. Due to\nthe potential model errors that cause off-sets, the scheme is also extended by\nleveraging an offset-free method. The favorable results of this control scheme\nare demonstrated and empirically verified with a nonlinear mass spring system\nand a nonlinear CSTR case study.",
    "descriptor": "",
    "authors": [
      "Zhengang Zhong",
      "Ehecatl Antonio del Rio-Chanona",
      "Panagiotis Petsagkourakis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.14595"
  },
  {
    "id": "arXiv:2211.14596",
    "title": "1st Place Solution to NeurIPS 2022 Challenge on Visual Domain Adaptation",
    "abstract": "The Visual Domain Adaptation(VisDA) 2022 Challenge calls for an unsupervised\ndomain adaptive model in semantic segmentation tasks for industrial waste\nsorting. In this paper, we introduce the SIA_Adapt method, which incorporates\nseveral methods for domain adaptive models. The core of our method in the\ntransferable representation from large-scale pre-training. In this process, we\nchoose a network architecture that differs from the state-of-the-art for domain\nadaptation. After that, self-training using pseudo-labels helps to make the\ninitial adaptation model more adaptable to the target domain. Finally, the\nmodel soup scheme helped to improve the generalization performance in the\ntarget domain. Our method SIA_Adapt achieves 1st place in the VisDA2022\nchallenge. The code is available on https:\n//github.com/DaehanKim-Korea/VisDA2022_Winner_Solution.",
    "descriptor": "\nComments: This technical paper contains a brief overview of the proposed method, SIA_Adapt, which wins the Visual Domain Adaptation(VisDA) challenge\n",
    "authors": [
      "Daehan Kim",
      "Minseok Seo",
      "YoungJin Jeon",
      "Dong-Geol Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14596"
  },
  {
    "id": "arXiv:2211.14599",
    "title": "Condensed Gradient Boosting",
    "abstract": "This paper presents a computationally efficient variant of gradient boosting\nfor multi-class classification and multi-output regression tasks. Standard\ngradient boosting uses a 1-vs-all strategy for classifications tasks with more\nthan two classes. This strategy translates in that one tree per class and\niteration has to be trained. In this work, we propose the use of multi-output\nregressors as base models to handle the multi-class problem as a single task.\nIn addition, the proposed modification allows the model to learn multi-output\nregression problems. An extensive comparison with other multi-ouptut based\ngradient boosting methods is carried out in terms of generalization and\ncomputational efficiency. The proposed method showed the best trade-off between\ngeneralization ability and training and predictions speeds.",
    "descriptor": "",
    "authors": [
      "Seyedsaman Emami",
      "Gonzalo Mart\u00ednez-Mu\u00f1oz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14599"
  },
  {
    "id": "arXiv:2211.14603",
    "title": "Analysis of Molecule Harvesting by Heterogeneous Receptors on MC  Transmitters",
    "abstract": "This paper designs a molecule harvesting transmitter (TX) model, where the\nsurface of a spherical TX is covered by heterogeneous receptors with different\nsizes and arbitrary locations. If molecules hit any receptor, they are absorbed\nby the TX immediately. Within the TX, molecules are stored in vesicles that are\ncontinuously generated and released by the TX via the membrane fusion process.\nConsidering a transparent receiver (RX) and molecular degradation during the\npropagation from the TX to the RX, we derive the molecule release rate and the\nfraction of molecules absorbed by the TX as well as the received signal at the\nRX. Notably, this analytical result is applicable for different numbers, sizes,\nand locations of receptors, and its accuracy is verified via particle-based\nsimulations. Numerical results show that different vesicle generation rates\nresult in the same number of molecules absorbed by the TX, but different peak\nreceived signals at the RX.",
    "descriptor": "\nComments: 6 pages, 4 figures, submitted to IEEE ICC 2023\n",
    "authors": [
      "Xinyu Huang",
      "Yu Huang",
      "Miaowen Wen",
      "Nan Yang",
      "Robert Schober"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.14603"
  },
  {
    "id": "arXiv:2211.14604",
    "title": "Reduced Representation of Deformation Fields for Effective Non-rigid  Shape Matching",
    "abstract": "In this work we present a novel approach for computing correspondences\nbetween non-rigid objects, by exploiting a reduced representation of\ndeformation fields. Different from existing works that represent deformation\nfields by training a general-purpose neural network, we advocate for an\napproximation based on mesh-free methods. By letting the network learn\ndeformation parameters at a sparse set of positions in space (nodes), we\nreconstruct the continuous deformation field in a closed-form with guaranteed\nsmoothness. With this reduction in degrees of freedom, we show significant\nimprovement in terms of data-efficiency thus enabling limited supervision.\nFurthermore, our approximation provides direct access to first-order\nderivatives of deformation fields, which facilitates enforcing desirable\nregularization effectively. Our resulting model has high expressive power and\nis able to capture complex deformations. We illustrate its effectiveness\nthrough state-of-the-art results across multiple deformable shape matching\nbenchmarks. Our code and data are publicly available at:\nhttps://github.com/Sentient07/DeformationBasis.",
    "descriptor": "",
    "authors": [
      "Ramana Sundararaman",
      "Riccardo Marin",
      "Emanuele Rodola",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.14604"
  },
  {
    "id": "arXiv:2211.14605",
    "title": "Looking at the posterior: on the origin of uncertainty in neural-network  classification",
    "abstract": "Bayesian inference can quantify uncertainty in the predictions of neural\nnetworks using posterior distributions for model parameters and network output.\nBy looking at these posterior distributions, one can separate the origin of\nuncertainty into aleatoric and epistemic. We use the joint distribution of\npredictive uncertainty and epistemic uncertainty to quantify how this\ninterpretation of uncertainty depends upon model architecture, dataset\ncomplexity, and data distributional shifts in image classification tasks. We\nconclude that the origin of uncertainty is subjective to each neural network\nand that the quantification of the induced uncertainty from data distributional\nshifts depends on the complexity of the underlying dataset. Furthermore, we\nshow that the joint distribution of predictive and epistemic uncertainty can be\nused to identify data domains where the model is most accurate. To arrive at\nthese results, we use two common posterior approximation methods, Monte-Carlo\ndropout and deep ensembles, for fully-connected, convolutional and\nattention-based neural networks.",
    "descriptor": "\nComments: 25 pages, 6 figures, 5 tables, 1 appendix\n",
    "authors": [
      "H. Linander",
      "O. Balabanov",
      "H. Yang",
      "B. Mehlig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14605"
  },
  {
    "id": "arXiv:2211.14607",
    "title": "Sketch2FullStack: Generating Skeleton Code of Full Stack Website and  Application from Sketch using Deep Learning and Computer Vision",
    "abstract": "For a full-stack web or app development, it requires a software firm or more\nspecifically a team of experienced developers to contribute a large portion of\ntheir time and resources to design the website and then convert it to code. As\na result, the efficiency of the development team is significantly reduced when\nit comes to converting UI wireframes and database schemas into an actual\nworking system. It would save valuable resources and fasten the overall\nworkflow if the clients or developers can automate this process of converting\nthe pre-made full-stack website design to get a partially working if not fully\nworking code. In this paper, we present a novel approach of generating the\nskeleton code from sketched images using Deep Learning and Computer Vision\napproaches. The dataset for training are first-hand sketched images of low\nfidelity wireframes, database schemas and class diagrams. The approach consists\nof three parts. First, the front-end or UI elements detection and extraction\nfrom custom-made UI wireframes. Second, individual database table creation from\nschema designs and lastly, creating a class file from class diagrams.",
    "descriptor": "\nComments: 12 pages, 10 figures, preprint\n",
    "authors": [
      "Somoy Subandhu Barua",
      "Imam Mohammad Zulkarnain",
      "Abhishek Roy",
      "Md. Golam Rabiul Alam",
      "Md Zia Uddin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.14607"
  },
  {
    "id": "arXiv:2211.14608",
    "title": "EEGLog: Lifelogging EEG Data When You Listen to Music",
    "abstract": "Self-tracking has been long discussed, which can monitor daily activities and\nhelp users to recall previous experiences. Such data-capturing technique is no\nlonger limited to photos, text messages, or personal diaries in recent years.\nWith the development of wearable EEG devices, we introduce a novel modality of\nlogging EEG data while listening to music, and bring up the idea of the\nneural-centric way of life with the designed data analysis application named\nEEGLog. Four consumer-grade wearable EEG devices are explored by collecting EEG\ndata from 24 participants. Three modules are introduced in EEGLog, including\nthe summary module of EEG data, emotion reports, music listening activities,\nand memorial moments, the emotion detection module, and the music\nrecommendation module. Feedback from interviews about using EEG devices and\nEEGLog were obtained and analyzed for future EEG logging development.",
    "descriptor": "",
    "authors": [
      "Jiyang Li",
      "Ann Gina Konnayil",
      "Adam Russell",
      "Dingran Wang",
      "Yincheng Jin",
      "Seokmin Choi",
      "Zhanpeng Jin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.14608"
  },
  {
    "id": "arXiv:2211.14609",
    "title": "BEAMERS: Brain-Engaged, Active Music-based Emotion Regulation System",
    "abstract": "With the increasing demands of emotion comprehension and regulation in our\ndaily life, a customized music-based emotion regulation system is introduced by\nemploying current EEG information and song features, which predicts users'\nemotion variation in the valence-arousal model before recommending music. The\nwork shows that: (1) a novel music-based emotion regulation system with a\ncommercial EEG device is designed without employing deterministic emotion\nrecognition models for daily usage; (2) the system considers users' variant\nemotions towards the same song, and by which calculate user's emotion\ninstability and it is in accordance with Big Five Personality Test; (3) the\nsystem supports different emotion regulation styles with users' designation of\ndesired emotion variation, and achieves an accuracy of over $0.85$ with\n2-seconds EEG data; (4) people feel easier to report their emotion variation\ncomparing with absolute emotional states, and would accept a more delicate\nmusic recommendation system for emotion regulation according to the\nquestionnaire.",
    "descriptor": "",
    "authors": [
      "Jiyang Li",
      "Wei Wang",
      "Kratika Bhagtani",
      "Yincheng Jin",
      "Zhanpeng Jin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.14609"
  },
  {
    "id": "arXiv:2211.14611",
    "title": "The Principles of Data-Centric AI (DCAI)",
    "abstract": "Data is a crucial infrastructure to how artificial intelligence (AI) systems\nlearn. However, these systems to date have been largely model-centric, putting\na premium on the model at the expense of the data quality. Data quality issues\nbeset the performance of AI systems, particularly in downstream deployments and\nin real-world applications. Data-centric AI (DCAI) as an emerging concept\nbrings data, its quality and its dynamism to the forefront in considerations of\nAI systems through an iterative and systematic approach. As one of the first\noverviews, this article brings together data-centric perspectives and concepts\nto outline the foundations of DCAI. It specifically formulates six guiding\nprinciples for researchers and practitioners and gives direction for future\nadvancement of DCAI.",
    "descriptor": "\nComments: Forthcoming: The Communications of the ACM\n",
    "authors": [
      "Mohammad Hossein Jarrahi",
      "Ali Memariani",
      "Shion Guha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.14611"
  },
  {
    "id": "arXiv:2211.14613",
    "title": "Some Remarks on Almost Periodic Sequences and Languages",
    "abstract": "Almost periodicity has been considered in Formal Language Theory in\nconnection with some topics in Symbolic Dynamics. In (P\\u{a}un and Marcus,\nBulletin of EATCS 53 (1994)) some problems concerning this property are raised.\nFor instance it is asked whether there exists some almost periodic word\n$\\alpha$ such that $Sub(\\alpha)$, the set of its finite factors, is\ncontext-free non-regular.\nWe answer negatively (even in a stronger form) this question, as well as\ndiscussing other related topics.",
    "descriptor": "\nComments: Reconstructed source file of a paper originally published in 1995 in a volume currently without an online version (and with limited availability). Uploaded in order to ensure the online availability (and preservation) of the paper. This version faithfully reproduces the original, except for the addition of a note about the solution of Open Problem 3 and the correction of some minor typos\n",
    "authors": [
      "Gabriel Istrate"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.14613"
  },
  {
    "id": "arXiv:2211.14617",
    "title": "Mixture of Decision Trees for Interpretable Machine Learning",
    "abstract": "This work introduces a novel interpretable machine learning method called\nMixture of Decision Trees (MoDT). It constitutes a special case of the Mixture\nof Experts ensemble architecture, which utilizes a linear model as gating\nfunction and decision trees as experts. Our proposed method is ideally suited\nfor problems that cannot be satisfactorily learned by a single decision tree,\nbut which can alternatively be divided into subproblems. Each subproblem can\nthen be learned well from a single decision tree. Therefore, MoDT can be\nconsidered as a method that improves performance while maintaining\ninterpretability by making each of its decisions understandable and traceable\nto humans.\nOur work is accompanied by a Python implementation, which uses an\ninterpretable gating function, a fast learning algorithm, and a direct\ninterface to fine-tuned interpretable visualization methods. The experiments\nconfirm that the implementation works and, more importantly, show the\nsuperiority of our approach compared to single decision trees and random\nforests of similar complexity.",
    "descriptor": "\nComments: Accepted for publication at the 21st IEEE International Conference of Machine Learning and Applications (ICMLA)\n",
    "authors": [
      "Simeon Br\u00fcggenj\u00fcrgen",
      "Nina Schaaf",
      "Pascal Kerschke",
      "Marco F. Huber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14617"
  },
  {
    "id": "arXiv:2211.14619",
    "title": "A Quantum Approach Towards the Adaptive Prediction of Cloud Workloads",
    "abstract": "This work presents a novel Evolutionary Quantum Neural Network (EQNN) based\nworkload prediction model for Cloud datacenter. It exploits the computational\nefficiency of quantum computing by encoding workload information into qubits\nand propagating this information through the network to estimate the workload\nor resource demands with enhanced accuracy proactively. The rotation and\nreverse rotation effects of the Controlled-NOT (C-NOT) gate serve activation\nfunction at the hidden and output layers to adjust the qubit weights. In\naddition, a Self Balanced Adaptive Differential Evolution (SB-ADE) algorithm is\ndeveloped to optimize qubit network weights. The accuracy of the EQNN\nprediction model is extensively evaluated and compared with seven\nstate-of-the-art methods using eight real world benchmark datasets of three\ndifferent categories. Experimental results reveal that the use of the quantum\napproach to evolutionary neural network substantially improves the prediction\naccuracy up to 91.6% over the existing approaches.",
    "descriptor": "",
    "authors": [
      "Ashutosh Kumar Singh",
      "Deepika Saxena",
      "Jitendra Kumar",
      "Vrinda Gupta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.14619"
  },
  {
    "id": "arXiv:2211.14620",
    "title": "The distribution of syntactic dependency distances",
    "abstract": "The syntactic structure of a sentence can be represented as a graph where\nvertices are words and edges indicate syntactic dependencies between them. In\nthis setting, the distance between two syntactically linked words can be\ndefined as the difference between their positions. Here we want to contribute\nto the characterization of the actual distribution of syntactic dependency\ndistances, and unveil its relationship with short-term memory limitations. We\npropose a new double-exponential model in which decay in probability is allowed\nto change after a break-point. This transition could mirror the transition from\nthe processing of words chunks to higher-level structures. We find that a\ntwo-regime model -- where the first regime follows either an exponential or a\npower-law decay -- is the most likely one in all 20 languages we considered,\nindependently of sentence length and annotation style. Moreover, the\nbreak-point is fairly stable across languages and averages values of 4-5 words,\nsuggesting that the amount of words that can be simultaneously processed\nabstracts from the specific language to a high degree. Finally, we give an\naccount of the relation between the best estimated model and the closeness of\nsyntactic dependencies, as measured by a recently introduced optimality score.",
    "descriptor": "",
    "authors": [
      "Sonia Petrini",
      "Ramon Ferrer-i-Cancho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14620"
  },
  {
    "id": "arXiv:2211.14627",
    "title": "Where to Pay Attention in Sparse Training for Feature Selection?",
    "abstract": "A new line of research for feature selection based on neural networks has\nrecently emerged. Despite its superiority to classical methods, it requires\nmany training iterations to converge and detect informative features. The\ncomputational time becomes prohibitively long for datasets with a large number\nof samples or a very high dimensional feature space. In this paper, we present\na new efficient unsupervised method for feature selection based on sparse\nautoencoders. In particular, we propose a new sparse training algorithm that\noptimizes a model's sparse topology during training to pay attention to\ninformative features quickly. The attention-based adaptation of the sparse\ntopology enables fast detection of informative features after a few training\niterations. We performed extensive experiments on 10 datasets of different\ntypes, including image, speech, text, artificial, and biological. They cover a\nwide range of characteristics, such as low and high-dimensional feature spaces,\nand few and large training samples. Our proposed approach outperforms the\nstate-of-the-art methods in terms of selecting informative features while\nreducing training iterations and computational costs substantially. Moreover,\nthe experiments show the robustness of our method in extremely noisy\nenvironments.",
    "descriptor": "\nComments: Accepted at Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Ghada Sokar",
      "Zahra Atashgahi",
      "Mykola Pechenizkiy",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14627"
  },
  {
    "id": "arXiv:2211.14631",
    "title": "Searching for Discriminative Words in Multidimensional Continuous  Feature Space",
    "abstract": "Word feature vectors have been proven to improve many NLP tasks. With recent\nadvances in unsupervised learning of these feature vectors, it became possible\nto train it with much more data, which also resulted in better quality of\nlearned features. Since it learns joint probability of latent features of\nwords, it has the advantage that we can train it without any prior knowledge\nabout the goal task we want to solve. We aim to evaluate the universal\napplicability property of feature vectors, which has been already proven to\nhold for many standard NLP tasks like part-of-speech tagging or syntactic\nparsing. In our case, we want to understand the topical focus of text documents\nand design an efficient representation suitable for discriminating different\ntopics. The discriminativeness can be evaluated adequately on text\ncategorisation task. We propose a novel method to extract discriminative\nkeywords from documents. We utilise word feature vectors to understand the\nrelations between words better and also understand the latent topics which are\ndiscussed in the text and not mentioned directly but inferred logically. We\nalso present a simple way to calculate document feature vectors out of\nextracted discriminative words. We evaluate our method on the four most popular\ndatasets for text categorisation. We show how different discriminative metrics\ninfluence the overall results. We demonstrate the effectiveness of our approach\nby achieving state-of-the-art results on text categorisation task using just a\nsmall number of extracted keywords. We prove that word feature vectors can\nsubstantially improve the topical inference of documents' meaning. We conclude\nthat distributed representation of words can be used to build higher levels of\nabstraction as we demonstrate and build feature vectors of documents.",
    "descriptor": "",
    "authors": [
      "Marius Sajgalik",
      "Michal Barla",
      "Maria Bielikova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.14631"
  },
  {
    "id": "arXiv:2211.14632",
    "title": "Why Neural Networks Work",
    "abstract": "We argue that many properties of fully-connected feedforward neural networks\n(FCNNs), also called multi-layer perceptrons (MLPs), are explainable from the\nanalysis of a single pair of operations, namely a random projection into a\nhigher-dimensional space than the input, followed by a sparsification\noperation. For convenience, we call this pair of successive operations\nexpand-and-sparsify following the terminology of Dasgupta. We show how\nexpand-and-sparsify can explain the observed phenomena that have been discussed\nin the literature, such as the so-called Lottery Ticket Hypothesis, the\nsurprisingly good performance of randomly-initialized untrained neural\nnetworks, the efficacy of Dropout in training and most importantly, the\nmysterious generalization ability of overparameterized models, first\nhighlighted by Zhang et al. and subsequently identified even in non-neural\nnetwork models by Belkin et al.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Sayandev Mukherjee",
      "Bernardo A. Huberman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14632"
  },
  {
    "id": "arXiv:2211.14633",
    "title": "A Contextual Master-Slave Framework on Urban Region Graph for Urban  Village Detection",
    "abstract": "Urban villages (UVs) refer to the underdeveloped informal settlement falling\nbehind the rapid urbanization in a city. Since there are high levels of social\ninequality and social risks in these UVs, it is critical for city managers to\ndiscover all UVs for making appropriate renovation policies. Existing\napproaches to detecting UVs are labor-intensive or have not fully addressed the\nunique challenges in UV detection such as the scarcity of labeled UVs and the\ndiverse urban patterns in different regions. To this end, we first build an\nurban region graph (URG) to model the urban area in a hierarchically structured\nway. Then, we design a novel contextual master-slave framework to effectively\ndetect the urban village from the URG. The core idea of such a framework is to\nfirstly pre-train a basis (or master) model over the URG, and then to\nadaptively derive specific (or slave) models from the basis model for different\nregions. The proposed framework can learn to balance the generality and\nspecificity for UV detection in an urban area. Finally, we conduct extensive\nexperiments in three cities to demonstrate the effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Congxi Xiao",
      "Jingbo Zhou",
      "Jizhou Huang",
      "Hengshu Zhu",
      "Tong Xu",
      "Dejing Dou",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14633"
  },
  {
    "id": "arXiv:2211.14638",
    "title": "Cross-domain Microscopy Cell Counting by Disentangled Transfer Learning",
    "abstract": "Microscopy cell images of biological experiments on different\ntissues/organs/imaging conditions usually contain cells with various shapes and\nappearances on different image backgrounds, making a cell counting model\ntrained in a source domain hard to be transferred to a new target domain. Thus,\ncostly manual annotation is required to train deep learning-based cell counting\nmodels across different domains. Instead, we propose a cross-domain cell\ncounting approach with only a little human annotation effort. First, we design\na cell counting network that can disentangle domain-specific knowledge and\ndomain-agnostic knowledge in cell images, which are related to the generation\nof domain style images and cell density maps, respectively. Secondly, we\npropose an image synthesis method capable of synthesizing a large number of\nimages based on a few annotated ones. Finally, we use a public dataset of\nsynthetic cells, which has no annotation cost at all as the source domain to\ntrain our cell counting network; then, only the domain-agnostic knowledge in\nthe trained model is transferred to a new target domain of real cell images, by\nprogressively fine-tuning the trained model using synthesized target-domain\nimages and a few annotated ones. Evaluated on two public target datasets of\nreal cell images, our cross-domain cell counting approach that only needs\nannotation on a few images in a new target domain achieves good performance,\ncompared to state-of-the-art methods that rely on fully annotated training\nimages in the target domain.",
    "descriptor": "\nComments: Tech. report (10 pages and 4 figures)\n",
    "authors": [
      "Zuhui Wang",
      "Zhaozheng Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14638"
  },
  {
    "id": "arXiv:2211.14639",
    "title": "Gender Biases Unexpectedly Fluctuate in the Pre-training Stage of Masked  Language Models",
    "abstract": "Masked language models pick up gender biases during pre-training. Such biases\nare usually attributed to a certain model architecture and its pre-training\ncorpora, with the implicit assumption that other variations in the pre-training\nprocess, such as the choices of the random seed or the stopping point, have no\neffect on the biases measured. However, we show that severe fluctuations exist\nat the fundamental level of individual templates, invalidating the assumption.\nFurther against the intuition of how humans acquire biases, these fluctuations\nare not correlated with the certainty of the predicted pronouns or the\nprofession frequencies in pre-training corpora. We release our code and data to\nbenefit future research.",
    "descriptor": "",
    "authors": [
      "Kenan Tang",
      "Hanchun Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14639"
  },
  {
    "id": "arXiv:2211.14640",
    "title": "Derandomization under Different Resource Constraints",
    "abstract": "We provide another proof to the EL Theorem. We show the tradeoff between\ncompressibility of codebooks and their communication capacity. A resource\nbounded version of the EL Theorem is proven. This is used to prove three\ninstances of resource bounded derandomization. This paper is in support of the\ngeneral claim that if the existence of an object can be proven with the\nprobabilistic method, then bounds on its Kolmogorov complexity can be proven as\nwell.",
    "descriptor": "",
    "authors": [
      "Samuel Epstein"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.14640"
  },
  {
    "id": "arXiv:2211.14642",
    "title": "SCAPHY: Detecting Modern ICS Attacks by Correlating Behaviors in SCADA  and PHYsical",
    "abstract": "Modern Industrial Control Systems (ICS) attacks evade existing tools by using\nknowledge of ICS processes to blend their activities with benign Supervisory\nControl and Data Acquisition (SCADA) operation, causing physical world damages.\nWe present SCAPHY to detect ICS attacks in SCADA by leveraging the unique\nexecution phases of SCADA to identify the limited set of legitimate behaviors\nto control the physical world in different phases, which differentiates from\nattackers activities. For example, it is typical for SCADA to setup ICS device\nobjects during initialization, but anomalous during processcontrol. To extract\nunique behaviors of SCADA execution phases, SCAPHY first leverages open ICS\nconventions to generate a novel physical process dependency and impact graph\n(PDIG) to identify disruptive physical states. SCAPHY then uses PDIG to inform\na physical process-aware dynamic analysis, whereby code paths of SCADA\nprocess-control execution is induced to reveal API call behaviors unique to\nlegitimate process-control phases. Using this established behavior, SCAPHY\nselectively monitors attackers physical world-targeted activities that violates\nlegitimate processcontrol behaviors. We evaluated SCAPHY at a U.S. national lab\nICS testbed environment. Using diverse ICS deployment scenarios and attacks\nacross 4 ICS industries, SCAPHY achieved 95% accuracy & 3.5% false positives\n(FP), compared to 47.5% accuracy and 25% FP of existing work. We analyze\nSCAPHYs resilience to futuristic attacks where attacker knows our approach.",
    "descriptor": "\nComments: IEEE Security and Privacy 2023\n",
    "authors": [
      "Moses Ike",
      "Kandy Phan",
      "Keaton Sadoski",
      "Romuald Valme",
      "Wenke Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.14642"
  },
  {
    "id": "arXiv:2211.14646",
    "title": "Towards Better Input Masking for Convolutional Neural Networks",
    "abstract": "The ability to remove features from the input of machine learning models is\nvery important to understand and interpret model predictions. However, this is\nnon-trivial for vision models since masking out parts of the input image and\nreplacing them with a baseline color like black or grey typically causes large\ndistribution shifts. Masking may even make the model focus on the masking\npatterns for its prediction rather than the unmasked portions of the image. In\nrecent work, it has been shown that vision transformers are less affected by\nsuch issues as one can simply drop the tokens corresponding to the masked image\nportions. They are thus more easily interpretable using techniques like LIME\nwhich rely on input perturbation. Using the same intuition, we devise a masking\ntechnique for CNNs called layer masking, which simulates running the CNN on\nonly the unmasked input. We find that our method is (i) much less disruptive to\nthe model's output and its intermediate activations, and (ii) much better than\ncommonly used masking techniques for input perturbation based interpretability\ntechniques like LIME. Thus, layer masking is able to close the interpretability\ngap between CNNs and transformers, and even make CNNs more interpretable in\nmany cases.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Sriram Balasubramanian",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14646"
  },
  {
    "id": "arXiv:2211.14647",
    "title": "Hacky Racers: Exploiting Instruction-Level Parallelism to Generate  Stealthy Fine-Grained Timers",
    "abstract": "Side-channel attacks pose serious threats to many security models, especially\nsandbox-based browsers. While transient-execution side channels in out-of-order\nprocessors have previously been blamed for vulnerabilities such as Spectre and\nMeltdown, we show that in fact, the capability of out-of-order execution\n\\emph{itself} to cause mayhem is far more general.\nWe develop Hacky Racers, a new type of timing gadget that uses\ninstruction-level parallelism, another key feature of out-of-order execution,\nto measure arbitrary fine-grained timing differences, even in the presence of\nhighly restricted JavaScript sandbox environments. While such environments try\nto mitigate timing side channels by reducing timer precision and removing\nlanguage features such as \\textit{SharedArrayBuffer} that can be used to\nindirectly generate timers via thread-level parallelism, no such restrictions\ncan be designed to limit Hacky Racers. We also design versions of Hacky Racers\nthat require no misspeculation whatsoever, demonstrating that transient\nexecution is not the only threat to security from modern microarchitectural\nperformance optimization.\nWe use Hacky Racers to construct novel \\textit{backwards-in-time} Spectre\ngadgets, which break many hardware countermeasures in the literature by leaking\nsecrets before misspeculation is discovered. We also use them to generate the\nfirst known last-level cache eviction set generator in JavaScript that does not\nrequire \\textit{SharedArrayBuffer} support.",
    "descriptor": "\nComments: This paper is accepted at ASPLOS 2023\n",
    "authors": [
      "Haocheng Xiao",
      "Sam Ainsworth"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.14647"
  },
  {
    "id": "arXiv:2211.14648",
    "title": "Learning Visuo-Haptic Skewering Strategies for Robot-Assisted Feeding",
    "abstract": "Acquiring food items with a fork poses an immense challenge to a\nrobot-assisted feeding system, due to the wide range of material properties and\nvisual appearances present across food groups. Deformable foods necessitate\ndifferent skewering strategies than firm ones, but inferring such\ncharacteristics for several previously unseen items on a plate remains\nnontrivial. Our key insight is to leverage visual and haptic observations\nduring interaction with an item to rapidly and reactively plan skewering\nmotions. We learn a generalizable, multimodal representation for a food item\nfrom raw sensory inputs which informs the optimal skewering strategy. Given\nthis representation, we propose a zero-shot framework to sense visuo-haptic\nproperties of a previously unseen item and reactively skewer it, all within a\nsingle interaction. Real-robot experiments with foods of varying levels of\nvisual and textural diversity demonstrate that our multimodal policy\noutperforms baselines which do not exploit both visual and haptic cues or do\nnot reactively plan. Across 6 plates of different food items, our proposed\nframework achieves 71\\% success over 69 skewering attempts total. Supplementary\nmaterial, datasets, code, and videos can be found on our\n$\\href{https://sites.google.com/view/hapticvisualnet-corl22/home}{website}$.",
    "descriptor": "",
    "authors": [
      "Priya Sundaresan",
      "Suneel Belkhale",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14648"
  },
  {
    "id": "arXiv:2211.14651",
    "title": "SliceMatch: Geometry-guided Aggregation for Cross-View Pose Estimation",
    "abstract": "This work addresses cross-view camera pose estimation, i.e., determining the\n3-DoF camera pose of a given ground-level image w.r.t. an aerial image of the\nlocal area. We propose SliceMatch, which consists of ground and aerial feature\nextractors, feature aggregators, and a pose predictor. The feature extractors\nextract dense features from the ground and aerial images. Given a set of\ncandidate camera poses, the feature aggregators construct a single ground\ndescriptor and a set of rotational equivariant pose-dependent aerial\ndescriptors. Notably, our novel aerial feature aggregator has a cross-view\nattention module for ground-view guided aerial feature selection, and utilizes\nthe geometric projection of the ground camera's viewing frustum on the aerial\nimage to pool features. The efficient construction of aerial descriptors is\nachieved by using precomputed masks and by re-assembling the aerial descriptors\nfor rotated poses. SliceMatch is trained using contrastive learning and pose\nestimation is formulated as a similarity comparison between the ground\ndescriptor and the aerial descriptors. SliceMatch outperforms the\nstate-of-the-art by 19% and 62% in median localization error on the VIGOR and\nKITTI datasets, with 3x FPS of the fastest baseline.",
    "descriptor": "",
    "authors": [
      "Ted de Vries Lentsch",
      "Zimin Xia",
      "Holger Caesar",
      "Julian F. P. Kooij"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14651"
  },
  {
    "id": "arXiv:2211.14652",
    "title": "Learning Bimanual Scooping Policies for Food Acquisition",
    "abstract": "A robotic feeding system must be able to acquire a variety of foods. Prior\nbite acquisition works consider single-arm spoon scooping or fork skewering,\nwhich do not generalize to foods with complex geometries and deformabilities.\nFor example, when acquiring a group of peas, skewering could smoosh the peas\nwhile scooping without a barrier could result in chasing the peas on the plate.\nIn order to acquire foods with such diverse properties, we propose stabilizing\nfood items during scooping using a second arm, for example, by pushing peas\nagainst the spoon with a flat surface to prevent dispersion. The added\nstabilizing arm can lead to new challenges. Critically, this arm should\nstabilize the food scene without interfering with the acquisition motion, which\nis especially difficult for easily breakable high-risk food items like tofu.\nThese high-risk foods can break between the pusher and spoon during scooping,\nwhich can lead to food waste falling out of the spoon. We propose a general\nbimanual scooping primitive and an adaptive stabilization strategy that enables\nsuccessful acquisition of a diverse set of food geometries and physical\nproperties. Our approach, CARBS: Coordinated Acquisition with Reactive Bimanual\nScooping, learns to stabilize without impeding task progress by identifying\nhigh-risk foods and robustly scooping them using closed-loop visual feedback.\nWe find that CARBS is able to generalize across food shape, size, and\ndeformability and is additionally able to manipulate multiple food items\nsimultaneously. CARBS achieves 87.0% success on scooping rigid foods, which is\n25.8% more successful than a single-arm baseline, and reduces food breakage by\n16.2% compared to an analytical baseline. Videos can be found at\nhttps://sites.google.com/view/bimanualscoop-corl22/home .",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL) 2022. First two authors contributed equally\n",
    "authors": [
      "Jennifer Grannen",
      "Yilin Wu",
      "Suneel Belkhale",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14652"
  },
  {
    "id": "arXiv:2211.14654",
    "title": "Unsupervised Wildfire Change Detection based on Contrastive Learning",
    "abstract": "The accurate characterization of the severity of the wildfire event strongly\ncontributes to the characterization of the fuel conditions in fire-prone areas,\nand provides valuable information for disaster response. The aim of this study\nis to develop an autonomous system built on top of high-resolution\nmultispectral satellite imagery, with an advanced deep learning method for\ndetecting burned area change. This work proposes an initial exploration of\nusing an unsupervised model for feature extraction in wildfire scenarios. It is\nbased on the contrastive learning technique SimCLR, which is trained to\nminimize the cosine distance between augmentations of images. The distance\nbetween encoded images can also be used for change detection. We propose\nchanges to this method that allows it to be used for unsupervised burned area\ndetection and following downstream tasks. We show that our proposed method\noutperforms the tested baseline approaches.",
    "descriptor": "\nComments: 5 pages (+3 in appendix), 3 figures (+2 in appendix). Artificial Intelligence for Humanitarian Assistance and Disaster Response Workshop (AI+HADR 2022), 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Beichen Zhang",
      "Huiqi Wang",
      "Amani Alabri",
      "Karol Bot",
      "Cole McCall",
      "Dale Hamilton",
      "V\u00edt R\u016f\u017ei\u010dka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14654"
  },
  {
    "id": "arXiv:2211.14655",
    "title": "How Crucial is Transformer in Decision Transformer?",
    "abstract": "Decision Transformer (DT) is a recently proposed architecture for\nReinforcement Learning that frames the decision-making process as an\nauto-regressive sequence modeling problem and uses a Transformer model to\npredict the next action in a sequence of states, actions, and rewards. In this\npaper, we analyze how crucial the Transformer model is in the complete DT\narchitecture on continuous control tasks. Namely, we replace the Transformer by\nan LSTM model while keeping the other parts unchanged to obtain what we call a\nDecision LSTM model. We compare it to DT on continuous control tasks, including\npendulum swing-up and stabilization, in simulation and on physical hardware.\nOur experiments show that DT struggles with continuous control problems, such\nas inverted pendulum and Furuta pendulum stabilization. On the other hand, the\nproposed Decision LSTM is able to achieve expert-level performance on these\ntasks, in addition to learning a swing-up controller on the real system. These\nresults suggest that the strength of the Decision Transformer for continuous\ncontrol tasks may lie in the overall sequential modeling architecture and not\nin the Transformer per se.",
    "descriptor": "\nComments: 9 pages, 6 figures, Foundation Models for Decision Making Workshop at Neural Information Processing Systems, 2022\n",
    "authors": [
      "Max Siebenborn",
      "Boris Belousov",
      "Junning Huang",
      "Jan Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14655"
  },
  {
    "id": "arXiv:2211.14656",
    "title": "Robust fast direct integral equation solver for three-dimensional  quasi-periodic scattering problems with a large number of layers",
    "abstract": "A boundary integral equation method for the 3-D Helmholtz equation in\nmultilayered media with many quasi-periodic layers is presented. Compared with\nconventional quasi-periodic Green's function method, the new method is robust\nat all scattering parameters. A periodizing scheme is used to decompose the\nsolution into near- and far-field contributions. The near-field contribution\nuses the free-space Green's function in an integral equation on the interface\nin the unit cell and its immediate eight neighbors; the far-field contribution\nuses proxy point sources that enclose the unit cell. A specialized high-order\nquadrature is developed to discretize the underlying surface integral operators\nto keep the number of unknowns per layer small. We achieve overall linear\ncomputational complexity in the number of layers by reducing the linear system\ninto block tridiagonal form and then solving the system directly via block LU\ndecomposition. The new solver is capable of handling a 100-interface structure\nwith 961.3k unknowns to $10^{-5}$ accuracy in less than 2 hours on a desktop\nworkstation.",
    "descriptor": "\nComments: 17 pages, 6 figures, 1 table\n",
    "authors": [
      "Bowei Wu",
      "Min Hyung Cho"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14656"
  },
  {
    "id": "arXiv:2211.14658",
    "title": "Hardness Results for Minimizing the Covariance of Randomly Signed Sum of  Vectors",
    "abstract": "Given vectors $\\mathbb{v}_1, \\ldots, \\mathbb{v}_n \\in \\mathbb{R}^d$ with\nEuclidean norm at most $1$ and $\\mathbb{x}_0 \\in [-1,1]^n$, our goal is to\nsample a random signing $\\mathbb{x} \\in \\{\\pm 1\\}^n$ with\n$\\mathbb{E}[\\mathbb{x}] = \\mathbb{x}_0$ such that the operator norm of the\ncovariance of the signed sum of the vectors $\\sum_{i=1}^n \\mathbb{x}(i)\n\\mathbb{v}_i$ is as small as possible. This problem arises from the algorithmic\ndiscrepancy theory and its application in the design of randomized experiments.\nIt is known that one can sample a random signing with expectation\n$\\mathbb{x}_0$ and the covariance operator norm at most $1$.\nIn this paper, we prove two hardness results for this problem. First, we show\nit is NP-hard to distinguish a list of vectors for which there exists a random\nsigning with expectation ${\\bf 0}$ such that the operator norm is $0$ from\nthose for which any signing with expectation ${\\bf 0}$ must have the operator\nnorm $\\Omega(1)$. Second, we consider $\\mathbb{x}_0 \\in [-1,1]^n$ whose entries\nare all around an arbitrarily fixed $p \\in [-1,1]$. We show it is NP-hard to\ndistinguish a list of vectors for which there exists a random signing with\nexpectation $\\mathbb{x}_0$ such that the operator norm is $0$ from those for\nwhich any signing with expectation ${\\bf 0}$ must have the operator norm\n$\\Omega((1-|p|)^2)$.",
    "descriptor": "",
    "authors": [
      "Peng Zhang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.14658"
  },
  {
    "id": "arXiv:2211.14662",
    "title": "3D Reconstruction of Protein Complex Structures Using Synthesized  Multi-View AFM Images",
    "abstract": "Recent developments in deep learning-based methods demonstrated its potential\nto predict the 3D protein structures using inputs such as protein sequences,\nCryo-Electron microscopy (Cryo-EM) images of proteins, etc. However, these\nmethods struggle to predict the protein complexes (PC), structures with more\nthan one protein. In this work, we explore the atomic force microscope (AFM)\nassisted deep learning-based methods to predict the 3D structure of PCs. The\nimages produced by AFM capture the protein structure in different and random\norientations. These multi-view images can help train the neural network to\npredict the 3D structure of protein complexes. However, obtaining the dataset\nof actual AFM images is time-consuming and not a pragmatic task. We propose a\nvirtual AFM imaging pipeline that takes a 'PDB' protein file and generates\nmulti-view 2D virtual AFM images using volume rendering techniques. With this,\nwe created a dataset of around 8K proteins. We train a neural network for 3D\nreconstruction called Pix2Vox++ using the synthesized multi-view 2D AFM images\ndataset. We compare the predicted structure obtained using a different number\nof views and get the intersection over union (IoU) value of 0.92 on the\ntraining dataset and 0.52 on the validation dataset. We believe this approach\nwill lead to better prediction of the structure of protein complexes.",
    "descriptor": "\nComments: 5 apges, 8 figures, Machine Learning for Structural Biology Workshop, NeurIPS 2022\n",
    "authors": [
      "Jaydeep Rade",
      "Soumik Sarkar",
      "Anwesha Sarkar",
      "Adarsh Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.14662"
  },
  {
    "id": "arXiv:2211.14663",
    "title": "Computational Co-Design for Variable Geometry Truss",
    "abstract": "Living creatures and machines interact with the world through their\nmorphology and motions. Recent advances in creating bio-inspired morphing\nrobots and machines have led to the study of variable geometry truss (VGT),\nstructures that can approximate arbitrary geometries and has large degree of\nfreedom to deform. However, they are limited to simple geometries and motions\ndue to the excessively complex control system. While a recent work PneuMesh\nsolves this challenge with a novel VGT design that introduces a selective\nchannel connection strategy, it imposes new challenge in identifying effective\nchannel groupings and control methods.\nBuilding on top of the hardware concept presented in PneuMesh, we frame the\nchallenge into a co-design problem and introduce a learning-based model to find\na sub-optimal design. Specifically, given an initial truss structure provided\nby a human designer, we first adopt a genetic algorithm (GA) to optimize the\nchannel grouping, and then couple GA with reinforcement learning (RL) for the\ncontrol. The model is tailored to the PneuMesh system with customized\ninitialization, mutation and selection functions, as well as the customized\ntranslation-invariant state vector for reinforcement learning. The result shows\nthat our method enables a robotic table-based VGT to achieve various motions\nwith a limited number of control inputs. The table is trained to move, lower\nits body or tilt its tabletop to accommodate multiple use cases such as\nbenefiting kids and painters to use it in different shape states, allowing\ninclusive and adaptive design through morphing trusses.",
    "descriptor": "",
    "authors": [
      "Jianzhe Gu",
      "Lining Yao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14663"
  },
  {
    "id": "arXiv:2211.14664",
    "title": "Lower Bounds on Retroactive Data Structures",
    "abstract": "We prove essentially optimal fine-grained lower bounds on the gap between a\ndata structure and a partially retroactive version of the same data structure.\nPrecisely, assuming any one of three standard conjectures, we describe a\nproblem that has a data structure where operations run in $O(T(n,m))$ time per\noperation, but any partially retroactive version of that data structure\nrequires $T(n,m) \\cdot m^{1-o(1)}$ worst-case time per operation, where $n$ is\nthe size of the data structure at any time and $m$ is the number of operations.\nAny data structure with operations running in $O(T(n,m))$ time per operation\ncan be converted (via the \"rollback method\") into a partially retroactive data\nstructure running in $O(T(n,m) \\cdot m)$ time per operation, so our lower bound\nis tight up to an $m^{o(1)}$ factor common in fine-grained complexity.",
    "descriptor": "\nComments: 13 pages. Proceedings of the 33rd International Symposium on Algorithms and Computation (ISAAC 2022)\n",
    "authors": [
      "Lily Chung",
      "Erik D. Demaine",
      "Dylan Hendrickson",
      "Jayson Lynch"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.14664"
  },
  {
    "id": "arXiv:2211.14666",
    "title": "Synergies Between Disentanglement and Sparsity: a Multi-Task Learning  Perspective",
    "abstract": "Although disentangled representations are often said to be beneficial for\ndownstream tasks, current empirical and theoretical understanding is limited.\nIn this work, we provide evidence that disentangled representations coupled\nwith sparse base-predictors improve generalization. In the context of\nmulti-task learning, we prove a new identifiability result that provides\nconditions under which maximally sparse base-predictors yield disentangled\nrepresentations. Motivated by this theoretical result, we propose a practical\napproach to learn disentangled representations based on a sparsity-promoting\nbi-level optimization problem. Finally, we explore a meta-learning version of\nthis algorithm based on group Lasso multiclass SVM base-predictors, for which\nwe derive a tractable dual formulation. It obtains competitive results on\nstandard few-shot classification benchmarks, while each task is using only a\nfraction of the learned representations.",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "S\u00e9bastien Lachapelle",
      "Tristan Deleu",
      "Divyat Mahajan",
      "Ioannis Mitliagkas",
      "Yoshua Bengio",
      "Simon Lacoste-Julien",
      "Quentin Bertrand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14666"
  },
  {
    "id": "arXiv:2211.14667",
    "title": "Deep Fake Detection, Deterrence and Response: Challenges and  Opportunities",
    "abstract": "According to the 2020 cyber threat defence report, 78% of Canadian\norganizations experienced at least one successful cyberattack in 2020. The\nconsequences of such attacks vary from privacy compromises to immersing damage\ncosts for individuals, companies, and countries. Specialists predict that the\nglobal loss from cybercrime will reach 10.5 trillion US dollars annually by\n2025. Given such alarming statistics, the need to prevent and predict\ncyberattacks is as high as ever. Our increasing reliance on Machine\nLearning(ML)-based systems raises serious concerns about the security and\nsafety of these systems. Especially the emergence of powerful ML techniques to\ngenerate fake visual, textual, or audio content with a high potential to\ndeceive humans raised serious ethical concerns. These artificially crafted\ndeceiving videos, images, audio, or texts are known as Deepfakes garnered\nattention for their potential use in creating fake news, hoaxes, revenge porn,\nand financial fraud. Diversity and the widespread of deepfakes made their\ntimely detection a significant challenge. In this paper, we first offer\nbackground information and a review of previous works on the detection and\ndeterrence of deepfakes. Afterward, we offer a solution that is capable of 1)\nmaking our AI systems robust against deepfakes during development and\ndeployment phases; 2) detecting video, image, audio, and textual deepfakes; 3)\nidentifying deepfakes that bypass detection (deepfake hunting); 4) leveraging\navailable intelligence for timely identification of deepfake campaigns launched\nby state-sponsored hacking teams; 5) conducting in-depth forensic analysis of\nidentified deepfake payloads. Our solution would address important elements of\nthe Canada National Cyber Security Action Plan(2019-2024) in increasing the\ntrustworthiness of our critical services.",
    "descriptor": "",
    "authors": [
      "Amin Azmoodeh",
      "Ali Dehghantanha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14667"
  },
  {
    "id": "arXiv:2211.14668",
    "title": "A Maximum Log-Likelihood Method for Imbalanced Few-Shot Learning Tasks",
    "abstract": "Few-shot learning is a rapidly evolving area of research in machine learning\nwhere the goal is to classify unlabeled data with only one or \"a few\" labeled\nexemplary samples. Neural networks are typically trained to minimize a distance\nmetric between labeled exemplary samples and a query set. Early few-shot\napproaches use an episodic training process to sub-sample the training data\ninto few-shot batches. This training process matches the sub-sampling done on\nevaluation. Recently, conventional supervised training coupled with a cosine\ndistance has achieved superior performance for few-shot. Despite the diversity\nof few-shot approaches over the past decade, most methods still rely on the\ncosine or Euclidean distance layer between the latent features of the trained\nnetwork. In this work, we investigate the distributions of trained few-shot\nfeatures and demonstrate that they can be roughly approximated as exponential\ndistributions. Under this assumption of an exponential distribution, we propose\na new maximum log-likelihood metric for few-shot architectures. We demonstrate\nthat the proposed metric achieves superior performance accuracy w.r.t.\nconventional similarity metrics (e.g., cosine, Euclidean, etc.), and achieve\nstate-of-the-art inductive few-shot performance. Further, additional gains can\nbe achieved by carefully combining multiple metrics and neither of our methods\nrequire post-processing feature transformations, which are common to many\nalgorithms. Finally, we demonstrate a novel iterative algorithm designed around\nour maximum log-likelihood approach that achieves state-of-the-art transductive\nfew-shot performance when the evaluation data is imbalanced. We have made our\ncode publicly available at https://github.com/samuelhess/MLL_FSL/.",
    "descriptor": "\nComments: 10 pages, 4 figures, 5 tables\n",
    "authors": [
      "Samuel Hess",
      "Gregory Ditzler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14668"
  },
  {
    "id": "arXiv:2211.14669",
    "title": "Game Theoretic Mixed Experts for Combinational Adversarial Machine  Learning",
    "abstract": "Recent advances in adversarial machine learning have shown that defenses\nconsidered to be robust are actually susceptible to adversarial attacks which\nare specifically tailored to target their weaknesses. These defenses include\nBarrage of Random Transforms (BaRT), Friendly Adversarial Training (FAT), Trash\nis Treasure (TiT) and ensemble models made up of Vision Transformers (ViTs),\nBig Transfer models and Spiking Neural Networks (SNNs). A natural question\narises: how can one best leverage a combination of adversarial defenses to\nthwart such attacks? In this paper, we provide a game-theoretic framework for\nensemble adversarial attacks and defenses which answers this question. In\naddition to our framework we produce the first adversarial defense\ntransferability study to further motivate a need for combinational defenses\nutilizing a diverse set of defense architectures. Our framework is called Game\ntheoretic Mixed Experts (GaME) and is designed to find the Mixed-Nash strategy\nfor a defender when facing an attacker employing compositional adversarial\nattacks. We show that this framework creates an ensemble of defenses with\ngreater robustness than multiple state-of-the-art, single-model defenses in\naddition to combinational defenses with uniform probability distributions.\nOverall, our framework and analyses advance the field of adversarial machine\nlearning by yielding new insights into compositional attack and defense\nformulations.",
    "descriptor": "\nComments: 21 pages, 6 figures\n",
    "authors": [
      "Ethan Rathbun",
      "Kaleel Mahmood",
      "Sohaib Ahmad",
      "Caiwen Ding",
      "Marten van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.14669"
  },
  {
    "id": "arXiv:2211.14670",
    "title": "Mediated Cheap Talk Design (with proofs)",
    "abstract": "We study an information design problem with two informed senders and a\nreceiver in which, in contrast to traditional Bayesian persuasion settings,\nsenders do not have commitment power. In our setting, a trusted\nmediator/platform gathers data from the senders and recommends the receiver\nwhich action to play. We characterize the set of implementable action\ndistributions that can be obtained in equilibrium, and provide an $O(n \\log n)$\nalgorithm (where $n$ is the number of states) that computes the optimal\nequilibrium for the senders. Additionally, we show that the optimal equilibrium\nfor the receiver can be obtained by a simple revelation mechanism.",
    "descriptor": "\nComments: To be presented at AAAI'23\n",
    "authors": [
      "Itai Arieli",
      "Ivan Geffner",
      "Moshe Tennenholtz"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.14670"
  },
  {
    "id": "arXiv:2211.14672",
    "title": "Multi-Transmitter Coded Caching with Secure Delivery over Linear  Networks -- Extended Version",
    "abstract": "In this paper, we consider multiple cache-enabled end-users connected to\nmultiple transmitters through a linear network. We also prevent a totally\npassive eavesdropper, who sniffs the packets in the delivery phase, from\nobtaining any information about the original files in cache-aided networks.\nThree different secure centralized multi-transmitter coded caching scenarios\nnamely, secure multi-transmitter coded caching, secure multi-transmitter coded\ncaching with reduced subpacketization, and secure multi-transmitter coded\ncaching with reduced feedback, are considered and closed-form coding delay and\nsecret shared key storage expressions are provided. As our security guarantee,\nwe show that the delivery phase does not reveal any information to the\neavesdropper using the mutual information metric. Moreover, we investigate the\nsecure decentralized multi-transmitter coded caching scenario, in which there\nis no cooperation between the clients and transmitters during the cache content\nplacement phase and study its performance compared to the centralized scheme.\nWe analyze the system's performance in terms of Coding Delay and guarantee the\nsecurity of our presented schemes using the Mutual Information metric.\nNumerical evaluations verify that security incurs a negligible cost in terms of\nmemory usage when the number of files and users are scaled up, in both\ncentralized and decentralized scenarios. Also, we numerically show that by\nincreasing the number of files and users, the secure coding delay of\ncentralized and decentralized schemes became asymptotically equal.",
    "descriptor": "",
    "authors": [
      "Mohammad Javad Sojdeh",
      "Mehdi Letafati",
      "Seyed Pooya Shariatpanahi",
      "Babak Hossein Khalaj"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.14672"
  },
  {
    "id": "arXiv:2211.14673",
    "title": "Evaluation Beyond Task Performance: Analyzing Concepts in AlphaZero in  Hex",
    "abstract": "AlphaZero, an approach to reinforcement learning that couples neural networks\nand Monte Carlo tree search (MCTS), has produced state-of-the-art strategies\nfor traditional board games like chess, Go, shogi, and Hex. While researchers\nand game commentators have suggested that AlphaZero uses concepts that humans\nconsider important, it is unclear how these concepts are captured in the\nnetwork. We investigate AlphaZero's internal representations in the game of Hex\nusing two evaluation techniques from natural language processing (NLP): model\nprobing and behavioral tests. In doing so, we introduce new evaluation tools to\nthe RL community and illustrate how evaluations other than task performance can\nbe used to provide a more complete picture of a model's strengths and\nweaknesses. Our analyses in the game of Hex reveal interesting patterns and\ngenerate some testable hypotheses about how such models learn in general. For\nexample, we find that MCTS discovers concepts before the neural network learns\nto encode them. We also find that concepts related to short-term end-game\nplanning are best encoded in the final layers of the model, whereas concepts\nrelated to long-term planning are encoded in the middle layers of the model.",
    "descriptor": "\nComments: 10 pages, Neural Information Processing Systems 2022\n",
    "authors": [
      "Charles Lovering",
      "Jessica Zosa Forde",
      "George Konidaris",
      "Ellie Pavlick",
      "Michael L. Littman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14673"
  },
  {
    "id": "arXiv:2211.14680",
    "title": "A Physics-informed Diffusion Model for High-fidelity Flow Field  Reconstruction",
    "abstract": "Machine learning models are gaining increasing popularity in the domain of\nfluid dynamics for their potential to accelerate the production of\nhigh-fidelity computational fluid dynamics data. However, many recently\nproposed machine learning models for high-fidelity data reconstruction require\nlow-fidelity data for model training. Such requirement restrains the\napplication performance of these models, since their data reconstruction\naccuracy would drop significantly if the low-fidelity input data used in model\ntest has a large deviation from the training data. To overcome this restraint,\nwe propose a diffusion model which only uses high-fidelity data at training.\nWith different configurations, our model is able to reconstruct high-fidelity\ndata from either a regular low-fidelity sample or a sparsely measured sample,\nand is also able to gain an accuracy increase by using physics-informed\nconditioning information from a known partial differential equation when that\nis available. Experimental results demonstrate that our model can produce\naccurate reconstruction results for 2d turbulent flows based on different input\nsources without retraining.",
    "descriptor": "",
    "authors": [
      "Dule Shu",
      "Zijie Li",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.14680"
  },
  {
    "id": "arXiv:2211.14686",
    "title": "Towards a Decentralized Metaverse: Synchronized Orchestration of Digital  Twins and Sub-Metaverses",
    "abstract": "Accommodating digital twins (DTs) in the metaverse is essential to achieving\ndigital reality. This need for integrating DTs into the metaverse while\noperating them at the network edge has increased the demand for a decentralized\nedge-enabled metaverse. Hence, to consolidate the fusion between real and\ndigital entities, it is necessary to harmonize the interoperability between DTs\nand the metaverse at the edge. In this paper, a novel decentralized metaverse\nframework that incorporates DT operations at the wireless edge is presented. In\nparticular, a system of autonomous physical twins (PTs) operating in a\nmassively-sensed zone is replicated as cyber twins (CTs) at the mobile edge\ncomputing (MEC) servers. To render the CTs' digital environment, this zone is\npartitioned and teleported as distributed sub-metaverses to the MEC servers. To\nguarantee seamless synchronization of the sub-metaverses and their associated\nCTs with the dynamics of the real world and PTs, respectively, this joint\nsynchronization problem is posed as an optimization problem whose goal is to\nminimize the average sub-synchronization time between the real and digital\nworlds, while meeting the DT synchronization intensity requirements. To solve\nthis problem, a novel iterative algorithm for joint sub-metaverse and DT\nassociation at the MEC servers is proposed. This algorithm exploits the\nrigorous framework of optimal transport theory so as to efficiently distribute\nthe sub-metaverses and DTs, while considering the computing and communication\nresource allocations. Simulation results show that the proposed solution can\norchestrate the interplay between DTs and sub-metaverses to achieve a 25.75 %\nreduction in the sub-synchronization time in comparison to the signal-to-noise\nratio-based association scheme.",
    "descriptor": "",
    "authors": [
      "Omar Hashash",
      "Christina Chaccour",
      "Walid Saad",
      "Kei Sakaguchi",
      "Tao Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.14686"
  },
  {
    "id": "arXiv:2211.14694",
    "title": "DigGAN: Discriminator gradIent Gap Regularization for GAN Training with  Limited Data",
    "abstract": "Generative adversarial nets (GANs) have been remarkably successful at\nlearning to sample from distributions specified by a given dataset,\nparticularly if the given dataset is reasonably large compared to its\ndimensionality. However, given limited data, classical GANs have struggled, and\nstrategies like output-regularization, data-augmentation, use of pre-trained\nmodels and pruning have been shown to lead to improvements. Notably, the\napplicability of these strategies is 1) often constrained to particular\nsettings, e.g., availability of a pretrained GAN; or 2) increases training\ntime, e.g., when using pruning. In contrast, we propose a Discriminator\ngradIent Gap regularized GAN (DigGAN) formulation which can be added to any\nexisting GAN. DigGAN augments existing GANs by encouraging to narrow the gap\nbetween the norm of the gradient of a discriminator's prediction w.r.t.\\ real\nimages and w.r.t.\\ the generated samples. We observe this formulation to avoid\nbad attractors within the GAN loss landscape, and we find DigGAN to\nsignificantly improve the results of GAN training when limited data is\navailable. Code is available at \\url{https://github.com/AilsaF/DigGAN}.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Tiantian Fang",
      "Ruoyu Sun",
      "Alex Schwing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14694"
  },
  {
    "id": "arXiv:2211.14699",
    "title": "A Theoretical Study of Inductive Biases in Contrastive Learning",
    "abstract": "Understanding self-supervised learning is important but challenging. Previous\ntheoretical works study the role of pretraining losses, and view neural\nnetworks as general black boxes. However, the recent work of Saunshi et al.\nargues that the model architecture -- a component largely ignored by previous\nworks -- also has significant influences on the downstream performance of\nself-supervised learning. In this work, we provide the first theoretical\nanalysis of self-supervised learning that incorporates the effect of inductive\nbiases originating from the model class. In particular, we focus on contrastive\nlearning -- a popular self-supervised learning method that is widely used in\nthe vision domain. We show that when the model has limited capacity,\ncontrastive representations would recover certain special clustering structures\nthat are compatible with the model architecture, but ignore many other\nclustering structures in the data distribution. As a result, our theory can\ncapture the more realistic setting where contrastive representations have much\nlower dimensionality than the number of clusters in the data distribution. We\ninstantiate our theory on several synthetic data distributions, and provide\nempirical evidence to support the theory.",
    "descriptor": "",
    "authors": [
      "Jeff Z. HaoChen",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14699"
  },
  {
    "id": "arXiv:2211.14700",
    "title": "A novel multimodal dynamic fusion network for disfluency detection in  spoken utterances",
    "abstract": "Disfluency, though originating from human spoken utterances, is primarily\nstudied as a uni-modal text-based Natural Language Processing (NLP) task. Based\non early-fusion and self-attention-based multimodal interaction between text\nand acoustic modalities, in this paper, we propose a novel multimodal\narchitecture for disfluency detection from individual utterances. Our\narchitecture leverages a multimodal dynamic fusion network that adds minimal\nparameters over an existing text encoder commonly used in prior art to leverage\nthe prosodic and acoustic cues hidden in speech. Through experiments, we show\nthat our proposed model achieves state-of-the-art results on the widely used\nEnglish Switchboard for disfluency detection and outperforms prior unimodal and\nmultimodal systems in literature by a significant margin. In addition, we make\na thorough qualitative analysis and show that, unlike text-only systems, which\nsuffer from spurious correlations in the data, our system overcomes this\nproblem through additional cues from speech signals. We make all our codes\npublicly available on GitHub.",
    "descriptor": "\nComments: Submitted to ICASSP 2023. arXiv admin note: text overlap with arXiv:2203.16794\n",
    "authors": [
      "Sreyan Ghosh",
      "Utkarsh Tyagi",
      "Sonal Kumar",
      "Manan Suri",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.14700"
  },
  {
    "id": "arXiv:2211.14701",
    "title": "Spatio-Temporal Meta-Graph Learning for Traffic Forecasting",
    "abstract": "Traffic forecasting as a canonical task of multivariate time series\nforecasting has been a significant research topic in AI community. To address\nthe spatio-temporal heterogeneity and non-stationarity implied in the traffic\nstream, in this study, we propose Spatio-Temporal Meta-Graph Learning as a\nnovel Graph Structure Learning mechanism on spatio-temporal data. Specifically,\nwe implement this idea into Meta-Graph Convolutional Recurrent Network\n(MegaCRN) by plugging the Meta-Graph Learner powered by a Meta-Node Bank into\nGCRN encoder-decoder. We conduct a comprehensive evaluation on two benchmark\ndatasets (METR-LA and PEMS-BAY) and a new large-scale traffic speed dataset in\nwhich traffic incident information is contained. Our model outperformed the\nstate-of-the-arts to a large degree on all three datasets (over 27% MAE and 34%\nRMSE). Besides, through a series of qualitative evaluations, we demonstrate\nthat our model can explicitly disentangle the road links and time slots with\ndifferent patterns and be robustly adaptive to any anomalous traffic\nsituations. Codes and datasets are available at\nhttps://github.com/deepkashiwa20/MegaCRN.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Renhe Jiang",
      "Zhaonan Wang",
      "Jiawei Yong",
      "Puneet Jeph",
      "Quanjun Chen",
      "Yasumasa Kobayashi",
      "Xuan Song",
      "Shintaro Fukushima",
      "Toyotaro Suzumura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14701"
  },
  {
    "id": "arXiv:2211.14703",
    "title": "Exploring Consistency in Cross-Domain Transformer for Domain Adaptive  Semantic Segmentation",
    "abstract": "While transformers have greatly boosted performance in semantic segmentation,\ndomain adaptive transformers are not yet well explored. We identify that the\ndomain gap can cause discrepancies in self-attention. Due to this gap, the\ntransformer attends to spurious regions or pixels, which deteriorates accuracy\non the target domain. We propose to perform adaptation on attention maps with\ncross-domain attention layers that share features between the source and the\ntarget domains. Specifically, we impose consistency between predictions from\ncross-domain attention and self-attention modules to encourage similar\ndistribution in the attention and output of the model across domains, i.e.,\nattention-level and output-level alignment. We also enforce consistency in\nattention maps between different augmented views to further strengthen the\nattention-based alignment. Combining these two components, our method mitigates\nthe discrepancy in attention maps across domains and further boosts the\nperformance of the transformer under unsupervised domain adaptation settings.\nOur model outperforms the existing state-of-the-art baseline model on three\nwidely used benchmarks, including GTAV-to-Cityscapes by 1.3 percent point (pp),\nSynthia-to-Cityscapes by 0.6 pp, and Cityscapes-to-ACDC by 1.1 pp, on average.\nAdditionally, we verify the effectiveness and generalizability of our method\nthrough extensive experiments. Our code will be publicly available.",
    "descriptor": "",
    "authors": [
      "Kaihong Wang",
      "Donghyun Kim",
      "Regerio Feris",
      "Kate Saenko",
      "Margrit Betke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14703"
  },
  {
    "id": "arXiv:2211.14705",
    "title": "Semantic-Aware Local-Global Vision Transformer",
    "abstract": "Vision Transformers have achieved remarkable progresses, among which Swin\nTransformer has demonstrated the tremendous potential of Transformer for vision\ntasks. It surmounts the key challenge of high computational complexity by\nperforming local self-attention within shifted windows. In this work we propose\nthe Semantic-Aware Local-Global Vision Transformer (SALG), to further\ninvestigate two potential improvements towards Swin Transformer. First, unlike\nSwin Transformer that performs uniform partition to produce equal size of\nregular windows for local self-attention, our SALG performs semantic\nsegmentation in an unsupervised way to explore the underlying semantic priors\nin the image. As a result, each segmented region can correspond to a\nsemantically meaningful part in the image, potentially leading to more\neffective features within each of segmented regions. Second, instead of only\nperforming local self-attention within local windows as Swin Transformer does,\nthe proposed SALG performs both 1) local intra-region self-attention for\nlearning fine-grained features within each region and 2) global inter-region\nfeature propagation for modeling global dependencies among all regions.\nConsequently, our model is able to obtain the global view when learning\nfeatures for each token, which is the essential advantage of Transformer. Owing\nto the explicit modeling of the semantic priors and the proposed local-global\nmodeling mechanism, our SALG is particularly advantageous for small-scale\nmodels when the modeling capacity is not sufficient for other models to learn\nsemantics implicitly. Extensive experiments across various vision tasks\ndemonstrates the merit of our model over other vision Transformers, especially\nin the small-scale modeling scenarios.",
    "descriptor": "",
    "authors": [
      "Jiatong Zhang",
      "Zengwei Yao",
      "Fanglin Chen",
      "Guangming Lu",
      "Wenjie Pei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14705"
  },
  {
    "id": "arXiv:2211.14706",
    "title": "Neural Network Verification as Piecewise Linear Optimization:  Formulations for the Composition of Staircase Functions",
    "abstract": "We present a technique for neural network verification using mixed-integer\nprogramming (MIP) formulations. We derive a \\emph{strong formulation} for each\nneuron in a network using piecewise linear activation functions. Additionally,\nas in general, these formulations may require an exponential number of\ninequalities, we also derive a separation procedure that runs in super-linear\ntime in the input dimension. We first introduce and develop our technique on\nthe class of \\emph{staircase} functions, which generalizes the ReLU, binarized,\nand quantized activation functions. We then use results for staircase\nactivation functions to obtain a separation method for general piecewise linear\nactivation functions. Empirically, using our strong formulation and separation\ntechnique, we can reduce the computational time in exact verification settings\nbased on MIP and improve the false negative rate for inexact verifiers relying\non the relaxation of the MIP formulation.",
    "descriptor": "",
    "authors": [
      "Tu Anh-Nguyen",
      "Joey Huchette"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.14706"
  },
  {
    "id": "arXiv:2211.14709",
    "title": "Open-Source Ground-based Sky Image Datasets for Very Short-term Solar  Forecasting, Cloud Analysis and Modeling: A Comprehensive Survey",
    "abstract": "This study presents a comprehensive survey of open-source ground-based sky\nimage datasets for very short-term solar forecasting. Related research areas\nwhich could potentially help improve solar forecasting methods, including cloud\nsegmentation, cloud classification, and cloud motion prediction are also\nconsidered. We first identify 72 open-source sky image datasets that satisfy\nthe needs of machine/deep learning. Then a database of information about\nvarious aspects of the datasets is constructed. To evaluate each surveyed\ndatasets, we further develop a multi-criteria ranking system based on 8\ndimensions of the datasets which could potentially have important impacts on\nusage of the data. Finally, we provide insights on the usage of these datasets\nin the open literature. We hope this paper provide an overview for researchers\nwho are looking for datasets for training deep learning models for very\nshort-term solar forecasting, cloud analysis, and atmospheric modeling.",
    "descriptor": "",
    "authors": [
      "Yuhao Nie",
      "Xiatong Li",
      "Quentin Paletta",
      "Max Aragon",
      "Andea Scott",
      "Adam Brandt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14709"
  },
  {
    "id": "arXiv:2211.14710",
    "title": "3D Point Positional Encoding for Multi-Camera 3D Object Detection  Transformers",
    "abstract": "Multi-camera 3D object detection, a critical component for vision-only\ndriving systems, has achieved impressive progress. Notably, transformer-based\nmethods with 2D features augmented by 3D positional encodings (PE) have enjoyed\ngreat success. However, the mechanism and options of 3D PE have not been\nthoroughly explored. In this paper, we first explore, analyze and compare\nvarious 3D positional encodings. In particular, we devise 3D point PE and show\nits superior performance since more precise positioning may lead to superior 3D\ndetection. In practice, we utilize monocular depth estimation to obtain the 3D\npoint positions for multi-camera 3D object detection. The PE with estimated 3D\npoint locations can bring significant improvements compared to the commonly\nused camera-ray PE. Among DETR-based strategies, our method achieves\nstate-of-the-art 45.6 mAP and 55.1 NDS on the competitive nuScenes valuation\nset. It's the first time that the performance gap between the vision-only\n(DETR-based) and LiDAR-based methods is reduced within 5\\% mAP and 6\\% NDS.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Changyong Shu",
      "Fisher Yu",
      "Yifan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14710"
  },
  {
    "id": "arXiv:2211.14711",
    "title": "Development of a Modular Real-time Shared-control System for a Smart  Wheelchair",
    "abstract": "In this paper, we propose a modular navigation system that can be mounted on\na regular powered wheelchair to assist disabled children and the elderly with\nautonomous mobility and shared-control features. The lack of independent\nmobility drastically affects an individual's mental and physical health making\nthem feel less self-reliant, especially children with Cerebral Palsy and\nlimited cognitive skills. To address this problem, we propose a comparatively\ninexpensive and modular system that uses a stereo camera to perform tasks such\nas path planning, obstacle avoidance, and collision detection in environments\nwith narrow corridors. We avoid any major changes to the hardware of the\nwheelchair for an easy installation by replacing wheel encoders with a stereo\ncamera for visual odometry. An open source software package, the Real-Time\nAppearance Based Mapping package, running on top of the Robot Operating System\n(ROS) allows us to perform visual SLAM that allows mapping and localizing\nitself in the environment. The path planning is performed by the move base\npackage provided by ROS, which quickly and efficiently computes the path\ntrajectory for the wheelchair. In this work, we present the design and\ndevelopment of the system along with its significant functionalities. Further,\nwe report experimental results from a Gazebo simulation and real-world\nscenarios to prove the effectiveness of our proposed system with a compact form\nfactor and a single stereo camera.",
    "descriptor": "",
    "authors": [
      "Vaishanth Ramaraj",
      "Atharva Paralikar",
      "Eung Joo Lee",
      "Syed Muhammad Anwar",
      "Reza Monfaredi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14711"
  },
  {
    "id": "arXiv:2211.14714",
    "title": "Coverage Analysis for Cellular-Connected Random 3D Mobile UAVs with  Directional Antennas",
    "abstract": "This letter proposes an analytical framework to evaluate the coverage\nperformance of a cellular-connected unmanned aerial vehicle (UAV) network in\nwhich UAV user equipments (UAV-UEs) are equipped with directional antennas and\nmove according to a three-dimensional (3D) mobility model. The ground base\nstations (GBSs) equipped with practical down-tilted antennas are distributed\naccording to a Poisson point process (PPP). With tools from stochastic\ngeometry, we derive the handover probability and coverage probability of a\nrandom UAV-UE under the strongest average received signal strength (RSS)\nassociation strategy. The proposed analytical framework allows to investigate\nthe effect of UAV-UE antenna beamwidth, mobility speed, cell association, and\nvertical motions on both the handover probability and coverage probability. We\nconclude that the optimal UAV-UE antenna beamwidth decreases with the GBS\ndensity, and the omnidirectional antenna model is preferred in the sparse\nnetwork scenario. What's more, the superiority of the strongest average RSS\nassociation over the nearest association diminishes with the increment of GBS\ndensity.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to IEEE Wireless Communications Letters\n",
    "authors": [
      "Hongguang Sun",
      "Chao Ma",
      "Linyi Zhang",
      "Jiahui Li",
      "Xijun Wang",
      "Shuqin Li",
      "Tony Q.S. Quek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.14714"
  },
  {
    "id": "arXiv:2211.14715",
    "title": "A Knowledge-based Learning Framework for Self-supervised Pre-training  Towards Enhanced Recognition of Medical Images",
    "abstract": "Self-supervised pre-training has become the priory choice to establish\nreliable models for automated recognition of massive medical images, which are\nroutinely annotation-free, without semantics, and without guarantee of quality.\nNote that this paradigm is still at its infancy and limited by closely related\nopen issues: 1) how to learn robust representations in an unsupervised manner\nfrom unlabelled medical images of low diversity in samples? and 2) how to\nobtain the most significant representations demanded by a high-quality\nsegmentation? Aiming at these issues, this study proposes a knowledge-based\nlearning framework towards enhanced recognition of medical images, which works\nin three phases by synergizing contrastive learning and generative learning\nmodels: 1) Sample Space Diversification: Reconstructive proxy tasks have been\nenabled to embed a priori knowledge with context highlighted to diversify the\nexpanded sample space; 2) Enhanced Representation Learning: Informative\nnoise-contrastive estimation loss regularizes the encoder to enhance\nrepresentation learning of annotation-free images; 3) Correlated Optimization:\nOptimization operations in pre-training the encoder and the decoder have been\ncorrelated via image restoration from proxy tasks, targeting the need for\nsemantic segmentation. Extensive experiments have been performed on various\npublic medical image datasets (e.g., CheXpert and DRIVE) against the\nstate-of-the-art counterparts (e.g., SimCLR and MoCo), and results demonstrate\nthat: The proposed framework statistically excels in self-supervised\nbenchmarks, achieving 2.08, 1.23, 1.12, 0.76 and 1.38 percentage points\nimprovements over SimCLR in AUC/Dice. The proposed framework achieves\nlabel-efficient semi-supervised learning, e.g., reducing the annotation cost by\nup to 99% in pathological classification.",
    "descriptor": "\nComments: 10 pages, 9 figures, 3 tables, submitted to IEEE-TMI\n",
    "authors": [
      "Wei Chen",
      "Chen Li",
      "Dan Chen",
      "Xin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14715"
  },
  {
    "id": "arXiv:2211.14716",
    "title": "Fingerprint Pore Detection: A Survey",
    "abstract": "This work presents the first survey on fingerprint pore detection. The survey\nprovides a general overview of the field and discusses methods, datasets, and\nevaluation protocols. We also present a baseline method inspired on the\nstate-of-the-art that implements a customizable Fully Convolutional Network,\nwhose hyperparameters were tuned to achieve optimal pore detection rates.\nFinally, we also reimplementated three other approaches proposed in the\nliterature for evaluation purposes. We have made the source code of (1) the\nbaseline method, (2) the reimplemented approaches, and (3) the training and\nevaluation processes for two different datasets available to the public to\nattract more researchers to the field and to facilitate future comparisons\nunder the same conditions. The code is available in the following repository:\nhttps://github.com/azimIbragimov/Fingerprint-Pore-Detection-A-Survey",
    "descriptor": "",
    "authors": [
      "Azim Ibragimov",
      "Mauricio Pamplona Segundo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14716"
  },
  {
    "id": "arXiv:2211.14719",
    "title": "BadPrompt: Backdoor Attacks on Continuous Prompts",
    "abstract": "The prompt-based learning paradigm has gained much research attention\nrecently. It has achieved state-of-the-art performance on several NLP tasks,\nespecially in the few-shot scenarios. While steering the downstream tasks, few\nworks have been reported to investigate the security problems of the\nprompt-based models. In this paper, we conduct the first study on the\nvulnerability of the continuous prompt learning algorithm to backdoor attacks.\nWe observe that the few-shot scenarios have posed a great challenge to backdoor\nattacks on the prompt-based models, limiting the usability of existing NLP\nbackdoor methods. To address this challenge, we propose BadPrompt, a\nlightweight and task-adaptive algorithm, to backdoor attack continuous prompts.\nSpecially, BadPrompt first generates candidate triggers which are indicative\nfor predicting the targeted label and dissimilar to the samples of the\nnon-targeted labels. Then, it automatically selects the most effective and\ninvisible trigger for each sample with an adaptive trigger optimization\nalgorithm. We evaluate the performance of BadPrompt on five datasets and two\ncontinuous prompt models. The results exhibit the abilities of BadPrompt to\neffectively attack continuous prompts while maintaining high performance on the\nclean test sets, outperforming the baseline models by a large margin. The\nsource code of BadPrompt is publicly available at\nhttps://github.com/papersPapers/BadPrompt.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Xiangrui Cai",
      "Haidong Xu",
      "Sihan Xu",
      "Ying Zhang",
      "Xiaojie Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14719"
  },
  {
    "id": "arXiv:2211.14720",
    "title": "Rectified Pessimistic-Optimistic Learning for Stochastic Continuum-armed  Bandit with Constraints",
    "abstract": "This paper studies the problem of stochastic continuum-armed bandit with\nconstraints (SCBwC), where we optimize a black-box reward function $f(x)$\nsubject to a black-box constraint function $g(x)\\leq 0$ over a continuous space\n$\\mathcal X$. We model reward and constraint functions via Gaussian processes\n(GPs) and propose a Rectified Pessimistic-Optimistic Learning framework (RPOL),\na penalty-based method incorporating optimistic and pessimistic GP bandit\nlearning for reward and constraint functions, respectively. We consider the\nmetric of cumulative constraint violation $\\sum_{t=1}^T(g(x_t))^{+},$ which is\nstrictly stronger than the traditional long-term constraint violation\n$\\sum_{t=1}^Tg(x_t).$ The rectified design for the penalty update and the\npessimistic learning for the constraint function in RPOL guarantee the\ncumulative constraint violation is minimal. RPOL can achieve sublinear regret\nand cumulative constraint violation for SCBwC and its variants (e.g., under\ndelayed feedback and non-stationary environment). These theoretical results\nmatch their unconstrained counterparts. Our experiments justify RPOL\noutperforms several existing baseline algorithms.",
    "descriptor": "",
    "authors": [
      "Hengquan Guo",
      "Qi Zhu",
      "Xin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14720"
  },
  {
    "id": "arXiv:2211.14721",
    "title": "Generalizing Gaussian Smoothing for Random Search",
    "abstract": "Gaussian smoothing (GS) is a derivative-free optimization (DFO) algorithm\nthat estimates the gradient of an objective using perturbations of the current\nparameters sampled from a standard normal distribution. We generalize it to\nsampling perturbations from a larger family of distributions. Based on an\nanalysis of DFO for non-convex functions, we propose to choose a distribution\nfor perturbations that minimizes the mean squared error (MSE) of the gradient\nestimate. We derive three such distributions with provably smaller MSE than\nGaussian smoothing. We conduct evaluations of the three sampling distributions\non linear regression, reinforcement learning, and DFO benchmarks in order to\nvalidate our claims. Our proposal improves on GS with the same computational\ncomplexity, and are usually competitive with and often outperform Guided ES and\nOrthogonal ES, two computationally more expensive algorithms that adapt the\ncovariance matrix of normally distributed perturbations.",
    "descriptor": "\nComments: This work was published at ICML 2022. This version contains some minor corrections and a link to a code repository\n",
    "authors": [
      "Katelyn Gao",
      "Ozan Sener"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.14721"
  },
  {
    "id": "arXiv:2211.14729",
    "title": "Unbiased Knowledge Distillation for Recommendation",
    "abstract": "As a promising solution for model compression, knowledge distillation (KD)\nhas been applied in recommender systems (RS) to reduce inference latency.\nTraditional solutions first train a full teacher model from the training data,\nand then transfer its knowledge (\\ie \\textit{soft labels}) to supervise the\nlearning of a compact student model. However, we find such a standard\ndistillation paradigm would incur serious bias issue -- popular items are more\nheavily recommended after the distillation. This effect prevents the student\nmodel from making accurate and fair recommendations, decreasing the\neffectiveness of RS.\nIn this work, we identify the origin of the bias in KD -- it roots in the\nbiased soft labels from the teacher, and is further propagated and intensified\nduring the distillation. To rectify this, we propose a new KD method with a\nstratified distillation strategy. It first partitions items into multiple\ngroups according to their popularity, and then extracts the ranking knowledge\nwithin each group to supervise the learning of the student. Our method is\nsimple and teacher-agnostic -- it works on distillation stage without affecting\nthe training of the teacher model. We conduct extensive theoretical and\nempirical studies to validate the effectiveness of our proposal. We release our\ncode at: https://github.com/chengang95/UnKD.",
    "descriptor": "",
    "authors": [
      "Gang Chen",
      "Jiawei Chen",
      "Fuli Feng",
      "Sheng Zhou",
      "Xiangnan He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14729"
  },
  {
    "id": "arXiv:2211.14730",
    "title": "A Time Series is Worth 64 Words: Long-term Forecasting with Transformers",
    "abstract": "We propose an efficient design of Transformer-based models for multivariate\ntime series forecasting and self-supervised representation learning. It is\nbased on two key components: (i) segmentation of time series into\nsubseries-level patches which are served as input tokens to Transformer; (ii)\nchannel-independence where each channel contains a single univariate time\nseries that shares the same embedding and Transformer weights across all the\nseries. Patching design naturally has three-fold benefit: local semantic\ninformation is retained in the embedding; computation and memory usage of the\nattention maps are quadratically reduced given the same look-back window; and\nthe model can attend longer history. Our channel-independent patch time series\nTransformer (PatchTST) can improve the long-term forecasting accuracy\nsignificantly when compared with that of SOTA Transformer-based models. We also\napply our model to self-supervised pre-training tasks and attain excellent\nfine-tuning performance, which outperforms supervised training on large\ndatasets. Transferring of masked pre-trained representation on one dataset to\nothers also produces SOTA forecasting accuracy. Code is available at:\nhttps://github.com/yuqinie98/PatchTST.",
    "descriptor": "",
    "authors": [
      "Yuqi Nie",
      "Nam H. Nguyen",
      "Phanwadee Sinthong",
      "Jayant Kalagnanam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14730"
  },
  {
    "id": "arXiv:2211.14731",
    "title": "BALF: Simple and Efficient Blur Aware Local Feature Detector",
    "abstract": "Local feature detection is a key ingredient of many image processing and\ncomputer vision applications, such as visual odometry and localization. Most\nexisting algorithms focus on feature detection from a sharp image. They would\nthus have degraded performance once the image is blurred, which could happen\neasily under low-lighting conditions. To address this issue, we propose a\nsimple yet both efficient and effective keypoint detection method that is able\nto accurately localize the salient keypoints in a blurred image. Our method\ntakes advantages of a novel multi-layer perceptron (MLP) based architecture\nthat significantly improve the detection repeatability for a blurred image. The\nnetwork is also light-weight and able to run in real-time, which enables its\ndeployment for time-constrained applications. Extensive experimental results\ndemonstrate that our detector is able to improve the detection repeatability\nwith blurred images, while keeping comparable performance as existing\nstate-of-the-art detectors for sharp images.",
    "descriptor": "",
    "authors": [
      "Zhenjun Zhao",
      "Yu Zhai",
      "Ben M. Chen",
      "Peidong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14731"
  },
  {
    "id": "arXiv:2211.14732",
    "title": "Deep representation learning: Fundamentals, Perspectives, Applications,  and Open Challenges",
    "abstract": "Machine Learning algorithms have had a profound impact on the field of\ncomputer science over the past few decades. These algorithms performance is\ngreatly influenced by the representations that are derived from the data in the\nlearning process. The representations learned in a successful learning process\nshould be concise, discrete, meaningful, and able to be applied across a\nvariety of tasks. A recent effort has been directed toward developing Deep\nLearning models, which have proven to be particularly effective at capturing\nhigh-dimensional, non-linear, and multi-modal characteristics. In this work, we\ndiscuss the principles and developments that have been made in the process of\nlearning representations, and converting them into desirable applications. In\naddition, for each framework or model, the key issues and open challenges, as\nwell as the advantages, are examined.",
    "descriptor": "",
    "authors": [
      "Kourosh T. Baghaei",
      "Amirreza Payandeh",
      "Pooya Fayyazsanavi",
      "Shahram Rahimi",
      "Zhiqian Chen",
      "Somayeh Bakhtiari Ramezani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14732"
  },
  {
    "id": "arXiv:2211.14734",
    "title": "X-PuDu at SemEval-2022 Task 7: A Replaced Token Detection Task  Pre-trained Model with Pattern-aware Ensembling for Identifying Plausible  Clarifications",
    "abstract": "This paper describes our winning system on SemEval 2022 Task 7: Identifying\nPlausible Clarifications of Implicit and Underspecified Phrases in\nInstructional Texts. A replaced token detection pre-trained model is utilized\nwith minorly different task-specific heads for SubTask-A: Multi-class\nClassification and SubTask-B: Ranking. Incorporating a pattern-aware ensemble\nmethod, our system achieves a 68.90% accuracy score and 0.8070 spearman's rank\ncorrelation score surpassing the 2nd place with a large margin by 2.7 and 2.2\npercent points for SubTask-A and SubTask-B, respectively. Our approach is\nsimple and easy to implement, and we conducted ablation studies and qualitative\nand quantitative analyses for the working strategies used in our system.",
    "descriptor": "\nComments: Accepted at the 16th International Workshop on Semantic Evaluation (SemEval-2022), NAACL\n",
    "authors": [
      "Junyuan Shang",
      "Shuohuan Wang",
      "Yu Sun",
      "Yanjun Yu",
      "Yue Zhou",
      "Li Xiang",
      "Guixiu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14734"
  },
  {
    "id": "arXiv:2211.14736",
    "title": "Attribution-based XAI Methods in Computer Vision: A Review",
    "abstract": "The advancements in deep learning-based methods for visual perception tasks\nhave seen astounding growth in the last decade, with widespread adoption in a\nplethora of application areas from autonomous driving to clinical decision\nsupport systems. Despite their impressive performance, these deep\nlearning-based models remain fairly opaque in their decision-making process,\nmaking their deployment in human-critical tasks a risky endeavor. This in turn\nmakes understanding the decisions made by these models crucial for their\nreliable deployment. Explainable AI (XAI) methods attempt to address this by\noffering explanations for such black-box deep learning methods. In this paper,\nwe provide a comprehensive survey of attribution-based XAI methods in computer\nvision and review the existing literature for gradient-based,\nperturbation-based, and contrastive methods for XAI, and provide insights on\nthe key challenges in developing and evaluating robust XAI methods.",
    "descriptor": "\nComments: Technical report from December 2020; 22 pages, 1 figure\n",
    "authors": [
      "Kumar Abhishek",
      "Deeksha Kamath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14736"
  },
  {
    "id": "arXiv:2211.14738",
    "title": "Distilled Visual and Robot Kinematics Embeddings for Metric Depth  Estimation in Monocular Scene Reconstruction",
    "abstract": "Estimating precise metric depth and scene reconstruction from monocular\nendoscopy is a fundamental task for surgical navigation in robotic surgery.\nHowever, traditional stereo matching adopts binocular images to perceive the\ndepth information, which is difficult to transfer to the soft robotics-based\nsurgical systems due to the use of monocular endoscopy. In this paper, we\npresent a novel framework that combines robot kinematics and monocular\nendoscope images with deep unsupervised learning into a single network for\nmetric depth estimation and then achieve 3D reconstruction of complex anatomy.\nSpecifically, we first obtain the relative depth maps of surgical scenes by\nleveraging a brightness-aware monocular depth estimation method. Then, the\ncorresponding endoscope poses are computed based on non-linear optimization of\ngeometric and photometric reprojection residuals. Afterwards, we develop a\nDepth-driven Sliding Optimization (DDSO) algorithm to extract the scaling\ncoefficient from kinematics and calculated poses offline. By coupling the\nmetric scale and relative depth data, we form a robust ensemble that represents\nthe metric and consistent depth. Next, we treat the ensemble as supervisory\nlabels to train a metric depth estimation network for surgeries (i.e.,\nMetricDepthS-Net) that distills the embeddings from the robot kinematics,\nendoscopic videos, and poses. With accurate metric depth estimation, we utilize\na dense visual reconstruction method to recover the 3D structure of the whole\nsurgical site. We have extensively evaluated the proposed framework on public\nSCARED and achieved comparable performance with stereo-based depth estimation\nmethods. Our results demonstrate the feasibility of the proposed approach to\nrecover the metric depth and 3D structure with monocular inputs.",
    "descriptor": "",
    "authors": [
      "Ruofeng Wei",
      "Bin Li",
      "Hangjie Mo",
      "Fangxun Zhong",
      "Yonghao Long",
      "Qi Dou",
      "Yun-Hui Liu",
      "Dong Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14738"
  },
  {
    "id": "arXiv:2211.14739",
    "title": "MNER-QG: An End-to-End MRC framework for Multimodal Named Entity  Recognition with Query Grounding",
    "abstract": "Multimodal named entity recognition (MNER) is a critical step in information\nextraction, which aims to detect entity spans and classify them to\ncorresponding entity types given a sentence-image pair. Existing methods either\n(1) obtain named entities with coarse-grained visual clues from attention\nmechanisms, or (2) first detect fine-grained visual regions with toolkits and\nthen recognize named entities. However, they suffer from improper alignment\nbetween entity types and visual regions or error propagation in the two-stage\nmanner, which finally imports irrelevant visual information into texts. In this\npaper, we propose a novel end-to-end framework named MNER-QG that can\nsimultaneously perform MRC-based multimodal named entity recognition and query\ngrounding. Specifically, with the assistance of queries, MNER-QG can provide\nprior knowledge of entity types and visual regions, and further enhance\nrepresentations of both texts and images. To conduct the query grounding task,\nwe provide manual annotations and weak supervisions that are obtained via\ntraining a highly flexible visual grounding model with transfer learning. We\nconduct extensive experiments on two public MNER datasets, Twitter2015 and\nTwitter2017. Experimental results show that MNER-QG outperforms the current\nstate-of-the-art models on the MNER task, and also improves the query grounding\nperformance.",
    "descriptor": "\nComments: 13 pages, 6 figures, published to AAAI\n",
    "authors": [
      "Meihuizi Jia",
      "Lei Shen",
      "Xin Shen",
      "Lejian Liao",
      "Meng Chen",
      "Xiaodong He",
      "Zhendong Chen",
      "Jiaqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14739"
  },
  {
    "id": "arXiv:2211.14742",
    "title": "Dynamic Feature Pruning and Consolidation for Occluded Person  Re-Identification",
    "abstract": "Occluded person re-identification (ReID) is a challenging problem due to\ncontamination from occluders, and existing approaches address the issue with\nprior knowledge cues, eg human body key points, semantic segmentations and etc,\nwhich easily fails in the presents of heavy occlusion and other humans as\noccluders. In this paper, we propose a feature pruning and consolidation (FPC)\nframework to circumvent explicit human structure parse, which mainly consists\nof a sparse encoder, a global and local feature ranking module, and a feature\nconsolidation decoder. Specifically, the sparse encoder drops less important\nimage tokens (mostly related to background noise and occluders) solely\naccording to correlation within the class token attention instead of relying on\nprior human shape information. Subsequently, the ranking stage relies on the\npreserved tokens produced by the sparse encoder to identify k-nearest neighbors\nfrom a pre-trained gallery memory by measuring the image and patch-level\ncombined similarity. Finally, we use the feature consolidation module to\ncompensate pruned features using identified neighbors for recovering essential\ninformation while disregarding disturbance from noise and occlusion.\nExperimental results demonstrate the effectiveness of our proposed framework on\noccluded, partial and holistic Re-ID datasets. In particular, our method\noutperforms state-of-the-art results by at least 8.6% mAP and 6.0% Rank-1\naccuracy on the challenging Occluded-Duke dataset.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Yuteng Ye",
      "Hang Zhou",
      "Junqing Yu",
      "Qiang Hu",
      "Wei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14742"
  },
  {
    "id": "arXiv:2211.14743",
    "title": "Searching for Uncollected Litter with Computer Vision",
    "abstract": "This study combines photo metadata and computer vision to quantify where\nuncollected litter is present. Images from the Trash Annotations in Context\n(TACO) dataset were used to teach an algorithm to detect 10 categories of\ngarbage. Although it worked well with smartphone photos, it struggled when\ntrying to process images from vehicle mounted cameras. However, increasing the\nvariety of perspectives and backgrounds in the dataset will help it improve in\nunfamiliar situations. These data are plotted onto a map which, as accuracy\nimproves, could be used for measuring waste management strategies and\nquantifying trends.",
    "descriptor": "\nComments: 17 pages, 6 figures\n",
    "authors": [
      "Julian Hernandez",
      "Dr. Clark Fitzgerald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14743"
  },
  {
    "id": "arXiv:2211.14744",
    "title": "BEAR: Physics-Principled Building Environment for Control and  Reinforcement Learning",
    "abstract": "Recent advancements in reinforcement learning algorithms have opened doors\nfor researchers to operate and optimize building energy management systems\nautonomously. However, the lack of an easily configurable building dynamical\nmodel and energy management task simulation and evaluation platform has\narguably slowed the progress in developing advanced and dedicated reinforcement\nlearning (RL) and control algorithms for building operation tasks. Here we\npropose \"BEAR\", a physics-principled Building Environment for Control And\nReinforcement Learning. The platform allows researchers to benchmark both\nmodel-based and model-free controllers using a broad collection of standard\nbuilding models in Python without co-simulation using external building\nsimulators. In this paper, we discuss the design of this platform and compare\nit with other existing building simulation frameworks. We demonstrate the\ncompatibility and performance of BEAR with different controllers, including\nboth model predictive control (MPC) and several state-of-the-art RL methods\nwith two case studies.",
    "descriptor": "\nComments: Accepted at ACM e-Energy 2023; Code available at this https URL\n",
    "authors": [
      "Chi Zhang",
      "Yuanyuan Shi",
      "Yize Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14744"
  },
  {
    "id": "arXiv:2211.14745",
    "title": "Cross-domain Few-shot Segmentation with Transductive Fine-tuning",
    "abstract": "Few-shot segmentation (FSS) expects models trained on base classes to work on\nnovel classes with the help of a few support images. However, when there exists\na domain gap between the base and novel classes, the state-of-the-art FSS\nmethods may even fail to segment simple objects. To improve their performance\non unseen domains, we propose to transductively fine-tune the base model on a\nset of query images under the few-shot setting, where the core idea is to\nimplicitly guide the segmentation of query images using support labels.\nAlthough different images are not directly comparable, their class-wise\nprototypes are desired to be aligned in the feature space. By aligning query\nand support prototypes with an uncertainty-aware contrastive loss, and using a\nsupervised cross-entropy loss and an unsupervised boundary loss as\nregularizations, our method could generalize the base model to the target\ndomain without additional labels. We conduct extensive experiments under\nvarious cross-domain settings of natural, remote sensing, and medical images.\nThe results show that our method could consistently and significantly improve\nthe performance of prototypical FSS models in all cross-domain tasks.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Yuhang Lu",
      "Xinyi Wu",
      "Zhenyao Wu",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14745"
  },
  {
    "id": "arXiv:2211.14746",
    "title": "Puffy: A Step-by-step Guide to Craft Bio-inspired Artifacts with  Interactive Materiality",
    "abstract": "A rising number of HCI scholars have begun to use materiality as a starting\npoint for exploring the design's potential and restrictions. Despite the\ntheoretical flourishing, the practical design process and instruction for\nbeginner practitioners are still in scarcity. We leveraged the pictorial format\nto illustrate our crafting process of Puffy, a bio-inspired artifact that\nfeatures a cilia-mimetic surface expressing anthropomorphic qualities through\nshape changes. Our approach consists of three key activities (i.e., analysis,\nsynthesis, and detailing) interlaced recursively throughout the journey. Using\nthis approach, we analyzed different input sources, synthesized peers'\ncritiques and self-reflection, and detailed the designed experience with\niterative prototypes. Building on a reflective analysis of our approach, we\nconcluded with a set of practical implications and design recommendations to\ninform other practitioners to initiate their investigations in interactive\nmateriality.",
    "descriptor": "\nComments: 17th International Conference On Tangible Embedded And Embodied Interaction\n",
    "authors": [
      "Sark Pangrui Xing",
      "Bart van Dijk",
      "Pengcheng An",
      "Miguel Bruns",
      "Yaliang Chuang",
      "Stephen Jia Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.14746"
  },
  {
    "id": "arXiv:2211.14748",
    "title": "Safe Human Robot-Interaction using Switched Model Reference Admittance  Control",
    "abstract": "Physical Human-Robot Interaction (pHRI) task involves tight coupling between\nsafety constraints and compliance with human intentions. In this paper, a novel\nswitched model reference admittance controller is developed to maintain\ncompliance with the external force while upholding safety constraints in the\nworkspace for an n-link manipulator involved in pHRI. A switched reference\nmodel is designed for the admittance controller to generate the reference\ntrajectory within the safe workspace. The stability analysis of the switched\nreference model is carried out by an appropriate selection of the Common\nQuadratic Lyapunov Function (CQLF) so that asymptotic convergence of the\ntrajectory tracking error is ensured. The efficacy of the proposed controller\nis validated in simulation on a two-link robot manipulator.",
    "descriptor": "",
    "authors": [
      "Chayan Kumar Paul",
      "Bhabani Shankar Dey",
      "Udayan Banerjee",
      "Indra Narayan Kar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14748"
  },
  {
    "id": "arXiv:2211.14750",
    "title": "Conditioning Covert Geo-Location (CGL) Detection on Semantic Class  Information",
    "abstract": "The primary goal of artificial intelligence is to mimic humans. Therefore, to\nadvance toward this goal, the AI community attempts to imitate qualities/skills\npossessed by humans and imbibes them into machines with the help of\ndatasets/tasks. Earlier, many tasks which require knowledge about the objects\npresent in an image are satisfactorily solved by vision models. Recently, with\nthe aim to incorporate knowledge about non-object image regions (hideouts,\nturns, and other obscured regions), a task for identification of potential\nhideouts termed Covert Geo-Location (CGL) detection was proposed by Saha et al.\nIt involves identification of image regions which have the potential to either\ncause an imminent threat or appear as target zones to be accessed for further\ninvestigation to identify any occluded objects. Only certain occluding items\nbelonging to certain semantic classes can give rise to CGLs. This fact was\noverlooked by Saha et al. and no attempts were made to utilize semantic class\ninformation, which is crucial for CGL detection. In this paper, we propose a\nmultitask-learning-based approach to achieve 2 goals - i) extraction of\nfeatures having semantic class information; ii) robust training of the common\nencoder, exploiting large standard annotated datasets as training set for the\nauxiliary task (semantic segmentation). To explicitly incorporate class\ninformation in the features extracted by the encoder, we have further employed\nattention mechanism in a novel manner. We have also proposed a better\nevaluation metric for CGL detection that gives more weightage to recognition\nrather than precise localization. Experimental evaluations performed on the CGL\ndataset, demonstrate a significant increase in performance of about 3% to 14%\nmIoU and 3% to 16% DaR on split 1, and 1% mIoU and 1% to 2% DaR on split 2 over\nSOTA, serving as a testimony to the superiority of our approach.",
    "descriptor": "",
    "authors": [
      "Binoy Saha",
      "Sukhendu Das"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14750"
  },
  {
    "id": "arXiv:2211.14751",
    "title": "Estimating Reflectance Layer from A Single Image: Integrating  Reflectance Guidance and Shadow/Specular Aware Learning",
    "abstract": "Estimating reflectance layer from a single image is a challenging task. It\nbecomes more challenging when the input image contains shadows or specular\nhighlights, which often render an inaccurate estimate of the reflectance layer.\nTherefore, we propose a two-stage learning method, including reflectance\nguidance and a Shadow/Specular-Aware (S-Aware) network to tackle the problem.\nIn the first stage, an initial reflectance layer free from shadows and\nspecularities is obtained with the constraint of novel losses that are guided\nby prior-based shadow-free and specular-free images. To further enforce the\nreflectance layer to be independent from shadows and specularities in the\nsecond-stage refinement, we introduce an S-Aware network that distinguishes the\nreflectance image from the input image. Our network employs a classifier to\ncategorize shadow/shadow-free, specular/specular-free classes, enabling the\nactivation features to function as attention maps that focus on shadow/specular\nregions. Our quantitative and qualitative evaluations show that our method\noutperforms the state-of-the-art methods in the reflectance layer estimation\nthat is free from shadows and specularities.",
    "descriptor": "\nComments: Accepted to AAAI2023\n",
    "authors": [
      "Yeying Jin",
      "Ruoteng Li",
      "Wenhan Yang",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14751"
  },
  {
    "id": "arXiv:2211.14752",
    "title": "Differentiable Meta Multigraph Search with Partial Message Propagation  on Heterogeneous Information Networks",
    "abstract": "Heterogeneous information networks (HINs) are widely employed for describing\nreal-world data with intricate entities and relationships. To automatically\nutilize their semantic information, graph neural architecture search has\nrecently been developed on various tasks of HINs. Existing works, on the other\nhand, show weaknesses in instability and inflexibility. To address these\nissues, we propose a novel method called Partial Message Meta Multigraph search\n(PMMM) to automatically optimize the neural architecture design on HINs.\nSpecifically, to learn how graph neural networks (GNNs) propagate messages\nalong various types of edges, PMMM adopts an efficient differentiable framework\nto search for a meaningful meta multigraph, which can capture more flexible and\ncomplex semantic relations than a meta graph. The differentiable search\ntypically suffers from performance instability, so we further propose a stable\nalgorithm called partial message search to ensure that the searched meta\nmultigraph consistently surpasses the manually designed meta-structures, i.e.,\nmeta-paths. Extensive experiments on six benchmark datasets over two\nrepresentative tasks, including node classification and recommendation,\ndemonstrate the effectiveness of the proposed method. Our approach outperforms\nthe state-of-the-art heterogeneous GNNs, finds out meaningful meta multigraphs,\nand is significantly more stable.",
    "descriptor": "\nComments: 12 pages, 7 figures, 8 tables, accepted by AAAI 2023 conference\n",
    "authors": [
      "Chao Li",
      "Hao Xu",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14752"
  },
  {
    "id": "arXiv:2211.14753",
    "title": "A Self-adaptive Neuroevolution Approach to Constructing Deep Neural  Network Architectures Across Different Types",
    "abstract": "Neuroevolution has greatly promoted Deep Neural Network (DNN) architecture\ndesign and its applications, while there is a lack of methods available across\ndifferent DNN types concerning both their scale and performance. In this study,\nwe propose a self-adaptive neuroevolution (SANE) approach to automatically\nconstruct various lightweight DNN architectures for different tasks. One of the\nkey settings in SANE is the search space defined by cells and organs\nself-adapted to different DNN types. Based on this search space, a constructive\nevolution strategy with uniform evolution settings and operations is designed\nto grow DNN architectures gradually. SANE is able to self-adaptively adjust\nevolution exploration and exploitation to improve search efficiency. Moreover,\na speciation scheme is developed to protect evolution from early convergence by\nrestricting selection competition within species. To evaluate SANE, we carry\nout neuroevolution experiments to generate different DNN architectures\nincluding convolutional neural network, generative adversarial network and long\nshort-term memory. The results illustrate that the obtained DNN architectures\ncould have smaller scale with similar performance compared to existing DNN\narchitectures. Our proposed SANE provides an efficient approach to\nself-adaptively search DNN architectures across different types.",
    "descriptor": "",
    "authors": [
      "Zhenhao Shuai",
      "Hongbo Liu",
      "Zhaolin Wan",
      "Wei-Jie Yu",
      "Jun Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14753"
  },
  {
    "id": "arXiv:2211.14758",
    "title": "VideoReTalking: Audio-based Lip Synchronization for Talking Head Video  Editing In the Wild",
    "abstract": "We present VideoReTalking, a new system to edit the faces of a real-world\ntalking head video according to input audio, producing a high-quality and\nlip-syncing output video even with a different emotion. Our system disentangles\nthis objective into three sequential tasks: (1) face video generation with a\ncanonical expression; (2) audio-driven lip-sync; and (3) face enhancement for\nimproving photo-realism. Given a talking-head video, we first modify the\nexpression of each frame according to the same expression template using the\nexpression editing network, resulting in a video with the canonical expression.\nThis video, together with the given audio, is then fed into the lip-sync\nnetwork to generate a lip-syncing video. Finally, we improve the photo-realism\nof the synthesized faces through an identity-aware face enhancement network and\npost-processing. We use learning-based approaches for all three steps and all\nour modules can be tackled in a sequential pipeline without any user\nintervention. Furthermore, our system is a generic approach that does not need\nto be retrained to a specific person. Evaluations on two widely-used datasets\nand in-the-wild examples demonstrate the superiority of our framework over\nother state-of-the-art methods in terms of lip-sync accuracy and visual\nquality.",
    "descriptor": "\nComments: Accepted by SIGGRAPH Asia 2022 Conference Proceedings. Project page: this https URL\n",
    "authors": [
      "Kun Cheng",
      "Xiaodong Cun",
      "Yong Zhang",
      "Menghan Xia",
      "Fei Yin",
      "Mingrui Zhu",
      "Xuan Wang",
      "Jue Wang",
      "Nannan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14758"
  },
  {
    "id": "arXiv:2211.14763",
    "title": "Multi-Label Continual Learning using Augmented Graph Convolutional  Network",
    "abstract": "Multi-Label Continual Learning (MLCL) builds a class-incremental framework in\na sequential multi-label image recognition data stream. The critical challenges\nof MLCL are the construction of label relationships on past-missing and\nfuture-missing partial labels of training data and the catastrophic forgetting\non old classes, resulting in poor generalization. To solve the problems, the\nstudy proposes an Augmented Graph Convolutional Network (AGCN++) that can\nconstruct the cross-task label relationships in MLCL and sustain catastrophic\nforgetting. First, we build an Augmented Correlation Matrix (ACM) across all\nseen classes, where the intra-task relationships derive from the hard label\nstatistics. In contrast, the inter-task relationships leverage hard and soft\nlabels from data and a constructed expert network. Then, we propose a novel\npartial label encoder (PLE) for MLCL, which can extract dynamic class\nrepresentation for each partial label image as graph nodes and help generate\nsoft labels to create a more convincing ACM and suppress forgetting. Last, to\nsuppress the forgetting of label dependencies across old tasks, we propose a\nrelationship-preserving constrainter to construct label relationships. The\ninter-class topology can be augmented automatically, which also yields\neffective class representations. The proposed method is evaluated using two\nmulti-label image benchmarks. The experimental results show that the proposed\nway is effective for MLCL image recognition and can build convincing\ncorrelations across tasks even if the labels of previous tasks are missing.",
    "descriptor": "",
    "authors": [
      "Kaile Du",
      "Fan Lyu",
      "Linyan Li",
      "Fuyuan Hu",
      "Wei Feng",
      "Fenglei Xu",
      "Xuefeng Xi",
      "Hanjing Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14763"
  },
  {
    "id": "arXiv:2211.14764",
    "title": "Prototype as Query for Few Shot Semantic Segmentation",
    "abstract": "Few-shot Semantic Segmentation (FSS) was proposed to segment unseen classes\nin a query image, referring to only a few annotated examples named support\nimages. One of the characteristics of FSS is spatial inconsistency between\nquery and support targets, e.g., texture or appearance. This greatly challenges\nthe generalization ability of methods for FSS, which requires to effectively\nexploit the dependency of the query image and the support examples. Most\nexisting methods abstracted support features into prototype vectors and\nimplemented the interaction with query features using cosine similarity or\nfeature concatenation. However, this simple interaction may not capture spatial\ndetails in query features. To alleviate this limitation, a few methods utilized\nall pixel-wise support information via computing the pixel-wise correlations\nbetween paired query and support features implemented with the attention\nmechanism of Transformer. These approaches suffer from heavy computation on the\ndot-product attention between all pixels of support and query features. In this\npaper, we propose a simple yet effective framework built upon Transformer\ntermed as ProtoFormer to fully capture spatial details in query features. It\nviews the abstracted prototype of the target class in support features as Query\nand the query features as Key and Value embeddings, which are input to the\nTransformer decoder. In this way, the spatial details can be better captured\nand the semantic features of target class in the query image can be focused.\nThe output of the Transformer-based module can be viewed as semantic-aware\ndynamic kernels to filter out the segmentation mask from the enriched query\nfeatures. Extensive experiments on PASCAL-$5^{i}$ and COCO-$20^{i}$ show that\nour ProtoFormer significantly advances the state-of-the-art methods.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Leilei Cao",
      "Yibo Guo",
      "Ye Yuan",
      "Qiangguo Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.14764"
  },
  {
    "id": "arXiv:2211.14768",
    "title": "Constrained Pure Exploration Multi-Armed Bandits with a Fixed Budget",
    "abstract": "We consider a constrained, pure exploration, stochastic multi-armed bandit\nformulation under a fixed budget. Each arm is associated with an unknown,\npossibly multi-dimensional distribution and is described by multiple attributes\nthat are a function of this distribution. The aim is to optimize a particular\nattribute subject to user-defined constraints on the other attributes. This\nframework models applications such as financial portfolio optimization, where\nit is natural to perform risk-constrained maximization of mean return. We\nassume that the attributes can be estimated using samples from the arms'\ndistributions and that these estimators satisfy suitable concentration\ninequalities. We propose an algorithm called \\textsc{Constrained-SR} based on\nthe Successive Rejects framework, which recommends an optimal arm and flags the\ninstance as being feasible or infeasible. A key feature of this algorithm is\nthat it is designed on the basis of an information theoretic lower bound for\ntwo-armed instances. We characterize an instance-dependent upper bound on the\nprobability of error under \\textsc{Constrained-SR}, that decays exponentially\nwith respect to the budget. We further show that the associated decay rate is\nnearly optimal relative to an information theoretic lower bound in certain\nspecial cases.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Fathima Zarin Faizal",
      "Jayakrishnan Nair"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14768"
  },
  {
    "id": "arXiv:2211.14769",
    "title": "Navigation as the Attacker Wishes? Towards Building Byzantine-Robust  Embodied Agents under Federated Learning",
    "abstract": "Federated embodied agent learning protects the data privacy of individual\nvisual environments by keeping data locally at each client (the individual\nenvironment) during training. However, since the local data is inaccessible to\nthe server under federated learning, attackers may easily poison the training\ndata of the local client to build a backdoor in the agent without notice.\nDeploying such an agent raises the risk of potential harm to humans, as the\nattackers may easily navigate and control the agent as they wish via the\nbackdoor. Towards Byzantine-robust federated embodied agent learning, in this\npaper, we study the attack and defense for the task of vision-and-language\nnavigation (VLN), where the agent is required to follow natural language\ninstructions to navigate indoor environments. First, we introduce a simple but\neffective attack strategy, Navigation as Wish (NAW), in which the malicious\nclient manipulates local trajectory data to implant a backdoor into the global\nmodel. Results on two VLN datasets (R2R and RxR) show that NAW can easily\nnavigate the deployed VLN agent regardless of the language instruction, without\naffecting its performance on normal test sets. Then, we propose a new\nPrompt-Based Aggregation (PBA) to defend against the NAW attack in federated\nVLN, which provides the server with a ''prompt'' of the vision-and-language\nalignment variance between the benign and malicious clients so that they can be\ndistinguished during training. We validate the effectiveness of the PBA method\non protecting the global model from the NAW attack, which outperforms other\nstate-of-the-art defense methods by a large margin in the defense metrics on\nR2R and RxR.",
    "descriptor": "",
    "authors": [
      "Yunchao Zhang",
      "Zonglin Di",
      "Kaiwen Zhou",
      "Cihang Xie",
      "Xin Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14769"
  },
  {
    "id": "arXiv:2211.14770",
    "title": "ReGrAt: Regularization in Graphs using Attention to handle class  imbalance",
    "abstract": "Node classification is an important task to solve in graph-based learning.\nEven though a lot of work has been done in this field, imbalance is neglected.\nReal-world data is not perfect, and is imbalanced in representations most of\nthe times. Apart from text and images, data can be represented using graphs,\nand thus addressing the imbalance in graphs has become of paramount importance.\nIn the context of node classification, one class has less examples than others.\nChanging data composition is a popular way to address the imbalance in node\nclassification. This is done by resampling the data to balance the dataset.\nHowever, that can sometimes lead to loss of information or add noise to the\ndataset. Therefore, in this work, we implicitly solve the problem by changing\nthe model loss. Specifically, we study how attention networks can help tackle\nimbalance. Moreover, we observe that using a regularizer to assign larger\nweights to minority nodes helps to mitigate this imbalance. We achieve State of\nthe Art results than the existing methods on several standard citation\nbenchmark datasets.",
    "descriptor": "",
    "authors": [
      "Neeraja Kirtane",
      "Jeshuren Chelladurai",
      "Balaraman Ravindran",
      "Ashish Tendulkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14770"
  },
  {
    "id": "arXiv:2211.14773",
    "title": "Class-aware Information for Logit-based Knowledge Distillation",
    "abstract": "Knowledge distillation aims to transfer knowledge to the student model by\nutilizing the predictions/features of the teacher model, and feature-based\ndistillation has recently shown its superiority over logit-based distillation.\nHowever, due to the cumbersome computation and storage of extra feature\ntransformation, the training overhead of feature-based methods is much higher\nthan that of logit-based distillation. In this work, we revisit the logit-based\nknowledge distillation, and observe that the existing logit-based distillation\nmethods treat the prediction logits only in the instance level, while many\nother useful semantic information is overlooked. To address this issue, we\npropose a Class-aware Logit Knowledge Distillation (CLKD) method, that extents\nthe logit distillation in both instance-level and class-level. CLKD enables the\nstudent model mimic higher semantic information from the teacher model, hence\nimproving the distillation performance. We further introduce a novel loss\ncalled Class Correlation Loss to force the student learn the inherent\nclass-level correlation of the teacher. Empirical comparisons demonstrate the\nsuperiority of the proposed method over several prevailing logit-based methods\nand feature-based methods, in which CLKD achieves compelling results on various\nvisual classification tasks and outperforms the state-of-the-art baselines.",
    "descriptor": "\nComments: 12 pages, 4 figures, 12 tables\n",
    "authors": [
      "Shuoxi Zhang",
      "Hanpeng Liu",
      "John E. Hopcroft",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14773"
  },
  {
    "id": "arXiv:2211.14777",
    "title": "Alignment-Enriched Tuning for Patch-Level Pre-trained Document Image  Models",
    "abstract": "Alignment between image and text has shown promising improvements on\npatch-level pre-trained document image models. However, investigating more\neffective or finer-grained alignment techniques during pre-training requires a\nlarge amount of computation cost and time. Thus, a question naturally arises:\nCould we fine-tune the pre-trained models adaptive to downstream tasks with\nalignment objectives and achieve comparable or better performance? In this\npaper, we propose a new model architecture with alignment-enriched tuning\n(dubbed AETNet) upon pre-trained document image models, to adapt downstream\ntasks with the joint task-specific supervised and alignment-aware contrastive\nobjective. Specifically, we introduce an extra visual transformer as the\nalignment-ware image encoder and an extra text transformer as the\nalignment-ware text encoder before multimodal fusion. We consider alignment in\nthe following three aspects: 1) document-level alignment by leveraging the\ncross-modal and intra-modal contrastive loss; 2) global-local alignment for\nmodeling localized and structural information in document images; and 3)\nlocal-level alignment for more accurate patch-level information. Experiments on\nvarious downstream tasks show that AETNet can achieve state-of-the-art\nperformance on various downstream tasks. Notably, AETNet consistently\noutperforms state-of-the-art pre-trained models, such as LayoutLMv3 with\nfine-tuning techniques, on three different downstream tasks.",
    "descriptor": "\nComments: Accepted by AAAI 2023. Code is available at this https URL\n",
    "authors": [
      "Lei Wang",
      "Jiabang He",
      "Xing Xu",
      "Ning Liu",
      "Hui Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14777"
  },
  {
    "id": "arXiv:2211.14779",
    "title": "Who is Gambling? Finding Cryptocurrency Gamblers Using Multi-modal  Retrieval Methods",
    "abstract": "With the popularity of cryptocurrencies and the remarkable development of\nblockchain technology, decentralized applications emerged as a revolutionary\nforce for the Internet. Meanwhile, decentralized applications have also\nattracted intense attention from the online gambling community, with more and\nmore decentralized gambling platforms created through the help of smart\ncontracts. Compared with conventional gambling platforms, decentralized\ngambling have transparent rules and a low participation threshold, attracting a\nsubstantial number of gamblers. In order to discover gambling behaviors and\nidentify the contracts and addresses involved in gambling, we propose a tool\ntermed ETHGamDet. The tool is able to automatically detect the smart contracts\nand addresses involved in gambling by scrutinizing the smart contract code and\naddress transaction records. Interestingly, we present a novel LightGBM model\nwith memory components, which possesses the ability to learn from its own\nmisclassifications. As a side contribution, we construct and release a\nlarge-scale gambling dataset at\nhttps://github.com/AwesomeHuang/Bitcoin-Gambling-Dataset to facilitate future\nresearch in this field. Empirically, ETHGamDet achieves a F1-score of 0.72 and\n0.89 in address classification and contract classification respectively, and\noffers novel and interesting insights.",
    "descriptor": "",
    "authors": [
      "Zhengjie Huang",
      "Zhenguang Liu",
      "Jianhai Chen",
      "Qinming He",
      "Shuang Wu",
      "Lei Zhu",
      "Meng Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.14779"
  },
  {
    "id": "arXiv:2211.14781",
    "title": "Architecture, Protocols, and Algorithms for Location-Aware Services in  Beyond 5G Networks",
    "abstract": "The automotive and railway industries are rapidly transforming with a strong\ndrive towards automation and digitalization, with the goal of increased\nconvenience, safety, efficiency, and sustainability. Since assisted and fully\nautomated automotive and train transport services increasingly rely on\nvehicle-to-everything communications, and high-accuracy real-time positioning,\nit is necessary to continuously maintain high-accuracy localization, even in\nocclusion scenes such as tunnels, urban canyons, or areas covered by dense\nfoliage. In this paper, we review the 5G positioning framework of the 3rd\nGeneration Partnership Project in terms of methods and architecture and propose\nenhancements to meet the stringent requirements imposed by the transport\nindustry. In particular, we highlight the benefit of fusing cellular and sensor\nmeasurements and discuss required architecture and protocol support for\nachieving this at the network side. We also propose a positioning framework to\nfuse cellular network measurements with measurements by onboard sensors. We\nillustrate the viability of the proposed fusion-based positioning approach\nusing a numerical example.",
    "descriptor": "\nComments: 7 pages, 5 figures, accepted for publication in IEEE Communications Standards Magazine\n",
    "authors": [
      "Peter Hammarberg",
      "Julia Vinogradova",
      "G\u00e1bor Fodor",
      "Ritesh Shreevastav",
      "Satyam Dwivedi",
      "Fredrik Gunnarsson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.14781"
  },
  {
    "id": "arXiv:2211.14782",
    "title": "Breaking Immutable: Information-Coupled Prototype Elaboration for  Few-Shot Object Detection",
    "abstract": "Few-shot object detection, expecting detectors to detect novel classes with a\nfew instances, has made conspicuous progress. However, the prototypes extracted\nby existing meta-learning based methods still suffer from insufficient\nrepresentative information and lack awareness of query images, which cannot be\nadaptively tailored to different query images. Firstly, only the support images\nare involved for extracting prototypes, resulting in scarce perceptual\ninformation of query images. Secondly, all pixels of all support images are\ntreated equally when aggregating features into prototype vectors, thus the\nsalient objects are overwhelmed by the cluttered background. In this paper, we\npropose an Information-Coupled Prototype Elaboration (ICPE) method to generate\nspecific and representative prototypes for each query image. Concretely, a\nconditional information coupling module is introduced to couple information\nfrom the query branch to the support branch, strengthening the query-perceptual\ninformation in support features. Besides, we design a prototype dynamic\naggregation module that dynamically adjusts intra-image and inter-image\naggregation weights to highlight the salient information useful for detecting\nquery images. Experimental results on both Pascal VOC and MS COCO demonstrate\nthat our method achieves state-of-the-art performance in almost all settings.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Xiaonan Lu",
      "Wenhui Diao",
      "Yongqiang Mao",
      "Junxi Li",
      "Peijin Wang",
      "Xian Sun",
      "Kun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14782"
  },
  {
    "id": "arXiv:2211.14785",
    "title": "Training Deep Learning Models for Massive MIMO CSI Feedback with Small  Datasets in New Environments",
    "abstract": "Deep learning (DL)-based channel state information (CSI) feedback has shown\npromising potential to improve spectrum efficiency in massive MIMO systems.\nHowever, practical DL approaches require a sizeable CSI dataset for each\nscenario, and require large storage for multiple learned models. To overcome\nthis costly barrier, we develop a solution for efficient training and\ndeployment enhancement of DL-based CSI feedback by exploiting a lightweight\ntranslation model to cope with new CSI environments and by proposing novel\ndataset augmentation based on domain knowledge. Specifically, we first develop\na deep unfolding CSI feedback network, SPTM2-ISTANet+, which employs spherical\nnormalization to address the challenge of path loss variation. We also\nintroduce an integration of a trainable measurement matrix and residual CSI\nrecovery blocks within SPTM2-ISTANet+ to improve efficiency and accuracy. Using\nSPTM2-ISTANet+ as the anchor feedback model, we propose an efficient\nscenario-adaptive CSI feedback architecture. This new CSI-TransNet exploits a\nplug-in module for CSI translation consisting of a sparsity aligning function\nand lightweight DL module to reuse pretrained models in unseen environments. To\nwork with small datasets, we propose a lightweight and general augmentation\nstrategy based on domain knowledge. Test results demonstrate the efficacy and\nefficiency of the proposed solution for accurate CSI feedback given limited\nmeasurements for unseen CSI environments.",
    "descriptor": "",
    "authors": [
      "Zhenyu Liu",
      "Zhi Ding"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.14785"
  },
  {
    "id": "arXiv:2211.14790",
    "title": "Devils in the Clouds: An Evolutionary Study of Telnet Bot Loaders",
    "abstract": "One of the innovations brought by Mirai and its derived malware is the\nadoption of self-contained loaders for infecting IoT devices and recruiting\nthem in botnets. Functionally decoupled from other botnet components and not\nembedded in the payload, loaders cannot be analysed using conventional\napproaches that rely on honeypots for capturing samples. Different approaches\nare necessary for studying the loaders evolution and defining a genealogy. To\naddress the insufficient knowledge about loaders' lineage in existing studies,\nin this paper, we propose a semantic-aware method to measure, categorize, and\ncompare different loader servers, with the goal of highlighting their\nevolution, independent from the payload evolution. Leveraging behavior-based\nmetrics, we cluster the discovered loaders and define eight families to\ndetermine the genealogy and draw a homology map. Our study shows that the\nsource code of Mirai is evolving and spawning new botnets with new\ncapabilities, both on the client side and the server side. In turn, shedding\nlight on the infection loaders can help the cybersecurity community to improve\ndetection and prevention tools.",
    "descriptor": "\nComments: 10 pages, 5 figures, ICC 2023. arXiv admin note: text overlap with arXiv:2206.00385\n",
    "authors": [
      "Yuhui Zhu",
      "Zhenxiang Chen",
      "Qiben Yan",
      "Shanshan Wang",
      "Alberto Giaretta",
      "Enlong Li",
      "Lizhi Peng",
      "Chuan Zhao",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.14790"
  },
  {
    "id": "arXiv:2211.14793",
    "title": "A Data-driven Pricing Scheme for Optimal Routing through Artificial  Currencies",
    "abstract": "Mobility systems often suffer from a high price of anarchy due to the\nuncontrolled behavior of selfish users. This may result in societal costs that\nare significantly higher compared to what could be achieved by a centralized\nsystem-optimal controller. Monetary tolling schemes can effectively align the\nbehavior of selfish users with the system-optimum. Yet, they inevitably\ndiscriminate the population in terms of income. Artificial currencies were\nrecently presented as an effective alternative that can achieve the same\nperformance, whilst guaranteeing fairness among the population. However, those\nstudies were based on behavioral models that may differ from practical\nimplementations. This paper presents a data-driven approach to automatically\nadapt artificial-currency tolls within repetitive-game settings. We first\nconsider a parallel-arc setting whereby users commute on a daily basis from a\nunique origin to a unique destination, choosing a route in exchange of an\nartificial-currency price or reward while accounting for the impact of the\nchoices of the other users on travel discomfort. Second, we devise a\nmodel-based reinforcement learning controller that autonomously learns the\noptimal pricing policy by interacting with the proposed framework considering\nthe closeness of the observed aggregate flows to a desired system-optimal\ndistribution as a reward function. Our numerical results show that the proposed\ndata-driven pricing scheme can effectively align the users' flows with the\nsystem optimum, significantly reducing the societal costs with respect to the\nuncontrolled flows (by about 15% and 25% depending on the scenario), and\nrespond to environmental changes in a robust and efficient manner.",
    "descriptor": "",
    "authors": [
      "David van de Sanden",
      "Maarten Schoukens",
      "Mauro Salazar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14793"
  },
  {
    "id": "arXiv:2211.14794",
    "title": "Traditional Classification Neural Networks are Good Generators: They are  Competitive with DDPMs and GANs",
    "abstract": "Classifiers and generators have long been separated. We break down this\nseparation and showcase that conventional neural network classifiers can\ngenerate high-quality images of a large number of categories, being comparable\nto the state-of-the-art generative models (e.g., DDPMs and GANs). We achieve\nthis by computing the partial derivative of the classification loss function\nwith respect to the input to optimize the input to produce an image. Since it\nis widely known that directly optimizing the inputs is similar to targeted\nadversarial attacks incapable of generating human-meaningful images, we propose\na mask-based stochastic reconstruction module to make the gradients\nsemantic-aware to synthesize plausible images. We further propose a\nprogressive-resolution technique to guarantee fidelity, which produces\nphotorealistic images. Furthermore, we introduce a distance metric loss and a\nnon-trivial distribution loss to ensure classification neural networks can\nsynthesize diverse and high-fidelity images. Using traditional neural network\nclassifiers, we can generate good-quality images of 256$\\times$256 resolution\non ImageNet. Intriguingly, our method is also applicable to text-to-image\ngeneration by regarding image-text foundation models as generalized\nclassifiers.\nProving that classifiers have learned the data distribution and are ready for\nimage generation has far-reaching implications, for classifiers are much easier\nto train than generative models like DDPMs and GANs. We don't even need to\ntrain classification models because tons of public ones are available for\ndownload. Also, this holds great potential for the interpretability and\nrobustness of classifiers.",
    "descriptor": "\nComments: This paper has 29 pages with 22 figures, including rich supplementary information\n",
    "authors": [
      "Guangrun Wang",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14794"
  },
  {
    "id": "arXiv:2211.14797",
    "title": "Latent SHAP: Toward Practical Human-Interpretable Explanations",
    "abstract": "Model agnostic feature attribution algorithms (such as SHAP and LIME) are\nubiquitous techniques for explaining the decisions of complex classification\nmodels, such as deep neural networks. However, since complex classification\nmodels produce superior performance when trained on low-level (or encoded)\nfeatures, in many cases, the explanations generated by these algorithms are\nneither interpretable nor usable by humans. Methods proposed in recent studies\nthat support the generation of human-interpretable explanations are\nimpractical, because they require a fully invertible transformation function\nthat maps the model's input features to the human-interpretable features. In\nthis work, we introduce Latent SHAP, a black-box feature attribution framework\nthat provides human-interpretable explanations, without the requirement for a\nfully invertible transformation function. We demonstrate Latent SHAP's\neffectiveness using (1) a controlled experiment where invertible transformation\nfunctions are available, which enables robust quantitative evaluation of our\nmethod, and (2) celebrity attractiveness classification (using the CelebA\ndataset) where invertible transformation functions are not available, which\nenables thorough qualitative evaluation of our method.",
    "descriptor": "",
    "authors": [
      "Ron Bitton",
      "Alon Malach",
      "Amiel Meiseles",
      "Satoru Momiyama",
      "Toshinori Araki",
      "Jun Furukawa",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14797"
  },
  {
    "id": "arXiv:2211.14799",
    "title": "Sampling Neural Radiance Fields for Refractive Objects",
    "abstract": "Recently, differentiable volume rendering in neural radiance fields (NeRF)\nhas gained a lot of popularity, and its variants have attained many impressive\nresults. However, existing methods usually assume the scene is a homogeneous\nvolume so that a ray is cast along the straight path. In this work, the scene\nis instead a heterogeneous volume with a piecewise-constant refractive index,\nwhere the path will be curved if it intersects the different refractive\nindices. For novel view synthesis of refractive objects, our NeRF-based\nframework aims to optimize the radiance fields of bounded volume and boundary\nfrom multi-view posed images with refractive object silhouettes. To tackle this\nchallenging problem, the refractive index of a scene is reconstructed from\nsilhouettes. Given the refractive index, we extend the stratified and\nhierarchical sampling techniques in NeRF to allow drawing samples along a\ncurved path tracked by the Eikonal equation. The results indicate that our\nframework outperforms the state-of-the-art method both quantitatively and\nqualitatively, demonstrating better performance on the perceptual similarity\nmetric and an apparent improvement in the rendering quality on several\nsynthetic and real scenes.",
    "descriptor": "\nComments: SIGGRAPH Asia 2022 Technical Communications. 4 pages, 4 figures, 1 table. Project: this https URL Code: this https URL\n",
    "authors": [
      "Jen-I Pan",
      "Jheng-Wei Su",
      "Kai-Wen Hsiao",
      "Ting-Yu Yen",
      "Hung-Kuo Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14799"
  },
  {
    "id": "arXiv:2211.14802",
    "title": "Neural Font Rasterization",
    "abstract": "Recent advances in deep learning techniques and applications have\nrevolutionized artistic creation and manipulation in many domains (text,\nimages, music); however, fonts have not yet been integrated with deep learning\narchitectures in a manner that supports their multi-scale nature. In this work\nwe aim to bridge this gap, proposing a network architecture capable of\nrasterizing glyphs in multiple sizes, potentially paving the way for easy and\naccessible creation and manipulation of fonts.",
    "descriptor": "",
    "authors": [
      "Daniel Anderson",
      "Ariel Shamir",
      "Ohad Fried"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14802"
  },
  {
    "id": "arXiv:2211.14805",
    "title": "Rethinking Data Augmentation for Single-source Domain Generalization in  Medical Image Segmentation",
    "abstract": "Single-source domain generalization (SDG) in medical image segmentation is a\nchallenging yet essential task as domain shifts are quite common among clinical\nimage datasets. Previous attempts most conduct global-only/random augmentation.\nTheir augmented samples are usually insufficient in diversity and\ninformativeness, thus failing to cover the possible target domain distribution.\nIn this paper, we rethink the data augmentation strategy for SDG in medical\nimage segmentation. Motivated by the class-level representation invariance and\nstyle mutability of medical images, we hypothesize that unseen target data can\nbe sampled from a linear combination of $C$ (the class number) random\nvariables, where each variable follows a location-scale distribution at the\nclass level. Accordingly, data augmented can be readily made by sampling the\nrandom variables through a general form. On the empirical front, we implement\nsuch strategy with constrained B$\\acute{\\rm e}$zier transformation on both\nglobal and local (i.e. class-level) regions, which can largely increase the\naugmentation diversity. A Saliency-balancing Fusion mechanism is further\nproposed to enrich the informativeness by engaging the gradient information,\nguiding augmentation with proper orientation and magnitude. As an important\ncontribution, we prove theoretically that our proposed augmentation can lead to\nan upper bound of the generalization risk on the unseen target domain, thus\nconfirming our hypothesis. Combining the two strategies, our Saliency-balancing\nLocation-scale Augmentation (SLAug) exceeds the state-of-the-art works by a\nlarge margin in two challenging SDG tasks. Code is available at\nhttps://github.com/Kaiseem/SLAug .",
    "descriptor": "",
    "authors": [
      "Zixian Su",
      "Kai Yao",
      "Xi Yang",
      "Qiufeng Wang",
      "Jie Sun",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14805"
  },
  {
    "id": "arXiv:2211.14806",
    "title": "Targeted Demand Response: Formulation, LMP Implications, and Fast  Algorithms",
    "abstract": "Demand response (DR) is regarded as a solution to the issue of high\nelectricity prices in the wholesale market, as the flexibility of the demand\ncan be harnessed to lower the demand level for price reductions. As an\nacross-the-board DR in a system is impractical due to the enrollment budget for\ninstance, it is necessary to select a small group of nodes for DR implementing.\nCurrent studies resort to intuitive yet naive approaches for DR targeting, as\nprice is implicitly associated with demand, though optimality cannot be\nensured. In this paper, we derive such a relationship in the\nsecurity-constrained economic dispatch via the multi-parametric programming\ntheory, based on which the DR targeting problem is rigorously formulated as a\nmixed-integer quadratic programming problem aiming at reducing the averaged\nprice to a reference level by efficiently reducing targeted nodes' demand. A\nsolution strategy is proposed to accelerate the computation. Numerical studies\ndemonstrate compared with the benchmarking strategy, the proposed approach can\nreduce the price to the reference point with less efforts in demand reduction.\nBesides, we empirically show that the proposed approach is immune to inaccurate\nsystem parameters, and can be generalized to variants of DR targeting tasks.",
    "descriptor": "\nComments: submitted to IEEE Transactions on Power Systems\n",
    "authors": [
      "Yufan Zhang",
      "Honglin Wen",
      "Tao Feng",
      "Yize Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14806"
  },
  {
    "id": "arXiv:2211.14807",
    "title": "Universal convex covering problems under translation and discrete  rotations",
    "abstract": "We consider the smallest-area universal covering of planar objects of\nperimeter 2 (or equivalently closed curves of length 2) allowing translation\nand discrete rotations. In particular, we show that the solution is an\nequilateral triangle of height 1 when translation and discrete rotation of\n$\\pi$ are allowed. Our proof is purely geometric and elementary. We also give\nconvex coverings of closed curves of length 2 under translation and discrete\nrotations of multiples of $\\pi/2$ and $2\\pi/3$. We show a minimality of the\ncovering for discrete rotation of multiples of $\\pi/2$, which is an equilateral\ntriangle of height smaller than 1, and conjecture that the covering is the\nsmallest-area convex covering. Finally, we give the smallest-area convex\ncoverings of all unit segments under translation and discrete rotations\n$2\\pi/k$ for all integers $k\\ge 3$.",
    "descriptor": "",
    "authors": [
      "Mook Kwon Jung",
      "Sang Duk Yoon",
      "Hee-Kap Ahn",
      "Takeshi Tokuyama"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.14807"
  },
  {
    "id": "arXiv:2211.14810",
    "title": "A Kernel Perspective of Skip Connections in Convolutional Networks",
    "abstract": "Over-parameterized residual networks (ResNets) are amongst the most\nsuccessful convolutional neural architectures for image processing. Here we\nstudy their properties through their Gaussian Process and Neural Tangent\nkernels. We derive explicit formulas for these kernels, analyze their spectra,\nand provide bounds on their implied condition numbers. Our results indicate\nthat (1) with ReLU activation, the eigenvalues of these residual kernels decay\npolynomially at a similar rate compared to the same kernels when skip\nconnections are not used, thus maintaining a similar frequency bias; (2)\nhowever, residual kernels are more locally biased. Our analysis further shows\nthat the matrices obtained by these residual kernels yield favorable condition\nnumbers at finite depths than those obtained without the skip connections,\nenabling therefore faster convergence of training with gradient descent.",
    "descriptor": "",
    "authors": [
      "Daniel Barzilai",
      "Amnon Geifman",
      "Meirav Galun",
      "Ronen Basri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14810"
  },
  {
    "id": "arXiv:2211.14813",
    "title": "SegCLIP: Patch Aggregation with Learnable Centers for Open-Vocabulary  Semantic Segmentation",
    "abstract": "Recently, the contrastive language-image pre-training, e.g., CLIP, has\ndemonstrated promising results on various downstream tasks. The pre-trained\nmodel can capture enriched visual concepts for images by learning from a large\nscale of text-image data. However, transferring the learned visual knowledge to\nopen-vocabulary semantic segmentation is still under-explored. In this paper,\nwe propose a CLIP-based model named SegCLIP for the topic of open-vocabulary\nsegmentation in an annotation-free manner. The SegCLIP achieves segmentation\nbased on ViT and the main idea is to gather patches with learnable centers to\nsemantic regions through training on text-image pairs. The gathering operation\ncan dynamically capture the semantic groups, which can be used to generate the\nfinal segmentation results. We further propose a reconstruction loss on masked\npatches and a superpixel-based KL loss with pseudo-labels to enhance the visual\nrepresentation. Experimental results show that our model achieves comparable or\nsuperior segmentation accuracy on the PASCAL VOC 2012 (+1.4% mIoU), PASCAL\nContext (+2.4% mIoU), and COCO (+5.6% mIoU) compared with baselines. We release\nthe code at https://github.com/ArrowLuo/SegCLIP.",
    "descriptor": "",
    "authors": [
      "Huaishao Luo",
      "Junwei Bao",
      "Youzheng Wu",
      "Xiaodong He",
      "Tianrui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14813"
  },
  {
    "id": "arXiv:2211.14818",
    "title": "Speeding-up Symbol-Level Precoding Using Separable and Dual  Optimizations",
    "abstract": "Symbol-level precoding (SLP) manipulates the transmitted signals to\naccurately exploit the multi-user interference (MUI) in the multi-user\ndownlink. This enables that all the resultant interference contributes to\ncorrect detection, which is the so-called constructive interference (CI). Its\nperformance superiority comes at the cost of solving a nonlinear optimization\nproblem on a symbol-by-symbol basis, for which the resulting complexity becomes\nprohibitive in realistic wireless communication systems. In this paper, we\ninvestigate low-complexity SLP algorithms for both phase-shift keying (PSK) and\nquadrature amplitude modulation (QAM). Specifically, we first prove that the\nmax-min SINR balancing (SB) SLP problem for PSK signaling is not separable,\nwhich is contrary to the power minimization (PM) SLP problem, and accordingly,\nexisting decomposition methods are not applicable. Next, we establish an\nexplicit duality between the PM-SLP and SB-SLP problems for PSK modulation. The\nproposed duality facilitates obtaining the solution to the SB-SLP given the\nsolution to the PM-SLP without the need for one-dimension search, and vice\nversa. We then propose a closed-form power scaling algorithm to solve the\nSB-SLP via PM-SLP to take advantage of the separability of the PM-SLP. As for\nQAM modulation, we convert the PM-SLP problem into a separable equivalent\noptimization problem, and decompose the new problem into several simple\nparallel subproblems with closed-form solutions, leveraging the proximal\nJacobian alternating direction method of multipliers (PJ-ADMM). We further\nprove that the proposed duality can be generalized to the multi-level\nmodulation case, based on which a power scaling parallel inverse-free algorithm\nis also proposed to solve the SB-SLP for QAM signaling. Numerical results show\nthat the proposed algorithms offer optimal performance with lower complexity\nthan the state-of-the-art.",
    "descriptor": "\nComments: 30 pages, 11 figures\n",
    "authors": [
      "Junwen Yang",
      "Ang Li",
      "Xuewen Liao",
      "Christos Masouros"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.14818"
  },
  {
    "id": "arXiv:2211.14819",
    "title": "Deep Active Learning for Computer Vision: Past and Future",
    "abstract": "As an important data selection schema, active learning emerges as the\nessential component when iterating an Artificial Intelligence (AI) model. It\nbecomes even more critical given the dominance of deep neural network based\nmodels, which are composed of a large number of parameters and data hungry, in\napplication. Despite its indispensable role for developing AI models, research\non active learning is not as intensive as other research directions. In this\npaper, we present a review of active learning through deep active learning\napproaches from the following perspectives: 1) technical advancements in active\nlearning, 2) applications of active learning in computer vision, 3) industrial\nsystems leveraging or with potential to leverage active learning for data\niteration, 4) current limitations and future research directions. We expect\nthis paper to clarify the significance of active learning in a modern AI model\nmanufacturing process and to bring additional research attention to active\nlearning. By addressing data automation challenges and coping with automated\nmachine learning systems, active learning will facilitate democratization of AI\ntechnologies by boosting model production at scale.",
    "descriptor": "",
    "authors": [
      "Rinyoichi Takezoe",
      "Xu Liu",
      "Shunan Mao",
      "Marco Tianyu Chen",
      "Zhanpeng Feng",
      "Shiliang Zhang",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14819"
  },
  {
    "id": "arXiv:2211.14821",
    "title": "Towards Realistic Underwater Dataset Generation and Color Restoration",
    "abstract": "Recovery of true color from underwater images is an ill-posed problem. This\nis because the wide-band attenuation coefficients for the RGB color channels\ndepend on object range, reflectance, etc. which are difficult to model. Also,\nthere is backscattering due to suspended particles in water. Thus, most\nexisting deep-learning based color restoration methods, which are trained on\nsynthetic underwater datasets, do not perform well on real underwater data.\nThis can be attributed to the fact that synthetic data cannot accurately\nrepresent real conditions. To address this issue, we use an image to image\ntranslation network to bridge the gap between the synthetic and real domains by\ntranslating images from synthetic underwater domain to real underwater domain.\nUsing this multimodal domain adaptation technique, we create a dataset that can\ncapture a diverse array of underwater conditions. We then train a simple but\neffective CNN based network on our domain adapted dataset to perform color\nrestoration. Code and pre-trained models can be accessed at\nhttps://github.com/nehamjain10/TRUDGCR",
    "descriptor": "",
    "authors": [
      "Neham Jain",
      "Gopi Matta",
      "Kaushik Mitra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.14821"
  },
  {
    "id": "arXiv:2211.14822",
    "title": "Adjustable Method Based on Body Parts for Improving the Accuracy of 3D  Reconstruction in Visually Important Body Parts from Silhouettes",
    "abstract": "This research proposes a novel adjustable algorithm for reconstructing 3D\nbody shapes from front and side silhouettes. Most recent silhouette-based\napproaches use a deep neural network trained by silhouettes and key points to\nestimate the shape parameters but cannot accurately fit the model to the body\ncontours and consequently are struggling to cover detailed body geometry,\nespecially in the torso. In addition, in most of these cases, body parts have\nthe same accuracy priority, making the optimization harder and avoiding\nreaching the optimum possible result in essential body parts, like the torso,\nwhich is visually important in most applications, such as virtual garment\nfitting. In the proposed method, we can adjust the expected accuracy for each\nbody part based on our purpose by assigning coefficients for the distance of\neach body part between the projected 3D body and 2D silhouettes. To measure\nthis distance, we first recognize the correspondent body parts using body\nsegmentation in both views. Then, we align individual body parts by 2D rigid\nregistration and match them using pairwise matching. The objective function\ntries to minimize the distance cost for the individual body parts in both views\nbased on distances and coefficients by optimizing the statistical model\nparameters. We also handle the slight variation in the degree of arms and limbs\nby matching the pose. We evaluate the proposed method with synthetic body\nmeshes from the normalized S-SCAPE. The result shows that the algorithm can\nmore accurately reconstruct visually important body parts with high\ncoefficients.",
    "descriptor": "\nComments: 16 pages, 17 images\n",
    "authors": [
      "Aref Hemati",
      "Azam Bastanfard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14822"
  },
  {
    "id": "arXiv:2211.14823",
    "title": "3D Scene Creation and Rendering via Rough Meshes: A Lighting Transfer  Avenue",
    "abstract": "This paper studies how to flexibly integrate reconstructed 3D models into\npractical 3D modeling pipelines such as 3D scene creation and rendering. Due to\nthe technical difficulty, one can only obtain rough 3D models (R3DMs) for most\nreal objects using existing 3D reconstruction techniques. As a result,\nphysically-based rendering (PBR) would render low-quality images or videos for\nscenes that are constructed by R3DMs. One promising solution would be\nrepresenting real-world objects as Neural Fields such as NeRFs, which are able\nto generate photo-realistic renderings of an object under desired viewpoints.\nHowever, a drawback is that the synthesized views through Neural Fields\nRendering (NFR) cannot reflect the simulated lighting details on R3DMs in PBR\npipelines, especially when object interactions in the 3D scene creation cause\nlocal shadows. To solve this dilemma, we propose a lighting transfer network\n(LighTNet) to bridge NFR and PBR, such that they can benefit from each other.\nLighTNet reasons about a simplified image composition model, remedies the\nuneven surface issue caused by R3DMs, and is empowered by several\nperceptual-motivated constraints and a new Lab angle loss which enhances the\ncontrast between lighting strength and colors. Comparisons demonstrate that\nLighTNet is superior in synthesizing impressive lighting, and is promising in\npushing NFR further in practical 3D modeling workflows. Project page:\nhttps://3d-front-future.github.io/LighTNet .",
    "descriptor": "",
    "authors": [
      "Yujie Li",
      "Bowen Cai",
      "Yuqin Liang",
      "Rongfei Jia",
      "Binqiang Zhao",
      "Mingming Gong",
      "Huan Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14823"
  },
  {
    "id": "arXiv:2211.14825",
    "title": "Dynamic Kernel Sparsifiers",
    "abstract": "A geometric graph associated with a set of points $P= \\{x_1, x_2, \\cdots, x_n\n\\} \\subset \\mathbb{R}^d$ and a fixed kernel function\n$\\mathsf{K}:\\mathbb{R}^d\\times \\mathbb{R}^d\\to\\mathbb{R}_{\\geq 0}$ is a\ncomplete graph on $P$ such that the weight of edge $(x_i, x_j)$ is\n$\\mathsf{K}(x_i, x_j)$. We present a fully-dynamic data structure that\nmaintains a spectral sparsifier of a geometric graph under updates that change\nthe locations of points in $P$ one at a time. The update time of our data\nstructure is $n^{o(1)}$ with high probability, and the initialization time is\n$n^{1+o(1)}$. Under certain assumption, we can provide a fully dynamic spectral\nsparsifier with the robostness to adaptive adversary.\nWe further show that, for the Laplacian matrices of these geometric graphs,\nit is possible to maintain random sketches for the results of matrix vector\nmultiplication and inverse-matrix vector multiplication in $n^{o(1)}$ time,\nunder updates that change the locations of points in $P$ or change the query\nvector by a sparse difference.",
    "descriptor": "",
    "authors": [
      "Yichuan Deng",
      "Wenyu Jin",
      "Zhao Song",
      "Xiaorui Sun",
      "Omri Weinstein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.14825"
  },
  {
    "id": "arXiv:2211.14827",
    "title": "Domain Generalization for Robust Model-Based Offline Reinforcement  Learning",
    "abstract": "Existing offline reinforcement learning (RL) algorithms typically assume that\ntraining data is either: 1) generated by a known policy, or 2) of entirely\nunknown origin. We consider multi-demonstrator offline RL, a middle ground\nwhere we know which demonstrators generated each dataset, but make no\nassumptions about the underlying policies of the demonstrators. This is the\nmost natural setting when collecting data from multiple human operators, yet\nremains unexplored. Since different demonstrators induce different data\ndistributions, we show that this can be naturally framed as a domain\ngeneralization problem, with each demonstrator corresponding to a different\ndomain. Specifically, we propose Domain-Invariant Model-based Offline RL\n(DIMORL), where we apply Risk Extrapolation (REx) (Krueger et al., 2020) to the\nprocess of learning dynamics and rewards models. Our results show that models\ntrained with REx exhibit improved domain generalization performance when\ncompared with the natural baseline of pooling all demonstrators' data. We\nobserve that the resulting models frequently enable the learning of superior\npolicies in the offline model-based RL setting, can improve the stability of\nthe policy learning process, and potentially enable increased exploration.",
    "descriptor": "\nComments: Accepted to the NeurIPS 2022 Workshops on Distribution Shifts and Offline Reinforcement Learning\n",
    "authors": [
      "Alan Clark",
      "Shoaib Ahmed Siddiqui",
      "Robert Kirk",
      "Usman Anwar",
      "Stephen Chung",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14827"
  },
  {
    "id": "arXiv:2211.14828",
    "title": "Towards Efficient and Accurate Approximation: Tensor Decomposition Based  on Randomized Block Krylov Iteration",
    "abstract": "Efficient and accurate low-rank approximation (LRA) methods are of great\nsignificance for large-scale data analysis. Randomized tensor decompositions\nhave emerged as powerful tools to meet this need, but most existing methods\nperform poorly in the presence of noise interference. Inspired by the\nremarkable performance of randomized block Krylov iteration (rBKI) in reducing\nthe effect of tail singular values, this work designs an rBKI-based Tucker\ndecomposition (rBKI-TK) for accurate approximation, together with a\nhierarchical tensor ring decomposition based on rBKI-TK for efficient\ncompression of large-scale data. Besides, the error bound between the\ndeterministic LRA and the randomized LRA is studied. Numerical experiences\ndemonstrate the efficiency, accuracy and scalability of the proposed methods in\nboth data compression and denoising.",
    "descriptor": "",
    "authors": [
      "Yichun Qiu",
      "Weijun Sun",
      "Guoxu Zhou",
      "Qibin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14828"
  },
  {
    "id": "arXiv:2211.14829",
    "title": "AWTE-BERT:Attending to Wordpiece Tokenization Explicitly on BERT for  Joint Intent Classification and SlotFilling",
    "abstract": "Intent classification and slot filling are two core tasks in natural language\nunderstanding (NLU). The interaction nature of the two tasks makes the joint\nmodels often outperform the single designs. One of the promising solutions,\ncalled BERT (Bidirectional Encoder Representations from Transformers), achieves\nthe joint optimization of the two tasks. BERT adopts the wordpiece to tokenize\neach input token into multiple sub-tokens, which causes a mismatch between the\ntokens and the labels lengths. Previous methods utilize the hidden states\ncorresponding to the first sub-token as input to the classifier, which limits\nperformance improvement since some hidden semantic informations is discarded in\nthe fine-tune process. To address this issue, we propose a novel joint model\nbased on BERT, which explicitly models the multiple sub-tokens features after\nwordpiece tokenization, thereby generating the context features that contribute\nto slot filling. Specifically, we encode the hidden states corresponding to\nmultiple sub-tokens into a context vector via the attention mechanism. Then, we\nfeed each context vector into the slot filling encoder, which preserves the\nintegrity of the sentence. Experimental results demonstrate that our proposed\nmodel achieves significant improvement on intent classification accuracy, slot\nfilling F1, and sentence-level semantic frame accuracy on two public benchmark\ndatasets. The F1 score of the slot filling in particular has been improved from\n96.1 to 98.2 (2.1% absolute) on the ATIS dataset.",
    "descriptor": "",
    "authors": [
      "Yu Guo",
      "Zhilong Xie",
      "Xingyan Chen",
      "Leilei Wang",
      "Gang Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14829"
  },
  {
    "id": "arXiv:2211.14831",
    "title": "Combined Peak Reduction and Self-Consumption Using Proximal Policy  Optimization",
    "abstract": "Residential demand response programs aim to activate demand flexibility at\nthe household level. In recent years, reinforcement learning (RL) has gained\nsignificant attention for these type of applications. A major challenge of RL\nalgorithms is data efficiency. New RL algorithms, such as proximal policy\noptimisation (PPO), have tried to increase data efficiency. Additionally,\ncombining RL with transfer learning has been proposed in an effort to mitigate\nthis challenge. In this work, we further improve upon state-of-the-art transfer\nlearning performance by incorporating demand response domain knowledge into the\nlearning pipeline. We evaluate our approach on a demand response use case where\npeak shaving and self-consumption is incentivised by means of a capacity\ntariff. We show our adapted version of PPO, combined with transfer learning,\nreduces cost by 14.51% compared to a regular hysteresis controller and by 6.68%\ncompared to traditional PPO.",
    "descriptor": "\nComments: Submitted to Elsevier Energy and AI\n",
    "authors": [
      "Thijs Peirelinck",
      "Chris Hermans",
      "Fred Spiessens",
      "Geert Deconinck"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14831"
  },
  {
    "id": "arXiv:2211.14835",
    "title": "CLID: Controlled-Length Image Descriptions with Limited Data",
    "abstract": "Controllable image captioning models generate human-like image descriptions,\nenabling some kind of control over the generated captions. This paper focuses\non controlling the caption length, i.e. a short and concise description or a\nlong and detailed one. Since existing image captioning datasets contain mostly\nshort captions, generating long captions is challenging. To address the\nshortage of long training examples, we propose to enrich the dataset with\nvarying-length self-generated captions. These, however, might be of varying\nquality and are thus unsuitable for conventional training. We introduce a novel\ntraining strategy that selects the data points to be used at different times\nduring the training. Our method dramatically improves the length-control\nabilities, while exhibiting SoTA performance in terms of caption quality. Our\napproach is general and is shown to be applicable also to paragraph generation.",
    "descriptor": "",
    "authors": [
      "Elad Hirsch",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14835"
  },
  {
    "id": "arXiv:2211.14837",
    "title": "Numerical analysis of a time discretized method for nonlinear filtering  problem with L\u00e9vy process observations",
    "abstract": "In this paper, we consider a nonlinear filtering model with observations\ndriven by correlated Wiener processes and point processes. We first derive a\nZakai equation whose solution is a unnormalized probability density function of\nthe filter solution. Then we apply a splitting-up technique to decompose the\nZakai equation into three stochastic differential equations, based on which we\nconstruct a splitting-up approximate solution and prove its half-order\nconvergence. Furthermore, we apply a finite difference method to construct a\ntime semi-discrete approximate solution to the splitting-up system and prove\nits half-order convergence to the exact solution of the Zakai equation.\nFinally, we present some numerical experiments to demonstrate the theoretical\nanalysis.",
    "descriptor": "",
    "authors": [
      "Fengshan Zhang",
      "Yongkui Zou",
      "Shimin Chai",
      "Yanzhao Cao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.14837"
  },
  {
    "id": "arXiv:2211.14838",
    "title": "PUnifiedNER: a Prompting-based Unified NER System for Diverse Datasets",
    "abstract": "Much of named entity recognition (NER) research focuses on developing\ndataset-specific models based on data from the domain of interest, and a\nlimited set of related entity types. This is frustrating as each new dataset\nrequires a new model to be trained and stored. In this work, we present a\n``versatile'' model -- the Prompting-based Unified NER system (PUnifiedNER) --\nthat works with data from different domains and can recognise up to 37 entity\ntypes simultaneously, and theoretically it could be as many as possible. By\nusing prompt learning, PUnifiedNER is a novel approach that is able to jointly\ntrain across multiple corpora, implementing intelligent on-demand entity\nrecognition. Experimental results show that PUnifiedNER leads to significant\nprediction benefits compared to dataset-specific models with impressively\nreduced model deployment costs. Furthermore, the performance of PUnifiedNER can\nachieve competitive or even better performance than state-of-the-art\ndomain-specific methods for some datasets. We also perform comprehensive pilot\nand ablation studies to support in-depth analysis of each component in\nPUnifiedNER.",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Jinghui Lu",
      "Rui Zhao",
      "Brian Mac Namee",
      "Fei Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14838"
  },
  {
    "id": "arXiv:2211.14839",
    "title": "Waveflow: Enforcing boundary conditions in smooth normalizing flows with  application to fermionic wave functions",
    "abstract": "In this paper, we introduce four main novelties: First, we present a new way\nof handling the topology problem of normalizing flows. Second, we describe a\ntechnique to enforce certain classes of boundary conditions onto normalizing\nflows. Third, we introduce the I-Spline bijection, which, similar to previous\nwork, leverages splines but, in contrast to those works, can be made\narbitrarily often differentiable. And finally, we use these techniques to\ncreate Waveflow, an Ansatz for the one-space-dimensional multi-particle\nfermionic wave functions in real space based on normalizing flows, that can be\nefficiently trained with Variational Quantum Monte Carlo without the need for\nMCMC nor estimation of a normalization constant. To enforce the necessary\nanti-symmetry of fermionic wave functions, we train the normalizing flow only\non the fundamental domain of the permutation group, which effectively reduces\nit to a boundary value problem.",
    "descriptor": "\nComments: 27 pages, 11 figures\n",
    "authors": [
      "Luca Thiede",
      "Chong Sun",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.14839"
  },
  {
    "id": "arXiv:2211.14842",
    "title": "Unified Discrete Diffusion for Simultaneous Vision-Language Generation",
    "abstract": "The recently developed discrete diffusion models perform extraordinarily well\nin the text-to-image task, showing significant promise for handling the\nmulti-modality signals. In this work, we harness these traits and present a\nunified multimodal generation model that can conduct both the \"modality\ntranslation\" and \"multi-modality generation\" tasks using a single model,\nperforming text-based, image-based, and even vision-language simultaneous\ngeneration. Specifically, we unify the discrete diffusion process for\nmultimodal signals by proposing a unified transition matrix. Moreover, we\ndesign a mutual attention module with fused embedding layer and a unified\nobjective function to emphasise the inter-modal linkages, which are vital for\nmulti-modality generation. Extensive experiments indicate that our proposed\nmethod can perform comparably to the state-of-the-art solutions in various\ngeneration tasks.",
    "descriptor": "",
    "authors": [
      "Minghui Hu",
      "Chuanxia Zheng",
      "Heliang Zheng",
      "Tat-Jen Cham",
      "Chaoyue Wang",
      "Zuopeng Yang",
      "Dacheng Tao",
      "Ponnuthurai N. Suganthan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14842"
  },
  {
    "id": "arXiv:2211.14843",
    "title": "Learning Object-Language Alignments for Open-Vocabulary Object Detection",
    "abstract": "Existing object detection methods are bounded in a fixed-set vocabulary by\ncostly labeled data. When dealing with novel categories, the model has to be\nretrained with more bounding box annotations. Natural language supervision is\nan attractive alternative for its annotation-free attributes and broader object\nconcepts. However, learning open-vocabulary object detection from language is\nchallenging since image-text pairs do not contain fine-grained object-language\nalignments. Previous solutions rely on either expensive grounding annotations\nor distilling classification-oriented vision models. In this paper, we propose\na novel open-vocabulary object detection framework directly learning from\nimage-text pair data. We formulate object-language alignment as a set matching\nproblem between a set of image region features and a set of word embeddings. It\nenables us to train an open-vocabulary object detector on image-text pairs in a\nmuch simple and effective way. Extensive experiments on two benchmark datasets,\nCOCO and LVIS, demonstrate our superior performance over the competing\napproaches on novel categories, e.g. achieving 32.0% mAP on COCO and 21.7% mask\nmAP on LVIS. Code is available at: https://github.com/clin1223/VLDet.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Chuang Lin",
      "Peize Sun",
      "Yi Jiang",
      "Ping Luo",
      "Lizhen Qu",
      "Gholamreza Haffari",
      "Zehuan Yuan",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14843"
  },
  {
    "id": "arXiv:2211.14844",
    "title": "Estimating the number of communities in weighted networks",
    "abstract": "Community detection in weighted networks has been a popular topic in recent\nyears. However, while there exist several flexible methods for estimating\ncommunities in weighted networks, these methods usually assume that the number\nof communities is known. It is usually unclear how to determine the exact\nnumber of communities one should use. Here, to estimate the number of\ncommunities for weighted networks generated from arbitrary distribution under\nthe degree-corrected distribution-free model, we propose one approach that\ncombines weighted modularity with spectral clustering. This approach allows a\nweighted network to have negative edge weights and it also works for signed\nnetworks. We compare the proposed method to several existing methods and show\nthat our method is more accurate for estimating the number of communities both\nnumerically and empirically.",
    "descriptor": "",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.14844"
  },
  {
    "id": "arXiv:2211.14851",
    "title": "Performance evaluation of deep segmentation models on Landsat-8 imagery",
    "abstract": "Contrails, short for condensation trails, are line-shaped ice clouds produced\nby aircraft engine exhaust when they fly through cold and humid air. They\ngenerate a greenhouse effect by absorbing or directing back to Earth\napproximately 33% of emitted outgoing longwave radiation. They account for over\nhalf of the climate change resulting from aviation activities. Avoiding\ncontrails and adjusting flight routes could be an inexpensive and effective way\nto reduce their impact. An accurate, automated, and reliable detection\nalgorithm is required to develop and evaluate contrail avoidance strategies.\nAdvancement in contrail detection has been severely limited due to several\nfactors, primarily due to a lack of quality-labeled data. Recently, proposed a\nlarge human-labeled Landsat-8 contrails dataset. Each contrail is carefully\nlabeled with various inputs in various scenes of Landsat-8 satellite imagery.\nIn this work, we benchmark several popular segmentation models with\ncombinations of different loss functions and encoder backbones. This work is\nthe first to apply state-of-the-art segmentation techniques to detect contrails\nin low-orbit satellite imagery. Our work can also be used as an open benchmark\nfor contrail segmentation and is publicly available.",
    "descriptor": "\nComments: Accepted to Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022\n",
    "authors": [
      "Akshat Bhandari",
      "Sriya Rallabandi",
      "Sanchit Singhal",
      "Aditya Kasliwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14851"
  },
  {
    "id": "arXiv:2211.14858",
    "title": "\"Explain it in the Same Way!\" -- Model-Agnostic Group Fairness of  Counterfactual Explanations",
    "abstract": "Counterfactual explanations are a popular type of explanation for making the\noutcomes of a decision making system transparent to the user. Counterfactual\nexplanations tell the user what to do in order to change the outcome of the\nsystem in a desirable way. However, it was recently discovered that the\nrecommendations of what to do can differ significantly in their complexity\nbetween protected groups of individuals. Providing more difficult\nrecommendations of actions to one group leads to a disadvantage of this group\ncompared to other groups.\nIn this work we propose a model-agnostic method for computing counterfactual\nexplanations that do not differ significantly in their complexity between\nprotected groups.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Artelt",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.14858"
  },
  {
    "id": "arXiv:2211.14859",
    "title": "Quantifying spatial, temporal, angular and spectral structure of  effective daylight in perceptually meaningful ways",
    "abstract": "We present a method to capture the 7-dimensional light field structure, and\ntranslate it into perceptually-relevant information. Our spectral cubic\nillumination method quantifies objective correlates of perceptually relevant\ndiffuse and directed light components, including their variations over time,\nspace, in color and direction, and the environment's response to sky and\nsunlight. We applied it 'in the wild', capturing how light on a sunny day\ndiffers between light and shadow, and how light varies over sunny and cloudy\ndays. We discuss the added value of our method for capturing nuanced lighting\neffects on scene and object appearance, such as chromatic gradients.",
    "descriptor": "",
    "authors": [
      "Cehao Yu",
      "Maarten Wijntjes",
      "Elmar Eisemann",
      "Sylvia Pont"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Biological Physics (physics.bio-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.14859"
  },
  {
    "id": "arXiv:2211.14860",
    "title": "Foiling Explanations in Deep Neural Networks",
    "abstract": "Deep neural networks (DNNs) have greatly impacted numerous fields over the\npast decade. Yet despite exhibiting superb performance over many problems,\ntheir black-box nature still poses a significant challenge with respect to\nexplainability. Indeed, explainable artificial intelligence (XAI) is crucial in\nseveral fields, wherein the answer alone -- sans a reasoning of how said answer\nwas derived -- is of little value. This paper uncovers a troubling property of\nexplanation methods for image-based DNNs: by making small visual changes to the\ninput image -- hardly influencing the network's output -- we demonstrate how\nexplanations may be arbitrarily manipulated through the use of evolution\nstrategies. Our novel algorithm, AttaXAI, a model-agnostic, adversarial attack\non XAI algorithms, only requires access to the output logits of a classifier\nand to the explanation map; these weak assumptions render our approach highly\nuseful where real-world models and data are concerned. We compare our method's\nperformance on two benchmark datasets -- CIFAR100 and ImageNet -- using four\ndifferent pretrained deep-learning models: VGG16-CIFAR100, VGG16-ImageNet,\nMobileNet-CIFAR100, and Inception-v3-ImageNet. We find that the XAI methods can\nbe manipulated without the use of gradients or other model internals. Our novel\nalgorithm is successfully able to manipulate an image in a manner imperceptible\nto the human eye, such that the XAI method outputs a specific explanation map.\nTo our knowledge, this is the first such method in a black-box setting, and we\nbelieve it has significant value where explainability is desired, required, or\nlegally mandatory.",
    "descriptor": "",
    "authors": [
      "Snir Vitrack Tamam",
      "Raz Lapid",
      "Moshe Sipper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14860"
  },
  {
    "id": "arXiv:2211.14864",
    "title": "A Faster, Lighter and Stronger Deep Learning-Based Approach for Place  Recognition",
    "abstract": "Visual Place Recognition is an essential component of systems for camera\nlocalization and loop closure detection, and it has attracted widespread\ninterest in multiple domains such as computer vision, robotics and AR/VR. In\nthis work, we propose a faster, lighter and stronger approach that can generate\nmodels with fewer parameters and can spend less time in the inference stage. We\ndesigned RepVGG-lite as the backbone network in our architecture, it is more\ndiscriminative than other general networks in the Place Recognition task.\nRepVGG-lite has more speed advantages while achieving higher performance. We\nextract only one scale patch-level descriptors from global descriptors in the\nfeature extraction stage. Then we design a trainable feature matcher to exploit\nboth spatial relationships of the features and their visual appearance, which\nis based on the attention mechanism. Comprehensive experiments on challenging\nbenchmark datasets demonstrate the proposed method outperforming recent other\nstate-of-the-art learned approaches, and achieving even higher inference speed.\nOur system has 14 times less params than Patch-NetVLAD, 6.8 times lower\ntheoretical FLOPs, and run faster 21 and 33 times in feature extraction and\nfeature matching. Moreover, the performance of our approach is 0.5\\% better\nthan Patch-NetVLAD in Recall@1. We used subsets of Mapillary Street Level\nSequences dataset to conduct experiments for all other challenging conditions.",
    "descriptor": "\nComments: CCF Conference on Computer Supported Cooperative Work and Social Computing (ChineseCSCW)\n",
    "authors": [
      "Rui Huang",
      "Ze Huang",
      "Songzhi Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14864"
  },
  {
    "id": "arXiv:2211.14865",
    "title": "Understanding BLOOM: An empirical study on diverse NLP tasks",
    "abstract": "In this work, we present an evaluation of smaller BLOOM model variants\n(350m/560m and 1b3/1b7) on various natural language processing tasks. This\nincludes GLUE - language understanding, prompt-based zero-shot and few-shot\ntext classification and extraction, question answering, prompt-based text\ngeneration, and multi-lingual text classification to understand model\nstrengths/weaknesses and behavior. Empirical results show that BLOOM variants\nunder-perform on all GLUE tasks (except WNLI), question-answering, and text\ngeneration. The variants bloom for WNLI, with an accuracy of 56.3%, and for\nprompt-based few-shot text extraction on MIT Movies and ATIS datasets. The\nBLOOM variants on average have 7% greater accuracy over GPT-2 and GPT-Neo\nmodels on Director and Airline Name extraction from MIT Movies and ATIS\ndatasets, respectively.",
    "descriptor": "",
    "authors": [
      "Parag Pravin Dakle",
      "SaiKrishna Rallabandi",
      "Preethi Raghavan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14865"
  },
  {
    "id": "arXiv:2211.14866",
    "title": "Spatially Sparse Precoding in Wideband Hybrid Terahertz Massive MIMO  Systems",
    "abstract": "In terahertz (THz) massive multiple-input multiple-output (MIMO) systems, the\ncombination of huge bandwidth and massive antennas results in severe beam\nsplit, thus making the conventional phase-shifter based hybrid precoding\narchitecture ineffective. With the incorporation of true-time-delay (TTD) lines\nin the hardware implementation of the analog precoders, delay-phase precoding\n(DPP) emerges as a promising architecture to effectively overcome beam split.\nHowever, existing DPP approaches suffer from poor performance, high complexity,\nand weak robustness in practical THz channels. In this paper, we propose a\nnovel DPP approach in wideband THz massive MIMO systems. First, the\noptimization problem is converted into a compressive sensing (CS) form, which\ncan be solved by the extended spatially sparse precoding (SSP) algorithm. To\ncompensate for beam split, frequency-dependent measurement matrices are\nintroduced, which can be approximately realized by feasible phase and delay\ncodebooks. Then, several efficient atom selection techniques are developed to\nfurther reduce the complexity of extended SSP. In simulation, the proposed DPP\napproach achieves superior performance, complexity, and robustness by using it\nalone or in combination with existing DPP approaches.",
    "descriptor": "",
    "authors": [
      "Jiabao Gao",
      "Caijun Zhong",
      "Geoffrey Ye Li",
      "Joseph B. Soriaga",
      "Arash Behboodi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.14866"
  },
  {
    "id": "arXiv:2211.14873",
    "title": "Socially Fair and Hierarchical Facility Location Problems",
    "abstract": "The classic facility location problem seeks to open a set of facilities to\nminimize the cost of opening the chosen facilities and the total cost of\nconnecting all the clients to their nearby open facilities. Such an objective\nmay induce an unequal cost over certain socioeconomic groups of clients, e.g.,\nthe average distance traveled by clients who do not have health insurance. To\nreduce the disproportionate impact of opening new facilities such as emergency\nrooms, we consider minimizing the Minkowski $p$-norm of the total distance\ntraveled by each client group and the cost of opening facilities. We show that\nthere is a small portfolio of solutions where for any norm, at least one of the\nsolutions is a constant-factor approximation with respect to any $p$-norm,\nthereby alleviating the need for deciding on a particular value of $p$ to\ndefine what might be \"fair\". We also give a lower bound on the cardinality of\nsuch portfolios. We further introduce the notion of weak and strong refinements\nfor the facility location problem, where the former requires that the set of\nfacilities open for a lower $p$-norm is a superset of those open for higher\n$p$-norms, and the latter further imposes a partition refinement over the\nassignment of clients to open facilities in different norms. We give an\n$O(1)$-approximation for weak refinements, $\\text{poly}(r^{1/\\sqrt{\\log\nr}})$-approximation for strong refinement in general metrics and $O(\\log\nr)$-approximation for the tree metric, where $r$ is the number of (disjoint)\nclient groups. We show that our techniques generalize to hierarchical versions\nof the facility location problem, which may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Swati Gupta",
      "Jai Moondra",
      "Mohit Singh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.14873"
  },
  {
    "id": "arXiv:2211.14874",
    "title": "Reinforcement Learning from Simulation to Real World Autonomous Driving  using Digital Twin",
    "abstract": "Reinforcement learning (RL) is a promising solution for autonomous vehicles\nto deal with complex and uncertain traffic environments. The RL training\nprocess is however expensive, unsafe, and time consuming. Algorithms are often\ndeveloped first in simulation and then transferred to the real world, leading\nto a common sim2real challenge that performance decreases when the domain\nchanges. In this paper, we propose a transfer learning process to minimize the\ngap by exploiting digital twin technology, relying on a systematic and\nsimultaneous combination of virtual and real world data coming from vehicle\ndynamics and traffic scenarios. The model and testing environment are evolved\nfrom model, hardware to vehicle in the loop and proving ground testing stages,\nsimilar to standard development cycle in automotive industry. In particular, we\nalso integrate other transfer learning techniques such as domain randomization\nand adaptation in each stage. The simulation and real data are gradually\nincorporated to accelerate and make the transfer learning process more robust.\nThe proposed RL methodology is applied to develop a path following steering\ncontroller for an autonomous electric vehicle. After learning and deploying the\nreal-time RL control policy on the vehicle, we obtained satisfactory and safe\ncontrol performance already from the first deployment, demonstrating the\nadvantages of the proposed digital twin based learning process.",
    "descriptor": "\nComments: This work has been submitted to IFAC for possible publication\n",
    "authors": [
      "Kevin Voogd",
      "Jean Pierre Allamaa",
      "Javier Alonso-Mora",
      "Tong Duy Son"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14874"
  },
  {
    "id": "arXiv:2211.14875",
    "title": "Detect-Localize-Repair: A Unified Framework for Learning to Debug with  CodeT5",
    "abstract": "Automated software debugging is a crucial task for improving the productivity\nof software developers. Many neural-based techniques have been proven effective\nfor debugging-related tasks such as bug localization and program repair (or bug\nfixing). However, these techniques often focus only on either one of them or\napproach them in a stage-wise manner, ignoring the mutual benefits between\nthem. In this work, we propose a novel unified \\emph{Detect-Localize-Repair}\nframework based on a pretrained programming language model CodeT5 to seamlessly\naddress these tasks, named CodeT5-DLR. Specifically, we propose three\nobjectives to adapt the generic CodeT5 for debugging: a bug detection objective\nto determine whether a given code snippet is buggy or not, a bug localization\nobjective to identify the buggy lines, and a program repair objective to\ntranslate the buggy code to its fixed version. We evaluate it on each of these\ntasks and their combined setting on two newly collected line-level debugging\ndatasets in Java and Python. Extensive results show that our model\nsignificantly outperforms existing baselines from both NLP and software\nengineering domains.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 Findings Track\n",
    "authors": [
      "Nghi D. Q. Bui",
      "Yue Wang",
      "Steven Hoi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14875"
  },
  {
    "id": "arXiv:2211.14876",
    "title": "Dense Text Retrieval based on Pretrained Language Models: A Survey",
    "abstract": "Text retrieval is a long-standing research topic on information seeking,\nwhere a system is required to return relevant information resources to user's\nqueries in natural language. From classic retrieval methods to learning-based\nranking functions, the underlying retrieval models have been continually\nevolved with the ever-lasting technical innovation. To design effective\nretrieval models, a key point lies in how to learn the text representation and\nmodel the relevance matching. The recent success of pretrained language models\n(PLMs) sheds light on developing more capable text retrieval approaches by\nleveraging the excellent modeling capacity of PLMs. With powerful PLMs, we can\neffectively learn the representations of queries and texts in the latent\nrepresentation space, and further construct the semantic matching function\nbetween the dense vectors for relevance modeling. Such a retrieval approach is\nreferred to as dense retrieval, since it employs dense vectors (a.k.a.,\nembeddings) to represent the texts. Considering the rapid progress on dense\nretrieval, in this survey, we systematically review the recent advances on\nPLM-based dense retrieval. Different from previous surveys on dense retrieval,\nwe take a new perspective to organize the related work by four major aspects,\nincluding architecture, training, indexing and integration, and summarize the\nmainstream techniques for each aspect. We thoroughly survey the literature, and\ninclude 300+ related reference papers on dense retrieval. To support our\nsurvey, we create a website for providing useful resources, and release a code\nrepertory and toolkit for implementing dense retrieval models. This survey aims\nto provide a comprehensive, practical reference focused on the major progress\nfor dense text retrieval.",
    "descriptor": "",
    "authors": [
      "Wayne Xin Zhao",
      "Jing Liu",
      "Ruiyang Ren",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.14876"
  },
  {
    "id": "arXiv:2211.14880",
    "title": "Improving Low-Resource Question Answering using Active Learning in  Multiple Stages",
    "abstract": "Neural approaches have become very popular in the domain of Question\nAnswering, however they require a large amount of annotated data. Furthermore,\nthey often yield very good performance but only in the domain they were trained\non. In this work we propose a novel approach that combines data augmentation\nvia question-answer generation with Active Learning to improve performance in\nlow resource settings, where the target domains are diverse in terms of\ndifficulty and similarity to the source domain. We also investigate Active\nLearning for question answering in different stages, overall reducing the\nannotation effort of humans. For this purpose, we consider target domains in\nrealistic settings, with an extremely low amount of annotated samples but with\nmany unlabeled documents, which we assume can be obtained with little effort.\nAdditionally, we assume sufficient amount of labeled data from the source\ndomain is available. We perform extensive experiments to find the best setup\nfor incorporating domain experts. Our findings show that our novel approach,\nwhere humans are incorporated as early as possible in the process, boosts\nperformance in the low-resource, domain-specific setting, allowing for\nlow-labeling-effort question answering systems in new, specialized domains.\nThey further demonstrate how human annotation affects the performance of QA\ndepending on the stage it is performed.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Maximilian Schmidt",
      "Andrea Bartezzaghi",
      "Jasmina Bogojeska",
      "A. Cristiano I. Malossi",
      "Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14880"
  },
  {
    "id": "arXiv:2211.14882",
    "title": "Dynamic Programmable Wireless Environment with UAV-mounted Static  Metasurfaces",
    "abstract": "Reconfigurable intelligent surfaces (RISs) are artificial planar structures\nable to offer a unique way of manipulating propagated wireless signals.\nCommonly composed of a number of reconfigurable passive cell components and\nbasic electronic circuits, RISs can almost freely perform a set of wave\nmodification functionalities, in order to realize programmable wireless\nenvironments (PWEs). However, a more energy-efficient way to realize a PWE is\nthrough dynamically relocating static metasurfaces that perform a unique\nfunctionality. In this paper, we employ a UAV swarm to dynamically deploy a set\nof lowcost passive metasurfaces that are able to perform only one\nelectromagnetic functionality, but with the benefit of requiring no power.\nSpecifically, the UAV-mounted static metasurfaces are carefully positioned\nacross the sky to create cascaded channels for improved user service and\nsecurity hardening. The performance evaluation results, based on",
    "descriptor": "",
    "authors": [
      "Prodromos-Vasileios Mekikis",
      "Dimitrios Tyrovolas",
      "Sotiris Tegos",
      "Alexandros Papadopoulos",
      "Alexandros Pitilakis",
      "Sotiris Ioannidis",
      "Ageliki Tsiolaridou",
      "Panagiotis Diamantoulakis",
      "Nikolaos Kantartzis",
      "George K. Karagiannidis",
      "Christos Liaskos"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.14882"
  },
  {
    "id": "arXiv:2211.14885",
    "title": "Geo-Adaptive Deep Spatio-Temporal predictive modeling for human mobility",
    "abstract": "Deep learning approaches for spatio-temporal prediction problems such as\ncrowd-flow prediction assumes data to be of fixed and regular shaped tensor and\nface challenges of handling irregular, sparse data tensor. This poses\nlimitations in use-case scenarios such as predicting visit counts of\nindividuals' for a given spatial area at a particular temporal resolution using\nraster/image format representation of the geographical region, since the\nmovement patterns of an individual can be largely restricted and localized to a\ncertain part of the raster. Additionally, current deep-learning approaches for\nsolving such problem doesn't account for the geographical awareness of a region\nwhile modelling the spatio-temporal movement patterns of an individual. To\naddress these limitations, there is a need to develop a novel strategy and\nmodeling approach that can handle both sparse, irregular data while\nincorporating geo-awareness in the model. In this paper, we make use of\nquadtree as the data structure for representing the image and introduce a novel\ngeo-aware enabled deep learning layer, GA-ConvLSTM that performs the\nconvolution operation based on a novel geo-aware module based on quadtree data\nstructure for incorporating spatial dependencies while maintaining the\nrecurrent mechanism for accounting for temporal dependencies. We present this\napproach in the context of the problem of predicting spatial behaviors of an\nindividual (e.g., frequent visits to specific locations) through deep-learning\nbased predictive model, GADST-Predict. Experimental results on two GPS based\ntrace data shows that the proposed method is effective in handling frequency\nvisits over different use-cases with considerable high accuracy.",
    "descriptor": "",
    "authors": [
      "Syed Mohammed Arshad Zaidi",
      "Varun Chandola",
      "EunHye Yoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14885"
  },
  {
    "id": "arXiv:2211.14886",
    "title": "Managing Controlled Unclassified Information in Research Institutions",
    "abstract": "In order to operate in a regulated world, researchers need to ensure\ncompliance with ever-evolving landscape of information security regulations and\nbest practices. This work explains the concept of Controlled Unclassified\nInformation (CUI) and the challenges it brings to the research institutions.\nSurvey from the user perceptions showed that most researchers and IT\nadministrators lack a good understanding of CUI and how it is related to other\nregulations, such as HIPAA, ITAR, GLBA, and FERPA. A managed research ecosystem\nis introduced in this work. The workflow of this efficient and cost effective\nframework is elaborated to demonstrate how controlled research data are\nprocessed to be compliant with one of the highest level of cybersecurity in a\ncampus environment. Issues beyond the framework itself is also discussed. The\nframework serves as a reference model for other institutions to support CUI\nresearch. The awareness and training program developed from this work will be\nshared with other institutions to build a bigger CUI ecosystem.",
    "descriptor": "",
    "authors": [
      "Baijian Yang",
      "Carolyn Ellis",
      "Preston Smith",
      "Huyunting Huang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.14886"
  },
  {
    "id": "arXiv:2211.14889",
    "title": "Machine Learning for Smart and Energy-Efficient Buildings",
    "abstract": "Energy consumption in buildings, both residential and commercial, accounts\nfor approximately 40% of all energy usage in the U.S., and similar numbers are\nbeing reported from countries around the world. This significant amount of\nenergy is used to maintain a comfortable, secure, and productive environment\nfor the occupants. So, it is crucial that the energy consumption in buildings\nmust be optimized, all the while maintaining satisfactory levels of occupant\ncomfort, health, and safety. Recently, Machine Learning has been proven to be\nan invaluable tool in deriving important insights from data and optimizing\nvarious systems. In this work, we review the ways in which machine learning has\nbeen leveraged to make buildings smart and energy-efficient. For the\nconvenience of readers, we provide a brief introduction of several machine\nlearning paradigms and the components and functioning of each smart building\nsystem we cover. Finally, we discuss challenges faced while implementing\nmachine learning algorithms in smart buildings and provide future avenues for\nresearch at the intersection of smart buildings and machine learning.",
    "descriptor": "",
    "authors": [
      "Hari Prasanna Das",
      "Yu-Wen Lin",
      "Utkarsha Agwan",
      "Lucas Spangher",
      "Alex Devonport",
      "Yu Yang",
      "Jan Drgona",
      "Adrian Chong",
      "Stefano Schiavon",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14889"
  },
  {
    "id": "arXiv:2211.14896",
    "title": "Knowledge Retrieval Using Functional Object-Oriented Networks",
    "abstract": "Robotic agents often perform tasks that transform sets of input objects into\noutput objects through functional motions. This work describes the FOON\nknowledge representation model for robotic tasks. We define the structure and\nkey components of FOON and describe the process we followed to create our\nuniversal FOON dataset. The paper describes various search algorithms and\nheuristic functions we used to search for objects within the FOON. We performed\nmultiple searches on our universal FOON using these algorithms and discussed\nthe effectiveness of each algorithm.",
    "descriptor": "\nComments: 4 pages, 3 figures, 3 tables\n",
    "authors": [
      "Gabriel Laverghetta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14896"
  },
  {
    "id": "arXiv:2211.14902",
    "title": "3inGAN: Learning a 3D Generative Model from Images of a Self-similar  Scene",
    "abstract": "We introduce 3inGAN, an unconditional 3D generative model trained from 2D\nimages of a single self-similar 3D scene. Such a model can be used to produce\n3D \"remixes\" of a given scene, by mapping spatial latent codes into a 3D\nvolumetric representation, which can subsequently be rendered from arbitrary\nviews using physically based volume rendering. By construction, the generated\nscenes remain view-consistent across arbitrary camera configurations, without\nany flickering or spatio-temporal artifacts. During training, we employ a\ncombination of 2D, obtained through differentiable volume tracing, and 3D\nGenerative Adversarial Network (GAN) losses, across multiple scales, enforcing\nrealism on both its 3D structure and the 2D renderings. We show results on\nsemi-stochastic scenes of varying scale and complexity, obtained from real and\nsynthetic sources. We demonstrate, for the first time, the feasibility of\nlearning plausible view-consistent 3D scene variations from a single exemplar\nscene and provide qualitative and quantitative comparisons against recent\nrelated methods.",
    "descriptor": "\nComments: Conference accept at 3DV 2022\n",
    "authors": [
      "Animesh Karnewar",
      "Oliver Wang",
      "Tobias Ritschel",
      "Niloy Mitra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.14902"
  },
  {
    "id": "arXiv:2211.14905",
    "title": "Multi-Modal Few-Shot Temporal Action Detection via Vision-Language  Meta-Adaptation",
    "abstract": "Few-shot (FS) and zero-shot (ZS) learning are two different approaches for\nscaling temporal action detection (TAD) to new classes. The former adapts a\npretrained vision model to a new task represented by as few as a single video\nper class, whilst the latter requires no training examples by exploiting a\nsemantic description of the new class. In this work, we introduce a new\nmulti-modality few-shot (MMFS) TAD problem, which can be considered as a\nmarriage of FS-TAD and ZS-TAD by leveraging few-shot support videos and new\nclass names jointly. To tackle this problem, we further introduce a novel\nMUlti-modality PromPt mETa-learning (MUPPET) method. This is enabled by\nefficiently bridging pretrained vision and language models whilst maximally\nreusing already learned capacity. Concretely, we construct multi-modal prompts\nby mapping support videos into the textual token space of a vision-language\nmodel using a meta-learned adapter-equipped visual semantics tokenizer. To\ntackle large intra-class variation, we further design a query feature\nregulation scheme. Extensive experiments on ActivityNetv1.3 and THUMOS14\ndemonstrate that our MUPPET outperforms state-of-the-art alternative methods,\noften by a large margin. We also show that our MUPPET can be easily extended to\ntackle the few-shot object detection problem and again achieves the\nstate-of-the-art performance on MS-COCO dataset. The code will be available in\nhttps://github.com/sauradip/MUPPET",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Sauradip Nag",
      "Mengmeng Xu",
      "Xiatian Zhu",
      "Juan-Manuel Perez-Rua",
      "Bernard Ghanem",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.14905"
  },
  {
    "id": "arXiv:2211.14906",
    "title": "Beyond 1-WL with Local Ego-Network Encodings",
    "abstract": "Identifying similar network structures is key to capture graph isomorphisms\nand learn representations that exploit structural information encoded in graph\ndata. This work shows that ego-networks can produce a structural encoding\nscheme for arbitrary graphs with greater expressivity than the\nWeisfeiler-Lehman (1-WL) test. We introduce IGEL, a preprocessing step to\nproduce features that augment node representations by encoding ego-networks\ninto sparse vectors that enrich Message Passing (MP) Graph Neural Networks\n(GNNs) beyond 1-WL expressivity. We describe formally the relation between IGEL\nand 1-WL, and characterize its expressive power and limitations. Experiments\nshow that IGEL matches the empirical expressivity of state-of-the-art methods\non isomorphism detection while improving performance on seven GNN\narchitectures.",
    "descriptor": "\nComments: Presented at the First Learning on Graphs Conference (LoG 2022), Virtual Event, December 9-12, 2022\n",
    "authors": [
      "Nurudin Alvarez-Gonzalez",
      "Andreas Kaltenbrunner",
      "Vicen\u00e7 G\u00f3mez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14906"
  },
  {
    "id": "arXiv:2211.14907",
    "title": "Strategically revealing capabilities in General Lotto games",
    "abstract": "Can revealing one's competitive capabilities to an opponent offer strategic\nbenefits? In this paper, we address this question in the context of General\nLotto games, a class of two-player competitive resource allocation models. We\nconsider an asymmetric information setting where the opponent is uncertain\nabout the resource budget of the other player, and holds a prior belief on its\nvalue. We assume the other player, called the signaler, is able to send a noisy\nsignal about its budget to the opponent. With its updated belief, the opponent\nthen must decide to invest in costly resources that it will deploy against the\nsignaler's resource budget in a General Lotto game. We derive the subgame\nperfect equilibrium to this extensive-form game. In particular, we identify\nnecessary and sufficient conditions for which a signaling policy improves the\nsignaler's resulting performance in comparison to the scenario where it does\nnot send any signal. Moreover, we provide the optimal signaling policy when\nthese conditions are met. Notably we find that for some scenarios, the signaler\ncan effectively double its performance.",
    "descriptor": "",
    "authors": [
      "Keith Paarporn",
      "Philip N. Brown"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14907"
  },
  {
    "id": "arXiv:2211.14912",
    "title": "Impact of Labelled Set Selection and Supervision Policies on  Semi-supervised Learning",
    "abstract": "In semi-supervised representation learning frameworks, when the number of\nlabelled data is very scarce, the quality and representativeness of these\nsamples become increasingly important. Existing literature on semi-supervised\nlearning randomly sample a limited number of data points for labelling. All\nthese labelled samples are then used along with the unlabelled data throughout\nthe training process. In this work, we ask two important questions in this\ncontext: (1) does it matter which samples are selected for labelling? (2) does\nit matter how the labelled samples are used throughout the training process\nalong with the unlabelled data? To answer the first question, we explore a\nnumber of unsupervised methods for selecting specific subsets of data to label\n(without prior knowledge of their labels), with the goal of maximizing\nrepresentativeness w.r.t. the unlabelled set. Then, for our second line of\ninquiry, we define a variety of different label injection strategies in the\ntraining process. Extensive experiments on four popular datasets, CIFAR-10,\nCIFAR-100, SVHN, and STL-10, show that unsupervised selection of samples that\nare more representative of the entire data improves performance by up to ~2%\nover the existing semi-supervised frameworks such as MixMatch, ReMixMatch,\nFixMatch and others with random sample labelling. We show that this boost could\neven increase to 7.5% for very few-labelled scenarios. However, our study shows\nthat gradually injecting the labels throughout the training procedure does not\nimpact the performance considerably versus when all the existing labels are\nused throughout the entire training.",
    "descriptor": "",
    "authors": [
      "Shuvendu Roy",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14912"
  },
  {
    "id": "arXiv:2211.14913",
    "title": "Complexity of Safety and coSafety Fragments of Linear Temporal Logic",
    "abstract": "Linear Temporal Logic (LTL) is the de-facto standard temporal logic for\nsystem specification, whose foundational properties have been studied for over\nfive decades. Safety and cosafety properties define notable fragments of LTL,\nwhere a prefix of a trace suffices to establish whether a formula is true or\nnot over that trace. In this paper, we study the complexity of the problems of\nsatisfiability, validity, and realizability over infinite and finite traces for\nthe safety and cosafety fragments of LTL. As for satisfiability and validity\nover infinite traces, we prove that the majority of the fragments have the same\ncomplexity as full LTL, that is, they are PSPACE-complete. The picture is\nradically different for realizability: we find fragments with the same\nexpressive power whose complexity varies from 2EXPTIME-complete (as full LTL)\nto EXPTIME-complete. Notably, for all cosafety fragments, the complexity of the\nthree problems does not change passing from infinite to finite traces, while\nfor all safety fragments the complexity of satisfiability (resp.,\nrealizability) over finite traces drops to NP-complete (resp.,\n${\\Pi}^P_2$-complete).",
    "descriptor": "",
    "authors": [
      "Alessandro Artale",
      "Luca Geatti",
      "Nicola Gigante",
      "Andrea Mazzullo",
      "Angelo Montanari"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.14913"
  },
  {
    "id": "arXiv:2211.14917",
    "title": "CorrectNet: Robustness Enhancement of Analog In-Memory Computing for  Neural Networks by Error Suppression and Compensation",
    "abstract": "The last decade has witnessed the breakthrough of deep neural networks (DNNs)\nin many fields. With the increasing depth of DNNs, hundreds of millions of\nmultiply-and-accumulate (MAC) operations need to be executed. To accelerate\nsuch operations efficiently, analog in-memory computing platforms based on\nemerging devices, e.g., resistive RAM (RRAM), have been introduced. These\nacceleration platforms rely on analog properties of the devices and thus suffer\nfrom process variations and noise. Consequently, weights in neural networks\nconfigured into these platforms can deviate from the expected values, which may\nlead to feature errors and a significant degradation of inference accuracy. To\naddress this issue, in this paper, we propose a framework to enhance the\nrobustness of neural networks under variations and noise. First, a modified\nLipschitz constant regularization is proposed during neural network training to\nsuppress the amplification of errors propagated through network layers.\nAfterwards, error compensation is introduced at necessary locations determined\nby reinforcement learning to rescue the feature maps with remaining errors.\nExperimental results demonstrate that inference accuracy of neural networks can\nbe recovered from as low as 1.69% under variations and noise back to more than\n95% of their original accuracy, while the training and hardware cost are\nnegligible.",
    "descriptor": "\nComments: Accepted by DATE 2023 (Design, Automation and Test in Europe)\n",
    "authors": [
      "Amro Eldebiky",
      "Grace Li Zhang",
      "Georg Boecherer",
      "Bing Li",
      "Ulf Schlichtmann"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14917"
  },
  {
    "id": "arXiv:2211.14920",
    "title": "EPIK: Eliminating multi-model Pipelines with Knowledge-distillation",
    "abstract": "Real-world tasks are largely composed of multiple models, each performing a\nsub-task in a larger chain of tasks, i.e., using the output from a model as\ninput for another model in a multi-model pipeline. A model like MATRa performs\nthe task of Crosslingual Transliteration in two stages, using English as an\nintermediate transliteration target when transliterating between two indic\nlanguages. We propose a novel distillation technique, EPIK, that condenses\ntwo-stage pipelines for hierarchical tasks into a single end-to-end model\nwithout compromising performance. This method can create end-to-end models for\ntasks without needing a dedicated end-to-end dataset, solving the data scarcity\nproblem. The EPIK model has been distilled from the MATra model using this\ntechnique of knowledge distillation. The MATra model can perform crosslingual\ntransliteration between 5 languages - English, Hindi, Tamil, Kannada and\nBengali. The EPIK model executes the task of transliteration without any\nintermediate English output while retaining the performance and accuracy of the\nMATra model. The EPIK model can perform transliteration with an average CER\nscore of 0.015 and average phonetic accuracy of 92.1%. In addition, the average\ntime for execution has reduced by 54.3% as compared to the teacher model and\nhas a similarity score of 97.5% with the teacher encoder. In a few cases, the\nEPIK model (student model) can outperform the MATra model (teacher model) even\nthough it has been distilled from the MATra model.",
    "descriptor": "",
    "authors": [
      "Bhavesh Laddagiri",
      "Yash Raj",
      "Anshuman Dash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14920"
  },
  {
    "id": "arXiv:2211.14923",
    "title": "Unsupervised Opinion Summarisation in the Wasserstein Space",
    "abstract": "Opinion summarisation synthesises opinions expressed in a group of documents\ndiscussing the same topic to produce a single summary. Recent work has looked\nat opinion summarisation of clusters of social media posts. Such posts are\nnoisy and have unpredictable structure, posing additional challenges for the\nconstruction of the summary distribution and the preservation of meaning\ncompared to online reviews, which has been so far the focus of opinion\nsummarisation. To address these challenges we present \\textit{WassOS}, an\nunsupervised abstractive summarization model which makes use of the Wasserstein\ndistance. A Variational Autoencoder is used to get the distribution of\ndocuments/posts, and the distributions are disentangled into separate semantic\nand syntactic spaces. The summary distribution is obtained using the\nWasserstein barycenter of the semantic and syntactic distributions. A latent\nvariable sampled from the summary distribution is fed into a GRU decoder with a\ntransformer layer to produce the final summary. Our experiments on multiple\ndatasets including Twitter clusters, Reddit threads, and reviews show that\nWassOS almost always outperforms the state-of-the-art on ROUGE metrics and\nconsistently produces the best summaries with respect to meaning preservation\naccording to human evaluations.",
    "descriptor": "",
    "authors": [
      "Jiayu Song",
      "Iman Munire Bilal",
      "Adam Tsakalidis",
      "Rob Procter",
      "Maria Liakata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14923"
  },
  {
    "id": "arXiv:2211.14924",
    "title": "Post-Processing Temporal Action Detection",
    "abstract": "Existing Temporal Action Detection (TAD) methods typically take a\npre-processing step in converting an input varying-length video into a\nfixed-length snippet representation sequence, before temporal boundary\nestimation and action classification. This pre-processing step would temporally\ndownsample the video, reducing the inference resolution and hampering the\ndetection performance in the original temporal resolution. In essence, this is\ndue to a temporal quantization error introduced during the resolution\ndownsampling and recovery. This could negatively impact the TAD performance,\nbut is largely ignored by existing methods. To address this problem, in this\nwork we introduce a novel model-agnostic post-processing method without model\nredesign and retraining. Specifically, we model the start and end points of\naction instances with a Gaussian distribution for enabling temporal boundary\ninference at a sub-snippet level. We further introduce an efficient\nTaylor-expansion based approximation, dubbed as Gaussian Approximated\nPost-processing (GAP). Extensive experiments demonstrate that our GAP can\nconsistently improve a wide variety of pre-trained off-the-shelf TAD models on\nthe challenging ActivityNet (+0.2% -0.7% in average mAP) and THUMOS (+0.2%\n-0.5% in average mAP) benchmarks. Such performance gains are already\nsignificant and highly comparable to those achieved by novel model designs.\nAlso, GAP can be integrated with model training for further performance gain.\nImportantly, GAP enables lower temporal resolutions for more efficient\ninference, facilitating low-resource applications. The code will be available\nin https://github.com/sauradip/GAP",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Sauradip Nag",
      "Xiatian Zhu",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14924"
  },
  {
    "id": "arXiv:2211.14926",
    "title": "SteppingNet: A Stepping Neural Network with Incremental Accuracy  Enhancement",
    "abstract": "Deep neural networks (DNNs) have successfully been applied in many fields in\nthe past decades. However, the increasing number of multiply-and-accumulate\n(MAC) operations in DNNs prevents their application in resource-constrained and\nresource-varying platforms, e.g., mobile phones and autonomous vehicles. In\nsuch platforms, neural networks need to provide acceptable results quickly and\nthe accuracy of the results should be able to be enhanced dynamically according\nto the computational resources available in the computing system. To address\nthese challenges, we propose a design framework called SteppingNet. SteppingNet\nconstructs a series of subnets whose accuracy is incrementally enhanced as more\nMAC operations become available. Therefore, this design allows a trade-off\nbetween accuracy and latency. In addition, the larger subnets in SteppingNet\nare built upon smaller subnets, so that the results of the latter can directly\nbe reused in the former without recomputation. This property allows SteppingNet\nto decide on-the-fly whether to enhance the inference accuracy by executing\nfurther MAC operations. Experimental results demonstrate that SteppingNet\nprovides an effective incremental accuracy improvement and its inference\naccuracy consistently outperforms the state-of-the-art work under the same\nlimit of computational resources.",
    "descriptor": "\nComments: accepted by DATE2023 (Design, Automation and Test in Europe)\n",
    "authors": [
      "Wenhao Sun",
      "Grace Li Zhang",
      "Xunzhao Yin",
      "Cheng Zhuo",
      "Huaxi Gu",
      "Bing Li",
      "Ulf Schlichtmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14926"
  },
  {
    "id": "arXiv:2211.14927",
    "title": "BEV-Locator: An End-to-end Visual Semantic Localization Network Using  Multi-View Images",
    "abstract": "Accurate localization ability is fundamental in autonomous driving.\nTraditional visual localization frameworks approach the semantic map-matching\nproblem with geometric models, which rely on complex parameter tuning and thus\nhinder large-scale deployment. In this paper, we propose BEV-Locator: an\nend-to-end visual semantic localization neural network using multi-view camera\nimages. Specifically, a visual BEV (Birds-Eye-View) encoder extracts and\nflattens the multi-view images into BEV space. While the semantic map features\nare structurally embedded as map queries sequence. Then a cross-model\ntransformer associates the BEV features and semantic map queries. The\nlocalization information of ego-car is recursively queried out by\ncross-attention modules. Finally, the ego pose can be inferred by decoding the\ntransformer outputs. We evaluate the proposed method in large-scale nuScenes\nand Qcraft datasets. The experimental results show that the BEV-locator is\ncapable to estimate the vehicle poses under versatile scenarios, which\neffectively associates the cross-model information from multi-view images and\nglobal semantic maps. The experiments report satisfactory accuracy with mean\nabsolute errors of 0.052m, 0.135m and 0.251$^\\circ$ in lateral, longitudinal\ntranslation and heading angle degree.",
    "descriptor": "",
    "authors": [
      "Zhihuang Zhang",
      "Meng Xu",
      "Wenqiang Zhou",
      "Tao Peng",
      "Liang Li",
      "Stefan Poslad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14927"
  },
  {
    "id": "arXiv:2211.14928",
    "title": "Class-based Quantization for Neural Networks",
    "abstract": "In deep neural networks (DNNs), there are a huge number of weights and\nmultiply-and-accumulate (MAC) operations. Accordingly, it is challenging to\napply DNNs on resource-constrained platforms, e.g., mobile phones. Quantization\nis a method to reduce the size and the computational complexity of DNNs.\nExisting quantization methods either require hardware overhead to achieve a\nnon-uniform quantization or focus on model-wise and layer-wise uniform\nquantization, which are not as fine-grained as filter-wise quantization. In\nthis paper, we propose a class-based quantization method to determine the\nminimum number of quantization bits for each filter or neuron in DNNs\nindividually. In the proposed method, the importance score of each filter or\nneuron with respect to the number of classes in the dataset is first evaluated.\nThe larger the score is, the more important the filter or neuron is and thus\nthe larger the number of quantization bits should be. Afterwards, a search\nalgorithm is adopted to exploit the different importance of filters and neurons\nto determine the number of quantization bits of each filter or neuron.\nExperimental results demonstrate that the proposed method can maintain the\ninference accuracy with low bit-width quantization. Given the same number of\nquantization bits, the proposed method can also achieve a better inference\naccuracy than the existing methods.",
    "descriptor": "\nComments: accepted by DATE2023 (Design, Automation and Test in Europe)\n",
    "authors": [
      "Wenhao Sun",
      "Grace Li Zhang",
      "Huaxi Gu",
      "Bing Li",
      "Ulf Schlichtmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14928"
  },
  {
    "id": "arXiv:2211.14931",
    "title": "UAV-Assisted Space-Air-Ground Integrated Networks: A Technical Review of  Recent Learning Algorithms",
    "abstract": "Recent technological advancements in space, air and ground components have\nmade possible a new network paradigm called \"space-air-ground integrated\nnetwork\" (SAGIN). Unmanned aerial vehicles (UAVs) play a key role in SAGINs.\nHowever, due to UAVs' high dynamics and complexity, the real-world deployment\nof a SAGIN becomes a major barrier for realizing such SAGINs. Compared to the\nspace and terrestrial components, UAVs are expected to meet performance\nrequirements with high flexibility and dynamics using limited resources.\nTherefore, employing UAVs in various usage scenarios requires well-designed\nplanning in algorithmic approaches. In this paper, we provide a comprehensive\nreview of recent learning-based algorithmic approaches. We consider possible\nreward functions and discuss the state-of-the-art algorithms for optimizing the\nreward functions, including Q-learning, deep Q-learning, multi-armed bandit\n(MAB), particle swarm optimization (PSO) and satisfaction-based learning\nalgorithms. Unlike other survey papers, we focus on the methodological\nperspective of the optimization problem, which can be applicable to various\nUAV-assisted missions on a SAGIN using these algorithms. We simulate users and\nenvironments according to real-world scenarios and compare the learning-based\nand PSO-based methods in terms of throughput, load, fairness, computation time,\netc. We also implement and evaluate the 2-dimensional (2D) and 3-dimensional\n(3D) variations of these algorithms to reflect different deployment cases. Our\nsimulation suggests that the $3$D satisfaction-based learning algorithm\noutperforms the other approaches for various metrics in most cases. We discuss\nsome open challenges at the end and our findings aim to provide design\nguidelines for algorithm selections while optimizing the deployment of\nUAV-assisted SAGINs.",
    "descriptor": "\nComments: Submitted to the IEEE Internet of Things Journal in June 2022\n",
    "authors": [
      "Atefeh H. Arani",
      "Peng Hu",
      "Yeying Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.14931"
  },
  {
    "id": "arXiv:2211.14932",
    "title": "Counterfactual Optimism: Rate Optimal Regret for Stochastic Contextual  MDPs",
    "abstract": "We present the UC$^3$RL algorithm for regret minimization in Stochastic\nContextual MDPs (CMDPs). The algorithm operates under the minimal assumptions\nof realizable function class, and access to offline least squares and log loss\nregression oracles. Our algorithm is efficient (assuming efficient offline\nregression oracles) and enjoys an $\\widetilde{O}(H^3 \\sqrt{T |S| |A|(\\log\n(|\\mathcal{F}|/\\delta) + \\log (|\\mathcal{P}|/ \\delta) )})$ regret guarantee,\nwith $T$ being the number of episodes, $S$ the state space, $A$ the action\nspace, $H$ the horizon, and $\\mathcal{P}$ and $\\mathcal{F}$ are finite function\nclasses, used to approximate the context-dependent dynamics and rewards,\nrespectively. To the best of our knowledge, our algorithm is the first\nefficient and rate-optimal regret minimization algorithm for CMDPs, which\noperates under the general offline function approximation setting.",
    "descriptor": "",
    "authors": [
      "Orin Levy",
      "Asaf Cassel",
      "Alon Cohen",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14932"
  },
  {
    "id": "arXiv:2211.14935",
    "title": "RecXplainer: Post-Hoc Attribute-Based Explanations for Recommender  Systems",
    "abstract": "Recommender systems are ubiquitous in most of our interactions in the current\ndigital world. Whether shopping for clothes, scrolling YouTube for exciting\nvideos, or searching for restaurants in a new city, the recommender systems at\nthe back-end power these services. Most large-scale recommender systems are\nhuge models trained on extensive datasets and are black-boxes to both their\ndevelopers and end-users. Prior research has shown that providing\nrecommendations along with their reason enhances trust, scrutability, and\npersuasiveness of the recommender systems. Recent literature in explainability\nhas been inundated with works proposing several algorithms to this end. Most of\nthese works provide item-style explanations, i.e., `We recommend item A because\nyou bought item B.' We propose a novel approach, RecXplainer, to generate more\nfine-grained explanations based on the user's preference over the attributes of\nthe recommended items. We perform experiments using real-world datasets and\ndemonstrate the efficacy of RecXplainer in capturing users' preferences and\nusing them to explain recommendations. We also propose ten new evaluation\nmetrics and compare RecXplainer to six baseline methods.",
    "descriptor": "\nComments: Awarded the Best Student Paper at TEA Workshop at NeurIPS 2022. 13 pages\n",
    "authors": [
      "Sahil Verma",
      "Anurag Beniwal",
      "Narayanan Sadagopan",
      "Arjun Seshadri"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14935"
  },
  {
    "id": "arXiv:2211.14936",
    "title": "Common bibliometric approaches fail to assess correctly the number of  important scientific advances for most countries and institutions",
    "abstract": "Although not explicitly declared, most research rankings of countries and\ninstitutions are supposed to reveal their contribution to the advancement of\nknowledge. However, such advances are based on very highly cited publications\nwith very low frequency, which can only very exceptionally be counted with\nstatistical reliability. Percentile indicators enable calculations of the\nprobability or frequency of such rare publications using counts of much more\nfrequent publications; the general rule is that rankings based on the number of\ntop 10% or 1% cited publications (Ptop 10%, Ptop 1%) will also be valid for the\nrare publications that push the boundaries of knowledge. Japan and its\nuniversities are exceptions, as their frequent Nobel Prizes contradicts their\nlow Ptop 10% and Ptop 1%. We explain that this occurs because, in single\nresearch fields, the singularity of percentile indicators holds only for\nresearch groups that are homogeneous in their aims and efficiency. Correct\ncalculations for ranking countries and institutions should add the results of\ntheir homogeneous groups, instead of considering all publications as a single\nset. Although based on Japan, our findings have a general character. Common\npredictions of scientific advances based on Ptop 10% might be severalfold lower\nthan correct calculations.",
    "descriptor": "\nComments: 30 pages, tables and figures embedded in a single pdf file\n",
    "authors": [
      "Alonso Rodriguez-Navarro",
      "Ricardo Brito"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.14936"
  },
  {
    "id": "arXiv:2211.14938",
    "title": "An Anomaly Detection Method for Satellites Using Monte Carlo Dropout",
    "abstract": "Recently, there has been a significant amount of interest in satellite\ntelemetry anomaly detection (AD) using neural networks (NN). For AD purposes,\nthe current approaches focus on either forecasting or reconstruction of the\ntime series, and they cannot measure the level of reliability or the\nprobability of correct detection. Although the Bayesian neural network\n(BNN)-based approaches are well known for time series uncertainty estimation,\nthey are computationally intractable. In this paper, we present a tractable\napproximation for BNN based on the Monte Carlo (MC) dropout method for\ncapturing the uncertainty in the satellite telemetry time series, without\nsacrificing accuracy. For time series forecasting, we employ an NN, which\nconsists of several Long Short-Term Memory (LSTM) layers followed by various\ndense layers. We employ the MC dropout inside each LSTM layer and before the\ndense layers for uncertainty estimation. With the proposed uncertainty region\nand by utilizing a post-processing filter, we can effectively capture the\nanomaly points. Numerical results show that our proposed time series AD\napproach outperforms the existing methods from both prediction accuracy and AD\nperspectives.",
    "descriptor": "",
    "authors": [
      "Mohammad Amin Maleki Sadr",
      "Yeying Zhu",
      "Peng Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.14938"
  },
  {
    "id": "arXiv:2211.14939",
    "title": "Applying Deep Reinforcement Learning to the HP Model for Protein  Structure Prediction",
    "abstract": "A central problem in computational biophysics is protein structure\nprediction, i.e., finding the optimal folding of a given amino acid sequence.\nThis problem has been studied in a classical abstract model, the HP model,\nwhere the protein is modeled as a sequence of H (hydrophobic) and P (polar)\namino acids on a lattice. The objective is to find conformations maximizing H-H\ncontacts. It is known that even in this reduced setting, the problem is\nintractable (NP-hard). In this work, we apply deep reinforcement learning (DRL)\nto the two-dimensional HP model. We can obtain the conformations of best known\nenergies for benchmark HP sequences with lengths from 20 to 50. Our DRL is\nbased on a deep Q-network (DQN). We find that a DQN based on long short-term\nmemory (LSTM) architecture greatly enhances the RL learning ability and\nsignificantly improves the search process. DRL can sample the state space\nefficiently, without the need of manual heuristics. Experimentally we show that\nit can find multiple distinct best-known solutions per trial. This study\ndemonstrates the effectiveness of deep reinforcement learning in the HP model\nfor protein folding.",
    "descriptor": "\nComments: 21 pages, 12 figures, 3 tables. Extended abstract accepted by the Machine Learning and the Physical Sciences workshop, NeurIPS 2022\n",
    "authors": [
      "Kaiyuan Yang",
      "Houjing Huang",
      "Olafs Vandans",
      "Adithya Murali",
      "Fujia Tian",
      "Roland H.C. Yap",
      "Liang Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.14939"
  },
  {
    "id": "arXiv:2211.14944",
    "title": "HULK-V: a Heterogeneous Ultra-low-power Linux capable RISC-V SoC",
    "abstract": "IoT applications span a wide range in performance and memory footprint, under\ntight cost and power constraints. High-end applications rely on power-hungry\nSystems-on-Chip (SoCs) featuring powerful processors, large LPDDR/DDR3/4/5\nmemories, and supporting full-fledged Operating Systems (OS). On the contrary,\nlow-end applications typically rely on Ultra-Low-Power ucontrollers with a\n\"close to metal\" software environment and simple micro-kernel-based runtimes.\nEmerging applications and trends of IoT require the \"best of both worlds\":\ncheap and low-power SoC systems with a well-known and agile software\nenvironment based on full-fledged OS (e.g., Linux), coupled with extreme energy\nefficiency and parallel digital signal processing capabilities. We present\nHULK-V: an open-source Heterogeneous Linux-capable RISC-V-based SoC coupling a\n64-bit RISC-V processor with an 8-core Programmable Multi-Core Accelerator\n(PMCA), delivering up to 13.8 GOps, up to 157 GOps/W and accelerating the\nexecution of complex DSP and ML tasks by up to 112x over the host processor.\nHULK-V leverages a lightweight, fully digital memory hierarchy based on\nHyperRAM IoT DRAM that exposes up to 512 MB of DRAM memory to the host CPU.\nFeaturing HyperRAMs, HULK-V doubles the energy efficiency without significant\nperformance loss compared to featuring power-hungry LPDDR memories, requiring\nexpensive and large mixed-signal PHYs. HULK-V, implemented in Global Foundries\n22nm FDX technology, is a fully digital ultra-low-cost SoC running a 64-bit\nLinux software stack with OpenMP host-to-PMCA offload within a power envelope\nof just 250 mW.",
    "descriptor": "\nComments: This paper has been accepted as full paper at DATE23 this https URL\n",
    "authors": [
      "Luca Valente",
      "Yvan Tortorella",
      "Mattia Sinigaglia",
      "Giuseppe Tagliavini",
      "Alessandro Capotondi",
      "Luca Benini",
      "Davide Rossi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.14944"
  },
  {
    "id": "arXiv:2211.14946",
    "title": "Self-Destructing Models: Increasing the Costs of Harmful Dual Uses in  Foundation Models",
    "abstract": "A growing ecosystem of large, open-source foundation models has reduced the\nlabeled data and technical expertise necessary to apply machine learning to\nmany new problems. Yet foundation models pose a clear dual-use risk,\nindiscriminately reducing the costs of building both harmful and beneficial\nmachine learning systems. To mitigate this risk, we propose the task blocking\nparadigm, in which foundation models are trained with an additional mechanism\nto impede adaptation to harmful tasks while retaining good performance on\ndesired tasks. We call the resulting models self-destructing models, inspired\nby mechanisms that prevent adversaries from using tools for harmful purposes.\nWe present an algorithm for training self-destructing models leveraging\ntechniques from meta-learning and adversarial learning, showing that it can\nlargely prevent a BERT-based model from learning to perform gender\nidentification without harming the model's ability to perform profession\nclassification. We conclude with a discussion of future directions.",
    "descriptor": "\nComments: Presented at the First Workshop of Pre-training: Perspectives, Pitfalls, and Paths Forward (ICML, 2022) and New Frontiers in Adversarial Machine Learning Workshop (ICML, 2022)\n",
    "authors": [
      "Eric Mitchell",
      "Peter Henderson",
      "Christopher D. Manning",
      "Dan Jurafsky",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14946"
  },
  {
    "id": "arXiv:2211.14948",
    "title": "Metaverse Security and Privacy: An Overview",
    "abstract": "Metaverse is a living space and cyberspace that realizes the process of\nvirtualizing and digitizing the real world. It integrates a plethora of\nexisting technologies with the goal of being able to map the real world, even\nbeyond the real world. Metaverse has a bright future and is expected to have\nmany applications in various scenarios. The support of the Metaverse is based\non numerous related technologies becoming mature. Hence, there is no doubt that\nthe security risks of the development of the Metaverse may be more prominent\nand more complex. We present some Metaverse-related technologies and some\npotential security and privacy issues in the Metaverse. We present current\nsolutions for Metaverse security and privacy derived from these technologies.\nIn addition, we also raise some unresolved questions about the potential\nMetaverse. To summarize, this survey provides an in-depth review of the\nsecurity and privacy issues raised by key technologies in Metaverse\napplications. We hope that this survey will provide insightful research\ndirections and prospects for the Metaverse's development, particularly in terms\nof security and privacy protection in the Metaverse.",
    "descriptor": "\nComments: IEEE BigData 2022. 10 pages, 2 figures\n",
    "authors": [
      "Zefeng Chen",
      "Jiayang Wu",
      "Wensheng Gan",
      "Zhenlian Qi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.14948"
  },
  {
    "id": "arXiv:2211.14950",
    "title": "GRelPose: Generalizable End-to-End Relative Camera Pose Regression",
    "abstract": "This paper proposes a generalizable, end-to-end deep learning-based method\nfor relative pose regression between two images. Given two images of the same\nscene captured from different viewpoints, our algorithm predicts the relative\nrotation and translation between the two respective cameras. Despite recent\nprogress in the field, current deep-based methods exhibit only limited\ngeneralization to scenes not seen in training. Our approach introduces a\nnetwork architecture that extracts a grid of coarse features for each input\nimage using the pre-trained LoFTR network. It subsequently relates\ncorresponding features in the two images, and finally uses a convolutional\nnetwork to recover the relative rotation and translation between the respective\ncameras. Our experiments indicate that the proposed architecture can generalize\nto novel scenes, obtaining higher accuracy than existing deep-learning-based\nmethods in various settings and datasets, in particular with limited training\ndata.",
    "descriptor": "",
    "authors": [
      "Fadi Khatib",
      "Yuval Margalit",
      "Meirav Galun",
      "Ronen Basri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14950"
  },
  {
    "id": "arXiv:2211.14951",
    "title": "Metaverse in Education: Vision, Opportunities, and Challenges",
    "abstract": "Traditional education has been updated with the development of information\ntechnology in human history. Within big data and cyber-physical systems, the\nMetaverse has generated strong interest in various applications (e.g.,\nentertainment, business, and cultural travel) over the last decade. As a novel\nsocial work idea, the Metaverse consists of many kinds of technologies, e.g.,\nbig data, interaction, artificial intelligence, game design, Internet\ncomputing, Internet of Things, and blockchain. It is foreseeable that the usage\nof Metaverse will contribute to educational development. However, the\narchitectures of the Metaverse in education are not yet mature enough. There\nare many questions we should address for the Metaverse in education. To this\nend, this paper aims to provide a systematic literature review of Metaverse in\neducation. This paper is a comprehensive survey of the Metaverse in education,\nwith a focus on current technologies, challenges, opportunities, and future\ndirections. First, we present a brief overview of the Metaverse in education,\nas well as the motivation behind its integration. Then, we survey some\nimportant characteristics for the Metaverse in education, including the\npersonal teaching environment and the personal learning environment. Next, we\nenvisage what variations of this combination will bring to education in the\nfuture and discuss their strengths and weaknesses. We also review the\nstate-of-the-art case studies (including technical companies and educational\ninstitutions) for Metaverse in education. Finally, we point out several\nchallenges and issues in this promising area.",
    "descriptor": "\nComments: IEEE BigData 2022. 10 pages, 5 figures, 3 tables\n",
    "authors": [
      "Hong Lin",
      "Shicheng Wan",
      "Wensheng Gan",
      "Jiahui Chen",
      "Han-Chieh Chao"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.14951"
  },
  {
    "id": "arXiv:2211.14952",
    "title": "Federated Learning Attacks and Defenses: A Survey",
    "abstract": "In terms of artificial intelligence, there are several security and privacy\ndeficiencies in the traditional centralized training methods of machine\nlearning models by a server. To address this limitation, federated learning\n(FL) has been proposed and is known for breaking down ``data silos\" and\nprotecting the privacy of users. However, FL has not yet gained popularity in\nthe industry, mainly due to its security, privacy, and high cost of\ncommunication. For the purpose of advancing the research in this field,\nbuilding a robust FL system, and realizing the wide application of FL, this\npaper sorts out the possible attacks and corresponding defenses of the current\nFL system systematically. Firstly, this paper briefly introduces the basic\nworkflow of FL and related knowledge of attacks and defenses. It reviews a\ngreat deal of research about privacy theft and malicious attacks that have been\nstudied in recent years. Most importantly, in view of the current three\nclassification criteria, namely the three stages of machine learning, the three\ndifferent roles in federated learning, and the CIA (Confidentiality, Integrity,\nand Availability) guidelines on privacy protection, we divide attack approaches\ninto two categories according to the training stage and the prediction stage in\nmachine learning. Furthermore, we also identify the CIA property violated for\neach attack method and potential attack role. Various defense mechanisms are\nthen analyzed separately from the level of privacy and security. Finally, we\nsummarize the possible challenges in the application of FL from the aspect of\nattacks and defenses and discuss the future development direction of FL\nsystems. In this way, the designed FL system has the ability to resist\ndifferent attacks and is more secure and stable.",
    "descriptor": "\nComments: IEEE BigData. 10 pages, 2 figures, 2 tables\n",
    "authors": [
      "Yao Chen",
      "Yijie Gui",
      "Hong Lin",
      "Wensheng Gan",
      "Yongdong Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14952"
  },
  {
    "id": "arXiv:2211.14953",
    "title": "OBMeshfree: An optimization-based meshfree solver for nonlocal diffusion  and peridynamics models",
    "abstract": "We present OBMeshfree, an Optimization-Based Meshfree solver for compactly\nsupported nonlocal integro-differential equations (IDEs) that can describe\nmaterial heterogeneity and brittle fractures. OBMeshfree is developed based on\na quadrature rule calculated via an equality constrained least square problem\nto reproduce exact integrals for polynomials. As such, a meshfree\ndiscretization method is obtained, whose solution possesses the asymptotically\ncompatible convergence to the corresponding local solution. Moreover, when\nfracture occurs, this meshfree formulation automatically provides a sharp\nrepresentation of the fracture surface by breaking bonds, avoiding the loss of\nmass. As numerical examples, we consider the problem of modeling both\nhomogeneous and heterogeneous materials with nonlocal diffusion and\nperidynamics models. Convergences to the analytical nonlocal solution and to\nthe local theory are demonstrated. Finally, we verify the applicability of the\napproach to realistic problems by reproducing high-velocity impact results from\nthe Kalthoff-Winkler experiments. Discussions on possible immediate extensions\nof the code to other nonlocal diffusion and peridynamics problems are provided.\nOBMeshfree is freely available on GitHub.",
    "descriptor": "\nComments: For associated code, see this https URL\n",
    "authors": [
      "Yiming Fan",
      "Huaiqian You",
      "Yue Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.14953"
  },
  {
    "id": "arXiv:2211.14954",
    "title": "Topic Segmentation in the Wild: Towards Segmentation of Semi-structured  & Unstructured Chats",
    "abstract": "Breaking down a document or a conversation into multiple contiguous segments\nbased on its semantic structure is an important and challenging problem in NLP,\nwhich can assist many downstream tasks. However, current works on topic\nsegmentation often focus on segmentation of structured texts. In this paper, we\ncomprehensively analyze the generalization capabilities of state-of-the-art\ntopic segmentation models on unstructured texts. We find that: (a) Current\nstrategies of pre-training on a large corpus of structured text such as\nWiki-727K do not help in transferability to unstructured texts. (b) Training\nfrom scratch with only a relatively small-sized dataset of the target\nunstructured domain improves the segmentation results by a significant margin.",
    "descriptor": "\nComments: NeurIPS 2022 : ENLSP\n",
    "authors": [
      "Reshmi Ghosh",
      "Harjeet Singh Kajal",
      "Sharanya Kamath",
      "Dhuri Shrivastava",
      "Samyadeep Basu",
      "Soundararajan Srinivasan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14954"
  },
  {
    "id": "arXiv:2211.14958",
    "title": "MGDoc: Pre-training with Multi-granular Hierarchy for Document Image  Understanding",
    "abstract": "Document images are a ubiquitous source of data where the text is organized\nin a complex hierarchical structure ranging from fine granularity (e.g.,\nwords), medium granularity (e.g., regions such as paragraphs or figures), to\ncoarse granularity (e.g., the whole page). The spatial hierarchical\nrelationships between content at different levels of granularity are crucial\nfor document image understanding tasks. Existing methods learn features from\neither word-level or region-level but fail to consider both simultaneously.\nWord-level models are restricted by the fact that they originate from pure-text\nlanguage models, which only encode the word-level context. In contrast,\nregion-level models attempt to encode regions corresponding to paragraphs or\ntext blocks into a single embedding, but they perform worse with additional\nword-level features. To deal with these issues, we propose MGDoc, a new\nmulti-modal multi-granular pre-training framework that encodes page-level,\nregion-level, and word-level information at the same time. MGDoc uses a unified\ntext-visual encoder to obtain multi-modal features across different\ngranularities, which makes it possible to project the multi-granular features\ninto the same hyperspace. To model the region-word correlation, we design a\ncross-granular attention mechanism and specific pre-training tasks for our\nmodel to reinforce the model of learning the hierarchy between regions and\nwords. Experiments demonstrate that our proposed model can learn better\nfeatures that perform well across granularities and lead to improvements in\ndownstream tasks.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zilong Wang",
      "Jiuxiang Gu",
      "Chris Tensmeyer",
      "Nikolaos Barmpalios",
      "Ani Nenkova",
      "Tong Sun",
      "Jingbo Shang",
      "Vlad I. Morariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14958"
  },
  {
    "id": "arXiv:2211.14960",
    "title": "Label Alignment Regularization for Distribution Shift",
    "abstract": "Recent work reported the label alignment property in a supervised learning\nsetting: the vector of all labels in the dataset is mostly in the span of the\ntop few singular vectors of the data matrix. Inspired by this observation, we\nderive a regularization method for unsupervised domain adaptation. Instead of\nregularizing representation learning as done by popular domain adaptation\nmethods, we regularize the classifier so that the target domain predictions can\nto some extent ``align\" with the top singular vectors of the unsupervised data\nmatrix from the target domain. In a linear regression setting, we theoretically\njustify the label alignment property and characterize the optimality of the\nsolution of our regularization by bounding its distance to the optimal\nsolution. We conduct experiments to show that our method can work well on the\nlabel shift problems, where classic domain adaptation methods are known to\nfail. We also report mild improvement over domain adaptation baselines on a set\nof commonly seen MNIST-USPS domain adaptation tasks and on cross-lingual\nsentiment analysis tasks.",
    "descriptor": "",
    "authors": [
      "Ehsan Imani",
      "Guojun Zhang",
      "Jun Luo",
      "Pascal Poupart",
      "Yangchen Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14960"
  },
  {
    "id": "arXiv:2211.14963",
    "title": "Neural Architecture for Online Ensemble Continual Learning",
    "abstract": "Continual learning with an increasing number of classes is a challenging\ntask. The difficulty rises when each example is presented exactly once, which\nrequires the model to learn online. Recent methods with classic parameter\noptimization procedures have been shown to struggle in such setups or have\nlimitations like non-differentiable components or memory buffers. For this\nreason, we present the fully differentiable ensemble method that allows us to\nefficiently train an ensemble of neural networks in the end-to-end regime. The\nproposed technique achieves SOTA results without a memory buffer and clearly\noutperforms the reference methods. The conducted experiments have also shown a\nsignificant increase in the performance for small ensembles, which demonstrates\nthe capability of obtaining relatively high classification accuracy with a\nreduced number of classifiers.",
    "descriptor": "",
    "authors": [
      "Mateusz W\u00f3jcik",
      "Witold Ko\u015bciukiewicz",
      "Tomasz Kajdanowicz",
      "Adam Gonczarek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14963"
  },
  {
    "id": "arXiv:2211.14966",
    "title": "Adversarial Rademacher Complexity of Deep Neural Networks",
    "abstract": "Deep neural networks are vulnerable to adversarial attacks. Ideally, a robust\nmodel shall perform well on both the perturbed training data and the unseen\nperturbed test data. It is found empirically that fitting perturbed training\ndata is not hard, but generalizing to perturbed test data is quite difficult.\nTo better understand adversarial generalization, it is of great interest to\nstudy the adversarial Rademacher complexity (ARC) of deep neural networks.\nHowever, how to bound ARC in multi-layers cases is largely unclear due to the\ndifficulty of analyzing adversarial loss in the definition of ARC. There have\nbeen two types of attempts of ARC. One is to provide the upper bound of ARC in\nlinear and one-hidden layer cases. However, these approaches seem hard to\nextend to multi-layer cases. Another is to modify the adversarial loss and\nprovide upper bounds of Rademacher complexity on such surrogate loss in\nmulti-layer cases. However, such variants of Rademacher complexity are not\nguaranteed to be bounds for meaningful robust generalization gaps (RGG). In\nthis paper, we provide a solution to this unsolved problem. Specifically, we\nprovide the first bound of adversarial Rademacher complexity of deep neural\nnetworks. Our approach is based on covering numbers. We provide a method to\nhandle the robustify function classes of DNNs such that we can calculate the\ncovering numbers. Finally, we provide experiments to study the empirical\nimplication of our bounds and provide an analysis of poor adversarial\ngeneralization.",
    "descriptor": "",
    "authors": [
      "Jiancong Xiao",
      "Yanbo Fan",
      "Ruoyu Sun",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14966"
  },
  {
    "id": "arXiv:2211.14969",
    "title": "Parallel Optimizations for the Hierarchical Poincar\u00e9-Steklov Scheme  (HPS)",
    "abstract": "Parallel optimizations for the 2D Hierarchical Poincar\\'e-Steklov (HPS)\ndiscretization scheme are described. HPS is a multi-domain spectral collocation\nscheme that allows for combining very high order discretizations with direct\nsolvers, making the discretization powerful in resolving highly oscillatory\nsolutions to high accuracy. HPS can be viewed as a domain decomposition scheme\nwhere the domains are connected directly through the use of a sparse direct\nsolver. This manuscript describes optimizations of HPS that are simple to\nimplement, and that leverage batched linear algebra on modern hybrid\narchitectures to improve the practical speed of the solver. In particular, the\nmanuscript demonstrates that the traditionally high cost of performing local\nstatic condensation for discretizations involving very high local order $p$ can\nbe reduced dramatically.",
    "descriptor": "",
    "authors": [
      "Anna Yesypenko",
      "Per-Gunnar Martinsson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14969"
  },
  {
    "id": "arXiv:2211.14977",
    "title": "QLAMMP: A Q-Learning Agent for Optimizing Fees on Automated Market  Making Protocols",
    "abstract": "Automated Market Makers (AMMs) have cemented themselves as an integral part\nof the decentralized finance (DeFi) space. AMMs are a type of exchange that\nallows users to trade assets without the need for a centralized exchange. They\nform the foundation for numerous decentralized exchanges (DEXs), which help\nfacilitate the quick and efficient exchange of on-chain tokens. All present-day\npopular DEXs are static protocols, with fixed parameters controlling the fee\nand the curvature - they suffer from invariance and cannot adapt to quickly\nchanging market conditions. This characteristic may cause traders to stay away\nduring high slippage conditions brought about by intractable market movements.\nWe propose an RL framework to optimize the fees collected on an AMM protocol.\nIn particular, we develop a Q-Learning Agent for Market Making Protocols\n(QLAMMP) that learns the optimal fee rates and leverage coefficients for a\ngiven AMM protocol and maximizes the expected fee collected under a range of\ndifferent market conditions. We show that QLAMMP is consistently able to\noutperform its static counterparts under all the simulated test conditions.",
    "descriptor": "",
    "authors": [
      "Dev Churiwala",
      "Bhaskar Krishnamachari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2211.14977"
  },
  {
    "id": "arXiv:2211.14980",
    "title": "Optimal Sparse Regression Trees",
    "abstract": "Regression trees are one of the oldest forms of AI models, and their\npredictions can be made without a calculator, which makes them broadly useful,\nparticularly for high-stakes applications. Within the large literature on\nregression trees, there has been little effort towards full provable\noptimization, mainly due to the computational hardness of the problem. This\nwork proposes a dynamic-programming-with-bounds approach to the construction of\nprovably-optimal sparse regression trees. We leverage a novel lower bound based\non an optimal solution to the k-Means clustering algorithm in 1-dimension over\nthe set of labels. We are often able to find optimal sparse trees in seconds,\neven for challenging datasets that involve large numbers of samples and\nhighly-correlated features.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Rui Zhang",
      "Rui Xin",
      "Margo Seltzer",
      "Cynthia Rudin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14980"
  },
  {
    "id": "arXiv:2211.14981",
    "title": "The Grind for Good Data: Understanding ML Practitioners' Struggles and  Aspirations in Making Good Data",
    "abstract": "We thought data to be simply given, but reality tells otherwise; it is\ncostly, situation-dependent, and muddled with dilemmas, constantly requiring\nhuman intervention. The ML community's focus on quality data is increasing in\nthe same vein, as good data is vital for successful ML systems. Nonetheless,\nfew works have investigated the dataset builders and the specifics of what they\ndo and struggle to make good data. In this study, through semi-structured\ninterviews with 19 ML experts, we present what humans actually do and consider\nin each step of the data construction pipeline. We further organize their\nstruggles under three themes: 1) trade-offs from real-world constraints; 2)\nharmonizing assorted data workers for consistency; 3) the necessity of human\nintuition and tacit knowledge for processing data. Finally, we discuss why such\nstruggles are inevitable for good data and what practitioners aspire, toward\nproviding systematic support for data works.",
    "descriptor": "",
    "authors": [
      "Inha Cha",
      "Juhyun Oh",
      "Cheul Young Park",
      "Jiyoon Han",
      "Hwalsuk Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.14981"
  },
  {
    "id": "arXiv:2211.14982",
    "title": "Two Is Better Than One: Dual Embeddings for Complementary Product  Recommendations",
    "abstract": "Embedding based product recommendations have gained popularity in recent\nyears due to its ability to easily integrate to large-scale systems and\nallowing nearest neighbor searches in real-time. The bulk of studies in this\narea has predominantly been focused on similar item recommendations. Research\non complementary item recommendations, on the other hand, still remains\nconsiderably under-explored. We define similar items as items that are\ninterchangeable in terms of their utility and complementary items as items that\nserve different purposes, yet are compatible when used with one another. In\nthis paper, we apply a novel approach to finding complementary items by\nleveraging dual embedding representations for products. We demonstrate that the\nnotion of relatedness discovered in NLP for skip-gram negative sampling (SGNS)\nmodels translates effectively to the concept of complementarity when training\nitem representations using co-purchase data. Since sparsity of purchase data is\na major challenge in real-world scenarios, we further augment the model using\nsynthetic samples to extend coverage. This allows the model to provide\ncomplementary recommendations for items that do not share co-purchase data by\nleveraging other abundantly available data modalities such as images, text,\nclicks etc. We establish the effectiveness of our approach in improving both\ncoverage and quality of recommendations on real world data for a major online\nretail company. We further show the importance of task specific hyperparameter\ntuning in training SGNS. Our model is effective yet simple to implement, making\nit a great candidate for generating complementary item recommendations at any\ne-commerce website.",
    "descriptor": "\nComments: Accepted at ICKG 2022\n",
    "authors": [
      "Giorgi Kvernadze",
      "Putu Ayu G. Sudyanti",
      "Nishan Subedi",
      "Mohammad Hajiaghayi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14982"
  },
  {
    "id": "arXiv:2211.14983",
    "title": "Multiagent Reinforcement Learning for Autonomous Routing and Pickup  Problem with Adaptation to Variable Demand",
    "abstract": "We derive a learning framework to generate routing/pickup policies for a\nfleet of vehicles tasked with servicing stochastically appearing requests on a\ncity map. We focus on policies that 1) give rise to coordination amongst the\nvehicles, thereby reducing wait times for servicing requests, 2) are\nnon-myopic, considering a-priori unknown potential future requests, and 3) can\nadapt to changes in the underlying demand distribution. Specifically, we are\ninterested in adapting to fluctuations of actual demand conditions in urban\nenvironments, such as on-peak vs. off-peak hours. We achieve this through a\ncombination of (i) online play, a lookahead optimization method that improves\nthe performance of rollout methods via an approximate policy iteration step,\nand (ii) an offline approximation scheme that allows for adapting to changes in\nthe underlying demand model. In particular, we achieve adaptivity of our\nlearned policy to different demand distributions by quantifying a region of\nvalidity using the q-valid radius of a Wasserstein Ambiguity Set. We propose a\nmechanism for switching the originally trained offline approximation when the\ncurrent demand is outside the original validity region. In this case, we\npropose to use an offline architecture, trained on a historical demand model\nthat is closer to the current demand in terms of Wasserstein distance. We learn\nrouting and pickup policies over real taxicab requests in downtown San\nFrancisco with high variability between on-peak and off-peak hours,\ndemonstrating the ability of our method to adapt to real fluctuation in demand\ndistributions. Our numerical results demonstrate that our method outperforms\nrollout-based reinforcement learning, as well as several benchmarks based on\nclassical methods from the field of operations research.",
    "descriptor": "\nComments: 7 pages, 6 figures, 3 tables, submitted to ICRA\n",
    "authors": [
      "Daniel Garces",
      "Sushmita Bhattacharya",
      "Stephanie Gil",
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14983"
  },
  {
    "id": "arXiv:2211.14984",
    "title": "RIS-assisted Scheduling for High-Speed Railway Secure Communications",
    "abstract": "With the rapid development of high-speed railway systems and railway wireless\ncommunication, the application of ultra-wideband millimeter wave band is an\ninevitable trend. However, the millimeter wave channel has large propagation\nloss and is easy to be blocked. Moreover, there are many problems such as\neavesdropping between the base station (BS) and the train. As an emerging\ntechnology, reconfigurable intelligent surface (RIS) can achieve the effect of\npassive beamforming by controlling the propagation of the incident\nelectromagnetic wave in the desired direction.We propose a RIS-assisted\nscheduling scheme for scheduling interrupted transmission and improving quality\nof service (QoS).In the propsed scheme, an RIS is deployed between the BS and\nmultiple mobile relays (MRs). By jointly optimizing the beamforming vector and\nthe discrete phase shift of the RIS, the constructive interference between\ndirect link signals and indirect link signals can be achieved, and the channel\ncapacity of eavesdroppers is guaranteed to be within a controllable range.\nFinally, the purpose of maximizing the number of successfully scheduled tasks\nand satisfying their QoS requirements can be practically realized. Extensive\nsimulations demonstrate that the proposed scheme has superior performance\nregarding the number of completed tasks and the system secrecy capacity over\nfour baseline schemes in literature.",
    "descriptor": "\nComments: 15 pages, 10 figures, to appear in IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Panpan Li",
      "Yong Niu",
      "Hao Wu",
      "Zhu Han",
      "Bo Ai",
      "Ning Wang",
      "Zhangdui Zhong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.14984"
  },
  {
    "id": "arXiv:2211.14985",
    "title": "CoMMA Protocol: Towards Complete Mitigation of Maximal Extractable Value  (MEV) Attacks",
    "abstract": "MEV attacks have been an omnipresent evil in the blockchain world, an\nimplicit tax that uninformed users pay for using the service. The problem\narises from the miners' ability to reorder and insert arbitrary transactions in\nthe blocks they mine. This paper proposes a 2-phased transaction protocol to\neliminate MEV attacks. The user requests an interaction token from the on-chain\ncounter-party. This token serves as a blind preemption for the counter-party\nand prevents the reordering of transactions at lower levels in the blockchain\nframework. We prove the correctness of the CoMMA protocol and demonstrate its\nefficacy against MEV attacks.",
    "descriptor": "",
    "authors": [
      "Dev Churiwala",
      "Bhaskar Krishnamachari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.14985"
  },
  {
    "id": "arXiv:2211.14987",
    "title": "Dual Information Enhanced Multi-view Attributed Graph Clustering",
    "abstract": "Multi-view attributed graph clustering is an important approach to partition\nmulti-view data based on the attribute feature and adjacent matrices from\ndifferent views. Some attempts have been made in utilizing Graph Neural Network\n(GNN), which have achieved promising clustering performance. Despite this, few\nof them pay attention to the inherent specific information embedded in multiple\nviews. Meanwhile, they are incapable of recovering the latent high-level\nrepresentation from the low-level ones, greatly limiting the downstream\nclustering performance. To fill these gaps, a novel Dual Information enhanced\nmulti-view Attributed Graph Clustering (DIAGC) method is proposed in this\npaper. Specifically, the proposed method introduces the Specific Information\nReconstruction (SIR) module to disentangle the explorations of the consensus\nand specific information from multiple views, which enables GCN to capture the\nmore essential low-level representations. Besides, the Mutual Information\nMaximization (MIM) module maximizes the agreement between the latent high-level\nrepresentation and low-level ones, and enables the high-level representation to\nsatisfy the desired clustering structure with the help of the Self-supervised\nClustering (SC) module. Extensive experiments on several real-world benchmarks\ndemonstrate the effectiveness of the proposed DIAGC method compared with the\nstate-of-the-art baselines.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Jia-Qi Lin",
      "Man-Sheng Chen",
      "Xi-Ran Zhu",
      "Chang-Dong Wang",
      "Haizhang Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14987"
  },
  {
    "id": "arXiv:2211.14995",
    "title": "Arguments to Key Points Mapping with Prompt-based Learning",
    "abstract": "Handling and digesting a huge amount of information in an efficient manner\nhas been a long-term demand in modern society. Some solutions to map key points\n(short textual summaries capturing essential information and filtering\nredundancies) to a large number of arguments/opinions have been provided\nrecently (Bar-Haim et al., 2020). To complement the full picture of the\nargument-to-keypoint mapping task, we mainly propose two approaches in this\npaper. The first approach is to incorporate prompt engineering for fine-tuning\nthe pre-trained language models (PLMs). The second approach utilizes\nprompt-based learning in PLMs to generate intermediary texts, which are then\ncombined with the original argument-keypoint pairs and fed as inputs to a\nclassifier, thereby mapping them. Furthermore, we extend the experiments to\ncross/in-domain to conduct an in-depth analysis. In our evaluation, we find\nthat i) using prompt engineering in a more direct way (Approach 1) can yield\npromising results and improve the performance; ii) Approach 2 performs\nconsiderably worse than Approach 1 due to the negation issue of the PLM.",
    "descriptor": "\nComments: Accepted at ICNLSP 2022\n",
    "authors": [
      "Ahnaf Mozib Samin",
      "Behrooz Nikandish",
      "Jingyan Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14995"
  },
  {
    "id": "arXiv:2211.14998",
    "title": "Anderson Acceleration for Partially Observable Markov Decision  Processes: A Maximum Entropy Approach",
    "abstract": "Partially observable Markov decision processes (POMDPs) is a rich\nmathematical framework that embraces a large class of complex sequential\ndecision-making problems under uncertainty with limited observations. However,\nthe complexity of POMDPs poses various computational challenges, motivating the\nneed for an efficient algorithm that rapidly finds a good enough suboptimal\nsolution. In this paper, we propose a novel accelerated offline POMDP algorithm\nexploiting Anderson acceleration (AA) that is capable of efficiently solving\nfixed-point problems using previous solution estimates. Our algorithm is based\non the Q-function approximation (QMDP) method to alleviate the scalability\nissue inherent in POMDPs. Inspired by the quasi-Newton interpretation of AA, we\npropose a maximum entropy variant of QMDP, which we call soft QMDP, to fully\nbenefit from AA. We prove that the overall algorithm converges to the\nsuboptimal solution obtained by soft QMDP. Our algorithm can also be\nimplemented in a model-free manner using simulation data. Provable error bounds\non the residual and the solution are provided to examine how the simulation\nerrors are propagated through the proposed algorithm. Finally, the performance\nof our algorithm is tested on several benchmark problems. According to the\nresults of our experiments, the proposed algorithm converges significantly\nfaster without degrading the solution quality compared to its standard\ncounterparts.",
    "descriptor": "",
    "authors": [
      "Mingyu Park",
      "Jaeuk Shin",
      "Insoon Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14998"
  },
  {
    "id": "arXiv:2211.15003",
    "title": "STAGE: Span Tagging and Greedy Inference Scheme for Aspect Sentiment  Triplet Extraction",
    "abstract": "Aspect Sentiment Triplet Extraction (ASTE) has become an emerging task in\nsentiment analysis research, aiming to extract triplets of the aspect term, its\ncorresponding opinion term, and its associated sentiment polarity from a given\nsentence. Recently, many neural networks based models with different tagging\nschemes have been proposed, but almost all of them have their limitations:\nheavily relying on 1) prior assumption that each word is only associated with a\nsingle role (e.g., aspect term, or opinion term, etc. ) and 2) word-level\ninteractions and treating each opinion/aspect as a set of independent words.\nHence, they perform poorly on the complex ASTE task, such as a word associated\nwith multiple roles or an aspect/opinion term with multiple words. Hence, we\npropose a novel approach, Span TAgging and Greedy infErence (STAGE), to extract\nsentiment triplets in span-level, where each span may consist of multiple words\nand play different roles simultaneously. To this end, this paper formulates the\nASTE task as a multi-class span classification problem. Specifically, STAGE\ngenerates more accurate aspect sentiment triplet extractions via exploring\nspan-level information and constraints, which consists of two components,\nnamely, span tagging scheme and greedy inference strategy. The former tag all\npossible candidate spans based on a newly-defined tagging set. The latter\nretrieves the aspect/opinion term with the maximum length from the candidate\nsentiment snippet to output sentiment triplets. Furthermore, we propose a\nsimple but effective model based on the STAGE, which outperforms the\nstate-of-the-arts by a large margin on four widely-used datasets. Moreover, our\nSTAGE can be easily generalized to other pair/triplet extraction tasks, which\nalso demonstrates the superiority of the proposed scheme STAGE.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Shuo Liang",
      "Wei Wei",
      "Xian-Ling Mao",
      "Yuanyuan Fu",
      "Rui Fang",
      "Dangyang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15003"
  },
  {
    "id": "arXiv:2211.15006",
    "title": "Fine-tuning language models to find agreement among humans with diverse  preferences",
    "abstract": "Recent work in large language modeling (LLMs) has used fine-tuning to align\noutputs with the preferences of a prototypical user. This work assumes that\nhuman preferences are static and homogeneous across individuals, so that\naligning to a a single \"generic\" user will confer more general alignment. Here,\nwe embrace the heterogeneity of human preferences to consider a different\nchallenge: how might a machine help people with diverse views find agreement?\nWe fine-tune a 70 billion parameter LLM to generate statements that maximize\nthe expected approval for a group of people with potentially diverse opinions.\nHuman participants provide written opinions on thousands of questions touching\non moral and political issues (e.g., \"should we raise taxes on the rich?\"), and\nrate the LLM's generated candidate consensus statements for agreement and\nquality. A reward model is then trained to predict individual preferences,\nenabling it to quantify and rank consensus statements in terms of their appeal\nto the overall group, defined according to different aggregation (social\nwelfare) functions. The model produces consensus statements that are preferred\nby human users over those from prompted LLMs (>70%) and significantly\noutperforms a tight fine-tuned baseline that lacks the final ranking step.\nFurther, our best model's consensus statements are preferred over the best\nhuman-generated opinions (>65%). We find that when we silently constructed\nconsensus statements from only a subset of group members, those who were\nexcluded were more likely to dissent, revealing the sensitivity of the\nconsensus to individual contributions. These results highlight the potential to\nuse LLMs to help groups of humans align their values with one another.",
    "descriptor": "",
    "authors": [
      "Michiel A. Bakker",
      "Martin J. Chadwick",
      "Hannah R. Sheahan",
      "Michael Henry Tessler",
      "Lucy Campbell-Gillingham",
      "Jan Balaguer",
      "Nat McAleese",
      "Amelia Glaese",
      "John Aslanides",
      "Matthew M. Botvinick",
      "Christopher Summerfield"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15006"
  },
  {
    "id": "arXiv:2211.15007",
    "title": "An Exploration of Cross-Patch Collaborations via Patch Linkage in  OpenStack",
    "abstract": "Contemporary development projects benefit from code review as it improves the\nquality of a project. Large ecosystems of inter-dependent projects like\nOpenStack generate a large number of reviews, which poses new challenges for\ncollaboration (improving patches, fixing defects). Review tools allow\ndevelopers to link between patches, to indicate patch dependency, competing\nsolutions, or provide broader context. We hypothesize that such patch linkage\nmay also simulate cross-collaboration.\nWith a case study of OpenStack, we take a first step to explore\ncollaborations that occur after a patch linkage was posted between two patches\n(i.e., cross-patch collaboration). Our empirical results show that although\npatch linkage that requests collaboration is relatively less prevalent, the\nprobability of collaboration is relatively higher. Interestingly, the results\nalso show that collaborative contributions via patch linkage are non-trivial,\ni.e, contributions can affect the review outcome (such as voting) or even\nimprove the patch (i.e., revising). This work opens up future directions to\nunderstand barriers and opportunities related to this new kind of\ncollaboration, that assists with code review and development tasks in large\necosystems.",
    "descriptor": "",
    "authors": [
      "Dong Wang",
      "Patanamon Thongtanunam",
      "Raula Gaikovina Kula",
      "Kenichi Matsumoto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.15007"
  },
  {
    "id": "arXiv:2211.15009",
    "title": "BJTU-WeChat's Systems for the WMT22 Chat Translation Task",
    "abstract": "This paper introduces the joint submission of the Beijing Jiaotong University\nand WeChat AI to the WMT'22 chat translation task for English-German. Based on\nthe Transformer, we apply several effective variants. In our experiments, we\nutilize the pre-training-then-fine-tuning paradigm. In the first pre-training\nstage, we employ data filtering and synthetic data generation (i.e.,\nback-translation, forward-translation, and knowledge distillation). In the\nsecond fine-tuning stage, we investigate speaker-aware in-domain data\ngeneration, speaker adaptation, prompt-based context modeling, target denoising\nfine-tuning, and boosted self-COMET-based model ensemble. Our systems achieve\n0.810 and 0.946 COMET scores. The COMET scores of English-German and\nGerman-English are the highest among all submissions.",
    "descriptor": "\nComments: Accepted by WMT 2022 as a system paper\n",
    "authors": [
      "Yunlong Liang",
      "Fandong Meng",
      "Jinan Xu",
      "Yufeng Chen",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15009"
  },
  {
    "id": "arXiv:2211.15013",
    "title": "Enhancing Data Security for Cloud Computing Applications through  Distributed Blockchain-based SDN Architecture in IoT Networks",
    "abstract": "Blockchain (BC) and Software Defined Networking (SDN) are some of the most\nprominent emerging technologies in recent research. These technologies provide\nsecurity, integrity, as well as confidentiality in their respective\napplications. Cloud computing has also been a popular comprehensive technology\nfor several years. Confidential information is often shared with the cloud\ninfrastructure to give customers access to remote resources, such as\ncomputation and storage operations. However, cloud computing also presents\nsubstantial security threats, issues, and challenges. Therefore, to overcome\nthese difficulties, we propose integrating Blockchain and SDN in the cloud\ncomputing platform. In this research, we introduce the architecture to better\nsecure clouds. Moreover, we leverage a distributed Blockchain approach to\nconvey security, confidentiality, privacy, integrity, adaptability, and\nscalability in the proposed architecture. BC provides a distributed or\ndecentralized and efficient environment for users. Also, we present an SDN\napproach to improving the reliability, stability, and load balancing\ncapabilities of the cloud infrastructure. Finally, we provide an experimental\nevaluation of the performance of our SDN and BC-based implementation using\ndifferent parameters, also monitoring some attacks in the system and proving\nits efficacy.",
    "descriptor": "\nComments: 12 Pages 16 Figures 3 Tables\n",
    "authors": [
      "Anichur Rahman",
      "Md. Jahidul Islam",
      "Rafiqul Islam",
      "Ayesha Aziz",
      "Dipanjali Kundu",
      "Sadia Sazzad",
      "Md. Razaul Karim",
      "Mahedi Hasan",
      "Ziaur Rahman",
      "Said Elnaffar",
      "Shahab S. Band"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15013"
  },
  {
    "id": "arXiv:2211.15022",
    "title": "Summer: WeChat Neural Machine Translation Systems for the WMT22  Biomedical Translation Task",
    "abstract": "This paper introduces WeChat's participation in WMT 2022 shared biomedical\ntranslation task on Chinese to English. Our systems are based on the\nTransformer, and use several different Transformer structures to improve the\nquality of translation. In our experiments, we employ data filtering, data\ngeneration, several variants of Transformer, fine-tuning and model ensemble.\nOur Chinese$\\to$English system, named Summer, achieves the highest BLEU score\namong all submissions.",
    "descriptor": "",
    "authors": [
      "Ernan Li",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15022"
  },
  {
    "id": "arXiv:2211.15023",
    "title": "AcceRL: Policy Acceleration Framework for Deep Reinforcement Learning",
    "abstract": "Deep reinforcement learning has achieved great success in various fields with\nits super decision-making ability. However, the policy learning process\nrequires a large amount of training time, causing energy consumption. Inspired\nby the redundancy of neural networks, we propose a lightweight parallel\ntraining framework based on neural network compression, AcceRL, to accelerate\nthe policy learning while ensuring policy quality. Specifically, AcceRL speeds\nup the experience collection by flexibly combining various neural network\ncompression methods. Overall, the AcceRL consists of five components, namely\nActor, Learner, Compressor, Corrector, and Monitor. The Actor uses the\nCompressor to compress the Learner's policy network to interact with the\nenvironment. And the generated experiences are transformed by the Corrector\nwith Off-Policy methods, such as V-trace, Retrace and so on. Then the corrected\nexperiences are feed to the Learner for policy learning. We believe this is the\nfirst general reinforcement learning framework that incorporates multiple\nneural network compression techniques. Extensive experiments conducted in gym\nshow that the AcceRL reduces the time cost of the actor by about 2.0 X to 4.13\nX compared to the traditional methods. Furthermore, the AcceRL reduces the\nwhole training time by about 29.8% to 40.3% compared to the traditional methods\nwhile keeps the same policy quality.",
    "descriptor": "\nComments: 14 pages, 50 figures\n",
    "authors": [
      "Hongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15023"
  },
  {
    "id": "arXiv:2211.15025",
    "title": "Biot model with generalized eigenvalue problems for scalability and  robustness to parameters",
    "abstract": "We consider Biot model with block preconditioners and generalized eigenvalue\nproblems for scalability and robustness to parameters. A discontinuous Galerkin\ndiscretization is employed with the displacement and Darcy flow flux\ndiscretized as piecewise continuous in $P_1$ elements, and the pore pressure as\npiecewise constant in the $P_0$ element with a stabilizing term. Parallel\nalgorithms are designed to solve the resulting linear system. Specifically, the\nGMRES method is employed as the outer iteration algorithm and block-triangular\npreconditioners are designed to accelerate the convergence. In the\npreconditioners, the elliptic operators are further approximated by using\nincomplete Cholesky factorization or two-level additive overlapping Schwartz\nmethod where coarse grids are constructed by generalized eigenvalue problems in\nthe overlaps (GenEO). Extensive numerical experiments show a scalability and\nparametric robustness of the resulting parallel algorithms.",
    "descriptor": "\nComments: Submitted to the 27th International Conference on Domain Decomposition Methods (DD27), 8 pages, 1 figure\n",
    "authors": [
      "Pilhwa Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.15025"
  },
  {
    "id": "arXiv:2211.15028",
    "title": "Joint Multimodal Entity-Relation Extraction Based on Edge-enhanced Graph  Alignment Network and Word-pair Relation Tagging",
    "abstract": "Multimodal named entity recognition (MNER) and multimodal relation extraction\n(MRE) are two fundamental subtasks in the multimodal knowledge graph\nconstruction task. However, the existing methods usually handle two tasks\nindependently, which ignores the bidirectional interaction between them. This\npaper is the first to propose jointly performing MNER and MRE as a joint\nmultimodal entity-relation extraction task (JMERE). Besides, the current MNER\nand MRE models only consider aligning the visual objects with textual entities\nin visual and textual graphs but ignore the entity-entity relationships and\nobject-object relationships. To address the above challenges, we propose an\nedge-enhanced graph alignment network and a word-pair relation tagging (EEGA)\nfor JMERE task. Specifically, we first design a word-pair relation tagging to\nexploit the bidirectional interaction between MNER and MRE and avoid the error\npropagation. Then, we propose an edge-enhanced graph alignment network to\nenhance the JMERE task by aligning nodes and edges in the cross-graph. Compared\nwith previous methods, the proposed method can leverage the edge information to\nauxiliary alignment between objects and entities and find the correlations\nbetween entity-entity relationships and object-object relationships.\nExperiments are conducted to show the effectiveness of our model.",
    "descriptor": "\nComments: accepted in AAAI-2023\n",
    "authors": [
      "Li Yuan",
      "Yi Cai",
      "Jin Wang",
      "Qing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.15028"
  },
  {
    "id": "arXiv:2211.15029",
    "title": "DiffusionBERT: Improving Generative Masked Language Models with  Diffusion Models",
    "abstract": "We present DiffusionBERT, a new generative masked language model based on\ndiscrete diffusion models. Diffusion models and many pre-trained language\nmodels have a shared training objective, i.e., denoising, making it possible to\ncombine the two powerful models and enjoy the best of both worlds. On the one\nhand, diffusion models offer a promising training strategy that helps improve\nthe generation quality. On the other hand, pre-trained denoising language\nmodels (e.g., BERT) can be used as a good initialization that accelerates\nconvergence. We explore training BERT to learn the reverse process of a\ndiscrete diffusion process with an absorbing state and elucidate several\ndesigns to improve it. First, we propose a new noise schedule for the forward\ndiffusion process that controls the degree of noise added at each step based on\nthe information of each token. Second, we investigate several designs of\nincorporating the time step into BERT. Experiments on unconditional text\ngeneration demonstrate that DiffusionBERT achieves significant improvement over\nexisting diffusion models for text (e.g., D3PM and Diffusion-LM) and previous\ngenerative masked language models in terms of perplexity and BLEU score.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Zhengfu He",
      "Tianxiang Sun",
      "Kuanning Wang",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15029"
  },
  {
    "id": "arXiv:2211.15030",
    "title": "Imperceptible Adversarial Attack via Invertible Neural Networks",
    "abstract": "Adding perturbations via utilizing auxiliary gradient information or\ndiscarding existing details of the benign images are two common approaches for\ngenerating adversarial examples. Though visual imperceptibility is the desired\nproperty of adversarial examples, conventional adversarial attacks still\ngenerate traceable adversarial perturbations. In this paper, we introduce a\nnovel Adversarial Attack via Invertible Neural Networks (AdvINN) method to\nproduce robust and imperceptible adversarial examples. Specifically, AdvINN\nfully takes advantage of the information preservation property of Invertible\nNeural Networks and thereby generates adversarial examples by simultaneously\nadding class-specific semantic information of the target class and dropping\ndiscriminant information of the original class. Extensive experiments on\nCIFAR-10, CIFAR-100, and ImageNet-1K demonstrate that the proposed AdvINN\nmethod can produce less imperceptible adversarial images than the\nstate-of-the-art methods and AdvINN yields more robust adversarial examples\nwith high confidence compared to other adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Zihan Chen",
      "Ziyue Wang",
      "Junjie Huang",
      "Wentao Zhao",
      "Xiao Liu",
      "Dejian Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.15030"
  },
  {
    "id": "arXiv:2211.15034",
    "title": "Quantile Constrained Reinforcement Learning: A Reinforcement Learning  Framework Constraining Outage Probability",
    "abstract": "Constrained reinforcement learning (RL) is an area of RL whose objective is\nto find an optimal policy that maximizes expected cumulative return while\nsatisfying a given constraint. Most of the previous constrained RL works\nconsider expected cumulative sum cost as the constraint. However, optimization\nwith this constraint cannot guarantee a target probability of outage event that\nthe cumulative sum cost exceeds a given threshold. This paper proposes a\nframework, named Quantile Constrained RL (QCRL), to constrain the quantile of\nthe distribution of the cumulative sum cost that is a necessary and sufficient\ncondition to satisfy the outage constraint. This is the first work that tackles\nthe issue of applying the policy gradient theorem to the quantile and provides\ntheoretical results for approximating the gradient of the quantile. Based on\nthe derived theoretical results and the technique of the Lagrange multiplier,\nwe construct a constrained RL algorithm named Quantile Constrained Policy\nOptimization (QCPO). We use distributional RL with the Large Deviation\nPrinciple (LDP) to estimate quantiles and tail probability of the cumulative\nsum cost for the implementation of QCPO. The implemented algorithm satisfies\nthe outage probability constraint after the training period.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Whiyoung Jung",
      "Myungsik Cho",
      "Jongeui Park",
      "Youngchul Sung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15034"
  },
  {
    "id": "arXiv:2211.15036",
    "title": "Quantized control of non-Lipschitz nonlinear systems: a novel control  framework with prescribed transient performance and lower design complexity",
    "abstract": "A novel control design framework is proposed for a class of non-Lipschitz\nnonlinear systems with quantized states, meanwhile prescribed transient\nperformance and lower control design complexity could be guaranteed. Firstly,\ndifferent from all existing control methods for systems with state\nquantization, global stability of strict-feedback nonlinear systems is achieved\nwithout requiring the condition that the nonlinearities of the system model\nsatisfy global Lipschitz continuity. Secondly, a novel barrier function-free\nprescribed performance control (BFPPC) method is proposed, which can guarantee\nprescribed transient performance under quantized states. Thirdly, a new\n\\textit{W}-function-based control scheme is designed such that virtual control\nsignals are not required to be differentiated repeatedly and the controller\ncould be designed in a simple way, which guarantees global stability and lower\ndesign complexity compared with traditional dynamic surface control (DSC).\nSimulation results demonstrate the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Zongcheng Liu",
      "Jiangshuai Huang",
      "Changyun Wen",
      "Jing Zhou",
      "Xiucai Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15036"
  },
  {
    "id": "arXiv:2211.15037",
    "title": "SongRewriter: A Chinese Song Rewriting System with Controllable Content  and Rhyme Scheme",
    "abstract": "Although lyrics generation has achieved significant progress in recent years,\nit has limited practical applications because the generated lyrics cannot be\nperformed without composing compatible melodies. In this work, we bridge this\npractical gap by proposing a song rewriting system which rewrites the lyrics of\nan existing song such that the generated lyrics are compatible with the rhythm\nof the existing melody and thus singable. In particular, we propose\nSongRewriter, a controllable Chinese lyric generation and editing system which\nassists users without prior knowledge of melody composition. The system is\ntrained by a randomized multi-level masking strategy which produces a unified\nmodel for generating entirely new lyrics or editing a few fragments. To improve\nthe controllabiliy of the generation process, we further incorporate a keyword\nprompt to control the lexical choices of the content and propose novel decoding\nconstraints and a vowel modeling task to enable flexible end and internal rhyme\nschemes. While prior rhyming metrics are mainly for rap lyrics, we propose\nthree novel rhyming evaluation metrics for song lyrics. Both automatic and\nhuman evaluations show that the proposed model performs better than the\nstate-of-the-art models in both contents and rhyming quality. Our code and\nmodels implemented in MindSpore Lite tool will be available.",
    "descriptor": "",
    "authors": [
      "Yusen Sun",
      "Liangyou Li",
      "Qun Liu",
      "Dit-Yan Yeung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15037"
  },
  {
    "id": "arXiv:2211.15039",
    "title": "Renmin University of China at TRECVID 2022: Improving Video Search by  Feature Fusion and Negation Understanding",
    "abstract": "We summarize our TRECVID 2022 Ad-hoc Video Search (AVS) experiments. Our\nsolution is built with two new techniques, namely Lightweight Attentional\nFeature Fusion (LAFF) for combining diverse visual / textual features and\nBidirectional Negation Learning (BNL) for addressing queries that contain\nnegation cues. In particular, LAFF performs feature fusion at both early and\nlate stages and at both text and video ends to exploit diverse (off-the-shelf)\nfeatures. Compared to multi-head self attention, LAFF is much more compact yet\nmore effective. Its attentional weights can also be used for selecting fewer\nfeatures, with the retrieval performance mostly preserved. BNL trains a\nnegation-aware video retrieval model by minimizing a bidirectionally\nconstrained loss per triplet, where a triplet consists of a given training\nvideo, its original description and a partially negated description. For video\nfeature extraction, we use pre-trained CLIP, BLIP, BEiT, ResNeXt-101 and irCSN.\nAs for text features, we adopt bag-of-words, word2vec, CLIP and BLIP. Our\ntraining data consists of MSR-VTT, TGIF and VATEX that were used in our\nprevious participation. In addition, we automatically caption the V3C1\ncollection for pre-training. The 2022 edition of the TRECVID benchmark has\nagain been a fruitful participation for the RUCMM team. Our best run, with an\ninfAP of 0.262, is ranked at the second place teamwise.",
    "descriptor": "",
    "authors": [
      "Xirong Li",
      "Aozhu Chen",
      "Ziyue Wang",
      "Fan Hu",
      "Kaibin Tian",
      "Xinru Chen",
      "Chengbo Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.15039"
  },
  {
    "id": "arXiv:2211.15043",
    "title": "Higher-order Knowledge Transfer for Dynamic Community Detection with  Great Changes",
    "abstract": "Network structure evolves with time in the real world, and the discovery of\nchanging communities in dynamic networks is an important research topic that\nposes challenging tasks. Most existing methods assume that no significant\nchange in the network occurs; namely, the difference between adjacent snapshots\nis slight. However, great change exists in the real world usually. The great\nchange in the network will result in the community detection algorithms are\ndifficulty obtaining valuable information from the previous snapshot, leading\nto negative transfer for the next time steps. This paper focuses on dynamic\ncommunity detection with substantial changes by integrating higher-order\nknowledge from the previous snapshots to aid the subsequent snapshots.\nMoreover, to improve search efficiency, a higher-order knowledge transfer\nstrategy is designed to determine first-order and higher-order knowledge by\ndetecting the similarity of the adjacency matrix of snapshots. In this way, our\nproposal can better keep the advantages of previous community detection results\nand transfer them to the next task. We conduct the experiments on four\nreal-world networks, including the networks with great or minor changes.\nExperimental results in the low-similarity datasets demonstrate that\nhigher-order knowledge is more valuable than first-order knowledge when the\nnetwork changes significantly and keeps the advantage even if handling the\nhigh-similarity datasets. Our proposal can also guide other dynamic\noptimization problems with great changes.",
    "descriptor": "\nComments: Submitted to IEEE TEVC\n",
    "authors": [
      "Huixin Ma",
      "Kai Wu",
      "Handing Wang",
      "Jing Liu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.15043"
  },
  {
    "id": "arXiv:2211.15044",
    "title": "Machine Learning Accelerated PDE Backstepping Observers",
    "abstract": "State estimation is important for a variety of tasks, from forecasting to\nsubstituting for unmeasured states in feedback controllers. Performing\nreal-time state estimation for PDEs using provably and rapidly converging\nobservers, such as those based on PDE backstepping, is computationally\nexpensive and in many cases prohibitive. We propose a framework for\naccelerating PDE observer computations using learning-based approaches that are\nmuch faster while maintaining accuracy. In particular, we employ the\nrecently-developed Fourier Neural Operator (FNO) to learn the functional\nmapping from the initial observer state and boundary measurements to the state\nestimate. By employing backstepping observer gains for previously-designed\nobservers with particular convergence rate guarantees, we provide numerical\nexperiments that evaluate the increased computational efficiency gained with\nFNO. We consider the state estimation for three benchmark PDE examples\nmotivated by applications: first, for a reaction-diffusion (parabolic) PDE\nwhose state is estimated with an exponential rate of convergence; second, for a\nparabolic PDE with exact prescribed-time estimation; and, third, for a pair of\ncoupled first-order hyperbolic PDEs that modeling traffic flow density and\nvelocity. The ML-accelerated observers trained on simulation data sets for\nthese PDEs achieves up to three orders of magnitude improvement in\ncomputational speed compared to classical methods. This demonstrates the\nattractiveness of the ML-accelerated observers for real-time state estimation\nand control.",
    "descriptor": "\nComments: Accepted to the 61st IEEE Conference on Decision and Control (CDC), 2022\n",
    "authors": [
      "Yuanyuan Shi",
      "Zongyi Li",
      "Huan Yu",
      "Drew Steeves",
      "Anima Anandkumar",
      "Miroslav Krstic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15044"
  },
  {
    "id": "arXiv:2211.15045",
    "title": "CLIP2GAN: Towards Bridging Text with the Latent Space of GANs",
    "abstract": "In this work, we are dedicated to text-guided image generation and propose a\nnovel framework, i.e., CLIP2GAN, by leveraging CLIP model and StyleGAN. The key\nidea of our CLIP2GAN is to bridge the output feature embedding space of CLIP\nand the input latent space of StyleGAN, which is realized by introducing a\nmapping network. In the training stage, we encode an image with CLIP and map\nthe output feature to a latent code, which is further used to reconstruct the\nimage. In this way, the mapping network is optimized in a self-supervised\nlearning way. In the inference stage, since CLIP can embed both image and text\ninto a shared feature embedding space, we replace CLIP image encoder in the\ntraining architecture with CLIP text encoder, while keeping the following\nmapping network as well as StyleGAN model. As a result, we can flexibly input a\ntext description to generate an image. Moreover, by simply adding mapped text\nfeatures of an attribute to a mapped CLIP image feature, we can effectively\nedit the attribute to the image. Extensive experiments demonstrate the superior\nperformance of our proposed CLIP2GAN compared to previous methods.",
    "descriptor": "",
    "authors": [
      "Yixuan Wang",
      "Wengang Zhou",
      "Jianmin Bao",
      "Weilun Wang",
      "Li Li",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15045"
  },
  {
    "id": "arXiv:2211.15046",
    "title": "Regional Precipitation Nowcasting Based on CycleGAN Extension",
    "abstract": "Unusually, intensive heavy rain hit the central region of Korea on August 8,\n2022. Many low-lying areas were submerged, so traffic and life were severely\nparalyzed. It was the critical damage caused by torrential rain for just a few\nhours. This event reminded us of the need for a more reliable regional\nprecipitation nowcasting method. In this paper, we bring cycle-consistent\nadversarial networks (CycleGAN) into the time-series domain and extend it to\npropose a reliable model for regional precipitation nowcasting. The proposed\nmodel generates composite hybrid surface rainfall (HSR) data after 10 minutes\nfrom the present time. Also, the proposed model provides a reliable prediction\nof up to 2 hours with a gradual extension of the training time steps. Unlike\nthe existing complex nowcasting methods, the proposed model does not use\nrecurrent neural networks (RNNs) and secures temporal causality via sequential\ntraining in the cycle. Our precipitation nowcasting method outperforms\nconvolutional long short-term memory (ConvLSTM) based on RNNs. Additionally, we\ndemonstrate the superiority of our approach by qualitative and quantitative\ncomparisons against MAPLE, the McGill algorithm for precipitation nowcasting by\nlagrangian extrapolation, one of the real quantitative precipitation forecast\n(QPF) models.",
    "descriptor": "",
    "authors": [
      "Jaeho Choi",
      "Yura Kim",
      "Kwang-Ho Kim",
      "Sung-Hwa Jung",
      "Ikhyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15046"
  },
  {
    "id": "arXiv:2211.15055",
    "title": "AdaTask: A Task-aware Adaptive Learning Rate Approach to Multi-task  Learning",
    "abstract": "Multi-task learning (MTL) models have demonstrated impressive results in\ncomputer vision, natural language processing, and recommender systems. Even\nthough many approaches have been proposed, how well these approaches balance\ndifferent tasks on each parameter still remains unclear. In this paper, we\npropose to measure the task dominance degree of a parameter by the total\nupdates of each task on this parameter. Specifically, we compute the total\nupdates by the exponentially decaying Average of the squared Updates (AU) on a\nparameter from the corresponding task.Based on this novel metric, we observe\nthat many parameters in existing MTL methods, especially those in the higher\nshared layers, are still dominated by one or several tasks. The dominance of AU\nis mainly due to the dominance of accumulative gradients from one or several\ntasks. Motivated by this, we propose a Task-wise Adaptive learning rate\napproach, AdaTask in short, to separate the \\emph{accumulative gradients} and\nhence the learning rate of each task for each parameter in adaptive learning\nrate approaches (e.g., AdaGrad, RMSProp, and Adam). Comprehensive experiments\non computer vision and recommender system MTL datasets demonstrate that AdaTask\nsignificantly improves the performance of dominated tasks, resulting SOTA\naverage task-wise performance. Analysis on both synthetic and real-world\ndatasets shows AdaTask balance parameters in every shared layer well.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Enneng Yang",
      "Junwei Pan",
      "Ximei Wang",
      "Haibin Yu",
      "Li Shen",
      "Xihua Chen",
      "Lei Xiao",
      "Jie Jiang",
      "Guibing Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.15055"
  },
  {
    "id": "arXiv:2211.15057",
    "title": "An adaptive shortest-solution guided decimation approach to sparse  high-dimensional linear regression",
    "abstract": "High-dimensional linear regression model is the most popular statistical\nmodel for high-dimensional data, but it is quite a challenging task to achieve\na sparse set of regression coefficients. In this paper, we propose a simple\nheuristic algorithm to construct sparse high-dimensional linear regression\nmodels, which is adapted from the shortest solution-guided decimation algorithm\nand is referred to as ASSD. This algorithm constructs the support of regression\ncoefficients under the guidance of the least-squares solution of the\nrecursively decimated linear equations, and it applies an early-stopping\ncriterion and a second-stage thresholding procedure to refine this support. Our\nextensive numerical results demonstrate that ASSD outperforms LASSO, vector\napproximate message passing, and two other representative greedy algorithms in\nsolution accuracy and robustness. ASSD is especially suitable for linear\nregression problems with highly correlated measurement matrices encountered in\nreal-world applications.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Xue Yu",
      "Yifan Sun",
      "Haijun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.15057"
  },
  {
    "id": "arXiv:2211.15058",
    "title": "Mix and Localize: Localizing Sound Sources in Mixtures",
    "abstract": "We present a method for simultaneously localizing multiple sound sources\nwithin a visual scene. This task requires a model to both group a sound mixture\ninto individual sources, and to associate them with a visual signal. Our method\njointly solves both tasks at once, using a formulation inspired by the\ncontrastive random walk of Jabri et al. We create a graph in which images and\nseparated sounds correspond to nodes, and train a random walker to transition\nbetween nodes from different modalities with high return probability. The\ntransition probabilities for this walk are determined by an audio-visual\nsimilarity metric that is learned by our model. We show through experiments\nwith musical instruments and human speech that our model can successfully\nlocalize multiple sounds, outperforming other self-supervised methods. Project\nsite: https://hxixixh.github.io/mix-and-localize",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Xixi Hu",
      "Ziyang Chen",
      "Andrew Owens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15058"
  },
  {
    "id": "arXiv:2211.15059",
    "title": "Learning Dense Object Descriptors from Multiple Views for Low-shot  Category Generalization",
    "abstract": "A hallmark of the deep learning era for computer vision is the successful use\nof large-scale labeled datasets to train feature representations for tasks\nranging from object recognition and semantic segmentation to optical flow\nestimation and novel view synthesis of 3D scenes. In this work, we aim to learn\ndense discriminative object representations for low-shot category recognition\nwithout requiring any category labels. To this end, we propose Deep Object\nPatch Encodings (DOPE), which can be trained from multiple views of object\ninstances without any category or semantic object part labels. To train DOPE,\nwe assume access to sparse depths, foreground masks and known cameras, to\nobtain pixel-level correspondences between views of an object, and use this to\nformulate a self-supervised learning task to learn discriminative object\npatches. We find that DOPE can directly be used for low-shot classification of\nnovel categories using local-part matching, and is competitive with and\noutperforms supervised and self-supervised learning baselines. Code and data\navailable at https://github.com/rehg-lab/dope_selfsup.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. Code and data available at this https URL\n",
    "authors": [
      "Stefan Stojanov",
      "Anh Thai",
      "Zixuan Huang",
      "James M. Rehg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15059"
  },
  {
    "id": "arXiv:2211.15060",
    "title": "Interactive Visual Feature Search",
    "abstract": "Many visualization techniques have been created to help explain the behavior\nof convolutional neural networks (CNNs), but they largely consist of static\ndiagrams that convey limited information. Interactive visualizations can\nprovide more rich insights and allow users to more easily explore a model's\nbehavior; however, they are typically not easily reusable and are specific to a\nparticular model.\nWe introduce Visual Feature Search, a novel interactive visualization that is\ngeneralizable to any CNN and can easily be incorporated into a researcher's\nworkflow. Our tool allows a user to highlight an image region and search for\nimages from a given dataset with the most similar CNN features. It supports\nsearching through large image datasets with an efficient cache-based search\nimplementation. We demonstrate how our tool elucidates different aspects of\nmodel behavior by performing experiments on supervised, self-supervised, and\nhuman-edited CNNs. We also release a portable Python library and several\nIPython notebooks to enable researchers to easily use our tool in their own\nexperiments. Our code can be found at\nhttps://github.com/lookingglasslab/VisualFeatureSearch.",
    "descriptor": "",
    "authors": [
      "Devon Ulrich",
      "Ruth Fong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15060"
  },
  {
    "id": "arXiv:2211.15064",
    "title": "High-fidelity Facial Avatar Reconstruction from Monocular Video with  Generative Priors",
    "abstract": "High-fidelity facial avatar reconstruction from a monocular video is a\nsignificant research problem in computer graphics and computer vision.\nRecently, Neural Radiance Field (NeRF) has shown impressive novel view\nrendering results and has been considered for facial avatar reconstruction.\nHowever, the complex facial dynamics and missing 3D information in monocular\nvideos raise significant challenges for faithful facial reconstruction. In this\nwork, we propose a new method for NeRF-based facial avatar reconstruction that\nutilizes 3D-aware generative prior. Different from existing works that depend\non a conditional deformation field for dynamic modeling, we propose to learn a\npersonalized generative prior, which is formulated as a local and low\ndimensional subspace in the latent space of 3D-GAN. We propose an efficient\nmethod to construct the personalized generative prior based on a small set of\nfacial images of a given individual. After learning, it allows for\nphoto-realistic rendering with novel views and the face reenactment can be\nrealized by performing navigation in the latent space. Our proposed method is\napplicable for different driven signals, including RGB images, 3DMM\ncoefficients, and audios. Compared with existing works, we obtain superior\nnovel view synthesis results and faithfully face reenactment performance.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Yunpeng Bai",
      "Yanbo Fan",
      "Xuan Wang",
      "Yong Zhang",
      "Jingxiang Sun",
      "Chun Yuan",
      "Ying Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15064"
  },
  {
    "id": "arXiv:2211.15065",
    "title": "State-Aware Proximal Pessimistic Algorithms for Offline Reinforcement  Learning",
    "abstract": "Pessimism is of great importance in offline reinforcement learning (RL). One\nbroad category of offline RL algorithms fulfills pessimism by explicit or\nimplicit behavior regularization. However, most of them only consider policy\ndivergence as behavior regularization, ignoring the effect of how the offline\nstate distribution differs with that of the learning policy, which may lead to\nunder-pessimism for some states and over-pessimism for others. Taking account\nof this problem, we propose a principled algorithmic framework for offline RL,\ncalled \\emph{State-Aware Proximal Pessimism} (SA-PP). The key idea of SA-PP is\nleveraging discounted stationary state distribution ratios between the learning\npolicy and the offline dataset to modulate the degree of behavior\nregularization in a state-wise manner, so that pessimism can be implemented in\na more appropriate way. We first provide theoretical justifications on the\nsuperiority of SA-PP over previous algorithms, demonstrating that SA-PP\nproduces a lower suboptimality upper bound in a broad range of settings.\nFurthermore, we propose a new algorithm named \\emph{State-Aware Conservative\nQ-Learning} (SA-CQL), by building SA-PP upon representative CQL algorithm with\nthe help of DualDICE for estimating discounted stationary state distribution\nratios. Extensive experiments on standard offline RL benchmark show that SA-CQL\noutperforms the popular baselines on a large portion of benchmarks and attains\nthe highest average return.",
    "descriptor": "",
    "authors": [
      "Chen Chen",
      "Hongyao Tang",
      "Yi Ma",
      "Chao Wang",
      "Qianli Shen",
      "Dong Li",
      "Jianye Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15065"
  },
  {
    "id": "arXiv:2211.15066",
    "title": "Semi-Supervised Confidence-Level-based Contrastive Discrimination for  Class-Imbalanced Semantic Segmentation",
    "abstract": "To overcome the data-hungry challenge, we have proposed a semi-supervised\ncontrastive learning framework for the task of class-imbalanced semantic\nsegmentation. First and foremost, to make the model operate in a\nsemi-supervised manner, we proposed the confidence-level-based contrastive\nlearning to achieve instance discrimination in an explicit manner, and make the\nlow-confidence low-quality features align with the high-confidence\ncounterparts. Moreover, to tackle the problem of class imbalance in crack\nsegmentation and road components extraction, we proposed the data imbalance\nloss to replace the traditional cross entropy loss in pixel-level semantic\nsegmentation. Finally, we have also proposed an effective multi-stage fusion\nnetwork architecture to improve semantic segmentation performance. Extensive\nexperiments on the real industrial crack segmentation and the road segmentation\ndemonstrate the superior effectiveness of the proposed framework. Our proposed\nmethod can provide satisfactory segmentation results with even merely 3.5%\nlabeled data.",
    "descriptor": "\nComments: IEEE Cyber 2022 (Oral)\n",
    "authors": [
      "Kangcheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15066"
  },
  {
    "id": "arXiv:2211.15068",
    "title": "Learning to design without prior data: Discovering generalizable design  strategies using deep learning and tree search",
    "abstract": "Building an AI agent that can design on its own has been a goal since the\n1980s. Recently, deep learning has shown the ability to learn from large-scale\ndata, enabling significant advances in data-driven design. However, learning\nover prior data limits us only to solve problems that have been solved before\nand biases data-driven learning towards existing solutions. The ultimate goal\nfor a design agent is the ability to learn generalizable design behavior in a\nproblem space without having seen it before. We introduce a self-learning agent\nframework in this work that achieves this goal. This framework integrates a\ndeep policy network with a novel tree search algorithm, where the tree search\nexplores the problem space, and the deep policy network leverages\nself-generated experience to guide the search further. This framework first\ndemonstrates an ability to discover high-performing generative strategies\nwithout any prior data, and second, it illustrates a zero-shot generalization\nof generative strategies across various unseen boundary conditions. This work\nevaluates the effectiveness and versatility of the framework by solving\nmultiple versions of two engineering design problems without retraining.\nOverall, this paper presents a methodology to self-learn high-performing and\ngeneralizable problem-solving behavior in an arbitrary problem space,\ncircumventing the needs for expert data, existing solutions, and\nproblem-specific learning.",
    "descriptor": "\nComments: ASME. J. Mech. Des\n",
    "authors": [
      "Ayush Raina",
      "Jonathan Cagan",
      "Christopher McComb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15068"
  },
  {
    "id": "arXiv:2211.15069",
    "title": "FeatureBooster: Boosting Feature Descriptors with a Lightweight Neural  Network",
    "abstract": "We introduce a lightweight network to improve descriptors of keypoints within\nthe same image. The network takes the original descriptors and the geometric\nproperties of keypoints as the input, and uses an MLP-based self-boosting stage\nand a Transformer-based cross-boosting stage to enhance the descriptors. The\nenhanced descriptors can be either real-valued or binary ones. We use the\nproposed network to boost both hand-crafted (ORB, SIFT) and the\nstate-of-the-art learning-based descriptors (SuperPoint, ALIKE) and evaluate\nthem on image matching, visual localization, and structure-from-motion tasks.\nThe results show that our method significantly improves the performance of each\ntask, particularly in challenging cases such as large illumination changes or\nrepetitive patterns. Our method requires only 3.2ms on desktop GPU and 27ms on\nembedded GPU to process 2000 features, which is fast enough to be applied to a\npractical system.",
    "descriptor": "\nComments: 14 pages, 8 figures, 5 tables\n",
    "authors": [
      "Xinjiang Wang",
      "Zeyu Liu",
      "Yu Hu",
      "Wei Xi",
      "Wenxian Yu",
      "Danping Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15069"
  },
  {
    "id": "arXiv:2211.15071",
    "title": "Pitfalls of Conditional Batch Normalization for Contextual Multi-Modal  Learning",
    "abstract": "Humans have perfected the art of learning from multiple modalities through\nsensory organs. Despite their impressive predictive performance on a single\nmodality, neural networks cannot reach human level accuracy with respect to\nmultiple modalities. This is a particularly challenging task due to variations\nin the structure of respective modalities. Conditional Batch Normalization\n(CBN) is a popular method that was proposed to learn contextual features to aid\ndeep learning tasks. This technique uses auxiliary data to improve\nrepresentational power by learning affine transformations for convolutional\nneural networks. Despite the boost in performance observed by using CBN layers,\nour work reveals that the visual features learned by introducing auxiliary data\nvia CBN deteriorates. We perform comprehensive experiments to evaluate the\nbrittleness of CBN networks to various datasets, suggesting that learning from\nvisual features alone could often be superior for generalization. We evaluate\nCBN models on natural images for bird classification and histology images for\ncancer type classification. We observe that the CBN network learns close to no\nvisual features on the bird classification dataset and partial visual features\non the histology dataset. Our extensive experiments reveal that CBN may\nencourage shortcut learning between the auxiliary data and labels.",
    "descriptor": "\nComments: Accepted at ICBINB workshop @ NeurIPS 2022\n",
    "authors": [
      "Ivaxi Sheth",
      "Aamer Abdul Rahman",
      "Mohammad Havaei",
      "Samira Ebrahimi Kahou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15071"
  },
  {
    "id": "arXiv:2211.15076",
    "title": "Refined Semantic Enhancement towards Frequency Diffusion for Video  Captioning",
    "abstract": "Video captioning aims to generate natural language sentences that describe\nthe given video accurately. Existing methods obtain favorable generation by\nexploring richer visual representations in encode phase or improving the\ndecoding ability. However, the long-tailed problem hinders these attempts at\nlow-frequency tokens, which rarely occur but carry critical semantics, playing\na vital role in the detailed generation. In this paper, we introduce a novel\nRefined Semantic enhancement method towards Frequency Diffusion (RSFD), a\ncaptioning model that constantly perceives the linguistic representation of the\ninfrequent tokens. Concretely, a Frequency-Aware Diffusion (FAD) module is\nproposed to comprehend the semantics of low-frequency tokens to break through\ngeneration limitations. In this way, the caption is refined by promoting the\nabsorption of tokens with insufficient occurrence. Based on FAD, we design a\nDivergent Semantic Supervisor (DSS) module to compensate for the information\nloss of high-frequency tokens brought by the diffusion process, where the\nsemantics of low-frequency tokens is further emphasized to alleviate the\nlong-tailed problem. Extensive experiments indicate that RSFD outperforms the\nstate-of-the-art methods on two benchmark datasets, i.e., MSR-VTT and MSVD,\ndemonstrate that the enhancement of low-frequency tokens semantics can obtain a\ncompetitive generation effect. Code is available at\nhttps://github.com/lzp870/RSFD.",
    "descriptor": "",
    "authors": [
      "Xian Zhong",
      "Zipeng Li",
      "Shuqin Chen",
      "Kui Jiang",
      "Chen Chen",
      "Mang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15076"
  },
  {
    "id": "arXiv:2211.15078",
    "title": "On the use of hybrid coarse-level models in multilevel minimization  methods",
    "abstract": "Solving large-scale nonlinear minimization problems is computationally\ndemanding. Nonlinear multilevel minimization (NMM) methods explore the\nstructure of the underlying minimization problem to solve such problems in a\ncomputationally efficient and scalable manner. The efficiency of the NMM\nmethods relies on the quality of the coarse-level models. Traditionally,\ncoarse-level models are constructed using the additive approach, where the\nso-called $\\tau$-correction enforces a local coherence between the fine-level\nand coarse-level objective functions. In this work, we extend this methodology\nand discuss how to enforce local coherence between the objective functions\nusing a multiplicative approach. Moreover, we also present a hybrid approach,\nwhich takes advantage of both, additive and multiplicative, approaches. Using\nnumerical experiments from the field of deep learning, we show that employing a\nhybrid approach can greatly improve the convergence speed of NMM methods and\ntherefore it provides an attractive alternative to the almost universally used\nadditive approach.",
    "descriptor": "",
    "authors": [
      "Alena Kopani\u010d\u00e1kov\u00e1"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15078"
  },
  {
    "id": "arXiv:2211.15079",
    "title": "Lightweight and Adaptive FDD Massive MIMO CSI Feedback with Deep  Equilibrium Learning",
    "abstract": "In frequency-division duplexing (FDD) massive multiple-input multiple-output\n(MIMO) systems, downlink channel state information (CSI) needs to be sent from\nusers back to the base station (BS), which causes prohibitive feedback\noverhead. In this paper, we propose a lightweight and adaptive deep\nlearning-based CSI feedback scheme by capitalizing on deep equilibrium models.\nDifferent from existing deep learning-based approaches that stack multiple\nexplicit layers, we propose an implicit equilibrium block to mimic the process\nof an infinite-depth neural network. In particular, the implicit equilibrium\nblock is defined by a fixed-point iteration and the trainable parameters in\neach iteration are shared, which results in a lightweight model. Furthermore,\nthe number of forward iterations can be adjusted according to the users'\ncomputational capability, achieving an online accuracy-efficiency trade-off.\nSimulation results will show that the proposed method obtains a comparable\nperformance as the existing benchmarks but with much-reduced complexity and\npermits an accuracy-efficiency trade-off at runtime.",
    "descriptor": "\nComments: submitted to IEEE for possible publication\n",
    "authors": [
      "Yifan Ma",
      "Wentao Yu",
      "Xianghao Yu",
      "Jun Zhang",
      "Shenghui Song",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.15079"
  },
  {
    "id": "arXiv:2211.15081",
    "title": "Flip Initial Features: Generalization of Neural Networks for  Semi-supervised Node Classification",
    "abstract": "Graph neural networks (GNNs) have been widely used under semi-supervised\nsettings. Prior studies have mainly focused on finding appropriate graph\nfilters (e.g., aggregation schemes) to generalize well for both homophilic and\nheterophilic graphs. Even though these approaches are essential and effective,\nthey still suffer from the sparsity in initial node features inherent in the\nbag-of-words representation. Common in semi-supervised learning where the\ntraining samples often fail to cover the entire dimensions of graph filters\n(hyperplanes), this can precipitate over-fitting of specific dimensions in the\nfirst projection matrix. To deal with this problem, we suggest a simple and\nnovel strategy; create additional space by flipping the initial features and\nhyperplane simultaneously. Training in both the original and in the flip space\ncan provide precise updates of learnable parameters. To the best of our\nknowledge, this is the first attempt that effectively moderates the overfitting\nproblem in GNN. Extensive experiments on real-world datasets demonstrate that\nthe proposed technique improves the node classification accuracy up to 40.2 %",
    "descriptor": "",
    "authors": [
      "Yoonhyuk Choi",
      "Chong-Kwon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15081"
  },
  {
    "id": "arXiv:2211.15082",
    "title": "DGI: Easy and Efficient Inference for GNNs",
    "abstract": "While many systems have been developed to train Graph Neural Networks (GNNs),\nefficient model inference and evaluation remain to be addressed. For instance,\nusing the widely adopted node-wise approach, model evaluation can account for\nup to 94% of the time in the end-to-end training process due to neighbor\nexplosion, which means that a node accesses its multi-hop neighbors. On the\nother hand, layer-wise inference avoids the neighbor explosion problem by\nconducting inference layer by layer such that the nodes only need their one-hop\nneighbors in each layer. However, implementing layer-wise inference requires\nsubstantial engineering efforts because users need to manually decompose a GNN\nmodel into layers for computation and split workload into batches to fit into\ndevice memory. In this paper, we develop Deep Graph Inference (DGI) -- a system\nfor easy and efficient GNN model inference, which automatically translates the\ntraining code of a GNN model for layer-wise execution. DGI is general for\nvarious GNN models and different kinds of inference requests, and supports\nout-of-core execution on large graphs that cannot fit in CPU memory.\nExperimental results show that DGI consistently outperforms layer-wise\ninference across different datasets and hardware settings, and the speedup can\nbe over 1,000x.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Peiqi Yin",
      "Xiao Yan",
      "Jinjing Zhou",
      "Qiang Fu",
      "Zhenkun Cai",
      "James Cheng",
      "Bo Tang",
      "Minjie Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15082"
  },
  {
    "id": "arXiv:2211.15084",
    "title": "Exploring Immersive Interpersonal Communication via AR",
    "abstract": "A central challenge of social computing research is to enable people to\ncommunicate expressively with each other remotely. Augmented reality has great\npromise for expressive communication since it enables communication beyond\ntexts and photos and towards immersive experiences rendered in recipients'\nphysical environments. Little research, however, has explored AR's potential\nfor everyday interpersonal communication. In this work, we prototype an AR\nmessaging system, ARwand, to understand people's behaviors and perceptions\naround communicating with friends via AR messaging. We present our findings\nunder four themes observed from a user study with 24 participants, including\nthe types of immersive messages people choose to send to each other, which\nfactors contribute to a sense of immersiveness, and what concerns arise over\nthis new form of messaging. We discuss important implications of our findings\non the design of future immersive communication systems.",
    "descriptor": "\nComments: will be published in PACM HCI, CSCW1, April 2023 issue\n",
    "authors": [
      "Kyungjun Lee",
      "Hong Li",
      "Muhammad Rizky Wellyanto",
      "Yu Jiang Tham",
      "Andr\u00e9s Monroy-Hern\u00e1ndez",
      "Fannie Liu",
      "Brian A. Smith",
      "Rajan Vaish"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.15084"
  },
  {
    "id": "arXiv:2211.15088",
    "title": "Class Adaptive Network Calibration",
    "abstract": "Recent studies have revealed that, beyond conventional accuracy, calibration\nshould also be considered for training modern deep neural networks. To address\nmiscalibration during learning, some methods have explored different penalty\nfunctions as part of the learning objective, alongside a standard\nclassification loss, with a hyper-parameter controlling the relative\ncontribution of each term. Nevertheless, these methods share two major\ndrawbacks: 1) the scalar balancing weight is the same for all classes,\nhindering the ability to address different intrinsic difficulties or imbalance\namong classes; and 2) the balancing weight is usually fixed without an adaptive\nstrategy, which may prevent from reaching the best compromise between accuracy\nand calibration, and requires hyper-parameter search for each application. We\npropose Class Adaptive Label Smoothing (CALS) for calibrating deep networks,\nwhich allows to learn class-wise multipliers during training, yielding a\npowerful alternative to common label smoothing penalties. Our method builds on\na general Augmented Lagrangian approach, a well-established technique in\nconstrained optimization, but we introduce several modifications to tailor it\nfor large-scale, class-adaptive training. Comprehensive evaluation and multiple\ncomparisons on a variety of benchmarks, including standard and long-tailed\nimage classification, semantic segmentation, and text classification,\ndemonstrate the superiority of the proposed method. The code is available at\nhttps://github.com/by-liu/CALS.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Bingyuan Liu",
      "J\u00e9r\u00f4me Rony",
      "Adrian Galdran",
      "Jose Dolz",
      "Ismail Ben Ayed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15088"
  },
  {
    "id": "arXiv:2211.15089",
    "title": "Continuous diffusion for categorical data",
    "abstract": "Diffusion models have quickly become the go-to paradigm for generative\nmodelling of perceptual signals (such as images and sound) through iterative\nrefinement. Their success hinges on the fact that the underlying physical\nphenomena are continuous. For inherently discrete and categorical data such as\nlanguage, various diffusion-inspired alternatives have been proposed. However,\nthe continuous nature of diffusion models conveys many benefits, and in this\nwork we endeavour to preserve it. We propose CDCD, a framework for modelling\ncategorical data with diffusion models that are continuous both in time and\ninput space. We demonstrate its efficacy on several language modelling tasks.",
    "descriptor": "\nComments: 26 pages, 8 figures\n",
    "authors": [
      "Sander Dieleman",
      "Laurent Sartran",
      "Arman Roshannai",
      "Nikolay Savinov",
      "Yaroslav Ganin",
      "Pierre H. Richemond",
      "Arnaud Doucet",
      "Robin Strudel",
      "Chris Dyer",
      "Conor Durkan",
      "Curtis Hawthorne",
      "R\u00e9mi Leblond",
      "Will Grathwohl",
      "Jonas Adler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15089"
  },
  {
    "id": "arXiv:2211.15092",
    "title": "Hierarchy-guided Model Selection for Time Series Forecasting",
    "abstract": "Generalizability of time series forecasting models depends on the quality of\nmodel selection. Temporal cross validation (TCV) is a standard technique to\nperform model selection in forecasting tasks. TCV sequentially partitions the\ntraining time series into train and validation windows, and performs\nhyperparameter optmization (HPO) of the forecast model to select the model with\nthe best validation performance. Model selection with TCV often leads to poor\ntest performance when the test data distribution differs from that of the\nvalidation data. We propose a novel model selection method, H-Pro that exploits\nthe data hierarchy often associated with a time series dataset. Generally, the\naggregated data at the higher levels of the hierarchy show better\npredictability and more consistency compared to the bottom-level data which is\nmore sparse and (sometimes) intermittent. H-Pro performs the HPO of the\nlowest-level student model based on the test proxy forecasts obtained from a\nset of teacher models at higher levels in the hierarchy. The consistency of the\nteachers' proxy forecasts help select better student models at the\nlowest-level. We perform extensive empirical studies on multiple datasets to\nvalidate the efficacy of the proposed method. H-Pro along with off-the-shelf\nforecasting models outperform existing state-of-the-art forecasting methods\nincluding the winning models of the M5 point-forecasting competition.",
    "descriptor": "",
    "authors": [
      "Arindam Jati",
      "Vijay Ekambaram",
      "Shaonli Pal",
      "Brian Quanz",
      "Wesley M. Gifford",
      "Pavithra Harsha",
      "Stuart Siegel",
      "Sumanta Mukherjee",
      "Chandra Narayanaswami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15092"
  },
  {
    "id": "arXiv:2211.15093",
    "title": "Robot Kinematics: Motion, Kinematics and Dynamics",
    "abstract": "This is a follow-up tutorial article of our previous article entitled \"Robot\nBasics: Representation, Rotation and Velocity\". For better understanding of the\ntopics covered in this articles, we recommend the readers to first read our\nprevious tutorial article on robot basics. Specifically, in this article, we\nwill cover some more advanced topics on robot kinematics, including robot\nmotion, forward kinematics, inverse kinematics, and robot dynamics. For the\ntopics, terminologies and notations introduced in the previous article, we will\nuse them directly without re-introducing them again in this article. Also\nsimilar to the previous article, math and formulas will also be heavily used in\nthis article as well (hope the readers are well prepared for the upcoming math\nbomb). After reading this article, readers should be able to have a deeper\nunderstanding about how robot motion, kinematics and dynamics. As to some more\nadvanced topics about robot control, we will introduce them in the following\ntutorial articles for readers instead.",
    "descriptor": "\nComments: 56 pages, 18 figures\n",
    "authors": [
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15093"
  },
  {
    "id": "arXiv:2211.15095",
    "title": "Discretized Linear Regression and Multiclass Support Vector Based Air  Pollution Forecasting Technique",
    "abstract": "Air pollution is a vital issue emerging from the uncontrolled utilization of\ntraditional energy sources as far as developing countries are concerned. Hence,\ningenious air pollution forecasting methods are indispensable to minimize the\nrisk. To that end, this paper proposes an Internet of Things (IoT) enabled\nsystem for monitoring and controlling air pollution in the cloud computing\nenvironment. A method called Linear Regression and Multiclass Support Vector\n(LR-MSV) IoT-based Air Pollution Forecast is proposed to monitor the air\nquality data and the air quality index measurement to pave the way for\ncontrolling effectively. Extensive experiments carried out on the air quality\ndata in the India dataset have revealed the outstanding performance of the\nproposed LR-MSV method when benchmarked with well-established state-of-the-art\nmethods. The results obtained by the LR-MSV method witness a significant\nincrease in air pollution forecasting accuracy by reducing the air pollution\nforecasting time and error rate compared with the results produced by the other\nstate-of-the-art methods",
    "descriptor": "\nComments: 9 pages, 7 figures, Published with International Journal of Engineering Trends and Technology (IJETT)\n",
    "authors": [
      "Dhanalakshmi M",
      "Radha V"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15095"
  },
  {
    "id": "arXiv:2211.15096",
    "title": "Understanding Impedance Ratio Criteria for Converter-Based AC Power  System",
    "abstract": "Nyquist criterion-based impedance ratio criteria (IRCs) have been widely\napplied for inspecting the risk of small-signal instability among\nconverter-based AC power systems. Aided by a comparative study on voltage\nsource converter, including the single-input single-output (SISO) and multiple\ninput multiple output (MIMO) analyses in both the dq and the sequence domain,\ntwo aspects are emphasized in this paper: 1) the sufficiency of SISO analysis\nwhen the mapping function (MF) is observable to potentially unstable modes, and\n2) the inconvenience of IRCs with an unintended right-half plane pole emergence\nof MF due to the source-load partition. The strictness of analyses is proved by\na systematical deduction of explicit analytical impedance models using the\nstate space. Moreover, a novel criterion that relies on the logarithmic\nderivative of MFs is proposed, which can identify the system modes directly,\nserve as an alternative to IRCs, and be extended to other transfer\nfunction-based stability analyses.",
    "descriptor": "",
    "authors": [
      "Chongbin Zhao",
      "Qirong Jiang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15096"
  },
  {
    "id": "arXiv:2211.15098",
    "title": "MGFN: Magnitude-Contrastive Glance-and-Focus Network for  Weakly-Supervised Video Anomaly Detection",
    "abstract": "Weakly supervised detection of anomalies in surveillance videos is a\nchallenging task. Going beyond existing works that have deficient capabilities\nto localize anomalies in long videos, we propose a novel glance and focus\nnetwork to effectively integrate spatial-temporal information for accurate\nanomaly detection. In addition, we empirically found that existing approaches\nthat use feature magnitudes to represent the degree of anomalies typically\nignore the effects of scene variations, and hence result in sub-optimal\nperformance due to the inconsistency of feature magnitudes across scenes. To\naddress this issue, we propose the Feature Amplification Mechanism and a\nMagnitude Contrastive Loss to enhance the discriminativeness of feature\nmagnitudes for detecting anomalies. Experimental results on two large-scale\nbenchmarks UCF-Crime and XD-Violence manifest that our method outperforms\nstate-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Yingxian Chen",
      "Zhengzhe Liu",
      "Baoheng Zhang",
      "Wilton Fok",
      "Xiaojuan Qi",
      "Yik-Chung Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15098"
  },
  {
    "id": "arXiv:2211.15103",
    "title": "VLTinT: Visual-Linguistic Transformer-in-Transformer for Coherent Video  Paragraph Captioning",
    "abstract": "Video paragraph captioning aims to generate a multi-sentence description of\nan untrimmed video with several temporal event locations in coherent\nstorytelling. Following the human perception process, where the scene is\neffectively understood by decomposing it into visual (e.g. human, animal) and\nnon-visual components (e.g. action, relations) under the mutual influence of\nvision and language, we first propose a visual-linguistic (VL) feature. In the\nproposed VL feature, the scene is modeled by three modalities including (i) a\nglobal visual environment; (ii) local visual main agents; (iii) linguistic\nscene elements. We then introduce an autoregressive Transformer-in-Transformer\n(TinT) to simultaneously capture the semantic coherence of intra- and\ninter-event contents within a video. Finally, we present a new VL contrastive\nloss function to guarantee learnt embedding features are matched with the\ncaptions semantics. Comprehensive experiments and extensive ablation studies on\nActivityNet Captions and YouCookII datasets show that the proposed\nVisual-Linguistic Transformer-in-Transform (VLTinT) outperforms prior\nstate-of-the-art methods on accuracy and diversity.",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Kashu Yamazaki",
      "Khoa Vo",
      "Sang Truong",
      "Bhiksha Raj",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15103"
  },
  {
    "id": "arXiv:2211.15104",
    "title": "Approximate Predictive Control Barrier Functions using Neural Networks:  A Computationally Cheap and Permissive Safety Filter",
    "abstract": "A predictive control barrier function (PCBF) based safety filter allows for\nverifying arbitrary control inputs with respect to future constraint\nsatisfaction. The approach relies on the solution of two optimization problems\ncomputing the minimal constraint relaxations given the current state, and then\ncomputing the minimal deviation from a proposed input such that the relaxed\nconstraints are satisfied. This paper presents an approximation procedure that\nuses a neural network to approximate the optimal value function of the first\noptimization problem from samples, such that the computation becomes\nindependent of the prediction horizon. It is shown that this approximation\nguarantees that states converge to a neighborhood of the implicitly defined\nsafe set of the original problem, where system constraints can be satisfied for\nall times forward. The convergence result relies on a novel class $\\mathcal{K}$\nlower bound on the PCBF decrease and depends on the approximation error of the\nneural network. Lastly, we demonstrate our approach in simulation for an\nautonomous driving example and show that the proposed approximation leads to a\nsignificant decrease in computation time compared to the original approach.",
    "descriptor": "\nComments: Submitted to ECC23\n",
    "authors": [
      "Alexandre Didier",
      "Robin C. Jacobs",
      "Jerome Sieber",
      "Kim P. Wabersich",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15104"
  },
  {
    "id": "arXiv:2211.15107",
    "title": "A Light Touch Approach to Teaching Transformers Multi-view Geometry",
    "abstract": "Transformers are powerful visual learners, in large part due to their\nconspicuous lack of manually-specified priors. This flexibility can be\nproblematic in tasks that involve multiple-view geometry, due to the\nnear-infinite possible variations in 3D shapes and viewpoints (requiring\nflexibility), and the precise nature of projective geometry (obeying rigid\nlaws). To resolve this conundrum, we propose a \"light touch\" approach, guiding\nvisual Transformers to learn multiple-view geometry but allowing them to break\nfree when needed. We achieve this by using epipolar lines to guide the\nTransformer's cross-attention maps, penalizing attention values outside the\nepipolar lines and encouraging higher attention along these lines since they\ncontain geometrically plausible matches. Unlike previous methods, our proposal\ndoes not require any camera pose information at test-time. We focus on\npose-invariant object instance retrieval, where standard Transformer networks\nstruggle, due to the large differences in viewpoint between query and retrieved\nimages. Experimentally, our method outperforms state-of-the-art approaches at\nobject retrieval, without needing pose information at test-time.",
    "descriptor": "",
    "authors": [
      "Yash Bhalgat",
      "Joao F. Henriques",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15107"
  },
  {
    "id": "arXiv:2211.15114",
    "title": "LoNe Sampler: Graph node embeddings by coordinated local neighborhood  sampling",
    "abstract": "Local graph neighborhood sampling is a fundamental computational problem that\nis at the heart of algorithms for node representation learning. Several works\nhave presented algorithms for learning discrete node embeddings where graph\nnodes are represented by discrete features such as attributes of neighborhood\nnodes. Discrete embeddings offer several advantages compared to continuous\nword2vec-like node embeddings: ease of computation, scalability, and\ninterpretability. We present LoNe Sampler, a suite of algorithms for generating\ndiscrete node embeddings by Local Neighborhood Sampling, and address two\nshortcomings of previous work. First, our algorithms have rigorously understood\ntheoretical properties. Second, we show how to generate approximate explicit\nvector maps that avoid the expensive computation of a Gram matrix for the\ntraining of a kernel model. Experiments on benchmark datasets confirm the\ntheoretical findings and demonstrate the advantages of the proposed methods.",
    "descriptor": "\nComments: Accepted to AAAI 2023. arXiv admin note: substantial text overlap with arXiv:2102.04770\n",
    "authors": [
      "Konstantin Kutzkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.15114"
  },
  {
    "id": "arXiv:2211.15115",
    "title": "Generalized Category Discovery with Decoupled Prototypical Network",
    "abstract": "Generalized Category Discovery (GCD) aims to recognize both known and novel\ncategories from a set of unlabeled data, based on another dataset labeled with\nonly known categories. Without considering differences between known and novel\ncategories, current methods learn about them in a coupled manner, which can\nhurt model's generalization and discriminative ability. Furthermore, the\ncoupled training approach prevents these models transferring category-specific\nknowledge explicitly from labeled data to unlabeled data, which can lose\nhigh-level semantic information and impair model performance. To mitigate above\nlimitations, we present a novel model called Decoupled Prototypical Network\n(DPN). By formulating a bipartite matching problem for category prototypes, DPN\ncan not only decouple known and novel categories to achieve different training\ntargets effectively, but also align known categories in labeled and unlabeled\ndata to transfer category-specific knowledge explicitly and capture high-level\nsemantics. Furthermore, DPN can learn more discriminative features for both\nknown and novel categories through our proposed Semantic-aware Prototypical\nLearning (SPL). Besides capturing meaningful semantic information, SPL can also\nalleviate the noise of hard pseudo labels through semantic-weighted soft\nassignment. Extensive experiments show that DPN outperforms state-of-the-art\nmodels by a large margin on all evaluation metrics across multiple benchmark\ndatasets. Code and data are available at https://github.com/Lackel/DPN.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Wenbin An",
      "Feng Tian",
      "Qinghua Zheng",
      "Wei Ding",
      "QianYing Wang",
      "Ping Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15115"
  },
  {
    "id": "arXiv:2211.15118",
    "title": "A Faster $k$-means++ Algorithm",
    "abstract": "K-means++ is an important algorithm to choose initial cluster centers for the\nk-means clustering algorithm. In this work, we present a new algorithm that can\nsolve the $k$-means++ problem with near optimal running time. Given $n$ data\npoints in $\\mathbb{R}^d$, the current state-of-the-art algorithm runs in\n$\\widetilde{O}(k )$ iterations, and each iteration takes $\\widetilde{O}(nd k)$\ntime. The overall running time is thus $\\widetilde{O}(n d k^2)$. We propose a\nnew algorithm \\textsc{FastKmeans++} that only takes in $\\widetilde{O}(nd +\nnk^2)$ time, in total.",
    "descriptor": "",
    "authors": [
      "Jiehao Liang",
      "Somdeb Sarkhel",
      "Zhao Song",
      "Chenbo Yin",
      "Danyang Zhuo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15118"
  },
  {
    "id": "arXiv:2211.15119",
    "title": "OpTree: An Efficient Algorithm for All-gather Operation in Optical  Interconnect Systems",
    "abstract": "All-gather collective communication is one of the most important\ncommunication primitives in parallel and distributed computation, which plays\nan essential role in many HPC applications such as distributed Deep Learning\n(DL) with model and hybrid parallelism. To solve the communication bottleneck\nof All-gather, optical interconnection network can provide unprecedented high\nbandwidth and reliability for data transfer among the distributed nodes.\nHowever, most traditional All-gather algorithms are designed for electrical\ninterconnection, which cannot fit well for optical interconnect systems,\nresulting in poor performance. This paper proposes an efficient scheme, called\nOpTree, for All-gather operation on optical interconnect systems. OpTree\nderives an optimal $m$-ary tree corresponding to the optimal number of\ncommunication stages, achieving minimum communication time. We further analyze\nand compare the communication steps of OpTree with existing All-gather\nalgorithms. Theoretical results exhibit that OpTree requires much less number\nof communication steps than existing All-gather algorithms on optical\ninterconnect systems. Simulation results show that OpTree can reduce\ncommunication time by 72.21%, 94.30%, and 88.58%, respectively, compared with\nthree existing All-gather schemes, WRHT, Ring, and NE.",
    "descriptor": "\nComments: This paper is under review at a conference\n",
    "authors": [
      "Fei Dai",
      "Yawen Chen",
      "Zhiyi Huang",
      "Haibo Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.15119"
  },
  {
    "id": "arXiv:2211.15120",
    "title": "Improved Representation of Asymmetrical Distances with Interval  Quasimetric Embeddings",
    "abstract": "Asymmetrical distance structures (quasimetrics) are ubiquitous in our lives\nand are gaining more attention in machine learning applications. Imposing such\nquasimetric structures in model representations has been shown to improve many\ntasks, including reinforcement learning (RL) and causal relation learning. In\nthis work, we present four desirable properties in such quasimetric models, and\nshow how prior works fail at them. We propose Interval Quasimetric Embedding\n(IQE), which is designed to satisfy all four criteria. On three quasimetric\nlearning experiments, IQEs show strong approximation and generalization\nabilities, leading to better performance and improved efficiency over prior\nmethods.\nProject Page: https://www.tongzhouwang.info/interval_quasimetric_embedding\nQuasimetric Learning Code Package:\nhttps://www.github.com/quasimetric-learning/torch-quasimetric",
    "descriptor": "\nComments: NeurIPS 2022 NeurReps Workshop Proceedings Track\n",
    "authors": [
      "Tongzhou Wang",
      "Phillip Isola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15120"
  },
  {
    "id": "arXiv:2211.15127",
    "title": "Safety-quantifiable Line Feature-based Monocular Visual Localization  with 3D Prior Map",
    "abstract": "Accurate and safety-quantifiable localization is of great significance for\nsafety-critical autonomous systems, such as unmanned ground vehicles (UGV) and\nunmanned aerial vehicles (UAV). The visual odometry-based method can provide\naccurate positioning in a short period but is subjected to drift over time.\nMoreover, the quantification of the safety of the localization solution (the\nerror is bounded by a certain value) is still a challenge. To fill the gaps,\nthis paper proposes a safety-quantifiable line feature-based visual\nlocalization method with a prior map. The visual-inertial odometry provides a\nhigh-frequency local pose estimation which serves as the initial guess for the\nvisual localization. By obtaining a visual line feature pair association, a\nfoot point-based constraint is proposed to construct the cost function between\nthe 2D lines extracted from the real-time image and the 3D lines extracted from\nthe high-precision prior 3D point cloud map. Moreover, a global navigation\nsatellite systems (GNSS) receiver autonomous integrity monitoring (RAIM)\ninspired method is employed to quantify the safety of the derived localization\nsolution. Among that, an outlier rejection (also well-known as fault detection\nand exclusion) strategy is employed via the weighted sum of squares residual\nwith a Chi-squared probability distribution. A protection level (PL) scheme\nconsidering multiple outliers is derived and utilized to quantify the potential\nerror bound of the localization solution in both position and rotation domains.\nThe effectiveness of the proposed safety-quantifiable localization system is\nverified using the datasets collected in the UAV indoor and UGV outdoor\nenvironments.",
    "descriptor": "",
    "authors": [
      "Xi Zheng",
      "Weisong Wen",
      "Li-Ta Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15127"
  },
  {
    "id": "arXiv:2211.15133",
    "title": "SI-GAT: A method based on improved Graph Attention Network for sonar  image classification",
    "abstract": "The existing sonar image classification methods based on deep learning are\noften analyzed in Euclidean space, only considering the local image features.\nFor this reason, this paper presents a sonar classification method based on\nimproved Graph Attention Network (GAT), namely SI-GAT, which is applicable to\nmultiple types imaging sonar. This method quantifies the correlation\nrelationship between nodes based on the joint calculation of color proximity\nand spatial proximity that represent the sonar characteristics in non-Euclidean\nspace, then the KNN (K-Nearest Neighbor) algorithm is used to determine the\nneighborhood range and adjacency matrix in the graph attention mechanism, which\nare jointly considered with the attention coefficient matrix to construct the\nkey part of the SI-GAT. This SI-GAT is superior to several CNN (Convolutional\nNeural Network) methods based on Euclidean space through validation of real\ndata.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Can Lei",
      "Huigang Wang",
      "Juan Lei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15133"
  },
  {
    "id": "arXiv:2211.15136",
    "title": "Collective Intelligence for Object Manipulation with Mobile Robots",
    "abstract": "While natural systems often present collective intelligence that allows them\nto self-organize and adapt to changes, the equivalent is missing in most\nartificial systems. We explore the possibility of such a system in the context\nof cooperative object manipulation using mobile robots. Although conventional\nworks demonstrate potential solutions for the problem in restricted settings,\nthey have computational and learning difficulties. More importantly, these\nsystems do not possess the ability to adapt when facing environmental changes.\nIn this work, we show that by distilling a planner derived from a\ngradient-based soft-body physics simulator into an attention-based neural\nnetwork, our multi-robot manipulation system can achieve better performance\nthan baselines. In addition, our system also generalizes to unseen\nconfigurations during training and is able to adapt toward task completions\nwhen external turbulence and environmental changes are applied.",
    "descriptor": "",
    "authors": [
      "So Kuroki",
      "Tatsuya Matsushima",
      "Jumpei Arima",
      "Yutaka Matsuo",
      "Shixiang Shane Gu",
      "Yujin Tang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15136"
  },
  {
    "id": "arXiv:2211.15143",
    "title": "Explaining Deep Convolutional Neural Networks for Image Classification  by Evolving Local Interpretable Model-agnostic Explanations",
    "abstract": "Deep convolutional neural networks have proven their effectiveness, and have\nbeen acknowledged as the most dominant method for image classification.\nHowever, a severe drawback of deep convolutional neural networks is poor\nexplainability. Unfortunately, in many real-world applications, users need to\nunderstand the rationale behind the predictions of deep convolutional neural\nnetworks when determining whether they should trust the predictions or not. To\nresolve this issue, a novel genetic algorithm-based method is proposed for the\nfirst time to automatically evolve local explanations that can assist users to\nassess the rationality of the predictions. Furthermore, the proposed method is\nmodel-agnostic, i.e., it can be utilised to explain any deep convolutional\nneural network models. In the experiments, ResNet is used as an example model\nto be explained, and the ImageNet dataset is selected as the benchmark dataset.\nDenseNet and MobileNet are further explained to demonstrate the model-agnostic\ncharacteristic of the proposed method. The evolved local explanations on four\nimages, randomly selected from ImageNet, are presented, which show that the\nevolved local explanations are straightforward to be recognised by humans.\nMoreover, the evolved explanations can explain the predictions of deep\nconvolutional neural networks on all four images very well by successfully\ncapturing meaningful interpretable features of the sample images. Further\nanalysis based on the 30 runs of the experiments exhibits that the evolved\nlocal explanations can also improve the probabilities/confidences of the deep\nconvolutional neural network models in making the predictions. The proposed\nmethod can obtain local explanations within one minute, which is more than ten\ntimes faster than LIME (the state-of-the-art method).",
    "descriptor": "",
    "authors": [
      "Bin Wang",
      "Wenbin Pei",
      "Bing Xue",
      "Mengjie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15143"
  },
  {
    "id": "arXiv:2211.15144",
    "title": "Offline Q-Learning on Diverse Multi-Task Data Both Scales And  Generalizes",
    "abstract": "The potential of offline reinforcement learning (RL) is that high-capacity\nmodels trained on large, heterogeneous datasets can lead to agents that\ngeneralize broadly, analogously to similar advances in vision and NLP. However,\nrecent works argue that offline RL methods encounter unique challenges to\nscaling up model capacity. Drawing on the learnings from these works, we\nre-examine previous design choices and find that with appropriate choices:\nResNets, cross-entropy based distributional backups, and feature normalization,\noffline Q-learning algorithms exhibit strong performance that scales with model\ncapacity. Using multi-task Atari as a testbed for scaling and generalization,\nwe train a single policy on 40 games with near-human performance using up-to 80\nmillion parameter networks, finding that model performance scales favorably\nwith capacity. In contrast to prior work, we extrapolate beyond dataset\nperformance even when trained entirely on a large (400M transitions) but highly\nsuboptimal dataset (51% human-level performance). Compared to\nreturn-conditioned supervised approaches, offline Q-learning scales similarly\nwith model capacity and has better performance, especially when the dataset is\nsuboptimal. Finally, we show that offline Q-learning with a diverse dataset is\nsufficient to learn powerful representations that facilitate rapid transfer to\nnovel games and fast online learning on new variations of a training game,\nimproving over existing state-of-the-art representation learning approaches.",
    "descriptor": "",
    "authors": [
      "Aviral Kumar",
      "Rishabh Agarwal",
      "Xinyang Geng",
      "George Tucker",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15144"
  },
  {
    "id": "arXiv:2211.15148",
    "title": "Recent Advances in RecBole: Extensions with more Practical  Considerations",
    "abstract": "RecBole has recently attracted increasing attention from the research\ncommunity. As the increase of the number of users, we have received a number of\nsuggestions and update requests. This motivates us to make some significant\nimprovements on our library, so as to meet the user requirements and contribute\nto the research community. In order to show the recent update in RecBole, we\nwrite this technical report to introduce our latest improvements on RecBole. In\ngeneral, we focus on the flexibility and efficiency of RecBole in the past few\nmonths. More specifically, we have four development targets: (1) more flexible\ndata processing, (2) more efficient model training, (3) more reproducible\nconfigurations, and (4) more comprehensive user documentation. Readers can\ndownload the above updates at: https://github.com/RUCAIBox/RecBole.",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables\n",
    "authors": [
      "Lanling Xu",
      "Zhen Tian",
      "Gaowei Zhang",
      "Lei Wang",
      "Junjie Zhang",
      "Bowen Zheng",
      "Yifan Li",
      "Yupeng Hou",
      "Xingyu Pan",
      "Yushuo Chen",
      "Wayne Xin Zhao",
      "Xu Chen",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.15148"
  },
  {
    "id": "arXiv:2211.15153",
    "title": "Semi-supervised binary classification with latent distance learning",
    "abstract": "Binary classification (BC) is a practical task that is ubiquitous in\nreal-world problems, such as distinguishing healthy and unhealthy objects in\nbiomedical diagnostics and defective and non-defective products in\nmanufacturing inspections. Nonetheless, fully annotated data are commonly\nrequired to effectively solve this problem, and their collection by domain\nexperts is a tedious and expensive procedure. In contrast to BC, several\nsignificant semi-supervised learning techniques that heavily rely on stochastic\ndata augmentation techniques have been devised for solving multi-class\nclassification. In this study, we demonstrate that the stochastic data\naugmentation technique is less suitable for solving typical BC problems because\nit can omit crucial features that strictly distinguish between positive and\nnegative samples. To address this issue, we propose a new learning\nrepresentation to solve the BC problem using a few labels with a random k-pair\ncross-distance learning mechanism. First, by harnessing a few labeled samples,\nthe encoder network learns the projection of positive and negative samples in\nangular spaces to maximize and minimize their inter-class and intra-class\ndistances, respectively. Second, the classifier learns to discriminate between\npositive and negative samples using on-the-fly labels generated based on the\nangular space and labeled samples to solve BC tasks. Extensive experiments were\nconducted using four real-world publicly available BC datasets. With few labels\nand without any data augmentation techniques, the proposed method outperformed\nstate-of-the-art semi-supervised and self-supervised learning methods.\nMoreover, with 10% labeling, our semi-supervised classifier could obtain\ncompetitive accuracy compared with a fully supervised setting.",
    "descriptor": "",
    "authors": [
      "Imam Mustafa Kamal",
      "Hyerim Bae"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15153"
  },
  {
    "id": "arXiv:2211.15154",
    "title": "Data-driven multinomial random forest",
    "abstract": "In this paper, we strengthen the previous weak consistency proof method of\nrandom forest variants into a strong consistency proof method, and strengthen\nthe data-driven degree of RF variants, so as to obtain better theoretical\nproperties and experimental performance. In addition, we also propose a\ndata-driven multinomial random forest (DMRF) based on the multinomial random\nforest (MRF), which meets the strong consistency and has lower complexity than\nMRF, and the effect is equal to or better than MRF. As far as we know, DMRF\nalgorithm is a variant of RF with low algorithm complexity and excellent\nperformance.",
    "descriptor": "\nComments: 28 pages, 3 figures\n",
    "authors": [
      "JunHao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15154"
  },
  {
    "id": "arXiv:2211.15155",
    "title": "GraphPNAS: Learning Distribution of Good Neural Architectures via Deep  Graph Generative Models",
    "abstract": "Neural architectures can be naturally viewed as computational graphs.\nMotivated by this perspective, we, in this paper, study neural architecture\nsearch (NAS) through the lens of learning random graph models. In contrast to\nexisting NAS methods which largely focus on searching for a single best\narchitecture, i.e, point estimation, we propose GraphPNAS a deep graph\ngenerative model that learns a distribution of well-performing architectures.\nRelying on graph neural networks (GNNs), our GraphPNAS can better capture\ntopologies of good neural architectures and relations between operators\ntherein. Moreover, our graph generator leads to a learnable probabilistic\nsearch method that is more flexible and efficient than the commonly used RNN\ngenerator and random search methods. Finally, we learn our generator via an\nefficient reinforcement learning formulation for NAS. To assess the\neffectiveness of our GraphPNAS, we conduct extensive experiments on three\nsearch spaces, including the challenging RandWire on TinyImageNet, ENAS on\nCIFAR10, and NAS-Bench-101/201. The complexity of RandWire is significantly\nlarger than other search spaces in the literature. We show that our proposed\ngraph generator consistently outperforms RNN-based one and achieves better or\ncomparable performances than state-of-the-art NAS methods.",
    "descriptor": "",
    "authors": [
      "Muchen Li",
      "Jeffrey Yunfan Liu",
      "Leonid Sigal",
      "Renjie Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15155"
  },
  {
    "id": "arXiv:2211.15156",
    "title": "Matrix representations of spiking neural P systems: Revisited",
    "abstract": "In the 2010, matrix representation of SN P system without delay was presented\nwhile in the case of SN P systems with delay, matrix representation was\nsuggested in the 2017. These representations brought about series of simulation\nof SN P systems using computer software and hardware technology. In this work,\nwe revisit these representation and provide some observations on the behavior\nof the computations of SN P systems. The concept of reachability of\nconfiguration is considered in both SN P systems with and without delays. A\nbetter computation of next configuration is proposed in the case of SN P system\nwith delay.",
    "descriptor": "\nComments: In: Gheorghe Paun (Ed) Proceedings of the 20th International Conference on Membrane Computing (CMC20), Editura Bibliostar, Ramnicu Valcea (2019) pp 227-247\n",
    "authors": [
      "Henry N. Adorna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.15156"
  },
  {
    "id": "arXiv:2211.15158",
    "title": "Heterogeneous Graph Learning for Multi-modal Medical Data Analysis",
    "abstract": "Routine clinical visits of a patient produce not only image data, but also\nnon-image data containing clinical information regarding the patient, i.e.,\nmedical data is multi-modal in nature. Such heterogeneous modalities offer\ndifferent and complementary perspectives on the same patient, resulting in more\naccurate clinical decisions when they are properly combined. However, despite\nits significance, how to effectively fuse the multi-modal medical data into a\nunified framework has received relatively little attention. In this paper, we\npropose an effective graph-based framework called HetMed (Heterogeneous Graph\nLearning for Multi-modal Medical Data Analysis) for fusing the multi-modal\nmedical data. Specifically, we construct a multiplex network that incorporates\nmultiple types of non-image features of patients to capture the complex\nrelationship between patients in a systematic way, which leads to more accurate\nclinical decisions. Extensive experiments on various real-world datasets\ndemonstrate the superiority and practicality of HetMed. The source code for\nHetMed is available at https://github.com/Sein-Kim/Multimodal-Medical.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Sein Kim",
      "Namkyeong Lee",
      "Junseok Lee",
      "Dongmin Hyun",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15158"
  },
  {
    "id": "arXiv:2211.15159",
    "title": "Properties of SN P system and its Configuration Graph",
    "abstract": "Several studies have been reported in the literature about SN P system and\nits variants. Often, the results provide universality of various variants and\nthe classes of languages that these variants generate and recognize. The state\nof SN P system is its configuration. We refer to our previous result on\nreachability of configuration as the {\\it Fundamental state equation for SN P\nsystem.} This paper provides a preliminary investigation on the behavioral and\nstructural properties of SN P system without delay that depend primarily to\nthis fundamental state equation. Also, we introduce the idea of configuration\ngraph $CG_{\\Pi}$ of an SN P system $\\Pi$ without delay to characterize\nbehavioral properties of $\\Pi$ with respect to $CG_{\\Pi}.$ The matrix $M_{\\Pi}$\nof an SN P system $\\Pi$ without delay is used to characterize structural\nproperties of $\\Pi.$",
    "descriptor": "\nComments: Invited Talk: International Conference on Membrane Computing, September 14-18, 2020, TU Wien, Austria\n",
    "authors": [
      "Henry N. Adorna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.15159"
  },
  {
    "id": "arXiv:2211.15162",
    "title": "Long-tail Cross Modal Hashing",
    "abstract": "Existing Cross Modal Hashing (CMH) methods are mainly designed for balanced\ndata, while imbalanced data with long-tail distribution is more general in\nreal-world. Several long-tail hashing methods have been proposed but they can\nnot adapt for multi-modal data, due to the complex interplay between labels and\nindividuality and commonality information of multi-modal data. Furthermore, CMH\nmethods mostly mine the commonality of multi-modal data to learn hash codes,\nwhich may override tail labels encoded by the individuality of respective\nmodalities. In this paper, we propose LtCMH (Long-tail CMH) to handle\nimbalanced multi-modal data. LtCMH firstly adopts auto-encoders to mine the\nindividuality and commonality of different modalities by minimizing the\ndependency between the individuality of respective modalities and by enhancing\nthe commonality of these modalities. Then it dynamically combines the\nindividuality and commonality with direct features extracted from respective\nmodalities to create meta features that enrich the representation of tail\nlabels, and binaries meta features to generate hash codes. LtCMH significantly\noutperforms state-of-the-art baselines on long-tail datasets and holds a better\n(or comparable) performance on datasets with balanced labels.",
    "descriptor": "\nComments: Accepted by the Thirty-Seventh AAAI Conference on Artificial Intelligence(AAAI2023)\n",
    "authors": [
      "Zijun Gao",
      "Jun Wang",
      "Guoxian Yu",
      "Zhongmin Yan",
      "Carlotta Domeniconi",
      "Jinglin Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15162"
  },
  {
    "id": "arXiv:2211.15163",
    "title": "When Private Blockchain Meets Deterministic Database",
    "abstract": "Private blockchain as a replicated transactional system shares many\ncommonalities with distributed database. However, the intimacy between private\nblockchain and deterministic database has never been studied. In essence,\nprivate blockchain and deterministic database both ensure replica consistency\nby determinism. In this paper, we present a comprehensive analysis to uncover\nthe connections between private blockchain and deterministic database. While\nprivate blockchains have started to pursue deterministic transaction executions\nrecently, deterministic databases have already studied deterministic\nconcurrency control protocols for almost a decade. This motivates us to propose\nHarmony, a novel deterministic concurrency control protocol designed for\nblockchain use. We use Harmony to build a new relational blockchain, namely\nHarmonyBC, which features low abort rates, hotspot resiliency, and inter-block\nparallelism, all of which are especially important to disk-oriented blockchain.\nEmpirical results on Smallbank, YCSB, and TPC-C show that HarmonyBC offers 2.0x\nto 3.5x throughput better than the state-of-the-art private blockchains.",
    "descriptor": "",
    "authors": [
      "Ziliang Lai",
      "Chris Liu",
      "Eric Lo"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.15163"
  },
  {
    "id": "arXiv:2211.15166",
    "title": "Toward Global Sensing Quality Maximization: A Configuration Optimization  Scheme for Camera Networks",
    "abstract": "The performance of a camera network monitoring a set of targets depends\ncrucially on the configuration of the cameras. In this paper, we investigate\nthe reconfiguration strategy for the parameterized camera network model, with\nwhich the sensing qualities of the multiple targets can be optimized globally\nand simultaneously. We first propose to use the number of pixels occupied by a\nunit-length object in image as a metric of the sensing quality of the object,\nwhich is determined by the parameters of the camera, such as intrinsic,\nextrinsic, and distortional coefficients. Then, we form a single quantity that\nmeasures the sensing quality of the targets by the camera network. This\nquantity further serves as the objective function of our optimization problem\nto obtain the optimal camera configuration. We verify the effectiveness of our\napproach through extensive simulations and experiments, and the results reveal\nits improved performance on the AprilTag detection tasks. Codes and related\nutilities for this work are open-sourced and available at\nhttps://github.com/sszxc/MultiCam-Simulation.",
    "descriptor": "\nComments: The 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Xuechao Zhang",
      "Xuda Ding",
      "Yi Ren",
      "Yu Zheng",
      "Chongrong Fang",
      "Jianping He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15166"
  },
  {
    "id": "arXiv:2211.15175",
    "title": "Automating and Mechanizing Cutoff-based Verification of Distributed  Protocols",
    "abstract": "Distributed protocols are generally parametric and can be executed on a\nsystem with any number of nodes, and hence proving their correctness becomes an\ninfinite state verification problem. The most popular approach for verifying\ndistributed protocols is to find an inductive invariant which is strong enough\nto prove the required safety property. However, finding inductive invariants is\nknown to be notoriously hard, and is especially harder in the context of\ndistributed protocols which are quite complex due to their asynchronous nature.\nIn this work, we investigate an orthogonal cut-off based approach to verifying\ndistributed protocols which sidesteps the problem of finding an inductive\ninvariant, and instead reduces checking correctness to a finite state\nverification problem. The main idea is to find a finite, fixed protocol\ninstance called the cutoff instance, such that if the cutoff instance is safe,\nthen any protocol instance would also be safe. Previous cutoff based approaches\nhave only been applied to a restricted class of protocols and specifications.\nWe formalize the cutoff approach in the context of a general protocol modeling\nlanguage (RML), and identify sufficient conditions which can be efficiently\nencoded in SMT to check whether a given protocol instance is a cutoff instance.\nFurther, we propose a simple static analysis-based algorithm to automatically\nsynthesize a cut-off instance. We have applied our approach successfully on a\nnumber of complex distributed protocols, providing the first known cut-off\nresults for many of them.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Shreesha G. Bhat",
      "Kartik Nagar"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.15175"
  },
  {
    "id": "arXiv:2211.15180",
    "title": "Rethinking the Number of Shots in Robust Model-Agnostic Meta-Learning",
    "abstract": "Robust Model-Agnostic Meta-Learning (MAML) is usually adopted to train a\nmeta-model which may fast adapt to novel classes with only a few exemplars and\nmeanwhile remain robust to adversarial attacks. The conventional solution for\nrobust MAML is to introduce robustness-promoting regularization during\nmeta-training stage. With such a regularization, previous robust MAML methods\nsimply follow the typical MAML practice that the number of training shots\nshould match with the number of test shots to achieve an optimal adaptation\nperformance. However, although the robustness can be largely improved, previous\nmethods sacrifice clean accuracy a lot. In this paper, we observe that\nintroducing robustness-promoting regularization into MAML reduces the intrinsic\ndimension of clean sample features, which results in a lower capacity of clean\nrepresentations. This may explain why the clean accuracy of previous robust\nMAML methods drops severely. Based on this observation, we propose a simple\nstrategy, i.e., increasing the number of training shots, to mitigate the loss\nof intrinsic dimension caused by robustness-promoting regularization. Though\nsimple, our method remarkably improves the clean accuracy of MAML without much\nloss of robustness, producing a robust yet accurate model. Extensive\nexperiments demonstrate that our method outperforms prior arts in achieving a\nbetter trade-off between accuracy and robustness. Besides, we observe that our\nmethod is less sensitive to the number of fine-tuning steps during\nmeta-training, which allows for a reduced number of fine-tuning steps to\nimprove training efficiency.",
    "descriptor": "",
    "authors": [
      "Xiaoyue Duan",
      "Guoliang Kang",
      "Runqi Wang",
      "Shumin Han",
      "Song Xue",
      "Tian Wang",
      "Baochang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15180"
  },
  {
    "id": "arXiv:2211.15181",
    "title": "MixFairFace: Towards Ultimate Fairness via MixFair Adapter in Face  Recognition",
    "abstract": "Although significant progress has been made in face recognition, demographic\nbias still exists in face recognition systems. For instance, it usually happens\nthat the face recognition performance for a certain demographic group is lower\nthan the others. In this paper, we propose MixFairFace framework to improve the\nfairness in face recognition models. First of all, we argue that the commonly\nused attribute-based fairness metric is not appropriate for face recognition. A\nface recognition system can only be considered fair while every person has a\nclose performance. Hence, we propose a new evaluation protocol to fairly\nevaluate the fairness performance of different approaches. Different from\nprevious approaches that require sensitive attribute labels such as race and\ngender for reducing the demographic bias, we aim at addressing the identity\nbias in face representation, i.e., the performance inconsistency between\ndifferent identities, without the need for sensitive attribute labels. To this\nend, we propose MixFair Adapter to determine and reduce the identity bias of\ntraining samples. Our extensive experiments demonstrate that our MixFairFace\napproach achieves state-of-the-art fairness performance on all benchmark\ndatasets.",
    "descriptor": "\nComments: Accepted in AAAI-23; Code: this https URL\n",
    "authors": [
      "Fu-En Wang",
      "Chien-Yi Wang",
      "Min Sun",
      "Shang-Hong Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15181"
  },
  {
    "id": "arXiv:2211.15182",
    "title": "Easy Begun is Half Done: Spatial-Temporal Graph Modeling with  ST-Curriculum Dropout",
    "abstract": "Spatial-temporal (ST) graph modeling, such as traffic speed forecasting and\ntaxi demand prediction, is an important task in deep learning area. However,\nfor the nodes in graph, their ST patterns can vary greatly in difficulties for\nmodeling, owning to the heterogeneous nature of ST data. We argue that\nunveiling the nodes to the model in a meaningful order, from easy to complex,\ncan provide performance improvements over traditional training procedure. The\nidea has its root in Curriculum Learning which suggests in the early stage of\ntraining models can be sensitive to noise and difficult samples. In this paper,\nwe propose ST-Curriculum Dropout, a novel and easy-to-implement strategy for\nspatial-temporal graph modeling. Specifically, we evaluate the learning\ndifficulty of each node in high-level feature space and drop those difficult\nones out to ensure the model only needs to handle fundamental ST relations at\nthe beginning, before gradually moving to hard ones. Our strategy can be\napplied to any canonical deep learning architecture without extra trainable\nparameters, and extensive experiments on a wide range of datasets are conducted\nto illustrate that, by controlling the difficulty level of ST relations as the\ntraining progresses, the model is able to capture better representation of the\ndata and thus yields better generalization.",
    "descriptor": "",
    "authors": [
      "Hongjun Wang",
      "Jiyuan Chen",
      "Tong Pan",
      "Zipei Fan",
      "Boyuan Zhang",
      "Renhe Jiang",
      "Lingyu Zhang",
      "Yi Xie",
      "Zhongyi Wang",
      "Xuan Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.15182"
  },
  {
    "id": "arXiv:2211.15183",
    "title": "Continuous Episodic Control",
    "abstract": "Non-parametric episodic memory can be used to quickly latch onto high-reward\nexperience in reinforcement learning tasks. In contrast to parametric deep\nreinforcement learning approaches, these methods only need to discover the\nsolution once, and may then repeatedly solve the task. However, episodic\ncontrol solutions are stored in discrete tables, and this approach has so far\nonly been applied to discrete action space problems. Therefore, this paper\nintroduces Continuous Episodic Control (CEC), a novel non-parametric episodic\nmemory algorithm for sequential decision making in problems with a continuous\naction space. Results on several sparse-reward continuous control environments\nshow that our proposed method learns faster than state-of-the-art model-free RL\nand memory-augmented RL algorithms, while maintaining good long-run performance\nas well. In short, CEC can be a fast approach for learning in continuous\ncontrol tasks, and a useful addition to parametric RL methods in a hybrid\napproach as well.",
    "descriptor": "",
    "authors": [
      "Zhao Yang",
      "Thomas M. Moerland",
      "Mike Preuss",
      "Aske Plaat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15183"
  },
  {
    "id": "arXiv:2211.15184",
    "title": "Macrophages trajectories smoothing by evolving curves",
    "abstract": "When analyzing cell trajectories, we often have to deal with noisy data due\nto the random motion of the cells and possible imperfections in cell center\ndetection. To smooth these trajectories, we present a mathematical model and\nnumerical method based on evolving open-plane curve approach in the Lagrangian\nformulation. The model contains two terms: the first is the smoothing term\ngiven by the influence of local curvature, while the other attracts the curve\nto the original trajectory. We use the flowing finite volume method to\ndiscretize the advection-diffusion partial differential equation. The PDE\nincludes the asymptotically uniform tangential redistribution of curve grid\npoints. We present results for macrophage trajectory smoothing and define a\nmethod to compute the cell velocity for the discrete points on the smoothed\ncurve.",
    "descriptor": "",
    "authors": [
      "Giulia Lupi",
      "Karol Mikula",
      "Seol Ah Park"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15184"
  },
  {
    "id": "arXiv:2211.15188",
    "title": "Incremental Fourier Neural Operator",
    "abstract": "Recently, neural networks have proven their impressive ability to solve\npartial differential equations (PDEs). Among them, Fourier neural operator\n(FNO) has shown success in learning solution operators for highly non-linear\nproblems such as turbulence flow. FNO is discretization-invariant, where it can\nbe trained on low-resolution data and generalizes to problems with\nhigh-resolution. This property is related to the low-pass filters in FNO, where\nonly a limited number of frequency modes are selected to propagate information.\nHowever, it is still a challenge to select an appropriate number of frequency\nmodes and training resolution for different PDEs. Too few frequency modes and\nlow-resolution data hurt generalization, while too many frequency modes and\nhigh-resolution data are computationally expensive and lead to over-fitting. To\nthis end, we propose Incremental Fourier Neural Operator (IFNO), which augments\nboth the frequency modes and data resolution incrementally during training. We\nshow that IFNO achieves better generalization (around 15% reduction on testing\nL2 loss) while reducing the computational cost by 35%, compared to the standard\nFNO. In addition, we observe that IFNO follows the behavior of implicit\nregularization in FNO, which explains its excellent generalization ability.",
    "descriptor": "",
    "authors": [
      "Jiawei Zhao",
      "Robert Joseph George",
      "Yifei Zhang",
      "Zongyi Li",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15188"
  },
  {
    "id": "arXiv:2211.15195",
    "title": "Distance Metric Learning Loss Functions in Few-Shot Scenarios of  Supervised Language Models Fine-Tuning",
    "abstract": "This paper presents an analysis regarding an influence of the Distance Metric\nLearning (DML) loss functions on the supervised fine-tuning of the language\nmodels for classification tasks. We experimented with known datasets from\nSentEval Transfer Tasks.\nOur experiments show that applying the DML loss function can increase\nperformance on downstream classification tasks of RoBERTa-large models in\nfew-shot scenarios. Models fine-tuned with the use of SoftTriple loss can\nachieve better results than models with a standard categorical cross-entropy\nloss function by about 2.89 percentage points from 0.04 to 13.48 percentage\npoints depending on the training dataset. Additionally, we accomplished a\ncomprehensive analysis with explainability techniques to assess the models'\nreliability and explain their results.",
    "descriptor": "",
    "authors": [
      "Witold Sosnowski",
      "Karolina Seweryn",
      "Anna Wr\u00f3blewska",
      "Piotr Gawrysiak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15195"
  },
  {
    "id": "arXiv:2211.15196",
    "title": "Forged Image Detection using SOTA Image Classification Deep Learning  Methods for Image Forensics with Error Level Analysis",
    "abstract": "The advancement in the area of computer vision has been brought using deep\nlearning mechanisms. Image Forensics is one of the major areas of computer\nvision application. Forgery of images is sub-category of image forensics and\ncan be detected using Error Level Analysis. Using such images as an input, this\ncan turn out to be a binary classification problem which can be leveraged using\nvariations of convolutional neural networks. In this paper we perform transfer\nlearning with state-of-the-art image classification models over error level\nanalysis induced CASIA ITDE v.2 dataset. The algorithms used are VGG-19,\nInception-V3, ResNet-152-V2, XceptionNet and EfficientNet-V2L with their\nrespective methodologies and results.",
    "descriptor": "\nComments: 8 pages, 5 figures. To appear in proceedings of 2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)\n",
    "authors": [
      "Raunak Joshi",
      "Abhishek Gupta",
      "Nandan Kanvinde",
      "Pandharinath Ghonge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15196"
  },
  {
    "id": "arXiv:2211.15197",
    "title": "Metric Learning as a Service with Covariance Embedding",
    "abstract": "With the emergence of deep learning, metric learning has gained significant\npopularity in numerous machine learning tasks dealing with complex and\nlarge-scale datasets, such as information retrieval, object recognition and\nrecommendation systems. Metric learning aims to maximize and minimize inter-\nand intra-class similarities. However, existing models mainly rely on distance\nmeasures to obtain a separable embedding space and implicitly maximize the\nintra-class similarity while neglecting the inter-class relationship. We argue\nthat to enable metric learning as a service for high-performance deep learning\napplications, we should also wisely deal with inter-class relationships to\nobtain a more advanced and meaningful embedding space representation. In this\npaper, a novel metric learning is presented as a service methodology that\nincorporates covariance to signify the direction of the linear relationship\nbetween data points in an embedding space. Unlike conventional metric learning,\nour covariance-embedding-enhanced approach enables metric learning as a service\nto be more expressive for computing similar or dissimilar measures and can\ncapture positive, negative, or neutral relationships. Extensive experiments\nconducted using various benchmark datasets, including natural, biomedical, and\nfacial images, demonstrate that the proposed model as a service with\ncovariance-embedding optimizations can obtain higher-quality, more separable,\nand more expressive embedding representations than existing models.",
    "descriptor": "",
    "authors": [
      "Imam Mustafa Kamal",
      "Hyerim Bae",
      "Ling Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15197"
  },
  {
    "id": "arXiv:2211.15198",
    "title": "Critical Clearing Time Estimates of Power Grid Faults via a Set-Based  Method",
    "abstract": "This paper is concerned with estimating critical clearing times in the\ntransient stability problem of power grids without extensive time-domain\nsimulations. We consider a highdimensional post-fault system (the grid after\nthe fault is cleared) which we decouple into many smaller subsystems. Then, for\neach subsystem, we find the so-called safety sets and simulate the faulted\nsystem once to deduce the so-called safe and unsafe critical clearing times,\nwhich specify the intervals of time over which the fault may remain active\nbefore safety is compromised. We demonstrate the approach with a numerical\nexample involving the IEEE 14 bus system.",
    "descriptor": "\nComments: 6 pages, 3 figures. Paper is under review\n",
    "authors": [
      "Willem Esterhuizen",
      "Gyula Moln\u00e1r",
      "Tim Aschenbruck",
      "Franz Ru\u00dfwurm",
      "Halil Askan",
      "Stefan Streif"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15198"
  },
  {
    "id": "arXiv:2211.15199",
    "title": "Large Pre-Trained Models with Extra-Large Vocabularies: A Contrastive  Analysis of Hebrew BERT Models and a New One to Outperform Them All",
    "abstract": "We present a new pre-trained language model (PLM) for modern Hebrew, termed\nAlephBERTGimmel, which employs a much larger vocabulary (128K items) than\nstandard Hebrew PLMs before. We perform a contrastive analysis of this model\nagainst all previous Hebrew PLMs (mBERT, heBERT, AlephBERT) and assess the\neffects of larger vocabularies on task performance. Our experiments show that\nlarger vocabularies lead to fewer splits, and that reducing splits is better\nfor model performance, across different tasks. All in all this new model\nachieves new SOTA on all available Hebrew benchmarks, including Morphological\nSegmentation, POS Tagging, Full Morphological Analysis, NER, and Sentiment\nAnalysis. Subsequently we advocate for PLMs that are larger not only in terms\nof number of layers or training data, but also in terms of their vocabulary. We\nrelease the new model publicly for unrestricted use.",
    "descriptor": "",
    "authors": [
      "Eylon Guetta",
      "Avi Shmidman",
      "Shaltiel Shmidman",
      "Cheyn Shmuel Shmidman",
      "Joshua Guedalia",
      "Moshe Koppel",
      "Dan Bareket",
      "Amit Seker",
      "Reut Tsarfaty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15199"
  },
  {
    "id": "arXiv:2211.15200",
    "title": "Angular triangle distance for ordinal metric learning",
    "abstract": "Deep metric learning (DML) aims to automatically construct task-specific\ndistances or similarities of data, resulting in a low-dimensional\nrepresentation. Several significant metric-learning methods have been proposed.\nNonetheless, no approach guarantees the preservation of the ordinal nature of\nthe original data in a low-dimensional space. Ordinal data are ubiquitous in\nreal-world problems, such as the severity of symptoms in biomedical cases,\nproduction quality in manufacturing, rating level in businesses, and aging\nlevel in face recognition. This study proposes a novel angular triangle\ndistance (ATD) and ordinal triplet network (OTD) to obtain an accurate and\nmeaningful embedding space representation for ordinal data. The ATD projects\nthe ordinal relation of data in the angular space, whereas the OTD learns its\nordinal projection. We also demonstrated that our new distance measure\nsatisfies the distance metric properties mathematically. The proposed method\nwas assessed using real-world data with an ordinal nature, such as biomedical,\nfacial, and hand-gestured images. Extensive experiments have been conducted,\nand the results show that our proposed method not only semantically preserves\nthe ordinal nature but is also more accurate than existing DML models.\nMoreover, we also demonstrate that our proposed method outperforms the\nstate-of-the-art ordinal metric learning method.",
    "descriptor": "",
    "authors": [
      "Imam Mustafa Kamal",
      "Hyerim Bae"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15200"
  },
  {
    "id": "arXiv:2211.15202",
    "title": "Revisiting Distance Metric Learning for Few-Shot Natural Language  Classification",
    "abstract": "Distance Metric Learning (DML) has attracted much attention in image\nprocessing in recent years. This paper analyzes its impact on supervised\nfine-tuning language models for Natural Language Processing (NLP)\nclassification tasks under few-shot learning settings. We investigated several\nDML loss functions in training RoBERTa language models on known SentEval\nTransfer Tasks datasets. We also analyzed the possibility of using proxy-based\nDML losses during model inference.\nOur systematic experiments have shown that under few-shot learning settings,\nparticularly proxy-based DML losses can positively affect the fine-tuning and\ninference of a supervised language model. Models tuned with a combination of\nCCE (categorical cross-entropy loss) and ProxyAnchor Loss have, on average, the\nbest performance and outperform models with only CCE by about 3.27 percentage\npoints -- up to 10.38 percentage points depending on the training dataset.",
    "descriptor": "",
    "authors": [
      "Witold Sosnowski",
      "Anna Wr\u00f3blewska",
      "Karolina Seweryn",
      "Piotr Gawrysiak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15202"
  },
  {
    "id": "arXiv:2211.15205",
    "title": "CIM: Constrained Intrinsic Motivation for Sparse-Reward Continuous  Control",
    "abstract": "Intrinsic motivation is a promising exploration technique for solving\nreinforcement learning tasks with sparse or absent extrinsic rewards. There\nexist two technical challenges in implementing intrinsic motivation: 1) how to\ndesign a proper intrinsic objective to facilitate efficient exploration; and 2)\nhow to combine the intrinsic objective with the extrinsic objective to help\nfind better solutions. In the current literature, the intrinsic objectives are\nall designed in a task-agnostic manner and combined with the extrinsic\nobjective via simple addition (or used by itself for reward-free pre-training).\nIn this work, we show that these designs would fail in typical sparse-reward\ncontinuous control tasks. To address the problem, we propose Constrained\nIntrinsic Motivation (CIM) to leverage readily attainable task priors to\nconstruct a constrained intrinsic objective, and at the same time, exploit the\nLagrangian method to adaptively balance the intrinsic and extrinsic objectives\nvia a simultaneous-maximization framework. We empirically show, on multiple\nsparse-reward continuous control tasks, that our CIM approach achieves greatly\nimproved performance and sample efficiency over state-of-the-art methods.\nMoreover, the key techniques of our CIM can also be plugged into existing\nmethods to boost their performances.",
    "descriptor": "",
    "authors": [
      "Xiang Zheng",
      "Xingjun Ma",
      "Cong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15205"
  },
  {
    "id": "arXiv:2211.15207",
    "title": "Multiple Query Satisfiability of Constrained Horn Clauses",
    "abstract": "We address the problem of checking the satisfiability of a set of constrained\nHorn clauses (CHCs) possibly including more than one query. We propose a\ntransformation technique that takes as input a set of CHCs, including a set of\nqueries, and returns as output a new set of CHCs, such that the transformed\nCHCs are satisfiable if and only if so are the original ones, and the\ntransformed CHCs incorporate in each new query suitable information coming from\nthe other ones so that the CHC satisfiability algorithm is able to exploit the\nrelationships among all queries. We show that our proposed technique is\neffective on a non trivial benchmark of sets of CHCs that encode many\nverification problems for programs manipulating algebraic data types such as\nlists and trees.",
    "descriptor": "",
    "authors": [
      "Emanuele De Angelis",
      "Fabio Fioravanti",
      "Alberto Pettorossi",
      "Maurizio Proietti"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.15207"
  },
  {
    "id": "arXiv:2211.15211",
    "title": "What's Behind the Mask: Estimating Uncertainty in Image-to-Image  Problems",
    "abstract": "Estimating uncertainty in image-to-image networks is an important task,\nparticularly as such networks are being increasingly deployed in the biological\nand medical imaging realms. In this paper, we introduce a new approach to this\nproblem based on masking. Given an existing image-to-image network, our\napproach computes a mask such that the distance between the masked\nreconstructed image and the masked true image is guaranteed to be less than a\nspecified threshold, with high probability. The mask thus identifies the more\ncertain regions of the reconstructed image. Our approach is agnostic to the\nunderlying image-to-image network, and only requires triples of the input\n(degraded), reconstructed and true images for training. Furthermore, our method\nis agnostic to the distance metric used. As a result, one can use $L_p$-style\ndistances or perceptual distances like LPIPS, which contrasts with\ninterval-based approaches to uncertainty. Our theoretical guarantees derive\nfrom a conformal calibration procedure. We evaluate our mask-based approach to\nuncertainty on image colorization, image completion, and super-resolution\ntasks, demonstrating high quality performance on each.",
    "descriptor": "",
    "authors": [
      "Gilad Kutiel",
      "Regev Cohen",
      "Michael Elad",
      "Daniel Freedman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15211"
  },
  {
    "id": "arXiv:2211.15215",
    "title": "Progressive Learning without Forgetting",
    "abstract": "Learning from changing tasks and sequential experience without forgetting the\nobtained knowledge is a challenging problem for artificial neural networks. In\nthis work, we focus on two challenging problems in the paradigm of Continual\nLearning (CL) without involving any old data: (i) the accumulation of\ncatastrophic forgetting caused by the gradually fading knowledge space from\nwhich the model learns the previous knowledge; (ii) the uncontrolled tug-of-war\ndynamics to balance the stability and plasticity during the learning of new\ntasks. In order to tackle these problems, we present Progressive Learning\nwithout Forgetting (PLwF) and a credit assignment regime in the optimizer. PLwF\ndensely introduces model functions from previous tasks to construct a knowledge\nspace such that it contains the most reliable knowledge on each task and the\ndistribution information of different tasks, while credit assignment controls\nthe tug-of-war dynamics by removing gradient conflict through projection.\nExtensive ablative experiments demonstrate the effectiveness of PLwF and credit\nassignment. In comparison with other CL methods, we report notably better\nresults even without relying on any raw data.",
    "descriptor": "",
    "authors": [
      "Tao Feng",
      "Hangjie Yuan",
      "Mang Wang",
      "Ziyuan Huang",
      "Ang Bian",
      "Jianzhou Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15215"
  },
  {
    "id": "arXiv:2211.15217",
    "title": "AquaFeL-PSO: A Monitoring System for Water Resources using Autonomous  Surface Vehicles based on Multimodal PSO and Federated Learning",
    "abstract": "The preservation, monitoring, and control of water resources has been a major\nchallenge in recent decades. Water resources must be constantly monitored to\nknow the contamination levels of water. To meet this objective, this paper\nproposes a water monitoring system using autonomous surface vehicles, equipped\nwith water quality sensors, based on a multimodal particle swarm optimization,\nand the federated learning technique, with Gaussian process as a surrogate\nmodel, the AquaFeL-PSO algorithm. The proposed monitoring system has two\nphases, the exploration phase and the exploitation phase. In the exploration\nphase, the vehicles examine the surface of the water resource, and with the\ndata acquired by the water quality sensors, a first water quality model is\nestimated in the central server. In the exploitation phase, the area is divided\ninto action zones using the model estimated in the exploration phase for a\nbetter exploitation of the contamination zones. To obtain the final water\nquality model of the water resource, the models obtained in both phases are\ncombined. The results demonstrate the efficiency of the proposed path planner\nin obtaining water quality models of the pollution zones, with a 14$\\%$\nimprovement over the other path planners compared, and the entire water\nresource, obtaining a 400$\\%$ better model, as well as in detecting pollution\npeaks, the improvement in this case study is 4,000$\\%$. It was also proven that\nthe results obtained by applying the federated learning technique are very\nsimilar to the results of a centralized system.",
    "descriptor": "",
    "authors": [
      "Micaela Jara Ten Kathen",
      "Princy Johnson",
      "Isabel Jurado Flores",
      "Daniel Guti errez Reina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15217"
  },
  {
    "id": "arXiv:2211.15218",
    "title": "Application of the YOLOv5 Model for the Detection of Microobjects in the  Marine Environment",
    "abstract": "The efficiency of using the YOLOV5 machine learning model for solving the\nproblem of automatic de-tection and recognition of micro-objects in the marine\nenvironment is studied. Samples of microplankton and microplastics were\nprepared, according to which a database of classified images was collected for\ntraining an image recognition neural network. The results of experiments using\na trained network to find micro-objects in photo and video images in real time\nare presented. Experimental studies have shown high efficiency, comparable to\nmanual recognition, of the proposed model in solving problems of detect-ing\nmicro-objects in the marine environment.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Aleksandr N. Grekov",
      "Yurii E. Shishkin",
      "Sergei S. Peliushenko",
      "Aleksandr S. Mavrin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2211.15218"
  },
  {
    "id": "arXiv:2211.15220",
    "title": "Federated Learning for 5G Base Station Traffic Forecasting",
    "abstract": "Mobile traffic prediction is of great importance on the path of enabling 5G\nmobile networks to perform smart and efficient infrastructure planning and\nmanagement. However, available data are limited to base station logging\ninformation. Hence, training methods for generating high-quality predictions\nthat can generalize to new observations on different parties are in demand.\nTraditional approaches require collecting measurements from different base\nstations and sending them to a central entity, followed by performing machine\nlearning operations using the received data. The dissemination of local\nobservations raises privacy, confidentiality, and performance concerns,\nhindering the applicability of machine learning techniques. Various distributed\nlearning methods have been proposed to address this issue, but their\napplication to traffic prediction has yet to be explored. In this work, we\nstudy the effectiveness of federated learning applied to raw base station\naggregated LTE data for time-series forecasting. We evaluate one-step\npredictions using 5 different neural network architectures trained with a\nfederated setting on non-iid data. The presented algorithms have been submitted\nto the Global Federated Traffic Prediction for 5G and Beyond Challenge. Our\nresults show that the learning architectures adapted to the federated setting\nachieve equivalent prediction error to the centralized setting, pre-processing\ntechniques on base stations lead to higher forecasting accuracy, while\nstate-of-the-art aggregators do not outperform simple approaches.",
    "descriptor": "",
    "authors": [
      "Vasileios Perifanis",
      "Nikolaos Pavlidis",
      "Remous-Aris Koutsiamanis",
      "Pavlos S. Efraimidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.15220"
  },
  {
    "id": "arXiv:2211.15221",
    "title": "A reduced basis super-localized orthogonal decomposition for  reaction-convection-diffusion problems",
    "abstract": "This paper presents a method for the numerical treatment of\nreaction-convection-diffusion problems with parameter-dependent coefficients\nthat are arbitrary rough and possibly varying at a very fine scale. The\npresented technique combines the reduced basis (RB) framework with the recently\nproposed super-localized orthogonal decomposition (SLOD). More specifically,\nthe RB is used for accelerating the typically costly SLOD basis computation,\nwhile the SLOD is employed for an efficient compression of the problem's\nsolution operator requiring coarse solves only. The combined advantages of both\nmethods allow one to tackle the challenges arising from parametric\nheterogeneous coefficients. Given a value of the parameter vector, the method\noutputs a corresponding compressed solution operator which can be used to\nefficiently treat multiple, possibly non-affine, right-hand sides at the same\ntime, requiring only one coarse solve per right-hand side.",
    "descriptor": "\nComments: 27 pages, 6 figures\n",
    "authors": [
      "Francesca Bonizzoni",
      "Moritz Hauck",
      "Daniel Peterseim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15221"
  },
  {
    "id": "arXiv:2211.15225",
    "title": "Meet-in-the-middle: Multi-scale upsampling and matching \\\\ for  cross-resolution face recognition",
    "abstract": "In this paper, we aim to address the large domain gap between high-resolution\nface images, e.g., from professional portrait photography, and low-quality\nsurveillance images, e.g., from security cameras. Establishing an identity\nmatch between disparate sources like this is a classical surveillance face\nidentification scenario, which continues to be a challenging problem for modern\nface recognition techniques. To that end, we propose a method that combines\nface super-resolution, resolution matching, and multi-scale template\naccumulation to reliably recognize faces from long-range surveillance footage,\nincluding from low quality sources. The proposed approach does not require\ntraining or fine-tuning on the target dataset of real surveillance images.\nExtensive experiments show that our proposed method is able to outperform even\nexisting methods fine-tuned to the SCFace dataset.",
    "descriptor": "",
    "authors": [
      "Klemen Grm",
      "Berk Kemal \u00d6zata",
      "Vitomir \u0160truc",
      "Haz\u0131m Kemal Ekenel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15225"
  },
  {
    "id": "arXiv:2211.15226",
    "title": "RAMP: A Flat Nanosecond Optical Network and MPI Operations for  Distributed Deep Learning Systems",
    "abstract": "Distributed deep learning (DDL) systems strongly depend on network\nperformance. Current electronic packet switched (EPS) network architectures and\ntechnologies suffer from variable diameter topologies, low-bisection bandwidth\nand over-subscription affecting completion time of communication and collective\noperations.\nWe introduce a near-exascale, full-bisection bandwidth, all-to-all,\nsingle-hop, all-optical network architecture with nanosecond reconfiguration\ncalled RAMP, which supports large-scale distributed and parallel computing\nsystems (12.8~Tbps per node for up to 65,536 nodes).\nFor the first time, a custom RAMP-x MPI strategy and a network transcoder is\nproposed to run MPI collective operations across the optical circuit switched\n(OCS) network in a schedule-less and contention-less manner. RAMP achieves\n7.6-171$\\times$ speed-up in completion time across all MPI operations compared\nto realistic EPS and OCS counterparts. It can also deliver a 1.3-16$\\times$ and\n7.8-58$\\times$ reduction in Megatron and DLRM training time respectively} while\noffering 42-53$\\times$ and 3.3-12.4$\\times$ improvement in energy consumption\nand cost respectively.",
    "descriptor": "",
    "authors": [
      "Alessandro Ottino",
      "Joshua Benjamin",
      "Georgios Zervas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15226"
  },
  {
    "id": "arXiv:2211.15231",
    "title": "Chroma-VAE: Mitigating Shortcut Learning with Generative Classifiers",
    "abstract": "Deep neural networks are susceptible to shortcut learning, using simple\nfeatures to achieve low training loss without discovering essential semantic\nstructure. Contrary to prior belief, we show that generative models alone are\nnot sufficient to prevent shortcut learning, despite an incentive to recover a\nmore comprehensive representation of the data than discriminative approaches.\nHowever, we observe that shortcuts are preferentially encoded with minimal\ninformation, a fact that generative models can exploit to mitigate shortcut\nlearning. In particular, we propose Chroma-VAE, a two-pronged approach where a\nVAE classifier is initially trained to isolate the shortcut in a small latent\nsubspace, allowing a secondary classifier to be trained on the complementary,\nshortcut-free latent subspace. In addition to demonstrating the efficacy of\nChroma-VAE on benchmark and real-world shortcut learning tasks, our work\nhighlights the potential for manipulating the latent space of generative\nclassifiers to isolate or interpret specific correlations.",
    "descriptor": "\nComments: Presented at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Wanqian Yang",
      "Polina Kirichenko",
      "Micah Goldblum",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15231"
  },
  {
    "id": "arXiv:2211.15233",
    "title": "Tackling Visual Control via Multi-View Exploration Maximization",
    "abstract": "We present MEM: Multi-view Exploration Maximization for tackling complex\nvisual control tasks. To the best of our knowledge, MEM is the first approach\nthat combines multi-view representation learning and intrinsic reward-driven\nexploration in reinforcement learning (RL). More specifically, MEM first\nextracts the specific and shared information of multi-view observations to form\nhigh-quality features before performing RL on the learned features, enabling\nthe agent to fully comprehend the environment and yield better actions.\nFurthermore, MEM transforms the multi-view features into intrinsic rewards\nbased on entropy maximization to encourage exploration. As a result, MEM can\nsignificantly promote the sample-efficiency and generalization ability of the\nRL agent, facilitating solving real-world problems with high-dimensional\nobservations and spare-reward space. We evaluate MEM on various tasks from\nDeepMind Control Suite and Procgen games. Extensive simulation results\ndemonstrate that MEM can achieve superior performance and outperform the\nbenchmarking schemes with simple architecture and higher efficiency.",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "Mingqi Yuan",
      "Xin Jin",
      "Bo Li",
      "Wenjun Zeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15233"
  },
  {
    "id": "arXiv:2211.15234",
    "title": "Shoupa: An AI System for Early Diagnosis of Parkinson's Disease",
    "abstract": "Parkinson's Disease (PD) is a progressive nervous system disorder that has\naffected more than 5.8 million people, especially the elderly. Due to the\ncomplexity of its symptoms and its similarity to other neurological disorders,\nearly detection requires neurologists or PD specialists to be involved, which\nis not accessible to most old people. Therefore, we integrate smart mobile\ndevices with AI technologies. In this paper, we introduce the framework of our\ndeveloped PD early detection system which combines different tasks evaluating\nboth motor and non-motor symptoms. With the developed model, we help users\ndetect PD punctually in non-clinical settings and figure out their most severe\nsymptoms. The results are expected to be further used for PD rehabilitation\nguidance and detection of other neurological disorders.",
    "descriptor": "\nComments: 2 pages, 1 figure, accepted by IEEE/ACM CHASE 2022 (Poster Presentation)\n",
    "authors": [
      "Jingwei Li",
      "Ruitian Wu",
      "Tzu-liang Huang",
      "Zian Pan",
      "Ming-chun Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15234"
  },
  {
    "id": "arXiv:2211.15235",
    "title": "Reducing Domain Gap in Frequency and Spatial domain for Cross-modality  Domain Adaptation on Medical Image Segmentation",
    "abstract": "Unsupervised domain adaptation (UDA) aims to learn a model trained on source\ndomain and performs well on unlabeled target domain. In medical image\nsegmentation field, most existing UDA methods depend on adversarial learning to\naddress the domain gap between different image modalities, which is ineffective\ndue to its complicated training process. In this paper, we propose a simple yet\neffective UDA method based on frequency and spatial domain transfer uner\nmulti-teacher distillation framework. In the frequency domain, we first\nintroduce non-subsampled contourlet transform for identifying domain-invariant\nand domain-variant frequency components (DIFs and DVFs), and then keep the DIFs\nunchanged while replacing the DVFs of the source domain images with that of the\ntarget domain images to narrow the domain gap. In the spatial domain, we\npropose a batch momentum update-based histogram matching strategy to reduce the\ndomain-variant image style bias. Experiments on two cross-modality medical\nimage segmentation datasets (cardiac, abdominal) show that our proposed method\nachieves superior performance compared to state-of-the-art methods.",
    "descriptor": "\nComments: accepted at Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)\n",
    "authors": [
      "Shaolei Liu",
      "Siqi Yin",
      "Linhao Qu",
      "Manning Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15235"
  },
  {
    "id": "arXiv:2211.15242",
    "title": "Ising Model on Locally Tree-like Graphs: Uniqueness of Solutions to  Cavity Equations",
    "abstract": "In the study of Ising models on large locally tree-like graphs, in both\nrigorous and non-rigorous methods one is often led to understanding the\nso-called belief propagation distributional recursions and its fixed points. We\nprove that there is at most one non-trivial fixed point for Ising models with\nzero or certain random external fields. Previously this was only known for\nsufficiently ``low-temperature'' models. Our main innovation is in applying\ninformation-theoretic ideas of channel comparison leading to a new metric\n(degradation index) between binary-input-symmetric (BMS) channels under which\nthe Belief Propagation (BP) operator is a strict contraction (albeit\nnon-multiplicative). A key ingredient of our proof is a strengthening of the\nclassical stringy tree lemma of (Evans-Kenyon-Peres-Schulman'00).\nOur result simultaneously closes the following 6 conjectures in the\nliterature: 1) independence of robust reconstruction accuracy to leaf noise in\nbroadcasting on trees (Mossel-Neeman-Sly'16); 2) uselessness of global\ninformation for a labeled 2-community stochastic block model, or 2-SBM\n(Kanade-Mossel-Schramm'16); 3) optimality of local algorithms for 2-SBM under\nnoisy side information (Mossel-Xu'16); 4) uniqueness of BP fixed point in\nbroadcasting on trees in the Gaussian (large degree) limit (ibid); 5) boundary\nirrelevance in broadcasting on trees (Abbe-Cornacchia-Gu-P.'21); 6)\ncharacterization of entropy (and mutual information) of community labels given\nthe graph in 2-SBM (ibid).",
    "descriptor": "",
    "authors": [
      "Qian Yu",
      "Yury Polyanskiy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.15242"
  },
  {
    "id": "arXiv:2211.15243",
    "title": "DeepAngle: Fast calculation of contact angles in tomography images using  deep learning",
    "abstract": "DeepAngle is a machine learning-based method to determine the contact angles\nof different phases in the tomography images of porous materials. Measurement\nof angles in 3--D needs to be done within the surface perpendicular to the\nangle planes, and it could become inaccurate when dealing with the discretized\nspace of the image voxels. A computationally intensive solution is to correlate\nand vectorize all surfaces using an adaptable grid, and then measure the angles\nwithin the desired planes. On the contrary, the present study provides a rapid\nand low-cost technique powered by deep learning to estimate the interfacial\nangles directly from images. DeepAngle is tested on both synthetic and\nrealistic images against the direct measurement technique and found to improve\nthe r-squared by 5 to 16% while lowering the computational cost 20 times. This\nrapid method is especially applicable for processing large tomography data and\ntime-resolved images, which is computationally intensive. The developed code\nand the dataset are available at an open repository on GitHub\n(https://www.github.com/ArashRabbani/DeepAngle).",
    "descriptor": "",
    "authors": [
      "Arash Rabbani",
      "Chenhao Sun",
      "Masoud Babaei",
      "Vahid J. Niasar",
      "Ryan T. Armstrong",
      "Peyman Mostaghimi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15243"
  },
  {
    "id": "arXiv:2211.15248",
    "title": "Efficient Answer Enumeration in Description Logics with Functional Roles  -- Extended Version",
    "abstract": "We study the enumeration of answers to ontology-mediated queries when the\nontology is formulated in a description logic that supports functional roles\nand the query is a CQ. In particular, we show that enumeration is possible with\nlinear preprocessing and constant delay when a certain extension of the CQ\n(pertaining to functional roles) is acyclic and free-connex acyclic. This holds\nboth for complete answers and for partial answers. We provide matching lower\nbounds for the case where the query is self-join free.",
    "descriptor": "\nComments: This is an extended version of a paper accepted to AAAI'23\n",
    "authors": [
      "Carsten Lutz",
      "Marcin Przybylko"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.15248"
  },
  {
    "id": "arXiv:2211.15253",
    "title": "Lipschitz constant estimation for 1D convolutional neural networks",
    "abstract": "In this work, we propose a dissipativity-based method for Lipschitz constant\nestimation of 1D convolutional neural networks (CNNs). In particular, we\nanalyze the dissipativity properties of convolutional, pooling, and fully\nconnected layers making use of incremental quadratic constraints for nonlinear\nactivation functions and pooling operations. The Lipschitz constant of the\nconcatenation of these mappings is then estimated by solving a semidefinite\nprogram which we derive from dissipativity theory. To make our method as\nefficient as possible, we take the structure of convolutional layers into\naccount realizing these finite impulse response filters as causal dynamical\nsystems in state space and carrying out the dissipativity analysis for the\nstate space realizations. The examples we provide show that our Lipschitz\nbounds are advantageous in terms of accuracy and scalability.",
    "descriptor": "",
    "authors": [
      "Patricia Pauli",
      "Dennis Gramlich",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15253"
  },
  {
    "id": "arXiv:2211.15255",
    "title": "GADMSL: Graph Anomaly Detection on Attributed Networks via Multi-scale  Substructure Learning",
    "abstract": "Recently, graph anomaly detection has attracted increasing attention in data\nmining and machine learning communities. Apart from existing attribute\nanomalies, graph anomaly detection also captures suspicious\ntopological-abnormal nodes that differ from the major counterparts. Although\nmassive graph-based detection approaches have been proposed, most of them focus\non node-level comparison while pay insufficient attention on the surrounding\ntopology structures. Nodes with more dissimilar neighborhood substructures have\nmore suspicious to be abnormal. To enhance the local substructure detection\nability, we propose a novel Graph Anomaly Detection framework via Multi-scale\nSubstructure Learning (GADMSL for abbreviation). Unlike previous algorithms, we\nmanage to capture anomalous substructures where the inner similarities are\nrelatively low in dense-connected regions. Specifically, we adopt a region\nproposal module to find high-density substructures in the network as suspicious\nregions. Their inner-node embedding similarities indicate the anomaly degree of\nthe detected substructures. Generally, a lower degree of embedding similarities\nmeans a higher probability that the substructure contains topology anomalies.\nTo distill better embeddings of node attributes, we further introduce a graph\ncontrastive learning scheme, which observes attribute anomalies in the\nmeantime. In this way, GADMSL can detect both topology and attribute anomalies.\nUltimately, extensive experiments on benchmark datasets show that GADMSL\ngreatly improves detection performance (up to 7.30% AUC and 17.46% AUPRC gains)\ncompared to state-of-the-art attributed networks anomaly detection algorithms.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Duan Jingcan",
      "Wang Siwei",
      "Liu Xinwang",
      "Zhou Haifang",
      "Hu Jingtao",
      "Jin Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15255"
  },
  {
    "id": "arXiv:2211.15258",
    "title": "Bayesian Network Models of Causal Interventions in Healthcare Decision  Making: Literature Review and Software Evaluation",
    "abstract": "This report summarises the outcomes of a systematic literature search to\nidentify Bayesian network models used to support decision making in healthcare.\nAfter describing the search methodology, the selected research papers are\nbriefly reviewed, with the view to identify publicly available models and\ndatasets that are well suited to analysis using the causal interventional\nanalysis software tool developed in Wang B, Lyle C, Kwiatkowska M (2021).\nFinally, an experimental evaluation of applying the software on a selection of\nmodels is carried out and preliminary results are reported.",
    "descriptor": "\nComments: 50 pages (19 + 31 Appendix)\n",
    "authors": [
      "Artem Velikzhanin",
      "Benjie Wang",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15258"
  },
  {
    "id": "arXiv:2211.15259",
    "title": "A Call to Reflect on Evaluation Practices for Failure Detection in Image  Classification",
    "abstract": "Reliable application of machine learning-based decision systems in the wild\nis one of the major challenges currently investigated by the field. A large\nportion of established approaches aims to detect erroneous predictions by means\nof assigning confidence scores. This confidence may be obtained by either\nquantifying the model's predictive uncertainty, learning explicit scoring\nfunctions, or assessing whether the input is in line with the training\ndistribution. Curiously, while these approaches all state to address the same\neventual goal of detecting failures of a classifier upon real-life application,\nthey currently constitute largely separated research fields with individual\nevaluation protocols, which either exclude a substantial part of relevant\nmethods or ignore large parts of relevant failure sources. In this work, we\nsystematically reveal current pitfalls caused by these inconsistencies and\nderive requirements for a holistic and realistic evaluation of failure\ndetection. To demonstrate the relevance of this unified perspective, we present\na large-scale empirical study for the first time enabling benchmarking\nconfidence scoring functions w.r.t all relevant methods and failure sources.\nThe revelation of a simple softmax response baseline as the overall best\nperforming method underlines the drastic shortcomings of current evaluation in\nthe abundance of publicized research on confidence scoring. Code and trained\nmodels are at https://github.com/IML-DKFZ/fd-shifts.",
    "descriptor": "",
    "authors": [
      "Paul F. Jaeger",
      "Carsten T. L\u00fcth",
      "Lukas Klein",
      "Till J. Bungert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15259"
  },
  {
    "id": "arXiv:2211.15261",
    "title": "Flexible Correct-by-Construction Programming",
    "abstract": "Correctness-by-Construction (CbC) is an incremental program construction\nprocess to construct functionally correct programs. The programs are\nconstructed stepwise along with a specification that is inherently guaranteed\nto be satisfied. CbC is complex to use without specialized tool support, since\nit needs a set of predefined refinement rules of fixed granularity which are\nadditional rules on top of the programming language. Each refinement rule\nintroduces a specific programming statement and developers cannot depart from\nthese rules to construct programs. CbC allows to develop software in a\nstructured and incremental way to ensure correctness, but the limited\nflexibility is a disadvantage of CbC. In this work, we compare classic CbC with\nCbC-Block and TraitCbC. Both approaches CbC-Block and TraitCbC, are related to\nCbC, but they have new language constructs that enable a more flexible software\nconstruction approach. We provide for both approaches a programming guideline,\nwhich similar to CbC, leads to well-structured programs. CbC-Block extends CbC\nby adding a refinement rule to insert any block of statements. Therefore, we\nintroduce CbC-Block as an extension of CbC. TraitCbC implements\ncorrectness-by-construction on the basis of traits with specified methods. We\nformally introduce TraitCbC and prove soundness of the construction strategy.\nAll three development approaches are qualitatively compared regarding their\nprogramming constructs, tool support, and usability to assess which is best\nsuited for certain tasks and developers.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.05644\n",
    "authors": [
      "Tobias Runge",
      "Tabea Bordis",
      "Alex Potanin",
      "Thomas Th\u00fcm",
      "Ina Schaefer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.15261"
  },
  {
    "id": "arXiv:2211.15262",
    "title": "HERDPhobia: A Dataset for Hate Speech against Fulani in Nigeria",
    "abstract": "Social media platforms allow users to freely share their opinions about\nissues or anything they feel like. However, they also make it easier to spread\nhate and abusive content. The Fulani ethnic group has been the victim of this\nunfortunate phenomenon. This paper introduces the HERDPhobia - the first\nannotated hate speech dataset on Fulani herders in Nigeria - in three\nlanguages: English, Nigerian-Pidgin, and Hausa. We present a benchmark\nexperiment using pre-trained languages models to classify the tweets as either\nhateful or non-hateful. Our experiment shows that the XML-T model provides\nbetter performance with 99.83% weighted F1. We released the dataset at\nhttps://github.com/hausanlp/HERDPhobia for further research.",
    "descriptor": "\nComments: To appear in the Proceedings of the Sixth Workshop on Widening Natural Language Processing at EMNLP2022\n",
    "authors": [
      "Saminu Mohammad Aliyu",
      "Gregory Maksha Wajiga",
      "Muhammad Murtala",
      "Shamsuddeen Hassan Muhammad",
      "Idris Abdulmumin",
      "Ibrahim Said Ahmad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15262"
  },
  {
    "id": "arXiv:2211.15265",
    "title": "Assessing Bias in Face Image Quality Assessment",
    "abstract": "Face image quality assessment (FIQA) attempts to improve face recognition\n(FR) performance by providing additional information about sample quality.\nBecause FIQA methods attempt to estimate the utility of a sample for face\nrecognition, it is reasonable to assume that these methods are heavily\ninfluenced by the underlying face recognition system. Although modern face\nrecognition systems are known to perform well, several studies have found that\nsuch systems often exhibit problems with demographic bias. It is therefore\nlikely that such problems are also present with FIQA techniques. To investigate\nthe demographic biases associated with FIQA approaches, this paper presents a\ncomprehensive study involving a variety of quality assessment methods\n(general-purpose image quality assessment, supervised face quality assessment,\nand unsupervised face quality assessment methods) and three diverse\nstate-of-theart FR models. Our analysis on the Balanced Faces in the Wild (BFW)\ndataset shows that all techniques considered are affected more by variations in\nrace than sex. While the general-purpose image quality assessment methods\nappear to be less biased with respect to the two demographic factors\nconsidered, the supervised and unsupervised face image quality assessment\nmethods both show strong bias with a tendency to favor white individuals (of\neither sex). In addition, we found that methods that are less racially biased\nperform worse overall. This suggests that the observed bias in FIQA methods is\nto a significant extent related to the underlying face recognition system.",
    "descriptor": "\nComments: The content of this paper was published in EUSIPCO 2022\n",
    "authors": [
      "\u017diga Babnik",
      "Vitomir \u0160truc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15265"
  },
  {
    "id": "arXiv:2211.15267",
    "title": "Folded Polynomial Codes for Coded Distributed $AA^\\top$-Type Matrix  Multiplication",
    "abstract": "In this paper, due to the important value in practical applications, we\nconsider the coded distributed matrix multiplication problem of computing\n$AA^\\top$ in a distributed computing system with $N$ worker nodes and a master\nnode, where the input matrices $A$ and $A^\\top$ are partitioned into $p$-by-$m$\nand $m$-by-$p$ blocks of equal-size sub-matrices respectively. For effective\nstraggler mitigation, we propose a novel computation strategy, named\n\\emph{folded polynomial code}, which is obtained by modifying the entangled\npolynomial codes. Moreover, we characterize a lower bound on the optimal\nrecovery threshold among all linear computation strategies when the underlying\nfield is real number field, and our folded polynomial codes can achieve this\nbound in the case of $m=1$. Compared with all known computation strategies for\ncoded distributed matrix multiplication, our folded polynomial codes outperform\nthem in terms of recovery threshold, download cost and decoding complexity.",
    "descriptor": "\nComments: 14 pages, 2 table\n",
    "authors": [
      "Jingke Xu",
      "Yaqian Zhang",
      "Libo Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15267"
  },
  {
    "id": "arXiv:2211.15268",
    "title": "Scientific and Creative Analogies in Pretrained Language Models",
    "abstract": "This paper examines the encoding of analogy in large-scale pretrained\nlanguage models, such as BERT and GPT-2. Existing analogy datasets typically\nfocus on a limited set of analogical relations, with a high similarity of the\ntwo domains between which the analogy holds. As a more realistic setup, we\nintroduce the Scientific and Creative Analogy dataset (SCAN), a novel analogy\ndataset containing systematic mappings of multiple attributes and relational\nstructures across dissimilar domains. Using this dataset, we test the\nanalogical reasoning capabilities of several widely-used pretrained language\nmodels (LMs). We find that state-of-the-art LMs achieve low performance on\nthese complex analogy tasks, highlighting the challenges still posed by analogy\nunderstanding.",
    "descriptor": "\nComments: To be published in Findings of EMNLP 2022\n",
    "authors": [
      "Tamara Czinczoll",
      "Helen Yannakoudakis",
      "Pushkar Mishra",
      "Ekaterina Shutova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15268"
  },
  {
    "id": "arXiv:2211.15271",
    "title": "The Myth of Culturally Agnostic AI Models",
    "abstract": "The paper discusses the potential of large vision-language models as objects\nof interest for empirical cultural studies. Focusing on the comparative\nanalysis of outputs from two popular text-to-image synthesis models, DALL-E 2\nand Stable Diffusion, the paper tries to tackle the pros and cons of striving\ntowards culturally agnostic vs. culturally specific AI models. The paper\ndiscusses several examples of memorization and bias in generated outputs which\nshowcase the trade-off between risk mitigation and cultural specificity, as\nwell as the overall impossibility of developing culturally agnostic models.",
    "descriptor": "",
    "authors": [
      "Eva Cetinic"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15271"
  },
  {
    "id": "arXiv:2211.15272",
    "title": "Topologically faithful image segmentation via induced matching of  persistence barcodes",
    "abstract": "Image segmentation is a largely researched field where neural networks find\nvast applications in many facets of technology. Some of the most popular\napproaches to train segmentation networks employ loss functions optimizing\npixel-overlap, an objective that is insufficient for many segmentation tasks.\nIn recent years, their limitations fueled a growing interest in topology-aware\nmethods, which aim to recover the correct topology of the segmented structures.\nHowever, so far, none of the existing approaches achieve a spatially correct\nmatching between the topological features of ground truth and prediction.\nIn this work, we propose the first topologically and feature-wise accurate\nmetric and loss function for supervised image segmentation, which we term Betti\nmatching. We show how induced matchings guarantee the spatially correct\nmatching between barcodes in a segmentation setting. Furthermore, we propose an\nefficient algorithm to compute the Betti matching of images. We show that the\nBetti matching error is an interpretable metric to evaluate the topological\ncorrectness of segmentations, which is more sensitive than the well-established\nBetti number error. Moreover, the differentiability of the Betti matching loss\nenables its use as a loss function. It improves the topological performance of\nsegmentation networks across six diverse datasets while preserving the\nvolumetric performance. Our code is available in\nhttps://github.com/nstucki/Betti-matching.",
    "descriptor": "",
    "authors": [
      "Nico Stucki",
      "Johannes C. Paetzold",
      "Suprosanna Shit",
      "Bjoern Menze",
      "Ulrich Bauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15272"
  },
  {
    "id": "arXiv:2211.15273",
    "title": "Tchebycheffian B-splines in isogeometric Galerkin methods",
    "abstract": "Tchebycheffian splines are smooth piecewise functions whose pieces are drawn\nfrom (possibly different) Tchebycheff spaces, a natural generalization of\nalgebraic polynomial spaces. They enjoy most of the properties known in the\npolynomial spline case. In particular, under suitable assumptions,\nTchebycheffian splines admit a representation in terms of basis functions,\ncalled Tchebycheffian B-splines (TB-splines), completely analogous to\npolynomial B-splines. A particularly interesting subclass consists of\nTchebycheffian splines with pieces belonging to null-spaces of\nconstant-coefficient linear differential operators. They grant the freedom of\ncombining polynomials with exponential and trigonometric functions with any\nnumber of individual shape parameters. Moreover, they have been recently\nequipped with efficient evaluation and manipulation procedures. In this paper,\nwe consider the use of TB-splines with pieces belonging to null-spaces of\nconstant-coefficient linear differential operators as an attractive substitute\nfor standard polynomial B-splines and rational NURBS in isogeometric Galerkin\nmethods. We discuss how to exploit the large flexibility of the geometrical and\nanalytical features of the underlying Tchebycheff spaces according to\nproblem-driven selection strategies. TB-splines offer a wide and robust\nenvironment for the isogeometric paradigm beyond the limits of the rational\nNURBS model.",
    "descriptor": "\nComments: 35 pages, 18 figures\n",
    "authors": [
      "Krunal Raval",
      "Carla Manni",
      "Hendrik Speleers"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15273"
  },
  {
    "id": "arXiv:2211.15275",
    "title": "A Conflict-driven Interface between Symbolic Planning and Nonlinear  Constraint Solving",
    "abstract": "Robotic planning in real-world scenarios typically requires joint\noptimization of logic and continuous variables. A core challenge to combine the\nstrengths of logic planners and continuous solvers is the design of an\nefficient interface that informs the logical search about continuous\ninfeasibilities. In this paper we present a novel iterative algorithm that\nconnects logic planning with nonlinear optimization through a bidirectional\ninterface, achieved by the detection of minimal subsets of nonlinear\nconstraints that are infeasible. The algorithm continuously builds a database\nof graphs that represent (in)feasible subsets of continuous variables and\nconstraints, and encodes this knowledge in the logical description. As a\nfoundation for this algorithm, we introduce Planning with Nonlinear Transition\nConstraints (PNTC), a novel planning formulation that clarifies the exact\nassumptions our algorithm requires and can be applied to model Task and Motion\nPlanning (TAMP) efficiently. Our experimental results show that our framework\nsignificantly outperforms alternative optimization-based approaches for TAMP.",
    "descriptor": "",
    "authors": [
      "Joaquim Ortiz-Haro",
      "Erez Karpas",
      "Michael Katz",
      "Marc Toussaint"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15275"
  },
  {
    "id": "arXiv:2211.15279",
    "title": "Establishment of Neural Networks Robust to Label Noise",
    "abstract": "Label noise is a significant obstacle in deep learning model training. It can\nhave a considerable impact on the performance of image classification models,\nparticularly deep neural networks, which are especially susceptible because\nthey have a strong propensity to memorise noisy labels. In this paper, we have\nexamined the fundamental concept underlying related label noise approaches. A\ntransition matrix estimator has been created, and its effectiveness against the\nactual transition matrix has been demonstrated. In addition, we examined the\nlabel noise robustness of two convolutional neural network classifiers with\nLeNet and AlexNet designs. The two FashionMINIST datasets have revealed the\nrobustness of both models. We are not efficiently able to demonstrate the\ninfluence of the transition matrix noise correction on robustness enhancements\ndue to our inability to correctly tune the complex convolutional neural network\nmodel due to time and computing resource constraints. There is a need for\nadditional effort to fine-tune the neural network model and explore the\nprecision of the estimated transition model in future research.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Pengwei Yang",
      "Angel Teng",
      "Jack Mangos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15279"
  },
  {
    "id": "arXiv:2211.15281",
    "title": "Flow: Per-Instance Personalized Federated Learning Through Dynamic  Routing",
    "abstract": "Personalization in Federated Learning (FL) aims to modify a collaboratively\ntrained global model according to each client. Current approaches to\npersonalization in FL are at a coarse granularity, i.e. all the input instances\nof a client use the same personalized model. This ignores the fact that some\ninstances are more accurately handled by the global model due to better\ngeneralizability. To address this challenge, this work proposes Flow, a\nfine-grained stateless personalized FL approach. Flow creates dynamic\npersonalized models by learning a routing mechanism that determines whether an\ninput instance prefers the local parameters or its global counterpart. Thus,\nFlow introduces per-instance routing in addition to leveraging per-client\npersonalization to improve accuracies at each client. Further, Flow is\nstateless which makes it unnecessary for a client to retain its personalized\nstate across FL rounds. This makes Flow practical for large-scale FL settings\nand friendly to newly joined clients. Evaluations on Stackoverflow, Reddit, and\nEMNIST datasets demonstrate the superiority in prediction accuracy of Flow over\nstate-of-the-art non-personalized and only per-client personalized approaches\nto FL.",
    "descriptor": "",
    "authors": [
      "Kunjal Panchal",
      "Sunav Choudhary",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15281"
  },
  {
    "id": "arXiv:2211.15282",
    "title": "FLOWViZ: Framework for Phylogenetic Processing",
    "abstract": "The increasing risk of epidemics and a fast-growing world population has\ncontributed to a great investment in phylogenetic analysis, in order to track\nnumerous diseases and conceive effective medication and treatments.\nPhylogenetic analysis requires large quantities of information to be analyzed\nand processed for knowledge extraction, using suitable techniques and,\nnowadays, specific software and algorithms, to deliver results as efficiently\nand fast as possible. These algorithms and techniques are already provided by\nseveral free and available frameworks and tools. Usually, the process of\nphylogenetic analysis consists of several processing steps, which define a\npipeline. Some phylogenetic frameworks have available more than one processing\nstep, such as inferring phylogenetic trees, data integration, and\nvisualization, but due to the continuous growth in involved data amounts, each\nstep may last several hours or days.\nScientific workflow systems may use high performance computing facilities, if\navailable, for processing large volumes of data, concurrently. But most of\nthese scientific workflow systems cannot be easily installed and configured,\nare available as centralized services, and, usually, it is not easy to\nintegrate tools and processing steps available in phylogenetic frameworks.\nThis paper summarizes the thesis document of the FLOWViZ framework, which\nmain goal is to provide a software integration framework between a phylogenetic\nframework and a scientific workflow system. This framework makes it possible to\nbuild a customized integration with much fewer lines of code, while providing\nexisting phylogenetic frameworks with workflow building and execution, to\nmanage the processing of great amounts of data.\nThe project was supported by funds, for a student grant of FCT - NGPHYLO\nPTDC/CCI-BIO/29676/2017 and an IPL project - IPL/2021/DIVA.",
    "descriptor": "",
    "authors": [
      "Miguel Luis",
      "Catia Vaz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.15282"
  },
  {
    "id": "arXiv:2211.15286",
    "title": "Masked Autoencoders for Egocentric Video Understanding @ Ego4D Challenge  2022",
    "abstract": "In this report, we present our approach and empirical results of applying\nmasked autoencoders in two egocentric video understanding tasks, namely, Object\nState Change Classification and PNR Temporal Localization, of Ego4D Challenge\n2022. As team TheSSVL, we ranked 2nd place in both tasks. Our code will be made\navailable.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Jiachen Lei",
      "Shuang Ma",
      "Zhongjie Ba",
      "Sai Vemprala",
      "Ashish Kapoor",
      "Kui Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15286"
  },
  {
    "id": "arXiv:2211.15287",
    "title": "YA-DA: YAng-Based DAta Model for Fine-Grained IIoT Air Quality  Monitoring",
    "abstract": "With the development of industrialization, air pollution is also steadily on\nthe rise since both industrial and daily activities generate a massive amount\nof air pollution. Since decreasing air pollution is critical for citizens'\nhealth and well-being, air pollution monitoring is becoming an essential topic.\nIndustrial Internet of Things (IIoT) research focuses on this crucial area.\nSeveral attempts already exist for air pollution monitoring. However, none of\nthem are improving the performance of IoT data collection at the desired level.\nInspired by the genuine Yet Another Next Generation (YANG) data model, we\npropose a YAng-based DAta model (YA-DA) to improve the performance of IIoT data\ncollection. Moreover, by taking advantage of digital twin (DT) technology, we\npropose a DT-enabled fine-grained IIoT air quality monitoring system using\nYA-DA. As a result, DT synchronization becomes fine-grained. In turn, we\nimprove the performance of IIoT data collection resulting in lower round-trip\ntime (RTT), higher DT synchronization, and lower DT latency.",
    "descriptor": "\nComments: This paper has been accepted at the 4th Workshop on Future of Wireless Access and Sensing for Industrial IoT (FUTUREIIOT) in IEEE Global Communications Conference (IEEE GLOBECOM) 2022\n",
    "authors": [
      "Yagmur Yigit",
      "Khayal Huseynov",
      "Hamed Ahmadi",
      "Berk Canberk"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.15287"
  },
  {
    "id": "arXiv:2211.15294",
    "title": "Fairness Scheduling in Dense User-Centric Cell-Free Massive MIMO  Networks",
    "abstract": "We consider a user-centric scalable cell-free massive MIMO network with a\ntotal of $LM$ distributed remote radio unit antennas serving $K$ user\nequipments (UEs). Many works in the current literature assume $LM\\gg K$,\nenabling high UE data rates but also leading to a system not operating at its\nmaximum performance in terms of sum throughput. We provide a new perspective on\ncell-free massive MIMO networks, investigating rate allocation and the UE\ndensity regime in which the network makes use of its full capability. The UE\ndensity $K$ approximately equal to $\\frac{LM}{2}$ is the range in which the\nsystem reaches the largest sum throughput. In addition, there is a significant\nfraction of UEs with relatively low throughput, when serving $K>\\frac{LM}{2}$\nUEs simultaneously. We propose to reduce the number of active UEs per time\nslot, such that the system does not operate at ``full load'', and impose\nthroughput fairness among all users via a scheduler designed to maximize a\nsuitably defined concave componentwise non-decreasing network utility function.\nOur numerical simulations show that we can tune the system such that a desired\ndistribution of the UE throughput, depending on the utility function, is\nachieved.",
    "descriptor": "",
    "authors": [
      "Fabian G\u00f6ttsch",
      "Noboru Osawa",
      "Takeo Ohseki",
      "Yoshiaki Amano",
      "Issei Kanno",
      "Kosuke Yamazaki",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15294"
  },
  {
    "id": "arXiv:2211.15300",
    "title": "P4Testgen: An Extensible Test Oracle For P4",
    "abstract": "We present P4Testgen, a test oracle for the P4-16 language that supports\nautomatic generation of packet tests for any P4-programmable device. Given a P4\nprogram and sufficient time, P4Testgen generates tests that cover every\nreachable statement in the input program. Each generated test consists of an\ninput packet, control-plane configuration, and output packet(s), and can be\nexecuted in software or on hardware. Unlike prior work, P4Testgen is open\nsource and extensible, making it a general resource for the community.\nP4Testgen not only covers the full P4-16 language specification, it also\nsupports modeling the semantics of an entire packet-processing pipeline,\nincluding target-specific behaviors-i.e., whole-program semantics. Handling\naspects of packet processing that lie outside of the official specification is\ncritical for supporting real-world targets (e.g., switches, NICs, end host\nstacks). In addition, P4Testgen uses taint tracking and concolic execution to\nmodel complex externs (e.g., checksums and hash functions) that have been\nomitted by other tools, and ensures the generated tests are correct and\ndeterministic. We have instantiated P4Testgen to build test oracles for the\nV1model, eBPF, and the Tofino (TNA and T2NA) architectures; each of these\nextensions only required effort commensurate with the complexity of the target.\nWe validated the tests generated by P4Testgen by running them across the entire\nP4C program test suite as well as the Tofino programs supplied with Intel's P4\nStudio. In just a few months using the tool, we discovered and confirmed 25\nbugs in the mature, production toolchains for BMv2 and Tofino, and are\nconducting ongoing investigations into further faults uncovered by P4Testgen.",
    "descriptor": "",
    "authors": [
      "Fabian Ruffy",
      "Jed Liu",
      "Prathima Kotikalapudi",
      "Vojt\u011bch Havel",
      "Rob Sherwood",
      "Vlad Dubina",
      "Volodymyr Peschanenko",
      "Nate Foster",
      "Anirudh Sivaraman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Symbolic Computation (cs.SC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.15300"
  },
  {
    "id": "arXiv:2211.15301",
    "title": "Learning Coherent Clusters in Weakly-Connected Network Systems",
    "abstract": "We propose a structure-preserving model-reduction methodology for large-scale\ndynamic networks with tightly-connected components. First, the coherent groups\nare identified by a spectral clustering algorithm on the graph Laplacian matrix\nthat models the network feedback. Then, a reduced network is built, where each\nnode represents the aggregate dynamics of each coherent group, and the reduced\nnetwork captures the dynamic coupling between the groups. We provide an upper\nbound on the approximation error when the network graph is randomly generated\nfrom a weight stochastic block model. Finally, numerical experiments align with\nand validate our theoretical findings.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2209.13701\n",
    "authors": [
      "Hancheng Min",
      "Enrique Mallada"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.15301"
  },
  {
    "id": "arXiv:2211.15303",
    "title": "Conditional Progressive Generative Adversarial Network for satellite  image generation",
    "abstract": "Image generation and image completion are rapidly evolving fields, thanks to\nmachine learning algorithms that are able to realistically replace missing\npixels. However, generating large high resolution images, with a large level of\ndetails, presents important computational challenges. In this work, we\nformulate the image generation task as completion of an image where one out of\nthree corners is missing. We then extend this approach to iteratively build\nlarger images with the same level of detail. Our goal is to obtain a scalable\nmethodology to generate high resolution samples typically found in satellite\nimagery data sets. We introduce a conditional progressive Generative\nAdversarial Networks (GAN), that generates the missing tile in an image, using\nas input three initial adjacent tiles encoded in a latent vector by a\nWasserstein auto-encoder. We focus on a set of images used by the United\nNations Satellite Centre (UNOSAT) to train flood detection tools, and validate\nthe quality of synthetic images in a realistic setup.",
    "descriptor": "\nComments: Published at the SyntheticData4ML Neurips workshop\n",
    "authors": [
      "Renato Cardoso",
      "Sofia Vallecorsa",
      "Edoardo Nemni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15303"
  },
  {
    "id": "arXiv:2211.15308",
    "title": "Domain decomposition solvers for operators with fractional interface  perturbations",
    "abstract": "Operators with fractional perturbations are crucial components for robust\npreconditioning of interface-coupled multiphysics systems. However, in case the\nperturbation is strong, standard approaches can fail to provide scalable\napproximation of the inverse, thus compromising efficiency of the entire\nmultiphysics solver. In this work, we develop efficient and parameter-robust\nalgorithms for interface-perturbed operators based on the non-overlapping\ndomain decomposition method. As preconditioners for the resulting Schur\ncomplement problems we utilize (inverses of) weighted sums of fractional powers\nof the interfacial Laplacian. Realization of the preconditioner in terms of\nrational approximation is discussed. We demonstrate performance of the solvers\nby numerical examples including application to coupled Darcy-Stokes problem.",
    "descriptor": "\nComments: Submitted to Proceedings of the 27th International Conference on Domain% Decomposition Methods in Prague, CZE\n",
    "authors": [
      "Miroslav Kuchta"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15308"
  },
  {
    "id": "arXiv:2211.15311",
    "title": "NeuralMPS: Non-Lambertian Multispectral Photometric Stereo via Spectral  Reflectance Decomposition",
    "abstract": "Multispectral photometric stereo(MPS) aims at recovering the surface normal\nof a scene from a single-shot multispectral image captured under multispectral\nilluminations. Existing MPS methods adopt the Lambertian reflectance model to\nmake the problem tractable, but it greatly limits their application to\nreal-world surfaces. In this paper, we propose a deep neural network named\nNeuralMPS to solve the MPS problem under general non-Lambertian spectral\nreflectances. Specifically, we present a spectral reflectance\ndecomposition(SRD) model to disentangle the spectral reflectance into geometric\ncomponents and spectral components. With this decomposition, we show that the\nMPS problem for surfaces with a uniform material is equivalent to the\nconventional photometric stereo(CPS) with unknown light intensities. In this\nway, NeuralMPS reduces the difficulty of the non-Lambertian MPS problem by\nleveraging the well-studied non-Lambertian CPS methods. Experiments on both\nsynthetic and real-world scenes demonstrate the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Jipeng Lv",
      "Heng Guo",
      "Guanying Chen",
      "Jinxiu Liang",
      "Boxin Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15311"
  },
  {
    "id": "arXiv:2211.15313",
    "title": "MicroAST: Towards Super-Fast Ultra-Resolution Arbitrary Style Transfer",
    "abstract": "Arbitrary style transfer (AST) transfers arbitrary artistic styles onto\ncontent images. Despite the recent rapid progress, existing AST methods are\neither incapable or too slow to run at ultra-resolutions (e.g., 4K) with\nlimited resources, which heavily hinders their further applications. In this\npaper, we tackle this dilemma by learning a straightforward and lightweight\nmodel, dubbed MicroAST. The key insight is to completely abandon the use of\ncumbersome pre-trained Deep Convolutional Neural Networks (e.g., VGG) at\ninference. Instead, we design two micro encoders (content and style encoders)\nand one micro decoder for style transfer. The content encoder aims at\nextracting the main structure of the content image. The style encoder, coupled\nwith a modulator, encodes the style image into learnable dual-modulation\nsignals that modulate both intermediate features and convolutional filters of\nthe decoder, thus injecting more sophisticated and flexible style signals to\nguide the stylizations. In addition, to boost the ability of the style encoder\nto extract more distinct and representative style signals, we also introduce a\nnew style signal contrastive loss in our model. Compared to the state of the\nart, our MicroAST not only produces visually superior results but also is 5-73\ntimes smaller and 6-18 times faster, for the first time enabling super-fast\n(about 0.5 seconds) AST at 4K ultra-resolutions. Code is available at\nhttps://github.com/EndyWon/MicroAST.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Zhizhong Wang",
      "Lei Zhao",
      "Zhiwen Zuo",
      "Ailin Li",
      "Haibo Chen",
      "Wei Xing",
      "Dongming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15313"
  },
  {
    "id": "arXiv:2211.15320",
    "title": "RankDNN: Learning to Rank for Few-shot Learning",
    "abstract": "This paper introduces a new few-shot learning pipeline that casts relevance\nranking for image retrieval as binary ranking relation classification. In\ncomparison to image classification, ranking relation classification is sample\nefficient and domain agnostic. Besides, it provides a new perspective on\nfew-shot learning and is complementary to state-of-the-art methods. The core\ncomponent of our deep neural network is a simple MLP, which takes as input an\nimage triplet encoded as the difference between two vector-Kronecker products,\nand outputs a binary relevance ranking order. The proposed RankMLP can be built\non top of any state-of-the-art feature extractors, and our entire deep neural\nnetwork is called the ranking deep neural network, or RankDNN. Meanwhile,\nRankDNN can be flexibly fused with other post-processing methods. During the\nmeta test, RankDNN ranks support images according to their similarity with the\nquery samples, and each query sample is assigned the class label of its nearest\nneighbor. Experiments demonstrate that RankDNN can effectively improve the\nperformance of its baselines based on a variety of backbones and it outperforms\nprevious state-of-the-art algorithms on multiple few-shot learning benchmarks,\nincluding miniImageNet, tieredImageNet, Caltech-UCSD Birds, and CIFAR-FS.\nFurthermore, experiments on the cross-domain challenge demonstrate the superior\ntransferability of RankDNN.The code is available at:\nhttps://github.com/guoqianyu-alberta/RankDNN.",
    "descriptor": "\nComments: 12 pages, 4 figures. Accepted to AAAI2023\n",
    "authors": [
      "Qianyu Guo",
      "Hongtong Gong",
      "Xujun Wei",
      "Yanwei Fu",
      "Weifeng Ge",
      "Yizhou Yu",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15320"
  },
  {
    "id": "arXiv:2211.15322",
    "title": "Transductive Kernels for Gaussian Processes on Graphs",
    "abstract": "Kernels on graphs have had limited options for node-level problems. To\naddress this, we present a novel, generalized kernel for graphs with node\nfeature data for semi-supervised learning. The kernel is derived from a\nregularization framework by treating the graph and feature data as two Hilbert\nspaces. We also show how numerous kernel-based models on graphs are instances\nof our design. A kernel defined this way has transductive properties, and this\nleads to improved ability to learn on fewer training points, as well as better\nhandling of highly non-Euclidean data. We demonstrate these advantages using\nsynthetic data where the distribution of the whole graph can inform the pattern\nof the labels. Finally, by utilizing a flexible polynomial of the graph\nLaplacian within the kernel, the model also performed effectively in\nsemi-supervised classification on graphs of various levels of homophily.",
    "descriptor": "",
    "authors": [
      "Yin-Cong Zhi",
      "Felix L. Opolka",
      "Yin Cheng Ng",
      "Pietro Li\u00f2",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15322"
  },
  {
    "id": "arXiv:2211.15323",
    "title": "Security Analysis of the Consumer Remote SIM Provisioning Protocol",
    "abstract": "Remote SIM provisioning (RSP) for consumer devices is the protocol specified\nby the GSM Association for downloading SIM profiles into a secure element in a\nmobile device. The process is commonly known as eSIM, and it is expected to\nreplace removable SIM cards. The security of the protocol is critical because\nthe profile includes the credentials with which the mobile device will\nauthenticate to the mobile network. In this paper, we present a formal security\nanalysis of the consumer RSP protocol. We model the multi-party protocol in\napplied pi calculus, define formal security goals, and verify them in ProVerif.\nThe analysis shows that the consumer RSP protocol protects against a network\nadversary when all the intended participants are honest. However, we also model\nthe protocol in realistic partial compromise scenarios where the adversary\ncontrols a legitimate participant or communication channel. The security\nfailures in the partial compromise scenarios reveal weaknesses in the protocol\ndesign. The most important observation is that the security of RSP depends\nunnecessarily on it being encapsulated in a TLS tunnel. Also, the lack of\npre-established identifiers means that a compromised download server anywhere\nin the world or a compromised secure element can be used for attacks against\nRSP between honest participants. Additionally, the lack of reliable methods for\nverifying user intent can lead to serious security failures. Based on the\nfindings, we recommend practical improvements to RSP implementations, to future\nversions of the specification, and to mobile operator processes to increase the\nrobustness of eSIM security.",
    "descriptor": "\nComments: 33 pages, 8 figures, Associated ProVerif model files located at this https URL\n",
    "authors": [
      "Abu Shohel Ahmed",
      "Aleksi Peltonen",
      "Mohit Sethi",
      "Tuomas Aura"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15323"
  },
  {
    "id": "arXiv:2211.15324",
    "title": "Low-resource Personal Attribute Prediction from Conversation",
    "abstract": "Personal knowledge bases (PKBs) are crucial for a broad range of applications\nsuch as personalized recommendation and Web-based chatbots. A critical\nchallenge to build PKBs is extracting personal attribute knowledge from users'\nconversation data. Given some users of a conversational system, a personal\nattribute and these users' utterances, our goal is to predict the ranking of\nthe given personal attribute values for each user. Previous studies often rely\non a relative number of resources such as labeled utterances and external data,\nyet the attribute knowledge embedded in unlabeled utterances is underutilized\nand their performance of predicting some difficult personal attributes is still\nunsatisfactory. In addition, it is found that some text classification methods\ncould be employed to resolve this task directly. However, they also perform not\nwell over those difficult personal attributes. In this paper, we propose a\nnovel framework PEARL to predict personal attributes from conversations by\nleveraging the abundant personal attribute knowledge from utterances under a\nlow-resource setting in which no labeled utterances or external data are\nutilized. PEARL combines the biterm semantic information with the word\nco-occurrence information seamlessly via employing the updated prior attribute\nknowledge to refine the biterm topic model's Gibbs sampling process in an\niterative manner. The extensive experimental results show that PEARL\noutperforms all the baseline methods not only on the task of personal attribute\nprediction from conversations over two data sets, but also on the more general\nweakly supervised text classification task over one data set.",
    "descriptor": "\nComments: Accepted by AAAI'23\n",
    "authors": [
      "Yinan Liu",
      "Hu Chen",
      "Wei Shen",
      "Jiaoyan Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15324"
  },
  {
    "id": "arXiv:2211.15327",
    "title": "Task-Aware Asynchronous Multi-Task Model with Class Incremental  Contrastive Learning for Surgical Scene Understanding",
    "abstract": "Purpose: Surgery scene understanding with tool-tissue interaction recognition\nand automatic report generation can play an important role in intra-operative\nguidance, decision-making and postoperative analysis in robotic surgery.\nHowever, domain shifts between different surgeries with inter and intra-patient\nvariation and novel instruments' appearance degrade the performance of model\nprediction. Moreover, it requires output from multiple models, which can be\ncomputationally expensive and affect real-time performance.\nMethodology: A multi-task learning (MTL) model is proposed for surgical\nreport generation and tool-tissue interaction prediction that deals with domain\nshift problems. The model forms of shared feature extractor, mesh-transformer\nbranch for captioning and graph attention branch for tool-tissue interaction\nprediction. The shared feature extractor employs class incremental contrastive\nlearning (CICL) to tackle intensity shift and novel class appearance in the\ntarget domain. We design Laplacian of Gaussian (LoG) based curriculum learning\ninto both shared and task-specific branches to enhance model learning. We\nincorporate a task-aware asynchronous MTL optimization technique to fine-tune\nthe shared weights and converge both tasks optimally.\nResults: The proposed MTL model trained using task-aware optimization and\nfine-tuning techniques reported a balanced performance (BLEU score of 0.4049\nfor scene captioning and accuracy of 0.3508 for interaction detection) for both\ntasks on the target domain and performed on-par with single-task models in\ndomain adaptation.\nConclusion: The proposed multi-task model was able to adapt to domain shifts,\nincorporate novel instruments in the target domain, and perform tool-tissue\ninteraction detection and report generation on par with single-task models.",
    "descriptor": "\nComments: Manuscript accepted in the International Journal of Computer Assisted Radiology and Surgery. codes available: this https URL\n",
    "authors": [
      "Lalithkumar Seenivasan",
      "Mobarakol Islam",
      "Mengya Xu",
      "Chwee Ming Lim",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.15327"
  },
  {
    "id": "arXiv:2211.15328",
    "title": "A Survey on Conversational Search and Applications in Biomedicine",
    "abstract": "This paper aims to provide a radical rundown on Conversation Search\n(ConvSearch), an approach to enhance the information retrieval method where\nusers engage in a dialogue for the information-seeking tasks. In this survey,\nwe predominantly focused on the human interactive characteristics of the\nConvSearch systems, highlighting the operations of the action modules, likely\nthe Retrieval system, Question-Answering, and Recommender system. We labeled\nvarious ConvSearch research problems in knowledge bases, natural language\nprocessing, and dialogue management systems along with the action modules. We\nfurther categorized the framework to ConvSearch and the application is directed\ntoward biomedical and healthcare fields for the utilization of clinical social\ntechnology. Finally, we conclude by talking through the challenges and issues\nof ConvSearch, particularly in Bio-Medicine. Our main aim is to provide an\nintegrated and unified vision of the ConvSearch components from different\nfields, which benefit the information-seeking process in healthcare systems.",
    "descriptor": "",
    "authors": [
      "Naga Sai Krishna Adatrao",
      "Gowtham Reddy Gadireddy",
      "Jiho Noh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.15328"
  },
  {
    "id": "arXiv:2211.15330",
    "title": "UAS in the Airspace: A Review on Integration, Simulation, Optimization,  and Open Challenges",
    "abstract": "Air transportation is essential for society, and it is increasing gradually\ndue to its importance. To improve the airspace operation, new technologies are\nunder development, such as Unmanned Aircraft Systems (UAS). In fact, in the\npast few years, there has been a growth in UAS numbers in segregated airspace.\nHowever, there is an interest in integrating these aircraft into the National\nAirspace System (NAS). The UAS is vital to different industries due to its\nadvantages brought to the airspace (e.g., efficiency). Conversely, the\nrelationship between UAS and Air Traffic Control (ATC) needs to be well-defined\ndue to the impacts on ATC capacity these aircraft may present. Throughout the\nyears, this impact may be lower than it is nowadays because the current lack of\nfamiliarity in this relationship contributes to higher workload levels.\nThereupon, the primary goal of this research is to present a comprehensive\nreview of the advancements in the integration of UAS in the National Airspace\nSystem (NAS) from different perspectives. We consider the challenges regarding\nsimulation, final approach, and optimization of problems related to the\ninteroperability of such systems in the airspace. Finally, we identify several\nopen challenges in the field based on the existing state-of-the-art proposals.",
    "descriptor": "",
    "authors": [
      "Euclides Carlos Pinto Neto",
      "Derick Moreira Baum",
      "Jorge Rady de Almeida Jr.",
      "Joao Batista Camargo Jr.",
      "Paulo Sergio Cugnasca"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15330"
  },
  {
    "id": "arXiv:2211.15334",
    "title": "Beyond S-curves: Recurrent Neural Networks for Technology Forecasting",
    "abstract": "Because of the considerable heterogeneity and complexity of the technological\nlandscape, building accurate models to forecast is a challenging endeavor. Due\nto their high prevalence in many complex systems, S-curves are a popular\nforecasting approach in previous work. However, their forecasting performance\nhas not been directly compared to other technology forecasting approaches.\nAdditionally, recent developments in time series forecasting that claim to\nimprove forecasting accuracy are yet to be applied to technological development\ndata. This work addresses both research gaps by comparing the forecasting\nperformance of S-curves to a baseline and by developing an autencoder approach\nthat employs recent advances in machine learning and time series forecasting.\nS-curves forecasts largely exhibit a mean average percentage error (MAPE)\ncomparable to a simple ARIMA baseline. However, for a minority of emerging\ntechnologies, the MAPE increases by two magnitudes. Our autoencoder approach\nimproves the MAPE by 13.5% on average over the second-best result. It forecasts\nestablished technologies with the same accuracy as the other approaches.\nHowever, it is especially strong at forecasting emerging technologies with a\nmean MAPE 18% lower than the next best result. Our results imply that a simple\nARIMA model is preferable over the S-curve for technology forecasting.\nPractitioners looking for more accurate forecasts should opt for the presented\nautoencoder approach.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Alexander Glavackij",
      "Dimitri Percia David",
      "Alain Mermoud",
      "Angelika Romanou",
      "Karl Aberer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15334"
  },
  {
    "id": "arXiv:2211.15335",
    "title": "You Can Have Better Graph Neural Networks by Not Training Weights at  All: Finding Untrained GNNs Tickets",
    "abstract": "Recent works have impressively demonstrated that there exists a subnetwork in\nrandomly initialized convolutional neural networks (CNNs) that can match the\nperformance of the fully trained dense networks at initialization, without any\noptimization of the weights of the network (i.e., untrained networks). However,\nthe presence of such untrained subnetworks in graph neural networks (GNNs)\nstill remains mysterious. In this paper we carry out the first-of-its-kind\nexploration of discovering matching untrained GNNs. With sparsity as the core\ntool, we can find \\textit{untrained sparse subnetworks} at the initialization,\nthat can match the performance of \\textit{fully trained dense} GNNs. Besides\nthis already encouraging finding of comparable performance, we show that the\nfound untrained subnetworks can substantially mitigate the GNN over-smoothing\nproblem, hence becoming a powerful tool to enable deeper GNNs without bells and\nwhistles. We also observe that such sparse untrained subnetworks have appealing\nperformance in out-of-distribution detection and robustness of input\nperturbations. We evaluate our method across widely-used GNN architectures on\nvarious popular datasets including the Open Graph Benchmark (OGB).",
    "descriptor": "\nComments: Accepted by the LoG conference 2022 as a spotlight\n",
    "authors": [
      "Tianjin Huang",
      "Tianlong Chen",
      "Meng Fang",
      "Vlado Menkovski",
      "Jiaxu Zhao",
      "Lu Yin",
      "Yulong Pei",
      "Decebal Constantin Mocanu",
      "Zhangyang Wang",
      "Mykola Pechenizkiy",
      "Shiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15335"
  },
  {
    "id": "arXiv:2211.15338",
    "title": "Learning Integrable Dynamics with Action-Angle Networks",
    "abstract": "Machine learning has become increasingly popular for efficiently modelling\nthe dynamics of complex physical systems, demonstrating a capability to learn\neffective models for dynamics which ignore redundant degrees of freedom.\nLearned simulators typically predict the evolution of the system in a\nstep-by-step manner with numerical integration techniques. However, such models\noften suffer from instability over long roll-outs due to the accumulation of\nboth estimation and integration error at each prediction step. Here, we propose\nan alternative construction for learned physical simulators that are inspired\nby the concept of action-angle coordinates from classical mechanics for\ndescribing integrable systems. We propose Action-Angle Networks, which learn a\nnonlinear transformation from input coordinates to the action-angle space,\nwhere evolution of the system is linear. Unlike traditional learned simulators,\nAction-Angle Networks do not employ any higher-order numerical integration\nmethods, making them extremely efficient at modelling the dynamics of\nintegrable physical systems.",
    "descriptor": "\nComments: Accepted at Machine Learning and the Physical Sciences workshop at NeurIPS 2022\n",
    "authors": [
      "Ameya Daigavane",
      "Arthur Kosmala",
      "Miles Cranmer",
      "Tess Smidt",
      "Shirley Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.15338"
  },
  {
    "id": "arXiv:2211.15339",
    "title": "Discovering Generalizable Spatial Goal Representations via Graph-based  Active Reward Learning",
    "abstract": "In this work, we consider one-shot imitation learning for object\nrearrangement tasks, where an AI agent needs to watch a single expert\ndemonstration and learn to perform the same task in different environments. To\nachieve a strong generalization, the AI agent must infer the spatial goal\nspecification for the task. However, there can be multiple goal specifications\nthat fit the given demonstration. To address this, we propose a reward learning\napproach, Graph-based Equivalence Mappings (GEM), that can discover spatial\ngoal representations that are aligned with the intended goal specification,\nenabling successful generalization in unseen environments. Specifically, GEM\nrepresents a spatial goal specification by a reward function conditioned on i)\na graph indicating important spatial relationships between objects and ii)\nstate equivalence mappings for each edge in the graph indicating invariant\nproperties of the corresponding relationship. GEM combines inverse\nreinforcement learning and active reward learning to efficiently improve the\nreward function by utilizing the graph structure and domain randomization\nenabled by the equivalence mappings. We conducted experiments with simulated\noracles and with human subjects. The results show that GEM can drastically\nimprove the generalizability of the learned goal representations over strong\nbaselines.",
    "descriptor": "\nComments: ICML 2022, the first two authors contributed equally, project page this https URL\n",
    "authors": [
      "Aviv Netanyahu",
      "Tianmin Shu",
      "Joshua Tenenbaum",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15339"
  },
  {
    "id": "arXiv:2211.15343",
    "title": "Explainable Artificial Intelligence (XAI) from a user perspective- A  synthesis of prior literature and problematizing avenues for future research",
    "abstract": "The final search query for the Systematic Literature Review (SLR) was\nconducted on 15th July 2022. Initially, we extracted 1707 journal and\nconference articles from the Scopus and Web of Science databases. Inclusion and\nexclusion criteria were then applied, and 58 articles were selected for the\nSLR. The findings show four dimensions that shape the AI explanation, which are\nformat (explanation representation format), completeness (explanation should\ncontain all required information, including the supplementary information),\naccuracy (information regarding the accuracy of the explanation), and currency\n(explanation should contain recent information). Moreover, along with the\nautomatic representation of the explanation, the users can request additional\ninformation if needed. We have also found five dimensions of XAI effects:\ntrust, transparency, understandability, usability, and fairness. In addition,\nwe investigated current knowledge from selected articles to problematize future\nresearch agendas as research questions along with possible research paths.\nConsequently, a comprehensive framework of XAI and its possible effects on user\nbehavior has been developed.",
    "descriptor": "",
    "authors": [
      "AKM Bahalul Haque",
      "A.K.M. Najmul Islam",
      "Patrick Mikalef"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15343"
  },
  {
    "id": "arXiv:2211.15346",
    "title": "Environment-based Assistance Modulation for a Hip Exosuit via Computer  Vision",
    "abstract": "Just like in humans vision plays a fundamental role in guiding adaptive\nlocomotion, when designing the control strategy for a walking assistive\ntechnology, Computer Vision may bring substantial improvements when performing\nan environment-based assistance modulation. In this work, we developed a hip\nexosuit controller able to distinguish among three different walking terrains\nthrough the use of an RGB camera and to adapt the assistance accordingly. The\nsystem was tested with seven healthy participants walking throughout an\noverground path comprising of staircases and level ground. Subjects performed\nthe task with the exosuit disabled (Exo Off), constant assistance profile\n(Vision Off ), and with assistance modulation (Vision On). Our results showed\nthat the controller was able to promptly classify in real-time the path in\nfront of the user with an overall accuracy per class above the 85%, and to\nperform assistance modulation accordingly. Evaluation related to the effects on\nthe user showed that Vision On was able to outperform the other two conditions:\nwe obtained significantly higher metabolic savings than Exo Off, with a peak of\nabout -20% when climbing up the staircase and about -16% in the overall path,\nand than Vision Off when ascending or descending stairs. Such advancements in\nthe field may yield to a step forward for the exploitation of lightweight\nwalking assistive technologies in real-life scenarios.",
    "descriptor": "",
    "authors": [
      "Enrica Tricomi",
      "Mirko Mossini",
      "Francesco Missiroli",
      "Nicola Lotti",
      "Michele Xiloyannis",
      "Loris Roveda",
      "Lorenzo Masia"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15346"
  },
  {
    "id": "arXiv:2211.15347",
    "title": "A Tutorial on Linear Least Square Estimation",
    "abstract": "This is a brief tutorial on the least square estimation technique that is\nstraightforward yet effective for parameter estimation. The tutorial is focused\non the linear LSEs instead of nonlinear versions, since most nonlinear LSEs can\nbe approximated non-trivially using its linear counterparts. Linear LSEs can\nalso provide insight into the study of the nonlinear techniques, e.g.,\nGauss-Newton method and Lavenberg-Marquardt method etc. Linear LSEs are\ncomputationally efficient for most occasions, so they are widely applied in\npractice. In this tutorial, both the original batch least square estimation and\nits recursive variants are reviewed comprehensively with detailed mathematical\nderivations.",
    "descriptor": "\nComments: 3 Pages, tutorial\n",
    "authors": [
      "Qingrui Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15347"
  },
  {
    "id": "arXiv:2211.15349",
    "title": "Shielding in Resource-Constrained Goal POMDPs",
    "abstract": "We consider partially observable Markov decision processes (POMDPs) modeling\nan agent that needs a supply of a certain resource (e.g., electricity stored in\nbatteries) to operate correctly. The resource is consumed by agent's actions\nand can be replenished only in certain states. The agent aims to minimize the\nexpected cost of reaching some goal while preventing resource exhaustion, a\nproblem we call \\emph{resource-constrained goal optimization} (RSGO). We take a\ntwo-step approach to the RSGO problem. First, using formal methods techniques,\nwe design an algorithm computing a \\emph{shield} for a given scenario: a\nprocedure that observes the agent and prevents it from using actions that might\neventually lead to resource exhaustion. Second, we augment the POMCP heuristic\nsearch algorithm for POMDP planning with our shields to obtain an algorithm\nsolving the RSGO problem. We implement our algorithm and present experiments\nshowing its applicability to benchmarks from the literature.",
    "descriptor": "",
    "authors": [
      "Michal Ajdar\u00f3w",
      "\u0160imon Brlej",
      "Petr Novotn\u00fd"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15349"
  },
  {
    "id": "arXiv:2211.15350",
    "title": "Three classes of BCH codes and their duals",
    "abstract": "BCH codes are an important class of cyclic codes, and have wide applicantions\nin communication and storage systems. However, it is difficult to determine the\nparameters of BCH codes and only a few cases are known. In this paper, we main\nstudy three classes of BCH codes with\n$n=q^{m}-1,\\frac{q^{2s}-1}{q+1},\\frac{q^{m}-1}{q-1}$. On one hand, we\naccurately give the parameters of $\\mathcal C_{(q,n,\\delta,1)}$ and its dual\ncodes. On the other hand, we give the sufficient and necessary for $\\mathcal\nC_{(q,n,\\delta,2)}$ being dually-BCH codes.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Yanhui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15350"
  },
  {
    "id": "arXiv:2211.15351",
    "title": "Testing the effectiveness of saliency-based explainability in NLP using  randomized survey-based experiments",
    "abstract": "As the applications of Natural Language Processing (NLP) in sensitive areas\nlike Political Profiling, Review of Essays in Education, etc. proliferate,\nthere is a great need for increasing transparency in NLP models to build trust\nwith stakeholders and identify biases. A lot of work in Explainable AI has\naimed to devise explanation methods that give humans insights into the workings\nand predictions of NLP models. While these methods distill predictions from\ncomplex models like Neural Networks into consumable explanations, how humans\nunderstand these explanations is still widely unexplored. Innate human\ntendencies and biases can handicap the understanding of these explanations in\nhumans, and can also lead to them misjudging models and predictions as a\nresult. We designed a randomized survey-based experiment to understand the\neffectiveness of saliency-based Post-hoc explainability methods in Natural\nLanguage Processing. The result of the experiment showed that humans have a\ntendency to accept explanations with a less critical view.",
    "descriptor": "",
    "authors": [
      "Adel Rahimi",
      "Shaurya Jain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15351"
  },
  {
    "id": "arXiv:2211.15352",
    "title": "Interactive Image Manipulation with Complex Text Instructions",
    "abstract": "Recently, text-guided image manipulation has received increasing attention in\nthe research field of multimedia processing and computer vision due to its high\nflexibility and controllability. Its goal is to semantically manipulate parts\nof an input reference image according to the text descriptions. However, most\nof the existing works have the following problems: (1) text-irrelevant content\ncannot always be maintained but randomly changed, (2) the performance of image\nmanipulation still needs to be further improved, (3) only can manipulate\ndescriptive attributes. To solve these problems, we propose a novel image\nmanipulation method that interactively edits an image using complex text\ninstructions. It allows users to not only improve the accuracy of image\nmanipulation but also achieve complex tasks such as enlarging, dwindling, or\nremoving objects and replacing the background with the input image. To make\nthese tasks possible, we apply three strategies. First, the given image is\ndivided into text-relevant content and text-irrelevant content. Only the\ntext-relevant content is manipulated and the text-irrelevant content can be\nmaintained. Second, a super-resolution method is used to enlarge the\nmanipulation region to further improve the operability and to help manipulate\nthe object itself. Third, a user interface is introduced for editing the\nsegmentation map interactively to re-modify the generated image according to\nthe user's desires. Extensive experiments on the Caltech-UCSD Birds-200-2011\n(CUB) dataset and Microsoft Common Objects in Context (MS COCO) datasets\ndemonstrate our proposed method can enable interactive, flexible, and accurate\nimage manipulation in real-time. Through qualitative and quantitative\nevaluations, we show that the proposed model outperforms other state-of-the-art\nmethods.",
    "descriptor": "\nComments: Accepted to WACV2023\n",
    "authors": [
      "Ryugo Morita",
      "Zhiqiang Zhang",
      "Man M. Ho",
      "Jinjia Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15352"
  },
  {
    "id": "arXiv:2211.15353",
    "title": "Copula Density Neural Estimation",
    "abstract": "Probability density estimation from observed data constitutes a central task\nin statistics. Recent advancements in machine learning offer new tools but also\npose new challenges. The big data era demands analysis of long-range spatial\nand long-term temporal dependencies in large collections of raw data, rendering\nneural networks an attractive solution for density estimation. In this paper,\nwe exploit the concept of copula to explicitly build an estimate of the\nprobability density function associated to any observed data. In particular, we\nseparate univariate marginal distributions from the joint dependence structure\nin the data, the copula itself, and we model the latter with a neural\nnetwork-based method referred to as copula density neural estimation (CODINE).\nResults show that the novel learning approach is capable of modeling complex\ndistributions and it can be applied for mutual information estimation and data\ngeneration.",
    "descriptor": "\nComments: 5 pages, 4 figures. This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Nunzio A. Letizia",
      "Andrea M. Tonello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15353"
  },
  {
    "id": "arXiv:2211.15355",
    "title": "Causal Deep Reinforcement Learning using Observational Data",
    "abstract": "Deep reinforcement learning (DRL) requires the collection of plenty of\ninterventional data, which is sometimes expensive and even unethical in the\nreal world, such as in the autonomous driving and the medical field. Offline\nreinforcement learning promises to alleviate this issue by exploiting the vast\namount of observational data available in the real world. However,\nobservational data may mislead the learning agent to undesirable outcomes if\nthe behavior policy that generates the data depends on unobserved random\nvariables (i.e., confounders). In this paper, we propose two deconfounding\nmethods in DRL to address this problem. The methods first calculate the\nimportance degree of different samples based on the causal inference technique,\nand then adjust the impact of different samples on the loss function by\nreweighting or resampling the offline dataset to ensure its unbiasedness. These\ndeconfounding methods can be flexibly combined with the existing model-free DRL\nalgorithms such as soft actor-critic and deep Q-learning, provided that a weak\ncondition can be satisfied by the loss functions of these algorithms. We prove\nthe effectiveness of our deconfounding methods and validate them\nexperimentally.",
    "descriptor": "",
    "authors": [
      "Wenxuan Zhu",
      "Chao Yu",
      "Qiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15355"
  },
  {
    "id": "arXiv:2211.15356",
    "title": "A quantum algorithm to estimate the closeness to the Strict Avalanche  criterion in Boolean functions",
    "abstract": "We propose a quantum algorithm (in the form of a quantum oracle) that\nestimates the closeness of a given Boolean function to one that satisfies the\n``strict avalanche criterion'' (SAC). This algorithm requires $n$ queries of\nthe Boolean function oracle, where $n$ is the number of input variables, this\nis fewer than the queries required by the classical algorithm to perform the\nsame task. We compare our approach with other quantum algorithms that may be\nused for estimating the closeness to SAC and it is shown our algorithm verifies\nSAC with the fewest possible calls to quantum oracle and requires the fewest\nsamples for a given confidence bound.",
    "descriptor": "",
    "authors": [
      "C. A. Jothishwaran",
      "Abhishek Chakraborty",
      "Vishvendra Singh Poonia",
      "Pantelimon Stanica",
      "Sugata Gangopadhyay"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.15356"
  },
  {
    "id": "arXiv:2211.15359",
    "title": "Towards Improving Proactive Dialog Agents Using Socially-Aware  Reinforcement Learning",
    "abstract": "The next step for intelligent dialog agents is to escape their role as silent\nbystanders and become proactive. Well-defined proactive behavior may improve\nhuman-machine cooperation, as the agent takes a more active role during\ninteraction and takes off responsibility from the user. However, proactivity is\na double-edged sword because poorly executed pre-emptive actions may have a\ndevastating effect not only on the task outcome but also on the relationship\nwith the user. For designing adequate proactive dialog strategies, we propose a\nnovel approach including both social as well as task-relevant features in the\ndialog. Here, the primary goal is to optimize proactive behavior so that it is\ntask-oriented - this implies high task success and efficiency - while also\nbeing socially effective by fostering user trust. Including both aspects in the\nreward function for training a proactive dialog agent using reinforcement\nlearning showed the benefit of our approach for more successful human-machine\ncooperation.",
    "descriptor": "",
    "authors": [
      "Matthias Kraus",
      "Nicolas Wagner",
      "Ron Riekenbrauck",
      "Wolfgang Minker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15359"
  },
  {
    "id": "arXiv:2211.15360",
    "title": "Learning Recommendations from User Actions in the Item-poor Insurance  Domain",
    "abstract": "While personalised recommendations are successful in domains like retail,\nwhere large volumes of user feedback on items are available, the generation of\nautomatic recommendations in data-sparse domains, like insurance purchasing, is\nan open problem. The insurance domain is notoriously data-sparse because the\nnumber of products is typically low (compared to retail) and they are usually\npurchased to last for a long time. Also, many users still prefer the telephone\nover the web for purchasing products, reducing the amount of web-logged user\ninteractions. To address this, we present a recurrent neural network\nrecommendation model that uses past user sessions as signals for learning\nrecommendations. Learning from past user sessions allows dealing with the data\nscarcity of the insurance domain. Specifically, our model learns from several\ntypes of user actions that are not always associated with items, and unlike all\nprior session-based recommendation models, it models relationships between\ninput sessions and a target action (purchasing insurance) that does not take\nplace within the input sessions. Evaluation on a real-world dataset from the\ninsurance domain (ca. 44K users, 16 items, 54K purchases, and 117K sessions)\nagainst several state-of-the-art baselines shows that our model outperforms the\nbaselines notably. Ablation analysis shows that this is mainly due to the\nlearning of dependencies across sessions in our model. We contribute the first\never session-based model for insurance recommendation, and make available our\ndataset to the research community.",
    "descriptor": "",
    "authors": [
      "Simone Borg Bruun",
      "Maria Maistro",
      "Christina Lioma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.15360"
  },
  {
    "id": "arXiv:2211.15362",
    "title": "Good helper is around you: Attention-driven Masked Image Modeling",
    "abstract": "It has been witnessed that masked image modeling (MIM) has shown a huge\npotential in self-supervised learning in the past year. Benefiting from the\nuniversal backbone vision transformer, MIM learns self-supervised visual\nrepresentations through masking a part of patches of the image while attempting\nto recover the missing pixels. Most previous works mask patches of the image\nrandomly, which underutilizes the semantic information that is beneficial to\nvisual representation learning. On the other hand, due to the large size of the\nbackbone, most previous works have to spend much time on pre-training. In this\npaper, we propose \\textbf{Attention-driven Masking and Throwing Strategy}\n(AMT), which could solve both problems above. We first leverage the\nself-attention mechanism to obtain the semantic information of the image during\nthe training process automatically without using any supervised methods.\nMasking strategy can be guided by that information to mask areas selectively,\nwhich is helpful for representation learning. Moreover, a redundant patch\nthrowing strategy is proposed, which makes learning more efficient. As a\nplug-and-play module for masked image modeling, AMT improves the linear probing\naccuracy of MAE by $2.9\\% \\sim 5.9\\%$ on CIFAR-10/100, STL-10, Tiny ImageNet,\nand ImageNet-1K, and obtains an improved performance with respect to\nfine-tuning accuracy of MAE and SimMIM. Moreover, this design also achieves\nsuperior performance on downstream detection and segmentation tasks.",
    "descriptor": "\nComments: This paper is accepted by AAAI 2023\n",
    "authors": [
      "Jie Gui",
      "Zhengqi Liu",
      "Hao Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15362"
  },
  {
    "id": "arXiv:2211.15363",
    "title": "On the Security Vulnerabilities of Text-to-SQL Models",
    "abstract": "Recent studies show that, despite being effective on numerous tasks, text\nprocessing algorithms may be vulnerable to deliberate attacks. However, the\nquestion of whether such weaknesses can directly lead to security threats is\nstill under-explored. To bridge this gap, we conducted vulnerability tests on\nText-to-SQL, a technique that builds natural language interfaces for databases.\nEmpirically, we showed that the Text-to-SQL modules of two commercial black\nboxes (Baidu-UNIT and Codex-powered Ai2sql) can be manipulated to produce\nmalicious code, potentially leading to data breaches and Denial of Service.\nThis is the first demonstration of the danger of NLP models being exploited as\nattack vectors in the wild. Moreover, experiments involving four open-source\nframeworks verified that simple backdoor attacks can achieve a 100% success\nrate on Text-to-SQL systems with almost no prediction performance impact. By\nreporting these findings and suggesting practical defences, we call for\nimmediate attention from the NLP community to the identification and\nremediation of software security issues.",
    "descriptor": "",
    "authors": [
      "Xutan Peng",
      "Yipeng Zhang",
      "Jingfeng Yang",
      "Mark Stevenson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.15363"
  },
  {
    "id": "arXiv:2211.15367",
    "title": "Few-shot Non-line-of-sight Imaging with Signal-surface Collaborative  Regularization",
    "abstract": "The non-line-of-sight imaging technique aims to reconstruct targets from\nmultiply reflected light. For most existing methods, dense points on the relay\nsurface are raster scanned to obtain high-quality reconstructions, which\nrequires a long acquisition time. In this work, we propose a signal-surface\ncollaborative regularization (SSCR) framework that provides noise-robust\nreconstructions with a minimal number of measurements. Using Bayesian\ninference, we design joint regularizations of the estimated signal, the 3D\nvoxel-based representation of the objects, and the 2D surface-based description\nof the targets. To our best knowledge, this is the first work that combines\nregularizations in mixed dimensions for hidden targets. Experiments on\nsynthetic and experimental datasets illustrated the efficiency and robustness\nof the proposed method under both confocal and non-confocal settings. We report\nthe reconstruction of the hidden targets with complex geometric structures with\nonly $5 \\times 5$ confocal measurements from public datasets, indicating an\nacceleration of the conventional measurement process by a factor of 10000.\nBesides, the proposed method enjoys low time and memory complexities with\nsparse measurements. Our approach has great potential in real-time\nnon-line-of-sight imaging applications such as rescue operations and autonomous\ndriving.",
    "descriptor": "\nComments: main article: 10 pages, 7 figures supplement: 11 pages, 24 figures\n",
    "authors": [
      "Xintong Liu",
      "Jianyu Wang",
      "Leping Xiao",
      "Xing Fu",
      "Lingyun Qiu",
      "Zuoqiang Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.15367"
  },
  {
    "id": "arXiv:2211.15368",
    "title": "Hide and Seek: Scaling Machine Learning for Combinatorial Optimization  via the Probabilistic Method",
    "abstract": "Applying deep learning to solve real-life instances of hard combinatorial\nproblems has tremendous potential. Research in this direction has focused on\nthe Boolean satisfiability (SAT) problem, both because of its theoretical\ncentrality and practical importance. A major roadblock faced, though, is that\ntraining sets are restricted to random formulas of size several orders of\nmagnitude smaller than formulas of practical interest, raising serious concerns\nabout generalization. This is because labeling random formulas of increasing\nsize rapidly becomes intractable. By exploiting the probabilistic method in a\nfundamental way, we remove this roadblock entirely: we show how to generate\ncorrectly labeled random formulas of any desired size, without having to solve\nthe underlying decision problem. Moreover, the difficulty of the classification\ntask for the formulas produced by our generator is tunable by varying a simple\nscalar parameter. This opens up an entirely new level of sophistication for the\nmachine learning methods that can be brought to bear on Satisfiability. Using\nour generator, we train existing state-of-the-art models for the task of\npredicting satisfiability on formulas with 10,000 variables. We find that they\ndo no better than random guessing. As a first indication of what can be\nachieved with the new generator, we present a novel classifier that performs\nsignificantly better than random guessing 99% on the same datasets, for most\ndifficulty levels. Crucially, unlike past approaches that learn based on\nsyntactic features of a formula, our classifier performs its learning on a\nshort prefix of a solver's computation, an approach that we expect to be of\nindependent interest.",
    "descriptor": "",
    "authors": [
      "Dimitris Achlioptas",
      "Amrit Daswaney",
      "Periklis A. Papakonstantinou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15368"
  },
  {
    "id": "arXiv:2211.15370",
    "title": "Clarity: an improved gradient method for producing quality visual  counterfactual explanations",
    "abstract": "Visual counterfactual explanations identify modifications to an image that\nwould change the prediction of a classifier. We propose a set of techniques\nbased on generative models (VAE) and a classifier ensemble directly trained in\nthe latent space, which all together, improve the quality of the gradient\nrequired to compute visual counterfactuals. These improvements lead to a novel\nclassification model, Clarity, which produces realistic counterfactual\nexplanations over all images. We also present several experiments that give\ninsights on why these techniques lead to better quality results than those in\nthe literature. The explanations produced are competitive with the\nstate-of-the-art and emphasize the importance of selecting a meaningful input\nspace for training.",
    "descriptor": "",
    "authors": [
      "Claire Theobald",
      "Fr\u00e9d\u00e9ric Pennerath",
      "Brieuc Conan-Guez",
      "Miguel Couceiro",
      "Amedeo Napoli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15370"
  },
  {
    "id": "arXiv:2211.15374",
    "title": "Identification of Surface Defects on Solar PV Panels and Wind Turbine  Blades using Attention based Deep Learning Model",
    "abstract": "According to Global Electricity Review 2022, electricity generation from\nrenewable energy sources has increased by 20% worldwide primarily due to more\ninstallation of large green power plants. Monitoring the renewable energy\nassets in those large power plants is still challenging as the assets are\nhighly impacted by several environmental factors, resulting in issues like less\npower generation, malfunctioning, and degradation of asset life. Therefore,\ndetecting the surface defects on the renewable energy assets would facilitate\nthe process to maintain the safety and efficiency of the green power plants. An\ninnovative detection framework is proposed to achieve an economical renewable\nenergy asset surface monitoring system. First capture the asset's\nhigh-resolution images on a regular basis and inspect them to detect the\ndamages. For inspection this paper presents a unified deep learning-based image\ninspection model which analyzes the captured images to identify the surface or\nstructural damages on the various renewable energy assets in large power\nplants. We use the Vision Transformer (ViT), the latest developed deep-learning\nmodel in computer vision, to detect the damages on solar panels and wind\nturbine blades and classify the type of defect to suggest the preventive\nmeasures. With the ViT model, we have achieved above 97% accuracy for both the\nassets, which outperforms the benchmark classification models for the input\nimages of varied modalities taken from publicly available sources.",
    "descriptor": "",
    "authors": [
      "Divyanshi Dwivedi",
      "K. Victor Sam Moses Babu",
      "Pradeep Kumar Yemula",
      "Pratyush Chakraborty",
      "Mayukha Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.15374"
  },
  {
    "id": "arXiv:2211.15378",
    "title": "Aesthetically Relevant Image Captioning",
    "abstract": "Image aesthetic quality assessment (AQA) aims to assign numerical aesthetic\nratings to images whilst image aesthetic captioning (IAC) aims to generate\ntextual descriptions of the aesthetic aspects of images. In this paper, we\nstudy image AQA and IAC together and present a new IAC method termed\nAesthetically Relevant Image Captioning (ARIC). Based on the observation that\nmost textual comments of an image are about objects and their interactions\nrather than aspects of aesthetics, we first introduce the concept of Aesthetic\nRelevance Score (ARS) of a sentence and have developed a model to automatically\nlabel a sentence with its ARS. We then use the ARS to design the ARIC model\nwhich includes an ARS weighted IAC loss function and an ARS based diverse\naesthetic caption selector (DACS). We present extensive experimental results to\nshow the soundness of the ARS concept and the effectiveness of the ARIC model\nby demonstrating that texts with higher ARS's can predict the aesthetic ratings\nmore accurately and that the new ARIC model can generate more accurate,\naesthetically more relevant and more diverse image captions. Furthermore, a\nlarge new research database containing 510K images with over 5 million comments\nand 350K aesthetic scores, and code for implementing ARIC are available at\nhttps://github.com/PengZai/ARIC.",
    "descriptor": "\nComments: Aceepted by AAAI2023. Code and results available at this https URL\n",
    "authors": [
      "Zhipeng Zhong",
      "Fei Zhou",
      "Guoping Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15378"
  },
  {
    "id": "arXiv:2211.15381",
    "title": "Incentive-Aware Recommender Systems in Two-Sided Markets",
    "abstract": "Online platforms in the Internet Economy commonly incorporate recommender\nsystems that recommend arms (e.g., products) to agents (e.g., users). In such\nplatforms, a myopic agent has a natural incentive to exploit, by choosing the\nbest product given the current information rather than to explore various\nalternatives to collect information that will be used for other agents. We\npropose a novel recommender system that respects agents' incentives and enjoys\nasymptotically optimal performances expressed by the regret in repeated games.\nWe model such an incentive-aware recommender system as a multi-agent bandit\nproblem in a two-sided market which is equipped with an incentive constraint\ninduced by agents' opportunity costs. If the opportunity costs are known to the\nprincipal, we show that there exists an incentive-compatible recommendation\npolicy, which pools recommendations across a genuinely good arm and an unknown\narm via a randomized and adaptive approach. On the other hand, if the\nopportunity costs are unknown to the principal, we propose a policy that\nrandomly pools recommendations across all arms and uses each arm's cumulative\nloss as feedback for exploration. We show that both policies also satisfy an\nex-post fairness criterion, which protects agents from over-exploitation.",
    "descriptor": "",
    "authors": [
      "Xiaowu Dai",
      "Yuan",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15381"
  },
  {
    "id": "arXiv:2211.15382",
    "title": "Neural Network Complexity of Chaos and Turbulence",
    "abstract": "We study the complexity of chaos and turbulence as viewed by deep neural\nnetworks by considering network classification tasks of distinguishing\nturbulent from chaotic fluid flows, noise and real world images of cats or\ndogs. We analyze the relative difficulty of these classification tasks and\nquantify the complexity of the computation at the intermediate and final\nstages. We analyze incompressible as well as weakly compressible fluid flows\nand provide evidence for the feature identified by the neural network to\ndistinguish turbulence from chaos.",
    "descriptor": "",
    "authors": [
      "Tim Whittaker",
      "Romuald A. Janik",
      "Yaron Oz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Theory (hep-th)",
      "Chaotic Dynamics (nlin.CD)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.15382"
  },
  {
    "id": "arXiv:2211.15384",
    "title": "Double Deep Q-Learning in Opponent Modeling",
    "abstract": "Multi-agent systems in which secondary agents with conflicting agendas also\nalter their methods need opponent modeling. In this study, we simulate the main\nagent's and secondary agents' tactics using Double Deep Q-Networks (DDQN) with\na prioritized experience replay mechanism. Then, under the opponent modeling\nsetup, a Mixture-of-Experts architecture is used to identify various opponent\nstrategy patterns. Finally, we analyze our models in two environments with\nseveral agents. The findings indicate that the Mixture-of-Experts model, which\nis based on opponent modeling, performs better than DDQN.",
    "descriptor": "",
    "authors": [
      "Yangtianze Tao",
      "John Doe"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15384"
  },
  {
    "id": "arXiv:2211.15386",
    "title": "PC-SNN: Supervised Learning with Local Hebbian Synaptic Plasticity based  on Predictive Coding in Spiking Neural Networks",
    "abstract": "Deemed as the third generation of neural networks, the event-driven Spiking\nNeural Networks(SNNs) combined with bio-plausible local learning rules make it\npromising to build low-power, neuromorphic hardware for SNNs. However, because\nof the non-linearity and discrete property of spiking neural networks, the\ntraining of SNN remains difficult and is still under discussion. Originating\nfrom gradient descent, backprop has achieved stunning success in multi-layer\nSNNs. Nevertheless, it is assumed to lack biological plausibility, while\nconsuming relatively high computational resources. In this paper, we propose a\nnovel learning algorithm inspired by predictive coding theory and show that it\ncan perform supervised learning fully autonomously and successfully as the\nbackprop, utilizing only local Hebbian plasticity. Furthermore, this method\nachieves a favorable performance compared to the state-of-the-art multi-layer\nSNNs: test accuracy of 99.25% for the Caltech Face/Motorbike dataset, 84.25%\nfor the ETH-80 dataset, 98.1% for the MNIST dataset and 98.5% for the\nneuromorphic dataset: N-MNIST. Furthermore, our work provides a new perspective\non how supervised learning algorithms are directly implemented in spiking\nneural circuitry, which may give some new insights into neuromorphological\ncalculation in neuroscience.",
    "descriptor": "\nComments: 15 pages, 11figs\n",
    "authors": [
      "Mengting Lan",
      "Xiaogang Xiong",
      "Zixuan Jiang",
      "Yunjiang Lou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.15386"
  },
  {
    "id": "arXiv:2211.15387",
    "title": "AIREPAIR: A Repair Platform for Neural Networks",
    "abstract": "We present AIREPAIR, a platform for repairing neural networks. It features\nthe integration of existing network repair tools. Based on AIREPAIR, one can\nrun different repair methods on the same model, thus enabling the fair\ncomparison of different repair techniques. We evaluate AIREPAIR with three\nstate-of-the-art repair tools on popular deep-learning datasets and models. Our\nevaluation confirms the utility of AIREPAIR, by comparing and analyzing the\nresults from different repair techniques. A demonstration is available at\nhttps://youtu.be/UkKw5neeWhw.",
    "descriptor": "",
    "authors": [
      "Xidan Song",
      "Youcheng Sun",
      "Mustafa A. Mustafa",
      "Lucas Cordeiro"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15387"
  },
  {
    "id": "arXiv:2211.15388",
    "title": "Shifted Diffusion for Text-to-image Generation",
    "abstract": "We present Corgi, a novel method for text-to-image generation. Corgi is based\non our proposed shifted diffusion model, which achieves better image embedding\ngeneration from input text. Unlike the baseline diffusion model used in DALL-E\n2, our method seamlessly encodes prior knowledge of the pre-trained CLIP model\nin its diffusion process by designing a new initialization distribution and a\nnew transition step of the diffusion. Compared to the strong DALL-E 2 baseline,\nour method performs better in generating image embedding from the text in terms\nof both efficiency and effectiveness, resulting in better text-to-image\ngeneration. Extensive large-scale experiments are conducted and evaluated in\nterms of both quantitative measures and human evaluation, indicating a stronger\ngeneration ability of our method compared to existing ones. Furthermore, our\nmodel enables semi-supervised and language-free training for text-to-image\ngeneration, where only part or none of the images in the training dataset have\nan associated caption. Trained with only 1.7% of the images being captioned,\nour semi-supervised model obtains FID results comparable to DALL-E 2 on\nzero-shot text-to-image generation evaluated on MS-COCO. Corgi also achieves\nnew state-of-the-art results across different datasets on downstream\nlanguage-free text-to-image generation tasks, outperforming the previous\nmethod, Lafite, by a large margin.",
    "descriptor": "",
    "authors": [
      "Yufan Zhou",
      "Bingchen Liu",
      "Yizhe Zhu",
      "Xiao Yang",
      "Changyou Chen",
      "Jinhui Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15388"
  },
  {
    "id": "arXiv:2211.15393",
    "title": "Video Test-Time Adaptation for Action Recognition",
    "abstract": "Although action recognition systems can achieve top performance when\nevaluated on in-distribution test points, they are vulnerable to unanticipated\ndistribution shifts in test data. However, test-time adaptation of video action\nrecognition models against common distribution shifts has so far not been\ndemonstrated. We propose to address this problem with an approach tailored to\nspatio-temporal models that is capable of adaptation on a single video sample\nat a step. It consists in a feature distribution alignment technique that\naligns online estimates of test set statistics towards the training statistics.\nWe further enforce prediction consistency over temporally augmented views of\nthe same test video sample. Evaluations on three benchmark action recognition\ndatasets show that our proposed technique is architecture-agnostic and able to\nsignificantly boost the performance on both, the state of the art convolutional\narchitecture TANet and the Video Swin Transformer. Our proposed method\ndemonstrates a substantial performance gain over existing test-time adaptation\napproaches in both evaluations of a single distribution shift and the\nchallenging case of random distribution shifts. Code will be available at\n\\url{https://github.com/wlin-at/ViTTA}.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Wei Lin",
      "Muhammad Jehanzeb Mirza",
      "Mateusz Kozinski",
      "Horst Possegger",
      "Hilde Kuehne",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15393"
  },
  {
    "id": "arXiv:2211.15395",
    "title": "CodeExp: Explanatory Code Document Generation",
    "abstract": "Developing models that can automatically generate detailed code explanation\ncan greatly benefit software maintenance and programming education. However,\nexisting code-to-text generation models often produce only high-level summaries\nof code that do not capture implementation-level choices essential for these\nscenarios. To fill in this gap, we propose the code explanation generation\ntask. We first conducted a human study to identify the criteria for\nhigh-quality explanatory docstring for code. Based on that, we collected and\nrefined a large-scale code docstring corpus and formulated automatic evaluation\nmetrics that best match human assessments. Finally, we present a multi-stage\nfine-tuning strategy and baseline models for the task. Our experiments show\nthat (1) our refined training dataset lets models achieve better performance in\nthe explanation generation tasks compared to larger unrefined data (15x\nlarger), and (2) fine-tuned models can generate well-structured long docstrings\ncomparable to human-written ones. We envision our training dataset,\nhuman-evaluation protocol, recommended metrics, and fine-tuning strategy can\nboost future code explanation research. The code and annotated data are\navailable at https://github.com/subercui/CodeExp.",
    "descriptor": "\nComments: Accepted in Findings of EMNLP 2022\n",
    "authors": [
      "Haotian Cui",
      "Chenglong Wang",
      "Junjie Huang",
      "Jeevana Priya Inala",
      "Todd Mytkowicz",
      "Bo Wang",
      "Jianfeng Gao",
      "Nan Duan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15395"
  },
  {
    "id": "arXiv:2211.15397",
    "title": "Automating Systematic Literature Reviews with Natural Language  Processing and Text Mining: a Systematic Literature Review",
    "abstract": "Objectives: An SLR is presented focusing on text mining based automation of\nSLR creation. The present review identifies the objectives of the automation\nstudies and the aspects of those steps that were automated. In so doing, the\nvarious ML techniques used, challenges, limitations and scope of further\nresearch are explained.\nMethods: Accessible published literature studies that primarily focus on\nautomation of study selection, study quality assessment, data extraction and\ndata synthesis portions of SLR. Twenty-nine studies were analyzed.\nResults: This review identifies the objectives of the automation studies,\nsteps within the study selection, study quality assessment, data extraction and\ndata synthesis portions that were automated, the various ML techniques used,\nchallenges, limitations and scope of further research.\nDiscussion: We describe uses of NLP/TM techniques to support increased\nautomation of systematic literature reviews. This area has attracted increase\nattention in the last decade due to significant gaps in the applicability of TM\nto automate steps in the SLR process. There are significant gaps in the\napplication of TM and related automation techniques in the areas of data\nextraction, monitoring, quality assessment and data synthesis. There is thus a\nneed for continued progress in this area, and this is expected to ultimately\nsignificantly facilitate the construction of systematic literature reviews.",
    "descriptor": "",
    "authors": [
      "Girish Sundaram",
      "Daniel Berleant"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.15397"
  },
  {
    "id": "arXiv:2211.15398",
    "title": "Leveraging per Image-Token Consistency for Vision-Language Pre-training",
    "abstract": "Most existing vision-language pre-training (VLP) approaches adopt cross-modal\nmasked language modeling (CMLM) to learn vision-language associations. However,\nwe find that CMLM is insufficient for this purpose according to our\nobservations: (1) Modality bias: a considerable amount of masked tokens in CMLM\ncan be recovered with only the language information, ignoring the visual\ninputs. (2) Under-utilization of the unmasked tokens: CMLM primarily focuses on\nthe masked token but it cannot simultaneously leverage other tokens to learn\nvision-language associations. To handle those limitations, we propose EPIC\n(lEveraging Per Image-Token Consistency for vision-language pre-training). In\nEPIC, for each image-sentence pair, we mask tokens that are salient to the\nimage (i.e., Saliency-based Masking Strategy) and replace them with\nalternatives sampled from a language model (i.e., Inconsistent Token Generation\nProcedure), and then the model is required to determine for each token in the\nsentence whether they are consistent with the image (i.e., Image-Text\nConsistent Task). The proposed EPIC method is easily combined with pre-training\nmethods. Extensive experiments show that the combination of the EPIC method and\nstate-of-the-art pre-training approaches, including ViLT, ALBEF, METER, and\nX-VLM, leads to significant improvements on downstream tasks.",
    "descriptor": "",
    "authors": [
      "Yunhao Gou",
      "Tom Ko",
      "Hansi Yang",
      "James Kwok",
      "Yu Zhang",
      "Mingxuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15398"
  },
  {
    "id": "arXiv:2211.15402",
    "title": "Perceive, Ground, Reason, and Act: A Benchmark for General-purpose  Visual Representation",
    "abstract": "Current computer vision models, unlike the human visual system, cannot yet\nachieve general-purpose visual understanding. Existing efforts to create a\ngeneral vision model are limited in the scope of assessed tasks and offer no\noverarching framework to perform them holistically. We present a new\ncomprehensive benchmark, General-purpose Visual Understanding Evaluation\n(G-VUE), covering the full spectrum of visual cognitive abilities with four\nfunctional domains $\\unicode{x2014}$ Perceive, Ground, Reason, and Act. The\nfour domains are embodied in 11 carefully curated tasks, from 3D reconstruction\nto visual reasoning and manipulation. Along with the benchmark, we provide a\ngeneral encoder-decoder framework to allow for the evaluation of arbitrary\nvisual representation on all 11 tasks. We evaluate various pre-trained visual\nrepresentations with our framework and observe that (1) Transformer-based\nvisual backbone generally outperforms CNN-based backbone on G-VUE, (2) visual\nrepresentations from vision-language pre-training are superior to those with\nvision-only pre-training across visual tasks. With G-VUE, we provide a holistic\nevaluation standard to motivate research toward building general-purpose visual\nsystems via obtaining more general-purpose visual representations.",
    "descriptor": "",
    "authors": [
      "Jiangyong Huang",
      "William Yicheng Zhu",
      "Baoxiong Jia",
      "Zan Wang",
      "Xiaojian Ma",
      "Qing Li",
      "Siyuan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15402"
  },
  {
    "id": "arXiv:2211.15404",
    "title": "Modern DDoS Attacks and Defences -- Survey",
    "abstract": "Denial of Service (DoS) and Distributed Denial of Service of Service (DDoS)\nattacks are commonly used to disrupt network services. Attack techniques are\nalways improving and due to the structure of the internet and properties of\nnetwork protocols it is difficult to keep detection and mitigation techniques\nup to date. A lot of research has been conducted in this area which has\ndemonstrated the difficulty of preventing DDoS attacks altogether, therefore\nthe primary aim of most research is to maximize quality of service (QoS) for\nlegitimate users. This survey paper aims to provide a clear summary of DDoS\nattacks and focuses on some recently proposed techniques for defence. The\nresearch papers that are analysed in depth primarily focused on the use of\nvirtual machines (VMs) (HoneyMesh) and network function virtualization (NFV)\n(VGuard and VFence).",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Jonah Burgess"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15404"
  },
  {
    "id": "arXiv:2211.15405",
    "title": "Malware and Exploits on the Dark Web",
    "abstract": "In recent years, the darknet has become the key location for the distribution\nof malware and exploits. We have seen scenarios where software vulnerabilities\nhave been disclosed by vendors and shortly after, operational exploits are\navailable on darknet forums and marketplaces. Many marketplace vendors offer\nzero-day exploits that have not yet been discovered or disclosed. This trend\nhas led to security companies offering darknet analysis services to detect new\nexploits and malware, providing proactive threat intelligence. This paper\npresents information on the scale of malware distribution, the trends of\nmalware types offered, the methods for discovering new exploits and the\neffectiveness of darknet analysis in detecting malware at the earliest possible\nstage.",
    "descriptor": "\nComments: 5 pages, 0 figures\n",
    "authors": [
      "Jonah Burgess"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15405"
  },
  {
    "id": "arXiv:2211.15406",
    "title": "Automated Detection of Dolphin Whistles with Convolutional Networks and  Transfer Learning",
    "abstract": "Effective conservation of maritime environments and wildlife management of\nendangered species require the implementation of efficient, accurate and\nscalable solutions for environmental monitoring. Ecoacoustics offers the\nadvantages of non-invasive, long-duration sampling of environmental sounds and\nhas the potential to become the reference tool for biodiversity surveying.\nHowever, the analysis and interpretation of acoustic data is a time-consuming\nprocess that often requires a great amount of human supervision. This issue\nmight be tackled by exploiting modern techniques for automatic audio signal\nanalysis, which have recently achieved impressive performance thanks to the\nadvances in deep learning research. In this paper we show that convolutional\nneural networks can indeed significantly outperform traditional automatic\nmethods in a challenging detection task: identification of dolphin whistles\nfrom underwater audio recordings. The proposed system can detect signals even\nin the presence of ambient noise, at the same time consistently reducing the\nlikelihood of producing false positives and false negatives. Our results\nfurther support the adoption of artificial intelligence technology to improve\nthe automatic monitoring of marine ecosystems.",
    "descriptor": "",
    "authors": [
      "Burla Nur Korkmaz",
      "Roee Diamant",
      "Gil Danino",
      "Alberto Testolin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.15406"
  },
  {
    "id": "arXiv:2211.15407",
    "title": "Fine-tuned Sentiment Analysis of COVID-19 Vaccine-Related Social Media  Data: Comparative Study",
    "abstract": "This study investigated and compared public sentiment related to COVID-19\nvaccines expressed on two popular social media platforms, Reddit and Twitter,\nharvested from January 1, 2020, to March 1, 2022. To accomplish this task, we\ncreated a fine-tuned DistilRoBERTa model to predict sentiments of approximately\n9.5 million Tweets and 70 thousand Reddit comments. To fine-tune our model, our\nteam manually labeled the sentiment of 3600 Tweets and then augmented our\ndataset by the method of back-translation. Text sentiment for each social media\nplatform was then classified with our fine-tuned model using Python and the\nHuggingface sentiment analysis pipeline. Our results determined that the\naverage sentiment expressed on Twitter was more negative (52% positive) than\npositive and the sentiment expressed on Reddit was more positive than negative\n(53% positive). Though average sentiment was found to vary between these social\nmedia platforms, both displayed similar behavior related to sentiment shared at\nkey vaccine-related developments during the pandemic. Considering this similar\ntrend in shared sentiment demonstrated across social media platforms, Twitter\nand Reddit continue to be valuable data sources that public health officials\ncan utilize to strengthen vaccine confidence and combat misinformation. As the\nspread of misinformation poses a range of psychological and psychosocial risks\n(anxiety, fear, etc.), there is an urgency in understanding the public\nperspective and attitude toward shared falsities. Comprehensive educational\ndelivery systems tailored to the population's expressed sentiments that\nfacilitate digital literacy, health information-seeking behavior, and precision\nhealth promotion could aid in clarifying such misinformation.",
    "descriptor": "\nComments: 11 Pages, 5 Figures, and 1 Table\n",
    "authors": [
      "Chad A Melton",
      "Brianna M White",
      "Robert L Davis",
      "Robert A Bednarczyk",
      "Arash Shaban-Nejad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.15407"
  },
  {
    "id": "arXiv:2211.15408",
    "title": "Fuzziness, Indeterminacy and Soft Sets: Frontiers and Perspectives",
    "abstract": "The present paper comes across the main steps that laid from Zadeh's\nfuzziness ana Atanassov's intuitionistic fuzzy sets to Smarandache's\nindeterminacy and to Molodstov's soft sets. Two hybrid methods for assessment\nand decision making respectively under fuzzy conditions are also presented\nthrough suitable examples that use soft sets and real intervals as tools. The\ndecision making method improves an earlier method of Maji et al. Further, it is\ndescribed how the concept of topological space, the most general category of\nmathematical spaces, can be extended to fuzzy structures and how to generalize\nthe fundamental mathematical concepts of limit, continuity compactness and\nHausdorff space within such kind of structures. In particular, fuzzy and soft\ntopological spaces are defined and examples are given to illustrate these\ngeneralizations.",
    "descriptor": "\nComments: 15 pages, 2 figures, 3 Tables, 30n references\n",
    "authors": [
      "Michael Gr. Voskoglou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15408"
  },
  {
    "id": "arXiv:2211.15409",
    "title": "A framework for structural shape optimization based on automatic  differentiation, the adjoint method and accelerated linear algebra",
    "abstract": "Shape optimization is of great significance in structural engineering, as an\nefficient geometry leads to better performance of structures. However, the\napplication of gradient-based shape optimization for structural and\narchitectural design is limited, which is partly due to the difficulty and the\ncomplexity in gradient evaluation. In this work, an efficient framework based\non automatic differentiation (AD), the adjoint method and accelerated linear\nalgebra (XLA) is proposed to promote the implementation of gradient-based shape\noptimization. The framework is realized by the implementation of the\nhigh-performance computing (HPC) library JAX. We leverage AD for gradient\nevaluation in the sensitivity analysis stage. Compared to numerical\ndifferentiation, AD is more accurate; compared to analytical and symbolic\ndifferentiation, AD is more efficient and easier to apply. In addition, the\nadjoint method is used to reduce the complexity of computation of the\nsensitivity. The XLA feature is exploited by an efficient programming\narchitecture that we proposed, which can boost gradient evaluation. The\nproposed framework also supports hardware acceleration such as GPUs. The\nframework is applied to the form finding of arches and different free-form\ngridshells: gridshell inspired by Mannheim Multihalle, four-point supported\ngridshell, and canopy-like structures. Two geometric descriptive methods are\nused: non-parametric and parametric description via B\\'ezier surface.\nNon-constrained and constrained shape optimization problems are considered,\nwhere the former is solved by gradient descent and the latter is solved by\nsequential quadratic programming (SQP). Through these examples, the proposed\nframework is shown to be able to provide structural engineers with a more\nefficient tool for shape optimization, enabling better design for the built\nenvironment.",
    "descriptor": "",
    "authors": [
      "Gaoyuan Wu"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15409"
  },
  {
    "id": "arXiv:2211.15410",
    "title": "Private Multi-Winner Voting for Machine Learning",
    "abstract": "Private multi-winner voting is the task of revealing $k$-hot binary vectors\nsatisfying a bounded differential privacy (DP) guarantee. This task has been\nunderstudied in machine learning literature despite its prevalence in many\ndomains such as healthcare. We propose three new DP multi-winner mechanisms:\nBinary, $\\tau$, and Powerset voting. Binary voting operates independently per\nlabel through composition. $\\tau$ voting bounds votes optimally in their\n$\\ell_2$ norm for tight data-independent guarantees. Powerset voting operates\nover the entire binary vector by viewing the possible outcomes as a power set.\nOur theoretical and empirical analysis shows that Binary voting can be a\ncompetitive mechanism on many tasks unless there are strong correlations\nbetween labels, in which case Powerset voting outperforms it. We use our\nmechanisms to enable privacy-preserving multi-label learning in the central\nsetting by extending the canonical single-label technique: PATE. We find that\nour techniques outperform current state-of-the-art approaches on large,\nreal-world healthcare data and standard multi-label benchmarks. We further\nenable multi-label confidential and private collaborative (CaPC) learning and\nshow that model performance can be significantly improved in the multi-site\nsetting.",
    "descriptor": "\nComments: Accepted at PoPETS 2023\n",
    "authors": [
      "Adam Dziedzic",
      "Christopher A Choquette-Choo",
      "Natalie Dullerud",
      "Vinith Menon Suriyakumar",
      "Ali Shahin Shamsabadi",
      "Muhammad Ahmad Kaleem",
      "Somesh Jha",
      "Nicolas Papernot",
      "Xiao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15410"
  },
  {
    "id": "arXiv:2211.15411",
    "title": "Single-agent to Multi-agent in Deep Reinforcement-learning",
    "abstract": "OW QMIX, CW QMIX, QTRAN, QMIX, and VDN are the state-of-the-art algorithms\nfor solving Dec-POMDP domains. OW QMIX, CW QMIX, QTRAN, QMIX, and VDN failed to\nsolve complex agents' cooperation domains such as box-pushing. We give a\n2-stage algorithm to solve such problems. On 1st stage we solve single-agent\nproblem (POMDP) and get an optimal policy traces. On 2nd stage we solve\nmulti-agent problem (Dec-POMDP) with the single-agent optimal policy traces.\nSingle-agent to multi-agent has a clear advantage over OW QMIX, CW QMIX, QTRAN,\nQMIX, and VDN on complex agents' cooperative domains.",
    "descriptor": "",
    "authors": [
      "Nitsan Soffair"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.15411"
  },
  {
    "id": "arXiv:2211.15413",
    "title": "Towards Developing Safety Assurance Cases for Learning-Enabled Medical  Cyber-Physical Systems",
    "abstract": "Machine Learning (ML) technologies have been increasingly adopted in Medical\nCyber-Physical Systems (MCPS) to enable smart healthcare. Assuring the safety\nand effectiveness of learning-enabled MCPS is challenging, as such systems must\naccount for diverse patient profiles and physiological dynamics and handle\noperational uncertainties. In this paper, we develop a safety assurance case\nfor ML controllers in learning-enabled MCPS, with an emphasis on establishing\nconfidence in the ML-based predictions. We present the safety assurance case in\ndetail for Artificial Pancreas Systems (APS) as a representative application of\nlearning-enabled MCPS, and provide a detailed analysis by implementing a deep\nneural network for the prediction in APS. We check the sufficiency of the ML\ndata and analyze the correctness of the ML-based prediction using formal\nverification. Finally, we outline open research problems based on our\nexperience in this paper.",
    "descriptor": "",
    "authors": [
      "Maryam Bagheri",
      "Josephine Lamp",
      "Xugui Zhou",
      "Lu Feng",
      "Homa Alemzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15413"
  },
  {
    "id": "arXiv:2211.15414",
    "title": "Dynamic Collaborative Multi-Agent Reinforcement Learning Communication  for Autonomous Drone Reforestation",
    "abstract": "We approach autonomous drone-based reforestation with a collaborative\nmulti-agent reinforcement learning (MARL) setup. Agents can communicate as part\nof a dynamically changing network. We explore collaboration and communication\non the back of a high-impact problem. Forests are the main resource to control\nrising CO2 conditions. Unfortunately, the global forest volume is decreasing at\nan unprecedented rate. Many areas are too large and hard to traverse to plant\nnew trees. To efficiently cover as much area as possible, here we propose a\nGraph Neural Network (GNN) based communication mechanism that enables\ncollaboration. Agents can share location information on areas needing\nreforestation, which increases viewed area and planted tree count. We compare\nour proposed communication mechanism with a multi-agent baseline without the\nability to communicate. Results show how communication enables collaboration\nand increases collective performance, planting precision and the risk-taking\npropensity of individual agents.",
    "descriptor": "\nComments: Deep Reinforcement Learning Workshop at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Philipp Dominic Siedler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15414"
  },
  {
    "id": "arXiv:2211.15416",
    "title": "Development of a Neural Network-Based Mathematical Operation Protocol  for Embedded Hexadecimal Digits Using Neural Architecture Search (NAS)",
    "abstract": "It is beneficial to develop an efficient machine-learning based method for\naddition using embedded hexadecimal digits. Through a comparison between\nhuman-developed machine learning model and models sampled through Neural\nArchitecture Search (NAS) we determine an efficient approach to solve this\nproblem with a final testing loss of 0.2937 for a human-developed model.",
    "descriptor": "",
    "authors": [
      "Victor Robila",
      "Kexin Pei",
      "Junfeng Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15416"
  },
  {
    "id": "arXiv:2211.15417",
    "title": "Proof-of-randomness protocol for blockchain consensus: the white paper  version 1.0",
    "abstract": "A proof-of-randomness (PoR) protocol could be a fair and low energy-cost\nconsensus mechanism for blockchains. Each network node of a blockchain could\nuse a true random number generator (TRNG) and hash algorism to fulfil the PoR\nprotocol. In this whitepaper, we give the consensus mechanism of the PoR\nprotocol, and show how it could make the random numbers unforgeable. The PoR\nprotocol could generate a blockchain without any competition of computing power\nor stake of cryptocurrency. Besides, we give some advantages of integrating\nquantum random number generator (QRNG) chips in hardware wallets, and also\ndiscuss the route to cooperate with quantum key distribution (QKD) technology.",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Wen-Zhuo Zhang",
      "Victor Kai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.15417"
  },
  {
    "id": "arXiv:2211.15421",
    "title": "A Benchmark for Structured Extractions from Complex Documents",
    "abstract": "Understanding visually-rich business documents to extract structured data and\nautomate business workflows has been receiving attention both in academia and\nindustry. Although recent multi-modal language models have achieved impressive\nresults, we find that existing benchmarks do not reflect the complexity of real\ndocuments seen in industry. In this work, we identify the desiderata for a more\ncomprehensive benchmark and propose one we call Visually Rich Document\nUnderstanding (VRDU). VRDU contains two datasets that represent several\nchallenges: rich schema including diverse data types as well as nested\nentities, complex templates including tables and multi-column layouts, and\ndiversity of different layouts (templates) within a single document type. We\ndesign few-shot and conventional experiment settings along with a carefully\ndesigned matching algorithm to evaluate extraction results. We report the\nperformance of strong baselines and three observations: (1) generalizing to new\ndocument templates is very challenging, (2) few-shot performance has a lot of\nheadroom, and (3) models struggle with nested fields such as line-items in an\ninvoice. We plan to open source the benchmark and the evaluation toolkit. We\nhope this helps the community make progress on these challenging tasks in\nextracting structured data from visually rich documents.",
    "descriptor": "",
    "authors": [
      "Zilong Wang",
      "Yichao Zhou",
      "Wei Wei",
      "Chen-Yu Lee",
      "Sandeep Tata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15421"
  },
  {
    "id": "arXiv:2211.15424",
    "title": "DeepParliament: A Legal domain Benchmark & Dataset for Parliament Bills  Prediction",
    "abstract": "This paper introduces DeepParliament, a legal domain Benchmark Dataset that\ngathers bill documents and metadata and performs various bill status\nclassification tasks. The proposed dataset text covers a broad range of bills\nfrom 1986 to the present and contains richer information on parliament bill\ncontent. Data collection, detailed statistics and analyses are provided in the\npaper. Moreover, we experimented with different types of models ranging from\nRNN to pretrained and reported the results. We are proposing two new\nbenchmarks: Binary and Multi-Class Bill Status classification. Models developed\nfor bill documents and relevant supportive tasks may assist Members of\nParliament (MPs), presidents, and other legal practitioners. It will help\nreview or prioritise bills, thus speeding up the billing process, improving the\nquality of decisions and reducing the time consumption in both houses.\nConsidering that the foundation of the country's democracy is Parliament and\nstate legislatures, we anticipate that our research will be an essential\naddition to the Legal NLP community. This work will be the first to present a\nParliament bill prediction task. In order to improve the accessibility of legal\nAI resources and promote reproducibility, we have made our code and dataset\npublicly accessible at github.com/monk1337/DeepParliament",
    "descriptor": "\nComments: Accepted at EMNLP 2022 (UM-IoS)\n",
    "authors": [
      "Ankit Pal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15424"
  },
  {
    "id": "arXiv:2211.15425",
    "title": "FAF: A novel multimodal emotion recognition approach integrating face,  body and text",
    "abstract": "Multimodal emotion analysis performed better in emotion recognition depending\non more comprehensive emotional clues and multimodal emotion dataset. In this\npaper, we developed a large multimodal emotion dataset, named \"HED\" dataset, to\nfacilitate the emotion recognition task, and accordingly propose a multimodal\nemotion recognition method. To promote recognition accuracy, \"Feature After\nFeature\" framework was used to explore crucial emotional information from the\naligned face, body and text samples. We employ various benchmarks to evaluate\nthe \"HED\" dataset and compare the performance with our method. The results show\nthat the five classification accuracy of the proposed multimodal fusion method\nis about 83.75%, and the performance is improved by 1.83%, 9.38%, and 21.62%\nrespectively compared with that of individual modalities. The complementarity\nbetween each channel is effectively used to improve the performance of emotion\nrecognition. We had also established a multimodal online emotion prediction\nplatform, aiming to provide free emotion prediction to more users.",
    "descriptor": "",
    "authors": [
      "Zhongyu Fang",
      "Aoyun He",
      "Qihui Yu",
      "Baopeng Gao",
      "Weiping Ding",
      "Tong Zhang",
      "Lei Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15425"
  },
  {
    "id": "arXiv:2211.15426",
    "title": "Analysis on English Vocabulary Appearance Pattern in Korean CSAT",
    "abstract": "A text-mining-based word class categorization method and LSTM-based\nvocabulary pattern prediction method are introduced in this paper. A\npreprocessing method based on simple text appearance frequency analysis is\nfirst described. This method was developed as a data screening tool but showed\n4.35 ~ 6.21 times higher than previous works. An LSTM deep learning method is\nalso suggested for vocabulary appearance pattern prediction method. AI performs\na regression with various size of data window of previous exams to predict the\nprobabilities of word appearance in the next exam. Predicted values of AI over\nvarious data windows are processed into a single score as a weighted sum, which\nwe call an \"AI-Score\", which represents the probability of word appearance in\nnext year's exam. Suggested method showed 100% accuracy at the range 100-score\narea and showed only 1.7% error of prediction in the section where the scores\nwere over 60 points. All source codes are freely available at the authors' Git\nHub repository. (https://github.com/needleworm/bigdata_voca)",
    "descriptor": "\nComments: update additional experiment result\n",
    "authors": [
      "Byunghyun Ban",
      "Jejong Lee",
      "Hyeonmok Hwang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15426"
  },
  {
    "id": "arXiv:2211.15428",
    "title": "Explanation on Pretraining Bias of Finetuned Vision Transformer",
    "abstract": "As the number of fine tuning of pretrained models increased, understanding\nthe bias of pretrained model is essential. However, there is little tool to\nanalyse transformer architecture and the interpretation of the attention maps\nis still challenging. To tackle the interpretability, we propose\nInput-Attribution and Attention Score Vector (IAV) which measures the\nsimilarity between attention map and input-attribution and shows the general\ntrend of interpretable attention patterns. We empirically explain the\npretraining bias of supervised and unsupervised pretrained ViT models, and show\nthat each head in ViT has a specific range of agreement on the decision of the\nclassification. We show that generalization, robustness and entropy of\nattention maps are not property of pretraining types. On the other hand, IAV\ntrend can separate the pretraining types.",
    "descriptor": "",
    "authors": [
      "Bumjin Park",
      "Jaesik Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15428"
  },
  {
    "id": "arXiv:2211.15429",
    "title": "Detecting Methane Plumes using PRISMA: Deep Learning Model and Data  Augmentation",
    "abstract": "The new generation of hyperspectral imagers, such as PRISMA, has improved\nsignificantly our detection capability of methane (CH4) plumes from space at\nhigh spatial resolution (30m). We present here a complete framework to identify\nCH4 plumes using images from the PRISMA satellite mission and a deep learning\nmodel able to detect plumes over large areas. To compensate for the relative\nscarcity of PRISMA images, we trained our model by transposing high resolution\nplumes from Sentinel-2 to PRISMA. Our methodology thus avoids computationally\nexpensive synthetic plume generation from Large Eddy Simulations by generating\na broad and realistic training database, and paves the way for large-scale\ndetection of methane plumes using future hyperspectral sensors (EnMAP, EMIT,\nCarbonMapper).",
    "descriptor": "",
    "authors": [
      "Alexis Groshenry",
      "Clement Giron",
      "Thomas Lauvaux",
      "Alexandre d'Aspremont",
      "Thibaud Ehret"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15429"
  },
  {
    "id": "arXiv:2211.15432",
    "title": "E2E Segmentation in a Two-Pass Cascaded Encoder ASR Model",
    "abstract": "We explore unifying a neural segmenter with two-pass cascaded encoder ASR\ninto a single model. A key challenge is allowing the segmenter (which runs in\nreal-time, synchronously with the decoder) to finalize the 2nd pass (which runs\n900 ms behind real-time) without introducing user-perceived latency or deletion\nerrors during inference. We propose a design where the neural segmenter is\nintegrated with the causal 1st pass decoder to emit a end-of-segment (EOS)\nsignal in real-time. The EOS signal is then used to finalize the non-causal 2nd\npass. We experiment with different ways to finalize the 2nd pass, and find that\na novel dummy frame injection strategy allows for simultaneous high quality 2nd\npass results and low finalization latency. On a real-world long-form captioning\ntask (YouTube), we achieve 2.4% relative WER and 140 ms EOS latency gains over\na baseline VAD-based segmenter with the same cascaded encoder.",
    "descriptor": "",
    "authors": [
      "W. Ronny Huang",
      "Shuo-Yiin Chang",
      "Tara N. Sainath",
      "Yanzhang He",
      "David Rybach",
      "Robert David",
      "Rohit Prabhavalkar",
      "Cyril Allauzen",
      "Cal Peyser",
      "Trevor D. Strohman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15432"
  },
  {
    "id": "arXiv:2211.15435",
    "title": "Hyperspectral Demosaicing of Snapshot Camera Images Using Deep Learning",
    "abstract": "Spectral imaging technologies have rapidly evolved during the past decades.\nThe recent development of single-camera-one-shot techniques for hyperspectral\nimaging allows multiple spectral bands to be captured simultaneously (3x3, 4x4\nor 5x5 mosaic), opening up a wide range of applications. Examples include\nintraoperative imaging, agricultural field inspection and food quality\nassessment. To capture images across a wide spectrum range, i.e. to achieve\nhigh spectral resolution, the sensor design sacrifices spatial resolution. With\nincreasing mosaic size, this effect becomes increasingly detrimental.\nFurthermore, demosaicing is challenging. Without incorporating edge, shape, and\nobject information during interpolation, chromatic artifacts are likely to\nappear in the obtained images. Recent approaches use neural networks for\ndemosaicing, enabling direct information extraction from image data. However,\nobtaining training data for these approaches poses a challenge as well. This\nwork proposes a parallel neural network based demosaicing procedure trained on\na new ground truth dataset captured in a controlled environment by a\nhyperspectral snapshot camera with a 4x4 mosaic pattern. The dataset is a\ncombination of real captured scenes with images from publicly available data\nadapted to the 4x4 mosaic pattern. To obtain real world ground-truth data, we\nperformed multiple camera captures with 1-pixel shifts in order to compose the\nentire data cube. Experiments show that the proposed network outperforms\nstate-of-art networks.",
    "descriptor": "\nComments: German Conference on Pattern Recognition (GCPR) 2022\n",
    "authors": [
      "Eric L. Wisotzky",
      "Charul Daudkhane",
      "Anna Hilsmann",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.15435"
  },
  {
    "id": "arXiv:2211.15436",
    "title": "Context-Adaptive Deep Neural Networks via Bridge-Mode Connectivity",
    "abstract": "The deployment of machine learning models in safety-critical applications\ncomes with the expectation that such models will perform well over a range of\ncontexts (e.g., a vision model for classifying street signs should work in\nrural, city, and highway settings under varying lighting/weather conditions).\nHowever, these one-size-fits-all models are typically optimized for average\ncase performance, encouraging them to achieve high performance in nominal\nconditions but exposing them to unexpected behavior in challenging or rare\ncontexts. To address this concern, we develop a new method for training\ncontext-dependent models. We extend Bridge-Mode Connectivity (BMC) (Garipov et\nal., 2018) to train an infinite ensemble of models over a continuous measure of\ncontext such that we can sample model parameters specifically tuned to the\ncorresponding evaluation context. We explore the definition of context in image\nclassification tasks through multiple lenses including changes in the risk\nprofile, long-tail image statistics/appearance, and context-dependent\ndistribution shift. We develop novel extensions of the BMC optimization for\neach of these cases and our experiments demonstrate that model performance can\nbe successfully tuned to context in each scenario.",
    "descriptor": "\nComments: Accepted to the NeurIPS 2022 ML Safety Workshop\n",
    "authors": [
      "Nathan Drenkow",
      "Alvin Tan",
      "Chace Ashcraft",
      "Kiran Karra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15436"
  },
  {
    "id": "arXiv:2211.15437",
    "title": "Analytic Estimation of Region of Attraction of an LQR Controller for  Torque Limited Simple Pendulum",
    "abstract": "Linear-quadratic regulators (LQR) are a well known and widely used tool in\ncontrol theory for both linear and nonlinear dynamics. For nonlinear problems,\nan LQR-based controller is usually only locally viable, thus, raising the\nproblem of estimating the region of attraction (ROA). The need for good ROA\nestimations becomes especially pressing for underactuated systems, as a failure\nof controls might lead to unsafe and unrecoverable system states. Known\napproaches based on optimization or sampling, while working well, might be too\nslow in time critical applications and are hard to verify formally. In this\nwork, we propose a novel approach to estimate the ROA based on the analytic\nsolutions to linear ODEs for the torque limited simple pendulum. In simulation\nand physical experiments, we compared our approach to a Lyapunov-sampling\nbaseline approach and found that our approach was faster to compute, while\nyielding ROA estimations of similar phase space area.",
    "descriptor": "\nComments: 7 pages, 5 figures, 2 tables, to be published in proceedings of 61st IEEE Conference on Decision and Control (CDC)\n",
    "authors": [
      "Lukas Gross",
      "Lasse Maywald",
      "Shivesh Kumar",
      "Frank Kirchner",
      "Christoph L\u00fcth"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15437"
  },
  {
    "id": "arXiv:2211.15440",
    "title": "Near-Field Channel Estimation for Extremely Large-Scale Array  Communications: A model-based deep learning approach",
    "abstract": "Extremely large-scale massive MIMO (XL-MIMO) has been reviewed as a promising\ntechnology for future wireless communications. The deployment of XL-MIMO,\nespecially at high-frequency bands, leads to users being located in the\nnear-field region instead of the conventional far-field. This letter proposes\nefficient model-based deep learning algorithms for estimating the near-field\nwireless channel of XL-MIMO communications. In particular, we first formulate\nthe XL-MIMO near-field channel estimation task as a compressed sensing problem\nusing the spatial gridding-based sparsifying dictionary, and then solve the\nresulting problem by applying the Learning Iterative Shrinkage and Thresholding\nAlgorithm (LISTA). Due to the near-field characteristic, the spatial\ngridding-based sparsifying dictionary may result in low channel estimation\naccuracy and a heavy computational burden. To address this issue, we further\npropose a new sparsifying dictionary learning-LISTA (SDL-LISTA) algorithm that\nformulates the sparsifying dictionary as a neural network layer and embeds it\ninto LISTA neural network. The numerical results show that our proposed\nalgorithms outperform non-learning benchmark schemes, and SDL-LISTA achieves\nbetter performance than LISTA with ten times atoms reduction.",
    "descriptor": "\nComments: 4 pages, 5 figures\n",
    "authors": [
      "Xiangyu Zhang",
      "Zening Wang",
      "Haiyang Zhang",
      "Luxi Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.15440"
  },
  {
    "id": "arXiv:2211.15441",
    "title": "Graceful Forgetting II. Data as a Process",
    "abstract": "Data are rapidly growing in size and importance for society, a trend\nmotivated by their enabling power. The accumulation of new data, sustained by\nprogress in technology, leads to a boundless expansion of stored data, in some\ncases with an exponential increase in the accrual rate itself. Massive data are\nhard to process, transmit, store, and exploit, and it is particularly hard to\nkeep abreast of the data store as a whole. This paper distinguishes three\nphases in the life of data: acquisition, curation, and exploitation. Each\ninvolves a distinct process, that may be separated from the others in time,\nwith a different set of priorities. The function of the second phase, curation,\nis to maximize the future value of the data given limited storage. I argue that\nthis requires that (a) the data take the form of summary statistics and (b)\nthese statistics follow an endless process of rescaling. The summary may be\nmore compact than the original data, but its data structure is more complex and\nit requires an on-going computational process that is much more sophisticated\nthan mere storage. Rescaling results in dimensionality reduction that may be\nbeneficial for learning, but that must be carefully controlled to preserve\nrelevance. Rescaling may be tuned based on feedback from usage, with the\nproviso that our memory of the past serves the future, the needs of which are\nnot fully known.",
    "descriptor": "\nComments: 30 pages, 17 figures\n",
    "authors": [
      "Alain de Cheveign\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.15441"
  },
  {
    "id": "arXiv:2211.15443",
    "title": "Replacing Automatic Differentiation by Sobolev Cubatures fastens Physics  Informed Neural Nets and strengthens their Approximation Power",
    "abstract": "We present a novel class of approximations for variational losses, being\napplicable for the training of physics-informed neural nets (PINNs). The loss\nformulation reflects classic Sobolev space theory for partial differential\nequations and their weak formulations. The loss computation rests on an\nextension of Gauss-Legendre cubatures, we term Sobolev cubatures, replacing\nautomatic differentiation (A.D.). We prove the runtime complexity of training\nthe resulting Soblev-PINNs (SC-PINNs) to be less than required by PINNs relying\non A.D. On top of one-to-two order of magnitude speed-up the SC-PINNs are\ndemonstrated to achieve closer solution approximations for prominent forward\nand inverse PDE problems than established PINNs achieve.",
    "descriptor": "",
    "authors": [
      "Juan Esteban Suarez Cardona",
      "Michael Hecht"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15443"
  },
  {
    "id": "arXiv:2211.15444",
    "title": "DAMO-YOLO : A Report on Real-Time Object Detection Design",
    "abstract": "In this report, we present a fast and accurate object detection method dubbed\nDAMO-YOLO, which achieves higher performance than the state-of-the-art YOLO\nseries. DAMO-YOLO is extended from YOLO with some new technologies, including\nNeural Architecture Search (NAS), efficient Reparameterized Generalized-FPN\n(RepGFPN), a lightweight head with AlignedOTA label assignment, and\ndistillation enhancement. In particular, we use MAE-NAS, a method guided by the\nprinciple of maximum entropy, to search our detection backbone under the\nconstraints of low latency and high performance, producing ResNet-like /\nCSP-like structures with spatial pyramid pooling and focus modules. In the\ndesign of necks and heads, we follow the rule of \"large neck, small head\". We\nimport Generalized-FPN with accelerated queen-fusion to build the detector neck\nand upgrade its CSPNet with efficient layer aggregation networks (ELAN) and\nreparameterization. Then we investigate how detector head size affects\ndetection performance and find that a heavy neck with only one task projection\nlayer would yield better results. In addition, AlignedOTA is proposed to solve\nthe misalignment problem in label assignment. And a distillation schema is\nintroduced to improve performance to a higher level. Based on these new techs,\nwe build a suite of models at various scales to meet the needs of different\nscenarios, i.e., DAMO-YOLO-Tiny/Small/Medium. They can achieve 43.0/46.8/50.0\nmAPs on COCO with the latency of 2.78/3.83/5.62 ms on T4 GPUs respectively. The\ncode is available at https://github.com/tinyvision/damo-yolo.",
    "descriptor": "",
    "authors": [
      "Xianzhe Xu",
      "Yiqi Jiang",
      "Weihua Chen",
      "Yilun Huang",
      "Yuan Zhang",
      "Xiuyu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15444"
  },
  {
    "id": "arXiv:2211.15445",
    "title": "$\\texttt{davos}$: a Python \"smuggler\" for constructing lightweight  reproducible notebooks",
    "abstract": "Reproducibility is a core requirement of modern scientific research. For\ncomputational research, reproducibility means that code should produce the same\nresults, even when run on different systems. A standard approach to ensuring\nreproducibility entails packaging a project's dependencies along with its\nprimary code base. Existing solutions vary in how deeply these dependencies are\nspecified, ranging from virtual environments, to containers, to virtual\nmachines. Each of these existing solutions requires installing or setting up a\nsystem for running the desired code, increasing the complexity and time cost of\nsharing or engaging with reproducible science. Here, we propose a\nlighter-weight solution: the $\\texttt{davos}$ package. When used in combination\nwith a notebook-based Python project, $\\texttt{davos}$ provides a mechanism for\nspecifying (and automatically installing) the correct versions of the project's\ndependencies. The $\\texttt{davos}$ package further ensures that those packages\nand specific versions are used every time the notebook's code is executed. This\nenables researchers to share a complete reproducible copy of their code within\na single Jupyter notebook file.",
    "descriptor": "",
    "authors": [
      "Paxton C. Fitzpatrick",
      "Jeremy R. Manning"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2211.15445"
  },
  {
    "id": "arXiv:2211.15451",
    "title": "Discovering Unsupervised Behaviours from Full-State Trajectories",
    "abstract": "Improving open-ended learning capabilities is a promising approach to enable\nrobots to face the unbounded complexity of the real-world. Among existing\nmethods, the ability of Quality-Diversity algorithms to generate large\ncollections of diverse and high-performing skills is instrumental in this\ncontext. However, most of those algorithms rely on a hand-coded behavioural\ndescriptor to characterise the diversity, hence requiring prior knowledge about\nthe considered tasks. In this work, we propose an additional analysis of\nAutonomous Robots Realising their Abilities; a Quality-Diversity algorithm that\nautonomously finds behavioural characterisations. We evaluate this approach on\na simulated robotic environment, where the robot has to autonomously discover\nits abilities from its full-state trajectories. All algorithms were applied to\nthree tasks: navigation, moving forward with a high velocity, and performing\nhalf-rolls. The experimental results show that the algorithm under study\ndiscovers autonomously collections of solutions that are diverse with respect\nto all tasks. More specifically, the analysed approach autonomously finds\npolicies that make the robot move to diverse positions, but also utilise its\nlegs in diverse ways, and even perform half-rolls.",
    "descriptor": "\nComments: Published at the Workshop on Agent Learning in Open-Endedness (ALOE) at ICLR 2022. arXiv admin note: substantial text overlap with arXiv:2204.09828\n",
    "authors": [
      "Luca Grillotti",
      "Antoine Cully"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15451"
  },
  {
    "id": "arXiv:2211.15453",
    "title": "An Alphabet of Leakage Measures",
    "abstract": "We introduce a family of information leakage measures called maximal\n$\\alpha,\\beta$-leakage, parameterized by real numbers $\\alpha$ and $\\beta$. The\nmeasure is formalized via an operational definition involving an adversary\nguessing an unknown function of the data given the released data. We obtain a\nsimple, computable expression for the measure and show that it satisfies\nseveral basic properties such as monotonicity in $\\beta$ for a fixed $\\alpha$,\nnon-negativity, data processing inequalities, and additivity over independent\nreleases. Finally, we highlight the relevance of this family by showing that it\nbridges several known leakage measures, including maximal $\\alpha$-leakage\n$(\\beta=1)$, maximal leakage $(\\alpha=\\infty,\\beta=1)$, local differential\nprivacy $(\\alpha=\\infty,\\beta=\\infty)$, and local Renyi differential privacy\n$(\\alpha=\\beta)$.",
    "descriptor": "",
    "authors": [
      "Atefeh Gilani",
      "Gowtham R. Kurri",
      "Oliver Kosut",
      "Lalitha Sankar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15453"
  },
  {
    "id": "arXiv:2211.15457",
    "title": "Hypernetworks for Zero-shot Transfer in Reinforcement Learning",
    "abstract": "In this paper, hypernetworks are trained to generate behaviors across a range\nof unseen task conditions, via a novel TD-based training objective and data\nfrom a set of near-optimal RL solutions for training tasks. This work relates\nto meta RL, contextual RL, and transfer learning, with a particular focus on\nzero-shot performance at test time, enabled by knowledge of the task parameters\n(also known as context). Our technical approach is based upon viewing each RL\nalgorithm as a mapping from the MDP specifics to the near-optimal value\nfunction and policy and seek to approximate it with a hypernetwork that can\ngenerate near-optimal value functions and policies, given the parameters of the\nMDP. We show that, under certain conditions, this mapping can be considered as\na supervised learning problem. We empirically evaluate the effectiveness of our\nmethod for zero-shot transfer to new reward and transition dynamics on a series\nof continuous control tasks from DeepMind Control Suite. Our method\ndemonstrates significant improvements over baselines from multitask and meta RL\napproaches.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Sahand Rezaei-Shoshtari",
      "Charlotte Morissette",
      "Francois Robert Hogan",
      "Gregory Dudek",
      "David Meger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15457"
  },
  {
    "id": "arXiv:2211.15458",
    "title": "Validating Large Language Models with ReLM",
    "abstract": "Although large language models (LLMs) have been touted for their ability to\ngenerate natural-sounding text, there are growing concerns around possible\nnegative effects of LLMs such as data memorization, bias, and inappropriate\nlanguage. Unfortunately, the complexity and generation capacities of LLMs make\nvalidating (and correcting) such concerns difficult. In this work, we introduce\nReLM, a system for validating and querying LLMs using standard regular\nexpressions. ReLM formalizes and enables a broad range of language model\nevaluations, reducing complex evaluation rules to simple regular expression\nqueries. Our results exploring queries surrounding memorization, gender bias,\ntoxicity, and language understanding show that ReLM achieves up to 15x higher\nsystem efficiency, 2.5x data efficiency, and increased statistical and\nprompt-tuning coverage compared to state-of-the-art ad-hoc queries. ReLM offers\na competitive and general baseline for the increasingly important problem of\nLLM validation.",
    "descriptor": "",
    "authors": [
      "Michael Kuchnik",
      "Virginia Smith",
      "George Amvrosiadis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15458"
  },
  {
    "id": "arXiv:2211.15460",
    "title": "Fragment-History Volumes",
    "abstract": "Hardware-based triangle rasterization is still the prevalent method for\ngenerating images at real-time interactive frame rates. With the availability\nof a programmable graphics pipeline a large variety of techniques are supported\nfor evaluating lighting and material properties of fragments. However, these\ntechniques are usually restricted to evaluating local lighting and material\neffects. In addition, view-point changes require the complete processing of\nscene data to generate appropriate images. Reusing already rendered data in the\nframe buffer for a given view point by warping for a new viewpoint increases\nnavigation fidelity at the expense of introducing artifacts for fragments\npreviously hidden from the viewer.\nWe present fragment-history volumes (FHV), a rendering technique based on a\nsparse, discretized representation of a 3d scene that emerges from recording\nall fragments that pass the rasterization stage in the graphics pipeline. These\nfragments are stored into per-pixel or per-octant lists for further processing;\nessentially creating an A-buffer. FHVs using per-octant fragment lists are view\nindependent and allow fast resampling for image generation as well as for using\nmore sophisticated approaches to evaluate material and lighting properties,\neventually enabling global-illumination evaluation in the standard graphics\npipeline available on current hardware.\nWe show how FHVs are stored on the GPU in several ways, how they are created,\nand how they can be used for image generation at high rates. We discuss results\nfor different usage scenarios, variations of the technique, and some\nlimitations.",
    "descriptor": "",
    "authors": [
      "Francisco In\u00e1cio",
      "Jan P. Springer"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.15460"
  },
  {
    "id": "arXiv:2211.15462",
    "title": "Investigating Prompt Engineering in Diffusion Models",
    "abstract": "With the spread of the use of Text2Img diffusion models such as DALL-E 2,\nImagen, Mid Journey and Stable Diffusion, one challenge that artists face is\nselecting the right prompts to achieve the desired artistic output. We present\ntechniques for measuring the effect that specific words and phrases in prompts\nhave, and (in the Appendix) present guidance on the selection of prompts to\nproduce desired effects.",
    "descriptor": "\nComments: Paper submitted for Creativity and Design workshop at NeurIPS 2022. (4 pages including references + 7 page appendix). We would like to thank Google and the ML Developer Programs Team for their assistance and compute credits used in the experiments for this paper\n",
    "authors": [
      "Sam Witteveen",
      "Martin Andrews"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15462"
  },
  {
    "id": "arXiv:2211.15464",
    "title": "Considerations for meaningful sign language machine translation based on  glosses",
    "abstract": "Automatic sign language processing is gaining popularity in Natural Language\nProcessing (NLP) research (Yin et al., 2021). In machine translation (MT) in\nparticular, sign language translation based on glosses is a prominent approach.\nIn this paper, we review recent works on neural gloss translation. We find that\nlimitations of glosses in general and limitations of specific datasets are not\ndiscussed in a transparent manner and that there is no common standard for\nevaluation.\nTo address these issues, we put forward concrete recommendations for future\nresearch on gloss translation. Our suggestions advocate awareness of the\ninherent limitations of gloss-based approaches, realistic datasets, stronger\nbaselines and convincing evaluation.",
    "descriptor": "",
    "authors": [
      "Mathias M\u00fcller",
      "Zifan Jiang",
      "Amit Moryossef",
      "Annette Rios",
      "Sarah Ebling"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15464"
  },
  {
    "id": "arXiv:2211.15467",
    "title": "Progressively Dual Prior Guided Few-shot Semantic Segmentation",
    "abstract": "Few-shot semantic segmentation task aims at performing segmentation in query\nimages with a few annotated support samples. Currently, few-shot segmentation\nmethods mainly focus on leveraging foreground information without fully\nutilizing the rich background information, which could result in wrong\nactivation of foreground-like background regions with the inadaptability to\ndramatic scene changes of support-query image pairs. Meanwhile, the lack of\ndetail mining mechanism could cause coarse parsing results without some\nsemantic components or edge areas since prototypes have limited ability to cope\nwith large object appearance variance. To tackle these problems, we propose a\nprogressively dual prior guided few-shot semantic segmentation network.\nSpecifically, a dual prior mask generation (DPMG) module is firstly designed to\nsuppress the wrong activation in foreground-background comparison manner by\nregarding background as assisted refinement information. With dual prior masks\nrefining the location of foreground area, we further propose a progressive\nsemantic detail enrichment (PSDE) module which forces the parsing model to\ncapture the hidden semantic details by iteratively erasing the high-confidence\nforeground region and activating details in the rest region with a hierarchical\nstructure. The collaboration of DPMG and PSDE formulates a novel few-shot\nsegmentation network that can be learned in an end-to-end manner. Comprehensive\nexperiments on PASCAL-5i and MS COCO powerfully demonstrate that our proposed\nalgorithm achieves the great performance.",
    "descriptor": "",
    "authors": [
      "Qinglong Cao",
      "Yuntian Chen",
      "Xiwen Yao",
      "Junwei Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15467"
  },
  {
    "id": "arXiv:2211.15470",
    "title": "Learning to Learn: How to Continuously Teach Humans and Machines",
    "abstract": "Our education system comprises a series of curricula. For example, when we\nlearn mathematics at school, we learn in order from addition, to\nmultiplication, and later to integration. Delineating a curriculum for teaching\neither a human or a machine shares the underlying goal of maximizing the\npositive knowledge transfer from early to later tasks and minimizing forgetting\nof the early tasks. Here, we exhaustively surveyed the effect of curricula on\nexisting continual learning algorithms in the class-incremental setting, where\nalgorithms must learn classes one at a time from a continuous stream of data.\nWe observed that across a breadth of possible class orders (curricula),\ncurricula influence the retention of information and that this effect is not\njust a product of stochasticity. Further, as a primary effort toward automated\ncurriculum design, we proposed a method capable of designing and ranking\neffective curricula based on inter-class feature similarities. We compared the\npredicted curricula against empirically determined effectual curricula and\nobserved significant overlaps between the two. To support the study of a\ncurriculum designer, we conducted a series of human psychophysics experiments\nand contributed a new Continual Learning benchmark in object recognition. We\nassessed the degree of agreement in effective curricula between humans and\nmachines. Surprisingly, our curriculum designer successfully predicts an\noptimal set of curricula that is effective for human learning. There are many\nconsiderations in curriculum design, such as timely student feedback and\nlearning with multiple modalities. Our study is the first attempt to set a\nstandard framework for the community to tackle the problem of teaching humans\nand machines to learn to learn continuously.",
    "descriptor": "",
    "authors": [
      "Parantak Singh",
      "You Li",
      "Ankur Sikarwar",
      "Weixian Lei",
      "Daniel Gao",
      "Morgan Bruce Talbot",
      "Ying Sun",
      "Mike Zheng Shou",
      "Gabriel Kreiman",
      "Mengmi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15470"
  },
  {
    "id": "arXiv:2211.15472",
    "title": "Toward a Flexible Metadata Pipeline for Fish Specimen Images",
    "abstract": "Flexible metadata pipelines are crucial for supporting the FAIR data\nprinciples. Despite this need, researchers seldom report their approaches for\nidentifying metadata standards and protocols that support optimal flexibility.\nThis paper reports on an initiative targeting the development of a flexible\nmetadata pipeline for a collection containing over 300,000 digital fish\nspecimen images, harvested from multiple data repositories and fish\ncollections. The images and their associated metadata are being used for\nAI-related scientific research involving automated species identification,\nsegmentation and trait extraction. The paper provides contextual background,\nfollowed by the presentation of a four-phased approach involving: 1. Assessment\nof the Problem, 2. Investigation of Solutions, 3. Implementation, and 4.\nRefinement. The work is part of the NSF Harnessing the Data Revolution, Biology\nGuided Neural Networks (NSF/HDR-BGNN) project and the HDR Imageomics Institute.\nAn RDF graph prototype pipeline is presented, followed by a discussion of\nresearch implications and conclusion summarizing the results.",
    "descriptor": "\nComments: 12 pages. 5 figures. Presented at the 16th International Conference on Metadata and Semantics Research. To be published in the conference proceedings of Metadata and Semantic Research: 16th International Conference, MTSR 2022, London, United Kingdom, November 8-10, 2022\n",
    "authors": [
      "Dom Jebbia",
      "Xiaojun Wang",
      "Yasin Bakis",
      "Henry L. Bart Jr.",
      "Jane Greenberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Other Quantitative Biology (q-bio.OT)"
    ],
    "url": "https://arxiv.org/abs/2211.15472"
  },
  {
    "id": "arXiv:2211.15474",
    "title": "Unsupervised Superpixel Generation using Edge-Sparse Embedding",
    "abstract": "Partitioning an image into superpixels based on the similarity of pixels with\nrespect to features such as colour or spatial location can significantly reduce\ndata complexity and improve subsequent image processing tasks. Initial\nalgorithms for unsupervised superpixel generation solely relied on local cues\nwithout prioritizing significant edges over arbitrary ones. On the other hand,\nmore recent methods based on unsupervised deep learning either fail to properly\naddress the trade-off between superpixel edge adherence and compactness or lack\ncontrol over the generated number of superpixels. By using random images with\nstrong spatial correlation as input, \\ie, blurred noise images, in a\nnon-convolutional image decoder we can reduce the expected number of contrasts\nand enforce smooth, connected edges in the reconstructed image. We generate\nedge-sparse pixel embeddings by encoding additional spatial information into\nthe piece-wise smooth activation maps from the decoder's last hidden layer and\nuse a standard clustering algorithm to extract high quality superpixels. Our\nproposed method reaches state-of-the-art performance on the BSDS500,\nPASCAL-Context and a microscopy dataset.",
    "descriptor": "",
    "authors": [
      "Jakob Geusen",
      "Gustav Bredell",
      "Tianfei Zhou",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15474"
  },
  {
    "id": "arXiv:2211.15475",
    "title": "Introduction and Exemplars of Uncertainty Decomposition",
    "abstract": "Uncertainty plays a crucial role in the machine learning field. Both model\ntrustworthiness and performance require the understanding of uncertainty,\nespecially for models used in high-stake applications where errors can cause\ncataclysmic consequences, such as medical diagnosis and autonomous driving.\nAccordingly, uncertainty decomposition and quantification have attracted more\nand more attention in recent years. This short report aims to demystify the\nnotion of uncertainty decomposition through an introduction to two types of\nuncertainty and several decomposition exemplars, including maximum likelihood\nestimation, Gaussian processes, deep neural network, and ensemble learning. In\nthe end, cross connections to other topics in this seminar and two conclusions\nare provided.",
    "descriptor": "",
    "authors": [
      "Shuo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15475"
  },
  {
    "id": "arXiv:2211.15478",
    "title": "EVNet: An Explainable Deep Network for Dimension Reduction",
    "abstract": "Dimension reduction (DR) is commonly utilized to capture the intrinsic\nstructure and transform high-dimensional data into low-dimensional space while\nretaining meaningful properties of the original data. It is used in various\napplications, such as image recognition, single-cell sequencing analysis, and\nbiomarker discovery. However, contemporary parametric-free and parametric DR\ntechniques suffer from several significant shortcomings, such as the inability\nto preserve global and local features and the pool generalization performance.\nOn the other hand, regarding explainability, it is crucial to comprehend the\nembedding process, especially the contribution of each part to the embedding\nprocess, while understanding how each feature affects the embedding results\nthat identify critical components and help diagnose the embedding process. To\naddress these problems, we have developed a deep neural network method called\nEVNet, which provides not only excellent performance in structural\nmaintainability but also explainability to the DR therein. EVNet starts with\ndata augmentation and a manifold-based loss function to improve embedding\nperformance. The explanation is based on saliency maps and aims to examine the\ntrained EVNet parameters and contributions of components during the embedding\nprocess. The proposed techniques are integrated with a visual interface to help\nthe user to adjust EVNet to achieve better DR performance and explainability.\nThe interactive visual interface makes it easier to illustrate the data\nfeatures, compare different DR techniques, and investigate DR. An in-depth\nexperimental comparison shows that EVNet consistently outperforms the\nstate-of-the-art methods in both performance measures and explainability.",
    "descriptor": "\nComments: 18 pages, 15 figures, accepted by TVCG\n",
    "authors": [
      "Zelin Zang",
      "Shenghui Cheng",
      "Linyan Lu",
      "Hanchen Xia",
      "Liangyu Li",
      "Yaoting Sun",
      "Yongjie Xu",
      "Lei Shang",
      "Baigui Sun",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15478"
  },
  {
    "id": "arXiv:2211.15479",
    "title": "Object Detection in Aerial Imagery",
    "abstract": "Object detection in natural images has achieved remarkable results over the\nyears. However, a similar progress has not yet been observed in aerial object\ndetection due to several challenges, such as high resolution images, instances\nscale variation, class imbalance etc. We show the performance of two-stage,\none-stage and attention based object detectors on the iSAID dataset.\nFurthermore, we describe some modifications and analysis performed for\ndifferent models - a) In two stage detector: introduced weighted attention\nbased FPN, class balanced sampler and density prediction head. b) In one stage\ndetector: used weighted focal loss and introduced FPN. c) In attention based\ndetector: compare single,multi-scale attention and demonstrate effect of\ndifferent backbones. Finally, we show a comparative study highlighting the pros\nand cons of different models in aerial imagery setting.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Dmitry Demidov",
      "Rushali Grandhe",
      "Salem AlMarri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15479"
  },
  {
    "id": "arXiv:2211.15480",
    "title": "Underground Diagnosis Based on GPR and Learning in the Model Space",
    "abstract": "Ground Penetrating Radar (GPR) has been widely used in pipeline detection and\nunderground diagnosis. In practical applications, the characteristics of the\nGPR data of the detected area and the likely underground anomalous structures\ncould be rarely acknowledged before fully analyzing the obtained GPR data,\ncausing challenges to identify the underground structures or abnormals\nautomatically. In this paper, a GPR B-scan image diagnosis method based on\nlearning in the model space is proposed. The idea of learning in the model\nspace is to use models fitted on parts of data as more stable and parsimonious\nrepresentations of the data. For the GPR image, 2-Direction Echo State Network\n(2D-ESN) is proposed to fit the image segments through the next item\nprediction. By building the connections between the points on the image in both\nthe horizontal and vertical directions, the 2D-ESN regards the GPR image\nsegment as a whole and could effectively capture the dynamic characteristics of\nthe GPR image. And then, semi-supervised and supervised learning methods could\nbe further implemented on the 2D-ESN models for underground diagnosis.\nExperiments on real-world datasets are conducted, and the results demonstrate\nthe effectiveness of the proposed model.",
    "descriptor": "",
    "authors": [
      "Ao Chen",
      "Xiren Zhou",
      "Yizhan Fan",
      "Huanhuan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15480"
  },
  {
    "id": "arXiv:2211.15481",
    "title": "LSA-T: The first continuous Argentinian Sign Language dataset for Sign  Language Translation",
    "abstract": "Sign language translation (SLT) is an active field of study that encompasses\nhuman-computer interaction, computer vision, natural language processing and\nmachine learning. Progress on this field could lead to higher levels of\nintegration of deaf people. This paper presents, to the best of our knowledge,\nthe first continuous Argentinian Sign Language (LSA) dataset. It contains\n14,880 sentence level videos of LSA extracted from the CN Sordos YouTube\nchannel with labels and keypoints annotations for each signer. We also present\na method for inferring the active signer, a detailed analysis of the\ncharacteristics of the dataset, a visualization tool to explore the dataset and\na neural SLT model to serve as baseline for future experiments.",
    "descriptor": "\nComments: Accepted at IBERAMIA 2022. Dataset download info at this https URL\n",
    "authors": [
      "Pedro Dal Bianco",
      "Gast\u00f3n R\u00edos",
      "Franco Ronchetti",
      "Facundo Quiroga",
      "Oscar Stanchi",
      "Waldo Hasperu\u00e9",
      "Alejandro Rosete"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15481"
  },
  {
    "id": "arXiv:2211.15482",
    "title": "Discovering Dynamic Patterns from Spatiotemporal Data with Time-Varying  Low-Rank Autoregression",
    "abstract": "The problem of broad practical interest in spatiotemporal data analysis,\ni.e., discovering interpretable dynamic patterns from spatiotemporal data, is\nstudied in this paper. Towards this end, we develop a time-varying reduced-rank\nvector autoregression (VAR) model whose coefficient matrices are parameterized\nby low-rank tensor factorization. Benefiting from the tensor factorization\nstructure, the proposed model can simultaneously achieve model compression and\npattern discovery. In particular, the proposed model allows one to characterize\nnonstationarity and time-varying system behaviors underlying spatiotemporal\ndata. To evaluate the proposed model, extensive experiments are conducted on\nvarious spatiotemporal data representing different nonlinear dynamical systems,\nincluding fluid dynamics, sea surface temperature, USA surface temperature, and\nNYC taxi trips. Experimental results demonstrate the effectiveness of modeling\nspatiotemporal data and characterizing spatial/temporal patterns with the\nproposed model. In the spatial context, the spatial patterns can be\nautomatically extracted and intuitively characterized by the spatial modes. In\nthe temporal context, the complex time-varying system behaviors can be revealed\nby the temporal modes in the proposed model. Thus, our model lays an insightful\nfoundation for understanding complex spatiotemporal data in real-world\ndynamical systems. The adapted datasets and Python implementation are publicly\navailable at https://github.com/xinychen/vars.",
    "descriptor": "",
    "authors": [
      "Xinyu Chen",
      "Chengyuan Zhang",
      "Xiaoxu Chen",
      "Nicolas Saunier",
      "Lijun Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.15482"
  },
  {
    "id": "arXiv:2211.15485",
    "title": "Cell Biomechanical Modeling Based on Membrane Theory with Considering  Speed Effect of Microinjection",
    "abstract": "As an effective method to deliver external materials into biological cells,\nmicroinjection has been widely applied in the biomedical field. However, the\ncognition of cell mechanical property is still inadequate, which greatly limits\nthe efficiency and success rate of injection. Thus, a new rate-dependent\nmechanical model based on membrane theory is proposed for the first time. In\nthis model, an analytical equilibrium equation between the injection force and\ncell deformation is established by considering the speed effect of\nmicroinjection. Different from the traditional membrane-theory-based model, the\nelastic coefficient of the constitutive material in the proposed model is\nmodified as a function of the injection velocity and acceleration, effectively\nsimulating the influence of speeds on the mechanical responses and providing a\nmore generalized and practical model. Using this model, other mechanical\nresponses at different speeds can be also accurately predicted, including the\ndistribution of membrane tension and stress and the deformed shape. To verify\nthe validity of the model, numerical simulations and experiments are carried\nout. The results show that the proposed model can match the real mechanical\nresponses well at different injection speeds.",
    "descriptor": "\nComments: 10 pages, 12 figures, submitted to IEEE TMech;\n",
    "authors": [
      "Shengzheng Kang",
      "Zhicheng Song",
      "Xiaolong Yang",
      "Yao Li",
      "Hongtao Wu",
      "Tao Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15485"
  },
  {
    "id": "arXiv:2211.15487",
    "title": "An Optimized Multi-Layer Resource Management in Mobile Edge Computing  Networks: A Joint Computation Offloading and Caching Solution",
    "abstract": "Nowadays, data caching is being used as a high-speed data storage layer in\nmobile edge computing networks employing flow control methodologies at an\nexponential rate. This study shows how to discover the best architecture for\nbackhaul networks with caching capability using a distributed offloading\ntechnique. This article used a continuous power flow analysis to achieve the\noptimum load constraints, wherein the power of macro base stations with various\ncaching capacities is supplied by either an intelligent grid network or\nrenewable energy systems. This work proposes ubiquitous connectivity between\nusers at the cell edge and offloading the macro cells so as to provide features\nthe macro cell itself cannot cope with, such as extreme changes in the required\nuser data rate and energy efficiency. The offloading framework is then reformed\ninto a neural weighted framework that considers convergence and Lyapunov\ninstability requirements of mobile-edge computing under Karush Kuhn Tucker\noptimization restrictions in order to get accurate solutions. The cell-layer\nperformance is analyzed in the boundary and in the center point of the cells.\nThe analytical and simulation results show that the suggested method\noutperforms other energy-saving techniques. Also, compared to other solutions\nstudied in the literature, the proposed approach shows a two to three times\nincrease in both the throughput of the cell edge users and the aggregate\nthroughput per cluster.",
    "descriptor": "",
    "authors": [
      "Amir Ziaeddini",
      "Amin Mohajer",
      "Davoud Yousefi",
      "A.Mirzaei",
      "Shu Gonglee"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.15487"
  },
  {
    "id": "arXiv:2211.15494",
    "title": "Automated Routing of Droplets for DNA Storage on a Digital Microfluidics  Platform",
    "abstract": "Technologies for sequencing (reading) and synthesizing (writing) DNA have\nprogressed on a Moore's law-like trajectory over the last three decades. This\nhas motivated the idea of using DNA for data storage. Theoretically, DNA-based\nstorage systems could out-compete all existing forms of archival storage.\nHowever, a large gap exists between what is theoretically possible in terms of\nread and write speeds and what has been practically demonstrated with DNA. This\npaper introduces a novel approach to DNA storage, with automated assembly on a\ndigital microfluidic biochip. This technology offers unprecedented parallelism\nin DNA assembly using a dual library of \"symbols\" and \"linkers\". An algorithmic\nsolution is discussed for the problem of managing droplet \"traffic\" on the\ndigital microfluidic device, with prioritized A star routing. Detailed\nsimulation results are presented for routing a large number of droplets in\nparallel on the device, minimizing the amount of congestion, and maximizing\nthroughput.",
    "descriptor": "\nComments: 16 pages, 23 figures, 59 references. To be submitted to the \"Royal Society of Chemistry: Lab on a Chip\" journal\n",
    "authors": [
      "Ajay Manicka",
      "Andrew Stephan",
      "Sriram Chari",
      "Gemma Mendonsa",
      "Peyton Okubo",
      "John Stolzberg-Schray",
      "Anil Reddy",
      "Marc Riedel"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.15494"
  },
  {
    "id": "arXiv:2211.15495",
    "title": "FastCycle: A Message Sharing Framework for Modular Automated Driving  Systems",
    "abstract": "Automated Driving Systems (ADS) have rapidly evolved in recent years and\ntheir architecture becomes sophisticated. Ensuring robustness, reliability and\nsafety of performance is particularly important. The main challenge in building\nan ADS is the ability to meet certain stringent performance requirements in\nterms of both making safe operational decisions and finishing processing in\nreal-time. Middlewares play a crucial role to handle these requirements in ADS.\nThe way middlewares share data between the different system components has a\ndirect impact on the overall performance, particularly the latency overhead. To\nthis end, this paper presents FastCycle as a lightweight multi-threaded\nzero-copy messaging broker to meet the requirements of a high fidelity ADS in\nterms of modularity, real-time performance and security. We discuss the\narchitecture and the main features of the proposed framework. Evaluation of the\nproposed framework based on standard metrics in comparison with popular\nmiddlewares used in robotics and automated driving shows the improved\nperformance of our framework. The implementation of FastCycle and the\nassociated comparisons with other frameworks are open sourced.",
    "descriptor": "",
    "authors": [
      "Mehdi Testouri",
      "Gamal Elghazaly",
      "Raphael Frank"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15495"
  },
  {
    "id": "arXiv:2211.15501",
    "title": "Proactive Robot Assistance via Spatio-Temporal Object Modeling",
    "abstract": "Proactive robot assistance enables a robot to anticipate and provide for a\nuser's needs without being explicitly asked. We formulate proactive assistance\nas the problem of the robot anticipating temporal patterns of object movements\nassociated with everyday user routines, and proactively assisting the user by\nplacing objects to adapt the environment to their needs. We introduce a\ngenerative graph neural network to learn a unified spatio-temporal predictive\nmodel of object dynamics from temporal sequences of object arrangements. We\nadditionally contribute the Household Object Movements from Everyday Routines\n(HOMER) dataset, which tracks household objects associated with human\nactivities of daily living across 50+ days for five simulated households. Our\nmodel outperforms the leading baseline in predicting object movement, correctly\npredicting locations for 11.1% more objects and wrongly predicting locations\nfor 11.5% fewer objects used by the human user.",
    "descriptor": "",
    "authors": [
      "Maithili Patel",
      "Sonia Chernova"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15501"
  },
  {
    "id": "arXiv:2211.15502",
    "title": "ToothInpaintor: Tooth Inpainting from Partial 3D Dental Model and 2D  Panoramic Image",
    "abstract": "In orthodontic treatment, a full tooth model consisting of both the crown and\nroot is indispensable in making the treatment plan. However, acquiring tooth\nroot information to obtain the full tooth model from CBCT images is sometimes\nrestricted due to the massive radiation of CBCT scanning. Thus, reconstructing\nthe full tooth shape from the ready-to-use input, e.g., the partial intra-oral\nscan and the 2D panoramic image, is an applicable and valuable solution. In\nthis paper, we propose a neural network, called ToothInpaintor, that takes as\ninput a partial 3D dental model and a 2D panoramic image and reconstructs the\nfull tooth model with high-quality root(s). Technically, we utilize the\nimplicit representation for both the 3D and 2D inputs, and learn a latent space\nof the full tooth shapes. At test time, given an input, we successfully project\nit to the learned latent space via neural optimization to obtain the full tooth\nmodel conditioned on the input. To help find the robust projection, a novel\nadversarial learning module is exploited in our pipeline. We extensively\nevaluate our method on a dataset collected from real-world clinics. The\nevaluation, comparison, and comprehensive ablation studies demonstrate that our\napproach produces accurate complete tooth models robustly and outperforms the\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yuezhi Yang",
      "Zhiming Cui",
      "Changjian Li",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15502"
  },
  {
    "id": "arXiv:2211.15504",
    "title": "Semantic Table Detection with LayoutLMv3",
    "abstract": "This paper presents an application of the LayoutLMv3 model for semantic table\ndetection on financial documents from the IIIT-AR-13K dataset. The motivation\nbehind this paper's experiment was that LayoutLMv3's official paper had no\nresults for table detection using semantic information. We concluded that our\napproach did not improve the model's table detection capabilities, for which we\ncan give several possible reasons. Either the model's weights were unsuitable\nfor our purpose, or we needed to invest more time in optimising the model's\nhyperparameters. It is also possible that semantic information does not improve\na model's table detection accuracy.",
    "descriptor": "\nComments: 4 pages, 2 tables\n",
    "authors": [
      "Ivan Silajev",
      "Niels Victor",
      "Phillip Mortimer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15504"
  },
  {
    "id": "arXiv:2211.15505",
    "title": "Object Permanence in Object Detection Leveraging Temporal Priors at  Inference Time",
    "abstract": "Object permanence is the concept that objects do not suddenly disappear in\nthe physical world. Humans understand this concept at young ages and know that\nanother person is still there, even though it is temporarily occluded. Neural\nnetworks currently often struggle with this challenge. Thus, we introduce\nexplicit object permanence into two stage detection approaches drawing\ninspiration from particle filters. At the core, our detector uses the\npredictions of previous frames as additional proposals for the current one at\ninference time. Experiments confirm the feedback loop improving detection\nperformance by a up to 10.3 mAP with little computational overhead.\nOur approach is suited to extend two-stage detectors for stabilized and\nreliable detections even under heavy occlusion. Additionally, the ability to\napply our method without retraining an existing model promises wide application\nin real-world tasks.",
    "descriptor": "\nComments: 6 pages + references, 5 figures, 3 tables\n",
    "authors": [
      "Michael F\u00fcrst",
      "Priyash Bhugra",
      "Ren\u00e9 Schuster",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15505"
  },
  {
    "id": "arXiv:2211.15506",
    "title": "Fast non-Hermitian Toeplitz eigenvalue computations, joining matrix-less  algorithms and FDE approximation matrices",
    "abstract": "The present work is devoted to the eigenvalue asymptotic expansion of the\nToeplitz matrix $T_{n}(a)$ whose generating function $a$ is complex valued and\nhas a power singularity at one point. As a consequence, $T_{n}(a)$ is\nnon-Hermitian and we know that the eigenvalue computation is a non-trivial task\nin the non-Hermitian setting for large sizes. We follow the work of Bogoya,\nB\\\"ottcher, Grudsky, and Maximenko and deduce a complete asymptotic expansion\nfor the eigenvalues. After that, we apply matrix-less algorithms, in the spirit\nof the work by Ekstr\\\"om, Furci, Garoni, Serra-Capizzano et al, for computing\nthose eigenvalues. Since the inner and extreme eigenvalues have different\nasymptotic behaviors, we worked on them independently, and combined the results\nto produce a high precision global numerical and matrix-less algorithm.\nThe numerical results are very precise and the computational cost of the\nproposed algorithms is independent of the size of the considered matrices for\neach eigenvalue, which implies a linear cost when all the spectrum is computed.\nFrom the viewpoint of real world applications, we emphasize that the matrix\nclass under consideration includes the matrices stemming from the numerical\napproximation of fractional diffusion equations. In the final conclusion\nsection a concise discussion on the matter and few open problems are presented.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "M. Bogoya",
      "S.M. Grudsky",
      "S. Serra-Capizzano"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15506"
  },
  {
    "id": "arXiv:2211.15508",
    "title": "Self Supervised Clustering of Traffic Scenes using Graph Representations",
    "abstract": "Examining graphs for similarity is a well-known challenge, but one that is\nmandatory for grouping graphs together. We present a data-driven method to\ncluster traffic scenes that is self-supervised, i.e. without manual labelling.\nWe leverage the semantic scene graph model to create a generic graph embedding\nof the traffic scene, which is then mapped to a low-dimensional embedding space\nusing a Siamese network, in which clustering is performed. In the training\nprocess of our novel approach, we augment existing traffic scenes in the\nCartesian space to generate positive similarity samples. This allows us to\novercome the challenge of reconstructing a graph and at the same time obtain a\nrepresentation to describe the similarity of traffic scenes. We could show,\nthat the resulting clusters possess common semantic characteristics. The\napproach was evaluated on the INTERACTION dataset.",
    "descriptor": "",
    "authors": [
      "Maximilian Zipfl",
      "Moritz Jarosch",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15508"
  },
  {
    "id": "arXiv:2211.15510",
    "title": "Shortcut Removal for Improved OOD-Generalization",
    "abstract": "Machine learning is a data-driven discipline, and learning success is largely\ndependent on the quality of the underlying data sets. However, it is becoming\nincreasingly clear that even high performance on held-out test data does not\nnecessarily mean that a model generalizes or learns anything meaningful at all.\nOne reason for this is the presence of machine learning shortcuts, i.e., hints\nin the data that are predictive but accidental and semantically unconnected to\nthe problem. We present a new approach to detect such shortcuts and a technique\nto automatically remove them from datasets. Using an adversarially trained\nlens, any small and highly predictive clues in images can be detected and\nremoved. We show that this approach 1) does not cause degradation of model\nperformance in the absence of these shortcuts, and 2) reliably identifies and\nneutralizes shortcuts from different image datasets. In our experiments, we are\nable to recover up to 93,8% of model performance in the presence of different\nshortcuts. Finally, we apply our model to a real-world dataset from the medical\ndomain consisting of chest x-rays and identify and remove several types of\nshortcuts that are known to hinder real-world applicability. Thus, we hope that\nour proposed approach fosters real-world applicability of machine learning.",
    "descriptor": "",
    "authors": [
      "Nicolas M. M\u00fcller",
      "Jochen Jacobs",
      "Jennifer Williams",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.15510"
  },
  {
    "id": "arXiv:2211.15513",
    "title": "Composite Score for Anomaly Detection in Imbalanced Real-World  Industrial Dataset",
    "abstract": "In recent years, the industrial sector has evolved towards its fourth\nrevolution. The quality control domain is particularly interested in advanced\nmachine learning for computer vision anomaly detection. Nevertheless, several\nchallenges have to be faced, including imbalanced datasets, the image\ncomplexity, and the zero-false-negative (ZFN) constraint to guarantee the\nhigh-quality requirement. This paper illustrates a use case for an industrial\npartner, where Printed Circuit Board Assembly (PCBA) images are first\nreconstructed with a Vector Quantized Generative Adversarial Network (VQGAN)\ntrained on normal products. Then, several multi-level metrics are extracted on\na few normal and abnormal images, highlighting anomalies through reconstruction\ndifferences. Finally, a classifer is trained to build a composite anomaly score\nthanks to the metrics extracted. This three-step approach is performed on the\npublic MVTec-AD datasets and on the partner PCBA dataset, where it achieves a\nregular accuracy of 95.69% and 87.93% under the ZFN constraint.",
    "descriptor": "",
    "authors": [
      "Arnaud Bougaham",
      "Mohammed El Adoui",
      "Isabelle Linden",
      "Beno\u00eet Fr\u00e9nay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15513"
  },
  {
    "id": "arXiv:2211.15516",
    "title": "DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and  Grounding",
    "abstract": "In this paper, we study the problem of visual grounding by considering both\nphrase extraction and grounding (PEG). In contrast to the previous\nphrase-known-at-test setting, PEG requires a model to extract phrases from text\nand locate objects from images simultaneously, which is a more practical\nsetting in real applications. As phrase extraction can be regarded as a $1$D\ntext segmentation problem, we formulate PEG as a dual detection problem and\npropose a novel DQ-DETR model, which introduces dual queries to probe different\nfeatures from image and text for object prediction and phrase mask prediction.\nEach pair of dual queries is designed to have shared positional parts but\ndifferent content parts. Such a design effectively alleviates the difficulty of\nmodality alignment between image and text (in contrast to a single query\ndesign) and empowers Transformer decoder to leverage phrase mask-guided\nattention to improve performance. To evaluate the performance of PEG, we also\npropose a new metric CMAP (cross-modal average precision), analogous to the AP\nmetric in object detection. The new metric overcomes the ambiguity of Recall@1\nin many-box-to-one-phrase cases in phrase grounding. As a result, our PEG\npre-trained DQ-DETR establishes new state-of-the-art results on all visual\ngrounding benchmarks with a ResNet-101 backbone. For example, it achieves\n$91.04\\%$ and $83.51\\%$ in terms of recall rate on RefCOCO testA and testB with\na ResNet-101 backbone. Code will be availabl at\n\\url{https://github.com/IDEA-Research/DQ-DETR}.",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Shilong Liu",
      "Yaoyuan Liang",
      "Feng Li",
      "Shijia Huang",
      "Hao Zhang",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15516"
  },
  {
    "id": "arXiv:2211.15518",
    "title": "ReCo: Region-Controlled Text-to-Image Generation",
    "abstract": "Recently, large-scale text-to-image (T2I) models have shown impressive\nperformance in generating high-fidelity images, but with limited\ncontrollability, e.g., precisely specifying the content in a specific region\nwith a free-form text description. In this paper, we propose an effective\ntechnique for such regional control in T2I generation. We augment T2I models'\ninputs with an extra set of position tokens, which represent the quantized\nspatial coordinates. Each region is specified by four position tokens to\nrepresent the top-left and bottom-right corners, followed by an open-ended\nnatural language regional description. Then, we fine-tune a pre-trained T2I\nmodel with such new input interface. Our model, dubbed as ReCo\n(Region-Controlled T2I), enables the region control for arbitrary objects\ndescribed by open-ended regional texts rather than by object labels from a\nconstrained category set. Empirically, ReCo achieves better image quality than\nthe T2I model strengthened by positional words (FID: 8.82->7.36, SceneFID:\n15.54->6.51 on COCO), together with objects being more accurately placed,\namounting to a 20.40% region classification accuracy improvement on COCO.\nFurthermore, we demonstrate that ReCo can better control the object count,\nspatial relationship, and region attributes such as color/size, with the\nfree-form regional description. Human evaluation on PaintSkill shows that ReCo\nis +19.28% and +17.21% more accurate in generating images with correct object\ncount and spatial relationship than the T2I model.",
    "descriptor": "",
    "authors": [
      "Zhengyuan Yang",
      "Jianfeng Wang",
      "Zhe Gan",
      "Linjie Li",
      "Kevin Lin",
      "Chenfei Wu",
      "Nan Duan",
      "Zicheng Liu",
      "Ce Liu",
      "Michael Zeng",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15518"
  },
  {
    "id": "arXiv:2211.15520",
    "title": "Symmetric Formulas for Products of Permutations",
    "abstract": "We study the formula complexity of the word problem $\\mathsf{Word}_{S_n,k} :\n\\{0,1\\}^{kn^2} \\to \\{0,1\\}$: given $n$-by-$n$ permutation matrices\n$M_1,\\dots,M_k$, compute the $(1,1)$-entry of the matrix product $M_1\\cdots\nM_k$. An important feature of this function is that it is invariant under\naction of $S_n^{k-1}$ given by \\[\n(\\pi_1,\\dots,\\pi_{k-1})(M_1,\\dots,M_k) =\n(M_1\\pi_1^{-1},\\pi_1M_2\\pi_2^{-1},\\dots,\\pi_{k-2}M_{k-1}\\pi_{k-1}^{-1},\\pi_{k-1}M_k).\n\\] This symmetry is also exhibited in the smallest known unbounded fan-in\n$\\{\\mathsf{AND},\\mathsf{OR},\\mathsf{NOT}\\}$-formulas for\n$\\mathsf{Word}_{S_n,k}$, which have size $n^{O(\\log k)}$.\nIn this paper we prove a matching $n^{\\Omega(\\log k)}$ lower bound for\n$S_n^{k-1}$-invariant formulas computing $\\mathsf{Word}_{S_n,k}$. This result\nis motivated by the fact that a similar lower bound for unrestricted\n(non-invariant) formulas would separate complexity classes $\\mathsf{NC}^1$ and\n$\\mathsf{Logspace}$.\nOur more general main theorem gives a nearly tight $n^{d(k^{1/d}-1)}$ lower\nbound on the $G^{k-1}$-invariant depth-$d$\n$\\{\\mathsf{MAJ},\\mathsf{AND},\\mathsf{OR},\\mathsf{NOT}\\}$-formula size of\n$\\mathsf{Word}_{G,k}$ for any finite simple group $G$ whose minimum permutation\nrepresentation has degree~$n$. We also give nearly tight lower bounds on the\n$G^{k-1}$-invariant depth-$d$\n$\\{\\mathsf{AND},\\mathsf{OR},\\mathsf{NOT}\\}$-formula size in the case where $G$\nis an abelian group.",
    "descriptor": "\nComments: ITCS 2023\n",
    "authors": [
      "William He",
      "Benjamin Rossman"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.15520"
  },
  {
    "id": "arXiv:2211.15521",
    "title": "G^3: Geolocation via Guidebook Grounding",
    "abstract": "We demonstrate how language can improve geolocation: the task of predicting\nthe location where an image was taken. Here we study explicit knowledge from\nhuman-written guidebooks that describe the salient and class-discriminative\nvisual features humans use for geolocation. We propose the task of Geolocation\nvia Guidebook Grounding that uses a dataset of StreetView images from a diverse\nset of locations and an associated textual guidebook for GeoGuessr, a popular\ninteractive geolocation game. Our approach predicts a country for each image by\nattending over the clues automatically extracted from the guidebook.\nSupervising attention with country-level pseudo labels achieves the best\nperformance. Our approach substantially outperforms a state-of-the-art\nimage-only geolocation method, with an improvement of over 5% in Top-1\naccuracy. Our dataset and code can be found at\nhttps://github.com/g-luo/geolocation_via_guidebook_grounding.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Grace Luo",
      "Giscard Biamby",
      "Trevor Darrell",
      "Daniel Fried",
      "Anna Rohrbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15521"
  },
  {
    "id": "arXiv:2211.15524",
    "title": "Differentiable Dictionary Search: Integrating Linear Mixing with Deep  Non-Linear Modelling for Audio Source Separation",
    "abstract": "This paper describes several improvements to a new method for signal\ndecomposition that we recently formulated under the name of Differentiable\nDictionary Search (DDS). The fundamental idea of DDS is to exploit a class of\npowerful deep invertible density estimators called normalizing flows, to model\nthe dictionary in a linear decomposition method such as NMF, effectively\ncreating a bijection between the space of dictionary elements and the\nassociated probability space, allowing a differentiable search through the\ndictionary space, guided by the estimated densities. As the initial formulation\nwas a proof of concept with some practical limitations, we will present several\nsteps towards making it scalable, hoping to improve both the computational\ncomplexity of the method and its signal decomposition capabilities. As a\ntestbed for experimental evaluation, we choose the task of frame-level piano\ntranscription, where the signal is to be decomposed into sources whose activity\nis attributed to individual piano notes. To highlight the impact of improved\nnon-linear modelling of sources, we compare variants of our method to a linear\novercomplete NMF baseline. Experimental results will show that even in the\nabsence of additional constraints, our models produce increasingly sparse and\nprecise decompositions, according to two pertinent evaluation measures.",
    "descriptor": "\nComments: Published in the Proceedings of the 24th International Congress on Acoustics (ICA 2022), Gyeongju, Korea, October 24-28, 2022\n",
    "authors": [
      "Luk\u00e1\u0161 Samuel Mart\u00e1k",
      "Rainer Kelz",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.15524"
  },
  {
    "id": "arXiv:2211.15525",
    "title": "Multi-User Privacy Mechanism Design with Non-zero Leakage",
    "abstract": "A privacy mechanism design problem is studied through the lens of information\ntheory. In this work, an agent observes useful data $Y=(Y_1,...,Y_N)$ that is\ncorrelated with private data $X=(X_1,...,X_N)$ which is assumed to be also\naccessible by the agent. Here, we consider $K$ users where user $i$ demands a\nsub-vector of $Y$, denoted by $C_{i}$. The agent wishes to disclose $C_{i}$ to\nuser $i$. Since $C_{i}$ is correlated with $X$ it can not be disclosed\ndirectly. A privacy mechanism is designed to generate disclosed data $U$ which\nmaximizes a linear combinations of the users utilities while satisfying a\nbounded privacy constraint in terms of mutual information. In a similar work it\nhas been assumed that $X_i$ is a deterministic function of $Y_i$, however in\nthis work we let $X_i$ and $Y_i$ be arbitrarily correlated. First, an upper\nbound on the privacy-utility trade-off is obtained by using a specific\ntransformation, Functional Representation Lemma and Strong Functional\nRepresentaion Lemma, then we show that the upper bound can be decomposed into\n$N$ parallel problems. Next, lower bounds on privacy-utility trade-off are\nderived using Functional Representation Lemma and Strong Functional\nRepresentaion Lemma. The upper bound is tight within a constant and the lower\nbounds assert that the disclosed data is independent of all $\\{X_j\\}_{i=1}^N$\nexcept one which we allocate the maximum allowed leakage to it. Finally, the\nobtained bounds are studied in special cases.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2205.04881, arXiv:2201.08738\n",
    "authors": [
      "Amirreza Zamani",
      "Tobias J. Oechtering",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15525"
  },
  {
    "id": "arXiv:2211.15532",
    "title": "YZR-net : Self-supervised Hidden representations Invariant to  Transformations for profanity detection",
    "abstract": "On current {\\it e-}learning platforms, live classes are an important tool\nthat provides students with an opportunity to get more involved while learning\nnew concepts. In such classes, the element of interaction with teachers and\nfellow peers helps in removing learning silos and gives each student a chance\nto experience some aspects relevant to offline learning in this era of virtual\nclasses. One common way of interaction in a class is through the chats /\nmessaging framework, where the teacher can broadcast messages as well as get\ninstant feedback from the students in the live class. This freedom of\ninteraction is a crucial aspect for any student's learning growth but misuse of\nit can have serious repercussions. Some miscreants use this framework to send\nprofane messages which can have a negative impact on other students as well as\nthe teacher of the class. These rare but high impact situations obviate the\nneed for automatic detection mechanisms that prevent the posting of such chats\non any platform. In this work we develop YZR-Net which is a self-supervised\nframework that is able to robustly detect profane words used in a chat even if\nthe student tries to add clever modifications to fool the system. The matching\nmechanism on token / word level allows us to maintain a compact as well as\ndynamic profane vocabulary which can be updated without retraining the\nunderlying model. Our profanity detection framework is language independent and\ncan handle abuses in both English as well as its transliterated counterpart\nHinglish (Hindi language words written in English).",
    "descriptor": "",
    "authors": [
      "Vedant Sandeep Joshi",
      "Sivanagaraja Tatinati",
      "Yubo Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.15532"
  },
  {
    "id": "arXiv:2211.15533",
    "title": "The Stack: 3 TB of permissively licensed source code",
    "abstract": "Large Language Models (LLMs) play an ever-increasing role in the field of\nArtificial Intelligence (AI)--not only for natural language processing but also\nfor code understanding and generation. To stimulate open and responsible\nresearch on LLMs for code, we introduce The Stack, a 3.1 TB dataset consisting\nof permissively licensed source code in 30 programming languages. We describe\nhow we collect the full dataset, construct a permissively licensed subset,\npresent a data governance plan, discuss limitations, and show promising results\non text2code benchmarks by training 350M-parameter decoders on different Python\nsubsets. We find that (1) near-deduplicating the data significantly boosts\nperformance across all experiments, and (2) it is possible to match previously\nreported HumanEval and MBPP performance using only permissively licensed data.\nWe make the dataset available at https://hf.co/BigCode, provide a tool called\n\"Am I in The Stack\" (https://hf.co/spaces/bigcode/in-the-stack) for developers\nto search The Stack for copies of their code, and provide a process for code to\nbe removed from the dataset by following the instructions at\nhttps://www.bigcode-project.org/docs/about/the-stack/.",
    "descriptor": "",
    "authors": [
      "Denis Kocetkov",
      "Raymond Li",
      "Loubna Ben Allal",
      "Jia Li",
      "Chenghao Mou",
      "Carlos Mu\u00f1oz Ferrandis",
      "Yacine Jernite",
      "Margaret Mitchell",
      "Sean Hughes",
      "Thomas Wolf",
      "Dzmitry Bahdanau",
      "Leandro von Werra",
      "Harm de Vries"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15533"
  },
  {
    "id": "arXiv:2211.15536",
    "title": "Sentiment analysis and opinion mining on E-commerce site",
    "abstract": "Sentiment analysis or opinion mining help to illustrate the phrase NLP\n(Natural Language Processing). Sentiment analysis has been the most significant\ntopic in recent years. The goal of this study is to solve the sentiment\npolarity classification challenges in sentiment analysis. A broad technique for\ncategorizing sentiment opposition is presented, along with comprehensive\nprocess explanations. With the results of the analysis, both sentence-level\nclassification and review-level categorization are conducted. Finally, we\ndiscuss our plans for future sentiment analysis research.",
    "descriptor": "\nComments: 5 pages, 6 figures, 4 tables\n",
    "authors": [
      "Fatema Tuz Zohra Anny",
      "Oahidul Islam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15536"
  },
  {
    "id": "arXiv:2211.15538",
    "title": "Graph Convolutional Network for Multi-Target Multi-Camera Vehicle  Tracking",
    "abstract": "This letter focuses on the task of Multi-Target Multi-Camera vehicle\ntracking. We propose to associate single-camera trajectories into multi-camera\nglobal trajectories by training a Graph Convolutional Network. Our approach\nsimultaneously processes all cameras providing a global solution, and it is\nalso robust to large cameras unsynchronizations. Furthermore, we design a new\nloss function to deal with class imbalance. Our proposal outperforms the\nrelated work showing better generalization and without requiring ad-hoc manual\nannotations or thresholds, unlike compared approaches.",
    "descriptor": "",
    "authors": [
      "Elena Luna",
      "Juan Carlos San Miguel",
      "Jos\u00e9 Mar\u00eda Mart\u00ednez",
      "Marcos Escudero-Vi\u00f1olo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15538"
  },
  {
    "id": "arXiv:2211.15542",
    "title": "Autonomous Assessment of Demonstration Sufficiency via Bayesian Inverse  Reinforcement Learning",
    "abstract": "In this paper we examine the problem of determining demonstration sufficiency\nfor AI agents that learn from demonstrations: how can an AI agent self-assess\nwhether it has received enough demonstrations from an expert to ensure a\ndesired level of performance? To address this problem we propose a novel\nself-assessment approach based on Bayesian inverse reinforcement learning and\nvalue-at-risk to enable agents that learn from demonstrations to compute\nhigh-confidence bounds on their performance and use these bounds to determine\nwhen they have a sufficient number of demonstrations. We propose and evaluate\ntwo definitions of sufficiency: (1) normalized expected value difference, which\nmeasures regret with respect to the expert's unobserved reward function, and\n(2) improvement over a baseline policy. We demonstrate how to formulate\nhigh-confidence bounds on both of these metrics. We evaluate our approach in\nsimulation and demonstrate the feasibility of developing an AI system that can\naccurately evaluate whether it has received sufficient training data to\nguarantee, with high confidence, that it can match an expert's performance or\nsurpass the performance of a baseline policy within some desired safety\nthreshold.",
    "descriptor": "\nComments: Appears in Proceedings of AAAI FSS-22 Symposium \"Lessons Learned for Autonomous Assessment of Machine Abilities (LLAAMA)\"\n",
    "authors": [
      "Tu Trinh",
      "Daniel S. Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15542"
  },
  {
    "id": "arXiv:2211.15544",
    "title": "Automatically Extracting Information in Medical Dialogue: Expert System  And Attention for Labelling",
    "abstract": "Medical dialogue information extraction is becoming an increasingly\nsignificant problem in modern medical care. It is difficult to extract key\ninformation from electronic medical records (EMRs) due to their large numbers.\nPreviously, researchers proposed attention-based models for retrieving features\nfrom EMRs, but their limitations were reflected in their inability to recognize\ndifferent categories in medical dialogues. In this paper, we propose a novel\nmodel, Expert System and Attention for Labelling (ESAL). We use mixture of\nexperts and pre-trained BERT to retrieve the semantics of different categories,\nenabling the model to fuse the differences between them. In our experiment,\nESAL was applied to a public dataset and the experimental results indicated\nthat ESAL significantly improved the performance of Medical Information\nClassification.",
    "descriptor": "",
    "authors": [
      "Xinshi Wang",
      "Daniel Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15544"
  },
  {
    "id": "arXiv:2211.15549",
    "title": "Realtime Fewshot Portrait Stylization Based On Geometric Alignment",
    "abstract": "This paper presents a portrait stylization method designed for real-time\nmobile applications with limited style examples available. Previous learning\nbased stylization methods suffer from the geometric and semantic gaps between\nportrait domain and style domain, which obstacles the style information to be\ncorrectly transferred to the portrait images, leading to poor stylization\nquality. Based on the geometric prior of human facial attributions, we propose\nto utilize geometric alignment to tackle this issue. Firstly, we apply\nThin-Plate-Spline (TPS) on feature maps in the generator network and also\ndirectly to style images in pixel space, generating aligned portrait-style\nimage pairs with identical landmarks, which closes the geometric gaps between\ntwo domains. Secondly, adversarial learning maps the textures and colors of\nportrait images to the style domain. Finally, geometric aware cycle consistency\npreserves the content and identity information unchanged, and deformation\ninvariant constraint suppresses artifacts and distortions. Qualitative and\nquantitative comparison validate our method outperforms existing methods, and\nexperiments proof our method could be trained with limited style examples (100\nor less) in real-time (more than 40 FPS) on mobile devices. Ablation study\ndemonstrates the effectiveness of each component in the framework.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Xinrui Wang",
      "Zhuoru Li",
      "Xiao Zhou",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15549"
  },
  {
    "id": "arXiv:2211.15552",
    "title": "AI Enabled Maneuver Identification via the Maneuver Identification  Challenge",
    "abstract": "Artificial intelligence (AI) has enormous potential to improve Air Force\npilot training by providing actionable feedback to pilot trainees on the\nquality of their maneuvers and enabling instructor-less flying familiarization\nfor early-stage trainees in low-cost simulators. Historically, AI challenges\nconsisting of data, problem descriptions, and example code have been critical\nto fueling AI breakthroughs. The Department of the Air Force-Massachusetts\nInstitute of Technology AI Accelerator (DAF-MIT AI Accelerator) developed such\nan AI challenge using real-world Air Force flight simulator data. The Maneuver\nID challenge assembled thousands of virtual reality simulator flight recordings\ncollected by actual Air Force student pilots at Pilot Training Next (PTN). This\ndataset has been publicly released at Maneuver-ID.mit.edu and represents the\nfirst of its kind public release of USAF flight training data. Using this\ndataset, we have applied a variety of AI methods to separate \"good\" vs \"bad\"\nsimulator data and categorize and characterize maneuvers. These data,\nalgorithms, and software are being released as baselines of model performance\nfor others to build upon to enable the AI ecosystem for flight simulator\ntraining.",
    "descriptor": "\nComments: 10 pages, 7 figures, 4 tables, accepted to and presented at I/ITSEC\n",
    "authors": [
      "Kaira Samuel",
      "Matthew LaRosa",
      "Kyle McAlpin",
      "Morgan Schaefer",
      "Brandon Swenson",
      "Devin Wasilefsky",
      "Yan Wu",
      "Dan Zhao",
      "Jeremy Kepner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15552"
  },
  {
    "id": "arXiv:2211.15556",
    "title": "Attack on Unfair ToS Clause Detection: A Case Study using Universal  Adversarial Triggers",
    "abstract": "Recent work has demonstrated that natural language processing techniques can\nsupport consumer protection by automatically detecting unfair clauses in the\nTerms of Service (ToS) Agreement. This work demonstrates that transformer-based\nToS analysis systems are vulnerable to adversarial attacks. We conduct\nexperiments attacking an unfair-clause detector with universal adversarial\ntriggers. Experiments show that a minor perturbation of the text can\nconsiderably reduce the detection performance. Moreover, to measure the\ndetectability of the triggers, we conduct a detailed human evaluation study by\ncollecting both answer accuracy and response time from the participants. The\nresults show that the naturalness of the triggers remains key to tricking\nreaders.",
    "descriptor": "\nComments: Accepted at NLLP@EMNLP2022\n",
    "authors": [
      "Shanshan Xu",
      "Irina Broda",
      "Rashid Haddad",
      "Marco Negrini",
      "Matthias Grabmair"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15556"
  },
  {
    "id": "arXiv:2211.15557",
    "title": "Beyond CAGE: Investigating Generalization of Learned Autonomous Network  Defense Policies",
    "abstract": "Advancements in reinforcement learning (RL) have inspired new directions in\nintelligent automation of network defense. However, many of these advancements\nhave either outpaced their application to network security or have not\nconsidered the challenges associated with implementing them in the real-world.\nTo understand these problems, this work evaluates several RL approaches\nimplemented in the second edition of the CAGE Challenge, a public competition\nto build an autonomous network defender agent in a high-fidelity network\nsimulator. Our approaches all build on the Proximal Policy Optimization (PPO)\nfamily of algorithms, and include hierarchical RL, action masking, custom\ntraining, and ensemble RL. We find that the ensemble RL technique performs\nstrongest, outperforming our other models and taking second place in the\ncompetition. To understand applicability to real environments we evaluate each\nmethod's ability to generalize to unseen networks and against an unknown attack\nstrategy. In unseen environments, all of our approaches perform worse, with\ndegradation varied based on the type of environmental change. Against an\nunknown attacker strategy, we found that our models had reduced overall\nperformance even though the new strategy was less efficient than the ones our\nmodels trained on. Together, these results highlight promising research\ndirections for autonomous network defense in the real world.",
    "descriptor": "\nComments: NeurIPS 2022 Workshop: Reinforcement Learning for Real Life\n",
    "authors": [
      "Melody Wolk",
      "Andy Applebaum",
      "Camron Denver",
      "Patrick Dwyer",
      "Marina Moskowitz",
      "Harold Nguyen",
      "Nicole Nichols",
      "Nicole Park",
      "Paul Rachwalski",
      "Frank Rau",
      "Adrian Webster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15557"
  },
  {
    "id": "arXiv:2211.15561",
    "title": "Graph Neural Networks for Breast Cancer Data Integration",
    "abstract": "International initiatives such as METABRIC (Molecular Taxonomy of Breast\nCancer International Consortium) have collected several multigenomic and\nclinical data sets to identify the undergoing molecular processes taking place\nthroughout the evolution of various cancers. Numerous Machine Learning and\nstatistical models have been designed and trained to analyze these types of\ndata independently, however, the integration of such differently shaped and\nsourced information streams has not been extensively studied. To better\nintegrate these data sets and generate meaningful representations that can\nultimately be leveraged for cancer detection tasks could lead to giving\nwell-suited treatments to patients. Hence, we propose a novel learning pipeline\ncomprising three steps - the integration of cancer data modalities as graphs,\nfollowed by the application of Graph Neural Networks in an unsupervised setting\nto generate lower-dimensional embeddings from the combined data, and finally\nfeeding the new representations on a cancer sub-type classification model for\nevaluation. The graph construction algorithms are described in-depth as\nMETABRIC does not store relationships between the patient modalities, with a\ndiscussion of their influence over the quality of the generated embeddings. We\nalso present the models used to generate the lower-latent space\nrepresentations: Graph Neural Networks, Variational Graph Autoencoders and Deep\nGraph Infomax. In parallel, the pipeline is tested on a synthetic dataset to\ndemonstrate that the characteristics of the underlying data, such as homophily\nlevels, greatly influence the performance of the pipeline, which ranges between\n51\\% to 98\\% accuracy on artificial data, and 13\\% and 80\\% on METABRIC. This\nproject has the potential to improve cancer data understanding and encourages\nthe transition of regular data sets to graph-shaped data.",
    "descriptor": "\nComments: 64 pages\n",
    "authors": [
      "Teodora Reu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2211.15561"
  },
  {
    "id": "arXiv:2211.15564",
    "title": "Machine Learning for Health symposium 2022 -- Extended Abstract track",
    "abstract": "A collection of the extended abstracts that were presented at the 2nd Machine\nLearning for Health symposium (ML4H 2022), which was held both virtually and in\nperson on November 28, 2022, in New Orleans, Louisiana, USA. Machine Learning\nfor Health (ML4H) is a longstanding venue for research into machine learning\nfor health, including both theoretical works and applied works. ML4H 2022\nfeatured two submission tracks: a proceedings track, which encompassed\nfull-length submissions of technically mature and rigorous work, and an\nextended abstract track, which would accept less mature, but innovative\nresearch for discussion. All the manuscripts submitted to ML4H Symposium\nunderwent a double-blind peer-review process. Extended abstracts included in\nthis collection describe innovative machine learning research focused on\nrelevant problems in health and biomedicine.",
    "descriptor": "",
    "authors": [
      "Antonio Parziale",
      "Monica Agrawal",
      "Shalmali Joshi",
      "Irene Y. Chen",
      "Shengpu Tang",
      "Luis Oala",
      "Adarsh Subbaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15564"
  },
  {
    "id": "arXiv:2211.15565",
    "title": "A Critical Analysis of Classifier Selection in Learned Bloom Filters",
    "abstract": "Learned Bloom Filters, i.e., models induced from data via machine learning\ntechniques and solving the approximate set membership problem, have recently\nbeen introduced with the aim of enhancing the performance of standard Bloom\nFilters, with special focus on space occupancy. Unlike in the classical case,\nthe \"complexity\" of the data used to build the filter might heavily impact on\nits performance. Therefore, here we propose the first in-depth analysis, to the\nbest of our knowledge, for the performance assessment of a given Learned Bloom\nFilter, in conjunction with a given classifier, on a dataset of a given\nclassification complexity. Indeed, we propose a novel methodology, supported by\nsoftware, for designing, analyzing and implementing Learned Bloom Filters in\nfunction of specific constraints on their multi-criteria nature (that is,\nconstraints involving space efficiency, false positive rate, and reject time).\nOur experiments show that the proposed methodology and the supporting software\nare valid and useful: we find out that only two classifiers have desirable\nproperties in relation to problems with different data complexity, and,\ninterestingly, none of them has been considered so far in the literature. We\nalso experimentally show that the Sandwiched variant of Learned Bloom filters\nis the most robust to data complexity and classifier performance variability,\nas well as those usually having smaller reject times. The software can be\nreadily used to test new Learned Bloom Filter proposals, which can be compared\nwith the best ones identified here.",
    "descriptor": "",
    "authors": [
      "Dario Malchiodi",
      "Davide Raimondi",
      "Giacomo Fumagalli",
      "Raffaele Giancarlo",
      "Marco Frasca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15565"
  },
  {
    "id": "arXiv:2211.15566",
    "title": "Neuro-Symbolic Spatio-Temporal Reasoning",
    "abstract": "Knowledge about space and time is necessary to solve problems in the physical\nworld: An AI agent situated in the physical world and interacting with objects\noften needs to reason about positions of and relations between objects; and as\nsoon as the agent plans its actions to solve a task, it needs to consider the\ntemporal aspect (e.g., what actions to perform over time). Spatio-temporal\nknowledge, however, is required beyond interacting with the physical world, and\nis also often transferred to the abstract world of concepts through analogies\nand metaphors (e.g., \"a threat that is hanging over our heads\"). As spatial and\ntemporal reasoning is ubiquitous, different attempts have been made to\nintegrate this into AI systems. In the area of knowledge representation,\nspatial and temporal reasoning has been largely limited to modeling objects and\nrelations and developing reasoning methods to verify statements about objects\nand relations. On the other hand, neural network researchers have tried to\nteach models to learn spatial relations from data with limited reasoning\ncapabilities. Bridging the gap between these two approaches in a mutually\nbeneficial way could allow us to tackle many complex real-world problems, such\nas natural language processing, visual question answering, and semantic image\nsegmentation. In this chapter, we view this integration problem from the\nperspective of Neuro-Symbolic AI. Specifically, we propose a synergy between\nlogical reasoning and machine learning that will be grounded on spatial and\ntemporal knowledge. Describing some successful applications, remaining\nchallenges, and evaluation datasets pertaining to this direction is the main\ntopic of this contribution.",
    "descriptor": "\nComments: Contribution to the book \"A Compendium of Neuro-Symbolic Artificial Intelligence\", which is to appear in the first half of 2023\n",
    "authors": [
      "Jae Hee Lee",
      "Michael Sioutis",
      "Kyra Ahrens",
      "Marjan Alirezaie",
      "Matthias Kerzel",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15566"
  },
  {
    "id": "arXiv:2211.15568",
    "title": "Automatically generating question-answer pairs for assessing basic  reading comprehension in Swedish",
    "abstract": "This paper presents an evaluation of the quality of automatically generated\nreading comprehension questions from Swedish text, using the Quinductor method.\nThis method is a light-weight, data-driven but non-neural method for automatic\nquestion generation (QG). The evaluation shows that Quinductor is a viable QG\nmethod that can provide a strong baseline for neural-network-based QG methods.",
    "descriptor": "\nComments: Accepted to SLTC 2022\n",
    "authors": [
      "Dmytro Kalpakchi",
      "Johan Boye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15568"
  },
  {
    "id": "arXiv:2211.15578",
    "title": "Mutual Exclusivity Training and Primitive Augmentation to Induce  Compositionality",
    "abstract": "Recent datasets expose the lack of the systematic generalization ability in\nstandard sequence-to-sequence models. In this work, we analyze this behavior of\nseq2seq models and identify two contributing factors: a lack of mutual\nexclusivity bias (i.e., a source sequence already mapped to a target sequence\nis less likely to be mapped to other target sequences), and the tendency to\nmemorize whole examples rather than separating structures from contents. We\npropose two techniques to address these two issues respectively: Mutual\nExclusivity Training that prevents the model from producing seen generations\nwhen facing novel, unseen examples via an unlikelihood-based loss; and\nprim2primX data augmentation that automatically diversifies the arguments of\nevery syntactic function to prevent memorizing and provide a compositional\ninductive bias without exposing test-set data. Combining these two techniques,\nwe show substantial empirical improvements using standard sequence-to-sequence\nmodels (LSTMs and Transformers) on two widely-used compositionality datasets:\nSCAN and COGS. Finally, we provide analysis characterizing the improvements as\nwell as the remaining challenges, and provide detailed ablations of our method.\nOur code is available at https://github.com/owenzx/met-primaug",
    "descriptor": "\nComments: EMNLP 2022 (16 pages; the first 2 authors contributed equally)\n",
    "authors": [
      "Yichen Jiang",
      "Xiang Zhou",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15578"
  },
  {
    "id": "arXiv:2211.15583",
    "title": "On the Effectiveness of Parameter-Efficient Fine-Tuning",
    "abstract": "Fine-tuning pre-trained models has been ubiquitously proven to be effective\nin a wide range of NLP tasks. However, fine-tuning the whole model is parameter\ninefficient as it always yields an entirely new model for each task. Currently,\nmany research works propose to only fine-tune a small portion of the parameters\nwhile keeping most of the parameters shared across different tasks. These\nmethods achieve surprisingly good performance and are shown to be more stable\nthan their corresponding fully fine-tuned counterparts. However, such kind of\nmethods is still not well understood. Some natural questions arise: How does\nthe parameter sparsity lead to promising performance? Why is the model more\nstable than the fully fine-tuned models? How to choose the tunable parameters?\nIn this paper, we first categorize the existing methods into random approaches,\nrule-based approaches, and projection-based approaches based on how they choose\nwhich parameters to tune. Then, we show that all of the methods are actually\nsparse fine-tuned models and conduct a novel theoretical analysis of them. We\nindicate that the sparsity is actually imposing a regularization on the\noriginal model by controlling the upper bound of the stability. Such stability\nleads to better generalization capability which has been empirically observed\nin a lot of recent research works. Despite the effectiveness of sparsity\ngrounded by our theory, it still remains an open problem of how to choose the\ntunable parameters. To better choose the tunable parameters, we propose a novel\nSecond-order Approximation Method (SAM) which approximates the original problem\nwith an analytically solvable optimization function. The tunable parameters are\ndetermined by directly optimizing the approximation function. The experimental\nresults show that our proposed SAM model outperforms many strong baseline\nmodels and it also verifies our theoretical analysis.",
    "descriptor": "",
    "authors": [
      "Zihao Fu",
      "Haoran Yang",
      "Anthony Man-Cho So",
      "Wai Lam",
      "Lidong Bing",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15583"
  },
  {
    "id": "arXiv:2211.15588",
    "title": "Internet of Behaviors: A Survey",
    "abstract": "The Internet of Behavior is a research theme that aims to analyze human\nbehavior data on the Internet from the perspective of behavioral psychology,\nobtain insights about human behavior, and better understand the intention\nbehind the behavior. In this way, the Internet of Behavior can predict human\nbehavioral trends in the future and even change human behavior, which can\nprovide more convenience for human life. With the increasing prosperity of the\nInternet of Things, more and more behavior-related data is collected on the\nInternet by connected devices such as sensors. People and behavior are\nconnected through the extension of the Internet of Things -- the Internet of\nBehavior. At present, the Internet of Behavior has gradually been applied to\nour lives, but it is still in its early stages, and many opportunities and\nchallenges are emerging. This paper provides an in-depth overview of the\nfundamental aspects of the Internet of Behavior: (1) We introduce the\ndevelopment process and research status of the Internet of Behavior from the\nperspective of the Internet of Things. (2) We propose the characteristics of\nthe Internet of Behavior and define its development direction in terms of three\naspects: real-time, autonomy, and reliability. (3) We provide a comprehensive\nsummary of the current applications of the Internet of Behavior, including\nspecific discussions in five scenarios that give an overview of the application\nstatus of the Internet of Behavior. (4) We discuss the challenges of the\nInternet of Behavior's development and its future directions, which hopefully\nwill bring some progress to the Internet of Behavior. To the best of our\nknowledge, this is the first survey paper on the Internet of Behavior. We hope\nthat this in-depth review can provide some useful directions for more\nproductive research in related fields.",
    "descriptor": "\nComments: Preprint. 9 figures, 1 table\n",
    "authors": [
      "Jiayi Sun",
      "Wensheng Gan",
      "Han-Chieh Chao",
      "Philip S. Yu",
      "Weiping Ding"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.15588"
  },
  {
    "id": "arXiv:2211.15589",
    "title": "Inapplicable Actions Learning for Knowledge Transfer in Reinforcement  Learning",
    "abstract": "Reinforcement Learning (RL) algorithms are known to scale poorly to\nenvironments with many available actions, requiring numerous samples to learn\nan optimal policy. The traditional approach of considering the same fixed\naction space in every possible state implies that the agent must understand,\nwhile also learning to maximize its reward, to ignore irrelevant actions such\nas $\\textit{inapplicable actions}$ (i.e. actions that have no effect on the\nenvironment when performed in a given state). Knowing this information can help\nreduce the sample complexity of RL algorithms by masking the inapplicable\nactions from the policy distribution to only explore actions relevant to\nfinding an optimal policy. This is typically done in an ad-hoc manner with\nhand-crafted domain logic added to the RL algorithm. In this paper, we propose\na more systematic approach to introduce this knowledge into the algorithm. We\n(i) standardize the way knowledge can be manually specified to the agent; and\n(ii) present a new framework to autonomously learn these state-dependent action\nconstraints jointly with the policy. We show experimentally that learning\ninapplicable actions greatly improves the sample efficiency of the algorithm by\nproviding a reliable signal to mask out irrelevant actions. Moreover, we\ndemonstrate that thanks to the transferability of the knowledge acquired, it\ncan be reused in other tasks to make the learning process more efficient.",
    "descriptor": "",
    "authors": [
      "Leo Ardon",
      "Alberto Pozanco",
      "Daniel Borrajo",
      "Sumitra Ganesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15589"
  },
  {
    "id": "arXiv:2211.15590",
    "title": "A Bayesian Approach to Reconstructing Interdependent Infrastructure  Networks from Cascading Failures",
    "abstract": "Analyzing the behavior of complex interdependent networks requires complete\ninformation about the network topology and the interdependent links across\nnetworks. For many applications such as critical infrastructure systems,\nunderstanding network interdependencies is crucial to anticipate cascading\nfailures and plan for disruptions. However, data on the topology of individual\nnetworks are often publicly unavailable due to privacy and security concerns.\nAdditionally, interdependent links are often only revealed in the aftermath of\na disruption as a result of cascading failures. We propose a scalable\nnonparametric Bayesian approach to reconstruct the topology of interdependent\ninfrastructure networks from observations of cascading failures.\nMetropolis-Hastings algorithm coupled with the infrastructure-dependent\nproposal are employed to increase the efficiency of sampling possible graphs.\nResults of reconstructing a synthetic system of interdependent infrastructure\nnetworks demonstrate that the proposed approach outperforms existing methods in\nboth accuracy and computational time. We further apply this approach to\nreconstruct the topology of one synthetic and two real-world systems of\ninterdependent infrastructure networks, including gas-power-water networks in\nShelby County, TN, USA, and an interdependent system of power-water networks in\nItaly, to demonstrate the general applicability of the approach.",
    "descriptor": "",
    "authors": [
      "Yu Wang",
      "Jin-Zhu Yu",
      "Hiba Baroud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.15590"
  },
  {
    "id": "arXiv:2211.15593",
    "title": "GPT-Neo for commonsense reasoning-a theoretical and practical lens",
    "abstract": "Recent work has demonstrated substantial gains in pre-training large-scale\nunidirectional language models such as the GPT-2, GPT-3, and GPT-neo, followed\nby fine-tuning on a downstream task. In this paper, we evaluate the performance\nof the GPT-neo 1.3 billion model for commonsense reasoning tasks. We assess the\nmodel performance on six commonsense reasoning benchmark tasks and report the\naccuracy scores for these tasks. When fine-tuned using the right set of\nhyperparameters, we obtain competitive scores on three of these tasks but\nstruggle when the dataset size is significantly smaller. The low model\nperformance on a few of these tasks suggests the inherent difficulty in these\ndatasets and since it fails to establish coherent patterns given their limited\ntraining samples. We also investigate and substantiate our results using\nvisualization and conduct numerous inference tests to understand the model\nperformance better. Finally, we conduct thorough robustness tests using various\nmethods to gauge the model performance under numerous settings. These findings\nsuggest a promising path for exploring smaller language models than the GPT-3\n175 billion model to perform tasks requiring natural language understanding.",
    "descriptor": "\nComments: 6 Pages\n",
    "authors": [
      "Rohan Kashyap",
      "Vivek Kashyap",
      "Narendra C.P"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15593"
  },
  {
    "id": "arXiv:2211.15595",
    "title": "FsaNet: Frequency Self-attention for Semantic Segmentation",
    "abstract": "Considering the spectral properties of images, we propose a new\nself-attention mechanism with highly reduced computational complexity, up to a\nlinear rate. To better preserve edges while promoting similarity within\nobjects, we propose individualized processes over different frequency bands. In\nparticular, we study a case where the process is merely over low-frequency\ncomponents. By ablation study, we show that low frequency self-attention can\nachieve very close or better performance relative to full frequency even\nwithout retraining the network. Accordingly, we design and embed novel\nplug-and-play modules to the head of a CNN network that we refer to as FsaNet.\nThe frequency self-attention 1) takes low frequency coefficients as input, 2)\ncan be mathematically equivalent to spatial domain self-attention with linear\nstructures, 3) simplifies token mapping ($1\\times1$ convolution) stage and\ntoken mixing stage simultaneously. We show that the frequency self-attention\nrequires $87.29\\% \\sim 90.04\\%$ less memory, $96.13\\% \\sim 98.07\\%$ less FLOPs,\nand $97.56\\% \\sim 98.18\\%$ in run time than the regular self-attention.\nCompared to other ResNet101-based self-attention networks, FsaNet achieves a\nnew state-of-the-art result ($83.0\\%$ mIoU) on Cityscape test dataset and\ncompetitive results on ADE20k and VOCaug.",
    "descriptor": "",
    "authors": [
      "Fengyu Zhang",
      "Ashkan Panahi",
      "Guangjun Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15595"
  },
  {
    "id": "arXiv:2211.15596",
    "title": "A survey of deep learning optimizers-first and second order methods",
    "abstract": "Deep Learning optimization involves minimizing a high-dimensional loss\nfunction in the weight space which is often perceived as difficult due to its\ninherent difficulties such as saddle points, local minima, ill-conditioning of\nthe Hessian and limited compute resources. In this paper, we provide a\ncomprehensive review of 12 standard optimization methods successfully used in\ndeep learning research and a theoretical assessment of the difficulties in\nnumerical optimization from the optimization literature.",
    "descriptor": "\nComments: 19 Pages\n",
    "authors": [
      "Rohan V Kashyap"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15596"
  },
  {
    "id": "arXiv:2211.15597",
    "title": "Lightning Fast Video Anomaly Detection via Adversarial Knowledge  Distillation",
    "abstract": "We propose a very fast frame-level model for anomaly detection in video,\nwhich learns to detect anomalies by distilling knowledge from multiple highly\naccurate object-level teacher models. To improve the fidelity of our student,\nwe distill the low-resolution anomaly maps of the teachers by jointly applying\nstandard and adversarial distillation, introducing an adversarial discriminator\nfor each teacher to distinguish between target and generated anomaly maps. We\nconduct experiments on three benchmarks (Avenue, ShanghaiTech, UCSD Ped2),\nshowing that our method is over 7 times faster than the fastest competing\nmethod, and between 28 and 62 times faster than object-centric models, while\nobtaining comparable results to recent methods. Our evaluation also indicates\nthat our model achieves the best trade-off between speed and accuracy, due to\nits previously unheard-of speed of 1480 FPS. In addition, we carry out a\ncomprehensive ablation study to justify our architectural design choices.",
    "descriptor": "",
    "authors": [
      "Nicolae-Catalin Ristea",
      "Florinel-Alin Croitoru",
      "Dana Dascalescu",
      "Radu Tudor Ionescu",
      "Fahad Shahbaz Khan",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15597"
  },
  {
    "id": "arXiv:2211.15600",
    "title": "Measurement, Analysis, and Insight of NFTs Transaction Networks",
    "abstract": "Non-fungible tokens (NFTs) are unique digital items with blockchain managed\nownership. Ethereum blockchain based smart contract created the environment for\nNFTs (ERC721) to reach its one of the most important future application\ndomains. Non fungible tokens got more attention when the market saw record\nbreaking sales in 2021. Virtually anything of value can be traced and traded on\nthe blockchain network by minting them as NFTs. NFTs provide the users with a\ndecentralized proof of ownership representation, as every transaction and trade\nof NFTs gets recorded in the Ethereum network blocks. The value of NFTs is\nderived from their being non fungible meaning that the token cannot be replaced\nwith an identical token (giving it inherent scarcity). In this paper, we study\nthe growth rate and evolutionary nature of the NFT network and try to\nunderstand the NFT ecosystem. We explore the evolving nature of the NFT\ninteraction network from a temporal graph perspective. We study the growth rate\nand observer the semantics of the network. Here on the observer network, we\nwill run two graph algorithms on the dataset. Lastly, observe and forecast the\nsurvival of NFTs bubble by applying the Logarithmic periodic power law (LPPL)\nmodel to the time series data on one of the most famous NFT collections\nCryptoPunks (predicting price increase), which has seen sales of around $23.7\nmillion around mid of 2021.",
    "descriptor": "\nComments: 10 pages, 12 figures, A class project\n",
    "authors": [
      "Prakhyat Khati"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.15600"
  },
  {
    "id": "arXiv:2211.15601",
    "title": "Fast-SNARF: A Fast Deformer for Articulated Neural Fields",
    "abstract": "Neural fields have revolutionized the area of 3D reconstruction and novel\nview synthesis of rigid scenes. A key challenge in making such methods\napplicable to articulated objects, such as the human body, is to model the\ndeformation of 3D locations between the rest pose (a canonical space) and the\ndeformed space. We propose a new articulation module for neural fields,\nFast-SNARF, which finds accurate correspondences between canonical space and\nposed space via iterative root finding. Fast-SNARF is a drop-in replacement in\nfunctionality to our previous work, SNARF, while significantly improving its\ncomputational efficiency. We contribute several algorithmic and implementation\nimprovements over SNARF, yielding a speed-up of $150\\times$. These improvements\ninclude voxel-based correspondence search, pre-computing the linear blend\nskinning function, and an efficient software implementation with CUDA kernels.\nFast-SNARF enables efficient and simultaneous optimization of shape and\nskinning weights given deformed observations without correspondences (e.g. 3D\nmeshes). Because learning of deformation maps is a crucial component in many 3D\nhuman avatar methods and since Fast-SNARF provides a computationally efficient\nsolution, we believe that this work represents a significant step towards the\npractical creation of 3D virtual humans.",
    "descriptor": "\nComments: github page: this https URL\n",
    "authors": [
      "Xu Chen",
      "Tianjian Jiang",
      "Jie Song",
      "Max Rietmann",
      "Andreas Geiger",
      "Michael J. Black",
      "Otmar Hilliges"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15601"
  },
  {
    "id": "arXiv:2211.15602",
    "title": "Some Upper Bounds on the Running Time of Policy Iteration on  Deterministic MDPs",
    "abstract": "Policy Iteration (PI) is a widely used family of algorithms to compute\noptimal policies for Markov Decision Problems (MDPs). We derive upper bounds on\nthe running time of PI on Deterministic MDPs (DMDPs): the class of MDPs in\nwhich every state-action pair has a unique next state. Our results include a\nnon-trivial upper bound that applies to the entire family of PI algorithms, and\naffirmation that a conjecture regarding Howard's PI on MDPs is true for DMDPs.\nOur analysis is based on certain graph-theoretic results, which may be of\nindependent interest.",
    "descriptor": "",
    "authors": [
      "Ritesh Goenka",
      "Eashan Gupta",
      "Sushil Khyalia",
      "Pratyush Agarwal",
      "Mulinti Shaik Wajid",
      "Shivaram Kalyanakrishnan"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.15602"
  },
  {
    "id": "arXiv:2211.15603",
    "title": "Action-GPT: Leveraging Large-scale Language Models for Improved and  Generalized Zero Shot Action Generation",
    "abstract": "We introduce Action-GPT, a plug and play framework for incorporating Large\nLanguage Models (LLMs) into text-based action generation models. Action phrases\nin current motion capture datasets contain minimal and to-the-point\ninformation. By carefully crafting prompts for LLMs, we generate richer and\nfine-grained descriptions of the action. We show that utilizing these detailed\ndescriptions instead of the original action phrases leads to better alignment\nof text and motion spaces. Our experiments show qualitative and quantitative\nimprovement in the quality of synthesized motions produced by recent\ntext-to-motion models. Code, pretrained models and sample videos will be made\navailable at https://actiongpt.github.io",
    "descriptor": "\nComments: WIP. Code, pretrained models and sample videos will be made available at \\url{this https URL}\n",
    "authors": [
      "Sai Shashank Kalakonda",
      "Shubh Maheshwari",
      "Ravi Kiran Sarvadevabhatla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.15603"
  },
  {
    "id": "arXiv:2211.15605",
    "title": "Development of an Equation-based Parallelization Method for Multiphase  Particle-in-Cell Simulations",
    "abstract": "Manufacturers have been developing new graphics processing unit (GPU) nodes\nwith large capacity, high bandwidth memory and very high bandwidth intra-node\ninterconnects. This enables moving large amounts of data between GPUs on the\nsame node at low cost. However, small packet bandwidths and latencies have not\ndecreased which makes global dot products expensive. These characteristics\nfavor a new kind of problem decomposition called \"equation decomposition\"\nrather than traditional domain decomposition. In this approach, each GPU is\nassigned one equation set to solve in parallel so that the frequent and\nexpensive dot product synchronization points in traditional distributed linear\nsolvers are eliminated. In exchange, the method involves infrequent movement of\nstate variables over the high bandwidth, intra-node interconnects. To test this\ntheory, our flagship code Multiphase Flow with Interphase eXchanges (MFiX) was\nported to TensorFlow. This new product is known as MFiX-AI and can produce near\nidentical results to the original version of MFiX with significant acceleration\nin multiphase particle-in-cell (MP-PIC) simulations. The performance of a\nsingle node with 4 NVIDIA A100s connected over NVLINK 2.0 was shown to be\ncompetitive to 1000 CPU cores (25 nodes) on the JOULE 2.0 supercomputer,\nleading to an energy savings of up to 90%. This is a substantial performance\nbenefit for small- to intermediate-sized problems. This benefit is expected to\ngrow as GPU nodes become more powerful. Further, MFiX-AI is poised to accept\nnative artificial intelligence/machine learning models for further acceleration\nand development.",
    "descriptor": "\nComments: 28 pages, 11 figures\n",
    "authors": [
      "Mino Woo",
      "Terry Jordan",
      "Tarak Nandi",
      "Jean Francois Dietiker",
      "Christopher Guenther",
      "Dirk Van Essendelft"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Mathematical Software (cs.MS)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.15605"
  },
  {
    "id": "arXiv:2211.15608",
    "title": "Representation with Incomplete Votes",
    "abstract": "Platforms for online civic participation rely heavily on methods for\ncondensing thousands of comments into a relevant handful based on whether\nparticipants agree or disagree with them. We argue that these methods should\nguarantee fair representation of the participants, as their outcomes may affect\nthe health of the conversation and inform impactful downstream decisions. To\nthat end, we draw on the literature on approval-based committee elections. Our\nsetting is novel in that the approval votes are incomplete since participants\nwill typically not vote on all comments. We prove that this complication\nrenders non-adaptive algorithms impractical in terms of the amount of\ninformation they must gather. Therefore, we develop an adaptive algorithm that\nuses information more efficiently by presenting incoming participants with\nstatements that appear promising based on votes by previous participants. We\nprove that this method satisfies commonly used notions of fair representation,\neven when participants only vote on a small fraction of comments. Finally, an\nempirical evaluation on real data shows that the proposed algorithm provides\nrepresentative outcomes in practice.",
    "descriptor": "",
    "authors": [
      "Daniel Halpern",
      "Gregory Kehne",
      "Ariel D. Procaccia",
      "Jamie Tucker-Foltz",
      "Manuel W\u00fcthrich"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.15608"
  },
  {
    "id": "arXiv:2211.15611",
    "title": "Special Cases of the Minimum Spanning Tree Problem under Explorable Edge  and Vertex Uncertainty",
    "abstract": "This article studies the Minimum Spanning Tree Problem under Explorable\nUncertainty as well as a related vertex uncertainty version of the problem. We\nparticularly consider special instance types, including cactus graphs, for\nwhich we provide randomized algorithms. We introduce the problem of finding a\nminimum weight spanning star under uncertainty for which we show that no\nalgorithm can achieve constant competitive ratio.",
    "descriptor": "",
    "authors": [
      "Corinna Mathwieser",
      "Eranda Cela"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15611"
  },
  {
    "id": "arXiv:2211.15612",
    "title": "Learning From Good Trajectories in Offline Multi-Agent Reinforcement  Learning",
    "abstract": "Offline multi-agent reinforcement learning (MARL) aims to learn effective\nmulti-agent policies from pre-collected datasets, which is an important step\ntoward the deployment of multi-agent systems in real-world applications.\nHowever, in practice, each individual behavior policy that generates\nmulti-agent joint trajectories usually has a different level of how well it\nperforms. e.g., an agent is a random policy while other agents are medium\npolicies. In the cooperative game with global reward, one agent learned by\nexisting offline MARL often inherits this random policy, jeopardizing the\nperformance of the entire team. In this paper, we investigate offline MARL with\nexplicit consideration on the diversity of agent-wise trajectories and propose\na novel framework called Shared Individual Trajectories (SIT) to address this\nproblem. Specifically, an attention-based reward decomposition network assigns\nthe credit to each agent through a differentiable key-value memory mechanism in\nan offline manner. These decomposed credits are then used to reconstruct the\njoint offline datasets into prioritized experience replay with individual\ntrajectories, thereafter agents can share their good trajectories and\nconservatively train their policies with a graph attention network (GAT) based\ncritic. We evaluate our method in both discrete control (i.e., StarCraft II and\nmulti-agent particle environment) and continuous control (i.e, multi-agent\nmujoco). The results indicate that our method achieves significantly better\nresults in complex and mixed offline multi-agent datasets, especially when the\ndifference of data quality between individual trajectories is large.",
    "descriptor": "",
    "authors": [
      "Qi Tian",
      "Kun Kuang",
      "Furui Liu",
      "Baoxiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15612"
  },
  {
    "id": "arXiv:2211.15613",
    "title": "Frustratingly Easy Label Projection for Cross-lingual Transfer",
    "abstract": "Translating training data into many languages has emerged as a practical\nsolution for improving cross-lingual transfer. For tasks that involve\nspan-level annotations, such as information extraction or question answering,\nan additional label projection step is required to map annotated spans onto the\ntranslated texts. Recently, a few efforts have utilized a simple\nmark-then-translate method to jointly perform translation and projection by\ninserting special markers around the labeled spans in the original sentence.\nHowever, as far as we are aware, no empirical analysis has been conducted on\nhow this approach compares to traditional annotation projection based on word\nalignment. In this paper, we present an extensive empirical study across 42\nlanguages and three tasks (QA, NER, and Event Extraction) to evaluate the\neffectiveness and limitations of both methods, filling an important gap in the\nliterature. Experimental results show that our optimized version of\nmark-then-translate, which we call EasyProject, is easily applied to many\nlanguages and works surprisingly well, outperforming the more complex word\nalignment-based methods. We analyze several key factors that affect end-task\nperformance, and show EasyProject works well because it can accurately preserve\nlabel span boundaries after translation. We will publicly release all our code\nand data.",
    "descriptor": "",
    "authors": [
      "Yang Chen",
      "Chao Jiang",
      "Alan Ritter",
      "Wei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15613"
  },
  {
    "id": "arXiv:2211.15616",
    "title": "Weight Predictor Network with Feature Selection for Small Sample Tabular  Biomedical Data",
    "abstract": "Tabular biomedical data is often high-dimensional but with a very small\nnumber of samples. Although recent work showed that well-regularised simple\nneural networks could outperform more sophisticated architectures on tabular\ndata, they are still prone to overfitting on tiny datasets with many\npotentially irrelevant features. To combat these issues, we propose Weight\nPredictor Network with Feature Selection (WPFS) for learning neural networks\nfrom high-dimensional and small sample data by reducing the number of learnable\nparameters and simultaneously performing feature selection. In addition to the\nclassification network, WPFS uses two small auxiliary networks that together\noutput the weights of the first layer of the classification model. We evaluate\non nine real-world biomedical datasets and demonstrate that WPFS outperforms\nother standard as well as more recent methods typically applied to tabular\ndata. Furthermore, we investigate the proposed feature selection mechanism and\nshow that it improves performance while providing useful insights into the\nlearning task.",
    "descriptor": "\nComments: Accepted to AAAI-2023\n",
    "authors": [
      "Andrei Margeloiu",
      "Nikola Simidjievski",
      "Pietro Lio",
      "Mateja Jamnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15616"
  },
  {
    "id": "arXiv:2211.15621",
    "title": "A Boosting Approach to Constructing an Ensemble Stack",
    "abstract": "An approach to evolutionary ensemble learning for classification is proposed\nin which boosting is used to construct a stack of programs. Each application of\nboosting identifies a single champion and a residual dataset, i.e. the training\nrecords that thus far were not correctly classified. The next program is only\ntrained against the residual, with the process iterating until some maximum\nensemble size or no further residual remains. Training against a residual\ndataset actively reduces the cost of training. Deploying the ensemble as a\nstack also means that only one classifier might be necessary to make a\nprediction, so improving interpretability. Benchmarking studies are conducted\nto illustrate competitiveness with the prediction accuracy of current\nstate-of-the-art evolutionary ensemble learning algorithms, while providing\nsolutions that are orders of magnitude simpler. Further benchmarking with a\nhigh cardinality dataset indicates that the proposed method is also more\naccurate and efficient than XGBoost.",
    "descriptor": "\nComments: 16 pages, 3 figures, 6 tables\n",
    "authors": [
      "Zhilei Zhou",
      "Ziyu Qiu",
      "Brad Niblett",
      "Andrew Johnston",
      "Jeffrey Schwartzentruber",
      "Nur Zincir-Heywood",
      "Malcolm Heywood"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.15621"
  },
  {
    "id": "arXiv:2211.15634",
    "title": "High-performance xPU Stencil Computations in Julia",
    "abstract": "We present an efficient approach for writing architecture-agnostic parallel\nhigh-performance stencil computations in Julia, which is instantiated in the\npackage ParallelStencil.jl. Powerful metaprogramming, costless abstractions and\nmultiple dispatch enable writing a single code that is suitable for both\nproductive prototyping on a single CPU thread and production runs on multi-GPU\nor CPU workstations or supercomputers. We demonstrate performance close to the\ntheoretical upper bound on GPUs for a 3-D heat diffusion solver, which is a\nmassive improvement over reachable performance with CUDA.jl Array programming.",
    "descriptor": "\nComments: submitted to JuliaCon Proceedings 2022\n",
    "authors": [
      "Samuel Omlin",
      "Ludovic R\u00e4ss"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.15634"
  },
  {
    "id": "arXiv:2211.15643",
    "title": "A posteriori error bounds for the block-Lanczos method for matrix  function approximation",
    "abstract": "We extend the error bounds from [SIMAX, Vol. 43, Iss. 2, pp. 787-811 (2022)]\nfor the Lanczos method for matrix function approximation to the block\nalgorithm. Numerical experiments suggest that our bounds are fairly robust to\nchanging block size. Further experiments work towards a better understanding of\nhow certain hyperparameters should be chosen in order to maximize the quality\nof the error bounds.",
    "descriptor": "",
    "authors": [
      "Qichen Xu",
      "Tyler Chen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15643"
  },
  {
    "id": "arXiv:2211.15644",
    "title": "Efficient Mirror Detection via Multi-level Heterogeneous Learning",
    "abstract": "We present HetNet (Multi-level \\textbf{Het}erogeneous \\textbf{Net}work), a\nhighly efficient mirror detection network. Current mirror detection methods\nfocus more on performance than efficiency, limiting the real-time applications\n(such as drones). Their lack of efficiency is aroused by the common design of\nadopting homogeneous modules at different levels, which ignores the difference\nbetween different levels of features. In contrast, HetNet detects potential\nmirror regions initially through low-level understandings (\\textit{e.g.},\nintensity contrasts) and then combines with high-level understandings\n(contextual discontinuity for instance) to finalize the predictions. To perform\naccurate yet efficient mirror detection, HetNet follows an effective\narchitecture that obtains specific information at different stages to detect\nmirrors. We further propose a multi-orientation intensity-based contrasted\nmodule (MIC) and a reflection semantic logical module (RSL), equipped on\nHetNet, to predict potential mirror regions by low-level understandings and\nanalyze semantic logic in scenarios by high-level understandings, respectively.\nCompared to the state-of-the-art method, HetNet runs 664$\\%$ faster and draws\nan average performance gain of 8.9$\\%$ on MAE, 3.1$\\%$ on IoU, and 2.0$\\%$ on\nF-measure on two mirror detection benchmarks.",
    "descriptor": "\nComments: Accepted to AAAI 2023. The code is available at this https URL\n",
    "authors": [
      "Ruozhen He",
      "Jiaying Lin",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15644"
  },
  {
    "id": "arXiv:2211.15649",
    "title": "Beyond Counting Datasets: A Survey of Multilingual Dataset Construction  and Necessary Resources",
    "abstract": "While the NLP community is generally aware of resource disparities among\nlanguages, we lack research that quantifies the extent and types of such\ndisparity. Prior surveys estimating the availability of resources based on the\nnumber of datasets can be misleading as dataset quality varies: many datasets\nare automatically induced or translated from English data. To provide a more\ncomprehensive picture of language resources, we examine the characteristics of\n156 publicly available NLP datasets. We manually annotate how they are created,\nincluding input text and label sources and tools used to build them, and what\nthey study, tasks they address and motivations for their creation. After\nquantifying the qualitative NLP resource gap across languages, we discuss how\nto improve data collection in low-resource languages. We survey\nlanguage-proficient NLP researchers and crowd workers per language, finding\nthat their estimated availability correlates with dataset availability. Through\ncrowdsourcing experiments, we identify strategies for collecting high-quality\nmultilingual data on the Mechanical Turk platform. We conclude by making macro\nand micro-level suggestions to the NLP community and individual researchers for\nfuture multilingual data development.",
    "descriptor": "\nComments: Accepted to Findings of EMNLP 2022. You can view our annotations, contribute to our survey, and view the analysis visualizations on our website at this https URL\n",
    "authors": [
      "Xinyan Velocity Yu",
      "Akari Asai",
      "Trina Chatterjee",
      "Junjie Hu",
      "Eunsol Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15649"
  },
  {
    "id": "arXiv:2211.15654",
    "title": "OpenScene: 3D Scene Understanding with Open Vocabularies",
    "abstract": "Traditional 3D scene understanding approaches rely on labeled 3D datasets to\ntrain a model for a single task with supervision. We propose OpenScene, an\nalternative approach where a model predicts dense features for 3D scene points\nthat are co-embedded with text and image pixels in CLIP feature space. This\nzero-shot approach enables task-agnostic training and open-vocabulary queries.\nFor example, to perform SOTA zero-shot 3D semantic segmentation it first infers\nCLIP features for every 3D point and later classifies them based on\nsimilarities to embeddings of arbitrary class labels. More interestingly, it\nenables a suite of open-vocabulary scene understanding applications that have\nnever been done before. For example, it allows a user to enter an arbitrary\ntext query and then see a heat map indicating which parts of a scene match. Our\napproach is effective at identifying objects, materials, affordances,\nactivities, and room types in complex 3D scenes, all using a single model\ntrained without any labeled 3D data.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Songyou Peng",
      "Kyle Genova",
      "Chiyu \"Max\" Jiang",
      "Andrea Tagliasacchi",
      "Marc Pollefeys",
      "Thomas Funkhouser"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15654"
  },
  {
    "id": "arXiv:2211.15656",
    "title": "SuperFusion: Multilevel LiDAR-Camera Fusion for Long-Range HD Map  Generation and Prediction",
    "abstract": "High-definition (HD) semantic map generation of the environment is an\nessential component of autonomous driving. Existing methods have achieved good\nperformance in this task by fusing different sensor modalities, such as LiDAR\nand camera. However, current works are based on raw data or network\nfeature-level fusion and only consider short-range HD map generation, limiting\ntheir deployment to realistic autonomous driving applications. In this paper,\nwe focus on the task of building the HD maps in both short ranges, i.e., within\n30 m, and also predicting long-range HD maps up to 90 m, which is required by\ndownstream path planning and control tasks to improve the smoothness and safety\nof autonomous driving. To this end, we propose a novel network named\nSuperFusion, exploiting the fusion of LiDAR and camera data at multiple levels.\nWe benchmark our SuperFusion on the nuScenes dataset and a self-recorded\ndataset and show that it outperforms the state-of-the-art baseline methods with\nlarge margins. Furthermore, we propose a new metric to evaluate the long-range\nHD map prediction and apply the generated HD map to a downstream path planning\ntask. The results show that by using the long-range HD maps predicted by our\nmethod, we can make better path planning for autonomous vehicles. The code will\nbe available at https://github.com/haomo-ai/SuperFusion.",
    "descriptor": "",
    "authors": [
      "Hao Dong",
      "Xianjing Zhang",
      "Xuan Jiang",
      "Jun Zhang",
      "Jintao Xu",
      "Rui Ai",
      "Weihao Gu",
      "Huimin Lu",
      "Juho Kannala",
      "Xieyuanli Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15656"
  },
  {
    "id": "arXiv:2211.15657",
    "title": "Is Conditional Generative Modeling all you need for Decision-Making?",
    "abstract": "Recent improvements in conditional generative modeling have made it possible\nto generate high-quality images from language descriptions alone. We\ninvestigate whether these methods can directly address the problem of\nsequential decision-making. We view decision-making not through the lens of\nreinforcement learning (RL), but rather through conditional generative\nmodeling. To our surprise, we find that our formulation leads to policies that\ncan outperform existing offline RL approaches across standard benchmarks. By\nmodeling a policy as a return-conditional diffusion model, we illustrate how we\nmay circumvent the need for dynamic programming and subsequently eliminate many\nof the complexities that come with traditional offline RL. We further\ndemonstrate the advantages of modeling policies as conditional diffusion models\nby considering two other conditioning variables: constraints and skills.\nConditioning on a single constraint or skill during training leads to behaviors\nat test-time that can satisfy several constraints together or demonstrate a\ncomposition of skills. Our results illustrate that conditional generative\nmodeling is a powerful tool for decision-making.",
    "descriptor": "\nComments: Website: this https URL\n",
    "authors": [
      "Anurag Ajay",
      "Yilun Du",
      "Abhi Gupta",
      "Joshua Tenenbaum",
      "Tommi Jaakkola",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15657"
  },
  {
    "id": "arXiv:2211.15658",
    "title": "Connecting the Dots: Floorplan Reconstruction Using Two-Level Queries",
    "abstract": "We address 2D floorplan reconstruction from 3D scans. Existing approaches\ntypically employ heuristically designed multi-stage pipelines. Instead, we\nformulate floorplan reconstruction as a single-stage structured prediction\ntask: find a variable-size set of polygons, which in turn are variable-length\nsequences of ordered vertices. To solve it we develop a novel Transformer\narchitecture that generates polygons of multiple rooms in parallel, in a\nholistic manner without hand-crafted intermediate stages. The model features\ntwo-level queries for polygons and corners, and includes polygon matching to\nmake the network end-to-end trainable. Our method achieves a new\nstate-of-the-art for two challenging datasets, Structured3D and SceneCAD, along\nwith significantly faster inference than previous methods. Moreover, it can\nreadily be extended to predict additional information, i.e., semantic room\ntypes and architectural elements like doors and windows. Our code and models\nwill be available at: https://github.com/ywyue/RoomFormer.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yuanwen Yue",
      "Theodora Kontogianni",
      "Konrad Schindler",
      "Francis Engelmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15658"
  },
  {
    "id": "arXiv:2211.15660",
    "title": "Satlas: A Large-Scale, Multi-Task Dataset for Remote Sensing Image  Understanding",
    "abstract": "Remote sensing images are useful for a wide variety of environmental and\nearth monitoring tasks, including tracking deforestation, illegal fishing,\nurban expansion, and natural disasters. The earth is extremely diverse -- the\namount of potential tasks in remote sensing images is massive, and the sizes of\nfeatures range from several kilometers to just tens of centimeters. However,\ncreating generalizable computer vision methods is a challenge in part due to\nthe lack of a large-scale dataset that captures these diverse features for many\ntasks. In this paper, we present Satlas, a remote sensing dataset and benchmark\nthat is large in both breadth, featuring all of the aforementioned applications\nand more, as well as scale, comprising 290M labels under 137 categories and\nseven label modalities. We evaluate eight baselines and a proposed method on\nSatlas, and find that there is substantial room for improvement in addressing\nresearch challenges specific to remote sensing, including processing image time\nseries that consist of images from very different types of sensors, and taking\nadvantage of long-range spatial context. We also find that pre-training on\nSatlas substantially improves performance on downstream tasks with few labeled\nexamples, increasing average accuracy by 16% over ImageNet and 5% over the next\nbest baseline.",
    "descriptor": "",
    "authors": [
      "Favyen Bastani",
      "Piper Wolters",
      "Ritwik Gupta",
      "Joe Ferdinando",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15660"
  },
  {
    "id": "arXiv:2211.15661",
    "title": "What learning algorithm is in-context learning? Investigations with  linear models",
    "abstract": "Neural sequence models, especially transformers, exhibit a remarkable\ncapacity for in-context learning. They can construct new predictors from\nsequences of labeled examples $(x, f(x))$ presented in the input without\nfurther parameter updates. We investigate the hypothesis that transformer-based\nin-context learners implement standard learning algorithms implicitly, by\nencoding smaller models in their activations, and updating these implicit\nmodels as new examples appear in the context. Using linear regression as a\nprototypical problem, we offer three sources of evidence for this hypothesis.\nFirst, we prove by construction that transformers can implement learning\nalgorithms for linear models based on gradient descent and closed-form ridge\nregression. Second, we show that trained in-context learners closely match the\npredictors computed by gradient descent, ridge regression, and exact\nleast-squares regression, transitioning between different predictors as\ntransformer depth and dataset noise vary, and converging to Bayesian estimators\nfor large widths and depths. Third, we present preliminary evidence that\nin-context learners share algorithmic features with these predictors: learners'\nlate layers non-linearly encode weight vectors and moment matrices. These\nresults suggest that in-context learning is understandable in algorithmic\nterms, and that (at least in the linear case) learners may rediscover standard\nestimation algorithms. Code and reference implementations released at this\n$\\href{https://github.com/ekinakyurek/google-research/blob/master/incontext}{http\\,link}$.",
    "descriptor": "\nComments: 28 pages, 8 figures\n",
    "authors": [
      "Ekin Aky\u00fcrek",
      "Dale Schuurmans",
      "Jacob Andreas",
      "Tengyu Ma",
      "Denny Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15661"
  },
  {
    "id": "arXiv:2211.15662",
    "title": "High-fidelity 3D GAN Inversion by Pseudo-multi-view Optimization",
    "abstract": "We present a high-fidelity 3D generative adversarial network (GAN) inversion\nframework that can synthesize photo-realistic novel views while preserving\nspecific details of the input image. High-fidelity 3D GAN inversion is\ninherently challenging due to the geometry-texture trade-off in 3D inversion,\nwhere overfitting to a single view input image often damages the estimated\ngeometry during the latent optimization. To solve this challenge, we propose a\nnovel pipeline that builds on the pseudo-multi-view estimation with visibility\nanalysis. We keep the original textures for the visible parts and utilize\ngenerative priors for the occluded parts. Extensive experiments show that our\napproach achieves advantageous reconstruction and novel view synthesis quality\nover state-of-the-art methods, even for images with out-of-distribution\ntextures. The proposed pipeline also enables image attribute editing with the\ninverted latent code and 3D-aware texture modification. Our approach enables\nhigh-fidelity 3D rendering from a single image, which is promising for various\napplications of AI-generated 3D content.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Jiaxin Xie",
      "Hao Ouyang",
      "Jingtan Piao",
      "Chenyang Lei",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15662"
  },
  {
    "id": "arXiv:2211.15663",
    "title": "Hand-Object Interaction Image Generation",
    "abstract": "In this work, we are dedicated to a new task, i.e., hand-object interaction\nimage generation, which aims to conditionally generate the hand-object image\nunder the given hand, object and their interaction status. This task is\nchallenging and research-worthy in many potential application scenarios, such\nas AR/VR games and online shopping, etc. To address this problem, we propose a\nnovel HOGAN framework, which utilizes the expressive model-aware hand-object\nrepresentation and leverages its inherent topology to build the unified surface\nspace. In this space, we explicitly consider the complex self- and mutual\nocclusion during interaction. During final image synthesis, we consider\ndifferent characteristics of hand and object and generate the target image in a\nsplit-and-combine manner. For evaluation, we build a comprehensive protocol to\naccess both the fidelity and structure preservation of the generated image.\nExtensive experiments on two large-scale datasets, i.e., HO3Dv3 and DexYCB,\ndemonstrate the effectiveness and superiority of our framework both\nquantitatively and qualitatively. The project page is available at\nhttps://play-with-hoi-generation.github.io/.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 (Spotlight); Project Page: this https URL\n",
    "authors": [
      "Hezhen Hu",
      "Weilun Wang",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15663"
  },
  {
    "id": "arXiv:2211.14311",
    "title": "Sub-1ms Instinctual Interference Adaptive GaN LNA Front-End with Power  and Linearity Tuning",
    "abstract": "One of the major challenges in communication, radar, and electronic warfare\nreceivers arises from nearby device interference. The paper presents a 2-6 GHz\nGaN LNA front-end with onboard sensing, processing, and feedback utilizing\nmicrocontroller-based controls to achieve adaptation to a variety of\ninterference scenarios through power and linearity regulations. The utilization\nof GaN LNA provides high power handling capability (30 dBm) and high linearity\n(OIP3= 30 dBm) for radar and EW applications. The system permits an LNA power\nconsumption to tune from 500 mW to 2 W (4X increase) in order to adjust the\nlinearity from P\\textsubscript{1dB,IN}=-10.5 dBm to 0.5 dBm (>10X increase).\nAcross the tuning range, the noise figure increases by approximately 0.4 dB.\nFeedback control methods are presented with backgrounds from control theory.\nThe rest of the controls consume $\\leq$10$\\%$ (100 mW) of nominal LNA power (1\nW) to achieve an adaptation time <1 ms.",
    "descriptor": "\nComments: 16 Pages, 22 Figures. Accepted in TMTT, to be published\n",
    "authors": [
      "Jie Yang",
      "Baibhab Chatterjee",
      "Mohammad Abu Khater",
      "Mattias Thorsell",
      "Sten E. Gunnarsson",
      "Tero Kiuru",
      "Shreyas Sen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14311"
  },
  {
    "id": "arXiv:2211.14312",
    "title": "Automated Deep Aberration Detection from Chromosome Karyotype Images",
    "abstract": "Chromosome analysis is essential for diagnosing genetic disorders. For\nhematologic malignancies, identification of somatic clonal aberrations by\nkaryotype analysis remains the standard of care. However, karyotyping is costly\nand time-consuming because of the largely manual process and the expertise\nrequired in identifying and annotating aberrations. Efforts to automate\nkaryotype analysis to date fell short in aberration detection. Using a training\nset of ~10k patient specimens and ~50k karyograms from over 5 years from the\nFred Hutchinson Cancer Center, we created a labeled set of images representing\nindividual chromosomes. These individual chromosomes were used to train and\nassess deep learning models for classifying the 24 human chromosomes and\nidentifying chromosomal aberrations. The top-accuracy models utilized the\nrecently introduced Topological Vision Transformers (TopViTs) with\n2-level-block-Toeplitz masking, to incorporate structural inductive bias.\nTopViT outperformed CNN (Inception) models with >99.3% accuracy for chromosome\nidentification, and exhibited accuracies >99% for aberration detection in most\naberrations. Notably, we were able to show high-quality performance even in\n\"few shot\" learning scenarios. Incorporating the definition of clonality\nsubstantially improved both precision and recall (sensitivity). When applied to\n\"zero shot\" scenarios, the model captured aberrations without training, with\nperfect precision at >50% recall. Together these results show that modern deep\nlearning models can approach expert-level performance for chromosome aberration\ndetection. To our knowledge, this is the first study demonstrating the\ndownstream effectiveness of TopViTs. These results open up exciting\nopportunities for not only expediting patient results but providing a scalable\ntechnology for early screening of low-abundance chromosomal lesions.",
    "descriptor": "",
    "authors": [
      "Zahra Shamsi",
      "Drew Bryant",
      "Jacob Wilson",
      "Xiaoyu Qu",
      "Avinava Dubey",
      "Konik Kothari",
      "Mostafa Dehghani",
      "Mariya Chavarha",
      "Valerii Likhosherstov",
      "Brian Williams",
      "Michael Frumkin",
      "Fred Appelbaum",
      "Krzysztof Choromanski",
      "Ali Bashir",
      "Min Fang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14312"
  },
  {
    "id": "arXiv:2211.14313",
    "title": "AICOM-MP: an AI-based Monkeypox Detector for Resource-Constrained  Environments",
    "abstract": "Under the Autonomous Mobile Clinics (AMCs) initiative, we are developing,\nopen sourcing, and standardizing health AI technologies to enable healthcare\naccess in least developed countries (LDCs). We deem AMCs as the next generation\nof health care delivery platforms, whereas health AI engines are applications\non these platforms, similar to how various applications expand the usage\nscenarios of smart phones. Facing the recent global monkeypox outbreak, in this\narticle, we introduce AICOM-MP, an AI-based monkeypox detector specially aiming\nfor handling images taken from resource-constrained devices. Compared to\nexisting AI-based monkeypox detectors, AICOM-MP has achieved state-of-the-art\n(SOTA) performance. We have hosted AICOM-MP as a web service to allow universal\naccess to monkeypox screening technology. We have also open sourced both the\nsource code and the dataset of AICOM-MP to allow health AI professionals to\nintegrate AICOM-MP into their services. Also, through the AICOM-MP project, we\nhave generalized a methodology of developing health AI technologies for AMCs to\nallow universal access even in resource-constrained environments.",
    "descriptor": "",
    "authors": [
      "Tim Tianyi Yang",
      "Tom Tianze Yang",
      "Andrew Liu",
      "Jie Tang",
      "Na An",
      "Shaoshan Liu",
      "Xue Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.14313"
  },
  {
    "id": "arXiv:2211.14372",
    "title": "Interpretability Analysis of Deep Models for COVID-19 Detection",
    "abstract": "During the outbreak of COVID-19 pandemic, several research areas joined\nefforts to mitigate the damages caused by SARS-CoV-2. In this paper we present\nan interpretability analysis of a convolutional neural network based model for\nCOVID-19 detection in audios. We investigate which features are important for\nmodel decision process, investigating spectrograms, F0, F0 standard deviation,\nsex and age. Following, we analyse model decisions by generating heat maps for\nthe trained models to capture their attention during the decision process.\nFocusing on a explainable Inteligence Artificial approach, we show that studied\nmodels can taken unbiased decisions even in the presence of spurious data in\nthe training set, given the adequate preprocessing steps. Our best model has\n94.44% of accuracy in detection, with results indicating that models favors\nspectrograms for the decision process, particularly, high energy areas in the\nspectrogram related to prosodic domains, while F0 also leads to efficient\nCOVID-19 detection.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Daniel Peixoto Pinto da Silva",
      "Edresson Casanova",
      "Lucas Rafael Stefanel Gris",
      "Arnaldo Candido Junior",
      "Marcelo Finger",
      "Flaviane Svartman",
      "Beatriz Raposo",
      "Marcus Vin\u00edcius Moreira Martins",
      "Sandra Maria Alu\u00edsio",
      "Larissa Cristina Berti",
      "Jo\u00e3o Paulo Teixeira"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.14372"
  },
  {
    "id": "arXiv:2211.14378",
    "title": "Stereo Speech Enhancement Using Custom Mid-Side Signals and Monaural  Processing",
    "abstract": "Speech Enhancement (SE) systems typically operate on monaural input and are\nused for applications including voice communications and capture cleanup for\nuser generated content. Recent advancements and changes in the devices used for\nthese applications are likely to lead to an increase in the amount of\ntwo-channel content for the same applications. However, SE systems are\ntypically designed for monaural input; stereo results produced using trivial\nmethods such as channel independent or mid-side processing may be\nunsatisfactory, including substantial speech distortions. To address this, we\npropose a system which creates a novel representation of stereo signals called\nCustom Mid-Side Signals (CMSS). CMSS allow benefits of mid-side signals for\ncenter-panned speech to be extended to a much larger class of input signals.\nThis in turn allows any existing monaural SE system to operate as an efficient\nstereo system by processing the custom mid signal. We describe how the\nparameters needed for CMSS can be efficiently estimated by a component of the\nspatio-level filtering source separation system. Subjective listening using\nstate-of-the-art deep learning-based SE systems on stereo content with various\nspeech mixing styles shows that CMSS processing leads to improved speech\nquality at approximately half the cost of channel-independent processing.",
    "descriptor": "\nComments: 12 pages, 5 figures. Submitted to the Journal of the Audio Engineering Society\n",
    "authors": [
      "Aaron Master",
      "Lie Lu",
      "Nathan Swedlow"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.14378"
  },
  {
    "id": "arXiv:2211.14400",
    "title": "Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev  Spaces",
    "abstract": "We study the problem of how efficiently, in terms of the number of\nparameters, deep neural networks with the ReLU activation function can\napproximate functions in the Sobolev space $W^s(L_q(\\Omega))$ on a bounded\ndomain $\\Omega$, where the error is measured in $L_p(\\Omega)$. This problem is\nimportant for studying the application of neural networks in scientific\ncomputing and has previously been solved only in the case $p=q=\\infty$. Our\ncontribution is to provide a solution for all $1\\leq p,q\\leq \\infty$ and $s >\n0$. Our results show that deep ReLU networks significantly outperform classical\nmethods of approximation, but that this comes at the cost of parameters which\nare not encodable.",
    "descriptor": "",
    "authors": [
      "Jonathan W. Siegel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14400"
  },
  {
    "id": "arXiv:2211.14401",
    "title": "Elements of effective machine learning datasets in astronomy",
    "abstract": "In this work, we identify elements of effective machine learning datasets in\nastronomy and present suggestions for their design and creation. Machine\nlearning has become an increasingly important tool for analyzing and\nunderstanding the large-scale flood of data in astronomy. To take advantage of\nthese tools, datasets are required for training and testing. However, building\nmachine learning datasets for astronomy can be challenging. Astronomical data\nis collected from instruments built to explore science questions in a\ntraditional fashion rather than to conduct machine learning. Thus, it is often\nthe case that raw data, or even downstream processed data is not in a form\namenable to machine learning. We explore the construction of machine learning\ndatasets and we ask: what elements define effective machine learning datasets?\nWe define effective machine learning datasets in astronomy to be formed with\nwell-defined data points, structure, and metadata. We discuss why these\nelements are important for astronomical applications and ways to put them in\npractice. We posit that these qualities not only make the data suitable for\nmachine learning, they also help to foster usable, reusable, and replicable\nscience practices.",
    "descriptor": "",
    "authors": [
      "Bernie Boscoe",
      "Tuan Do",
      "Evan Jones",
      "Yunqi Li",
      "Kevin Alfaro",
      "Christy Ma"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14401"
  },
  {
    "id": "arXiv:2211.14429",
    "title": "Supervised Pretraining for Molecular Force Fields and Properties  Prediction",
    "abstract": "Machine learning approaches have become popular for molecular modeling tasks,\nincluding molecular force fields and properties prediction. Traditional\nsupervised learning methods suffer from scarcity of labeled data for particular\ntasks, motivating the use of large-scale dataset for other relevant tasks. We\npropose to pretrain neural networks on a dataset of 86 millions of molecules\nwith atom charges and 3D geometries as inputs and molecular energies as labels.\nExperiments show that, compared to training from scratch, fine-tuning the\npretrained model can significantly improve the performance for seven molecular\nproperty prediction tasks and two force field tasks. We also demonstrate that\nthe learned representations from the pretrained model contain adequate\ninformation about molecular structures, by showing that linear probing of the\nrepresentations can predict many molecular information including atom types,\ninteratomic distances, class of molecular scaffolds, and existence of molecular\nfragments. Our results show that supervised pretraining is a promising research\ndirection in molecular modeling",
    "descriptor": "\nComments: AI4Science Workshop at NeurIPS 2022\n",
    "authors": [
      "Xiang Gao",
      "Weihao Gao",
      "Wenzhi Xiao",
      "Zhirui Wang",
      "Chong Wang",
      "Liang Xiang"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.14429"
  },
  {
    "id": "arXiv:2211.14525",
    "title": "Calculus rules for proximal \u03b5-subdifferentials and inexact  proximity operators for weakly convex functions",
    "abstract": "We investigate inexact proximity operators for weakly convex functions. To\nthis aim, we derive sum rules for proximal {\\epsilon}-subdifferentials, by\nincorporating the moduli of weak convexity of the functions into the respective\nformulas. This allows us to investigate inexact proximity operators for weakly\nconvex functions in terms of proximal {\\epsilon}-subdifferentials.",
    "descriptor": "",
    "authors": [
      "Ewa Bednarczuk",
      "Giovanni Bruccola",
      "Gabriele Scrivanti",
      "Hung Tran"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14525"
  },
  {
    "id": "arXiv:2211.14543",
    "title": "When Spectral Modeling Meets Convolutional Networks: A Method for  Discovering Reionization-era Lensed Quasars in Multi-band Imaging Data",
    "abstract": "Over the last two decades, around three hundred quasars have been discovered\nat $z\\gtrsim6$, yet only one was identified as being strong-gravitationally\nlensed. We explore a new approach, enlarging the permitted spectral parameter\nspace while introducing a new spatial geometry veto criterion, implemented via\nimage-based deep learning. We made the first application of this approach in a\nsystematic search for reionization-era lensed quasars, using data from the Dark\nEnergy Survey, the Visible and Infrared Survey Telescope for Astronomy\nHemisphere Survey, and the Wide-field Infrared Survey Explorer. Our search\nmethod consists of two main parts: (i) pre-selection of the candidates based on\ntheir spectral energy distributions (SEDs) using catalog-level photometry and\n(ii) relative probabilities calculation of being a lens or some contaminant\nutilizing a convolutional neural network (CNN) classification. The training\ndatasets are constructed by painting deflected point-source lights over actual\ngalaxy images to generate realistic galaxy-quasar lens models, optimized to\nfind systems with small image separations, i.e., Einstein radii of\n$\\theta_\\mathrm{E} \\leq 1$ arcsec. Visual inspection is then performed for\nsources with CNN scores of $P_\\mathrm{lens} > 0.1$, which led us to obtain 36\nnewly-selected lens candidates, waiting for spectroscopic confirmation. These\nfindings show that automated SED modeling and deep learning pipelines,\nsupported by modest human input, are a promising route for detecting strong\nlenses from large catalogs that can overcome the veto limitations of primarily\ndropout-based SED selection approaches.",
    "descriptor": "\nComments: 24 pages, 17 figures, and 2 tables. Accepted for publication in The Astrophysical Journal. We welcome comments from the reader\n",
    "authors": [
      "Irham Taufik Andika",
      "Knud Jahnke",
      "Arjen van der Wel",
      "Eduardo Ba\u00f1ados",
      "Sarah E. I. Bosman",
      "Frederick B. Davies",
      "Anna-Christina Eilers",
      "Anton Timur Jaelani",
      "Chiara Mazzucchelli",
      "Masafusa Onoue",
      "Jan-Torge Schindler"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14543"
  },
  {
    "id": "arXiv:2211.14548",
    "title": "Contextual Expressive Text-to-Speech",
    "abstract": "The goal of expressive Text-to-speech (TTS) is to synthesize natural speech\nwith desired content, prosody, emotion, or timbre, in high expressiveness. Most\nof previous studies attempt to generate speech from given labels of styles and\nemotions, which over-simplifies the problem by classifying styles and emotions\ninto a fixed number of pre-defined categories. In this paper, we introduce a\nnew task setting, Contextual TTS (CTTS). The main idea of CTTS is that how a\nperson speaks depends on the particular context she is in, where the context\ncan typically be represented as text. Thus, in the CTTS task, we propose to\nutilize such context to guide the speech synthesis process instead of relying\non explicit labels of styles and emotions. To achieve this task, we construct a\nsynthetic dataset and develop an effective framework. Experiments show that our\nframework can generate high-quality expressive speech based on the given\ncontext both in synthetic datasets and real-world scenarios.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Jianhong Tu",
      "Zeyu Cui",
      "Xiaohuan Zhou",
      "Siqi Zheng",
      "Kai Hu",
      "Ju Fan",
      "Chang Zhou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.14548"
  },
  {
    "id": "arXiv:2211.14555",
    "title": "Distribution Free Prediction Sets for Node Classification",
    "abstract": "Graph Neural Networks (GNNs) are able to achieve high classification accuracy\non many large real world datasets, but provide no rigorous notion of predictive\nuncertainty. We leverage recent advances in conformal prediction to construct\nprediction sets for node classification in inductive learning scenarios, and\nverify the efficacy of our approach across standard benchmark datasets using\npopular GNN models. The code is available at\n\\href{https://github.com/jase-clarkson/graph_cp}{this link}.",
    "descriptor": "\nComments: To appear as an extended abstract at the LoG 2022 conference\n",
    "authors": [
      "Jase Clarkson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14555"
  },
  {
    "id": "arXiv:2211.14557",
    "title": "CMC v2: Towards More Accurate COVID-19 Detection with Discriminative  Video Priors",
    "abstract": "This paper presents our solution for the 2nd COVID-19 Competition, occurring\nin the framework of the AIMIA Workshop at the European Conference on Computer\nVision (ECCV 2022). In our approach, we employ the winning solution last year\nwhich uses a strong 3D Contrastive Mixup Classifcation network (CMC v1) as the\nbaseline method, composed of contrastive representation learning and mixup\nclassification. In this paper, we propose CMC v2 by introducing natural video\npriors to COVID-19 diagnosis. Specifcally, we adapt a pre-trained (on video\ndataset) video transformer backbone to COVID-19 detection. Moreover, advanced\ntraining strategies, including hybrid mixup and cutmix, slicelevel\naugmentation, and small resolution training are also utilized to boost the\nrobustness and the generalization ability of the model. Among 14 participating\nteams, CMC v2 ranked 1st in the 2nd COVID-19 Competition with an average Macro\nF1 Score of 89.11%.",
    "descriptor": "\nComments: ECCV AIMIA Workshop 2022\n",
    "authors": [
      "Junlin Hou",
      "Jilan Xu",
      "Nan Zhang",
      "Yi Wang",
      "Yuejie Zhang",
      "Xiaobo Zhang",
      "Rui Feng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14557"
  },
  {
    "id": "arXiv:2211.14559",
    "title": "Boosting COVID-19 Severity Detection with Infection-aware Contrastive  Mixup Classifcation",
    "abstract": "This paper presents our solution for the 2nd COVID-19 Severity Detection\nCompetition. This task aims to distinguish the Mild, Moderate, Severe, and\nCritical grades in COVID-19 chest CT images. In our approach, we devise a novel\ninfection-aware 3D Contrastive Mixup Classifcation network for severity\ngrading. Specifcally, we train two segmentation networks to frst extract the\nlung region and then the inner lesion region. The lesion segmentation mask\nserves as complementary information for the original CT slices. To relieve the\nissue of imbalanced data distribution, we further improve the advanced\nContrastive Mixup Classifcation network by weighted cross-entropy loss. On the\nCOVID-19 severity detection leaderboard, our approach won the frst place with a\nMacro F1 Score of 51.76%. It signifcantly outperforms the baseline method by\nover 11.46%.",
    "descriptor": "\nComments: ECCV AIMIA Workshop 2022\n",
    "authors": [
      "Junlin Hou",
      "Jilan Xu",
      "Nan Zhang",
      "Yuejie Zhang",
      "Xiaobo Zhang",
      "Rui Feng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14559"
  },
  {
    "id": "arXiv:2211.14560",
    "title": "A dynamic multi-region MFD model for ride-sourcing systems with  ridesplitting",
    "abstract": "Dynamic network-level models directly addressing ride-sourcing services can\nsupport the development of efficient strategies for both congestion alleviation\nand promotion of more sustainable mobility. Recent developments presented\nmodels focusing on ride-hailing (solo rides), but no work addressed\nridesplitting (shared rides) in dynamic contexts. Here, we sought to develop a\ndynamic aggregated traffic network model capable of representing ride-sourcing\nservices and background traffic in a macroscopic multi-region urban network. We\ncombined the Macroscopic Fundamental Diagram (MFD) with detailed state-space\nand transition descriptions of background traffic and ride-sourcing vehicles in\ntheir activities to formulate mass conservation equations. Accumulation-based\nMFD models might experience additional errors due to the variation profile of\ntrip lengths, e.g., when vehicles cruise for passengers. We integrate the\nso-called M-model that utilizes the total remaining distance to capture\ndynamics of regional and inter-regional flows and accumulations for different\nvehicle (private or ride-sourcing) states. This aggregated model is capable to\nreproduce the dynamics of complex systems without using resource-expensive\nsimulations. We also show that the model can accurately forecast the vehicles'\nconditions in near-future predictions. Later, a comparison with benchmark\nmodels showed lower errors in the proposed model in all states. Finally, we\nevaluated the model's robustness to noises in its inputs, and forecast errors\nremained below 15% even where inputs were 20% off the actual values for\nride-sourcing vehicles. The development of such a model prepares the path for\ndeveloping real-time feedback-based management policies such as priority-based\nperimeter control or repositioning strategies for idle ride-sourcing vehicles\nand developing regulations over ride-sourcing in congested areas.",
    "descriptor": "\nComments: Submitted to Transportation Science\n",
    "authors": [
      "Caio Vitor Beojone",
      "Nikolas Geroliminis"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14560"
  },
  {
    "id": "arXiv:2211.14576",
    "title": "CFNet: Conditional Filter Learning with Dynamic Noise Estimation for  Real Image Denoising",
    "abstract": "A mainstream type of the state of the arts (SOTAs) based on convolutional\nneural network (CNN) for real image denoising contains two sub-problems, i.e.,\nnoise estimation and non-blind denoising. This paper considers real noise\napproximated by heteroscedastic Gaussian/Poisson Gaussian distributions with\nin-camera signal processing pipelines. The related works always exploit the\nestimated noise prior via channel-wise concatenation followed by a\nconvolutional layer with spatially sharing kernels. Due to the variable modes\nof noise strength and frequency details of all feature positions, this design\ncannot adaptively tune the corresponding denoising patterns. To address this\nproblem, we propose a novel conditional filter in which the optimal kernels for\ndifferent feature positions can be adaptively inferred by local features from\nthe image and the noise map. Also, we bring the thought that alternatively\nperforms noise estimation and non-blind denoising into CNN structure, which\ncontinuously updates noise prior to guide the iterative feature denoising. In\naddition, according to the property of heteroscedastic Gaussian distribution, a\nnovel affine transform block is designed to predict the stationary noise\ncomponent and the signal-dependent noise component. Compared with SOTAs,\nextensive experiments are conducted on five synthetic datasets and three real\ndatasets, which shows the improvement of the proposed CFNet.",
    "descriptor": "",
    "authors": [
      "Yifan Zuo",
      "Jiacheng Xie",
      "Yuming Fang",
      "Yan Huang",
      "Wenhui Jiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14576"
  },
  {
    "id": "arXiv:2211.14578",
    "title": "Transfer learning with high-dimensional quantile regression",
    "abstract": "Transfer learning has become an essential technique to exploit information\nfrom the source domain to boost performance of the target task. Despite the\nprevalence in high-dimensional data, heterogeneity and/or heavy tails tend to\nbe discounted in current transfer learning approaches and thus may undermine\nthe resulting performance. We propose a transfer learning procedure in the\nframework of high-dimensional quantile regression models to accommodate the\nheterogeneity and heavy tails in the source and target domains. We establish\nerror bounds of the transfer learning estimator based on delicately selected\ntransferable source domains, showing that lower error bounds can be achieved\nfor critical selection criterion and larger sample size of source tasks. We\nfurther propose valid confidence interval and hypothesis test procedures for\nindividual component of quantile regression coefficients by advocating a\none-step debiased estimator of transfer learning estimator wherein the\nconsistent variance estimation is proposed via the technique of transfer\nlearning again. Simulation results demonstrate that the proposed method\nexhibits some favorable performances.",
    "descriptor": "\nComments: 108 pages, 4 figures\n",
    "authors": [
      "Jiayu Huang",
      "Mingqiu Wang",
      "Yuanshan Wu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.14578"
  },
  {
    "id": "arXiv:2211.14645",
    "title": "Accelerated Riemannian Optimization: Handling Constraints with a Prox to  Bound Geometric Penalties",
    "abstract": "We propose a globally-accelerated, first-order method for the optimization of\nsmooth and (strongly or not) geodesically-convex functions in a wide class of\nHadamard manifolds. We achieve the same convergence rates as Nesterov's\naccelerated gradient descent, up to a multiplicative geometric penalty and log\nfactors.\nCrucially, we can enforce our method to stay within a compact set we define.\nPrior fully accelerated works \\textit{resort to assuming} that the iterates of\ntheir algorithms stay in some pre-specified compact set, except for two\nprevious methods of limited applicability. For our manifolds, this solves the\nopen question in [KY22] about obtaining global general acceleration without\niterates assumptively staying in the feasible set.",
    "descriptor": "\nComments: arxiv submission, first circulated in May 2022\n",
    "authors": [
      "David Mart\u00ednez-Rubio",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14645"
  },
  {
    "id": "arXiv:2211.14659",
    "title": "Sharp bounds on Helmholtz impedance-to-impedance maps and application to  overlapping domain decomposition",
    "abstract": "We prove sharp bounds on certain impedance-to-impedance maps (and their\ncompositions) for the Helmholtz equation with large wavenumber (i.e., at\nhigh-frequency) using semiclassical defect measures. The paper [GGGLS]\n(Gong-Gander-Graham-Lafontaine-Spence, 2022) recently showed that the behaviour\nof these impedance-to-impedance maps (and their compositions) dictates the\nconvergence of the parallel overlapping Schwarz domain-decomposition method\nwith impedance boundary conditions on the subdomain boundaries. For a model\ndecomposition with two subdomains and sufficiently-large overlap, the results\nof this paper combined with those in [GGGLS] show that the parallel Schwarz\nmethod is power contractive, independent of the wavenumber. For strip-type\ndecompositions with many subdomains, the results of this paper show that the\ncomposite impedance-to-impedance maps, in general, behave \"badly\" with respect\nto the wavenumber; nevertheless, by proving results about the composite maps\napplied to a restricted class of data, we give insight into the\nwavenumber-robustness of the parallel Schwarz method observed in the numerical\nexperiments in [GGGLS].",
    "descriptor": "",
    "authors": [
      "David Lafontaine",
      "Euan A. Spence"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14659"
  },
  {
    "id": "arXiv:2211.14661",
    "title": "Iterated Function Systems: A Comprehensive Survey",
    "abstract": "We provide an overview of iterated function systems (IFS), where randomly\nchosen state-to-state maps are applied iteratively to a state. We aim to\nsummarize the state of art and, where possible, identify fundamental challenges\nand opportunities for further research.",
    "descriptor": "",
    "authors": [
      "Ramen Ghosh",
      "Jakub Marecek"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.14661"
  },
  {
    "id": "arXiv:2211.14676",
    "title": "Maximizing the Probability of Fixation in the Positional Voter Model",
    "abstract": "The Voter model is a well-studied stochastic process that models the invasion\nof a novel trait $A$ (e.g., a new opinion, social meme, genetic mutation,\nmagnetic spin) in a network of individuals (agents, people, genes, particles)\ncarrying an existing resident trait $B$. Individuals change traits by\noccasionally sampling the trait of a neighbor, while an invasion bias\n$\\delta\\geq 0$ expresses the stochastic preference to adopt the novel trait $A$\nover the resident trait $B$. The strength of an invasion is measured by the\nprobability that eventually the whole population adopts trait $A$, i.e., the\nfixation probability. In more realistic settings, however, the invasion bias is\nnot ubiquitous, but rather manifested only in parts of the network. For\ninstance, when modeling the spread of a social trait, the invasion bias\nrepresents localized incentives. In this paper, we generalize the standard\nbiased Voter model to the positional Voter model, in which the invasion bias is\neffectuated only on an arbitrary subset of the network nodes, called biased\nnodes. We study the ensuing optimization problem, which is, given a budget $k$,\nto choose $k$ biased nodes so as to maximize the fixation probability of a\nrandomly occurring invasion. We show that the problem is NP-hard both for\nfinite $\\delta$ and when $\\delta \\rightarrow \\infty$ (strong bias), while the\nobjective function is not submodular in either setting, indicating strong\ncomputational hardness. On the other hand, we show that, when\n$\\delta\\rightarrow 0$ (weak bias), we can obtain a tight approximation in\n$O(n^{2\\omega})$ time, where $\\omega$ is the matrix-multiplication exponent. We\ncomplement our theoretical results with an experimental evaluation of some\nproposed heuristics.",
    "descriptor": "\nComments: Accepted for publication in AAAI 2023\n",
    "authors": [
      "Petros Petsinis",
      "Andreas Pavlogiannis",
      "Panagiotis Karras"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Computational Complexity (cs.CC)",
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14676"
  },
  {
    "id": "arXiv:2211.14708",
    "title": "Identifying Chemicals Through Dimensionality Reduction",
    "abstract": "Civilizations have tried to make drinking water safe to consume for thousands\nof years. The process of determining water contaminants has evolved with the\ncomplexity of the contaminants due to pesticides and heavy metals. The routine\nprocedure to determine water safety is to use targeted analysis which searches\nfor specific substances from some known list; however, we do not explicitly\nknow which substances should be on this list. Before experimentally determining\nwhich substances are contaminants, how do we answer the sampling problem of\nidentifying all the substances in the water? Here, we present an approach that\nbuilds on the work of Jaanus Liigand et al., which used non-targeted analysis\nthat conducts a broader search on the sample to develop a random-forest\nregression model, to predict the names of all the substances in a sample, as\nwell as their respective concentrations[1]. This work utilizes techniques from\ndimensionality reduction and linear decompositions to present a more accurate\nmodel using data from the European Massbank Metabolome Library to produce a\nglobal list of chemicals that researchers can then identify and test for when\npurifying water.",
    "descriptor": "\nComments: 12 pages, 24 figures\n",
    "authors": [
      "Emile Anand",
      "Charles Steinhardt",
      "Martin Hansen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14708"
  },
  {
    "id": "arXiv:2211.14722",
    "title": "Convergence Rate Analysis for Optimal Computing Budget Allocation  Algorithms",
    "abstract": "Ordinal optimization (OO) is a widely-studied technique for optimizing\ndiscrete-event dynamic systems (DEDS). It evaluates the performance of the\nsystem designs in a finite set by sampling and aims to correctly make ordinal\ncomparison of the designs. A well-known method in OO is the optimal computing\nbudget allocation (OCBA). It builds the optimality conditions for the number of\nsamples allocated to each design, and the sample allocation that satisfies the\noptimality conditions is shown to asymptotically maximize the probability of\ncorrect selection for the best design. In this paper, we investigate two\npopular OCBA algorithms. With known variances for samples of each design, we\ncharacterize their convergence rates with respect to different performance\nmeasures. We first demonstrate that the two OCBA algorithms achieve the optimal\nconvergence rate under measures of probability of correct selection and\nexpected opportunity cost. It fills the void of convergence analysis for OCBA\nalgorithms. Next, we extend our analysis to the measure of cumulative regret, a\nmain measure studied in the field of machine learning. We show that with minor\nmodification, the two OCBA algorithms can reach the optimal convergence rate\nunder cumulative regret. It indicates the potential of broader use of\nalgorithms designed based on the OCBA optimality conditions.",
    "descriptor": "",
    "authors": [
      "Yanwen Li",
      "Siyang Gao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.14722"
  },
  {
    "id": "arXiv:2211.14723",
    "title": "Asymptotic Optimality of Myopic Ranking and Selection Procedures",
    "abstract": "Ranking and selection (R&S) is a popular model for studying discrete-event\ndynamic systems. It aims to select the best design (the design with the largest\nmean performance) from a finite set, where the mean of each design is unknown\nand has to be learned by samples. Great research efforts have been devoted to\nthis problem in the literature for developing procedures with superior\nempirical performance and showing their optimality. In these efforts, myopic\nprocedures were popular. They select the best design using a 'naive' mechanism\nof iteratively and myopically improving an approximation of the objective\nmeasure. Although they are based on simple heuristics and lack theoretical\nsupport, they turned out highly effective, and often achieved competitive\nempirical performance compared to procedures that were proposed later and shown\nto be asymptotically optimal. In this paper, we theoretically analyze these\nmyopic procedures and prove that they also satisfy the optimality conditions of\nR&S, just like some other popular R&S methods. It explains the good performance\nof myopic procedures in various numerical tests, and provides good insight into\nthe structure and theoretical development of efficient R&S procedures.",
    "descriptor": "",
    "authors": [
      "Yanwen Li",
      "Siyang Gao",
      "Zhongshun Shi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.14723"
  },
  {
    "id": "arXiv:2211.14728",
    "title": "Development of Millimeter Wave Wireless Communication",
    "abstract": "The future wireless communication system faces the bottleneck of the shortage\nof traditional spectrum resources and the explosive growth of the demand for\nwireless services. Millimeter-wave communication with spectral resources has\nbecome an effective choice for the next generation of wireless broadband\ncellular communication. However, the transmission path loss is large and oxygen\nand water molecules absorb Characteristics such as seriousness have brought\ngreat challenges to millimeter wave communication, and it is necessary to seek\na technical approach different from low-frequency wireless communication. In\nthe analysis of millimeter wave transmission characteristics After the\nanalysis, the research progress of millimeter wave communication technology and\nthe RF front-end is comprehensively analyzed, and the technology of millimeter\nwave communication is thoroughly analyzed with technical challenges and\nproposed corresponding research directions.",
    "descriptor": "\nComments: White paper\n",
    "authors": [
      "Quanda Zhang",
      "Hudi Wang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "General Literature (cs.GL)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.14728"
  },
  {
    "id": "arXiv:2211.14780",
    "title": "Nonlinear Schwarz preconditioning for nonlinear optimization problems  with bound constraints",
    "abstract": "We propose a nonlinear additive Schwarz method for solving nonlinear\noptimization problems with bound constraints. Our method is used as a\n\"right-preconditioner\" for solving the first-order optimality system arising\nwithin the sequential quadratic programming (SQP) framework using Newton's\nmethod. The algorithmic scalability of this preconditioner is enhanced by\nincorporating a solution-dependent coarse space, which takes into account the\nrestricted constraints from the fine level. By means of numerical examples, we\ndemonstrate that the proposed preconditioned Newton methods outperform standard\nactive-set methods considered in the literature.",
    "descriptor": "",
    "authors": [
      "Hardik Kothari",
      "Alena Kopani\u010d\u00e1kov\u00e1",
      "Rolf Krause"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14780"
  },
  {
    "id": "arXiv:2211.14811",
    "title": "Improved Quasi-Recurrent Neural Network for Hyperspectral Image  Denoising",
    "abstract": "Hyperspectral image is unique and useful for its abundant spectral bands, but\nit subsequently requires extra elaborated treatments of the spatial-spectral\ncorrelation as well as the global correlation along the spectrum for building a\nrobust and powerful HSI restoration algorithm. By considering such HSI\ncharacteristics, 3D Quasi-Recurrent Neural Network (QRNN3D) is one of the HSI\ndenoising networks that has been shown to achieve excellent performance and\nflexibility. In this paper, we show that with a few simple modifications, the\nperformance of QRNN3D could be substantially improved further. Our\nmodifications are based on the finding that through QRNN3D is powerful for\nmodeling spectral correlation, it neglects the proper treatment between\nfeatures from different sources and its training strategy is suboptimal. We,\ntherefore, introduce an adaptive fusion module to replace its vanilla additive\nskip connection to better fuse the features of the encoder and decoder. We\nadditionally identify several important techniques to further enhance the\nperformance, which includes removing batch normalization, use of extra\nfrequency loss, and learning rate warm-up. Experimental results on various\nnoise settings demonstrate the effectiveness and superior performance of our\nmethod.",
    "descriptor": "\nComments: technical report\n",
    "authors": [
      "Zeqiang Lai",
      "Ying Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14811"
  },
  {
    "id": "arXiv:2211.14830",
    "title": "Medical Image Segmentation Review: The success of U-Net",
    "abstract": "Automatic medical image segmentation is a crucial topic in the medical domain\nand successively a critical counterpart in the computer-aided diagnosis\nparadigm. U-Net is the most widespread image segmentation architecture due to\nits flexibility, optimized modular design, and success in all medical image\nmodalities. Over the years, the U-Net model achieved tremendous attention from\nacademic and industrial researchers. Several extensions of this network have\nbeen proposed to address the scale and complexity created by medical tasks.\nAddressing the deficiency of the naive U-Net model is the foremost step for\nvendors to utilize the proper U-Net variant model for their business. Having a\ncompendium of different variants in one place makes it easier for builders to\nidentify the relevant research. Also, for ML researchers it will help them\nunderstand the challenges of the biological tasks that challenge the model. To\naddress this, we discuss the practical aspects of the U-Net model and suggest a\ntaxonomy to categorize each network variant. Moreover, to measure the\nperformance of these strategies in a clinical application, we propose fair\nevaluations of some unique and famous designs on well-known datasets. We\nprovide a comprehensive implementation library with trained models for future\nresearch. In addition, for ease of future studies, we created an online list of\nU-Net papers with their possible official implementation. All information is\ngathered in https://github.com/NITR098/Awesome-U-Net repository.",
    "descriptor": "\nComments: Submitted to the IEEE Transactions on Pattern Analysis and Machine Intelligence Journal\n",
    "authors": [
      "Reza Azad",
      "Ehsan Khodapanah Aghdam",
      "Amelie Rauland",
      "Yiwei Jia",
      "Atlas Haddadi Avval",
      "Afshin Bozorgpour",
      "Sanaz Karimijafarbigloo",
      "Joseph Paul Cohen",
      "Ehsan Adeli",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14830"
  },
  {
    "id": "arXiv:2211.14847",
    "title": "Deep Learning-Based Prediction of Molecular Tumor Biomarkers from H&E: A  Practical Review",
    "abstract": "Molecular and genomic properties are critical in selecting cancer treatments\nto target individual tumors, particularly for immunotherapy. However, the\nmethods to assess such properties are expensive, time-consuming, and often not\nroutinely performed. Applying machine learning to H&E images can provide a more\ncost-effective screening method. Dozens of studies over the last few years have\ndemonstrated that a variety of molecular biomarkers can be predicted from H&E\nalone using the advancements of deep learning: molecular alterations, genomic\nsubtypes, protein biomarkers, and even the presence of viruses. This article\nreviews the diverse applications across cancer types and the methodology to\ntrain and validate these models on whole slide images. From bottom-up to\npathologist-driven to hybrid approaches, the leading trends include a variety\nof weakly supervised deep learning-based approaches, as well as mechanisms for\ntraining strongly supervised models in select situations. While results of\nthese algorithms look promising, some challenges still persist, including small\ntraining sets, rigorous validation, and model explainability. Biomarker\nprediction models may yield a screening method to determine when to run\nmolecular tests or an alternative when molecular tests are not possible. They\nalso create new opportunities in quantifying intratumoral heterogeneity and\npredicting patient outcomes.",
    "descriptor": "\nComments: 20 pages, 2 figures\n",
    "authors": [
      "Heather D. Couture"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14847"
  },
  {
    "id": "arXiv:2211.14853",
    "title": "Safety Envelope for Orthogonal Collocation Methods in Embedded Optimal  Control",
    "abstract": "Orthogonal collocation methods are direct simultaneous approaches for solving\noptimal control problems (OCP). A high solution accuracy is achieved with few\noptimization variables, making it more favorable for embedded and real-time\nNMPC applications. However, collocation approaches lack a guarantee about the\nsafety of the resulting continuous trajectory as inequality constraints are\nonly set on a finite number of collocation points. In this paper we propose a\nmethod to efficiently create a convex safety envelope containing the full\ntrajectory such that the solution fully satisfies the OCP constraints. We make\nuse of the Bernstein approximations of a polynomial's extrema and span the\nsolution over an orthogonal basis using the Legendre polynomials. The tightness\nof the safety envelope estimation, high spectral accuracy of the method in\nsolving the underlying differential equations, fast rate of convergence and\nlittle conservatism are properties of the presented approach making it a\nsuitable method for safe real-time NMPC deployment. We show that our method has\ncomparable computational performance to the pseudospectral approaches and can\napproximate the original OCP more accurately and up to 9 times more quickly\nthan standard multiple-shooting methods in autonomous driving applications,\nwithout adding complexity to the formulation.",
    "descriptor": "",
    "authors": [
      "Jean Pierre Allamaa",
      "Panagiotis Patrinos",
      "Herman Van der Auweraer",
      "Tong Duy Son"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14853"
  },
  {
    "id": "arXiv:2211.14857",
    "title": "Information Measures for Entropy and Symmetry",
    "abstract": "Entropy and information can be considered dual: entropy is a measure of the\nsubspace defined by the information constraining the given ambient space.\nNegative entropies, arising in na\\\"ive extensions of the definition of entropy\nfrom discrete to continuous settings, are byproducts of the use of\nprobabilities, which only work in the discrete case by a fortunate coincidence.\nWe introduce notions such as sup-normalization and information measures, which\nallow for the appropriate generalization of the definition of entropy that\nkeeps with the interpretation of entropy as a subspace volume. Applying this in\nthe context of topological groups and Haar measures, we elucidate the\nrelationship between entropy, symmetry, and uniformity.",
    "descriptor": "",
    "authors": [
      "Daniel Lazarev"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.14857"
  },
  {
    "id": "arXiv:2211.14908",
    "title": "A Permutation-free Kernel Two-Sample Test",
    "abstract": "The kernel Maximum Mean Discrepancy~(MMD) is a popular multivariate distance\nmetric between distributions that has found utility in two-sample testing. The\nusual kernel-MMD test statistic is a degenerate U-statistic under the null, and\nthus it has an intractable limiting distribution. Hence, to design a\nlevel-$\\alpha$ test, one usually selects the rejection threshold as the\n$(1-\\alpha)$-quantile of the permutation distribution. The resulting\nnonparametric test has finite-sample validity but suffers from large\ncomputational cost, since every permutation takes quadratic time. We propose\nthe cross-MMD, a new quadratic-time MMD test statistic based on\nsample-splitting and studentization. We prove that under mild assumptions, the\ncross-MMD has a limiting standard Gaussian distribution under the null.\nImportantly, we also show that the resulting test is consistent against any\nfixed alternative, and when using the Gaussian kernel, it has minimax\nrate-optimal power against local alternatives. For large sample sizes, our new\ncross-MMD provides a significant speedup over the MMD, for only a slight loss\nin power.",
    "descriptor": "\nComments: Accepted for publication at the Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS), with an oral presentation\n",
    "authors": [
      "Shubhanshu Shekhar",
      "Ilmun Kim",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14908"
  },
  {
    "id": "arXiv:2211.14929",
    "title": "Multi-Label Chest X-Ray Classification via Deep Learning",
    "abstract": "In this era of pandemic, the future of healthcare industry has never been\nmore exciting. Artificial intelligence and machine learning (AI & ML) present\nopportunities to develop solutions that cater for very specific needs within\nthe industry. Deep learning in healthcare had become incredibly powerful for\nsupporting clinics and in transforming patient care in general. Deep learning\nis increasingly being applied for the detection of clinically important\nfeatures in the images beyond what can be perceived by the naked human eye.\nChest X-ray images are one of the most common clinical method for diagnosing a\nnumber of diseases such as pneumonia, lung cancer and many other abnormalities\nlike lesions and fractures. Proper diagnosis of a disease from X-ray images is\noften challenging task for even expert radiologists and there is a growing need\nfor computerized support systems due to the large amount of information encoded\nin X-Ray images. The goal of this paper is to develop a lightweight solution to\ndetect 14 different chest conditions from an X ray image. Given an X-ray image\nas input, our classifier outputs a label vector indicating which of 14 disease\nclasses does the image fall into. Along with the image features, we are also\ngoing to use non-image features available in the data such as X-ray view type,\nage, gender etc. The original study conducted Stanford ML Group is our base\nline. Original study focuses on predicting 5 diseases. Our aim is to improve\nupon previous work, expand prediction to 14 diseases and provide insight for\nfuture chest radiography research.",
    "descriptor": "",
    "authors": [
      "Aravind Sasidharan Pillai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14929"
  },
  {
    "id": "arXiv:2211.14961",
    "title": "Linear Classification of Neural Manifolds with Correlated Variability",
    "abstract": "Understanding how the statistical and geometric properties of neural\nactivations relate to network performance is a key problem in theoretical\nneuroscience and deep learning. In this letter, we calculate how correlations\nbetween object representations affect the capacity, a measure of linear\nseparability. We show that for spherical object manifolds, introducing\ncorrelations between centroids effectively pushes the spheres closer together,\nwhile introducing correlations between the spheres' axes effectively shrinks\ntheir radii, revealing a duality between neural correlations and geometry. We\nthen show that our results can be used to accurately estimate the capacity with\nreal neural data.",
    "descriptor": "\nComments: 6 pages and 5 figures in main text. 11 pages and 1 figure in supplementary material\n",
    "authors": [
      "Albert J. Wakhloo",
      "Tamara J. Sussman",
      "SueYeon Chung"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14961"
  },
  {
    "id": "arXiv:2211.14962",
    "title": "Fault-Tolerant Detection Systems on the King's Grid",
    "abstract": "A detection system, modeled in a graph, uses \"detectors\" on a subset of\nvertices to uniquely identify an \"intruder\" at any vertex. We consider two\ntypes of detection systems: open-locating-dominating (OLD) sets and identifying\ncodes (ICs). An OLD set gives each vertex a unique, non-empty open neighborhood\nof detectors, while an IC provides a unique, non-empty closed neighborhood of\ndetectors. We explore their fault-tolerant variants: redundant OLD (RED:OLD)\nsets and redundant ICs (RED:ICs), which ensure that removing/disabling at most\none detector guarantees the properties of OLD sets and ICs, respectively. This\npaper focuses on constructing optimal RED:OLD sets and RED:ICs on the infinite\nking's grid, and presents the proof for the bounds on their minimum densities;\n[3/10, 1/3] for RED:OLD sets and [3/11, 1/3] for RED:ICs.",
    "descriptor": "",
    "authors": [
      "Devin Jean",
      "Suk Seo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.14962"
  },
  {
    "id": "arXiv:2211.14986",
    "title": "An Unpaired Cross-modality Segmentation Framework Using Data  Augmentation and Hybrid Convolutional Networks for Segmenting Vestibular  Schwannoma and Cochlea",
    "abstract": "The crossMoDA challenge aims to automatically segment the vestibular\nschwannoma (VS) tumor and cochlea regions of unlabeled high-resolution T2 scans\nby leveraging labeled contrast-enhanced T1 scans. The 2022 edition extends the\nsegmentation task by including multi-institutional scans. In this work, we\nproposed an unpaired cross-modality segmentation framework using data\naugmentation and hybrid convolutional networks. Considering heterogeneous\ndistributions and various image sizes for multi-institutional scans, we apply\nthe min-max normalization for scaling the intensities of all scans between -1\nand 1, and use the voxel size resampling and center cropping to obtain\nfixed-size sub-volumes for training. We adopt two data augmentation methods for\neffectively learning the semantic information and generating realistic target\ndomain scans: generative and online data augmentation. For generative data\naugmentation, we use CUT and CycleGAN to generate two groups of realistic T2\nvolumes with different details and appearances for supervised segmentation\ntraining. For online data augmentation, we design a random tumor signal\nreducing method for simulating the heterogeneity of VS tumor signals.\nFurthermore, we utilize an advanced hybrid convolutional network with\nmulti-dimensional convolutions to adaptively learn sparse inter-slice\ninformation and dense intra-slice information for accurate volumetric\nsegmentation of VS tumor and cochlea regions in anisotropic scans. On the\ncrossMoDA2022 validation dataset, our method produces promising results and\nachieves the mean DSC values of 72.47% and 76.48% and ASSD values of 3.42 mm\nand 0.53 mm for VS tumor and cochlea regions, respectively.",
    "descriptor": "\nComments: Accepted by BrainLes MICCAI proceedings\n",
    "authors": [
      "Yuzhou Zhuang",
      "Hong Liu",
      "Enmin Song",
      "Coskun Cetinkaya",
      "Chih-Cheng Hung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14986"
  },
  {
    "id": "arXiv:2211.14989",
    "title": "Solving 3D Radar Imaging Inverse Problems with a Multi-cognition  Task-oriented Framework",
    "abstract": "This work focuses on 3D Radar imaging inverse problems. Current methods\nobtain undifferentiated results that suffer task-depended information retrieval\nloss and thus don't meet the task's specific demands well. For example, biased\nscattering energy may be acceptable for screen imaging but not for scattering\ndiagnosis. To address this issue, we propose a new task-oriented imaging\nframework. The imaging principle is task-oriented through an analysis phase to\nobtain task's demands. The imaging model is multi-cognition regularized to\nembed and fulfill demands. The imaging method is designed to be general-ized,\nwhere couplings between cognitions are decoupled and solved individually with\napproximation and variable-splitting techniques. Tasks include scattering\ndiagnosis, person screen imaging, and parcel screening imaging are given as\nexamples. Experiments on data from two systems indicate that the pro-posed\nframework outperforms the current ones in task-depended information retrieval.",
    "descriptor": "",
    "authors": [
      "Xu Zhan",
      "Xiaoling Zhang",
      "Mou Wang",
      "Jun Shi",
      "Shunjun Wei",
      "Tianjiao Zeng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14989"
  },
  {
    "id": "arXiv:2211.14990",
    "title": "Near-filed SAR Image Restoration with Deep Learning Inverse Technique: A  Preliminary Study",
    "abstract": "Benefiting from a relatively larger aperture's angle, and in combination with\na wide transmitting bandwidth, near-field synthetic aperture radar (SAR)\nprovides a high-resolution image of a target's scattering distribution-hot\nspots. Meanwhile, imaging result suffers inevitable degradation from sidelobes,\nclutters, and noises, hindering the information retrieval of the target. To\nrestore the image, current methods make simplified assumptions; for example,\nthe point spread function (PSF) is spatially consistent, the target consists of\nsparse point scatters, etc. Thus, they achieve limited restoration performance\nin terms of the target's shape, especially for complex targets. To address\nthese issues, a preliminary study is conducted on restoration with the recent\npromising deep learning inverse technique in this work. We reformulate the\ndegradation model into a spatially variable complex-convolution model, where\nthe near-field SAR's system response is considered. Adhering to it, a\nmodel-based deep learning network is designed to restore the image. A simulated\ndegraded image dataset from multiple complex target models is constructed to\nvalidate the network. All the images are formulated using the electromagnetic\nsimulation tool. Experiments on the dataset reveal their effectiveness.\nCompared with current methods, superior performance is achieved regarding the\ntarget's shape and energy estimation.",
    "descriptor": "",
    "authors": [
      "Xu Zhan",
      "Xiaoling Zhang",
      "Wensi Zhang",
      "Jun Shi",
      "Shunjun Wei",
      "Tianjiao Zeng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14990"
  },
  {
    "id": "arXiv:2211.14997",
    "title": "A Comprehensive Survey on Enterprise Financial Risk Analysis: Problems,  Methods, Spotlights and Applications",
    "abstract": "Enterprise financial risk analysis aims at predicting the enterprises' future\nfinancial risk.Due to the wide application, enterprise financial risk analysis\nhas always been a core research issue in finance. Although there are already\nsome valuable and impressive surveys on risk management, these surveys\nintroduce approaches in a relatively isolated way and lack the recent advances\nin enterprise financial risk analysis. Due to the rapid expansion of the\nenterprise financial risk analysis, especially from the computer science and\nbig data perspective, it is both necessary and challenging to comprehensively\nreview the relevant studies. This survey attempts to connect and systematize\nthe existing enterprise financial risk researches, as well as to summarize and\ninterpret the mechanisms and the strategies of enterprise financial risk\nanalysis in a comprehensive way, which may help readers have a better\nunderstanding of the current research status and ideas. This paper provides a\nsystematic literature review of over 300 articles published on enterprise risk\nanalysis modelling over a 50-year period, 1968 to 2022. We first introduce the\nformal definition of enterprise risk as well as the related concepts. Then, we\ncategorized the representative works in terms of risk type and summarized the\nthree aspects of risk analysis. Finally, we compared the analysis methods used\nto model the enterprise financial risk. Our goal is to clarify current\ncutting-edge research and its possible future directions to model enterprise\nrisk, aiming to fully understand the mechanisms of enterprise risk\ncommunication and influence and its application on corporate governance,\nfinancial institution and government regulation.",
    "descriptor": "",
    "authors": [
      "Yu Zhao",
      "Huaming Du"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14997"
  },
  {
    "id": "arXiv:2211.15002",
    "title": "A Model-data-driven Network Embedding Multidimensional Features for  Tomographic SAR Imaging",
    "abstract": "Deep learning (DL)-based tomographic SAR imaging algorithms are gradually\nbeing studied. Typically, they use an unfolding network to mimic the iterative\ncalculation of the classical compressive sensing (CS)-based methods and process\neach range-azimuth unit individually. However, only one-dimensional features\nare effectively utilized in this way. The correlation between adjacent\nresolution units is ignored directly. To address that, we propose a new\nmodel-data-driven network to achieve tomoSAR imaging based on multi-dimensional\nfeatures. Guided by the deep unfolding methodology, a two-dimensional deep\nunfolding imaging network is constructed. On the basis of it, we add two 2D\nprocessing modules, both convolutional encoder-decoder structures, to enhance\nmulti-dimensional features of the imaging scene effectively. Meanwhile, to\ntrain the proposed multifeature-based imaging network, we construct a tomoSAR\nsimulation dataset consisting entirely of simulation data of buildings.\nExperiments verify the effectiveness of the model. Compared with the\nconventional CS-based FISTA method and DL-based gamma-Net method, the result of\nour proposed method has better performance on completeness while having decent\nimaging accuracy.",
    "descriptor": "",
    "authors": [
      "Yu Ren",
      "Xiaoling Zhang",
      "Xu Zhan",
      "Jun Shi",
      "Shunjun Wei",
      "Tianjiao Zeng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15002"
  },
  {
    "id": "arXiv:2211.15047",
    "title": "Synthetic Low-Field MRI Super-Resolution Via Nested U-Net Architecture",
    "abstract": "Low-field (LF) MRI scanners have the power to revolutionize medical imaging\nby providing a portable and cheaper alternative to high-field MRI scanners.\nHowever, such scanners are usually significantly noisier and lower quality than\ntheir high-field counterparts. The aim of this paper is to improve the SNR and\noverall image quality of low-field MRI scans to improve diagnostic capability.\nTo address this issue, we propose a Nested U-Net neural network architecture\nsuper-resolution algorithm that outperforms previously suggested deep learning\nmethods with an average PSNR of 78.83 and SSIM of 0.9551. We tested our network\non artificial noisy downsampled synthetic data from a major T1 weighted MRI\nimage dataset called the T1-mix dataset. One board-certified radiologist scored\n25 images on the Likert scale (1-5) assessing overall image quality, anatomical\nstructure, and diagnostic confidence across our architecture and other\npublished works (SR DenseNet, Generator Block, SRCNN, etc.). We also introduce\na new type of loss function called natural log mean squared error (NLMSE). In\nconclusion, we present a more accurate deep learning method for single image\nsuper-resolution applied to synthetic low-field MRI via a Nested U-Net\narchitecture.",
    "descriptor": "",
    "authors": [
      "Aryan Kalluvila",
      "Neha Koonjoo",
      "Danyal Bhutto",
      "Marcio Rockenbach",
      "Matthew S. Rosen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15047"
  },
  {
    "id": "arXiv:2211.15053",
    "title": "Distinguishing representational geometries with controversial stimuli:  Bayesian experimental design and its application to face dissimilarity  judgments",
    "abstract": "Comparing representations of complex stimuli in neural network layers to\nhuman brain representations or behavioral judgments can guide model\ndevelopment. However, even qualitatively distinct neural network models often\npredict similar representational geometries of typical stimulus sets. We\npropose a Bayesian experimental design approach to synthesizing stimulus sets\nfor adjudicating among representational models efficiently. We apply our method\nto discriminate among candidate neural network models of behavioral face\ndissimilarity judgments. Our results indicate that a neural network trained to\ninvert a 3D-face-model graphics renderer is more human-aligned than the same\narchitecture trained on identification, classification, or autoencoding. Our\nproposed stimulus synthesis objective is generally applicable to designing\nexperiments to be analyzed by representational similarity analysis for model\ncomparison.",
    "descriptor": "",
    "authors": [
      "Tal Golan",
      "Wenxuan Guo",
      "Heiko H. Sch\u00fctt",
      "Nikolaus Kriegeskorte"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.15053"
  },
  {
    "id": "arXiv:2211.15072",
    "title": "FaiREE: Fair Classification with Finite-Sample and Distribution-Free  Guarantee",
    "abstract": "Algorithmic fairness plays an increasingly critical role in machine learning\nresearch. Several group fairness notions and algorithms have been proposed.\nHowever, the fairness guarantee of existing fair classification methods mainly\ndepends on specific data distributional assumptions, often requiring large\nsample sizes, and fairness could be violated when there is a modest number of\nsamples, which is often the case in practice. In this paper, we propose FaiREE,\na fair classification algorithm that can satisfy group fairness constraints\nwith finite-sample and distribution-free theoretical guarantees. FaiREE can be\nadapted to satisfy various group fairness notions (e.g., Equality of\nOpportunity, Equalized Odds, Demographic Parity, etc.) and achieve the optimal\naccuracy. These theoretical guarantees are further supported by experiments on\nboth synthetic and real data. FaiREE is shown to have favorable performance\nover state-of-the-art algorithms.",
    "descriptor": "\nComments: 45 pages, 9 figures\n",
    "authors": [
      "Puheng Li",
      "James Zou",
      "Linjun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15072"
  },
  {
    "id": "arXiv:2211.15075",
    "title": "Inter-KD: Intermediate Knowledge Distillation for CTC-Based Automatic  Speech Recognition",
    "abstract": "Recently, the advance in deep learning has brought a considerable improvement\nin the end-to-end speech recognition field, simplifying the traditional\npipeline while producing promising results. Among the end-to-end models, the\nconnectionist temporal classification (CTC)-based model has attracted research\ninterest due to its non-autoregressive nature. However, such CTC models require\na heavy computational cost to achieve outstanding performance. To mitigate the\ncomputational burden, we propose a simple yet effective knowledge distillation\n(KD) for the CTC framework, namely Inter-KD, that additionally transfers the\nteacher's knowledge to the intermediate CTC layers of the student network. From\nthe experimental results on the LibriSpeech, we verify that the Inter-KD shows\nbetter achievements compared to the conventional KD methods. Without using any\nlanguage model (LM) and data augmentation, Inter-KD improves the word error\nrate (WER) performance from 8.85 % to 6.30 % on the test-clean.",
    "descriptor": "\nComments: Accepted by 2022 SLT Workshop\n",
    "authors": [
      "Ji Won Yoon",
      "Beom Jun Woo",
      "Sunghwan Ahn",
      "Hyeonseung Lee",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.15075"
  },
  {
    "id": "arXiv:2211.15105",
    "title": "PlasmoID: A dataset for Indonesian malaria parasite detection and  segmentation in thin blood smear",
    "abstract": "Indonesia holds the second-highest-ranking country for the highest number of\nmalaria cases in Southeast Asia. A different malaria parasite semantic\nsegmentation technique based on a deep learning approach is an alternative to\nreduce the limitations of traditional methods. However, the main problem of the\nsemantic segmentation technique is raised since large parasites are dominant,\nand the tiny parasites are suppressed. In addition, the amount and variance of\ndata are important influences in establishing their models. In this study, we\nconduct two contributions. First, we collect 559 microscopic images containing\n691 malaria parasites of thin blood smears. The dataset is named PlasmoID, and\nmost data comes from rural Indonesia. PlasmoID also provides ground truth for\nparasite detection and segmentation purposes. Second, this study proposes a\nmalaria parasite segmentation and detection scheme by combining Faster RCNN and\na semantic segmentation technique. The proposed scheme has been evaluated on\nthe PlasmoID dataset. It has been compared with recent studies of semantic\nsegmentation techniques, namely UNet, ResFCN-18, DeepLabV3, DeepLabV3plus and\nResUNet-18. The result shows that our proposed scheme can improve the\nsegmentation and detection of malaria parasite performance compared to original\nsemantic segmentation techniques.",
    "descriptor": "",
    "authors": [
      "Hanung Adi Nugroho",
      "Rizki Nurfauzi",
      "E. Elsa Herdiana Murhandarwati",
      "Purwono Purwono"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15105"
  },
  {
    "id": "arXiv:2211.15129",
    "title": "On the Sample Complexity of Representation Learning in Multi-task  Bandits with Global and Local structure",
    "abstract": "We investigate the sample complexity of learning the optimal arm for\nmulti-task bandit problems. Arms consist of two components: one that is shared\nacross tasks (that we call representation) and one that is task-specific (that\nwe call predictor). The objective is to learn the optimal (representation,\npredictor)-pair for each task, under the assumption that the optimal\nrepresentation is common to all tasks. Within this framework, efficient\nlearning algorithms should transfer knowledge across tasks. We consider the\nbest-arm identification problem for a fixed confidence, where, in each round,\nthe learner actively selects both a task, and an arm, and observes the\ncorresponding reward. We derive instance-specific sample complexity lower\nbounds satisfied by any $(\\delta_G,\\delta_H)$-PAC algorithm (such an algorithm\nidentifies the best representation with probability at least $1-\\delta_G$, and\nthe best predictor for a task with probability at least $1-\\delta_H$). We\ndevise an algorithm OSRL-SC whose sample complexity approaches the lower bound,\nand scales at most as $H(G\\log(1/\\delta_G)+ X\\log(1/\\delta_H))$, with $X,G,H$\nbeing, respectively, the number of tasks, representations and predictors. By\ncomparison, this scaling is significantly better than the classical best-arm\nidentification algorithm that scales as $HGX\\log(1/\\delta)$.",
    "descriptor": "\nComments: Accepted at the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI23)\n",
    "authors": [
      "Alessio Russo",
      "Alexandre Proutiere"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15129"
  },
  {
    "id": "arXiv:2211.15145",
    "title": "Emerging trends in machine learning for computational fluid dynamics",
    "abstract": "The renewed interest from the scientific community in machine learning (ML)\nis opening many new areas of research. Here we focus on how novel trends in ML\nare providing opportunities to improve the field of computational fluid\ndynamics (CFD). In particular, we discuss synergies between ML and CFD that\nhave already shown benefits, and we also assess areas that are under\ndevelopment and may produce important benefits in the coming years. We believe\nthat it is also important to emphasize a balanced perspective of cautious\noptimism for these emerging approaches",
    "descriptor": "",
    "authors": [
      "Ricardo Vinuesa",
      "Steve Brunton"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15145"
  },
  {
    "id": "arXiv:2211.15164",
    "title": "To what extent homophily and influencer networks explain song popularity",
    "abstract": "Forecasting the popularity of new songs has become a standard practice in the\nmusic industry and provides a comparative advantage for those that do it well.\nConsiderable efforts were put into machine learning prediction models for that\npurpose. It is known that in these models, relevant predictive parameters\ninclude intrinsic lyrical and acoustic characteristics, extrinsic factors\n(e.g., publisher influence and support), and the previous popularity of the\nartists. Much less attention was given to the social components of the\nspreading of song popularity. Recently, evidence for musical homophily - the\ntendency that people who are socially linked also share musical tastes - was\nreported. Here we determine how musical homophily can be used to predict song\npopularity. The study is based on an extensive dataset from the last.fm online\nmusic platform from which we can extract social links between listeners and\ntheir listening patterns. To quantify the importance of networks in the\nspreading of songs that eventually determines their popularity, we use musical\nhomophily to design a predictive influence parameter and show that its\ninclusion in state-of-the-art machine learning models enhances predictions of\nsong popularity. The influence parameter improves the prediction precision\n(TP/(TP+FN)) by about 50% from 0.14 to 0.21, indicating that the social\ncomponent in the spreading of music plays at least as significant a role as the\nartist's popularity or the impact of the genre.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Niklas Reisz",
      "Vito D. P. Servedio",
      "Stefan Thurner"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.15164"
  },
  {
    "id": "arXiv:2211.15192",
    "title": "Deep Grading based on Collective Artificial Intelligence for AD  Diagnosis and Prognosis",
    "abstract": "Accurate diagnosis and prognosis of Alzheimer's disease are crucial to\ndevelop new therapies and reduce the associated costs. Recently, with the\nadvances of convolutional neural networks, methods have been proposed to\nautomate these two tasks using structural MRI. However, these methods often\nsuffer from lack of interpretability, generalization, and can be limited in\nterms of performance. In this paper, we propose a novel deep framework designed\nto overcome these limitations. Our framework consists of two stages. In the\nfirst stage, we propose a deep grading model to extract meaningful features. To\nenhance the robustness of these features against domain shift, we introduce an\ninnovative collective artificial intelligence strategy for training and\nevaluating steps. In the second stage, we use a graph convolutional neural\nnetwork to better capture AD signatures. Our experiments based on 2074 subjects\nshow the competitive performance of our deep framework compared to\nstate-of-the-art methods on different datasets for both AD diagnosis and\nprognosis.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2206.03247\n",
    "authors": [
      "Huy-Dung Nguyen",
      "Micha\u00ebl Cl\u00e9ment",
      "Boris Mansencal",
      "Pierrick Coup\u00e9"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15192"
  },
  {
    "id": "arXiv:2211.15206",
    "title": "Path Planning for Concentric Tube Robots: a Toolchain with Application  to Stereotactic Neurosurgery",
    "abstract": "We present a toolchain for solving path planning problems for concentric tube\nrobots through obstacle fields. First, ellipsoidal sets representing the target\narea and obstacles are constructed from labelled point clouds. Then, the\nnonlinear and highly nonconvex optimal control problem is solved by introducing\na homotopy on the obstacle positions where at one extreme of the parameter the\nobstacles are removed from the operating space, and at the other extreme they\nare located at their intended positions. We present a detailed example (with\nmore than a thousand obstacles) from stereotactic neurosurgery with real-world\ndata obtained from labelled MPRI scans.",
    "descriptor": "\nComments: 8 pages, 7 figures. Paper under review\n",
    "authors": [
      "Matthias K. Hoffmann",
      "Willem Esterhuizen",
      "Karl Worthmann",
      "Kathrin Fla\u00dfkamp"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15206"
  },
  {
    "id": "arXiv:2211.15223",
    "title": "Gamma-convergence of a nonlocal perimeter arising in adversarial machine  learning",
    "abstract": "In this paper we prove Gamma-convergence of a nonlocal perimeter of Minkowski\ntype to a local anisotropic perimeter. The nonlocal model describes the\nregularizing effect of adversarial training in binary classifications. The\nenergy essentially depends on the interaction between two distributions\nmodelling likelihoods for the associated classes. We overcome typical strict\nregularity assumptions for the distributions by only assuming that they have\nbounded $BV$ densities. In the natural topology coming from compactness, we\nprove Gamma-convergence to a weighted perimeter with weight determined by an\nanisotropic function of the two densities. Despite being local, this sharp\ninterface limit reflects classification stability with respect to adversarial\nperturbations. We further apply our results to deduce Gamma-convergence of the\nassociated total variations, to study the asymptotics of adversarial training,\nand to prove Gamma-convergence of graph discretizations for the nonlocal\nperimeter.",
    "descriptor": "",
    "authors": [
      "Leon Bungert",
      "Kerrek Stinson"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15223"
  },
  {
    "id": "arXiv:2211.15241",
    "title": "Synthetic Principal Component Design: Fast Covariate Balancing with  Synthetic Controls",
    "abstract": "The optimal design of experiments typically involves solving an NP-hard\ncombinatorial optimization problem. In this paper, we aim to develop a globally\nconvergent and practically efficient optimization algorithm. Specifically, we\nconsider a setting where the pre-treatment outcome data is available and the\nsynthetic control estimator is invoked. The average treatment effect is\nestimated via the difference between the weighted average outcomes of the\ntreated and control units, where the weights are learned from the observed\ndata. {Under this setting, we surprisingly observed that the optimal\nexperimental design problem could be reduced to a so-called \\textit{phase\nsynchronization} problem.} We solve this problem via a normalized variant of\nthe generalized power method with spectral initialization. On the theoretical\nside, we establish the first global optimality guarantee for experiment design\nwhen pre-treatment data is sampled from certain data-generating processes.\nEmpirically, we conduct extensive experiments to demonstrate the effectiveness\nof our method on both the US Bureau of Labor Statistics and the\nAbadie-Diemond-Hainmueller California Smoking Data. In terms of the root mean\nsquare error, our algorithm surpasses the random design by a large margin.",
    "descriptor": "",
    "authors": [
      "Yiping Lu",
      "Jiajin Li",
      "Lexing Ying",
      "Jose Blanchet"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15241"
  },
  {
    "id": "arXiv:2211.15254",
    "title": "Learnable Front Ends Based on Temporal Modulation for Music Tagging",
    "abstract": "While end-to-end systems are becoming popular in auditory signal processing\nincluding automatic music tagging, models using raw audio as input needs a\nlarge amount of data and computational resources without domain knowledge.\nInspired by the fact that temporal modulation is regarded as an essential\ncomponent in auditory perception, we introduce the Temporal Modulation Neural\nNetwork (TMNN) that combines Mel-like data-driven front ends and temporal\nmodulation filters with a simple ResNet back end. The structure includes a set\nof temporal modulation filters to capture long-term patterns in all frequency\nchannels. Experimental results show that the proposed front ends surpass\nstate-of-the-art (SOTA) methods on the MagnaTagATune dataset in automatic music\ntagging, and they are also helpful for keyword spotting on speech commands.\nMoreover, the model performance for each tag suggests that genre or instrument\ntags with complex rhythm and mood tags can especially be improved with temporal\nmodulation.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Yinghao Ma",
      "Richard M. Stern"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.15254"
  },
  {
    "id": "arXiv:2211.15307",
    "title": "Tuning-free Plug-and-Play Hyperspectral Image Deconvolution with Deep  Priors",
    "abstract": "Deconvolution is a widely used strategy to mitigate the blurring and noisy\ndegradation of hyperspectral images~(HSI) generated by the acquisition devices.\nThis issue is usually addressed by solving an ill-posed inverse problem. While\ninvestigating proper image priors can enhance the deconvolution performance, it\nis not trivial to handcraft a powerful regularizer and to set the\nregularization parameters. To address these issues, in this paper we introduce\na tuning-free Plug-and-Play (PnP) algorithm for HSI deconvolution.\nSpecifically, we use the alternating direction method of multipliers (ADMM) to\ndecompose the optimization problem into two iterative sub-problems. A flexible\nblind 3D denoising network (B3DDN) is designed to learn deep priors and to\nsolve the denoising sub-problem with different noise levels. A measure of 3D\nresidual whiteness is then investigated to adjust the penalty parameters when\nsolving the quadratic sub-problems, as well as a stopping criterion.\nExperimental results on both simulated and real-world data with ground-truth\ndemonstrate the superiority of the proposed method.",
    "descriptor": "\nComments: IEEE Trans. Geosci. Remote sens. Manuscript submitted June 30, 2022\n",
    "authors": [
      "Xiuheng Wang",
      "Jie Chen",
      "C\u00e9dric Richard"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15307"
  },
  {
    "id": "arXiv:2211.15310",
    "title": "Stochastic Steffensen method",
    "abstract": "Is it possible for a first-order method, i.e., only first derivatives\nallowed, to be quadratically convergent? For univariate loss functions, the\nanswer is yes -- the Steffensen method avoids second derivatives and is still\nquadratically convergent like Newton method. By incorporating an optimal step\nsize we can even push its convergence order beyond quadratic to $1+\\sqrt{2}\n\\approx 2.414$. While such high convergence orders are a pointless overkill for\na deterministic algorithm, they become rewarding when the algorithm is\nrandomized for problems of massive sizes, as randomization invariably\ncompromises convergence speed. We will introduce two adaptive learning rates\ninspired by the Steffensen method, intended for use in a stochastic\noptimization setting and requires no hyperparameter tuning aside from batch\nsize. Extensive experiments show that they compare favorably with several\nexisting first-order methods. When restricted to a quadratic objective, our\nstochastic Steffensen methods reduce to randomized Kaczmarz method -- note that\nthis is not true for SGD or SLBFGS -- and thus we may also view our methods as\na generalization of randomized Kaczmarz to arbitrary objectives.",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Minda Zhao",
      "Zehua Lai",
      "Lek-Heng Lim"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15310"
  },
  {
    "id": "arXiv:2211.15331",
    "title": "On the Emergence of Cooperation in the Repeated Prisoner's Dilemma",
    "abstract": "This article explores which parameters of the repeated Prisoner's Dilemma\nlead to cooperation. Using simulations, I demonstrate that the potential\nfunction of the stochastic evolutionary dynamics of the Grim Trigger strategy\nis useful to predict cooperation between Q-learners. The frontier separating\nthe parameter spaces that induce either cooperation or defection can be\ndetermined based on the kinetic energy exerted by the respective basins of\nattraction. When the incentive compatibility constraint of the Grim Trigger\nstrategy is slack, a sudden increase in the observed cooperation rates occurs\nwhen the ratio of the kinetic energies approaches a critical value, which\nitself is a function of the discount factor, multiplied by a correction factor\nto account for the effect of the algorithms' exploration probability. Using\nmetadata from laboratory experiments, I provide evidence that the insights\nobtained from the simulations are also useful to explain the emergence of\ncooperation between humans. The observed cooperation rates show a positive\ngradient at the frontier characterized by an exploration probability of\napproximately five percent. In the context of human-to-human interaction, the\nexploration probability can be viewed as the belief about the opponent's\nprobability to deviate from the equilibrium action.",
    "descriptor": "",
    "authors": [
      "Maximilian Schaefer"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.15331"
  },
  {
    "id": "arXiv:2211.15341",
    "title": "Non-inferiority of Deep Learning Model to Segment Acute Stroke on  Non-contrast CT Compared to Neuroradiologists",
    "abstract": "Purpose: To develop a deep learning model to segment the acute ischemic\ninfarct on non-contrast Computed Tomography (NCCT). Materials and Methods In\nthis retrospective study, 227 Head NCCT examinations from 200 patients enrolled\nin the multicenter DEFUSE 3 trial were included. Three experienced\nneuroradiologists (experts A, B and C) independently segmented the acute\ninfarct on each study. The dataset was randomly split into 5 folds with\ntraining and validation cases. A 3D deep Convolutional Neural Network (CNN)\narchitecture was optimized for the data set properties and task needs. The\ninput to the model was the NCCT and the output was a segmentation mask. The\nmodel was trained and optimized on expert A. The outcome was assessed by a set\nof volume, overlap and distance metrics. The predicted segmentations of the\nbest model and expert A were compared to experts B and C. Then we used a paired\nWilcoxon signed-rank test in a one-sided test procedure for all metrics to test\nfor non-inferiority in terms of bias and precision. Results: The best\nperforming model reached a Surface Dice at Tolerance (SDT)5mm of 0.68 \\pm 0.04.\nThe predictions were non-inferior when compared to independent experts in terms\nof bias and precision (paired one-sided test procedure for differences in\nmedians and bootstrapped standard deviations with non-inferior boundaries of\n-0.05, 2ml, and 2mm, p < 0.05, n=200). Conclusion: For the segmentation of\nacute ischemic stroke on NCCT, our 3D CNN trained with the annotations of one\nneuroradiologist is non-inferior when compared to two independent\nneuroradiologists.",
    "descriptor": "",
    "authors": [
      "Sophie Ostmeier",
      "Jeremy J. Heit",
      "Brian Axelrod",
      "Li-Jia Li",
      "Greg Zaharchuk",
      "Benjamin F.J. Verhaaren",
      "Abdelkader Mahammedi",
      "Soren Christensen",
      "Maarten G. Lansberg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15341"
  },
  {
    "id": "arXiv:2211.15348",
    "title": "Learning Feynman Diagrams using Graph Neural Networks",
    "abstract": "In the wake of the growing popularity of machine learning in particle\nphysics, this work finds a new application of geometric deep learning on\nFeynman diagrams to make accurate and fast matrix element predictions with the\npotential to be used in analysis of quantum field theory. This research uses\nthe graph attention layer which makes matrix element predictions to 1\nsignificant figure accuracy above 90% of the time. Peak performance was\nachieved in making predictions to 3 significant figure accuracy over 10% of the\ntime with less than 200 epochs of training, serving as a proof of concept on\nwhich future works can build upon for better performance. Finally, a procedure\nis suggested, to use the network to make advancements in quantum field theory\nby constructing Feynman diagrams with effective particles that represent\nnon-perturbative calculations.",
    "descriptor": "",
    "authors": [
      "Harrison Mitchell",
      "Alexander Norcliffe",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15348"
  },
  {
    "id": "arXiv:2211.15371",
    "title": "Content-Based Medical Image Retrieval with Opponent Class Adaptive  Margin Loss",
    "abstract": "Broadspread use of medical imaging devices with digital storage has paved the\nway for curation of substantial data repositories. Fast access to image samples\nwith similar appearance to suspected cases can help establish a consulting\nsystem for healthcare professionals, and improve diagnostic procedures while\nminimizing processing delays. However, manual querying of large data\nrepositories is labor intensive. Content-based image retrieval (CBIR) offers an\nautomated solution based on dense embedding vectors that represent image\nfeatures to allow quantitative similarity assessments. Triplet learning has\nemerged as a powerful approach to recover embeddings in CBIR, albeit\ntraditional loss functions ignore the dynamic relationship between opponent\nimage classes. Here, we introduce a triplet-learning method for automated\nquerying of medical image repositories based on a novel Opponent Class Adaptive\nMargin (OCAM) loss. OCAM uses a variable margin value that is updated\ncontinually during the course of training to maintain optimally discriminative\nrepresentations. CBIR performance of OCAM is compared against state-of-the-art\nloss functions for representational learning on three public databases\n(gastrointestinal disease, skin lesion, lung disease). Comprehensive\nexperiments in each application domain demonstrate the superior performance of\nOCAM against baselines.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "\u015eaban \u00d6zt\u00fcrk",
      "Emin Celik",
      "Tolga Cukur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15371"
  },
  {
    "id": "arXiv:2211.15375",
    "title": "Visual Simulation Software Demonstration for Quantum Multi-Drone  Reinforcement Learning",
    "abstract": "Quantum computing (QC) has received a lot of attention according to its light\ntraining parameter numbers and computational speeds by qubits. Moreover,\nvarious researchers have tried to enable quantum machine learning (QML) using\nQC, where there are also multifarious efforts to use QC to implement quantum\nmulti-agent reinforcement learning (QMARL). Existing classical multi-agent\nreinforcement learning (MARL) using neural network features non-stationarity\nand uncertain properties due to its large number of parameters. Therefore, this\npaper presents a visual simulation software framework for a novel QMARL\nalgorithm to control autonomous multi-drone systems to take advantage of QC.\nOur proposed QMARL framework accomplishes reasonable reward convergence and\nservice quality performance with fewer trainable parameters than the classical\nMARL. Furthermore, QMARL shows more stable training results than existing MARL\nalgorithms. Lastly, our proposed visual simulation software allows us to\nanalyze the agents' training process and results.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Chanyoung Park",
      "Jae Pyoung Kim",
      "Won Joon Yun",
      "Soyi Jung",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.15375"
  },
  {
    "id": "arXiv:2211.15377",
    "title": "Whose Emotion Matters? Speaker Detection without Prior Knowledge",
    "abstract": "The task of emotion recognition in conversations (ERC) benefits from the\navailability of multiple modalities, as offered, for example, in the\nvideo-based MELD dataset. However, only a few research approaches use both\nacoustic and visual information from the MELD videos. There are two reasons for\nthis: First, label-to-video alignments in MELD are noisy, making those videos\nan unreliable source of emotional speech data. Second, conversations can\ninvolve several people in the same scene, which requires the detection of the\nperson speaking the utterance. In this paper we demonstrate that by using\nrecent automatic speech recognition and active speaker detection models, we are\nable to realign the videos of MELD, and capture the facial expressions from\nuttering speakers in 96.92% of the utterances provided in MELD. Experiments\nwith a self-supervised voice recognition model indicate that the realigned MELD\nvideos more closely match the corresponding utterances offered in the dataset.\nFinally, we devise a model for emotion recognition in conversations trained on\nthe face and audio information of the MELD realigned videos, which outperforms\nstate-of-the-art models for ERC based on vision alone. This indicates that\nactive speaker detection is indeed effective for extracting facial expressions\nfrom the uttering speakers, and that faces provide more informative visual cues\nthan the visual features state-of-the-art models have been using so far.",
    "descriptor": "\nComments: 22 pages, 8 figures, 6 tables, submitted to Neurocomputing\n",
    "authors": [
      "Hugo Carneiro",
      "Cornelius Weber",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.15377"
  },
  {
    "id": "arXiv:2211.15380",
    "title": "CaloMan: Fast generation of calorimeter showers with density estimation  on learned manifolds",
    "abstract": "Precision measurements and new physics searches at the Large Hadron Collider\nrequire efficient simulations of particle propagation and interactions within\nthe detectors. The most computationally expensive simulations involve\ncalorimeter showers. Advances in deep generative modelling - particularly in\nthe realm of high-dimensional data - have opened the possibility of generating\nrealistic calorimeter showers orders of magnitude more quickly than\nphysics-based simulation. However, the high-dimensional representation of\nshowers belies the relative simplicity and structure of the underlying physical\nlaws. This phenomenon is yet another example of the manifold hypothesis from\nmachine learning, which states that high-dimensional data is supported on\nlow-dimensional manifolds. We thus propose modelling calorimeter showers first\nby learning their manifold structure, and then estimating the density of data\nacross this manifold. Learning manifold structure reduces the dimensionality of\nthe data, which enables fast training and generation when compared with\ncompeting methods.",
    "descriptor": "\nComments: Accepted to the Machine Learning and the Physical Sciences Workshop at NeurIPS 2022\n",
    "authors": [
      "Jesse C. Cresswell",
      "Brendan Leigh Ross",
      "Gabriel Loaiza-Ganem",
      "Humberto Reyes-Gonzalez",
      "Marco Letizia",
      "Anthony L. Caterini"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2211.15380"
  },
  {
    "id": "arXiv:2211.15383",
    "title": "Deflated Multigrid Multilevel Monte Carlo",
    "abstract": "In lattice QCD, the trace of the inverse of the discretized Dirac operator\nappears in the disconnected fermion loop contribution to an observable. As\nsimulation methods get more and more precise, these contributions become\nincreasingly important. Hence, we consider here the problem of computing the\ntrace $\\mathrm{tr}(D^{-1})$, with $D$ the Dirac operator. The Hutchinson\nmethod, which is very frequently used to stochastically estimate the trace of a\nfunction of a matrix, approximates the trace as the average over estimates of\nthe form $x^{H} D^{-1} x$, with the entries of the vector $x$ following a\ncertain probability distribution. For $N$ samples, the accuracy is\n$\\mathcal{O}(1/\\sqrt{N})$. In recent work, we have introduced multigrid\nmultilevel Monte Carlo: having a multigrid hierarchy with operators $D_{\\ell}$,\n$P_{\\ell}$ and $R_{\\ell}$, for level $\\ell$, we can rewrite the trace\n$\\mathrm{tr}(D^{-1})$ via a telescopic sum with difference-levels, written in\nterms of the aforementioned operators and with a reduced variance. We have seen\nsignificant reductions in the variance and the total work with respect to\nexactly deflated Hutchinson. In this work, we explore the use of exact\ndeflation in combination with the multigrid multilevel Monte Carlo method, and\ndemonstrate how this leads to both algorithmic and computational gains.",
    "descriptor": "",
    "authors": [
      "Andreas Frommer",
      "Gustavo Ramirez-Hidalgo"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15383"
  },
  {
    "id": "arXiv:2211.15415",
    "title": "Machine Learning for Screening Large Organic Molecules",
    "abstract": "Organic semiconductors are promising materials for cheap, scalable and\nsustainable electronics, light-emitting diodes and photovoltaics. For organic\nphotovoltaic cells, it is a challenge to find compounds with suitable\nproperties in the vast chemical compound space. For example, the ionization\nenergy should fit to the optical spectrum of sun light, and the energy levels\nmust allow efficient charge transport. Here, a machine-learning model is\ndeveloped for rapidly and accurately estimating the HOMO and LUMO energies of a\ngiven molecular structure. It is build upon the SchNet model (Sch\\\"utt et al.\n(2018)) and augmented with a `Set2Set' readout module (Vinyals et al. (2016)).\nThe Set2Set module has more expressive power than sum and average aggregation\nand is more suitable for the complex quantities under consideration. Most\nprevious models have been trained and evaluated on rather small molecules.\nTherefore, the second contribution is extending the scope of machine-learning\nmethods by adding also larger molecules from other sources and establishing a\nconsistent train/validation/test split. As a third contribution, we make a\nmultitask ansatz to resolve the problem of different sources coming at\ndifferent levels of theory. All three contributions in conjunction bring the\naccuracy of the model close to chemical accuracy.",
    "descriptor": "\nComments: Presented at E-MRS Fall Meeting 2022, Symposium C\n",
    "authors": [
      "Christopher Gaul",
      "Santiago Cuesta-Lopez"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.15415"
  },
  {
    "id": "arXiv:2211.15420",
    "title": "Equivariant Networks for Crystal Structures",
    "abstract": "Supervised learning with deep models has tremendous potential for\napplications in materials science. Recently, graph neural networks have been\nused in this context, drawing direct inspiration from models for molecules.\nHowever, materials are typically much more structured than molecules, which is\na feature that these models do not leverage. In this work, we introduce a class\nof models that are equivariant with respect to crystalline symmetry groups. We\ndo this by defining a generalization of the message passing operations that can\nbe used with more general permutation groups, or that can alternatively be seen\nas defining an expressive convolution operation on the crystal graph.\nEmpirically, these models achieve competitive results with state-of-the-art on\nproperty prediction tasks.",
    "descriptor": "\nComments: 10 pages, 4 figures + appendix\n",
    "authors": [
      "S\u00e9kou-Oumar Kaba",
      "Siamak Ravanbakhsh"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15420"
  },
  {
    "id": "arXiv:2211.15423",
    "title": "Effective Data Sampling Strategies and Boundary Condition Constraints of  Physics-Informed Neural Networks for Identifying Material Properties in Solid  Mechanics",
    "abstract": "Material identification is critical for understanding the relationship\nbetween mechanical properties and the associated mechanical functions. However,\nmaterial identification is a challenging task, especially when the\ncharacteristic of the material is highly nonlinear in nature, as is common in\nbiological tissue. In this work, we identify unknown material properties in\ncontinuum solid mechanics via physics-informed neural networks (PINNs). To\nimprove the accuracy and efficiency of PINNs, we developed efficient strategies\nto nonuniformly sample observational data. We also investigated different\napproaches to enforce Dirichlet boundary conditions as soft or hard\nconstraints. Finally, we apply the proposed methods to a diverse set of\ntime-dependent and time-independent solid mechanic examples that span linear\nelastic and hyperelastic material space. The estimated material parameters\nachieve relative errors of less than 1%. As such, this work is relevant to\ndiverse applications, including optimizing structural integrity and developing\nnovel materials.",
    "descriptor": "",
    "authors": [
      "Wensi Wu",
      "Mitchell Daneker",
      "Matthew A. Jolley",
      "Kevin T. Turner",
      "Lu Lu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15423"
  },
  {
    "id": "arXiv:2211.15439",
    "title": "Probabilistic Modelling of Signal Mixtures with Differentiable  Dictionaries",
    "abstract": "We introduce a novel way to incorporate prior information into (semi-)\nsupervised non-negative matrix factorization, which we call differentiable\ndictionary search. It enables general, highly flexible and principled modelling\nof mixtures where non-linear sources are linearly mixed. We study its behavior\non an audio decomposition task, and conduct an extensive, highly controlled\nstudy of its modelling capabilities.",
    "descriptor": "\nComments: Published in the Proceedings of the 29th European Signal Processing Conference (EUSIPCO 2021), Dublin, Ireland, August 23-27, 2021 (IEEE), 441-445\n",
    "authors": [
      "Luk\u00e1\u0161 Samuel Mart\u00e1k",
      "Rainer Kelz",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.15439"
  },
  {
    "id": "arXiv:2211.15456",
    "title": "Noise-resilient approach for deep tomographic imaging",
    "abstract": "We propose a noise-resilient deep reconstruction algorithm for X-ray\ntomography. Our approach shows strong noise resilience without obtaining noisy\ntraining examples. The advantages of our framework may further enable\nlow-photon tomographic imaging.",
    "descriptor": "\nComments: 2022 CLEO (the Conference on Lasers and Electro-Optics) conference submission\n",
    "authors": [
      "Zhen Guo",
      "Zhiguang Liu",
      "Qihang Zhang",
      "George Barbastathis",
      "Michael E. Glinsky"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15456"
  },
  {
    "id": "arXiv:2211.15459",
    "title": "Classification of Human Monkeypox Disease Using Deep Learning Models and  Attention Mechanisms",
    "abstract": "As the world is still trying to rebuild from the destruction caused by the\nwidespread reach of the COVID-19 virus, and the recent alarming surge of human\nmonkeypox disease outbreaks in numerous countries threatens to become a new\nglobal pandemic too. Human monkeypox disease syndromes are quite similar to\nchickenpox, and measles classic symptoms, with very intricate differences such\nas skin blisters, which come in diverse forms. Various deep-learning methods\nhave shown promising performances in the image-based diagnosis of COVID-19,\ntumor cell, and skin disease classification tasks. In this paper, we try to\nintegrate deep transfer-learning-based methods, along with a convolutional\nblock attention module (CBAM), to focus on the relevant portion of the feature\nmaps to conduct an image-based classification of human monkeypox disease. We\nimplement five deep-learning models, VGG19, Xception, DenseNet121,\nEfficientNetB3, and MobileNetV2, along with integrated channel and spatial\nattention mechanisms, and perform a comparative analysis among them. An\narchitecture consisting of Xception-CBAM-Dense layers performed better than the\nother models at classifying human monkeypox and other diseases with a\nvalidation accuracy of 83.89%.",
    "descriptor": "\nComments: This paper is currently under review at ICCIT 2022\n",
    "authors": [
      "Md. Enamul Haque",
      "Md. Rayhan Ahmed",
      "Razia Sultana Nila",
      "Salekul Islam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15459"
  },
  {
    "id": "arXiv:2211.15466",
    "title": "Metric entropy of causal, discrete-time LTI systems",
    "abstract": "In [1] it is shown that recurrent neural networks (RNNs) can learn - in a\nmetric entropy optimal manner - discrete time, linear time-invariant (LTI)\nsystems. This is effected by comparing the number of bits needed to encode the\napproximating RNN to the metric entropy of the class of LTI systems under\nconsideration [2, 3]. The purpose of this note is to provide an elementary\nself-contained proof of the metric entropy results in [2, 3], in the process of\nwhich minor mathematical issues appearing in [2, 3] are cleaned up. These\ncorrections also lead to the correction of a constant in a result in [1] (see\nRemark 2.5).",
    "descriptor": "\nComments: [1] arXiv:2105.02556\n",
    "authors": [
      "Clemens Hutter",
      "Thomas Allard",
      "Helmut B\u00f6lcskei"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15466"
  },
  {
    "id": "arXiv:2211.15476",
    "title": "Meta-analysis of individualized treatment rules via sign-coherency",
    "abstract": "Medical treatments tailored to a patient's baseline characteristics hold the\npotential of improving patient outcomes while reducing negative side effects.\nLearning individualized treatment rules (ITRs) often requires aggregation of\nmultiple datasets(sites); however, current ITR methodology does not take\nbetween-site heterogeneity into account, which can hurt model generalizability\nwhen deploying back to each site. To address this problem, we develop a method\nfor individual-level meta-analysis of ITRs, which jointly learns site-specific\nITRs while borrowing information about feature sign-coherency via a\nscientifically-motivated directionality principle. We also develop an adaptive\nprocedure for model tuning, using information criteria tailored to the ITR\nlearning problem. We study the proposed methods through numerical experiments\nto understand their performance under different levels of between-site\nheterogeneity and apply the methodology to estimate ITRs in a large\nmulti-center database of electronic health records. This work extends several\npopular methodologies for estimating ITRs (A-learning, weighted learning) to\nthe multiple-sites setting.",
    "descriptor": "\nComments: Machine Learning for Health (ML4H), 2022\n",
    "authors": [
      "Jay Jojo Cheng",
      "Jared D. Huling",
      "Guanhua Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.15476"
  },
  {
    "id": "arXiv:2211.15477",
    "title": "On digraphs without onion star immersions",
    "abstract": "The $t$-onion star is the digraph obtained from a star with $2t$ leaves by\nreplacing every edge by a triple of arcs, where in $t$ triples we orient two\narcs away from the center, and in the remaining $t$ triples we orient two arcs\ntowards the center. Note that the $t$-onion star contains, as an immersion,\nevery digraph on $t$ vertices where each vertex has outdegree at most $2$ and\nindegree at most $1$, or vice versa. We investigate the structure in digraphs\nthat exclude a fixed onion star as an immersion. The main discovery is that in\nsuch digraphs, for some duality statements true in the undirected setting we\ncan prove their directed analogues. More specifically, we show the next two\nstatements.\nThere is a function $f\\colon \\mathbb{N}\\to \\mathbb{N}$ satisfying the\nfollowing: If a digraph $D$ contains a set $X$ of $2t+1$ vertices such that for\nany $x,y\\in X$ there are $f(t)$ arc-disjoint paths from $x$ to $y$, then $D$\ncontains the $t$-onion star as an immersion.\nThere is a function $g\\colon \\mathbb{N}\\times \\mathbb{N}\\to \\mathbb{N}$\nsatisfying the following: If $x$ and $y$ is a pair of vertices in a digraph $D$\nsuch that there are at least $g(t,k)$ arc-disjoint paths from $x$ to $y$ and\nthere are at least $g(t,k)$ arc-disjoint paths from $y$ to $x$, then either $D$\ncontains the $t$-onion star as an immersion, or there is a family of $2k$\npairwise arc-disjoint paths with $k$ paths from $x$ to $y$ and $k$ paths from\n$y$ to $x$.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "\u0141ukasz Bo\u017cyk",
      "Oscar Defrain",
      "Karolina Okrasa",
      "Micha\u0142 Pilipczuk"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.15477"
  },
  {
    "id": "arXiv:2211.15486",
    "title": "MAPPING: Model Average with Post-processing for Stroke Lesion  Segmentation",
    "abstract": "Accurate stroke lesion segmentation plays a pivotal role in stroke\nrehabilitation research, to provide lesion shape and size information which can\nbe used for quantification of the extent of the stroke and to assess treatment\nefficacy. Recently, automatic segmentation algorithms using deep learning\ntechniques have been developed and achieved promising results. In this report,\nwe present our stroke lesion segmentation model based on nnU-Net framework, and\napply it to the Anatomical Tracings of Lesions After Stroke (ATLAS v2.0)\ndataset. Furthermore, we describe an effective post-processing strategy that\ncan improve some segmentation metrics. Our method took the first place in the\n2022 MICCAI ATLAS Challenge with an average Dice score of 0.6667, Lesion-wise\nF1 score of 0.5643, Simple Lesion Count score of 4.5367, and Volume Difference\nscore of 8804.9102. Our code and trained model weights are publicly available\nat https://github.com/King-HAW/ATLAS-R2-Docker-Submission.",
    "descriptor": "\nComments: Challenge Report, 1st place in 2022 MICCAI ATLAS Challenge\n",
    "authors": [
      "Jiayu Huo",
      "Liyun Chen",
      "Yang Liu",
      "Maxence Boels",
      "Alejandro Granados",
      "Sebastien Ourselin",
      "Rachel Sparks"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15486"
  },
  {
    "id": "arXiv:2211.15489",
    "title": "The Christoffel-Darboux kernel for topological data analysis",
    "abstract": "Persistent homology has been widely used to study the topology of point\nclouds in $\\mathbb{R}^n$. Standard approaches are very sensitive to outliers,\nand their computational complexity depends badly on the number of data points.\nIn this paper we introduce a novel persistence module for a point cloud using\nthe theory of Christoffel-Darboux kernels. This module is robust to\n(statistical) outliers in the data, and can be computed in time linear in the\nnumber of data points. We illustrate the benefits and limitations of our new\nmodule with various numerical examples in $\\mathbb{R}^n$, for $n=1, 2, 3$. Our\nwork expands upon recent applications of Christoffel-Darboux kernels in the\ncontext of statistical data analysis and geometric inference (Lasserre, Pauwels\nand Putinar, 2022). There, these kernels are used to construct a polynomial\nwhose level sets capture the geometry of a point cloud in a precise sense. We\nshow that the persistent homology associated to the sublevel set filtration of\nthis polynomial is stable with respect to the Wasserstein distance. Moreover,\nwe show that the persistent homology of this filtration can be computed in\nsingly exponential time in the ambient dimension $n$, using a recent algorithm\nof Basu & Karisani (2022).",
    "descriptor": "\nComments: 22 pages, 11 figures, 1 table\n",
    "authors": [
      "Pepijn Roos Hoefgeest",
      "Lucas Slot"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15489"
  },
  {
    "id": "arXiv:2211.15498",
    "title": "Physics-informed neural networks with unknown measurement noise",
    "abstract": "Physics-informed neural networks (PINNs) constitute a flexible approach to\nboth finding solutions and identifying parameters of partial differential\nequations. Most works on the topic assume noiseless data, or data contaminated\nby weak Gaussian noise. We show that the standard PINN framework breaks down in\ncase of non-Gaussian noise. We give a way of resolving this fundamental issue\nand we propose to jointly train an energy-based model (EBM) to learn the\ncorrect noise distribution. We illustrate the improved performance of our\napproach using multiple examples.",
    "descriptor": "",
    "authors": [
      "Philipp Pilar",
      "Niklas Wahlstr\u00f6m"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15498"
  },
  {
    "id": "arXiv:2211.15515",
    "title": "How to Prepare for the Next Pandemic -- Investigation of Correlation  Between Food Prices and COVID-19 From Global and Local Perspectives",
    "abstract": "The coronavirus disease (COVID-19) has caused enormous disruptions to not\nonly the United States, but also the global economy. Due to the pandemic,\nissues in the supply chain and concerns about food shortage drove up the food\nprices. According to the U.S. Bureau of Labor Statistics, the prices for food\nincreased 4.1% and 3.7% over the year ended in August 2020 and August 2021,\nrespectively, while the amount of annual increase in the food prices prior to\nthe COVID-19 pandemic is less than 2.0%. Previous studies show that such kinds\nof exogenous disasters, including the 2011 Tohoku Earthquake, 9/11 terrorist\nattacks, and major infectious diseases, and the resulted unusual food prices\noften led to subsequent changes in people's consumption behaviors. We\nhypothesize that the COVID-19 pandemic causes food price changes and the price\nchanges alter people's grocery shopping behaviors as well. To thoroughly\nexplore this, we formulate our analysis from two different perspectives, by\ncollecting data both globally, from China, Japan, United Kingdom, and United\nStates, and locally, from different groups of people inside the US. In\nparticular, we analyze the trends between food prices and COVID-19 as well as\nbetween food prices and spending, aiming to find out their correlations and the\nlessons for preparing the next pandemic.",
    "descriptor": "",
    "authors": [
      "Y. Zhao",
      "C. Huang",
      "J. Luo"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.15515"
  },
  {
    "id": "arXiv:2211.15527",
    "title": "A Study of Representational Properties of Unsupervised Anomaly Detection  in Brain MRI",
    "abstract": "Anomaly detection in MRI is of high clinical value in imaging and diagnosis.\nUnsupervised methods for anomaly detection provide interesting formulations\nbased on reconstruction or latent embedding, offering a way to observe\nproperties related to factorization. We study four existing modeling methods,\nand report our empirical observations using simple data science tools, to seek\noutcomes from the perspective of factorization as it would be most relevant to\nthe task of unsupervised anomaly detection, considering the case of brain\nstructural MRI. Our study indicates that anomaly detection algorithms that\nexhibit factorization related properties are well capacitated with delineatory\ncapabilities to distinguish between normal and anomaly data. We have validated\nour observations in multiple anomaly and normal datasets.",
    "descriptor": "\nComments: Accepted at MICCAI Medical Applications with Disentanglements (MAD) Workshop 2022 this https URL\n",
    "authors": [
      "Ayantika Das",
      "Arun Palla",
      "Keerthi Ram",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15527"
  },
  {
    "id": "arXiv:2211.15539",
    "title": "On the Rellich eigendecomposition of para-Hermitian matrices and the  sign characteristics of $*$-palindromic matrix polynomials",
    "abstract": "We study the eigendecompositions of para-Hermitian matrices $H(z)$, that is,\nmatrix-valued functions that are analytic and Hermitian on the unit circle $S^1\n\\subset \\mathbb C$. In particular, we fill existing gaps in the literature and\nprove the existence of a decomposition $H(z)=U(z)D(z)U(z)^P$ where, for all $z\n\\in S^1$, $U(z)$ is unitary, $U(z)^P=U(z)^*$ is its conjugate transpose, and\n$D(z)$ is real diagonal; moreover, $U(z)$ and $D(z)$ are analytic functions of\n$w=z^{1/N}$ for some positive integer $N$, and $U(z)^P$ is the so-called\npara-Hermitian conjugate of $U(z)$. This generalizes the celebrated theorem of\nRellich for matrix-valued functions that are analytic and Hermitian on the real\nline. We also show that there also exists a decomposition $H(z)=V(z)C(z)V(z)^P$\nwhere $C(z)$ is pseudo-circulant, $V(z)$ is unitary and both are analytic in\n$z$. We argue that, in fact, a version of Rellich's theorem can be stated for\nmatrix-valued function that are analytic and Hermitian on any line or any\ncircle on the complex plane. Moreover, we extend these results to\npara-Hermitian matrices whose entries are Puiseux series (that is, on the unit\ncircle they are analytic in $w$ but possibly not in $z$). Finally, we discuss\nthe implications of our results on the singular value decomposition of a matrix\nwhose entries are $S^1$-analytic functions of $w$, and on the sign\ncharacteristics associated with unimodular eigenvalues of $*$-palindromic\nmatrix polynomials.",
    "descriptor": "",
    "authors": [
      "Giovanni Barbarino",
      "Vanni Noferini"
    ],
    "subjectives": [
      "Complex Variables (math.CV)",
      "Commutative Algebra (math.AC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.15539"
  },
  {
    "id": "arXiv:2211.15577",
    "title": "Exoplanet Detection by Machine Learning with Data Augmentation",
    "abstract": "It has recently been demonstrated that deep learning has significant\npotential to automate parts of the exoplanet detection pipeline using light\ncurve data from satellites such as Kepler \\cite{borucki2010kepler}\n\\cite{koch2010kepler} and NASA's Transiting Exoplanet Survey Satellite (TESS)\n\\cite{ricker2010transiting}. Unfortunately, the smallness of the available\ndatasets makes it difficult to realize the level of performance one expects\nfrom powerful network architectures.\nIn this paper, we investigate the use of data augmentation techniques on\nlight curve data from to train neural networks to identify exoplanets. The\naugmentation techniques used are of two classes: Simple (e.g. additive noise\naugmentation) and learning-based (e.g. first training a GAN\n\\cite{goodfellow2020generative} to generate new examples). We demonstrate that\ndata augmentation has a potential to improve model performance for the\nexoplanet detection problem, and recommend the use of augmentation based on\ngenerative models as more data becomes available.",
    "descriptor": "",
    "authors": [
      "Koray Aydo\u011fan"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15577"
  },
  {
    "id": "arXiv:2211.15618",
    "title": "Multi-Scaling Differential Contraction Integral Method for Inverse  Scattering Problems with Inhomogeneous Media",
    "abstract": "Practical applications of microwave imaging often require the solution of\ninverse scattering problems with inhomogeneous backgrounds. Towards this end, a\nnovel inversion strategy, which combines the multi-scaling (MS) regularization\nscheme and the Difference Contraction Integral Equation (DCIE) formulation, is\nproposed. Such an integrated approach mitigates the non-linearity and the\nill-posedness of the problem to obtain reliable high-resolution reconstructions\nof the unknown scattering profiles. The arising algorithmic implementation,\ndenoted as MS-DCIE, does not require the computation of the Green's function of\nthe inhomogeneous background, thus it provides an efficient and effective way\nto deal with complex scenarios. The performance of the MS-DCIE are assessed by\nmeans of numerical and experimental tests, in comparison with competitive\nstate-of-the-art inversion strategies, as well.",
    "descriptor": "",
    "authors": [
      "Yu Zhong",
      "Francesco Zardi",
      "Marco Salucci",
      "Giacomo Oliveri",
      "Andrea Massa"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15618"
  },
  {
    "id": "arXiv:2211.15631",
    "title": "Benchmarking simulated and physical quantum processing units using  quantum and hybrid algorithms",
    "abstract": "Powerful hardware services and software libraries are vital tools for quickly\nand affordably designing, testing, and executing quantum algorithms. A robust\nlarge-scale study of how the performance of these platforms scales with the\nnumber of qubits is key to providing quantum solutions to challenging industry\nproblems. Such an evaluation is difficult owing to the availability and price\nof physical quantum processing units. This work benchmarks the runtime and\naccuracy for a representative sample of specialized high-performance simulated\nand physical quantum processing units. Results show the QMware cloud computing\nservice can reduce the runtime for executing a quantum circuit by up to 78%\ncompared to the next fastest option for algorithms with fewer than 27 qubits.\nThe AWS SV1 simulator offers a runtime advantage for larger circuits, up to the\nmaximum 34 qubits available with SV1. Beyond this limit, QMware provides the\nability to execute circuits as large as 40 qubits. Physical quantum devices,\nsuch as Rigetti's Aspen-M2, can provide an exponential runtime advantage for\ncircuits with more than 30. However, the high financial cost of physical\nquantum processing units presents a serious barrier to practical use. Moreover,\nof the four quantum devices tested, only IonQ's Harmony achieves high fidelity\nwith more than four qubits. This study paves the way to understanding the\noptimal combination of available software and hardware for executing practical\nquantum algorithms.",
    "descriptor": "\nComments: 17 pages, 4 figures, 11 tables\n",
    "authors": [
      "Mohammad Kordzanganeh",
      "Markus Buchberger",
      "Maxim Povolotskii",
      "Wilhelm Fischer",
      "Andrii Kurkin",
      "Wilfrid Somogyi",
      "Asel Sagingalieva",
      "Markus Pflitsch",
      "Alexey Melnikov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.15631"
  },
  {
    "id": "arXiv:2211.15646",
    "title": "Beyond Invariance: Test-Time Label-Shift Adaptation for Distributions  with \"Spurious\" Correlations",
    "abstract": "Spurious correlations, or correlations that change across domains where a\nmodel can be deployed, present significant challenges to real-world\napplications of machine learning models. However, such correlations are not\nalways \"spurious\"; often, they provide valuable prior information for a\nprediction beyond what can be extracted from the input alone. Here, we present\na test-time adaptation method that exploits the spurious correlation\nphenomenon, in contrast to recent approaches that attempt to eliminate spurious\ncorrelations through invariance. We consider situations where the prior\ndistribution $p(y, z)$, which models the marginal dependence between the class\nlabel $y$ and the nuisance factors $z$, may change across domains, but the\ngenerative model for features $p(\\mathbf{x}|y, z)$ is constant. We note that\nthis is an expanded version of the label shift assumption, where the labels now\nalso include the nuisance factors $z$. Based on this observation, we train a\nclassifier to predict $p(y, z|\\mathbf{x})$ on the source distribution, and\nimplement a test-time label shift correction that adapts to changes in the\nmarginal distribution $p(y, z)$ using unlabeled samples from the target domain.\nWe call our method \"Test-Time Label-Shift Adaptation\" or TTLSA. We apply our\nmethod to two different image datasets -- the CheXpert chest X-ray dataset and\nthe colored MNIST dataset -- and show that it gives better downstream results\nthan methods that try to train classifiers which are invariant to the changes\nin prior distribution. Code reproducing experiments is available at\nhttps://github.com/nalzok/test-time-label-shift .",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Qingyao Sun",
      "Kevin Murphy",
      "Sayna Ebrahimi",
      "Alexander D'Amour"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15646"
  },
  {
    "id": "arXiv:2211.15652",
    "title": "Stochastic Optimal Control via Local Occupation Measures",
    "abstract": "Viewing stochastic processes through the lens of occupation measures has\nproven to be a powerful angle of attack for the theoretical and computational\nanalysis for a wide range of stochastic optimal control problems. We present a\nsimple modification of the traditional occupation measure framework derived\nfrom resolving the occupation measures locally on a partition of the state\nspace and control horizon. This modification bridges the gap between\ndiscretization based approximations to the solution of the\nHamilton-Jacobi-Bellmann equations and convex optimization based approaches\nrelying on the moment-sum-of-squares hierarchy. When combined with the\nmoment-sum-of-squares hierarchy, the notion of local occupation measures\nprovides fine-grained control over the construction of highly structured\nsemidefinite programming relaxations for a rich class of stochastic optimal\ncontrol problems with embedded diffusion and jump processes. We show how these\nrelaxations are constructed, analyze their favorable properties, and\ndemonstrate with examples that they hold the potential to allow for the\ncomputation of tighter bounds orders of magnitude faster than is possible via\nnaive combination of the moment-sum-of-squares hierarchy with the traditional\noccupation measure framework.",
    "descriptor": "\nComments: 22 pages, 10 figures, associated implementation: this https URL\n",
    "authors": [
      "Flemming Holtorf",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15652"
  },
  {
    "id": "arXiv:1711.00956",
    "title": "Running Time Analysis of the (1+1)-EA for OneMax and LeadingOnes under  Bit-wise Noise",
    "abstract": "Running Time Analysis of the (1+1)-EA for OneMax and LeadingOnes under  Bit-wise Noise",
    "descriptor": "",
    "authors": [
      "Chao Qian",
      "Chao Bian",
      "Wu Jiang",
      "Ke Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1711.00956"
  },
  {
    "id": "arXiv:1711.07214",
    "title": "Maximizing Submodular or Monotone Approximately Submodular Functions by  Multi-objective Evolutionary Algorithms",
    "abstract": "Maximizing Submodular or Monotone Approximately Submodular Functions by  Multi-objective Evolutionary Algorithms",
    "descriptor": "",
    "authors": [
      "Chao Qian",
      "Yang Yu",
      "Ke Tang",
      "Xin Yao",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1711.07214"
  },
  {
    "id": "arXiv:1810.05045",
    "title": "Analysis of Noisy Evolutionary Optimization When Sampling Fails",
    "abstract": "Analysis of Noisy Evolutionary Optimization When Sampling Fails",
    "descriptor": "",
    "authors": [
      "Chao Qian",
      "Chao Bian",
      "Yang Yu",
      "Ke Tang",
      "Xin Yao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1810.05045"
  },
  {
    "id": "arXiv:1901.10112",
    "title": "Evaluating Generalization Ability of Convolutional Neural Networks and  Capsule Networks for Image Classification via Top-2 Classification",
    "abstract": "Evaluating Generalization Ability of Convolutional Neural Networks and  Capsule Networks for Image Classification via Top-2 Classification",
    "descriptor": "",
    "authors": [
      "Hao Ren",
      "Jianlin Su",
      "Hong Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1901.10112"
  },
  {
    "id": "arXiv:1904.07693",
    "title": "Frequent Itemset Mining using QUBO",
    "abstract": "Frequent Itemset Mining using QUBO",
    "descriptor": "",
    "authors": [
      "Jonas N\u00fc\u00dflein"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/1904.07693"
  },
  {
    "id": "arXiv:1907.08759",
    "title": "Latency Minimization for Multiuser Computation Offloading in Fog-Radio  Access Networks",
    "abstract": "Comments: submitted for publication",
    "descriptor": "\nComments: submitted for publication\n",
    "authors": [
      "Wei Zhang",
      "Shafei Wang",
      "Ye Pan",
      "Qiang Li",
      "Jingran Lin",
      "Xiaoxiao Wu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1907.08759"
  },
  {
    "id": "arXiv:1907.13100",
    "title": "On the Robustness of Median Sampling in Noisy Evolutionary Optimization",
    "abstract": "Comments: 19 pages. arXiv admin note: text overlap with arXiv:1810.05045, arXiv:1711.00956",
    "descriptor": "\nComments: 19 pages. arXiv admin note: text overlap with arXiv:1810.05045, arXiv:1711.00956\n",
    "authors": [
      "Chao Bian",
      "Chao Qian",
      "Yang Yu",
      "Ke Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1907.13100"
  },
  {
    "id": "arXiv:1909.06988",
    "title": "Explicit near-Ramanujan graphs of every degree",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Sidhanth Mohanty",
      "Ryan O'Donnell",
      "Pedro Paredes"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1909.06988"
  },
  {
    "id": "arXiv:1910.00277",
    "title": "Polynomial-Time Data Reduction for Weighted Problems Beyond Additive  Goal Functions",
    "abstract": "Polynomial-Time Data Reduction for Weighted Problems Beyond Additive  Goal Functions",
    "descriptor": "",
    "authors": [
      "Matthias Bentert",
      "Ren\u00e9 van Bevern",
      "Till Fluschnik",
      "Andr\u00e9 Nichterlein",
      "Rolf Niedermeier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1910.00277"
  },
  {
    "id": "arXiv:1910.05492",
    "title": "Multi-objective Evolutionary Algorithms are Still Good: Maximizing  Monotone Approximately Submodular Minus Modular Functions",
    "abstract": "Multi-objective Evolutionary Algorithms are Still Good: Maximizing  Monotone Approximately Submodular Minus Modular Functions",
    "descriptor": "",
    "authors": [
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/1910.05492"
  },
  {
    "id": "arXiv:1911.10783",
    "title": "Financial Event Extraction Using Wikipedia-Based Weak Supervision",
    "abstract": "Financial Event Extraction Using Wikipedia-Based Weak Supervision",
    "descriptor": "",
    "authors": [
      "Liat Ein-Dor",
      "Ariel Gera",
      "Orith Toledo-Ronen",
      "Alon Halfon",
      "Benjamin Sznajder",
      "Lena Dankin",
      "Yonatan Bilu",
      "Yoav Katz",
      "Noam Slonim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/1911.10783"
  },
  {
    "id": "arXiv:1912.01391",
    "title": "Diffusion Maps for Embedded Manifolds with Boundary with Applications to  PDEs",
    "abstract": "Diffusion Maps for Embedded Manifolds with Boundary with Applications to  PDEs",
    "descriptor": "",
    "authors": [
      "Ryan Vaughn",
      "Tyrus Berry",
      "Harbir Antil"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/1912.01391"
  },
  {
    "id": "arXiv:2002.11830",
    "title": "Polynomial algorithms for p-dispersion problems in a planar Pareto Front",
    "abstract": "Polynomial algorithms for p-dispersion problems in a planar Pareto Front",
    "descriptor": "",
    "authors": [
      "Nicolas Dupin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2002.11830"
  },
  {
    "id": "arXiv:2003.08080",
    "title": "Improving the Robustness to Data Inconsistency between Training and  Testing for Code Completion by Hierarchical Language Model",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Yixiao Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2003.08080"
  },
  {
    "id": "arXiv:2003.11313",
    "title": "Fair allocation of indivisible items with conflict graphs",
    "abstract": "Comments: A preliminary version containing some of the results presented here appeared in the proceedings of IWOCA 2020",
    "descriptor": "\nComments: A preliminary version containing some of the results presented here appeared in the proceedings of IWOCA 2020\n",
    "authors": [
      "Nina Chiarelli",
      "Matja\u017e Krnc",
      "Martin Milani\u010d",
      "Ulrich Pferschy",
      "Nevena Piva\u010d",
      "Joachim Schauer"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2003.11313"
  },
  {
    "id": "arXiv:2004.08694",
    "title": "Syn-QG: Syntactic and Shallow Semantic Rules for Question Generation",
    "abstract": "Comments: Removed Table 5 of earlier version since row 1,4 couldn't be reproduced",
    "descriptor": "\nComments: Removed Table 5 of earlier version since row 1,4 couldn't be reproduced\n",
    "authors": [
      "Kaustubh D. Dhole",
      "Christopher D. Manning"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2004.08694"
  },
  {
    "id": "arXiv:2009.04975",
    "title": "Forecasting financial markets with semantic network analysis in the  COVID-19 crisis",
    "abstract": "Forecasting financial markets with semantic network analysis in the  COVID-19 crisis",
    "descriptor": "",
    "authors": [
      "A. Fronzetti Colladon",
      "S. Grassi",
      "F. Ravazzolo",
      "F. Violante"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2009.04975"
  },
  {
    "id": "arXiv:2011.10916",
    "title": "Hierachical Delta-Attention Method for Multimodal Fusion",
    "abstract": "Comments: Need to update the results",
    "descriptor": "\nComments: Need to update the results\n",
    "authors": [
      "Kunjal Panchal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.10916"
  },
  {
    "id": "arXiv:2103.06615",
    "title": "Controlled Gaussian Process Dynamical Models with Application to Robotic  Cloth Manipulation",
    "abstract": "Controlled Gaussian Process Dynamical Models with Application to Robotic  Cloth Manipulation",
    "descriptor": "",
    "authors": [
      "Fabio Amadio",
      "Juan Antonio Delgado-Guerrero",
      "Adri\u00e0 Colom\u00e9",
      "Carme Torras"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06615"
  },
  {
    "id": "arXiv:2104.02206",
    "title": "Lifelong Compositional Feature Replays Beat Image Replays in Stream  Learning",
    "abstract": "Lifelong Compositional Feature Replays Beat Image Replays in Stream  Learning",
    "descriptor": "",
    "authors": [
      "Morgan B. Talbot",
      "Rushikesh Zawar",
      "Rohil Badkundri",
      "Mengmi Zhang",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.02206"
  },
  {
    "id": "arXiv:2104.07932",
    "title": "Interval-censored Hawkes processes",
    "abstract": "Interval-censored Hawkes processes",
    "descriptor": "",
    "authors": [
      "Marian-Andrei Rizoiu",
      "Alexander Soen",
      "Shidi Li",
      "Pio Calderon",
      "Leanne Dong",
      "Aditya Krishna Menon",
      "Lexing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.07932"
  },
  {
    "id": "arXiv:2105.06178",
    "title": "Paying Attention to Astronomical Transients: Introducing the Time-series  Transformer for Photometric Classification",
    "abstract": "Comments: Revised argument in section 5.2 and 5.3, and minor change to title, results unchanged. 15 pages, 12 figures",
    "descriptor": "\nComments: Revised argument in section 5.2 and 5.3, and minor change to title, results unchanged. 15 pages, 12 figures\n",
    "authors": [
      "Tarek Allam Jr.",
      "Jason D. McEwen"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.06178"
  },
  {
    "id": "arXiv:2105.06948",
    "title": "People construct simplified mental representations to plan",
    "abstract": "Comments: 56 pages, 5 main figures, 10 extended data figures, supplementary information is included in ancillary files",
    "descriptor": "\nComments: 56 pages, 5 main figures, 10 extended data figures, supplementary information is included in ancillary files\n",
    "authors": [
      "Mark K. Ho",
      "David Abel",
      "Carlos G. Correa",
      "Michael L. Littman",
      "Jonathan D. Cohen",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06948"
  },
  {
    "id": "arXiv:2105.12972",
    "title": "Tight Lower Bounds for $\u03b1$-Divergences Under Moment Constraints and  Relations Between Different $\u03b1$",
    "abstract": "Comments: 13 pages. arXiv admin note: text overlap with arXiv:2010.13548",
    "descriptor": "\nComments: 13 pages. arXiv admin note: text overlap with arXiv:2010.13548\n",
    "authors": [
      "Tomohiro Nishiyama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.12972"
  },
  {
    "id": "arXiv:2106.03844",
    "title": "Mean-Shifted Contrastive Loss for Anomaly Detection",
    "abstract": "Comments: AAAI 2023",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Tal Reiss",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03844"
  },
  {
    "id": "arXiv:2106.09547",
    "title": "Machine Learning for Postprocessing Ensemble Streamflow Forecasts",
    "abstract": "Machine Learning for Postprocessing Ensemble Streamflow Forecasts",
    "descriptor": "",
    "authors": [
      "Sanjib Sharma",
      "Ganesh Raj Ghimire",
      "Ridwan Siddique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09547"
  },
  {
    "id": "arXiv:2106.11299",
    "title": "Boundary Graph Neural Networks for 3D Simulations",
    "abstract": "Comments: accepted for presentation at the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)",
    "descriptor": "\nComments: accepted for presentation at the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)\n",
    "authors": [
      "Andreas Mayr",
      "Sebastian Lehner",
      "Arno Mayrhofer",
      "Christoph Kloss",
      "Sepp Hochreiter",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.11299"
  },
  {
    "id": "arXiv:2107.00157",
    "title": "Cross-Lingual Transfer Learning for Statistical Type Inference",
    "abstract": "Cross-Lingual Transfer Learning for Statistical Type Inference",
    "descriptor": "",
    "authors": [
      "Zhiming Li",
      "Xiaofei Xie",
      "Haoliang Li",
      "Zhengzi Xu",
      "Yi Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00157"
  },
  {
    "id": "arXiv:2107.03642",
    "title": "Image restoration quality assessment based on regional differential  information entropy",
    "abstract": "Comments: 14 pages, 8 figures, 5 tables",
    "descriptor": "\nComments: 14 pages, 8 figures, 5 tables\n",
    "authors": [
      "Zhiyu Wang",
      "Jiayan Zhuang",
      "Ningyuan Xu",
      "Sichao Ye",
      "Jiangjian Xiao",
      "Chengbin Peng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.03642"
  },
  {
    "id": "arXiv:2107.09543",
    "title": "Data synthesis and adversarial networks: A review and meta-analysis in  cancer imaging",
    "abstract": "Comments: v2, 51 pages, 15 Figures, 9 Tables, accepted for publication in Medical Image Analysis",
    "descriptor": "\nComments: v2, 51 pages, 15 Figures, 9 Tables, accepted for publication in Medical Image Analysis\n",
    "authors": [
      "Richard Osuala",
      "Kaisar Kushibar",
      "Lidia Garrucho",
      "Akis Linardos",
      "Zuzanna Szafranowska",
      "Stefan Klein",
      "Ben Glocker",
      "Oliver Diaz",
      "Karim Lekadir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.09543"
  },
  {
    "id": "arXiv:2108.00207",
    "title": "The Separation Capacity of Random Neural Networks",
    "abstract": "Comments: The current version of the manuscript has been accepted to Journal of Machine Learning Research",
    "descriptor": "\nComments: The current version of the manuscript has been accepted to Journal of Machine Learning Research\n",
    "authors": [
      "Sjoerd Dirksen",
      "Martin Genzel",
      "Laurent Jacques",
      "Alexander Stollenwerk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2108.00207"
  },
  {
    "id": "arXiv:2108.04551",
    "title": "ABC-FL: Anomalous and Benign client Classification in Federated Learning",
    "abstract": "ABC-FL: Anomalous and Benign client Classification in Federated Learning",
    "descriptor": "",
    "authors": [
      "Hyejun Jeong",
      "Joonyong Hwang",
      "Tai Myung Chung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.04551"
  },
  {
    "id": "arXiv:2108.10392",
    "title": "A generalized stacked reinforcement learning method for sampled systems",
    "abstract": "A generalized stacked reinforcement learning method for sampled systems",
    "descriptor": "",
    "authors": [
      "Pavel Osinenko",
      "Dmitrii Dobriborsci",
      "Grigory Yaremenko",
      "Georgiy Malaniya"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.10392"
  },
  {
    "id": "arXiv:2108.13408",
    "title": "View Synthesis of Dynamic Scenes based on Deep 3D Mask Volume",
    "abstract": "Comments: This is the extended version of the paper published at ICCV 2021. Code and dataset available at: this https URL",
    "descriptor": "\nComments: This is the extended version of the paper published at ICCV 2021. Code and dataset available at: this https URL\n",
    "authors": [
      "Kai-En Lin",
      "Guowei Yang",
      "Lei Xiao",
      "Feng Liu",
      "Ravi Ramamoorthi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2108.13408"
  },
  {
    "id": "arXiv:2109.06366",
    "title": "A Dyadic Simulation Approach to Efficient Range-Summability",
    "abstract": "A Dyadic Simulation Approach to Efficient Range-Summability",
    "descriptor": "",
    "authors": [
      "Jingfan Meng",
      "Huayi Wang",
      "Jun Xu",
      "Mitsunori Ogihara"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.06366"
  },
  {
    "id": "arXiv:2109.12769",
    "title": "Heterogeneous Treatment Effect Estimation using machine learning for  Healthcare application: tutorial and benchmark",
    "abstract": "Comments: 52 pages, 8 figures",
    "descriptor": "\nComments: 52 pages, 8 figures\n",
    "authors": [
      "Yaobin Ling",
      "Pulakesh Upadhyaya",
      "Luyao Chen",
      "Xiaoqian Jiang",
      "Yejin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2109.12769"
  },
  {
    "id": "arXiv:2109.13956",
    "title": "Bit Complexity of Jordan Normal Form and Spectral Factorization",
    "abstract": "Comments: 19pp",
    "descriptor": "\nComments: 19pp\n",
    "authors": [
      "Papri Dey",
      "Ravi Kannan",
      "Nick Ryder",
      "Nikhil Srivastava"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Symbolic Computation (cs.SC)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.13956"
  },
  {
    "id": "arXiv:2110.03912",
    "title": "Stereo Dense Scene Reconstruction and Accurate Localization for  Learning-Based Navigation of Laparoscope in Minimally Invasive Surgery",
    "abstract": "Stereo Dense Scene Reconstruction and Accurate Localization for  Learning-Based Navigation of Laparoscope in Minimally Invasive Surgery",
    "descriptor": "",
    "authors": [
      "Ruofeng Wei",
      "Bin Li",
      "Hangjie Mo",
      "Bo Lu",
      "Yonghao Long",
      "Bohan Yang",
      "Qi Dou",
      "Yunhui Liu",
      "Dong Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.03912"
  },
  {
    "id": "arXiv:2110.05437",
    "title": "Autonomous Racing using a Hybrid Imitation-Reinforcement Learning  Architecture",
    "abstract": "Autonomous Racing using a Hybrid Imitation-Reinforcement Learning  Architecture",
    "descriptor": "",
    "authors": [
      "Chinmay Vilas Samak",
      "Tanmay Vilas Samak",
      "Sivanathan Kandhasamy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.05437"
  },
  {
    "id": "arXiv:2110.08298",
    "title": "Non-Euclidean Contraction Analysis of Continuous-Time Neural Networks",
    "abstract": "Non-Euclidean Contraction Analysis of Continuous-Time Neural Networks",
    "descriptor": "",
    "authors": [
      "Alexander Davydov",
      "Anton V. Proskurnikov",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.08298"
  },
  {
    "id": "arXiv:2110.08567",
    "title": "Detecting directional forces in the evolution of grammar: A case study  of the English perfect using EEBO, COHA, and Google Books",
    "abstract": "Comments: 22 pages, 3 figures, 4 tables, with SM",
    "descriptor": "\nComments: 22 pages, 3 figures, 4 tables, with SM\n",
    "authors": [
      "Shimpei Okuda",
      "Michio Hosaka",
      "Kazutoshi Sasahara"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.08567"
  },
  {
    "id": "arXiv:2110.09813",
    "title": "Multi-Objective Loss Balancing for Physics-Informed Deep Learning",
    "abstract": "Multi-Objective Loss Balancing for Physics-Informed Deep Learning",
    "descriptor": "",
    "authors": [
      "Rafael Bischof",
      "Michael Kraus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09813"
  },
  {
    "id": "arXiv:2110.12534",
    "title": "Integration of Blockchain and Auction Models: A Survey, Some  Applications, and Challenges",
    "abstract": "Integration of Blockchain and Auction Models: A Survey, Some  Applications, and Challenges",
    "descriptor": "",
    "authors": [
      "Zeshun Shi",
      "Cees de Laat",
      "Paola Grosso",
      "Zhiming Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.12534"
  },
  {
    "id": "arXiv:2111.00043",
    "title": "Multivariate rank via entropic optimal transport: sample efficiency and  generative modeling",
    "abstract": "Comments: 46 pages, 10 figures. Replacement note: Substantial revision over V2: Title change, first authors contribution change, new improved theoretical results relaxing compactness assumptions",
    "descriptor": "\nComments: 46 pages, 10 figures. Replacement note: Substantial revision over V2: Title change, first authors contribution change, new improved theoretical results relaxing compactness assumptions\n",
    "authors": [
      "Shoaib Bin Masud",
      "Matthew Werenski",
      "James M. Murphy",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00043"
  },
  {
    "id": "arXiv:2111.08093",
    "title": "Monotone Inclusions, Acceleration and Closed-Loop Control",
    "abstract": "Comments: Accepted by Mathematics of Operations Research; 42 Pages",
    "descriptor": "\nComments: Accepted by Mathematics of Operations Research; 42 Pages\n",
    "authors": [
      "Tianyi Lin",
      "Michael. I. Jordan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.08093"
  },
  {
    "id": "arXiv:2111.12958",
    "title": "Self-Distilled Self-Supervised Representation Learning",
    "abstract": "Comments: WACV 23, 11 pages",
    "descriptor": "\nComments: WACV 23, 11 pages\n",
    "authors": [
      "Jiho Jang",
      "Seonhoon Kim",
      "Kiyoon Yoo",
      "Chaerin Kong",
      "Jangho Kim",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12958"
  },
  {
    "id": "arXiv:2111.13108",
    "title": "Combating Unknown Bias with Effective Bias-Conflicting Scoring and  Gradient Alignment",
    "abstract": "Combating Unknown Bias with Effective Bias-Conflicting Scoring and  Gradient Alignment",
    "descriptor": "",
    "authors": [
      "Bowen Zhao",
      "Chen Chen",
      "Qian-Wei Wang",
      "Anfeng He",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13108"
  },
  {
    "id": "arXiv:2111.13636",
    "title": "On a Stochastic Fundamental Lemma and Its Use for Data-Driven Optimal  Control",
    "abstract": "On a Stochastic Fundamental Lemma and Its Use for Data-Driven Optimal  Control",
    "descriptor": "",
    "authors": [
      "Guanru Pan",
      "Ruchuan Ou",
      "Timm Faulwasser"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.13636"
  },
  {
    "id": "arXiv:2111.15147",
    "title": "State-of-Charge Aware EV Charging",
    "abstract": "Comments: Best Paper, 2023 Power and Energy Society General Meeting (PESGM) on Renewables, Storage, and Electric Vehicles. Code available at this https URL",
    "descriptor": "\nComments: Best Paper, 2023 Power and Energy Society General Meeting (PESGM) on Renewables, Storage, and Electric Vehicles. Code available at this https URL\n",
    "authors": [
      "Yize Chen",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.15147"
  },
  {
    "id": "arXiv:2112.00639",
    "title": "A Systematic Review of Robustness in Deep Learning for Computer Vision:  Mind the gap?",
    "abstract": "A Systematic Review of Robustness in Deep Learning for Computer Vision:  Mind the gap?",
    "descriptor": "",
    "authors": [
      "Nathan Drenkow",
      "Numair Sani",
      "Ilya Shpitser",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00639"
  },
  {
    "id": "arXiv:2112.01075",
    "title": "Memory-efficient array redistribution through portable collective  communication",
    "abstract": "Comments: minor errata fixed",
    "descriptor": "\nComments: minor errata fixed\n",
    "authors": [
      "Norman A. Rink",
      "Adam Paszke",
      "Dimitrios Vytiniotis",
      "Georg Stefan Schmid"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2112.01075"
  },
  {
    "id": "arXiv:2112.01517",
    "title": "Efficient Neural Radiance Fields for Interactive Free-viewpoint Video",
    "abstract": "Comments: SIGGRAPH Asia 2022; Project page: this https URL",
    "descriptor": "\nComments: SIGGRAPH Asia 2022; Project page: this https URL\n",
    "authors": [
      "Haotong Lin",
      "Sida Peng",
      "Zhen Xu",
      "Yunzhi Yan",
      "Qing Shuai",
      "Hujun Bao",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01517"
  },
  {
    "id": "arXiv:2112.02731",
    "title": "Detecting DeFi Securities Violations from Token Smart Contract Code",
    "abstract": "Detecting DeFi Securities Violations from Token Smart Contract Code",
    "descriptor": "",
    "authors": [
      "Arianna Trozze",
      "Bennett Kleinberg",
      "Toby Davies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02731"
  },
  {
    "id": "arXiv:2112.03235",
    "title": "Simulation Intelligence: Towards a New Generation of Scientific Methods",
    "abstract": "Simulation Intelligence: Towards a New Generation of Scientific Methods",
    "descriptor": "",
    "authors": [
      "Alexander Lavin",
      "David Krakauer",
      "Hector Zenil",
      "Justin Gottschlich",
      "Tim Mattson",
      "Johann Brehmer",
      "Anima Anandkumar",
      "Sanjay Choudry",
      "Kamil Rocki",
      "At\u0131l\u0131m G\u00fcne\u015f Baydin",
      "Carina Prunkl",
      "Brooks Paige",
      "Olexandr Isayev",
      "Erik Peterson",
      "Peter L. McMahon",
      "Jakob Macke",
      "Kyle Cranmer",
      "Jiaxin Zhang",
      "Haruko Wainwright",
      "Adi Hanuka",
      "Manuela Veloso",
      "Samuel Assefa",
      "Stephan Zheng",
      "Avi Pfeffer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2112.03235"
  },
  {
    "id": "arXiv:2112.10644",
    "title": "Self-attention Presents Low-dimensional Knowledge Graph Embeddings for  Link Prediction",
    "abstract": "Comments: 14 pages, 3 figure, 6 tables",
    "descriptor": "\nComments: 14 pages, 3 figure, 6 tables\n",
    "authors": [
      "Peyman Baghershahi",
      "Reshad Hosseini",
      "Hadi Moradi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.10644"
  },
  {
    "id": "arXiv:2112.12438",
    "title": "Using Sequential Statistical Tests for Efficient Hyperparameter Tuning",
    "abstract": "Using Sequential Statistical Tests for Efficient Hyperparameter Tuning",
    "descriptor": "",
    "authors": [
      "Philip Buczak",
      "Andreas Groll",
      "Markus Pauly",
      "Jakob Rehof",
      "Daniel Horn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.12438"
  },
  {
    "id": "arXiv:2112.12510",
    "title": "Neuroevolution deep learning architecture search for estimation of river  surface elevation from photogrammetric Digital Surface Models",
    "abstract": "Comments: extended version of NeurIPS 2021 Workshop paper - ML4PhysicalSciences",
    "descriptor": "\nComments: extended version of NeurIPS 2021 Workshop paper - ML4PhysicalSciences\n",
    "authors": [
      "Rados\u0142aw Szostak",
      "Marcin Pietro\u0144",
      "Miros\u0142aw Zimnoch",
      "Przemys\u0142aw Wachniew",
      "Pawe\u0142 \u0106wi\u0105ka\u0142a",
      "Edyta Puniach"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12510"
  },
  {
    "id": "arXiv:2112.14351",
    "title": "Geometric Decompositions of $H(\\textrm{div})$-conforming Finite Element  Tensors, Part I: Vector and Matrix Functions",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Long Chen",
      "Xuehai Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.14351"
  },
  {
    "id": "arXiv:2201.00387",
    "title": "On the convex hull of convex quadratic optimization problems with  indicators",
    "abstract": "On the convex hull of convex quadratic optimization problems with  indicators",
    "descriptor": "",
    "authors": [
      "Linchuan Wei",
      "Alper Atamt\u00fcrk",
      "Andr\u00e9s G\u00f3mez",
      "Simge K\u00fc\u00e7\u00fckyavuz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00387"
  },
  {
    "id": "arXiv:2201.00426",
    "title": "Deep Learning and Linear Programming for Automated Ensemble Forecasting  and Interpretation",
    "abstract": "Deep Learning and Linear Programming for Automated Ensemble Forecasting  and Interpretation",
    "descriptor": "",
    "authors": [
      "Lars Lien Ankile",
      "Kjartan Krange"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2201.00426"
  },
  {
    "id": "arXiv:2201.00567",
    "title": "Ant colonization processed algorithm for design of a toroidal shaped  mobile 5G antenna",
    "abstract": "Comments: Withdrawn for major modifications",
    "descriptor": "\nComments: Withdrawn for major modifications\n",
    "authors": [
      "Sunit Shantanu DIgamber Fulari",
      "Harbinder Singh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.00567"
  },
  {
    "id": "arXiv:2201.00569",
    "title": "Design of Differently shaped antenna by using Major Modifications in  Design of copper annealed and FR4 junction",
    "abstract": "Comments: Withdrawn for major modifications",
    "descriptor": "\nComments: Withdrawn for major modifications\n",
    "authors": [
      "Sunit Shantanu Digamber Fulari",
      "Harbinder Singh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.00569"
  },
  {
    "id": "arXiv:2201.00573",
    "title": "Antenna parameterization for effectiveness in horn shaped antenna for 5G  communication as future of Antennas",
    "abstract": "Comments: Withdrawn for major modifications",
    "descriptor": "\nComments: Withdrawn for major modifications\n",
    "authors": [
      "Sunit Shantanu Digamber Fulari",
      "Harbinder Singh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.00573"
  },
  {
    "id": "arXiv:2201.01825",
    "title": "Planted Dense Subgraphs in Dense Random Graphs Can Be Recovered using  Graph-based Machine Learning",
    "abstract": "Planted Dense Subgraphs in Dense Random Graphs Can Be Recovered using  Graph-based Machine Learning",
    "descriptor": "",
    "authors": [
      "Itay Levinas",
      "Yoram Louzoun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01825"
  },
  {
    "id": "arXiv:2201.03615",
    "title": "Geometric Rank and Linear Determinantal Varieties",
    "abstract": "Geometric Rank and Linear Determinantal Varieties",
    "descriptor": "",
    "authors": [
      "Runshi Geng"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.03615"
  },
  {
    "id": "arXiv:2201.05242",
    "title": "Neural Circuit Architectural Priors for Embodied Control",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Nikhil X. Bhattasali",
      "Anthony M. Zador",
      "Tatiana A. Engel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2201.05242"
  },
  {
    "id": "arXiv:2201.05646",
    "title": "ULTRA: A Data-driven Approach for Recommending Team Formation in  Response to Proposal Calls",
    "abstract": "Comments: 8 pages, Accepted to IEEE ICDM Workshop on AI for Nudging and Personalization (WAIN) 2022",
    "descriptor": "\nComments: 8 pages, Accepted to IEEE ICDM Workshop on AI for Nudging and Personalization (WAIN) 2022\n",
    "authors": [
      "Biplav Srivastava",
      "Tarmo Koppel",
      "Sai Teja Paladi",
      "Siva Likitha Valluru",
      "Rohit Sharma",
      "Owen Bond"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.05646"
  },
  {
    "id": "arXiv:2201.06714",
    "title": "AdaTerm: Adaptive T-Distribution Estimated Robust Moments towards  Noise-Robust Stochastic Gradient Optimizer",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Wendyam Eric Lionel Ilboudo",
      "Taisuke Kobayashi",
      "Takamitsu Matsubara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06714"
  },
  {
    "id": "arXiv:2201.07791",
    "title": "On the success probability of quantum order finding",
    "abstract": "Comments: This revision resolves a minor issue in Alg. 4, and addresses a number of other minor issues. It furthermore adds a number of extensions and clarifications, in particular with respect to potential optimizations. No key results or findings in the original version of the manuscript are affected by this revision",
    "descriptor": "\nComments: This revision resolves a minor issue in Alg. 4, and addresses a number of other minor issues. It furthermore adds a number of extensions and clarifications, in particular with respect to potential optimizations. No key results or findings in the original version of the manuscript are affected by this revision\n",
    "authors": [
      "Martin Eker\u00e5"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.07791"
  },
  {
    "id": "arXiv:2201.08482",
    "title": "Deep Attention-Based Supernovae Classification of Multi-Band  Light-Curves",
    "abstract": "Comments: Submitted to AJ on 14-Jan-2022",
    "descriptor": "\nComments: Submitted to AJ on 14-Jan-2022\n",
    "authors": [
      "\u00d3scar Pimentel",
      "Pablo A. Est\u00e9vez",
      "Francisco F\u00f6rster"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08482"
  },
  {
    "id": "arXiv:2202.00824",
    "title": "KSD Aggregated Goodness-of-fit Test",
    "abstract": "Comments: 27 pages, 3 figures",
    "descriptor": "\nComments: 27 pages, 3 figures\n",
    "authors": [
      "Antonin Schrab",
      "Benjamin Guedj",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.00824"
  },
  {
    "id": "arXiv:2202.02455",
    "title": "Using Stochastic local search in designing microstrip antenna for 5G  communication",
    "abstract": "Comments: Withdrawn for major modifications",
    "descriptor": "\nComments: Withdrawn for major modifications\n",
    "authors": [
      "Sunit Shantanu DIgamber Fulari",
      "Harbinder Singh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02455"
  },
  {
    "id": "arXiv:2202.03597",
    "title": "Local Explanations for Reinforcement Learning",
    "abstract": "Comments: Accepted to AAAI 2023",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Ronny Luss",
      "Amit Dhurandhar",
      "Miao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03597"
  },
  {
    "id": "arXiv:2202.04481",
    "title": "Minimax Rate-Distortion",
    "abstract": "Minimax Rate-Distortion",
    "descriptor": "",
    "authors": [
      "Adeel Mahmood",
      "Aaron B. Wagner"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04481"
  },
  {
    "id": "arXiv:2202.06464",
    "title": "Synthetic Data Can Also Teach: Synthesizing Effective Data for  Unsupervised Visual Representation Learning",
    "abstract": "Synthetic Data Can Also Teach: Synthesizing Effective Data for  Unsupervised Visual Representation Learning",
    "descriptor": "",
    "authors": [
      "Yawen Wu",
      "Zhepeng Wang",
      "Dewen Zeng",
      "Yiyu Shi",
      "Jingtong Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06464"
  },
  {
    "id": "arXiv:2202.08232",
    "title": "Quantum Lazy Training",
    "abstract": "Comments: 18 pages, 7 figures + 5 page appendix (V2: Added a couple of remarks; V3: Fixed typo, updated figure and added URL of GitHub repository; V4: Applied changes after getting reviewed)",
    "descriptor": "\nComments: 18 pages, 7 figures + 5 page appendix (V2: Added a couple of remarks; V3: Fixed typo, updated figure and added URL of GitHub repository; V4: Applied changes after getting reviewed)\n",
    "authors": [
      "Erfan Abedi",
      "Salman Beigi",
      "Leila Taghavi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08232"
  },
  {
    "id": "arXiv:2202.09497",
    "title": "Gradient Estimation with Discrete Stein Operators",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Jiaxin Shi",
      "Yuhao Zhou",
      "Jessica Hwang",
      "Michalis K. Titsias",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09497"
  },
  {
    "id": "arXiv:2202.09826",
    "title": "Continual Learning Beyond a Single Model",
    "abstract": "Comments: Keywords: continual learning, neural network subspaces, efficient training",
    "descriptor": "\nComments: Keywords: continual learning, neural network subspaces, efficient training\n",
    "authors": [
      "Thang Doan",
      "Seyed Iman Mirzadeh",
      "Mehrdad Farajtabar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09826"
  },
  {
    "id": "arXiv:2202.10108",
    "title": "ViTAEv2: Vision Transformer Advanced by Exploring Inductive Bias for  Image Recognition and Beyond",
    "abstract": "Comments: An extended version of the Neurips paper \"ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias\". arXiv admin note: substantial text overlap with arXiv:2106.03348",
    "descriptor": "\nComments: An extended version of the Neurips paper \"ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias\". arXiv admin note: substantial text overlap with arXiv:2106.03348\n",
    "authors": [
      "Qiming Zhang",
      "Yufei Xu",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10108"
  },
  {
    "id": "arXiv:2202.10525",
    "title": "A Probabilistic Approach to The Perfect Sum Problem",
    "abstract": "Comments: 22 pages, 6 figures",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Kristof Pusztai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.10525"
  },
  {
    "id": "arXiv:2202.12861",
    "title": "Hierarchical Control for Head-to-Head Autonomous Racing",
    "abstract": "Hierarchical Control for Head-to-Head Autonomous Racing",
    "descriptor": "",
    "authors": [
      "Rishabh Saumil Thakkar",
      "Aryaman Singh Samyal",
      "David Fridovich-Keil",
      "Zhe Xu",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.12861"
  },
  {
    "id": "arXiv:2202.13453",
    "title": "Fourier--Hermite Dynamic Programming for Optimal Control",
    "abstract": "Fourier--Hermite Dynamic Programming for Optimal Control",
    "descriptor": "",
    "authors": [
      "Sakira Hassan",
      "Simo S\u00e4rkk\u00e4"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.13453"
  },
  {
    "id": "arXiv:2203.01442",
    "title": "Deformable Radar Polygon: A Lightweight and Predictable Occupancy  Representation for Short-range Collision Avoidance",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Gao Xiangyu",
      "Ding Sihao",
      "Vanas Karl",
      "Dasari Harshavardhan Reddy",
      "Soderlund Henrik"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.01442"
  },
  {
    "id": "arXiv:2203.03805",
    "title": "Discrete Robust Control of Robot Manipulators using an Uncertainty and  Disturbance Estimator",
    "abstract": "Comments: 20 pages, 7 figures, 1 table",
    "descriptor": "\nComments: 20 pages, 7 figures, 1 table\n",
    "authors": [
      "Ram Padmanabhan",
      "Maithili Shetty",
      "T. S. Chandar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03805"
  },
  {
    "id": "arXiv:2203.04428",
    "title": "DeepSE-WF: Unified Security Estimation for Website Fingerprinting  Defenses",
    "abstract": "Comments: Major revision - added experiments with new dataset and alternative neural network architectures for estimating the BER",
    "descriptor": "\nComments: Major revision - added experiments with new dataset and alternative neural network architectures for estimating the BER\n",
    "authors": [
      "Alexander Veicht",
      "Cedric Renggli",
      "Diogo Barradas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.04428"
  },
  {
    "id": "arXiv:2203.05176",
    "title": "Stability of structure-aware Taylor methods for tents",
    "abstract": "Comments: 26 pages; edited Lemma 6.2, deleted Section 5.3, and corrected typos in the previous version of the preprint",
    "descriptor": "\nComments: 26 pages; edited Lemma 6.2, deleted Section 5.3, and corrected typos in the previous version of the preprint\n",
    "authors": [
      "Jay Gopalakrishnan",
      "Zheng Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.05176"
  },
  {
    "id": "arXiv:2203.05550",
    "title": "Back to the Feature: Classical 3D Features are (Almost) All You Need for  3D Anomaly Detection",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Eliahu Horwitz",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05550"
  },
  {
    "id": "arXiv:2203.07283",
    "title": "HyperATL*: A Logic for Hyperproperties in Multi-Agent Systems",
    "abstract": "HyperATL*: A Logic for Hyperproperties in Multi-Agent Systems",
    "descriptor": "",
    "authors": [
      "Raven Beutner",
      "Bernd Finkbeiner"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.07283"
  },
  {
    "id": "arXiv:2203.07667",
    "title": "SATS: Self-Attention Transfer for Continual Semantic Segmentation",
    "abstract": "Comments: Under review in Pattern Recognition Journal",
    "descriptor": "\nComments: Under review in Pattern Recognition Journal\n",
    "authors": [
      "Yiqiao Qiu",
      "Yixing Shen",
      "Zhuohao Sun",
      "Yanchong Zheng",
      "Xiaobin Chang",
      "Weishi Zheng",
      "Ruixuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07667"
  },
  {
    "id": "arXiv:2203.11194",
    "title": "Test-time adaptation with slot-centric models",
    "abstract": "Comments: Project website at this https URL",
    "descriptor": "\nComments: Project website at this https URL\n",
    "authors": [
      "Mihir Prabhudesai",
      "Anirudh Goyal",
      "Sujoy Paul",
      "Sjoerd van Steenkiste",
      "Mehdi S. M. Sajjadi",
      "Gaurav Aggarwal",
      "Thomas Kipf",
      "Deepak Pathak",
      "Katerina Fragkiadaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.11194"
  },
  {
    "id": "arXiv:2203.15368",
    "title": "Multiclass classification using quantum convolutional neural networks  with hybrid quantum-classical learning",
    "abstract": "Comments: 7 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 7 pages, 5 figures, 3 tables\n",
    "authors": [
      "Denis Bokhan",
      "Alena S. Mastiukova",
      "Aleksey S. Boev",
      "Dmitrii N. Trubnikov",
      "Aleksey K. Fedorov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15368"
  },
  {
    "id": "arXiv:2203.15698",
    "title": "Addressing Non-Intervention Challenges via Resilient Robotics utilizing  a Digital Twin",
    "abstract": "Comments: 6 pages, 7 figures, preprint conference submission for ICRA 2023",
    "descriptor": "\nComments: 6 pages, 7 figures, preprint conference submission for ICRA 2023\n",
    "authors": [
      "Sam Harper",
      "Shivoh Nandakumar",
      "Daniel Mitchell",
      "Jamie Blanche",
      "Theodore Lim",
      "David Flynn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15698"
  },
  {
    "id": "arXiv:2204.00791",
    "title": "CL-XABSA: Contrastive Learning for Cross-lingual Aspect-based Sentiment  Analysis",
    "abstract": "CL-XABSA: Contrastive Learning for Cross-lingual Aspect-based Sentiment  Analysis",
    "descriptor": "",
    "authors": [
      "Nankai Lin",
      "Yingwen Fu",
      "Xiaotian Lin",
      "Aimin Yang",
      "Shengyi Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.00791"
  },
  {
    "id": "arXiv:2204.03014",
    "title": "EfficientCellSeg: Efficient Volumetric Cell Segmentation Using Context  Aware Pseudocoloring",
    "abstract": "Comments: Accepted at MIDL 2022 (Oral); Updated link to challenge submission",
    "descriptor": "\nComments: Accepted at MIDL 2022 (Oral); Updated link to challenge submission\n",
    "authors": [
      "Royden Wagner",
      "Karl Rohr"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03014"
  },
  {
    "id": "arXiv:2204.03911",
    "title": "A posteriori learning for quasi-geostrophic turbulence parametrization",
    "abstract": "Comments: 42 pages, 12 figures, accepted for publication in Journal of Advances in Modeling Earth Systems (JAMES)",
    "descriptor": "\nComments: 42 pages, 12 figures, accepted for publication in Journal of Advances in Modeling Earth Systems (JAMES)\n",
    "authors": [
      "Hugo Frezat",
      "Julien Le Sommer",
      "Ronan Fablet",
      "Guillaume Balarac",
      "Redouane Lguensat"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.03911"
  },
  {
    "id": "arXiv:2204.04057",
    "title": "The Power of Filling in Balanced Allocations",
    "abstract": "Comments: This paper refines and extends the content on filling processes in arXiv:2110.10759. It consists of 34 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: This paper refines and extends the content on filling processes in arXiv:2110.10759. It consists of 34 pages, 6 figures, 2 tables\n",
    "authors": [
      "Dimitrios Los",
      "Thomas Sauerwald",
      "John Sylvester"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2204.04057"
  },
  {
    "id": "arXiv:2204.05566",
    "title": "Compact Model Training by Low-Rank Projection with Energy Transfer",
    "abstract": "Compact Model Training by Low-Rank Projection with Energy Transfer",
    "descriptor": "",
    "authors": [
      "Kailing Guo",
      "Zhenquan Lin",
      "Xiaofen Xing",
      "Fang Liu",
      "Xiangmin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05566"
  },
  {
    "id": "arXiv:2204.06331",
    "title": "Transparent Shape from a Single View Polarization Image",
    "abstract": "Transparent Shape from a Single View Polarization Image",
    "descriptor": "",
    "authors": [
      "Mingqi Shao",
      "Chongkun Xia",
      "Zhendong Yang",
      "Junnan Huang",
      "Xueqian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.06331"
  },
  {
    "id": "arXiv:2204.06767",
    "title": "Learning Task-Aware Energy Disaggregation: a Federated Approach",
    "abstract": "Comments: Accepted to conference on decision and control (CDC) 2022, code is available at (github link: this https URL)",
    "descriptor": "\nComments: Accepted to conference on decision and control (CDC) 2022, code is available at (github link: this https URL)\n",
    "authors": [
      "Ruohong Liu",
      "Yize Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.06767"
  },
  {
    "id": "arXiv:2204.07496",
    "title": "Improving Passage Retrieval with Zero-Shot Question Generation",
    "abstract": "Comments: EMNLP 2022 camera-ready version. Code is available at: this https URL",
    "descriptor": "\nComments: EMNLP 2022 camera-ready version. Code is available at: this https URL\n",
    "authors": [
      "Devendra Singh Sachan",
      "Mike Lewis",
      "Mandar Joshi",
      "Armen Aghajanyan",
      "Wen-tau Yih",
      "Joelle Pineau",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.07496"
  },
  {
    "id": "arXiv:2204.09266",
    "title": "Hessian Averaging in Stochastic Newton Methods Achieves Superlinear  Convergence",
    "abstract": "Comments: 43 pages, 16 figures",
    "descriptor": "\nComments: 43 pages, 16 figures\n",
    "authors": [
      "Sen Na",
      "Micha\u0142 Derezi\u0144ski",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.09266"
  },
  {
    "id": "arXiv:2204.11639",
    "title": "Investigating Black-Box Function Recognition Using Hardware Performance  Counters",
    "abstract": "Investigating Black-Box Function Recognition Using Hardware Performance  Counters",
    "descriptor": "",
    "authors": [
      "Carlton Shepherd",
      "Benjamin Semal",
      "Konstantinos Markantonakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.11639"
  },
  {
    "id": "arXiv:2204.11689",
    "title": "Deep electric field predictions by drift-reduced Braginskii theory with  plasma-neutral interactions based upon experimental images of boundary  turbulence",
    "abstract": "Comments: 6 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 6 pages, 3 figures, 2 tables\n",
    "authors": [
      "Abhilash Mathews",
      "Jerry Hughes",
      "James Terry",
      "Seung-Gyou Baek"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.11689"
  },
  {
    "id": "arXiv:2204.13613",
    "title": "DoPose-6D dataset for object segmentation and 6D pose estimation",
    "abstract": "Comments: accepted for IEEE ICMLA 2022",
    "descriptor": "\nComments: accepted for IEEE ICMLA 2022\n",
    "authors": [
      "Anas Gouda",
      "Abraham Ghanem",
      "Christopher Reining"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.13613"
  },
  {
    "id": "arXiv:2205.00738",
    "title": "Evocube: a Genetic Labeling Framework for Polycube-Maps",
    "abstract": "Evocube: a Genetic Labeling Framework for Polycube-Maps",
    "descriptor": "",
    "authors": [
      "Corentin Dumery",
      "Fran\u00e7ois Protais",
      "S\u00e9bastien Mestrallet",
      "Christophe Bourcier",
      "Franck Ledoux"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.00738"
  },
  {
    "id": "arXiv:2205.01694",
    "title": "End2End Multi-View Feature Matching using Differentiable Pose  Optimization",
    "abstract": "Comments: Video: this https URL",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Barbara Roessle",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01694"
  },
  {
    "id": "arXiv:2205.06365",
    "title": "Fractional-Step Runge--Kutta Methods: Representation and Linear  Stability Analysis",
    "abstract": "Fractional-Step Runge--Kutta Methods: Representation and Linear  Stability Analysis",
    "descriptor": "",
    "authors": [
      "Raymond J. Spiteri",
      "Siqi Wei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.06365"
  },
  {
    "id": "arXiv:2205.07134",
    "title": "ETAD: Training Action Detection End to End on a Laptop",
    "abstract": "ETAD: Training Action Detection End to End on a Laptop",
    "descriptor": "",
    "authors": [
      "Shuming Liu",
      "Mengmeng Xu",
      "Chen Zhao",
      "Xu Zhao",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.07134"
  },
  {
    "id": "arXiv:2205.09778",
    "title": "FogROS2: An Adaptive Platform for Cloud and Fog Robotics Using ROS 2",
    "abstract": "FogROS2: An Adaptive Platform for Cloud and Fog Robotics Using ROS 2",
    "descriptor": "",
    "authors": [
      "Jeffrey Ichnowski",
      "Kaiyuan Chen",
      "Karthik Dharmarajan",
      "Simeon Adebola",
      "Michael Danielczuk",
      "V\u0131ctor Mayoral-Vilches",
      "Nikhil Jha",
      "Hugo Zhan",
      "Edith LLontop",
      "Derek Xu",
      "John Kubiatowicz",
      "Ion Stoica",
      "Joseph Gonzalez",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.09778"
  },
  {
    "id": "arXiv:2205.10536",
    "title": "Knowledge Distillation from A Stronger Teacher",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Tao Huang",
      "Shan You",
      "Fei Wang",
      "Chen Qian",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10536"
  },
  {
    "id": "arXiv:2205.11196",
    "title": "Zero-Sum Games and Linear Programming Duality",
    "abstract": "Comments: v3: Theorem 7 with new proof that does NOT use LP duality, now achieving the same as Brooks/Reny",
    "descriptor": "\nComments: v3: Theorem 7 with new proof that does NOT use LP duality, now achieving the same as Brooks/Reny\n",
    "authors": [
      "Bernhard von Stengel"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.11196"
  },
  {
    "id": "arXiv:2205.12621",
    "title": "Unbiased and Efficient Sampling of Dependency Trees",
    "abstract": "Comments: 16 pages, 4 algorithms, 7 figures",
    "descriptor": "\nComments: 16 pages, 4 algorithms, 7 figures\n",
    "authors": [
      "Milo\u0161 Stanojevi\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.12621"
  },
  {
    "id": "arXiv:2205.13068",
    "title": "Tight Lower Bounds on Worst-Case Guarantees for Zero-Shot Learning with  Attributes",
    "abstract": "Tight Lower Bounds on Worst-Case Guarantees for Zero-Shot Learning with  Attributes",
    "descriptor": "",
    "authors": [
      "Alessio Mazzetto",
      "Cristina Menghini",
      "Andrew Yuan",
      "Eli Upfal",
      "Stephen H. Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13068"
  },
  {
    "id": "arXiv:2205.13189",
    "title": "AI for Porosity and Permeability Prediction from Geologic Core X-Ray  Micro-Tomography",
    "abstract": "AI for Porosity and Permeability Prediction from Geologic Core X-Ray  Micro-Tomography",
    "descriptor": "",
    "authors": [
      "Zangir Iklassov",
      "Dmitrii Medvedev",
      "Otabek Nazarov",
      "Shakhboz Razzokov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13189"
  },
  {
    "id": "arXiv:2205.14623",
    "title": "SKFlow: Learning Optical Flow with Super Kernels",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Shangkun Sun",
      "Yuanqi Chen",
      "Yu Zhu",
      "Guodong Guo",
      "Ge Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.14623"
  },
  {
    "id": "arXiv:2205.14885",
    "title": "A Connected Component Labeling Algorithm for Implicitly-Defined Domains",
    "abstract": "Comments: 15 pages, 7 figures, 3 algorithms",
    "descriptor": "\nComments: 15 pages, 7 figures, 3 algorithms\n",
    "authors": [
      "Robert I. Saye"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.14885"
  },
  {
    "id": "arXiv:2205.14971",
    "title": "Knowledge Distillation for 6D Pose Estimation by Aligning Distributions  of Local Predictions",
    "abstract": "Knowledge Distillation for 6D Pose Estimation by Aligning Distributions  of Local Predictions",
    "descriptor": "",
    "authors": [
      "Shuxuan Guo",
      "Yinlin Hu",
      "Jose M. Alvarez",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14971"
  },
  {
    "id": "arXiv:2205.15967",
    "title": "You Can't Count on Luck: Why Decision Transformers and RvS Fail in  Stochastic Environments",
    "abstract": "Comments: Added experiments with Decision Transformers; Fixed error in Theorem 2.1; Updated related works; Added link for code",
    "descriptor": "\nComments: Added experiments with Decision Transformers; Fixed error in Theorem 2.1; Updated related works; Added link for code\n",
    "authors": [
      "Keiran Paster",
      "Sheila McIlraith",
      "Jimmy Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.15967"
  },
  {
    "id": "arXiv:2206.00803",
    "title": "Robust recovery of low-rank matrices and low-tubal-rank tensors from  noisy sketches",
    "abstract": "Comments: Major revision. 21 pages, 4 figures",
    "descriptor": "\nComments: Major revision. 21 pages, 4 figures\n",
    "authors": [
      "Anna Ma",
      "Dominik St\u00f6ger",
      "Yizhe Zhu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2206.00803"
  },
  {
    "id": "arXiv:2206.01506",
    "title": "Can Hybrid Geometric Scattering Networks Help Solve the Maximum Clique  Problem?",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Yimeng Min",
      "Frederik Wenkel",
      "Michael Perlmutter",
      "Guy Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01506"
  },
  {
    "id": "arXiv:2206.02874",
    "title": "Dissecting Tensor Cores via Microbenchmarks: Latency, Throughput and  Numeric Behaviors",
    "abstract": "Dissecting Tensor Cores via Microbenchmarks: Latency, Throughput and  Numeric Behaviors",
    "descriptor": "",
    "authors": [
      "Wei Sun",
      "Ang Li",
      "Tong Geng",
      "Sander Stuijk",
      "Henk Corporaal"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2206.02874"
  },
  {
    "id": "arXiv:2206.03262",
    "title": "Using sensitive data to prevent discrimination by artificial  intelligence: Does the GDPR need a new exception?",
    "abstract": "Using sensitive data to prevent discrimination by artificial  intelligence: Does the GDPR need a new exception?",
    "descriptor": "",
    "authors": [
      "Marvin van Bekkum",
      "Frederik Zuiderveen Borgesius"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03262"
  },
  {
    "id": "arXiv:2206.03688",
    "title": "Identifying good directions to escape the NTK regime and efficiently  learn low-degree plus sparse polynomials",
    "abstract": "Comments: v2: NeurIPS 2022 camera ready version",
    "descriptor": "\nComments: v2: NeurIPS 2022 camera ready version\n",
    "authors": [
      "Eshaan Nichani",
      "Yu Bai",
      "Jason D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.03688"
  },
  {
    "id": "arXiv:2206.04281",
    "title": "Local Spatiotemporal Representation Learning for  Longitudinally-consistent Neuroimage Analysis",
    "abstract": "Comments: Camera ready for NeurIPS. Code available at this https URL; Project page: this https URL",
    "descriptor": "\nComments: Camera ready for NeurIPS. Code available at this https URL; Project page: this https URL\n",
    "authors": [
      "Mengwei Ren",
      "Neel Dey",
      "Martin A. Styner",
      "Kelly Botteron",
      "Guido Gerig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.04281"
  },
  {
    "id": "arXiv:2206.05312",
    "title": "Vehicle-To-Pedestrian Communication Feedback Module: A Study on  Increasing Legibility, Public Acceptance and Trust",
    "abstract": "Vehicle-To-Pedestrian Communication Feedback Module: A Study on  Increasing Legibility, Public Acceptance and Trust",
    "descriptor": "",
    "authors": [
      "Melanie Schmidt-Wolf",
      "David Feil-Seifer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.05312"
  },
  {
    "id": "arXiv:2206.05498",
    "title": "A Review of Causality for Learning Algorithms in Medical Image Analysis",
    "abstract": "Comments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL\". ; Paper ID: 2022:028",
    "descriptor": "\nComments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) this https URL\". ; Paper ID: 2022:028\n",
    "authors": [
      "Athanasios Vlontzos",
      "Daniel Rueckert",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2206.05498"
  },
  {
    "id": "arXiv:2206.05825",
    "title": "A Unified Approach to Reinforcement Learning, Quantal Response  Equilibria, and Two-Player Zero-Sum Games",
    "abstract": "A Unified Approach to Reinforcement Learning, Quantal Response  Equilibria, and Two-Player Zero-Sum Games",
    "descriptor": "",
    "authors": [
      "Samuel Sokota",
      "Ryan D'Orazio",
      "J. Zico Kolter",
      "Nicolas Loizou",
      "Marc Lanctot",
      "Ioannis Mitliagkas",
      "Noam Brown",
      "Christian Kroer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2206.05825"
  },
  {
    "id": "arXiv:2206.07694",
    "title": "DIRECTOR: Generator-Classifiers For Supervised Language Modeling",
    "abstract": "DIRECTOR: Generator-Classifiers For Supervised Language Modeling",
    "descriptor": "",
    "authors": [
      "Kushal Arora",
      "Kurt Shuster",
      "Sainbayar Sukhbaatar",
      "Jason Weston"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.07694"
  },
  {
    "id": "arXiv:2206.09194",
    "title": "Efficient Aggregated Kernel Tests using Incomplete $U$-statistics",
    "abstract": "Comments: 33 pages, 4 figures",
    "descriptor": "\nComments: 33 pages, 4 figures\n",
    "authors": [
      "Antonin Schrab",
      "Ilmun Kim",
      "Benjamin Guedj",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.09194"
  },
  {
    "id": "arXiv:2206.09578",
    "title": "Performance-Oriented Design for Intelligent Reflecting Surface Assisted  Federated Learning",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Yapeng Zhao",
      "Qingqing Wu",
      "Wen Chen",
      "Celimuge Wu",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.09578"
  },
  {
    "id": "arXiv:2206.09889",
    "title": "Nocturne: a scalable driving benchmark for bringing multi-agent learning  one step closer to the real world",
    "abstract": "Nocturne: a scalable driving benchmark for bringing multi-agent learning  one step closer to the real world",
    "descriptor": "",
    "authors": [
      "Eugene Vinitsky",
      "Nathan Lichtl\u00e9",
      "Xiaomeng Yang",
      "Brandon Amos",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.09889"
  },
  {
    "id": "arXiv:2206.10614",
    "title": "On the Impossibility of Learning to Cooperate with Adaptive Partner  Strategies in Repeated Games",
    "abstract": "Comments: 9 pages, to be published in The Proceedings of the 39th International Conference on Machine Learning, 2022",
    "descriptor": "\nComments: 9 pages, to be published in The Proceedings of the 39th International Conference on Machine Learning, 2022\n",
    "authors": [
      "Robert Loftin",
      "Frans A. Oliehoek"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2206.10614"
  },
  {
    "id": "arXiv:2206.10999",
    "title": "Neural Networks as Paths through the Space of Representations",
    "abstract": "Comments: 10 pages, submitted to ICLR 2023",
    "descriptor": "\nComments: 10 pages, submitted to ICLR 2023\n",
    "authors": [
      "Richard D. Lange",
      "Devin Kwok",
      "Jordan Matelsky",
      "Xinyue Wang",
      "David S. Rolnick",
      "Konrad P. Kording"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.10999"
  },
  {
    "id": "arXiv:2206.11398",
    "title": "Fusion of Model-free Reinforcement Learning with Microgrid Control:  Review and Vision",
    "abstract": "Comments: 14 pages, 4 figures, published on IEEE Transaction on Smart Grid 2022 Nov 15. See: this https URL",
    "descriptor": "\nComments: 14 pages, 4 figures, published on IEEE Transaction on Smart Grid 2022 Nov 15. See: this https URL\n",
    "authors": [
      "Buxin She",
      "Fangxing Li",
      "Hantao Cui",
      "Jingqiu Zhang",
      "Rui Bo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.11398"
  },
  {
    "id": "arXiv:2206.11403",
    "title": "Curious Exploration via Structured World Models Yields Zero-Shot Object  Manipulation",
    "abstract": "Comments: NeurIPS 2022 camera-ready version",
    "descriptor": "\nComments: NeurIPS 2022 camera-ready version\n",
    "authors": [
      "Cansu Sancaktar",
      "Sebastian Blaes",
      "Georg Martius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.11403"
  },
  {
    "id": "arXiv:2206.11896",
    "title": "EventNeRF: Neural Radiance Fields from a Single Colour Event Camera",
    "abstract": "Comments: 18 pages, 18 figures, 3 tables",
    "descriptor": "\nComments: 18 pages, 18 figures, 3 tables\n",
    "authors": [
      "Viktor Rudnev",
      "Mohamed Elgharib",
      "Christian Theobalt",
      "Vladislav Golyanik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11896"
  },
  {
    "id": "arXiv:2206.12340",
    "title": "How to hide your voice: Noise-cancelling bird photography blind",
    "abstract": "Comments: 26 pages, 11 figures. Revised argument in sections 2 and 4, results unchanged, references added",
    "descriptor": "\nComments: 26 pages, 11 figures. Revised argument in sections 2 and 4, results unchanged, references added\n",
    "authors": [
      "Caner Baydur",
      "Baojing Pu",
      "Xiaoqing Xu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.12340"
  },
  {
    "id": "arXiv:2206.12668",
    "title": "Covering $b$-Symbol Metric Codes and the Generalized Singleton Bound",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12668"
  },
  {
    "id": "arXiv:2206.12933",
    "title": "Wiener Graph Deconvolutional Network Improves Graph Self-Supervised  Learning",
    "abstract": "Comments: 13 pages; Accepted to AAAI'23",
    "descriptor": "\nComments: 13 pages; Accepted to AAAI'23\n",
    "authors": [
      "Jiashun Cheng",
      "Man Li",
      "Jia Li",
      "Fugee Tsung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.12933"
  },
  {
    "id": "arXiv:2206.13294",
    "title": "LaRa: Latents and Rays for Multi-Camera Bird's-Eye-View Semantic  Segmentation",
    "abstract": "LaRa: Latents and Rays for Multi-Camera Bird's-Eye-View Semantic  Segmentation",
    "descriptor": "",
    "authors": [
      "Florent Bartoccioni",
      "\u00c9loi Zablocki",
      "Andrei Bursuc",
      "Patrick P\u00e9rez",
      "Matthieu Cord",
      "Karteek Alahari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.13294"
  },
  {
    "id": "arXiv:2206.14516",
    "title": "On Hull-Variation Problem of Equivalent Linear Codes",
    "abstract": "Comments: 34 pages, revised version",
    "descriptor": "\nComments: 34 pages, revised version\n",
    "authors": [
      "Hao Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.14516"
  },
  {
    "id": "arXiv:2207.00052",
    "title": "Visual Pre-training for Navigation: What Can We Learn from Noise?",
    "abstract": "Comments: To appear in NeurIPS 2022",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Yanwei Wang",
      "Ching-Yun Ko",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.00052"
  },
  {
    "id": "arXiv:2207.01328",
    "title": "DUET: Cross-modal Semantic Grounding for Contrastive Zero-shot Learning",
    "abstract": "Comments: AAAI 2023. Repository: this https URL",
    "descriptor": "\nComments: AAAI 2023. Repository: this https URL\n",
    "authors": [
      "Zhuo Chen",
      "Yufeng Huang",
      "Jiaoyan Chen",
      "Yuxia Geng",
      "Wen Zhang",
      "Yin Fang",
      "Jeff Z. Pan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.01328"
  },
  {
    "id": "arXiv:2207.01613",
    "title": "Doubly-Asynchronous Value Iteration: Making Value Iteration Asynchronous  in Actions",
    "abstract": "Doubly-Asynchronous Value Iteration: Making Value Iteration Asynchronous  in Actions",
    "descriptor": "",
    "authors": [
      "Tian Tian",
      "Kenny Young",
      "Richard S. Sutton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.01613"
  },
  {
    "id": "arXiv:2207.01754",
    "title": "Cryptography with Certified Deletion",
    "abstract": "Cryptography with Certified Deletion",
    "descriptor": "",
    "authors": [
      "James Bartusek",
      "Dakshita Khurana"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.01754"
  },
  {
    "id": "arXiv:2207.01933",
    "title": "Convergence of a time discrete scheme for a chemotaxis-consumption model",
    "abstract": "Convergence of a time discrete scheme for a chemotaxis-consumption model",
    "descriptor": "",
    "authors": [
      "Francisco Guill\u00e9n-Gonz\u00e1lez",
      "Andr\u00e9 Luiz Corr\u00eaa Vianna Filho"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.01933"
  },
  {
    "id": "arXiv:2207.02108",
    "title": "AI-based Malware and Ransomware Detection Models",
    "abstract": "AI-based Malware and Ransomware Detection Models",
    "descriptor": "",
    "authors": [
      "Benjamin Marais",
      "Tony Quertier",
      "St\u00e9phane Morucci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.02108"
  },
  {
    "id": "arXiv:2207.02264",
    "title": "Understanding blockchain: definitions, architecture, design, and system  comparison",
    "abstract": "Comments: 33 pages, 10 figures, 8 tables",
    "descriptor": "\nComments: 33 pages, 10 figures, 8 tables\n",
    "authors": [
      "Mohammad Hossein Tabatabaei",
      "Roman Vitenberg",
      "Narasimha Raghavan Veeraragavan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.02264"
  },
  {
    "id": "arXiv:2207.02274",
    "title": "STOCHOS: Stochastic Opportunistic Maintenance Scheduling For Offshore  Wind Farms",
    "abstract": "STOCHOS: Stochastic Opportunistic Maintenance Scheduling For Offshore  Wind Farms",
    "descriptor": "",
    "authors": [
      "Petros Papadopoulos",
      "David W. Coit",
      "Ahmed Aziz Ezzat"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2207.02274"
  },
  {
    "id": "arXiv:2207.02910",
    "title": "Ant Hill Colonization optimization algorithm(AHCOA) for controlling the  side lobe of a uniform linear array",
    "abstract": "Comments: Withdrawn for major modifications",
    "descriptor": "\nComments: Withdrawn for major modifications\n",
    "authors": [
      "Sunit Shantanu Digamber Fulari",
      "Harbinder Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.02910"
  },
  {
    "id": "arXiv:2207.04046",
    "title": "Optimal Pattern synthesis of linear antenna array using Ant Hill  Colonization Optimization algorithm(AHCOA)",
    "abstract": "Comments: Withdrawn for major modifications",
    "descriptor": "\nComments: Withdrawn for major modifications\n",
    "authors": [
      "Sunit Shantanu Digamber Fulari",
      "Harbinder Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.04046"
  },
  {
    "id": "arXiv:2207.04491",
    "title": "DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in  Transformer",
    "abstract": "Comments: Accepted to AAAI 2023",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Maoyuan Ye",
      "Jing Zhang",
      "Shanshan Zhao",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04491"
  },
  {
    "id": "arXiv:2207.05112",
    "title": "An Interpretable Joint Nonnegative Matrix Factorization-Based Point  Cloud Distance Measure",
    "abstract": "An Interpretable Joint Nonnegative Matrix Factorization-Based Point  Cloud Distance Measure",
    "descriptor": "",
    "authors": [
      "Hannah Friedman",
      "Amani R. Maina-Kilaas",
      "Julianna Schalkwyk",
      "Hina Ahmed",
      "Jamie Haddock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05112"
  },
  {
    "id": "arXiv:2207.06993",
    "title": "A fundamental non-classical logic",
    "abstract": "Comments: Forthcoming in Logics, Vol. 1. Added footnote 15 and corrected antepenultimate sentence of Section 6",
    "descriptor": "\nComments: Forthcoming in Logics, Vol. 1. Added footnote 15 and corrected antepenultimate sentence of Section 6\n",
    "authors": [
      "Wesley H. Holliday"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2207.06993"
  },
  {
    "id": "arXiv:2207.07036",
    "title": "u-HuBERT: Unified Mixed-Modal Speech Pretraining And Zero-Shot Transfer  to Unlabeled Modality",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Wei-Ning Hsu",
      "Bowen Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.07036"
  },
  {
    "id": "arXiv:2207.07933",
    "title": "Consistency of Implicit and Explicit Features Matters for Monocular 3D  Object Detection",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Qian Ye",
      "Ling Jiang",
      "Wang Zhen",
      "Yuyang Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.07933"
  },
  {
    "id": "arXiv:2207.08779",
    "title": "Simplifying Clustering with Graph Neural Networks",
    "abstract": "Simplifying Clustering with Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Filippo Maria Bianchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08779"
  },
  {
    "id": "arXiv:2207.09344",
    "title": "Online Dynamics Learning for Predictive Control with an Application to  Aerial Robots",
    "abstract": "Comments: Accepted into Conference on Robot Learning (CoRL) 2022, 8 pages, 4 figures",
    "descriptor": "\nComments: Accepted into Conference on Robot Learning (CoRL) 2022, 8 pages, 4 figures\n",
    "authors": [
      "Tom Z. Jiahao",
      "Kong Yao Chee",
      "M. Ani Hsieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09344"
  },
  {
    "id": "arXiv:2207.09446",
    "title": "ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model",
    "abstract": "ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model",
    "descriptor": "",
    "authors": [
      "Rao Fu",
      "Xiao Zhan",
      "Yiwen Chen",
      "Daniel Ritchie",
      "Srinath Sridhar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.09446"
  },
  {
    "id": "arXiv:2207.10821",
    "title": "Rethinking Sim2Real: Lower Fidelity Simulation Leads to Higher Sim2Real  Transfer in Navigation",
    "abstract": "Rethinking Sim2Real: Lower Fidelity Simulation Leads to Higher Sim2Real  Transfer in Navigation",
    "descriptor": "",
    "authors": [
      "Joanne Truong",
      "Max Rudolph",
      "Naoki Yokoyama",
      "Sonia Chernova",
      "Dhruv Batra",
      "Akshara Rai"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10821"
  },
  {
    "id": "arXiv:2207.10929",
    "title": "Static Hovering Realization for Multirotor Aerial Vehicles with Tiltable  Propellers",
    "abstract": "Static Hovering Realization for Multirotor Aerial Vehicles with Tiltable  Propellers",
    "descriptor": "",
    "authors": [
      "Mahmoud Hamandi",
      "Lakmal Seneviratne",
      "Yahya Zweiri"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.10929"
  },
  {
    "id": "arXiv:2207.12673",
    "title": "A Data Driven Method for Multi-step Prediction of Ship Roll Motion in  High Sea States",
    "abstract": "A Data Driven Method for Multi-step Prediction of Ship Roll Motion in  High Sea States",
    "descriptor": "",
    "authors": [
      "Dan Zhang",
      "Xi Zhou",
      "Zi-Hao Wang",
      "Yan Peng",
      "Shao-Rong Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2207.12673"
  },
  {
    "id": "arXiv:2207.12888",
    "title": "LaKo: Knowledge-driven Visual Question Answering via Late  Knowledge-to-Text Injection",
    "abstract": "Comments: IJCKG 2022. Repository: github.com/hackerchenzhuo/LaKo",
    "descriptor": "\nComments: IJCKG 2022. Repository: github.com/hackerchenzhuo/LaKo\n",
    "authors": [
      "Zhuo Chen",
      "Yufeng Huang",
      "Jiaoyan Chen",
      "Yuxia Geng",
      "Yin Fang",
      "Jeff Pan",
      "Ningyu Zhang",
      "Wen Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.12888"
  },
  {
    "id": "arXiv:2207.13532",
    "title": "Contrastive Masked Autoencoders are Stronger Vision Learners",
    "abstract": "Contrastive Masked Autoencoders are Stronger Vision Learners",
    "descriptor": "",
    "authors": [
      "Zhicheng Huang",
      "Xiaojie Jin",
      "Chengze Lu",
      "Qibin Hou",
      "Ming-Ming Cheng",
      "Dongmei Fu",
      "Xiaohui Shen",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.13532"
  },
  {
    "id": "arXiv:2207.14083",
    "title": "Weakly-Supervised Camouflaged Object Detection with Scribble Annotations",
    "abstract": "Comments: Accepted to AAAI 2023. The code and dataset are available at this https URL",
    "descriptor": "\nComments: Accepted to AAAI 2023. The code and dataset are available at this https URL\n",
    "authors": [
      "Ruozhen He",
      "Qihua Dong",
      "Jiaying Lin",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.14083"
  },
  {
    "id": "arXiv:2208.00671",
    "title": "RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in  Racket Sports",
    "abstract": "RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in  Racket Sports",
    "descriptor": "",
    "authors": [
      "Jiang Wu",
      "Dongyu Liu",
      "Ziyang Guo",
      "Yingcai Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.00671"
  },
  {
    "id": "arXiv:2208.02229",
    "title": "A Nonparametric Framework for Online Stochastic Matching with Correlated  Arrivals",
    "abstract": "A Nonparametric Framework for Online Stochastic Matching with Correlated  Arrivals",
    "descriptor": "",
    "authors": [
      "Ali Aouad",
      "Will Ma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.02229"
  },
  {
    "id": "arXiv:2208.03111",
    "title": "Data-free Backdoor Removal based on Channel Lipschitzness",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Runkai Zheng",
      "Rongjun Tang",
      "Jianze Li",
      "Li Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.03111"
  },
  {
    "id": "arXiv:2208.03523",
    "title": "Generalizing Downsampling from Regular Data to Graphs",
    "abstract": "Comments: Accepted at AAAI 2023; Extended version with proofs",
    "descriptor": "\nComments: Accepted at AAAI 2023; Extended version with proofs\n",
    "authors": [
      "Davide Bacciu",
      "Alessio Conte",
      "Francesco Landolfi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.03523"
  },
  {
    "id": "arXiv:2208.04425",
    "title": "Controlled Sparsity via Constrained Optimization or: How I Learned to  Stop Tuning Penalties and Love Constraints",
    "abstract": "Comments: NeurIPS 2022 - Code available at this https URL",
    "descriptor": "\nComments: NeurIPS 2022 - Code available at this https URL\n",
    "authors": [
      "Jose Gallego-Posada",
      "Juan Ramirez",
      "Akram Erraqabi",
      "Yoshua Bengio",
      "Simon Lacoste-Julien"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.04425"
  },
  {
    "id": "arXiv:2208.06857",
    "title": "Underwater Ranker: Learn Which Is Better and How to Be Better",
    "abstract": "Comments: 9 pages, 10 figures",
    "descriptor": "\nComments: 9 pages, 10 figures\n",
    "authors": [
      "Chunle Guo",
      "Ruiqi Wu",
      "Xin Jin",
      "Linghao Han",
      "Zhi Chai",
      "Weidong Zhang",
      "Chongyi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06857"
  },
  {
    "id": "arXiv:2208.07541",
    "title": "Social Interactions for Autonomous Driving: A Review and Perspectives",
    "abstract": "Comments: 183 pages, 36 figures",
    "descriptor": "\nComments: 183 pages, 36 figures\n",
    "authors": [
      "Wenshuo Wang",
      "Letian Wang",
      "Chengyuan Zhang",
      "Changliu Liu",
      "Lijun Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.07541"
  },
  {
    "id": "arXiv:2208.08965",
    "title": "GSRFormer: Grounded Situation Recognition Transformer with Alternate  Semantic Attention Refinement",
    "abstract": "Comments: ACM Multimedia 2022 (Oral), Code: this https URL",
    "descriptor": "\nComments: ACM Multimedia 2022 (Oral), Code: this https URL\n",
    "authors": [
      "Zhi-Qi Cheng",
      "Qi Dai",
      "Siyao Li",
      "Teruko Mitamura",
      "Alexander G. Hauptmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.08965"
  },
  {
    "id": "arXiv:2208.09029",
    "title": "Communication-Efficient Collaborative Best Arm Identification",
    "abstract": "Comments: 12 pages, 12 figures",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Nikolai Karpov",
      "Qin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09029"
  },
  {
    "id": "arXiv:2208.10244",
    "title": "Unit Testing for Concepts in Neural Networks",
    "abstract": "Comments: TACL, In Press. 12 Pages",
    "descriptor": "\nComments: TACL, In Press. 12 Pages\n",
    "authors": [
      "Charles Lovering",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.10244"
  },
  {
    "id": "arXiv:2208.10364",
    "title": "Scaling Up Dynamic Graph Representation Learning via Spiking Neural  Networks",
    "abstract": "Comments: Accepted by AAAI 2023.Contains appendix with additional details about algorithms and experiments. Code available at this https URL",
    "descriptor": "\nComments: Accepted by AAAI 2023.Contains appendix with additional details about algorithms and experiments. Code available at this https URL\n",
    "authors": [
      "Jintang Li",
      "Zhouxin Yu",
      "Zulun Zhu",
      "Liang Chen",
      "Qi Yu",
      "Zibin Zheng",
      "Sheng Tian",
      "Ruofan Wu",
      "Changhua Meng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10364"
  },
  {
    "id": "arXiv:2208.11445",
    "title": "Induced Natural Language Rationales and Interleaved Markup Tokens Enable  Extrapolation in Large Language Models",
    "abstract": "Induced Natural Language Rationales and Interleaved Markup Tokens Enable  Extrapolation in Large Language Models",
    "descriptor": "",
    "authors": [
      "Mirelle Bueno",
      "Carlos Gemmell",
      "Jeffrey Dalton",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.11445"
  },
  {
    "id": "arXiv:2208.11510",
    "title": "Quantum Multi-Agent Meta Reinforcement Learning",
    "abstract": "Comments: (To be) presented at AAAI 2023",
    "descriptor": "\nComments: (To be) presented at AAAI 2023\n",
    "authors": [
      "Won Joon Yun",
      "Jihong Park",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.11510"
  },
  {
    "id": "arXiv:2208.11660",
    "title": "Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind  Approach",
    "abstract": "Comments: 9 pages, Accepted at AAAI 2023",
    "descriptor": "\nComments: 9 pages, Accepted at AAAI 2023\n",
    "authors": [
      "Samuel Westby",
      "Christoph Riedl"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.11660"
  },
  {
    "id": "arXiv:2208.12835",
    "title": "A Path Towards Clinical Adaptation of Accelerated MRI",
    "abstract": "Comments: Accepted to ML4H 2022",
    "descriptor": "\nComments: Accepted to ML4H 2022\n",
    "authors": [
      "Michael S. Yao",
      "Michael S. Hansen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.12835"
  },
  {
    "id": "arXiv:2208.12866",
    "title": "Reducing Computational Complexity of Neural Networks in Optical Channel  Equalization: From Concepts to Implementation",
    "abstract": "Reducing Computational Complexity of Neural Networks in Optical Channel  Equalization: From Concepts to Implementation",
    "descriptor": "",
    "authors": [
      "Pedro J. Freire",
      "Antonio Napoli",
      "Diego Arguello Ron",
      "Bernhard Spinnler",
      "Michael Anderson",
      "Wolfgang Schairer",
      "Thomas Bex",
      "Nelson Costa",
      "Sergei K. Turitsyn",
      "Jaroslaw E. Prilepsky"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computational Complexity (cs.CC)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.12866"
  },
  {
    "id": "arXiv:2208.13754",
    "title": "Simple and Rigorous Proof Method for the Security of Practical Quantum  Key Distribution in the Single-Qubit Regime Using Mismatched Basis  Measurements",
    "abstract": "Comments: 31 pages; includes the correction of a flaw in v1 of this preprint",
    "descriptor": "\nComments: 31 pages; includes the correction of a flaw in v1 of this preprint\n",
    "authors": [
      "Michel Boyer",
      "Gilles Brassard",
      "Nicolas Godbout",
      "Rotem Liss",
      "St\u00e9phane Virally"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.13754"
  },
  {
    "id": "arXiv:2208.14210",
    "title": "Learned k-NN Distance Estimation",
    "abstract": "Comments: Accepted to SIGSPATIAL2022 (as short paper)",
    "descriptor": "\nComments: Accepted to SIGSPATIAL2022 (as short paper)\n",
    "authors": [
      "Daichi Amagata",
      "Yusuke Arai",
      "Sumio Fujita",
      "Takahiro Hara"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.14210"
  },
  {
    "id": "arXiv:2208.14226",
    "title": "Unsupervised Representation Learning in Deep Reinforcement Learning: A  Review",
    "abstract": "Unsupervised Representation Learning in Deep Reinforcement Learning: A  Review",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Botteghi",
      "Mannes Poel",
      "Christoph Brune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.14226"
  },
  {
    "id": "arXiv:2208.14698",
    "title": "Bayesian Optimization-based Combinatorial Assignment",
    "abstract": "Bayesian Optimization-based Combinatorial Assignment",
    "descriptor": "",
    "authors": [
      "Jakob Weissteiner",
      "Jakob Heiss",
      "Julien Siems",
      "Sven Seuken"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.14698"
  },
  {
    "id": "arXiv:2208.14839",
    "title": "QuantNAS for super resolution: searching for efficient  quantization-friendly architectures against quantization noise",
    "abstract": "QuantNAS for super resolution: searching for efficient  quantization-friendly architectures against quantization noise",
    "descriptor": "",
    "authors": [
      "Egor Shvetsov",
      "Dmitry Osin",
      "Alexey Zaytsev",
      "Ivan Koryakovskiy",
      "Valentin Buchnev",
      "Ilya Trofimov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.14839"
  },
  {
    "id": "arXiv:2209.00721",
    "title": "Generalizing intrusion detection for heterogeneous networks: A  stacked-unsupervised federated learning approach",
    "abstract": "Comments: Preprint (Under revision), 35 pages. Added repository link, see this https URL",
    "descriptor": "\nComments: Preprint (Under revision), 35 pages. Added repository link, see this https URL\n",
    "authors": [
      "Gustavo de Carvalho Bertoli",
      "Louren\u00e7o Alves Pereira Junior",
      "Aldri Luiz dos Santos",
      "Osamu Saotome"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.00721"
  },
  {
    "id": "arXiv:2209.01174",
    "title": "Extend and Explain: Interpreting Very Long Language Models",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Joel Stremmel",
      "Brian L. Hill",
      "Jeffrey Hertzberg",
      "Jaime Murillo",
      "Llewelyn Allotey",
      "Eran Halperin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.01174"
  },
  {
    "id": "arXiv:2209.01348",
    "title": "How to cut a discrete cake fairly",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Ayumi Igarashi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2209.01348"
  },
  {
    "id": "arXiv:2209.02514",
    "title": "Learned Distributed Image Compression with Multi-Scale Patch Matching in  Feature Domain",
    "abstract": "Comments: This work is accepted by the AAAI 2023",
    "descriptor": "\nComments: This work is accepted by the AAAI 2023\n",
    "authors": [
      "Yujun Huang",
      "Bin Chen",
      "Shiyu Qin",
      "Jiawei Li",
      "Yaowei Wang",
      "Tao Dai",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.02514"
  },
  {
    "id": "arXiv:2209.02633",
    "title": "Energy Management of Multi-mode Hybrid Electric Vehicles based on  Hand-shaking Multi-agent Learning",
    "abstract": "Energy Management of Multi-mode Hybrid Electric Vehicles based on  Hand-shaking Multi-agent Learning",
    "descriptor": "",
    "authors": [
      "Min Hua",
      "Zhi Li",
      "Quan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.02633"
  },
  {
    "id": "arXiv:2209.04903",
    "title": "Cores of Games via Total Dual Integrality, with Applications to Perfect  Graphs and Polymatroids",
    "abstract": "Comments: 14 pages. arXiv admin note: text overlap with arXiv:2202.00619",
    "descriptor": "\nComments: 14 pages. arXiv admin note: text overlap with arXiv:2202.00619\n",
    "authors": [
      "Vijay V. Vazirani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2209.04903"
  },
  {
    "id": "arXiv:2209.06091",
    "title": "Approaching Digital Humanities at the University: a Cultural Challenge",
    "abstract": "Approaching Digital Humanities at the University: a Cultural Challenge",
    "descriptor": "",
    "authors": [
      "Silvio Peroni",
      "Francesca Tomasi"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2209.06091"
  },
  {
    "id": "arXiv:2209.06271",
    "title": "Semi-strict chordality of digraphs",
    "abstract": "Comments: 16 pages, 4 figures. arXiv admin note: text overlap with arXiv:2008.03568",
    "descriptor": "\nComments: 16 pages, 4 figures. arXiv admin note: text overlap with arXiv:2008.03568\n",
    "authors": [
      "Jing Huang",
      "Ying Ying Ye"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2209.06271"
  },
  {
    "id": "arXiv:2209.06434",
    "title": "ConvNeXt Based Neural Network for Audio Anti-Spoofing",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Qiaowei Ma",
      "Jinghui Zhong",
      "Yitao Yang",
      "Weiheng Liu",
      "Ying Gao",
      "Wing W.Y. Ng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.06434"
  },
  {
    "id": "arXiv:2209.06896",
    "title": "Persistently Feasible Robust Safe Control by Safety Index Synthesis and  Convex Semi-Infinite Programming",
    "abstract": "Persistently Feasible Robust Safe Control by Safety Index Synthesis and  Convex Semi-Infinite Programming",
    "descriptor": "",
    "authors": [
      "Tianhao Wei",
      "Shucheng Kang",
      "Weiye Zhao",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.06896"
  },
  {
    "id": "arXiv:2209.07046",
    "title": "Exploring Visual Interpretability for Contrastive Language-Image  Pre-training",
    "abstract": "Comments: 15 pages, 9 figures",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Yi Li",
      "Hualiang Wang",
      "Yiqun Duan",
      "Hang Xu",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07046"
  },
  {
    "id": "arXiv:2209.07669",
    "title": "Stability Constrained Reinforcement Learning for Decentralized Real-Time  Voltage Control",
    "abstract": "Comments: This paper extends the result of our previous conference version arXiv:2109.14854",
    "descriptor": "\nComments: This paper extends the result of our previous conference version arXiv:2109.14854\n",
    "authors": [
      "Jie Feng",
      "Yuanyuan Shi",
      "Guannan Qu",
      "Steven H. Low",
      "Anima Anandkumar",
      "Adam Wierman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.07669"
  },
  {
    "id": "arXiv:2209.08893",
    "title": "A Secure Authentication Framework to Guarantee the Traceability of  Avatars in Metaverse",
    "abstract": "Comments: 13 pages, 12 figures",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Kedi Yang",
      "Zhenyong Zhang",
      "Youliang Tian",
      "Jianfeng Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.08893"
  },
  {
    "id": "arXiv:2209.09339",
    "title": "Identifying and Characterizing Behavioral Classes of Radicalization  within the QAnon Conspiracy on Twitter",
    "abstract": "Comments: 12 pages, 10 figures, 2 tables. Accepted at ICWSM 2023!",
    "descriptor": "\nComments: 12 pages, 10 figures, 2 tables. Accepted at ICWSM 2023!\n",
    "authors": [
      "Emily L. Wang",
      "Luca Luceri",
      "Francesco Pierri",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.09339"
  },
  {
    "id": "arXiv:2209.09616",
    "title": "Provably Uncertainty-Guided Universal Domain Adaptation",
    "abstract": "Comments: 13 pages. arXiv admin note: text overlap with arXiv:2207.09280",
    "descriptor": "\nComments: 13 pages. arXiv admin note: text overlap with arXiv:2207.09280\n",
    "authors": [
      "Yifan Wang",
      "Lin Zhang",
      "Ran Song",
      "Lin Ma",
      "Wei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09616"
  },
  {
    "id": "arXiv:2209.10509",
    "title": "Downward Self-Reducibility in TFNP",
    "abstract": "Comments: 16 pages, 2 figures",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Prahladh Harsha",
      "Daniel Mitropolsky",
      "Alon Rosen"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2209.10509"
  },
  {
    "id": "arXiv:2209.10876",
    "title": "An Attention Matrix for Every Decision: Faithfulness-based Arbitration  Among Multiple Attention-Based Interpretations of Transformers in Text  Classification",
    "abstract": "Comments: 16 pages, 7 figures, 5 tables, Submitted to DAMI Journal (ECMLPKDD2023 Special Issue)",
    "descriptor": "\nComments: 16 pages, 7 figures, 5 tables, Submitted to DAMI Journal (ECMLPKDD2023 Special Issue)\n",
    "authors": [
      "Nikolaos Mylonas",
      "Ioannis Mollas",
      "Grigorios Tsoumakas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.10876"
  },
  {
    "id": "arXiv:2209.11979",
    "title": "Robust Hyperspectral Image Fusion with Simultaneous Guide Image  Denoising via Constrained Convex Optimization",
    "abstract": "Comments: Accepted to IEEE Transactions on Geoscience and Remote Sensing",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Geoscience and Remote Sensing\n",
    "authors": [
      "Saori Takeyama",
      "Shunsuke Ono"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11979"
  },
  {
    "id": "arXiv:2209.13296",
    "title": "Video-based estimation of pain indicators in dogs",
    "abstract": "Comments: 20 pages, 7 figures",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Hongyi Zhu",
      "Yasemin Salg\u0131rl\u0131",
      "P\u0131nar Can",
      "Durmu\u015f At\u0131lgan",
      "Albert Ali Salah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.13296"
  },
  {
    "id": "arXiv:2209.14125",
    "title": "Spectral Diffusion Processes",
    "abstract": "Comments: 17 pages, 11 figures, Score-based Method Workshop at 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 17 pages, 11 figures, Score-based Method Workshop at 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Angus Phillips",
      "Thomas Seror",
      "Michael Hutchinson",
      "Valentin De Bortoli",
      "Arnaud Doucet",
      "Emile Mathieu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14125"
  },
  {
    "id": "arXiv:2209.14967",
    "title": "Statistical Learning and Inverse Problems: A Stochastic Gradient  Approach",
    "abstract": "Statistical Learning and Inverse Problems: A Stochastic Gradient  Approach",
    "descriptor": "",
    "authors": [
      "Yuri R. Fonseca",
      "Yuri F. Saporito"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14967"
  },
  {
    "id": "arXiv:2209.15369",
    "title": "Towards effective assessment of steady state performance in Java  software: Are we there yet?",
    "abstract": "Comments: Published in Empirical Software Engineering (EMSE)",
    "descriptor": "\nComments: Published in Empirical Software Engineering (EMSE)\n",
    "authors": [
      "Luca Traini",
      "Vittorio Cortellessa",
      "Daniele Di Pompeo",
      "Michele Tucci"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.15369"
  },
  {
    "id": "arXiv:2210.00065",
    "title": "Application of Deep Q Learning with Simulation Results for Elevator  Optimization",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Zheng Cao",
      "Raymond Guo",
      "Caesar M. Tuguinay",
      "Mark Pock",
      "Jiayi Gao",
      "Ziyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00065"
  },
  {
    "id": "arXiv:2210.00243",
    "title": "An experimental study of algorithms for obtaining a singly connected  subgraph",
    "abstract": "An experimental study of algorithms for obtaining a singly connected  subgraph",
    "descriptor": "",
    "authors": [
      "Ahmed Zahloote",
      "Al-hasan Saleh",
      "Ayman Ghanem",
      "Hiba Hasan",
      "Asem Dreibaty",
      "Ali Abodaraa",
      "Nermeen Suleiman",
      "Nour Naameh",
      "Ali Ibrahim",
      "Zeinab mahfoud"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.00243"
  },
  {
    "id": "arXiv:2210.00445",
    "title": "ManiCLIP: Multi-Attribute Face Manipulation from Text",
    "abstract": "ManiCLIP: Multi-Attribute Face Manipulation from Text",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Guosheng Lin",
      "Ana Garc\u00eda del Molino",
      "Anran Wang",
      "Zehuan Yuan",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00445"
  },
  {
    "id": "arXiv:2210.01869",
    "title": "Memory in humans and deep language models: Linking hypotheses for model  augmentation",
    "abstract": "Comments: 6 figures",
    "descriptor": "\nComments: 6 figures\n",
    "authors": [
      "Omri Raccah",
      "Phoebe Chen",
      "Ted L. Willke",
      "David Poeppel",
      "Vy A. Vo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01869"
  },
  {
    "id": "arXiv:2210.03629",
    "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
    "abstract": "Comments: v2 adds the project site with code: this https URL",
    "descriptor": "\nComments: v2 adds the project site with code: this https URL\n",
    "authors": [
      "Shunyu Yao",
      "Jeffrey Zhao",
      "Dian Yu",
      "Nan Du",
      "Izhak Shafran",
      "Karthik Narasimhan",
      "Yuan Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03629"
  },
  {
    "id": "arXiv:2210.04993",
    "title": "Learning with an Evolving Class Ontology",
    "abstract": "Comments: NeurIPS 2022; Website: this https URL",
    "descriptor": "\nComments: NeurIPS 2022; Website: this https URL\n",
    "authors": [
      "Zhiqiu Lin",
      "Deepak Pathak",
      "Yu-Xiong Wang",
      "Deva Ramanan",
      "Shu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04993"
  },
  {
    "id": "arXiv:2210.05468",
    "title": "High-precision Density Mapping of Marine Debris and Floating Plastics  via Satellite Imagery",
    "abstract": "Comments: 14 pages, 4 tables, 4 figures",
    "descriptor": "\nComments: 14 pages, 4 tables, 4 figures\n",
    "authors": [
      "Henry Booth",
      "Wanli Ma",
      "Oktay Karakus"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05468"
  },
  {
    "id": "arXiv:2210.05976",
    "title": "Human Joint Kinematics Diffusion-Refinement for Stochastic Motion  Prediction",
    "abstract": "Comments: Accepted by AAAI2023",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Dong Wei",
      "Huaijiang Sun",
      "Bin Li",
      "Jianfeng Lu",
      "Weiqing Li",
      "Xiaoning Sun",
      "Shengxiang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05976"
  },
  {
    "id": "arXiv:2210.06853",
    "title": "NeuralRoom: Geometry-Constrained Neural Implicit Surfaces for Indoor  Scene Reconstruction",
    "abstract": "NeuralRoom: Geometry-Constrained Neural Implicit Surfaces for Indoor  Scene Reconstruction",
    "descriptor": "",
    "authors": [
      "Yusen Wang",
      "Zongcheng Li",
      "Yu Jiang",
      "Kaixuan Zhou",
      "Tuo Cao",
      "Yanping Fu",
      "Chunxia Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06853"
  },
  {
    "id": "arXiv:2210.08714",
    "title": "Selective Query-guided Debiasing for Video Corpus Moment Retrieval",
    "abstract": "Comments: 16 pages, 6 figures, Accepted in ECCV 2022",
    "descriptor": "\nComments: 16 pages, 6 figures, Accepted in ECCV 2022\n",
    "authors": [
      "Sunjae Yoon",
      "Ji Woo Hong",
      "Eunseop Yoon",
      "Dahyun Kim",
      "Junyeong Kim",
      "Hee Suk Yoon",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08714"
  },
  {
    "id": "arXiv:2210.08923",
    "title": "RPoA: Redefined Proof of Activity",
    "abstract": "Comments: 11 pages with 1 figure",
    "descriptor": "\nComments: 11 pages with 1 figure\n",
    "authors": [
      "Sina Kamali",
      "Shayan Shabihi",
      "Taha Fakharian",
      "Alireza Arbabi",
      "Pouriya Tajmehrabi",
      "Mohammad Saadati",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.08923"
  },
  {
    "id": "arXiv:2210.09782",
    "title": "Decoupling Features in Hierarchical Propagation for Video Object  Segmentation",
    "abstract": "Comments: Accepted by NeurIPS 2022 (Spotlight)",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 (Spotlight)\n",
    "authors": [
      "Zongxin Yang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09782"
  },
  {
    "id": "arXiv:2210.11675",
    "title": "Granular-Ball Fuzzy Set and Its Implementation in SVM",
    "abstract": "Granular-Ball Fuzzy Set and Its Implementation in SVM",
    "descriptor": "",
    "authors": [
      "Shuyin Xia",
      "Xiaoyu Lian",
      "Guoyin Wang",
      "Xinbo Gao",
      "Yabin Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11675"
  },
  {
    "id": "arXiv:2210.11879",
    "title": "GLCC: A General Framework for Graph-level Clustering",
    "abstract": "Comments: Accepted by Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2023)",
    "descriptor": "\nComments: Accepted by Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2023)\n",
    "authors": [
      "Wei Ju",
      "Yiyang Gu",
      "Binqi Chen",
      "Gongbo Sun",
      "Yifang Qin",
      "Xingyuming Liu",
      "Xiao Luo",
      "Ming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.11879"
  },
  {
    "id": "arXiv:2210.12045",
    "title": "Optimization of side lobe level of linear antenna array using nature  optimized ants bridging solutions(NOABS)",
    "abstract": "Comments: Withdrawn for major modifications",
    "descriptor": "\nComments: Withdrawn for major modifications\n",
    "authors": [
      "Sunit Shantanu Digamber Fulari",
      "Dr.Harbinder Singh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.12045"
  },
  {
    "id": "arXiv:2210.12854",
    "title": "Artificial Life using a Book and Bookmarker",
    "abstract": "Artificial Life using a Book and Bookmarker",
    "descriptor": "",
    "authors": [
      "Keishu Utimula"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12854"
  },
  {
    "id": "arXiv:2210.14306",
    "title": "Reading Between the Lines: Modeling User Behavior and Costs in  AI-Assisted Programming",
    "abstract": "Reading Between the Lines: Modeling User Behavior and Costs in  AI-Assisted Programming",
    "descriptor": "",
    "authors": [
      "Hussein Mozannar",
      "Gagan Bansal",
      "Adam Fourney",
      "Eric Horvitz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14306"
  },
  {
    "id": "arXiv:2210.14335",
    "title": "A Depolarizing Noise-aware Transpiler for Optimal Amplitude  Amplification",
    "abstract": "A Depolarizing Noise-aware Transpiler for Optimal Amplitude  Amplification",
    "descriptor": "",
    "authors": [
      "Debashis Ganguly",
      "Wonsun Ahn"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.14335"
  },
  {
    "id": "arXiv:2210.15461",
    "title": "LVP-M3: Language-aware Visual Prompt for Multilingual Multimodal Machine  Translation",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Hongcheng Guo",
      "Jiaheng Liu",
      "Haoyang Huang",
      "Jian Yang",
      "Zhoujun Li",
      "Dongdong Zhang",
      "Zheng Cui",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.15461"
  },
  {
    "id": "arXiv:2210.16401",
    "title": "The Fisher-Rao Loss for Learning under Label Noise",
    "abstract": "Comments: 20 pages, 5 figures, minor improvements. Accepted for publication in Information Geometry",
    "descriptor": "\nComments: 20 pages, 5 figures, minor improvements. Accepted for publication in Information Geometry\n",
    "authors": [
      "Henrique K. Miyamoto",
      "F\u00e1bio C. C. Meneghetti",
      "Sueli I. R. Costa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.16401"
  },
  {
    "id": "arXiv:2210.17274",
    "title": "Anomaly Detection in Additive Manufacturing Processes using Supervised  Classification with Imbalanced Sensor Data based on Generative Adversarial  Network",
    "abstract": "Anomaly Detection in Additive Manufacturing Processes using Supervised  Classification with Imbalanced Sensor Data based on Generative Adversarial  Network",
    "descriptor": "",
    "authors": [
      "Jihoon Chung",
      "Bo Shen",
      "Zhenyu",
      "Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.17274"
  },
  {
    "id": "arXiv:2211.01112",
    "title": "Adversarial Attack on Radar-based Environment Perception Systems",
    "abstract": "Adversarial Attack on Radar-based Environment Perception Systems",
    "descriptor": "",
    "authors": [
      "Amira Guesmi",
      "Ihsen Alouani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01112"
  },
  {
    "id": "arXiv:2211.02213",
    "title": "SSDA-YOLO: Semi-supervised Domain Adaptive YOLO for Cross-Domain Object  Detection",
    "abstract": "Comments: submitted to CVIU",
    "descriptor": "\nComments: submitted to CVIU\n",
    "authors": [
      "Huayi Zhou",
      "Fei Jiang",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02213"
  },
  {
    "id": "arXiv:2211.02396",
    "title": "Rethinking the positive role of cluster structure in complex networks  for link prediction tasks",
    "abstract": "Comments: 15 pages, 6 figures",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Shanfan Zhang",
      "Wenjiao Zhang",
      "Zhan Bu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02396"
  },
  {
    "id": "arXiv:2211.02452",
    "title": "Agent-update Models",
    "abstract": "Agent-update Models",
    "descriptor": "",
    "authors": [
      "Shikha Singh",
      "Kamal Lodaya",
      "Deepak Khemani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.02452"
  },
  {
    "id": "arXiv:2211.02738",
    "title": "Intriguing Properties of Compression on Multilingual Models",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Kelechi Ogueji",
      "Orevaoghene Ahia",
      "Gbemileke Onilude",
      "Sebastian Gehrmann",
      "Sara Hooker",
      "Julia Kreutzer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02738"
  },
  {
    "id": "arXiv:2211.03550",
    "title": "Underwater Image Super-Resolution using Generative Adversarial  Network-based Model",
    "abstract": "Underwater Image Super-Resolution using Generative Adversarial  Network-based Model",
    "descriptor": "",
    "authors": [
      "Alireza Aghelan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.03550"
  },
  {
    "id": "arXiv:2211.03628",
    "title": "Decentralized Complete Dictionary Learning via $\\ell^{4}$-Norm  Maximization",
    "abstract": "Decentralized Complete Dictionary Learning via $\\ell^{4}$-Norm  Maximization",
    "descriptor": "",
    "authors": [
      "Qiheng Lu",
      "Lixiang Lian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.03628"
  },
  {
    "id": "arXiv:2211.04258",
    "title": "MetaLoc: Learning to Learn Wireless Localization",
    "abstract": "MetaLoc: Learning to Learn Wireless Localization",
    "descriptor": "",
    "authors": [
      "Jun Gao",
      "Dongze Wu",
      "Feng Yin",
      "Qinglei Kong",
      "Lexi Xu",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04258"
  },
  {
    "id": "arXiv:2211.04442",
    "title": "Algorithmic Bias in Machine Learning Based Delirium Prediction",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 14 pages",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 14 pages\n",
    "authors": [
      "Sandhya Tripathi",
      "Bradley A Fritz",
      "Michael S Avidan",
      "Yixin Chen",
      "Christopher R King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04442"
  },
  {
    "id": "arXiv:2211.04455",
    "title": "Microprocessor Design with Dynamic Clock Source and Multi-Width  Instructions",
    "abstract": "Microprocessor Design with Dynamic Clock Source and Multi-Width  Instructions",
    "descriptor": "",
    "authors": [
      "Keyu Chen",
      "Xuyi Hu",
      "Robert Killey"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04455"
  },
  {
    "id": "arXiv:2211.04700",
    "title": "NoiSER: Noise is All You Need for Low-Light Image Enhancement",
    "abstract": "NoiSER: Noise is All You Need for Low-Light Image Enhancement",
    "descriptor": "",
    "authors": [
      "Zhao Zhang",
      "Suiyi Zhao",
      "Xiaojie Jin",
      "Mingliang Xu",
      "Yi Yang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04700"
  },
  {
    "id": "arXiv:2211.04757",
    "title": "Lower bounds for piecewise polynomial approximations of oscillatory  functions",
    "abstract": "Comments: Updated introductory material and included proof of optimality for the low-frequency estimates in full generality",
    "descriptor": "\nComments: Updated introductory material and included proof of optimality for the low-frequency estimates in full generality\n",
    "authors": [
      "Jeffrey Galkowski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04757"
  },
  {
    "id": "arXiv:2211.05172",
    "title": "Speech separation with large-scale self-supervised learning",
    "abstract": "Speech separation with large-scale self-supervised learning",
    "descriptor": "",
    "authors": [
      "Zhuo Chen",
      "Naoyuki Kanda",
      "Jian Wu",
      "Yu Wu",
      "Xiaofei Wang",
      "Takuya Yoshioka",
      "Jinyu Li",
      "Sunit Sivasankaran",
      "Sefik Emre Eskimez"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.05172"
  },
  {
    "id": "arXiv:2211.05225",
    "title": "Variational Quantum Kernels with Task-Specific Quantum Metric Learning",
    "abstract": "Variational Quantum Kernels with Task-Specific Quantum Metric Learning",
    "descriptor": "",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05225"
  },
  {
    "id": "arXiv:2211.05610",
    "title": "BERT on a Data Diet: Finding Important Examples by Gradient-Based  Pruning",
    "abstract": "Comments: ENLSP @ NeurIPS2022",
    "descriptor": "\nComments: ENLSP @ NeurIPS2022\n",
    "authors": [
      "Mohsen Fayyaz",
      "Ehsan Aghazadeh",
      "Ali Modarressi",
      "Mohammad Taher Pilehvar",
      "Yadollah Yaghoobzadeh",
      "Samira Ebrahimi Kahou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05610"
  },
  {
    "id": "arXiv:2211.05739",
    "title": "FedLesScan: Mitigating Stragglers in Serverless Federated Learning",
    "abstract": "Comments: IEEE BigData 2022",
    "descriptor": "\nComments: IEEE BigData 2022\n",
    "authors": [
      "Mohamed Elzohairy",
      "Mohak Chadha",
      "Anshul Jindal",
      "Andreas Grafberger",
      "Jianfeng Gu",
      "Michael Gerndt",
      "Osama Abboud"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05739"
  },
  {
    "id": "arXiv:2211.07137",
    "title": "DroneNet: Crowd Density Estimation using Self-ONNs for Drones",
    "abstract": "Comments: The paper has been accepted for presentation in 2023 IEEE Consumer Communications & Networking Conference (CCNC)",
    "descriptor": "\nComments: The paper has been accepted for presentation in 2023 IEEE Consumer Communications & Networking Conference (CCNC)\n",
    "authors": [
      "Muhammad Asif Khan",
      "Hamid Menouar",
      "Ridha Hamila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07137"
  },
  {
    "id": "arXiv:2211.08074",
    "title": "Predicting Eye Gaze Location on Websites",
    "abstract": "Predicting Eye Gaze Location on Websites",
    "descriptor": "",
    "authors": [
      "Ciheng Zhang",
      "Decky Aspandi",
      "Steffen Staab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.08074"
  },
  {
    "id": "arXiv:2211.08615",
    "title": "GLFF: Global and Local Feature Fusion for Face Forgery Detection",
    "abstract": "GLFF: Global and Local Feature Fusion for Face Forgery Detection",
    "descriptor": "",
    "authors": [
      "Yan Ju",
      "Shan Jia",
      "Jialing Cai",
      "Haiying Guan",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08615"
  },
  {
    "id": "arXiv:2211.09184",
    "title": "An Empirical Analysis of the Advantages of Finite- v.s. Infinite-Width  Bayesian Neural Networks",
    "abstract": "An Empirical Analysis of the Advantages of Finite- v.s. Infinite-Width  Bayesian Neural Networks",
    "descriptor": "",
    "authors": [
      "Jiayu Yao",
      "Yaniv Yacoby",
      "Beau Coker",
      "Weiwei Pan",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09184"
  },
  {
    "id": "arXiv:2211.10052",
    "title": "Pedestrian Spatio-Temporal Information Fusion For Video Anomaly  Detection",
    "abstract": "Comments: International Conference on Intelligent Media, Big Data and Knowledge Mining",
    "descriptor": "\nComments: International Conference on Intelligent Media, Big Data and Knowledge Mining\n",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10052"
  },
  {
    "id": "arXiv:2211.10227",
    "title": "Adversarial Detection by Approximation of Ensemble Boundary",
    "abstract": "Comments: 6 pages, 3 figures, 5 tables",
    "descriptor": "\nComments: 6 pages, 3 figures, 5 tables\n",
    "authors": [
      "T. Windeatt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10227"
  },
  {
    "id": "arXiv:2211.10438",
    "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large  Language Models",
    "abstract": "Comments: The first two authors contributed equally to this work",
    "descriptor": "\nComments: The first two authors contributed equally to this work\n",
    "authors": [
      "Guangxuan Xiao",
      "Ji Lin",
      "Mickael Seznec",
      "Julien Demouth",
      "Song Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10438"
  },
  {
    "id": "arXiv:2211.10486",
    "title": "DGRec: Graph Neural Network for Recommendation with Diversified  Embedding Generation",
    "abstract": "Comments: 9 pages, WSDM 2023",
    "descriptor": "\nComments: 9 pages, WSDM 2023\n",
    "authors": [
      "Liangwei Yang",
      "Shengjie Wang",
      "Yunzhe Tao",
      "Jiankai Sun",
      "Xiaolong Liu",
      "Philip S. Yu",
      "Taiqing Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.10486"
  },
  {
    "id": "arXiv:2211.10658",
    "title": "EDGE: Editable Dance Generation From Music",
    "abstract": "Comments: Project website: this https URL",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Jonathan Tseng",
      "Rodrigo Castellon",
      "C. Karen Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.10658"
  },
  {
    "id": "arXiv:2211.10660",
    "title": "Evaluating the Perceived Safety of Urban City via Maximum Entropy Deep  Inverse Reinforcement Learning",
    "abstract": "Comments: ACML2022 Camera-ready Version",
    "descriptor": "\nComments: ACML2022 Camera-ready Version\n",
    "authors": [
      "Yaxuan Wang",
      "Zhixin Zeng",
      "Qijun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10660"
  },
  {
    "id": "arXiv:2211.10936",
    "title": "Learning to Search for Job Shop Scheduling via Deep Reinforcement  Learning",
    "abstract": "Learning to Search for Job Shop Scheduling via Deep Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Cong Zhang",
      "Wen Song",
      "Zhiguang Cao",
      "Jie Zhang",
      "Puay Siew Tan",
      "Chi Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10936"
  },
  {
    "id": "arXiv:2211.11033",
    "title": "On the Complexity of Bayesian Generalization",
    "abstract": "On the Complexity of Bayesian Generalization",
    "descriptor": "",
    "authors": [
      "Yu-Zhe Shi",
      "Manjie Xu",
      "John E. Hopcroft",
      "Kun He",
      "Joshua B. Tenenbaum",
      "Song-Chun Zhu",
      "Ying Nian Wu",
      "Wenjuan Han",
      "Yixin Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11033"
  },
  {
    "id": "arXiv:2211.11082",
    "title": "DynIBaR: Neural Dynamic Image-Based Rendering",
    "abstract": "Comments: Project page: dynibar.github.io",
    "descriptor": "\nComments: Project page: dynibar.github.io\n",
    "authors": [
      "Zhengqi Li",
      "Qianqian Wang",
      "Forrester Cole",
      "Richard Tucker",
      "Noah Snavely"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11082"
  },
  {
    "id": "arXiv:2211.11147",
    "title": "Optimal quaternary linear codes with one-dimensional Hermitian hull and  the related EAQECCs",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2211.02480",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2211.02480\n",
    "authors": [
      "Shitao Li",
      "Minjia Shi",
      "Huizhou Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11147"
  },
  {
    "id": "arXiv:2211.11174",
    "title": "On the Robustness, Generalization, and Forgetting of Shape-Texture  Debiased Continual Learning",
    "abstract": "On the Robustness, Generalization, and Forgetting of Shape-Texture  Debiased Continual Learning",
    "descriptor": "",
    "authors": [
      "Zenglin Shi",
      "Ying Sun",
      "Joo Hwee Lim",
      "Mengmi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11174"
  },
  {
    "id": "arXiv:2211.11262",
    "title": "Boosting Novel Category Discovery Over Domains with Soft Contrastive  Learning and All-in-One Classifier",
    "abstract": "Comments: The paper found additional problems",
    "descriptor": "\nComments: The paper found additional problems\n",
    "authors": [
      "Zelin Zang",
      "Lei Shang",
      "Senqiao Yang",
      "Baigui Sun",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11262"
  },
  {
    "id": "arXiv:2211.11418",
    "title": "L3Cube-HindBERT and DevBERT: Pre-Trained BERT Transformer models for  Devanagari based Hindi and Marathi Languages",
    "abstract": "L3Cube-HindBERT and DevBERT: Pre-Trained BERT Transformer models for  Devanagari based Hindi and Marathi Languages",
    "descriptor": "",
    "authors": [
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11418"
  },
  {
    "id": "arXiv:2211.12051",
    "title": "Adaptive Dynamic Filtering Network for Image Denoising",
    "abstract": "Comments: 9 pages, Accepted in AAAI Conference on Artificial Intelligence (AAAI) 2023",
    "descriptor": "\nComments: 9 pages, Accepted in AAAI Conference on Artificial Intelligence (AAAI) 2023\n",
    "authors": [
      "Hao Shen",
      "Zhong-Qiu Zhao",
      "Wandi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12051"
  },
  {
    "id": "arXiv:2211.12141",
    "title": "MGADN: A Multi-task Graph Anomaly Detection Network for Multivariate  Time Series",
    "abstract": "MGADN: A Multi-task Graph Anomaly Detection Network for Multivariate  Time Series",
    "descriptor": "",
    "authors": [
      "Weixuan Xiong",
      "Xiaochen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12141"
  },
  {
    "id": "arXiv:2211.12311",
    "title": "Generalizable Industrial Visual Anomaly Detection with Self-Induction  Vision Transformer",
    "abstract": "Comments: 8 pages, 6 figures,",
    "descriptor": "\nComments: 8 pages, 6 figures,\n",
    "authors": [
      "Haiming Yao",
      "Xue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12311"
  },
  {
    "id": "arXiv:2211.12432",
    "title": "Multi-task Learning for Camera Calibration",
    "abstract": "Comments: 20 pages, 12 figures, 8 tables",
    "descriptor": "\nComments: 20 pages, 12 figures, 8 tables\n",
    "authors": [
      "Talha Hanif Butt",
      "Murtaza Taj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12432"
  },
  {
    "id": "arXiv:2211.12857",
    "title": "Explaining Image Classifiers with Multiscale Directional Image  Representation",
    "abstract": "Explaining Image Classifiers with Multiscale Directional Image  Representation",
    "descriptor": "",
    "authors": [
      "Stefan Kolek",
      "Robert Windesheim",
      "Hector Andrade Loarca",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12857"
  },
  {
    "id": "arXiv:2211.12921",
    "title": "Hybrid Learning of Time-Series Inverse Dynamics Models for Locally  Isotropic Robot Motion",
    "abstract": "Comments: Accepted for publication in IEEE Robotics and Automation Letters ( see this https URL ). 8 pages, 8 figures",
    "descriptor": "\nComments: Accepted for publication in IEEE Robotics and Automation Letters ( see this https URL ). 8 pages, 8 figures\n",
    "authors": [
      "Tolga-Can \u00c7allar",
      "Sven B\u00f6ttger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12921"
  },
  {
    "id": "arXiv:2211.12979",
    "title": "FLAIR #1: semantic segmentation and domain adaptation dataset",
    "abstract": "FLAIR #1: semantic segmentation and domain adaptation dataset",
    "descriptor": "",
    "authors": [
      "Anatol Garioud",
      "St\u00e9phane Peillet",
      "Eva Bookjans",
      "S\u00e9bastien Giordano",
      "Boris Wattrelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.12979"
  },
  {
    "id": "arXiv:2211.13226",
    "title": "ClimateNeRF: Physically-based Neural Rendering for Extreme Climate  Synthesis",
    "abstract": "Comments: project page: this https URL",
    "descriptor": "\nComments: project page: this https URL\n",
    "authors": [
      "Yuan Li",
      "Zhi-Hao Lin",
      "David Forsyth",
      "Jia-Bin Huang",
      "Shenlong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.13226"
  },
  {
    "id": "arXiv:2211.13234",
    "title": "RNTrajRec: Road Network Enhanced Trajectory Recovery with  Spatial-Temporal Transformer",
    "abstract": "RNTrajRec: Road Network Enhanced Trajectory Recovery with  Spatial-Temporal Transformer",
    "descriptor": "",
    "authors": [
      "Yuqi Chen",
      "Hanyuan Zhang",
      "Weiwei Sun",
      "Baihua Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13234"
  },
  {
    "id": "arXiv:2211.13289",
    "title": "Shapley Curves: A Smoothing Perspective",
    "abstract": "Shapley Curves: A Smoothing Perspective",
    "descriptor": "",
    "authors": [
      "Ratmir Miftachov",
      "Georg Keilbar",
      "Wolfgang Karl H\u00e4rdle"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.13289"
  },
  {
    "id": "arXiv:2211.13358",
    "title": "Turning the Tables: Biased, Imbalanced, Dynamic Tabular Datasets for ML  Evaluation",
    "abstract": "Comments: Accepted at NeurIPS 2022. this https URL",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. this https URL\n",
    "authors": [
      "S\u00e9rgio Jesus",
      "Jos\u00e9 Pombal",
      "Duarte Alves",
      "Andr\u00e9 Cruz",
      "Pedro Saleiro",
      "Rita P. Ribeiro",
      "Jo\u00e3o Gama",
      "Pedro Bizarro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13358"
  },
  {
    "id": "arXiv:2211.13508",
    "title": "1st Workshop on Maritime Computer Vision (MaCVi) 2023: Challenge Results",
    "abstract": "Comments: MaCVi 2023 was part of WACV 2023. This report (38 pages) discusses the competition as part of MaCVi",
    "descriptor": "\nComments: MaCVi 2023 was part of WACV 2023. This report (38 pages) discusses the competition as part of MaCVi\n",
    "authors": [
      "Benjamin Kiefer",
      "Matej Kristan",
      "Janez Per\u0161",
      "Lojze \u017dust",
      "Fabio Poiesi",
      "Fabio Augusto de Alcantara Andrade",
      "Alexandre Bernardino",
      "Matthew Dawkins",
      "Jenni Raitoharju",
      "Yitong Quan",
      "Adem Atmaca",
      "Timon H\u00f6fer",
      "Qiming Zhang",
      "Yufei Xu",
      "Jing Zhang",
      "Dacheng Tao",
      "Lars Sommer",
      "Raphael Spraul",
      "Hangyue Zhao",
      "Hongpu Zhang",
      "Yanyun Zhao",
      "Jan Lukas Augustin",
      "Eui-ik Jeon",
      "Impyeong Lee",
      "Luca Zedda",
      "Andrea Loddo",
      "Cecilia Di Ruberto",
      "Sagar Verma",
      "Siddharth Gupta",
      "Shishir Muralidhara",
      "Niharika Hegde",
      "Daitao Xing",
      "Nikolaos Evangeliou",
      "Anthony Tzes",
      "Vojt\u011bch Bartl",
      "Jakub \u0160pa\u0148hel",
      "Adam Herout",
      "Neelanjan Bhowmik",
      "Toby P. Breckon",
      "Shivanand Kundargi",
      "Tejas Anvekar",
      "Chaitra Desai",
      "Ramesh Ashok Tabib",
      "Uma Mudengudi",
      "Arpita Vats",
      "Yang Song",
      "Delong Liu",
      "Yonglin Li",
      "Shuman Li",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13508"
  },
  {
    "id": "arXiv:2211.13649",
    "title": "End-to-end Wind Turbine Wake Modelling with Deep Graph Representation  Learning",
    "abstract": "Comments: 20 pages, 12 figures",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "Siyi Li",
      "Mingrui Zhang",
      "Matthew D. Piggott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.13649"
  },
  {
    "id": "arXiv:2211.13670",
    "title": "SmartIntentNN: Towards Smart Contract Intent Detection",
    "abstract": "Comments: 4 pages, 3 figures, conference tool track. arXiv admin note: substantial text overlap with arXiv:2211.10724",
    "descriptor": "\nComments: 4 pages, 3 figures, conference tool track. arXiv admin note: substantial text overlap with arXiv:2211.10724\n",
    "authors": [
      "Youwei Huang",
      "Tao Zhang",
      "Sen Fang",
      "Youshuai Tan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13670"
  },
  {
    "id": "arXiv:2211.13676",
    "title": "Perception-Oriented Single Image Super-Resolution using Optimal  Objective Estimation",
    "abstract": "Comments: Code and trained models will be available at this https URL",
    "descriptor": "\nComments: Code and trained models will be available at this https URL\n",
    "authors": [
      "Seung Ho Park",
      "Young Su Moon",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.13676"
  },
  {
    "id": "arXiv:2211.13778",
    "title": "Design and Prototyping Distributed CNN Inference Acceleration in Edge  Computing",
    "abstract": "Comments: Accepted by European Wireless 2022",
    "descriptor": "\nComments: Accepted by European Wireless 2022\n",
    "authors": [
      "Zhongtian Dong",
      "Nan Li",
      "Alexandros Iosifidis",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.13778"
  },
  {
    "id": "arXiv:2211.13787",
    "title": "Semantic Communication Enabling Robust Edge Intelligence for  Time-Critical IoT Applications",
    "abstract": "Semantic Communication Enabling Robust Edge Intelligence for  Time-Critical IoT Applications",
    "descriptor": "",
    "authors": [
      "Andrea Cavagna",
      "Nan Li",
      "Alexandros Iosifidis",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.13787"
  },
  {
    "id": "arXiv:2211.13960",
    "title": "The European AI Liability Directives -- Critique of a Half-Hearted  Approach and Lessons for the Future",
    "abstract": "Comments: under peer-review; contains 3 Tables",
    "descriptor": "\nComments: under peer-review; contains 3 Tables\n",
    "authors": [
      "Philipp Hacker"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13960"
  },
  {
    "id": "arXiv:2211.13964",
    "title": "Generating 2D and 3D Master Faces for Dictionary Attacks with a  Network-Assisted Latent Space Evolution",
    "abstract": "Comments: accepted for publication in IEEE Transactions on Biometrics, Behavior, and Identity Science (TBIOM). This paper extends arXiv:2108.01077 that was accepted to IEEE FG 2021",
    "descriptor": "\nComments: accepted for publication in IEEE Transactions on Biometrics, Behavior, and Identity Science (TBIOM). This paper extends arXiv:2108.01077 that was accepted to IEEE FG 2021\n",
    "authors": [
      "Tomer Friedlander",
      "Ron Shmelkin",
      "Lior Wolf"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13964"
  },
  {
    "id": "arXiv:2211.13968",
    "title": "MIAD: A Maintenance Inspection Dataset for Unsupervised Anomaly  Detection",
    "abstract": "MIAD: A Maintenance Inspection Dataset for Unsupervised Anomaly  Detection",
    "descriptor": "",
    "authors": [
      "Tianpeng Bao",
      "Jiadong Chen",
      "Wei Li",
      "Xiang Wang",
      "Jingjing Fei",
      "Liwei Wu",
      "Rui Zhao",
      "Ye Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13968"
  },
  {
    "id": "arXiv:2211.13974",
    "title": "ILSGAN: Independent Layer Synthesis for Unsupervised  Foreground-Background Segmentation",
    "abstract": "Comments: Accepted by AAAI 2023",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Qiran Zou",
      "Yu Yang",
      "Wing Yin Cheung",
      "Chang Liu",
      "Xiangyang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13974"
  },
  {
    "id": "arXiv:2211.14115",
    "title": "Inverse Solvability and Security with Applications to Federated Learning",
    "abstract": "Inverse Solvability and Security with Applications to Federated Learning",
    "descriptor": "",
    "authors": [
      "Tomasz Piotrowski",
      "Matthias Frey",
      "Renato L.G. Cavalcante",
      "Rafail Ismailov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14115"
  },
  {
    "id": "arXiv:2211.14206",
    "title": "McEliece cryptosystem based on Plotkin construction with QC-MDPC and  QC-LDPC codes",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Belkacem Imine",
      "Naima Hadj-Said",
      "Adda Ali-Pacha",
      "Herv\u00e9 Tal\u00e9 Kalachi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.14206"
  },
  {
    "id": "arXiv:2211.14297",
    "title": "Doubly robust nearest neighbors in factor models",
    "abstract": "Doubly robust nearest neighbors in factor models",
    "descriptor": "",
    "authors": [
      "Raaz Dwivedi",
      "Katherine Tian",
      "Sabina Tomkins",
      "Predrag Klasnja",
      "Susan Murphy",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14297"
  }
]
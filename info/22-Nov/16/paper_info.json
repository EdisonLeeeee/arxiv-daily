[
  {
    "id": "arXiv:2211.07641",
    "title": "Motif-topology improved Spiking Neural Network for the Cocktail Party  Effect and McGurk Effect",
    "abstract": "Network architectures and learning principles are playing key in forming\ncomplex functions in artificial neural networks (ANNs) and spiking neural\nnetworks (SNNs). SNNs are considered the new-generation artificial networks by\nincorporating more biological features than ANNs, including dynamic spiking\nneurons, functionally specified architectures, and efficient learning\nparadigms. Network architectures are also considered embodying the function of\nthe network. Here, we propose a Motif-topology improved SNN (M-SNN) for the\nefficient multi-sensory integration and cognitive phenomenon simulations. The\ncognitive phenomenon simulation we simulated includes the cocktail party effect\nand McGurk effect, which are discussed by many researchers. Our M-SNN\nconstituted by the meta operator called network motifs. The source of 3-node\nnetwork motifs topology from artificial one pre-learned from the spatial or\ntemporal dataset. In the single-sensory classification task, the results showed\nthe accuracy of M-SNN using network motif topologies was higher than the pure\nfeedforward network topology without using them. In the multi-sensory\nintegration task, the performance of M-SNN using artificial network motif was\nbetter than the state-of-the-art SNN using BRP (biologically-plausible reward\npropagation). Furthermore, the M-SNN could better simulate the cocktail party\neffect and McGurk effect with lower computational cost. We think the artificial\nnetwork motifs could be considered as some prior knowledge that would\ncontribute to the multi-sensory integration of SNNs and provide more benefits\nfor simulating the cognitive phenomenon.",
    "descriptor": "",
    "authors": [
      "Shuncheng Jia",
      "Tielin Zhang",
      "Ruichen Zuo",
      "Bo Xu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.07641"
  },
  {
    "id": "arXiv:2211.07642",
    "title": "HigeNet: A Highly Efficient Modeling for Long Sequence Time Series  Prediction in AIOps",
    "abstract": "Modern IT system operation demands the integration of system software and\nhardware metrics. As a result, it generates a massive amount of data, which can\nbe potentially used to make data-driven operational decisions. In the basic\nform, the decision model needs to monitor a large set of machine data, such as\nCPU utilization, allocated memory, disk and network latency, and predicts the\nsystem metrics to prevent performance degradation. Nevertheless, building an\neffective prediction model in this scenario is rather challenging as the model\nhas to accurately capture the long-range coupling dependency in the\nMultivariate Time-Series (MTS). Moreover, this model needs to have low\ncomputational complexity and can scale efficiently to the dimension of data\navailable. In this paper, we propose a highly efficient model named HigeNet to\npredict the long-time sequence time series. We have deployed the HigeNet on\nproduction in the D-matrix platform. We also provide offline evaluations on\nseveral publicly available datasets as well as one online dataset to\ndemonstrate the model's efficacy. The extensive experiments show that training\ntime, resource usage and accuracy of the model are found to be significantly\nbetter than five state-of-the-art competing models.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Jiajia Li",
      "Feng Tan",
      "Cheng He",
      "Zikai Wang",
      "Haitao Song",
      "Lingfei Wu",
      "Pengwei Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07642"
  },
  {
    "id": "arXiv:2211.07643",
    "title": "Secure and Privacy-Preserving Automated End-to-End Integrated  IoT-Edge-Artificial Intelligence-Blockchain Monitoring System for Diabetes  Mellitus Prediction",
    "abstract": "Diabetes Mellitus, one of the leading causes of death worldwide, has no cure\ntill date and can lead to severe health complications, such as retinopathy,\nlimb amputation, cardiovascular diseases, and neuronal disease, if left\nuntreated.\nConsequently, it becomes crucial to take precautionary measures to\navoid/predict the occurrence of diabetes. Machine learning approaches have been\nproposed and evaluated in the literature for diabetes prediction. This paper\nproposes an IoT-edge-Artificial Intelligence (AI)-blockchain system for\ndiabetes prediction based on risk factors. The proposed system is underpinned\nby the blockchain to obtain a cohesive view of the risk factors data from\npatients across different hospitals and to ensure security and privacy of the\nuser data. Furthermore, we provide a comparative analysis of different medical\nsensors, devices, and methods to measure and collect the risk factors values in\nthe system. Numerical experiments and comparative analysis were carried out\nbetween our proposed system, using the most accurate random forest (RF) model,\nand the two most used state-of-the-art machine learning approaches, Logistic\nRegression (LR) and Support Vector Machine (SVM), using three real-life\ndiabetes datasets. The results show that the proposed system using RF predicts\ndiabetes with 4.57% more accuracy on average compared to LR and SVM, with 2.87\ntimes more execution time. Data balancing without feature selection does not\nshow significant improvement. The performance is improved by 1.14% and 0.02%\nafter feature selection for PIMA Indian and Sylhet datasets respectively, while\nit reduces by 0.89% for MIMIC III.",
    "descriptor": "",
    "authors": [
      "Leila Ismail",
      "Alain Hennebelle",
      "Huned Materwala",
      "Juma Al Kaabi",
      "Priya Ranjan",
      "Rajiv Janardhanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07643"
  },
  {
    "id": "arXiv:2211.07644",
    "title": "Bounds and Estimates on the Average Edit Distance",
    "abstract": "The edit distance is a metric of dissimilarity between strings, widely\napplied in computational biology, speech recognition, and machine learning. Let\n$e_k(n)$ denote the average edit distance between random, independent strings\nof $n$ characters from an alphabet of size $k$. For $k \\geq 2$, it is an open\nproblem how to efficiently compute the exact value of $\\alpha_{k}(n) =\ne_k(n)/n$ as well as of $\\alpha_{k} = \\lim_{n \\to \\infty} \\alpha_{k}(n)$, a\nlimit known to exist.\nThis paper shows that $\\alpha_k(n)-Q(n) \\leq \\alpha_k \\leq \\alpha_k(n)$, for\na specific $Q(n)=\\Theta(\\sqrt{\\log n / n})$, a result which implies that\n$\\alpha_k$ is computable. The exact computation of $\\alpha_k(n)$ is explored,\nleading to an algorithm running in time $T=\\mathcal{O}(n^2k\\min(3^n,k^n))$, a\ncomplexity that makes it of limited practical use.\nAn analysis of statistical estimates is proposed, based on McDiarmid's\ninequality, showing how $\\alpha_k(n)$ can be evaluated with good accuracy, high\nconfidence level, and reasonable computation time, for values of $n$ say up to\na quarter million. Correspondingly, 99.9\\% confidence intervals of width\napproximately $10^{-2}$ are obtained for $\\alpha_k$.\nCombinatorial arguments on edit scripts are exploited to analytically\ncharacterize an efficiently computable lower bound $\\beta_k^*$ to $\\alpha_k$,\nsuch that $ \\lim_{k \\to \\infty} \\beta_k^*=1$. In general, $\\beta_k^* \\leq\n\\alpha_k \\leq 1-1/k$; for $k$ greater than a few dozens, computing $\\beta_k^*$\nis much faster than generating good statistical estimates with confidence\nintervals of width $1-1/k-\\beta_k^*$.\nThe techniques developed in the paper yield improvements on most previously\npublished numerical values as well as results for alphabet sizes and string\nlengths not reported before.",
    "descriptor": "\nComments: 42 pages, 1 figure, 9 tables, submitted for review\n",
    "authors": [
      "Gianfranco Bilardi",
      "Michele Schimd"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.07644"
  },
  {
    "id": "arXiv:2211.07645",
    "title": "Evaluating Distribution System Reliability with Hyperstructures Graph  Convolutional Nets",
    "abstract": "Nowadays, it is broadly recognized in the power system community that to meet\nthe ever expanding energy sector's needs, it is no longer possible to rely\nsolely on physics-based models and that reliable, timely and sustainable\noperation of energy systems is impossible without systematic integration of\nartificial intelligence (AI) tools. Nevertheless, the adoption of AI in power\nsystems is still limited, while integration of AI particularly into\ndistribution grid investment planning is still an uncharted territory. We make\nthe first step forward to bridge this gap by showing how graph convolutional\nnetworks coupled with the hyperstructures representation learning framework can\nbe employed for accurate, reliable, and computationally efficient distribution\ngrid planning with resilience objectives. We further propose a Hyperstructures\nGraph Convolutional Neural Networks (Hyper-GCNNs) to capture hidden higher\norder representations of distribution networks with attention mechanism. Our\nnumerical experiments show that the proposed Hyper-GCNNs approach yields\nsubstantial gains in computational efficiency compared to the prevailing\nmethodology in distribution grid planning and also noticeably outperforms seven\nstate-of-the-art models from deep learning (DL) community.",
    "descriptor": "\nComments: IEEE BigData 2022\n",
    "authors": [
      "Yuzhou Chen",
      "Tian Jiang",
      "Miguel Heleno",
      "Alexandre Moreira",
      "Yulia R. Gel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.07645"
  },
  {
    "id": "arXiv:2211.07647",
    "title": "An Interpretable Neuron Embedding for Static Knowledge Distillation",
    "abstract": "Although deep neural networks have shown well-performance in various tasks,\nthe poor interpretability of the models is always criticized. In the paper, we\npropose a new interpretable neural network method, by embedding neurons into\nthe semantic space to extract their intrinsic global semantics. In contrast to\nprevious methods that probe latent knowledge inside the model, the proposed\nsemantic vector externalizes the latent knowledge to static knowledge, which is\neasy to exploit. Specifically, we assume that neurons with similar activation\nare of similar semantic information. Afterwards, semantic vectors are optimized\nby continuously aligning activation similarity and semantic vector similarity\nduring the training of the neural network. The visualization of semantic\nvectors allows for a qualitative explanation of the neural network. Moreover,\nwe assess the static knowledge quantitatively by knowledge distillation tasks.\nEmpirical experiments of visualization show that semantic vectors describe\nneuron activation semantics well. Without the sample-by-sample guidance from\nthe teacher model, static knowledge distillation exhibit comparable or even\nsuperior performance with existing relation-based knowledge distillation\nmethods.",
    "descriptor": "",
    "authors": [
      "Wei Han",
      "Yangqiming Wang",
      "Christian B\u00f6hm",
      "Junming Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07647"
  },
  {
    "id": "arXiv:2211.07650",
    "title": "Explainer Divergence Scores (EDS): Some Post-Hoc Explanations May be  Effective for Detecting Unknown Spurious Correlations",
    "abstract": "Recent work has suggested post-hoc explainers might be ineffective for\ndetecting spurious correlations in Deep Neural Networks (DNNs). However, we\nshow there are serious weaknesses with the existing evaluation frameworks for\nthis setting. Previously proposed metrics are extremely difficult to interpret\nand are not directly comparable between explainer methods. To alleviate these\nconstraints, we propose a new evaluation methodology, Explainer Divergence\nScores (EDS), grounded in an information theory approach to evaluate\nexplainers. EDS is easy to interpret and naturally comparable across\nexplainers. We use our methodology to compare the detection performance of\nthree different explainers - feature attribution methods, influential examples\nand concept extraction, on two different image datasets. We discover post-hoc\nexplainers often contain substantial information about a DNN's dependence on\nspurious artifacts, but in ways often imperceptible to human users. This\nsuggests the need for new techniques that can use this information to better\ndetect a DNN's reliance on spurious correlations.",
    "descriptor": "\nComments: Presented at the AIMLAI workshop at the 31st ACM International Conference on Information and Knowledge Management (CIKM 2022)\n",
    "authors": [
      "Shea Cardozo",
      "Gabriel Islas Montero",
      "Dmitry Kazhdan",
      "Botty Dimanov",
      "Maleakhi Wijaya",
      "Mateja Jamnik",
      "Pietro Lio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07650"
  },
  {
    "id": "arXiv:2211.07652",
    "title": "Machine Learning Performance Analysis to Predict Stroke Based on  Imbalanced Medical Dataset",
    "abstract": "Cerebral stroke, the second most substantial cause of death universally, has\nbeen a primary public health concern over the last few years. With the help of\nmachine learning techniques, early detection of various stroke alerts is\naccessible, which can efficiently prevent or diminish the stroke. Medical\ndataset, however, are frequently unbalanced in their class label, with a\ntendency to poorly predict minority classes. In this paper, the potential risk\nfactors for stroke are investigated. Moreover, four distinctive approaches are\napplied to improve the classification of the minority class in the imbalanced\nstroke dataset, which are the ensemble weight voting classifier, the Synthetic\nMinority Over-sampling Technique (SMOTE), Principal Component Analysis with\nK-Means Clustering (PCA-Kmeans), Focal Loss with the Deep Neural Network (DNN)\nand compare their performance. Through the analysis results, SMOTE and\nPCA-Kmeans with DNN-Focal Loss work best for the limited size of a large severe\nimbalanced dataset,which is 2-4 times outperform Kaggle work.",
    "descriptor": "\nComments: Accepted by CAIBDA 2022\n",
    "authors": [
      "Yuru Jing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07652"
  },
  {
    "id": "arXiv:2211.07675",
    "title": "On the Global Convergence of Fitted Q-Iteration with Two-layer Neural  Network Parametrization",
    "abstract": "Deep Q-learning based algorithms have been applied successfully in many\ndecision making problems, while their theoretical foundations are not as well\nunderstood. In this paper, we study a Fitted Q-Iteration with two-layer ReLU\nneural network parametrization, and find the sample complexity guarantees for\nthe algorithm. The approach estimates the Q-function in each iteration using a\nconvex optimization problem. We show that this approach achieves a sample\ncomplexity of $\\tilde{\\mathcal{O}}(1/\\epsilon^{2})$, which is order-optimal.\nThis result holds for a countable state-space and does not require any\nassumptions such as a linear or low rank structure on the MDP.",
    "descriptor": "",
    "authors": [
      "Mudit Gaur",
      "Vaneet Aggarwal",
      "Mridul Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07675"
  },
  {
    "id": "arXiv:2211.07687",
    "title": "Uncovering the Portability Limitation of Deep Learning-Based Wireless  Device Fingerprints",
    "abstract": "Recent device fingerprinting approaches rely on deep learning to extract\ndevice-specific features solely from raw RF signals to identify, classify and\nauthenticate wireless devices. One widely known issue lies in the inability of\nthese approaches to maintain good performances when the training data and\ntesting data are collected under varying deployment domains. For example, when\nthe learning model is trained on data collected from one receiver but tested on\ndata collected from a different receiver, the performance degrades\nsubstantially compared to when both training and testing data are collected\nusing the same receiver. The same also happens when considering other varying\ndomains, like channel condition and protocol configuration. In this paper, we\nbegin by explaining, through testbed experiments, the challenges these\nfingerprinting techniques face when it comes to domain portability. We will\nthen present some ideas on how to go about addressing these challenges so as to\nmake deep learning-based device fingerprinting more resilient to domain\nvariability.",
    "descriptor": "\nComments: This article has also been accepted to 6G Summit, Abu Dhabi, UAE, Nov. 2022\n",
    "authors": [
      "Bechir Hamdaoui",
      "Abdurrahman Elmaghbub"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.07687"
  },
  {
    "id": "arXiv:2211.07690",
    "title": "LQ Optimal Control for Power Tracking Operation of Wind Turbines",
    "abstract": "In this paper, an approach for active power control of individual wind\nturbines is presented. State-of-the-art controllers typically employ separate\ncontrol loops for torque and pitch control. In contrast, we use a multivariable\ncontrol approach. In detail, active power control is achieved by using\nreference trajectories for generator speed, generator torque, and pitch angle\nsuch that a desired power demand is met if weather conditions allow. Then, a\nlinear quadratic (LQ) optimal controller is used for reference tracking. In an\nOpenFAST simulation environment, the controller is compared to a\nstate-of-the-art approach. The simulations show a similar active power tracking\nperformance, while the LQ optimal controller results in lower mechanical wear.\nMoreover, the presented approach exhibits good reference tracking and by\nimproving the reference trajectory generation further performance increases can\nbe expected.",
    "descriptor": "",
    "authors": [
      "Aaron Grapentin",
      "Arnold Sterle",
      "J\u00f6rg Raisch",
      "Christian A. Hans"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.07690"
  },
  {
    "id": "arXiv:2211.07691",
    "title": "Low-depth arithmetic circuit lower bounds via shifted partials",
    "abstract": "We prove super-polynomial lower bounds for low-depth arithmetic circuits\nusing the shifted partials measure [Gupta-Kamath-Kayal-Saptharishi, CCC 2013],\n[Kayal, ECCC 2012] and the affine projections of partials measure\n[Garg-Kayal-Saha, FOCS 2020], [Kayal-Nair-Saha, STACS 2016]. The recent\nbreakthrough work of Limaye, Srinivasan and Tavenas [FOCS 2021] proved these\nlower bounds by proving lower bounds for low-depth set-multilinear circuits. An\ninteresting aspect of our proof is that it does not require conversion of a\ncircuit to a set-multilinear circuit, nor does it involve a random restriction.\nWe are able to upper bound the measures for homogeneous formulas directly,\nwithout going via set-multilinearity. Our lower bounds hold for the iterated\nmatrix multiplication as well as the Nisan-Wigderson design polynomials. We\nalso define a subclass of homogeneous formulas which we call unique parse tree\n(UPT) formulas, and prove superpolynomial lower bounds for these. This\ngeneralizes the superpolynomial lower bounds for regular formulas in\n[Kayal-Saha-Saptharishi, STOC 2014], [Fournier-Limaye-Malod-Srinivasan, STOC\n2014].",
    "descriptor": "",
    "authors": [
      "Prashanth Amireddy",
      "Ankit Garg",
      "Neeraj Kayal",
      "Chandan Saha",
      "Bhargav Thankey"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2211.07691"
  },
  {
    "id": "arXiv:2211.07692",
    "title": "Self-training of Machine Learning Models for Liver Histopathology:  Generalization under Clinical Shifts",
    "abstract": "Histopathology images are gigapixel-sized and include features and\ninformation at different resolutions. Collecting annotations in histopathology\nrequires highly specialized pathologists, making it expensive and\ntime-consuming. Self-training can alleviate annotation constraints by learning\nfrom both labeled and unlabeled data, reducing the amount of annotations\nrequired from pathologists. We study the design of teacher-student\nself-training systems for Non-alcoholic Steatohepatitis (NASH) using clinical\nhistopathology datasets with limited annotations. We evaluate the models on\nin-distribution and out-of-distribution test data under clinical data shifts.\nWe demonstrate that through self-training, the best student model statistically\noutperforms the teacher with a $3\\%$ absolute difference on the macro F1 score.\nThe best student model also approaches the performance of a fully supervised\nmodel trained with twice as many annotations.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 6 pages\n",
    "authors": [
      "Jin Li",
      "Deepta Rajan",
      "Chintan Shah",
      "Dinkar Juyal",
      "Shreya Chakraborty",
      "Chandan Akiti",
      "Filip Kos",
      "Janani Iyer",
      "Anand Sampat",
      "Ali Behrooz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07692"
  },
  {
    "id": "arXiv:2211.07693",
    "title": "Experimental and Theoretical Investigations of a Ground Source Heat Pump  System for Water and Space Heating Applications in Kazakhstan",
    "abstract": "The ground source heat pump heating system is considered as one of the best\nsolutions for the transition towards green heating under the continental\nclimate conditions like Kazakhstan. In this paper, experimental and theoretical\ninvestigations were carried out to develop a ground source heat pump-based\nheating system under the weather conditions in Kazakhstan and to evaluate its\nthermodynamic performance. The water-to-water heat pump heating system,\nintegrated with a ground source heat exchanger and used refrigerant R134a, was\ndesigned to provide hot water to meet the requirements for space heating. The\npredicted values of the coefficient of performance and the experimental results\nwere found to be in good agreement within 6.2%. The thermodynamic performance\nof the system was also assessed using various environment-friendly\nrefrigerants, such as R152a, R450A, R513A, R1234yf and R1234ze, as potential\nreplacements for R134a. Although R152a is found to be a good alternative for\nR134a in terms of coefficient of performance and total equivalent warming\nimpact, its flammability hinders its application. The heating system using\nrefrigerants R450A, R513A, R1234yf and R1234ze shows 2-3% lower coefficient of\nperformance than that of R134a. The highest exergy destruction is found to be\nattributed to the compressor, followed by the expansion valve, evaporator, and\ncondenser. Considering their low flammability and low environmental impact,\nR450A, R513A, R1234yf and R1234ze are identified as valuable replacements for\nR134a.",
    "descriptor": "",
    "authors": [
      "Yelnar Yerdesh",
      "Tangnur Amanzholov",
      "Abdurashid Aliuly",
      "Abzal Seitov",
      "Amankeldy Toleukhanov",
      "Mohanraj Murugesan",
      "Olivier Botella",
      "Michel Feidt",
      "Hua Sheng Wang",
      "Alexandr Tsoy",
      "Yerzhan Belyayev"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.07693"
  },
  {
    "id": "arXiv:2211.07696",
    "title": "Supervised Fine-tuning Evaluation for Long-term Visual Place Recognition",
    "abstract": "In this paper, we present a comprehensive study on the utility of deep\nconvolutional neural networks with two state-of-the-art pooling layers which\nare placed after convolutional layers and fine-tuned in an end-to-end manner\nfor visual place recognition task in challenging conditions, including seasonal\nand illumination variations. We compared extensively the performance of deep\nlearned global features with three different loss functions, e.g. triplet,\ncontrastive and ArcFace, for learning the parameters of the architectures in\nterms of fraction of the correct matches during deployment. To verify\neffectiveness of our results, we utilized two real world datasets in place\nrecognition, both indoor and outdoor. Our investigation demonstrates that fine\ntuning architectures with ArcFace loss in an end-to-end manner outperforms\nother two losses by approximately 1~4% in outdoor and 1~2% in indoor datasets,\ngiven certain thresholds, for the visual place recognition tasks.",
    "descriptor": "",
    "authors": [
      "Farid Alijani",
      "Esa Rahtu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07696"
  },
  {
    "id": "arXiv:2211.07697",
    "title": "Do Neural Networks Trained with Topological Features Learn Different  Internal Representations?",
    "abstract": "There is a growing body of work that leverages features extracted via\ntopological data analysis to train machine learning models. While this field,\nsometimes known as topological machine learning (TML), has seen some notable\nsuccesses, an understanding of how the process of learning from topological\nfeatures differs from the process of learning from raw data is still limited.\nIn this work, we begin to address one component of this larger issue by asking\nwhether a model trained with topological features learns internal\nrepresentations of data that are fundamentally different than those learned by\na model trained with the original raw data. To quantify ``different'', we\nexploit two popular metrics that can be used to measure the similarity of the\nhidden representations of data within neural networks, neural stitching and\ncentered kernel alignment. From these we draw a range of conclusions about how\ntraining with topological features does and does not change the representations\nthat a model learns. Perhaps unsurprisingly, we find that structurally, the\nhidden representations of models trained and evaluated on topological features\ndiffer substantially compared to those trained and evaluated on the\ncorresponding raw data. On the other hand, our experiments show that in some\ncases, these representations can be reconciled (at least to the degree required\nto solve the corresponding task) using a simple affine transformation. We\nconjecture that this means that neural networks trained on raw data may extract\nsome limited topological features in the process of making predictions.",
    "descriptor": "\nComments: To appear at NeurIPS 2022 Workshop on Symmetry and Geometry in Neural Representations (NeurReps)\n",
    "authors": [
      "Sarah McGuire",
      "Shane Jackson",
      "Tegan Emerson",
      "Henry Kvinge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2211.07697"
  },
  {
    "id": "arXiv:2211.07700",
    "title": "Disentangling Variational Autoencoders",
    "abstract": "A variational autoencoder (VAE) is a probabilistic machine learning framework\nfor posterior inference that projects an input set of high-dimensional data to\na lower-dimensional, latent space. The latent space learned with a VAE offers\nexciting opportunities to develop new data-driven design processes in creative\ndisciplines, in particular, to automate the generation of multiple novel\ndesigns that are aesthetically reminiscent of the input data but that were\nunseen during training. However, the learned latent space is typically\ndisorganized and entangled: traversing the latent space along a single\ndimension does not result in changes to single visual attributes of the data.\nThe lack of latent structure impedes designers from deliberately controlling\nthe visual attributes of new designs generated from the latent space. This\npaper presents an experimental study that investigates latent space\ndisentanglement. We implement three different VAE models from the literature\nand train them on a publicly available dataset of 60,000 images of hand-written\ndigits. We perform a sensitivity analysis to find a small number of latent\ndimensions necessary to maximize a lower bound to the log marginal likelihood\nof the data. Furthermore, we investigate the trade-offs between the quality of\nthe reconstruction of the decoded images and the level of disentanglement of\nthe latent space. We are able to automatically align three latent dimensions\nwith three interpretable visual properties of the digits: line weight, tilt and\nwidth. Our experiments suggest that i) increasing the contribution of the\nKullback-Leibler divergence between the prior over the latents and the\nvariational distribution to the evidence lower bound, and ii) conditioning\ninput image class enhances the learning of a disentangled latent space with a\nVAE.",
    "descriptor": "",
    "authors": [
      "Rafael Pastrana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07700"
  },
  {
    "id": "arXiv:2211.07703",
    "title": "Alzheimer's Diagnosis and Generation-Based Chatbot Using Hierarchical  Attention and Transformer",
    "abstract": "In this paper, we propose a natural language processing architecture that can\nhandle tasks that previously required two models as one model. With a single\nmodel, we analyze the language patterns and conversational context of\nAlzheimer's patients and derive answers from two results: patient\nclassification and chatbot. If the patient's language characteristics are\nidentified by chatbots in daily life, doctors can plan more precise diagnosis\nand treatment for early diagnosis. The proposed model is used to develop\nchatbots that replace questionnaires that required experts. There are two\nnatural language processing tasks performed by the model. The first is a\n'natural language classification' that indicates with probability whether the\npatient has an illness, and the second is to generate the next 'answer' of the\nchatbot to the patient's answer. In the first half, a context vector, which is\na characteristic of patient utterance, is extracted through a self-attention\nneural network. This context vector and chatbot (expert, moderator) questions\nare entered together into the encoder to obtain a matrix containing the\ncharacteristics of the interaction between the questioner and the patient. The\nvectorized matrix becomes a probability value for classification of patients.\nEnter the matrix into the decoder with the next answer from the chatbot (the\nmoderator) to generate the next utterance. As a result of learning this\nstructure with DmentiaBank's cookie theft description corpus, it was confirmed\nthat the value of the loss function of the encoder and decoder was\nsignificantly reduced and converged. This shows that capturing the speech\nlanguage pattern of Alzheimer's disease patients can contribute to early\ndiagnosis and longitudinal studies of the disease in the future.",
    "descriptor": "\nComments: 3 pages, in Korean language, 6 figures, 2022 Journal of The Korea Society of Computer and Information (KSCI)\n",
    "authors": [
      "Park Jun Yeong",
      "Shin Su Jong",
      "Choi Chang Hwan",
      "Lee Jung Jae",
      "Choi Sang-il"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07703"
  },
  {
    "id": "arXiv:2211.07704",
    "title": "Laplacian Filtered Loop-Star Decompositions and Quasi-Helmholtz  Laplacian Filters: Definitions, Analysis, and Efficient Algorithms",
    "abstract": "Quasi-Helmholtz decompositions are fundamental tools in integral equation\nmodeling of electromagnetic problems because of their ability of rescaling\nsolenoidal and non-solenoidal components of solutions, operator matrices, and\nradiated fields. These tools are however incapable, per se, of modifying the\nrefinement-dependent spectral behavior of the different operators and often\nneed to be combined with other preconditioning strategies. This paper\nintroduces the new concept of filtered quasi-Helmholtz decompositions proposing\nthem in two incarnations: the filtered Loop-Star functions and the\nquasi-Helmholtz Laplacian filters. Because they are capable of manipulating\nlarge parts of the operators' spectra, new families of preconditioners and fast\nsolvers can be derived from these new tools. A first application to the case of\nthe frequency and h-refinement preconditioning of the electric field integral\nequation is presented together with numerical results showing the practical\neffectiveness of the newly proposed decompositions.",
    "descriptor": "",
    "authors": [
      "Adrien Merlini",
      "Cl\u00e9ment Henry",
      "Davide Consoli",
      "Lyes Rahmouni",
      "Alexandre D\u00e9ly",
      "Francesco P. Andriulli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.07704"
  },
  {
    "id": "arXiv:2211.07705",
    "title": "A Machine Learning Approach to Classifying Construction Cost Documents  into the International Construction Measurement Standard",
    "abstract": "We introduce the first automated models for classifying natural language\ndescriptions provided in cost documents called \"Bills of Quantities\" (BoQs)\npopular in the infrastructure construction industry, into the International\nConstruction Measurement Standard (ICMS). The models we deployed and\nsystematically evaluated for multi-class text classification are learnt from a\ndataset of more than 50 thousand descriptions of items retrieved from 24 large\ninfrastructure construction projects across the United Kingdom. We describe our\napproach to language representation and subsequent modelling to examine the\nstrength of contextual semantics and temporal dependency of language used in\nconstruction project documentation. To do that we evaluate two experimental\npipelines to inferring ICMS codes from text, on the basis of two different\nlanguage representation models and a range of state-of-the-art sequence-based\nclassification methods, including recurrent and convolutional neural network\narchitectures. The findings indicate a highly effective and accurate ICMS\nautomation model is within reach, with reported accuracy results above 90% F1\nscore on average, on 32 ICMS categories. Furthermore, due to the specific\nnature of language use in the BoQs text; short, largely descriptive and\ntechnical, we find that simpler models compare favourably to achieving higher\naccuracy results. Our analysis suggest that information is more likely embedded\nin local key features in the descriptive text, which explains why a simpler\ngeneric temporal convolutional network (TCN) exhibits comparable memory to\nrecurrent architectures with the same capacity, and subsequently outperforms\nthese at this task.",
    "descriptor": "\nComments: Submitted to Engineering Applications of Artificial Intelligence\n",
    "authors": [
      "J. Ignacio Deza",
      "Hisham Ihshaish",
      "Lamine Mahdjoubi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07705"
  },
  {
    "id": "arXiv:2211.07708",
    "title": "Infinite horizon for symetric strategy population game",
    "abstract": "To predict the behavior of a population game when time becomes very long, the\nprocess that characterizes the evolution of our game dynamics must be\nreversible. Known games satisfying this are 2 strategy games as well as\npotential games with an exponential protocol. We will try to extend the study\nof infinite horizons for what are called symetric strategy games.",
    "descriptor": "",
    "authors": [
      "Meziane Privat"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.07708"
  },
  {
    "id": "arXiv:2211.07709",
    "title": "Incongruity Detection between Bangla News Headline and Body Content  through Graph Neural Network",
    "abstract": "Incongruity between news headlines and the body content is a common method of\ndeception used to attract readers. Profitable headlines pique readers' interest\nand encourage them to visit a specific website. This is usually done by adding\nan element of dishonesty, using enticements that do not precisely reflect the\ncontent being delivered. As a result, automatic detection of incongruent news\nbetween headline and body content using language analysis has gained the\nresearch community's attention. However, various solutions are primarily being\ndeveloped for English to address this problem, leaving low-resource languages\nout of the picture. Bangla is ranked 7th among the top 100 most widely spoken\nlanguages, which motivates us to pay special attention to the Bangla language.\nFurthermore, Bangla has a more complex syntactic structure and fewer natural\nlanguage processing resources, so it becomes challenging to perform NLP tasks\nlike incongruity detection and stance detection. To tackle this problem, for\nthe Bangla language, we offer a graph-based hierarchical dual encoder (BGHDE)\nmodel that learns the content similarity and contradiction between Bangla news\nheadlines and content paragraphs effectively. The experimental results show\nthat the proposed Bangla graph-based neural network model achieves above 90%\naccuracy on various Bangla news datasets.",
    "descriptor": "\nComments: 6 figures, 2 tables\n",
    "authors": [
      "Md Aminul Haque Palash",
      "Akib Khan",
      "Kawsarul Islam",
      "MD Abdullah Al Nasim",
      "Ryan Mohammad Bin Shahjahan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07709"
  },
  {
    "id": "arXiv:2211.07710",
    "title": "End-to-End Speech to Intent Prediction to improve E-commerce Customer  Support Voicebot in Hindi and English",
    "abstract": "Automation of on-call customer support relies heavily on accurate and\nefficient speech-to-intent (S2I) systems. Building such systems using\nmulti-component pipelines can pose various challenges because they require\nlarge annotated datasets, have higher latency, and have complex deployment.\nThese pipelines are also prone to compounding errors. To overcome these\nchallenges, we discuss an end-to-end (E2E) S2I model for customer support\nvoicebot task in a bilingual setting. We show how we can solve E2E intent\nclassification by leveraging a pre-trained automatic speech recognition (ASR)\nmodel with slight modification and fine-tuning on small annotated datasets.\nExperimental results show that our best E2E model outperforms a conventional\npipeline by a relative ~27% on the F1 score.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 Industry Track\n",
    "authors": [
      "Abhinav Goyal",
      "Anupam Singh",
      "Nikesh Garera"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.07710"
  },
  {
    "id": "arXiv:2211.07711",
    "title": "Multilevel Transformer For Multimodal Emotion Recognition",
    "abstract": "Multimodal emotion recognition has attracted much attention recently. Fusing\nmultiple modalities effectively with limited labeled data is a challenging\ntask. Considering the success of pre-trained model and fine-grained nature of\nemotion expression, it is reasonable to take these two aspects into\nconsideration. Unlike previous methods that mainly focus on one aspect, we\nintroduce a novel multi-granularity framework, which combines fine-grained\nrepresentation with pre-trained utterance-level representation. Inspired by\nTransformer TTS, we propose a multilevel transformer model to perform\nfine-grained multimodal emotion recognition. Specifically, we explore different\nmethods to incorporate phoneme-level embedding with word-level embedding. To\nperform multi-granularity learning, we simply combine multilevel transformer\nmodel with Albert. Extensive experimental results show that both our multilevel\ntransformer model and multi-granularity model outperform previous\nstate-of-the-art approaches on IEMOCAP dataset with text transcripts and speech\nsignal.",
    "descriptor": "\nComments: 5 pages, 2 figures, conference\n",
    "authors": [
      "Junyi He",
      "Meimei Wu",
      "Meng Li",
      "Xiaobo Zhu",
      "Feng Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07711"
  },
  {
    "id": "arXiv:2211.07712",
    "title": "Cloning Ideology and Style using Deep Learning",
    "abstract": "Text generation tasks have gotten the attention of researchers in the last\nfew years because of their applications on a large scale.In the past, many\nresearchers focused on task-based text generations.Our research focuses on text\ngeneration based on the ideology and style of a specific author, and text\ngeneration on a topic that was not written by the same author in the past.Our\ntrained model requires an input prompt containing initial few words of text to\nproduce a few paragraphs of text based on the ideology and style of the author\non which the model is trained.Our methodology to accomplish this task is based\non Bi-LSTM.The Bi-LSTM model is used to make predictions at the character\nlevel, during the training corpus of a specific author is used along with the\nground truth corpus.A pre-trained model is used to identify the sentences of\nground truth having contradiction with the author's corpus to make our language\nmodel inclined.During training, we have achieved a perplexity score of 2.23 at\nthe character level. The experiments show a perplexity score of around 3 over\nthe test dataset.",
    "descriptor": "\nComments: 11 pages, 7 figures, 3 tables\n",
    "authors": [
      "Dr. Omer Beg",
      "Muhammad Nasir Zafar",
      "Waleed Anjum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07712"
  },
  {
    "id": "arXiv:2211.07713",
    "title": "How Long Is Enough? Exploring the Optimal Intervals of Long-Range  Clinical Note Language Modeling",
    "abstract": "Large pre-trained language models (LMs) have been widely adopted in\nbiomedical and clinical domains, introducing many powerful LMs such as bio-lm\nand BioELECTRA. However, the applicability of these methods to real clinical\nuse cases is hindered, due to the limitation of pre-trained LMs in processing\nlong textual data with thousands of words, which is a common length for a\nclinical note. In this work, we explore long-range adaptation from such LMs\nwith Longformer, allowing the LMs to capture longer clinical notes context. We\nconduct experiments on three n2c2 challenges datasets and a longitudinal\nclinical dataset from Hong Kong Hospital Authority electronic health record\n(EHR) system to show the effectiveness and generalizability of this concept,\nachieving 10\\% F1-score improvement. Based on our experiments, we conclude that\ncapturing a longer clinical note interval is beneficial to the model\nperformance, but there are different cut-off intervals to achieve the optimal\nperformance for different target variables. Our code is available at\nhttps://github.com/HLTCHKUST/long-biomedical-model.",
    "descriptor": "",
    "authors": [
      "Samuel Cahyawijaya",
      "Bryan Wilie",
      "Holy Lovenia",
      "Huan Zhong",
      "MingQian Zhong",
      "Yuk-Yu Nancy Ip",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07713"
  },
  {
    "id": "arXiv:2211.07714",
    "title": "Revisiting Attention Weights as Explanations from an Information  Theoretic Perspective",
    "abstract": "Attention mechanisms have recently demonstrated impressive performance on a\nrange of NLP tasks, and attention scores are often used as a proxy for model\nexplainability. However, there is a debate on whether attention weights can, in\nfact, be used to identify the most important inputs to a model. We approach\nthis question from an information theoretic perspective by measuring the mutual\ninformation between the model output and the hidden states. From extensive\nexperiments, we draw the following conclusions: (i) Additive and Deep attention\nmechanisms are likely to be better at preserving the information between the\nhidden states and the model output (compared to Scaled Dot-product); (ii)\nablation studies indicate that Additive attention can actively learn to explain\nthe importance of its input hidden representations; (iii) when attention values\nare nearly the same, the rank order of attention values is not consistent with\nthe rank order of the mutual information(iv) Using Gumbel-Softmax with a\ntemperature lower than one, tends to produce a more skewed attention score\ndistribution compared to softmax and hence is a better choice for explainable\ndesign; (v) some building blocks are better at preserving the correlation\nbetween the ordered list of mutual information and attention weights order (for\ne.g., the combination of BiLSTM encoder and Additive attention). Our findings\nindicate that attention mechanisms do have the potential to function as a\nshortcut to model explanations when they are carefully combined with other\nmodel elements.",
    "descriptor": "",
    "authors": [
      "Bingyang Wen",
      "K.P. Subbalakshmi",
      "Fan Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07714"
  },
  {
    "id": "arXiv:2211.07715",
    "title": "Fast DistilBERT on CPUs",
    "abstract": "Transformer-based language models have become the standard approach to\nsolving natural language processing tasks. However, industry adoption usually\nrequires the maximum throughput to comply with certain latency constraints that\nprevents Transformer models from being used in production. To address this gap,\nmodel compression techniques such as quantization and pruning may be used to\nimprove inference efficiency. However, these compression techniques require\nspecialized software to apply and deploy at scale. In this work, we propose a\nnew pipeline for creating and running Fast Transformer models on CPUs,\nutilizing hardware-aware pruning, knowledge distillation, quantization, and our\nown Transformer inference runtime engine with optimized kernels for sparse and\nquantized operators. We demonstrate the efficiency of our pipeline by creating\na Fast DistilBERT model showing minimal accuracy loss on the question-answering\nSQuADv1.1 benchmark, and throughput results under typical production\nconstraints and environments. Our results outperform existing state-of-the-art\nNeural Magic's DeepSparse runtime performance by up to 50% and up to 4.1x\nperformance speedup over ONNX Runtime.",
    "descriptor": "\nComments: 9 pages, NeurIPS 2022, ENLSP Workshop\n",
    "authors": [
      "Haihao Shen",
      "Ofir Zafrir",
      "Bo Dong",
      "Hengyu Meng",
      "Xinyu Ye",
      "Zhe Wang",
      "Yi Ding",
      "Hanwen Chang",
      "Guy Boudoukh",
      "Moshe Wasserblat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07715"
  },
  {
    "id": "arXiv:2211.07716",
    "title": "Zero-Shot Text Matching for Automated Auditing using Sentence  Transformers",
    "abstract": "Natural language processing methods have several applications in automated\nauditing, including document or passage classification, information retrieval,\nand question answering. However, training such models requires a large amount\nof annotated data which is scarce in industrial settings. At the same time,\ntechniques like zero-shot and unsupervised learning allow for application of\nmodels pre-trained using general domain data to unseen domains.\nIn this work, we study the efficiency of unsupervised text matching using\nSentence-Bert, a transformer-based model, by applying it to the semantic\nsimilarity of financial passages. Experimental results show that this model is\nrobust to documents from in- and out-of-domain data.",
    "descriptor": "\nComments: To be published in proceedings of IEEE International Conference on Machine Learning Applications IEEE ICMLA 2022\n",
    "authors": [
      "David Biesner",
      "Maren Pielka",
      "Rajkumar Ramamurthy",
      "Tim Dilmaghani",
      "Bernd Kliem",
      "R\u00fcdiger Loitz",
      "Rafet Sifa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07716"
  },
  {
    "id": "arXiv:2211.07717",
    "title": "Deep Temporal Modelling of Clinical Depression through Social Media Text",
    "abstract": "We describe the development of a model to detect user-level clinical\ndepression based on a user's temporal social media posts. Our model uses a\nDepression Symptoms Detection (DSD) model, which is trained on the largest\nexisting samples of clinician annotated tweets for clinical depression\nsymptoms. We subsequently use our DSD model to extract clinically relevant\nfeatures, e.g., depression scores and their consequent temporal patterns, as\nwell as user posting activity patterns, e.g., quantifying their ``no activity''\nor ``silence.'' Furthermore, to evaluate the efficacy of these extracted\nfeatures, we create three kinds of datasets including a test dataset, from two\nexisting well-known benchmark datasets for user-level depression detection. We\nthen provide accuracy measures based on single features, baseline features and\nfeature ablation tests, at several different levels of temporal granularity,\ndata distributions, and clinical depression detection related settings to draw\na complete picture of the impact of these features across our created datasets.\nFinally, we show that, in general, only semantic oriented representation models\nperform well. However, clinical features may enhance overall performance\nprovided that the training and testing distribution is similar, and there is\nmore data in a user's timeline. Further, we show that the predictive capability\nof depression scores increase significantly while used in a more sensitive\nclinical depression detection settings.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Nawshad Farruque",
      "Randy Goebel",
      "Sudhakar Sivapalan",
      "Osmar R. Za\u00efane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07717"
  },
  {
    "id": "arXiv:2211.07719",
    "title": "(When) Are Contrastive Explanations of Reinforcement Learning Helpful?",
    "abstract": "Global explanations of a reinforcement learning (RL) agent's expected\nbehavior can make it safer to deploy. However, such explanations are often\ndifficult to understand because of the complicated nature of many RL policies.\nEffective human explanations are often contrastive, referencing a known\ncontrast (policy) to reduce redundancy. At the same time, these explanations\nalso require the additional effort of referencing that contrast when evaluating\nan explanation. We conduct a user study to understand whether and when\ncontrastive explanations might be preferable to complete explanations that do\nnot require referencing a contrast. We find that complete explanations are\ngenerally more effective when they are the same size or smaller than a\ncontrastive explanation of the same policy, and no worse when they are larger.\nThis suggests that contrastive explanations are not sufficient to solve the\nproblem of effectively explaining reinforcement learning policies, and require\nadditional careful study for use in this context.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 workshop on Human in the Loop Learning\n",
    "authors": [
      "Sanjana Narayanan",
      "Isaac Lage",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.07719"
  },
  {
    "id": "arXiv:2211.07722",
    "title": "The Birds Need Attention Too: Analysing usage of Self Attention in  identifying bird calls in soundscapes",
    "abstract": "Birds are vital parts of ecosystems across the world and are an excellent\nmeasure of the quality of life on earth. Many bird species are endangered while\nothers are already extinct. Ecological efforts in understanding and monitoring\nbird populations are important to conserve their habitat and species, but this\nmostly relies on manual methods in rough terrains. Recent advances in Machine\nLearning and Deep Learning have made automatic bird recognition in diverse\nenvironments possible. Birdcall recognition till now has been performed using\nconvolutional neural networks. In this work, we try and understand how\nself-attention can aid in this endeavor. With that we build an pre-trained\nAttention-based Spectrogram Transformer baseline for BirdCLEF 2022 and compare\nthe results against the pre-trained Convolution-based baseline. Our results\nshow that the transformer models outperformed the convolutional model and we\nfurther validate our results by building baselines and analyzing the results\nfor the previous year BirdCLEF 2021 challenge. Source code available at\nhttps://github.com/ck090/BirdCLEF-22",
    "descriptor": "\nComments: 12 pages, 9 tables and 7 figures\n",
    "authors": [
      "Chandra Kanth Nagesh",
      "Abhishek Purushothama"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.07722"
  },
  {
    "id": "arXiv:2211.07725",
    "title": "Hierarchically Structured Task-Agnostic Continual Learning",
    "abstract": "One notable weakness of current machine learning algorithms is the poor\nability of models to solve new problems without forgetting previously acquired\nknowledge. The Continual Learning paradigm has emerged as a protocol to\nsystematically investigate settings where the model sequentially observes\nsamples generated by a series of tasks. In this work, we take a task-agnostic\nview of continual learning and develop a hierarchical information-theoretic\noptimality principle that facilitates a trade-off between learning and\nforgetting. We derive this principle from a Bayesian perspective and show its\nconnections to previous approaches to continual learning. Based on this\nprinciple, we propose a neural network layer, called the\nMixture-of-Variational-Experts layer, that alleviates forgetting by creating a\nset of information processing paths through the network which is governed by a\ngating policy. Equipped with a diverse and specialized set of parameters, each\npath can be regarded as a distinct sub-network that learns to solve tasks. To\nimprove expert allocation, we introduce diversity objectives, which we evaluate\nin additional ablation studies. Importantly, our approach can operate in a\ntask-agnostic way, i.e., it does not require task-specific knowledge, as is the\ncase with many existing continual learning algorithms. Due to the general\nformulation based on generic utility functions, we can apply this optimality\nprinciple to a large variety of learning problems, including supervised\nlearning, reinforcement learning, and generative modeling. We demonstrate the\ncompetitive performance of our method on continual reinforcement learning and\nvariants of the MNIST, CIFAR-10, and CIFAR-100 datasets.",
    "descriptor": "",
    "authors": [
      "Heinke Hihn",
      "Daniel A. Braun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.07725"
  },
  {
    "id": "arXiv:2211.07727",
    "title": "Logical Tasks for Measuring Extrapolation and Rule Comprehension",
    "abstract": "Logical reasoning is essential in a variety of human activities. A\nrepresentative example of a logical task is mathematics. Recent large-scale\nmodels trained on large datasets have been successful in various fields, but\ntheir reasoning ability in arithmetic tasks is limited, which we reproduce\nexperimentally. Here, we recast this limitation as not unique to mathematics\nbut common to tasks that require logical operations. We then propose a new set\nof tasks, termed logical tasks, which will be the next challenge to address.\nThis higher point of view helps the development of inductive biases that have\nbroad impact beyond the solution of individual tasks. We define and\ncharacterize logical tasks and discuss system requirements for their solution.\nFurthermore, we discuss the relevance of logical tasks to concepts such as\nextrapolation, explainability, and inductive bias. Finally, we provide\ndirections for solving logical tasks.",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Ippei Fujisawa",
      "Ryota Kanai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07727"
  },
  {
    "id": "arXiv:2211.07729",
    "title": "Aligning Learners' Expectations and Performance by Learning Analytics  Systemwith a Predictive Model",
    "abstract": "Learning analytics (LA) is data collection, analysis, and representation of\ndata about learners in order to improve their learning and performance.\nFurthermore, LA opens the door to opportunities for self-regulated learning in\nhigher education, a circular process in which learners activate and sustain\nbehaviours that are oriented toward their personal learning goals. The\npotentials of LA and self-regulated learning are huge; however, they are not\nyet widely applied in higher education institutions. Slovenian higher education\ninstitutions have lagged behind other European countries in LA adoption. Our\nresearch aims to fill this gap by using a qualitatively and quantitatively led\nworkflow for building a requirement-oriented LA solution, consisting of\nempirically gathering the students' expectations of LA and presenting a\ndashboard solution. Translated Student Expectations of Learning Analytics\nQuestionnaire and focus groups were used to gather expectations from learners.\nBased on them, a user interface utilizing LA and grade prediction with an AI\nmodel was implemented for a selected course. The interface includes early grade\nprediction, peer comparison, and historical data overview. Grade prediction is\nbased on a machine learning model built on users' interaction in the virtual\nlearning environment, demographic data and lab grades. First, classification is\nused to determine students at risk of failing - its precision reaches 98% after\nthe first month of the course. Second, the exact grade is predicted with the\nDecision Tree Regressor, reaching a mean absolute error of 11.2grade points (on\na 100 points scale) after the first month. The proposed system's main benefit\nis the support for self-regulation of the learning process during the semester,\npossibly motivating students to adjust their learning strategies to prevent\nfailing the course. Initial student evaluation showed positive results.",
    "descriptor": "\nComments: 11 pages, 4 figures, submitted to ACM IUI conference\n",
    "authors": [
      "Sa\u0161a Brdnik",
      "Bo\u0161tjan \u0160umak",
      "Vili Podgorelec"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.07729"
  },
  {
    "id": "arXiv:2211.07730",
    "title": "QueryForm: A Simple Zero-shot Form Entity Query Framework",
    "abstract": "Zero-shot transfer learning for document understanding is a crucial yet\nunder-investigated scenario to help reduce the high cost involved in annotating\ndocument entities. We present a novel query-based framework, QueryForm, that\nextracts entity values from form-like documents in a zero-shot fashion.\nQueryForm contains a dual prompting mechanism that composes both the document\nschema and a specific entity type into a query, which is used to prompt a\nTransformer model to perform a single entity extraction task. Furthermore, we\npropose to leverage large-scale query-entity pairs generated from form-like\nwebpages with weak HTML annotations to pre-train QueryForm. By unifying\npre-training and fine-tuning into the same query-based framework, QueryForm\nenables models to learn from structured documents containing various entities\nand layouts, leading to better generalization to target document types without\nthe need for target-specific training data. QueryForm sets new state-of-the-art\naverage F1 score on both the XFUND (+4.6%~10.1%) and the Payment (+3.2%~9.5%)\nzero-shot benchmark, with a smaller model size and no additional image input.",
    "descriptor": "",
    "authors": [
      "Zifeng Wang",
      "Zizhao Zhang",
      "Jacob Devlin",
      "Chen-Yu Lee",
      "Guolong Su",
      "Hao Zhang",
      "Jennifer Dy",
      "Vincent Perot",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07730"
  },
  {
    "id": "arXiv:2211.07733",
    "title": "Speaking Multiple Languages Affects the Moral Bias of Language Models",
    "abstract": "Pre-trained multilingual language models (PMLMs) are commonly used when\ndealing with data from multiple languages and cross-lingual transfer. However,\nPMLMs are trained on varying amounts of data for each language. In practice\nthis means their performance is often much better on English than many other\nlanguages. We explore to what extent this also applies to moral norms. Do the\nmodels capture moral norms from English and impose them on other languages? Do\nthe models exhibit random and thus potentially harmful beliefs in certain\nlanguages? Both these issues could negatively impact cross-lingual transfer and\npotentially lead to harmful outcomes. In this paper, we (1) apply the\nMoralDirection framework to multilingual models, comparing results in German,\nCzech, Arabic, Mandarin Chinese, and English, (2) analyse model behaviour on\nfiltered parallel subtitles corpora, and (3) apply the models to a Moral\nFoundations Questionnaire, comparing with human responses from different\ncountries. Our experiments demonstrate that, indeed, PMLMs encode differing\nmoral biases, but these do not necessarily correspond to cultural differences\nor commonalities in human opinions.",
    "descriptor": "",
    "authors": [
      "Katharina H\u00e4mmerl",
      "Bj\u00f6rn Deiseroth",
      "Patrick Schramowski",
      "Jind\u0159ich Libovick\u00fd",
      "Constantin A. Rothkopf",
      "Alexander Fraser",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07733"
  },
  {
    "id": "arXiv:2211.07735",
    "title": "Monte Carlo Planning in Hybrid Belief POMDPs",
    "abstract": "Real-world problems often require reasoning about hybrid beliefs, over both\ndiscrete and continuous random variables. Yet, such a setting has hardly been\ninvestigated in the context of planning. Moreover, existing online Partially\nObservable Markov Decision Processes (POMDPs) solvers do not support hybrid\nbeliefs directly. In particular, these solvers do not address the added\ncomputational burden due to an increasing number of hypotheses with the\nplanning horizon, which can grow exponentially. As part of this work, we\npresent a novel algorithm, Hybrid Belief Monte Carlo Planning (HB-MCP) that\nutilizes the Monte Carlo Tree Search (MCTS) algorithm to solve a POMDP while\nmaintaining a hybrid belief. We illustrate how the upper confidence bound (UCB)\nexploration bonus can be leveraged to guide the growth of hypotheses trees\nalongside the belief trees. We then evaluate our approach in highly aliased\nsimulated environments where unresolved data association leads to multi-modal\nbelief hypotheses.",
    "descriptor": "",
    "authors": [
      "Moran Barenboim",
      "Moshe Shienman",
      "Vadim Indelman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.07735"
  },
  {
    "id": "arXiv:2211.07737",
    "title": "Describing emotions with acoustic property prompts for speech emotion  recognition",
    "abstract": "Emotions lie on a broad continuum and treating emotions as a discrete number\nof classes limits the ability of a model to capture the nuances in the\ncontinuum. The challenge is how to describe the nuances of emotions and how to\nenable a model to learn the descriptions. In this work, we devise a method to\nautomatically create a description (or prompt) for a given audio by computing\nacoustic properties, such as pitch, loudness, speech rate, and articulation\nrate. We pair a prompt with its corresponding audio using 5 different emotion\ndatasets. We trained a neural network model using these audio-text pairs. Then,\nwe evaluate the model using one more dataset. We investigate how the model can\nlearn to associate the audio with the descriptions, resulting in performance\nimprovement of Speech Emotion Recognition and Speech Audio Retrieval. We expect\nour findings to motivate research describing the broad continuum of emotion",
    "descriptor": "",
    "authors": [
      "Hira Dhamyal",
      "Benjamin Elizalde",
      "Soham Deshmukh",
      "Huaming Wang",
      "Bhiksha Raj",
      "Rita Singh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.07737"
  },
  {
    "id": "arXiv:2211.07738",
    "title": "A survey of the European Open Science Cloud services for expanding the  capacity and capabilities of multidisciplinary scientific applications",
    "abstract": "Open Science is a paradigm in which scientific data, procedures, tools and\nresults are shared transparently and reused by society as a whole. The\ninitiative known as the European Open Science Cloud (EOSC) is an effort in\nEurope to provide an open, trusted, virtual and federated computing environment\nto execute scientific applications, and to store, share and re-use research\ndata across borders and scientific disciplines. Additionally, scientific\nservices are becoming increasingly data-intensive, not only in terms of\ncomputationally intensive tasks but also in terms of storage resources.\nComputing paradigms such as High Performance Computing (HPC) and Cloud\nComputing are applied to e-science applications to meet these demands. However,\nadapting applications and services to these paradigms is not a trivial task,\ncommonly requiring a deep knowledge of the underlying technologies, which often\nconstitutes a barrier for its uptake by scientists in general. In this context,\nEOSC-SYNERGY, a collaborative project involving more than 20 institutions from\neight European countries pooling their knowledge and experience to enhance\nEOSC's capabilities and capacities, aims to bring EOSC closer to the scientific\ncommunities. This article provides a summary analysis of the adaptations made\nin the ten thematic services of EOSC-SYNERGY to embrace this paradigm. These\nservices are grouped into four categories: Earth Observation, Environment,\nBiomedicine, and Astrophysics. The analysis will lead to the identification of\ncommonalities, best practices and common requirements, regardless of the\nthematic area of the service. Experience gained from the thematic services\ncould be transferred to new services for the adoption of the EOSC ecosystem\nframework.",
    "descriptor": "",
    "authors": [
      "Amanda Calatrava",
      "Hern\u00e1n Asorey",
      "Jan Astalos",
      "Alberto Azevedo",
      "Francesco Benincasa",
      "Ignacio Blanquer",
      "Martin Bobak",
      "Francisco Brasileiro",
      "Laia Cod\u00f3",
      "Laura del Cano",
      "Borja Esteban",
      "Meritxell Ferret",
      "Josef Handl",
      "Tobias Kerzenmacher",
      "Valentin Kozlov",
      "Ale\u0161 K\u0159enek",
      "Ricardo Martins",
      "Manuel Pavesio",
      "Antonio Juan Rubio-Montero",
      "Juan S\u00e1nchez-Ferrero"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.07738"
  },
  {
    "id": "arXiv:2211.07740",
    "title": "Denoising Diffusion Models for Out-of-Distribution Detection",
    "abstract": "Out-of-distribution detection is crucial to the safe deployment of machine\nlearning systems. Currently, the state-of-the-art in unsupervised\nout-of-distribution detection is dominated by generative-based approaches that\nmake use of estimates of the likelihood or other measurements from a generative\nmodel. Reconstruction-based methods offer an alternative approach, in which a\nmeasure of reconstruction error is used to determine if a sample is\nout-of-distribution. However, reconstruction-based approaches are less\nfavoured, as they require careful tuning of the model's information bottleneck\n- such as the size of the latent dimension - to produce good results. In this\nwork, we exploit the view of denoising diffusion probabilistic models (DDPM) as\ndenoising autoencoders where the bottleneck is controlled externally, by means\nof the amount of noise applied. We propose to use DDPMs to reconstruct an input\nthat has been noised to a range of noise levels, and use the resulting\nmulti-dimensional reconstruction error to classify out-of-distribution inputs.\nOur approach outperforms not only reconstruction-based methods, but also\nstate-of-the-art generative-based approaches.",
    "descriptor": "",
    "authors": [
      "Mark S. Graham",
      "Walter H.L. Pinaya",
      "Petru-Daniel Tudosiu",
      "Parashkev Nachev",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07740"
  },
  {
    "id": "arXiv:2211.07743",
    "title": "Generative Aspect-Based Sentiment Analysis with Contrastive Learning and  Expressive Structure",
    "abstract": "Generative models have demonstrated impressive results on Aspect-based\nSentiment Analysis (ABSA) tasks, particularly for the emerging task of\nextracting Aspect-Category-Opinion-Sentiment (ACOS) quadruples. However, these\nmodels struggle with implicit sentiment expressions, which are commonly\nobserved in opinionated content such as online reviews. In this work, we\nintroduce GEN-SCL-NAT, which consists of two techniques for improved structured\ngeneration for ACOS quadruple extraction. First, we propose GEN-SCL, a\nsupervised contrastive learning objective that aids quadruple prediction by\nencouraging the model to produce input representations that are discriminable\nacross key input attributes, such as sentiment polarity and the existence of\nimplicit opinions and aspects. Second, we introduce GEN-NAT, a new structured\ngeneration format that better adapts autoregressive encoder-decoder models to\nextract quadruples in a generative fashion. Experimental results show that\nGEN-SCL-NAT achieves top performance across three ACOS datasets, averaging\n1.48% F1 improvement, with a maximum 1.73% increase on the LAPTOP-L1 dataset.\nAdditionally, we see significant gains on implicit aspect and opinion splits\nthat have been shown as challenging for existing ACOS approaches.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Joseph J. Peper",
      "Lu Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07743"
  },
  {
    "id": "arXiv:2211.07747",
    "title": "Detection of fraudulent financial papers by picking a collection of  characteristics using optimization algorithms and classification techniques  based on squirrels",
    "abstract": "To produce important investment decisions, investors require financial\nrecords and economic information. However, most companies manipulate investors\nand financial institutions by inflating their financial statements. Fraudulent\nFinancial Activities exist in any monetary or financial transaction scenario,\nwhether physical or electronic. A challenging problem that arises in this\ndomain is the issue that affects and troubles individuals and institutions.\nThis problem has attracted more attention in the field in part owing to the\nprevalence of financial fraud and the paucity of previous research. For this\npurpose, in this study, the main approach to solve this problem, an anomaly\ndetection-based approach based on a combination of feature selection based on\nsquirrel optimization pattern and classification methods have been used. The\naim is to develop this method to provide a model for detecting anomalies in\nfinancial statements using a combination of selected features with the nearest\nneighbor classifications, neural networks, support vector machine, and\nBayesian. Anomaly samples are then analyzed and compared to recommended\ntechniques using assessment criteria. Squirrel optimization's meta-exploratory\ncapability, along with the approach's ability to identify abnormalities in\nfinancial data, has been shown to be effective in implementing the suggested\nstrategy. They discovered fake financial statements because of their expertise.",
    "descriptor": "",
    "authors": [
      "Peyman Mohammadzadeh germi",
      "Mohsen Najarbashi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07747"
  },
  {
    "id": "arXiv:2211.07748",
    "title": "3D Reconstruction-Based Seed Counting of Sorghum Panicles for  Agricultural Inspection",
    "abstract": "In this paper, we present a method for creating high-quality 3D models of\nsorghum panicles for phenotyping in breeding experiments. This is achieved with\na novel reconstruction approach that uses seeds as semantic landmarks in both\n2D and 3D. To evaluate the performance, we develop a new metric for assessing\nthe quality of reconstructed point clouds without having a ground-truth point\ncloud. Finally, a counting method is presented where the density of seed\ncenters in the 3D model allows 2D counts from multiple views to be effectively\ncombined into a whole-panicle count. We demonstrate that using this method to\nestimate seed count and weight for sorghum outperforms count extrapolation from\n2D images, an approach used in most state of the art methods for seeds and\ngrains of comparable size.",
    "descriptor": "",
    "authors": [
      "Harry Freeman",
      "Eric Schneider",
      "Chung Hee Kim",
      "Moonyoung Lee",
      "George Kantor"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07748"
  },
  {
    "id": "arXiv:2211.07750",
    "title": "A Matlab and CasADi-based Implementation of RICE Dynamic Game",
    "abstract": "The most widely used integrated assessment model for studying the economics\nof climate change is the dynamic/regional integrated model of climate and\neconomy (DICE/RICE). In this document, we first represent the RICE-2011 model\nas a dynamic game, termed the RICE game. Then, both cooperative and\nnon-cooperative solutions to the RICE game are considered. Next, a description\nof how to use the repository RICE-GAME on GitHub is provided. The repository\nRICE-GAME is a Matlab and CasADi-based implementation of the RICE game and its\ncooperative and non-cooperative solutions.",
    "descriptor": "",
    "authors": [
      "Yijun Chen",
      "Guodong Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.07750"
  },
  {
    "id": "arXiv:2211.07751",
    "title": "Arbitrary Style Guidance for Enhanced Diffusion-Based Text-to-Image  Generation",
    "abstract": "Diffusion-based text-to-image generation models like GLIDE and DALLE-2 have\ngained wide success recently for their superior performance in turning complex\ntext inputs into images of high quality and wide diversity. In particular, they\nare proven to be very powerful in creating graphic arts of various formats and\nstyles. Although current models supported specifying style formats like oil\npainting or pencil drawing, fine-grained style features like color\ndistributions and brush strokes are hard to specify as they are randomly picked\nfrom a conditional distribution based on the given text input. Here we propose\na novel style guidance method to support generating images using arbitrary\nstyle guided by a reference image. The generation method does not require a\nseparate style transfer model to generate desired styles while maintaining\nimage quality in generated content as controlled by the text input.\nAdditionally, the guidance method can be applied without a style reference,\ndenoted as self style guidance, to generate images of more diverse styles.\nComprehensive experiments prove that the proposed method remains robust and\neffective in a wide range of conditions, including diverse graphic art forms,\nimage content types and diffusion models.",
    "descriptor": "\nComments: To appear at WACV 2023\n",
    "authors": [
      "Zhihong Pan",
      "Xin Zhou",
      "Hao Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.07751"
  },
  {
    "id": "arXiv:2211.07752",
    "title": "Robot Operating System 2: Design, Architecture, and Uses In The Wild",
    "abstract": "The next chapter of the robotics revolution is well underway with the\ndeployment of robots for a broad range of commercial use-cases. Even in a\nmyriad of applications and environments, there exists a common vocabulary of\ncomponents that robots share - the need for a modular, scalable, and reliable\narchitecture; sensing; planning; mobility; and autonomy. The Robot Operating\nSystem (ROS) was an integral part of the last chapter, demonstrably expediting\nrobotics research with freely-available components and a modular framework.\nHowever, ROS 1 was not designed with many necessary production-grade features\nand algorithms. ROS 2 and its related projects have been redesigned from the\nground up to meet the challenges set forth by modern robotic systems in new and\nexploratory domains at all scales. In this review, we highlight the\nphilosophical and architectural changes of ROS 2 powering this new chapter in\nthe robotics revolution. We also show through case studies the influence ROS 2\nand its adoption has had on accelerating real robot systems to reliable\ndeployment in an assortment of challenging environments.",
    "descriptor": "\nComments: This manuscript has been accepted for publication in Science Robotics. This version has not undergone final editing. Please refer to the complete version of record at this https URL The manuscript may not be reproduced or used in any manner that does not fall within the fair use provisions of the Copyright Act without the prior, written permission of AAAS\n",
    "authors": [
      "Steve Macenski",
      "Tully Foote",
      "Brian Gerkey",
      "Chris Lalancette",
      "William Woodall"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.07752"
  },
  {
    "id": "arXiv:2211.07761",
    "title": "Impact of spiking neurons leakages and network recurrences on  event-based spatio-temporal pattern recognition",
    "abstract": "Spiking neural networks coupled with neuromorphic hardware and event-based\nsensors are getting increased interest for low-latency and low-power inference\nat the edge. However, multiple spiking neuron models have been proposed in the\nliterature with different levels of biological plausibility and different\ncomputational features and complexities. Consequently, there is a need to\ndefine the right level of abstraction from biology in order to get the best\nperformance in accurate, efficient and fast inference in neuromorphic hardware.\nIn this context, we explore the impact of synaptic and membrane leakages in\nspiking neurons. We confront three neural models with different computational\ncomplexities using feedforward and recurrent topologies for event-based visual\nand auditory pattern recognition. Our results show that, in terms of accuracy,\nleakages are important when there are both temporal information in the data and\nexplicit recurrence in the network. In addition, leakages do not necessarily\nincrease the sparsity of spikes flowing in the network. We also investigate the\nimpact of heterogeneity in the time constant of leakages, and the results show\na slight improvement in accuracy when using data with a rich temporal\nstructure. These results advance our understanding of the computational role of\nthe neural leakages and network recurrences, and provide valuable insights for\nthe design of compact and energy-efficient neuromorphic hardware for embedded\nsystems.",
    "descriptor": "",
    "authors": [
      "Mohamed Sadek Bouanane",
      "Dalila Cherifi",
      "Elisabetta Chicca",
      "Lyes Khacef"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.07761"
  },
  {
    "id": "arXiv:2211.07768",
    "title": "Meta-Learning of Neural State-Space Models Using Data From Similar  Systems",
    "abstract": "Deep neural state-space models (SSMs) provide a powerful tool for modeling\ndynamical systems solely using operational data. Typically, neural SSMs are\ntrained using data collected from the actual system under consideration,\ndespite the likely existence of operational data from similar systems which\nhave previously been deployed in the field. In this paper, we propose the use\nof model-agnostic meta-learning (MAML) for constructing deep encoder\nnetwork-based SSMs, by leveraging a combination of archived data from similar\nsystems (used to meta-train offline) and limited data from the actual system\n(used for rapid online adaptation). We demonstrate using a numerical example\nthat meta-learning can result in more accurate neural SSM models than\nsupervised- or transfer-learning, despite few adaptation steps and limited\nonline data. Additionally, we show that by carefully partitioning and adapting\nthe encoder layers while fixing the state-transition operator, we can achieve\ncomparable performance to MAML while reducing online adaptation complexity.",
    "descriptor": "\nComments: Submitted for conference publication\n",
    "authors": [
      "Ankush Chakrabarty",
      "Gordon Wichern",
      "Christopher R. Laughman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.07768"
  },
  {
    "id": "arXiv:2211.07769",
    "title": "Improving Children's Speech Recognition by Fine-tuning Self-supervised  Adult Speech Representations",
    "abstract": "Children's speech recognition is a vital, yet largely overlooked domain when\nbuilding inclusive speech technologies. The major challenge impeding progress\nin this domain is the lack of adequate child speech corpora; however, recent\nadvances in self-supervised learning have created a new opportunity for\novercoming this problem of data scarcity. In this paper, we leverage\nself-supervised adult speech representations and use three well-known child\nspeech corpora to build models for children's speech recognition. We assess the\nperformance of fine-tuning on both native and non-native children's speech,\nexamine the effect of cross-domain child corpora, and investigate the minimum\namount of child speech required to fine-tune a model which outperforms a\nstate-of-the-art adult model. We also analyze speech recognition performance\nacross children's ages. Our results demonstrate that fine-tuning with\ncross-domain child corpora leads to relative improvements of up to 46.08% and\n45.53% for native and non-native child speech respectively, and absolute\nimprovements of 14.70% and 31.10%. We also show that with as little as 5 hours\nof transcribed children's speech, it is possible to fine-tune a children's\nspeech recognition system that outperforms a state-of-the-art adult model\nfine-tuned on 960 hours of adult speech.",
    "descriptor": "\nComments: Under-review @ Speech Communication Journal\n",
    "authors": [
      "Renee Lu",
      "Mostafa Shahin",
      "Beena Ahmed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.07769"
  },
  {
    "id": "arXiv:2211.07771",
    "title": "Edge2Vec: A High Quality Embedding for the Jigsaw Puzzle Problem",
    "abstract": "Pairwise compatibility measure (CM) is a key component in solving the jigsaw\npuzzle problem (JPP) and many of its recently proposed variants. With the rapid\nrise of deep neural networks (DNNs), a trade-off between performance (i.e.,\naccuracy) and computational efficiency has become a very significant issue.\nWhereas an end-to-end DNN-based CM model exhibits high performance, it becomes\nvirtually infeasible on very large puzzles, due to its highly intensive\ncomputation. On the other hand, exploiting the concept of embeddings to\nalleviate significantly the computational efficiency, has resulted in degraded\nperformance, according to recent studies. This paper derives an advanced CM\nmodel (based on modified embeddings and a new loss function, called hard batch\ntriplet loss) for closing the above gap between speed and accuracy; namely a CM\nmodel that achieves SOTA results in terms of performance and efficiency\ncombined. We evaluated our newly derived CM on three commonly used datasets,\nand obtained a reconstruction improvement of 5.8% and 19.5% for so-called\nType-1 and Type-2 problem variants, respectively, compared to best known\nresults due to previous CMs.",
    "descriptor": "",
    "authors": [
      "Daniel Rika",
      "Dror Sholomon",
      "Eli David",
      "Nathan S. Netanyahu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07771"
  },
  {
    "id": "arXiv:2211.07772",
    "title": "Robust Deep Learning for Autonomous Driving",
    "abstract": "The last decade's research in artificial intelligence had a significant\nimpact on the advance of autonomous driving. Yet, safety remains a major\nconcern when it comes to deploying such systems in high-risk environments. The\nobjective of this thesis is to develop methodological tools which provide\nreliable uncertainty estimates for deep neural networks. First, we introduce a\nnew criterion to reliably estimate model confidence: the true class probability\n(TCP). We show that TCP offers better properties for failure prediction than\ncurrent uncertainty measures. Since the true class is by essence unknown at\ntest time, we propose to learn TCP criterion from data with an auxiliary model,\nintroducing a specific learning scheme adapted to this context. The relevance\nof the proposed approach is validated on image classification and semantic\nsegmentation datasets. Then, we extend our learned confidence approach to the\ntask of domain adaptation where it improves the selection of pseudo-labels in\nself-training methods. Finally, we tackle the challenge of jointly detecting\nmisclassification and out-of-distributions samples by introducing a new\nuncertainty measure based on evidential models and defined on the simplex.",
    "descriptor": "\nComments: Phd Thesis, defended on March 16th 2022\n",
    "authors": [
      "Charles Corbi\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.07772"
  },
  {
    "id": "arXiv:2211.07774",
    "title": "Interpreting Bias in the Neural Networks: A Peek Into Representational  Similarity",
    "abstract": "Neural networks trained on standard image classification data sets are shown\nto be less resistant to data set bias. It is necessary to comprehend the\nbehavior objective function that might correspond to superior performance for\ndata with biases. However, there is little research on the selection of the\nobjective function and its representational structure when trained on data set\nwith biases.\nIn this paper, we investigate the performance and internal representational\nstructure of convolution-based neural networks (e.g., ResNets) trained on\nbiased data using various objective functions. We specifically study\nsimilarities in representations, using Centered Kernel Alignment (CKA), for\ndifferent objective functions (probabilistic and margin-based) and offer a\ncomprehensive analysis of the chosen ones.\nAccording to our findings, ResNets representations obtained with Negative Log\nLikelihood $(\\mathcal{L}_{NLL})$ and Softmax Cross-Entropy\n($\\mathcal{L}_{SCE}$) as loss functions are equally capable of producing better\nperformance and fine representations on biased data. We note that without\nprogressive representational similarities among the layers of a neural network,\nthe performance is less likely to be robust.",
    "descriptor": "",
    "authors": [
      "Gnyanesh Bangaru",
      "Lalith Bharadwaj Baru",
      "Kiran Chakravarthula"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07774"
  },
  {
    "id": "arXiv:2211.07777",
    "title": "FLUPS -- a flexible and performant massively parallel Fourier transform  library",
    "abstract": "Massively parallel Fourier transforms are widely used in computational\nsciences, and specifically in computational fluid dynamics which involves\nunbounded Poisson problems. In practice the latter is usually the most\ntime-consuming operation due to its inescapable all-to-all communication\npattern. The original flups library tackles that issue with an implementation\nof the distributed Fourier transform tailor-made for successive resolutions of\nunbounded Poisson problems. However the proposed implementation lacks of\nflexibility as it only supports cell-centered data layout and features a plain\ncommunication strategy. This work extends the library along two directions.\nFirst, flups implementation is generalized to support a node-centered data\nlayout. Second, three distinct approaches are provided to handle the\ncommunications: one all-to-all, and two non-blocking implementations relying on\nmanual packing and MPI_Datatype to communicate over the network. The proposed\nsoftware is validated against analytical solutions for unbounded,\nsemi-unbounded, and periodic domains. The performance of the approaches is then\ncompared against accFFT, another distributed FFT implementation, using a\nperiodic case. Finally the performance metrics of each implementation are\nanalyzed and detailed on various top-tier European infrastructures up to 49,152\ncores. This work brings flups up to a fully production-ready and performant\ndistributed FFT library, featuring all the possible types of FFTs and with\nflexibility in the data-layout. The code is available under a BSD-3 license at\ngithub.com/vortexlab-uclouvain/flups.",
    "descriptor": "\nComments: submitted for publication on Nov. 14th 2022\n",
    "authors": [
      "Pierre Balty",
      "Philippe Chatelain",
      "Thomas Gillis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.07777"
  },
  {
    "id": "arXiv:2211.07782",
    "title": "An approach for Test Impact Analysis on the Integration Level in Java  programs",
    "abstract": "Test Impact Analysis is an approach to obtain a subset of tests impacted by\ncode changes. This approach is mainly applied to unit testing where the link\nbetween the code and its associated tests is easy to obtain. On the integration\nlevel, however, it is not straightforward to find such a link programmatically,\nespecially when the integration tests are held into separate repositories. We\npropose an approach for selecting integration tests based on the runtime\nanalysis of code changes to reduce the test execution overhead. We provide a\nset of tools and a framework that can be plugged into existing CI/CD pipelines.\nWe have evaluated the approach on a range of open-source Java programs and\nfound $\\approx$50\\% reduction in tests on average, and above 80\\% in a few\ncases. We have also applied the approach to a large-scale commercial system in\nproduction and found similar results.",
    "descriptor": "\nComments: 8th International Congress on Information and Communication Technology (ICICT) 2023, LNNS\n",
    "authors": [
      "Muzammil Shahbaz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.07782"
  },
  {
    "id": "arXiv:2211.07791",
    "title": "Differentially-Private Dynamic Average Consensus",
    "abstract": "We address differential privacy for dynamic average consensus. Not only is\ndynamic average consensus widely used in cooperative control and distributed\ntracking, it is also a fundamental building block in numerous distributed\ncomputation algorithms such as multi-agent optimization and distributed Nash\nequilibrium seeking. By co-designing the dynamic average consensus mechanism\nand the differential-privacy noise injection mechanism, we propose the first\ndynamic average consensus algorithm that can ensure both provable convergence\nto the exact average reference signal and rigorous $\\epsilon$-differential\nprivacy, even when the number of iterations tends to infinity. Given that\ndynamic average consensus includes the static average consensus as a special\ncase, the approach can also be used to ensure rigorous $\\epsilon$-differential\nprivacy in static average consensus while maintaining accurate consensus\nresult. To our knowledge, ensuring both provable convergence and rigorous\n$\\epsilon$-differential privacy (even for infinite number of iterations) has\nnot been achieved before in average consensus algorithms. Numerical simulation\nresults confirm the effectiveness of the proposed approach.",
    "descriptor": "\nComments: IEEE CDC. arXiv admin note: substantial text overlap with arXiv:2210.16395; text overlap with arXiv:2209.01486\n",
    "authors": [
      "Yongqiang Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.07791"
  },
  {
    "id": "arXiv:2211.07794",
    "title": "Augmented Thresholds for MONI",
    "abstract": "MONI (Rossi et al., 2022) can store a pangenomic dataset T in small space and\nlater, given a pattern P, quickly find the maximal exact matches (MEMs) of P\nwith respect to T. In this paper we consider its one-pass version (Boucher et\nal., 2021), whose query times are dominated in our experiments by longest\ncommon extension (LCE) queries. We show how a small modification lets us avoid\nmost of these queries and thus significantly speeds up MONI in practice while\nonly slightly increasing its size.",
    "descriptor": "\nComments: 10 pages, 2 figures, preprint\n",
    "authors": [
      "C\u00e9sar Mart\u00ednez-Guardiola",
      "Nathaniel K. Brown",
      "Fernando Silva-Coira",
      "Dominik K\u00f6ppl",
      "Travis Gagie",
      "Susana Ladra"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.07794"
  },
  {
    "id": "arXiv:2211.07796",
    "title": "Massively Parallel Algorithms for $b$-Matching",
    "abstract": "This paper presents an $O(\\log\\log \\bar{d})$ round massively parallel\nalgorithm for $1+\\epsilon$ approximation of maximum weighted $b$-matchings,\nusing near-linear memory per machine. Here $\\bar{d}$ denotes the average degree\nin the graph and $\\epsilon$ is an arbitrarily small positive constant. Recall\nthat $b$-matching is the natural and well-studied generalization of the\nmatching problem where different vertices are allowed to have multiple (and\ndiffering number of) incident edges in the matching. Concretely, each vertex\n$v$ is given a positive integer budget $b_v$ and it can have up to $b_v$\nincident edges in the matching. Previously, there were known algorithms with\nround complexity $O(\\log\\log n)$, or $O(\\log\\log \\Delta)$ where $\\Delta$\ndenotes maximum degree, for $1+\\epsilon$ approximation of weighted matching and\nfor maximal matching [Czumaj et al., STOC'18, Ghaffari et al. PODC'18; Assadi\net al. SODA'19; Behnezhad et al. FOCS'19; Gamlath et al. PODC'19], but these\nalgorithms do not extend to the more general $b$-matching problem.",
    "descriptor": "\nComments: This paper appeared in Proceedings of the 34th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA) 2022\n",
    "authors": [
      "Mohsen Ghaffari",
      "Christoph Grunau",
      "Slobodan Mitrovi\u0107"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.07796"
  },
  {
    "id": "arXiv:2211.07797",
    "title": "Energy Storage Price Arbitrage via Opportunity Value Function Prediction",
    "abstract": "This paper proposes a novel energy storage price arbitrage algorithm\ncombining supervised learning with dynamic programming. The proposed approach\nuses a neural network to directly predicts the opportunity cost at different\nenergy storage state-of-charge levels, and then input the predicted opportunity\ncost into a model-based arbitrage control algorithm for optimal decisions. We\ngenerate the historical optimal opportunity value function using price data and\na dynamic programming algorithm, then use it as the ground truth and historical\nprice as predictors to train the opportunity value function prediction model.\nOur method achieves 65% to 90% profit compared to perfect foresight in case\nstudies using different energy storage models and price data from New York\nState, which significantly outperforms existing model-based and learning-based\nmethods. While guaranteeing high profitability, the algorithm is also\nlight-weighted and can be trained and implemented with minimal computational\ncost. Our results also show that the learned prediction model has excellent\ntransferability. The prediction model trained using price data from one region\nalso provides good arbitrage results when tested over other regions.",
    "descriptor": "",
    "authors": [
      "Ningkun Zheng",
      "Xiaoxiang Liu",
      "Bolun Xu",
      "Yuanyuan Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07797"
  },
  {
    "id": "arXiv:2211.07804",
    "title": "Diffusion Models for Medical Image Analysis: A Comprehensive Survey",
    "abstract": "Denoising diffusion models, a class of generative models, have garnered\nimmense interest lately in various deep-learning problems. A diffusion\nprobabilistic model defines a forward diffusion stage where the input data is\ngradually perturbed over several steps by adding Gaussian noise and then learns\nto reverse the diffusion process to retrieve the desired noise-free data from\nnoisy data samples. Diffusion models are widely appreciated for their strong\nmode coverage and quality of the generated samples despite their known\ncomputational burdens. Capitalizing on the advances in computer vision, the\nfield of medical imaging has also observed a growing interest in diffusion\nmodels. To help the researcher navigate this profusion, this survey intends to\nprovide a comprehensive overview of diffusion models in the discipline of\nmedical image analysis. Specifically, we introduce the solid theoretical\nfoundation and fundamental concepts behind diffusion models and the three\ngeneric diffusion modelling frameworks: diffusion probabilistic models,\nnoise-conditioned score networks, and stochastic differential equations. Then,\nwe provide a systematic taxonomy of diffusion models in the medical domain and\npropose a multi-perspective categorization based on their application, imaging\nmodality, organ of interest, and algorithms. To this end, we cover extensive\napplications of diffusion models in the medical domain. Furthermore, we\nemphasize the practical use case of some selected approaches, and then we\ndiscuss the limitations of the diffusion models in the medical domain and\npropose several directions to fulfill the demands of this field. Finally, we\ngather the overviewed studies with their available open-source implementations\nat\nhttps://github.com/amirhossein-kz/Awesome-Diffusion-Models-in-Medical-Imaging.",
    "descriptor": "\nComments: Submitted to MIA Journal\n",
    "authors": [
      "Amirhossein Kazerouni",
      "Ehsan Khodapanah Aghdam",
      "Moein Heidari",
      "Reza Azad",
      "Mohsen Fayyaz",
      "Ilker Hacihaliloglu",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07804"
  },
  {
    "id": "arXiv:2211.07805",
    "title": "Agent-State Construction with Auxiliary Inputs",
    "abstract": "In many, if not every realistic sequential decision-making task, the\ndecision-making agent is not able to model the full complexity of the world.\nThe environment is often much larger and more complex than the agent, a setting\nalso known as partial observability. In such settings, the agent must leverage\nmore than just the current sensory inputs; it must construct an agent state\nthat summarizes previous interactions with the world. Currently, a popular\napproach for tackling this problem is to learn the agent-state function via a\nrecurrent network from the agent's sensory stream as input. Many impressive\nreinforcement learning applications have instead relied on environment-specific\nfunctions to aid the agent's inputs for history summarization. These\naugmentations are done in multiple ways, from simple approaches like\nconcatenating observations to more complex ones such as uncertainty estimates.\nAlthough ubiquitous in the field, these additional inputs, which we term\nauxiliary inputs, are rarely emphasized, and it is not clear what their role or\nimpact is. In this work we explore this idea further, and relate these\nauxiliary inputs to prior classic approaches to state construction. We present\na series of examples illustrating the different ways of using auxiliary inputs\nfor reinforcement learning. We show that these auxiliary inputs can be used to\ndiscriminate between observations that would otherwise be aliased, leading to\nmore expressive features that smoothly interpolate between different states.\nFinally, we show that this approach is complementary to state-of-the-art\nmethods such as recurrent neural networks and truncated back-propagation\nthrough time, and acts as a heuristic that facilitates longer temporal credit\nassignment, leading to better performance.",
    "descriptor": "\nComments: 12 pages + 2 references + 12 appendix, 10 figures\n",
    "authors": [
      "Ruo Yu Tao",
      "Adam White",
      "Marlos C. Machado"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07805"
  },
  {
    "id": "arXiv:2211.07814",
    "title": "Extending the Neural Additive Model for Survival Analysis with EHR Data",
    "abstract": "With increasing interest in applying machine learning to develop healthcare\nsolutions, there is a desire to create interpretable deep learning models for\nsurvival analysis. In this paper, we extend the Neural Additive Model (NAM) by\nincorporating pairwise feature interaction networks and equip these models with\nloss functions that fit both proportional and non-proportional extensions of\nthe Cox model. We show that within this extended framework, we can construct\nnon-proportional hazard models, which we call TimeNAM, that significantly\nimprove performance over the standard NAM model architecture on benchmark\nsurvival datasets. We apply these model architectures to data from the\nElectronic Health Record (EHR) database of Seoul National University Hospital\nGangnam Center (SNUHGC) to build an interpretable neural network survival model\nfor gastric cancer prediction. We demonstrate that on both benchmark survival\nanalysis datasets, as well as on our gastric cancer dataset, our model\narchitectures yield performance that matches, or surpasses, the current\nstate-of-the-art black-box methods.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 14 pages\n",
    "authors": [
      "Matthew Peroni",
      "Marharyta Kurban",
      "Sun Young Yang",
      "Young Sun Kim",
      "Hae Yeon Kang",
      "Ji Hyun Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07814"
  },
  {
    "id": "arXiv:2211.07815",
    "title": "Cable Network Management Infrastructure Evolution",
    "abstract": "An approach to enable advanced troubleshooting, granular analysis and service\nquality of experience assessment is presented. The use of topology information\nin the identification of each cable network element along with granular\ninformation of the element configuration and health is proposed. This technique\ncovers multiple layers including the service layer. At the physical layers\nstreet addresses, taps and amplifiers are used to identify impairment location.\nAll layers are leveraged to measure network and service reliability, service\ndegradation and to quantify quality of experience. A cable infrastructure\nimplementation is described as an example.",
    "descriptor": "\nComments: 19 pages, 13 figures, SCTE CableTec Expo, 2014\n",
    "authors": [
      "L Alberto Campos",
      "Jennifer Andreoli-Fang",
      "Vivek Ganti"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.07815"
  },
  {
    "id": "arXiv:2211.07816",
    "title": "Quantifying the Impact of Label Noise on Federated Learning",
    "abstract": "Federated Learning (FL) is a distributed machine learning paradigm where\nclients collaboratively train a model using their local (human-generated)\ndatasets while preserving privacy. While existing studies focus on FL algorithm\ndevelopment to tackle data heterogeneity across clients, the important issue of\ndata quality (e.g., label noise) in FL is overlooked. This paper aims to fill\nthis gap by providing a quantitative study on the impact of label noise on FL.\nTheoretically speaking, we derive an upper bound for the generalization error\nthat is linear in the clients' label noise level. Empirically speaking, we\nconduct experiments on MNIST and CIFAR-10 datasets using various FL algorithms.\nWe show that the global model accuracy linearly decreases as the noise level\nincreases, which is consistent with our theoretical analysis. We further find\nthat label noise slows down the convergence of FL training, and the global\nmodel tends to overfit when the noise level is high.",
    "descriptor": "",
    "authors": [
      "Shuqi Ke",
      "Chao Huang",
      "Xin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.07816"
  },
  {
    "id": "arXiv:2211.07817",
    "title": "Multi-Player Bandits Robust to Adversarial Collisions",
    "abstract": "Motivated by cognitive radios, stochastic Multi-Player Multi-Armed Bandits\nhas been extensively studied in recent years. In this setting, each player\npulls an arm, and receives a reward corresponding to the arm if there is no\ncollision, namely the arm was selected by one single player. Otherwise, the\nplayer receives no reward if collision occurs. In this paper, we consider the\npresence of malicious players (or attackers) who obstruct the cooperative\nplayers (or defenders) from maximizing their rewards, by deliberately colliding\nwith them. We provide the first decentralized and robust algorithm RESYNC for\ndefenders whose performance deteriorates gracefully as $\\tilde{O}(C)$ as the\nnumber of collisions $C$ from the attackers increases. We show that this\nalgorithm is order-optimal by proving a lower bound which scales as\n$\\Omega(C)$. This algorithm is agnostic to the algorithm used by the attackers\nand agnostic to the number of collisions $C$ faced from attackers.",
    "descriptor": "",
    "authors": [
      "Shivakumar Mahesh",
      "Anshuka Rangi",
      "Haifeng Xu",
      "Long Tran-Thanh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.07817"
  },
  {
    "id": "arXiv:2211.07818",
    "title": "AgileAvatar: Stylized 3D Avatar Creation via Cascaded Domain Bridging",
    "abstract": "Stylized 3D avatars have become increasingly prominent in our modern life.\nCreating these avatars manually usually involves laborious selection and\nadjustment of continuous and discrete parameters and is time-consuming for\naverage users. Self-supervised approaches to automatically create 3D avatars\nfrom user selfies promise high quality with little annotation cost but fall\nshort in application to stylized avatars due to a large style domain gap. We\npropose a novel self-supervised learning framework to create high-quality\nstylized 3D avatars with a mix of continuous and discrete parameters. Our\ncascaded domain bridging framework first leverages a modified portrait\nstylization approach to translate input selfies into stylized avatar renderings\nas the targets for desired 3D avatars. Next, we find the best parameters of the\navatars to match the stylized avatar renderings through a differentiable\nimitator we train to mimic the avatar graphics engine. To ensure we can\neffectively optimize the discrete parameters, we adopt a cascaded\nrelaxation-and-search pipeline. We use a human preference study to evaluate how\nwell our method preserves user identity compared to previous work as well as\nmanual creation. Our results achieve much higher preference scores than\nprevious work and close to those of manual creation. We also provide an\nablation study to justify the design choices in our pipeline.",
    "descriptor": "\nComments: ACM SIGGRAPH Asia 2022 Conference Proceedings\n",
    "authors": [
      "Shen Sang",
      "Tiancheng Zhi",
      "Guoxian Song",
      "Minghao Liu",
      "Chunpong Lai",
      "Jing Liu",
      "Xiang Wen",
      "James Davis",
      "Linjie Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.07818"
  },
  {
    "id": "arXiv:2211.07819",
    "title": "General Intelligence Requires Rethinking Exploration",
    "abstract": "We are at the cusp of a transition from \"learning from data\" to \"learning\nwhat data to learn from\" as a central focus of artificial intelligence (AI)\nresearch. While the first-order learning problem is not completely solved,\nlarge models under unified architectures, such as transformers, have shifted\nthe learning bottleneck from how to effectively train our models to how to\neffectively acquire and use task-relevant data. This problem, which we frame as\nexploration, is a universal aspect of learning in open-ended domains, such as\nthe real world. Although the study of exploration in AI is largely limited to\nthe field of reinforcement learning, we argue that exploration is essential to\nall learning systems, including supervised learning. We propose the problem of\ngeneralized exploration to conceptually unify exploration-driven learning\nbetween supervised learning and reinforcement learning, allowing us to\nhighlight key similarities across learning settings and open research\nchallenges. Importantly, generalized exploration serves as a necessary\nobjective for maintaining open-ended learning processes, which in continually\nlearning to discover and solve new problems, provides a promising path to more\ngeneral intelligence.",
    "descriptor": "",
    "authors": [
      "Minqi Jiang",
      "Tim Rockt\u00e4schel",
      "Edward Grefenstette"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07819"
  },
  {
    "id": "arXiv:2211.07820",
    "title": "Clinically Plausible Pathology-Anatomy Disentanglement in Patient Brain  MRI with Structured Variational Priors",
    "abstract": "We propose a hierarchically structured variational inference model for\naccurately disentangling observable evidence of disease (e.g. brain lesions or\natrophy) from subject-specific anatomy in brain MRIs. With flexible, partially\nautoregressive priors, our model (1) addresses the subtle and fine-grained\ndependencies that typically exist between anatomical and pathological\ngenerating factors of an MRI to ensure the clinical validity of generated\nsamples; (2) preserves and disentangles finer pathological details pertaining\nto a patient's disease state. Additionally, we experiment with an alternative\ntraining configuration where we provide supervision to a subset of latent\nunits. It is shown that (1) a partially supervised latent space achieves a\nhigher degree of disentanglement between evidence of disease and\nsubject-specific anatomy; (2) when the prior is formulated with an\nautoregressive structure, knowledge from the supervision can propagate to the\nunsupervised latent units, resulting in more informative latent representations\ncapable of modelling anatomy-pathology interdependencies.",
    "descriptor": "\nComments: 11 pages (6-page extended abstract, 0.5-page acknowledgments, 2.5-page references, 2-pages appendices); 8 figures; ML4H 2022 Extended Abstract Collection\n",
    "authors": [
      "Anjun Hu",
      "Jean-Pierre R. Falet",
      "Brennan S. Nichyporuk",
      "Changjian Shui",
      "Douglas L. Arnold",
      "Sotirios A. Tsaftaris",
      "Tal Arbel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07820"
  },
  {
    "id": "arXiv:2211.07825",
    "title": "Direct Inversion: Optimization-Free Text-Driven Real Image Editing with  Diffusion Models",
    "abstract": "With the rise of large, publicly-available text-to-image diffusion models,\ntext-guided real image editing has garnered much research attention recently.\nExisting methods tend to either rely on some form of per-instance or per-task\nfine-tuning and optimization, require multiple novel views, or they inherently\nentangle preservation of real image identity, semantic coherence, and\nfaithfulness to text guidance. In this paper, we propose an optimization-free\nand zero fine-tuning framework that applies complex and non-rigid edits to a\nsingle real image via a text prompt, avoiding all the pitfalls described above.\nUsing widely-available generic pre-trained text-to-image diffusion models, we\ndemonstrate the ability to modulate pose, scene, background, style, color, and\neven racial identity in an extremely flexible manner through a single target\ntext detailing the desired edit. Furthermore, our method, which we name\n$\\textit{Direct Inversion}$, proposes multiple intuitively configurable\nhyperparameters to allow for a wide range of types and extents of real image\nedits. We prove our method's efficacy in producing high-quality, diverse,\nsemantically coherent, and faithful real image edits through applying it on a\nvariety of inputs for a multitude of tasks. We also formalize our method in\nwell-established theory, detail future experiments for further improvement, and\ncompare against state-of-the-art attempts.",
    "descriptor": "",
    "authors": [
      "Adham Elarabawy",
      "Harish Kamath",
      "Samuel Denton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07825"
  },
  {
    "id": "arXiv:2211.07828",
    "title": "Adaptation Approaches for Nearest Neighbor Language Models",
    "abstract": "Semi-parametric Nearest Neighbor Language Models ($k$NN-LMs) have produced\nimpressive gains over purely parametric LMs, by leveraging large-scale\nneighborhood retrieval over external memory datastores. However, there has been\nlittle investigation into adapting such models for new domains. This work\nattempts to fill that gap and suggests the following approaches for adapting\n$k$NN-LMs -- 1) adapting the underlying LM (using Adapters), 2) expanding\nneighborhood retrieval over an additional adaptation datastore, and 3) adapting\nthe weights (scores) of retrieved neighbors using a learned Rescorer module. We\nstudy each adaptation strategy separately, as well as the combined performance\nimprovement through ablation experiments and an extensive set of evaluations\nrun over seven adaptation domains. Our combined adaptation approach\nconsistently outperforms purely parametric adaptation and zero-shot ($k$NN-LM)\nbaselines that construct datastores from the adaptation data. On average, we\nsee perplexity improvements of 17.1\\% and 16\\% for these respective baselines,\nacross domains.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Rishabh Bhardwaj",
      "George Polovets",
      "Monica Sunkara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07828"
  },
  {
    "id": "arXiv:2211.07829",
    "title": "On Sparsification of Stochastic Packing Problems",
    "abstract": "Motivated by recent progress on stochastic matching with few queries, we\nembark on a systematic study of the sparsification of stochastic packing\nproblems (SPP) more generally. Specifically, we consider SPPs where elements\nare independently active with a probability p, and ask whether one can\n(non-adaptively) compute a sparse set of elements guaranteed to contain an\napproximately optimal solution to the realized (active) subproblem. We seek\nstructural and algorithmic results of broad applicability to such problems. Our\nfocus is on computing sparse sets containing on the order of d feasible\nsolutions to the packing problem, where d is linear or at most poly. in 1/p.\nCrucially, we require d to be independent of the any parameter related to the\n``size'' of the packing problem. We refer to d as the degree of the sparsifier,\nas is consistent with graph theoretic degree in the special case of matching.\nFirst, we exhibit a generic sparsifier of degree 1/p based on contention\nresolution. This sparsifier's approximation ratio matches the best contention\nresolution scheme (CRS) for any packing problem for additive objectives, and\napproximately matches the best monotone CRS for submodular objectives. Second,\nwe embark on outperforming this generic sparsifier for matroids, their\nintersections and weighted matching. These improved sparsifiers feature\ndifferent algorithmic and analytic approaches, and have degree linear in 1/p.\nIn the case of a single matroid, our sparsifier tends to the optimal solution.\nFor weighted matching, we combine our contention-resolution-based sparsifier\nwith technical approaches of prior work to improve the state of the art ratio\nfrom 0.501 to 0.536. Third, we examine packing problems with submodular\nobjectives. We show that even the simplest such problems do not admit\nsparsifiers approaching optimality.",
    "descriptor": "\nComments: 43 pages, 2 figures\n",
    "authors": [
      "Shaddin Dughmi",
      "Yusuf Hakan Kalayci",
      "Neel Patel"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.07829"
  },
  {
    "id": "arXiv:2211.07830",
    "title": "Prompting Language Models for Linguistic Structure",
    "abstract": "Although pretrained language models (PLMs) can be prompted to perform a wide\nrange of language tasks, it remains an open question how much this ability\ncomes from generalizable linguistic representations versus more surface-level\nlexical patterns. To test this, we present a structured prompting approach that\ncan be used to prompt for linguistic structure prediction tasks, allowing us to\nperform zero- and few-shot sequence tagging with autoregressive PLMs. We\nevaluate this approach on part-of-speech tagging, named entity recognition, and\nsentence chunking and demonstrate strong few-shot performance in all cases. We\nalso find that, though the surface forms of the tags provide some signal,\nstructured prompting can retrieve linguistic structure even with arbitrary\nlabels, indicating that PLMs contain this knowledge in a general manner robust\nto label choice.",
    "descriptor": "",
    "authors": [
      "Terra Blevins",
      "Hila Gonen",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07830"
  },
  {
    "id": "arXiv:2211.07832",
    "title": "The Ball is in Our Court: Conducting Visualization Research with Sports  Experts",
    "abstract": "Most sports visualizations rely on a combination of spatial, highly temporal,\nand user-centric data, making sports a challenging target for visualization.\nEmerging technologies, such as augmented and mixed reality (AR/XR), have\nbrought exciting opportunities along with new challenges for sports\nvisualization. We share our experience working with sports domain experts and\npresent lessons learned from conducting visualization research in SportsXR. In\nour previous work, we have targeted different types of users in sports,\nincluding athletes, game analysts, and fans. Each user group has unique design\nconstraints and requirements, such as obtaining real-time visual feedback in\ntraining, automating the low-level video analysis workflow, or personalizing\nembedded visualizations for live game data analysis. In this paper, we\nsynthesize our best practices and pitfalls we identified while working on\nSportsXR. We highlight lessons learned in working with sports domain experts in\ndesigning and evaluating sports visualizations and in working with emerging\nAR/XR technologies. We envision that sports visualization research will benefit\nthe larger visualization community through its unique challenges and\nopportunities for immersive and situated analytics.",
    "descriptor": "\nComments: To appear in IEEE Transactions on Computer Graphics and Applications (IEEE CG&A), 2022\n",
    "authors": [
      "Tica Lin",
      "Zhutian Chen",
      "Johanna Beyer",
      "Yincai Wu",
      "Hanspeter Pfister",
      "Yalong Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.07832"
  },
  {
    "id": "arXiv:2211.07837",
    "title": "An Ontology for the Social Determinants of Health Domain",
    "abstract": "Social determinants of health are societal factors, such as where a person\nwas born, grew up, works, lives, etc, along with socioeconomic and community\nfactors that affect individual health. Social Determinants of Health are\ncorrelated with many clinical outcomes, hence it is desirable to record SDOH\ndata in Electronic Health Records (EHRs). Besides storing images, text, etc.,\nEHRs rely on coded terms available in standard ontologies and terminologies to\nrecord observations and analyses. There is a substantial amount of research on\nunderstanding the clinical impact of SDOH, ranging from screening tools to\npractice based interventions. However, there is no comprehensive collection of\nterms for recording SDOH observations in EHRs. Our research goal is to develop\nan ontology that covers the terms describing SDOH. We present a prototype\nontology called Social Determinant of Health Ontology (SOHO) that covers\nrelevant concepts and IS--A relationships describing impacts and associations\nof social determinants. We describe the evaluation techniques that we applied\nto SOHO, including human experts review and algorithmic evaluation.",
    "descriptor": "\nComments: Submitted for publishing\n",
    "authors": [
      "Navya Martin Kollapally",
      "Yan Chen",
      "Julia Xu",
      "James Geller"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.07837"
  },
  {
    "id": "arXiv:2211.07842",
    "title": "Evaluating How Fine-tuning on Bimodal Data Effects Code Generation",
    "abstract": "Despite the increase in popularity of language models for code generation, it\nis still unknown how training on bimodal coding forums affects a model's code\ngeneration performance and reliability. We, therefore, collect a dataset of\nover 2.2M StackOverflow questions with answers for finetuning. These fine-tuned\nmodels have average $pass@k$ improvements of 54.64% and 85.35% on the HumanEval\n(Chen et al., 2021) and Mostly Basic Program Problems (Austin et al., 2021)\ntasks, respectively. This regime further decreases the number of generated\nprograms with both syntax and runtime errors. However, we find that at higher\ntemperatures, there are significant decreases to the model's ability to\ngenerate runnable programs despite higher $pass@k$ scores, underscoring the\nneed for better methods of incorporating such data that mitigate these side\neffects. The code can be found\nhttps://github.com/gabeorlanski/bimodalcode-generation",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Gabriel Orlanski",
      "Seonhye Yang",
      "Michael Healy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.07842"
  },
  {
    "id": "arXiv:2211.07843",
    "title": "Chinese Spelling Check with Nearest Neighbors",
    "abstract": "Chinese Spelling Check (CSC) aims to detect and correct error tokens in\nChinese contexts, which has a wide range of applications. In this paper, we\nintroduce InfoKNN-CSC, extending the standard CSC model by linearly\ninterpolating it with a k-nearest neighbors (kNN) model. Moreover, the\nphonetic, graphic, and contextual information (info) of tokens and contexts are\nelaborately incorporated into the design of the query and key of kNN, according\nto the characteristics of the task. After retrieval, in order to match the\ncandidates more accurately, we also perform reranking methods based on the\noverlap of the n-gram values and inputs. Experiments on the SIGHAN benchmarks\ndemonstrate that the proposed model achieves state-of-the-art performance with\nsubstantial improvements over existing work.",
    "descriptor": "\nComments: work in progress\n",
    "authors": [
      "Xunjian Yin",
      "Xinyu Hu",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07843"
  },
  {
    "id": "arXiv:2211.07844",
    "title": "Characterizing the Spectrum of the NTK via a Power Series Expansion",
    "abstract": "Under mild conditions on the network initialization we derive a power series\nexpansion for the Neural Tangent Kernel (NTK) of arbitrarily deep feedforward\nnetworks in the infinite width limit. We provide expressions for the\ncoefficients of this power series which depend on both the Hermite coefficients\nof the activation function as well as the depth of the network. We observe\nfaster decay of the Hermite coefficients leads to faster decay in the NTK\ncoefficients. Using this series, first we relate the effective rank of the NTK\nto the effective rank of the input-data Gram. Second, for data drawn uniformly\non the sphere we derive an explicit formula for the eigenvalues of the NTK,\nwhich shows faster decay in the NTK coefficients implies a faster decay in its\nspectrum. From this we recover existing results on eigenvalue asymptotics for\nReLU networks and comment on how the activation function influences the RKHS.\nFinally, for generic data and activation functions with sufficiently fast\nHermite coefficient decay, we derive an asymptotic upper bound on the spectrum\nof the NTK.",
    "descriptor": "\nComments: 51 pages, 3 Figures, 1 Table\n",
    "authors": [
      "Michael Murray",
      "Hui Jin",
      "Benjamin Bowman",
      "Guido Montufar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07844"
  },
  {
    "id": "arXiv:2211.07845",
    "title": "Neighborhood Convolutional Network: A New Paradigm of Graph Neural  Networks for Node Classification",
    "abstract": "The decoupled Graph Convolutional Network (GCN), a recent development of GCN\nthat decouples the neighborhood aggregation and feature transformation in each\nconvolutional layer, has shown promising performance for graph representation\nlearning. Existing decoupled GCNs first utilize a simple neural network (e.g.,\nMLP) to learn the hidden features of the nodes, then propagate the learned\nfeatures on the graph with fixed steps to aggregate the information of\nmulti-hop neighborhoods. Despite effectiveness, the aggregation operation,\nwhich requires the whole adjacency matrix as the input, is involved in the\nmodel training, causing high training cost that hinders its potential on larger\ngraphs. On the other hand, due to the independence of node attributes as the\ninput, the neural networks used in decoupled GCNs are very simple, and advanced\ntechniques cannot be applied to the modeling. To this end, we further liberate\nthe aggregation operation from the decoupled GCN and propose a new paradigm of\nGCN, termed Neighborhood Convolutional Network (NCN), that utilizes the\nneighborhood aggregation result as the input, followed by a special\nconvolutional neural network tailored for extracting expressive node\nrepresentations from the aggregation input. In this way, the model could\ninherit the merit of decoupled GCN for aggregating neighborhood information, at\nthe same time, develop much more powerful feature learning modules. A training\nstrategy called mask training is incorporated to further boost the model\nperformance. Extensive results demonstrate the effectiveness of our model for\nthe node classification task on diverse homophilic graphs and heterophilic\ngraphs.",
    "descriptor": "\nComments: 8 pages, 4 figures, 2 tables, submitted to a conference of 2023\n",
    "authors": [
      "Jinsong Chen",
      "Boyu Li",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.07845"
  },
  {
    "id": "arXiv:2211.07846",
    "title": "Category-Adaptive Label Discovery and Noise Rejection for Multi-label  Image Recognition with Partial Positive Labels",
    "abstract": "As a promising solution of reducing annotation cost, training multi-label\nmodels with partial positive labels (MLR-PPL), in which merely few positive\nlabels are known while other are missing, attracts increasing attention. Due to\nthe absence of any negative labels, previous works regard unknown labels as\nnegative and adopt traditional MLR algorithms. To reject noisy labels, recent\nworks regard large loss samples as noise but ignore the semantic correlation\ndifferent multi-label images. In this work, we propose to explore semantic\ncorrelation among different images to facilitate the MLR-PPL task.\nSpecifically, we design a unified framework, Category-Adaptive Label Discovery\nand Noise Rejection, that discovers unknown labels and rejects noisy labels for\neach category in an adaptive manner. The framework consists of two\ncomplementary modules: (1) Category-Adaptive Label Discovery module first\nmeasures the semantic similarity between positive samples and then complement\nunknown labels with high similarities; (2) Category-Adaptive Noise Rejection\nmodule first computes the sample weights based on semantic similarities from\ndifferent samples and then discards noisy labels with low weights. Besides, we\npropose a novel category-adaptive threshold updating that adaptively adjusts\nthe threshold, to avoid the time-consuming manual tuning process. Extensive\nexperiments demonstrate that our proposed method consistently outperforms\ncurrent leading algorithms.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2205.13092\n",
    "authors": [
      "Tao Pu",
      "Qianru Lao",
      "Hefeng Wu",
      "Tianshui Chen",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07846"
  },
  {
    "id": "arXiv:2211.07847",
    "title": "Learning to Correct Mistakes: Backjumping in Long-Horizon Task and  Motion Planning",
    "abstract": "As robots become increasingly capable of manipulation and long-term autonomy,\nlong-horizon task and motion planning problems are becoming increasingly\nimportant. A key challenge in such problems is that early actions in the plan\nmay make future actions infeasible. When reaching a dead-end in the search,\nmost existing planners use backtracking, which exhaustively reevaluates\nmotion-level actions, often resulting in inefficient planning, especially when\nthe search depth is large. In this paper, we propose to learn backjumping\nheuristics which identify the culprit action directly using supervised learning\nmodels to guide the task-level search. Based on evaluations on two different\ntasks, we find that our method significantly improves planning efficiency\ncompared to backtracking and also generalizes to problems with novel numbers of\nobjects.",
    "descriptor": "\nComments: 17 pages, 3 figures, Published in the Conference on Robot Learning (CoRL), 2022\n",
    "authors": [
      "Yoonchang Sung",
      "Zizhao Wang",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.07847"
  },
  {
    "id": "arXiv:2211.07849",
    "title": "Linear Convergent Distributed Nash Equilibrium Seeking with Compression",
    "abstract": "Information compression techniques are often employed to reduce communication\ncost over peer-to-peer links. In this paper, we investigate distributed Nash\nequilibrium (NE) seeking problems in a class of non-cooperative games over\nmulti-agent networks with information compression. To improve system\nscalability and communication efficiency, a compressed distributed NE seeking\n(C-DNES) algorithm is proposed to obtain a Nash equilibrium for games, where\nthe differences between decision vectors and their estimates are compressed.\nThe proposed algorithm is compatible with a general class of compression\noperators, including both unbiased and biased compressors. It is shown that\nC-DNES not only inherits the advantages of the conventional distributed NE\nalgorithms, achieving linear convergence rate for games with strongly monotone\nmappings, but also saves communication costs in terms of transmitted bits.\nFinally, numerical simulations are provided to illustrate the effectiveness of\nthe proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Xiaomeng Chen",
      "Yuchi Wu",
      "Xinlei Yi",
      "Minyi Huang",
      "Ling Shi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.07849"
  },
  {
    "id": "arXiv:2211.07852",
    "title": "Stable rank-adaptive Dynamically Orthogonal Runge-Kutta schemes",
    "abstract": "We develop two new sets of stable, rank-adaptive Dynamically Orthogonal\nRunge-Kutta (DORK) schemes that capture high-order curvature of the nonlinear\nlow-rank manifold. The DORK schemes asymptotically approximate the truncated\nsingular value decomposition at a greatly reduced cost while preserving mode\ncontinuity using newly derived retractions. We show that arbitrarily high-order\noptimal perturbative retractions can be obtained, and we prove that these new\nretractions are stable. In addition, we demonstrate that repeatedly applying\nretractions yields a gradient-descent algorithm on the low-rank manifold that\nconverges geometrically when approximating a low-rank matrix. When\napproximating a higher-rank matrix, iterations converge linearly to the best\nlow-rank approximation. We then develop a rank-adaptive retraction that is\nrobust to overapproximation. Building off of these retractions, we derive two\nnovel, rank-adaptive integration schemes that dynamically update the subspace\nupon which the system dynamics is projected within each time-step: the stable,\noptimal Dynamically Orthogonal Runge-Kutta (so-DORK) and gradient-descent\nDynamically Orthogonal Runge-Kutta (gd-DORK) schemes. These integration schemes\nare numerically evaluated and compared on an ill-conditioned matrix\ndifferential equation, an advection-diffusion partial differential equation,\nand a nonlinear, stochastic reaction-diffusion partial differential equation.\nResults show a reduced error accumulation rate with the new stable, optimal and\ngradient-descent integrators. In addition, we find that rank adaptation allows\nfor highly accurate solutions while preserving computational efficiency.",
    "descriptor": "\nComments: 26 pages, 8 figures\n",
    "authors": [
      "Aaron Charous",
      "Pierre F.J. Lermusiaux"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Dynamical Systems (math.DS)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.07852"
  },
  {
    "id": "arXiv:2211.07855",
    "title": "Relationship of the language distance to English ability of a country",
    "abstract": "Language difference is one of the factors that hinder the acquisition of\nsecond language skills. In this article, we introduce a novel solution that\nleverages the strength of deep neural networks to measure the semantic\ndissimilarity between languages based on their word distributions in the\nembedding space of the multilingual pre-trained language model (e.g.,BERT).\nThen, we empirically examine the effectiveness of the proposed semantic\nlanguage distance (SLD) in explaining the consistent variation in English\nability of countries, which is proxied by their performance in the\nInternet-Based Test of English as Foreign Language (TOEFL iBT). The\nexperimental results show that the language distance demonstrates negative\ninfluence on a country's average English ability. Interestingly, the effect is\nmore significant on speaking and writing subskills, which pertain to the\nproductive aspects of language learning. Besides, we provide specific\nrecommendations for future research directions.",
    "descriptor": "",
    "authors": [
      "Cao Xinxin",
      "Lei Xiaolan",
      "Murtadha Ahmed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.07855"
  },
  {
    "id": "arXiv:2211.07859",
    "title": "Local Magnification for Data and Feature Augmentation",
    "abstract": "In recent years, many data augmentation techniques have been proposed to\nincrease the diversity of input data and reduce the risk of overfitting on deep\nneural networks. In this work, we propose an easy-to-implement and model-free\ndata augmentation method called Local Magnification (LOMA). Different from\nother geometric data augmentation methods that perform global transformations\non images, LOMA generates additional training data by randomly magnifying a\nlocal area of the image. This local magnification results in geometric changes\nthat significantly broaden the range of augmentations while maintaining the\nrecognizability of objects. Moreover, we extend the idea of LOMA and random\ncropping to the feature space to augment the feature map, which further boosts\nthe classification accuracy considerably. Experiments show that our proposed\nLOMA, though straightforward, can be combined with standard data augmentation\nto significantly improve the performance on image classification and object\ndetection. And further combination with our feature augmentation techniques,\ntermed LOMA_IF&FO, can continue to strengthen the model and outperform advanced\nintensity transformation methods for data augmentation.",
    "descriptor": "\nComments: 10 pages, 7 figures, 7 tables, submitted to a conference of 2023\n",
    "authors": [
      "Kun He",
      "Chang Liu",
      "Stephen Lin",
      "John E. Hopcroft"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07859"
  },
  {
    "id": "arXiv:2211.07860",
    "title": "Enabling AI Quality Control via Feature Hierarchical Edge Inference",
    "abstract": "With the rise of edge computing, various AI services are expected to be\navailable at a mobile side through the inference based on deep neural network\n(DNN) operated at the network edge, called edge inference (EI). On the other\nhand, the resulting AI quality (e.g., mean average precision in objective\ndetection) has been regarded as a given factor, and AI quality control has yet\nto be explored despite its importance in addressing the diverse demands of\ndifferent users. This work aims at tackling the issue by proposing a feature\nhierarchical EI (FHEI), comprising feature network and inference network\ndeployed at an edge server and corresponding mobile, respectively.\nSpecifically, feature network is designed based on feature hierarchy, a\none-directional feature dependency with a different scale. A higher scale\nfeature requires more computation and communication loads while it provides a\nbetter AI quality. The tradeoff enables FHEI to control AI quality gradually\nw.r.t. communication and computation loads, leading to deriving a\nnear-to-optimal solution to maximize multi-user AI quality under the\nconstraints of uplink \\& downlink transmissions and edge server and mobile\ncomputation capabilities. It is verified by extensive simulations that the\nproposed joint communication-and-computation control on FHEI architecture\nalways outperforms several benchmarks by differentiating each user's AI quality\ndepending on the communication and computation conditions.",
    "descriptor": "\nComments: 7 pages, 6 figures, Conference Version\n",
    "authors": [
      "Jinhyuk Choi",
      "Seong-Lyun Kim",
      "Seung-Woo Ko"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07860"
  },
  {
    "id": "arXiv:2211.07863",
    "title": "Music Similarity Calculation of Individual Instrumental Sounds Using  Metric Learning",
    "abstract": "The criteria for measuring music similarity are important for developing a\nflexible music recommendation system. Some data-driven methods have been\nproposed to calculate music similarity from only music signals, such as metric\nlearning based on a triplet loss using tag information on each musical piece.\nHowever, the resulting music similarity metric usually captures the entire\npiece of music, i.e., the mixing of various instrumental sound sources,\nlimiting the capability of the music recommendation system, e.g., it is\ndifficult to search for a musical piece containing similar drum sounds. Towards\nthe development of a more flexible music recommendation system, we propose a\nmusic similarity calculation method that focuses on individual instrumental\nsound sources in a musical piece. By fully exploiting the potential of\ndata-driven methods for our proposed method, we employ weakly supervised metric\nlearning to individual instrumental sound source signals without using any tag\ninformation, where positive and negative samples in a triplet loss are defined\nby whether or not they are from the same musical piece. Furthermore, assuming\nthat each instrumental sound source is not always available in practice, we\nalso investigate the effects of using instrumental sound source separation to\nobtain each source in the proposed method. Experimental results have shown that\n(1) unique similarity metrics can be learned for individual instrumental sound\nsources, (2) similarity metrics learned using some instrumental sound sources\nare possible to lead to more accurate results than that learned using the\nentire musical piece, (3) the performance degraded when learning with the\nseparated instrumental sounds, and (4) similarity metrics learned by the\nproposed method well produced results that correspond to perception by human\nsenses.",
    "descriptor": "\nComments: APSIPA ASC 2022 (pp.33--38)\n",
    "authors": [
      "Yuka Hashizume",
      "Li Li",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.07863"
  },
  {
    "id": "arXiv:2211.07864",
    "title": "Cross-domain Federated Adaptive Prompt Tuning for CLIP",
    "abstract": "Federated learning (FL) allows multiple parties to collaboratively train a\nglobal model without disclosing their data. Existing research often requires\nall model parameters to participate in the training procedure. However, with\nthe advent of powerful pre-trained models, it becomes possible to achieve\nhigher performance with fewer learnable parameters in FL. In this paper, we\npropose a federated adaptive prompt tuning algorithm, FedAPT, for cross-domain\nfederated image classification scenarios with the vision-language pre-trained\nmodel, CLIP, which gives play to the strong representation ability in FL.\nCompared with direct federated prompt tuning, our core idea is to adaptively\nunlock specific domain knowledge for each test sample in order to provide them\nwith personalized prompts. To implement this idea, we design an adaptive prompt\ntuning module, which consists of a global prompt, an adaptive network, and some\nkeys. The server randomly generates a set of keys and assigns a unique key to\neach client. Then all clients cooperatively train the global adaptive network\nand global prompt with the local datasets and the frozen keys. Ultimately, the\nglobal aggregation model can assign a personalized prompt to CLIP based on the\ndomain features of each test sample. We perform extensive experiments on two\nmulti-domain image classification datasets. The results show that FedAPT can\nachieve better performance with less than 10\\% of the number of parameters of\nthe fully trained model, and the global model can perform well in different\nclient domains simultaneously.",
    "descriptor": "",
    "authors": [
      "Shangchao Su",
      "Mingzhao Yang",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07864"
  },
  {
    "id": "arXiv:2211.07867",
    "title": "Machine Learning Methods Applied to Cortico-Cortical Evoked Potentials  Aid in Localizing Seizure Onset Zones",
    "abstract": "Epilepsy affects millions of people, reducing quality of life and increasing\nrisk of premature death. One-third of epilepsy cases are drug-resistant and\nrequire surgery for treatment, which necessitates localizing the seizure onset\nzone (SOZ) in the brain. Attempts have been made to use cortico-cortical evoked\npotentials (CCEPs) to improve SOZ localization but none have been successful\nenough for clinical adoption. Here, we compare the performance of ten machine\nlearning classifiers in localizing SOZ from CCEP data. This preliminary study\nvalidates a novel application of machine learning, and the results establish\nour approach as a promising line of research that warrants further\ninvestigation. This work also serves to facilitate discussion and collaboration\nwith fellow machine learning and/or epilepsy researchers.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 6 pages\n",
    "authors": [
      "Ian G. Malone",
      "Kaleb E. Smith",
      "Morgan E. Urdaneta",
      "Tyler S. Davis",
      "Daria Nesterovich Anderson",
      "Brian J. Phillip",
      "John D. Rolston",
      "Christopher R. Butson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.07867"
  },
  {
    "id": "arXiv:2211.07872",
    "title": "A Graph-Based Customizable Handover Framework for LEO Satellite Networks",
    "abstract": "Future satellite networks are expected to have thousands of low Earth orbit\n(LEO) satellites orbiting Earth at very high speeds. User equipment (UE)\ncommunicating directly with LEO satellites will experience frequent handovers.\nManaging the handover process is complicated due to the high frequency of\nhandovers and the availability of multiple LEO satellites as handover targets.\nIn addition, as the status of the communication link between a UE and an LEO\nsatellite varies in accordance with the visibility period of the satellite,\ninitiating handovers at the right time will significantly affect the quality of\nservice (QoS) of the communication provided. To address this problem, this work\nproposes a graph-based customizable handover framework that considers both the\nhandover timing and target while selecting a handover sequence that maintains\nQoS. A time-based graph is designed where the vertices represent the\nsatellites' instances over a certain period of time and the edges' weights are\nthe customizable handover criteria (i.e., data rate and delay in this work).\nThe appropriate sequence and timing of handovers that fulfill the required QoS\nare obtained by finding the shortest path in the graph. Discussion and\nsimulations, which were conducted on the Starlink Phase I constellation, show\nthe low complexity and performance advantages of the proposed handover\nframework.",
    "descriptor": "\nComments: 6 pages, 8 figures, 2022 IEEE Globecom Workshops (GC Wkshps): Workshop on Cellular UAV and Satellite Communications - Cellular UAV and Satellite Communications\n",
    "authors": [
      "Mohamed Hozayen",
      "Tasneem Darwish",
      "Gunes Karabulut",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.07872"
  },
  {
    "id": "arXiv:2211.07875",
    "title": "zk-PoT: Zero-Knowledge Proof of Traffic for Privacy Enabled Cooperative  Perception",
    "abstract": "Cooperative perception is an essential and widely discussed application of\nconnected automated vehicles. However, the authenticity of perception data is\nnot ensured, because the vehicles cannot independently verify the event they\ndid not see. Many methods, including trust-based (i.e., statistical) approaches\nand plausibility-based methods, have been proposed to determine data\nauthenticity. However, these methods cannot verify data without a priori\nknowledge. In this study, a novel approach of constructing a self-proving data\nfrom the number plate of target vehicles was proposed. By regarding the\npseudonym and number plate as a shared secret and letting multiple vehicles\nprove they know it independently, the data authenticity problem can be\ntransformed to a cryptography problem that can be solved without trust or\nplausibility evaluations. Our work can be adapted to the existing works\nincluding ETSI/ISO ITS standards while maintaining backward compatibility.\nAnalyses of common attacks and attacks specific to the proposed method reveal\nthat most attacks can be prevented, whereas preventing some other attacks, such\nas collusion attacks, can be mitigated. Experiments based on realistic data set\nshow that the rate of successful verification can achieve 70\\% to 80\\% at rush\nhours.",
    "descriptor": "\nComments: IEEE Consumer Communications & Networking Conference (CCNC) 2023\n",
    "authors": [
      "Ye Tao",
      "Yuze Jiang",
      "Pengfei Lin",
      "Manabu Tsukada",
      "Hiroshi Esaki"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.07875"
  },
  {
    "id": "arXiv:2211.07876",
    "title": "Brain Tumor Sequence Registration with Non-iterative Coarse-to-fine  Networks and Dual Deep Supervision",
    "abstract": "In this study, we focus on brain tumor sequence registration between\npre-operative and follow-up Magnetic Resonance Imaging (MRI) scans of brain\nglioma patients, in the context of Brain Tumor Sequence Registration challenge\n(BraTS-Reg 2022). Brain tumor registration is a fundamental requirement in\nbrain image analysis for quantifying tumor changes. This is a challenging task\ndue to large deformations and missing correspondences between pre-operative and\nfollow-up scans. For this task, we adopt our recently proposed Non-Iterative\nCoarse-to-finE registration Networks (NICE-Net) - a deep learning-based method\nfor coarse-to-fine registering images with large deformations. To overcome\nmissing correspondences, we extend the NICE-Net by introducing dual deep\nsupervision, where a deep self-supervised loss based on image similarity and a\ndeep weakly-supervised loss based on manually annotated landmarks are deeply\nembedded into the NICE-Net. At the BraTS-Reg 2022, our method achieved a\ncompetitive result on the validation set (mean absolute error: 3.387) and\nplaced 4th in the final testing phase (Score: 0.3544).",
    "descriptor": "\nComments: Brain Tumor Sequence Registration challenge (BraTS-Reg 2022)\n",
    "authors": [
      "Mingyuan Meng",
      "Lei Bi",
      "Dagan Feng",
      "Jinman Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07876"
  },
  {
    "id": "arXiv:2211.07882",
    "title": "Explainable Action Advising for Multi-Agent Reinforcement Learning",
    "abstract": "Action advising is a knowledge transfer technique for reinforcement learning\nbased on the teacher-student paradigm. An expert teacher provides advice to a\nstudent during training in order to improve the student's sample efficiency and\npolicy performance. Such advice is commonly given in the form of state-action\npairs. However, it makes it difficult for the student to reason with and apply\nto novel states. We introduce Explainable Action Advising, in which the teacher\nprovides action advice as well as associated explanations indicating why the\naction was chosen. This allows the student to self-reflect on what it has\nlearned, enabling advice generalization and leading to improved sample\nefficiency and learning performance - even in environments where the teacher is\nsub-optimal. We empirically show that our framework is effective in both\nsingle-agent and multi-agent scenarios, yielding improved policy returns and\nconvergence rates when compared to state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yue Guo",
      "Joseph Campbell",
      "Simon Stepputtis",
      "Ruiyu Li",
      "Dana Hughes",
      "Fei Fang",
      "Katia Sycara"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.07882"
  },
  {
    "id": "arXiv:2211.07885",
    "title": "Using Human Perception to Regularize Transfer Learning",
    "abstract": "Recent trends in the machine learning community show that models with\nfidelity toward human perceptual measurements perform strongly on vision tasks.\nLikewise, human behavioral measurements have been used to regularize model\nperformance. But can we transfer latent knowledge gained from this across\ndifferent learning objectives? In this work, we introduce PERCEP-TL (Perceptual\nTransfer Learning), a methodology for improving transfer learning with the\nregularization power of psychophysical labels in models. We demonstrate which\nmodels are affected the most by perceptual transfer learning and find that\nmodels with high behavioral fidelity -- including vision transformers --\nimprove the most from this regularization by as much as 1.9\\% Top@1 accuracy\npoints. These findings suggest that biologically inspired learning agents can\nbenefit from human behavioral measurements as regularizers and psychophysical\nlearned representations can be transferred to independent evaluation tasks.",
    "descriptor": "\nComments: 8 pages, 5 figures, student paper\n",
    "authors": [
      "Justin Dulay",
      "Walter J. Scheirer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07885"
  },
  {
    "id": "arXiv:2211.07886",
    "title": "A Survey for Efficient Open Domain Question Answering",
    "abstract": "Open domain question answering (ODQA) is a longstanding task aimed at\nanswering factual questions from a large knowledge corpus without any explicit\nevidence in natural language processing (NLP). Recent works have predominantly\nfocused on improving the answering accuracy and achieved promising progress.\nHowever, higher accuracy often comes with more memory consumption and inference\nlatency, which might not necessarily be efficient enough for direct deployment\nin the real world. Thus, a trade-off between accuracy, memory consumption and\nprocessing speed is pursued. In this paper, we provide a survey of recent\nadvances in the efficiency of ODQA models. We walk through the ODQA models and\nconclude the core techniques on efficiency. Quantitative analysis on memory\ncost, processing speed, accuracy and overall comparison are given. We hope that\nthis work would keep interested scholars informed of the advances and open\nchallenges in ODQA efficiency research, and thus contribute to the further\ndevelopment of ODQA efficiency.",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Qin Zhang",
      "Shangsi Chen",
      "Dongkuan Xu",
      "Qingqing Cao",
      "Xiaojun Chen",
      "Trevor Cohn",
      "Meng Fang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07886"
  },
  {
    "id": "arXiv:2211.07889",
    "title": "Pretraining ECG Data with Adversarial Masking Improves Model  Generalizability for Data-Scarce Tasks",
    "abstract": "Medical datasets often face the problem of data scarcity, as ground truth\nlabels must be generated by medical professionals. One mitigation strategy is\nto pretrain deep learning models on large, unlabelled datasets with\nself-supervised learning (SSL). Data augmentations are essential for improving\nthe generalizability of SSL-trained models, but they are typically handcrafted\nand tuned manually. We use an adversarial model to generate masks as\naugmentations for 12-lead electrocardiogram (ECG) data, where masks learn to\nocclude diagnostically-relevant regions of the ECGs. Compared to random\naugmentations, adversarial masking reaches better accuracy when transferring to\nto two diverse downstream objectives: arrhythmia classification and gender\nclassification. Compared to a state-of-art ECG augmentation method 3KG,\nadversarial masking performs better in data-scarce regimes, demonstrating the\ngeneralizability of our model.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 9 pages\n",
    "authors": [
      "Jessica Y. Bo",
      "Hen-Wei Huang",
      "Alvin Chan",
      "Giovanni Traverso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.07889"
  },
  {
    "id": "arXiv:2211.07891",
    "title": "Feedback Chain Network For Hippocampus Segmentation",
    "abstract": "The hippocampus plays a vital role in the diagnosis and treatment of many\nneurological disorders. Recent years, deep learning technology has made great\nprogress in the field of medical image segmentation, and the performance of\nrelated tasks has been constantly refreshed. In this paper, we focus on the\nhippocampus segmentation task and propose a novel hierarchical feedback chain\nnetwork. The feedback chain structure unit learns deeper and wider feature\nrepresentation of each encoder layer through the hierarchical feature\naggregation feedback chains, and achieves feature selection and feedback\nthrough the feature handover attention module. Then, we embed a global pyramid\nattention unit between the feature encoder and the decoder to further modify\nthe encoder features, including the pair-wise pyramid attention module for\nachieving adjacent attention interaction and the global context modeling module\nfor capturing the long-range knowledge. The proposed approach achieves\nstate-of-the-art performance on three publicly available datasets, compared\nwith existing hippocampus segmentation approaches.",
    "descriptor": "\nComments: Accepted by ACM TOMM 2022\n",
    "authors": [
      "Heyu Huang",
      "Runmin Cong",
      "Lianhe Yang",
      "Ling Du",
      "Cong Wang",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07891"
  },
  {
    "id": "arXiv:2211.07893",
    "title": "Federated Learning for Healthcare Domain -- Pipeline, Applications and  Challenges",
    "abstract": "Federated learning is the process of developing machine learning models over\ndatasets distributed across data centers such as hospitals, clinical research\nlabs, and mobile devices while preventing data leakage. This survey examines\nprevious research and studies on federated learning in the healthcare sector\nacross a range of use cases and applications. Our survey shows what challenges,\nmethods, and applications a practitioner should be aware of in the topic of\nfederated learning. This paper aims to lay out existing research and list the\npossibilities of federated learning for healthcare industries.",
    "descriptor": "\nComments: ACM Transactions on Computing for Healthcare, Vol. 3, No. 4, Article 40. Publication date: October 2022\n",
    "authors": [
      "Madhura Joshi",
      "Ankit Pal",
      "Malaikannan Sankarasubbu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.07893"
  },
  {
    "id": "arXiv:2211.07896",
    "title": "A Probabilistic Proof of the nCPA to CCA Bound",
    "abstract": "We provide a new proof of Maurer, Renard, and Pietzak's bound of the CCA\nadvantage of $P^{-1} \\circ Q$ by the nCPA advantages of $P$ and $Q$. Our proof\nuses probability directly, as opposed to information theory, and has the\nadvantage of providing an alternate sufficient condition of low CCA advantage.\nNamely, the CCA advantage of a random permutation can be bounded by its\nseparation distance from the uniform distribution. We use this alternate\ncondition to improve the best known bound on the security of the Swap or Not\nshuffle in the special case of having fewer queries than the square root of the\nnumber of cards.",
    "descriptor": "",
    "authors": [
      "Ben Morris",
      "Hans Oberschelp"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.07896"
  },
  {
    "id": "arXiv:2211.07898",
    "title": "Learning-Augmented Model-Based Planning for Visual Exploration",
    "abstract": "We consider the problem of time-limited robotic exploration in previously\nunseen environments where exploration is limited by a predefined amount of\ntime. We propose a novel exploration approach using learning-augmented\nmodel-based planning. We generate a set of subgoals associated with frontiers\non the current map and derive a Bellman Equation for exploration with these\nsubgoals. Visual sensing and advances in semantic mapping of indoor scenes are\nexploited for training a deep convolutional neural network to estimate\nproperties associated with each frontier: the expected unobserved area beyond\nthe frontier and the expected timesteps (discretized actions) required to\nexplore it. The proposed model-based planner is guaranteed to explore the whole\nscene if time permits. We thoroughly evaluate our approach on a large-scale\npseudo-realistic indoor dataset (Matterport3D) with the Habitat simulator. We\ncompare our approach with classical and more recent RL-based exploration\nmethods, demonstrating its clear advantages in several settings.",
    "descriptor": "",
    "authors": [
      "Yimeng Li",
      "Arnab Debnath",
      "Gregory Stein",
      "Jana Kosecka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07898"
  },
  {
    "id": "arXiv:2211.07900",
    "title": "Parameterized Inapproximability of the Minimum Distance Problem over all  Fields and the Shortest Vector Problem in all $\\ell_p$ Norms",
    "abstract": "We prove that the Minimum Distance Problem (MDP) on linear codes over any\nfixed finite field and parameterized by the input distance bound is W[1]-hard\nto approximate within any constant factor. We also prove analogous results for\nthe parameterized Shortest Vector Problem (SVP) on integer lattices.\nSpecifically, we prove that SVP in the $\\ell_p$ norm is W[1]-hard to\napproximate within any constant factor for any fixed $p >1$ and W[1]-hard to\napproximate within a factor approaching $2$ for $p=1$. (We show hardness under\nrandomized reductions in each case.)\nThese results answer the main questions left open (and explicitly posed) by\nBhattacharyya, Bonnet, Egri, Ghoshal, Karthik C. S., Lin, Manurangsi, and Marx\n(Journal of the ACM, 2021) on the complexity of parameterized MDP and SVP. For\nMDP, they established similar hardness for binary linear codes and left the\ncase of general fields open. For SVP in $\\ell_p$ norms with $p > 1$, they\nshowed inapproximability within some constant factor (depending on $p$) and\nleft open showing such hardness for arbitrary constant factors. They also left\nopen showing W[1]-hardness even of exact SVP in the $\\ell_1$ norm.",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Huck Bennett",
      "Mahdi Cheraghchi",
      "Venkatesan Guruswami",
      "Jo\u00e3o Ribeiro"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.07900"
  },
  {
    "id": "arXiv:2211.07902",
    "title": "Byzantine Spectral Ranking",
    "abstract": "We study the problem of rank aggregation where the goal is to obtain a global\nranking by aggregating pair-wise comparisons of voters over a set of items. We\nconsider an adversarial setting where the voters are partitioned into two sets.\nThe first set votes in a stochastic manner according to the popular score-based\nBradley-Terry-Luce (BTL) model for pairwise comparisons. The second set\ncomprises malicious Byzantine voters trying to deteriorate the ranking. We\nconsider a strongly-adversarial scenario where the Byzantine voters know the\nBTL scores, the votes of the good voters, the algorithm, and can collude with\neach other. We first show that the popular spectral ranking based\nRank-Centrality algorithm, though optimal for the BTL model, does not perform\nwell even when a small constant fraction of the voters are Byzantine. We\nintroduce the Byzantine Spectral Ranking Algorithm (and a faster variant of\nit), which produces a reliable ranking when the number of good voters exceeds\nthe number of Byzantine voters. We show that no algorithm can produce a\nsatisfactory ranking with probability > 1/2 for all BTL weights when there are\nmore Byzantine voters than good voters, showing that our algorithm works for\nall possible population fractions. We support our theoretical results with\nexperimental results on synthetic and real datasets to demonstrate the failure\nof the Rank-Centrality algorithm under several adversarial scenarios and how\nthe proposed Byzantine Spectral Ranking algorithm is robust in obtaining good\nrankings.",
    "descriptor": "\nComments: 24 pages, accepted at NeurIPS 22\n",
    "authors": [
      "Arnhav Datar",
      "Arun Rajkumar",
      "John Augustine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07902"
  },
  {
    "id": "arXiv:2211.07906",
    "title": "Hierarchical Phrase-based Sequence-to-Sequence Learning",
    "abstract": "We describe a neural transducer that maintains the flexibility of standard\nsequence-to-sequence (seq2seq) models while incorporating hierarchical phrases\nas a source of inductive bias during training and as explicit constraints\nduring inference. Our approach trains two models: a discriminative parser based\non a bracketing transduction grammar whose derivation tree hierarchically\naligns source and target phrases, and a neural seq2seq model that learns to\ntranslate the aligned phrases one-by-one. We use the same seq2seq model to\ntranslate at all phrase scales, which results in two inference modes: one mode\nin which the parser is discarded and only the seq2seq component is used at the\nsequence-level, and another in which the parser is combined with the seq2seq\nmodel. Decoding in the latter mode is done with the cube-pruned CKY algorithm,\nwhich is more involved but can make use of new translation rules during\ninference. We formalize our model as a source-conditioned synchronous grammar\nand develop an efficient variational inference algorithm for training. When\napplied on top of both randomly initialized and pretrained seq2seq models, we\nfind that both inference modes performs well compared to baselines on small\nscale machine translation benchmarks.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Bailin Wang",
      "Ivan Titov",
      "Jacob Andreas",
      "Yoon Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07906"
  },
  {
    "id": "arXiv:2211.07909",
    "title": "Selective Memory Recursive Least Squares: Uniformly Allocated  Approximation Capabilities of RBF Neural Networks in Real-Time Learning",
    "abstract": "When performing real-time learning tasks, the radial basis function neural\nnetwork (RBFNN) is expected to make full use of the training samples such that\nits learning accuracy and generalization capability are guaranteed. Since the\napproximation capability of the RBFNN is finite, training methods with\nforgetting mechanisms such as the forgetting factor recursive least squares\n(FFRLS) and stochastic gradient descent (SGD) methods are widely used to\nmaintain the learning ability of the RBFNN to new knowledge. However, with the\nforgetting mechanisms, some useful knowledge will get lost simply because they\nare learned a long time ago, which we refer to as the passive knowledge\nforgetting phenomenon. To address this problem, this paper proposes a real-time\ntraining method named selective memory recursive least squares (SMRLS) in which\nthe feature space of the RBFNN is evenly discretized into a finite number of\npartitions and a synthesized objective function is developed to replace the\noriginal objective function of the ordinary recursive least squares (RLS)\nmethod. SMRLS is featured with a memorization mechanism that synthesizes the\nsamples within each partition in real-time into representative samples\nuniformly distributed over the feature space, and thus overcomes the passive\nknowledge forgetting phenomenon and improves the generalization capability of\nthe learned knowledge. Compared with the SGD or FFRLS methods, SMRLS achieves\nimproved learning performance (learning speed, accuracy and generalization\ncapability), which is demonstrated by corresponding simulation results.",
    "descriptor": "\nComments: 18 pages, 13 figures\n",
    "authors": [
      "Yiming Fei",
      "Jiangang Li",
      "Yanan Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.07909"
  },
  {
    "id": "arXiv:2211.07911",
    "title": "Operation-level Concurrent Transaction Execution for Blockchains",
    "abstract": "Despite the success in various scenarios, blockchain systems, especially\nEVM-compatible ones that serially execute transactions, still face the\nsignificant challenge of limited throughput. Concurrent transaction execution\nis a promising technique to accelerate transaction processing and increase the\noverall throughput. Existing concurrency control algorithms, however, fail to\nobtain enough speedups in real-world blockchains due to the high-contention\nworkloads.\nIn this paper, we propose a novel operation-level concurrency control\nalgorithm designed for blockchains. The core idea behind our algorithm is that\nonly operations depending on conflicts should be executed serially, while all\nother conflict-free operations can be executed concurrently. Therefore, in\ncontrast to the traditional approaches, which block or abort the entire\ntransaction when encountering conflicts, our algorithm introduces a redo phase\nto resolve conflicts at the operation level by re-executing conflicting\noperations only. We also develop a set of data dependency tracking mechanisms\nto achieve precise identification and speedy re-execution for conflicting\noperations. We implement an open-source prototype based on Go Ethereum and\nevaluate it using real-world Ethereum blocks. The evaluation results show that\nour algorithm achieves an average speedup of 4.28$\\times$. If combined with\nstate prefetching techniques, our approach can further accelerate the\ntransaction execution by 7.11$\\times$.",
    "descriptor": "",
    "authors": [
      "Haoran Lin",
      "Yajin Zhou",
      "Lei Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.07911"
  },
  {
    "id": "arXiv:2211.07912",
    "title": "YORO -- Lightweight End to End Visual Grounding",
    "abstract": "We present YORO - a multi-modal transformer encoder-only architecture for the\nVisual Grounding (VG) task. This task involves localizing, in an image, an\nobject referred via natural language. Unlike the recent trend in the literature\nof using multi-stage approaches that sacrifice speed for accuracy, YORO seeks a\nbetter trade-off between speed an accuracy by embracing a single-stage design,\nwithout CNN backbone. YORO consumes natural language queries, image patches,\nand learnable detection tokens and predicts coordinates of the referred object,\nusing a single transformer encoder. To assist the alignment between text and\nvisual objects, a novel patch-text alignment loss is proposed. Extensive\nexperiments are conducted on 5 different datasets with ablations on\narchitecture design choices. YORO is shown to support real-time inference and\noutperform all approaches in this class (single-stage methods) by large\nmargins. It is also the fastest VG model and achieves the best speed/accuracy\ntrade-off in the literature.",
    "descriptor": "\nComments: Accepted to ECCVW on International Challenge on Compositional and Multimodal Perception\n",
    "authors": [
      "Chih-Hui Ho",
      "Srikar Appalaraju",
      "Bhavan Jasani",
      "R. Manmatha",
      "Nuno Vasconcelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07912"
  },
  {
    "id": "arXiv:2211.07915",
    "title": "Backdoor Attacks on Time Series: A Generative Approach",
    "abstract": "Backdoor attacks have emerged as one of the major security threats to deep\nlearning models as they can easily control the model's test-time predictions by\npre-injecting a backdoor trigger into the model at training time. While\nbackdoor attacks have been extensively studied on images, few works have\ninvestigated the threat of backdoor attacks on time series data. To fill this\ngap, in this paper we present a novel generative approach for time series\nbackdoor attacks against deep learning based time series classifiers. Backdoor\nattacks have two main goals: high stealthiness and high attack success rate. We\nfind that, compared to images, it can be more challenging to achieve the two\ngoals on time series. This is because time series have fewer input dimensions\nand lower degrees of freedom, making it hard to achieve a high attack success\nrate without compromising stealthiness. Our generative approach addresses this\nchallenge by generating trigger patterns that are as realistic as real-time\nseries patterns while achieving a high attack success rate without causing a\nsignificant drop in clean accuracy. We also show that our proposed attack is\nresistant to potential backdoor defenses. Furthermore, we propose a novel\nuniversal generator that can poison any type of time series with a single\ngenerator that allows universal attacks without the need to fine-tune the\ngenerative model for new time series datasets.",
    "descriptor": "",
    "authors": [
      "Yujing Jiang",
      "Xingjun Ma",
      "Sarah Monazam Erfani",
      "James Bailey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.07915"
  },
  {
    "id": "arXiv:2211.07916",
    "title": "A Dataset and Model for Crossing Indian Roads",
    "abstract": "Roads in medium-sized Indian towns often have lots of traffic but no (or\ndisregarded) traffic stops. This makes it hard for the blind to cross roads\nsafely, because vision is crucial to determine when crossing is safe. Automatic\nand reliable image-based safety classifiers thus have the potential to help the\nblind to cross Indian roads. Yet, we currently lack datasets collected on\nIndian roads from the pedestrian point-of-view, labelled with road crossing\nsafety information. Existing classifiers from other countries are often\nintended for crossroads, and hence rely on the detection and presence of\ntraffic lights, which is not applicable in Indian conditions. We introduce\nINDRA (INdian Dataset for RoAd crossing), the first dataset capturing videos of\nIndian roads from the pedestrian point-of-view. INDRA contains 104 videos\ncomprising of 26k 1080p frames, each annotated with a binary road crossing\nsafety label and vehicle bounding boxes. We train various classifiers to\npredict road crossing safety on this data, ranging from SVMs to convolutional\nneural networks (CNNs). The best performing model DilatedRoadCrossNet is a\nnovel single-image architecture tailored for deployment on the Nvidia Jetson\nNano. It achieves 79% recall at 90% precision on unseen images. Lastly, we\npresent a wearable road crossing assistant running DilatedRoadCrossNet, which\ncan help the blind cross Indian roads in real-time. The project webpage is\nthis http URL",
    "descriptor": "\nComments: Accepted at ICVGIP 2022\n",
    "authors": [
      "Siddhi Brahmbhatt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07916"
  },
  {
    "id": "arXiv:2211.07919",
    "title": "A Unified Mutual Supervision Framework for Referring Expression  Segmentation and Generation",
    "abstract": "Reference Expression Segmentation (RES) and Reference Expression Generation\n(REG) are mutually inverse tasks that can be naturally jointly trained. Though\nrecent work has explored such joint training, the mechanism of how RES and REG\ncan benefit each other is still unclear. In this paper, we propose a unified\nmutual supervision framework that enables two tasks to improve each other. Our\nmutual supervision contains two directions. On the one hand, Disambiguation\nSupervision leverages the expression unambiguity measurement provided by RES to\nenhance the language generation of REG. On the other hand, Generation\nSupervision uses expressions automatically generated by REG to scale up the\ntraining of RES. Such unified mutual supervision effectively improves two tasks\nby solving their bottleneck problems. Extensive experiments show that our\napproach significantly outperforms all existing methods on REG and RES tasks\nunder the same setting, and detailed ablation studies demonstrate the\neffectiveness of all components in our framework.",
    "descriptor": "",
    "authors": [
      "Shijia Huang",
      "Feng Li",
      "Hao Zhang",
      "Shilong Liu",
      "Lei Zhang",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07919"
  },
  {
    "id": "arXiv:2211.07923",
    "title": "A Theory for Discrete-time Boolean Finite Dynamical Systems with  Uncertainty",
    "abstract": "Dynamical Systems is a field that studies the collective behavior of objects\nthat update their states according to some rules. Discrete-time Boolean Finite\nDynamical System (DT-BFDS) is a subfield where the systems have some finite\nnumber of objects whose states are Boolean values, and the state updates occur\nin discrete time. In the subfield of DT-BFDS, researchers aim to (i) design\nmodels for capturing real-world phenomena and using the models to make\npredictions and (ii) develop simulation techniques for acquiring insights about\nthe systems' behavior. Useful for both aims is understanding the system\ndynamics mathematically before executing the systems. Obtaining a mathematical\nunderstanding of BFDS is quite challenging, even for simple systems, because\nthe state space of a system grows exponentially in the number of objects.\nResearchers have used computational complexity to circumvent the challenge. The\ncomplexity theoretic research in DT-BFDS has successfully produced complete\ncharacterizations for many dynamical problems.\nThe DT-BFDS studies have mainly dealt with deterministic models, where the\nupdate at each time step is deterministic, so the system dynamics are\ncompletely determinable from the initial setting. However, natural systems have\nuncertainty. Models having uncertainty may lead to far-better understandings of\nnature. Although a few attempts have explored DT-BFDS with uncertainty,\nincluding stochastic initialization and tie-breaking, they have scratched only\na tiny surface of models with uncertainty. The introduction of uncertainty can\nbe through two schemes. One is the introduction of alternate update functions.\nThe other is the introduction of alternate update schedules. 37This paper\nestablishes a theory of models with uncertainty and proves some fundamental\nresults.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Mitsunori Ogihara",
      "Kei Uchizawa"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.07923"
  },
  {
    "id": "arXiv:2211.07928",
    "title": "False: False Negative Samples Aware Contrastive Learning for Semantic  Segmentation of High-Resolution Remote Sensing Image",
    "abstract": "The existing SSCL of RSI is built based on constructing positive and negative\nsample pairs. However, due to the richness of RSI ground objects and the\ncomplexity of the RSI contextual semantics, the same RSI patches have the\ncoexistence and imbalance of positive and negative samples, which causing the\nSSCL pushing negative samples far away while pushing positive samples far away,\nand vice versa. We call this the sample confounding issue (SCI). To solve this\nproblem, we propose a False negAtive sampLes aware contraStive lEarning model\n(FALSE) for the semantic segmentation of high-resolution RSIs. Since the SSCL\npretraining is unsupervised, the lack of definable criteria for false negative\nsample (FNS) leads to theoretical undecidability, we designed two steps to\nimplement the FNS approximation determination: coarse determination of FNS and\nprecise calibration of FNS. We achieve coarse determination of FNS by the FNS\nself-determination (FNSD) strategy and achieve calibration of FNS by the FNS\nconfidence calibration (FNCC) loss function. Experimental results on three RSI\nsemantic segmentation datasets demonstrated that the FALSE effectively improves\nthe accuracy of the downstream RSI semantic segmentation task compared with the\ncurrent three models, which represent three different types of SSCL models. The\nmean Intersection-over-Union on ISPRS Potsdam dataset is improved by 0.7\\% on\naverage; on CVPR DGLC dataset is improved by 12.28\\% on average; and on\nXiangtan dataset this is improved by 1.17\\% on average. This indicates that the\nSSCL model has the ability to self-differentiate FNS and that the FALSE\neffectively mitigates the SCI in self-supervised contrastive learning. The\nsource code is available at https://github.com/GeoX-Lab/FALSE.",
    "descriptor": "\nComments: 5 Pages, 3 Figures, 5 tables\n",
    "authors": [
      "Zhaoyang Zhang",
      "Xuying Wang",
      "Xiaoming Mei",
      "Chao Tao",
      "Haifeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07928"
  },
  {
    "id": "arXiv:2211.07931",
    "title": "Personalized Federated Learning with Multi-branch Architecture",
    "abstract": "Federated learning (FL) is a decentralized machine learning technique that\nenables multiple clients to collaboratively train models without revealing the\nraw data to each other. Although the traditional FL trains a single global\nmodel with average performance among clients, the statistical data\nheterogeneity across clients motivates personalized FL (PFL) which learns\npersonalized models with good performance on each client's data. A key\nchallenge in PFL is how to promote clients with similar data to collaborate\nmore in a situation where each client has data from complex distribution and\ndoes not know each other's distribution. In this paper, we propose a new PFL\nmethod, personalized federated learning with multi-branch architecture\n(pFedMB), which achieves personalization by splitting each layer of neural\nnetworks into multiple branches and assigning client-specific weights to each\nbranch. pFedMB is simple but effective to facilitate each client to share the\nknowledge with similar clients by adjusting the weights assigned to each\nbranch. We experimentally show that pFedMB performs better than the\nstate-of-the-art PFL methods using CIFAR10 dataset.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Junki Mori",
      "Tomoyuki Yoshiyama",
      "Furukawa Ryo",
      "Isamu Teranishi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07931"
  },
  {
    "id": "arXiv:2211.07932",
    "title": "Using Open-Ended Stressor Responses to Predict Depressive Symptoms  across Demographics",
    "abstract": "Stressors are related to depression, but this relationship is complex. We\ninvestigate the relationship between open-ended text responses about stressors\nand depressive symptoms across gender and racial/ethnic groups. First, we use\ntopic models and other NLP tools to find thematic and vocabulary differences\nwhen reporting stressors across demographic groups. We train language models\nusing self-reported stressors to predict depressive symptoms, finding a\nrelationship between stressors and depression. Finally, we find that\ndifferences in stressors translate to downstream performance differences across\ndemographic groups.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 6 pages\n",
    "authors": [
      "Carlos Aguirre",
      "Mark Dredze",
      "Philip Resnik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07932"
  },
  {
    "id": "arXiv:2211.07937",
    "title": "An Improved Analysis of (Variance-Reduced) Policy Gradient and Natural  Policy Gradient Methods",
    "abstract": "In this paper, we revisit and improve the convergence of policy gradient\n(PG), natural PG (NPG) methods, and their variance-reduced variants, under\ngeneral smooth policy parametrizations. More specifically, with the Fisher\ninformation matrix of the policy being positive definite: i) we show that a\nstate-of-the-art variance-reduced PG method, which has only been shown to\nconverge to stationary points, converges to the globally optimal value up to\nsome inherent function approximation error due to policy parametrization; ii)\nwe show that NPG enjoys a lower sample complexity; iii) we propose SRVR-NPG,\nwhich incorporates variance-reduction into the NPG update. Our improvements\nfollow from an observation that the convergence of (variance-reduced) PG and\nNPG methods can improve each other: the stationary convergence analysis of PG\ncan be applied to NPG as well, and the global convergence analysis of NPG can\nhelp to establish the global convergence of (variance-reduced) PG methods. Our\nanalysis carefully integrates the advantages of these two lines of works.\nThanks to this improvement, we have also made variance-reduction for NPG\npossible, with both global convergence and an efficient finite-sample\ncomplexity.",
    "descriptor": "",
    "authors": [
      "Yanli Liu",
      "Kaiqing Zhang",
      "Tamer Ba\u015far",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07937"
  },
  {
    "id": "arXiv:2211.07940",
    "title": "A Metaheuristic Approach for Mining Gradual Patterns",
    "abstract": "Swarm intelligence is a discipline that studies the collective behavior that\nis produced by local interactions of a group of individuals with each other and\nwith their environment. In Computer Science domain, numerous swarm intelligence\ntechniques are applied to optimization problems that seek to efficiently find\nbest solutions within a search space. Gradual pattern mining is another\nComputer Science field that could benefit from the efficiency of swarm based\noptimization techniques in the task of finding gradual patterns from a huge\nsearch space. A gradual pattern is a rule-based correlation that describes the\ngradual relationship among the attributes of a data set. For example, given\nattributes {G,H} of a data set a gradual pattern may take the form: \"the less\nG, the more H\". In this paper, we propose a numeric encoding for gradual\npattern candidates that we use to define an effective search space. In\naddition, we present a systematic study of several meta-heuristic optimization\ntechniques as efficient solutions to the problem of finding gradual patterns\nusing our search space.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Dickson Odhiambo Owuor",
      "Thomas Runkler",
      "Anne Laurent"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.07940"
  },
  {
    "id": "arXiv:2211.07941",
    "title": "Automatic Evaluation of Excavator Operators using Learned Reward  Functions",
    "abstract": "Training novice users to operate an excavator for learning different skills\nrequires the presence of expert teachers. Considering the complexity of the\nproblem, it is comparatively expensive to find skilled experts as the process\nis time-consuming and requires precise focus. Moreover, since humans tend to be\nbiased, the evaluation process is noisy and will lead to high variance in the\nfinal score of different operators with similar skills. In this work, we\naddress these issues and propose a novel strategy for the automatic evaluation\nof excavator operators. We take into account the internal dynamics of the\nexcavator and the safety criterion at every time step to evaluate the\nperformance. To further validate our approach, we use this score prediction\nmodel as a source of reward for a reinforcement learning agent to learn the\ntask of maneuvering an excavator in a simulated environment that closely\nreplicates the real-world dynamics. For a policy learned using these external\nreward prediction models, our results demonstrate safer solutions following the\nrequired dynamic constraints when compared to policy trained with task-based\nreward functions only, making it one step closer to real-life adoption. For\nfuture research, we release our codebase at\nhttps://github.com/pranavAL/InvRL_Auto-Evaluate and video results\nhttps://drive.google.com/file/d/1jR1otOAu8zrY8mkhUOUZW9jkBOAKK71Z/view?usp=share_link .",
    "descriptor": "\nComments: 11 pages, 5 figures, Accepted at Reinforcement Learning for Real Life (RL4RealLife) Workshop at NeurIPS 2022\n",
    "authors": [
      "Pranav Agarwal",
      "Marek Teichmann",
      "Sheldon Andrews",
      "Samira Ebrahimi Kahou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07941"
  },
  {
    "id": "arXiv:2211.07945",
    "title": "Geometric Impedance Control on SE(3) for Robotic Manipulators",
    "abstract": "After its introduction, impedance control has been utilized as a primary\ncontrol scheme for robotic manipulation tasks that involve interaction with\nunknown environments. While impedance control has been extensively studied, the\ngeometric structure of SE(3) for the robotic manipulator itself and its use in\nformulating a robotic task has not been adequately addressed. In this paper, we\npropose a differential geometric approach to impedance control. Given a\nleft-invariant error metric in SE(3), the corresponding error vectors in\nposition and velocity are first derived. Using these geometrically consistent\nerror vectors, we propose a novel impedance control scheme, which adequately\naccounts for the geometric structure of the manipulator in SE(3). The\nclosed-loop stability for the proposed control schemes is verified using a\nLyapunov function-based analysis. The proposed control design clearly\noutperformed a conventional impedance control approach when tracking\nchallenging trajectory profiles.",
    "descriptor": "",
    "authors": [
      "Joohwan Seo",
      "Nikhil Potu Surya Prakash",
      "Alexander Rose",
      "Roberto Horowitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.07945"
  },
  {
    "id": "arXiv:2211.07947",
    "title": "Robust Quantum Circuit for Clique Problem with Intermediate Qudits",
    "abstract": "Clique problem has a wide range of applications due to its pattern matching\nability. There are various formulation of clique problem like $k$-clique\nproblem, maximum clique problem, etc. The $k$-Clique problem, determines\nwhether an arbitrary network has a clique or not whereas maximum clique problem\nfinds the largest clique in a graph. It is already exhibited in the literature\nthat the $k$-clique or maximum clique problem (NP-problem) can be solved in an\nasymptotically faster manner by using quantum algorithms as compared to the\nconventional computing. Quantum computing with higher dimensions is gaining\npopularity due to its large storage capacity and computation power. In this\narticle, we have shown an improved quantum circuit implementation for the\n$k$-clique problem and maximum clique problem (MCP) with the help of\nhigher-dimensional intermediate temporary qudits for the first time to the best\nof our knowledge. The cost of state-of-the-art quantum circuit for $k$-clique\nproblem is colossal due to a huge number of $n$-qubit Toffoli gates. We have\nexhibited an improved cost and depth over the circuit by applying a generalized\n$n$-qubit Toffoli gate decomposition with intermediate ququarts (4-dimensional\nqudits).",
    "descriptor": "\nComments: 19 pages, 22 figures\n",
    "authors": [
      "Arpita Sanyal",
      "Amit Saha",
      "Banani Saha",
      "Amlan Chakrabarti"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.07947"
  },
  {
    "id": "arXiv:2211.07950",
    "title": "Breakpoint Transformers for Modeling and Tracking Intermediate Beliefs",
    "abstract": "Can we teach natural language understanding models to track their beliefs\nthrough intermediate points in text? We propose a representation learning\nframework called breakpoint modeling that allows for learning of this type.\nGiven any text encoder and data marked with intermediate states (breakpoints)\nalong with corresponding textual queries viewed as true/false propositions\n(i.e., the candidate beliefs of a model, consisting of information changing\nthrough time) our approach trains models in an efficient and end-to-end fashion\nto build intermediate representations that facilitate teaching and direct\nquerying of beliefs at arbitrary points alongside solving other end tasks. To\nshow the benefit of our approach, we experiment with a diverse set of NLU tasks\nincluding relational reasoning on CLUTRR and narrative understanding on bAbI.\nUsing novel belief prediction tasks for both tasks, we show the benefit of our\nmain breakpoint transformer, based on T5, over conventional representation\nlearning approaches in terms of processing efficiency, prediction accuracy and\nprediction consistency, all with minimal to no effect on corresponding QA end\ntasks. To show the feasibility of incorporating our belief tracker into more\ncomplex reasoning pipelines, we also obtain SOTA performance on the\nthree-tiered reasoning challenge for the TRIP benchmark (around 23-32% absolute\nimprovement on Tasks 2-3).",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Kyle Richardson",
      "Ronen Tamari",
      "Oren Sultan",
      "Reut Tsarfaty",
      "Dafna Shahaf",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07950"
  },
  {
    "id": "arXiv:2211.07951",
    "title": "Show Me the Instruments: Musical Instrument Retrieval from Mixture Audio",
    "abstract": "As digital music production has become mainstream, the selection of\nappropriate virtual instruments plays a crucial role in determining the quality\nof music. To search the musical instrument samples or virtual instruments that\nmake one's desired sound, music producers use their ears to listen and compare\neach instrument sample in their collection, which is time-consuming and\ninefficient. In this paper, we call this task as Musical Instrument Retrieval\nand propose a method for retrieving desired musical instruments using reference\nmusic mixture as a query. The proposed model consists of the Single-Instrument\nEncoder and the Multi-Instrument Encoder, both based on convolutional neural\nnetworks. The Single-Instrument Encoder is trained to classify the instruments\nused in single-track audio, and we take its penultimate layer's activation as\nthe instrument embedding. The Multi-Instrument Encoder is trained to estimate\nmultiple instrument embeddings using the instrument embeddings computed by the\nSingle-Instrument Encoder as a set of target embeddings. For more generalized\ntraining and realistic evaluation, we also propose a new dataset called Nlakh.\nExperimental results showed that the Single-Instrument Encoder was able to\nlearn the mapping from the audio signal of unseen instruments to the instrument\nembedding space and the Multi-Instrument Encoder was able to extract multiple\nembeddings from the mixture of music and retrieve the desired instruments\nsuccessfully. The code used for the experiment and audio samples are available\nat: https://github.com/minju0821/musical_instrument_retrieval",
    "descriptor": "\nComments: 5 pages, 4 figures, submitted to ICASSP 2023\n",
    "authors": [
      "Kyungsu Kim",
      "Minju Park",
      "Haesun Joung",
      "Yunkee Chae",
      "Yeongbeom Hong",
      "Seonghyeon Go",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.07951"
  },
  {
    "id": "arXiv:2211.07953",
    "title": "A virtual element method on polyhedral meshes for the sixth-order  elliptic problem",
    "abstract": "In this work we analyze a virtual element method on polyhedral meshes for\nsolving the sixth-order elliptic problem with simply supported boundary\nconditions. We apply the Ciarlet-Raviart arguments to introduce an auxiliary\nunknown $\\sigma:=-\\Delta^2 u$ and to search the main uknown $u$ in the $H^2\\cap\nH_0^1$ Sobolev space. The virtual element discretization is well possed on a\n$C^1\\times C^0$ virtual element spaces. We also provide the convergence and\nerror estimates results. Finally, we report a series of numerical tests to\nverify the performance of numerical scheme.",
    "descriptor": "\nComments: 20 pages 5 figures\n",
    "authors": [
      "Franco Dassi",
      "David Mora",
      "Carlos Reales",
      "Iv\u00e0n Vel\u00e0squez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.07953"
  },
  {
    "id": "arXiv:2211.07954",
    "title": "An Overview on Controllable Text Generation via Variational  Auto-Encoders",
    "abstract": "Recent advances in neural-based generative modeling have reignited the hopes\nof having computer systems capable of conversing with humans and able to\nunderstand natural language. The employment of deep neural architectures has\nbeen largely explored in a multitude of context and tasks to fulfill various\nuser needs. On one hand, producing textual content that meets specific\nrequirements is of priority for a model to seamlessly conduct conversations\nwith different groups of people. On the other hand, latent variable models\n(LVM) such as variational auto-encoders (VAEs) as one of the most popular\ngenres of generative models are designed to characterize the distributional\npattern of textual data. Thus they are inherently capable of learning the\nintegral textual features that are worth exploring for controllable pursuits.\n\\noindent This overview gives an introduction to existing generation schemes,\nproblems associated with text variational auto-encoders, and a review of\nseveral applications about the controllable generation that are instantiations\nof these general formulations,\\footnote{A detailed paper list is available at\n\\url{https://github.com/ImKeTT/CTG-latentAEs}} as well as related datasets,\nmetrics and discussions for future researches. Hopefully, this overview will\nprovide an overview of living questions, popular methodologies and raw thoughts\nfor controllable language generation under the scope of variational\nauto-encoder.",
    "descriptor": "",
    "authors": [
      "Haoqin Tu",
      "Yitong Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07954"
  },
  {
    "id": "arXiv:2211.07955",
    "title": "IntegratedPIFu: Integrated Pixel Aligned Implicit Function for  Single-view Human Reconstruction",
    "abstract": "We propose IntegratedPIFu, a new pixel aligned implicit model that builds on\nthe foundation set by PIFuHD. IntegratedPIFu shows how depth and human parsing\ninformation can be predicted and capitalised upon in a pixel-aligned implicit\nmodel. In addition, IntegratedPIFu introduces depth oriented sampling, a novel\ntraining scheme that improve any pixel aligned implicit model ability to\nreconstruct important human features without noisy artefacts. Lastly,\nIntegratedPIFu presents a new architecture that, despite using less model\nparameters than PIFuHD, is able to improves the structural correctness of\nreconstructed meshes. Our results show that IntegratedPIFu significantly\noutperforms existing state of the arts methods on single view human\nreconstruction. Our code has been made available online.",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Kennard Yanting Chan",
      "Guosheng Lin",
      "Haiyu Zhao",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07955"
  },
  {
    "id": "arXiv:2211.07956",
    "title": "HGV4Risk: Hierarchical Global View-guided Sequence Representation  Learning for Risk Prediction",
    "abstract": "Risk prediction, as a typical time series modeling problem, is usually\nachieved by learning trends in markers or historical behavior from sequence\ndata, and has been widely applied in healthcare and finance. In recent years,\ndeep learning models, especially Long Short-Term Memory neural networks\n(LSTMs), have led to superior performances in such sequence representation\nlearning tasks. Despite that some attention or self-attention based models with\ntime-aware or feature-aware enhanced strategies have achieved better\nperformance compared with other temporal modeling methods, such improvement is\nlimited due to a lack of guidance from global view. To address this issue, we\npropose a novel end-to-end Hierarchical Global View-guided (HGV) sequence\nrepresentation learning framework. Specifically, the Global Graph Embedding\n(GGE) module is proposed to learn sequential clip-aware representations from\ntemporal correlation graph at instance level. Furthermore, following the way of\nkey-query attention, the harmonic $\\beta$-attention ($\\beta$-Attn) is also\ndeveloped for making a global trade-off between time-aware decay and\nobservation significance at channel level adaptively. Moreover, the\nhierarchical representations at both instance level and channel level can be\ncoordinated by the heterogeneous information aggregation under the guidance of\nglobal view. Experimental results on a benchmark dataset for healthcare risk\nprediction, and a real-world industrial scenario for Small and Mid-size\nEnterprises (SMEs) credit overdue risk prediction in MYBank, Ant Group, have\nillustrated that the proposed model can achieve competitive prediction\nperformance compared with other known baselines.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Youru Li",
      "Zhenfeng Zhu",
      "Xiaobo Guo",
      "Shaoshuai Li",
      "Yuchen Yang",
      "Yao Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2211.07956"
  },
  {
    "id": "arXiv:2211.07959",
    "title": "The Lean Data Scientist: Recent Advances towards Overcoming the Data  Bottleneck",
    "abstract": "Machine learning (ML) is revolutionizing the world, affecting almost every\nfield of science and industry. Recent algorithms (in particular, deep networks)\nare increasingly data-hungry, requiring large datasets for training. Thus, the\ndominant paradigm in ML today involves constructing large, task-specific\ndatasets.\nHowever, obtaining quality datasets of such magnitude proves to be a\ndifficult challenge. A variety of methods have been proposed to address this\ndata bottleneck problem, but they are scattered across different areas, and it\nis hard for a practitioner to keep up with the latest developments. In this\nwork, we propose a taxonomy of these methods. Our goal is twofold: (1) We wish\nto raise the community's awareness of the methods that already exist and\nencourage more efficient use of resources, and (2) we hope that such a taxonomy\nwill contribute to our understanding of the problem, inspiring novel ideas and\nstrategies to replace current annotation-heavy approaches.",
    "descriptor": "",
    "authors": [
      "Chen Shani",
      "Jonathan Zarecki",
      "Dafna Shahaf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07959"
  },
  {
    "id": "arXiv:2211.07964",
    "title": "A Simple and Efficient Lagrange Multiplier Based Mixed Finite Element  for Gradient Damage",
    "abstract": "A novel finite element formulation for gradient-regularized damage models is\npresented which allows for the robust, efficient, and mesh-independent\nsimulation of damage phenomena in engineering and biological materials. The\npaper presents a Lagrange multiplier based mixed finite element formulation for\nfinite strains. Thereby, no numerical stabilization or penalty parameters are\nrequired. On the other hand, no additional degrees of freedom appear for the\nLagrange multiplier which is achieved through a suitable FE-interpolation\nscheme allowing for static condensation. In contrast to competitive approaches\nfrom the literature with similar efficiency, the proposed formulation does not\nrequire cross-element information and thus, a straightforward implementation\nusing standard element routine interfaces is enabled. Numerical tests show\nmesh-independent solutions, robustness of the solution procedure for states of\nsevere damage and under cyclic loading conditions. It is demonstrated that the\ncomputing time of the gradient damage calculations exceeds the one of purely\nelastic computations only by an insignificant amount. Furthermore, an improved\nconvergence behavior compared to alternative approaches is shown.",
    "descriptor": "",
    "authors": [
      "Johannes Riesselmann",
      "Daniel Balzani"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.07964"
  },
  {
    "id": "arXiv:2211.07967",
    "title": "Coordination for Connected and Automated Vehicles at Non-signalized  Intersections: A Value Decomposition-based Multiagent Deep Reinforcement  Learning Approach",
    "abstract": "The recent proliferation of the research on multi-agent deep reinforcement\nlearning (MDRL) offers an encouraging way to coordinate multiple connected and\nautomated vehicles (CAVs) to pass the intersection. In this paper, we apply a\nvalue decomposition-based MDRL approach (QMIX) to control various CAVs in\nmixed-autonomy traffic of different densities to efficiently and safely pass\nthe non-signalized intersection with fairish fuel consumption. Implementation\ntricks including network-level improvements, Q value update by TD ($\\lambda$),\nand reward clipping operation are added to the pure QMIX framework, which is\nexpected to improve the convergence speed and the asymptotic performance of the\noriginal version. The efficacy of our approach is demonstrated by several\nevaluation metrics: average speed, the number of collisions, and average fuel\nconsumption per episode. The experimental results show that our approach's\nconvergence speed and asymptotic performance can exceed that of the original\nQMIX and the proximal policy optimization (PPO), a state-of-the-art\nreinforcement learning baseline applied to the non-signalized intersection.\nMoreover, CAVs under the lower traffic flow controlled by our method can\nimprove their average speed without collisions and consume the least fuel. The\ntraining is additionally conducted under the doubled traffic density, where the\nlearning reward converges. Consequently, the model with maximal reward and\nminimum crashes can still guarantee low fuel consumption, but slightly reduce\nthe efficiency of vehicles and induce more collisions than the lower-traffic\ncounterpart, implying the difficulty of generalizing RL policy to more advanced\nscenarios.",
    "descriptor": "",
    "authors": [
      "Zihan Guo",
      "Yan Wu",
      "Lifang Wang",
      "Junzhi Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.07967"
  },
  {
    "id": "arXiv:2211.07968",
    "title": "NeRFFaceEditing: Disentangled Face Editing in Neural Radiance Fields",
    "abstract": "Recent methods for synthesizing 3D-aware face images have achieved rapid\ndevelopment thanks to neural radiance fields, allowing for high quality and\nfast inference speed. However, existing solutions for editing facial geometry\nand appearance independently usually require retraining and are not optimized\nfor the recent work of generation, thus tending to lag behind the generation\nprocess. To address these issues, we introduce NeRFFaceEditing, which enables\nediting and decoupling geometry and appearance in the pretrained\ntri-plane-based neural radiance field while retaining its high quality and fast\ninference speed. Our key idea for disentanglement is to use the statistics of\nthe tri-plane to represent the high-level appearance of its corresponding\nfacial volume. Moreover, we leverage a generated 3D-continuous semantic mask as\nan intermediary for geometry editing. We devise a geometry decoder (whose\noutput is unchanged when the appearance changes) and an appearance decoder. The\ngeometry decoder aligns the original facial volume with the semantic mask\nvolume. We also enhance the disentanglement by explicitly regularizing rendered\nimages with the same appearance but different geometry to be similar in terms\nof color distribution for each facial component separately. Our method allows\nusers to edit via semantic masks with decoupled control of geometry and\nappearance. Both qualitative and quantitative evaluations show the superior\ngeometry and appearance control abilities of our method compared to existing\nand alternative solutions.",
    "descriptor": "",
    "authors": [
      "Kaiwen Jiang",
      "Shu-Yu Chen",
      "Feng-Lin Liu",
      "Hongbo Fu",
      "Lin Gao"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07968"
  },
  {
    "id": "arXiv:2211.07969",
    "title": "Foveated Rendering: a State-of-the-Art Survey",
    "abstract": "Recently, virtual reality (VR) technology has been widely used in medical,\nmilitary, manufacturing, entertainment, and other fields.\nThese applications must simulate different complex material surfaces, various\ndynamic objects, and complex physical phenomena, increasing the complexity of\nVR scenes. Current computing devices cannot efficiently render these complex\nscenes in real time, and delayed rendering makes the content observed by the\nuser inconsistent with the user's interaction, causing discomfort.\nFoveated rendering is a promising technique that can accelerate rendering. It\ntakes advantage of human eyes' inherent features and renders different regions\nwith different qualities without sacrificing perceived visual quality.\nFoveated rendering research has a history of 31 years and is mainly focused\non solving the following three problems.\nThe first is to apply perceptual models of the human visual system into\nfoveated rendering. The second is to render the image with different qualities\naccording to foveation principles. The third is to integrate foveated rendering\ninto existing rendering paradigms to improve rendering performance.\nIn this survey, we review foveated rendering research from 1990 to 2021.\nWe first revisit the visual perceptual models related to foveated rendering.\nSubsequently, we propose a new foveated rendering taxonomy and then classify\nand review the research on this basis. Finally, we discuss potential\nopportunities and open questions in the foveated rendering field.\nWe anticipate that this survey will provide new researchers with a high-level\noverview of the state of the art in this field, furnish experts with up-to-date\ninformation and offer ideas alongside a framework to VR display software and\nhardware designers and engineers.",
    "descriptor": "",
    "authors": [
      "Lili Wang",
      "Xuehuai Shi",
      "Yi Liu"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.07969"
  },
  {
    "id": "arXiv:2211.07970",
    "title": "Adaptive Multi-Neighborhood Attention based Transformer for Graph  Representation Learning",
    "abstract": "By incorporating the graph structural information into Transformers, graph\nTransformers have exhibited promising performance for graph representation\nlearning in recent years. Existing graph Transformers leverage specific\nstrategies, such as Laplacian eigenvectors and shortest paths of the node\npairs, to preserve the structural features of nodes and feed them into the\nvanilla Transformer to learn the representations of nodes. It is hard for such\npredefined rules to extract informative graph structural features for arbitrary\ngraphs whose topology structure varies greatly, limiting the learning capacity\nof the models. To this end, we propose an adaptive graph Transformer, termed\nMulti-Neighborhood Attention based Graph Transformer (MNA-GT), which captures\nthe graph structural information for each node from the multi-neighborhood\nattention mechanism adaptively. By defining the input to perform scaled-dot\nproduct as an attention kernel, MNA-GT constructs multiple attention kernels\nbased on different hops of neighborhoods such that each attention kernel can\ncapture specific graph structural information of the corresponding neighborhood\nfor each node pair. In this way, MNA-GT can preserve the graph structural\ninformation efficiently by incorporating node representations learned by\ndifferent attention kernels. MNA-GT further employs an attention layer to learn\nthe importance of different attention kernels to enable the model to adaptively\ncapture the graph structural information for different nodes. Extensive\nexperiments are conducted on a variety of graph benchmarks, and the empirical\nresults show that MNA-GT outperforms many strong baselines.",
    "descriptor": "\nComments: 8 pages, 4 figures, 5 tables, submitted to a conference of 2023\n",
    "authors": [
      "Gaichao Li",
      "Jinsong Chen",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.07970"
  },
  {
    "id": "arXiv:2211.07971",
    "title": "A review of discourse and conversation impairments in patients with  dementia",
    "abstract": "Neurodegeneration characterizes patients with different dementia subtypes\n(e.g., patients with Alzheimer's Disease, Primary Progressive Aphasia, and\nParkinson's Disease), leading to progressive decline in cognitive, linguistic,\nand social functioning. Speech and language impairments are early symptoms in\npatients with focal forms of neurodegenerative conditions, coupled with\ndeficits in cognitive, social, and behavioral domains. This paper reviews the\nfindings on language and communication deficits and identifies the effects of\ndementia on the production and perception of discourse. It discusses findings\nconcerning (i) language function, cognitive representation, and impairment ,\n(ii) communicative competence, emotions, empathy, and theory-of-mind, and (iii)\nspeech-in-interaction. It argues that clinical discourse analysis can provide a\ncomprehensive assessment of language and communication skills in patients,\nwhich complements the existing neurolinguistic evaluation for (differential)\ndiagnosis, prognosis, and treatment efficacy evaluation.",
    "descriptor": "",
    "authors": [
      "Charalambos Themistocleous"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07971"
  },
  {
    "id": "arXiv:2211.07977",
    "title": "Deep Instance Segmentation and Visual Servoing to Play Jenga with a  Cost-Effective Robotic System",
    "abstract": "The game of Jenga represents an inspiring benchmark for developing innovative\nmanipulation solutions for complex tasks. Indeed, it encouraged the study of\nnovel robotics methods to extract blocks from the tower successfully. A Jenga\ngame round undoubtedly embeds many traits of complex industrial or surgical\nmanipulation tasks, requiring a multi-step strategy, the combination of visual\nand tactile data, and the highly precise motion of the robotic arm to perform a\nsingle block extraction. In this work, we propose a novel cost-effective\narchitecture for playing Jenga with e.Do, a 6-DOF anthropomorphic manipulator\nmanufactured by Comau, a standard depth camera, and an inexpensive\nmonodirectional force sensor. Our solution focuses on a visual-based control\nstrategy to accurately align the end-effector with the desired block, enabling\nblock extraction by pushing. To this aim, we train an instance segmentation\ndeep learning model on a synthetic custom dataset to segment each piece of the\nJenga tower, allowing visual tracking of the desired block's pose during the\nmotion of the manipulator. We integrate the visual-based strategy with a 1D\nforce sensor to detect whether the block can be safely removed by identifying a\nforce threshold value. Our experimentation shows that our low-cost solution\nallows e.DO to precisely reach removable blocks and perform up to 14\nconsecutive extractions in a row.",
    "descriptor": "",
    "authors": [
      "Luca Marchionna",
      "Giulio Pugliese",
      "Mauro Martini",
      "Simone Angarano",
      "Francesco Salvetti",
      "Marcello Chiaberge"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.07977"
  },
  {
    "id": "arXiv:2211.07978",
    "title": "Shellability is hard even for balls",
    "abstract": "The main goal of this paper is to show that shellability is NP-hard for\ntriangulated d-balls (this also gives hardness for triangulated\nd-manifolds/d-pseudomanifolds with boundary) as soon as d is at least 3. This\nextends our earlier work with Goaoc, Pat\\'akov\\'a and Wagner on hardness of\nshellability of 2-complexes and answers some questions implicitly raised by\nDanaraj and Klee in 1978 and explicitly mentioned by Santamar\\'ia-Galvis and\nWoodroofe. Together with the main goal, we also prove that collapsibility is\nNP-hard for 3-complexes embeddable in the 3-space, extending an earlier work of\nthe second author and answering an open question mentioned by Cohen, Fasy,\nMiller, Nayyeri, Peng and Walkington; and that shellability is NP-hard for\n2-complexes embeddable in the 3-space, answering another question of\nSantamar\\'ia-Galvis and Woodroofe (in a slightly stronger form than what is\ngiven by the main result).",
    "descriptor": "\nComments: 66 pages, 51 figures (The figures take nontrivial portion of the space thus in reality the paper is a bit shorter.)\n",
    "authors": [
      "Pavel Pat\u00e1k",
      "Martin Tancer"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.07978"
  },
  {
    "id": "arXiv:2211.07980",
    "title": "A Benchmark and Dataset for Post-OCR text correction in Sanskrit",
    "abstract": "Sanskrit is a classical language with about 30 million extant manuscripts fit\nfor digitisation, available in written, printed or scannedimage forms. However,\nit is still considered to be a low-resource language when it comes to available\ndigital resources. In this work, we release a post-OCR text correction dataset\ncontaining around 218,000 sentences, with 1.5 million words, from 30 different\nbooks. Texts in Sanskrit are known to be diverse in terms of their linguistic\nand stylistic usage since Sanskrit was the 'lingua franca' for discourse in the\nIndian subcontinent for about 3 millennia. Keeping this in mind, we release a\nmulti-domain dataset, from areas as diverse as astronomy, medicine and\nmathematics, with some of them as old as 18 centuries. Further, we release\nmultiple strong baselines as benchmarks for the task, based on pre-trained\nSeq2Seq language models. We find that our best-performing model, consisting of\nbyte level tokenization in conjunction with phonetic encoding (Byt5+SLP1),\nyields a 23% point increase over the OCR output in terms of word and character\nerror rates. Moreover, we perform extensive experiments in evaluating these\nmodels on their performance and analyse common causes of mispredictions both at\nthe graphemic and lexical levels. Our code and dataset is publicly available at\nhttps://github.com/ayushbits/pe-ocr-sanskrit.",
    "descriptor": "\nComments: Findings of EMNLP, 2022. Code and Data: this https URL\n",
    "authors": [
      "Ayush Maheshwari",
      "Nikhil Singh",
      "Amrith Krishna",
      "Ganesh Ramakrishnan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07980"
  },
  {
    "id": "arXiv:2211.07982",
    "title": "Evaluating the Faithfulness of Saliency-based Explanations for Deep  Learning Models for Temporal Colour Constancy",
    "abstract": "The opacity of deep learning models constrains their debugging and\nimprovement. Augmenting deep models with saliency-based strategies, such as\nattention, has been claimed to help get a better understanding of the\ndecision-making process of black-box models. However, some recent works\nchallenged saliency's faithfulness in the field of Natural Language Processing\n(NLP), questioning attention weights' adherence to the true decision-making\nprocess of the model. We add to this discussion by evaluating the faithfulness\nof in-model saliency applied to a video processing task for the first time,\nnamely, temporal colour constancy. We perform the evaluation by adapting to our\ntarget task two tests for faithfulness from recent NLP literature, whose\nmethodology we refine as part of our contributions. We show that attention\nfails to achieve faithfulness, while confidence, a particular type of in-model\nvisual saliency, succeeds.",
    "descriptor": "",
    "authors": [
      "Matteo Rizzo",
      "Cristina Conati",
      "Daesik Jang",
      "Hui Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07982"
  },
  {
    "id": "arXiv:2211.07997",
    "title": "Security Closure of IC Layouts Against Hardware Trojans",
    "abstract": "Due to cost benefits, supply chains of integrated circuits (ICs) are largely\noutsourced nowadays. However, passing ICs through various third-party providers\ngives rise to many threats, like piracy of IC intellectual property or\ninsertion of hardware Trojans, i.e., malicious circuit modifications.\nIn this work, we proactively and systematically harden the physical layouts\nof ICs against post-design insertion of Trojans. Toward that end, we propose a\nmultiplexer-based logic-locking scheme that is (i) devised for layout-level\nTrojan prevention, (ii) resilient against state-of-the-art, oracle-less machine\nlearning attacks, and (iii) fully integrated into a tailored, yet generic,\ncommercial-grade design flow. Our work provides in-depth security and layout\nanalysis on a challenging benchmark suite. We show that ours can render layouts\nresilient, with reasonable overheads, against Trojan insertion in general and\nalso against second-order attacks (i.e., adversaries seeking to bypass the\nlocking defense in an oracle-less setting).\nWe release our layout artifacts for independent verification [29] and we will\nrelease our methodology's source code.",
    "descriptor": "\nComments: To appear in ISPD'23\n",
    "authors": [
      "Fangzhou Wang",
      "Qijing Wang",
      "Bangqi Fu",
      "Shui Jiang",
      "Xiaopeng Zhang",
      "Lilas Alrahis",
      "Ozgur Sinanoglu",
      "Johann Knechtel",
      "Tsung-Yi Ho",
      "Evangeline F. Y. Young"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07997"
  },
  {
    "id": "arXiv:2211.08005",
    "title": "Cross-Reality Re-Rendering: Manipulating between Digital and Physical  Realities",
    "abstract": "The advent of personalized reality has arrived. Rapid development in AR/MR/VR\nenables users to augment or diminish their perception of the physical world.\nRobust tooling for digital interface modification enables users to change how\ntheir software operates. As digital realities become an increasingly-impactful\naspect of human lives, we investigate the design of a system that enables users\nto manipulate the perception of both their physical realities and digital\nrealities. Users can inspect their view history from either reality, and\ngenerate interventions that can be interoperably rendered cross-reality in\nreal-time. Personalized interventions can be generated with mask, text, and\nmodel hooks. Collaboration between users scales the availability of\ninterventions. We verify our implementation against our design requirements\nwith cognitive walkthroughs, personas, and scalability tests.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2204.03731\n",
    "authors": [
      "Siddhartha Datta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.08005"
  },
  {
    "id": "arXiv:2211.08007",
    "title": "Uncertainty-aware Gait Recognition via Learning from Dirichlet  Distribution-based Evidence",
    "abstract": "Existing gait recognition frameworks retrieve an identity in the gallery\nbased on the distance between a probe sample and the identities in the gallery.\nHowever, existing methods often neglect that the gallery may not contain\nidentities corresponding to the probes, leading to recognition errors rather\nthan raising an alarm. In this paper, we introduce a novel uncertainty-aware\ngait recognition method that models the uncertainty of identification based on\nlearned evidence. Specifically, we treat our recognition model as an evidence\ncollector to gather evidence from input samples and parameterize a Dirichlet\ndistribution over the evidence. The Dirichlet distribution essentially\nrepresents the density of the probability assigned to the input samples. We\nutilize the distribution to evaluate the resultant uncertainty of each probe\nsample and then determine whether a probe has a counterpart in the gallery or\nnot. To the best of our knowledge, our method is the first attempt to tackle\ngait recognition with uncertainty modelling. Moreover, our uncertain modeling\nsignificantly improves the robustness against out-of-distribution (OOD)\nqueries. Extensive experiments demonstrate that our method achieves\nstate-of-the-art performance on datasets with OOD queries, and can also\ngeneralize well to other identity-retrieval tasks. Importantly, our method\noutperforms the state-of-the-art by a large margin of 44.19% when the OOD query\nrate is around 50% on OUMVLP.",
    "descriptor": "",
    "authors": [
      "Beibei Lin",
      "Chen Liu",
      "Lincheng Li",
      "Robby T. Tan",
      "Xin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08007"
  },
  {
    "id": "arXiv:2211.08008",
    "title": "MORA: Improving Ensemble Robustness Evaluation with Model-Reweighing  Attack",
    "abstract": "Adversarial attacks can deceive neural networks by adding tiny perturbations\nto their input data. Ensemble defenses, which are trained to minimize attack\ntransferability among sub-models, offer a promising research direction to\nimprove robustness against such attacks while maintaining a high accuracy on\nnatural inputs. We discover, however, that recent state-of-the-art (SOTA)\nadversarial attack strategies cannot reliably evaluate ensemble defenses,\nsizeably overestimating their robustness. This paper identifies the two factors\nthat contribute to this behavior. First, these defenses form ensembles that are\nnotably difficult for existing gradient-based method to attack, due to gradient\nobfuscation. Second, ensemble defenses diversify sub-model gradients,\npresenting a challenge to defeat all sub-models simultaneously, simply summing\ntheir contributions may counteract the overall attack objective; yet, we\nobserve that ensemble may still be fooled despite most sub-models being\ncorrect. We therefore introduce MORA, a model-reweighing attack to steer\nadversarial example synthesis by reweighing the importance of sub-model\ngradients. MORA finds that recent ensemble defenses all exhibit varying degrees\nof overestimated robustness. Comparing it against recent SOTA white-box\nattacks, it can converge orders of magnitude faster while achieving higher\nattack success rates across all ensemble models examined with three different\nensemble modes (i.e., ensembling by either softmax, voting or logits). In\nparticular, most ensemble defenses exhibit near or exactly 0% robustness\nagainst MORA with $\\ell^\\infty$ perturbation within 0.02 on CIFAR-10, and 0.01\non CIFAR-100. We make MORA open source with reproducible results and\npre-trained models; and provide a leaderboard of ensemble defenses under\nvarious attack strategies.",
    "descriptor": "\nComments: To appear in NeurIPS 2022. Project repository: this https URL\n",
    "authors": [
      "Yunrui Yu",
      "Xitong Gao",
      "Cheng-Zhong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08008"
  },
  {
    "id": "arXiv:2211.08010",
    "title": "Bayesian Federated Neural Matching that Completes Full Information",
    "abstract": "Federated learning is a contemporary machine learning paradigm where locally\ntrained models are distilled into a global model. Due to the intrinsic\npermutation invariance of neural networks, Probabilistic Federated Neural\nMatching (PFNM) employs a Bayesian nonparametric framework in the generation\nprocess of local neurons, and then creates a linear sum assignment formulation\nin each alternative optimization iteration. But according to our theoretical\nanalysis, the optimization iteration in PFNM omits global information from\nexisting. In this study, we propose a novel approach that overcomes this flaw\nby introducing a Kullback-Leibler divergence penalty at each iteration. The\neffectiveness of our approach is demonstrated by experiments on both image\nclassification and semantic segmentation tasks.",
    "descriptor": "",
    "authors": [
      "Peng Xiao",
      "Samuel Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08010"
  },
  {
    "id": "arXiv:2211.08013",
    "title": "Drone-based Volume Estimation in Indoor Environments",
    "abstract": "Volume estimation in large indoor spaces is an important challenge in robotic\ninspection of industrial warehouses. We propose an approach for volume\nestimation for autonomous systems using visual features for indoor localization\nand surface reconstruction from 2D-LiDAR measurements. A Gaussian Process-based\nmodel incorporates information collected from measurements given statistical\nprior information about the terrain, from which the volume estimate is\ncomputed. Our algorithm finds feasible trajectories which minimize the\nuncertainty of the volume estimate. We show results in simulation for the\nsurface reconstruction and volume estimate of topographic data.",
    "descriptor": "\nComments: 6 pages, 10 figures, Conference paper\n",
    "authors": [
      "Samuel Balula",
      "Dominic Liao-McPherson",
      "Stefan Stev\u0161i\u0107",
      "Alisa Rupenyan",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08013"
  },
  {
    "id": "arXiv:2211.08016",
    "title": "Contextual Transformer for Offline Meta Reinforcement Learning",
    "abstract": "The pretrain-finetuning paradigm in large-scale sequence models has made\nsignificant progress in natural language processing and computer vision tasks.\nHowever, such a paradigm is still hindered by several challenges in\nReinforcement Learning (RL), including the lack of self-supervised pretraining\nalgorithms based on offline data and efficient fine-tuning/prompt-tuning over\nunseen downstream tasks. In this work, we explore how prompts can improve\nsequence modeling-based offline reinforcement learning (offline-RL) algorithms.\nFirstly, we propose prompt tuning for offline RL, where a context vector\nsequence is concatenated with the input to guide the conditional policy\ngeneration. As such, we can pretrain a model on the offline dataset with\nself-supervised loss and learn a prompt to guide the policy towards desired\nactions. Secondly, we extend our framework to Meta-RL settings and propose\nContextual Meta Transformer (CMT); CMT leverages the context among different\ntasks as the prompt to improve generalization on unseen tasks. We conduct\nextensive experiments across three different offline-RL settings: offline\nsingle-agent RL on the D4RL dataset, offline Meta-RL on the MuJoCo benchmark,\nand offline MARL on the SMAC benchmark. Superior results validate the strong\nperformance, and generality of our methods.",
    "descriptor": "\nComments: Accepted by Foundation Models for Decision Making Workshop at Neural Information Processing Systems, 2022\n",
    "authors": [
      "Runji Lin",
      "Ye Li",
      "Xidong Feng",
      "Zhaowei Zhang",
      "Xian Hong Wu Fung",
      "Haifeng Zhang",
      "Jun Wang",
      "Yali Du",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08016"
  },
  {
    "id": "arXiv:2211.08018",
    "title": "Universal Time-Uniform Trajectory Approximation for Random Dynamical  Systems with Recurrent Neural Networks",
    "abstract": "The capability of recurrent neural networks to approximate trajectories of a\nrandom dynamical system, with random inputs, on non-compact domains, and over\nan indefinite or infinite time horizon is considered. The main result states\nthat certain random trajectories over an infinite time horizon may be\napproximated to any desired accuracy, uniformly in time, by a certain class of\ndeep recurrent neural networks, with simple feedback structures. The\nformulation here contrasts with related literature on this topic, much of which\nis restricted to compact state spaces and finite time intervals. The model\nconditions required here are natural, mild, and easy to test, and the proof is\nvery simple.",
    "descriptor": "",
    "authors": [
      "Adrian N. Bishop"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08018"
  },
  {
    "id": "arXiv:2211.08020",
    "title": "Detecting Malicious Domains Using Statistical Internationalized Domain  Name Features in Top Level Domains",
    "abstract": "The Domain Name System (DNS) is a core Internet service that translates\ndomain names into IP addresses. It is a distributed database and protocol with\nmany known weaknesses that subject to countless attacks including spoofing\nattacks, botnets, and domain name registrations. Still, the debate between\nsecurity and privacy is continuing, that is DNS over TLS or HTTP, and the lack\nof adoption of DNS security extensions, put users at risk. Consequently, the\nsecurity of domain names and characterizing malicious websites is becoming a\npriority. This paper analyzes the difference between the malicious and the\nnormal domain names and uses Python to extract various malicious DNS\nidentifying characteristics. In addition, the paper contributes two categories\nof features that suppers Internationalized Domain Names and scans domain system\nusing five tools to give it a rating. The overall accuracy of the Random Forest\nClassifier was 95.6%.",
    "descriptor": "",
    "authors": [
      "Alshaima Almarzooqi",
      "Jawahir Mahmoud",
      "Bayena Alzaabi",
      "Arsiema Ghebremichael",
      "Monther Aldwairi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.08020"
  },
  {
    "id": "arXiv:2211.08024",
    "title": "NAR-Former: Neural Architecture Representation Learning towards Holistic  Attributes Prediction",
    "abstract": "With the wide and deep adoption of deep learning models in real applications,\nthere is an increasing need to model and learn the representations of the\nneural networks themselves. These models can be used to estimate attributes of\ndifferent neural network architectures such as the accuracy and latency,\nwithout running the actual training or inference tasks. In this paper, we\npropose a neural architecture representation model that can be used to estimate\nthese attributes holistically. Specifically, we first propose a simple and\neffective tokenizer to encode both the operation and topology information of a\nneural network into a single sequence. Then, we design a multi-stage fusion\ntransformer to build a compact vector representation from the converted\nsequence. For efficient model training, we further propose an information flow\nconsistency augmentation and correspondingly design an architecture consistency\nloss, which brings more benefits with less augmentation samples compared with\nprevious random augmentation strategies. Experiment results on NAS-Bench-101,\nNAS-Bench-201, DARTS search space and NNLQP show that our proposed framework\ncan be used to predict the aforementioned latency and accuracy attributes of\nboth cell architectures and whole deep neural networks, and achieves promising\nperformance.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Yun Yi",
      "Haokui Zhang",
      "Wenze Hu",
      "Nannan Wang",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08024"
  },
  {
    "id": "arXiv:2211.08025",
    "title": "FedTune: A Deep Dive into Efficient Federated Fine-Tuning with  Pre-trained Transformers",
    "abstract": "Federated Learning (FL) is an emerging paradigm that enables distributed\nusers to collaboratively and iteratively train machine learning models without\nsharing their private data. Motivated by the effectiveness and robustness of\nself-attention-based architectures, researchers are turning to using\npre-trained Transformers (i.e., foundation models) instead of traditional\nconvolutional neural networks in FL to leverage their excellent transfer\nlearning capabilities. Despite recent progress, how pre-trained Transformer\nmodels play a role in FL remains obscure, that is, how to efficiently fine-tune\nthese pre-trained models in FL and how FL users could benefit from this new\nparadigm. In this paper, we explore this issue and demonstrate that the\nfine-tuned Transformers achieve extraordinary performance on FL, and that the\nlightweight fine-tuning method facilitates a fast convergence rate and low\ncommunication costs. Concretely, we conduct a rigorous empirical study of three\ntuning methods (i.e., modifying the input, adding extra modules, and adjusting\nthe backbone) using two types of pre-trained models (i.e., vision-language\nmodels and vision models) for FL. Our experiments show that 1) Fine-tuning the\nbias term of the backbone performs best when relying on a strong pre-trained\nmodel; 2) The vision-language model (e.g., CLIP) outperforms the pure vision\nmodel (e.g., ViT) and is more robust to the few-shot settings; 3) Compared to\npure local training, FL with pre-trained models has a higher accuracy because\nit alleviates the problem of over-fitting. We will release our code and\nencourage further exploration of pre-trained Transformers and FL.",
    "descriptor": "",
    "authors": [
      "Jinyu Chen",
      "Wenchao Xu",
      "Song Guo",
      "Junxiao Wang",
      "Jie Zhang",
      "Haozhao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08025"
  },
  {
    "id": "arXiv:2211.08029",
    "title": "Persian Emotion Detection using ParsBERT and Imbalanced Data Handling  Approaches",
    "abstract": "Emotion recognition is one of the machine learning applications which can be\ndone using text, speech, or image data gathered from social media spaces.\nDetecting emotion can help us in different fields, including opinion mining.\nWith the spread of social media, different platforms like Twitter have become\ndata sources, and the language used in these platforms is informal, making the\nemotion detection task difficult. EmoPars and ArmanEmo are two new\nhuman-labeled emotion datasets for the Persian language. These datasets,\nespecially EmoPars, are suffering from inequality between several samples\nbetween two classes. In this paper, we evaluate EmoPars and compare them with\nArmanEmo. Throughout this analysis, we use data augmentation techniques, data\nre-sampling, and class-weights with Transformer-based Pretrained Language\nModels(PLMs) to handle the imbalance problem of these datasets. Moreover,\nfeature selection is used to enhance the models' performance by emphasizing the\ntext's specific features. In addition, we provide a new policy for selecting\ndata from EmoPars, which selects the high-confidence samples; as a result, the\nmodel does not see samples that do not have specific emotion during training.\nOur model reaches a Macro-averaged F1-score of 0.81 and 0.76 on ArmanEmo and\nEmoPars, respectively, which are new state-of-the-art results in these\nbenchmarks.",
    "descriptor": "\nComments: 14 pages, 5 figures, 9 tables\n",
    "authors": [
      "Amirhossein Abaskohi",
      "Nazanin Sabri",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08029"
  },
  {
    "id": "arXiv:2211.08030",
    "title": "State of the Art of Quality Assessment of Facial Images",
    "abstract": "The goal of the project \"Facial Metrics for EES\" is to develop, implement and\npublish an open source algorithm for the quality assessment of facial images\n(OFIQ) for face recognition, in particular for border control scenarios.1 In\norder to stimulate the harmonization of the requirements and practices applied\nfor QA for facial images, the insights gained and algorithms developed in the\nproject will be contributed to the current (2022) revision of the ISO/IEC\n29794-5 standard. Furthermore, the implemented quality metrics and algorithms\nwill consider the recommendations and requirements from other relevant\nstandards, in particular ISO/IEC 19794-5:2011, ISO/IEC 29794-5:2010, ISO/IEC\n39794-5:2019 and Version 5.2 of the BSI Technical Guideline TR-03121 Part 3\nVolume 1. In order to establish an informed basis for the selection of quality\nmetrics and the development of corresponding quality assessment algorithms, the\nstate of the art of methods and algorithms (defining a metric), implementations\nand datasets for quality assessment for facial images is surveyed. For all\nrelevant quality aspects, this document summarizes the requirements of the\naforementioned standards, known results on their impact on face recognition\nperformance, publicly available datasets, proposed methods and algorithms and\nopen source software implementations.",
    "descriptor": "\nComments: This report has been created as part of the Project P 527 - Facial Metrics for EES (EESFM) of the Federal Office for Information Security\n",
    "authors": [
      "Johannes Merkle",
      "Christian Rathgeb",
      "Benjamin Tams",
      "Dhay-Parn Lou",
      "Andr\u00e9 D\u00f6rsch",
      "Pawel Drozdowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08030"
  },
  {
    "id": "arXiv:2211.08031",
    "title": "Model Predictive Control for Signal Temporal Logic Specifications with  Time Interval Decomposition",
    "abstract": "In this paper, we investigate the problem of Model Predictive Control (MPC)\nof dynamic systems for high-level specifications described by Signal Temporal\nLogic (STL) formulae. Recent works show that MPC has the great potential in\nhandling logical tasks in reactive environments. However, existing approaches\nsuffer from the heavy computational burden, especially for tasks with large\nhorizons. In this work, we propose a computationally more efficient MPC\nframework for STL tasks based on time interval decomposition. Specifically, we\nstill use the standard shrink horizon MPC framework with Mixed Integer Linear\nProgramming (MILP) techniques for open-loop optimization problems. However,\ninstead of applying MPC directly for the entire task horizon, we decompose the\nSTL formula into several sub-formulae with disjoint time horizons, and\nshrinking horizon MPC is applied for each short-horizon sub-formula\niteratively. To guarantee the satisfaction of the entire STL formula and to\nensure the recursive feasibility of the iterative process, we introduce new\nterminal constraints to connect each sub-formula. We show how these terminal\nconstraints can be computed by an effective inner-approximation approach. The\ncomputational efficiency of our approach is illustrated by a case study.",
    "descriptor": "",
    "authors": [
      "Xinyi Yu",
      "Chuwei Wang",
      "Dingran Yuan",
      "Shaoyuan Li",
      "Xiang Yin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.08031"
  },
  {
    "id": "arXiv:2211.08042",
    "title": "MM-Locate-News: Multimodal Focus Location Estimation in News",
    "abstract": "The consumption of news has changed significantly as the Web has become the\nmost influential medium for information. To analyze and contextualize the large\namount of news published every day, the geographic focus of an article is an\nimportant aspect in order to enable content-based news retrieval. There are\nmethods and datasets for geolocation estimation from text or photos, but they\nare typically considered as separate tasks. However, the photo might lack\ngeographical cues and text can include multiple locations, making it\nchallenging to recognize the focus location using a single modality. In this\npaper, a novel dataset called Multimodal Focus Location of News\n(MM-Locate-News) is introduced. We evaluate state-of-the-art methods on the new\nbenchmark dataset and suggest novel models to predict the focus location of\nnews using both textual and image content. The experimental results show that\nthe multimodal model outperforms unimodal models.",
    "descriptor": "",
    "authors": [
      "Golsa Tahmasebzadeh",
      "Eric M\u00fcller-Budack",
      "Sherzod Hakimov",
      "Ralph Ewerth"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.08042"
  },
  {
    "id": "arXiv:2211.08044",
    "title": "Backdoor Attacks for Remote Sensing Data with Wavelet Transform",
    "abstract": "Recent years have witnessed the great success of deep learning algorithms in\nthe geoscience and remote sensing realm. Nevertheless, the security and\nrobustness of deep learning models deserve special attention when addressing\nsafety-critical remote sensing tasks. In this paper, we provide a systematic\nanalysis of backdoor attacks for remote sensing data, where both scene\nclassification and semantic segmentation tasks are considered. While most of\nthe existing backdoor attack algorithms rely on visible triggers like squared\npatches with well-designed patterns, we propose a novel wavelet transform-based\nattack (WABA) method, which can achieve invisible attacks by injecting the\ntrigger image into the poisoned image in the low-frequency domain. In this way,\nthe high-frequency information in the trigger image can be filtered out in the\nattack, resulting in stealthy data poisoning. Despite its simplicity, the\nproposed method can significantly cheat the current state-of-the-art deep\nlearning models with a high attack success rate. We further analyze how\ndifferent trigger images and the hyper-parameters in the wavelet transform\nwould influence the performance of the proposed method. Extensive experiments\non four benchmark remote sensing datasets demonstrate the effectiveness of the\nproposed method for both scene classification and semantic segmentation tasks\nand thus highlight the importance of designing advanced backdoor defense\nalgorithms to address this threat in remote sensing scenarios. The code will be\navailable online at \\url{https://github.com/ndraeger/waba}.",
    "descriptor": "",
    "authors": [
      "Nikolaus Dr\u00e4ger",
      "Yonghao Xu",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08044"
  },
  {
    "id": "arXiv:2211.08046",
    "title": "X-Volt: Joint Tuning of Driver Strengths and Supply Voltages Against  Power Side-Channel Attacks",
    "abstract": "Power side-channel (PSC) attacks are well-known threats to sensitive hardware\nlike advanced encryption standard (AES) crypto cores. Given the significant\nimpact of supply voltages (VCCs) on power profiles, various countermeasures\nbased on VCC tuning have been proposed, among other defense strategies. Driver\nstrengths of cells, however, have been largely overlooked, despite having\ndirect and significant impact on power profiles as well.\nFor the first time, we thoroughly explore the prospects of jointly tuning\ndriver strengths and VCCs as novel working principle for PSC-attack\ncountermeasures. Toward this end, we take the following steps: 1) we develop a\nsimple circuit-level scheme for tuning; 2) we implement a CAD flow for\ndesign-time evaluation of ASICs, enabling security assessment of ICs before\ntape-out; 3) we implement a correlation power analysis (CPA) framework for\nthorough and comparative security analysis; 4) we conduct an extensive\nexperimental study of a regular AES design, implemented in ASIC as well as FPGA\nfabrics, under various tuning scenarios; 5) we summarize design guidelines for\nsecure and efficient joint tuning.\nIn our experiments, we observe that runtime tuning is more effective than\nstatic tuning, for both ASIC and FPGA implementations. For the latter, the AES\ncore is rendered >11.8x (i.e., at least 11.8 times) as resilient as the untuned\nbaseline design. Layout overheads can be considered acceptable, with, e.g.,\naround +10% critical-path delay for the most resilient tuning scenario in FPGA.\nWe will release source codes for our methodology, as well as artifacts from\nthe experimental study, post peer-review.",
    "descriptor": "\nComments: To appear at ISPD'23\n",
    "authors": [
      "Saideep Sreekumar",
      "Mohammed Ashraf",
      "Mohammed Nabeel",
      "Ozgur Sinanoglu",
      "Johann Knechtel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.08046"
  },
  {
    "id": "arXiv:2211.08047",
    "title": "Deep scene-scale material estimation from multi-view indoor captures",
    "abstract": "The movie and video game industries have adopted photogrammetry as a way to\ncreate digital 3D assets from multiple photographs of a real-world scene. But\nphotogrammetry algorithms typically output an RGB texture atlas of the scene\nthat only serves as visual guidance for skilled artists to create material maps\nsuitable for physically-based rendering. We present a learning-based approach\nthat automatically produces digital assets ready for physically-based\nrendering, by estimating approximate material maps from multi-view captures of\nindoor scenes that are used with retopologized geometry. We base our approach\non a material estimation Convolutional Neural Network (CNN) that we execute on\neach input image. We leverage the view-dependent visual cues provided by the\nmultiple observations of the scene by gathering, for each pixel of a given\nimage, the color of the corresponding point in other images. This image-space\nCNN provides us with an ensemble of predictions, which we merge in texture\nspace as the last step of our approach. Our results demonstrate that the\nrecovered assets can be directly used for physically-based rendering and\nediting of real indoor scenes from any viewpoint and novel lighting. Our method\ngenerates approximate material maps in a fraction of time compared to the\nclosest previous solutions.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Siddhant Prakash",
      "Gilles Rainer",
      "Adrien Bousseau",
      "George Drettakis"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08047"
  },
  {
    "id": "arXiv:2211.08049",
    "title": "Forecasting Future Instance Segmentation with Learned Optical Flow and  Warping",
    "abstract": "For an autonomous vehicle it is essential to observe the ongoing dynamics of\na scene and consequently predict imminent future scenarios to ensure safety to\nitself and others. This can be done using different sensors and modalities. In\nthis paper we investigate the usage of optical flow for predicting future\nsemantic segmentations. To do so we propose a model that forecasts flow fields\nautoregressively. Such predictions are then used to guide the inference of a\nlearned warping function that moves instance segmentations on to future frames.\nResults on the Cityscapes dataset demonstrate the effectiveness of optical-flow\nmethods.",
    "descriptor": "\nComments: Paper published as Poster at ICIAP21\n",
    "authors": [
      "Andrea Ciamarra",
      "Federico Becattini",
      "Lorenzo Seidenari",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08049"
  },
  {
    "id": "arXiv:2211.08055",
    "title": "PAI3D: Painting Adaptive Instance-Prior for 3D Object Detection",
    "abstract": "3D object detection is a critical task in autonomous driving. Recently\nmulti-modal fusion-based 3D object detection methods, which combine the\ncomplementary advantages of LiDAR and camera, have shown great performance\nimprovements over mono-modal methods. However, so far, no methods have\nattempted to utilize the instance-level contextual image semantics to guide the\n3D object detection. In this paper, we propose a simple and effective Painting\nAdaptive Instance-prior for 3D object detection (PAI3D) to fuse instance-level\nimage semantics flexibly with point cloud features. PAI3D is a multi-modal\nsequential instance-level fusion framework. It first extracts instance-level\nsemantic information from images, the extracted information, including objects\ncategorical label, point-to-object membership and object position, are then\nused to augment each LiDAR point in the subsequent 3D detection network to\nguide and improve detection performance. PAI3D outperforms the state-of-the-art\nwith a large margin on the nuScenes dataset, achieving 71.4 in mAP and 74.2 in\nNDS on the test split. Our comprehensive experiments show that instance-level\nimage semantics contribute the most to the performance gain, and PAI3D works\nwell with any good-quality instance segmentation models and any modern point\ncloud 3D encoders, making it a strong candidate for deployment on autonomous\nvehicles.",
    "descriptor": "",
    "authors": [
      "Hao Liu",
      "Zhuoran Xu",
      "Dan Wang",
      "Baofeng Zhang",
      "Guan Wang",
      "Bo Dong",
      "Xin Wen",
      "Xinyu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08055"
  },
  {
    "id": "arXiv:2211.08056",
    "title": "MeSHwA: The case for a Memory-Safe Software and Hardware Architecture  for Serverless Computing",
    "abstract": "Motivated by developer productivity, serverless computing, and microservices\nhave become the de facto development model in the cloud. Microservices\ndecompose monolithic applications into separate functional units deployed\nindividually. This deployment model, however, costs CSPs a large infrastructure\ntax of more than 25%. To overcome these limitations, CSPs shift workloads to\nInfrastructure Processing Units (IPUs) like Amazon's Nitro or, complementary,\ninnovate by building on memory-safe languages and novel software abstractions.\nBased on these trends, we hypothesize a \\arch providing a general-purpose\nruntime environment to specialize functionality when needed and strongly\nisolate components. To achieve this goal, we investigate building a single\naddress space OS or a multi-application library OS, possible hardware\nimplications, and demonstrate their capabilities, drawbacks and requirements.\nThe goal is to bring the advantages to all application workloads including\nlegacy and memory-unsafe applications, and analyze how hardware may improve the\nefficiency and security.",
    "descriptor": "\nComments: Workshop On Resource Disaggregation and Serverless Computing (WORDS)\n",
    "authors": [
      "Anjo Vahldiek-Oberwagner",
      "Mona Vij"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.08056"
  },
  {
    "id": "arXiv:2211.08057",
    "title": "Multilingual and Multimodal Topic Modelling with Pretrained Embeddings",
    "abstract": "This paper presents M3L-Contrast -- a novel multimodal multilingual (M3L)\nneural topic model for comparable data that maps texts from multiple languages\nand images into a shared topic space. Our model is trained jointly on texts and\nimages and takes advantage of pretrained document and image embeddings to\nabstract the complexities between different languages and modalities. As a\nmultilingual topic model, it produces aligned language-specific topics and as\nmultimodal model, it infers textual representations of semantic concepts in\nimages. We demonstrate that our model is competitive with a zero-shot topic\nmodel in predicting topic distributions for comparable multilingual data and\nsignificantly outperforms a zero-shot model in predicting topic distributions\nfor comparable texts and images. We also show that our model performs almost as\nwell on unaligned embeddings as it does on aligned embeddings.",
    "descriptor": "\nComments: Published in COLING 2022 Proceddings\n",
    "authors": [
      "Elaine Zosa",
      "Lidia Pivovarova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08057"
  },
  {
    "id": "arXiv:2211.08063",
    "title": "Multi-Label Quantification",
    "abstract": "Quantification, variously called \"supervised prevalence estimation\" or\n\"learning to quantify\", is the supervised learning task of generating\npredictors of the relative frequencies (a.k.a. \"prevalence values\") of the\nclasses of interest in unlabelled data samples. While many quantification\nmethods have been proposed in the past for binary problems and, to a lesser\nextent, single-label multiclass problems, the multi-label setting (i.e., the\nscenario in which the classes of interest are not mutually exclusive) remains\nby and large unexplored. A straightforward solution to the multi-label\nquantification problem could simply consist of recasting the problem as a set\nof independent binary quantification problems. Such a solution is simple but\nna\\\"ive, since the independence assumption upon which it rests is, in most\ncases, not satisfied. In these cases, knowing the relative frequency of one\nclass could be of help in determining the prevalence of other related classes.\nWe propose the first truly multi-label quantification methods, i.e., methods\nfor inferring estimators of class prevalence values that strive to leverage the\nstochastic dependencies among the classes of interest in order to predict their\nrelative frequencies more accurately. We show empirical evidence that natively\nmulti-label solutions outperform the na\\\"ive approaches by a large margin. The\ncode to reproduce all our experiments is available online.",
    "descriptor": "",
    "authors": [
      "Alejandro Moreo",
      "Manuel Francisco",
      "Fabrizio Sebastiani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08063"
  },
  {
    "id": "arXiv:2211.08064",
    "title": "Physics-Informed Machine Learning: A Survey on Problems, Methods and  Applications",
    "abstract": "Recent advances of data-driven machine learning have revolutionized fields\nlike computer vision, reinforcement learning, and many scientific and\nengineering domains. In many real-world and scientific problems, systems that\ngenerate data are governed by physical laws. Recent work shows that it provides\npotential benefits for machine learning models by incorporating the physical\nprior and collected data, which makes the intersection of machine learning and\nphysics become a prevailing paradigm. In this survey, we present this learning\nparadigm called Physics-Informed Machine Learning (PIML) which is to build a\nmodel that leverages empirical data and available physical prior knowledge to\nimprove performance on a set of tasks that involve a physical mechanism. We\nsystematically review the recent development of physics-informed machine\nlearning from three perspectives of machine learning tasks, representation of\nphysical prior, and methods for incorporating physical prior. We also propose\nseveral important open research problems based on the current trends in the\nfield. We argue that encoding different forms of physical prior into model\narchitectures, optimizers, inference algorithms, and significant\ndomain-specific applications like inverse engineering design and robotic\ncontrol is far from fully being explored in the field of physics-informed\nmachine learning. We believe that this study will encourage researchers in the\nmachine learning community to actively participate in the interdisciplinary\nresearch of physics-informed machine learning.",
    "descriptor": "",
    "authors": [
      "Zhongkai Hao",
      "Songming Liu",
      "Yichi Zhang",
      "Chengyang Ying",
      "Yao Feng",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08064"
  },
  {
    "id": "arXiv:2211.08068",
    "title": "Resisting Graph Adversarial Attack via Cooperative Homophilous  Augmentation",
    "abstract": "Recent studies show that Graph Neural Networks(GNNs) are vulnerable and\neasily fooled by small perturbations, which has raised considerable concerns\nfor adapting GNNs in various safety-critical applications. In this work, we\nfocus on the emerging but critical attack, namely, Graph Injection Attack(GIA),\nin which the adversary poisons the graph by injecting fake nodes instead of\nmodifying existing structures or node attributes. Inspired by findings that the\nadversarial attacks are related to the increased heterophily on perturbed\ngraphs (the adversary tends to connect dissimilar nodes), we propose a general\ndefense framework CHAGNN against GIA through cooperative homophilous\naugmentation of graph data and model. Specifically, the model generates\npseudo-labels for unlabeled nodes in each round of training to reduce\nheterophilous edges of nodes with distinct labels. The cleaner graph is fed\nback to the model, producing more informative pseudo-labels. In such an\niterative manner, model robustness is then promisingly enhanced. We present the\ntheoretical analysis of the effect of homophilous augmentation and provide the\nguarantee of the proposal's validity. Experimental results empirically\ndemonstrate the effectiveness of CHAGNN in comparison with recent\nstate-of-the-art defense methods on diverse real-world datasets.",
    "descriptor": "\nComments: The paper has been accepted for presentation at ECML PKDD 2022\n",
    "authors": [
      "Zhihao Zhu",
      "Chenwang Wu",
      "Min Zhou",
      "Hao Liao",
      "Defu Lian",
      "Enhong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08068"
  },
  {
    "id": "arXiv:2211.08071",
    "title": "Knowledge Distillation for Detection Transformer with Consistent  Distillation Points Sampling",
    "abstract": "DETR is a novel end-to-end transformer architecture object detector, which\nsignificantly outperforms classic detectors when scaling up the model size. In\nthis paper, we focus on the compression of DETR with knowledge distillation.\nWhile knowledge distillation has been well-studied in classic detectors, there\nis a lack of researches on how to make it work effectively on DETR. We first\nprovide experimental and theoretical analysis to point out that the main\nchallenge in DETR distillation is the lack of consistent distillation points.\nDistillation points refer to the corresponding inputs of the predictions for\nstudent to mimic, and reliable distillation requires sufficient distillation\npoints which are consistent between teacher and student. Based on this\nobservation, we propose a general knowledge distillation paradigm for\nDETR(KD-DETR) with consistent distillation points sampling. Specifically, we\ndecouple detection and distillation tasks by introducing a set of specialized\nobject queries to construct distillation points. In this paradigm, we further\npropose a general-to-specific distillation points sampling strategy to explore\nthe extensibility of KD-DETR. Extensive experiments on different DETR\narchitectures with various scales of backbones and transformer layers validate\nthe effectiveness and generalization of KD-DETR. KD-DETR boosts the performance\nof DAB-DETR with ResNet-18 and ResNet-50 backbone to 41.4$\\%$, 45.7$\\%$ mAP,\nrespectively, which are 5.2$\\%$, 3.5$\\%$ higher than the baseline, and\nResNet-50 even surpasses the teacher model by $2.2\\%$.",
    "descriptor": "",
    "authors": [
      "Yu Wang",
      "Xin Li",
      "Shengzhao Wen",
      "Fukui Yang",
      "Wanping Zhang",
      "Gang Zhang",
      "Haocheng Feng",
      "Junyu Han",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08071"
  },
  {
    "id": "arXiv:2211.08073",
    "title": "GLUE-X: Evaluating Natural Language Understanding Models from an  Out-of-distribution Generalization Perspective",
    "abstract": "Pre-trained language models (PLMs) improve the model generalization by\nleveraging massive data as the training corpus in the pre-training phase.\nHowever, currently, the out-of-distribution (OOD) generalization becomes a\ngenerally ill-posed problem, even for the large-scale PLMs in natural language\nunderstanding tasks, which prevents the deployment of NLP methods in the real\nworld. To facilitate the research in this direction, this paper makes the first\nattempt to establish a unified benchmark named GLUE-X, highlighting the\nimportance of OOD robustness and providing insights on how to measure the\nrobustness of a model and how to improve it. To this end, we collect 13\npublicly available datasets as OOD test data, and conduct evaluations on 8\nclassic NLP tasks over \\emph{18} popularly used models. Our findings confirm\nthat the OOD accuracy in NLP tasks needs to be paid more attention to since the\nsignificant performance decay compared to ID accuracy has been found in all\nsettings.",
    "descriptor": "\nComments: 16 pages, GLUE-X, OOD Generalization\n",
    "authors": [
      "Linyi Yang",
      "Shuibai Zhang",
      "Libo Qin",
      "Yafu Li",
      "Yidong Wang",
      "Hanmeng Liu",
      "Jindong Wang",
      "Xing Xie",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.08073"
  },
  {
    "id": "arXiv:2211.08074",
    "title": "Predicting Eye Gaze Location on Websites",
    "abstract": "World-wide-web, with the website and webpage as the main interface,\nfacilitates the dissemination of important information. Hence it is crucial to\noptimize them for better user interaction, which is primarily done by analyzing\nusers' behavior, especially users' eye-gaze locations. However, gathering these\ndata is still considered to be labor and time intensive. In this work, we\nenable the development of automatic eye-gaze estimations given a website\nscreenshots as the input. This is done by the curation of a unified dataset\nthat consists of website screenshots, eye-gaze heatmap and website's layout\ninformation in the form of image and text masks. Our pre-processed dataset\nallows us to propose an effective deep learning-based model that leverages both\nimage and text spatial location, which is combined through attention mechanism\nfor effective eye-gaze prediction. In our experiment, we show the benefit of\ncareful fine-tuning using our unified dataset to improve the accuracy of\neye-gaze predictions. We further observe the capability of our model to focus\non the targeted areas (images and text) to achieve high accuracy. Finally, the\ncomparison with other alternatives shows the state-of-the-art result of our\nmodel establishing the benchmark for the eye-gaze prediction task.",
    "descriptor": "",
    "authors": [
      "Ciheng Zhang",
      "Decky Aspandi",
      "Steffen Staab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.08074"
  },
  {
    "id": "arXiv:2211.08075",
    "title": "Extending the OSLC standard for ECA-based automation in DevOps  environments",
    "abstract": "The DevOps paradigm is taking over software development systems, helping\nbusinesses increase efficiency, accelerate production, and adapt quickly to\nmarket changes. However, adopting these principles can be challenging.\nPractitioners often face an important issue known as vendor lock-in caused by\nthe cost of tool replacement. In addition, automating the processes that\ninvolve these tools also requires investment. These issues could be addressed\nby standardizing service interfaces to facilitate their integration. Linked\nData is an attractive choice for implementing such a standard without\nsacrificing versatility. An exciting and promising proposal in this direction\nis the OSLC standard specification. Its purpose is to build an environment\nwhere services can interoperate using standard Linked Data models. However, the\ncurrent specification version still lacks standard definitions for concepts\nthat are critical to automating the execution of actions in fast-changing\nenvironments. Therefore, this paper proposes a new specification to extend\nOSLC, based on the ECA model, for event-based interoperable automation,\nespecially for DevOps environments, which are our motivational scenario. A\nsimple DevOps architecture is built as a prototype to validate the proposed\nmodel. Using that architecture, the proposed model is validated in a real-world\nworkflow to prove its contribution to the OSLC standard and the DevOps field.",
    "descriptor": "",
    "authors": [
      "Guillermo Garc\u00eda-Grao",
      "\u00c1lvaro Carrera"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.08075"
  },
  {
    "id": "arXiv:2211.08077",
    "title": "EDEN : An Event DEtection Network for the annotation of Breast Cancer  recurrences in administrative claims data",
    "abstract": "While the emergence of large administrative claims data provides\nopportunities for research, their use remains limited by the lack of clinical\nannotations relevant to disease outcomes, such as recurrence in breast cancer\n(BC). Several challenges arise from the annotation of such endpoints in\nadministrative claims, including the need to infer both the occurrence and the\ndate of the recurrence, the right-censoring of data, or the importance of time\nintervals between medical visits. Deep learning approaches have been\nsuccessfully used to label temporal medical sequences, but no method is\ncurrently able to handle simultaneously right-censoring and visit temporality\nto detect survival events in medical sequences. We propose EDEN (Event\nDEtection Network), a time-aware Long-Short-Term-Memory network for survival\nanalyses, and its custom loss function. Our method outperforms several\nstate-of-the-art approaches on real-world BC datasets. EDEN constitutes a\npowerful tool to annotate disease recurrence from administrative claims, thus\npaving the way for the massive use of such data in BC research.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 6 pages\n",
    "authors": [
      "Elise Dumas",
      "Anne-Sophie Hamy",
      "Sophie Houzard",
      "Eva Hernandez",
      "Aull\u00e8ne Toussaint",
      "Julien Guerin",
      "Laetitia Chanas",
      "Victoire de Castelbajac",
      "Mathilde Saint-Ghislain",
      "Beatriz Grandal",
      "Eric Daoud",
      "Fabien Reyal",
      "Chlo\u00e9-Agathe Azencott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08077"
  },
  {
    "id": "arXiv:2211.08080",
    "title": "Embedded Model Control of Networked Control Systems: an Experimental  Case-study -- Stability analysis and further results",
    "abstract": "In Networked Control Systems (NCS), the absence of physical communication\nlinks in the loop leads to relevant issues, such as measurement delays and\nasynchronous execution of the control commands. These issues may lead to\nunwanted control behaviours. This ArXiv paper is intended to give additional\nresults to the work presented in \"Embedded Model Control of Networked Control\nSystems: an Experimental Case-study\". The last one presents an original\napproach, based on the Embedded Model Control, to deal with experimental\nscenarios characterized by asynchronous control timing. The effectiveness of\nthe proposed approach is demonstrated with a differential-drive robot, first\nwith high-fidelity simulations and finally with several experimental tests.\nSpecifically, the present work aims to study the stability analysis of the EMC\nexperimental setup and to give further experimental results, to complement\nthose presented in the main paper, \"Embedded Model Control of Networked Control\nSystems: an Experimental Case-study\".",
    "descriptor": "\nComments: 8 pages, 8 figures, supplementary article to the main paper \"Embedded Model Control of Networked Control Systems: an Experimental Case-study\"\n",
    "authors": [
      "Luca Nanu",
      "Carlos Perez Montenegro",
      "Luigi Colangelo",
      "Carlo Novara"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08080"
  },
  {
    "id": "arXiv:2211.08081",
    "title": "Autonomous Golf Putting with Data-Driven and Physics-Based Methods",
    "abstract": "We are developing a self-learning mechatronic golf robot using combined\ndata-driven and physics-based methods, to have the robot autonomously learn to\nputt the ball from an arbitrary point on the green. Apart from the mechatronic\ncontrol design of the robot, this task is accomplished by a camera system with\nimage recognition and a neural network for predicting the stroke velocity\nvector required for a successful hole-in-one. To minimize the number of\ntime-consuming interactions with the real system, the neural network is\npretrained by evaluating basic physical laws on a model, which approximates the\ngolf ball dynamics on the green surface in a data-driven manner. Thus, we\ndemonstrate the synergetic combination of data-driven and physics-based methods\non the golf robot as a mechatronic example system.",
    "descriptor": "\nComments: accepted for: 2022 Sixth IEEE International Conference on Robotic Computing (IRC)\n",
    "authors": [
      "Annika Junker",
      "Niklas Fittkau",
      "Julia Timmermann",
      "Ansgar Tr\u00e4chtler"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.08081"
  },
  {
    "id": "arXiv:2211.08082",
    "title": "UniHPF : Universal Healthcare Predictive Framework with Zero Domain  Knowledge",
    "abstract": "Despite the abundance of Electronic Healthcare Records (EHR), its\nheterogeneity restricts the utilization of medical data in building predictive\nmodels. To address this challenge, we propose Universal Healthcare Predictive\nFramework (UniHPF), which requires no medical domain knowledge and minimal\npre-processing for multiple prediction tasks. Experimental results demonstrate\nthat UniHPF is capable of building large-scale EHR models that can process any\nform of medical data from distinct EHR systems. We believe that our findings\ncan provide helpful insights for further research on the multi-source learning\nof EHRs.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 19 pages(main paper 6 pages). arXiv admin note: substantial text overlap with arXiv:2207.09858\n",
    "authors": [
      "Kyunghoon Hur",
      "Jungwoo Oh",
      "Junu Kim",
      "Jiyoun Kim",
      "Min Jae Lee",
      "Eunbyeol Cho",
      "Seong-Eun Moon",
      "Young-Hak Kim",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.08082"
  },
  {
    "id": "arXiv:2211.08086",
    "title": "Visually Grounded VQA by Lattice-based Retrieval",
    "abstract": "Visual Grounding (VG) in Visual Question Answering (VQA) systems describes\nhow well a system manages to tie a question and its answer to relevant image\nregions. Systems with strong VG are considered intuitively interpretable and\nsuggest an improved scene understanding. While VQA accuracy performances have\nseen impressive gains over the past few years, explicit improvements to VG\nperformance and evaluation thereof have often taken a back seat on the road to\noverall accuracy improvements. A cause of this originates in the predominant\nchoice of learning paradigm for VQA systems, which consists of training a\ndiscriminative classifier over a predetermined set of answer options.\nIn this work, we break with the dominant VQA modeling paradigm of\nclassification and investigate VQA from the standpoint of an information\nretrieval task. As such, the developed system directly ties VG into its core\nsearch procedure. Our system operates over a weighted, directed, acyclic graph,\na.k.a. \"lattice\", which is derived from the scene graph of a given image in\nconjunction with region-referring expressions extracted from the question.\nWe give a detailed analysis of our approach and discuss its distinctive\nproperties and limitations. Our approach achieves the strongest VG performance\namong examined systems and exhibits exceptional generalization capabilities in\na number of scenarios.",
    "descriptor": "",
    "authors": [
      "Daniel Reich",
      "Felix Putze",
      "Tanja Schultz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08086"
  },
  {
    "id": "arXiv:2211.08089",
    "title": "ShadowDiffusion: Diffusion-based Shadow Removal using Classifier-driven  Attention and Structure Preservation",
    "abstract": "Shadow removal from a single image is challenging, particularly with the\npresence of soft and self shadows. Unlike hard shadows, soft shadows do not\nshow any clear boundaries, while self shadows are shadows that cast on the\nobject itself. Most existing methods require the detection/annotation of binary\nshadow masks, without taking into account the ambiguous boundaries of soft and\nself shadows. Most deep learning shadow removal methods are GAN-based and\nrequire statistical similarity between shadow and shadow-free domains. In\ncontrast to these methods, in this paper, we present ShadowDiffusion, the first\ndiffusion-based shadow removal method. ShadowDiffusion focuses on single-image\nshadow removal, even in the presence of soft and self shadows. To guide the\ndiffusion process to recover semantically meaningful structures during the\nreverse diffusion, we introduce a structure preservation loss, where we extract\nfeatures from the pre-trained Vision Transformer (DINO-ViT). Moreover, to focus\non the recovery of shadow regions, we inject classifier-driven attention into\nthe architecture of the diffusion model. To maintain the consistent colors of\nthe regions where the shadows have been removed, we introduce a chromaticity\nconsistency loss. Our ShadowDiffusion outperforms state-of-the-art methods on\nthe SRD, AISTD, LRSS, USR and UIUC datasets, removing hard, soft, and self\nshadows robustly. Our method outperforms the SOTA method by 20% of the RMSE of\nthe whole image on the SRD dataset.",
    "descriptor": "",
    "authors": [
      "Yeying Jin",
      "Wenhan Yang",
      "Wei Ye",
      "Yuan Yuan",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08089"
  },
  {
    "id": "arXiv:2211.08091",
    "title": "About the Reconstruction of Convex Lattice Sets from One or Two X-rays",
    "abstract": "We consider a class of problems of Discrete Tomography which has been deeply\ninvestigated in the past: the reconstruction of convex lattice sets from their\nhorizontal and/or vertical X-rays, i.e. from the number of points in a sequence\nof consecutive horizontal and vertical lines. The reconstruction of the\nHV-convex polyominoes works usually in two steps, first the filling step\nconsisting in filling operations, second the convex aggregation of the\nswitching components. We prove three results about the convex aggregation step:\n(1) The convex aggregation step used for the reconstruction of HV-convex\npolyominoes does not always provide a solution. The example yielding to this\nresult is called \\textit{the bad guy} and disproves a conjecture of the domain.\n(2) The reconstruction of a digital convex lattice set from only one X-ray can\nbe performed in polynomial time. We prove it by encoding the convex aggregation\nproblem in a Directed Acyclic Graph. (3) With the same strategy, we prove that\nthe reconstruction of fat digital convex sets from their horizontal and\nvertical X-rays can be solved in polynomial time. Fatness is a property of the\ndigital convex sets regarding the relative position of the left, right, top and\nbottom points of the set. The complexity of the reconstruction of the lattice\nsets which are not fat remains an open question.",
    "descriptor": "",
    "authors": [
      "Yan Gerard"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.08091"
  },
  {
    "id": "arXiv:2211.08095",
    "title": "Will Large-scale Generative Models Corrupt Future Datasets?",
    "abstract": "Recently proposed large-scale text-to-image generative models such as\nDALL$\\cdot$E 2, Midjourney, and StableDiffusion can generate high-quality and\nrealistic images from users' prompts. Not limited to the research community,\nordinary Internet users enjoy these generative models, and consequently a\ntremendous amount of generated images have been shared on the Internet.\nMeanwhile, today's success of deep learning in the computer vision field owes a\nlot to images collected from the Internet. These trends lead us to a research\nquestion: \"will such generated images impact the quality of future datasets and\nthe performance of computer vision models positively or negatively?\" This paper\nempirically answers this question by simulating contamination. Namely, we\ngenerate ImageNet-scale and COCO-scale datasets using a state-of-the-art\ngenerative model and evaluate models trained on ``contaminated'' datasets on\nvarious tasks including image classification and image generation. Throughout\nexperiments, we conclude that generated images negatively affect downstream\nperformance, while the significance depends on tasks and the amount of\ngenerated images. The generated datasets are available via\nhttps://github.com/moskomule/dataset-contamination.",
    "descriptor": "",
    "authors": [
      "Ryuichiro Hataya",
      "Han Bao",
      "Hiromi Arai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08095"
  },
  {
    "id": "arXiv:2211.08099",
    "title": "A Universal Discriminator for Zero-Shot Generalization",
    "abstract": "Generative modeling has been the dominant approach for large-scale\npretraining and zero-shot generalization. In this work, we challenge this\nconvention by showing that discriminative approaches perform substantially\nbetter than generative ones on a large number of NLP tasks. Technically, we\ntrain a single discriminator to predict whether a text sample comes from the\ntrue data distribution, similar to GANs. Since many NLP tasks can be formulated\nas selecting from a few options, we use this discriminator to predict the\noption with the highest probability. This simple formulation achieves\nstate-of-the-art zero-shot results on the T0 benchmark, outperforming T0 by\n16.0\\%, 7.8\\%, and 11.5\\% respectively on different scales. In the finetuning\nsetting, our approach also achieves new state-of-the-art results on a wide\nrange of NLP tasks, with only 1/4 parameters of previous methods. Meanwhile,\nour approach requires minimal prompting efforts, which largely improves\nrobustness and is essential for real-world applications. Furthermore, we also\njointly train a generalized UD in combination with generative tasks, which\nmaintains its advantage on discriminative tasks and simultaneously works on\ngenerative tasks.",
    "descriptor": "",
    "authors": [
      "Haike Xu",
      "Zongyu Lin",
      "Jing Zhou",
      "Yanan Zheng",
      "Zhilin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08099"
  },
  {
    "id": "arXiv:2211.08101",
    "title": "Generalised Regret Optimal Controller Synthesis for Constrained Systems",
    "abstract": "This paper presents a synthesis method for the generalised dynamic regret\nproblem, comparing the performance of a strictly causal controller to the\noptimal non-causal controller under a weighted disturbance. This framework\nencompasses both the dynamic regret problem, considering the difference of the\nincurred costs, as well as the competitive ratio, which considers their ratio,\nand which have both been proposed as inherently adaptive alternatives to\nclassical control methods. Furthermore, we extend the synthesis to the case of\npointwise in time bounds on the disturbance and show that the optimal solution\nis no worse than the bounded energy optimal solution and is lower bounded by a\nconstant factor, which is only dependent on the disturbance weight. The\nproposed optimisation-based synthesis allows considering systems subject to\nstate and input constraints. Finally, we provide a numerical example which\ncompares the synthesised controller performance to $\\mathcal{H}_2$- and\n$\\mathcal{H}_\\infty$-controllers.",
    "descriptor": "\nComments: Submitted to IFAC WC 2023\n",
    "authors": [
      "Alexandre Didier",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.08101"
  },
  {
    "id": "arXiv:2211.08102",
    "title": "Hierarchical Pronunciation Assessment with Multi-Aspect Attention",
    "abstract": "Automatic pronunciation assessment is a major component of a\ncomputer-assisted pronunciation training system. To provide in-depth feedback,\nscoring pronunciation at various levels of granularity such as phoneme, word,\nand utterance, with diverse aspects such as accuracy, fluency, and\ncompleteness, is essential. However, existing multi-aspect multi-granularity\nmethods simultaneously predict all aspects at all granularity levels;\ntherefore, they have difficulty in capturing the linguistic hierarchy of\nphoneme, word, and utterance. This limitation further leads to neglecting\nintimate cross-aspect relations at the same linguistic unit. In this paper, we\npropose a Hierarchical Pronunciation Assessment with Multi-aspect Attention\n(HiPAMA) model, which hierarchically represents the granularity levels to\ndirectly capture their linguistic structures and introduces multi-aspect\nattention that reflects associations across aspects at the same level to create\nmore connotative representations. By obtaining relational information from both\nthe granularity- and aspect-side, HiPAMA can take full advantage of multi-task\nlearning. Remarkable improvements in the experimental results on the\nspeachocean762 datasets demonstrate the robustness of HiPAMA, particularly in\nthe difficult-to-assess aspects.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Heejin Do",
      "Yunsu Kim",
      "Gary Geunbae Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08102"
  },
  {
    "id": "arXiv:2211.08104",
    "title": "DualNER: A Dual-Teaching framework for Zero-shot Cross-lingual Named  Entity Recognition",
    "abstract": "We present DualNER, a simple and effective framework to make full use of both\nannotated source language corpus and unlabeled target language text for\nzero-shot cross-lingual named entity recognition (NER). In particular, we\ncombine two complementary learning paradigms of NER, i.e., sequence labeling\nand span prediction, into a unified multi-task framework. After obtaining a\nsufficient NER model trained on the source data, we further train it on the\ntarget data in a {\\it dual-teaching} manner, in which the pseudo-labels for one\ntask are constructed from the prediction of the other task. Moreover, based on\nthe span prediction, an entity-aware regularization is proposed to enhance the\nintrinsic cross-lingual alignment between the same entities in different\nlanguages. Experiments and analysis demonstrate the effectiveness of our\nDualNER. Code is available at https://github.com/lemon0830/dualNER.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Jiali Zeng",
      "Yufan Jiang",
      "Yongjing Yin",
      "Xu Wang",
      "Binghuai Lin",
      "Yunbo Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08104"
  },
  {
    "id": "arXiv:2211.08106",
    "title": "Instance-aware Model Ensemble With Distillation For Unsupervised Domain  Adaptation",
    "abstract": "The linear ensemble based strategy, i.e., averaging ensemble, has been\nproposed to improve the performance in unsupervised domain adaptation tasks.\nHowever, a typical UDA task is usually challenged by dynamically changing\nfactors, such as variable weather, views, and background in the unlabeled\ntarget domain. Most previous ensemble strategies ignore UDA's dynamic and\nuncontrollable challenge, facing limited feature representations and\nperformance bottlenecks. To enhance the model, adaptability between domains and\nreduce the computational cost when deploying the ensemble model, we propose a\nnovel framework, namely Instance aware Model Ensemble With Distillation, IMED,\nwhich fuses multiple UDA component models adaptively according to different\ninstances and distills these components into a small model. The core idea of\nIMED is a dynamic instance aware ensemble strategy, where for each instance, a\nnonlinear fusion subnetwork is learned that fuses the extracted features and\npredicted labels of multiple component models. The nonlinear fusion method can\nhelp the ensemble model handle dynamically changing factors. After learning a\nlarge capacity ensemble model with good adaptability to different changing\nfactors, we leverage the ensemble teacher model to guide the learning of a\ncompact student model by knowledge distillation. Furthermore, we provide the\ntheoretical analysis of the validity of IMED for UDA. Extensive experiments\nconducted on various UDA benchmark datasets, e.g., Office 31, Office Home, and\nVisDA 2017, show the superiority of the model based on IMED to the state of the\nart methods under the comparable computation cost.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Weimin Wu",
      "Jiayuan Fan",
      "Tao Chen",
      "Hancheng Ye",
      "Bo Zhang",
      "Baopu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08106"
  },
  {
    "id": "arXiv:2211.08110",
    "title": "HeatViT: Hardware-Efficient Adaptive Token Pruning for Vision  Transformers",
    "abstract": "While vision transformers (ViTs) have continuously achieved new milestones in\nthe field of computer vision, their sophisticated network architectures with\nhigh computation and memory costs have impeded their deployment on\nresource-limited edge devices. In this paper, we propose a hardware-efficient\nimage-adaptive token pruning framework called HeatViT for efficient yet\naccurate ViT acceleration on embedded FPGAs. By analyzing the inherent\ncomputational patterns in ViTs, we first design an effective attention-based\nmulti-head token selector, which can be progressively inserted before\ntransformer blocks to dynamically identify and consolidate the non-informative\ntokens from input images. Moreover, we implement the token selector on hardware\nby adding miniature control logic to heavily reuse existing hardware components\nbuilt for the backbone ViT. To improve the hardware efficiency, we further\nemploy 8-bit fixed-point quantization, and propose polynomial approximations\nwith regularization effect on quantization error for the frequently used\nnonlinear functions in ViTs. Finally, we propose a latency-aware multi-stage\ntraining strategy to determine the transformer blocks for inserting token\nselectors and optimize the desired (average) pruning rates for inserted token\nselectors, in order to improve both the model accuracy and inference latency on\nhardware. Compared to existing ViT pruning studies, under the similar\ncomputation cost, HeatViT can achieve 0.7%$\\sim$8.9% higher accuracy; while\nunder the similar model accuracy, HeatViT can achieve more than\n28.4%$\\sim$65.3% computation reduction, for various widely used ViTs, including\nDeiT-T, DeiT-S, DeiT-B, LV-ViT-S, and LV-ViT-M, on the ImageNet dataset.\nCompared to the baseline hardware accelerator, our implementations of HeatViT\non the Xilinx ZCU102 FPGA achieve 3.46$\\times$$\\sim$4.89$\\times$ speedup.",
    "descriptor": "\nComments: HPCA 2023\n",
    "authors": [
      "Peiyan Dong",
      "Mengshu Sun",
      "Alec Lu",
      "Yanyue Xie",
      "Kenneth Liu",
      "Zhenglun Kong",
      "Xin Meng",
      "Zhengang Li",
      "Xue Lin",
      "Zhenman Fang",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08110"
  },
  {
    "id": "arXiv:2211.08112",
    "title": "An Efficient Active Learning Pipeline for Legal Text Classification",
    "abstract": "Active Learning (AL) is a powerful tool for learning with less labeled data,\nin particular, for specialized domains, like legal documents, where unlabeled\ndata is abundant, but the annotation requires domain expertise and is thus\nexpensive. Recent works have shown the effectiveness of AL strategies for\npre-trained language models. However, most AL strategies require a set of\nlabeled samples to start with, which is expensive to acquire. In addition,\npre-trained language models have been shown unstable during fine-tuning with\nsmall datasets, and their embeddings are not semantically meaningful. In this\nwork, we propose a pipeline for effectively using active learning with\npre-trained language models in the legal domain. To this end, we leverage the\navailable unlabeled data in three phases. First, we continue pre-training the\nmodel to adapt it to the downstream task. Second, we use knowledge distillation\nto guide the model's embeddings to a semantically meaningful space. Finally, we\npropose a simple, yet effective, strategy to find the initial set of labeled\nsamples with fewer actions compared to existing methods. Our experiments on\nContract-NLI, adapted to the classification task, and LEDGAR benchmarks show\nthat our approach outperforms standard AL strategies, and is more efficient.\nFurthermore, our pipeline reaches comparable results to the fully-supervised\napproach with a small performance gap, and dramatically reduced annotation\ncost. Code and the adapted data will be made available.",
    "descriptor": "",
    "authors": [
      "Sepideh Mamooler",
      "R\u00e9mi Lebret",
      "St\u00e9phane Massonnet",
      "Karl Aberer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08112"
  },
  {
    "id": "arXiv:2211.08115",
    "title": "Heatmap-based Out-of-Distribution Detection",
    "abstract": "Our work investigates out-of-distribution (OOD) detection as a neural network\noutput explanation problem. We learn a heatmap representation for detecting OOD\nimages while visualizing in- and out-of-distribution image regions at the same\ntime. Given a trained and fixed classifier, we train a decoder neural network\nto produce heatmaps with zero response for in-distribution samples and high\nresponse heatmaps for OOD samples, based on the classifier features and the\nclass prediction. Our main innovation lies in the heatmap definition for an OOD\nsample, as the normalized difference from the closest in-distribution sample.\nThe heatmap serves as a margin to distinguish between in- and\nout-of-distribution samples. Our approach generates the heatmaps not only for\nOOD detection, but also to indicate in- and out-of-distribution regions of the\ninput image. In our evaluations, our approach mostly outperforms the prior work\non fixed classifiers, trained on CIFAR-10, CIFAR-100 and Tiny ImageNet. The\ncode is publicly available at: https://github.com/jhornauer/heatmap_ood.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Julia Hornauer",
      "Vasileios Belagiannis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08115"
  },
  {
    "id": "arXiv:2211.08116",
    "title": "W-Trace: Robust and Effective Watermarking for GPS Trajectories",
    "abstract": "With the rise of data-driven methods for traffic forecasting, accident\nprediction, and profiling driving behavior, personal GPS trajectory data has\nbecome an essential asset for businesses and emerging data markets. However, as\npersonal data, GPS trajectories require protection. Especially by data\nbreaches, verification of GPS data ownership is a challenging problem.\nWatermarking facilitates data ownership verification by encoding provenance\ninformation into the data. GPS trajectory watermarking is particularly\nchallenging due to the spatio-temporal data properties and easiness of data\nmodification; as a result, existing methods embed only minimal provenance\ninformation and lack robustness. In this paper, we propose W-Trace - a novel\nGPS trajectory watermarking method based on Fourier transformation. We\ndemonstrate the effectiveness and robustness of W-Trace on two real-world GPS\ntrajectory datasets.",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Rajjat Dadwal",
      "Thorben Funke",
      "Michael N\u00fcsken",
      "Elena Demidova"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.08116"
  },
  {
    "id": "arXiv:2211.08117",
    "title": "Adjoint Variable Method for Transient Nonlinear Electroquasistatic  Problems",
    "abstract": "Many optimization problems in electrical engineering consider a large number\nof design parameters. A sensitivity analysis identifies the design parameters\nwith the strongest influence on the problem of interest. This paper introduces\nthe adjoint variable method as an efficient approach to study sensitivities of\nnonlinear electroquasistatic problems in time domain. In contrast to the more\ncommon direct sensitivity method, the adjoint variable method has a\ncomputational cost nearly independent of the number of parameters. The method\nis applied to study the sensitivity of the field grading material parameters on\nthe performance of a 320 kV cable joint specimen, which is modeled as a Finite\nElement nonlinear transient electroquasistatic problem. Special attention is\npaid to the treatment of quantities of interest, which are evaluated at\nspecific points in time or space. It is shown that shown that the method is a\nvaluable tool to study this strongly nonlinear and highly transient technical\nexample.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "M. Greta Ruppert",
      "Yvonne Sp\u00e4ck-Leigsnering",
      "Julian Buschbaum",
      "Herbert De Gersem"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.08117"
  },
  {
    "id": "arXiv:2211.08119",
    "title": "DeepRGVP: A Novel Microstructure-Informed Supervised Contrastive  Learning Framework for Automated Identification Of The Retinogeniculate  Pathway Using dMRI Tractography",
    "abstract": "The retinogeniculate pathway (RGVP) is responsible for carrying visual\ninformation from the retina to the lateral geniculate nucleus. Identification\nand visualization of the RGVP are important in studying the anatomy of the\nvisual system and can inform treatment of related brain diseases. Diffusion MRI\n(dMRI) tractography is an advanced imaging method that uniquely enables in vivo\nmapping of the 3D trajectory of the RGVP. Currently, identification of the RGVP\nfrom tractography data relies on expert (manual) selection of tractography\nstreamlines, which is time-consuming, has high clinical and expert labor costs,\nand affected by inter-observer variability. In this paper, we present what we\nbelieve is the first deep learning framework, namely DeepRGVP, to enable fast\nand accurate identification of the RGVP from dMRI tractography data. We design\na novel microstructure-informed supervised contrastive learning method that\nleverages both streamline label and tissue microstructure information to\ndetermine positive and negative pairs. We propose a simple and successful\nstreamline-level data augmentation method to address highly imbalanced training\ndata, where the number of RGVP streamlines is much lower than that of non-RGVP\nstreamlines. We perform comparisons with several state-of-the-art deep learning\nmethods that were designed for tractography parcellation, and we show superior\nRGVP identification results using DeepRGVP.",
    "descriptor": "\nComments: 5 pages, 2 figures, 2 tables\n",
    "authors": [
      "Sipei Li",
      "Jianzhong He",
      "Tengfei Xue",
      "Guoqiang Xie",
      "Shun Yao",
      "Yuqian Chen",
      "Erickson F. Torio",
      "Yuanjing Feng",
      "Dhiego CA Bastos",
      "Yogesh Rathi",
      "Nikos Makris",
      "Ron Kikinis",
      "Wenya Linda Bi",
      "Alexandra J Golby",
      "Lauren J O'Donnell",
      "Fan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.08119"
  },
  {
    "id": "arXiv:2211.08129",
    "title": "Self-supervised remote sensing feature learning: Learning Paradigms,  Challenges, and Future Works",
    "abstract": "Deep learning has achieved great success in learning features from massive\nremote sensing images (RSIs). To better understand the connection between\nfeature learning paradigms (e.g., unsupervised feature learning (USFL),\nsupervised feature learning (SFL), and self-supervised feature learning\n(SSFL)), this paper analyzes and compares them from the perspective of feature\nlearning signals, and gives a unified feature learning framework. Under this\nunified framework, we analyze the advantages of SSFL over the other two\nlearning paradigms in RSIs understanding tasks and give a comprehensive review\nof the existing SSFL work in RS, including the pre-training dataset,\nself-supervised feature learning signals, and the evaluation methods. We\nfurther analyze the effect of SSFL signals and pre-training data on the learned\nfeatures to provide insights for improving the RSI feature learning. Finally,\nwe briefly discuss some open problems and possible research directions.",
    "descriptor": "\nComments: 24 pages, 11 figures, 3 tables\n",
    "authors": [
      "Chao Tao",
      "Ji Qi",
      "Mingning Guo",
      "Qing Zhu",
      "Haifeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08129"
  },
  {
    "id": "arXiv:2211.08134",
    "title": "Prediction Accuracy and Autonomy",
    "abstract": "The tech industry has been criticised for designing applications that\nundermine individuals' autonomy. Recommender systems, in particular, have been\nidentified as a suspected culprit that might exercise unwanted control over\npeoples' lives. In this article we try to assess the objectives of recommender\nsystem research and offer a nuanced discussion of how these objectives can\nalign with users' goals. This discussion employs a qualitative literature\nsurvey connecting the dots between relevant research within the fields of\npsychology, design ethics, interaction design and recommender systems. Finally,\nwe focus on the specific use-case of YouTube's recommender system and propose\ndesign changes that will better align with individuals' autonomy. Based on our\nanalysis we offer directions for future research that will help secure rights\nto digital autonomy in the attention economy.",
    "descriptor": "\nComments: 12 pages, no figures. 2021 Workshop on Perspectives on the Evaluation of Recommender Systems\n",
    "authors": [
      "Anton Angwald",
      "Kalle Areskoug",
      "Alan Said"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.08134"
  },
  {
    "id": "arXiv:2211.08138",
    "title": "Design of Unmanned Air Vehicles Using Transformer Surrogate Models",
    "abstract": "Computer-aided design (CAD) is a promising new area for the application of\nartificial intelligence (AI) and machine learning (ML). The current practice of\ndesign of cyber-physical systems uses the digital twin methodology, wherein the\nactual physical design is preceded by building detailed models that can be\nevaluated by physics simulation models. These physics models are often slow and\nthe manual design process often relies on exploring near-by variations of\nexisting designs. AI holds the promise of breaking these design silos and\nincreasing the diversity and performance of designs by accelerating the\nexploration of the design space. In this paper, we focus on the design of\nelectrical unmanned aerial vehicles (UAVs). The high-density batteries and\npurely electrical propulsion systems have disrupted the space of UAV design,\nmaking this domain an ideal target for AI-based design. In this paper, we\ndevelop an AI Designer that synthesizes novel UAV designs. Our approach uses a\ndeep transformer model with a novel domain-specific encoding such that we can\nevaluate the performance of new proposed designs without running expensive\nflight dynamics models and CAD tools. We demonstrate that our approach\nsignificantly reduces the overall compute requirements for the design process\nand accelerates the design space exploration. Finally, we identify future\nresearch directions to achieve full-scale deployment of AI-assisted CAD for\nUAVs.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Adam D. Cobb",
      "Anirban Roy",
      "Daniel Elenius",
      "Susmit Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08138"
  },
  {
    "id": "arXiv:2211.08141",
    "title": "SSM-Net: feature learning for Music Structure Analysis using a  Self-Similarity-Matrix based loss",
    "abstract": "In this paper, we propose a new paradigm to learn audio features for Music\nStructure Analysis (MSA). We train a deep encoder to learn features such that\nthe Self-Similarity-Matrix (SSM) resulting from those approximates a\nground-truth SSM. This is done by minimizing a loss between both SSMs. Since\nthis loss is differentiable w.r.t. its input features we can train the encoder\nin a straightforward way. We successfully demonstrate the use of this training\nparadigm using the Area Under the Curve ROC (AUC) on the RWC-Pop dataset.",
    "descriptor": "\nComments: Extended Abstracts for the Late-Breaking Demo Session of the 23rd Int. Society for Music Information Retrieval Conf., Bengaluru, India, 2022\n",
    "authors": [
      "Geoffroy Peeters",
      "Florian Angulo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08141"
  },
  {
    "id": "arXiv:2211.08142",
    "title": "Semantic Representations of Mathematical Expressions in a Continuous  Vector Space",
    "abstract": "Mathematical notation makes up a large portion of STEM literature, yet,\nfinding semantic representations for formulae remains a challenging problem.\nBecause mathematical notation is precise and its meaning changes significantly\nwith small character shifts, the methods that work for natural text do not\nnecessarily work well for mathematical expressions. In this work, we describe\nan approach for representing mathematical expressions in a continuous vector\nspace. We use the encoder of a sequence-to-sequence architecture, trained on\nvisually different but mathematically equivalent expressions, to generate\nvector representations (embeddings). We compare this approach with an\nautoencoder and show that the former is better at capturing mathematical\nsemantics. Finally, to expedite future projects, we publish a corpus of\nequivalent transcendental and algebraic expression pairs.",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Neeraj Gangwar",
      "Nickvash Kani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08142"
  },
  {
    "id": "arXiv:2211.08143",
    "title": "Supporting the Task-driven Skill Identification in Open Source Project  Issue Tracking Systems",
    "abstract": "Selecting an appropriate task is challenging for contributors to Open Source\nSoftware (OSS), mainly for those who are contributing for the first time.\nTherefore, researchers and OSS projects have proposed various strategies to aid\nnewcomers, including labeling tasks. We investigate the automatic labeling of\nopen issues strategy to help the contributors to pick a task to contribute. We\nlabel the issues with API-domains--categories of APIs parsed from the source\ncode used to solve the issues. We plan to add social network analysis metrics\nfrom the issues conversations as new predictors. By identifying the skills, we\nclaim the contributor candidates should pick a task more suitable. We analyzed\ninterview transcripts and the survey's open-ended questions to comprehend the\nstrategies used to assist in onboarding contributors and used to pick up an\nissue. We applied quantitative studies to analyze the relevance of the labels\nin an experiment and compare the strategies' relative importance. We also mined\nissue data from OSS repositories to predict the API-domain labels with\ncomparable precision, recall, and F-measure with the state-of-art. We plan to\nuse a skill ontology to assist the matching process between contributors and\ntasks. By analyzing the confidence level of the matching instances in\nontologies describing contributors' skills and tasks, we might recommend issues\nfor contribution. So far, the results showed that organizing the issues--which\nincludes assigning labels is seen as an essential strategy for diverse roles in\nOSS communities. The API-domain labels are relevant for experienced\npractitioners. The predictions have an average precision of 75.5%. Labeling the\nissues indicates the skills involved in an issue. The labels represent possible\nskills in the source code related to an issue. By investigating this research\ntopic, we expect to assist the new contributors in finding a task.",
    "descriptor": "",
    "authors": [
      "Fabio Santos"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08143"
  },
  {
    "id": "arXiv:2211.08144",
    "title": "Monocular BEV Perception of Road Scenes via Front-to-Top View Projection",
    "abstract": "HD map reconstruction is crucial for autonomous driving. LiDAR-based methods\nare limited due to expensive sensors and time-consuming computation.\nCamera-based methods usually need to perform road segmentation and view\ntransformation separately, which often causes distortion and missing content.\nTo push the limits of the technology, we present a novel framework that\nreconstructs a local map formed by road layout and vehicle occupancy in the\nbird's-eye view given a front-view monocular image only. We propose a\nfront-to-top view projection (FTVP) module, which takes the constraint of cycle\nconsistency between views into account and makes full use of their correlation\nto strengthen the view transformation and scene understanding. In addition, we\nalso apply multi-scale FTVP modules to propagate the rich spatial information\nof low-level features to mitigate spatial deviation of the predicted object\nlocation. Experiments on public benchmarks show that our method achieves the\nstate-of-the-art performance in the tasks of road layout estimation, vehicle\noccupancy estimation, and multi-class semantic estimation. For multi-class\nsemantic estimation, in particular, our model outperforms all competitors by a\nlarge margin. Furthermore, our model runs at 25 FPS on a single GPU, which is\nefficient and applicable for real-time panorama HD map reconstruction.",
    "descriptor": "\nComments: Extension to CVPR'21 paper \"Projecting Your View Attentively: Monocular Road Scene Layout Estimation via Cross-View Transformation\"\n",
    "authors": [
      "Wenxi Liu",
      "Qi Li",
      "Weixiang Yang",
      "Jiaxin Cai",
      "Yuanlong Yu",
      "Yuexin Ma",
      "Shengfeng He",
      "Jia Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08144"
  },
  {
    "id": "arXiv:2211.08152",
    "title": "Evidence of In-Memory Computing in a Ferrofluid",
    "abstract": "Magnetic fluids are excellent candidates for important research fields\nincluding energy harvesting, biomedical applications, soft robotics and\nexploration. However, notwithstanding relevant advancements such as shape\nreconfigurability, that have been demonstrated, there is no evidence for their\ncomputation capability, including the emulation of synaptic functions. Here, we\nexperimentally demonstrate that a Fe3O4 water-based Ferrofluid (FF) can perform\nelectrical analog computing and be programmed using quasi DC signals and read\nat Radio Frequency (RF) mode. We have observed features in all respects\nattributable to a memristive behavior, featuring both short and long-term\ninformation storage capacity and plasticity. The colloid was capable of\nclassifying digits of a 8x8 pixel dataset using a custom in-memory signal\nprocessing scheme, and through Physical Reservoir Computing (PRC) by training a\nreadout layer.",
    "descriptor": "",
    "authors": [
      "Marco Crepaldi",
      "Charanraj Mohan",
      "Erik Garofalo",
      "Andrew Adamatzky",
      "Konrad Szaci\u0142owski",
      "Alessandro Chiolerio"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Other Condensed Matter (cond-mat.other)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.08152"
  },
  {
    "id": "arXiv:2211.08156",
    "title": "Shared Network Effects in Time- versus Event-Triggered Consensus of a  Single-Integrator Multi-Agent System",
    "abstract": "Event-triggered control has the potential to provide a similar performance\nlevel as time-triggered (periodic) control while triggering events less\nfrequently. It therefore appears intuitive that it is also a viable approach\nfor distributed systems to save scarce shared network resources used for\ninter-agent communication. While this motivation is commonly used also for\nmulti-agent systems, a theoretical analysis of the impact of network effects on\nthe performance of event- and time-triggered control for such distributed\nsystems is currently missing. With this paper, we contrast event- and\ntime-triggered control performance for a single-integrator consensus problem\nunder consideration of a shared communication medium. We therefore incorporate\ntransmission delays and packet loss in our analysis and compare the triggering\nscheme performance under two simple medium access control protocols. We find\nthat network effects can degrade the performance of event-triggered control\nbeyond the performance level of time-triggered control for the same average\ntriggering rate if the network is used intensively. Moreover, the performance\nadvantage of event-triggered control shrinks with an increasing number of\nagents and is even lost for sufficiently large networks in the considered\nsetup.",
    "descriptor": "\nComments: 7 pages, 1 figure, submitted to IFAC for possible publication\n",
    "authors": [
      "David Meister",
      "Frank D\u00fcrr",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08156"
  },
  {
    "id": "arXiv:2211.08157",
    "title": "Taming Large-Scale Genomic Analyses via Sparsified Genomics",
    "abstract": "Searching for similar genomic sequences is an essential and fundamental step\nin biomedical research and an overwhelming majority of genomic analyses.\nState-of-the-art computational methods performing such comparisons fail to cope\nwith the exponential growth of genomic sequencing data. We introduce the\nconcept of sparsified genomics where we systematically exclude a large number\nof bases from genomic sequences and enable much faster and more\nmemory-efficient processing of the sparsified, shorter genomic sequences, while\nproviding similar or even higher accuracy compared to processing non-sparsified\nsequences. Sparsified genomics provides significant benefits to many genomic\nanalyses and has broad applicability. We show that sparsifying genomic\nsequences greatly accelerates the state-of-the-art read mapper (minimap2) by\n1.54-8.8x using real Illumina, HiFi, and ONT reads, while providing a higher\nnumber of mapped reads and more detected small and structural variations.\nSparsifying genomic sequences makes containment search through very large\ngenomes and very large databases 72.7-75.88x faster and 723.3x more\nstorage-efficient than searching through non-sparsified genomic sequences (with\nCMash and KMC3). Sparsifying genomic sequences enables robust microbiome\ndiscovery by providing 54.15-61.88x faster and 720x more storage-efficient\ntaxonomic profiling of metagenomic samples over the state-of-art tool\n(Metalign). We design and open-source a framework called Genome-on-Diet as an\nexample tool for sparsified genomics, which can be freely downloaded from\nhttps://github.com/CMU-SAFARI/Genome-on-Diet.",
    "descriptor": "",
    "authors": [
      "Mohammed Alser",
      "Julien Eudine",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Genomics (q-bio.GN)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.08157"
  },
  {
    "id": "arXiv:2211.08158",
    "title": "CSynGEC: Incorporating Constituent-based Syntax for Grammatical Error  Correction with a Tailored GEC-Oriented Parser",
    "abstract": "Recently, Zhang et al. (2022) propose a syntax-aware grammatical error\ncorrection (GEC) approach, named SynGEC, showing that incorporating tailored\ndependency-based syntax of the input sentence is quite beneficial to GEC. This\nwork considers another mainstream syntax formalism, i.e., constituent-based\nsyntax. By drawing on the successful experience of SynGEC, we first propose an\nextended constituent-based syntax scheme to accommodate errors in ungrammatical\nsentences. Then, we automatically obtain constituency trees of ungrammatical\nsentences to train a GEC-oriented constituency parser by using parallel GEC\ndata as a pivot. For syntax encoding, we employ the graph convolutional network\n(GCN). Experimental results show that our method, named CSynGEC, yields\nsubstantial improvements over strong baselines. Moreover, we investigate the\nintegration of constituent-based and dependency-based syntax for GEC in two\nways: 1) intra-model combination, which means using separate GCNs to encode\nboth kinds of syntax for decoding in a single model; 2)inter-model combination,\nwhich means gathering and selecting edits predicted by different models to\nachieve final corrections. We find that the former method improves recall over\nusing one standalone syntax formalism while the latter improves precision, and\nboth lead to better F0.5 values.",
    "descriptor": "",
    "authors": [
      "Yue Zhang",
      "Zhenghua Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08158"
  },
  {
    "id": "arXiv:2211.08160",
    "title": "Spatiotemporal modeling of European paleoclimate using doubly sparse  Gaussian processes",
    "abstract": "Paleoclimatology -- the study of past climate -- is relevant beyond climate\nscience itself, such as in archaeology and anthropology for understanding past\nhuman dispersal. Information about the Earth's paleoclimate comes from\nsimulations of physical and biogeochemical processes and from proxy records\nfound in naturally occurring archives. Climate-field reconstructions (CFRs)\ncombine these data into a statistical spatial or spatiotemporal model. To date,\nthere exists no consensus spatiotemporal paleoclimate model that is continuous\nin space and time, produces predictions with uncertainty, and can include data\nfrom various sources. A Gaussian process (GP) model would have these desired\nproperties; however, GPs scale unfavorably with data of the magnitude typical\nfor building CFRs. We propose to build on recent advances in sparse\nspatiotemporal GPs that reduce the computational burden by combining\nvariational methods based on inducing variables with the state-space\nformulation of GPs. We successfully employ such a doubly sparse GP to construct\na probabilistic model of European paleoclimate from the Last Glacial Maximum\n(LGM) to the mid-Holocene (MH) that synthesizes paleoclimate simulations and\nfossilized pollen proxy data.",
    "descriptor": "\nComments: 8 pages, 4 figures, Accepted at 2022 NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems (GPSMDMS)\n",
    "authors": [
      "Seth D. Axen",
      "Alexandra Gessner",
      "Christian Sommer",
      "Nils Weitzel",
      "\u00c1lvaro Tejero-Cantero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.08160"
  },
  {
    "id": "arXiv:2211.08162",
    "title": "Faster Verifiable Delay Function For Shorter Delay Parameter",
    "abstract": "A Verifiable Delay Function (VDF) is a function that takes a specified\nsequential time $T$ to be evaluated, but can be verified in $O(\\log T)$-time.\nFor meaningful security, $T$ can be at most subexponential in the security\nparameter $\\lambda$ but has no lower bound. VDFs are useful in several\napplications ranging from randomness beacons to sustainable blockchains but are\nreally rare in practice. To the best of our knowledge, the sequential effort\nrequired for verification in all the VDFs [7,9,4] known to date, is in\n$\\Omega(\\log T)$.\nThis paper proposes a verifiable delay function that requires only two\nsequential squaring to verify when the delay parameter is polynomially-bounded\ni.e., $T\\le \\mathtt{poly}(\\lambda)$. Thus in our VDF, the sequential effort\nrequired for verification is fixed and independent of the security parameter.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.05997\n",
    "authors": [
      "Souvik Sur"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.08162"
  },
  {
    "id": "arXiv:2211.08165",
    "title": "What Can Algebraic Topology and Differential Geometry Teach Us About  Intrinsic Dynamics and Global Behavior of Robots?",
    "abstract": "Traditionally, robots are regarded as universal motion generation machines.\nThey are designed mainly by kinematics considerations while the desired\ndynamics is imposed by strong actuators and high-rate control loops. As an\nalternative, one can first consider the robot's intrinsic dynamics and optimize\nit in accordance with the desired tasks. Therefore, one needs to better\nunderstand intrinsic, uncontrolled dynamics of robotic systems. In this paper\nwe focus on periodic orbits, as fundamental dynamic properties with many\npractical applications. Algebraic topology and differential geometry provide\nsome fundamental statements about existence of periodic orbits. As an example,\nwe present periodic orbits of the simplest multi-body system: the\ndouble-pendulum in gravity. This simple system already displays a rich variety\nof periodic orbits. We classify these into three classes: toroidal orbits, disk\norbits and nonlinear normal modes. Some of these we found by geometrical\ninsights and some by numerical simulation and sampling.",
    "descriptor": "",
    "authors": [
      "Alin Albu-Sch\u00e4ffer",
      "Arne Sachtler"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08165"
  },
  {
    "id": "arXiv:2211.08168",
    "title": "Type Information Utilized Event Detection via Multi-Channel GNNs in  Electrical Power Systems",
    "abstract": "Event detection in power systems aims to identify triggers and event types,\nwhich helps relevant personnel respond to emergencies promptly and facilitates\nthe optimization of power supply strategies. However, the limited length of\nshort electrical record texts causes severe information sparsity, and numerous\ndomain-specific terminologies of power systems makes it difficult to transfer\nknowledge from language models pre-trained on general-domain texts. Traditional\nevent detection approaches primarily focus on the general domain and ignore\nthese two problems in the power system domain. To address the above issues, we\npropose a Multi-Channel graph neural network utilizing Type information for\nEvent Detection in power systems, named MC-TED, leveraging a semantic channel\nand a topological channel to enrich information interaction from short texts.\nConcretely, the semantic channel refines textual representations with semantic\nsimilarity, building the semantic information interaction among potential\nevent-related words. The topological channel generates a relation-type-aware\ngraph modeling word dependencies, and a word-type-aware graph integrating\npart-of-speech tags. To further reduce errors worsened by professional\nterminologies in type analysis, a type learning mechanism is designed for\nupdating the representations of both the word type and relation type in the\ntopological channel. In this way, the information sparsity and professional\nterm occurrence problems can be alleviated by enabling interaction between\ntopological and semantic information. Furthermore, to address the lack of\nlabeled data in power systems, we built a Chinese event detection dataset based\non electrical Power Event texts, named PoE. In experiments, our model achieves\ncompelling results not only on the PoE dataset, but on general-domain event\ndetection datasets including ACE 2005 and MAVEN.",
    "descriptor": "",
    "authors": [
      "Qian Li",
      "Jianxin Li",
      "Lihong Wang",
      "Cheng Ji",
      "Yiming Hei",
      "Jiawei Sheng",
      "Qingyun Sun",
      "Shan Xue",
      "Pengtao Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08168"
  },
  {
    "id": "arXiv:2211.08169",
    "title": "Few-Shot Inductive Learning on Temporal Knowledge Graphs using  Concept-Aware Information",
    "abstract": "Knowledge graph completion (KGC) aims to predict the missing links among\nknowledge graph (KG) entities. Though various methods have been developed for\nKGC, most of them can only deal with the KG entities seen in the training set\nand cannot perform well in predicting links concerning novel entities in the\ntest set. Similar problem exists in temporal knowledge graphs (TKGs), and no\nprevious temporal knowledge graph completion (TKGC) method is developed for\nmodeling newly-emerged entities. Compared to KGs, TKGs require temporal\nreasoning techniques for modeling, which naturally increases the difficulty in\ndealing with novel, yet unseen entities. In this work, we focus on the\ninductive learning of unseen entities' representations on TKGs. We propose a\nfew-shot out-of-graph (OOG) link prediction task for TKGs, where we predict the\nmissing entities from the links concerning unseen entities by employing a\nmeta-learning framework and utilizing the meta-information provided by only few\nedges associated with each unseen entity. We construct three new datasets for\nTKG few-shot OOG link prediction, and we propose a model that mines the\nconcept-aware information among entities. Experimental results show that our\nmodel achieves superior performance on all three datasets and our concept-aware\nmodeling component demonstrates a strong effect.",
    "descriptor": "\nComments: Automated Knowledge Base Construction 2022 Conference Paper, Honorable Mention\n",
    "authors": [
      "Zifeng Ding",
      "Jingpei Wu",
      "Bailan He",
      "Yunpu Ma",
      "Zhen Han",
      "Volker Tresp"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08169"
  },
  {
    "id": "arXiv:2211.08170",
    "title": "A Comparative Study of Question Answering over Knowledge Bases",
    "abstract": "Question answering over knowledge bases (KBQA) has become a popular approach\nto help users extract information from knowledge bases. Although several\nsystems exist, choosing one suitable for a particular application scenario is\ndifficult. In this article, we provide a comparative study of six\nrepresentative KBQA systems on eight benchmark datasets. In that, we study\nvarious question types, properties, languages, and domains to provide insights\non where existing systems struggle. On top of that, we propose an advanced\nmapping algorithm to aid existing models in achieving superior results.\nMoreover, we also develop a multilingual corpus COVID-KGQA, which encourages\nCOVID-19 research and multilingualism for the diversity of future AI. Finally,\nwe discuss the key findings and their implications as well as performance\nguidelines and some future improvements. Our source code is available at\n\\url{https://github.com/tamlhp/kbqa}.",
    "descriptor": "",
    "authors": [
      "Khiem Vinh Tran",
      "Hao Phu Phan",
      "Khang Nguyen Duc Quach",
      "Ngan Luu-Thuy Nguyen",
      "Jun Jo",
      "Thanh Tam Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08170"
  },
  {
    "id": "arXiv:2211.08173",
    "title": "Multi-Task Learning for massive MIMO CSI Feedback",
    "abstract": "Deep learning-based massive MIMO CSI feedback has received a lot of attention\nin recent years. Now, there exists a plethora of CSI feedback models that\nexploit a wide variety of deep learning models and techniques ranging from\nconvolutional neural networks (CNNs) to the recent attention-based transformer\nnetworks. Most of the models are based on auto-encoders (AE) architecture with\nan encoder network at the user equipment (UE) and a decoder network at the gNB\n(base station). However, these models are trained for a single user in a single\nchannel scenario, making them ineffective in scenarios where a gNB is\naddressing various users while each user has different abilities and may employ\na different CSI feedback encoder network and also in scenarios where the users\nare employing the same encoder network but are experiencing different channel\nconditions. In this work, we address these specific issues by exploiting the\ntechniques of multi-task learning (MTL) in the context of massive MIMO CSI\nfeedback.",
    "descriptor": "",
    "authors": [
      "Sharan Mourya",
      "SaiDhiraj Amuru",
      "Kiran Kumar Kuchi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08173"
  },
  {
    "id": "arXiv:2211.08177",
    "title": "Premonition Net, A Multi-Timeline Transformer Network Architecture  Towards Strawberry Tabletop Yield Forecasting",
    "abstract": "Yield forecasting is a critical first step necessary for yield optimisation,\nwith important consequences for the broader food supply chain, procurement,\nprice-negotiation, logistics, and supply. However yield forecasting is\nnotoriously difficult, and oft-inaccurate. Premonition Net is a multi-timeline,\ntime sequence ingesting approach towards processing the past, the present, and\npremonitions of the future. We show how this structure combined with\ntransformers attains critical yield forecasting proficiency towards improving\nfood security, lowering prices, and reducing waste. We find data availability\nto be a continued difficulty however using our premonition network and our own\ncollected data we attain yield forecasts 3 weeks ahead with a a testing set\nRMSE loss of ~0.08 across our latest season.",
    "descriptor": "\nComments: 9 pages, 6 figures, IEEE two column format style\n",
    "authors": [
      "George Onoufriou",
      "Marc Hanheide",
      "Georgios Leontidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08177"
  },
  {
    "id": "arXiv:2211.08180",
    "title": "Divisible linear rank metric",
    "abstract": "A subspace of matrices over $\\mathbb{F}_{q^e}^{m\\times n}$ can be naturally\nembedded as a subspace of matrices in $\\mathbb{F}_q^{em\\times en}$ with the\nproperty that the rank of any of its matrix is a multiple of $e$. It is quite\nnatural to ask whether or not all subspaces of matrices with such a property\narise from a subspace of matrices over a larger field. In this paper we explore\nthis question, which corresponds to studying divisible codes in the rank\nmetric. We determine some cases for which this question holds true, and\ndescribe counterexamples by constructing subspaces with this property which do\nnot arise from a subspace of matrices over a larger field.",
    "descriptor": "",
    "authors": [
      "Olga Polverino",
      "Paolo Santonastaso",
      "John Sheekey",
      "Ferdinando Zullo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.08180"
  },
  {
    "id": "arXiv:2211.08181",
    "title": "How hard are verifiable delay functions?",
    "abstract": "Verifiable delay functions (VDF) are functions that take a specified number\nof sequential steps to be evaluated but can be verified efficiently. In this\npaper, we introduce a new complexity class that contains all the VDFs. We show\nthat this new class $\\mathbf{VDF}$ is a subclass of $\\mathbf{CLS}$ (continuous\nlocal search) and Relaxed-Sink-of-Verifiable-Line is a complete problem for the\nclass $\\mathbf{VDF}$.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2202.10970\n",
    "authors": [
      "Souvik Sur"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.08181"
  },
  {
    "id": "arXiv:2211.08182",
    "title": "Grasping the Inconspicuous",
    "abstract": "Transparent objects are common in day-to-day life and hence find many\napplications that require robot grasping. Many solutions toward object grasping\nexist for non-transparent objects. However, due to the unique visual properties\nof transparent objects, standard 3D sensors produce noisy or distorted\nmeasurements. Modern approaches tackle this problem by either refining the\nnoisy depth measurements or using some intermediate representation of the\ndepth. Towards this, we study deep learning 6D pose estimation from RGB images\nonly for transparent object grasping. To train and test the suitability of\nRGB-based object pose estimation, we construct a dataset of RGB-only images\nwith 6D pose annotations. The experiments demonstrate the effectiveness of RGB\nimage space for grasping transparent objects.",
    "descriptor": "",
    "authors": [
      "Hrishikesh Gupta",
      "Stefan Thalhammer",
      "Markus Leitner",
      "Markus Vincze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08182"
  },
  {
    "id": "arXiv:2211.08183",
    "title": "Generation of Curved Meshes for the High-Lift Common Research Model",
    "abstract": "We answer the questions of the high-order technology focus group (HO-TFG)\nabout the mesh generation for the high-lift common research model of the 4-th\nhigh-lift prediction workshop. The HO-TFG seeks answers about the feasibility\nof generating meshes for complex geometries, and how to measure the quality of\ndifferent aspects of the mesh. To answer these questions, we first generate\nseveral curved meshes and then, we analyze different aspects of the curved mesh\nand perform a visual inspection. The main bottleneck of our curving methodology\nis the preparation of curving-friendly inputs, a process that can take several\ndays for complex geometries. Our distributed parallel implementation executed\nwith 768 processors is able to curve the presented meshes in minutes.",
    "descriptor": "\nComments: AIAA AVIATION 2022 Forum; 2022\n",
    "authors": [
      "Eloi Ruiz-Giron\u00e9s",
      "Xevi Roca"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.08183"
  },
  {
    "id": "arXiv:2211.08184",
    "title": "Improved Coresets for Euclidean $k$-Means",
    "abstract": "Given a set of $n$ points in $d$ dimensions, the Euclidean $k$-means problem\n(resp. the Euclidean $k$-median problem) consists of finding $k$ centers such\nthat the sum of squared distances (resp. sum of distances) from every point to\nits closest center is minimized. The arguably most popular way of dealing with\nthis problem in the big data setting is to first compress the data by computing\na weighted subset known as a coreset and then run any algorithm on this subset.\nThe guarantee of the coreset is that for any candidate solution, the ratio\nbetween coreset cost and the cost of the original instance is less than a\n$(1\\pm \\varepsilon)$ factor. The current state of the art coreset size is\n$\\tilde O(\\min(k^{2} \\cdot \\varepsilon^{-2},k\\cdot \\varepsilon^{-4}))$ for\nEuclidean $k$-means and $\\tilde O(\\min(k^{2} \\cdot \\varepsilon^{-2},k\\cdot\n\\varepsilon^{-3}))$ for Euclidean $k$-median. The best known lower bound for\nboth problems is $\\Omega(k \\varepsilon^{-2})$. In this paper, we improve the\nupper bounds $\\tilde O(\\min(k^{3/2} \\cdot \\varepsilon^{-2},k\\cdot\n\\varepsilon^{-4}))$ for $k$-means and $\\tilde O(\\min(k^{4/3} \\cdot\n\\varepsilon^{-2},k\\cdot \\varepsilon^{-3}))$ for $k$-median. In particular, ours\nis the first provable bound that breaks through the $k^2$ barrier while\nretaining an optimal dependency on $\\varepsilon$.",
    "descriptor": "",
    "authors": [
      "Vincent Cohen-Addad",
      "Kasper Green Larsen",
      "David Saulpic",
      "Chris Schwiegelshohn",
      "Omar Ali Sheikh-Omar"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08184"
  },
  {
    "id": "arXiv:2211.08187",
    "title": "Implementing prescribed-time convergent control: sampling and robustness",
    "abstract": "According to recent results, convergence in a prespecified or prescribed\nfinite time can be achieved under extreme model uncertainty if control is\napplied continuously over time. This paper shows that this extreme amount of\nuncertainty cannot be tolerated under sampling, not even if sampling could\nbecome infinitely frequent as the deadline is approached, unless the sampling\nstrategy were designed according to the growth of the control action.\nRobustness under model uncertainty is analyzed and the amount of uncertainty\nthat can be tolerated under sampling is quantified in order to formulate the\nleast restrictive prescribed-time control problem that is practically\nimplementable. Some solutions to this problem are given for a scalar system.\nMoreover, either under a-priori knowledge of bounds for initial conditions, or\nif the strategy can be selected after the first measurement becomes available,\nit is shown that the real, practically achievable objectives can also be\nreached with linear control and uniform sampling. These derivations serve to\nyield insight into the real advantages that implementation of prescribed-time\ncontrollers may have.",
    "descriptor": "\nComments: This work has been submitted to IFAC for possible publication\n",
    "authors": [
      "Hernan Haimovich",
      "Rodrigo Aldana-Lopez",
      "Richard Seeber",
      "David Gomez-Gutierrez"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08187"
  },
  {
    "id": "arXiv:2211.08188",
    "title": "Desarollo de un Dron Low-Cost para Tareas Indoor",
    "abstract": "Commercial drones are not yet dimensioned to perform indoor autonomous tasks,\nsince they use GPS for their location in the environment. When it comes to a\nspace with physical obstacles (walls, metal, etc.) between the communication of\nthe drone and the satellites that allow the precise location of the same, there\nis great difficulty in finding the satellites or it generates interference for\nthis location. This problem can cause an unexpected action of the drone, a\ncollision and a possible accident can occur. The work to follow presents the\ndevelopment of a drone capable of operating in a physical space (indoor),\nwithout the need for GPS. In this proposal, a prototype of a system for\ndetecting the distance (lidar) that the drone is from the walls is also\ndeveloped, with the aim of being able to take this information as the location\nof the drone.",
    "descriptor": "\nComments: in Spanish language. Articulo aceptado para la FEBITEC 2022\n",
    "authors": [
      "Martin Mattos",
      "Ricardo Grando",
      "Andr\u00e9 Kelbouscas"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08188"
  },
  {
    "id": "arXiv:2211.08190",
    "title": "Reconocimiento de Objetos a partir de Nube de Puntos en un Ve\u00edculo  A\u00e9reo no Tripulado",
    "abstract": "Currently, research in robotics, artificial intelligence and drones are\nadvancing exponentially, they are directly or indirectly related to various\nareas of the economy, from agriculture to industry. With this context, this\nproject covers these topics guiding them, seeking to provide a framework that\nis capable of helping to develop new future researchers. For this, we use an\naerial vehicle that works autonomously and is capable of mapping the scenario\nand providing useful information to the end user. This occurs from a\ncommunication between a simple programming language (Scratch) and one of the\nmost important and efficient robot operating systems today (ROS). This is how\nwe managed to develop a tool capable of generating a 3D map and detecting\nobjects using the camera attached to the drone. Although this tool can be used\nin the advanced fields of industry, it is also an important advance for the\nresearch sector. The implementation of this tool in intermediate-level\ninstitutions is aspired to provide the ability to carry out high-level projects\nfrom a simple programming language.",
    "descriptor": "\nComments: in Spanish language. Articulo aceptado en la FEBITEC 2022\n",
    "authors": [
      "Agustina Marion de Freitas Vidal",
      "Anthony Rodriguez",
      "Richard Suarez",
      "Andr\u00e9 Kelbouscas",
      "Ricardo Grando"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08190"
  },
  {
    "id": "arXiv:2211.08192",
    "title": "RobBERT-2022: Updating a Dutch Language Model to Account for Evolving  Language Use",
    "abstract": "Large transformer-based language models, e.g. BERT and GPT-3, outperform\nprevious architectures on most natural language processing tasks. Such language\nmodels are first pre-trained on gigantic corpora of text and later used as\nbase-model for finetuning on a particular task. Since the pre-training step is\nusually not repeated, base models are not up-to-date with the latest\ninformation. In this paper, we update RobBERT, a RoBERTa-based state-of-the-art\nDutch language model, which was trained in 2019. First, the tokenizer of\nRobBERT is updated to include new high-frequent tokens present in the latest\nDutch OSCAR corpus, e.g. corona-related words. Then we further pre-train the\nRobBERT model using this dataset. To evaluate if our new model is a plug-in\nreplacement for RobBERT, we introduce two additional criteria based on concept\ndrift of existing tokens and alignment for novel tokens.We found that for\ncertain language tasks this update results in a significant performance\nincrease. These results highlight the benefit of continually updating a\nlanguage model to account for evolving language use.",
    "descriptor": "\nComments: 9 pages, 1 figure, 3 tables\n",
    "authors": [
      "Pieter Delobelle",
      "Thomas Winters",
      "Bettina Berendt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08192"
  },
  {
    "id": "arXiv:2211.08193",
    "title": "Differentially Private Sampling from Distributions",
    "abstract": "We initiate an investigation of private sampling from distributions. Given a\ndataset with $n$ independent observations from an unknown distribution $P$, a\nsampling algorithm must output a single observation from a distribution that is\nclose in total variation distance to $P$ while satisfying differential privacy.\nSampling abstracts the goal of generating small amounts of realistic-looking\ndata. We provide tight upper and lower bounds for the dataset size needed for\nthis task for three natural families of distributions: arbitrary distributions\non $\\{1,\\ldots ,k\\}$, arbitrary product distributions on $\\{0,1\\}^d$, and\nproduct distributions on $\\{0,1\\}^d$ with bias in each coordinate bounded away\nfrom 0 and 1. We demonstrate that, in some parameter regimes, private sampling\nrequires asymptotically fewer observations than learning a description of $P$\nnonprivately; in other regimes, however, private sampling proves to be as\ndifficult as private learning. Notably, for some classes of distributions, the\noverhead in the number of observations needed for private learning compared to\nnon-private learning is completely captured by the number of observations\nneeded for private sampling.",
    "descriptor": "\nComments: 44 pages, preliminary version in NeurIPS 2021\n",
    "authors": [
      "Sofya Raskhodnikova",
      "Satchit Sivakumar",
      "Adam Smith",
      "Marika Swanberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.08193"
  },
  {
    "id": "arXiv:2211.08199",
    "title": "Allowing Safe Contact in Robotic Goal-Reaching: Planning and Tracking in  Operational and Null Spaces",
    "abstract": "In recent years, impressive results have been achieved in robotic\nmanipulation. While many efforts focus on generating collision-free reference\nsignals, few allow safe contact between the robot bodies and the environment.\nHowever, in human's daily manipulation, contact between arms and obstacles is\nprevalent and even necessary. This paper investigates the benefit of allowing\nsafe contact during robotic manipulation and advocates generating and tracking\ncompliance reference signals in both operational and null spaces. In addition,\nto optimize the collision-allowed trajectories, we present a hybrid solver that\nintegrates sampling- and gradient-based approaches. We evaluate the proposed\nmethod on a goal-reaching task in five simulated and real-world environments\nwith different collisional conditions. We show that allowing safe contact\nimproves goal-reaching efficiency and provides feasible solutions in highly\ncollisional scenarios where collision-free constraints cannot be enforced.\nMoreover, we demonstrate that planning in null space, in addition to\noperational space, improves trajectory safety.",
    "descriptor": "\nComments: 7 pages, 5 figures, submitted to ICRA 2023\n",
    "authors": [
      "Xinghao Zhu",
      "Wenzhao Lian",
      "Bodi Yuan",
      "C. Daniel Freeman",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08199"
  },
  {
    "id": "arXiv:2211.08200",
    "title": "On Inferring User Socioeconomic Status with Mobility Records",
    "abstract": "When users move in a physical space (e.g., an urban space), they would have\nsome records called mobility records (e.g., trajectories) generated by devices\nsuch as mobile phones and GPS devices. Naturally, mobility records capture\nessential information of how users work, live and entertain in their daily\nlives, and therefore, they have been used in a wide range of tasks such as user\nprofile inference, mobility prediction and traffic management. In this paper,\nwe expand this line of research by investigating the problem of inferring user\nsocioeconomic statuses (such as prices of users' living houses as a proxy of\nusers' socioeconomic statuses) based on their mobility records, which can\npotentially be used in real-life applications such as the car loan business.\nFor this task, we propose a socioeconomic-aware deep model called DeepSEI. The\nDeepSEI model incorporates two networks called deep network and recurrent\nnetwork, which extract the features of the mobility records from three aspects,\nnamely spatiality, temporality and activity, one at a coarse level and the\nother at a detailed level. We conduct extensive experiments on real mobility\nrecords data, POI data and house prices data. The results verify that the\nDeepSEI model achieves superior performance than existing studies. All datasets\nused in this paper will be made publicly available.",
    "descriptor": "\nComments: IEEE International Conference on Big Data (IEEE BigData 2022)\n",
    "authors": [
      "Zheng Wang",
      "Mingrui Liu",
      "Cheng Long",
      "Qianru Zhang",
      "Jiangneng Li",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08200"
  },
  {
    "id": "arXiv:2211.08201",
    "title": "Multiagent Rollout with Reshuffling for Warehouse Robots Path Planning",
    "abstract": "Efficiently solving path planning problems for a large number of robots is\ncritical to the successful operation of modern warehouses. The existing\napproaches adopt classical shortest path algorithms to plan in environments\nwhose cells are associated with both space and time in order to avoid collision\nbetween robots. In this work, we achieve the same goal by means of simulation\nin a smaller static environment. Built upon the new framework introduced in\n(Bertsekas, 2021a), we propose multiagent rollout with reshuffling algorithm,\nand apply it to address the warehouse robots path planning problem. The\nproposed scheme has a solid theoretical guarantee and exhibits consistent\nperformance in our numerical studies. Moreover, it inherits from the generic\nrollout methods the ability to adapt to a changing environment by online\nreplanning, which we demonstrate through examples where some robots\nmalfunction.",
    "descriptor": "",
    "authors": [
      "William Emanuelsson",
      "Alejandro Penacho Riveiros",
      "Yuchao Li",
      "Karl H. Johansson",
      "Jonas M\u00e5rtensson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08201"
  },
  {
    "id": "arXiv:2211.08202",
    "title": "A Mathematical Runtime Analysis of the Non-dominated Sorting Genetic  Algorithm III (NSGA-III)",
    "abstract": "The NSGA-II (Non-dominated Sorting Genetic Algorithm) is the most prominent\nmulti-objective evolutionary algorithm for real-world applications. While it\nperforms evidently well on bi-objective benchmarks, empirical studies suggest\nthat its performance worsens when applied to functions with more than two\nobjectives. As a remedy, the NSGA-III with a slightly adapted selection for the\nnext generation was proposed.\nIn this work, we provide the first mathematical runtime analysis of the\nNSGA-III, on a 3-objective variant of the \\textsc{OneMinMax} benchmark. We\nprove that employing sufficiently many (at least\n$\\frac{2n^2}{3}+\\frac{5n}{\\sqrt{3}}+3$) reference points ensures that once a\nsolution for a certain trade-off between the objectives is found, the\npopulation contains such a solution in all future iterations. Building on this\nobservation, we show that the expected number of iterations until the\npopulation covers the Pareto front is in $O(n^3)$. This result holds for all\npopulation sizes that are at least the size of the Pareto front.",
    "descriptor": "",
    "authors": [
      "Benjamin Doerr",
      "Simon Wietheger"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08202"
  },
  {
    "id": "arXiv:2211.08203",
    "title": "The Dependence on Frequency of Word Embedding Similarity Measures",
    "abstract": "Recent research has shown that static word embeddings can encode word\nfrequency information. However, little has been studied about this phenomenon\nand its effects on downstream tasks. In the present work, we systematically\nstudy the association between frequency and semantic similarity in several\nstatic word embeddings. We find that Skip-gram, GloVe and FastText embeddings\ntend to produce higher semantic similarity between high-frequency words than\nbetween other frequency combinations. We show that the association between\nfrequency and similarity also appears when words are randomly shuffled. This\nproves that the patterns found are not due to real semantic associations\npresent in the texts, but are an artifact produced by the word embeddings.\nFinally, we provide an example of how word frequency can strongly impact the\nmeasurement of gender bias with embedding-based metrics. In particular, we\ncarry out a controlled experiment that shows that biases can even change sign\nor reverse their order by manipulating word frequencies.",
    "descriptor": "",
    "authors": [
      "Francisco Valentini",
      "Diego Fernandez Slezak",
      "Edgar Altszyler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08203"
  },
  {
    "id": "arXiv:2211.08206",
    "title": "Phase Distribution in Probabilistic Movement Primitives, Representing  Time Variability for the Recognition and Reproduction of Human Movements",
    "abstract": "Probabilistic Movement Primitives (ProMPs) are a widely used representation\nof movements for human-robot interaction. They also facilitate the\nfactorization of temporal and spatial structure of movements. In this work we\ninvestigate a method to temporally align observations so that when learning\nProMPs, information in the spatial structure of the observed motion is\nmaximized while maintaining a smooth phase velocity. We apply the method on\nrecordings of hand trajectories in a two-dimensional reaching task. A system\nfor simultaneous recognition of movement and phase is proposed and performance\nof movement recognition and movement reproduction is discussed.",
    "descriptor": "",
    "authors": [
      "Vittorio Lippi",
      "Raphael Deimel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08206"
  },
  {
    "id": "arXiv:2211.08209",
    "title": "On counterfactual inference with unobserved confounding",
    "abstract": "Given an observational study with $n$ independent but heterogeneous units and\none $p$-dimensional sample per unit containing covariates, interventions, and\noutcomes, our goal is to learn the counterfactual distribution for each unit.\nWe consider studies with unobserved confounding which introduces statistical\nbiases between interventions and outcomes as well as exacerbates the\nheterogeneity across units. Modeling the underlying joint distribution as an\nexponential family and under suitable conditions, we reduce learning the $n$\nunit-level counterfactual distributions to learning $n$ exponential family\ndistributions with heterogeneous parameters and only one sample per\ndistribution. We introduce a convex objective that pools all $n$ samples to\njointly learn all $n$ parameters and provide a unit-wise mean squared error\nbound that scales linearly with the metric entropy of the parameter space. For\nexample, when the parameters are $s$-sparse linear combination of $k$ known\nvectors, the error is $O(s\\log k/p)$. En route, we derive sufficient conditions\nfor compactly supported distributions to satisfy the logarithmic Sobolev\ninequality.",
    "descriptor": "",
    "authors": [
      "Abhin Shah",
      "Raaz Dwivedi",
      "Devavrat Shah",
      "Gregory W. Wornell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.08209"
  },
  {
    "id": "arXiv:2211.08217",
    "title": "A Low-Shot Object Counting Network With Iterative Prototype Adaptation",
    "abstract": "We consider low-shot counting of arbitrary semantic categories in the image\nusing only few annotated exemplars (few-shot) or no exemplars (no-shot). The\nstandard few-shot pipeline follows extraction of appearance queries from\nexemplars and matching them with image features to infer the object counts.\nExisting methods extract queries by feature pooling, but neglect the shape\ninformation (e.g., size and aspect), which leads to a reduced object\nlocalization accuracy and count estimates. We propose a Low-shot Object\nCounting network with iterative prototype Adaptation (LOCA). Our main\ncontribution is the new object prototype extraction module, which iteratively\nfuses the exemplar shape and appearance queries with image features. The module\nis easily adapted to zero-shot scenario, enabling LOCA to cover the entire\nspectrum of low-shot counting problems. LOCA outperforms all recent\nstate-of-the-art methods on FSC147 benchmark by 20-30% in RMSE on one-shot and\nfew-shot and achieves state-of-the-art on zero-shot scenarios, while\ndemonstrating better generalization capabilities.",
    "descriptor": "",
    "authors": [
      "Nikola Djukic",
      "Alan Lukezic",
      "Vitjan Zavrtanik",
      "Matej Kristan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08217"
  },
  {
    "id": "arXiv:2211.08221",
    "title": "A Synchronous, Reservation Based Medium Access Control Protocol for  Multihop Wireless Networks",
    "abstract": "We describe a new synchronous and distributed medium access control (MAC)\nprotocol for multihop wireless networks that provides bandwidth guarantees to\nunicast connections. Our MAC protocol is based on a slotted time division\nmultiple access (TDMA) architecture, with a multi-mini-slotted signaling phase\nscheduling data transmissions over slots in the following data phase. Resolving\ncontentions at the beginning of a frame allows for effective utilization of\nbandwidth. Our protocol essentially combines the benefits of TDMA architecture\nwith the distributed reservation mechanism of IEEE 802.11 MAC protocol, thereby\nperforming well even at high loads. We implement a two-way handshake before\neach data slot to avoid deadlocks, a phenomena that plagues 802.11. Through\ntheoretical analysis, we derive the system throughput achieved by our MAC\nprotocol. We implemented our MAC protocol into ns-2 simulator, and demonstrate\nits vast superiority to IEEE 802.11 and a synchronous MAC protocol CATA through\nextensive simulations.",
    "descriptor": "\nComments: 5 pages, 5 figures, IEEE Wireless Communication and Networking Conference 2003. Author Jennifer Andreoli-Fang was previously known as Jennifer Fang\n",
    "authors": [
      "Jennifer Andreoli-Fang",
      "George Kondylis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.08221"
  },
  {
    "id": "arXiv:2211.08222",
    "title": "Impact of combining human and analytics feedback on students' engagement  with, and performance in, reflective writing tasks",
    "abstract": "Reflective writing is part of many higher education courses across the globe.\nIt is often considered a challenging task for students as it requires\nself-regulated learning skills to appropriately plan, timely engage and deeply\nreflect on learning experiences. Despite an advance in writing analytics and\nthe pervasiveness of human feedback aimed to support student reflections,\nlittle is known about how to integrate feedback from humans and analytics to\nimprove students' learning engagement and performance in reflective writing\ntasks. This study proposes a personalised behavioural feedback intervention\nbased on students' writing engagement analytics utilising time-series analysis\nof digital traces from a ubiquitous online word processing platform. In a\nsemester-long experimental study involving 81 postgraduate students, its impact\non learning engagement and performance was studied. The results showed that the\nintervention cohort engaged statistically significantly more in their\nreflective writing task after receiving the combined feedback compared to the\ncontrol cohort which only received human feedback on their reflective writing\ncontent. Further analyses revealed that the intervention cohort reflected more\nregularly at the weekly level, the regularity of weekly reflection led to\nbetter performance grades, and the impact on students with low self-regulated\nlearning skills was higher. This study emphasizes the powerful benefits of\nimplementing combined feedback approaches in which the strengths of analytics\nand human feedback are synthesized to improve student engagement and\nperformance. Further research should explore the long-term sustainability of\nthe observed effects and their validity in other contexts.",
    "descriptor": "\nComments: 28 pages, 5 figures, to be published in the International Journal of Educational Technology in Higher Education\n",
    "authors": [
      "Wannapon Suraworachet",
      "Qi Zhou",
      "Mutlu Cukurova"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.08222"
  },
  {
    "id": "arXiv:2211.08223",
    "title": "A stable and jump-aware projection onto a discrete multi-trace space",
    "abstract": "This work is concerned with boundary element methods on singular geometries,\nspecifically, those falling in the framework of ``multi-screens\" by Claeys and\nHiptmair. We construct a stable quasi-interpolant which preserves piecewise\nlinear jumps on the multi-trace space. This operator is the boundary element\nanalog of the Scott-Zhang quasi-interpolant used in the analysis of\nfinite-element methods. More precisely, let $\\Gamma$ be a multi-screen resolved\nby a triangulation $(\\mathcal{M}_{\\Gamma,h})$, and let $\\mathbb{V}_h(\\Gamma)$\nbe the space of continuous piecewise-linear multi-traces on $\\Gamma$. We\nconstruct a linear operator $\\Pi_h: \\mathbb{H}^{1/2}(\\Gamma) \\to\n\\mathbb{V}_h(\\Gamma)$ with the following properties: (i) $\\|\\Pi_h\nu\\|_{\\mathbb{H}^{1/2}} \\leq C_h \\|u\\|_{\\mathbb{H}^{1/2}(\\Gamma)}$ for all $u\n\\in \\mathbb{H}^{1/2}(\\Gamma)$, (ii) $\\Pi_h u_h = u_h$ for $u_h \\in\n\\mathbb{V}_h(\\Gamma)$ and, (iii) $[\\Pi_h u] = 0$ for every single trace $u \\in\nH^{1/2}([\\Gamma])$. The stability constant $C_h$ only depends on the aspect\nratio of the elements of $\\mathcal{M}_{\\Omega,h}$, where\n$\\mathcal{M}_{\\Omega,h}$ is a tetrahedralization of $\\mathcal{M}_{\\Gamma,h}$.\nWe deduce uniform bounds for the stability of the discrete harmonic lifting,\nand the equivalence of the $\\widetilde{H}^{1/2}$ norm with a discrete quotient\nnorm.",
    "descriptor": "",
    "authors": [
      "Martin Averseng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.08223"
  },
  {
    "id": "arXiv:2211.08227",
    "title": "Perona: Robust Infrastructure Fingerprinting for Resource-Efficient Big  Data Analytics",
    "abstract": "Choosing a good resource configuration for big data analytics applications\ncan be challenging, especially in cloud environments. Automated approaches are\ndesirable as poor decisions can reduce performance and raise costs. The\nmajority of existing automated approaches either build performance models from\nprevious workload executions or conduct iterative resource configuration\nprofiling until a near-optimal solution has been found. In doing so, they only\nobtain an implicit understanding of the underlying infrastructure, which is\ndifficult to transfer to alternative infrastructures and, thus, profiling and\nmodeling insights are not sustained beyond very specific situations.\nWe present Perona, a novel approach to robust infrastructure fingerprinting\nfor usage in the context of big data analytics. Perona employs common sets and\nconfigurations of benchmarking tools for target resources, so that resulting\nbenchmark metrics are directly comparable and ranking is enabled. Insignificant\nbenchmark metrics are discarded by learning a low-dimensional representation of\nthe input metric vector, and previous benchmark executions are taken into\nconsideration for context-awareness as well, allowing to detect resource\ndegradation. We evaluate our approach both on data gathered from our own\nexperiments as well as within related works for resource configuration\noptimization, demonstrating that Perona captures the characteristics from\nbenchmark runs in a compact manner and produces representations that can be\nused directly.",
    "descriptor": "\nComments: 8 pages, 5 figures, 3 tables\n",
    "authors": [
      "Dominik Scheinert",
      "Soeren Becker",
      "Jonathan Bader",
      "Lauritz Thamsen",
      "Jonathan Will",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08227"
  },
  {
    "id": "arXiv:2211.08228",
    "title": "When to Use What: An In-Depth Comparative Empirical Analysis of OpenIE  Systems for Downstream Applications",
    "abstract": "Open Information Extraction (OpenIE) has been used in the pipelines of\nvarious NLP tasks. Unfortunately, there is no clear consensus on which models\nto use in which tasks. Muddying things further is the lack of comparisons that\ntake differing training sets into account. In this paper, we present an\napplication-focused empirical survey of neural OpenIE models, training sets,\nand benchmarks in an effort to help users choose the most suitable OpenIE\nsystems for their applications. We find that the different assumptions made by\ndifferent models and datasets have a statistically significant effect on\nperformance, making it important to choose the most appropriate model for one's\napplications. We demonstrate the applicability of our recommendations on a\ndownstream Complex QA application.",
    "descriptor": "\nComments: 13 pages, 0 figures\n",
    "authors": [
      "Kevin Pei",
      "Ishan Jindal",
      "Kevin Chen-Chuan Chang",
      "Chengxiang Zhai",
      "Yunyao Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08228"
  },
  {
    "id": "arXiv:2211.08229",
    "title": "CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive  Learning",
    "abstract": "Contrastive learning (CL) pre-trains general-purpose encoders using an\nunlabeled pre-training dataset, which consists of images (called single-modal\nCL) or image-text pairs (called multi-modal CL). CL is vulnerable to data\npoisoning based backdoor attacks (DPBAs), in which an attacker injects poisoned\ninputs into the pre-training dataset so the encoder is backdoored. However,\nexisting DPBAs achieve limited effectiveness. In this work, we propose new\nDPBAs called CorruptEncoder to CL. Our experiments show that CorruptEncoder\nsubstantially outperforms existing DPBAs for both single-modal and multi-modal\nCL. CorruptEncoder is the first DPBA that achieves more than 90% attack success\nrates on single-modal CL with only a few (3) reference images and a small\npoisoning ratio (0.5%). Moreover, we also propose a defense, called localized\ncropping, to defend single-modal CL against DPBAs. Our results show that our\ndefense can reduce the effectiveness of DPBAs, but it sacrifices the utility of\nthe encoder, highlighting the needs of new defenses.",
    "descriptor": "",
    "authors": [
      "Jinghuai Zhang",
      "Hongbin Liu",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08229"
  },
  {
    "id": "arXiv:2211.08233",
    "title": "Temporal Modeling Matters: A Novel Temporal Emotional Modeling Approach  for Speech Emotion Recognition",
    "abstract": "Speech emotion recognition (SER) plays a vital role in improving the\ninteractions between humans and machines by inferring human emotion and\naffective states from speech signals. Whereas recent works primarily focus on\nmining spatiotemporal information from hand-crafted features, we explore how to\nmodel the temporal patterns of speech emotions from dynamic temporal scales.\nTowards that goal, we introduce a novel temporal emotional modeling approach\nfor SER, termed Temporal-aware bI-direction Multi-scale Network (TIM-Net),\nwhich learns multi-scale contextual affective representations from various time\nscales. Specifically, TIM-Net first employs temporal-aware blocks to learn\ntemporal affective representation, then integrates complementary information\nfrom the past and the future to enrich contextual representations, and finally,\nfuses multiple time scale features for better adaptation to the emotional\nvariation. Extensive experimental results on six benchmark SER datasets\ndemonstrate the superior performance of TIM-Net, gaining 2.34% and 2.61%\nimprovements of the average UAR and WAR over the second-best on each corpus.\nRemarkably, TIM-Net outperforms the latest domain-adaptation method on the\ncross-corpus SER tasks, demonstrating strong generalizability.",
    "descriptor": "\nComments: Submitted to ICASSP 2023. 8 pages, 6 figures\n",
    "authors": [
      "Jiaxin Ye",
      "Xincheng Wen",
      "Yujie Wei",
      "Yong Xu",
      "Kunhong Liu",
      "Hongming Shan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08233"
  },
  {
    "id": "arXiv:2211.08234",
    "title": "Build generally reusable agent-environment interaction models",
    "abstract": "This paper tackles the problem of how to pre-train a model and make it\ngenerally reusable backbones for downstream task learning. In pre-training, we\npropose a method that builds an agent-environment interaction model by learning\ndomain invariant successor features from the agent's vast experiences covering\nvarious tasks, then discretize them into behavior prototypes which result in an\nembodied set structure. To make the model generally reusable for downstream\ntask learning, we propose (1) embodied feature projection that retains previous\nknowledge by projecting the new task's observation-action pair to the embodied\nset structure and (2) projected Bellman updates which add learning plasticity\nfor the new task setting. We provide preliminary results that show downstream\ntask learning based on a pre-trained embodied set structure can handle unseen\nchanges in task objectives, environmental dynamics and sensor modalities.",
    "descriptor": "\nComments: Accepted in Foundation Models for Decision Making Workshop at Neural Information Processing Systems, 2022. Slides: this https URL\n",
    "authors": [
      "Jun Jin",
      "Hongming Zhang",
      "Jun Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08234"
  },
  {
    "id": "arXiv:2211.08237",
    "title": "Multilingual Speech Emotion Recognition With Multi-Gating Mechanism and  Neural Architecture Search",
    "abstract": "Speech emotion recognition (SER) classifies audio into emotion categories\nsuch as Happy, Angry, Fear, Disgust and Neutral. While Speech Emotion\nRecognition (SER) is a common application for popular languages, it continues\nto be a problem for low-resourced languages, i.e., languages with no pretrained\nspeech-to-text recognition models. This paper firstly proposes a\nlanguage-specific model that extract emotional information from multiple\npre-trained speech models, and then designs a multi-domain model that\nsimultaneously performs SER for various languages. Our multidomain model\nemploys a multi-gating mechanism to generate unique weighted feature\ncombination for each language, and also searches for specific neural network\nstructure for each language through a neural architecture search module. In\naddition, we introduce a contrastive auxiliary loss to build more separable\nrepresentations for audio data. Our experiments show that our model raises the\nstate-of-the-art accuracy by 3% for German and 14.3% for French.",
    "descriptor": "",
    "authors": [
      "Zihan Wang",
      "Qi Meng",
      "HaiFeng Lan",
      "XinRui Zhang",
      "KeHao Guo",
      "Akshat Gupta"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08237"
  },
  {
    "id": "arXiv:2211.08238",
    "title": "Exploiting Contrastive Learning and Numerical Evidence for Improving  Confusing Legal Judgment Prediction",
    "abstract": "Given the fact description text of a legal case, legal judgment prediction\n(LJP) aims to predict the case's charge, law article and penalty term. A core\nproblem of LJP is how to distinguish confusing legal cases, where only subtle\ntext differences exist. Previous studies fail to distinguish different\nclassification errors with a standard cross-entropy classification loss, and\nignore the numbers in the fact description for predicting the term of penalty.\nTo tackle these issues, in this work, first, we propose a moco-based supervised\ncontrastive learning to learn distinguishable representations, and explore the\nbest strategy to construct positive example pairs to benefit all three subtasks\nof LJP simultaneously. Second, in order to exploit the numbers in legal cases\nfor predicting the penalty terms of certain cases, we further enhance the\nrepresentation of the fact description with extracted crime amounts which are\nencoded by a pre-trained numeracy model. Extensive experiments on public\nbenchmarks show that the proposed method achieves new state-of-the-art results,\nespecially on confusing legal cases. Ablation studies also demonstrate the\neffectiveness of each component.",
    "descriptor": "\nComments: 10 pages, 3 figures, 8 tables\n",
    "authors": [
      "Leilei Gan",
      "Baokui Li",
      "Kun Kuang",
      "Yi Yang",
      "Fei Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08238"
  },
  {
    "id": "arXiv:2211.08239",
    "title": "Geometrical Penrose Tilings have Finite Type",
    "abstract": "Rhombus Penrose tilings are tilings of the plane by two decorated rhombi such\nthat the decoration match at the junction between two tiles (like in a jigsaw\npuzzle). In dynamical terms, they form a tiling space of finite type. If we\nremove the decorations, we get, by definition, a sofic tiling space that we\nhere call geometrical Penrose tilings. Here, we show how to compute the\npatterns of a given size which appear in these tilings by two different method:\none based on the substitutive structure of the Penrose tilings and the other on\ntheir definition by the cut and projection method. We use this to prove that\nthe geometrical Penrose tilings are characterized by a small set of patterns\ncalled vertex-atlas, i.e., they form a tiling space of finite type. Though\nconsidered as folk, no complete proof of this result has been published, to our\nknowledge.",
    "descriptor": "",
    "authors": [
      "Thomas Fernique",
      "Victor Lutfalla"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.08239"
  },
  {
    "id": "arXiv:2211.08243",
    "title": "Neural Bayesian Network Understudy",
    "abstract": "Bayesian Networks may be appealing for clinical decision-making due to their\ninclusion of causal knowledge, but their practical adoption remains limited as\na result of their inability to deal with unstructured data. While neural\nnetworks do not have this limitation, they are not interpretable and are\ninherently unable to deal with causal structure in the input space. Our goal is\nto build neural networks that combine the advantages of both approaches.\nMotivated by the perspective to inject causal knowledge while training such\nneural networks, this work presents initial steps in that direction. We\ndemonstrate how a neural network can be trained to output conditional\nprobabilities, providing approximately the same functionality as a Bayesian\nNetwork. Additionally, we propose two training strategies that allow encoding\nthe independence relations inferred from a given causal structure into the\nneural network. We present initial results in a proof-of-concept setting,\nshowing that the neural model acts as an understudy to its Bayesian Network\ncounterpart, approximating its probabilistic and causal properties.",
    "descriptor": "\nComments: 12 pages, submitted to NeurIPS 2022 Workshop on Causal Machine Learning for Real-World Impact (CML4Impact 2022)\n",
    "authors": [
      "Paloma Rabaey",
      "Cedric De Boom",
      "Thomas Demeester"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08243"
  },
  {
    "id": "arXiv:2211.08245",
    "title": "PhysiQ: Off-site Quality Assessment of Exercise in Physical Therapy",
    "abstract": "Physical therapy (PT) is crucial for patients to restore and maintain\nmobility, function, and well-being. Many on-site activities and body exercises\nare performed under the supervision of therapists or clinicians. However, the\npostures of some exercises at home cannot be performed accurately due to the\nlack of supervision, quality assessment, and self-correction. Therefore, in\nthis paper, we design a new framework, PhysiQ, that continuously tracks and\nquantitatively measures people's off-site exercise activity through passive\nsensory detection. In the framework, we create a novel multi-task\nspatio-temporal Siamese Neural Network that measures the absolute quality\nthrough classification and relative quality based on an individual's PT\nprogress through similarity comparison. PhysiQ digitizes and evaluates\nexercises in three different metrics: range of motions, stability, and\nrepetition.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Hanchen David Wang",
      "Meiyi Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08245"
  },
  {
    "id": "arXiv:2211.08246",
    "title": "Online Phase Reconstruction via DNN-based Phase Differences Estimation",
    "abstract": "This paper presents a two-stage online phase reconstruction framework using\ncausal deep neural networks (DNNs). Phase reconstruction is a task of\nrecovering phase of the short-time Fourier transform (STFT) coefficients only\nfrom the corresponding magnitude. However, phase is sensitive to waveform\nshifts and not easy to estimate from the magnitude even with a DNN. To overcome\nthis problem, we propose to use DNNs for estimating differences of phase\nbetween adjacent time-frequency bins. We show that convolutional neural\nnetworks are suitable for phase difference estimation, according to the\ntheoretical relation between partial derivatives of STFT phase and magnitude.\nThe estimated phase differences are used for reconstructing phase by solving a\nweighted least squares problem in a frame-by-frame manner. In contrast to\nexisting DNN-based phase reconstruction methods, the proposed framework is\ncausal and does not require any iterative procedure. The experiments showed\nthat the proposed method outperforms existing online methods and a DNN-based\nmethod for phase reconstruction.",
    "descriptor": "\nComments: Accepted to IEEE/ACM Trans. Audio, Speech, and Language Processing\n",
    "authors": [
      "Yoshiki Masuyama",
      "Kohei Yatabe",
      "Kento Nagatomo",
      "Yasuhiro Oikawa"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08246"
  },
  {
    "id": "arXiv:2211.08247",
    "title": "Scene-to-Patch Earth Observation: Multiple Instance Learning for Land  Cover Classification",
    "abstract": "Land cover classification (LCC), and monitoring how land use changes over\ntime, is an important process in climate change mitigation and adaptation.\nExisting approaches that use machine learning with Earth observation data for\nLCC rely on fully-annotated and segmented datasets. Creating these datasets\nrequires a large amount of effort, and a lack of suitable datasets has become\nan obstacle in scaling the use of LCC. In this study, we propose Scene-to-Patch\nmodels: an alternative LCC approach utilising Multiple Instance Learning (MIL)\nthat requires only high-level scene labels. This enables much faster\ndevelopment of new datasets whilst still providing segmentation through\npatch-level predictions, ultimately increasing the accessibility of using LCC\nfor different scenarios. On the DeepGlobe-LCC dataset, our approach outperforms\nnon-MIL baselines on both scene- and patch-level prediction. This work provides\nthe foundation for expanding the use of LCC in climate change mitigation\nmethods for technology, government, and academia.",
    "descriptor": "\nComments: 14 pages total (4 main content; 2 acknowledgments + citations; 8 appendices); 8 figures (2 main; 6 appendix); published at \"Tackling Climate Change with Machine Learning: Workshop at NeurIPS 2022\"\n",
    "authors": [
      "Joseph Early",
      "Ying-Jung Deweese",
      "Christine Evers",
      "Sarvapali Ramchurn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08247"
  },
  {
    "id": "arXiv:2211.08248",
    "title": "3D Cascade RCNN: High Quality Object Detection in Point Clouds",
    "abstract": "Recent progress on 2D object detection has featured Cascade RCNN, which\ncapitalizes on a sequence of cascade detectors to progressively improve\nproposal quality, towards high-quality object detection. However, there has not\nbeen evidence in support of building such cascade structures for 3D object\ndetection, a challenging detection scenario with highly sparse LiDAR point\nclouds. In this work, we present a simple yet effective cascade architecture,\nnamed 3D Cascade RCNN, that allocates multiple detectors based on the voxelized\npoint clouds in a cascade paradigm, pursuing higher quality 3D object detector\nprogressively. Furthermore, we quantitatively define the sparsity level of the\npoints within 3D bounding box of each object as the point completeness score,\nwhich is exploited as the task weight for each proposal to guide the learning\nof each stage detector. The spirit behind is to assign higher weights for\nhigh-quality proposals with relatively complete point distribution, while\ndown-weight the proposals with extremely sparse points that often incur noise\nduring training. This design of completeness-aware re-weighting elegantly\nupgrades the cascade paradigm to be better applicable for the sparse input\ndata, without increasing any FLOP budgets. Through extensive experiments on\nboth the KITTI dataset and Waymo Open Dataset, we validate the superiority of\nour proposed 3D Cascade RCNN, when comparing to state-of-the-art 3D object\ndetection techniques. The source code is publicly available at\n\\url{https://github.com/caiqi/Cascasde-3D}.",
    "descriptor": "\nComments: IEEE Transactions on Image Processing (TIP) 2022. The source code is publicly available at \\url{this https URL}\n",
    "authors": [
      "Qi Cai",
      "Yingwei Pan",
      "Ting Yao",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08248"
  },
  {
    "id": "arXiv:2211.08249",
    "title": "Explaining Cross-Domain Recognition with Interpretable Deep Classifier",
    "abstract": "The recent advances in deep learning predominantly construct models in their\ninternal representations, and it is opaque to explain the rationale behind and\ndecisions to human users. Such explainability is especially essential for\ndomain adaptation, whose challenges require developing more adaptive models\nacross different domains. In this paper, we ask the question: how much each\nsample in source domain contributes to the network's prediction on the samples\nfrom target domain. To address this, we devise a novel Interpretable Deep\nClassifier (IDC) that learns the nearest source samples of a target sample as\nevidence upon which the classifier makes the decision. Technically, IDC\nmaintains a differentiable memory bank for each category and the memory slot\nderives a form of key-value pair. The key records the features of\ndiscriminative source samples and the value stores the corresponding\nproperties, e.g., representative scores of the features for describing the\ncategory. IDC computes the loss between the output of IDC and the labels of\nsource samples to back-propagate to adjust the representative scores and update\nthe memory banks. Extensive experiments on Office-Home and VisDA-2017 datasets\ndemonstrate that our IDC leads to a more explainable model with almost no\naccuracy degradation and effectively calibrates classification for optimum\nreject options. More remarkably, when taking IDC as a prior interpreter,\ncapitalizing on 0.1% source training data selected by IDC still yields superior\nresults than that uses full training set on VisDA-2017 for unsupervised domain\nadaptation.",
    "descriptor": "",
    "authors": [
      "Yiheng Zhang",
      "Ting Yao",
      "Zhaofan Qiu",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08249"
  },
  {
    "id": "arXiv:2211.08250",
    "title": "SPE-Net: Boosting Point Cloud Analysis via Rotation Robustness  Enhancement",
    "abstract": "In this paper, we propose a novel deep architecture tailored for 3D point\ncloud applications, named as SPE-Net. The embedded ``Selective Position\nEncoding (SPE)'' procedure relies on an attention mechanism that can\neffectively attend to the underlying rotation condition of the input. Such\nencoded rotation condition then determines which part of the network parameters\nto be focused on, and is shown to efficiently help reduce the degree of freedom\nof the optimization during training. This mechanism henceforth can better\nleverage the rotation augmentations through reduced training difficulties,\nmaking SPE-Net robust against rotated data both during training and testing.\nThe new findings in our paper also urge us to rethink the relationship between\nthe extracted rotation information and the actual test accuracy. Intriguingly,\nwe reveal evidences that by locally encoding the rotation information through\nSPE-Net, the rotation-invariant features are still of critical importance in\nbenefiting the test samples without any actual global rotation. We empirically\ndemonstrate the merits of the SPE-Net and the associated hypothesis on four\nbenchmarks, showing evident improvements on both rotated and unrotated test\ndata over SOTA methods. Source code is available at\nhttps://github.com/ZhaofanQiu/SPE-Net.",
    "descriptor": "\nComments: ECCV 2022. Source code is available at this https URL\n",
    "authors": [
      "Zhaofan Qiu",
      "Yehao Li",
      "Yu Wang",
      "Yingwei Pan",
      "Ting Yao",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08250"
  },
  {
    "id": "arXiv:2211.08251",
    "title": "Offline Reinforcement Learning with Adaptive Behavior Regularization",
    "abstract": "Offline reinforcement learning (RL) defines a sample-efficient learning\nparadigm, where a policy is learned from static and previously collected\ndatasets without additional interaction with the environment. The major\nobstacle to offline RL is the estimation error arising from evaluating the\nvalue of out-of-distribution actions. To tackle this problem, most existing\noffline RL methods attempt to acquire a policy both ``close\" to the behaviors\ncontained in the dataset and sufficiently improved over them, which requires a\ntrade-off between two possibly conflicting targets. In this paper, we propose a\nnovel approach, which we refer to as adaptive behavior regularization (ABR), to\nbalance this critical trade-off. By simply utilizing a sample-based\nregularization, ABR enables the policy to adaptively adjust its optimization\nobjective between cloning and improving over the policy used to generate the\ndataset. In the evaluation on D4RL datasets, a widely adopted benchmark for\noffline reinforcement learning, ABR can achieve improved or competitive\nperformance compared to existing state-of-the-art algorithms.",
    "descriptor": "\nComments: Xijun Li is the corresponding author\n",
    "authors": [
      "Yunfan Zhou",
      "Xijun Li",
      "Qingyu Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08251"
  },
  {
    "id": "arXiv:2211.08252",
    "title": "Dynamic Temporal Filtering in Video Models",
    "abstract": "Video temporal dynamics is conventionally modeled with 3D spatial-temporal\nkernel or its factorized version comprised of 2D spatial kernel and 1D temporal\nkernel. The modeling power, nevertheless, is limited by the fixed window size\nand static weights of a kernel along the temporal dimension. The pre-determined\nkernel size severely limits the temporal receptive fields and the fixed weights\ntreat each spatial location across frames equally, resulting in sub-optimal\nsolution for long-range temporal modeling in natural scenes. In this paper, we\npresent a new recipe of temporal feature learning, namely Dynamic Temporal\nFilter (DTF), that novelly performs spatial-aware temporal modeling in\nfrequency domain with large temporal receptive field. Specifically, DTF\ndynamically learns a specialized frequency filter for every spatial location to\nmodel its long-range temporal dynamics. Meanwhile, the temporal feature of each\nspatial location is also transformed into frequency feature spectrum via 1D\nFast Fourier Transform (FFT). The spectrum is modulated by the learnt frequency\nfilter, and then transformed back to temporal domain with inverse FFT. In\naddition, to facilitate the learning of frequency filter in DTF, we perform\nframe-wise aggregation to enhance the primary temporal feature with its\ntemporal neighbors by inter-frame correlation. It is feasible to plug DTF block\ninto ConvNets and Transformer, yielding DTF-Net and DTF-Transformer. Extensive\nexperiments conducted on three datasets demonstrate the superiority of our\nproposals. More remarkably, DTF-Transformer achieves an accuracy of 83.5% on\nKinetics-400 dataset. Source code is available at\n\\url{https://github.com/FuchenUSTC/DTF}.",
    "descriptor": "\nComments: ECCV 2022. Source code is available at \\url{this https URL}\n",
    "authors": [
      "Fuchen Long",
      "Zhaofan Qiu",
      "Yingwei Pan",
      "Ting Yao",
      "Chong-Wah Ngo",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08252"
  },
  {
    "id": "arXiv:2211.08253",
    "title": "HMOE: Hypernetwork-based Mixture of Experts for Domain Generalization",
    "abstract": "Due to the domain shift, machine learning systems typically fail to\ngeneralize well to domains different from those of training data, which is the\nproblem that domain generalization (DG) aims to address. However, most\nmainstream DG algorithms lack interpretability and require domain labels, which\nare not available in many real-world scenarios. In this work, we propose a\nnovel DG method, HMOE: Hypernetwork-based Mixture of Experts (MoE), that does\nnot require domain labels and is more interpretable. We use hypernetworks to\ngenerate the weights of experts, allowing experts to share some useful\nmeta-knowledge. MoE has proven adept at detecting and identifying heterogeneous\npatterns in data. For DG, heterogeneity exactly arises from the domain shift.\nWe compare HMOE with other DG algorithms under a fair and unified\nbenchmark-DomainBed. Extensive experiments show that HMOE can perform latent\ndomain discovery from data of mixed domains and divide it into distinct\nclusters that are surprisingly more consistent with human intuition than\noriginal domain labels. Compared to other DG methods, HMOE shows competitive\nperformance and achieves SOTA results in some cases without using domain\nlabels.",
    "descriptor": "",
    "authors": [
      "Jingang Qu",
      "Thibault Faney",
      "Ze Wang",
      "Patrick Gallinari",
      "Soleiman Yousef",
      "Jean-Charles de Hemptinne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08253"
  },
  {
    "id": "arXiv:2211.08257",
    "title": "AutoTherm: A Dataset and Ablation Study for Thermal Comfort Prediction  in Vehicles",
    "abstract": "State recognition in well-known and customizable environments such as\nvehicles enables novel insights into users and potentially their intentions.\nBesides safety-relevant insights into, for example, fatigue, user\nexperience-related assessments become increasingly relevant. As thermal comfort\nis vital for overall comfort, we introduce a dataset for its prediction in\nvehicles incorporating 31 input signals and self-labeled user ratings based on\na 7-point Likert scale (-3 to +3) by 21 subjects. An importance ranking of such\nsignals indicates higher impact on prediction for signals like ambient\ntemperature, ambient humidity, radiation temperature, and skin temperature.\nLeveraging modern machine learning architectures enables us to not only\nautomatically recognize human thermal comfort state but also predict future\nstates. We provide details on how we train a recurrent network-based classifier\nand, thus, perform an initial performance benchmark of our proposed thermal\ncomfort dataset. Ultimately, we compare our collected dataset to publicly\navailable datasets.",
    "descriptor": "",
    "authors": [
      "Mark Colley",
      "Sebastian Hartwig",
      "Albin Zeqiri",
      "Timo Ropinski",
      "Enrico Rukzio"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.08257"
  },
  {
    "id": "arXiv:2211.08263",
    "title": "An implicit FFT-based method for wave propagation in elastic  heterogeneous media",
    "abstract": "An FFT-based algorithm is developed to simulate the propagation of elastic\nwaves in heterogeneous $d$-dimensional rectangular shape domains. The method\nallows one to prescribe the displacement as a function of time in a subregion\nof the domain, emulating the application of Dirichlet boundary conditions on an\nouter face. Time discretization is performed using an unconditionally stable\nbeta-Newmark approach. The implicit problem for obtaining the displacement at\neach time step is solved by transforming the equilibrium equations into Fourier\nspace and solving the corresponding linear system with a preconditioned Krylov\nsolver. The resulting method is validated against analytical solutions and\ncompared with implicit and explicit finite element simulations and with an\nexplicit FFT approach. The accuracy of the method is similar to or better than\nthat of finite elements, and the numerical performance is clearly superior,\nallowing the use of much larger models. To illustrate the capabilities of the\nmethod, some numerical examples are presented, including the propagation of\nplanar, circular, and spherical waves and the simulation of the propagation of\na pulse in a polycrystalline medium.",
    "descriptor": "\nComments: FFT-based homogenization, micromechanics, wave propagation, polycrystals, acoustics, elastodynamics, scattering} IN PRESS, Computer Methods in Applied Mechanics and Engineering, 2022\n",
    "authors": [
      "R. Sancho",
      "V. Rey de Pedraza",
      "P. Lafourcade",
      "R.A. Lebensohn",
      "J. Segurado"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2211.08263"
  },
  {
    "id": "arXiv:2211.08264",
    "title": "QAmeleon: Multilingual QA with Only 5 Examples",
    "abstract": "The availability of large, high-quality datasets has been one of the main\ndrivers of recent progress in question answering (QA). Such annotated datasets\nhowever are difficult and costly to collect, and rarely exist in languages\nother than English, rendering QA technology inaccessible to underrepresented\nlanguages. An alternative to building large monolingual training datasets is to\nleverage pre-trained language models (PLMs) under a few-shot learning setting.\nOur approach, QAmeleon, uses a PLM to automatically generate multilingual data\nupon which QA models are trained, thus avoiding costly annotation. Prompt\ntuning the PLM for data synthesis with only five examples per language delivers\naccuracy superior to translation-based baselines, bridges nearly 60% of the gap\nbetween an English-only baseline and a fully supervised upper bound trained on\nalmost 50,000 hand labeled examples, and always leads to substantial\nimprovements compared to fine-tuning a QA model directly on labeled examples in\nlow resource settings. Experiments on the TyDiQA-GoldP and MLQA benchmarks show\nthat few-shot prompt tuning for data synthesis scales across languages and is a\nviable alternative to large-scale annotation.",
    "descriptor": "",
    "authors": [
      "Priyanka Agrawal",
      "Chris Alberti",
      "Fantine Huot",
      "Joshua Maynez",
      "Ji Ma",
      "Sebastian Ruder",
      "Kuzman Ganchev",
      "Dipanjan Das",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08264"
  },
  {
    "id": "arXiv:2211.08268",
    "title": "A Comparative Study of Machine Learning and Deep Learning Techniques for  Prediction of Co2 Emission in Cars",
    "abstract": "The most recent concern of all people on Earth is the increase in the\nconcentration of greenhouse gas in the atmosphere. The concentration of these\ngases has risen rapidly over the last century and if the trend continues it can\ncause many adverse climatic changes. There have been ways implemented to curb\nthis by the government by limiting processes that emit a higher amount of CO2,\none such greenhouse gas. However, there is mounting evidence that the CO2\nnumbers supplied by the government do not accurately reflect the performance of\nautomobiles on the road. Our proposal of using artificial intelligence\ntechniques to improve a previously rudimentary process takes a radical tack,\nbut it fits the bill given the situation. To determine which algorithms and\nmodels produce the greatest outcomes, we compared them all and explored a novel\nmethod of ensembling them. Further, this can be used to foretell the rise in\nglobal temperature and to ground crucial policy decisions like the adoption of\nelectric vehicles. To estimate emissions from vehicles, we used machine\nlearning, deep learning, and ensemble learning on a massive dataset.",
    "descriptor": "\nComments: Will be published in Springer L.N.N.S. Data set used this https URL\n",
    "authors": [
      "Samveg Shah",
      "Shubham Thakar",
      "Kashish Jain",
      "Bhavya Shah",
      "Sudhir Dhage"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08268"
  },
  {
    "id": "arXiv:2211.08272",
    "title": "Low-Thrust Orbital Transfer using Dynamics-Agnostic Reinforcement  Learning",
    "abstract": "Low-thrust trajectory design and in-flight control remain two of the most\nchallenging topics for new-generation satellite operations. Most of the\nsolutions currently implemented are based on reference trajectories and lead to\nsub-optimal fuel usage. Other solutions are based on simple guidance laws that\nneed to be updated periodically, increasing the cost of operations. Whereas\nsome optimization strategies leverage Artificial Intelligence methods, all of\nthe approaches studied so far need either previously generated data or a strong\na priori knowledge of the satellite dynamics. This study uses model-free\nReinforcement Learning to train an agent on a constrained pericenter raising\nscenario for a low-thrust medium-Earth-orbit satellite. The agent does not have\nany prior knowledge of the environment dynamics, which makes it unbiased from\nclassical trajectory optimization patterns. The trained agent is then used to\ndesign a trajectory and to autonomously control the satellite during the\ncruise. Simulations show that a dynamics-agnostic agent is able to learn a\nquasi-optimal guidance law and responds well to uncertainties in the\nenvironment dynamics. The results obtained open the door to the usage of\nReinforcement Learning on more complex scenarios, multi-satellite problems, or\nto explore trajectories in environments where a reference solution is not known",
    "descriptor": "",
    "authors": [
      "Carlos M. Casas",
      "Belen Carro",
      "Antonio Sanchez-Esguevillas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08272"
  },
  {
    "id": "arXiv:2211.08273",
    "title": "Matrix Factorization for Cache Optimization in Content Delivery Networks  (CDN)",
    "abstract": "Content delivery networks (CDNs) are key components of high throughput, low\nlatency services on the internet. CDN cache servers have limited storage and\nbandwidth and implement state-of-the-art cache admission and eviction\nalgorithms to select the most popular and relevant content for the customers\nserved. The aim of this study was to utilize state-of-the-art recommender\nsystem techniques for predicting ratings for cache content in CDN. Matrix\nfactorization was used in predicting content popularity which is valuable\ninformation in content eviction and content admission algorithms run on CDN\nedge servers. A custom implemented matrix factorization class and MyMediaLite\nwere utilized. The input CDN logs were received from a European\ntelecommunication service provider. We built a matrix factorization model with\nthat data and utilized grid search to tune its hyper-parameters. Experimental\nresults indicate that there is promise about the proposed approaches and we\nshowed that a low root mean square error value can be achieved on the real-life\nCDN log data.",
    "descriptor": "",
    "authors": [
      "Adolf Kamuzora",
      "Wadie Skaf",
      "Ermiyas Birihanu",
      "Jiyan Mahmud",
      "P\u00e9ter Kiss",
      "Tam\u00e1s Jursonovics",
      "Peter Pogrzeba",
      "Imre Lend\u00e1k",
      "Tom\u00e1\u0161 Horv\u00e1th"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.08273"
  },
  {
    "id": "arXiv:2211.08275",
    "title": "Precise Derivations of Radiative Properties of Porous Media Using  Renewal Theory",
    "abstract": "This work uses the mathematical machinery of Renewal/Ruin (surplus risk)\ntheory to derive preliminary explicit estimations for the radiative properties\nof dilute and disperse porous media otherwise only computable accurately with\nMonte Carlo Ray Tracing (MCRT) simulations. Although random walk and Levy\nprocesses have been extensively used for modeling diffuse processes in various\ntransport problems and porous media modeling, relevance to radiation heat\ntransfer is scarce, as opposed to other problems such as probe diffusion and\npermeability modeling. Furthermore, closed form derivations that lead to\ntangible variance reduction in MCRT are widely missing. The particular angle of\nsurplus risk theory provides a richer apparatus to derive directly related\nquantities. To the best of the authors' knowledge, the current work is the only\nwork relating the surplus risk theory derivations to explicit computations of\nray tracing results in porous media. The paper contains mathematical\nderivations of the radiation heat transfer estimates using the extracted\nmachinery along with proofs and numerical validation using MCRT.",
    "descriptor": "",
    "authors": [
      "Shima Hajimirza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.08275"
  },
  {
    "id": "arXiv:2211.08277",
    "title": "SPADE4: Sparsity and Delay Embedding based Forecasting of Epidemics",
    "abstract": "Predicting the evolution of diseases is challenging, especially when the data\navailability is scarce and incomplete. The most popular tools for modelling and\npredicting infectious disease epidemics are compartmental models. They stratify\nthe population into compartments according to health status and model the\ndynamics of these compartments using dynamical systems. However, these\npredefined systems may not capture the true dynamics of the epidemic due to the\ncomplexity of the disease transmission and human interactions. In order to\novercome this drawback, we propose Sparsity and Delay Embedding based\nForecasting (SPADE4) for predicting epidemics. SPADE4 predicts the future\ntrajectory of an observable variable without the knowledge of the other\nvariables or the underlying system. We use random features model with sparse\nregression to handle the data scarcity issue and employ Takens' delay embedding\ntheorem to capture the nature of the underlying system from the observed\nvariable. We show that our approach outperforms compartmental models when\napplied to both simulated and real data.",
    "descriptor": "\nComments: 22 pages, 12 figures, 2 tables\n",
    "authors": [
      "Esha Saha",
      "Lam Si Tung Ho",
      "Giang Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2211.08277"
  },
  {
    "id": "arXiv:2211.08278",
    "title": "Data-Driven Occupancy Grid Mapping using Synthetic and Real-World Data",
    "abstract": "In perception tasks of automated vehicles (AVs) data-driven have often\noutperformed conventional approaches. This motivated us to develop a\ndata-driven methodology to compute occupancy grid maps (OGMs) from lidar\nmeasurements. Our approach extends previous work such that the estimated\nenvironment representation now contains an additional layer for cells occupied\nby dynamic objects. Earlier solutions could only distinguish between free and\noccupied cells. The information whether an obstacle could move plays an\nimportant role for planning the behavior of an AV. We present two approaches to\ngenerating training data. One approach extends our previous work on using\nsynthetic training data so that OGMs with the three aforementioned cell states\nare generated. The other approach uses manual annotations from the nuScenes\ndataset to create training data. We compare the performance of both models in a\nquantitative analysis on unseen data from the real-world dataset. Next, we\nanalyze the ability of both approaches to cope with a domain shift, i.e. when\npresented with lidar measurements from a different sensor on a different\nvehicle. We propose using information gained from evaluation on real-world data\nto further close the reality gap and create better synthetic data that can be\nused to train occupancy grid mapping models for arbitrary sensor\nconfigurations. Code is available at\nhttps://github.com/ika-rwth-aachen/DEviLOG.",
    "descriptor": "\nComments: Accepted to be published as part of the International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME), Maldives, November 16-18, 2022\n",
    "authors": [
      "Raphael van Kempen",
      "Bastian Lampe",
      "Lennart Reiher",
      "Timo Woopen",
      "Till Beemelmanns",
      "Lutz Eckstein"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08278"
  },
  {
    "id": "arXiv:2211.08279",
    "title": "Towards an objective characterization of an individual's facial  movements using Self-Supervised Person-Specific-Models",
    "abstract": "Disentangling facial movements from other facial characteristics,\nparticularly from facial identity, remains a challenging task, as facial\nmovements display great variation between individuals. In this paper, we aim to\ncharacterize individual-specific facial movements. We present a novel training\napproach to learn facial movements independently of other facial\ncharacteristics, focusing on each individual separately. We propose\nself-supervised Person-Specific Models (PSMs), in which one model per\nindividual can learn to extract an embedding of the facial movements\nindependently of the person's identity and other structural facial\ncharacteristics from unlabeled facial video. These models are trained using\nencoder-decoder-like architectures. We provide quantitative and qualitative\nevidence that a PSM learns a meaningful facial embedding that discovers\nfine-grained movements otherwise not characterized by a General Model (GM),\nwhich is trained across individuals and characterizes general patterns of\nfacial movements. We present quantitative and qualitative evidence that this\napproach is easily scalable and generalizable for new individuals: facial\nmovements knowledge learned on a person can quickly and effectively be\ntransferred to a new person. Lastly, we propose a novel PSM using curriculum\ntemporal learning to leverage the temporal contiguity between video frames. Our\ncode, analysis details, and all pretrained models are available in Github and\nSupplementary Materials.",
    "descriptor": "\nComments: 9 pages for main text with 6 figures + 5 supplementary figures\n",
    "authors": [
      "Yanis Tazi",
      "Michael Berger",
      "Winrich A. Freiwald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08279"
  },
  {
    "id": "arXiv:2211.08282",
    "title": "Homomorphic Self-Supervised Learning",
    "abstract": "In this work, we observe that many existing self-supervised learning\nalgorithms can be both unified and generalized when seen through the lens of\nequivariant representations. Specifically, we introduce a general framework we\ncall Homomorphic Self-Supervised Learning, and theoretically show how it may\nsubsume the use of input-augmentations provided an augmentation-homomorphic\nfeature extractor. We validate this theory experimentally for simple\naugmentations, demonstrate how the framework fails when representational\nstructure is removed, and further empirically explore how the parameters of\nthis framework relate to those of traditional augmentation-based\nself-supervised learning. We conclude with a discussion of the potential\nbenefits afforded by this new perspective on self-supervised learning.",
    "descriptor": "",
    "authors": [
      "T. Anderson Keller",
      "Xavier Suau",
      "Luca Zappella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08282"
  },
  {
    "id": "arXiv:2211.08283",
    "title": "The RED-BLUE SEPARATION problem on graphs",
    "abstract": "We introduce the Red-Blue Separation problem on graphs, where we are given a\ngraph $G=(V,E)$ whose vertices are colored either red or blue, and we want to\nselect a (small) subset $S \\subseteq V$, called red-blue separating set, such\nthat for every red-blue pair of vertices, there is a vertex $s \\in S$ whose\nclosed neighborhood contains exactly one of the two vertices of the pair. We\nstudy the computational complexity of Red-Blue Separation, in which one asks\nwhether a given red-blue colored graph has a red-blue separating set of size at\nmost a given integer. We prove that the problem is NP-complete even for\nrestricted graph classes. We also show that it is always approximable in\npolynomial time within a factor of $2\\ln n$, where $n$ is the input graph's\norder. In contrast, for triangle-free graphs and for graphs of bounded maximum\ndegree, we show that Red-Blue Separation is solvable in polynomial time when\nthe size of the smaller color class is bounded by a constant. However, on\ngeneral graphs, we show that the problem is $W[2]$-hard even when parameterized\nby the solution size plus the size of the smaller color class. We also consider\nthe problem Max Red-Blue Separation where the coloring is not part of the\ninput. Here, given an input graph $G$, we want to determine the smallest\ninteger $k$ such that, for every possible red-blue coloring of $G$, there is a\nred-blue separating set of size at most $k$. We derive tight bounds on the\ncardinality of an optimal solution of Max Red-Blue Separation, showing that it\ncan range from logarithmic in the graph order, up to the order minus one. We\nalso give bounds with respect to related parameters. For trees however we prove\nan upper bound of two-thirds the order. We then show that Max Red-Blue\nSeparation is NP-hard, even for graphs of bounded maximum degree, but can be\napproximated in polynomial time within a factor of $O(\\ln^2 n)$.",
    "descriptor": "",
    "authors": [
      "Subhadeep Ranjan Dev",
      "Sanjana Dey",
      "Florent Foucaud",
      "Ralf Klasing",
      "Tuomo Lehtil\u00e4"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.08283"
  },
  {
    "id": "arXiv:2211.08285",
    "title": "Identifying Spurious Correlations and Correcting them with an  Explanation-based Learning",
    "abstract": "Identifying spurious correlations learned by a trained model is at the core\nof refining a trained model and building a trustworthy model. We present a\nsimple method to identify spurious correlations that have been learned by a\nmodel trained for image classification problems. We apply image-level\nperturbations and monitor changes in certainties of predictions made using the\ntrained model. We demonstrate this approach using an image classification\ndataset that contains images with synthetically generated spurious regions and\nshow that the trained model was overdependent on spurious regions. Moreover, we\nremove the learned spurious correlations with an explanation based learning\napproach.",
    "descriptor": "\nComments: Accepted at the NeurIPS 2022 workshop on Human-in-the-Loop Learning (HILL)\n",
    "authors": [
      "Misgina Tsighe Hagos",
      "Kathleen M. Curran",
      "Brian Mac Namee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08285"
  },
  {
    "id": "arXiv:2211.08287",
    "title": "Towards 3D Object Detection with 2D Supervision",
    "abstract": "The great progress of 3D object detectors relies on large-scale data and 3D\nannotations. The annotation cost for 3D bounding boxes is extremely expensive\nwhile the 2D ones are easier and cheaper to collect. In this paper, we\nintroduce a hybrid training framework, enabling us to learn a visual 3D object\ndetector with massive 2D (pseudo) labels, even without 3D annotations. To break\nthrough the information bottleneck of 2D clues, we explore a new perspective:\nTemporal 2D Supervision. We propose a temporal 2D transformation to bridge the\n3D predictions with temporal 2D labels. Two steps, including homography wraping\nand 2D box deduction, are taken to transform the 3D predictions into 2D ones\nfor supervision. Experiments conducted on the nuScenes dataset show strong\nresults (nearly 90% of its fully-supervised performance) with only 25% 3D\nannotations. We hope our findings can provide new insights for using a large\nnumber of 2D annotations for 3D perception.",
    "descriptor": "",
    "authors": [
      "Jinrong Yang",
      "Tiancai Wang",
      "Zheng Ge",
      "Weixin Mao",
      "Xiaoping Li",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08287"
  },
  {
    "id": "arXiv:2211.08290",
    "title": "Cross-Stitched Multi-task Dual Recursive Networks for Unified Single  Image Deraining and Desnowing",
    "abstract": "We present the Cross-stitched Multi-task Unified Dual Recursive Network\n(CMUDRN) model targeting the task of unified deraining and desnowing in a\nmulti-task learning setting. This unified model borrows from the basic Dual\nRecursive Network (DRN) architecture developed by Cai et al. The proposed model\nmakes use of cross-stitch units that enable multi-task learning across two\nseparate DRN models, each tasked for single image deraining and desnowing,\nrespectively. By fixing cross-stitch units at several layers of basic\ntask-specific DRN networks, we perform multi-task learning over the two\nseparate DRN models. To enable blind image restoration, on top of these\nstructures we employ a simple neural fusion scheme which merges the output of\neach DRN. The separate task-specific DRN models and the fusion scheme are\nsimultaneously trained by enforcing local and global supervision. Local\nsupervision is applied on the two DRN submodules, and global supervision is\napplied on the data fusion submodule of the proposed model. Consequently, we\nboth enable feature sharing across task-specific DRN models and control the\nimage restoration behavior of the DRN submodules. An ablation study shows the\nstrength of the hypothesized CMUDRN model, and experiments indicate that its\nperformance is comparable or better than baseline DRN models on the single\nimage deraining and desnowing tasks. Moreover, CMUDRN enables blind image\nrestoration for the two underlying image restoration tasks, by unifying\ntask-specific image restoration pipelines via a naive parametric fusion scheme.\nThe CMUDRN implementation is available at https://github.com/VCL3D/CMUDRN.",
    "descriptor": "\nComments: 6 pages, 4 figures, conference\n",
    "authors": [
      "Sotiris Karavarsamis",
      "Alexandros Doumanoglou",
      "Konstantinos Konstantoudakis",
      "Dimitrios Zarpalas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08290"
  },
  {
    "id": "arXiv:2211.08292",
    "title": "Mobile-Aware Scheduling for Low Latency Backhaul over DOCSIS",
    "abstract": "In this paper, we discuss latency reduction techniques for mobile backhaul\nover Data Over Cable Service Interface Specifications (DOCSIS) networks. When\nthe latencies from both the wireless and the DOCSIS networks are added\ntogether, it can result in noticeable end-to-end system latency, particularly\nunder network congestion. Previously, we proposed a method to improve upstream\nuser-to-mobile core latency by coordinating the LTE and DOCSIS scheduling. The\nmethod reduces the impact on system latency from the DOCSIS network's\nrequest-grant-data loop, which is the main contributor of backhaul upstream\nlatency. Since the method reduces latency on the DOCSIS data path, it will\ntherefore improve performance of latency sensitive applications, particularly\nif TCP is used as the transport protocol, especially when the link is\ncongested. In this paper, we investigate the effect of HARQ failure on system\nperformance. Through simulation, we show that despite the uncertainty\nintroduced by the LTE protocol, coordinated scheduling improves overall system\nlatency.",
    "descriptor": "\nComments: IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), 2017\n",
    "authors": [
      "Jennifer Andreoli-Fang",
      "John T Chapman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.08292"
  },
  {
    "id": "arXiv:2211.08293",
    "title": "The ATLAS EventIndex: a BigData catalogue for all ATLAS experiment  events",
    "abstract": "The ATLAS EventIndex system comprises the catalogue of all events collected,\nprocessed or generated by the ATLAS experiment at the CERN LHC accelerator, and\nall associated software tools to collect, store and query this information.\nATLAS records several billion particle interactions every year of operation,\nprocesses them for analysis and generates even larger simulated data samples; a\nglobal catalogue is needed to keep track of the location of each event record\nand be able to search and retrieve specific events for in-depth investigations.\nEach EventIndex record includes summary information on the event itself and the\npointers to the files containing the full event. Most components of the\nEventIndex system are implemented using BigData open-source tools. This paper\ndescribes the architectural choices and their evolution in time, as well as the\npast, current and foreseen future implementations of all EventIndex components.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Dario Barberis",
      "Igor Aleksandrov",
      "Evgeny Alexandrov",
      "Zbigniew Baranowski",
      "Luca Canali",
      "Elizaveta Cherepanova",
      "Gancho Dimitrov",
      "Andrea Favareto",
      "Alvaro Fernandez Casani",
      "Elizabeth J. Gallas",
      "Carlos Garcia Montoro",
      "Santiago Gonzalez de la Hoz",
      "Julius Hrivnac",
      "Alexander Iakovlev",
      "Andrei Kazymov",
      "Mikhail Mineev",
      "Fedor Prokoshin",
      "Grigori Rybkin",
      "Jose Salt",
      "Javier Sanchez",
      "Roman Sorokoletov",
      "Rainer Toebbicke",
      "Petya Vasileva",
      "Miguel Villaplana Perez",
      "Ruijun Yuan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2211.08293"
  },
  {
    "id": "arXiv:2211.08295",
    "title": "An FNet based Auto Encoder for Long Sequence News Story Generation",
    "abstract": "In this paper, we design an auto encoder based off of Google's FNet\nArchitecture in order to generate text from a subset of news stories contained\nin Google's C4 dataset. We discuss previous attempts and methods to generate\ntext from autoencoders and non LLM Models. FNET poses multiple advantages to\nBERT based encoders in the realm of efficiency which train 80% faster on GPUs\nand 70% faster on TPUs. We then compare outputs of how this autencoder perfroms\non different epochs. Finally, we analyze what outputs the encoder produces with\ndifferent seed text.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Paul K. Mandal",
      "Rakeshkumar Mahto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08295"
  },
  {
    "id": "arXiv:2211.08296",
    "title": "Deep-Learning Empowered Inverse Design for Freeform Reconfigurable  Metasurfaces",
    "abstract": "The past decade has witnessed the advances of artificial intelligence with\nvarious applications in engineering. Recently, artificial neural network\nempowered inverse design for metasurfaces has been developed that can design\non-demand meta-atoms with diverse shapes and high performance, where the design\nprocess based on artificial intelligence is fast and automatic. However, once\nthe inverse-designed static meta-atom is fabricated, the function of the\nmetasurface is fixed. Reconfigurable metasurfaces can realize dynamic\nfunctions, while applying artificial intelligence to design reconfigurable\nmeta-atoms inversely has not been reported yet. Here, we present a\ndeep-learning empowered inverse design method for freeform reconfigurable\nmetasurfaces, which can generate on-demand reconfigurable coding meta-atoms at\nself-defined frequency bands. To reduce the scale of dataset, a decoupling\nmethod of the reconfigurable meta-atom based on microwave network theory is\nproposed at first, which can convert the inverse design process for\nreconfigurable coding meta-atoms to the inverse design for static structures. A\nconvolutional neural network model is trained to predict the responses of\nfree-shaped meta-atoms, and the genetic algorithm is applied to generate the\noptimal structure patterns rapidly. As a demonstration of concept, several\ninverse-designed examples are generated with different self-defined spectrum\nresponses in microwave band, and an inverse-designed wideband reconfigurable\nmetasurface prototype is fabricated and measured for beam scanning applications\nwith broad bandwidth. Our work paves the way for the fast and automatic design\nprocess of high-performance reconfigurable metasurfaces.",
    "descriptor": "",
    "authors": [
      "Changhao Liu",
      "Fan Yang",
      "Maokun Li",
      "Shenheng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.08296"
  },
  {
    "id": "arXiv:2211.08298",
    "title": "Low Latency Techniques for Mobile Backhaul over DOCSIS",
    "abstract": "The mobile network operators (MNOs) are looking into economically viable\nbackhaul solutions as alternatives to fiber, specifically the hybrid fiber\ncoaxial networks (HFC). When the latencies from both the wireless and the HFC\nnetworks are added together, the result is a noticeable end-to-end system\nlatency, particularly under network congestion. In order to decrease total\nsystem latency, we proposed a method to improve upstream user- to-mobile core\nlatency by coordinating the LTE and HFC scheduling in previous papers. In this\npaper, we implement and optimize the proposed method on a custom LTE and DOCSIS\nend-to-end system testbed. The testbed uses the OpenAirInterface (OAI) platform\nfor the LTE network, along with Cisco's broadband router cBR-8 that is\ncurrently deployed in the HFC networks around the world. Our results show a\nbackhaul latency improvement under all traffic load conditions.",
    "descriptor": "\nComments: IEEE Wireless Communications and Networking Conference (WCNC), 2018\n",
    "authors": [
      "John T Chapman",
      "Jennifer Andreoli-Fang",
      "Michel Chauvin",
      "Elias Chavarria Reyes",
      "Zheng Lu",
      "Dantong Liu",
      "Joey Padden",
      "Alon Bernstein"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.08298"
  },
  {
    "id": "arXiv:2211.08302",
    "title": "Solving clustering as ill-posed problem: experiments with K-Means  algorithm",
    "abstract": "In this contribution, the clustering procedure based on K-Means algorithm is\nstudied as an inverse problem, which is a special case of the illposed\nproblems. The attempts to improve the quality of the clustering inverse problem\ndrive to reduce the input data via Principal Component Analysis (PCA). Since\nthere exists a theorem by Ding and He that links the cardinality of the optimal\nclusters found with K-Means and the cardinality of the selected informative PCA\ncomponents, the computational experiments tested the theorem between two\nquantitative features selection methods: Kaiser criteria (based on imperative\ndecision) versus Wishart criteria (based on random matrix theory). The results\nsuggested that PCA reduction with features selection by Wishart criteria leads\nto a low matrix condition number and satisfies the relation between clusters\nand components predicts by the theorem. The data used for the computations are\nfrom a neuroscientific repository: it regards healthy and young subjects that\nperformed a task-oriented functional Magnetic Resonance Imaging (fMRI)\nparadigm.",
    "descriptor": "",
    "authors": [
      "Alberto Arturo Vergani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08302"
  },
  {
    "id": "arXiv:2211.08304",
    "title": "PARTNR: Pick and place Ambiguity Resolving by Trustworthy iNteractive  leaRning",
    "abstract": "Several recent works show impressive results in mapping language-based human\ncommands and image scene observations to direct robot executable policies\n(e.g., pick and place poses). However, these approaches do not consider the\nuncertainty of the trained policy and simply always execute actions suggested\nby the current policy as the most probable ones. This makes them vulnerable to\ndomain shift and inefficient in the number of required demonstrations. We\nextend previous works and present the PARTNR algorithm that can detect\nambiguities in the trained policy by analyzing multiple modalities in the pick\nand place poses using topological analysis. PARTNR employs an adaptive,\nsensitivity-based, gating function that decides if additional user\ndemonstrations are required. User demonstrations are aggregated to the dataset\nand used for subsequent training. In this way, the policy can adapt promptly to\ndomain shift and it can minimize the number of required demonstrations for a\nwell-trained policy. The adaptive threshold enables to achieve the\nuser-acceptable level of ambiguity to execute the policy autonomously and in\nturn, increase the trustworthiness of our system. We demonstrate the\nperformance of PARTNR in a table-top pick and place task.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 Workshop on Robot Learning; 8 pages; 4 figures; partnr-learn.github.io\n",
    "authors": [
      "Jelle Luijkx",
      "Zlatan Ajanovic",
      "Laura Ferranti",
      "Jens Kober"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08304"
  },
  {
    "id": "arXiv:2211.08308",
    "title": "Covariance-Based Hybrid Beamforming for Spectrally Efficient Joint  Radar-Communications",
    "abstract": "Joint radar-communications (JRC) is considered to be a vital technology in\ndeploying the next generation systems, since its useful in decongestion of the\nradio frequency (RF) spectrum and utilising the same hardware resources for\ndual functions. Using JRC systems for dual function generates interference\nbetween both the operations which needs to be addressed in future\nstandardization. Furthermore, JRC systems can be advanced by deploying hybrid\nbeamforming which implements fewer number of RF chains than the number of\ntransmit antennas. This paper designs a robust hybrid beamformer for minimizing\nthe interference of a JRC transmitter via RF chain selection resulting into\nmutual information maximization. We consider a weighted mutual information for\nthe dual function JRC system and implement a common analog beamformer for both\nthe operations. The mutual information maximization problem is formulated which\nis non-convex and difficult to solve. The problem is simplified to convex form\nand solved using Dinkelbach approximation abased fractional programming. The\nperformance of the optimal RF selection based proposed approach is evaluated,\ncompared with baselines and its effectiveness is inferred via numerical\nresults.",
    "descriptor": "\nComments: 6 pages, conference\n",
    "authors": [
      "Evangelos Vlachos",
      "Aryan Kaushik"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08308"
  },
  {
    "id": "arXiv:2211.08310",
    "title": "Identification of medical devices using machine learning on distribution  feeder data for informing power outage response",
    "abstract": "Power outages caused by extreme weather events due to climate change have\ndoubled in the United States in the last two decades. Outages pose severe\nhealth risks to over 4.4 million individuals dependent on in-home medical\ndevices. Data on the number of such individuals residing in a given area is\nlimited. This study proposes a load disaggregation model to predict the number\nof medical devices behind an electric distribution feeder. This data can be\nused to inform planning and response. The proposed solution serves as a measure\nfor climate change adaptation.",
    "descriptor": "\nComments: To appear in the Tackling Climate Change with Machine Learning workshop at NeurIPS 2022 (Proposals Track) 6 pages, 3 figures\n",
    "authors": [
      "Paraskevi Kourtza",
      "Maitreyee Marathe",
      "Anuj Shetty",
      "Diego Kiedanski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08310"
  },
  {
    "id": "arXiv:2211.08314",
    "title": "Extracting task trees using knowledge retrieval search algorithms in  functional object-oriented network",
    "abstract": "The functional object-oriented network (FOON) has been developed as a\nknowledge representation method that can be used by robots in order to perform\ntask planning. A FOON can be observed as a graph that can provide an ordered\nplan for robots to retrieve a task tree, through the knowledge retrieval\nprocess. We compare two search algorithms to evaluate their performance in\nextracting task trees: iterative deepening search (IDS) and greedy best-first\nsearch (GBFS) with two different heuristic functions. Then, we determine which\nalgorithm is capable of obtaining a task tree for various cooking recipes using\nthe least number of functional units. Preliminary results show that each\nalgorithm can perform better than the other, depending on the recipe provided\nto the search algorithm.",
    "descriptor": "\nComments: 5 pages, 8 figures, 8 tables\n",
    "authors": [
      "Tyree Lewis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08314"
  },
  {
    "id": "arXiv:2211.08316",
    "title": "FolkScope: Intention Knowledge Graph Construction for Discovering  E-commerce Commonsense",
    "abstract": "As stated by Oren Etzioni, ``commonsense is the dark matter of artificial\nintelligence''. In e-commerce, understanding users' needs or intentions\nrequires substantial commonsense knowledge, e.g., ``A user bought an iPhone and\na compatible case because the user wanted the phone to be protected''. In this\npaper, we present FolkScope, an intention knowledge graph construction\nframework, to reveal the structure of humans' minds about purchasing items on\ne-commerce platforms such as Amazon. As commonsense knowledge is usually\nineffable and not expressed explicitly, it is challenging to perform any kind\nof information extraction. Thus, we propose a new approach that leverages the\ngeneration power of large-scale language models and human-in-the-loop\nannotations to semi-automatically construct the knowledge graph. We annotate a\nlarge amount of assertions for both plausibility and typicality of an intention\nthat can explain a purchasing or co-purchasing behavior, where the intention\ncan be an open reason or a predicate falling into one of 18 categories aligning\nwith ConceptNet, e.g., IsA, MadeOf, UsedFor, etc. Then we populate the\nannotated information to all automatically generated ones, and further\nstructurize the assertions using pattern mining and conceptualization to form\nmore condensed and abstractive knowledge. We evaluate our knowledge graph using\nboth intrinsic quality measures and a downstream application, i.e.,\nrecommendation. The comprehensive study shows that our knowledge graph can well\nmodel e-commerce commonsense knowledge and can have many potential\napplications.",
    "descriptor": "",
    "authors": [
      "Changlong Yu",
      "Weiqi Wang",
      "Xin Liu",
      "Jiaxin Bai",
      "Yangqiu Song",
      "Zheng Li",
      "Yifan Gao",
      "Tianyu Cao",
      "Bing Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08316"
  },
  {
    "id": "arXiv:2211.08319",
    "title": "Reduced order modeling inversion of mono static data in a  multi-scattering environment",
    "abstract": "The data-driven reduced order models (ROMs) have recently emerged as an\nefficient tool for the solution of the inverse scattering problems with\napplications to seismic and sonar imaging. One specification of this approach\nis that it requires the full square multiple-output/multiple-input (MIMO)\nmatrix valued transfer function as data for multidimensional problems. The\nsynthetic aperture radar (SAR), however, is limited to single input/single\noutput (SISO) measurements corresponding to the diagonal of the matrix transfer\nfunction. Here we present a ROM based Lippmann-Schwinger approach overcoming\nthis drawback. The ROMs are constructed to match the data for each\nsource-receiver pair separately, and these are used to construct internal\nsolutions for the corresponding source using only the data-driven Gramian.\nEfficiency of the proposed approach is demonstrated on 2D and 2.5D (3D\npropagation and 2D reflectors) numerical examples. The new algorithm not only\nsuppresses multiple echoes seen in the Born imaging, but also takes advantage\nof illumination by them of some back sides of the reflectors, improving the\nquality of their mapping.",
    "descriptor": "",
    "authors": [
      "V. Druskin",
      "S. Moskow",
      "M. Zaslavsky"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.08319"
  },
  {
    "id": "arXiv:2211.08321",
    "title": "Simulated Mental Imagery for Robotic Task Planning",
    "abstract": "Traditional AI-planning methods for task planning in robotics require\nstrictly defined symbolic structural elements. While powerful in well-defined\nscenarios, setting this up requires substantial effort. Different from this,\nmost everyday planning tasks are solved by humans intuitively, using mental\nimagery of the different planning steps. Here we suggest that the same approach\ncan be used for robots, too, in cases which require only limited execution\naccuracy. In the current study, we propose a novel sub-symbolic method called\nSimulated Mental Imagery for Planning (SiMIP), which consists of several steps:\nperception, simulated action, success-checking and re-planning performed on\n'imagined' images. We show that it is possible this way to implement mental\nimagery-based planning in an algorithmically sound way by combining regular\nconvolutional neural networks and generative adversarial networks. With this\nmethod, the robot acquires the capability to use the initially existing scene\nto generate action plans without symbolic domain descriptions, hence, without\nthe need to define an explicit representation of the environment. We create a\ndataset from real scenes for a packing problem of having to correctly place\ndifferent objects into different target slots. This way efficiency and success\nrate of this algorithm could be quantified.",
    "descriptor": "",
    "authors": [
      "Shjia Li",
      "Tomas Kulvicius",
      "Minija Tamosiunaite",
      "Florentin W\u00f6rg\u00f6tter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08321"
  },
  {
    "id": "arXiv:2211.08324",
    "title": "Approximating Flexible Graph Connectivity via R\u00e4cke Tree based  Rounding",
    "abstract": "Flexible graph connectivity is a new network design model introduced by\nAdjiashvili. It has seen several recent algorithmic advances. Despite these,\nthe approximability even in the setting of a single-pair $(s,t)$ is poorly\nunderstood. In our recent work, we raised the question of whether there is\npoly-logarithmic approximation for the survivable network design version\n(Flex-SNDP) when the connectivity requirements are fixed constants. In this\npaper, we adapt a powerful framework for survivable network design recently\ndeveloped by Chen, Laekhanukit, Liao, and Zhang to give an affirmative answer\nto the question. The framework of is based on R\\\"acke trees and group Steiner\ntree rounding. The algorithm and analysis also establishes an upper bound on\nthe integrality gap of an LP relaxation for Flex-SNDP.",
    "descriptor": "",
    "authors": [
      "Chandra Chekuri",
      "Rhea Jain"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.08324"
  },
  {
    "id": "arXiv:2211.08327",
    "title": "Weighted Sum-Rate Maximization With Causal Inference for Latent  Interference Estimation",
    "abstract": "The paper investigates the weighted sum-rate maximization (WSRM) problem with\nlatent interfering sources outside the known network, whose power allocation\npolicy is hidden from and uncontrollable to optimization. The paper extends the\nfamous alternate optimization algorithm weighted minimum mean square error\n(WMMSE) [1] under a causal inference framework to tackle with WSRM under latent\ninterference. Namely, with the possibility of power policy shifting in the\nhidden network, computing an iterating direction based on the observed\ninterference inherently implies that counterfactual is ignored in decision\nmaking. A synthetic control (SC) method is used to estimate the counterfactual.\nFor any link in the known network, SC constructs a convex combination of the\ninterference on other links and uses it as an estimate. Power iteration is\nperformed on the estimated rather than the observed interference. The proposed\nSC-WMMSE requires no more information than its origin. To our best knowledge,\nthis is the first paper explores the potential of causal inference to assist\nmathematical optimization in addressing classic wireless optimization problems.\nNumerical results suggest the superiority of the SC-WMMSE over the original in\nboth convergence and objective.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Lei You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08327"
  },
  {
    "id": "arXiv:2211.08332",
    "title": "Versatile Diffusion: Text, Images and Variations All in One Diffusion  Model",
    "abstract": "The recent advances in diffusion models have set an impressive milestone in\nmany generation tasks. Trending works such as DALL-E2, Imagen, and Stable\nDiffusion have attracted great interest in academia and industry. Despite the\nrapid landscape changes, recent new approaches focus on extensions and\nperformance rather than capacity, thus requiring separate models for separate\ntasks. In this work, we expand the existing single-flow diffusion pipeline into\na multi-flow network, dubbed Versatile Diffusion (VD), that handles\ntext-to-image, image-to-text, image-variation, and text-variation in one\nunified model. Moreover, we generalize VD to a unified multi-flow multimodal\ndiffusion framework with grouped layers, swappable streams, and other\npropositions that can process modalities beyond images and text. Through our\nexperiments, we demonstrate that VD and its underlying framework have the\nfollowing merits: a) VD handles all subtasks with competitive quality; b) VD\ninitiates novel extensions and applications such as disentanglement of style\nand semantic, image-text dual-guided generation, etc.; c) Through these\nexperiments and applications, VD provides more semantic insights of the\ngenerated outputs. Our code and models are open-sourced at\nhttps://github.com/SHI-Labs/Versatile-Diffusion.",
    "descriptor": "\nComments: Github link: this https URL\n",
    "authors": [
      "Xingqian Xu",
      "Zhangyang Wang",
      "Eric Zhang",
      "Kai Wang",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08332"
  },
  {
    "id": "arXiv:2211.08339",
    "title": "Pruning Very Deep Neural Network Channels for Efficient Inference",
    "abstract": "In this paper, we introduce a new channel pruning method to accelerate very\ndeep convolutional neural networks. Given a trained CNN model, we propose an\niterative two-step algorithm to effectively prune each layer, by a LASSO\nregression based channel selection and least square reconstruction. We further\ngeneralize this algorithm to multi-layer and multi-branch cases. Our method\nreduces the accumulated error and enhances the compatibility with various\narchitectures. Our pruned VGG-16 achieves the state-of-the-art results by 5x\nspeed-up along with only 0.3% increase of error. More importantly, our method\nis able to accelerate modern networks like ResNet, Xception and suffers only\n1.4%, 1.0% accuracy loss under 2x speed-up respectively, which is significant.\nOur code has been made publicly available.",
    "descriptor": "\nComments: an extension of Channel Pruning for Accelerating Very Deep Neural Networks. arXiv admin note: substantial text overlap with arXiv:1707.06168\n",
    "authors": [
      "Yihui He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08339"
  },
  {
    "id": "arXiv:2211.08349",
    "title": "Probabilistic Deep Metric Learning for Hyperspectral Image  Classification",
    "abstract": "This paper proposes a probabilistic deep metric learning (PDML) framework for\nhyperspectral image classification, which aims to predict the category of each\npixel for an image captured by hyperspectral sensors. The core problem for\nhyperspectral image classification is the spectral variability between\nintraclass materials and the spectral similarity between interclass materials,\nmotivating the further incorporation of spatial information to differentiate a\npixel based on its surrounding patch. However, different pixels and even the\nsame pixel in one patch might not encode the same material due to the low\nspatial resolution of most hyperspectral sensors, leading to an inconsistent\njudgment of a specific pixel. To address this issue, we propose a probabilistic\ndeep metric learning framework to model the categorical uncertainty of the\nspectral distribution of an observed pixel. We propose to learn a global\nprobabilistic distribution for each pixel in the patch and a probabilistic\nmetric to model the distance between distributions. We treat each pixel in a\npatch as a training sample, enabling us to exploit more information from the\npatch compared with conventional methods. Our framework can be readily applied\nto existing hyperspectral image classification methods with various network\narchitectures and loss functions. Extensive experiments on four widely used\ndatasets including IN, UP, KSC, and Houston 2013 datasets demonstrate that our\nframework improves the performance of existing methods and further achieves the\nstate of the art. Code is available at: https://github.com/wzzheng/PDML.",
    "descriptor": "\nComments: Code is available at: this https URL\n",
    "authors": [
      "Chengkun Wang",
      "Wenzhao Zheng",
      "Xian Sun",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08349"
  },
  {
    "id": "arXiv:2211.08350",
    "title": "Motor imagery classification using EEG spectrograms",
    "abstract": "The loss of limb motion arising from damage to the spinal cord is a\ndisability that could effect people while performing their day-to-day\nactivities. The restoration of limb movement would enable people with spinal\ncord injury to interact with their environment more naturally and this is where\na brain-computer interface (BCI) system could be beneficial. The detection of\nlimb movement imagination (MI) could be significant for such a BCI, where the\ndetected MI can guide the computer system. Using MI detection through\nelectroencephalography (EEG), we can recognize the imagination of movement in a\nuser and translate this into a physical movement. In this paper, we utilize\npre-trained deep learning (DL) algorithms for the classification of imagined\nupper limb movements. We use a publicly available EEG dataset with data\nrepresenting seven classes of limb movements. We compute the spectrograms of\nthe time series EEG signal and use them as an input to the DL model for MI\nclassification. Our novel approach for the classification of upper limb\nmovements using pre-trained DL algorithms and spectrograms has achieved\nsignificantly improved results for seven movement classes. When compared with\nthe recently proposed state-of-the-art methods, our algorithm achieved a\nsignificant average accuracy of 84.9% for classifying seven movements.",
    "descriptor": "\nComments: Submitted to ISBI 2023\n",
    "authors": [
      "Saadat Ullah Khan",
      "Muhammad Majid",
      "Syed Muhammad Anwar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.08350"
  },
  {
    "id": "arXiv:2211.08352",
    "title": "Visual Semantic Segmentation Based on Few/Zero-Shot Learning: An  Overview",
    "abstract": "Visual semantic segmentation aims at separating a visual sample into diverse\nblocks with specific semantic attributes and identifying the category for each\nblock, and it plays a crucial role in environmental perception. Conventional\nlearning-based visual semantic segmentation approaches count heavily on\nlarge-scale training data with dense annotations and consistently fail to\nestimate accurate semantic labels for unseen categories. This obstruction spurs\na craze for studying visual semantic segmentation with the assistance of\nfew/zero-shot learning. The emergence and rapid progress of few/zero-shot\nvisual semantic segmentation make it possible to learn unseen-category from a\nfew labeled or zero-labeled samples, which advances the extension to practical\napplications. Therefore, this paper focuses on the recently published\nfew/zero-shot visual semantic segmentation methods varying from 2D to 3D space\nand explores the commonalities and discrepancies of technical settlements under\ndifferent segmentation circumstances. Specifically, the preliminaries on\nfew/zero-shot visual semantic segmentation, including the problem definitions,\ntypical datasets, and technical remedies, are briefly reviewed and discussed.\nMoreover, three typical instantiations are involved to uncover the interactions\nof few/zero-shot learning with visual semantic segmentation, including image\nsemantic segmentation, video object segmentation, and 3D segmentation. Finally,\nthe future challenges of few/zero-shot visual semantic segmentation are\ndiscussed.",
    "descriptor": "",
    "authors": [
      "Wenqi Ren",
      "Yang Tang",
      "Qiyu Sun",
      "Chaoqiang Zhao",
      "Qing-Long Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08352"
  },
  {
    "id": "arXiv:2211.08357",
    "title": "Improving AFL++ CmpLog: Tackling the bottlenecks",
    "abstract": "The performance of the AFL++ CmpLog feature varies considerably for specific\nprograms under test (PUTs). In this paper it is demonstrated that the main\ncause of the poor performance is low seed entropy, and a lack of deduplication\nof magic bytes candidates. An improvement is proposed by mapping comparisons to\ninput bytes, in order to track which comparisons are controlled by what input\nbytes. This mapping is then used to fuzz only the comparison values that are\nmagic byte candidates for that input part. Second, a caching mechanism is\nintroduced to reduce the number of redundant executions. The evaluation of the\nimproved versions shows a significant coverage gain compared to the original\nAFL++ implementation of CmpLog for all PUTs, without breaking functionality.\nThe proposed solution in this paper provides a solid basis for a redesign of\nCmpLog.",
    "descriptor": "",
    "authors": [
      "Sander Wiebing",
      "Thomas Rooijakkers",
      "Sebastiaan Tesink"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.08357"
  },
  {
    "id": "arXiv:2211.08358",
    "title": "MEAL: Stable and Active Learning for Few-Shot Prompting",
    "abstract": "Few-shot classification in NLP has recently made great strides due to the\navailability of large foundation models that, through priming and prompting,\nare highly effective few-shot learners. However, this approach has high\nvariance across different sets of few shots and across different finetuning\nruns. For example, we find that validation accuracy on RTE can vary by as much\nas 27 points. In this context, we make two contributions for more effective\nfew-shot learning. First, we propose novel ensembling methods and show that\nthey substantially reduce variance. Second, since performance depends a lot on\nthe set of few shots selected, active learning is promising for few-shot\nclassification. Based on our stable ensembling method, we build on existing\nwork on active learning and introduce a new criterion: inter-prompt uncertainty\nsampling with diversity. We present the first active learning based approach to\nselect training examples for prompt-based learning and show that it outperforms\nprior work on active learning. Finally, we show that our combined method, MEAL\n(Multiprompt finetuning and prediction Ensembling with Active Learning),\nimproves overall performance of prompt-based finetuning by 2.3 absolute points\non five different tasks.",
    "descriptor": "",
    "authors": [
      "Abdullatif K\u00f6ksal",
      "Timo Schick",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08358"
  },
  {
    "id": "arXiv:2211.08360",
    "title": "An environmental disturbance observer framework for autonomous ships",
    "abstract": "This paper proposes a robust disturbance observer framework for maritime\nautonomous surface ships considering model and measurement uncertainties. The\ncore contribution lies in a nonlinear disturbance observer, reconstructing the\nforces on a ship impacted by the environment, such as wind, waves, and sea\ncurrents. For this purpose, mappings are found that describe global\nexponentially stable error dynamics by assuming slow changes of disturbances.\nWith the stability theory of Lyapunov, it is proven that the error converges\nexponentially into a ball, even if the disturbances are highly dynamic. Since\nmeasurements are affected by noise and physical models can be erroneous, the\nmeasurements are filtered through an unscented Kalman filter and propagated\nthrough the proposed observer to deal with noisy measurements and inaccurate\nmodels. To investigate the capability of this observer framework, the\nenvironmental disturbances are simulated at different severity levels. The\nresults depict the simulation of a severe, worst-case scenario consisting of\nhighly dynamic disturbances, intense measurement noise, and an unreliable ship\nmodel. It can be seen that the observer framework accurately reconstructs the\nforces on a ship impacted by the environment despite using a low measurement\nsampling rate, an erroneous model, and uncertain measurements.",
    "descriptor": "",
    "authors": [
      "Daniel Menges",
      "Adil Rasheed"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08360"
  },
  {
    "id": "arXiv:2211.08361",
    "title": "Collaborative and AI-aided Exam Question Generation using Wikidata in  Education",
    "abstract": "Since the COVID-19 outbreak, the use of digital learning or education\nplatforms has significantly increased. Teachers now digitally distribute\nhomework and provide exercise questions. In both cases, teachers need to\ncontinuously develop novel and individual questions. This process can be very\ntime-consuming and should be facilitated and accelerated both through exchange\nwith other teachers and by using Artificial Intelligence (AI) capabilities. To\naddress this need, we propose a multilingual Wikimedia framework that allows\nfor collaborative worldwide teacher knowledge engineering and subsequent\nAI-aided question generation, test, and correction. As a proof of concept, we\npresent >>PhysWikiQuiz<<, a physics question generation and test engine. Our\nsystem (hosted by Wikimedia at https://physwikiquiz.wmflabs.org) retrieves\nphysics knowledge from the open community-curated database Wikidata. It can\ngenerate questions in different variations and verify answer values and units\nusing a Computer Algebra System (CAS). We evaluate the performance on a public\nbenchmark dataset at each stage of the system workflow. For an average formula\nwith three variables, the system can generate and correct up to 300 questions\nfor individual students based on a single formula concept name as input by the\nteacher.",
    "descriptor": "",
    "authors": [
      "Philipp Scharpf",
      "Moritz Schubotz",
      "Andreas Spitz",
      "Andre Greiner-Petter",
      "Bela Gipp"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.08361"
  },
  {
    "id": "arXiv:2211.08365",
    "title": "Classifying text using machine learning models and determining  conversation drift",
    "abstract": "Text classification helps analyse texts for semantic meaning and relevance,\nby mapping the words against this hierarchy. An analysis of various types of\ntexts is invaluable to understanding both their semantic meaning, as well as\ntheir relevance. Text classification is a method of categorising documents. It\ncombines computer text classification and natural language processing to\nanalyse text in aggregate. This method provides a descriptive categorization of\nthe text, with features like content type, object field, lexical\ncharacteristics, and style traits. In this research, the authors aim to use\nnatural language feature extraction methods in machine learning which are then\nused to train some of the basic machine learning models like Naive Bayes,\nLogistic Regression, and Support Vector Machine. These models are used to\ndetect when a teacher must get involved in a discussion when the lines go\noff-topic.",
    "descriptor": "\nComments: The Paper has been ACCEPTED at the \"2nd International Conference on Computing and Communication Networks(ICCCN-2022)\". This paper will be published by AIP publishing and DOI will be issued later on\n",
    "authors": [
      "Chaitanya Chadha",
      "Vandit Gupta",
      "Deepak Gupta",
      "Ashish Khanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08365"
  },
  {
    "id": "arXiv:2211.08366",
    "title": "User-Specific Bicluster-based Collaborative Filtering: Handling  Preference Locality, Sparsity and Subjectivity",
    "abstract": "Collaborative Filtering (CF), the most common approach to build Recommender\nSystems, became pervasive in our daily lives as consumers of products and\nservices. However, challenges limit the effectiveness of Collaborative\nFiltering approaches when dealing with recommendation data, mainly due to the\ndiversity and locality of user preferences, structural sparsity of user-item\nratings, subjectivity of rating scales, and increasingly high item\ndimensionality and user bases. To answer some of these challenges, some authors\nproposed successful approaches combining CF with Biclustering techniques.\nThis work assesses the effectiveness of Biclustering approaches for CF,\ncomparing the impact of algorithmic choices, and identifies principles for\nsuperior Biclustering-based CF. As a result, we propose USBFC, a\nBiclustering-based CF approach that creates user-specific models from strongly\ncoherent and statistically significant rating patterns, corresponding to\nsubspaces of shared preferences across users. Evaluation on real-world data\nreveals that USBCF achieves competitive predictive accuracy against\nstate-of-the-art CF methods. Moreover, USBFC successfully suppresses the main\nshortcomings of the previously proposed state-of-the-art biclustering-based CF\nby increasing coverage, and coclustering-based CF by strengthening subspace\nhomogeneity.",
    "descriptor": "",
    "authors": [
      "Miguel G. Silva",
      "Rui Henriques",
      "Sara C. Madeira"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08366"
  },
  {
    "id": "arXiv:2211.08367",
    "title": "FlowGrad: Using Motion for Visual Sound Source Localization",
    "abstract": "Most recent work in visual sound source localization relies on semantic\naudio-visual representations learned in a self-supervised manner, and by design\nexcludes temporal information present in videos. While it proves to be\neffective for widely used benchmark datasets, the method falls short for\nchallenging scenarios like urban traffic. This work introduces temporal context\ninto the state-of-the-art methods for sound source localization in urban scenes\nusing optical flow as a means to encode motion information. An analysis of the\nstrengths and weaknesses of our methods helps us better understand the problem\nof visual sound source localization and sheds light on open challenges for\naudio-visual scene understanding.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Rajsuryan Singh",
      "Pablo Zinemanas",
      "Xavier Serra",
      "Juan Pablo Bello",
      "Magdalena Fuentes"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08367"
  },
  {
    "id": "arXiv:2211.08368",
    "title": "A Survey on the Integration of Machine Learning with Sampling-based  Motion Planning",
    "abstract": "Sampling-based methods are widely adopted solutions for robot motion\nplanning. The methods are straightforward to implement, effective in practice\nfor many robotic systems. It is often possible to prove that they have\ndesirable properties, such as probabilistic completeness and asymptotic\noptimality. Nevertheless, they still face challenges as the complexity of the\nunderlying planning problem increases, especially under tight computation time\nconstraints, which impact the quality of returned solutions or given inaccurate\nmodels. This has motivated machine learning to improve the computational\nefficiency and applicability of Sampling-Based Motion Planners (SBMPs). This\nsurvey reviews such integrative efforts and aims to provide a classification of\nthe alternative directions that have been explored in the literature. It first\ndiscusses how learning has been used to enhance key components of SBMPs, such\nas node sampling, collision detection, distance or nearest neighbor\ncomputation, local planning, and termination conditions. Then, it highlights\nplanners that use learning to adaptively select between different\nimplementations of such primitives in response to the underlying problem's\nfeatures. It also covers emerging methods, which build complete machine\nlearning pipelines that reflect the traditional structure of SBMPs. It also\ndiscusses how machine learning has been used to provide data-driven models of\nrobots, which can then be used by a SBMP. Finally, it provides a comparative\ndiscussion of the advantages and disadvantages of the approaches covered, and\ninsights on possible future directions of research. An online version of this\nsurvey can be found at: https://prx-kinodynamic.github.io/",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Troy McMahon",
      "Aravind Sivaramakrishnan",
      "Edgar Granados",
      "Kostas E. Bekris"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08368"
  },
  {
    "id": "arXiv:2211.08369",
    "title": "Easy to Decide, Hard to Agree: Reducing Disagreements Between Saliency  Methods",
    "abstract": "A popular approach to unveiling the black box of neural NLP models is to\nleverage saliency methods, which assign scalar importance scores to each input\ncomponent. A common practice for evaluating whether an interpretability method\nis \\textit{faithful} and \\textit{plausible} has been to use\nevaluation-by-agreement -- multiple methods agreeing on an explanation\nincreases its credibility. However, recent work has found that even saliency\nmethods have weak rank correlations and advocated for the use of alternative\ndiagnostic methods. In our work, we demonstrate that rank correlation is not a\ngood fit for evaluating agreement and argue that Pearson-$r$ is a better suited\nalternative. We show that regularization techniques that increase faithfulness\nof attention explanations also increase agreement between saliency methods.\nThrough connecting our findings to instance categories based on training\ndynamics we show that, surprisingly, easy-to-learn instances exhibit low\nagreement in saliency method explanations.",
    "descriptor": "",
    "authors": [
      "Josip Juki\u0107",
      "Martin Tutek",
      "Jan \u0160najder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08369"
  },
  {
    "id": "arXiv:2211.08370",
    "title": "Methodological proposal to identify the nationality of Twitter users  through Random-Forests",
    "abstract": "We disclose a methodology to determine the participants in discussions and\ntheir contributions in social networks with a local relationship (e.g.,\nnationality), providing certain levels of trust and efficiency in the process.\nThe dynamic is a challenge that has demanded studies and some approximations to\nrecent solutions. The study addressed the problem of identifying the\nnationality of users in the Twitter social network before an opinion request\n(of a political nature and social participation). The employed methodology\nclassifies, via machine learning, the Twitter users' nationality to carry out\nopinion studies in three Central American countries. The Random Forests\nalgorithm is used to generate classification models with small training\nsamples, using exclusively numerical characteristics based on the number of\ntimes that different interactions among users occur. When averaging the\nproportions achieved by inferences of the ratio of nationals of each country,\nin the initial data, an average of 77.40% was calculated, compared to 91.60%\naveraged after applying the automatic classification model, an average increase\nof 14.20%. In conclusion, it can be seen that the suggested set of method\nprovides a reasonable approach and efficiency in the face of opinion problems.",
    "descriptor": "\nComments: 31 pages, 10 figures, 4 tables\n",
    "authors": [
      "Dami\u00e1n Quijano",
      "Richard Gil-Herrera"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08370"
  },
  {
    "id": "arXiv:2211.08371",
    "title": "Pragmatics in Grounded Language Learning: Phenomena, Tasks, and Modeling  Approaches",
    "abstract": "People rely heavily on context to enrich meaning beyond what is literally\nsaid, enabling concise but effective communication. To interact successfully\nand naturally with people, user-facing artificial intelligence systems will\nrequire similar skills in pragmatics: relying on various types of context --\nfrom shared linguistic goals and conventions, to the visual and embodied world\n-- to use language effectively.\nWe survey existing grounded settings and pragmatic modeling approaches and\nanalyze how the task goals, environmental contexts, and communicative\naffordances in each work enrich linguistic meaning. We present recommendations\nfor future grounded task design to naturally elicit pragmatic phenomena, and\nsuggest directions that focus on a broader range of communicative contexts and\naffordances.",
    "descriptor": "",
    "authors": [
      "Daniel Fried",
      "Nicholas Tomlin",
      "Jennifer Hu",
      "Roma Patel",
      "Aida Nematzadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08371"
  },
  {
    "id": "arXiv:2211.08373",
    "title": "SDPs and Robust Satisfiability of Promise CSP",
    "abstract": "For a constraint satisfaction problem (CSP), a robust satisfaction algorithm\nis one that outputs an assignment satisfying most of the constraints on\ninstances that are near-satisfiable. It is known that the CSPs that admit\nefficient robust satisfaction algorithms are precisely those of bounded width,\ni.e., CSPs whose satisfiability can be checked by a simple local consistency\nalgorithm (eg., 2-SAT or Horn-SAT in the Boolean case). While the exact\nsatisfiability of a bounded width CSP can be checked by combinatorial\nalgorithms, the robust algorithm is based on rounding a canonical Semidefinite\nprogramming(SDP) relaxation.\nIn this work, we initiate the study of robust satisfaction algorithms for\npromise CSPs, which are a vast generalization of CSPs that have received much\nattention recently. The motivation is to extend the theory beyond CSPs, as well\nas to better understand the power of SDPs. We present robust SDP rounding\nalgorithms under some general conditions, namely the existence of majority or\nalternating threshold polymorphisms. On the hardness front, we prove that the\nlack of such polymorphisms makes the PCSP hard for all pairs of symmetric\nBoolean predicates. Our method involves a novel method to argue SDP gaps via\nthe absence of certain colorings of the sphere, with connections to sphere\nRamsey theory.\nWe conjecture that PCSPs with robust satisfaction algorithms are precisely\nthose for which the feasibility of the canonical SDP implies (exact)\nsatisfiability. We also give a precise algebraic condition, known as a minion\ncharacterization, of which PCSPs have the latter property.",
    "descriptor": "\nComments: 60 pages\n",
    "authors": [
      "Joshua Brakensiek",
      "Venkatesan Guruswami",
      "Sai Sandeep"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.08373"
  },
  {
    "id": "arXiv:2211.08375",
    "title": "Stability and convergence of the Euler scheme for stochastic linear  evolution equations in Banach spaces",
    "abstract": "For the Euler scheme of the stochastic linear evolution equations, discrete\nstochastic maximal $ L^p $-regularity estimate is established, and a sharp\nerror estimate in the norm $ \\|\\cdot\\|_{L^p((0,T)\\times\\Omega;L^q(\\mathcal O))}\n$, $ p,q \\in [2,\\infty) $, is derived via a duality argument.",
    "descriptor": "",
    "authors": [
      "Binjie Li",
      "Xiaoping Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.08375"
  },
  {
    "id": "arXiv:2211.08378",
    "title": "Anomaly Detection in Multiplex Dynamic Networks: from Blockchain  Security to Brain Disease Prediction",
    "abstract": "The problem of identifying anomalies in dynamic networks is a fundamental\ntask with a wide range of applications. However, it raises critical challenges\ndue to the complex nature of anomalies, lack of ground truth knowledge, and\ncomplex and dynamic interactions in the network. Most existing approaches\nusually study networks with a single type of connection between vertices, while\nin many applications interactions between objects vary, yielding multiplex\nnetworks. We propose ANOMULY, a general, unsupervised edge anomaly detection\nframework for multiplex dynamic networks. In each relation type, ANOMULY sees\nnode embeddings at different GNN layers as hierarchical node states and employs\na GRU cell to capture temporal properties of the network and update node\nembeddings over time. We then add an attention mechanism that incorporates\ninformation across different types of relations. Our case study on brain\nnetworks shows how this approach could be employed as a new tool to understand\nabnormal brain activity that might reveal a brain disease or disorder.\nExtensive experiments on nine real-world datasets demonstrate that ANOMULY\nachieves state-of-the-art performance.",
    "descriptor": "\nComments: NeurIPS 2022 Temporal Graph Learning Workshop (Spotlight)\n",
    "authors": [
      "Ali Behrouz",
      "Margo Seltzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08378"
  },
  {
    "id": "arXiv:2211.08379",
    "title": "Music Instrument Classification Reprogrammed",
    "abstract": "The performance of approaches to Music Instrument Classification, a popular\ntask in Music Information Retrieval, is often impacted and limited by the lack\nof availability of annotated data for training. We propose to address this\nissue with \"reprogramming,\" a technique that utilizes pre-trained deep and\ncomplex neural networks originally targeting a different task by modifying and\nmapping both the input and output of the pre-trained model. We demonstrate that\nreprogramming can effectively leverage the power of the representation learned\nfor a different task and that the resulting reprogrammed system can perform on\npar or even outperform state-of-the-art systems at a fraction of training\nparameters. Our results, therefore, indicate that reprogramming is a promising\ntechnique potentially applicable to other tasks impeded by data scarcity.",
    "descriptor": "\nComments: Accepted at 29th International Conference on Multimedia Modeling (MMM23)\n",
    "authors": [
      "Hsin-Hung Chen",
      "Alexander Lerch"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08379"
  },
  {
    "id": "arXiv:2211.08380",
    "title": "Empowering Language Models with Knowledge Graph Reasoning for Question  Answering",
    "abstract": "Answering open-domain questions requires world knowledge about in-context\nentities. As pre-trained Language Models (LMs) lack the power to store all\nrequired knowledge, external knowledge sources, such as knowledge graphs, are\noften used to augment LMs. In this work, we propose knOwledge REasOning\nempowered Language Model (OREO-LM), which consists of a novel Knowledge\nInteraction Layer that can be flexibly plugged into existing Transformer-based\nLMs to interact with a differentiable Knowledge Graph Reasoning module\ncollaboratively. In this way, LM guides KG to walk towards the desired answer,\nwhile the retrieved knowledge improves LM. By adopting OREO-LM to RoBERTa and\nT5, we show significant performance gain, achieving state-of-art results in the\nClosed-Book setting. The performance enhancement is mainly from the KG\nreasoning's capacity to infer missing relational facts. In addition, OREO-LM\nprovides reasoning paths as rationales to interpret the model's decision.",
    "descriptor": "\nComments: Published on EMNLP 2022\n",
    "authors": [
      "Ziniu Hu",
      "Yichong Xu",
      "Wenhao Yu",
      "Shuohang Wang",
      "Ziyi Yang",
      "Chenguang Zhu",
      "Kai-Wei Chang",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08380"
  },
  {
    "id": "arXiv:2211.08381",
    "title": "Optimizing Polymatroid Functions",
    "abstract": "We consider a class of optimization problems that involve determining the\nmaximum value that a function in a particular class can attain subject to a\ncollection of difference constraints. We show that a particular linear\nprogramming technique, based on duality and projections, can be used to\nrederive some structural results that were previously established using more ad\nhoc methods. We then show that this technique can be used to obtain a\npolynomial-time algorithm for a certain type of simple difference constraints.\nFinally we give lower bound results that show that certain possible extensions\nof these results are probably not feasible.",
    "descriptor": "",
    "authors": [
      "Sungjin Im",
      "Benjamin Moseley",
      "Hung Q. Ngo",
      "Kirk Pruhs",
      "Alireza Samadian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.08381"
  },
  {
    "id": "arXiv:2211.08384",
    "title": "Universal Distributional Decision-based Black-box Adversarial Attack  with Reinforcement Learning",
    "abstract": "The vulnerability of the high-performance machine learning models implies a\nsecurity risk in applications with real-world consequences. Research on\nadversarial attacks is beneficial in guiding the development of machine\nlearning models on the one hand and finding targeted defenses on the other.\nHowever, most of the adversarial attacks today leverage the gradient or logit\ninformation from the models to generate adversarial perturbation. Works in the\nmore realistic domain: decision-based attacks, which generate adversarial\nperturbation solely based on observing the output label of the targeted model,\nare still relatively rare and mostly use gradient-estimation strategies. In\nthis work, we propose a pixel-wise decision-based attack algorithm that finds a\ndistribution of adversarial perturbation through a reinforcement learning\nalgorithm. We call this method Decision-based Black-box Attack with\nReinforcement learning (DBAR). Experiments show that the proposed approach\noutperforms state-of-the-art decision-based attacks with a higher attack\nsuccess rate and greater transferability.",
    "descriptor": "\nComments: 10 pages, 2 figures, conference\n",
    "authors": [
      "Yiran Huang",
      "Yexu Zhou",
      "Michael Hefenbrock",
      "Till Riedel",
      "Likun Fang",
      "Michael Beigl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.08384"
  },
  {
    "id": "arXiv:2211.08385",
    "title": "CardiacGen: A Hierarchical Deep Generative Model for Cardiac Signals",
    "abstract": "We present CardiacGen, a Deep Learning framework for generating synthetic but\nphysiologically plausible cardiac signals like ECG. Based on the physiology of\ncardiovascular system function, we propose a modular hierarchical generative\nmodel and impose explicit regularizing constraints for training each module\nusing multi-objective loss functions. The model comprises 2 modules, an HRV\nmodule focused on producing realistic Heart-Rate-Variability characteristics\nand a Morphology module focused on generating realistic signal morphologies for\ndifferent modalities. We empirically show that in addition to having realistic\nphysiological features, the synthetic data from CardiacGen can be used for data\naugmentation to improve the performance of Deep Learning based classifiers.\nCardiacGen code is available at\nhttps://github.com/SENSE-Lab-OSU/cardiac_gen_model.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 6 pages\n",
    "authors": [
      "Tushar Agarwal",
      "Emre Ertin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08385"
  },
  {
    "id": "arXiv:2211.08386",
    "title": "Generative Long-form Question Answering: Relevance, Faithfulness and  Succinctness",
    "abstract": "In this thesis, we investigated the relevance, faithfulness, and succinctness\naspects of Long Form Question Answering (LFQA). LFQA aims to generate an\nin-depth, paragraph-length answer for a given question, to help bridge the gap\nbetween real scenarios and the existing open-domain QA models which can only\nextract short-span answers. LFQA is quite challenging and under-explored. Few\nworks have been done to build an effective LFQA system. It is even more\nchallenging to generate a good-quality long-form answer relevant to the query\nand faithful to facts, since a considerable amount of redundant, complementary,\nor contradictory information will be contained in the retrieved documents.\nMoreover, no prior work has been investigated to generate succinct answers. We\nare among the first to research the LFQA task. We pioneered the research\ndirection to improve the answer quality in terms of 1) query-relevance, 2)\nanswer faithfulness, and 3) answer succinctness.",
    "descriptor": "\nComments: PhD Thesis\n",
    "authors": [
      "Dan Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08386"
  },
  {
    "id": "arXiv:2211.08387",
    "title": "AutoTemplate: A Simple Recipe for Lexically Constrained Text Generation",
    "abstract": "Lexically constrained text generation is one of the constrained text\ngeneration tasks, which aims to generate text that covers all the given\nconstraint lexicons. While the existing approaches tackle this problem using a\nlexically constrained beam search algorithm or dedicated model using\nnon-autoregressive decoding, there is a trade-off between the generated text\nquality and the hard constraint satisfaction. We introduce AutoTemplate, a\nsimple yet effective lexically constrained text generation framework divided\ninto template generation and lexicalization tasks. The template generation is\nto generate the text with the placeholders, and lexicalization replaces them\ninto the constraint lexicons to perform lexically constrained text generation.\nWe conducted the experiments on two tasks: keywords-to-sentence generations and\nentity-guided summarization. Experimental results show that the AutoTemplate\noutperforms the competitive baselines on both tasks while satisfying the hard\nlexical constraints.",
    "descriptor": "",
    "authors": [
      "Hayate Iso"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08387"
  },
  {
    "id": "arXiv:2211.08390",
    "title": "A New Technique for Improving Energy Efficiency in 5G Mm-wave Hybrid  Precoding Systems",
    "abstract": "In this article, we present a new approach to optimizing the energy\nefficiency of the cost-efficiency of quantized hybrid pre-encoding (HP) design.\nWe present effective alternating minimization algorithms (AMA) based on the\nzero gradient method to produce completely connected structures (CCSs) and\npartially connected structures (PCSs). Alternative minimization algorithms\noffer lower complexity by introducing orthogonal constraints on digital\npre-codes to concurrently maximize computing complexity and communication\npower. As a result, by improving CCS through advanced phase extraction, the\nalternating minimization technique enhances hybrid pre-encoding. For PCS, the\nenergy-saving ratio grew by 45.3 %, while for CCS, it increased by 18.12 %.",
    "descriptor": "",
    "authors": [
      "Adeb Salh",
      "Qazwan Abdullah",
      "Ghasan Hussain",
      "Razlai Ngah",
      "Lukman Audah",
      "Nor Shahida Mohd Shah",
      "Shipun Hamzah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08390"
  },
  {
    "id": "arXiv:2211.08393",
    "title": "On the Performance of Direct Loss Minimization for Bayesian Neural  Networks",
    "abstract": "Direct Loss Minimization (DLM) has been proposed as a pseudo-Bayesian method\nmotivated as regularized loss minimization. Compared to variational inference,\nit replaces the loss term in the evidence lower bound (ELBO) with the\npredictive log loss, which is the same loss function used in evaluation. A\nnumber of theoretical and empirical results in prior work suggest that DLM can\nsignificantly improve over ELBO optimization for some models. However, as we\npoint out in this paper, this is not the case for Bayesian neural networks\n(BNNs). The paper explores the practical performance of DLM for BNN, the\nreasons for its failure and its relationship to optimizing the ELBO, uncovering\nsome interesting facts about both algorithms.",
    "descriptor": "\nComments: I Cant Believe It is Not Better Workshop at NeurIPS 2022\n",
    "authors": [
      "Yadi Wei",
      "Roni Khardon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08393"
  },
  {
    "id": "arXiv:2211.08397",
    "title": "Local learning through propagation delays in spiking neural networks",
    "abstract": "We propose a novel local learning rule for spiking neural networks in which\nspike propagation times undergo activity-dependent plasticity. Our plasticity\nrule aligns pre-synaptic spike times to produce a stronger and more rapid\nresponse. Inputs are encoded by latency coding and outputs decoded by matching\nsimilar patterns of output spiking activity. We demonstrate the use of this\nmethod in a three-layer feedfoward network with inputs from a database of\nhandwritten digits. Networks consistently improve their classification accuracy\nafter training, and training with this method also allowed networks to\ngeneralize to an input class unseen during training. Our proposed method takes\nadvantage of the ability of spiking neurons to support many different\ntime-locked sequences of spikes, each of which can be activated by different\ninput activations. The proof-of-concept shown here demonstrates the great\npotential for local delay learning to expand the memory capacity and\ngeneralizability of spiking neural networks.",
    "descriptor": "\nComments: 4 pages, 4 figures; longer version under preparation\n",
    "authors": [
      "J\u00f8rgen Jensen Farner",
      "Ola Huse Ramstad",
      "Stefano Nichele",
      "Kristine Heiney"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.08397"
  },
  {
    "id": "arXiv:2211.08398",
    "title": "Structured Knowledge Distillation Towards Efficient and Compact  Multi-View 3D Detection",
    "abstract": "Detecting 3D objects from multi-view images is a fundamental problem in 3D\ncomputer vision. Recently, significant breakthrough has been made in multi-view\n3D detection tasks. However, the unprecedented detection performance of these\nvision BEV (bird's-eye-view) detection models is accompanied with enormous\nparameters and computation, which make them unaffordable on edge devices. To\naddress this problem, in this paper, we propose a structured knowledge\ndistillation framework, aiming to improve the efficiency of modern vision-only\nBEV detection models. The proposed framework mainly includes: (a)\nspatial-temporal distillation which distills teacher knowledge of information\nfusion from different timestamps and views, (b) BEV response distillation which\ndistills teacher response to different pillars, and (c) weight-inheriting which\nsolves the problem of inconsistent inputs between students and teacher in\nmodern transformer architectures. Experimental results show that our method\nleads to an average improvement of 2.16 mAP and 2.27 NDS on the nuScenes\nbenchmark, outperforming multiple baselines by a large margin.",
    "descriptor": "\nComments: Codes will be released if this paper is accepted\n",
    "authors": [
      "Linfeng Zhang",
      "Yukang Shi",
      "Hung-Shuo Tai",
      "Zhipeng Zhang",
      "Yuan He",
      "Ke Wang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08398"
  },
  {
    "id": "arXiv:2211.08399",
    "title": "Active Learning Framework to Automate NetworkTraffic Classification",
    "abstract": "Recent network traffic classification methods benefitfrom machine learning\n(ML) technology. However, there aremany challenges due to use of ML, such as:\nlack of high-qualityannotated datasets, data-drifts and other effects causing\naging ofdatasets and ML models, high volumes of network traffic etc. Thispaper\nargues that it is necessary to augment traditional workflowsof ML\ntraining&deployment and adapt Active Learning concepton network traffic\nanalysis. The paper presents a novel ActiveLearning Framework (ALF) to address\nthis topic. ALF providesprepared software components that can be used to deploy\nan activelearning loop and maintain an ALF instance that continuouslyevolves a\ndataset and ML model automatically. The resultingsolution is deployable for IP\nflow-based analysis of high-speed(100 Gb/s) networks, and also supports\nresearch experiments ondifferent strategies and methods for annotation,\nevaluation, datasetoptimization, etc. Finally, the paper lists some research\nchallengesthat emerge from the first experiments with ALF in practice.",
    "descriptor": "",
    "authors": [
      "Jaroslav Pe\u0161ek",
      "Dominik Soukup",
      "Tom\u00e1\u0161 \u010cejka"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08399"
  },
  {
    "id": "arXiv:2211.08400",
    "title": "Air Pollution Hotspot Detection and Source Feature Analysis using  Cross-domain Urban Data",
    "abstract": "Air pollution is a major global environmental health threat, in particular\nfor people who live or work near pollution sources. Areas adjacent to pollution\nsources often have high ambient pollution concentrations, and those areas are\ncommonly referred to as air pollution hotspots. Detecting and characterizing\npollution hotspots are of great importance for air quality management, but are\nchallenging due to the high spatial and temporal variability of air pollutants.\nIn this work, we explore the use of mobile sensing data (i.e., air quality\nsensors installed on vehicles) to detect pollution hotspots. One major\nchallenge with mobile sensing data is uneven sampling, i.e., data collection\ncan vary by both space and time. To address this challenge, we propose a\ntwo-step approach to detect hotspots from mobile sensing data, which includes\nlocal spike detection and sample-weighted clustering. Essentially, this\napproach tackles the uneven sampling issue by weighting samples based on their\nspatial frequency and temporal hit rate, so as to identify robust and\npersistent hotspots. To contextualize the hotspots and discover potential\npollution source characteristics, we explore a variety of cross-domain urban\ndata and extract features from them. As a soft-validation of the extracted\nfeatures, we build hotspot inference models for cities with and without mobile\nsensing data. Evaluation results using real-world mobile sensing air quality\ndata as well as cross-domain urban data demonstrate the effectiveness of our\napproach in detecting and inferring pollution hotspots. Furthermore, the\nempirical analysis of hotspots and source features yields useful insights\nregarding neighborhood pollution sources.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yawen Zhang",
      "Michael Hannigan",
      "Qin Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08400"
  },
  {
    "id": "arXiv:2211.08401",
    "title": "iTUAVs: Intermittently Tethered UAVs for Future Wireless Networks",
    "abstract": "We propose the intermittently tethered unmanned aerial vehicle (iTUAV) as a\ntradeoff between the power availability of a tethered UAV (TUAV) and the\nflexibility of an untethered UAV. An iTUAV can provide cellular connectivity\nwhile being temporarily tethered to the most adequate ground anchor. Also, it\ncan flexibly detach from one anchor, travel, then attach to another one to\nmaintain/improve the coverage quality for mobile users. Hence, we discuss here\nthe existing UAV-based cellular networking technologies, followed by a detailed\ndescription of the iTUAV system, its components, and mode of operation.\nSubsequently, we present a comparative study of the existing and proposed\nsystems highlighting the differences in key features such as mobility and\nenergy. To emphasize the potential of iTUAV systems, we conduct a case study,\nevaluate the iTUAV performance, and compare it to benchmarks. Obtained results\nshow that with only 10 anchors in the area, the iTUAV system can serve up to\n90% of the users covered by the untethered UAV swapping system. Moreover,\nresults from a small case study prove that the iTUAV allows to balance\nperformance/cost and can be implemented realistically. For instance, when user\nlocations are clustered, with only 2 active iTUAVs and 4 anchors, achieved\nperformance is superior to that of the system with 3 TUAVs, while when\nconsidering a single UAV on a 100 minutes event, a system with only 6 anchors\noutperforms the untethered UAV as it combines location flexibility with\nincreased mission time.",
    "descriptor": "",
    "authors": [
      "Nesrine Cherif",
      "Wael Jaafar",
      "Evgenii Vinogradov",
      "Halim Yanikomeroglu",
      "Sofie Pollin",
      "Abbas Yongacoglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08401"
  },
  {
    "id": "arXiv:2211.08402",
    "title": "Introducing Semantics into Speech Encoders",
    "abstract": "Recent studies find existing self-supervised speech encoders contain\nprimarily acoustic rather than semantic information. As a result, pipelined\nsupervised automatic speech recognition (ASR) to large language model (LLM)\nsystems achieve state-of-the-art results on semantic spoken language tasks by\nutilizing rich semantic representations from the LLM. These systems come at the\ncost of labeled audio transcriptions, which is expensive and time-consuming to\nobtain. We propose a task-agnostic unsupervised way of incorporating semantic\ninformation from LLMs into self-supervised speech encoders without labeled\naudio transcriptions. By introducing semantics, we improve existing speech\nencoder spoken language understanding performance by over 10\\% on intent\nclassification, with modest gains in named entity resolution and slot filling,\nand spoken question answering FF1 score by over 2\\%. Our unsupervised approach\nachieves similar performance as supervised methods trained on over 100 hours of\nlabeled audio transcripts, demonstrating the feasibility of unsupervised\nsemantic augmentations to existing speech encoders.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Derek Xu",
      "Shuyan Dong",
      "Changhan Wang",
      "Suyoun Kim",
      "Zhaojiang Lin",
      "Akshat Shrivastava",
      "Shang-Wen Li",
      "Liang-Hsuan Tseng",
      "Alexei Baevski",
      "Guan-Ting Lin",
      "Hung-yi Lee",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08402"
  },
  {
    "id": "arXiv:2211.08403",
    "title": "REPAIR: REnormalizing Permuted Activations for Interpolation Repair",
    "abstract": "In this paper we look into the conjecture of Entezari et al.(2021) which\nstates that if the permutation invariance of neural networks is taken into\naccount, then there is likely no loss barrier to the linear interpolation\nbetween SGD solutions. First, we observe that neuron alignment methods alone\nare insufficient to establish low-barrier linear connectivity between SGD\nsolutions due to a phenomenon we call variance collapse: interpolated deep\nnetworks suffer a collapse in the variance of their activations, causing poor\nperformance. Next, we propose REPAIR (REnormalizing Permuted Activations for\nInterpolation Repair) which mitigates variance collapse by rescaling the\npreactivations of such interpolated networks. We explore the interaction\nbetween our method and the choice of normalization layer, network width, and\ndepth, and demonstrate that using REPAIR on top of neuron alignment methods\nleads to 60%-100% relative barrier reduction across a wide variety of\narchitecture families and tasks. In particular, we report a 74% barrier\nreduction for ResNet50 on ImageNet and 90% barrier reduction for ResNet18 on\nCIFAR10.",
    "descriptor": "",
    "authors": [
      "Keller Jordan",
      "Hanie Sedghi",
      "Olga Saukh",
      "Rahim Entezari",
      "Behnam Neyshabur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08403"
  },
  {
    "id": "arXiv:2211.08404",
    "title": "Non-Linear Coordination Graphs",
    "abstract": "Value decomposition multi-agent reinforcement learning methods learn the\nglobal value function as a mixing of each agent's individual utility functions.\nCoordination graphs (CGs) represent a higher-order decomposition by\nincorporating pairwise payoff functions and thus is supposed to have a more\npowerful representational capacity. However, CGs decompose the global value\nfunction linearly over local value functions, severely limiting the complexity\nof the value function class that can be represented. In this paper, we propose\nthe first non-linear coordination graph by extending CG value decomposition\nbeyond the linear case. One major challenge is to conduct greedy action\nselections in this new function class to which commonly adopted DCOP algorithms\nare no longer applicable. We study how to solve this problem when mixing\nnetworks with LeakyReLU activation are used. An enumeration method with a\nglobal optimality guarantee is proposed and motivates an efficient iterative\noptimization method with a local optimality guarantee. We find that our method\ncan achieve superior performance on challenging multi-agent coordination tasks\nlike MACO.",
    "descriptor": "\nComments: Authors are listed in alphabetical order\n",
    "authors": [
      "Yipeng Kang",
      "Tonghan Wang",
      "Xiaoran Wu",
      "Qianlan Yang",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08404"
  },
  {
    "id": "arXiv:2211.08407",
    "title": "Trust-Awareness to Secure Swarm Intelligence from Data Injection Attack",
    "abstract": "Enabled by the emerging industrial agent (IA) technology, swarm intelligence\n(SI) is envisaged to play an important role in future industrial Internet of\nThings (IIoT) that is shaped by Sixth Generation (6G) mobile communications and\ndigital twin (DT). However, its fragility against data injection attack may\nhalt it from practical deployment. In this paper we propose an efficient trust\napproach to address this security concern for SI.",
    "descriptor": "\nComments: Submitted to ICC 2023\n",
    "authors": [
      "Bin Han",
      "Dennis Krummmacher",
      "Qiuheng Zhou",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.08407"
  },
  {
    "id": "arXiv:2211.08408",
    "title": "On the biological plausibility of orthogonal initialisation for solving  gradient instability in deep neural networks",
    "abstract": "Initialising the synaptic weights of artificial neural networks (ANNs) with\northogonal matrices is known to alleviate vanishing and exploding gradient\nproblems. A major objection against such initialisation schemes is that they\nare deemed biologically implausible as they mandate factorization techniques\nthat are difficult to attribute to a neurobiological process. This paper\npresents two initialisation schemes that allow a network to naturally evolve\nits weights to form orthogonal matrices, provides theoretical analysis that\npre-training orthogonalisation always converges, and empirically confirms that\nthe proposed schemes outperform randomly initialised recurrent and feedforward\nnetworks.",
    "descriptor": "\nComments: 9 pages, 3 figures, to be published in ISCMI2022 conference proceedings\n",
    "authors": [
      "Nikolay Manchev",
      "Michael Spratling"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08408"
  },
  {
    "id": "arXiv:2211.08410",
    "title": "Low Latency Conversion of Artificial Neural Network Models to  Rate-encoded Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) are well suited for resource-constrained\napplications as they do not need expensive multipliers. In a typical\nrate-encoded SNN, a series of binary spikes within a globally fixed time window\nis used to fire the neurons. The maximum number of spikes in this time window\nis also the latency of the network in performing a single inference, as well as\ndetermines the overall energy efficiency of the model. The aim of this paper is\nto reduce this while maintaining accuracy when converting ANNs to their\nequivalent SNNs. The state-of-the-art conversion schemes yield SNNs with\naccuracies comparable with ANNs only for large window sizes. In this paper, we\nstart with understanding the information loss when converting from pre-existing\nANN models to standard rate-encoded SNN models. From these insights, we propose\na suite of novel techniques that together mitigate the information lost in the\nconversion, and achieve state-of-art SNN accuracies along with very low\nlatency. Our method achieved a Top-1 SNN accuracy of 98.73% (1 time step) on\nthe MNIST dataset, 76.38% (8 time steps) on the CIFAR-100 dataset, and 93.71%\n(8 time steps) on the CIFAR-10 dataset. On ImageNet, an SNN accuracy of\n75.35%/79.16% was achieved with 100/200 time steps.",
    "descriptor": "",
    "authors": [
      "Zhanglu Yan",
      "Jun Zhou",
      "Weng-Fai Wong"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08410"
  },
  {
    "id": "arXiv:2211.08411",
    "title": "Large Language Models Struggle to Learn Long-Tail Knowledge",
    "abstract": "The internet contains a wealth of knowledge -- from the birthdays of\nhistorical figures to tutorials on how to code -- all of which may be learned\nby language models. However, there is a huge variability in the number of times\na given piece of information appears on the web. In this paper, we study the\nrelationship between the knowledge memorized by large language models and the\ninformation in their pre-training datasets. In particular, we show that a\nlanguage model's ability to answer a fact-based question relates to how many\ndocuments associated with that question were seen during pre-training. We\nidentify these relevant documents by entity linking pre-training datasets and\ncounting documents that contain the same entities as a given question-answer\npair. Our results demonstrate strong correlational and causal relationships\nbetween accuracy and relevant document count for numerous question answering\ndatasets (e.g., TriviaQA), pre-training corpora (e.g., ROOTS), and model sizes\n(e.g., 176B parameters). Moreover, we find that while larger models are better\nat learning long-tail knowledge, we estimate that today's models must be scaled\nby many orders of magnitude to reach competitive QA performance on questions\nwith little support in the pre-training data. Finally, we show that\nretrieval-augmentation can reduce the dependence on relevant document count,\npresenting a promising approach for capturing the long-tail.",
    "descriptor": "",
    "authors": [
      "Nikhil Kandpal",
      "Haikang Deng",
      "Adam Roberts",
      "Eric Wallace",
      "Colin Raffel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08411"
  },
  {
    "id": "arXiv:2211.08412",
    "title": "Evaluating the Factual Consistency of Large Language Models Through  Summarization",
    "abstract": "While large language models (LLMs) have proven to be effective on a large\nvariety of tasks, they are also known to hallucinate information. To measure\nwhether an LLM prefers factually consistent continuations of its input, we\npropose a new benchmark called FIB(Factual Inconsistency Benchmark) that\nfocuses on the task of summarization. Specifically, our benchmark involves\ncomparing the scores an LLM assigns to a factually consistent versus a\nfactually inconsistent summary for an input news article. For factually\nconsistent summaries, we use human-written reference summaries that we manually\nverify as factually consistent. To generate summaries that are factually\ninconsistent, we generate summaries from a suite of summarization models that\nwe have manually annotated as factually inconsistent. A model's factual\nconsistency is then measured according to its accuracy, i.e.\\ the proportion of\ndocuments where it assigns a higher score to the factually consistent summary.\nTo validate the usefulness of FIB, we evaluate 23 large language models ranging\nfrom 1B to 176B parameters from six different model families including BLOOM\nand OPT. We find that existing LLMs generally assign a higher score to\nfactually consistent summaries than to factually inconsistent summaries.\nHowever, if the factually inconsistent summaries occur verbatim in the\ndocument, then LLMs assign a higher score to these factually inconsistent\nsummaries than factually consistent summaries. We validate design choices in\nour benchmark including the scoring method and source of distractor summaries.\nOur code and benchmark data can be found at https://github.com/r-three/fib.",
    "descriptor": "",
    "authors": [
      "Derek Tam",
      "Anisha Mascarenhas",
      "Shiyue Zhang",
      "Sarah Kwan",
      "Mohit Bansal",
      "Colin Raffel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08412"
  },
  {
    "id": "arXiv:2211.08413",
    "title": "Decentralized Federated Learning: Fundamentals, State-of-the-art,  Frameworks, Trends, and Challenges",
    "abstract": "In the last decade, Federated Learning (FL) has gained relevance in training\ncollaborative models without sharing sensitive data. Since its birth,\nCentralized FL (CFL) has been the most common approach in the literature, where\na unique entity creates global models. However, using a centralized approach\nhas the disadvantages of bottleneck at the server node, single point of\nfailure, and trust needs. Decentralized Federated Learning (DFL) arose to solve\nthese aspects by embracing the principles of data sharing minimization and\ndecentralized model aggregation without relying on centralized architectures.\nHowever, despite the work done in DFL, the literature has not (i) studied the\nmain fundamentals differentiating DFL and CFL; (ii) reviewed application\nscenarios and solutions using DFL; and (iii) analyzed DFL frameworks to create\nand evaluate new solutions. To this end, this article identifies and analyzes\nthe main fundamentals of DFL in terms of federation architectures, topologies,\ncommunication mechanisms, security approaches, and key performance indicators.\nAdditionally, the paper at hand explores existing mechanisms to optimize\ncritical DFL fundamentals. Then, this work analyzes and compares the most used\nDFL application scenarios and solutions according to the fundamentals\npreviously defined. After that, the most relevant features of the current DFL\nframeworks are reviewed and compared. Finally, the evolution of existing DFL\nsolutions is analyzed to provide a list of trends, lessons learned, and open\nchallenges.",
    "descriptor": "",
    "authors": [
      "Enrique Tom\u00e1s Mart\u00ednez Beltr\u00e1n",
      "Mario Quiles P\u00e9rez",
      "Pedro Miguel S\u00e1nchez S\u00e1nchez",
      "Sergio L\u00f3pez Bernal",
      "G\u00e9r\u00f4me Bovet",
      "Manuel Gil P\u00e9rez",
      "Gregorio Mart\u00ednez P\u00e9rez",
      "Alberto Huertas Celdr\u00e1n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.08413"
  },
  {
    "id": "arXiv:2211.08414",
    "title": "Model free Shapley values for high dimensional data",
    "abstract": "A model-agnostic variable importance method can be used with arbitrary\nprediction functions. Here we present some model-free methods that do not\nrequire access to the prediction function. This is useful when that function is\nproprietary and not available, or just extremely expensive. It is also useful\nwhen studying residuals from a model. The cohort Shapley (CS) method is\nmodel-free but has exponential cost in the dimension of the input space. A\nsupervised on-manifold Shapley method from Frye et al. (2020) is also model\nfree but requires as input a second black box model that has to be trained for\nthe Shapley value problem. We introduce an integrated gradient version of\ncohort Shapley, called IGCS, with cost $\\mathcal{O}(nd)$. We show that over the\nvast majority of the relevant unit cube that the IGCS value function is close\nto a multilinear function for which IGCS matches CS. We use some area under the\ncurve (AUC) measures to quantify the performance of IGCS. On a problem from\nhigh energy physics we verify that IGCS has nearly the same AUCs as CS. We also\nuse it on a problem from computational chemistry in 1024 variables. We see\nthere that IGCS attains much higher AUCs than we get from Monte Carlo sampling.\nThe code is publicly available at\nhttps://github.com/cohortshapley/cohortintgrad.",
    "descriptor": "",
    "authors": [
      "Naofumi Hama",
      "Masayoshi Mase",
      "Art B. Owen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08414"
  },
  {
    "id": "arXiv:2211.08415",
    "title": "Online Anomalous Subtrajectory Detection on Road Networks with Deep  Reinforcement Learning",
    "abstract": "Detecting anomalous trajectories has become an important task in many\nlocation-based applications. While many approaches have been proposed for this\ntask, they suffer from various issues including (1) incapability of detecting\nanomalous subtrajectories, which are finer-grained anomalies in trajectory\ndata, and/or (2) non-data driven, and/or (3) requirement of sufficient\nsupervision labels which are costly to collect. In this paper, we propose a\nnovel reinforcement learning based solution called RL4OASD, which avoids all\naforementioned issues of existing approaches. RL4OASD involves two networks,\none responsible for learning features of road networks and trajectories and the\nother responsible for detecting anomalous subtrajectories based on the learned\nfeatures, and the two networks can be trained iteratively without labeled data.\nExtensive experiments are conducted on two real datasets, and the results show\nthat our solution can significantly outperform the state-of-the-art methods\n(with 20-30% improvement) and is efficient for online detection (it takes less\nthan 0.1ms to process each newly generated data point).",
    "descriptor": "",
    "authors": [
      "Qianru Zhang",
      "Zheng Wang",
      "Cheng Long",
      "Chao Huang",
      "Siu-Ming Yiu",
      "Yiding Liu",
      "Gao Cong",
      "Jieming Shi"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08415"
  },
  {
    "id": "arXiv:2211.08416",
    "title": "Robot Learning on the Job: Human-in-the-Loop Autonomy and Learning  During Deployment",
    "abstract": "With the rapid growth of computing powers and recent advances in deep\nlearning, we have witnessed impressive demonstrations of novel robot\ncapabilities in research settings. Nonetheless, these learning systems exhibit\nbrittle generalization and require excessive training data for practical tasks.\nTo harness the capabilities of state-of-the-art robot learning models while\nembracing their imperfections, we present Sirius, a principled framework for\nhumans and robots to collaborate through a division of work. In this framework,\npartially autonomous robots are tasked with handling a major portion of\ndecision-making where they work reliably; meanwhile, human operators monitor\nthe process and intervene in challenging situations. Such a human-robot team\nensures safe deployments in complex tasks. Further, we introduce a new learning\nalgorithm to improve the policy's performance on the data collected from the\ntask executions. The core idea is re-weighing training samples with\napproximated human trust and optimizing the policies with weighted behavioral\ncloning. We evaluate Sirius in simulation and on real hardware, showing that\nSirius consistently outperforms baselines over a collection of contact-rich\nmanipulation tasks, achieving 8% boost in simulation and 27% on real hardware\nthan the state-of-the-art methods, with 3 times faster convergence and 15%\nmemory size. Videos and code are available at\nhttps://ut-austin-rpl.github.io/sirius/",
    "descriptor": "",
    "authors": [
      "Huihan Liu",
      "Soroush Nasiriany",
      "Lance Zhang",
      "Zhiyao Bao",
      "Yuke Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08416"
  },
  {
    "id": "arXiv:2211.08419",
    "title": "Participation Interfaces for Human-Centered AI",
    "abstract": "Emerging artificial intelligence (AI) applications often balance the\npreferences and impacts among diverse and contentious stakeholder groups.\nAccommodating these stakeholder groups during system design, development, and\ndeployment requires tools for the elicitation of disparate system interests and\ncollaboration interfaces supporting negotiation balancing those interests. This\npaper introduces interactive visual \"participation interfaces\" for Markov\nDecision Processes (MDPs) and collaborative ranking problems as examples\nrestoring a human-centered locus of control.",
    "descriptor": "\nComments: 4 pages, 2 figures. To be published in Human-Centered AI Workshop at NeurIPS 2022\n",
    "authors": [
      "Sean McGregor"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08419"
  },
  {
    "id": "arXiv:2211.08422",
    "title": "Mechanistic Mode Connectivity",
    "abstract": "Neural networks are known to be biased towards learning mechanisms that help\nidentify $spurious\\, attributes$, yielding features that do not generalize well\nunder distribution shifts. To understand and address this limitation, we study\nthe geometry of neural network loss landscapes through the lens of $mode\\,\nconnectivity$, the observation that minimizers of neural networks are connected\nvia simple paths of low loss. Our work addresses two questions: (i) do\nminimizers that encode dissimilar mechanisms connect via simple paths of low\nloss? (ii) can fine-tuning a pretrained model help switch between such\nminimizers? We define a notion of $\\textit{mechanistic similarity}$ and\ndemonstrate that lack of linear connectivity between two minimizers implies the\ncorresponding models use dissimilar mechanisms for making their predictions.\nThis property helps us demonstrate that na$\\\"{i}$ve fine-tuning can fail to\neliminate a model's reliance on spurious attributes. We thus propose a method\nfor altering a model's mechanisms, named $connectivity$-$based$\n$fine$-$tuning$, and validate its usefulness by inducing models invariant to\nspurious attributes.",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Ekdeep Singh Lubana",
      "Eric J. Bigelow",
      "Robert P. Dick",
      "David Krueger",
      "Hidenori Tanaka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08422"
  },
  {
    "id": "arXiv:2203.13028",
    "title": "Brain inspired neuronal silencing mechanism to enable reliable sequence  identification",
    "abstract": "Real-time sequence identification is a core use-case of artificial neural\nnetworks (ANNs), ranging from recognizing temporal events to identifying\nverification codes. Existing methods apply recurrent neural networks, which\nsuffer from training difficulties; however, performing this function without\nfeedback loops remains a challenge. Here, we present an experimental neuronal\nlong-term plasticity mechanism for high-precision feedforward sequence\nidentification networks (ID-nets) without feedback loops, wherein input objects\nhave a given order and timing. This mechanism temporarily silences neurons\nfollowing their recent spiking activity. Therefore, transitory objects act on\ndifferent dynamically created feedforward sub-networks. ID-nets are\ndemonstrated to reliably identify 10 handwritten digit sequences, and are\ngeneralized to deep convolutional ANNs with continuous activation nodes trained\non image sequences. Counterintuitively, their classification performance, even\nwith a limited number of training examples, is high for sequences but low for\nindividual objects. ID-nets are also implemented for writer-dependent\nrecognition, and suggested as a cryptographic tool for encrypted\nauthentication. The presented mechanism opens new horizons for advanced ANN\nalgorithms.",
    "descriptor": "\nComments: 38 pages, 11 figures\n",
    "authors": [
      "Shiri Hodassman",
      "Yuval Meir",
      "Karin Kisos",
      "Itamar Ben-Noam",
      "Yael Tugendhaft",
      "Amir Goldental",
      "Roni Vardi",
      "Ido Kanter"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2203.13028"
  },
  {
    "id": "arXiv:2211.06369",
    "title": "Enhancing and Adversarial: Improve ASR with Speaker Labels",
    "abstract": "ASR can be improved by multi-task learning (MTL) with domain enhancing or\ndomain adversarial training, which are two opposite objectives with the aim to\nincrease/decrease domain variance towards domain-aware/agnostic ASR,\nrespectively. In this work, we study how to best apply these two opposite\nobjectives with speaker labels to improve conformer-based ASR. We also propose\na novel adaptive gradient reversal layer for stable and effective adversarial\ntraining without tuning effort. Detailed analysis and experimental verification\nare conducted to show the optimal positions in the ASR neural network (NN) to\napply speaker enhancing and adversarial training. We also explore their\ncombination for further improvement, achieving the same performance as\ni-vectors plus adversarial training. Our best speaker-based MTL achieves 7\\%\nrelative improvement on the Switchboard Hub5'00 set. We also investigate the\neffect of such speaker-based MTL w.r.t. cleaner dataset and weaker ASR NN.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Wei Zhou",
      "Haotian Wu",
      "Jingjing Xu",
      "Mohammad Zeineldeen",
      "Christoph L\u00fcscher",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.06369"
  },
  {
    "id": "arXiv:2211.07648",
    "title": "Removing fluid lensing effects from spatial images",
    "abstract": "Shallow water and coastal aquatic ecosystems such as coral reefs and seagrass\nmeadows play a critical role in regulating and understanding Earth's changing\nclimate and biodiversity. They also play an important role in protecting towns\nand cities from erosion and storm surges. Yet technology used for remote\nsensing (drones, UAVs, satellites) cannot produce detailed images of these\necosystems. Fluid lensing effects, the distortions caused by surface waves and\nlight on underwater objects, are what makes the remote sensing of these\necosystems a very challenging task. Using machine learning, a proof of concept\nmodel was developed that is able to remove most of these effects and produce a\nclearer more stable image.",
    "descriptor": "",
    "authors": [
      "Greg Sabella"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.07648"
  },
  {
    "id": "arXiv:2211.07651",
    "title": "Comparative Assessment of Biomechanical Parameters in Subjects with  Multiple Cerebral Aneurysms using Fluid-Structure Interaction Simulations",
    "abstract": "Cerebral aneurysm progression is a result of a complex interplay of the\nbiomechanical and clinical risk factors that drive aneurysmal growth and\nrupture. Subjects with multiple aneurysms are unique cases wherein clinical\nrisk factors are expected to affect each aneurysm equally, thus allowing for\ndisentangling the effect of biomechanical factors on aneurysmal growth. Towards\nthis end, we performed a comparative computational fluid--structure interaction\nanalysis of aneurysmal biomechanics in image-based models of stable and growing\naneurysms in the same subjects, using the cardiovascular simulation platform\nSimVascular. We observed that areas exposed to low shear and the median peak\nsystolic arterial wall displacement were higher by factors of 2 or more and\n1.5, respectively, in growing aneurysms as compared to stable aneurysms.\nFurthermore, we defined a novel metric, the oscillatory stress index (OStI),\nthat indicates locations of oscillating arterial wall stresses. We observed\nthat growing aneurysms were characterized by regions of combined low wall shear\nand low OStI, which we hypothesize to be associated with regions of collagen\ndegradation and remodeling. Such regions were either absent or below 5% of the\nsurface area in stable aneurysms. Our results lay the groundwork for future\nstudies in larger cohorts of subjects, to evaluate the statistical significance\nof these biomechanical parameters in cerebral aneurysm growth.",
    "descriptor": "\nComments: 21 pages, 8 figures + appendices; to appear in the ASME Journal of Biomechanical Engineering\n",
    "authors": [
      "Tanmay C. Shidhore",
      "Aaron A. Cohen-Gadol",
      "Vitaliy L. Rayz",
      "Ivan C. Christov"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.07651"
  },
  {
    "id": "arXiv:2211.07723",
    "title": "An online algorithm for contrastive Principal Component Analysis",
    "abstract": "Finding informative low-dimensional representations that can be computed\nefficiently in large datasets is an important problem in data analysis.\nRecently, contrastive Principal Component Analysis (cPCA) was proposed as a\nmore informative generalization of PCA that takes advantage of contrastive\nlearning. However, the performance of cPCA is sensitive to hyper-parameter\nchoice and there is currently no online algorithm for implementing cPCA. Here,\nwe introduce a modified cPCA method, which we denote cPCA*, that is more\ninterpretable and less sensitive to the choice of hyper-parameter. We derive an\nonline algorithm for cPCA* and show that it maps onto a neural network with\nlocal learning rules, so it can potentially be implemented in energy efficient\nneuromorphic hardware. We evaluate the performance of our online algorithm on\nreal datasets and highlight the differences and similarities with the original\nformulation.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Siavash Golkar",
      "David Lipshutz",
      "Tiberiu Tesileanu",
      "Dmitri B. Chklovskii"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.07723"
  },
  {
    "id": "arXiv:2211.07766",
    "title": "On Tuza's conjecture in co-chain graphs",
    "abstract": "In 1981, Tuza conjectured that the cardinality of a minimum set of edges that\nintersects every triangle of a graph is at most twice the cardinality of a\nmaximum set of edge-disjoint triangles. This conjecture have been proved for\nseveral important graph classes, as planar graphs, tripartite graphs, among\nothers. However, it remains open on other important classes of graphs, as\nchordal graphs. Furthermore, it remains open for main subclasses of chordal\ngraphs, as split graphs and interval graphs. In this paper, we show that Tuza's\nconjecture is valid for co-chain graphs with even number of vertices in both\nsides of the partition, a known subclass of interval graphs.",
    "descriptor": "",
    "authors": [
      "Luis Chahua",
      "Juan Guti\u00e9rrez"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.07766"
  },
  {
    "id": "arXiv:2211.07767",
    "title": "Learning to Optimize with Stochastic Dominance Constraints",
    "abstract": "In real-world decision-making, uncertainty is important yet difficult to\nhandle. Stochastic dominance provides a theoretically sound approach for\ncomparing uncertain quantities, but optimization with stochastic dominance\nconstraints is often computationally expensive, which limits practical\napplicability. In this paper, we develop a simple yet efficient approach for\nthe problem, the Light Stochastic Dominance Solver (light-SD), that leverages\nuseful properties of the Lagrangian. We recast the inner optimization in the\nLagrangian as a learning problem for surrogate approximation, which bypasses\napparent intractability and leads to tractable updates or even closed-form\nsolutions for gradient calculations. We prove convergence of the algorithm and\ntest it empirically. The proposed light-SD demonstrates superior performance on\nseveral representative problems ranging from finance to supply chain\nmanagement.",
    "descriptor": "\nComments: 24 pages, 44 figures\n",
    "authors": [
      "Hanjun Dai",
      "Yuan Xue",
      "Niao He",
      "Bethany Wang",
      "Na Li",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.07767"
  },
  {
    "id": "arXiv:2211.07793",
    "title": "Extreme Generative Image Compression by Learning Text Embedding from  Diffusion Models",
    "abstract": "Transferring large amount of high resolution images over limited bandwidth is\nan important but very challenging task. Compressing images using extremely low\nbitrates (<0.1 bpp) has been studied but it often results in low quality images\nof heavy artifacts due to the strong constraint in the number of bits available\nfor the compressed data. It is often said that a picture is worth a thousand\nwords but on the other hand, language is very powerful in capturing the essence\nof an image using short descriptions. With the recent success of diffusion\nmodels for text-to-image generation, we propose a generative image compression\nmethod that demonstrates the potential of saving an image as a short text\nembedding which in turn can be used to generate high-fidelity images which is\nequivalent to the original one perceptually. For a given image, its\ncorresponding text embedding is learned using the same optimization process as\nthe text-to-image diffusion model itself, using a learnable text embedding as\ninput after bypassing the original transformer. The optimization is applied\ntogether with a learning compression model to achieve extreme compression of\nlow bitrates <0.1 bpp. Based on our experiments measured by a comprehensive set\nof image quality metrics, our method outperforms the other state-of-the-art\ndeep learning methods in terms of both perceptual quality and diversity.",
    "descriptor": "",
    "authors": [
      "Zhihong Pan",
      "Xin Zhou",
      "Hao Tian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07793"
  },
  {
    "id": "arXiv:2211.07795",
    "title": "On Unsupervised Uncertainty-Driven Speech Pseudo-Label Filtering and  Model Calibration",
    "abstract": "Pseudo-label (PL) filtering forms a crucial part of Self-Training (ST)\nmethods for unsupervised domain adaptation. Dropout-based Uncertainty-driven\nSelf-Training (DUST) proceeds by first training a teacher model on source\ndomain labeled data. Then, the teacher model is used to provide PLs for the\nunlabeled target domain data. Finally, we train a student on augmented labeled\nand pseudo-labeled data. The process is iterative, where the student becomes\nthe teacher for the next DUST iteration. A crucial step that precedes the\nstudent model training in each DUST iteration is filtering out noisy PLs that\ncould lead the student model astray. In DUST, we proposed a simple, effective,\nand theoretically sound PL filtering strategy based on the teacher model's\nuncertainty about its predictions on unlabeled speech utterances. We estimate\nthe model's uncertainty by computing disagreement amongst multiple samples\ndrawn from the teacher model during inference by injecting noise via dropout.\nIn this work, we show that DUST's PL filtering, as initially used, may fail\nunder severe source and target domain mismatch. We suggest several approaches\nto eliminate or alleviate this issue. Further, we bring insights from the\nresearch in neural network model calibration to DUST and show that a\nwell-calibrated model correlates strongly with a positive outcome of the DUST\nPL filtering step.",
    "descriptor": "",
    "authors": [
      "Nauman Dawalatabad",
      "Sameer Khurana",
      "Antoine Laurent",
      "James Glass"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07795"
  },
  {
    "id": "arXiv:2211.07798",
    "title": "A Uniform Sampling Procedure for Abstract Triangulations of Surfaces",
    "abstract": "We present a procedure to sample uniformly from the set of combinatorial\nisomorphism types of balanced triangulations of surfaces - also known as\ngraph-encoded surfaces. For a given number $n$, the sample is a weighted set of\ngraph-encoded surfaces with $2n$ triangles.\nThe sampling procedure relies on connections between graph-encoded surfaces\nand permutations, and basic properties of the symmetric group.\nWe implement our method and present a number of experimental findings based\non the analysis of $138$ million runs of our sampling procedure, producing\ngraph-encoded surfaces with up to $280$ triangles.\nNamely, we determine that, for $n$ fixed, the empirical mean genus\n$\\bar{g}(n)$ of our sample is very close to $\\bar{g}(n) = \\frac{n-1}{2} -\n(16.98n -110.61)^{1/4}$. Moreover, we present experimental evidence that the\nassociated genus distribution more and more concentrates on a vanishing portion\nof all possible genera as $n$ tends to infinity. Finally, we observe from our\ndata that the mean number of non-trivial symmetries of a uniformly chosen graph\nencoding of a surface decays to zero at a rate super-exponential in $n$.",
    "descriptor": "\nComments: 12 pages, 17 figures\n",
    "authors": [
      "Rajan Shankar",
      "Jonathan Spreer"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.07798"
  },
  {
    "id": "arXiv:2211.07800",
    "title": "A physics-based model of swarming jellyfish",
    "abstract": "We propose a model for the structure formation of jellyfish swimming based on\nactive Brownian particles. We address the phenomena of counter-current\nswimming, avoidance of turbulent flow regions and foraging. We motivate\ncorresponding mechanisms from observations of jellyfish swarming reported in\nthe literature and incorporate them into the generic modelling framework. The\nmodel characteristics is tested in three paradigmatic flow environments.",
    "descriptor": "\nComments: 31 pages, 12 figures\n",
    "authors": [
      "Erik Gengel",
      "Zafrir Kuplik",
      "Dror Angel",
      "Eyal Heifetz"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Numerical Analysis (math.NA)",
      "Pattern Formation and Solitons (nlin.PS)",
      "Biological Physics (physics.bio-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.07800"
  },
  {
    "id": "arXiv:2211.07807",
    "title": "Hierarchical Inference of the Lensing Convergence from Photometric  Catalogs with Bayesian Graph Neural Networks",
    "abstract": "We present a Bayesian graph neural network (BGNN) that can estimate the weak\nlensing convergence ($\\kappa$) from photometric measurements of galaxies along\na given line of sight. The method is of particular interest in strong\ngravitational time delay cosmography (TDC), where characterizing the \"external\nconvergence\" ($\\kappa_{\\rm ext}$) from the lens environment and line of sight\nis necessary for precise inference of the Hubble constant ($H_0$). Starting\nfrom a large-scale simulation with a $\\kappa$ resolution of $\\sim$1$'$, we\nintroduce fluctuations on galaxy-galaxy lensing scales of $\\sim$1$''$ and\nextract random sightlines to train our BGNN. We then evaluate the model on test\nsets with varying degrees of overlap with the training distribution. For each\ntest set of 1,000 sightlines, the BGNN infers the individual $\\kappa$\nposteriors, which we combine in a hierarchical Bayesian model to yield\nconstraints on the hyperparameters governing the population. For a test field\nwell sampled by the training set, the BGNN recovers the population mean of\n$\\kappa$ precisely and without bias, resulting in a contribution to the $H_0$\nerror budget well under 1\\%. In the tails of the training set with sparse\nsamples, the BGNN, which can ingest all available information about each\nsightline, extracts more $\\kappa$ signal compared to a simplified version of\nthe traditional method based on matching galaxy number counts, which is limited\nby sample variance. Our hierarchical inference pipeline using BGNNs promises to\nimprove the $\\kappa_{\\rm ext}$ characterization for precision TDC. The\nimplementation of our pipeline is available as a public Python package, Node to\nJoy.",
    "descriptor": "\nComments: 15 pages, 8 figures (+ 6 pages, 2 figures in Appendix). Submitted to ApJ. Code at this https URL\n",
    "authors": [
      "Ji Won Park",
      "Simon Birrer",
      "Madison Ueland",
      "Miles Cranmer",
      "Adriano Agnello",
      "Sebastian Wagner-Carena",
      "Philip J. Marshall",
      "Aaron Roodman",
      "LSST Dark Energy Science Collaboration"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07807"
  },
  {
    "id": "arXiv:2211.07833",
    "title": "Optimal sizing of renewable energy storage: A comparative study of  hydrogen and battery system considering degradation and seasonal storage",
    "abstract": "Renewable energy storage (RES) is essential to address the intermittence\nissues of renewable energy systems, thereby enhancing the system stability and\nreliability. This study presents an optimisation study of sizing and\noperational strategy parameters of a grid-connected photovoltaic\n(PV)-hydrogen/battery systems using a Multi-Objective Modified Firefly\nAlgorithm (MOMFA). An operational strategy that utilises the ability of\nhydrogen to store energy over a long time was also investigated. The proposed\nmethod was applied to a real-world distributed energy project located in the\ntropical climate zone. To further demonstrate the robustness and versatility of\nthe method, another synthetic test case was examined for a location in the\nsubtropical weather zone, which has a high seasonal mismatch. The performance\nof the proposed MOMFA method is compared with the NSGA-II method, which has\nbeen widely used to design renewable energy storage systems in the literature.\nThe result shows that MOMFA is more accurate and robust than NSGA-II owing to\nthe complex and dynamic nature of energy storage system. The optimisation\nresults show that battery storage systems, as a mature technology, yield better\neconomic performance than current hydrogen storage systems. However, it is\nproven that hydrogen storage systems provide better techno-economic performance\nand can be a viable long-term storage solution when high penetration of\nrenewable energy is required. The study also proves that the proposed long-term\noperational strategy can lower component degradation, enhance efficiency, and\nincrease the total economic performance of hydrogen storage systems. The\nfindings of this study can support the implementation of energy storage systems\nfor renewable energy.",
    "descriptor": "",
    "authors": [
      "Son Tay Le",
      "Tuan Ngoc Nguyen",
      "Dac-Khuong Bui",
      "Tuan Duc Ngo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.07833"
  },
  {
    "id": "arXiv:2211.07854",
    "title": "Variational Quantum Algorithms for Chemical Simulation and Drug  Discovery",
    "abstract": "Quantum computing has gained a lot of attention recently, and scientists have\nseen potential applications in this field using quantum computing for\nCryptography and Communication to Machine Learning and Healthcare. Protein\nfolding has been one of the most interesting areas to study, and it is also one\nof the biggest problems of biochemistry. Each protein folds distinctively, and\nthe difficulty of finding its stable shape rapidly increases with an increase\nin the number of amino acids in the chain. A moderate protein has about 100\namino acids, and the number of combinations one needs to verify to find the\nstable structure is enormous. At some point, the number of these combinations\nwill be so vast that classical computers cannot even attempt to solve them. In\nthis paper, we examine how this problem can be solved with the help of quantum\ncomputing using two different algorithms, Variational Quantum Eigensolver (VQE)\nand Quantum Approximate Optimization Algorithm (QAOA), using Qiskit Nature. We\ncompare the results of different quantum hardware and simulators and check how\nerror mitigation affects the performance. Further, we make comparisons with\nSoTA algorithms and evaluate the reliability of the method.",
    "descriptor": "",
    "authors": [
      "Hasan Mustafa",
      "Sai Nandan Morapakula",
      "Prateek Jain",
      "Srinjoy Ganguly"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07854"
  },
  {
    "id": "arXiv:2211.07861",
    "title": "Regularized Stein Variational Gradient Flow",
    "abstract": "The Stein Variational Gradient Descent (SVGD) algorithm is an deterministic\nparticle method for sampling. However, a mean-field analysis reveals that the\ngradient flow corresponding to the SVGD algorithm (i.e., the Stein Variational\nGradient Flow) only provides a constant-order approximation to the Wasserstein\nGradient Flow corresponding to the KL-divergence minimization. In this work, we\npropose the Regularized Stein Variational Gradient Flow which interpolates\nbetween the Stein Variational Gradient Flow and the Wasserstein Gradient Flow.\nWe establish various theoretical properties of the Regularized Stein\nVariational Gradient Flow (and its time-discretization) including convergence\nto equilibrium, existence and uniqueness of weak solutions, and stability of\nthe solutions. We provide preliminary numerical evidence of the improved\nperformance offered by the regularization.",
    "descriptor": "",
    "authors": [
      "Ye He",
      "Krishnakumar Balasubramanian",
      "Bharath K. Sriperumbudur",
      "Jianfeng Lu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.07861"
  },
  {
    "id": "arXiv:2211.07866",
    "title": "Adaptive Embedding for Temporal Network",
    "abstract": "Temporal network has become ubiquitous with the rise of online social\nplatform and e-commerce, but largely under investigated in literature. In this\npaper, we propose a statistical framework for temporal network analysis,\nleveraging strengths of adaptive network merging, tensor decomposition and\npoint process. A two-step embedding procedure and a regularized maximum\nlikelihood estimate based on Poisson point process is developed, where the\ninitial estimate is based on equal spaced time intervals while the final\nestimate on the adaptively merging time intervals. A projected gradient descent\nalgorithm is proposed to facilitate estimation, where the upper bound of the\ntensor estimation error in each iteration is established. Through analysis, it\nis shown that the tensor estimation error is significantly reduced by the\nproposed method. Extensive numerical experiments also validate this phenomenon,\nas well as its advantage over other existing competitors. The proposed method\nis also applied to analyze a militarized interstate dispute dataset, where not\nonly the prediction accuracy increases, but the adaptively merged intervals\nalso lead to clear interpretation.",
    "descriptor": "\nComments: 4 pages and 3 figures; the appendix including technical proof will be uploaded later\n",
    "authors": [
      "Haoran Zhang",
      "Junhui Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07866"
  },
  {
    "id": "arXiv:2211.07871",
    "title": "DINER: Disorder-Invariant Implicit Neural Representation",
    "abstract": "Implicit neural representation (INR) characterizes the attributes of a signal\nas a function of corresponding coordinates which emerges as a sharp weapon for\nsolving inverse problems. However, the capacity of INR is limited by the\nspectral bias in the network training. In this paper, we find that such a\nfrequency-related problem could be largely solved by re-arranging the\ncoordinates of the input signal, for which we propose the disorder-invariant\nimplicit neural representation (DINER) by augmenting a hash-table to a\ntraditional INR backbone. Given discrete signals sharing the same histogram of\nattributes and different arrangement orders, the hash-table could project the\ncoordinates into the same distribution for which the mapped signal can be\nbetter modeled using the subsequent INR network, leading to significantly\nalleviated spectral bias. Experiments not only reveal the generalization of the\nDINER for different INR backbones (MLP vs. SIREN) and various tasks\n(image/video representation, phase retrieval, and refractive index recovery)\nbut also show the superiority over the state-of-the-art algorithms both in\nquality and speed.",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Shaowen Xie",
      "Hao Zhu",
      "Zhen Liu",
      "Qi Zhang",
      "You Zhou",
      "Xun Cao",
      "Zhan Ma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07871"
  },
  {
    "id": "arXiv:2211.07881",
    "title": "ET-AL: Entropy-Targeted Active Learning for Bias Mitigation in Materials  Data",
    "abstract": "Growing materials data and data-centric informatics tools drastically promote\nthe discovery and design of materials. While data-driven models, such as\nmachine learning, have drawn much attention and observed significant progress,\nthe quality of data resources is equally important but less studied. In this\nwork, we focus on bias mitigation, an important aspect of materials data\nquality. Quantifying the diversity of stability in different crystal systems,\nwe propose a metric for measuring structure-stability bias in materials data.\nTo mitigate the bias, we develop an entropy-target active learning (ET-AL)\nframework, guiding the acquisition of new data so that diversities of\nunderrepresented crystal systems are improved, thus mitigating the bias. With\nexperiments on materials datasets, we demonstrate the capability of ET-AL and\nthe improvement in machine learning models that mitigating bias offers through\nbias mitigation. The approach is applicable to data-centric informatics in\nother scientific domains.",
    "descriptor": "\nComments: Working paper, 16 pages, 6 figures\n",
    "authors": [
      "Hengrui Zhang",
      "Wei Wayne Chen",
      "James M. Rondinelli",
      "Wei Chen"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07881"
  },
  {
    "id": "arXiv:2211.07897",
    "title": "Notes on Aharoni's rainbow cycle conjecture",
    "abstract": "In 2017, Ron Aharoni made the following conjecture about rainbow cycles in\nedge-coloured graphs: If $G$ is an $n$-vertex graph whose edges are coloured\nwith $n$ colours and each colour class has size at least $r$, then $G$ contains\na rainbow cycle of length at most $\\lceil \\frac{n}{r} \\rceil$. One motivation\nfor studying Aharoni's conjecture is that it is a strengthening of the\nCaccetta-H\\\"aggkvist conjecture on digraphs from 1978.\nIn this article, we present a survey of Aharoni's conjecture, including many\nrecent partial results and related conjectures. We also present a new result\nfor the $r=3$ case. We prove that if $G$ is an $n$-vertex graph whose edges are\ncoloured with $n$ colours and each colour class has size at least 3, then $G$\ncontains a rainbow cycle of length less than $\\frac{4n}{9}+8$. We also discuss\nhow our approach might generalise to larger values of $r$.",
    "descriptor": "\nComments: 11 pages, 0 figures\n",
    "authors": [
      "Katie Clinch",
      "Jackson Goerner",
      "Tony Huynh",
      "Freddie Illingworth"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.07897"
  },
  {
    "id": "arXiv:2211.07907",
    "title": "MMD-B-Fair: Learning Fair Representations with Statistical Testing",
    "abstract": "We introduce a method, MMD-B-Fair, to learn fair representations of data via\nkernel two-sample testing. We find neural features of our data where a maximum\nmean discrepancy (MMD) test cannot distinguish between different values of\nsensitive attributes, while preserving information about the target. Minimizing\nthe power of an MMD test is more difficult than maximizing it (as done in\nprevious work), because the test threshold's complex behavior cannot be simply\nignored. Our method exploits the simple asymptotics of block testing schemes to\nefficiently find fair representations without requiring the complex adversarial\noptimization or generative modelling schemes widely used by existing work on\nfair representation learning. We evaluate our approach on various datasets,\nshowing its ability to \"hide\" information about sensitive attributes, and its\neffectiveness in downstream transfer tasks.",
    "descriptor": "",
    "authors": [
      "Namrata Deka",
      "Danica J. Sutherland"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07907"
  },
  {
    "id": "arXiv:2211.07949",
    "title": "Optimal exploration strategies for finite horizon regret minimization in  some adaptive control problems",
    "abstract": "In this work, we consider the problem of regret minimization in adaptive\nminimum variance and linear quadratic control problems. Regret minimization has\nbeen extensively studied in the literature for both types of adaptive control\nproblems. Most of these works give results of the optimal rate of the regret in\nthe asymptotic regime. In the minimum variance case, the optimal asymptotic\nrate for the regret is $\\log(T)$ which can be reached without any additional\nexternal excitation. On the contrary, for most adaptive linear quadratic\nproblems, it is necessary to add an external excitation in order to get the\noptimal asymptotic rate of $\\sqrt{T}$. In this paper, we will actually show\nfrom an a theoretical study, as well as, in simulations that when the control\nhorizon is pre-specified a lower regret can be obtained with either no external\nexcitation or a new exploration type termed immediate.",
    "descriptor": "",
    "authors": [
      "K\u00e9vin Colin",
      "H\u00e5kan Hjalmarsson",
      "Xavier Bombois"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.07949"
  },
  {
    "id": "arXiv:2211.07966",
    "title": "Adaptive PromptNet For Auxiliary Glioma Diagnosis without  Contrast-Enhanced MRI",
    "abstract": "Multi-contrast magnetic resonance imaging (MRI)-based automatic auxiliary\nglioma diagnosis plays an important role in the clinic. Contrast-enhanced MRI\nsequences (e.g., contrast-enhanced T1-weighted imaging) were utilized in most\nof the existing relevant studies, in which remarkable diagnosis results have\nbeen reported. Nevertheless, acquiring contrast-enhanced MRI data is sometimes\nnot feasible due to the patients physiological limitations. Furthermore, it is\nmore time-consuming and costly to collect contrast-enhanced MRI data in the\nclinic. In this paper, we propose an adaptive PromptNet to address these\nissues. Specifically, a PromptNet for glioma grading utilizing only\nnon-enhanced MRI data has been constructed. PromptNet receives constraints from\nfeatures of contrast-enhanced MR data during training through a designed prompt\nloss. To further boost the performance, an adaptive strategy is designed to\ndynamically weight the prompt loss in a sample-based manner. As a result,\nPromptNet is capable of dealing with more difficult samples. The effectiveness\nof our method is evaluated on a widely-used BraTS2020 dataset, and competitive\nglioma grading performance on NE-MRI data is achieved.",
    "descriptor": "\nComments: 5 pages, 2 figures, 2 tables\n",
    "authors": [
      "Yeqi Wang",
      "Weijian Huang",
      "Cheng Li",
      "Xiawu Zheng",
      "Yusong Lin",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07966"
  },
  {
    "id": "arXiv:2211.07985",
    "title": "Blind Performance Prediction for Deep Learning Based Ultra-Massive MIMO  Channel Estimation",
    "abstract": "Reliability is of paramount importance for the physical layer of wireless\nsystems due to its decisive impact on end-to-end performance. However, the\nuncertainty of prevailing deep learning (DL)-based physical layer algorithms is\nhard to quantify due to the black-box nature of neural networks. This\nlimitation is a major obstacle that hinders their practical deployment. In this\npaper, we attempt to quantify the uncertainty of an important category of\nDL-based channel estimators. An efficient statistical method is proposed to\nmake blind predictions for the mean squared error of the DL-estimated channel\nsolely based on received pilots, without knowledge of the ground-truth channel,\nthe prior distribution of the channel, or the noise statistics. The complexity\nof the blind performance prediction is low and scales only linearly with the\nnumber of antennas. Simulation results for ultra-massive multiple-input\nmultiple-output (UM-MIMO) channel estimation with a mixture of far-field and\nnear-field paths are provided to verify the accuracy and efficiency of the\nproposed method.",
    "descriptor": "\nComments: 6 pages, 3 figures, 1 table, submitted to IEEE for possible publication\n",
    "authors": [
      "Wentao Yu",
      "Hengtao He",
      "Xianghao Yu",
      "Shenghui Song",
      "Jun Zhang",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.07985"
  },
  {
    "id": "arXiv:2211.07993",
    "title": "DIGEST: Deeply supervIsed knowledGE tranSfer neTwork learning for brain  tumor segmentation with incomplete multi-modal MRI scans",
    "abstract": "Brain tumor segmentation based on multi-modal magnetic resonance imaging\n(MRI) plays a pivotal role in assisting brain cancer diagnosis, treatment, and\npostoperative evaluations. Despite the achieved inspiring performance by\nexisting automatic segmentation methods, multi-modal MRI data are still\nunavailable in real-world clinical applications due to quite a few\nuncontrollable factors (e.g. different imaging protocols, data corruption, and\npatient condition limitations), which lead to a large performance drop during\npractical applications. In this work, we propose a Deeply supervIsed knowledGE\ntranSfer neTwork (DIGEST), which achieves accurate brain tumor segmentation\nunder different modality-missing scenarios. Specifically, a knowledge transfer\nlearning frame is constructed, enabling a student model to learn\nmodality-shared semantic information from a teacher model pretrained with the\ncomplete multi-modal MRI data. To simulate all the possible modality-missing\nconditions under the given multi-modal data, we generate incomplete multi-modal\nMRI samples based on Bernoulli sampling. Finally, a deeply supervised knowledge\ntransfer loss is designed to ensure the consistency of the teacher-student\nstructure at different decoding stages, which helps the extraction of inherent\nand effective modality representations. Experiments on the BraTS 2020 dataset\ndemonstrate that our method achieves promising results for the incomplete\nmulti-modal MR image segmentation task.",
    "descriptor": "\nComments: 4 pages,2 figures,2 tables\n",
    "authors": [
      "Haoran Li",
      "Cheng Li",
      "Weijian Huang",
      "Xiawu Zheng",
      "Yan Xi",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07993"
  },
  {
    "id": "arXiv:2211.08006",
    "title": "Auto-outlier Fusion Technique for Chest X-ray classification with  Multi-head Attention Mechanism",
    "abstract": "A chest X-ray is one of the most widely available radiological examinations\nfor diagnosing and detecting various lung illnesses. The National Institutes of\nHealth (NIH) provides an extensive database, ChestX-ray8 and ChestXray14, to\nhelp establish a deep learning community for analysing and predicting lung\ndiseases. ChestX-ray14 consists of 112,120 frontal-view X-ray images of 30,805\ndistinct patients with text-mined fourteen disease image labels, where each\nimage has multiple labels and has been utilised in numerous research in the\npast. To our current knowledge, no previous study has investigated outliers and\nmulti-label impact for a single X-ray image during the preprocessing stage. The\neffect of outliers is mitigated in this paper by our proposed auto-outlier\nfusion technique. The image label is regenerated by concentrating on a\nparticular factor in one image. The final cleaned dataset will be used to\ncompare the mechanisms of multi-head self-attention and multi-head attention\nwith generalised max-pooling.",
    "descriptor": "\nComments: Accepted by the Journal of Image Processing Theory and Applications\n",
    "authors": [
      "Yuru Jing",
      "Zixuan Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.08006"
  },
  {
    "id": "arXiv:2211.08036",
    "title": "Provably Reliable Large-Scale Sampling from Gaussian Processes",
    "abstract": "When comparing approximate Gaussian process (GP) models, it can be helpful to\nbe able to generate data from any GP. If we are interested in how approximate\nmethods perform at scale, we may wish to generate very large synthetic datasets\nto evaluate them. Na\\\"{i}vely doing so would cost \\(\\mathcal{O}(n^3)\\) flops\nand \\(\\mathcal{O}(n^2)\\) memory to generate a size \\(n\\) sample. We demonstrate\nhow to scale such data generation to large \\(n\\) whilst still providing\nguarantees that, with high probability, the sample is indistinguishable from a\nsample from the desired GP.",
    "descriptor": "\nComments: Main article 4 pages + 14 pages of supplementary material. To be published in NeurIPS 2022 Proceedings Workshop on \"Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems\"\n",
    "authors": [
      "Anthony Stephenson",
      "Robert Allison",
      "Edward Pyzer-Knapp"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.08036"
  },
  {
    "id": "arXiv:2211.08043",
    "title": "On the rate of convergence of Bregman proximal methods in constrained  variational inequalities",
    "abstract": "We examine the last-iterate convergence rate of Bregman proximal methods -\nfrom mirror descent to mirror-prox - in constrained variational inequalities.\nOur analysis shows that the convergence speed of a given method depends sharply\non the Legendre exponent of the underlying Bregman regularizer (Euclidean,\nentropic, or other), a notion that measures the growth rate of said regularizer\nnear a solution. In particular, we show that boundary solutions exhibit a clear\nseparation of regimes between methods with a zero and non-zero Legendre\nexponent respectively, with linear convergence for the former versus sublinear\nfor the latter. This dichotomy becomes even more pronounced in linearly\nconstrained problems where, specifically, Euclidean methods converge along\nsharp directions in a finite number of steps, compared to a linear rate for\nentropic methods.",
    "descriptor": "\nComments: 34 pages, 2 tables, 3 figures\n",
    "authors": [
      "Wa\u00efss Azizian",
      "Franck Iutzeler",
      "J\u00e9r\u00f4me Malick",
      "Panayotis Mertikopoulos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08043"
  },
  {
    "id": "arXiv:2211.08105",
    "title": "Few hamiltonian cycles in graphs with one or two vertex degrees",
    "abstract": "We fully disprove a conjecture of Haythorpe on the minimum number of\nhamiltonian cycles in regular hamiltonian graphs, thereby extending a result of\nZamfirescu, as well as correct and complement Haythorpe's computational\nenumerative results from [Experim. Math. 27 (2018) 426-430]. Thereafter, we use\nthe Lov\\'asz Local Lemma to extend Thomassen's independent dominating set\nmethod. Regarding the limitations of this method, we answer a question of\nHaxell, Seamone, and Verstraete, and settle the first open case of a problem of\nThomassen. Motivated by an observation of Aldred and Thomassen, we prove that\nfor every $\\kappa \\in \\{ 2, 3 \\}$ and any positive integer $k$, there are\ninfinitely many non-regular graphs of connectivity $\\kappa$ containing exactly\none hamiltonian cycle and in which every vertex has degree $3$ or $2k$.",
    "descriptor": "",
    "authors": [
      "Jan Goedgebeur",
      "Jorik Jooken",
      "On-Hei Solomon Lo",
      "Ben Seamone",
      "Carol T. Zamfirescu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.08105"
  },
  {
    "id": "arXiv:2211.08120",
    "title": "On the trace ratio method and Fisher's discriminant analysis for robust  multigroup classification",
    "abstract": "We compare two different linear dimensionality reduction strategies for the\nmultigroup classification problem: the trace ratio method and Fisher's\ndiscriminant analysis. Recently, trace ratio optimization has gained in\npopularity due to its computational efficiency for high-dimensional data, as\nwell as occasionally better classification results. However, a statistical\nunderstanding is still incomplete. We study and compare the properties of the\ntwo methods. Then, we propose a robust version of the trace ratio method, to\nhandle the presence of outliers in the data. We reinterpret an asymptotic\nperturbation bound for the solution to the trace ratio, in a contamination\nsetting. Finally, we compare the performance of the trace ratio method and\nFisher's discriminant analysis on both synthetic and real datasets, using\nclassical and robust estimators.",
    "descriptor": "",
    "authors": [
      "Giulia Ferrandi",
      "Igor V. Kravchenko",
      "Michiel E. Hochstenbach",
      "M. Ros\u00e1rio Oliveira"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08120"
  },
  {
    "id": "arXiv:2211.08140",
    "title": "A network science approach to identify disruptive elements of an airline",
    "abstract": "Nowadays, flight delays are quite notorious and propagate from an originating\nflight to connecting flights, which lead to big disruptions in the overall\nschedule. These disruptions cause huge economic losses, affect the reputation\nof airlines, lead to a wastage of time and money of passengers, and have a\ndirect environmental impact. This paper presents a novel network science\napproach for modelling and analysis of an airline's flight schedules and its\nhistorical operational data. The final aim is to find out the most disruptive\nairports, flights, flight-connections and connection-type in an airline\nnetwork. In this regard, disruptive elements refer to influential or critical\nentities of an airline network. These are the elements which either can cause\n(as per airline schedules) or has caused (as per the historical data) the\nbiggest disturbances in the network. An airline, then can improve their\noperations by avoiding disruptive elements. This can be achieved through\nintroduction of an extra slack time between connecting flights and by creation\nof alternate arrangements for aircraft and crew members for the disruptive\nflights and flight-connections. The proposed network science approach for\ndisruptive elements' analysis is validated with a case-study of an operating\nairline. Interestingly, the analysis shows that (potential) disruptive elements\nin the schedule of the airline are also (actual) disruptive elements in the\nhistorical data and should be attended first to improve operations.",
    "descriptor": "\nComments: (under review)\n",
    "authors": [
      "Vinod Kumar Chauhan",
      "Anna Ledwoch",
      "Alexandra Brintrup",
      "Manuel Herrera",
      "Vaggelis Giannikas",
      "Goran Stojkovic",
      "Duncan Mcfarlane"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.08140"
  },
  {
    "id": "arXiv:2211.08146",
    "title": "Encoding feature supervised UNet++: Redesigning Supervision for liver  and tumor segmentation",
    "abstract": "Liver tumor segmentation in CT images is a critical step in the diagnosis,\nsurgical planning and postoperative evaluation of liver disease. An automatic\nliver and tumor segmentation method can greatly relieve physicians of the heavy\nworkload of examining CT images and better improve the accuracy of diagnosis.\nIn the last few decades, many modifications based on U-Net model have been\nproposed in the literature. However, there are relatively few improvements for\nthe advanced UNet++ model. In our paper, we propose an encoding feature\nsupervised UNet++(ES-UNet++) and apply it to the liver and tumor segmentation.\nES-UNet++ consists of an encoding UNet++ and a segmentation UNet++. The\nwell-trained encoding UNet++ can extract the encoding features of label map\nwhich are used to additionally supervise the segmentation UNet++. By adding\nsupervision to the each encoder of segmentation UNet++, U-Nets of different\ndepths that constitute UNet++ outperform the original version by average 5.7%\nin dice score and the overall dice score is thus improved by 2.1%. ES-UNet++ is\nevaluated with dataset LiTS, achieving 95.6% for liver segmentation and 67.4%\nfor tumor segmentation in dice score. In this paper, we also concluded some\nvaluable properties of ES-UNet++ by conducting comparative anaylsis between\nES-UNet++ and UNet++:(1) encoding feature supervision can accelerate the\nconvergence of the model.(2) encoding feature supervision enhances the effect\nof model pruning by achieving huge speedup while providing pruned models with\nfairly good performance.",
    "descriptor": "",
    "authors": [
      "Jiahao Cui",
      "Ruoxin Xiao",
      "Shiyuan Fang",
      "Minnan Pei",
      "Yixuan Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08146"
  },
  {
    "id": "arXiv:2211.08161",
    "title": "Exploring the Joint Use of Rehearsal and Knowledge Distillation in  Continual Learning for Spoken Language Understanding",
    "abstract": "Continual learning refers to a dynamical framework in which a model or agent\nreceives a stream of non-stationary data over time and must adapt to new data\nwhile preserving previously acquired knowledge. Unfortunately, deep neural\nnetworks fail to meet these two desiderata, incurring the so-called\ncatastrophic forgetting phenomenon. Whereas a vast array of strategies have\nbeen proposed to attenuate forgetting in the computer vision domain, for\nspeech-related tasks, on the other hand, there is a dearth of works. In this\npaper, we turn our attention toward the joint use of rehearsal and knowledge\ndistillation (KD) approaches for spoken language understanding under a\nclass-incremental learning scenario. We report on multiple KD combinations at\ndifferent levels in the network, showing that combining feature-level and\npredictions-level KDs leads to the best results. Finally, we provide an\nablation study on the effect of the size of the rehearsal memory that\ncorroborates the appropriateness of our approach for low-resource devices.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Umberto Cappellazzo",
      "Daniele Falavigna",
      "Alessio Brutti"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08161"
  },
  {
    "id": "arXiv:2211.08179",
    "title": "Artificial intelligence approaches for materials-by-design of energetic  materials: state-of-the-art, challenges, and future directions",
    "abstract": "Artificial intelligence (AI) is rapidly emerging as an enabling tool for\nsolving various complex materials design problems. This paper aims to review\nrecent advances in AI-driven materials-by-design and their applications to\nenergetic materials (EM). Trained with data from numerical simulations and/or\nphysical experiments, AI models can assimilate trends and patterns within the\ndesign parameter space, identify optimal material designs (micro-morphologies,\ncombinations of materials in composites, etc.), and point to designs with\nsuperior/targeted property and performance metrics. We review approaches\nfocusing on such capabilities with respect to the three main stages of\nmaterials-by-design, namely representation learning of microstructure\nmorphology (i.e., shape descriptors), structure-property-performance (S-P-P)\nlinkage estimation, and optimization/design exploration. We provide a\nperspective view of these methods in terms of their potential, practicality,\nand efficacy towards the realization of materials-by-design. Specifically,\nmethods in the literature are evaluated in terms of their capacity to learn\nfrom a small/limited number of data, computational complexity,\ngeneralizability/scalability to other material species and operating\nconditions, interpretability of the model predictions, and the burden of\nsupervision/data annotation. Finally, we suggest a few promising future\nresearch directions for EM materials-by-design, such as meta-learning, active\nlearning, Bayesian learning, and semi-/weakly-supervised learning, to bridge\nthe gap between machine learning research and EM research.",
    "descriptor": "",
    "authors": [
      "Joseph B. Choi",
      "Phong C. H. Nguyen",
      "Oishik Sen",
      "H. S. Udaykumar",
      "Stephen Baek"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08179"
  },
  {
    "id": "arXiv:2211.08191",
    "title": "Improved disentangled speech representations using contrastive learning  in factorized hierarchical variational autoencoder",
    "abstract": "By utilizing the fact that speaker identity and content vary on different\ntime scales, \\acrlong{fhvae} (\\acrshort{fhvae}) uses a sequential latent\nvariable and a segmental latent variable to symbolize these two attributes.\nDisentanglement is carried out by assuming the latent variables representing\nspeaker and content follow sequence-dependent and sequence-independent priors.\nFor the sequence-dependent prior, \\acrshort{fhvae} assumes a Gaussian\ndistribution with an utterance-scale varying mean and a fixed small variance.\nThe training process promotes sequential variables getting close to the mean of\nits prior with small variance. However, this constraint is relatively weak.\nTherefore, we introduce contrastive learning in the \\acrshort{fhvae} framework.\nThe proposed method aims to make the sequential variables clustering when\nrepresenting the same speaker, while distancing themselves as far as possible\nfrom those of other speakers. The structure of the framework has not been\nchanged in the proposed method but only the training process, thus no more cost\nis needed during test. Voice conversion has been chosen as the application in\nthis paper. Latent variable evaluations include speakerincrease verification\nand identification for the sequential latent variable, and speech recognition\nfor the segmental latent variable. Furthermore, assessments of voice conversion\nperformance are on the grounds of speaker verification and speech recognition\nexperiments. Experiment results show that the proposed method improves both\nsequential and segmental feature extraction compared with \\acrshort{fhvae}, and\nmoderately improved voice conversion performance.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Yuying Xie",
      "Thomas Arildsen",
      "Zheng-Hua Tan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08191"
  },
  {
    "id": "arXiv:2211.08194",
    "title": "Machine learning for interpreting coherent X-ray speckle patterns",
    "abstract": "Speckle patterns produced by coherent X-ray have a close relationship with\nthe internal structure of materials but quantitative inversion of the\nrelationship to determine structure from images is challenging. Here, we\ninvestigate the link between coherent X-ray speckle patterns and sample\nstructures using a model 2D disk system and explore the ability of machine\nlearning to learn aspects of the relationship. Specifically, we train a deep\nneural network to classify the coherent X-ray speckle pattern images according\nto the disk number density in the corresponding structure. It is demonstrated\nthat the classification system is accurate for both non-disperse and disperse\nsize distributions.",
    "descriptor": "",
    "authors": [
      "Mingren Shen",
      "Dina Sheyfer",
      "Troy David Loeffler",
      "Subramanian K.R.S. Sankaranarayanan",
      "G. Brian Stephenson",
      "Maria K. Y. Chan",
      "Dane Morgan"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08194"
  },
  {
    "id": "arXiv:2211.08210",
    "title": "Reconfigurable Intelligent Surface Aided Wireless Sensing for Scene  Depth Estimation",
    "abstract": "Current scene depth estimation approaches mainly rely on optical sensing,\nwhich carries privacy concerns and suffers from estimation ambiguity for\ndistant, shiny, and transparent surfaces/objects. Reconfigurable intelligent\nsurfaces (RISs) provide a path for employing a massive number of antennas using\nlow-cost and energy-efficient architectures. This has the potential for\nrealizing RIS-aided wireless sensing with high spatial resolution. In this\npaper, we propose to employ RIS-aided wireless sensing systems for scene depth\nestimation. We develop a comprehensive framework for building accurate depth\nmaps using RIS-aided mmWave sensing systems. In this framework, we propose a\nnew RIS interaction codebook capable of creating a sensing grid of reflected\nbeams that meets the desirable characteristics of efficient scene depth map\nconstruction. Using the designed codebook, the received signals are processed\nto build high-resolution depth maps. Simulation results compare the proposed\nsolution against RGB-based approaches and highlight the promise of adopting\nRIS-aided mmWave sensing in scene depth perception.",
    "descriptor": "\nComments: Submitted to IEEE\n",
    "authors": [
      "Abdelrahman Taha",
      "Hao Luo",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.08210"
  },
  {
    "id": "arXiv:2211.08213",
    "title": "Is Style All You Need? Dependencies Between Emotion and GST-based  Speaker Recognition",
    "abstract": "In this work, we study the hypothesis that speaker identity embeddings\nextracted from speech samples may be used for detection and classification of\nemotion. In particular, we show that emotions can be effectively identified by\nlearning speaker identities by use of a 1-D Triplet Convolutional Neural\nNetwork (CNN) & Global Style Token (GST) scheme (e.g., DeepTalk Network) and\nreusing the trained speaker recognition model weights to generate features in\nthe emotion classification domain. The automatic speaker recognition (ASR)\nnetwork is trained with VoxCeleb1, VoxCeleb2, and Librispeech datasets with a\ntriplet training loss function using speaker identity labels. Using an Support\nVector Machine (SVM) classifier, we map speaker identity embeddings into\ndiscrete emotion categories from the CREMA-D, IEMOCAP, and MSP-Podcast\ndatasets. On the task of speech emotion detection, we obtain 80.8% ACC with\nacted emotion samples from CREMA-D, 81.2% ACC with semi-natural emotion samples\nin IEMOCAP, and 66.9% ACC with natural emotion samples in MSP-Podcast. We also\npropose a novel two-stage hierarchical classifier (HC) approach which\ndemonstrates +2% ACC improvement on CREMA-D emotion samples. Through this work,\nwe seek to convey the importance of holistically modeling intra-user variation\nwithin audio samples",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Morgan Sandler",
      "Arun Ross"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.08213"
  },
  {
    "id": "arXiv:2211.08244",
    "title": "Deep learning methods for automatic classification of medical images and  disease detection based on chest X-Ray images",
    "abstract": "Detecting and classifying diseases using X-Ray images is one of the more\nchallenging core tasks in the medical and research world. Innovations and\nrevolutions of Computer Vision with Deep learning methods offer great promise\nfor fast and accurate diagnosis of screening and detection from chest X-Ray\nimages (CXR). This work presents rapid detection of diseases in the lung using\nthe efficient Deep learning pre-trained RepVGG algorithm for deep feature\nextraction and classification. We performed automatic classification of X-Ray\nimages into three categories as Covid-19, Pneumonia, and Normal X-Ray cases.\nFor evaluation, first, we used a histogram-oriented gradient (HOG) to detect\nthe shape of the region of interest (ROI). We used the ROI object to improve\nthe detection accuracy for lung extraction, followed by data pre-processing and\naugmentation. Then a pre-trained RepVGG model is used for deep feature\nextraction and classification, similar to VGG and ResNet convolutional neural\nnetwork for the training-time and inference-time architecture transformed from\nthe multi to the flat mode by a structural re-parameterization technique. Next,\nusing the Computer Vision technique, we created a feature map and superimposed\nit on the original images. We used this technique for the automatic highlighted\ndetection of affected areas of people's lungs. Based on the X-Ray images, we\ndeveloped an algorithm that classifies X-Ray images with height accuracy and\npower faster thanks to the architecture transformation of the model. We compare\ndeep learning frameworks' accuracy and detection of disease. The study shows\nthe high power of deep learning methods for X-Ray images based on COVID-19\ndetection utilizing chest X-Ray. The proposed framework shows better diagnostic\naccuracy by comparing popular deep learning models, i.e., VGG, ResNet50,\ninceptionV3, DenseNet, and InceptionResnetV2.",
    "descriptor": "",
    "authors": [
      "Liora Mayats-Alpay"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08244"
  },
  {
    "id": "arXiv:2211.08267",
    "title": "Reads2Vec: Efficient Embedding of Raw High-Throughput Sequencing Reads  Data",
    "abstract": "The massive amount of genomic data appearing for SARS-CoV-2 since the\nbeginning of the COVID-19 pandemic has challenged traditional methods for\nstudying its dynamics. As a result, new methods such as Pangolin, which can\nscale to the millions of samples of SARS-CoV-2 currently available, have\nappeared. Such a tool is tailored to take as input assembled, aligned and\ncurated full-length sequences, such as those found in the GISAID database. As\nhigh-throughput sequencing technologies continue to advance, such assembly,\nalignment and curation may become a bottleneck, creating a need for methods\nwhich can process raw sequencing reads directly.\nIn this paper, we propose Reads2Vec, an alignment-free embedding approach\nthat can generate a fixed-length feature vector representation directly from\nthe raw sequencing reads without requiring assembly. Furthermore, since such an\nembedding is a numerical representation, it may be applied to highly optimized\nclassification and clustering algorithms. Experiments on simulated data show\nthat our proposed embedding obtains better classification results and better\nclustering properties contrary to existing alignment-free baselines. In a study\non real data, we show that alignment-free embeddings have better clustering\nproperties than the Pangolin tool and that the spike region of the SARS-CoV-2\ngenome heavily informs the alignment-free clusterings, which is consistent with\ncurrent biological knowledge of SARS-CoV-2.",
    "descriptor": "",
    "authors": [
      "Prakash Chourasia",
      "Sarwan Ali",
      "Simone Ciccolella",
      "Gianluca Della Vedova",
      "Murray Patterson"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2211.08267"
  },
  {
    "id": "arXiv:2211.08281",
    "title": "Forecasting Bitcoin volatility spikes from whale transactions and  CryptoQuant data using Synthesizer Transformer models",
    "abstract": "The cryptocurrency market is highly volatile compared to traditional\nfinancial markets. Hence, forecasting its volatility is crucial for risk\nmanagement. In this paper, we investigate CryptoQuant data (e.g. on-chain\nanalytics, exchange and miner data) and whale-alert tweets, and explore their\nrelationship to Bitcoin's next-day volatility, with a focus on extreme\nvolatility spikes. We propose a deep learning Synthesizer Transformer model for\nforecasting volatility. Our results show that the model outperforms existing\nstate-of-the-art models when forecasting extreme volatility spikes for Bitcoin\nusing CryptoQuant data as well as whale-alert tweets. We analysed our model\nwith the Captum XAI library to investigate which features are most important.\nWe also backtested our prediction results with different baseline trading\nstrategies and the results show that we are able to minimize drawdown while\nkeeping steady profits. Our findings underscore that the proposed method is a\nuseful tool for forecasting extreme volatility movements in the Bitcoin market.",
    "descriptor": "\nComments: Co-first authors\n",
    "authors": [
      "Dorien Herremans",
      "Kah Wee Low"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08281"
  },
  {
    "id": "arXiv:2211.08291",
    "title": "Attacking and Defending Deep-Learning-Based Off-Device Wireless  Positioning Systems",
    "abstract": "Localization services for wireless devices play an increasingly important\nrole and a plethora of emerging services and applications already rely on\nprecise position information. Widely used on-device positioning methods, such\nas the global positioning system, enable accurate outdoor positioning and\nprovide the users with full control over what services are allowed to access\nlocation information. To provide accurate positioning indoors or in cluttered\nurban scenarios without line-of-sight satellite connectivity, powerful\noff-device positioning systems, which process channel state information (CSI)\nwith deep neural networks, have emerged recently. Such off-device positioning\nsystems inherently link a user's data transmission with its localization, since\naccurate CSI measurements are necessary for reliable wireless communication --\nthis not only prevents the users from controlling who can access this\ninformation but also enables virtually everyone in the device's range to\nestimate its location, resulting in serious privacy and security concerns. We\npropose on-device attacks against off-device wireless positioning systems in\nmulti-antenna orthogonal frequency-division multiplexing systems while\nminimizing the impact on quality-of-service, and we demonstrate their efficacy\nusing measured datasets for outdoor and indoor scenarios. We also investigate\ndefenses to counter such attack mechanisms, and we discuss the limitations and\nimplications on protecting location privacy in future wireless communication\nsystems.",
    "descriptor": "\nComments: Submitted to a journal\n",
    "authors": [
      "Pengzhi Huang",
      "Emre G\u00f6n\u00fclta\u015f",
      "Maximilian Arnold",
      "K. Pavan Srinath",
      "Jakob Hoydis",
      "Christoph Studer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.08291"
  },
  {
    "id": "arXiv:2211.08303",
    "title": "Reverberation as Supervision for Speech Separation",
    "abstract": "This paper proposes reverberation as supervision (RAS), a novel unsupervised\nloss function for single-channel reverberant speech separation. Prior methods\nfor unsupervised separation required the synthesis of mixtures of mixtures or\nassumed the existence of a teacher model, making them difficult to consider as\npotential methods explaining the emergence of separation abilities in an\nanimal's auditory system. We assume the availability of two-channel mixtures at\ntraining time, and train a neural network to separate the sources given one of\nthe channels as input such that the other channel may be predicted from the\nseparated sources. As the relationship between the room impulse responses\n(RIRs) of each channel depends on the locations of the sources, which are\nunknown to the network, the network cannot rely on learning that relationship.\nInstead, our proposed loss function fits each of the separated sources to the\nmixture in the target channel via Wiener filtering, and compares the resulting\nmixture to the ground-truth one. We show that minimizing the scale-invariant\nsignal-to-distortion ratio (SI-SDR) of the predicted right-channel mixture with\nrespect to the ground truth implicitly guides the network towards separating\nthe left-channel sources. On a semi-supervised reverberant speech separation\ntask based on the WHAMR! dataset, using training data where just 5% (resp.,\n10%) of the mixtures are labeled with associated isolated sources, we achieve\n70% (resp., 78%) of the SI-SDR improvement obtained when training with\nsupervision on the full training set, while a model trained only on the labeled\ndata obtains 43% (resp., 45%).",
    "descriptor": "\nComments: 5 pages, 2 figures, 4 tables. Submitted to ICASSP 2023\n",
    "authors": [
      "Rohith Aralikatti",
      "Christoph Boeddeker",
      "Gordon Wichern",
      "Aswin Shanmugam Subramanian",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08303"
  },
  {
    "id": "arXiv:2211.08311",
    "title": "On Penalization in Stochastic Multi-armed Bandits",
    "abstract": "We study an important variant of the stochastic multi-armed bandit (MAB)\nproblem, which takes penalization into consideration. Instead of directly\nmaximizing cumulative expected reward, we need to balance between the total\nreward and fairness level. In this paper, we present some new insights in MAB\nand formulate the problem in the penalization framework, where rigorous\npenalized regret can be well defined and more sophisticated regret analysis is\npossible. Under such a framework, we propose a hard-threshold UCB-like\nalgorithm, which enjoys many merits including asymptotic fairness, nearly\noptimal regret, better tradeoff between reward and fairness. Both gap-dependent\nand gap-independent regret bounds have been established. Multiple insightful\ncomments are given to illustrate the soundness of our theoretical analysis.\nNumerous experimental results corroborate the theory and show the superiority\nof our method over other existing methods.",
    "descriptor": "",
    "authors": [
      "Guanhua Fang",
      "Ping Li",
      "Gennady Samorodnitsky"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08311"
  },
  {
    "id": "arXiv:2211.08326",
    "title": "Contrastive learning for regression in multi-site brain age prediction",
    "abstract": "Building accurate Deep Learning (DL) models for brain age prediction is a\nvery relevant topic in neuroimaging, as it could help better understand\nneurodegenerative disorders and find new biomarkers. To estimate accurate and\ngeneralizable models, large datasets have been collected, which are often\nmulti-site and multi-scanner. This large heterogeneity negatively affects the\ngeneralization performance of DL models since they are prone to overfit\nsite-related noise. Recently, contrastive learning approaches have been shown\nto be more robust against noise in data or labels. For this reason, we propose\na novel contrastive learning regression loss for robust brain age prediction\nusing MRI scans. Our method achieves state-of-the-art performance on the\nOpenBHB challenge, yielding the best generalization capability and robustness\nto site-related noise.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Carlo Alberto Barbano",
      "Benoit Dufumier",
      "Edouard Duchesnay",
      "Marco Grangetto",
      "Pietro Gori"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08326"
  },
  {
    "id": "arXiv:2211.08333",
    "title": "Deformation Spaces and Static Animations",
    "abstract": "We study applications of 3D printing to the broad goal of understanding how\nmathematical objects vary continuously in families. To do so, we model the\nvarying parameter as the vertical axis of a 3D print, introducing the notion of\na static animation: a 3D printed object each of whose layers is a member of the\ncontinuously deforming family. We survey examples and draw connections to\nalgebraic geometry, complex dynamics, chaos theory, and more. We also include a\ndetailed tutorial (with accompanying code and files) so that the reader can\ncreate static animations of their own.",
    "descriptor": "\nComments: 50 Pages, 52 figures. From the JMM Mini-Course \"3D Printing in Mathematics: Challenges and Applications.\" Submitted to the conference proceedings in PSAPM. Comments are welcome\n",
    "authors": [
      "Gabriel Dorfsman-Hopkins"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "Computational Geometry (cs.CG)",
      "Complex Variables (math.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08333"
  },
  {
    "id": "arXiv:2211.08345",
    "title": "On interpretability and proper latent decomposition of autoencoders",
    "abstract": "The dynamics of a turbulent flow tend to occupy only a portion of the phase\nspace at a statistically stationary regime. From a dynamical systems point of\nview, this portion is the attractor. The knowledge of the turbulent attractor\nis useful for two purposes, at least: (i) We can gain physical insight into\nturbulence (what is the shape and geometry of the attractor?), and (ii) it\nprovides the minimal number of degrees of freedom to accurately describe the\nturbulent dynamics. Autoencoders enable the computation of an optimal latent\nspace, which is a low-order representation of the dynamics. If properly trained\nand correctly designed, autoencoders can learn an approximation of the\nturbulent attractor, as shown by Doan, Racca and Magri (2022). In this paper,\nwe theoretically interpret the transformations of an autoencoder. First, we\nremark that the latent space is a curved manifold with curvilinear coordinates,\nwhich can be analyzed with simple tools from Riemann geometry. Second, we\ncharacterize the geometrical properties of the latent space. We mathematically\nderive the metric tensor, which provides a mathematical description of the\nmanifold. Third, we propose a method -- proper latent decomposition (PLD) --\nthat generalizes proper orthogonal decomposition of turbulent flows on the\nautoencoder latent space. This decomposition finds the dominant directions in\nthe curved latent space. This theoretical work opens up computational\nopportunities for interpreting autoencoders and creating reduced-order models\nof turbulent flows.",
    "descriptor": "\nComments: 9 pages, 2 figures, Proceedings of the Summer Program, Center for Turbulence Research, Stanford University\n",
    "authors": [
      "Luca Magri",
      "Anh Khoa Doan"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08345"
  },
  {
    "id": "arXiv:2211.08388",
    "title": "Photometric identification of compact galaxies, stars and quasars using  multiple neural networks",
    "abstract": "We present MargNet, a deep learning-based classifier for identifying stars,\nquasars and compact galaxies using photometric parameters and images from the\nSloan Digital Sky Survey (SDSS) Data Release 16 (DR16) catalogue. MargNet\nconsists of a combination of Convolutional Neural Network (CNN) and Artificial\nNeural Network (ANN) architectures. Using a carefully curated dataset\nconsisting of 240,000 compact objects and an additional 150,000 faint objects,\nthe machine learns classification directly from the data, minimising the need\nfor human intervention. MargNet is the first classifier focusing exclusively on\ncompact galaxies and performs better than other methods to classify compact\ngalaxies from stars and quasars, even at fainter magnitudes. This model and\nfeature engineering in such deep learning architectures will provide greater\nsuccess in identifying objects in the ongoing and upcoming surveys, such as\nDark Energy Survey (DES) and images from the Vera C. Rubin Observatory.",
    "descriptor": "\nComments: 14 pages, 10 figures, Accepted for publication in MNRAS\n",
    "authors": [
      "Siddharth Chaini",
      "Atharva Bagul",
      "Anish Deshpande",
      "Rishi Gondkar",
      "Kaushal Sharma",
      "M. Vivek",
      "Ajit Kembhavi"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08388"
  },
  {
    "id": "arXiv:2211.08405",
    "title": "Using multimodal learning and deep generative models for corporate  bankruptcy prediction",
    "abstract": "This research introduces for the first time the concept of multimodal\nlearning in bankruptcy prediction models. We use the Conditional Multimodal\nDiscriminative (CMMD) model to learn multimodal representations that embed\ninformation from accounting, market, and textual modalities. The CMMD model\nneeds a sample with all data modalities for model training. At test time, the\nCMMD model only needs access to accounting and market modalities to generate\nmultimodal representations, which are further used to make bankruptcy\npredictions. This fact makes the use of bankruptcy prediction models using\ntextual data realistic and possible, since accounting and market data are\navailable for all companies unlike textual data. The empirical results in this\nresearch show that the classification performance of our proposed methodology\nis superior compared to that of a large number of traditional classifier\nmodels. We also show that our proposed methodology solves the limitation of\nprevious bankruptcy models using textual data, as they can only make\npredictions for a small proportion of companies. Finally, based on multimodal\nrepresentations, we introduce an index that is able to capture the uncertainty\nof the financial situation of companies during periods of financial distress.",
    "descriptor": "",
    "authors": [
      "Rogelio A. Mancisidor"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08405"
  },
  {
    "id": "arXiv:2211.08406",
    "title": "Incorporating Pre-training Paradigm for Antibody Sequence-Structure  Co-design",
    "abstract": "Antibodies are versatile proteins that can bind to pathogens and provide\neffective protection for human body. Recently, deep learning-based\ncomputational antibody design has attracted popular attention since it\nautomatically mines the antibody patterns from data that could be complementary\nto human experiences. However, the computational methods heavily rely on\nhigh-quality antibody structure data, which is quite limited. Besides, the\ncomplementarity-determining region (CDR), which is the key component of an\nantibody that determines the specificity and binding affinity, is highly\nvariable and hard to predict. Therefore, the data limitation issue further\nraises the difficulty of CDR generation for antibodies. Fortunately, there\nexists a large amount of sequence data of antibodies that can help model the\nCDR and alleviate the reliance on structure data. By witnessing the success of\npre-training models for protein modeling, in this paper, we develop the\nantibody pre-training language model and incorporate it into the\n(antigen-specific) antibody design model in a systemic way. Specifically, we\nfirst pre-train an antibody language model based on the sequence data, then\npropose a one-shot way for sequence and structure generation of CDR to avoid\nthe heavy cost and error propagation from an autoregressive manner, and finally\nleverage the pre-trained antibody model for the antigen-specific antibody\ngeneration model with some carefully designed modules. Through various\nexperiments, we show that our method achieves superior performances over\nprevious baselines on different tasks, such as sequence and structure\ngeneration and antigen-binding CDR-H3 design.",
    "descriptor": "",
    "authors": [
      "Kaiyuan Gao",
      "Lijun Wu",
      "Jinhua Zhu",
      "Tianbo Peng",
      "Yingce Xia",
      "Liang He",
      "Shufang Xie",
      "Tao Qin",
      "Haiguang Liu",
      "Kun He",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08406"
  },
  {
    "id": "arXiv:2211.08417",
    "title": "Acyclic colourings of graphs with obstructions",
    "abstract": "Given a graph $G$, a colouring of $G$ is acyclic if it is a proper colouring\nof $G$ and every cycle contains at least three colours. Its acyclic chromatic\nnumber $\\chi_a(G)$ is the minimum $k$ such that there exists a proper\n$k$-colouring of $G$ with no bicoloured cycle. In general, when $G$ has maximum\ndegree $\\Delta$, it is known that $\\chi_a(G) = O(\\Delta^{4/3})$ as $\\Delta \\to\n\\infty$. We study the effect on this bound of further requiring that $G$ does\nnot contain some fixed subgraph $F$ on $t$ vertices. We establish that the\nbound is constant if $F$ is a subdivided tree, $O(t^{8/3}\\Delta^{2/3})$ if $F$\nis a forest, $O(\\sqrt{t}\\Delta)$ if $F$ is bipartite and 1-acyclic, $2\\Delta +\no(\\Delta)$ if $F$ is an even cycle of length at least $6$, and\n$O(t^{1/4}\\Delta^{5/4})$ if $F=K_{3,t}$.",
    "descriptor": "",
    "authors": [
      "Quentin Chuet",
      "Johanne Cohen",
      "Fran\u00e7ois Pirot"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.08417"
  },
  {
    "id": "arXiv:2211.08420",
    "title": "Is the Machine Smarter than the Theorist: Deriving Formulas for Particle  Kinematics with Symbolic Regression",
    "abstract": "We demonstrate the use of symbolic regression in deriving analytical\nformulas, which are needed at various stages of a typical experimental analysis\nin collider phenomenology. As a first application, we consider kinematic\nvariables like the stransverse mass, $M_{T2}$, which are defined\nalgorithmically through an optimization procedure and not in terms of an\nanalytical formula. We then train a symbolic regression and obtain the correct\nanalytical expressions for all known special cases of $M_{T2}$ in the\nliterature. As a second application, we reproduce the correct analytical\nexpression for a next-to-leading order (NLO) kinematic distribution from data,\nwhich is simulated with a NLO event generator. Finally, we derive analytical\napproximations for the NLO kinematic distributions after detector simulation,\nfor which no known analytical formulas currently exist.",
    "descriptor": "\nComments: 15 pages, 13 figures, 8 tables\n",
    "authors": [
      "Zhongtian Dong",
      "Kyoungchul Kong",
      "Konstantin T. Matchev",
      "Katia Matcheva"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2211.08420"
  },
  {
    "id": "arXiv:1811.06787",
    "title": "On the power of euclidean division: Lower bounds for algebraic machines,  semantically",
    "abstract": "On the power of euclidean division: Lower bounds for algebraic machines,  semantically",
    "descriptor": "",
    "authors": [
      "Thomas Seiller",
      "Luc Pellissier",
      "Ulysse L\u00e9chine"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1811.06787"
  },
  {
    "id": "arXiv:1902.01635",
    "title": "Riemannian optimization with a preconditioning scheme on the generalized  Stiefel manifold",
    "abstract": "Riemannian optimization with a preconditioning scheme on the generalized  Stiefel manifold",
    "descriptor": "",
    "authors": [
      "Boris Shustin",
      "Haim Avron"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1902.01635"
  },
  {
    "id": "arXiv:1906.02104",
    "title": "Unbiased estimators for the variance of MMD estimators",
    "abstract": "Comments: Fixes and extends the appendices of arXiv:1611.04488 and arXiv:1511.04581. v3: Fix a significant error, plus several improvements and references to recent alternatives",
    "descriptor": "\nComments: Fixes and extends the appendices of arXiv:1611.04488 and arXiv:1511.04581. v3: Fix a significant error, plus several improvements and references to recent alternatives\n",
    "authors": [
      "Danica J. Sutherland",
      "Namrata Deka"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1906.02104"
  },
  {
    "id": "arXiv:1907.03206",
    "title": "Filaments of crime: Informing policing via thresholded ridge estimation",
    "abstract": "Comments: 16 pages, 4 figures, accepted for publication in Decision Support Systems",
    "descriptor": "\nComments: 16 pages, 4 figures, accepted for publication in Decision Support Systems\n",
    "authors": [
      "Ben Moews",
      "Jaime R. Argueta Jr.",
      "Antonia Gieschen"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/1907.03206"
  },
  {
    "id": "arXiv:1907.07786",
    "title": "Product Aesthetic Design: A Machine Learning Augmentation",
    "abstract": "Product Aesthetic Design: A Machine Learning Augmentation",
    "descriptor": "",
    "authors": [
      "Alex Burnap",
      "John R. Hauser",
      "Artem Timoshenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1907.07786"
  },
  {
    "id": "arXiv:1909.00263",
    "title": "Homotopic curve shortening and the affine curve-shortening flow",
    "abstract": "Comments: Minor changes. 28 pages, 22 figures, 2 tables",
    "descriptor": "\nComments: Minor changes. 28 pages, 22 figures, 2 tables\n",
    "authors": [
      "Sergey Avvakumov",
      "Gabriel Nivasch"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/1909.00263"
  },
  {
    "id": "arXiv:1910.10376",
    "title": "Emanation Graph: A Plane Geometric Spanner with Steiner Points",
    "abstract": "Comments: A preliminary version of this work was presented at the 30th Canadian Conference on Computational Geometry (CCCG) and the 46th International Conference on Current Trends in Theory and Practice of Computer Science (SOFSEM)",
    "descriptor": "\nComments: A preliminary version of this work was presented at the 30th Canadian Conference on Computational Geometry (CCCG) and the 46th International Conference on Current Trends in Theory and Practice of Computer Science (SOFSEM)\n",
    "authors": [
      "Bardia Hamedmohseni",
      "Zahed Rahmati",
      "Debajyoti Mondal"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1910.10376"
  },
  {
    "id": "arXiv:2006.16395",
    "title": "On Bellman's Optimality Principle for zs-POSGs",
    "abstract": "Comments: 18 pages, 0 figures, 1 algorithm",
    "descriptor": "\nComments: 18 pages, 0 figures, 1 algorithm\n",
    "authors": [
      "Olivier Buffet",
      "Jilles Dibangoye",
      "Aur\u00e9lien Delage",
      "Abdallah Saffidine",
      "Vincent Thomas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2006.16395"
  },
  {
    "id": "arXiv:2007.02354",
    "title": "Analysis of a splitting scheme for a class of nonlinear stochastic  Schr\u00f6dinger equations",
    "abstract": "Analysis of a splitting scheme for a class of nonlinear stochastic  Schr\u00f6dinger equations",
    "descriptor": "",
    "authors": [
      "Charles-Edouard Br\u00e9hier",
      "David Cohen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2007.02354"
  },
  {
    "id": "arXiv:2007.03909",
    "title": "Best-First Beam Search",
    "abstract": "Comments: TACL 2020",
    "descriptor": "\nComments: TACL 2020\n",
    "authors": [
      "Clara Meister",
      "Tim Vieira",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2007.03909"
  },
  {
    "id": "arXiv:2008.03101",
    "title": "Privacy Guarantees for De-identifying Text Transformations",
    "abstract": "Comments: Proceedings of INTERSPEECH 2020 (Added link to code/data)",
    "descriptor": "\nComments: Proceedings of INTERSPEECH 2020 (Added link to code/data)\n",
    "authors": [
      "David Ifeoluwa Adelani",
      "Ali Davody",
      "Thomas Kleinbauer",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2008.03101"
  },
  {
    "id": "arXiv:2011.08552",
    "title": "Agafonov's Theorem for finite and infinite alphabets and probability  distributions different from equidistribution",
    "abstract": "Agafonov's Theorem for finite and infinite alphabets and probability  distributions different from equidistribution",
    "descriptor": "",
    "authors": [
      "Thomas Seiller",
      "Jakob Grue Simonsen"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Dynamical Systems (math.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2011.08552"
  },
  {
    "id": "arXiv:2011.12427",
    "title": "A New Periocular Dataset Collected by Mobile Devices in Unconstrained  Scenarios",
    "abstract": "A New Periocular Dataset Collected by Mobile Devices in Unconstrained  Scenarios",
    "descriptor": "",
    "authors": [
      "Luiz A. Zanlorensi",
      "Rayson Laroca",
      "Diego R. Lucio",
      "Lucas R. Santos",
      "Alceu S. Britto Jr.",
      "David Menotti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.12427"
  },
  {
    "id": "arXiv:2102.08485",
    "title": "Improved management of issue dependencies in issue trackers of large  collaborative projects",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Software Engineering. Published online 05 October 2022. 21 pages, 3 figures, 8 tables",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Software Engineering. Published online 05 October 2022. 21 pages, 3 figures, 8 tables\n",
    "authors": [
      "Mikko Raatikainen",
      "Quim Motger",
      "Clara Marie L\u00fcders",
      "Xavier Franch",
      "Lalli Myllyaho",
      "Elina Kettunen",
      "Jordi Marco",
      "Juha Tiihonen",
      "Mikko Halonen",
      "Tomi M\u00e4nnist\u00f6"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.08485"
  },
  {
    "id": "arXiv:2102.09149",
    "title": "Classically Verifiable NIZK for QMA with Preprocessing",
    "abstract": "Comments: 46 pages This is a major update version of arXiv:2003.10712. A new result, NIZK via Fiat-Shamir, is added. (Sec.5)",
    "descriptor": "\nComments: 46 pages This is a major update version of arXiv:2003.10712. A new result, NIZK via Fiat-Shamir, is added. (Sec.5)\n",
    "authors": [
      "Tomoyuki Morimae",
      "Takashi Yamakawa"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.09149"
  },
  {
    "id": "arXiv:2103.02227",
    "title": "Data Augmentation with Hierarchical SQL-to-Question Generation for  Cross-domain Text-to-SQL Parsing",
    "abstract": "Data Augmentation with Hierarchical SQL-to-Question Generation for  Cross-domain Text-to-SQL Parsing",
    "descriptor": "",
    "authors": [
      "Kun Wu",
      "Lijie Wang",
      "Zhenghua Li",
      "Ao Zhang",
      "Xinyan Xiao",
      "Hua Wu",
      "Min Zhang",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.02227"
  },
  {
    "id": "arXiv:2104.01888",
    "title": "Non-Homogeneous Haze Removal via Artificial Scene Prior and  Bidimensional Graph Reasoning",
    "abstract": "Non-Homogeneous Haze Removal via Artificial Scene Prior and  Bidimensional Graph Reasoning",
    "descriptor": "",
    "authors": [
      "Haoran Wei",
      "Qingbo Wu",
      "Hui Li",
      "King Ngi Ngan",
      "Hongliang Li",
      "Fanman Meng",
      "Linfeng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01888"
  },
  {
    "id": "arXiv:2104.13097",
    "title": "Minimum Stable Cut and Treewidth",
    "abstract": "Comments: Full version of ICALP 2021 paper",
    "descriptor": "\nComments: Full version of ICALP 2021 paper\n",
    "authors": [
      "Michael Lampis"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.13097"
  },
  {
    "id": "arXiv:2105.05172",
    "title": "The explicit formulae for the distributions of nonoverlapping words and  its applications to statistical tests for pseudo random numbers",
    "abstract": "The explicit formulae for the distributions of nonoverlapping words and  its applications to statistical tests for pseudo random numbers",
    "descriptor": "",
    "authors": [
      "Hayato Takahashi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.05172"
  },
  {
    "id": "arXiv:2106.02229",
    "title": "Differentiable Architecture Search for Reinforcement Learning",
    "abstract": "Comments: Published as a conference paper at the first Automated Machine Learning Conference (AutoML-Conf) 2022. Code can be found at this https URL",
    "descriptor": "\nComments: Published as a conference paper at the first Automated Machine Learning Conference (AutoML-Conf) 2022. Code can be found at this https URL\n",
    "authors": [
      "Yingjie Miao",
      "Xingyou Song",
      "John D. Co-Reyes",
      "Daiyi Peng",
      "Summer Yue",
      "Eugene Brevdo",
      "Aleksandra Faust"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02229"
  },
  {
    "id": "arXiv:2106.04690",
    "title": "Handcrafted Backdoors in Deep Neural Networks",
    "abstract": "Comments: Accepted to NeurIPS 2022 [Oral]",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 [Oral]\n",
    "authors": [
      "Sanghyun Hong",
      "Nicholas Carlini",
      "Alexey Kurakin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04690"
  },
  {
    "id": "arXiv:2106.08056",
    "title": "Coupled Gradient Estimators for Discrete Latent Variables",
    "abstract": "Comments: Published in NeurIPS 2021",
    "descriptor": "\nComments: Published in NeurIPS 2021\n",
    "authors": [
      "Zhe Dong",
      "Andriy Mnih",
      "George Tucker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.08056"
  },
  {
    "id": "arXiv:2106.12124",
    "title": "Secure Domain Adaptation with Multiple Sources",
    "abstract": "Secure Domain Adaptation with Multiple Sources",
    "descriptor": "",
    "authors": [
      "Serban Stan",
      "Mohammad Rostami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12124"
  },
  {
    "id": "arXiv:2107.01693",
    "title": "A precise bare simulation approach to the minimization of some  distances. Foundations",
    "abstract": "Comments: v3: considerably shortened and restructured version of v1/v2; 64 pages + 7 pages supplement. This work is accepted by the journal \"IEEE Transactions on Information Theory\", and is available in early-access form at this https URL",
    "descriptor": "\nComments: v3: considerably shortened and restructured version of v1/v2; 64 pages + 7 pages supplement. This work is accepted by the journal \"IEEE Transactions on Information Theory\", and is available in early-access form at this https URL\n",
    "authors": [
      "Michel Broniatowski",
      "Wolfgang Stummer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01693"
  },
  {
    "id": "arXiv:2108.00598",
    "title": "Interference-Aware Accurate Signal Recovery in sub-1 GHz UHF Band  Reuse-1 Cellular OFDMA Downlinks",
    "abstract": "Comments: in IEEE Open Journal of the Communications Society, 2022",
    "descriptor": "\nComments: in IEEE Open Journal of the Communications Society, 2022\n",
    "authors": [
      "Abhay Mohan M V",
      "Giridhar K"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.00598"
  },
  {
    "id": "arXiv:2108.01512",
    "title": "Spatial Analysis of Physical Reservoir Computers",
    "abstract": "Comments: 7 Pages, 5 Figures",
    "descriptor": "\nComments: 7 Pages, 5 Figures\n",
    "authors": [
      "Jake Love",
      "Jeroen Mulkers",
      "Robin Msiska",
      "George Bourianoff",
      "Jonathan Leliaert",
      "Karin Everschor-Sitte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Other Condensed Matter (cond-mat.other)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2108.01512"
  },
  {
    "id": "arXiv:2108.06259",
    "title": "VulnEx: Exploring Open-Source Software Vulnerabilities in Large  Development Organizations to Understand Risk Exposure",
    "abstract": "Comments: 5 pages, 3 figures, LaTeX; corrected typos and wording; added DOI",
    "descriptor": "\nComments: 5 pages, 3 figures, LaTeX; corrected typos and wording; added DOI\n",
    "authors": [
      "Frederik L. Dennig",
      "Eren Cakmak",
      "Henrik Plate",
      "Daniel A. Keim"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.06259"
  },
  {
    "id": "arXiv:2108.11106",
    "title": "Dropout against Deep Leakage from Gradients",
    "abstract": "Dropout against Deep Leakage from Gradients",
    "descriptor": "",
    "authors": [
      "Yanchong Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.11106"
  },
  {
    "id": "arXiv:2108.12018",
    "title": "Existence of Uncertainty Minimizers for the Continuous Wavelet Transform",
    "abstract": "Comments: 15 pages, v2 fixed minor typos",
    "descriptor": "\nComments: 15 pages, v2 fixed minor typos\n",
    "authors": [
      "Simon Halvdansson",
      "Jan-Fredrik Olsen",
      "Nir Sochen",
      "Ron Levie"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.12018"
  },
  {
    "id": "arXiv:2109.02580",
    "title": "Ultra-high Resolution Image Segmentation via Locality-aware Context  Fusion and Alternating Local Enhancement",
    "abstract": "Comments: Extension of ICCV 2021 \"From Contexts to Locality: Ultra-high Resolution Image Segmentation via Locality-aware Contextual Correlation\"",
    "descriptor": "\nComments: Extension of ICCV 2021 \"From Contexts to Locality: Ultra-high Resolution Image Segmentation via Locality-aware Contextual Correlation\"\n",
    "authors": [
      "Wenxi Liu",
      "Qi Li",
      "Xindai Lin",
      "Weixiang Yang",
      "Shengfeng He",
      "Yuanlong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.02580"
  },
  {
    "id": "arXiv:2109.05536",
    "title": "Link Scheduling using Graph Neural Networks",
    "abstract": "Comments: Main: 15 pages, 12 figures. Supplement: 5 pages, 7 figures. Accepted to IEEE Transactions on Wireless Communications. arXiv admin note: text overlap with arXiv:2011.09430",
    "descriptor": "\nComments: Main: 15 pages, 12 figures. Supplement: 5 pages, 7 figures. Accepted to IEEE Transactions on Wireless Communications. arXiv admin note: text overlap with arXiv:2011.09430\n",
    "authors": [
      "Zhongyuan Zhao",
      "Gunjan Verma",
      "Chirag Rao",
      "Ananthram Swami",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05536"
  },
  {
    "id": "arXiv:2109.07410",
    "title": "Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked  Claims in a Document",
    "abstract": "Comments: detecting previously fact-checked claims, fact-checking, disinformation, fake news, social media, political debates",
    "descriptor": "\nComments: detecting previously fact-checked claims, fact-checking, disinformation, fake news, social media, political debates\n",
    "authors": [
      "Shaden Shaar",
      "Nikola Georgiev",
      "Firoj Alam",
      "Giovanni Da San Martino",
      "Aisha Mohamed",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07410"
  },
  {
    "id": "arXiv:2109.12668",
    "title": "Expected value of the smallest denominator in a random interval of fixed  radius",
    "abstract": "Comments: 9 pages, streamlined proof, radius $\\delta$ from previous version replaced by $\\delta/2$",
    "descriptor": "\nComments: 9 pages, streamlined proof, radius $\\delta$ from previous version replaced by $\\delta/2$\n",
    "authors": [
      "Huayang Chen",
      "Alan Haynes"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.12668"
  },
  {
    "id": "arXiv:2110.02898",
    "title": "Coresets for Kernel Clustering",
    "abstract": "Coresets for Kernel Clustering",
    "descriptor": "",
    "authors": [
      "Shaofeng H.-C. Jiang",
      "Robert Krauthgamer",
      "Jianing Lou",
      "Yubo Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02898"
  },
  {
    "id": "arXiv:2110.07031",
    "title": "Improving the Robustness to Variations of Objects and Instructions with  a Neuro-Symbolic Approach for Interactive Instruction Following",
    "abstract": "Comments: Accepted to the 29th International Conference on MultiMedia Modeling (MMM 2023)",
    "descriptor": "\nComments: Accepted to the 29th International Conference on MultiMedia Modeling (MMM 2023)\n",
    "authors": [
      "Kazutoshi Shinoda",
      "Yuki Takezawa",
      "Masahiro Suzuki",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.07031"
  },
  {
    "id": "arXiv:2110.08413",
    "title": "Invariant Language Modeling",
    "abstract": "Comments: Published at EMNLP 2022",
    "descriptor": "\nComments: Published at EMNLP 2022\n",
    "authors": [
      "Maxime Peyrard",
      "Sarvjeet Singh Ghotra",
      "Martin Josifoski",
      "Vidhan Agarwal",
      "Barun Patra",
      "Dean Carignan",
      "Emre Kiciman",
      "Robert West"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08413"
  },
  {
    "id": "arXiv:2110.10972",
    "title": "Efficient Gradient Flows in Sliced-Wasserstein Space",
    "abstract": "Comments: Published in Transactions on Machine Learning Research (November 2022)",
    "descriptor": "\nComments: Published in Transactions on Machine Learning Research (November 2022)\n",
    "authors": [
      "Cl\u00e9ment Bonet",
      "Nicolas Courty",
      "Fran\u00e7ois Septier",
      "Lucas Drumetz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10972"
  },
  {
    "id": "arXiv:2110.11439",
    "title": "(Optimal) Online Bipartite Matching with Degree Information",
    "abstract": "Comments: To appear in NeurIPS'22. A prior version of this work was titled \"(Optimal) Online Bipartite Matching with Predicted Degrees\"",
    "descriptor": "\nComments: To appear in NeurIPS'22. A prior version of this work was titled \"(Optimal) Online Bipartite Matching with Predicted Degrees\"\n",
    "authors": [
      "Anders Aamand",
      "Justin Y. Chen",
      "Piotr Indyk"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11439"
  },
  {
    "id": "arXiv:2110.13509",
    "title": "An Arbitrary High Order and Positivity Preserving Method for the Shallow  Water Equations",
    "abstract": "An Arbitrary High Order and Positivity Preserving Method for the Shallow  Water Equations",
    "descriptor": "",
    "authors": [
      "Mirco Ciallella",
      "Lorenzo Micalizzi",
      "Philipp \u00d6ffner",
      "Davide Torlo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13509"
  },
  {
    "id": "arXiv:2110.14529",
    "title": "HSVI for zs-POSGs using Concavity, Convexity and Lipschitz Properties",
    "abstract": "Comments: 37 pages, 4 figures, 4 tables, 3 algorithms",
    "descriptor": "\nComments: 37 pages, 4 figures, 4 tables, 3 algorithms\n",
    "authors": [
      "Aur\u00e9lien Delage",
      "Olivier Buffet",
      "Jilles Dibangoye"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14529"
  },
  {
    "id": "arXiv:2111.03016",
    "title": "Graph neural network initialisation of quantum approximate optimisation",
    "abstract": "Comments: 12 pages, 8 Figures - publised version",
    "descriptor": "\nComments: 12 pages, 8 Figures - publised version\n",
    "authors": [
      "Nishant Jain",
      "Brian Coyle",
      "Elham Kashefi",
      "Niraj Kumar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03016"
  },
  {
    "id": "arXiv:2111.05504",
    "title": "Collocation approximation by deep neural ReLU networks for parametric  elliptic PDEs with lognormal inputs",
    "abstract": "Collocation approximation by deep neural ReLU networks for parametric  elliptic PDEs with lognormal inputs",
    "descriptor": "",
    "authors": [
      "Dinh D\u0169ng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.05504"
  },
  {
    "id": "arXiv:2111.11680",
    "title": "Computing with B-series",
    "abstract": "Computing with B-series",
    "descriptor": "",
    "authors": [
      "David I. Ketcheson",
      "Hendrik Ranocha"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2111.11680"
  },
  {
    "id": "arXiv:2111.13456",
    "title": "A posteriori error estimation and adaptivity for multiple-network  poroelasticity",
    "abstract": "Comments: Author names appear in alphabetical order in accordance with the standard convention of the mathematical sciences. All authors contributed equally to both the research and the writing of this work",
    "descriptor": "\nComments: Author names appear in alphabetical order in accordance with the standard convention of the mathematical sciences. All authors contributed equally to both the research and the writing of this work\n",
    "authors": [
      "Emilie Eliseussen",
      "Marie E. Rognes",
      "Travis B. Thompson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2111.13456"
  },
  {
    "id": "arXiv:2111.13755",
    "title": "A survey on multi-objective hyperparameter optimization algorithms for  Machine Learning",
    "abstract": "A survey on multi-objective hyperparameter optimization algorithms for  Machine Learning",
    "descriptor": "",
    "authors": [
      "Alejandro Morales-Hern\u00e1ndez",
      "Inneke Van Nieuwenhuyse",
      "Sebastian Rojas Gonzalez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.13755"
  },
  {
    "id": "arXiv:2112.00334",
    "title": "VisRuler: Visual Analytics for Extracting Decision Rules from Bagged and  Boosted Decision Trees",
    "abstract": "Comments: This manuscript is accepted for publication in the Information Visualization (IV) - SAGE Journals",
    "descriptor": "\nComments: This manuscript is accepted for publication in the Information Visualization (IV) - SAGE Journals\n",
    "authors": [
      "Angelos Chatzimparmpas",
      "Rafael M. Martins",
      "Andreas Kerren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.00334"
  },
  {
    "id": "arXiv:2112.03237",
    "title": "From Coarse to Fine-grained Concept based Discrimination for Phrase  Detection",
    "abstract": "From Coarse to Fine-grained Concept based Discrimination for Phrase  Detection",
    "descriptor": "",
    "authors": [
      "Maan Qraitem",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03237"
  },
  {
    "id": "arXiv:2112.04475",
    "title": "Reliable Simulation of Quantum Channels",
    "abstract": "Comments: V2: presentation improved, details on proofs added, references added, minor corrections",
    "descriptor": "\nComments: V2: presentation improved, details on proofs added, references added, minor corrections\n",
    "authors": [
      "Ke Li",
      "Yongsheng Yao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.04475"
  },
  {
    "id": "arXiv:2112.07096",
    "title": "Learning High-Dimensional Parametric Maps via Reduced Basis Adaptive  Residual Networks",
    "abstract": "Learning High-Dimensional Parametric Maps via Reduced Basis Adaptive  Residual Networks",
    "descriptor": "",
    "authors": [
      "Thomas O'Leary-Roseberry",
      "Xiaosong Du",
      "Anirban Chaudhuri",
      "Joaquim R. R. A. Martins",
      "Karen Willcox",
      "Omar Ghattas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07096"
  },
  {
    "id": "arXiv:2112.15361",
    "title": "Preference Swaps for the Stable Matching Problem",
    "abstract": "Preference Swaps for the Stable Matching Problem",
    "descriptor": "",
    "authors": [
      "Eduard Eiben",
      "Gregory Gutin",
      "Philip R. Neary",
      "Cl\u00e9ment Rambaud",
      "Magnus Wahlstr\u00f6m",
      "Anders Yeo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.15361"
  },
  {
    "id": "arXiv:2201.01514",
    "title": "Local limit theorem for complex valued sequences",
    "abstract": "Local limit theorem for complex valued sequences",
    "descriptor": "",
    "authors": [
      "Lucas Coeuret"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.01514"
  },
  {
    "id": "arXiv:2201.03767",
    "title": "Improved (Related-key) Differential-based Neural Distinguishers for  SIMON and SIMECK Block Ciphers",
    "abstract": "Improved (Related-key) Differential-based Neural Distinguishers for  SIMON and SIMECK Block Ciphers",
    "descriptor": "",
    "authors": [
      "Jinyu Lu",
      "Guoqiang Liu",
      "Bing Sun",
      "Chao Li",
      "Li Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.03767"
  },
  {
    "id": "arXiv:2201.05701",
    "title": "Diffusion Tensor Estimation with Transformer Neural Networks",
    "abstract": "Diffusion Tensor Estimation with Transformer Neural Networks",
    "descriptor": "",
    "authors": [
      "Davood Karimi",
      "Ali Gholipour"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2201.05701"
  },
  {
    "id": "arXiv:2201.05955",
    "title": "WANLI: Worker and AI Collaboration for Natural Language Inference  Dataset Creation",
    "abstract": "Comments: EMNLP Findings camera-ready",
    "descriptor": "\nComments: EMNLP Findings camera-ready\n",
    "authors": [
      "Alisa Liu",
      "Swabha Swayamdipta",
      "Noah A. Smith",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.05955"
  },
  {
    "id": "arXiv:2201.10142",
    "title": "Almost Optimal Variance-Constrained Best Arm Identification",
    "abstract": "Comments: 32 pages, 15 figures",
    "descriptor": "\nComments: 32 pages, 15 figures\n",
    "authors": [
      "Yunlong Hou",
      "Vincent Y. F. Tan",
      "Zixin Zhong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.10142"
  },
  {
    "id": "arXiv:2201.11176",
    "title": "DiscoScore: Evaluating Text Generation with BERT and Discourse Coherence",
    "abstract": "Comments: v3: revision in response to ARR",
    "descriptor": "\nComments: v3: revision in response to ARR\n",
    "authors": [
      "Wei Zhao",
      "Michael Strube",
      "Steffen Eger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11176"
  },
  {
    "id": "arXiv:2201.12032",
    "title": "Neural Approximation of Graph Topological Features",
    "abstract": "Comments: Accepted in NeurIPS 2022",
    "descriptor": "\nComments: Accepted in NeurIPS 2022\n",
    "authors": [
      "Zuoyu Yan",
      "Tengfei Ma",
      "Liangcai Gao",
      "Zhi Tang",
      "Yusu Wang",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12032"
  },
  {
    "id": "arXiv:2202.05631",
    "title": "Vehicle and License Plate Recognition with Novel Dataset for Toll  Collection",
    "abstract": "Vehicle and License Plate Recognition with Novel Dataset for Toll  Collection",
    "descriptor": "",
    "authors": [
      "Muhammad Usama",
      "Hafeez Anwar",
      "Abbas Anwar",
      "Saeed Anwar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05631"
  },
  {
    "id": "arXiv:2202.06843",
    "title": "Continual Learning from Demonstration of Robotic Skills",
    "abstract": "Continual Learning from Demonstration of Robotic Skills",
    "descriptor": "",
    "authors": [
      "Sayantan Auddy",
      "Jakob Hollenstein",
      "Matteo Saveriano",
      "Antonio Rodr\u00edguez-S\u00e1nchez",
      "Justus Piater"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06843"
  },
  {
    "id": "arXiv:2203.07807",
    "title": "End-to-end P300 BCI using Bayesian accumulation of Riemannian  probabilities",
    "abstract": "Comments: 9 pages, 7 figures, 3 tables",
    "descriptor": "\nComments: 9 pages, 7 figures, 3 tables\n",
    "authors": [
      "Quentin Barth\u00e9lemy",
      "Sylvain Chevallier",
      "Rapha\u00eblle Bertrand-Lalo",
      "Pierre Clisson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.07807"
  },
  {
    "id": "arXiv:2203.09636",
    "title": "A Density Evolution framework for Preferential Recovery of Covariance  and Causal Graphs from Compressed Measurements",
    "abstract": "A Density Evolution framework for Preferential Recovery of Covariance  and Causal Graphs from Compressed Measurements",
    "descriptor": "",
    "authors": [
      "Muralikrishnna G. Sethuraman",
      "Hang Zhang",
      "Faramarz Fekri"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.09636"
  },
  {
    "id": "arXiv:2203.10232",
    "title": "DuReader_retrieval: A Large-scale Chinese Benchmark for Passage  Retrieval from Web Search Engine",
    "abstract": "Comments: EMNLP 2022, 13 pages",
    "descriptor": "\nComments: EMNLP 2022, 13 pages\n",
    "authors": [
      "Yifu Qiu",
      "Hongyu Li",
      "Yingqi Qu",
      "Ying Chen",
      "Qiaoqiao She",
      "Jing Liu",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.10232"
  },
  {
    "id": "arXiv:2203.12680",
    "title": "The $k$-Cap Process on Geometric Random Graphs",
    "abstract": "Comments: We edited to extend the analysis of the discrete k-cap process from 1-D interval graphs to constant d-dimensional graphs",
    "descriptor": "\nComments: We edited to extend the analysis of the discrete k-cap process from 1-D interval graphs to constant d-dimensional graphs\n",
    "authors": [
      "Mirabel Reid",
      "Santosh S. Vempala"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.12680"
  },
  {
    "id": "arXiv:2203.14408",
    "title": "Control-Oriented Modeling of Pipe Flow in Gas Processing Facilities",
    "abstract": "Control-Oriented Modeling of Pipe Flow in Gas Processing Facilities",
    "descriptor": "",
    "authors": [
      "Sven Br\u00fcggemann",
      "Robert H. Moroto",
      "Robert R. Bitmead"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.14408"
  },
  {
    "id": "arXiv:2203.14661",
    "title": "Random matrix analysis of deep neural network weight matrices",
    "abstract": "Comments: 16 pages, 14 figures, updated version",
    "descriptor": "\nComments: 16 pages, 14 figures, updated version\n",
    "authors": [
      "Matthias Thamm",
      "Max Staats",
      "Bernd Rosenow"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.14661"
  },
  {
    "id": "arXiv:2204.02142",
    "title": "Computationally efficient robust MPC using optimized constraint  tightening",
    "abstract": "Comments: Accepted to the 61st IEEE Conference on Decision and Control, Cancun 2022",
    "descriptor": "\nComments: Accepted to the 61st IEEE Conference on Decision and Control, Cancun 2022\n",
    "authors": [
      "Anilkumar Parsi",
      "Panagiotis Anagnostaras",
      "Andrea Iannelli",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.02142"
  },
  {
    "id": "arXiv:2204.05011",
    "title": "FederatedScope: A Flexible Federated Learning Platform for Heterogeneity",
    "abstract": "Comments: We have released FederatedScope for users on this https URL",
    "descriptor": "\nComments: We have released FederatedScope for users on this https URL\n",
    "authors": [
      "Yuexiang Xie",
      "Zhen Wang",
      "Dawei Gao",
      "Daoyuan Chen",
      "Liuyi Yao",
      "Weirui Kuang",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05011"
  },
  {
    "id": "arXiv:2204.07120",
    "title": "Exploring Dual Encoder Architectures for Question Answering",
    "abstract": "Comments: Published in EMNLP 2022",
    "descriptor": "\nComments: Published in EMNLP 2022\n",
    "authors": [
      "Zhe Dong",
      "Jianmo Ni",
      "Daniel M. Bikel",
      "Enrique Alfonseca",
      "Yuan Wang",
      "Chen Qu",
      "Imed Zitouni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07120"
  },
  {
    "id": "arXiv:2204.09172",
    "title": "Node Deployment in Heterogeneous Rayleigh Fading Sensor Networks",
    "abstract": "Node Deployment in Heterogeneous Rayleigh Fading Sensor Networks",
    "descriptor": "",
    "authors": [
      "Saeed Karimi-Bidhendi",
      "Hamid Jafarkhani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.09172"
  },
  {
    "id": "arXiv:2204.10989",
    "title": "Dialogue Meaning Representation for Task-Oriented Dialogue Systems",
    "abstract": "Comments: EMNLP 2022 Findings camera ready",
    "descriptor": "\nComments: EMNLP 2022 Findings camera ready\n",
    "authors": [
      "Xiangkun Hu",
      "Junqi Dai",
      "Hang Yan",
      "Yi Zhang",
      "Qipeng Guo",
      "Xipeng Qiu",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.10989"
  },
  {
    "id": "arXiv:2204.12384",
    "title": "Qunity: A Unified Language for Quantum and Classical Computing (Extended  Version)",
    "abstract": "Comments: 76 pages, 37 figures. To appear at POPL 2023, previous version presented at QPL 2022. Expanded with additional background information and a characterization of the classical sublanguage",
    "descriptor": "\nComments: 76 pages, 37 figures. To appear at POPL 2023, previous version presented at QPL 2022. Expanded with additional background information and a characterization of the classical sublanguage\n",
    "authors": [
      "Finn Voichick",
      "Liyi Li",
      "Robert Rand",
      "Michael Hicks"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.12384"
  },
  {
    "id": "arXiv:2205.00062",
    "title": "On the Inf-Sup Stability of Crouzeix-Raviart Stokes Elements in 3D",
    "abstract": "On the Inf-Sup Stability of Crouzeix-Raviart Stokes Elements in 3D",
    "descriptor": "",
    "authors": [
      "Stefan Sauter",
      "C\u00e9line Torres"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.00062"
  },
  {
    "id": "arXiv:2205.00658",
    "title": "Sparse Fourier Transform over Lattices: A Unified Approach to Signal  Reconstruction",
    "abstract": "Sparse Fourier Transform over Lattices: A Unified Approach to Signal  Reconstruction",
    "descriptor": "",
    "authors": [
      "Zhao Song",
      "Baocheng Sun",
      "Omri Weinstein",
      "Ruizhe Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.00658"
  },
  {
    "id": "arXiv:2205.03990",
    "title": "Predicting parametric spatiotemporal dynamics by multi-resolution PDE  structure-preserved deep learning",
    "abstract": "Comments: 38 pages, 18 figures",
    "descriptor": "\nComments: 38 pages, 18 figures\n",
    "authors": [
      "Xin-Yang Liu",
      "Hao Sun",
      "Min Zhu",
      "Lu Lu",
      "Jian-Xun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.03990"
  },
  {
    "id": "arXiv:2205.07722",
    "title": "How Different Groups Prioritize Ethical Values for Responsible AI",
    "abstract": "How Different Groups Prioritize Ethical Values for Responsible AI",
    "descriptor": "",
    "authors": [
      "Maurice Jakesch",
      "Zana Bu\u00e7inca",
      "Saleema Amershi",
      "Alexandra Olteanu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.07722"
  },
  {
    "id": "arXiv:2205.09726",
    "title": "RankGen: Improving Text Generation with Large Ranking Models",
    "abstract": "Comments: EMNLP 2022 (34 pages), model checkpoints available at this https URL Added comparisons to newer decoding methods (contrastive search, contrastive decoding, eta sampling)",
    "descriptor": "\nComments: EMNLP 2022 (34 pages), model checkpoints available at this https URL Added comparisons to newer decoding methods (contrastive search, contrastive decoding, eta sampling)\n",
    "authors": [
      "Kalpesh Krishna",
      "Yapei Chang",
      "John Wieting",
      "Mohit Iyyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09726"
  },
  {
    "id": "arXiv:2205.09901",
    "title": "The Minimal Feature Removal Problem in Neural Networks",
    "abstract": "The Minimal Feature Removal Problem in Neural Networks",
    "descriptor": "",
    "authors": [
      "Ouns El Harzli",
      "Bernardo Cuenca Grau",
      "Ian Horrocks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.09901"
  },
  {
    "id": "arXiv:2205.10366",
    "title": "Actively Tracking the Optimal Arm in Non-Stationary Environments with  Mandatory Probing",
    "abstract": "Comments: Corrected the assumptions and removed the case-study due to an error",
    "descriptor": "\nComments: Corrected the assumptions and removed the case-study due to an error\n",
    "authors": [
      "Gourab Ghatak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.10366"
  },
  {
    "id": "arXiv:2205.11097",
    "title": "A Fine-grained Interpretability Evaluation Benchmark for Neural NLP",
    "abstract": "A Fine-grained Interpretability Evaluation Benchmark for Neural NLP",
    "descriptor": "",
    "authors": [
      "Lijie Wang",
      "Yaozong Shen",
      "Shuyuan Peng",
      "Shuai Zhang",
      "Xinyan Xiao",
      "Hao Liu",
      "Hongxuan Tang",
      "Ying Chen",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11097"
  },
  {
    "id": "arXiv:2205.12559",
    "title": "Envy-Free Cake Cutting with Graph Constraints",
    "abstract": "Comments: We have an updated version and one new co-author. Please refer to arXiv:2211.06458",
    "descriptor": "\nComments: We have an updated version and one new co-author. Please refer to arXiv:2211.06458\n",
    "authors": [
      "Ganesh Ghalme",
      "Xin Huang",
      "Nidhi Rathi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.12559"
  },
  {
    "id": "arXiv:2205.13909",
    "title": "(De-)Randomized Smoothing for Decision Stump Ensembles",
    "abstract": "Comments: NeurIPS 2022 Paper",
    "descriptor": "\nComments: NeurIPS 2022 Paper\n",
    "authors": [
      "Mikl\u00f3s Z. Horv\u00e1th",
      "Mark Niklas M\u00fcller",
      "Marc Fischer",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.13909"
  },
  {
    "id": "arXiv:2206.00288",
    "title": "Sustaining Security and Safety in ICT: A Quest for Terminology,  Objectives, and Limits",
    "abstract": "Sustaining Security and Safety in ICT: A Quest for Terminology,  Objectives, and Limits",
    "descriptor": "",
    "authors": [
      "Jan Tobias Muehlberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.00288"
  },
  {
    "id": "arXiv:2206.00525",
    "title": "Joint Active and Passive Beamforming Design for Reconfigurable  Intelligent Surface Enabled Integrated Sensing and Communication",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zhe Xing",
      "Rui Wang",
      "Xiaojun Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.00525"
  },
  {
    "id": "arXiv:2206.01825",
    "title": "Debiased Machine Learning without Sample-Splitting for Stable Estimators",
    "abstract": "Debiased Machine Learning without Sample-Splitting for Stable Estimators",
    "descriptor": "",
    "authors": [
      "Qizhao Chen",
      "Vasilis Syrgkanis",
      "Morgane Austern"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.01825"
  },
  {
    "id": "arXiv:2206.02969",
    "title": "A Simple and Optimal Policy Design with Safety against Heavy-tailed Risk  for Stochastic Bandits",
    "abstract": "Comments: Preliminary version appeared in NeurIPS 2022",
    "descriptor": "\nComments: Preliminary version appeared in NeurIPS 2022\n",
    "authors": [
      "David Simchi-Levi",
      "Zeyu Zheng",
      "Feng Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.02969"
  },
  {
    "id": "arXiv:2206.04423",
    "title": "Learning to generalize Dispatching rules on the Job Shop Scheduling",
    "abstract": "Learning to generalize Dispatching rules on the Job Shop Scheduling",
    "descriptor": "",
    "authors": [
      "Zangir Iklassov",
      "Dmitrii Medvedev",
      "Ruben Solozabal",
      "Martin Takac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.04423"
  },
  {
    "id": "arXiv:2206.05487",
    "title": "Scientific Inference With Interpretable Machine Learning: Analyzing  Models to Learn About Real-World Phenomena",
    "abstract": "Scientific Inference With Interpretable Machine Learning: Analyzing  Models to Learn About Real-World Phenomena",
    "descriptor": "",
    "authors": [
      "Timo Freiesleben",
      "Gunnar K\u00f6nig",
      "Christoph Molnar",
      "Alvaro Tejero-Cantero"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05487"
  },
  {
    "id": "arXiv:2206.06126",
    "title": "Robust Time Series Denoising with Learnable Wavelet Packet Transform",
    "abstract": "Comments: 15 pages, 13 figures, 8 tables",
    "descriptor": "\nComments: 15 pages, 13 figures, 8 tables\n",
    "authors": [
      "Gaetan Frusque",
      "Olga Fink"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.06126"
  },
  {
    "id": "arXiv:2206.06468",
    "title": "Stable Relationships",
    "abstract": "Stable Relationships",
    "descriptor": "",
    "authors": [
      "Sam Ganzfried"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.06468"
  },
  {
    "id": "arXiv:2206.07586",
    "title": "Pragmatic Theory of Machine Learning",
    "abstract": "Pragmatic Theory of Machine Learning",
    "descriptor": "",
    "authors": [
      "Marina Sapir"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2206.07586"
  },
  {
    "id": "arXiv:2206.09211",
    "title": "New LP-based Upper Bounds in the Rate-vs.-Distance Problem for Linear  Codes",
    "abstract": "New LP-based Upper Bounds in the Rate-vs.-Distance Problem for Linear  Codes",
    "descriptor": "",
    "authors": [
      "Elyassaf Loyfer",
      "Nati Linial"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.09211"
  },
  {
    "id": "arXiv:2206.09237",
    "title": "Systematic Analysis and Comparison of Security Advice as Datasets",
    "abstract": "Systematic Analysis and Comparison of Security Advice as Datasets",
    "descriptor": "",
    "authors": [
      "Christopher Bellman",
      "Paul C. van Oorschot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09237"
  },
  {
    "id": "arXiv:2206.09384",
    "title": "Sampling from Log-Concave Distributions over Polytopes via a  Soft-Threshold Dikin Walk",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2111.04089",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.04089\n",
    "authors": [
      "Oren Mangoubi",
      "Nisheeth K. Vishnoi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.09384"
  },
  {
    "id": "arXiv:2206.11398",
    "title": "Fusion of Model-free Reinforcement Learning with Microgrid Control:  Review and Vision",
    "abstract": "Comments: 14 pages, 4 figures, Accepted by IEEE Transaction on Smart Grid",
    "descriptor": "\nComments: 14 pages, 4 figures, Accepted by IEEE Transaction on Smart Grid\n",
    "authors": [
      "Buxin She",
      "Fangxing Li",
      "Hantao Cui",
      "Jingqiu Zhang",
      "Rui Bo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.11398"
  },
  {
    "id": "arXiv:2206.14244",
    "title": "Masked World Models for Visual Control",
    "abstract": "Comments: Project website: this https URL Accepted to CoRL 2022",
    "descriptor": "\nComments: Project website: this https URL Accepted to CoRL 2022\n",
    "authors": [
      "Younggyo Seo",
      "Danijar Hafner",
      "Hao Liu",
      "Fangchen Liu",
      "Stephen James",
      "Kimin Lee",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.14244"
  },
  {
    "id": "arXiv:2206.14483",
    "title": "Data augmentation for learning predictive models on EEG: a systematic  comparison",
    "abstract": "Comments: Accepted in Journal of Neural Engineering",
    "descriptor": "\nComments: Accepted in Journal of Neural Engineering\n",
    "authors": [
      "C\u00e9dric Rommel",
      "Joseph Paillard",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.14483"
  },
  {
    "id": "arXiv:2206.14674",
    "title": "Signature Methods in Machine Learning",
    "abstract": "Comments: Updated figures",
    "descriptor": "\nComments: Updated figures\n",
    "authors": [
      "Terry Lyons",
      "Andrew D. McLeod"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.14674"
  },
  {
    "id": "arXiv:2207.01493",
    "title": "AI Ethics: An Empirical Study on the Views of Practitioners and  Lawmakers",
    "abstract": "AI Ethics: An Empirical Study on the Views of Practitioners and  Lawmakers",
    "descriptor": "",
    "authors": [
      "Arif Ali Khan",
      "Muhammad Azeem Akbar",
      "Mahdi Fahmideh",
      "Peng Liang",
      "Muhammad Waseem",
      "Aakash Ahmad",
      "Mahmood Niazi",
      "Pekka Abrahamsson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.01493"
  },
  {
    "id": "arXiv:2207.04146",
    "title": "Information Rates with Non Ideal Photon Detectors in Time-Entanglement  Based QKD",
    "abstract": "Comments: Corrections and revisions were made to plots and formulas in section IV, with smaller revisions to sections III.E and VII, and with cosmetic improvements to most plots",
    "descriptor": "\nComments: Corrections and revisions were made to plots and formulas in section IV, with smaller revisions to sections III.E and VII, and with cosmetic improvements to most plots\n",
    "authors": [
      "Dunbar Birnie IV",
      "Christopher Cheng",
      "Emina Soljanin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2207.04146"
  },
  {
    "id": "arXiv:2207.04376",
    "title": "On Graph Neural Network Fairness in the Presence of Heterophilous  Neighborhoods",
    "abstract": "Comments: 6 pages, KDD 2022 DLG Workshop",
    "descriptor": "\nComments: 6 pages, KDD 2022 DLG Workshop\n",
    "authors": [
      "Donald Loveland",
      "Jiong Zhu",
      "Mark Heimann",
      "Ben Fish",
      "Michael T. Schaub",
      "Danai Koutra"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04376"
  },
  {
    "id": "arXiv:2207.04996",
    "title": "Construction of non-CSS quantum codes using measurements on cluster  states",
    "abstract": "Comments: 7 Pages, 4 Figures, Two Algorithms, One table",
    "descriptor": "\nComments: 7 Pages, 4 Figures, Two Algorithms, One table\n",
    "authors": [
      "Swayangprabha Shaw",
      "Harsh Gupta",
      "Shahid Mehraj Shah",
      "Ankur Raina"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04996"
  },
  {
    "id": "arXiv:2207.05273",
    "title": "Cross-Architecture Knowledge Distillation",
    "abstract": "Comments: Accepted by ACCV 2022",
    "descriptor": "\nComments: Accepted by ACCV 2022\n",
    "authors": [
      "Yufan Liu",
      "Jiajiong Cao",
      "Bing Li",
      "Weiming Hu",
      "Jingting Ding",
      "Liang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.05273"
  },
  {
    "id": "arXiv:2207.08925",
    "title": "Image to Icosahedral Projection for $\\mathrm{SO}(3)$ Object Reasoning  from Single-View Images",
    "abstract": "Image to Icosahedral Projection for $\\mathrm{SO}(3)$ Object Reasoning  from Single-View Images",
    "descriptor": "",
    "authors": [
      "David Klee",
      "Ondrej Biza",
      "Robert Platt",
      "Robin Walters"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08925"
  },
  {
    "id": "arXiv:2207.11697",
    "title": "Improving Mandarin Speech Recogntion with Block-augmented Transformer",
    "abstract": "Improving Mandarin Speech Recogntion with Block-augmented Transformer",
    "descriptor": "",
    "authors": [
      "Xiaoming Ren",
      "Huifeng Zhu",
      "Liuwei Wei",
      "Minghui Wu",
      "Jie Hao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.11697"
  },
  {
    "id": "arXiv:2207.12395",
    "title": "Statistical Inference with Stochastic Gradient Algorithms",
    "abstract": "Comments: 39 pgs",
    "descriptor": "\nComments: 39 pgs\n",
    "authors": [
      "Jeffrey Negrea",
      "Jun Yang",
      "Haoyue Feng",
      "Daniel M. Roy",
      "Jonathan H. Huggins"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.12395"
  },
  {
    "id": "arXiv:2207.14391",
    "title": "Distributed Stochastic Bandit Learning with Delayed Context Observation",
    "abstract": "Distributed Stochastic Bandit Learning with Delayed Context Observation",
    "descriptor": "",
    "authors": [
      "Jiabin Lin",
      "Shana Moothedath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14391"
  },
  {
    "id": "arXiv:2208.01424",
    "title": "Connection Reduction of DenseNet for Image Recognition",
    "abstract": "Connection Reduction of DenseNet for Image Recognition",
    "descriptor": "",
    "authors": [
      "Rui-Yang Ju",
      "Jen-Shiun Chiang",
      "Chih-Chia Chen",
      "Yu-Shian Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.01424"
  },
  {
    "id": "arXiv:2208.06174",
    "title": "Two-person Graph Convolutional Network for Skeleton-based Human  Interaction Recognition",
    "abstract": "Two-person Graph Convolutional Network for Skeleton-based Human  Interaction Recognition",
    "descriptor": "",
    "authors": [
      "Zhengcen Li",
      "Yueran Li",
      "Linlin Tang",
      "Tong Zhang",
      "Jingyong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.06174"
  },
  {
    "id": "arXiv:2208.06859",
    "title": "Virgo: Scalable Unsupervised Classification of Cosmological Shock Waves",
    "abstract": "Virgo: Scalable Unsupervised Classification of Cosmological Shock Waves",
    "descriptor": "",
    "authors": [
      "Max Lamparth",
      "Ludwig B\u00f6ss",
      "Ulrich Steinwandel",
      "Klaus Dolag"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2208.06859"
  },
  {
    "id": "arXiv:2208.07021",
    "title": "Pyramidal Predictive Network: A Model for Visual-frame Prediction Based  on Predictive Coding Theory",
    "abstract": "Pyramidal Predictive Network: A Model for Visual-frame Prediction Based  on Predictive Coding Theory",
    "descriptor": "",
    "authors": [
      "Chaofan Ling",
      "Junpei Zhong",
      "Weihua Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.07021"
  },
  {
    "id": "arXiv:2208.08753",
    "title": "Rate Splitting in MIMO RIS-assisted Systems with Hardware Impairments  and Improper Signaling",
    "abstract": "Comments: accepted at IEEE Transaction on Vehicular Technology",
    "descriptor": "\nComments: accepted at IEEE Transaction on Vehicular Technology\n",
    "authors": [
      "Mohammad Soleymani",
      "Ignacio Santamaria",
      "Eduard Jorswieck"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.08753"
  },
  {
    "id": "arXiv:2208.09897",
    "title": "Multiple Descent in the Multiple Random Feature Model",
    "abstract": "Comments: 89 pages, 10 figures. Version 2 adds new theoretical results proving triple descent in certain double random feature models",
    "descriptor": "\nComments: 89 pages, 10 figures. Version 2 adds new theoretical results proving triple descent in certain double random feature models\n",
    "authors": [
      "Xuran Meng",
      "Jianfeng Yao",
      "Yuan Cao"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.09897"
  },
  {
    "id": "arXiv:2208.10937",
    "title": "Improving Computed Tomography (CT) Reconstruction via 3D Shape Induction",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 11 pages",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 11 pages\n",
    "authors": [
      "Elena Sizikova",
      "Xu Cao",
      "Ashia Lewis",
      "Kenny Moise",
      "Megan Coffee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10937"
  },
  {
    "id": "arXiv:2208.13301",
    "title": "ECP SOLLVE: Validation and Verification Testsuite Status Update and  Compiler Insight for OpenMP",
    "abstract": "ECP SOLLVE: Validation and Verification Testsuite Status Update and  Compiler Insight for OpenMP",
    "descriptor": "",
    "authors": [
      "Thomas Huber",
      "Swaroop Pophale",
      "Nolan Baker",
      "Michael Carr",
      "Nikhil Rao",
      "Jaydon Reap",
      "Kristina Holsapple",
      "Joshua Hoke Davis",
      "Tobias Burnus",
      "Seyong Lee",
      "David E. Bernholdt",
      "Sunita Chandrasekaran"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.13301"
  },
  {
    "id": "arXiv:2209.02415",
    "title": "Automatic Infectious Disease Classification Analysis with Concept  Discovery",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 13 pages",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 13 pages\n",
    "authors": [
      "Elena Sizikova",
      "Joshua Vendrow",
      "Xu Cao",
      "Rachel Grotheer",
      "Jamie Haddock",
      "Lara Kassab",
      "Alona Kryshchenko",
      "Thomas Merkh",
      "R. W. M. A. Madushani",
      "Kenny Moise",
      "Annie Ulichney",
      "Huy V. Vo",
      "Chuntian Wang",
      "Megan Coffee",
      "Kathryn Leonard",
      "Deanna Needell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.02415"
  },
  {
    "id": "arXiv:2209.03675",
    "title": "Epic Fail: Emulators can tolerate polynomially many edge faults for free",
    "abstract": "Comments: ITCS 2023",
    "descriptor": "\nComments: ITCS 2023\n",
    "authors": [
      "Greg Bodwin",
      "Michael Dinitz",
      "Yasamin Nazari"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2209.03675"
  },
  {
    "id": "arXiv:2209.05407",
    "title": "Holistic Segmentation",
    "abstract": "Holistic Segmentation",
    "descriptor": "",
    "authors": [
      "Stefano Gasperini",
      "Alvaro Marcos-Ramiro",
      "Michael Schmidt",
      "Nassir Navab",
      "Benjamin Busam",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.05407"
  },
  {
    "id": "arXiv:2209.05559",
    "title": "Deep Reinforcement Learning for Cryptocurrency Trading: Practical  Approach to Address Backtest Overfitting",
    "abstract": "Deep Reinforcement Learning for Cryptocurrency Trading: Practical  Approach to Address Backtest Overfitting",
    "descriptor": "",
    "authors": [
      "Berend Jelmer Dirk Gort",
      "Xiao-Yang Liu",
      "Xinghang Sun",
      "Jiechao Gao",
      "Shuaiyu Chen",
      "Christina Dan Wang"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.05559"
  },
  {
    "id": "arXiv:2209.07042",
    "title": "Efficient Perception, Planning, and Control Algorithms for Vision-Based  Automated Vehicles",
    "abstract": "Comments: 7 figures, 12 pages",
    "descriptor": "\nComments: 7 figures, 12 pages\n",
    "authors": [
      "Der-Hau Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07042"
  },
  {
    "id": "arXiv:2209.07497",
    "title": "On Power Set Axiom",
    "abstract": "Comments: 4 pages. Sec 3.1 added",
    "descriptor": "\nComments: 4 pages. Sec 3.1 added\n",
    "authors": [
      "Leonid A. Levin"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.07497"
  },
  {
    "id": "arXiv:2209.07640",
    "title": "Haptic Feedback Relocation from the Fingertips to the Wrist for  Two-Finger Manipulation in Virtual Reality",
    "abstract": "Comments: 6 pages, 9 figures, 1 table, submitted and accepted to the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022 Conference",
    "descriptor": "\nComments: 6 pages, 9 figures, 1 table, submitted and accepted to the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2022 Conference\n",
    "authors": [
      "Jasmin E. Palmer",
      "Mine Sarac",
      "Aaron A. Garza",
      "Allison M. Okamura"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.07640"
  },
  {
    "id": "arXiv:2209.08860",
    "title": "A Survey of Deep Causal Models and Their Industrial Applications",
    "abstract": "A Survey of Deep Causal Models and Their Industrial Applications",
    "descriptor": "",
    "authors": [
      "Zongyu Li",
      "Zhenfeng Zhu",
      "Xiao bo Guo",
      "Shuai Zheng",
      "Zhenyu Guo",
      "Siwei Qiang",
      "Yao Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.08860"
  },
  {
    "id": "arXiv:2209.09090",
    "title": "Uncertainty-aware Efficient Subgraph Isomorphism using Graph Topology",
    "abstract": "Comments: Authors contributed equally. Names listed in alphabetical order",
    "descriptor": "\nComments: Authors contributed equally. Names listed in alphabetical order\n",
    "authors": [
      "Arpan Kusari",
      "Wenbo Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.09090"
  },
  {
    "id": "arXiv:2209.09367",
    "title": "Supporting Multi-Cloud in Serverless Computing",
    "abstract": "Comments: Accepted for the 15th IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC'22 Companion)",
    "descriptor": "\nComments: Accepted for the 15th IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC'22 Companion)\n",
    "authors": [
      "Haidong Zhao",
      "Zakaria Benomar",
      "Tobias Pfandzelter",
      "Nikolaos Georgantas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.09367"
  },
  {
    "id": "arXiv:2209.10811",
    "title": "IntereStyle: Encoding an Interest Region for Robust StyleGAN Inversion",
    "abstract": "IntereStyle: Encoding an Interest Region for Robust StyleGAN Inversion",
    "descriptor": "",
    "authors": [
      "Seungjun Moon",
      "Gyeong-Moon Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.10811"
  },
  {
    "id": "arXiv:2209.11572",
    "title": "Multi-Modal Cross-Domain Alignment Network for Video Moment Retrieval",
    "abstract": "Comments: Accepted by IEEE Transactions on Multimedia",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Multimedia\n",
    "authors": [
      "Xiang Fang",
      "Daizong Liu",
      "Pan Zhou",
      "Yuchong Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.11572"
  },
  {
    "id": "arXiv:2209.14946",
    "title": "EiHi Net: Out-of-Distribution Generalization Paradigm",
    "abstract": "EiHi Net: Out-of-Distribution Generalization Paradigm",
    "descriptor": "",
    "authors": [
      "Qinglai Wei",
      "Beiming Yuan",
      "Diancheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.14946"
  },
  {
    "id": "arXiv:2209.14997",
    "title": "Optimistic MLE -- A Generic Model-based Algorithm for Partially  Observable Sequential Decision Making",
    "abstract": "Optimistic MLE -- A Generic Model-based Algorithm for Partially  Observable Sequential Decision Making",
    "descriptor": "",
    "authors": [
      "Qinghua Liu",
      "Praneeth Netrapalli",
      "Csaba Szepesv\u00e1ri",
      "Chi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.14997"
  },
  {
    "id": "arXiv:2209.15605",
    "title": "Bias Mimicking: A Simple Sampling Approach for Bias Mitigation",
    "abstract": "Bias Mimicking: A Simple Sampling Approach for Bias Mitigation",
    "descriptor": "",
    "authors": [
      "Maan Qraitem",
      "Kate Saenko",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15605"
  },
  {
    "id": "arXiv:2210.00545",
    "title": "Seeing Through the Noisy Dark: Towards Real-world Low-Light Image  Enhancement and Denoising",
    "abstract": "Seeing Through the Noisy Dark: Towards Real-world Low-Light Image  Enhancement and Denoising",
    "descriptor": "",
    "authors": [
      "Jiahuan Ren",
      "Zhao Zhang",
      "Richang Hong",
      "Mingliang Xu",
      "Yi Yang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00545"
  },
  {
    "id": "arXiv:2210.00795",
    "title": "Hierarchical reinforcement learning for in-hand robotic manipulation  using Davenport chained rotations",
    "abstract": "Comments: 5 pages, 3 figures, 3 tables, submitted to ICARA 2023",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables, submitted to ICARA 2023\n",
    "authors": [
      "Francisco Roldan Sanchez",
      "Qiang Wang",
      "David Cordova Bulens",
      "Kevin McGuinness",
      "Stephen Redmond",
      "Noel O'Connor"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.00795"
  },
  {
    "id": "arXiv:2210.01596",
    "title": "Multi-marginal Approximation of the Linear Gromov-Wasserstein Distance",
    "abstract": "Multi-marginal Approximation of the Linear Gromov-Wasserstein Distance",
    "descriptor": "",
    "authors": [
      "Florian Beier",
      "Robert Beinert"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.01596"
  },
  {
    "id": "arXiv:2210.01971",
    "title": "Towards Efficient Modularity in Industrial Drying: A Combinatorial  Optimization Viewpoint",
    "abstract": "Towards Efficient Modularity in Industrial Drying: A Combinatorial  Optimization Viewpoint",
    "descriptor": "",
    "authors": [
      "Alisina Bayati",
      "Amber Srivastava",
      "Amir Malvandi",
      "Hao Feng",
      "Srinivasa Salapaka"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.01971"
  },
  {
    "id": "arXiv:2210.02976",
    "title": "A new efficient explicit Deferred Correction framework: analysis and  applications to hyperbolic PDEs and adaptivity",
    "abstract": "Comments: 52 pages and 48 figures in the main document 36 pages and 9 figures in the supplementary material",
    "descriptor": "\nComments: 52 pages and 48 figures in the main document 36 pages and 9 figures in the supplementary material\n",
    "authors": [
      "Lorenzo Micalizzi",
      "Davide Torlo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02976"
  },
  {
    "id": "arXiv:2210.03064",
    "title": "A Toolkit for Robust Thresholds",
    "abstract": "Comments: 39 pages. Improved exposition and corrected typos",
    "descriptor": "\nComments: 39 pages. Improved exposition and corrected typos\n",
    "authors": [
      "Huy Tuan Pham",
      "Ashwin Sah",
      "Mehtaab Sawhney",
      "Michael Simkin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.03064"
  },
  {
    "id": "arXiv:2210.03495",
    "title": "Total Variation-Based Reconstruction and Phase Retrieval for Diffraction  Tomography with an Arbitrarily Moving Object",
    "abstract": "Total Variation-Based Reconstruction and Phase Retrieval for Diffraction  Tomography with an Arbitrarily Moving Object",
    "descriptor": "",
    "authors": [
      "Robert Beinert",
      "Michael Quellmalz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.03495"
  },
  {
    "id": "arXiv:2210.03797",
    "title": "Named Entity Recognition in Twitter: A Dataset and Analysis on  Short-Term Temporal Shifts",
    "abstract": "Comments: AACL 2022 main conference",
    "descriptor": "\nComments: AACL 2022 main conference\n",
    "authors": [
      "Asahi Ushio",
      "Leonardo Neves",
      "Vitor Silva",
      "Francesco Barbieri",
      "Jose Camacho-Collados"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.03797"
  },
  {
    "id": "arXiv:2210.04339",
    "title": "Seller-buyer networks in NFT art are driven by preferential ties",
    "abstract": "Seller-buyer networks in NFT art are driven by preferential ties",
    "descriptor": "",
    "authors": [
      "Giovanni Colavizza"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.04339"
  },
  {
    "id": "arXiv:2210.05098",
    "title": "IsoVec: Controlling the Relative Isomorphism of Word Embedding Spaces",
    "abstract": "Comments: Updated EMNLP2022 Camera Ready (Spelling correction, clearer image)",
    "descriptor": "\nComments: Updated EMNLP2022 Camera Ready (Spelling correction, clearer image)\n",
    "authors": [
      "Kelly Marchisio",
      "Neha Verma",
      "Kevin Duh",
      "Philipp Koehn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05098"
  },
  {
    "id": "arXiv:2210.07335",
    "title": "FOON Creation and Traversal for Recipe Generation",
    "abstract": "FOON Creation and Traversal for Recipe Generation",
    "descriptor": "",
    "authors": [
      "Raj Patel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07335"
  },
  {
    "id": "arXiv:2210.07930",
    "title": "Machine learning frontier orbital energies of nanodiamonds",
    "abstract": "Machine learning frontier orbital energies of nanodiamonds",
    "descriptor": "",
    "authors": [
      "Thorren Kirschbaum",
      "B\u00f6rries von Seggern",
      "Joachim Dzubiella",
      "Annika Bande",
      "Frank No\u00e9"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07930"
  },
  {
    "id": "arXiv:2210.08248",
    "title": "A Closer Look at the Calibration of Differentially Private Learners",
    "abstract": "Comments: NeurIPS 2022 Workshop on Algorithmic Fairness through the Lens of Causality and Privacy",
    "descriptor": "\nComments: NeurIPS 2022 Workshop on Algorithmic Fairness through the Lens of Causality and Privacy\n",
    "authors": [
      "Hanlin Zhang",
      "Xuechen Li",
      "Prithviraj Sen",
      "Salim Roukos",
      "Tatsunori Hashimoto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08248"
  },
  {
    "id": "arXiv:2210.09974",
    "title": "Theoretical Guarantees for Permutation-Equivariant Quantum Neural  Networks",
    "abstract": "Comments: 15+21 pages, 5 + 5 figures. Prior generalization bounds replaced with more general theorem",
    "descriptor": "\nComments: 15+21 pages, 5 + 5 figures. Prior generalization bounds replaced with more general theorem\n",
    "authors": [
      "Louis Schatzki",
      "Martin Larocca",
      "Quynh T. Nguyen",
      "Frederic Sauvage",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.09974"
  },
  {
    "id": "arXiv:2210.11435",
    "title": "Learning and Retrieval from Prior Data for Skill-based Imitation  Learning",
    "abstract": "Comments: Conference on Robot Learning (CoRL), 2022",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL), 2022\n",
    "authors": [
      "Soroush Nasiriany",
      "Tian Gao",
      "Ajay Mandlekar",
      "Yuke Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.11435"
  },
  {
    "id": "arXiv:2210.12495",
    "title": "Quartic Samples Suffice for Fourier Interpolation",
    "abstract": "Quartic Samples Suffice for Fourier Interpolation",
    "descriptor": "",
    "authors": [
      "Zhao Song",
      "Baocheng Sun",
      "Omri Weinstein",
      "Ruizhe Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.12495"
  },
  {
    "id": "arXiv:2210.13772",
    "title": "Deformations of Boltzmann Distributions",
    "abstract": "Comments: Machine Learning for the Physical Sciences Workshop at NeurIPS '22",
    "descriptor": "\nComments: Machine Learning for the Physical Sciences Workshop at NeurIPS '22\n",
    "authors": [
      "B\u00e1lint M\u00e1t\u00e9",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.13772"
  },
  {
    "id": "arXiv:2210.13952",
    "title": "KnowGL: Knowledge Generation and Linking from Text",
    "abstract": "Comments: AAAI-23 Demo Track",
    "descriptor": "\nComments: AAAI-23 Demo Track\n",
    "authors": [
      "Gaetano Rossiello",
      "Md. Mahabub Faisal Chowdhury",
      "Nandana Mihindukulasooriya",
      "Owen Cornec",
      "Alfio Massimiliano Gliozzo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.13952"
  },
  {
    "id": "arXiv:2210.14353",
    "title": "RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question  Answering",
    "abstract": "Comments: The source code and evaluation for RoMQA are at this https URL",
    "descriptor": "\nComments: The source code and evaluation for RoMQA are at this https URL\n",
    "authors": [
      "Victor Zhong",
      "Weijia Shi",
      "Wen-tau Yih",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.14353"
  },
  {
    "id": "arXiv:2210.14896",
    "title": "DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image  Generative Models",
    "abstract": "Comments: 14 pages, 5 figures. The dataset is available at this https URL The code is at this https URL",
    "descriptor": "\nComments: 14 pages, 5 figures. The dataset is available at this https URL The code is at this https URL\n",
    "authors": [
      "Zijie J. Wang",
      "Evan Montoya",
      "David Munechika",
      "Haoyang Yang",
      "Benjamin Hoover",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14896"
  },
  {
    "id": "arXiv:2210.16251",
    "title": "Latent Space is Feature Space: Regularization Term for GANs Training on  Limited Dataset",
    "abstract": "Comments: 8 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 8 pages, 6 figures, 2 tables\n",
    "authors": [
      "Pengwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16251"
  },
  {
    "id": "arXiv:2210.16513",
    "title": "Mapping state transition susceptibility in reverse annealing",
    "abstract": "Comments: V2: Typo fixes",
    "descriptor": "\nComments: V2: Typo fixes\n",
    "authors": [
      "Elijah Pelofske"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.16513"
  },
  {
    "id": "arXiv:2210.17406",
    "title": "Emergent Linguistic Structures in Neural Networks are Fragile",
    "abstract": "Emergent Linguistic Structures in Neural Networks are Fragile",
    "descriptor": "",
    "authors": [
      "Emanuele La Malfa",
      "Matthew Wicker",
      "Marta Kiatkowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.17406"
  },
  {
    "id": "arXiv:2211.02250",
    "title": "Real-Time Target Sound Extraction",
    "abstract": "Real-Time Target Sound Extraction",
    "descriptor": "",
    "authors": [
      "Bandhav Veluri",
      "Justin Chan",
      "Malek Itani",
      "Tuochao Chen",
      "Takuya Yoshioka",
      "Shyamnath Gollakota"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02250"
  },
  {
    "id": "arXiv:2211.02579",
    "title": "V2X Misbehavior in Maneuver Sharing and Coordination Service:  Considerations for Standardization",
    "abstract": "Comments: 7 pages, 4 figures, 4 tables, IEEE CSCN 2022. arXiv admin note: text overlap with arXiv:2112.02184",
    "descriptor": "\nComments: 7 pages, 4 figures, 4 tables, IEEE CSCN 2022. arXiv admin note: text overlap with arXiv:2112.02184\n",
    "authors": [
      "Jean-Philippe Monteuuis",
      "Jonathan Petit",
      "Mohammad Raashid Ansari",
      "Cong Chen",
      "Seung Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.02579"
  },
  {
    "id": "arXiv:2211.02943",
    "title": "Predicting Treatment Adherence of Tuberculosis Patients at Scale",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Mihir Kulkarni",
      "Satvik Golechha",
      "Rishi Raj",
      "Jithin Sreedharan",
      "Ankit Bhardwaj",
      "Santanu Rathod",
      "Bhavin Vadera",
      "Jayakrishna Kurada",
      "Sanjay Mattoo",
      "Rajendra Joshi",
      "Kirankumar Rade",
      "Alpan Raval"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02943"
  },
  {
    "id": "arXiv:2211.03055",
    "title": "Learning Dual-Fused Modality-Aware Representations for RGBD Tracking",
    "abstract": "Learning Dual-Fused Modality-Aware Representations for RGBD Tracking",
    "descriptor": "",
    "authors": [
      "Shang Gao",
      "Jinyu Yang",
      "Zhe Li",
      "Feng Zheng",
      "Ale\u0161 Leonardis",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03055"
  },
  {
    "id": "arXiv:2211.03242",
    "title": "Fast Key Points Detection and Matching for Tree-Structured Images",
    "abstract": "Fast Key Points Detection and Matching for Tree-Structured Images",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Xiwen Chen",
      "Abolfazl Razi",
      "Rahul Amin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03242"
  },
  {
    "id": "arXiv:2211.03282",
    "title": "Performance and utility trade-off in interpretable sleep staging",
    "abstract": "Comments: Spotlight paper at NeurIPS 2022 Workshop on Learning from Time Series for Health",
    "descriptor": "\nComments: Spotlight paper at NeurIPS 2022 Workshop on Learning from Time Series for Health\n",
    "authors": [
      "Irfan Al-Hussaini",
      "Cassie S. Mitchell"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03282"
  },
  {
    "id": "arXiv:2211.04171",
    "title": "The Hypervolume Indicator Hessian Matrix: Analytical Expression,  Computational Time Complexity, and Sparsity",
    "abstract": "The Hypervolume Indicator Hessian Matrix: Analytical Expression,  Computational Time Complexity, and Sparsity",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 H. Deutz",
      "Michael T.M. Emmerich",
      "Hao Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04171"
  },
  {
    "id": "arXiv:2211.04242",
    "title": "Impact of Virtual Inertia on DC Grid Stability with Constant Power Loads",
    "abstract": "Impact of Virtual Inertia on DC Grid Stability with Constant Power Loads",
    "descriptor": "",
    "authors": [
      "Hao Tu",
      "Hui Yu",
      "Srdjan Lukic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04242"
  },
  {
    "id": "arXiv:2211.04627",
    "title": "Computing (1+epsilon)-Approximate Degeneracy in Sublinear Time",
    "abstract": "Computing (1+epsilon)-Approximate Degeneracy in Sublinear Time",
    "descriptor": "",
    "authors": [
      "Valerie King",
      "Alex Thomo",
      "Quinton Yong"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04627"
  },
  {
    "id": "arXiv:2211.04898",
    "title": "Mask More and Mask Later: Efficient Pre-training of Masked Language  Models by Disentangling the [MASK] Token",
    "abstract": "Comments: Code available at: this https URL",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Baohao Liao",
      "David Thulke",
      "Sanjika Hewavitharana",
      "Hermann Ney",
      "Christof Monz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04898"
  },
  {
    "id": "arXiv:2211.05207",
    "title": "Mapping the Ictal-Interictal-Injury Continuum Using Interpretable  Machine Learning",
    "abstract": "Comments: 16 pages, draft to be submitted for peer review",
    "descriptor": "\nComments: 16 pages, draft to be submitted for peer review\n",
    "authors": [
      "Alina Jade Barnett",
      "Zhicheng Guo",
      "Jin Jing",
      "Wendong Ge",
      "Cynthia Rudin",
      "M. Brandon Westover"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05207"
  },
  {
    "id": "arXiv:2211.05239",
    "title": "RecD: Deduplication for End-to-End Deep Learning Recommendation Model  Training Infrastructure",
    "abstract": "RecD: Deduplication for End-to-End Deep Learning Recommendation Model  Training Infrastructure",
    "descriptor": "",
    "authors": [
      "Mark Zhao",
      "Dhruv Choudhary",
      "Devashish Tyagi",
      "Ajay Somani",
      "Max Kaplan",
      "Sung-Han Lin",
      "Sarunya Pumma",
      "Jongsoo Park",
      "Aarti Basant",
      "Niket Agarwal",
      "Carole-Jean Wu",
      "Christos Kozyrakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.05239"
  },
  {
    "id": "arXiv:2211.05633",
    "title": "Transfer learning and Local interpretable model agnostic based visual  approach in Monkeypox Disease Detection and Classification: A Deep Learning  insights",
    "abstract": "Comments: We have removed the picture of the children from Figure 1 as we found it not to be appropriate or necessarily important",
    "descriptor": "\nComments: We have removed the picture of the children from Figure 1 as we found it not to be appropriate or necessarily important\n",
    "authors": [
      "Md Manjurul Ahsan",
      "Tareque Abu Abdullah",
      "Md Shahin Ali",
      "Fatematuj Jahora",
      "Md Khairul Islam",
      "Amin G. Alhashim",
      "Kishor Datta Gupta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05633"
  },
  {
    "id": "arXiv:2211.05908",
    "title": "Accelerating Irregular Applications via Efficient Synchronization and  Data Access Techniques",
    "abstract": "Comments: PhD Thesis",
    "descriptor": "\nComments: PhD Thesis\n",
    "authors": [
      "Christina Giannoula"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.05908"
  },
  {
    "id": "arXiv:2211.05939",
    "title": "pyRDDLGym: From RDDL to Gym Environments",
    "abstract": "pyRDDLGym: From RDDL to Gym Environments",
    "descriptor": "",
    "authors": [
      "Ayal Taitler",
      "Michael Gimelfarb",
      "Sriram Gopalakrishnan",
      "Xiaotian Liu",
      "Scott Sanner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05939"
  },
  {
    "id": "arXiv:2211.06665",
    "title": "A Survey on Explainable Reinforcement Learning: Concepts, Algorithms,  Challenges",
    "abstract": "A Survey on Explainable Reinforcement Learning: Concepts, Algorithms,  Challenges",
    "descriptor": "",
    "authors": [
      "Yunpeng Qing",
      "Shunyu Liu",
      "Jie Song",
      "Mingli Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.06665"
  },
  {
    "id": "arXiv:2211.06774",
    "title": "Large-Scale Bidirectional Training for Zero-Shot Image Captioning",
    "abstract": "Comments: Arxiv Preprint. Work in progress",
    "descriptor": "\nComments: Arxiv Preprint. Work in progress\n",
    "authors": [
      "Taehoon Kim",
      "Mark Marsden",
      "Pyunghwan Ahn",
      "Sangyun Kim",
      "Sihaeng Lee",
      "Alessandra Sala",
      "Seung Hwan Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.06774"
  },
  {
    "id": "arXiv:2211.06866",
    "title": "Mining Unseen Classes via Regional Objectness: A Simple Baseline for  Incremental Segmentation",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Zekang Zhang",
      "Guangyu Gao",
      "Zhiyuan Fang",
      "Jianbo Jiao",
      "Yunchao Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06866"
  },
  {
    "id": "arXiv:2211.06869",
    "title": "What would Harry say? Building Dialogue Agents for Characters in a Story",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Nuo Chen",
      "Yan Wang",
      "Haiyun Jiang",
      "Deng Cai",
      "Ziyang Chen",
      "Jia Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.06869"
  },
  {
    "id": "arXiv:2211.06924",
    "title": "A Tale of Two Graphs: Freezing and Denoising Graph Structures for  Multimodal Recommendation",
    "abstract": "Comments: 12 pages, 4 figures, working report",
    "descriptor": "\nComments: 12 pages, 4 figures, working report\n",
    "authors": [
      "Xin Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.06924"
  },
  {
    "id": "arXiv:2211.06956",
    "title": "Seeing Beyond the Brain: Conditional Diffusion Model with Sparse Masked  Modeling for Vision Decoding",
    "abstract": "Comments: 8 pages, 9 figures, 2 tables, submitted to anonymous conference, see this https URL for more information",
    "descriptor": "\nComments: 8 pages, 9 figures, 2 tables, submitted to anonymous conference, see this https URL for more information\n",
    "authors": [
      "Zijiao Chen",
      "Jiaxin Qing",
      "Tiange Xiang",
      "Wan Lin Yue",
      "Juan Helen Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06956"
  },
  {
    "id": "arXiv:2211.07084",
    "title": "Boosting Semi-Supervised 3D Object Detection with Semi-Sampling",
    "abstract": "Boosting Semi-Supervised 3D Object Detection with Semi-Sampling",
    "descriptor": "",
    "authors": [
      "Xiaopei Wu",
      "Yang Zhao",
      "Liang Peng",
      "Hua Chen",
      "Xiaoshui Huang",
      "Binbin Lin",
      "Haifeng Liu",
      "Deng Cai",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07084"
  },
  {
    "id": "arXiv:2211.07088",
    "title": "Recognition of Cardiac MRI Orientation via Deep Neural Networks and a  Method to Improve Prediction Accuracy",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2011.08761 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2011.08761 by other authors\n",
    "authors": [
      "Houxin Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07088"
  },
  {
    "id": "arXiv:2211.07092",
    "title": "Offline Estimation of Controlled Markov Chains: Minimax Nonparametric  Estimators and Sample Efficiency",
    "abstract": "Comments: 67 pages, 23 main-47 appendix",
    "descriptor": "\nComments: 67 pages, 23 main-47 appendix\n",
    "authors": [
      "Imon Banerjee",
      "Harsha Honnappa",
      "Vinayak Rao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.07092"
  },
  {
    "id": "arXiv:2211.07098",
    "title": "Knowledge Base Completion using Web-Based Question Answering and  Multimodal Fusion",
    "abstract": "Knowledge Base Completion using Web-Based Question Answering and  Multimodal Fusion",
    "descriptor": "",
    "authors": [
      "Yang Peng",
      "Daisy Zhe Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07098"
  },
  {
    "id": "arXiv:2211.07214",
    "title": "Robust Collaborative 3D Object Detection in Presence of Pose Errors",
    "abstract": "Robust Collaborative 3D Object Detection in Presence of Pose Errors",
    "descriptor": "",
    "authors": [
      "Yifan Lu",
      "Quanhao Li",
      "Baoan Liu",
      "Mehrdad Dianati",
      "Chen Feng",
      "Siheng Chen",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.07214"
  },
  {
    "id": "arXiv:2211.07263",
    "title": "Efficient Adversarial Training with Robust Early-Bird Tickets",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Zhiheng Xi",
      "Rui Zheng",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07263"
  },
  {
    "id": "arXiv:2211.07390",
    "title": "StereoISP: Rethinking Image Signal Processing for Dual Camera Systems",
    "abstract": "StereoISP: Rethinking Image Signal Processing for Dual Camera Systems",
    "descriptor": "",
    "authors": [
      "Ahmad Bin Rabiah",
      "Qi Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07390"
  },
  {
    "id": "arXiv:2211.07436",
    "title": "Giving RSEs a Larger Stage through the Better Scientific Software  Fellowship",
    "abstract": "Comments: submitted to Computing in Science & Engineering (CiSE), Special Issue on the Future of Research Software Engineers in the US",
    "descriptor": "\nComments: submitted to Computing in Science & Engineering (CiSE), Special Issue on the Future of Research Software Engineers in the US\n",
    "authors": [
      "William F. Godoy",
      "Ritu Arora",
      "Keith Beattie",
      "David E. Bernholdt",
      "Sarah E. Bratt",
      "Daniel S. Katz",
      "Ignacio Laguna",
      "Amiya K. Maji",
      "Addi Malviya Thakur",
      "Rafael M. Mudafort",
      "Nitin Sukhija",
      "Damian Rouson",
      "Cindy Rubio-Gonz\u00e1lez",
      "Karan Vahi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.07436"
  },
  {
    "id": "arXiv:2211.07542",
    "title": "On Consistency for Bulk-Bitwise Processing-in-Memory",
    "abstract": "Comments: To be published in the 29th IEEE International Symposium on High-Performance Computer Architecture (HPCA-29)",
    "descriptor": "\nComments: To be published in the 29th IEEE International Symposium on High-Performance Computer Architecture (HPCA-29)\n",
    "authors": [
      "Ben Perach",
      "Ronny Ronnen",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.07542"
  },
  {
    "id": "arXiv:2211.07547",
    "title": "On the Smoothed Complexity of Combinatorial Local Search",
    "abstract": "On the Smoothed Complexity of Combinatorial Local Search",
    "descriptor": "",
    "authors": [
      "Yiannis Giannakopoulos",
      "Alexander Grosz",
      "Themistoklis Melissourgos"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.07547"
  },
  {
    "id": "arXiv:2211.07549",
    "title": "Phenotype Detection in Real World Data via Online MixEHR Algorithm",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 6 pages",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 6 pages\n",
    "authors": [
      "Ying Xu",
      "Romane Gauriau",
      "Anna Decker",
      "Jacob Oppenheim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07549"
  }
]